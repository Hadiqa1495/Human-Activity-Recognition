{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from keras.applications.resnet_v2 import ResNet101V2\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "from scipy import stats as s\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_RGB = ResNet101V2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model_RGB = Sequential()\n",
    "model_RGB.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model_RGB.add(Dropout(0.5))\n",
    "model_RGB.add(Dense(512, activation='relu'))\n",
    "model_RGB.add(Dropout(0.5))\n",
    "model_RGB.add(Dense(256, activation='relu'))\n",
    "model_RGB.add(Dropout(0.5))\n",
    "model_RGB.add(Dense(128, activation='relu'))\n",
    "model_RGB.add(Dropout(0.5))\n",
    "model_RGB.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the trained weights\n",
    "model_RGB.load_weights(\"../Models/weightResNet101V2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_RGB.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_OF = ResNet101V2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model_OF = Sequential()\n",
    "model_OF.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model_OF.add(Dropout(0.5))\n",
    "model_OF.add(Dense(512, activation='relu'))\n",
    "model_OF.add(Dropout(0.5))\n",
    "model_OF.add(Dense(256, activation='relu'))\n",
    "model_OF.add(Dropout(0.5))\n",
    "model_OF.add(Dense(128, activation='relu'))\n",
    "model_OF.add(Dropout(0.5))\n",
    "model_OF.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the trained weights\n",
    "model_OF.load_weights(\"../Models/weightResNet101V2_OF.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_OF.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brush_hair', 'cartwheel', 'catch', 'chew', 'clap', 'climb', 'climb_stairs', 'dive', 'draw_sword', 'dribble', 'drink', 'eat', 'fall_floor', 'fencing', 'flic_flac', 'golf', 'handstand', 'hit', 'hug', 'jump', 'kick', 'kick_ball', 'kiss', 'laugh', 'pick', 'pour', 'pullup', 'punch', 'push', 'pushup', 'ride_bike', 'ride_horse', 'run', 'shake_hands', 'shoot_ball', 'shoot_bow', 'shoot_gun', 'sit', 'situp', 'smile', 'smoke', 'somersault', 'stand', 'swing_baseball', 'sword', 'sword_exercise', 'talk', 'throw', 'turn', 'walk', 'wave']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brush_hair/April_09_brush_hair_u_nm_np1_ba_goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brush_hair/April_09_brush_hair_u_nm_np1_ba_goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brush_hair/April_09_brush_hair_u_nm_np1_ba_goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brush_hair/Blonde_being_brushed_brush_hair_f_n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brush_hair/Blonde_being_brushed_brush_hair_u_c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          video_name\n",
       "0  brush_hair/April_09_brush_hair_u_nm_np1_ba_goo...\n",
       "1  brush_hair/April_09_brush_hair_u_nm_np1_ba_goo...\n",
       "2  brush_hair/April_09_brush_hair_u_nm_np1_ba_goo...\n",
       "3  brush_hair/Blonde_being_brushed_brush_hair_f_n...\n",
       "4  brush_hair/Blonde_being_brushed_brush_hair_u_c..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location='../data/test'\n",
    "classes=[]\n",
    "videos=[]\n",
    "test=pd.DataFrame()\n",
    "for foldername in sorted(os.listdir(location)):\n",
    "    classes.append(foldername)\n",
    "    for files in sorted(os.listdir(location+'/'+foldername)):\n",
    "        videos.append(foldername+'/'+files)\n",
    "test['video_name']=videos\n",
    "print(classes)\n",
    "test_videos=test['video_name']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the tags\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "y = train['class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1530/1530 [3:10:56<00:00,  5.36s/it]  \n"
     ]
    }
   ],
   "source": [
    "# creating two lists to store predicted and actual tags\n",
    "predict = []\n",
    "actual = []\n",
    "\n",
    "# for loop to extract frames from each test video\n",
    "for i in tqdm(range(test_videos.shape[0])):\n",
    "    count = 0\n",
    "    videoFile = test_videos[i]\n",
    "    # print('../data/test/'+videoFile)\n",
    "    cap = cv2.VideoCapture('../data/test/'+videoFile.split(' ')[0].split('/')[0]+'/'+videoFile.split(' ')[0].split('/')[1])   # capturing the video from the given path\n",
    "    \n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    x=1\n",
    "    # removing all other files from the temp folder\n",
    "    files = glob('../data/temp/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if (frameId % math.floor(frameRate) == 0):\n",
    "            # storing the frames of this particular video in temp folder\n",
    "#            print('../data/temp/' + \"_frame%d.jpg\" % count)\n",
    "            filename ='../data/temp/' + \"_frame%d.jpg\" % count;count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(\"../data/temp/*.jpg\")\n",
    "    \n",
    "    rgb_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(224,224,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255\n",
    "        rgb_images.append(img)\n",
    "        \n",
    "    # print(test_images.shape)\n",
    "    prediction=[]\n",
    "    # converting all the frames for a test video into numpy array\n",
    "    rgb_images = np.array(rgb_images)     \n",
    "    # extracting features using pre-trained model\n",
    "    prediction_images = base_model_RGB.predict(rgb_images)\n",
    "    # converting features in one dimensional array\n",
    "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*2048)\n",
    "    # predicting tags for each array\n",
    "    prediction_RGB = model_RGB.predict_classes(prediction_images)\n",
    "    \n",
    "    cap = cv2.VideoCapture('../data/test/'+videoFile.split(' ')[0].split('/')[0]+'/'+videoFile.split(' ')[0].split('/')[1])   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "#    print(frameRate)\n",
    "    frameRate=frameRate/2\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#    print(length)\n",
    "    \n",
    "    ret, frame1 = cap.read()  \n",
    "    prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    hsv = np.zeros_like(frame1)\n",
    "    hsv[...,1] = 255\n",
    "    x=1\n",
    "    \n",
    "    # removing all other files from the temp folder\n",
    "    files = glob('../data/temp/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    \n",
    "    #Iterate through every frame\n",
    "    while(x<length):        \n",
    "        count = count + 1        \n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame2 = cap.read()\n",
    "        x+=1\n",
    "        \n",
    "        if (ret != True):\n",
    "            break\n",
    "            \n",
    "        #Select frames according to frame rate\n",
    "        if (frameId % math.floor(frameRate) == 0):   \n",
    "            # storing the frames in a new folder named train_1\n",
    "            next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "            flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "            hsv[...,0] = ang*180/np.pi/2\n",
    "            hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "            rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "            \n",
    "            filename ='../data/temp/' + \"_flow%d.jpg\" % count;\n",
    "            cv2.imwrite(filename, rgb)\n",
    "    cap.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(\"../data/temp/*.jpg\")\n",
    "    \n",
    "    of_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(224,224,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img=img/255\n",
    "        of_images.append(img)\n",
    "\n",
    "    # converting all the frames for a test video into numpy array\n",
    "    of_images = np.array(of_images)\n",
    "    # print(prediction_images.shape)\n",
    "    # extracting features using pre-trained model\n",
    "    prediction_images = base_model_OF.predict(of_images)\n",
    "    # converting features in one dimensional array\n",
    "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*2048)\n",
    "    # predicting tags for each array\n",
    "    prediction_OF = model_OF.predict_classes(prediction_images)\n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    prediction=np.concatenate((prediction_RGB,prediction_OF))\n",
    "    \n",
    "    predict.append(y.columns.values[s.mode(prediction)[0][0]])\n",
    "    # print(predict)\n",
    "    # appending the actual tag of the video\n",
    "    actual.append(videoFile.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.169934640522875"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the accuracy of the predicted tags\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    brush_hair       0.20      0.43      0.27        30\n",
      "     cartwheel       0.23      0.10      0.14        30\n",
      "         catch       0.64      0.47      0.54        30\n",
      "          chew       0.30      0.60      0.40        30\n",
      "          clap       0.00      0.00      0.00        30\n",
      "         climb       0.21      0.63      0.31        30\n",
      "  climb_stairs       0.52      0.40      0.45        30\n",
      "          dive       0.35      0.20      0.26        30\n",
      "    draw_sword       0.34      0.47      0.39        30\n",
      "       dribble       0.71      0.80      0.75        30\n",
      "         drink       0.05      0.03      0.04        30\n",
      "           eat       0.18      0.57      0.28        30\n",
      "    fall_floor       0.23      0.27      0.25        30\n",
      "       fencing       0.53      0.30      0.38        30\n",
      "     flic_flac       0.25      0.07      0.11        30\n",
      "          golf       0.36      0.83      0.50        30\n",
      "     handstand       0.15      0.20      0.17        30\n",
      "           hit       0.00      0.00      0.00        30\n",
      "           hug       0.77      0.33      0.47        30\n",
      "          jump       0.17      0.03      0.06        30\n",
      "          kick       0.00      0.00      0.00        30\n",
      "     kick_ball       0.00      0.00      0.00        30\n",
      "          kiss       0.24      0.53      0.33        30\n",
      "         laugh       0.18      0.50      0.26        30\n",
      "          pick       0.00      0.00      0.00        30\n",
      "          pour       0.52      0.73      0.61        30\n",
      "        pullup       0.72      0.43      0.54        30\n",
      "         punch       0.38      0.20      0.26        30\n",
      "          push       0.71      0.33      0.45        30\n",
      "        pushup       0.67      0.13      0.22        30\n",
      "     ride_bike       0.29      0.63      0.40        30\n",
      "    ride_horse       0.15      0.80      0.25        30\n",
      "           run       0.00      0.00      0.00        30\n",
      "   shake_hands       0.60      0.30      0.40        30\n",
      "    shoot_ball       0.39      0.40      0.39        30\n",
      "     shoot_bow       0.63      0.57      0.60        30\n",
      "     shoot_gun       0.26      0.23      0.25        30\n",
      "           sit       0.00      0.00      0.00        30\n",
      "         situp       0.55      0.57      0.56        30\n",
      "         smile       0.50      0.03      0.06        30\n",
      "         smoke       0.38      0.20      0.26        30\n",
      "    somersault       0.28      0.33      0.30        30\n",
      "         stand       0.00      0.00      0.00        30\n",
      "swing_baseball       0.10      0.03      0.05        30\n",
      "         sword       0.00      0.00      0.00        30\n",
      "sword_exercise       0.00      0.00      0.00        30\n",
      "          talk       0.18      0.40      0.25        30\n",
      "         throw       0.03      0.03      0.03        30\n",
      "          turn       0.00      0.00      0.00        30\n",
      "          walk       0.26      0.23      0.25        30\n",
      "          wave       0.00      0.00      0.00        30\n",
      "\n",
      "      accuracy                           0.28      1530\n",
      "     macro avg       0.28      0.28      0.24      1530\n",
      "  weighted avg       0.28      0.28      0.24      1530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(actual,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0 ...  0  0  0]\n",
      " [ 1  3  0 ...  0  0  0]\n",
      " [ 1  0 14 ...  0  0  0]\n",
      " ...\n",
      " [ 3  0  0 ...  0  3  0]\n",
      " [ 1  0  0 ...  0  7  0]\n",
      " [ 1  1  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "cm=metrics.confusion_matrix(actual,predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Accuracy score: 28.169934640522875')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square=True, cmap=\"Blues_r\");\n",
    "plt.ylabel(\"Actual label\");\n",
    "plt.xlabel(\"Predicted label\")\n",
    "all_sample_title=\"Accuracy score: {0}\".format(metrics.accuracy_score(predict, actual)*100)\n",
    "plt.title(all_sample_title,size=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
