{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42373</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_flow6.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42374</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_flow7.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42375</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_flow7.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42376</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_flow8.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42377</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_flow8.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image class\n",
       "42373  winKen_wave_u_cm_np1_ri_bad_1_flow6.jpg  wave\n",
       "42374  winKen_wave_u_cm_np1_ri_bad_1_flow7.jpg  wave\n",
       "42375  winKen_wave_u_cm_np1_ri_bad_1_flow7.jpg  wave\n",
       "42376  winKen_wave_u_cm_np1_ri_bad_1_flow8.jpg  wave\n",
       "42377  winKen_wave_u_cm_np1_ri_bad_1_flow8.jpg  wave"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_OF.csv')\n",
    "train.sort_values(by=['class', 'image'])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42378/42378 [03:14<00:00, 217.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/train_frame_OF/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42378, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X_train = np.array(train_image,np.float16)\n",
    "\n",
    "# shape of the array\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8799</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8800</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8801</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8802</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image class\n",
       "8798  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "8799  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "8800  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "8801  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "8802  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.read_csv('../data/val_OF.csv')\n",
    "val.sort_values(by=['class', 'image'])\n",
    "val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8803/8803 [00:55<00:00, 157.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "val_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(val.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/val_frame_OF/'+val['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    val_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8803, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X_test = np.array(val_image,np.float16)\n",
    "\n",
    "# shape of the array\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image    21189\n",
      "class       51\n",
      "dtype: int64\n",
      "image    8803\n",
      "class      51\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# separating the target\n",
    "y_train = train['class']\n",
    "y_test = val['class']\n",
    "print(train.nunique())\n",
    "print(val.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42378, 51)\n",
      "(8803, 51)\n"
     ]
    }
   ],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, None, None, 6 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, None, None, 6 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, None, None, 6 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, None, None, 6 0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 6 256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, None, None, 6 0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 1 8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 1 512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 1 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, None, None, 9 0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, None, None, 9 384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, None, None, 9 0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 1 12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 1 512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 1 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, None, None, 1 0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, None, None, 1 512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, None, None, 1 0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 1 16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 1 512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 1 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, None, None, 1 0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, None, None, 1 640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, None, None, 1 0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, None, None, 1 20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, None, None, 1 512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, None, None, 1 0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, None, None, 1 0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, None, None, 1 768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, None, None, 1 0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, None, None, 1 24576       conv2_block5_0_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, None, None, 1 512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, None, None, 1 0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, None, None, 2 0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, None, None, 2 896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, None, None, 2 0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, None, None, 1 28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, None, None, 1 512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, None, None, 1 0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, None, None, 2 0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, None, None, 2 1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, None, None, 2 0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, None, None, 1 32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, None, None, 1 0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 1 512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, None, None, 1 0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, None, None, 1 0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, None, None, 1 640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, None, None, 1 0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, None, None, 1 0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, None, None, 1 768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, None, None, 1 0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, None, None, 2 0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, None, None, 2 896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, None, None, 2 0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, None, None, 2 0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, None, None, 2 1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, None, None, 2 0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, None, None, 1 512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, None, None, 1 0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, None, None, 2 0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, None, None, 2 1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, None, None, 2 0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, None, None, 1 36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, None, None, 1 512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, None, None, 1 0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, None, None, 3 0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, None, None, 3 1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, None, None, 3 0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, None, None, 1 40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, None, None, 1 512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, None, None, 1 0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, None, None, 3 0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, None, None, 3 1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, None, None, 3 0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, None, None, 1 45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, None, None, 1 512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, None, None, 1 0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, None, None, 3 0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, None, None, 3 1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, None, None, 3 0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, None, None, 1 49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, None, None, 1 512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, None, None, 1 0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block9_1_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, None, None, 4 0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, None, None, 4 1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, None, None, 4 0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, None, None, 1 53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, None, None, 1 512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, None, None, 1 0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, None, None, 3 36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, None, None, 4 0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, None, None, 4 1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, None, None, 4 0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, None, None, 1 57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, None, None, 1 512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, None, None, 1 0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, None, None, 3 36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, None, None, 4 0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, None, None, 4 1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, None, None, 4 0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, None, None, 1 61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, None, None, 1 512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, None, None, 1 0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, None, None, 3 36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, None, None, 5 0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, None, None, 5 2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, None, None, 5 0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, None, None, 2 131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, None, None, 2 0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 2 1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, None, None, 2 0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 1 512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 1 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, None, None, 2 0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, None, None, 2 1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, None, None, 2 0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 1 36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 1 512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 1 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, None, None, 3 0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, None, None, 3 1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, None, None, 3 0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 1 40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 1 512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 1 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, None, None, 3 0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, None, None, 3 1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, None, None, 3 0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 1 45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 1 512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 1 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, None, None, 3 0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, None, None, 3 1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, None, None, 3 0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 1 49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 1 512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 1 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, None, None, 4 0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, None, None, 4 1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, None, None, 4 0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 1 53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 1 512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 1 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, None, None, 4 0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, None, None, 4 1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, None, None, 4 0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, None, None, 1 57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, None, None, 1 512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, None, None, 1 0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, None, None, 4 0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, None, None, 4 1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block8_0_relu (Activation (None, None, None, 4 0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, None, None, 1 61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, None, None, 1 512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, None, None, 1 0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, None, None, 5 0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, None, None, 5 2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, None, None, 5 0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, None, None, 1 65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, None, None, 1 512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, None, None, 1 0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, None, None, 5 0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, None, None, 5 2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, None, None, 5 0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, None, None, 1 69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, None, None, 1 512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, None, None, 1 0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, None, None, 5 0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, None, None, 5 2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, None, None, 5 0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, None, None, 1 73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, None, None, 1 512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, None, None, 1 0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, None, None, 6 0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, None, None, 6 2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, None, None, 6 0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, None, None, 1 77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, None, None, 1 512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, None, None, 1 0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, None, None, 6 0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, None, None, 6 2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, None, None, 6 0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, None, None, 1 81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, None, None, 1 512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, None, None, 1 0           conv4_block13_1_bn[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, None, None, 6 0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, None, None, 6 2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, None, None, 6 0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, None, None, 1 86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, None, None, 1 512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, None, None, 1 0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, None, None, 7 0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, None, None, 7 2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, None, None, 7 0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, None, None, 1 90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, None, None, 1 512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, None, None, 1 0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, None, None, 7 0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, None, None, 7 2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, None, None, 7 0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, None, None, 1 94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, None, None, 1 512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, None, None, 1 0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, None, None, 7 0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, None, None, 7 3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, None, None, 7 0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, None, None, 1 98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, None, None, 1 512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, None, None, 1 0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, None, None, 8 0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, None, None, 8 3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, None, None, 8 0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, None, None, 1 102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, None, None, 1 512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, None, None, 1 0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, None, None, 8 0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, None, None, 8 3328        conv4_block18_concat[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, None, None, 8 0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, None, None, 1 106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, None, None, 1 512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, None, None, 1 0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, None, None, 8 0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, None, None, 8 3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, None, None, 8 0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, None, None, 1 110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, None, None, 1 512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, None, None, 1 0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, None, None, 8 0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, None, None, 8 3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, None, None, 8 0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, None, None, 1 114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, None, None, 1 512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, None, None, 1 0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, None, None, 9 0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, None, None, 9 3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, None, None, 9 0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, None, None, 1 118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, None, None, 1 512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, None, None, 1 0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, None, None, 9 0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, None, None, 9 3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, None, None, 9 0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, None, None, 1 122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, None, None, 1 512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, None, None, 1 0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, None, None, 9 0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, None, None, 9 3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, None, None, 9 0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, None, None, 1 126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, None, None, 1 512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block24_1_relu (Activatio (None, None, None, 1 0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, None, None, 1 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, None, None, 1 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, None, None, 1 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, None, None, 5 524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, None, None, 5 0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 5 2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, None, None, 5 0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 1 65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 1 512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 1 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, None, None, 5 0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, None, None, 5 2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, None, None, 5 0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 1 69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 1 512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 1 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, None, None, 5 0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, None, None, 5 2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, None, None, 5 0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 1 73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 1 512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 1 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, None, None, 6 0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, None, None, 6 2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, None, None, 6 0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, None, None, 1 77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, None, None, 1 512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, None, None, 1 0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, None, None, 6 0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, None, None, 6 2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, None, None, 6 0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, None, None, 1 81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, None, None, 1 512         conv5_block5_1_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, None, None, 1 0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, None, None, 6 0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, None, None, 6 2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, None, None, 6 0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, None, None, 1 86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, None, None, 1 512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, None, None, 1 0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, None, None, 7 0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, None, None, 7 2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, None, None, 7 0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, None, None, 1 90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, None, None, 1 512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, None, None, 1 0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, None, None, 7 0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, None, None, 7 2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, None, None, 7 0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, None, None, 1 94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, None, None, 1 512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, None, None, 1 0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, None, None, 7 0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, None, None, 7 3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, None, None, 7 0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, None, None, 1 98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, None, None, 1 512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, None, None, 1 0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, None, None, 8 0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, None, None, 8 3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, None, None, 8 0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, None, None, 1 102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, None, None, 1 512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, None, None, 1 0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, None, None, 8 0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, None, None, 8 3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, None, None, 8 0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, None, None, 1 106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, None, None, 1 512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, None, None, 1 0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, None, None, 8 0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, None, None, 8 3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, None, None, 8 0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, None, None, 1 110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, None, None, 1 512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, None, None, 1 0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, None, None, 8 0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, None, None, 8 3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, None, None, 8 0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, None, None, 1 114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, None, None, 1 512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, None, None, 1 0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, None, None, 9 0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, None, None, 9 3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, None, None, 9 0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, None, None, 1 118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, None, None, 1 512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, None, None, 1 0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, None, None, 9 0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, None, None, 9 3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, None, None, 9 0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, None, None, 1 122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, None, None, 1 512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, None, None, 1 0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, None, None, 9 0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, None, None, 9 3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, None, None, 9 0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, None, None, 1 126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5_block16_1_bn (BatchNormal (None, None, None, 1 512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, None, None, 1 0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, None, None, 1 0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, None, None, 1 4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, None, None, 1 0           bn[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 7,037,504\n",
      "Trainable params: 6,953,856\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'densenet121',\n",
       " 'layers': [{'name': 'input_1',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_1'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'zero_padding2d_1',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'zero_padding2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((3, 3), (3, 3)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv1/conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv1/conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (7, 7),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['zero_padding2d_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv1/bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv1/bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv1/conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv1/relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv1/relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv1/bn', 0, 0, {}]]]},\n",
       "  {'name': 'zero_padding2d_2',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'zero_padding2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv1/relu', 0, 0, {}]]]},\n",
       "  {'name': 'pool1',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'pool1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['zero_padding2d_2', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool1', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv2_block1_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['pool1', 0, 0, {}],\n",
       "     ['conv2_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv2_block2_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv2_block1_concat', 0, 0, {}],\n",
       "     ['conv2_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv2_block3_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv2_block2_concat', 0, 0, {}],\n",
       "     ['conv2_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block4_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block4_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block4_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block4_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block4_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block4_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block4_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv2_block4_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv2_block3_concat', 0, 0, {}],\n",
       "     ['conv2_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block5_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block5_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block4_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block5_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block5_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block5_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block5_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block5_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv2_block5_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv2_block4_concat', 0, 0, {}],\n",
       "     ['conv2_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block6_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block6_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block5_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block6_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block6_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block6_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block6_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block6_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv2_block6_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv2_block5_concat', 0, 0, {}],\n",
       "     ['conv2_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'pool2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block6_concat', 0, 0, {}]]]},\n",
       "  {'name': 'pool2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'pool2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['pool2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'pool2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'pool2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['pool2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'pool2_pool',\n",
       "   'class_name': 'AveragePooling2D',\n",
       "   'config': {'name': 'pool2_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool2_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block1_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['pool2_pool', 0, 0, {}],\n",
       "     ['conv3_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block2_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block1_concat', 0, 0, {}],\n",
       "     ['conv3_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block3_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block2_concat', 0, 0, {}],\n",
       "     ['conv3_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block4_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block3_concat', 0, 0, {}],\n",
       "     ['conv3_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block5_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block5_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block5_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block5_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block5_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block5_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block5_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block5_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block4_concat', 0, 0, {}],\n",
       "     ['conv3_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block6_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block6_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block5_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block6_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block6_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block6_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block6_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block6_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block6_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block5_concat', 0, 0, {}],\n",
       "     ['conv3_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block7_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block7_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block6_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block7_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block7_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block7_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block7_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block7_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block7_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block6_concat', 0, 0, {}],\n",
       "     ['conv3_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block8_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block8_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block7_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block8_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block8_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block8_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block8_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block8_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block8_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block7_concat', 0, 0, {}],\n",
       "     ['conv3_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block9_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block9_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block8_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block9_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block9_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block9_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block9_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block9_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block9_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block8_concat', 0, 0, {}],\n",
       "     ['conv3_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block10_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block10_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block9_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block10_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block10_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block10_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block10_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block10_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block10_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block9_concat', 0, 0, {}],\n",
       "     ['conv3_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block11_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block11_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block10_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block11_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block11_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block11_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block11_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block11_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block11_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block10_concat', 0, 0, {}],\n",
       "     ['conv3_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block12_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block12_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block11_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block12_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block12_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block12_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block12_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block12_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv3_block12_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv3_block11_concat', 0, 0, {}],\n",
       "     ['conv3_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool3_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'pool3_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block12_concat', 0, 0, {}]]]},\n",
       "  {'name': 'pool3_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'pool3_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['pool3_bn', 0, 0, {}]]]},\n",
       "  {'name': 'pool3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'pool3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['pool3_relu', 0, 0, {}]]]},\n",
       "  {'name': 'pool3_pool',\n",
       "   'class_name': 'AveragePooling2D',\n",
       "   'config': {'name': 'pool3_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool3_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block1_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['pool3_pool', 0, 0, {}],\n",
       "     ['conv4_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block2_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block1_concat', 0, 0, {}],\n",
       "     ['conv4_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block3_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block2_concat', 0, 0, {}],\n",
       "     ['conv4_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block4_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block3_concat', 0, 0, {}],\n",
       "     ['conv4_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block5_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block4_concat', 0, 0, {}],\n",
       "     ['conv4_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block6_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block5_concat', 0, 0, {}],\n",
       "     ['conv4_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block7_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block6_concat', 0, 0, {}],\n",
       "     ['conv4_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block8_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block7_concat', 0, 0, {}],\n",
       "     ['conv4_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block9_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block8_concat', 0, 0, {}],\n",
       "     ['conv4_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block10_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block9_concat', 0, 0, {}],\n",
       "     ['conv4_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block11_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block10_concat', 0, 0, {}],\n",
       "     ['conv4_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block12_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block11_concat', 0, 0, {}],\n",
       "     ['conv4_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block13_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block12_concat', 0, 0, {}],\n",
       "     ['conv4_block13_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block14_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block13_concat', 0, 0, {}],\n",
       "     ['conv4_block14_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block15_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block14_concat', 0, 0, {}],\n",
       "     ['conv4_block15_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block16_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block15_concat', 0, 0, {}],\n",
       "     ['conv4_block16_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block17_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block16_concat', 0, 0, {}],\n",
       "     ['conv4_block17_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block18_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block17_concat', 0, 0, {}],\n",
       "     ['conv4_block18_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block19_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block18_concat', 0, 0, {}],\n",
       "     ['conv4_block19_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block20_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block19_concat', 0, 0, {}],\n",
       "     ['conv4_block20_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block21_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block20_concat', 0, 0, {}],\n",
       "     ['conv4_block21_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block22_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block21_concat', 0, 0, {}],\n",
       "     ['conv4_block22_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block23_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block22_concat', 0, 0, {}],\n",
       "     ['conv4_block23_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block24_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block24_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block24_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block24_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block24_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block24_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block24_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block24_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block24_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block24_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block24_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block24_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block24_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block24_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block24_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block24_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block24_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block24_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv4_block24_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv4_block23_concat', 0, 0, {}],\n",
       "     ['conv4_block24_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool4_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'pool4_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block24_concat', 0, 0, {}]]]},\n",
       "  {'name': 'pool4_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'pool4_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['pool4_bn', 0, 0, {}]]]},\n",
       "  {'name': 'pool4_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'pool4_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['pool4_relu', 0, 0, {}]]]},\n",
       "  {'name': 'pool4_pool',\n",
       "   'class_name': 'AveragePooling2D',\n",
       "   'config': {'name': 'pool4_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool4_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool4_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block1_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['pool4_pool', 0, 0, {}],\n",
       "     ['conv5_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block2_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block1_concat', 0, 0, {}],\n",
       "     ['conv5_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block3_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block2_concat', 0, 0, {}],\n",
       "     ['conv5_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block4_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block4_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block4_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block4_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block4_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block4_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block4_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block4_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block3_concat', 0, 0, {}],\n",
       "     ['conv5_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block5_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block5_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block4_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block5_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block5_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block5_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block5_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block5_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block5_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block4_concat', 0, 0, {}],\n",
       "     ['conv5_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block6_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block6_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block5_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block6_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block6_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block6_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block6_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block6_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block6_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block5_concat', 0, 0, {}],\n",
       "     ['conv5_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block7_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block7_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block6_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block7_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block7_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block7_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block7_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block7_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block7_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block6_concat', 0, 0, {}],\n",
       "     ['conv5_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block8_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block8_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block7_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block8_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block8_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block8_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block8_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block8_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block8_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block7_concat', 0, 0, {}],\n",
       "     ['conv5_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block9_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block9_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block8_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block9_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block9_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block9_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block9_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block9_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block9_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block8_concat', 0, 0, {}],\n",
       "     ['conv5_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block10_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block10_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block9_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block10_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block10_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block10_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block10_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block10_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block10_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block9_concat', 0, 0, {}],\n",
       "     ['conv5_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block11_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block11_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block10_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block11_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block11_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block11_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block11_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block11_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block11_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block10_concat', 0, 0, {}],\n",
       "     ['conv5_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block12_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block12_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block11_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block12_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block12_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block12_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block12_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block12_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block12_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block11_concat', 0, 0, {}],\n",
       "     ['conv5_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block13_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block13_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block12_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block13_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block13_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block13_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block13_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block13_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block13_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block13_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block13_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block13_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block13_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block13_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block13_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block13_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block13_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block13_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block13_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block13_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block12_concat', 0, 0, {}],\n",
       "     ['conv5_block13_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block14_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block14_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block13_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block14_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block14_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block14_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block14_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block14_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block14_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block14_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block14_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block14_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block14_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block14_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block14_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block14_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block14_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block14_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block14_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block14_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block13_concat', 0, 0, {}],\n",
       "     ['conv5_block14_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block15_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block15_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block14_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block15_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block15_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block15_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block15_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block15_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block15_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block15_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block15_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block15_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block15_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block15_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block15_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block15_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block15_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block15_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block15_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block15_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block14_concat', 0, 0, {}],\n",
       "     ['conv5_block15_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block16_0_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block16_0_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block15_concat', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block16_0_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block16_0_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block16_0_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block16_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block16_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block16_0_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block16_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block16_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block16_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block16_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block16_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block16_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block16_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block16_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block16_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block16_concat',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'conv5_block16_concat',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['conv5_block15_concat', 0, 0, {}],\n",
       "     ['conv5_block16_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block16_concat', 0, 0, {}]]]},\n",
       "  {'name': 'relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['bn', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['relu', 0, 0]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-02 23:36:55.844655\n",
      "(42378, 7, 7, 1024)\n",
      "6:57:30.158094\n"
     ]
    }
   ],
   "source": [
    "t1=datetime.datetime.now()\n",
    "print(t1)\n",
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "print(X_train.shape)\n",
    "t2=datetime.datetime.now()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(42378, 7*7*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('../Pickle/DenseNet121_X_train_OF.pickle',\"wb\")\n",
    "pickle.dump(X_train, pickle_out, protocol=4)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42378, 50176)\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open('../Pickle/DenseNet121_X_train_OF.pickle',\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-03 10:14:00.338864\n",
      "(8803, 7, 7, 1024)\n",
      "2:16:25.999141\n"
     ]
    }
   ],
   "source": [
    "t3=datetime.datetime.now()\n",
    "print(t3)\n",
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "print(X_test.shape)\n",
    "t4=datetime.datetime.now()\n",
    "print(t4-t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(8803, 7*7*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Pickle/DenseNet121_X_test_OF.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(X_test, '../Pickle/DenseNet121_X_test_OF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "X_test = joblib.load('../Pickle/DenseNet121_X_test_OF.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42378, 50176)\n",
      "(8803, 50176)\n",
      "(42378, 51)\n",
      "(8803, 51)\n"
     ]
    }
   ],
   "source": [
    "# shape of images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(50176,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 51)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              51381248  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 51)                6579      \n",
      "=================================================================\n",
      "Total params: 52,076,851\n",
      "Trainable params: 52,076,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_1',\n",
       " 'layers': [{'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 50176),\n",
       "    'dtype': 'float32',\n",
       "    'units': 1024,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 512,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 256,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 128,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 51,\n",
       "    'activation': 'softmax',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('../Models/weightDenseNet121_OF.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-03 12:30:34.849711\n",
      "Train on 42378 samples, validate on 8803 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23424/42378 [===============>..............] - ETA: 9:42 - loss: 5.8211 - accuracy: 0.03 - ETA: 6:36 - loss: 9.3074 - accuracy: 0.01 - ETA: 5:37 - loss: 10.4362 - accuracy: 0.018 - ETA: 5:01 - loss: 10.7798 - accuracy: 0.019 - ETA: 4:39 - loss: 10.8506 - accuracy: 0.021 - ETA: 4:22 - loss: 10.5341 - accuracy: 0.026 - ETA: 4:11 - loss: 10.2608 - accuracy: 0.029 - ETA: 4:01 - loss: 9.9264 - accuracy: 0.027 - ETA: 3:53 - loss: 9.5862 - accuracy: 0.02 - ETA: 3:48 - loss: 9.2832 - accuracy: 0.02 - ETA: 3:43 - loss: 8.9439 - accuracy: 0.03 - ETA: 3:39 - loss: 8.6601 - accuracy: 0.03 - ETA: 3:35 - loss: 8.4301 - accuracy: 0.03 - ETA: 3:32 - loss: 8.2177 - accuracy: 0.02 - ETA: 3:29 - loss: 8.0019 - accuracy: 0.02 - ETA: 3:26 - loss: 7.7989 - accuracy: 0.02 - ETA: 3:24 - loss: 7.5999 - accuracy: 0.02 - ETA: 3:22 - loss: 7.4215 - accuracy: 0.02 - ETA: 3:20 - loss: 7.2542 - accuracy: 0.02 - ETA: 3:19 - loss: 7.1003 - accuracy: 0.02 - ETA: 3:18 - loss: 6.9674 - accuracy: 0.02 - ETA: 3:16 - loss: 6.8416 - accuracy: 0.02 - ETA: 3:15 - loss: 6.7251 - accuracy: 0.02 - ETA: 3:14 - loss: 6.6253 - accuracy: 0.02 - ETA: 3:13 - loss: 6.5286 - accuracy: 0.02 - ETA: 3:12 - loss: 6.4320 - accuracy: 0.02 - ETA: 3:11 - loss: 6.3461 - accuracy: 0.02 - ETA: 3:09 - loss: 6.2700 - accuracy: 0.02 - ETA: 3:08 - loss: 6.1969 - accuracy: 0.02 - ETA: 3:07 - loss: 6.1268 - accuracy: 0.02 - ETA: 3:06 - loss: 6.0593 - accuracy: 0.02 - ETA: 3:05 - loss: 5.9954 - accuracy: 0.02 - ETA: 3:04 - loss: 5.9377 - accuracy: 0.02 - ETA: 3:03 - loss: 5.8816 - accuracy: 0.02 - ETA: 3:02 - loss: 5.8265 - accuracy: 0.02 - ETA: 3:01 - loss: 5.7760 - accuracy: 0.02 - ETA: 3:00 - loss: 5.7285 - accuracy: 0.02 - ETA: 2:59 - loss: 5.6830 - accuracy: 0.02 - ETA: 2:58 - loss: 5.6384 - accuracy: 0.02 - ETA: 2:57 - loss: 5.5952 - accuracy: 0.02 - ETA: 2:56 - loss: 5.5560 - accuracy: 0.02 - ETA: 2:55 - loss: 5.5176 - accuracy: 0.02 - ETA: 2:54 - loss: 5.4832 - accuracy: 0.02 - ETA: 2:53 - loss: 5.4477 - accuracy: 0.02 - ETA: 2:52 - loss: 5.4148 - accuracy: 0.02 - ETA: 2:51 - loss: 5.3811 - accuracy: 0.02 - ETA: 2:50 - loss: 5.3525 - accuracy: 0.02 - ETA: 2:50 - loss: 5.3229 - accuracy: 0.02 - ETA: 2:49 - loss: 5.2949 - accuracy: 0.02 - ETA: 2:48 - loss: 5.2680 - accuracy: 0.02 - ETA: 2:47 - loss: 5.2423 - accuracy: 0.02 - ETA: 2:47 - loss: 5.2176 - accuracy: 0.02 - ETA: 2:46 - loss: 5.1932 - accuracy: 0.02 - ETA: 2:46 - loss: 5.1692 - accuracy: 0.02 - ETA: 2:45 - loss: 5.1478 - accuracy: 0.02 - ETA: 2:44 - loss: 5.1264 - accuracy: 0.02 - ETA: 2:44 - loss: 5.1057 - accuracy: 0.02 - ETA: 2:43 - loss: 5.0850 - accuracy: 0.02 - ETA: 2:42 - loss: 5.0657 - accuracy: 0.02 - ETA: 2:42 - loss: 5.0473 - accuracy: 0.02 - ETA: 2:41 - loss: 5.0300 - accuracy: 0.02 - ETA: 2:40 - loss: 5.0132 - accuracy: 0.02 - ETA: 2:40 - loss: 4.9955 - accuracy: 0.02 - ETA: 2:39 - loss: 4.9780 - accuracy: 0.02 - ETA: 2:38 - loss: 4.9624 - accuracy: 0.02 - ETA: 2:38 - loss: 4.9479 - accuracy: 0.02 - ETA: 2:37 - loss: 4.9324 - accuracy: 0.02 - ETA: 2:36 - loss: 4.9181 - accuracy: 0.02 - ETA: 2:36 - loss: 4.9046 - accuracy: 0.02 - ETA: 2:35 - loss: 4.8907 - accuracy: 0.03 - ETA: 2:34 - loss: 4.8767 - accuracy: 0.03 - ETA: 2:34 - loss: 4.8630 - accuracy: 0.03 - ETA: 2:33 - loss: 4.8493 - accuracy: 0.03 - ETA: 2:32 - loss: 4.8362 - accuracy: 0.03 - ETA: 2:32 - loss: 4.8250 - accuracy: 0.03 - ETA: 2:31 - loss: 4.8121 - accuracy: 0.03 - ETA: 2:30 - loss: 4.8005 - accuracy: 0.03 - ETA: 2:30 - loss: 4.7892 - accuracy: 0.03 - ETA: 2:29 - loss: 4.7778 - accuracy: 0.03 - ETA: 2:29 - loss: 4.7670 - accuracy: 0.03 - ETA: 2:28 - loss: 4.7564 - accuracy: 0.03 - ETA: 2:28 - loss: 4.7456 - accuracy: 0.03 - ETA: 2:27 - loss: 4.7350 - accuracy: 0.03 - ETA: 2:27 - loss: 4.7242 - accuracy: 0.03 - ETA: 2:26 - loss: 4.7144 - accuracy: 0.03 - ETA: 2:25 - loss: 4.7051 - accuracy: 0.03 - ETA: 2:25 - loss: 4.6959 - accuracy: 0.03 - ETA: 2:24 - loss: 4.6866 - accuracy: 0.03 - ETA: 2:23 - loss: 4.6783 - accuracy: 0.03 - ETA: 2:23 - loss: 4.6691 - accuracy: 0.03 - ETA: 2:22 - loss: 4.6611 - accuracy: 0.03 - ETA: 2:21 - loss: 4.6530 - accuracy: 0.03 - ETA: 2:21 - loss: 4.6450 - accuracy: 0.03 - ETA: 2:20 - loss: 4.6372 - accuracy: 0.03 - ETA: 2:19 - loss: 4.6301 - accuracy: 0.03 - ETA: 2:19 - loss: 4.6221 - accuracy: 0.03 - ETA: 2:18 - loss: 4.6152 - accuracy: 0.03 - ETA: 2:18 - loss: 4.6081 - accuracy: 0.03 - ETA: 2:17 - loss: 4.6015 - accuracy: 0.03 - ETA: 2:17 - loss: 4.5947 - accuracy: 0.03 - ETA: 2:16 - loss: 4.5885 - accuracy: 0.03 - ETA: 2:15 - loss: 4.5819 - accuracy: 0.03 - ETA: 2:15 - loss: 4.5751 - accuracy: 0.03 - ETA: 2:14 - loss: 4.5688 - accuracy: 0.03 - ETA: 2:14 - loss: 4.5623 - accuracy: 0.03 - ETA: 2:13 - loss: 4.5560 - accuracy: 0.03 - ETA: 2:13 - loss: 4.5498 - accuracy: 0.03 - ETA: 2:12 - loss: 4.5437 - accuracy: 0.03 - ETA: 2:11 - loss: 4.5378 - accuracy: 0.03 - ETA: 2:11 - loss: 4.5322 - accuracy: 0.03 - ETA: 2:10 - loss: 4.5263 - accuracy: 0.03 - ETA: 2:10 - loss: 4.5207 - accuracy: 0.03 - ETA: 2:09 - loss: 4.5148 - accuracy: 0.03 - ETA: 2:08 - loss: 4.5094 - accuracy: 0.03 - ETA: 2:08 - loss: 4.5041 - accuracy: 0.03 - ETA: 2:07 - loss: 4.4986 - accuracy: 0.03 - ETA: 2:07 - loss: 4.4932 - accuracy: 0.03 - ETA: 2:06 - loss: 4.4880 - accuracy: 0.03 - ETA: 2:05 - loss: 4.4828 - accuracy: 0.03 - ETA: 2:05 - loss: 4.4776 - accuracy: 0.03 - ETA: 2:04 - loss: 4.4727 - accuracy: 0.03 - ETA: 2:04 - loss: 4.4679 - accuracy: 0.03 - ETA: 2:03 - loss: 4.4636 - accuracy: 0.03 - ETA: 2:02 - loss: 4.4589 - accuracy: 0.03 - ETA: 2:02 - loss: 4.4537 - accuracy: 0.03 - ETA: 2:01 - loss: 4.4499 - accuracy: 0.03 - ETA: 2:00 - loss: 4.4452 - accuracy: 0.03 - ETA: 2:00 - loss: 4.4400 - accuracy: 0.03 - ETA: 1:59 - loss: 4.4351 - accuracy: 0.03 - ETA: 1:59 - loss: 4.4309 - accuracy: 0.03 - ETA: 1:58 - loss: 4.4266 - accuracy: 0.03 - ETA: 1:57 - loss: 4.4221 - accuracy: 0.03 - ETA: 1:57 - loss: 4.4182 - accuracy: 0.03 - ETA: 1:56 - loss: 4.4141 - accuracy: 0.03 - ETA: 1:56 - loss: 4.4105 - accuracy: 0.03 - ETA: 1:55 - loss: 4.4064 - accuracy: 0.03 - ETA: 1:55 - loss: 4.4028 - accuracy: 0.03 - ETA: 1:54 - loss: 4.3984 - accuracy: 0.03 - ETA: 1:53 - loss: 4.3947 - accuracy: 0.03 - ETA: 1:53 - loss: 4.3909 - accuracy: 0.03 - ETA: 1:52 - loss: 4.3874 - accuracy: 0.03 - ETA: 1:52 - loss: 4.3837 - accuracy: 0.03 - ETA: 1:51 - loss: 4.3804 - accuracy: 0.03 - ETA: 1:51 - loss: 4.3771 - accuracy: 0.03 - ETA: 1:50 - loss: 4.3736 - accuracy: 0.03 - ETA: 1:49 - loss: 4.3703 - accuracy: 0.03 - ETA: 1:49 - loss: 4.3668 - accuracy: 0.03 - ETA: 1:48 - loss: 4.3633 - accuracy: 0.03 - ETA: 1:47 - loss: 4.3594 - accuracy: 0.03 - ETA: 1:47 - loss: 4.3562 - accuracy: 0.03 - ETA: 1:46 - loss: 4.3528 - accuracy: 0.03 - ETA: 1:46 - loss: 4.3499 - accuracy: 0.03 - ETA: 1:45 - loss: 4.3468 - accuracy: 0.03 - ETA: 1:44 - loss: 4.3435 - accuracy: 0.03 - ETA: 1:44 - loss: 4.3400 - accuracy: 0.03 - ETA: 1:43 - loss: 4.3370 - accuracy: 0.03 - ETA: 1:43 - loss: 4.3342 - accuracy: 0.03 - ETA: 1:42 - loss: 4.3313 - accuracy: 0.03 - ETA: 1:41 - loss: 4.3287 - accuracy: 0.03 - ETA: 1:41 - loss: 4.3254 - accuracy: 0.03 - ETA: 1:40 - loss: 4.3225 - accuracy: 0.03 - ETA: 1:40 - loss: 4.3194 - accuracy: 0.03 - ETA: 1:39 - loss: 4.3164 - accuracy: 0.03 - ETA: 1:39 - loss: 4.3134 - accuracy: 0.03 - ETA: 1:38 - loss: 4.3106 - accuracy: 0.03 - ETA: 1:37 - loss: 4.3079 - accuracy: 0.03 - ETA: 1:37 - loss: 4.3055 - accuracy: 0.03 - ETA: 1:36 - loss: 4.3027 - accuracy: 0.03 - ETA: 1:35 - loss: 4.3003 - accuracy: 0.03 - ETA: 1:35 - loss: 4.2979 - accuracy: 0.03 - ETA: 1:34 - loss: 4.2949 - accuracy: 0.03 - ETA: 1:34 - loss: 4.2924 - accuracy: 0.03 - ETA: 1:33 - loss: 4.2900 - accuracy: 0.03 - ETA: 1:32 - loss: 4.2876 - accuracy: 0.03 - ETA: 1:32 - loss: 4.2849 - accuracy: 0.03 - ETA: 1:31 - loss: 4.2819 - accuracy: 0.03 - ETA: 1:31 - loss: 4.2792 - accuracy: 0.03 - ETA: 1:30 - loss: 4.2766 - accuracy: 0.03 - ETA: 1:29 - loss: 4.2741 - accuracy: 0.03 - ETA: 1:29 - loss: 4.2716 - accuracy: 0.03 - ETA: 1:28 - loss: 4.2696 - accuracy: 0.03 - ETA: 1:28 - loss: 4.2669 - accuracy: 0.03 - ETA: 1:27 - loss: 4.2644 - accuracy: 0.0395\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:26 - loss: 4.2620 - accuracy: 0.03 - ETA: 1:26 - loss: 4.2597 - accuracy: 0.03 - ETA: 1:25 - loss: 4.2571 - accuracy: 0.03 - ETA: 1:25 - loss: 4.2549 - accuracy: 0.03 - ETA: 1:24 - loss: 4.2523 - accuracy: 0.03 - ETA: 1:24 - loss: 4.2500 - accuracy: 0.04 - ETA: 1:23 - loss: 4.2484 - accuracy: 0.04 - ETA: 1:22 - loss: 4.2463 - accuracy: 0.03 - ETA: 1:22 - loss: 4.2433 - accuracy: 0.04 - ETA: 1:21 - loss: 4.2417 - accuracy: 0.04 - ETA: 1:21 - loss: 4.2396 - accuracy: 0.04 - ETA: 1:20 - loss: 4.2371 - accuracy: 0.04 - ETA: 1:19 - loss: 4.2350 - accuracy: 0.04 - ETA: 1:19 - loss: 4.2331 - accuracy: 0.04 - ETA: 1:18 - loss: 4.2309 - accuracy: 0.04 - ETA: 1:18 - loss: 4.2291 - accuracy: 0.04 - ETA: 1:17 - loss: 4.2273 - accuracy: 0.04 - ETA: 1:16 - loss: 4.2255 - accuracy: 0.04 - ETA: 1:16 - loss: 4.2236 - accuracy: 0.04 - ETA: 1:15 - loss: 4.2217 - accuracy: 0.04 - ETA: 1:14 - loss: 4.2199 - accuracy: 0.04 - ETA: 1:14 - loss: 4.2178 - accuracy: 0.04 - ETA: 1:13 - loss: 4.2159 - accuracy: 0.04 - ETA: 1:13 - loss: 4.2138 - accuracy: 0.04 - ETA: 1:12 - loss: 4.2115 - accuracy: 0.04 - ETA: 1:11 - loss: 4.2097 - accuracy: 0.04 - ETA: 1:11 - loss: 4.2079 - accuracy: 0.04 - ETA: 1:10 - loss: 4.2062 - accuracy: 0.04 - ETA: 1:10 - loss: 4.2042 - accuracy: 0.04 - ETA: 1:09 - loss: 4.2023 - accuracy: 0.04 - ETA: 1:09 - loss: 4.2009 - accuracy: 0.04 - ETA: 1:08 - loss: 4.1993 - accuracy: 0.04 - ETA: 1:07 - loss: 4.1980 - accuracy: 0.04 - ETA: 1:07 - loss: 4.1962 - accuracy: 0.04 - ETA: 1:06 - loss: 4.1944 - accuracy: 0.04 - ETA: 1:06 - loss: 4.1930 - accuracy: 0.04 - ETA: 1:05 - loss: 4.1913 - accuracy: 0.04 - ETA: 1:05 - loss: 4.1898 - accuracy: 0.04 - ETA: 1:04 - loss: 4.1882 - accuracy: 0.04 - ETA: 1:03 - loss: 4.1865 - accuracy: 0.04 - ETA: 1:03 - loss: 4.1847 - accuracy: 0.04 - ETA: 1:02 - loss: 4.1830 - accuracy: 0.04 - ETA: 1:02 - loss: 4.1817 - accuracy: 0.04 - ETA: 1:01 - loss: 4.1800 - accuracy: 0.04 - ETA: 1:00 - loss: 4.1787 - accuracy: 0.04 - ETA: 1:00 - loss: 4.1772 - accuracy: 0.04 - ETA: 59s - loss: 4.1757 - accuracy: 0.0422 - ETA: 59s - loss: 4.1745 - accuracy: 0.042 - ETA: 58s - loss: 4.1728 - accuracy: 0.042 - ETA: 57s - loss: 4.1716 - accuracy: 0.042 - ETA: 57s - loss: 4.1703 - accuracy: 0.042 - ETA: 56s - loss: 4.1689 - accuracy: 0.042 - ETA: 56s - loss: 4.1672 - accuracy: 0.042 - ETA: 55s - loss: 4.1659 - accuracy: 0.042 - ETA: 54s - loss: 4.1648 - accuracy: 0.042 - ETA: 54s - loss: 4.1631 - accuracy: 0.042 - ETA: 53s - loss: 4.1614 - accuracy: 0.043 - ETA: 53s - loss: 4.1601 - accuracy: 0.043 - ETA: 52s - loss: 4.1587 - accuracy: 0.043 - ETA: 51s - loss: 4.1572 - accuracy: 0.043 - ETA: 51s - loss: 4.1560 - accuracy: 0.043 - ETA: 50s - loss: 4.1548 - accuracy: 0.043 - ETA: 50s - loss: 4.1533 - accuracy: 0.043 - ETA: 49s - loss: 4.1523 - accuracy: 0.043 - ETA: 48s - loss: 4.1507 - accuracy: 0.043 - ETA: 48s - loss: 4.1497 - accuracy: 0.043 - ETA: 47s - loss: 4.1483 - accuracy: 0.043 - ETA: 47s - loss: 4.1469 - accuracy: 0.043 - ETA: 46s - loss: 4.1456 - accuracy: 0.043 - ETA: 46s - loss: 4.1445 - accuracy: 0.043 - ETA: 45s - loss: 4.1428 - accuracy: 0.043 - ETA: 44s - loss: 4.1415 - accuracy: 0.043 - ETA: 44s - loss: 4.1399 - accuracy: 0.043 - ETA: 43s - loss: 4.1387 - accuracy: 0.043 - ETA: 43s - loss: 4.1377 - accuracy: 0.043 - ETA: 42s - loss: 4.1363 - accuracy: 0.044 - ETA: 41s - loss: 4.1351 - accuracy: 0.044 - ETA: 41s - loss: 4.1337 - accuracy: 0.044 - ETA: 40s - loss: 4.1323 - accuracy: 0.044 - ETA: 40s - loss: 4.1311 - accuracy: 0.044 - ETA: 39s - loss: 4.1297 - accuracy: 0.044 - ETA: 38s - loss: 4.1284 - accuracy: 0.044 - ETA: 38s - loss: 4.1272 - accuracy: 0.044 - ETA: 37s - loss: 4.1258 - accuracy: 0.044 - ETA: 37s - loss: 4.1245 - accuracy: 0.044 - ETA: 36s - loss: 4.1231 - accuracy: 0.044 - ETA: 35s - loss: 4.1218 - accuracy: 0.044 - ETA: 35s - loss: 4.1204 - accuracy: 0.044 - ETA: 34s - loss: 4.1191 - accuracy: 0.044 - ETA: 34s - loss: 4.1176 - accuracy: 0.044 - ETA: 33s - loss: 4.1168 - accuracy: 0.044 - ETA: 33s - loss: 4.1157 - accuracy: 0.044 - ETA: 32s - loss: 4.1143 - accuracy: 0.045 - ETA: 31s - loss: 4.1134 - accuracy: 0.045 - ETA: 31s - loss: 4.1122 - accuracy: 0.045 - ETA: 30s - loss: 4.1109 - accuracy: 0.045 - ETA: 30s - loss: 4.1099 - accuracy: 0.045 - ETA: 29s - loss: 4.1087 - accuracy: 0.045 - ETA: 28s - loss: 4.1077 - accuracy: 0.045 - ETA: 28s - loss: 4.1066 - accuracy: 0.045 - ETA: 27s - loss: 4.1057 - accuracy: 0.045 - ETA: 27s - loss: 4.1043 - accuracy: 0.045 - ETA: 26s - loss: 4.1032 - accuracy: 0.045 - ETA: 25s - loss: 4.1021 - accuracy: 0.045 - ETA: 25s - loss: 4.1008 - accuracy: 0.045 - ETA: 24s - loss: 4.0993 - accuracy: 0.045 - ETA: 24s - loss: 4.0981 - accuracy: 0.045 - ETA: 23s - loss: 4.0970 - accuracy: 0.045 - ETA: 22s - loss: 4.0957 - accuracy: 0.045 - ETA: 22s - loss: 4.0947 - accuracy: 0.045 - ETA: 21s - loss: 4.0936 - accuracy: 0.045 - ETA: 21s - loss: 4.0925 - accuracy: 0.045 - ETA: 20s - loss: 4.0915 - accuracy: 0.045 - ETA: 20s - loss: 4.0903 - accuracy: 0.045 - ETA: 19s - loss: 4.0891 - accuracy: 0.045 - ETA: 18s - loss: 4.0881 - accuracy: 0.045 - ETA: 18s - loss: 4.0872 - accuracy: 0.045 - ETA: 17s - loss: 4.0859 - accuracy: 0.045 - ETA: 17s - loss: 4.0849 - accuracy: 0.045 - ETA: 16s - loss: 4.0840 - accuracy: 0.045 - ETA: 15s - loss: 4.0831 - accuracy: 0.045 - ETA: 15s - loss: 4.0824 - accuracy: 0.045 - ETA: 14s - loss: 4.0815 - accuracy: 0.045 - ETA: 14s - loss: 4.0805 - accuracy: 0.045 - ETA: 13s - loss: 4.0797 - accuracy: 0.045 - ETA: 12s - loss: 4.0787 - accuracy: 0.045 - ETA: 12s - loss: 4.0777 - accuracy: 0.046 - ETA: 11s - loss: 4.0767 - accuracy: 0.046 - ETA: 11s - loss: 4.0759 - accuracy: 0.046 - ETA: 10s - loss: 4.0748 - accuracy: 0.046 - ETA: 10s - loss: 4.0737 - accuracy: 0.046 - ETA: 9s - loss: 4.0728 - accuracy: 0.046 - ETA: 8s - loss: 4.0719 - accuracy: 0.04 - ETA: 8s - loss: 4.0711 - accuracy: 0.04 - ETA: 7s - loss: 4.0701 - accuracy: 0.04 - ETA: 7s - loss: 4.0691 - accuracy: 0.04 - ETA: 6s - loss: 4.0677 - accuracy: 0.04 - ETA: 5s - loss: 4.0669 - accuracy: 0.04 - ETA: 5s - loss: 4.0660 - accuracy: 0.04 - ETA: 4s - loss: 4.0652 - accuracy: 0.04 - ETA: 4s - loss: 4.0644 - accuracy: 0.04 - ETA: 3s - loss: 4.0633 - accuracy: 0.04 - ETA: 2s - loss: 4.0626 - accuracy: 0.04 - ETA: 2s - loss: 4.0615 - accuracy: 0.04 - ETA: 1s - loss: 4.0605 - accuracy: 0.04 - ETA: 1s - loss: 4.0597 - accuracy: 0.04 - ETA: 0s - loss: 4.0583 - accuracy: 0.04 - ETA: 0s - loss: 4.0574 - accuracy: 0.04 - 207s 5ms/step - loss: 4.0574 - accuracy: 0.0468 - val_loss: 3.9221 - val_accuracy: 0.0181\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:09 - loss: 3.6868 - accuracy: 0.05 - ETA: 3:04 - loss: 3.7530 - accuracy: 0.05 - ETA: 3:05 - loss: 3.7562 - accuracy: 0.05 - ETA: 3:06 - loss: 3.7463 - accuracy: 0.06 - ETA: 3:06 - loss: 3.7518 - accuracy: 0.06 - ETA: 3:05 - loss: 3.7532 - accuracy: 0.05 - ETA: 3:04 - loss: 3.7542 - accuracy: 0.05 - ETA: 3:04 - loss: 3.7427 - accuracy: 0.05 - ETA: 3:04 - loss: 3.7492 - accuracy: 0.05 - ETA: 3:02 - loss: 3.7416 - accuracy: 0.06 - ETA: 3:01 - loss: 3.7452 - accuracy: 0.06 - ETA: 3:00 - loss: 3.7511 - accuracy: 0.05 - ETA: 3:00 - loss: 3.7530 - accuracy: 0.05 - ETA: 2:59 - loss: 3.7531 - accuracy: 0.05 - ETA: 2:58 - loss: 3.7554 - accuracy: 0.05 - ETA: 2:57 - loss: 3.7563 - accuracy: 0.05 - ETA: 2:57 - loss: 3.7561 - accuracy: 0.05 - ETA: 2:57 - loss: 3.7511 - accuracy: 0.05 - ETA: 2:56 - loss: 3.7504 - accuracy: 0.05 - ETA: 2:56 - loss: 3.7502 - accuracy: 0.05 - ETA: 2:55 - loss: 3.7515 - accuracy: 0.05 - ETA: 2:55 - loss: 3.7572 - accuracy: 0.05 - ETA: 2:54 - loss: 3.7561 - accuracy: 0.05 - ETA: 2:54 - loss: 3.7566 - accuracy: 0.05 - ETA: 2:54 - loss: 3.7573 - accuracy: 0.06 - ETA: 2:54 - loss: 3.7595 - accuracy: 0.06 - ETA: 2:54 - loss: 3.7607 - accuracy: 0.05 - ETA: 2:53 - loss: 3.7583 - accuracy: 0.06 - ETA: 2:53 - loss: 3.7601 - accuracy: 0.06 - ETA: 2:52 - loss: 3.7596 - accuracy: 0.06 - ETA: 2:51 - loss: 3.7565 - accuracy: 0.06 - ETA: 2:51 - loss: 3.7553 - accuracy: 0.06 - ETA: 2:50 - loss: 3.7559 - accuracy: 0.06 - ETA: 2:50 - loss: 3.7570 - accuracy: 0.06 - ETA: 2:49 - loss: 3.7582 - accuracy: 0.06 - ETA: 2:49 - loss: 3.7555 - accuracy: 0.06 - ETA: 2:48 - loss: 3.7562 - accuracy: 0.06 - ETA: 2:47 - loss: 3.7569 - accuracy: 0.06 - ETA: 2:47 - loss: 3.7569 - accuracy: 0.06 - ETA: 2:46 - loss: 3.7558 - accuracy: 0.06 - ETA: 2:45 - loss: 3.7541 - accuracy: 0.06 - ETA: 2:45 - loss: 3.7572 - accuracy: 0.06 - ETA: 2:44 - loss: 3.7560 - accuracy: 0.06 - ETA: 2:44 - loss: 3.7546 - accuracy: 0.06 - ETA: 2:43 - loss: 3.7520 - accuracy: 0.06 - ETA: 2:42 - loss: 3.7538 - accuracy: 0.06 - ETA: 2:42 - loss: 3.7568 - accuracy: 0.06 - ETA: 2:41 - loss: 3.7570 - accuracy: 0.06 - ETA: 2:41 - loss: 3.7572 - accuracy: 0.06 - ETA: 2:40 - loss: 3.7567 - accuracy: 0.06 - ETA: 2:39 - loss: 3.7584 - accuracy: 0.06 - ETA: 2:39 - loss: 3.7580 - accuracy: 0.06 - ETA: 2:39 - loss: 3.7577 - accuracy: 0.06 - ETA: 2:38 - loss: 3.7582 - accuracy: 0.06 - ETA: 2:38 - loss: 3.7583 - accuracy: 0.06 - ETA: 2:37 - loss: 3.7588 - accuracy: 0.06 - ETA: 2:36 - loss: 3.7593 - accuracy: 0.06 - ETA: 2:36 - loss: 3.7610 - accuracy: 0.06 - ETA: 2:35 - loss: 3.7627 - accuracy: 0.06 - ETA: 2:35 - loss: 3.7625 - accuracy: 0.06 - ETA: 2:34 - loss: 3.7625 - accuracy: 0.06 - ETA: 2:33 - loss: 3.7637 - accuracy: 0.06 - ETA: 2:33 - loss: 3.7623 - accuracy: 0.06 - ETA: 2:32 - loss: 3.7626 - accuracy: 0.06 - ETA: 2:32 - loss: 3.7634 - accuracy: 0.06 - ETA: 2:31 - loss: 3.7641 - accuracy: 0.06 - ETA: 2:30 - loss: 3.7663 - accuracy: 0.06 - ETA: 2:30 - loss: 3.7658 - accuracy: 0.06 - ETA: 2:29 - loss: 3.7652 - accuracy: 0.06 - ETA: 2:29 - loss: 3.7657 - accuracy: 0.06 - ETA: 2:28 - loss: 3.7658 - accuracy: 0.06 - ETA: 2:27 - loss: 3.7668 - accuracy: 0.06 - ETA: 2:27 - loss: 3.7675 - accuracy: 0.06 - ETA: 2:26 - loss: 3.7669 - accuracy: 0.06 - ETA: 2:26 - loss: 3.7672 - accuracy: 0.06 - ETA: 2:25 - loss: 3.7672 - accuracy: 0.06 - ETA: 2:24 - loss: 3.7685 - accuracy: 0.06 - ETA: 2:24 - loss: 3.7668 - accuracy: 0.06 - ETA: 2:24 - loss: 3.7672 - accuracy: 0.06 - ETA: 2:23 - loss: 3.7679 - accuracy: 0.06 - ETA: 2:23 - loss: 3.7687 - accuracy: 0.06 - ETA: 2:22 - loss: 3.7678 - accuracy: 0.06 - ETA: 2:22 - loss: 3.7677 - accuracy: 0.06 - ETA: 2:21 - loss: 3.7683 - accuracy: 0.06 - ETA: 2:21 - loss: 3.7685 - accuracy: 0.06 - ETA: 2:20 - loss: 3.7682 - accuracy: 0.06 - ETA: 2:20 - loss: 3.7681 - accuracy: 0.06 - ETA: 2:19 - loss: 3.7690 - accuracy: 0.06 - ETA: 2:19 - loss: 3.7683 - accuracy: 0.06 - ETA: 2:18 - loss: 3.7667 - accuracy: 0.06 - ETA: 2:18 - loss: 3.7667 - accuracy: 0.06 - ETA: 2:17 - loss: 3.7658 - accuracy: 0.06 - ETA: 2:16 - loss: 3.7662 - accuracy: 0.06 - ETA: 2:16 - loss: 3.7660 - accuracy: 0.06 - ETA: 2:15 - loss: 3.7654 - accuracy: 0.06 - ETA: 2:15 - loss: 3.7639 - accuracy: 0.06 - ETA: 2:14 - loss: 3.7638 - accuracy: 0.06 - ETA: 2:13 - loss: 3.7639 - accuracy: 0.06 - ETA: 2:13 - loss: 3.7632 - accuracy: 0.06 - ETA: 2:12 - loss: 3.7634 - accuracy: 0.06 - ETA: 2:12 - loss: 3.7633 - accuracy: 0.06 - ETA: 2:11 - loss: 3.7627 - accuracy: 0.06 - ETA: 2:10 - loss: 3.7631 - accuracy: 0.06 - ETA: 2:10 - loss: 3.7630 - accuracy: 0.06 - ETA: 2:09 - loss: 3.7625 - accuracy: 0.06 - ETA: 2:09 - loss: 3.7621 - accuracy: 0.06 - ETA: 2:08 - loss: 3.7610 - accuracy: 0.06 - ETA: 2:08 - loss: 3.7600 - accuracy: 0.06 - ETA: 2:07 - loss: 3.7599 - accuracy: 0.06 - ETA: 2:07 - loss: 3.7580 - accuracy: 0.06 - ETA: 2:06 - loss: 3.7571 - accuracy: 0.06 - ETA: 2:05 - loss: 3.7566 - accuracy: 0.06 - ETA: 2:05 - loss: 3.7558 - accuracy: 0.06 - ETA: 2:04 - loss: 3.7558 - accuracy: 0.06 - ETA: 2:04 - loss: 3.7547 - accuracy: 0.06 - ETA: 2:03 - loss: 3.7532 - accuracy: 0.06 - ETA: 2:02 - loss: 3.7533 - accuracy: 0.06 - ETA: 2:02 - loss: 3.7534 - accuracy: 0.06 - ETA: 2:01 - loss: 3.7532 - accuracy: 0.06 - ETA: 2:01 - loss: 3.7526 - accuracy: 0.06 - ETA: 2:00 - loss: 3.7526 - accuracy: 0.06 - ETA: 2:00 - loss: 3.7514 - accuracy: 0.06 - ETA: 1:59 - loss: 3.7514 - accuracy: 0.06 - ETA: 1:59 - loss: 3.7498 - accuracy: 0.06 - ETA: 1:58 - loss: 3.7499 - accuracy: 0.06 - ETA: 1:57 - loss: 3.7490 - accuracy: 0.06 - ETA: 1:57 - loss: 3.7478 - accuracy: 0.06 - ETA: 1:56 - loss: 3.7483 - accuracy: 0.06 - ETA: 1:56 - loss: 3.7487 - accuracy: 0.06 - ETA: 1:55 - loss: 3.7500 - accuracy: 0.06 - ETA: 1:54 - loss: 3.7498 - accuracy: 0.06 - ETA: 1:54 - loss: 3.7488 - accuracy: 0.06 - ETA: 1:53 - loss: 3.7489 - accuracy: 0.06 - ETA: 1:53 - loss: 3.7483 - accuracy: 0.06 - ETA: 1:52 - loss: 3.7481 - accuracy: 0.06 - ETA: 1:52 - loss: 3.7479 - accuracy: 0.06 - ETA: 1:51 - loss: 3.7474 - accuracy: 0.06 - ETA: 1:51 - loss: 3.7475 - accuracy: 0.06 - ETA: 1:50 - loss: 3.7477 - accuracy: 0.06 - ETA: 1:49 - loss: 3.7474 - accuracy: 0.06 - ETA: 1:49 - loss: 3.7477 - accuracy: 0.06 - ETA: 1:48 - loss: 3.7477 - accuracy: 0.06 - ETA: 1:48 - loss: 3.7473 - accuracy: 0.06 - ETA: 1:47 - loss: 3.7474 - accuracy: 0.06 - ETA: 1:46 - loss: 3.7473 - accuracy: 0.06 - ETA: 1:46 - loss: 3.7474 - accuracy: 0.06 - ETA: 1:45 - loss: 3.7477 - accuracy: 0.06 - ETA: 1:45 - loss: 3.7471 - accuracy: 0.06 - ETA: 1:44 - loss: 3.7475 - accuracy: 0.06 - ETA: 1:43 - loss: 3.7470 - accuracy: 0.06 - ETA: 1:43 - loss: 3.7473 - accuracy: 0.06 - ETA: 1:42 - loss: 3.7474 - accuracy: 0.06 - ETA: 1:42 - loss: 3.7464 - accuracy: 0.06 - ETA: 1:41 - loss: 3.7459 - accuracy: 0.06 - ETA: 1:40 - loss: 3.7459 - accuracy: 0.06 - ETA: 1:40 - loss: 3.7457 - accuracy: 0.06 - ETA: 1:39 - loss: 3.7456 - accuracy: 0.06 - ETA: 1:39 - loss: 3.7453 - accuracy: 0.06 - ETA: 1:38 - loss: 3.7453 - accuracy: 0.06 - ETA: 1:38 - loss: 3.7453 - accuracy: 0.06 - ETA: 1:37 - loss: 3.7452 - accuracy: 0.06 - ETA: 1:36 - loss: 3.7458 - accuracy: 0.06 - ETA: 1:36 - loss: 3.7455 - accuracy: 0.06 - ETA: 1:35 - loss: 3.7453 - accuracy: 0.06 - ETA: 1:35 - loss: 3.7449 - accuracy: 0.06 - ETA: 1:34 - loss: 3.7447 - accuracy: 0.06 - ETA: 1:34 - loss: 3.7446 - accuracy: 0.06 - ETA: 1:33 - loss: 3.7446 - accuracy: 0.06 - ETA: 1:33 - loss: 3.7441 - accuracy: 0.06 - ETA: 1:32 - loss: 3.7442 - accuracy: 0.06 - ETA: 1:31 - loss: 3.7431 - accuracy: 0.06 - ETA: 1:31 - loss: 3.7432 - accuracy: 0.06 - ETA: 1:30 - loss: 3.7434 - accuracy: 0.06 - ETA: 1:30 - loss: 3.7420 - accuracy: 0.06 - ETA: 1:29 - loss: 3.7412 - accuracy: 0.06 - ETA: 1:29 - loss: 3.7405 - accuracy: 0.06 - ETA: 1:28 - loss: 3.7398 - accuracy: 0.06 - ETA: 1:27 - loss: 3.7393 - accuracy: 0.06 - ETA: 1:27 - loss: 3.7391 - accuracy: 0.06 - ETA: 1:26 - loss: 3.7394 - accuracy: 0.06 - ETA: 1:26 - loss: 3.7386 - accuracy: 0.06 - ETA: 1:25 - loss: 3.7377 - accuracy: 0.07 - ETA: 1:24 - loss: 3.7375 - accuracy: 0.07 - ETA: 1:24 - loss: 3.7372 - accuracy: 0.06 - ETA: 1:23 - loss: 3.7372 - accuracy: 0.07 - ETA: 1:23 - loss: 3.7374 - accuracy: 0.0700"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:22 - loss: 3.7372 - accuracy: 0.07 - ETA: 1:21 - loss: 3.7372 - accuracy: 0.07 - ETA: 1:21 - loss: 3.7368 - accuracy: 0.07 - ETA: 1:20 - loss: 3.7366 - accuracy: 0.07 - ETA: 1:20 - loss: 3.7360 - accuracy: 0.07 - ETA: 1:19 - loss: 3.7357 - accuracy: 0.07 - ETA: 1:19 - loss: 3.7356 - accuracy: 0.07 - ETA: 1:18 - loss: 3.7356 - accuracy: 0.07 - ETA: 1:18 - loss: 3.7353 - accuracy: 0.07 - ETA: 1:17 - loss: 3.7352 - accuracy: 0.07 - ETA: 1:17 - loss: 3.7348 - accuracy: 0.07 - ETA: 1:16 - loss: 3.7348 - accuracy: 0.07 - ETA: 1:15 - loss: 3.7343 - accuracy: 0.07 - ETA: 1:15 - loss: 3.7343 - accuracy: 0.07 - ETA: 1:14 - loss: 3.7342 - accuracy: 0.07 - ETA: 1:14 - loss: 3.7334 - accuracy: 0.07 - ETA: 1:13 - loss: 3.7339 - accuracy: 0.07 - ETA: 1:12 - loss: 3.7331 - accuracy: 0.07 - ETA: 1:12 - loss: 3.7319 - accuracy: 0.07 - ETA: 1:11 - loss: 3.7318 - accuracy: 0.07 - ETA: 1:11 - loss: 3.7315 - accuracy: 0.07 - ETA: 1:10 - loss: 3.7312 - accuracy: 0.07 - ETA: 1:10 - loss: 3.7308 - accuracy: 0.07 - ETA: 1:09 - loss: 3.7315 - accuracy: 0.07 - ETA: 1:08 - loss: 3.7313 - accuracy: 0.07 - ETA: 1:08 - loss: 3.7306 - accuracy: 0.07 - ETA: 1:07 - loss: 3.7306 - accuracy: 0.07 - ETA: 1:07 - loss: 3.7302 - accuracy: 0.07 - ETA: 1:06 - loss: 3.7301 - accuracy: 0.07 - ETA: 1:05 - loss: 3.7296 - accuracy: 0.07 - ETA: 1:05 - loss: 3.7288 - accuracy: 0.07 - ETA: 1:04 - loss: 3.7282 - accuracy: 0.07 - ETA: 1:04 - loss: 3.7277 - accuracy: 0.07 - ETA: 1:03 - loss: 3.7274 - accuracy: 0.07 - ETA: 1:03 - loss: 3.7263 - accuracy: 0.07 - ETA: 1:02 - loss: 3.7258 - accuracy: 0.07 - ETA: 1:02 - loss: 3.7257 - accuracy: 0.07 - ETA: 1:01 - loss: 3.7254 - accuracy: 0.07 - ETA: 1:00 - loss: 3.7246 - accuracy: 0.07 - ETA: 1:00 - loss: 3.7248 - accuracy: 0.07 - ETA: 59s - loss: 3.7250 - accuracy: 0.0729 - ETA: 59s - loss: 3.7247 - accuracy: 0.073 - ETA: 58s - loss: 3.7243 - accuracy: 0.073 - ETA: 57s - loss: 3.7246 - accuracy: 0.073 - ETA: 57s - loss: 3.7242 - accuracy: 0.073 - ETA: 56s - loss: 3.7244 - accuracy: 0.073 - ETA: 56s - loss: 3.7243 - accuracy: 0.073 - ETA: 55s - loss: 3.7241 - accuracy: 0.073 - ETA: 55s - loss: 3.7236 - accuracy: 0.073 - ETA: 54s - loss: 3.7233 - accuracy: 0.073 - ETA: 53s - loss: 3.7229 - accuracy: 0.073 - ETA: 53s - loss: 3.7224 - accuracy: 0.073 - ETA: 52s - loss: 3.7221 - accuracy: 0.073 - ETA: 52s - loss: 3.7221 - accuracy: 0.073 - ETA: 51s - loss: 3.7217 - accuracy: 0.073 - ETA: 51s - loss: 3.7208 - accuracy: 0.073 - ETA: 50s - loss: 3.7203 - accuracy: 0.073 - ETA: 49s - loss: 3.7199 - accuracy: 0.073 - ETA: 49s - loss: 3.7196 - accuracy: 0.073 - ETA: 48s - loss: 3.7194 - accuracy: 0.073 - ETA: 48s - loss: 3.7190 - accuracy: 0.073 - ETA: 47s - loss: 3.7190 - accuracy: 0.073 - ETA: 47s - loss: 3.7187 - accuracy: 0.074 - ETA: 46s - loss: 3.7186 - accuracy: 0.074 - ETA: 45s - loss: 3.7183 - accuracy: 0.074 - ETA: 45s - loss: 3.7186 - accuracy: 0.074 - ETA: 44s - loss: 3.7182 - accuracy: 0.074 - ETA: 44s - loss: 3.7178 - accuracy: 0.074 - ETA: 43s - loss: 3.7178 - accuracy: 0.074 - ETA: 43s - loss: 3.7179 - accuracy: 0.074 - ETA: 42s - loss: 3.7172 - accuracy: 0.074 - ETA: 41s - loss: 3.7176 - accuracy: 0.074 - ETA: 41s - loss: 3.7174 - accuracy: 0.074 - ETA: 40s - loss: 3.7176 - accuracy: 0.074 - ETA: 40s - loss: 3.7174 - accuracy: 0.074 - ETA: 39s - loss: 3.7167 - accuracy: 0.074 - ETA: 39s - loss: 3.7167 - accuracy: 0.074 - ETA: 38s - loss: 3.7166 - accuracy: 0.075 - ETA: 37s - loss: 3.7166 - accuracy: 0.075 - ETA: 37s - loss: 3.7168 - accuracy: 0.074 - ETA: 36s - loss: 3.7167 - accuracy: 0.075 - ETA: 36s - loss: 3.7164 - accuracy: 0.075 - ETA: 35s - loss: 3.7159 - accuracy: 0.075 - ETA: 35s - loss: 3.7161 - accuracy: 0.075 - ETA: 34s - loss: 3.7162 - accuracy: 0.075 - ETA: 33s - loss: 3.7163 - accuracy: 0.075 - ETA: 33s - loss: 3.7158 - accuracy: 0.075 - ETA: 32s - loss: 3.7152 - accuracy: 0.075 - ETA: 32s - loss: 3.7151 - accuracy: 0.075 - ETA: 31s - loss: 3.7148 - accuracy: 0.075 - ETA: 31s - loss: 3.7146 - accuracy: 0.075 - ETA: 30s - loss: 3.7142 - accuracy: 0.075 - ETA: 29s - loss: 3.7143 - accuracy: 0.075 - ETA: 29s - loss: 3.7142 - accuracy: 0.075 - ETA: 28s - loss: 3.7141 - accuracy: 0.076 - ETA: 28s - loss: 3.7138 - accuracy: 0.076 - ETA: 27s - loss: 3.7133 - accuracy: 0.076 - ETA: 27s - loss: 3.7135 - accuracy: 0.076 - ETA: 26s - loss: 3.7133 - accuracy: 0.076 - ETA: 25s - loss: 3.7133 - accuracy: 0.076 - ETA: 25s - loss: 3.7126 - accuracy: 0.076 - ETA: 24s - loss: 3.7124 - accuracy: 0.076 - ETA: 24s - loss: 3.7119 - accuracy: 0.076 - ETA: 23s - loss: 3.7120 - accuracy: 0.076 - ETA: 23s - loss: 3.7116 - accuracy: 0.076 - ETA: 22s - loss: 3.7115 - accuracy: 0.076 - ETA: 21s - loss: 3.7111 - accuracy: 0.076 - ETA: 21s - loss: 3.7111 - accuracy: 0.076 - ETA: 20s - loss: 3.7109 - accuracy: 0.076 - ETA: 20s - loss: 3.7107 - accuracy: 0.076 - ETA: 19s - loss: 3.7107 - accuracy: 0.076 - ETA: 19s - loss: 3.7106 - accuracy: 0.076 - ETA: 18s - loss: 3.7107 - accuracy: 0.076 - ETA: 17s - loss: 3.7108 - accuracy: 0.076 - ETA: 17s - loss: 3.7106 - accuracy: 0.076 - ETA: 16s - loss: 3.7102 - accuracy: 0.076 - ETA: 16s - loss: 3.7107 - accuracy: 0.076 - ETA: 15s - loss: 3.7108 - accuracy: 0.076 - ETA: 15s - loss: 3.7102 - accuracy: 0.076 - ETA: 14s - loss: 3.7094 - accuracy: 0.076 - ETA: 13s - loss: 3.7091 - accuracy: 0.077 - ETA: 13s - loss: 3.7086 - accuracy: 0.077 - ETA: 12s - loss: 3.7083 - accuracy: 0.077 - ETA: 12s - loss: 3.7081 - accuracy: 0.077 - ETA: 11s - loss: 3.7082 - accuracy: 0.077 - ETA: 11s - loss: 3.7083 - accuracy: 0.077 - ETA: 10s - loss: 3.7084 - accuracy: 0.077 - ETA: 9s - loss: 3.7085 - accuracy: 0.077 - ETA: 9s - loss: 3.7080 - accuracy: 0.07 - ETA: 8s - loss: 3.7078 - accuracy: 0.07 - ETA: 8s - loss: 3.7073 - accuracy: 0.07 - ETA: 7s - loss: 3.7066 - accuracy: 0.07 - ETA: 7s - loss: 3.7061 - accuracy: 0.07 - ETA: 6s - loss: 3.7057 - accuracy: 0.07 - ETA: 5s - loss: 3.7057 - accuracy: 0.07 - ETA: 5s - loss: 3.7057 - accuracy: 0.07 - ETA: 4s - loss: 3.7054 - accuracy: 0.07 - ETA: 4s - loss: 3.7054 - accuracy: 0.07 - ETA: 3s - loss: 3.7053 - accuracy: 0.07 - ETA: 2s - loss: 3.7048 - accuracy: 0.07 - ETA: 2s - loss: 3.7046 - accuracy: 0.07 - ETA: 1s - loss: 3.7044 - accuracy: 0.07 - ETA: 1s - loss: 3.7043 - accuracy: 0.07 - ETA: 0s - loss: 3.7038 - accuracy: 0.07 - ETA: 0s - loss: 3.7034 - accuracy: 0.07 - 204s 5ms/step - loss: 3.7034 - accuracy: 0.0784 - val_loss: 3.9128 - val_accuracy: 0.0334\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:02 - loss: 3.5649 - accuracy: 0.10 - ETA: 3:00 - loss: 3.6100 - accuracy: 0.09 - ETA: 2:59 - loss: 3.6094 - accuracy: 0.09 - ETA: 2:59 - loss: 3.6220 - accuracy: 0.09 - ETA: 3:02 - loss: 3.6332 - accuracy: 0.09 - ETA: 3:00 - loss: 3.6464 - accuracy: 0.09 - ETA: 3:00 - loss: 3.6539 - accuracy: 0.09 - ETA: 2:59 - loss: 3.6426 - accuracy: 0.09 - ETA: 2:58 - loss: 3.6291 - accuracy: 0.09 - ETA: 2:57 - loss: 3.6321 - accuracy: 0.09 - ETA: 2:57 - loss: 3.6319 - accuracy: 0.09 - ETA: 2:56 - loss: 3.6310 - accuracy: 0.09 - ETA: 2:55 - loss: 3.6258 - accuracy: 0.09 - ETA: 2:55 - loss: 3.6204 - accuracy: 0.09 - ETA: 2:55 - loss: 3.6224 - accuracy: 0.10 - ETA: 2:55 - loss: 3.6237 - accuracy: 0.10 - ETA: 2:54 - loss: 3.6272 - accuracy: 0.10 - ETA: 2:54 - loss: 3.6314 - accuracy: 0.09 - ETA: 2:53 - loss: 3.6332 - accuracy: 0.09 - ETA: 2:53 - loss: 3.6294 - accuracy: 0.09 - ETA: 2:52 - loss: 3.6337 - accuracy: 0.09 - ETA: 2:52 - loss: 3.6255 - accuracy: 0.10 - ETA: 2:51 - loss: 3.6259 - accuracy: 0.10 - ETA: 2:51 - loss: 3.6242 - accuracy: 0.10 - ETA: 2:50 - loss: 3.6182 - accuracy: 0.10 - ETA: 2:51 - loss: 3.6203 - accuracy: 0.10 - ETA: 2:51 - loss: 3.6161 - accuracy: 0.10 - ETA: 2:51 - loss: 3.6164 - accuracy: 0.10 - ETA: 2:50 - loss: 3.6196 - accuracy: 0.10 - ETA: 2:50 - loss: 3.6200 - accuracy: 0.10 - ETA: 2:50 - loss: 3.6175 - accuracy: 0.10 - ETA: 2:49 - loss: 3.6206 - accuracy: 0.10 - ETA: 2:49 - loss: 3.6226 - accuracy: 0.10 - ETA: 2:48 - loss: 3.6175 - accuracy: 0.10 - ETA: 2:48 - loss: 3.6159 - accuracy: 0.10 - ETA: 2:47 - loss: 3.6138 - accuracy: 0.10 - ETA: 2:46 - loss: 3.6153 - accuracy: 0.10 - ETA: 2:46 - loss: 3.6154 - accuracy: 0.10 - ETA: 2:45 - loss: 3.6121 - accuracy: 0.10 - ETA: 2:45 - loss: 3.6173 - accuracy: 0.10 - ETA: 2:44 - loss: 3.6187 - accuracy: 0.10 - ETA: 2:44 - loss: 3.6228 - accuracy: 0.10 - ETA: 2:43 - loss: 3.6229 - accuracy: 0.10 - ETA: 2:43 - loss: 3.6241 - accuracy: 0.10 - ETA: 2:42 - loss: 3.6240 - accuracy: 0.10 - ETA: 2:41 - loss: 3.6242 - accuracy: 0.10 - ETA: 2:41 - loss: 3.6250 - accuracy: 0.10 - ETA: 2:40 - loss: 3.6247 - accuracy: 0.10 - ETA: 2:40 - loss: 3.6256 - accuracy: 0.10 - ETA: 2:39 - loss: 3.6269 - accuracy: 0.10 - ETA: 2:39 - loss: 3.6249 - accuracy: 0.10 - ETA: 2:38 - loss: 3.6230 - accuracy: 0.10 - ETA: 2:37 - loss: 3.6242 - accuracy: 0.10 - ETA: 2:37 - loss: 3.6249 - accuracy: 0.10 - ETA: 2:36 - loss: 3.6239 - accuracy: 0.10 - ETA: 2:36 - loss: 3.6247 - accuracy: 0.09 - ETA: 2:36 - loss: 3.6249 - accuracy: 0.09 - ETA: 2:35 - loss: 3.6259 - accuracy: 0.09 - ETA: 2:34 - loss: 3.6279 - accuracy: 0.09 - ETA: 2:34 - loss: 3.6289 - accuracy: 0.09 - ETA: 2:33 - loss: 3.6295 - accuracy: 0.09 - ETA: 2:33 - loss: 3.6286 - accuracy: 0.09 - ETA: 2:32 - loss: 3.6282 - accuracy: 0.09 - ETA: 2:32 - loss: 3.6303 - accuracy: 0.09 - ETA: 2:31 - loss: 3.6286 - accuracy: 0.09 - ETA: 2:31 - loss: 3.6299 - accuracy: 0.09 - ETA: 2:30 - loss: 3.6287 - accuracy: 0.09 - ETA: 2:30 - loss: 3.6284 - accuracy: 0.09 - ETA: 2:29 - loss: 3.6272 - accuracy: 0.09 - ETA: 2:29 - loss: 3.6285 - accuracy: 0.09 - ETA: 2:28 - loss: 3.6278 - accuracy: 0.09 - ETA: 2:28 - loss: 3.6270 - accuracy: 0.09 - ETA: 2:27 - loss: 3.6260 - accuracy: 0.09 - ETA: 2:27 - loss: 3.6246 - accuracy: 0.09 - ETA: 2:26 - loss: 3.6245 - accuracy: 0.09 - ETA: 2:26 - loss: 3.6256 - accuracy: 0.09 - ETA: 2:25 - loss: 3.6234 - accuracy: 0.09 - ETA: 2:25 - loss: 3.6235 - accuracy: 0.09 - ETA: 2:24 - loss: 3.6246 - accuracy: 0.09 - ETA: 2:23 - loss: 3.6246 - accuracy: 0.09 - ETA: 2:23 - loss: 3.6257 - accuracy: 0.09 - ETA: 2:23 - loss: 3.6254 - accuracy: 0.09 - ETA: 2:22 - loss: 3.6266 - accuracy: 0.09 - ETA: 2:22 - loss: 3.6259 - accuracy: 0.09 - ETA: 2:21 - loss: 3.6259 - accuracy: 0.09 - ETA: 2:20 - loss: 3.6264 - accuracy: 0.09 - ETA: 2:20 - loss: 3.6274 - accuracy: 0.09 - ETA: 2:19 - loss: 3.6272 - accuracy: 0.09 - ETA: 2:18 - loss: 3.6271 - accuracy: 0.09 - ETA: 2:18 - loss: 3.6264 - accuracy: 0.09 - ETA: 2:17 - loss: 3.6260 - accuracy: 0.09 - ETA: 2:17 - loss: 3.6238 - accuracy: 0.09 - ETA: 2:16 - loss: 3.6235 - accuracy: 0.09 - ETA: 2:16 - loss: 3.6221 - accuracy: 0.09 - ETA: 2:15 - loss: 3.6214 - accuracy: 0.09 - ETA: 2:14 - loss: 3.6196 - accuracy: 0.09 - ETA: 2:14 - loss: 3.6190 - accuracy: 0.09 - ETA: 2:13 - loss: 3.6195 - accuracy: 0.09 - ETA: 2:12 - loss: 3.6176 - accuracy: 0.09 - ETA: 2:12 - loss: 3.6182 - accuracy: 0.09 - ETA: 2:11 - loss: 3.6173 - accuracy: 0.09 - ETA: 2:11 - loss: 3.6168 - accuracy: 0.09 - ETA: 2:10 - loss: 3.6158 - accuracy: 0.09 - ETA: 2:10 - loss: 3.6157 - accuracy: 0.09 - ETA: 2:09 - loss: 3.6176 - accuracy: 0.09 - ETA: 2:09 - loss: 3.6189 - accuracy: 0.09 - ETA: 2:08 - loss: 3.6175 - accuracy: 0.09 - ETA: 2:07 - loss: 3.6170 - accuracy: 0.09 - ETA: 2:07 - loss: 3.6183 - accuracy: 0.09 - ETA: 2:07 - loss: 3.6193 - accuracy: 0.09 - ETA: 2:06 - loss: 3.6193 - accuracy: 0.09 - ETA: 2:06 - loss: 3.6197 - accuracy: 0.09 - ETA: 2:05 - loss: 3.6205 - accuracy: 0.09 - ETA: 2:04 - loss: 3.6198 - accuracy: 0.09 - ETA: 2:04 - loss: 3.6194 - accuracy: 0.09 - ETA: 2:03 - loss: 3.6200 - accuracy: 0.09 - ETA: 2:02 - loss: 3.6200 - accuracy: 0.09 - ETA: 2:02 - loss: 3.6205 - accuracy: 0.09 - ETA: 2:01 - loss: 3.6216 - accuracy: 0.09 - ETA: 2:01 - loss: 3.6209 - accuracy: 0.09 - ETA: 2:00 - loss: 3.6207 - accuracy: 0.09 - ETA: 2:00 - loss: 3.6202 - accuracy: 0.09 - ETA: 1:59 - loss: 3.6204 - accuracy: 0.09 - ETA: 1:58 - loss: 3.6207 - accuracy: 0.09 - ETA: 1:58 - loss: 3.6209 - accuracy: 0.09 - ETA: 1:57 - loss: 3.6209 - accuracy: 0.09 - ETA: 1:57 - loss: 3.6204 - accuracy: 0.09 - ETA: 1:56 - loss: 3.6197 - accuracy: 0.09 - ETA: 1:56 - loss: 3.6184 - accuracy: 0.09 - ETA: 1:55 - loss: 3.6183 - accuracy: 0.09 - ETA: 1:54 - loss: 3.6184 - accuracy: 0.09 - ETA: 1:54 - loss: 3.6195 - accuracy: 0.09 - ETA: 1:53 - loss: 3.6187 - accuracy: 0.09 - ETA: 1:53 - loss: 3.6192 - accuracy: 0.09 - ETA: 1:52 - loss: 3.6183 - accuracy: 0.09 - ETA: 1:52 - loss: 3.6191 - accuracy: 0.09 - ETA: 1:51 - loss: 3.6198 - accuracy: 0.09 - ETA: 1:50 - loss: 3.6204 - accuracy: 0.09 - ETA: 1:50 - loss: 3.6200 - accuracy: 0.09 - ETA: 1:49 - loss: 3.6198 - accuracy: 0.09 - ETA: 1:49 - loss: 3.6198 - accuracy: 0.09 - ETA: 1:48 - loss: 3.6201 - accuracy: 0.09 - ETA: 1:48 - loss: 3.6200 - accuracy: 0.09 - ETA: 1:47 - loss: 3.6200 - accuracy: 0.09 - ETA: 1:46 - loss: 3.6198 - accuracy: 0.09 - ETA: 1:46 - loss: 3.6198 - accuracy: 0.09 - ETA: 1:45 - loss: 3.6189 - accuracy: 0.09 - ETA: 1:45 - loss: 3.6180 - accuracy: 0.09 - ETA: 1:44 - loss: 3.6184 - accuracy: 0.09 - ETA: 1:44 - loss: 3.6174 - accuracy: 0.09 - ETA: 1:43 - loss: 3.6169 - accuracy: 0.09 - ETA: 1:42 - loss: 3.6179 - accuracy: 0.09 - ETA: 1:42 - loss: 3.6179 - accuracy: 0.09 - ETA: 1:41 - loss: 3.6172 - accuracy: 0.09 - ETA: 1:41 - loss: 3.6170 - accuracy: 0.09 - ETA: 1:40 - loss: 3.6171 - accuracy: 0.09 - ETA: 1:39 - loss: 3.6176 - accuracy: 0.09 - ETA: 1:39 - loss: 3.6182 - accuracy: 0.09 - ETA: 1:38 - loss: 3.6174 - accuracy: 0.09 - ETA: 1:38 - loss: 3.6179 - accuracy: 0.09 - ETA: 1:37 - loss: 3.6182 - accuracy: 0.09 - ETA: 1:37 - loss: 3.6185 - accuracy: 0.09 - ETA: 1:36 - loss: 3.6189 - accuracy: 0.09 - ETA: 1:35 - loss: 3.6195 - accuracy: 0.09 - ETA: 1:35 - loss: 3.6192 - accuracy: 0.09 - ETA: 1:34 - loss: 3.6182 - accuracy: 0.09 - ETA: 1:34 - loss: 3.6173 - accuracy: 0.09 - ETA: 1:33 - loss: 3.6172 - accuracy: 0.09 - ETA: 1:33 - loss: 3.6165 - accuracy: 0.10 - ETA: 1:32 - loss: 3.6160 - accuracy: 0.10 - ETA: 1:31 - loss: 3.6164 - accuracy: 0.10 - ETA: 1:31 - loss: 3.6165 - accuracy: 0.09 - ETA: 1:30 - loss: 3.6164 - accuracy: 0.09 - ETA: 1:30 - loss: 3.6159 - accuracy: 0.09 - ETA: 1:29 - loss: 3.6148 - accuracy: 0.10 - ETA: 1:29 - loss: 3.6153 - accuracy: 0.10 - ETA: 1:28 - loss: 3.6151 - accuracy: 0.10 - ETA: 1:27 - loss: 3.6157 - accuracy: 0.10 - ETA: 1:27 - loss: 3.6158 - accuracy: 0.09 - ETA: 1:26 - loss: 3.6161 - accuracy: 0.09 - ETA: 1:26 - loss: 3.6147 - accuracy: 0.10 - ETA: 1:25 - loss: 3.6144 - accuracy: 0.10 - ETA: 1:25 - loss: 3.6140 - accuracy: 0.10 - ETA: 1:24 - loss: 3.6146 - accuracy: 0.10 - ETA: 1:24 - loss: 3.6143 - accuracy: 0.10 - ETA: 1:23 - loss: 3.6141 - accuracy: 0.1003"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:22 - loss: 3.6140 - accuracy: 0.10 - ETA: 1:22 - loss: 3.6135 - accuracy: 0.10 - ETA: 1:21 - loss: 3.6133 - accuracy: 0.10 - ETA: 1:21 - loss: 3.6133 - accuracy: 0.10 - ETA: 1:20 - loss: 3.6125 - accuracy: 0.10 - ETA: 1:20 - loss: 3.6116 - accuracy: 0.10 - ETA: 1:19 - loss: 3.6112 - accuracy: 0.10 - ETA: 1:18 - loss: 3.6108 - accuracy: 0.10 - ETA: 1:18 - loss: 3.6107 - accuracy: 0.10 - ETA: 1:17 - loss: 3.6108 - accuracy: 0.10 - ETA: 1:17 - loss: 3.6099 - accuracy: 0.10 - ETA: 1:16 - loss: 3.6098 - accuracy: 0.10 - ETA: 1:16 - loss: 3.6087 - accuracy: 0.10 - ETA: 1:15 - loss: 3.6084 - accuracy: 0.10 - ETA: 1:14 - loss: 3.6079 - accuracy: 0.10 - ETA: 1:14 - loss: 3.6071 - accuracy: 0.10 - ETA: 1:13 - loss: 3.6074 - accuracy: 0.10 - ETA: 1:13 - loss: 3.6072 - accuracy: 0.10 - ETA: 1:12 - loss: 3.6064 - accuracy: 0.10 - ETA: 1:11 - loss: 3.6066 - accuracy: 0.10 - ETA: 1:11 - loss: 3.6061 - accuracy: 0.10 - ETA: 1:10 - loss: 3.6054 - accuracy: 0.10 - ETA: 1:10 - loss: 3.6046 - accuracy: 0.10 - ETA: 1:09 - loss: 3.6041 - accuracy: 0.10 - ETA: 1:09 - loss: 3.6040 - accuracy: 0.10 - ETA: 1:08 - loss: 3.6036 - accuracy: 0.10 - ETA: 1:07 - loss: 3.6036 - accuracy: 0.10 - ETA: 1:07 - loss: 3.6038 - accuracy: 0.10 - ETA: 1:06 - loss: 3.6031 - accuracy: 0.10 - ETA: 1:06 - loss: 3.6029 - accuracy: 0.10 - ETA: 1:05 - loss: 3.6028 - accuracy: 0.10 - ETA: 1:05 - loss: 3.6023 - accuracy: 0.10 - ETA: 1:04 - loss: 3.6021 - accuracy: 0.10 - ETA: 1:03 - loss: 3.6023 - accuracy: 0.10 - ETA: 1:03 - loss: 3.6022 - accuracy: 0.10 - ETA: 1:02 - loss: 3.6018 - accuracy: 0.10 - ETA: 1:02 - loss: 3.6019 - accuracy: 0.10 - ETA: 1:01 - loss: 3.6023 - accuracy: 0.10 - ETA: 1:01 - loss: 3.6025 - accuracy: 0.10 - ETA: 1:00 - loss: 3.6020 - accuracy: 0.10 - ETA: 59s - loss: 3.6020 - accuracy: 0.1028 - ETA: 59s - loss: 3.6015 - accuracy: 0.103 - ETA: 58s - loss: 3.6020 - accuracy: 0.103 - ETA: 58s - loss: 3.6017 - accuracy: 0.103 - ETA: 57s - loss: 3.6018 - accuracy: 0.102 - ETA: 56s - loss: 3.6015 - accuracy: 0.102 - ETA: 56s - loss: 3.6017 - accuracy: 0.102 - ETA: 55s - loss: 3.6017 - accuracy: 0.102 - ETA: 55s - loss: 3.6019 - accuracy: 0.102 - ETA: 54s - loss: 3.6020 - accuracy: 0.103 - ETA: 54s - loss: 3.6013 - accuracy: 0.103 - ETA: 53s - loss: 3.6008 - accuracy: 0.103 - ETA: 52s - loss: 3.6009 - accuracy: 0.103 - ETA: 52s - loss: 3.6004 - accuracy: 0.103 - ETA: 51s - loss: 3.6002 - accuracy: 0.103 - ETA: 51s - loss: 3.5997 - accuracy: 0.103 - ETA: 50s - loss: 3.6003 - accuracy: 0.103 - ETA: 50s - loss: 3.6003 - accuracy: 0.103 - ETA: 49s - loss: 3.5994 - accuracy: 0.103 - ETA: 48s - loss: 3.5986 - accuracy: 0.103 - ETA: 48s - loss: 3.5988 - accuracy: 0.103 - ETA: 47s - loss: 3.5988 - accuracy: 0.103 - ETA: 47s - loss: 3.5991 - accuracy: 0.103 - ETA: 46s - loss: 3.5991 - accuracy: 0.103 - ETA: 46s - loss: 3.5984 - accuracy: 0.103 - ETA: 45s - loss: 3.5985 - accuracy: 0.103 - ETA: 44s - loss: 3.5990 - accuracy: 0.103 - ETA: 44s - loss: 3.5990 - accuracy: 0.103 - ETA: 43s - loss: 3.5986 - accuracy: 0.103 - ETA: 43s - loss: 3.5983 - accuracy: 0.103 - ETA: 42s - loss: 3.5975 - accuracy: 0.103 - ETA: 42s - loss: 3.5973 - accuracy: 0.104 - ETA: 41s - loss: 3.5967 - accuracy: 0.104 - ETA: 40s - loss: 3.5966 - accuracy: 0.104 - ETA: 40s - loss: 3.5965 - accuracy: 0.103 - ETA: 39s - loss: 3.5965 - accuracy: 0.103 - ETA: 39s - loss: 3.5964 - accuracy: 0.103 - ETA: 38s - loss: 3.5963 - accuracy: 0.104 - ETA: 37s - loss: 3.5960 - accuracy: 0.104 - ETA: 37s - loss: 3.5954 - accuracy: 0.104 - ETA: 36s - loss: 3.5949 - accuracy: 0.104 - ETA: 36s - loss: 3.5956 - accuracy: 0.104 - ETA: 35s - loss: 3.5953 - accuracy: 0.104 - ETA: 35s - loss: 3.5950 - accuracy: 0.104 - ETA: 34s - loss: 3.5948 - accuracy: 0.104 - ETA: 33s - loss: 3.5949 - accuracy: 0.104 - ETA: 33s - loss: 3.5954 - accuracy: 0.104 - ETA: 32s - loss: 3.5954 - accuracy: 0.104 - ETA: 32s - loss: 3.5952 - accuracy: 0.104 - ETA: 31s - loss: 3.5957 - accuracy: 0.103 - ETA: 31s - loss: 3.5958 - accuracy: 0.103 - ETA: 30s - loss: 3.5964 - accuracy: 0.103 - ETA: 29s - loss: 3.5963 - accuracy: 0.103 - ETA: 29s - loss: 3.5964 - accuracy: 0.103 - ETA: 28s - loss: 3.5961 - accuracy: 0.103 - ETA: 28s - loss: 3.5958 - accuracy: 0.103 - ETA: 27s - loss: 3.5957 - accuracy: 0.103 - ETA: 27s - loss: 3.5960 - accuracy: 0.103 - ETA: 26s - loss: 3.5960 - accuracy: 0.103 - ETA: 25s - loss: 3.5966 - accuracy: 0.103 - ETA: 25s - loss: 3.5963 - accuracy: 0.103 - ETA: 24s - loss: 3.5963 - accuracy: 0.103 - ETA: 24s - loss: 3.5962 - accuracy: 0.103 - ETA: 23s - loss: 3.5959 - accuracy: 0.103 - ETA: 23s - loss: 3.5957 - accuracy: 0.103 - ETA: 22s - loss: 3.5960 - accuracy: 0.103 - ETA: 21s - loss: 3.5959 - accuracy: 0.103 - ETA: 21s - loss: 3.5958 - accuracy: 0.103 - ETA: 20s - loss: 3.5958 - accuracy: 0.103 - ETA: 20s - loss: 3.5957 - accuracy: 0.103 - ETA: 19s - loss: 3.5955 - accuracy: 0.103 - ETA: 19s - loss: 3.5957 - accuracy: 0.103 - ETA: 18s - loss: 3.5960 - accuracy: 0.103 - ETA: 17s - loss: 3.5959 - accuracy: 0.103 - ETA: 17s - loss: 3.5963 - accuracy: 0.103 - ETA: 16s - loss: 3.5964 - accuracy: 0.103 - ETA: 16s - loss: 3.5958 - accuracy: 0.103 - ETA: 15s - loss: 3.5958 - accuracy: 0.103 - ETA: 15s - loss: 3.5955 - accuracy: 0.103 - ETA: 14s - loss: 3.5951 - accuracy: 0.103 - ETA: 13s - loss: 3.5954 - accuracy: 0.103 - ETA: 13s - loss: 3.5954 - accuracy: 0.103 - ETA: 12s - loss: 3.5952 - accuracy: 0.103 - ETA: 12s - loss: 3.5950 - accuracy: 0.103 - ETA: 11s - loss: 3.5956 - accuracy: 0.103 - ETA: 10s - loss: 3.5954 - accuracy: 0.103 - ETA: 10s - loss: 3.5952 - accuracy: 0.103 - ETA: 9s - loss: 3.5950 - accuracy: 0.103 - ETA: 9s - loss: 3.5950 - accuracy: 0.10 - ETA: 8s - loss: 3.5945 - accuracy: 0.10 - ETA: 8s - loss: 3.5945 - accuracy: 0.10 - ETA: 7s - loss: 3.5943 - accuracy: 0.10 - ETA: 6s - loss: 3.5937 - accuracy: 0.10 - ETA: 6s - loss: 3.5941 - accuracy: 0.10 - ETA: 5s - loss: 3.5938 - accuracy: 0.10 - ETA: 5s - loss: 3.5936 - accuracy: 0.10 - ETA: 4s - loss: 3.5938 - accuracy: 0.10 - ETA: 4s - loss: 3.5935 - accuracy: 0.10 - ETA: 3s - loss: 3.5932 - accuracy: 0.10 - ETA: 2s - loss: 3.5930 - accuracy: 0.10 - ETA: 2s - loss: 3.5927 - accuracy: 0.10 - ETA: 1s - loss: 3.5929 - accuracy: 0.10 - ETA: 1s - loss: 3.5931 - accuracy: 0.10 - ETA: 0s - loss: 3.5929 - accuracy: 0.10 - ETA: 0s - loss: 3.5928 - accuracy: 0.10 - 203s 5ms/step - loss: 3.5927 - accuracy: 0.1039 - val_loss: 3.8771 - val_accuracy: 0.0273\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:11 - loss: 3.4628 - accuracy: 0.15 - ETA: 3:14 - loss: 3.4152 - accuracy: 0.16 - ETA: 3:13 - loss: 3.4568 - accuracy: 0.14 - ETA: 3:14 - loss: 3.4615 - accuracy: 0.14 - ETA: 3:11 - loss: 3.4708 - accuracy: 0.13 - ETA: 3:09 - loss: 3.4920 - accuracy: 0.13 - ETA: 3:07 - loss: 3.5113 - accuracy: 0.12 - ETA: 3:05 - loss: 3.5410 - accuracy: 0.11 - ETA: 3:04 - loss: 3.5458 - accuracy: 0.11 - ETA: 3:03 - loss: 3.5580 - accuracy: 0.11 - ETA: 3:01 - loss: 3.5397 - accuracy: 0.11 - ETA: 3:00 - loss: 3.5507 - accuracy: 0.11 - ETA: 3:01 - loss: 3.5561 - accuracy: 0.11 - ETA: 3:00 - loss: 3.5626 - accuracy: 0.11 - ETA: 3:00 - loss: 3.5599 - accuracy: 0.11 - ETA: 2:59 - loss: 3.5527 - accuracy: 0.11 - ETA: 2:58 - loss: 3.5475 - accuracy: 0.11 - ETA: 2:58 - loss: 3.5492 - accuracy: 0.11 - ETA: 2:57 - loss: 3.5433 - accuracy: 0.11 - ETA: 2:56 - loss: 3.5501 - accuracy: 0.11 - ETA: 2:55 - loss: 3.5492 - accuracy: 0.11 - ETA: 2:56 - loss: 3.5572 - accuracy: 0.11 - ETA: 2:55 - loss: 3.5525 - accuracy: 0.12 - ETA: 2:54 - loss: 3.5504 - accuracy: 0.12 - ETA: 2:54 - loss: 3.5492 - accuracy: 0.12 - ETA: 2:53 - loss: 3.5524 - accuracy: 0.11 - ETA: 2:53 - loss: 3.5507 - accuracy: 0.12 - ETA: 2:52 - loss: 3.5521 - accuracy: 0.11 - ETA: 2:51 - loss: 3.5506 - accuracy: 0.11 - ETA: 2:51 - loss: 3.5476 - accuracy: 0.12 - ETA: 2:51 - loss: 3.5474 - accuracy: 0.12 - ETA: 2:51 - loss: 3.5490 - accuracy: 0.11 - ETA: 2:51 - loss: 3.5508 - accuracy: 0.11 - ETA: 2:50 - loss: 3.5485 - accuracy: 0.11 - ETA: 2:49 - loss: 3.5468 - accuracy: 0.11 - ETA: 2:48 - loss: 3.5464 - accuracy: 0.11 - ETA: 2:48 - loss: 3.5461 - accuracy: 0.11 - ETA: 2:47 - loss: 3.5417 - accuracy: 0.11 - ETA: 2:47 - loss: 3.5407 - accuracy: 0.12 - ETA: 2:46 - loss: 3.5410 - accuracy: 0.12 - ETA: 2:46 - loss: 3.5441 - accuracy: 0.11 - ETA: 2:45 - loss: 3.5478 - accuracy: 0.11 - ETA: 2:44 - loss: 3.5460 - accuracy: 0.11 - ETA: 2:43 - loss: 3.5488 - accuracy: 0.11 - ETA: 2:43 - loss: 3.5508 - accuracy: 0.11 - ETA: 2:42 - loss: 3.5477 - accuracy: 0.11 - ETA: 2:42 - loss: 3.5494 - accuracy: 0.11 - ETA: 2:41 - loss: 3.5516 - accuracy: 0.11 - ETA: 2:40 - loss: 3.5528 - accuracy: 0.11 - ETA: 2:40 - loss: 3.5530 - accuracy: 0.11 - ETA: 2:39 - loss: 3.5523 - accuracy: 0.11 - ETA: 2:39 - loss: 3.5540 - accuracy: 0.11 - ETA: 2:38 - loss: 3.5513 - accuracy: 0.11 - ETA: 2:38 - loss: 3.5517 - accuracy: 0.11 - ETA: 2:38 - loss: 3.5499 - accuracy: 0.11 - ETA: 2:37 - loss: 3.5487 - accuracy: 0.11 - ETA: 2:37 - loss: 3.5502 - accuracy: 0.11 - ETA: 2:37 - loss: 3.5478 - accuracy: 0.11 - ETA: 2:36 - loss: 3.5492 - accuracy: 0.11 - ETA: 2:36 - loss: 3.5478 - accuracy: 0.11 - ETA: 2:35 - loss: 3.5475 - accuracy: 0.11 - ETA: 2:35 - loss: 3.5475 - accuracy: 0.11 - ETA: 2:34 - loss: 3.5452 - accuracy: 0.11 - ETA: 2:33 - loss: 3.5436 - accuracy: 0.11 - ETA: 2:33 - loss: 3.5435 - accuracy: 0.11 - ETA: 2:32 - loss: 3.5440 - accuracy: 0.11 - ETA: 2:32 - loss: 3.5445 - accuracy: 0.11 - ETA: 2:31 - loss: 3.5441 - accuracy: 0.11 - ETA: 2:30 - loss: 3.5452 - accuracy: 0.11 - ETA: 2:30 - loss: 3.5479 - accuracy: 0.11 - ETA: 2:29 - loss: 3.5469 - accuracy: 0.11 - ETA: 2:28 - loss: 3.5466 - accuracy: 0.11 - ETA: 2:28 - loss: 3.5460 - accuracy: 0.11 - ETA: 2:27 - loss: 3.5447 - accuracy: 0.11 - ETA: 2:27 - loss: 3.5457 - accuracy: 0.11 - ETA: 2:26 - loss: 3.5462 - accuracy: 0.11 - ETA: 2:26 - loss: 3.5440 - accuracy: 0.11 - ETA: 2:25 - loss: 3.5423 - accuracy: 0.11 - ETA: 2:24 - loss: 3.5432 - accuracy: 0.11 - ETA: 2:24 - loss: 3.5440 - accuracy: 0.11 - ETA: 2:23 - loss: 3.5424 - accuracy: 0.11 - ETA: 2:22 - loss: 3.5424 - accuracy: 0.11 - ETA: 2:22 - loss: 3.5410 - accuracy: 0.11 - ETA: 2:21 - loss: 3.5416 - accuracy: 0.11 - ETA: 2:21 - loss: 3.5410 - accuracy: 0.11 - ETA: 2:20 - loss: 3.5412 - accuracy: 0.11 - ETA: 2:20 - loss: 3.5411 - accuracy: 0.11 - ETA: 2:19 - loss: 3.5409 - accuracy: 0.11 - ETA: 2:19 - loss: 3.5400 - accuracy: 0.11 - ETA: 2:18 - loss: 3.5386 - accuracy: 0.11 - ETA: 2:18 - loss: 3.5353 - accuracy: 0.11 - ETA: 2:17 - loss: 3.5332 - accuracy: 0.11 - ETA: 2:17 - loss: 3.5352 - accuracy: 0.11 - ETA: 2:16 - loss: 3.5359 - accuracy: 0.11 - ETA: 2:15 - loss: 3.5355 - accuracy: 0.11 - ETA: 2:15 - loss: 3.5346 - accuracy: 0.11 - ETA: 2:14 - loss: 3.5345 - accuracy: 0.11 - ETA: 2:14 - loss: 3.5347 - accuracy: 0.11 - ETA: 2:13 - loss: 3.5349 - accuracy: 0.11 - ETA: 2:12 - loss: 3.5346 - accuracy: 0.11 - ETA: 2:12 - loss: 3.5355 - accuracy: 0.11 - ETA: 2:11 - loss: 3.5359 - accuracy: 0.11 - ETA: 2:11 - loss: 3.5355 - accuracy: 0.11 - ETA: 2:10 - loss: 3.5342 - accuracy: 0.11 - ETA: 2:09 - loss: 3.5342 - accuracy: 0.11 - ETA: 2:09 - loss: 3.5349 - accuracy: 0.11 - ETA: 2:08 - loss: 3.5346 - accuracy: 0.11 - ETA: 2:08 - loss: 3.5347 - accuracy: 0.11 - ETA: 2:07 - loss: 3.5343 - accuracy: 0.11 - ETA: 2:06 - loss: 3.5339 - accuracy: 0.11 - ETA: 2:06 - loss: 3.5336 - accuracy: 0.11 - ETA: 2:05 - loss: 3.5347 - accuracy: 0.11 - ETA: 2:05 - loss: 3.5336 - accuracy: 0.11 - ETA: 2:04 - loss: 3.5323 - accuracy: 0.11 - ETA: 2:04 - loss: 3.5318 - accuracy: 0.11 - ETA: 2:03 - loss: 3.5322 - accuracy: 0.11 - ETA: 2:03 - loss: 3.5309 - accuracy: 0.11 - ETA: 2:02 - loss: 3.5307 - accuracy: 0.11 - ETA: 2:01 - loss: 3.5308 - accuracy: 0.11 - ETA: 2:01 - loss: 3.5310 - accuracy: 0.11 - ETA: 2:00 - loss: 3.5308 - accuracy: 0.11 - ETA: 2:00 - loss: 3.5302 - accuracy: 0.11 - ETA: 1:59 - loss: 3.5309 - accuracy: 0.11 - ETA: 1:58 - loss: 3.5313 - accuracy: 0.11 - ETA: 1:58 - loss: 3.5315 - accuracy: 0.11 - ETA: 1:57 - loss: 3.5314 - accuracy: 0.11 - ETA: 1:57 - loss: 3.5325 - accuracy: 0.11 - ETA: 1:56 - loss: 3.5334 - accuracy: 0.11 - ETA: 1:56 - loss: 3.5326 - accuracy: 0.11 - ETA: 1:55 - loss: 3.5317 - accuracy: 0.11 - ETA: 1:54 - loss: 3.5325 - accuracy: 0.11 - ETA: 1:54 - loss: 3.5316 - accuracy: 0.11 - ETA: 1:53 - loss: 3.5318 - accuracy: 0.11 - ETA: 1:53 - loss: 3.5317 - accuracy: 0.11 - ETA: 1:52 - loss: 3.5314 - accuracy: 0.11 - ETA: 1:52 - loss: 3.5301 - accuracy: 0.11 - ETA: 1:51 - loss: 3.5308 - accuracy: 0.11 - ETA: 1:50 - loss: 3.5308 - accuracy: 0.11 - ETA: 1:50 - loss: 3.5310 - accuracy: 0.11 - ETA: 1:49 - loss: 3.5309 - accuracy: 0.11 - ETA: 1:49 - loss: 3.5315 - accuracy: 0.11 - ETA: 1:48 - loss: 3.5317 - accuracy: 0.11 - ETA: 1:48 - loss: 3.5311 - accuracy: 0.11 - ETA: 1:47 - loss: 3.5310 - accuracy: 0.11 - ETA: 1:47 - loss: 3.5312 - accuracy: 0.11 - ETA: 1:46 - loss: 3.5298 - accuracy: 0.11 - ETA: 1:45 - loss: 3.5303 - accuracy: 0.11 - ETA: 1:45 - loss: 3.5301 - accuracy: 0.11 - ETA: 1:44 - loss: 3.5301 - accuracy: 0.11 - ETA: 1:44 - loss: 3.5306 - accuracy: 0.11 - ETA: 1:43 - loss: 3.5299 - accuracy: 0.11 - ETA: 1:42 - loss: 3.5299 - accuracy: 0.11 - ETA: 1:42 - loss: 3.5297 - accuracy: 0.11 - ETA: 1:41 - loss: 3.5296 - accuracy: 0.11 - ETA: 1:41 - loss: 3.5285 - accuracy: 0.11 - ETA: 1:40 - loss: 3.5283 - accuracy: 0.11 - ETA: 1:40 - loss: 3.5282 - accuracy: 0.11 - ETA: 1:39 - loss: 3.5280 - accuracy: 0.11 - ETA: 1:38 - loss: 3.5290 - accuracy: 0.11 - ETA: 1:38 - loss: 3.5284 - accuracy: 0.11 - ETA: 1:37 - loss: 3.5288 - accuracy: 0.11 - ETA: 1:37 - loss: 3.5271 - accuracy: 0.11 - ETA: 1:36 - loss: 3.5264 - accuracy: 0.11 - ETA: 1:35 - loss: 3.5263 - accuracy: 0.11 - ETA: 1:35 - loss: 3.5253 - accuracy: 0.11 - ETA: 1:34 - loss: 3.5253 - accuracy: 0.11 - ETA: 1:34 - loss: 3.5250 - accuracy: 0.11 - ETA: 1:33 - loss: 3.5244 - accuracy: 0.11 - ETA: 1:33 - loss: 3.5249 - accuracy: 0.11 - ETA: 1:32 - loss: 3.5252 - accuracy: 0.11 - ETA: 1:32 - loss: 3.5252 - accuracy: 0.11 - ETA: 1:31 - loss: 3.5242 - accuracy: 0.11 - ETA: 1:31 - loss: 3.5250 - accuracy: 0.11 - ETA: 1:30 - loss: 3.5254 - accuracy: 0.11 - ETA: 1:29 - loss: 3.5261 - accuracy: 0.11 - ETA: 1:29 - loss: 3.5259 - accuracy: 0.11 - ETA: 1:28 - loss: 3.5256 - accuracy: 0.11 - ETA: 1:28 - loss: 3.5258 - accuracy: 0.11 - ETA: 1:27 - loss: 3.5255 - accuracy: 0.11 - ETA: 1:26 - loss: 3.5257 - accuracy: 0.11 - ETA: 1:26 - loss: 3.5261 - accuracy: 0.11 - ETA: 1:25 - loss: 3.5264 - accuracy: 0.11 - ETA: 1:25 - loss: 3.5265 - accuracy: 0.11 - ETA: 1:24 - loss: 3.5262 - accuracy: 0.11 - ETA: 1:23 - loss: 3.5272 - accuracy: 0.11 - ETA: 1:23 - loss: 3.5269 - accuracy: 0.1145"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:22 - loss: 3.5264 - accuracy: 0.11 - ETA: 1:22 - loss: 3.5260 - accuracy: 0.11 - ETA: 1:21 - loss: 3.5264 - accuracy: 0.11 - ETA: 1:21 - loss: 3.5274 - accuracy: 0.11 - ETA: 1:20 - loss: 3.5266 - accuracy: 0.11 - ETA: 1:19 - loss: 3.5259 - accuracy: 0.11 - ETA: 1:19 - loss: 3.5256 - accuracy: 0.11 - ETA: 1:18 - loss: 3.5245 - accuracy: 0.11 - ETA: 1:18 - loss: 3.5253 - accuracy: 0.11 - ETA: 1:17 - loss: 3.5250 - accuracy: 0.11 - ETA: 1:17 - loss: 3.5244 - accuracy: 0.11 - ETA: 1:16 - loss: 3.5244 - accuracy: 0.11 - ETA: 1:15 - loss: 3.5250 - accuracy: 0.11 - ETA: 1:15 - loss: 3.5259 - accuracy: 0.11 - ETA: 1:14 - loss: 3.5256 - accuracy: 0.11 - ETA: 1:14 - loss: 3.5254 - accuracy: 0.11 - ETA: 1:13 - loss: 3.5252 - accuracy: 0.11 - ETA: 1:13 - loss: 3.5255 - accuracy: 0.11 - ETA: 1:12 - loss: 3.5256 - accuracy: 0.11 - ETA: 1:11 - loss: 3.5261 - accuracy: 0.11 - ETA: 1:11 - loss: 3.5253 - accuracy: 0.11 - ETA: 1:10 - loss: 3.5260 - accuracy: 0.11 - ETA: 1:10 - loss: 3.5258 - accuracy: 0.11 - ETA: 1:09 - loss: 3.5262 - accuracy: 0.11 - ETA: 1:09 - loss: 3.5261 - accuracy: 0.11 - ETA: 1:08 - loss: 3.5259 - accuracy: 0.11 - ETA: 1:07 - loss: 3.5249 - accuracy: 0.11 - ETA: 1:07 - loss: 3.5245 - accuracy: 0.11 - ETA: 1:06 - loss: 3.5249 - accuracy: 0.11 - ETA: 1:06 - loss: 3.5237 - accuracy: 0.11 - ETA: 1:05 - loss: 3.5234 - accuracy: 0.11 - ETA: 1:05 - loss: 3.5222 - accuracy: 0.11 - ETA: 1:04 - loss: 3.5220 - accuracy: 0.11 - ETA: 1:03 - loss: 3.5213 - accuracy: 0.11 - ETA: 1:03 - loss: 3.5215 - accuracy: 0.11 - ETA: 1:02 - loss: 3.5209 - accuracy: 0.11 - ETA: 1:02 - loss: 3.5209 - accuracy: 0.11 - ETA: 1:01 - loss: 3.5210 - accuracy: 0.11 - ETA: 1:00 - loss: 3.5207 - accuracy: 0.11 - ETA: 1:00 - loss: 3.5202 - accuracy: 0.11 - ETA: 59s - loss: 3.5200 - accuracy: 0.1150 - ETA: 59s - loss: 3.5198 - accuracy: 0.114 - ETA: 58s - loss: 3.5198 - accuracy: 0.114 - ETA: 58s - loss: 3.5202 - accuracy: 0.115 - ETA: 57s - loss: 3.5201 - accuracy: 0.115 - ETA: 56s - loss: 3.5196 - accuracy: 0.115 - ETA: 56s - loss: 3.5193 - accuracy: 0.115 - ETA: 55s - loss: 3.5186 - accuracy: 0.115 - ETA: 55s - loss: 3.5183 - accuracy: 0.115 - ETA: 54s - loss: 3.5186 - accuracy: 0.115 - ETA: 54s - loss: 3.5178 - accuracy: 0.115 - ETA: 53s - loss: 3.5179 - accuracy: 0.115 - ETA: 52s - loss: 3.5173 - accuracy: 0.115 - ETA: 52s - loss: 3.5171 - accuracy: 0.115 - ETA: 51s - loss: 3.5167 - accuracy: 0.115 - ETA: 51s - loss: 3.5170 - accuracy: 0.115 - ETA: 50s - loss: 3.5171 - accuracy: 0.115 - ETA: 50s - loss: 3.5165 - accuracy: 0.115 - ETA: 49s - loss: 3.5167 - accuracy: 0.115 - ETA: 48s - loss: 3.5165 - accuracy: 0.115 - ETA: 48s - loss: 3.5167 - accuracy: 0.115 - ETA: 47s - loss: 3.5166 - accuracy: 0.115 - ETA: 47s - loss: 3.5167 - accuracy: 0.115 - ETA: 46s - loss: 3.5168 - accuracy: 0.115 - ETA: 46s - loss: 3.5174 - accuracy: 0.115 - ETA: 45s - loss: 3.5166 - accuracy: 0.115 - ETA: 44s - loss: 3.5168 - accuracy: 0.115 - ETA: 44s - loss: 3.5166 - accuracy: 0.115 - ETA: 43s - loss: 3.5170 - accuracy: 0.115 - ETA: 43s - loss: 3.5172 - accuracy: 0.115 - ETA: 42s - loss: 3.5166 - accuracy: 0.115 - ETA: 42s - loss: 3.5170 - accuracy: 0.115 - ETA: 41s - loss: 3.5170 - accuracy: 0.115 - ETA: 40s - loss: 3.5172 - accuracy: 0.115 - ETA: 40s - loss: 3.5168 - accuracy: 0.115 - ETA: 39s - loss: 3.5169 - accuracy: 0.115 - ETA: 39s - loss: 3.5163 - accuracy: 0.116 - ETA: 38s - loss: 3.5164 - accuracy: 0.116 - ETA: 38s - loss: 3.5162 - accuracy: 0.116 - ETA: 37s - loss: 3.5160 - accuracy: 0.116 - ETA: 36s - loss: 3.5153 - accuracy: 0.116 - ETA: 36s - loss: 3.5155 - accuracy: 0.116 - ETA: 35s - loss: 3.5157 - accuracy: 0.116 - ETA: 35s - loss: 3.5158 - accuracy: 0.116 - ETA: 34s - loss: 3.5160 - accuracy: 0.116 - ETA: 34s - loss: 3.5162 - accuracy: 0.116 - ETA: 33s - loss: 3.5166 - accuracy: 0.116 - ETA: 32s - loss: 3.5168 - accuracy: 0.116 - ETA: 32s - loss: 3.5168 - accuracy: 0.116 - ETA: 31s - loss: 3.5163 - accuracy: 0.116 - ETA: 31s - loss: 3.5163 - accuracy: 0.116 - ETA: 30s - loss: 3.5165 - accuracy: 0.116 - ETA: 30s - loss: 3.5168 - accuracy: 0.116 - ETA: 29s - loss: 3.5164 - accuracy: 0.116 - ETA: 28s - loss: 3.5157 - accuracy: 0.116 - ETA: 28s - loss: 3.5153 - accuracy: 0.116 - ETA: 27s - loss: 3.5159 - accuracy: 0.116 - ETA: 27s - loss: 3.5156 - accuracy: 0.116 - ETA: 26s - loss: 3.5158 - accuracy: 0.116 - ETA: 26s - loss: 3.5155 - accuracy: 0.116 - ETA: 25s - loss: 3.5152 - accuracy: 0.116 - ETA: 24s - loss: 3.5148 - accuracy: 0.116 - ETA: 24s - loss: 3.5147 - accuracy: 0.116 - ETA: 23s - loss: 3.5144 - accuracy: 0.116 - ETA: 23s - loss: 3.5146 - accuracy: 0.116 - ETA: 22s - loss: 3.5143 - accuracy: 0.116 - ETA: 22s - loss: 3.5146 - accuracy: 0.116 - ETA: 21s - loss: 3.5148 - accuracy: 0.116 - ETA: 20s - loss: 3.5148 - accuracy: 0.116 - ETA: 20s - loss: 3.5144 - accuracy: 0.116 - ETA: 19s - loss: 3.5145 - accuracy: 0.116 - ETA: 19s - loss: 3.5140 - accuracy: 0.116 - ETA: 18s - loss: 3.5136 - accuracy: 0.116 - ETA: 17s - loss: 3.5137 - accuracy: 0.116 - ETA: 17s - loss: 3.5137 - accuracy: 0.116 - ETA: 16s - loss: 3.5135 - accuracy: 0.116 - ETA: 16s - loss: 3.5129 - accuracy: 0.116 - ETA: 15s - loss: 3.5131 - accuracy: 0.116 - ETA: 15s - loss: 3.5126 - accuracy: 0.117 - ETA: 14s - loss: 3.5126 - accuracy: 0.117 - ETA: 13s - loss: 3.5127 - accuracy: 0.116 - ETA: 13s - loss: 3.5130 - accuracy: 0.116 - ETA: 12s - loss: 3.5126 - accuracy: 0.117 - ETA: 12s - loss: 3.5126 - accuracy: 0.117 - ETA: 11s - loss: 3.5124 - accuracy: 0.117 - ETA: 11s - loss: 3.5123 - accuracy: 0.117 - ETA: 10s - loss: 3.5124 - accuracy: 0.117 - ETA: 9s - loss: 3.5118 - accuracy: 0.117 - ETA: 9s - loss: 3.5119 - accuracy: 0.11 - ETA: 8s - loss: 3.5117 - accuracy: 0.11 - ETA: 8s - loss: 3.5112 - accuracy: 0.11 - ETA: 7s - loss: 3.5108 - accuracy: 0.11 - ETA: 6s - loss: 3.5103 - accuracy: 0.11 - ETA: 6s - loss: 3.5102 - accuracy: 0.11 - ETA: 5s - loss: 3.5100 - accuracy: 0.11 - ETA: 5s - loss: 3.5100 - accuracy: 0.11 - ETA: 4s - loss: 3.5097 - accuracy: 0.11 - ETA: 4s - loss: 3.5091 - accuracy: 0.11 - ETA: 3s - loss: 3.5090 - accuracy: 0.11 - ETA: 2s - loss: 3.5089 - accuracy: 0.11 - ETA: 2s - loss: 3.5087 - accuracy: 0.11 - ETA: 1s - loss: 3.5088 - accuracy: 0.11 - ETA: 1s - loss: 3.5079 - accuracy: 0.11 - ETA: 0s - loss: 3.5079 - accuracy: 0.11 - ETA: 0s - loss: 3.5076 - accuracy: 0.11 - 204s 5ms/step - loss: 3.5076 - accuracy: 0.1182 - val_loss: 3.8820 - val_accuracy: 0.0340\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:17 - loss: 3.5676 - accuracy: 0.10 - ETA: 3:07 - loss: 3.4598 - accuracy: 0.12 - ETA: 3:05 - loss: 3.4784 - accuracy: 0.12 - ETA: 3:04 - loss: 3.4992 - accuracy: 0.11 - ETA: 3:02 - loss: 3.4475 - accuracy: 0.12 - ETA: 3:03 - loss: 3.4132 - accuracy: 0.13 - ETA: 3:04 - loss: 3.4162 - accuracy: 0.13 - ETA: 3:03 - loss: 3.4219 - accuracy: 0.13 - ETA: 3:03 - loss: 3.4123 - accuracy: 0.13 - ETA: 3:04 - loss: 3.4298 - accuracy: 0.13 - ETA: 3:05 - loss: 3.4281 - accuracy: 0.13 - ETA: 3:05 - loss: 3.4245 - accuracy: 0.13 - ETA: 3:04 - loss: 3.4271 - accuracy: 0.13 - ETA: 3:02 - loss: 3.4275 - accuracy: 0.13 - ETA: 3:02 - loss: 3.4172 - accuracy: 0.13 - ETA: 3:01 - loss: 3.4303 - accuracy: 0.12 - ETA: 3:00 - loss: 3.4345 - accuracy: 0.12 - ETA: 3:00 - loss: 3.4347 - accuracy: 0.12 - ETA: 2:59 - loss: 3.4415 - accuracy: 0.12 - ETA: 2:58 - loss: 3.4431 - accuracy: 0.12 - ETA: 2:57 - loss: 3.4503 - accuracy: 0.12 - ETA: 2:57 - loss: 3.4489 - accuracy: 0.12 - ETA: 2:56 - loss: 3.4414 - accuracy: 0.12 - ETA: 2:55 - loss: 3.4456 - accuracy: 0.12 - ETA: 2:54 - loss: 3.4467 - accuracy: 0.12 - ETA: 2:54 - loss: 3.4486 - accuracy: 0.12 - ETA: 2:53 - loss: 3.4508 - accuracy: 0.12 - ETA: 2:52 - loss: 3.4462 - accuracy: 0.12 - ETA: 2:52 - loss: 3.4465 - accuracy: 0.12 - ETA: 2:51 - loss: 3.4414 - accuracy: 0.12 - ETA: 2:50 - loss: 3.4476 - accuracy: 0.12 - ETA: 2:50 - loss: 3.4472 - accuracy: 0.12 - ETA: 2:49 - loss: 3.4496 - accuracy: 0.12 - ETA: 2:49 - loss: 3.4560 - accuracy: 0.12 - ETA: 2:48 - loss: 3.4524 - accuracy: 0.12 - ETA: 2:48 - loss: 3.4524 - accuracy: 0.12 - ETA: 2:47 - loss: 3.4538 - accuracy: 0.12 - ETA: 2:47 - loss: 3.4540 - accuracy: 0.12 - ETA: 2:46 - loss: 3.4538 - accuracy: 0.12 - ETA: 2:46 - loss: 3.4529 - accuracy: 0.12 - ETA: 2:46 - loss: 3.4539 - accuracy: 0.12 - ETA: 2:45 - loss: 3.4555 - accuracy: 0.12 - ETA: 2:45 - loss: 3.4559 - accuracy: 0.12 - ETA: 2:44 - loss: 3.4539 - accuracy: 0.12 - ETA: 2:44 - loss: 3.4541 - accuracy: 0.12 - ETA: 2:43 - loss: 3.4581 - accuracy: 0.12 - ETA: 2:43 - loss: 3.4563 - accuracy: 0.12 - ETA: 2:42 - loss: 3.4540 - accuracy: 0.12 - ETA: 2:41 - loss: 3.4546 - accuracy: 0.12 - ETA: 2:41 - loss: 3.4562 - accuracy: 0.12 - ETA: 2:40 - loss: 3.4533 - accuracy: 0.12 - ETA: 2:40 - loss: 3.4564 - accuracy: 0.12 - ETA: 2:39 - loss: 3.4548 - accuracy: 0.12 - ETA: 2:38 - loss: 3.4562 - accuracy: 0.12 - ETA: 2:38 - loss: 3.4552 - accuracy: 0.12 - ETA: 2:37 - loss: 3.4559 - accuracy: 0.12 - ETA: 2:36 - loss: 3.4575 - accuracy: 0.12 - ETA: 2:36 - loss: 3.4581 - accuracy: 0.12 - ETA: 2:35 - loss: 3.4562 - accuracy: 0.12 - ETA: 2:35 - loss: 3.4565 - accuracy: 0.12 - ETA: 2:34 - loss: 3.4606 - accuracy: 0.12 - ETA: 2:34 - loss: 3.4608 - accuracy: 0.12 - ETA: 2:33 - loss: 3.4603 - accuracy: 0.12 - ETA: 2:32 - loss: 3.4622 - accuracy: 0.12 - ETA: 2:32 - loss: 3.4618 - accuracy: 0.12 - ETA: 2:31 - loss: 3.4643 - accuracy: 0.12 - ETA: 2:31 - loss: 3.4614 - accuracy: 0.12 - ETA: 2:30 - loss: 3.4615 - accuracy: 0.12 - ETA: 2:30 - loss: 3.4631 - accuracy: 0.12 - ETA: 2:29 - loss: 3.4636 - accuracy: 0.12 - ETA: 2:29 - loss: 3.4630 - accuracy: 0.12 - ETA: 2:28 - loss: 3.4613 - accuracy: 0.12 - ETA: 2:27 - loss: 3.4618 - accuracy: 0.12 - ETA: 2:27 - loss: 3.4626 - accuracy: 0.12 - ETA: 2:26 - loss: 3.4602 - accuracy: 0.12 - ETA: 2:26 - loss: 3.4616 - accuracy: 0.12 - ETA: 2:25 - loss: 3.4626 - accuracy: 0.12 - ETA: 2:24 - loss: 3.4606 - accuracy: 0.12 - ETA: 2:24 - loss: 3.4613 - accuracy: 0.12 - ETA: 2:23 - loss: 3.4584 - accuracy: 0.12 - ETA: 2:23 - loss: 3.4584 - accuracy: 0.12 - ETA: 2:22 - loss: 3.4579 - accuracy: 0.12 - ETA: 2:22 - loss: 3.4589 - accuracy: 0.12 - ETA: 2:21 - loss: 3.4595 - accuracy: 0.12 - ETA: 2:20 - loss: 3.4600 - accuracy: 0.12 - ETA: 2:20 - loss: 3.4571 - accuracy: 0.12 - ETA: 2:19 - loss: 3.4570 - accuracy: 0.12 - ETA: 2:19 - loss: 3.4582 - accuracy: 0.12 - ETA: 2:18 - loss: 3.4590 - accuracy: 0.12 - ETA: 2:17 - loss: 3.4611 - accuracy: 0.12 - ETA: 2:17 - loss: 3.4609 - accuracy: 0.12 - ETA: 2:16 - loss: 3.4611 - accuracy: 0.12 - ETA: 2:16 - loss: 3.4625 - accuracy: 0.12 - ETA: 2:15 - loss: 3.4627 - accuracy: 0.12 - ETA: 2:15 - loss: 3.4628 - accuracy: 0.12 - ETA: 2:14 - loss: 3.4630 - accuracy: 0.12 - ETA: 2:14 - loss: 3.4623 - accuracy: 0.12 - ETA: 2:13 - loss: 3.4629 - accuracy: 0.12 - ETA: 2:12 - loss: 3.4626 - accuracy: 0.12 - ETA: 2:12 - loss: 3.4641 - accuracy: 0.12 - ETA: 2:11 - loss: 3.4648 - accuracy: 0.12 - ETA: 2:11 - loss: 3.4651 - accuracy: 0.12 - ETA: 2:10 - loss: 3.4659 - accuracy: 0.12 - ETA: 2:09 - loss: 3.4645 - accuracy: 0.12 - ETA: 2:09 - loss: 3.4651 - accuracy: 0.12 - ETA: 2:08 - loss: 3.4668 - accuracy: 0.12 - ETA: 2:08 - loss: 3.4669 - accuracy: 0.12 - ETA: 2:07 - loss: 3.4673 - accuracy: 0.12 - ETA: 2:07 - loss: 3.4671 - accuracy: 0.12 - ETA: 2:06 - loss: 3.4676 - accuracy: 0.12 - ETA: 2:06 - loss: 3.4683 - accuracy: 0.12 - ETA: 2:05 - loss: 3.4678 - accuracy: 0.12 - ETA: 2:04 - loss: 3.4678 - accuracy: 0.12 - ETA: 2:04 - loss: 3.4680 - accuracy: 0.12 - ETA: 2:03 - loss: 3.4689 - accuracy: 0.12 - ETA: 2:03 - loss: 3.4685 - accuracy: 0.12 - ETA: 2:02 - loss: 3.4708 - accuracy: 0.12 - ETA: 2:02 - loss: 3.4734 - accuracy: 0.12 - ETA: 2:01 - loss: 3.4737 - accuracy: 0.12 - ETA: 2:01 - loss: 3.4749 - accuracy: 0.12 - ETA: 2:00 - loss: 3.4763 - accuracy: 0.12 - ETA: 2:00 - loss: 3.4765 - accuracy: 0.12 - ETA: 1:59 - loss: 3.4756 - accuracy: 0.12 - ETA: 1:59 - loss: 3.4754 - accuracy: 0.12 - ETA: 1:58 - loss: 3.4743 - accuracy: 0.12 - ETA: 1:58 - loss: 3.4750 - accuracy: 0.12 - ETA: 1:57 - loss: 3.4727 - accuracy: 0.12 - ETA: 1:57 - loss: 3.4732 - accuracy: 0.12 - ETA: 1:56 - loss: 3.4750 - accuracy: 0.12 - ETA: 1:56 - loss: 3.4757 - accuracy: 0.12 - ETA: 1:55 - loss: 3.4753 - accuracy: 0.12 - ETA: 1:54 - loss: 3.4762 - accuracy: 0.12 - ETA: 1:54 - loss: 3.4759 - accuracy: 0.12 - ETA: 1:53 - loss: 3.4750 - accuracy: 0.12 - ETA: 1:53 - loss: 3.4756 - accuracy: 0.12 - ETA: 1:52 - loss: 3.4763 - accuracy: 0.12 - ETA: 1:51 - loss: 3.4762 - accuracy: 0.12 - ETA: 1:51 - loss: 3.4764 - accuracy: 0.12 - ETA: 1:50 - loss: 3.4760 - accuracy: 0.12 - ETA: 1:50 - loss: 3.4754 - accuracy: 0.12 - ETA: 1:49 - loss: 3.4753 - accuracy: 0.12 - ETA: 1:49 - loss: 3.4753 - accuracy: 0.12 - ETA: 1:48 - loss: 3.4757 - accuracy: 0.12 - ETA: 1:47 - loss: 3.4773 - accuracy: 0.12 - ETA: 1:47 - loss: 3.4770 - accuracy: 0.12 - ETA: 1:46 - loss: 3.4775 - accuracy: 0.12 - ETA: 1:46 - loss: 3.4773 - accuracy: 0.12 - ETA: 1:45 - loss: 3.4773 - accuracy: 0.12 - ETA: 1:45 - loss: 3.4768 - accuracy: 0.12 - ETA: 1:44 - loss: 3.4767 - accuracy: 0.12 - ETA: 1:44 - loss: 3.4769 - accuracy: 0.12 - ETA: 1:43 - loss: 3.4775 - accuracy: 0.12 - ETA: 1:42 - loss: 3.4775 - accuracy: 0.12 - ETA: 1:42 - loss: 3.4773 - accuracy: 0.12 - ETA: 1:41 - loss: 3.4771 - accuracy: 0.12 - ETA: 1:41 - loss: 3.4777 - accuracy: 0.12 - ETA: 1:40 - loss: 3.4772 - accuracy: 0.12 - ETA: 1:40 - loss: 3.4766 - accuracy: 0.12 - ETA: 1:39 - loss: 3.4774 - accuracy: 0.12 - ETA: 1:38 - loss: 3.4774 - accuracy: 0.12 - ETA: 1:38 - loss: 3.4780 - accuracy: 0.12 - ETA: 1:37 - loss: 3.4778 - accuracy: 0.12 - ETA: 1:37 - loss: 3.4772 - accuracy: 0.12 - ETA: 1:36 - loss: 3.4769 - accuracy: 0.12 - ETA: 1:36 - loss: 3.4773 - accuracy: 0.12 - ETA: 1:35 - loss: 3.4779 - accuracy: 0.12 - ETA: 1:34 - loss: 3.4777 - accuracy: 0.12 - ETA: 1:34 - loss: 3.4779 - accuracy: 0.12 - ETA: 1:33 - loss: 3.4782 - accuracy: 0.12 - ETA: 1:33 - loss: 3.4787 - accuracy: 0.12 - ETA: 1:32 - loss: 3.4790 - accuracy: 0.12 - ETA: 1:32 - loss: 3.4787 - accuracy: 0.12 - ETA: 1:31 - loss: 3.4787 - accuracy: 0.12 - ETA: 1:30 - loss: 3.4790 - accuracy: 0.12 - ETA: 1:30 - loss: 3.4801 - accuracy: 0.12 - ETA: 1:29 - loss: 3.4787 - accuracy: 0.12 - ETA: 1:29 - loss: 3.4799 - accuracy: 0.12 - ETA: 1:28 - loss: 3.4804 - accuracy: 0.12 - ETA: 1:28 - loss: 3.4804 - accuracy: 0.12 - ETA: 1:27 - loss: 3.4800 - accuracy: 0.12 - ETA: 1:27 - loss: 3.4795 - accuracy: 0.12 - ETA: 1:26 - loss: 3.4788 - accuracy: 0.12 - ETA: 1:25 - loss: 3.4789 - accuracy: 0.12 - ETA: 1:25 - loss: 3.4785 - accuracy: 0.12 - ETA: 1:24 - loss: 3.4780 - accuracy: 0.12 - ETA: 1:24 - loss: 3.4795 - accuracy: 0.1227"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:23 - loss: 3.4797 - accuracy: 0.12 - ETA: 1:22 - loss: 3.4789 - accuracy: 0.12 - ETA: 1:22 - loss: 3.4787 - accuracy: 0.12 - ETA: 1:21 - loss: 3.4783 - accuracy: 0.12 - ETA: 1:21 - loss: 3.4776 - accuracy: 0.12 - ETA: 1:20 - loss: 3.4778 - accuracy: 0.12 - ETA: 1:20 - loss: 3.4780 - accuracy: 0.12 - ETA: 1:19 - loss: 3.4777 - accuracy: 0.12 - ETA: 1:18 - loss: 3.4772 - accuracy: 0.12 - ETA: 1:18 - loss: 3.4772 - accuracy: 0.12 - ETA: 1:17 - loss: 3.4763 - accuracy: 0.12 - ETA: 1:17 - loss: 3.4759 - accuracy: 0.12 - ETA: 1:16 - loss: 3.4765 - accuracy: 0.12 - ETA: 1:15 - loss: 3.4760 - accuracy: 0.12 - ETA: 1:15 - loss: 3.4757 - accuracy: 0.12 - ETA: 1:14 - loss: 3.4756 - accuracy: 0.12 - ETA: 1:14 - loss: 3.4751 - accuracy: 0.12 - ETA: 1:13 - loss: 3.4748 - accuracy: 0.12 - ETA: 1:13 - loss: 3.4736 - accuracy: 0.12 - ETA: 1:12 - loss: 3.4740 - accuracy: 0.12 - ETA: 1:11 - loss: 3.4738 - accuracy: 0.12 - ETA: 1:11 - loss: 3.4744 - accuracy: 0.12 - ETA: 1:10 - loss: 3.4742 - accuracy: 0.12 - ETA: 1:10 - loss: 3.4736 - accuracy: 0.12 - ETA: 1:09 - loss: 3.4728 - accuracy: 0.12 - ETA: 1:09 - loss: 3.4728 - accuracy: 0.12 - ETA: 1:09 - loss: 3.4725 - accuracy: 0.12 - ETA: 1:08 - loss: 3.4724 - accuracy: 0.12 - ETA: 1:07 - loss: 3.4729 - accuracy: 0.12 - ETA: 1:07 - loss: 3.4730 - accuracy: 0.12 - ETA: 1:06 - loss: 3.4730 - accuracy: 0.12 - ETA: 1:06 - loss: 3.4722 - accuracy: 0.12 - ETA: 1:05 - loss: 3.4721 - accuracy: 0.12 - ETA: 1:05 - loss: 3.4719 - accuracy: 0.12 - ETA: 1:04 - loss: 3.4713 - accuracy: 0.12 - ETA: 1:03 - loss: 3.4710 - accuracy: 0.12 - ETA: 1:03 - loss: 3.4714 - accuracy: 0.12 - ETA: 1:02 - loss: 3.4712 - accuracy: 0.12 - ETA: 1:02 - loss: 3.4712 - accuracy: 0.12 - ETA: 1:01 - loss: 3.4712 - accuracy: 0.12 - ETA: 1:00 - loss: 3.4717 - accuracy: 0.12 - ETA: 1:00 - loss: 3.4715 - accuracy: 0.12 - ETA: 59s - loss: 3.4722 - accuracy: 0.1244 - ETA: 59s - loss: 3.4718 - accuracy: 0.124 - ETA: 58s - loss: 3.4717 - accuracy: 0.124 - ETA: 58s - loss: 3.4721 - accuracy: 0.124 - ETA: 57s - loss: 3.4719 - accuracy: 0.124 - ETA: 56s - loss: 3.4721 - accuracy: 0.124 - ETA: 56s - loss: 3.4721 - accuracy: 0.124 - ETA: 55s - loss: 3.4723 - accuracy: 0.124 - ETA: 55s - loss: 3.4725 - accuracy: 0.124 - ETA: 54s - loss: 3.4726 - accuracy: 0.124 - ETA: 53s - loss: 3.4730 - accuracy: 0.124 - ETA: 53s - loss: 3.4729 - accuracy: 0.124 - ETA: 52s - loss: 3.4722 - accuracy: 0.124 - ETA: 52s - loss: 3.4727 - accuracy: 0.124 - ETA: 51s - loss: 3.4727 - accuracy: 0.124 - ETA: 50s - loss: 3.4733 - accuracy: 0.124 - ETA: 50s - loss: 3.4732 - accuracy: 0.124 - ETA: 49s - loss: 3.4728 - accuracy: 0.124 - ETA: 49s - loss: 3.4724 - accuracy: 0.124 - ETA: 48s - loss: 3.4728 - accuracy: 0.124 - ETA: 47s - loss: 3.4731 - accuracy: 0.124 - ETA: 47s - loss: 3.4730 - accuracy: 0.124 - ETA: 46s - loss: 3.4720 - accuracy: 0.124 - ETA: 46s - loss: 3.4720 - accuracy: 0.124 - ETA: 45s - loss: 3.4717 - accuracy: 0.124 - ETA: 44s - loss: 3.4716 - accuracy: 0.124 - ETA: 44s - loss: 3.4707 - accuracy: 0.124 - ETA: 43s - loss: 3.4707 - accuracy: 0.124 - ETA: 43s - loss: 3.4710 - accuracy: 0.124 - ETA: 42s - loss: 3.4720 - accuracy: 0.124 - ETA: 42s - loss: 3.4721 - accuracy: 0.124 - ETA: 41s - loss: 3.4725 - accuracy: 0.124 - ETA: 40s - loss: 3.4728 - accuracy: 0.124 - ETA: 40s - loss: 3.4725 - accuracy: 0.124 - ETA: 39s - loss: 3.4723 - accuracy: 0.124 - ETA: 39s - loss: 3.4726 - accuracy: 0.124 - ETA: 38s - loss: 3.4728 - accuracy: 0.124 - ETA: 37s - loss: 3.4731 - accuracy: 0.124 - ETA: 37s - loss: 3.4724 - accuracy: 0.124 - ETA: 36s - loss: 3.4718 - accuracy: 0.124 - ETA: 36s - loss: 3.4717 - accuracy: 0.124 - ETA: 35s - loss: 3.4718 - accuracy: 0.124 - ETA: 35s - loss: 3.4714 - accuracy: 0.124 - ETA: 34s - loss: 3.4715 - accuracy: 0.124 - ETA: 33s - loss: 3.4720 - accuracy: 0.124 - ETA: 33s - loss: 3.4720 - accuracy: 0.124 - ETA: 32s - loss: 3.4716 - accuracy: 0.124 - ETA: 32s - loss: 3.4720 - accuracy: 0.124 - ETA: 31s - loss: 3.4716 - accuracy: 0.124 - ETA: 30s - loss: 3.4708 - accuracy: 0.124 - ETA: 30s - loss: 3.4709 - accuracy: 0.124 - ETA: 29s - loss: 3.4709 - accuracy: 0.124 - ETA: 29s - loss: 3.4709 - accuracy: 0.124 - ETA: 28s - loss: 3.4712 - accuracy: 0.124 - ETA: 28s - loss: 3.4714 - accuracy: 0.124 - ETA: 27s - loss: 3.4710 - accuracy: 0.124 - ETA: 26s - loss: 3.4721 - accuracy: 0.124 - ETA: 26s - loss: 3.4719 - accuracy: 0.124 - ETA: 25s - loss: 3.4722 - accuracy: 0.123 - ETA: 25s - loss: 3.4727 - accuracy: 0.123 - ETA: 24s - loss: 3.4719 - accuracy: 0.123 - ETA: 23s - loss: 3.4720 - accuracy: 0.123 - ETA: 23s - loss: 3.4717 - accuracy: 0.124 - ETA: 22s - loss: 3.4719 - accuracy: 0.123 - ETA: 22s - loss: 3.4719 - accuracy: 0.123 - ETA: 21s - loss: 3.4721 - accuracy: 0.123 - ETA: 21s - loss: 3.4715 - accuracy: 0.124 - ETA: 20s - loss: 3.4706 - accuracy: 0.124 - ETA: 19s - loss: 3.4705 - accuracy: 0.124 - ETA: 19s - loss: 3.4704 - accuracy: 0.124 - ETA: 18s - loss: 3.4707 - accuracy: 0.124 - ETA: 18s - loss: 3.4707 - accuracy: 0.124 - ETA: 17s - loss: 3.4712 - accuracy: 0.124 - ETA: 16s - loss: 3.4706 - accuracy: 0.124 - ETA: 16s - loss: 3.4705 - accuracy: 0.124 - ETA: 15s - loss: 3.4704 - accuracy: 0.124 - ETA: 15s - loss: 3.4705 - accuracy: 0.124 - ETA: 14s - loss: 3.4703 - accuracy: 0.124 - ETA: 14s - loss: 3.4702 - accuracy: 0.124 - ETA: 13s - loss: 3.4704 - accuracy: 0.124 - ETA: 12s - loss: 3.4702 - accuracy: 0.124 - ETA: 12s - loss: 3.4701 - accuracy: 0.124 - ETA: 11s - loss: 3.4694 - accuracy: 0.124 - ETA: 11s - loss: 3.4692 - accuracy: 0.124 - ETA: 10s - loss: 3.4688 - accuracy: 0.124 - ETA: 9s - loss: 3.4692 - accuracy: 0.124 - ETA: 9s - loss: 3.4690 - accuracy: 0.12 - ETA: 8s - loss: 3.4687 - accuracy: 0.12 - ETA: 8s - loss: 3.4685 - accuracy: 0.12 - ETA: 7s - loss: 3.4689 - accuracy: 0.12 - ETA: 7s - loss: 3.4686 - accuracy: 0.12 - ETA: 6s - loss: 3.4687 - accuracy: 0.12 - ETA: 5s - loss: 3.4684 - accuracy: 0.12 - ETA: 5s - loss: 3.4678 - accuracy: 0.12 - ETA: 4s - loss: 3.4680 - accuracy: 0.12 - ETA: 4s - loss: 3.4682 - accuracy: 0.12 - ETA: 3s - loss: 3.4683 - accuracy: 0.12 - ETA: 2s - loss: 3.4680 - accuracy: 0.12 - ETA: 2s - loss: 3.4683 - accuracy: 0.12 - ETA: 1s - loss: 3.4679 - accuracy: 0.12 - ETA: 1s - loss: 3.4676 - accuracy: 0.12 - ETA: 0s - loss: 3.4679 - accuracy: 0.12 - ETA: 0s - loss: 3.4681 - accuracy: 0.12 - 205s 5ms/step - loss: 3.4681 - accuracy: 0.1250 - val_loss: 3.8838 - val_accuracy: 0.0292\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:43 - loss: 3.3875 - accuracy: 0.14 - ETA: 3:23 - loss: 3.4374 - accuracy: 0.14 - ETA: 3:20 - loss: 3.4788 - accuracy: 0.12 - ETA: 3:19 - loss: 3.4841 - accuracy: 0.11 - ETA: 3:20 - loss: 3.4507 - accuracy: 0.12 - ETA: 3:19 - loss: 3.4418 - accuracy: 0.12 - ETA: 3:19 - loss: 3.4169 - accuracy: 0.13 - ETA: 3:16 - loss: 3.4451 - accuracy: 0.12 - ETA: 3:13 - loss: 3.4497 - accuracy: 0.12 - ETA: 3:11 - loss: 3.4362 - accuracy: 0.12 - ETA: 3:09 - loss: 3.4198 - accuracy: 0.13 - ETA: 3:08 - loss: 3.4107 - accuracy: 0.13 - ETA: 3:06 - loss: 3.4144 - accuracy: 0.12 - ETA: 3:07 - loss: 3.4291 - accuracy: 0.12 - ETA: 3:06 - loss: 3.4301 - accuracy: 0.12 - ETA: 3:06 - loss: 3.4246 - accuracy: 0.13 - ETA: 3:06 - loss: 3.4304 - accuracy: 0.12 - ETA: 3:06 - loss: 3.4332 - accuracy: 0.12 - ETA: 3:04 - loss: 3.4307 - accuracy: 0.13 - ETA: 3:03 - loss: 3.4321 - accuracy: 0.13 - ETA: 3:02 - loss: 3.4296 - accuracy: 0.13 - ETA: 3:01 - loss: 3.4341 - accuracy: 0.13 - ETA: 3:00 - loss: 3.4372 - accuracy: 0.12 - ETA: 3:00 - loss: 3.4365 - accuracy: 0.13 - ETA: 2:59 - loss: 3.4347 - accuracy: 0.13 - ETA: 2:58 - loss: 3.4365 - accuracy: 0.12 - ETA: 2:58 - loss: 3.4413 - accuracy: 0.12 - ETA: 2:57 - loss: 3.4459 - accuracy: 0.12 - ETA: 2:56 - loss: 3.4427 - accuracy: 0.12 - ETA: 2:56 - loss: 3.4415 - accuracy: 0.12 - ETA: 2:55 - loss: 3.4490 - accuracy: 0.12 - ETA: 2:54 - loss: 3.4551 - accuracy: 0.12 - ETA: 2:54 - loss: 3.4557 - accuracy: 0.12 - ETA: 2:53 - loss: 3.4576 - accuracy: 0.12 - ETA: 2:52 - loss: 3.4546 - accuracy: 0.12 - ETA: 2:51 - loss: 3.4536 - accuracy: 0.12 - ETA: 2:51 - loss: 3.4577 - accuracy: 0.12 - ETA: 2:50 - loss: 3.4607 - accuracy: 0.12 - ETA: 2:49 - loss: 3.4621 - accuracy: 0.12 - ETA: 2:49 - loss: 3.4619 - accuracy: 0.12 - ETA: 2:48 - loss: 3.4675 - accuracy: 0.12 - ETA: 2:48 - loss: 3.4695 - accuracy: 0.12 - ETA: 2:47 - loss: 3.4699 - accuracy: 0.12 - ETA: 2:47 - loss: 3.4727 - accuracy: 0.12 - ETA: 2:46 - loss: 3.4708 - accuracy: 0.12 - ETA: 2:45 - loss: 3.4709 - accuracy: 0.12 - ETA: 2:45 - loss: 3.4721 - accuracy: 0.12 - ETA: 2:44 - loss: 3.4742 - accuracy: 0.12 - ETA: 2:44 - loss: 3.4735 - accuracy: 0.12 - ETA: 2:43 - loss: 3.4760 - accuracy: 0.12 - ETA: 2:42 - loss: 3.4736 - accuracy: 0.12 - ETA: 2:41 - loss: 3.4757 - accuracy: 0.12 - ETA: 2:41 - loss: 3.4744 - accuracy: 0.12 - ETA: 2:40 - loss: 3.4751 - accuracy: 0.12 - ETA: 2:39 - loss: 3.4771 - accuracy: 0.12 - ETA: 2:38 - loss: 3.4777 - accuracy: 0.12 - ETA: 2:38 - loss: 3.4774 - accuracy: 0.12 - ETA: 2:37 - loss: 3.4743 - accuracy: 0.12 - ETA: 2:36 - loss: 3.4749 - accuracy: 0.12 - ETA: 2:36 - loss: 3.4758 - accuracy: 0.12 - ETA: 2:35 - loss: 3.4732 - accuracy: 0.12 - ETA: 2:34 - loss: 3.4722 - accuracy: 0.12 - ETA: 2:34 - loss: 3.4710 - accuracy: 0.12 - ETA: 2:33 - loss: 3.4685 - accuracy: 0.12 - ETA: 2:33 - loss: 3.4702 - accuracy: 0.12 - ETA: 2:32 - loss: 3.4704 - accuracy: 0.12 - ETA: 2:32 - loss: 3.4695 - accuracy: 0.12 - ETA: 2:31 - loss: 3.4696 - accuracy: 0.12 - ETA: 2:30 - loss: 3.4699 - accuracy: 0.12 - ETA: 2:30 - loss: 3.4700 - accuracy: 0.12 - ETA: 2:29 - loss: 3.4701 - accuracy: 0.12 - ETA: 2:29 - loss: 3.4698 - accuracy: 0.12 - ETA: 2:28 - loss: 3.4675 - accuracy: 0.12 - ETA: 2:28 - loss: 3.4665 - accuracy: 0.12 - ETA: 2:27 - loss: 3.4658 - accuracy: 0.12 - ETA: 2:26 - loss: 3.4643 - accuracy: 0.12 - ETA: 2:26 - loss: 3.4637 - accuracy: 0.12 - ETA: 2:25 - loss: 3.4652 - accuracy: 0.12 - ETA: 2:25 - loss: 3.4649 - accuracy: 0.12 - ETA: 2:24 - loss: 3.4643 - accuracy: 0.12 - ETA: 2:23 - loss: 3.4638 - accuracy: 0.12 - ETA: 2:23 - loss: 3.4642 - accuracy: 0.12 - ETA: 2:22 - loss: 3.4634 - accuracy: 0.12 - ETA: 2:22 - loss: 3.4624 - accuracy: 0.12 - ETA: 2:21 - loss: 3.4620 - accuracy: 0.12 - ETA: 2:20 - loss: 3.4609 - accuracy: 0.12 - ETA: 2:20 - loss: 3.4613 - accuracy: 0.12 - ETA: 2:19 - loss: 3.4618 - accuracy: 0.12 - ETA: 2:19 - loss: 3.4619 - accuracy: 0.12 - ETA: 2:18 - loss: 3.4604 - accuracy: 0.12 - ETA: 2:17 - loss: 3.4591 - accuracy: 0.12 - ETA: 2:17 - loss: 3.4586 - accuracy: 0.12 - ETA: 2:16 - loss: 3.4587 - accuracy: 0.12 - ETA: 2:16 - loss: 3.4581 - accuracy: 0.12 - ETA: 2:15 - loss: 3.4588 - accuracy: 0.12 - ETA: 2:15 - loss: 3.4570 - accuracy: 0.12 - ETA: 2:14 - loss: 3.4544 - accuracy: 0.12 - ETA: 2:14 - loss: 3.4544 - accuracy: 0.12 - ETA: 2:13 - loss: 3.4542 - accuracy: 0.12 - ETA: 2:13 - loss: 3.4535 - accuracy: 0.12 - ETA: 2:12 - loss: 3.4527 - accuracy: 0.12 - ETA: 2:12 - loss: 3.4535 - accuracy: 0.12 - ETA: 2:11 - loss: 3.4532 - accuracy: 0.12 - ETA: 2:11 - loss: 3.4546 - accuracy: 0.12 - ETA: 2:10 - loss: 3.4528 - accuracy: 0.12 - ETA: 2:09 - loss: 3.4536 - accuracy: 0.12 - ETA: 2:09 - loss: 3.4536 - accuracy: 0.12 - ETA: 2:08 - loss: 3.4529 - accuracy: 0.12 - ETA: 2:08 - loss: 3.4530 - accuracy: 0.12 - ETA: 2:07 - loss: 3.4521 - accuracy: 0.12 - ETA: 2:06 - loss: 3.4520 - accuracy: 0.12 - ETA: 2:06 - loss: 3.4524 - accuracy: 0.12 - ETA: 2:05 - loss: 3.4521 - accuracy: 0.12 - ETA: 2:05 - loss: 3.4501 - accuracy: 0.12 - ETA: 2:04 - loss: 3.4500 - accuracy: 0.12 - ETA: 2:04 - loss: 3.4495 - accuracy: 0.12 - ETA: 2:03 - loss: 3.4486 - accuracy: 0.12 - ETA: 2:03 - loss: 3.4492 - accuracy: 0.12 - ETA: 2:02 - loss: 3.4492 - accuracy: 0.12 - ETA: 2:02 - loss: 3.4516 - accuracy: 0.12 - ETA: 2:01 - loss: 3.4525 - accuracy: 0.12 - ETA: 2:00 - loss: 3.4507 - accuracy: 0.12 - ETA: 2:00 - loss: 3.4503 - accuracy: 0.12 - ETA: 1:59 - loss: 3.4511 - accuracy: 0.12 - ETA: 1:59 - loss: 3.4514 - accuracy: 0.12 - ETA: 1:58 - loss: 3.4517 - accuracy: 0.12 - ETA: 1:58 - loss: 3.4525 - accuracy: 0.12 - ETA: 1:57 - loss: 3.4523 - accuracy: 0.12 - ETA: 1:56 - loss: 3.4523 - accuracy: 0.12 - ETA: 1:56 - loss: 3.4511 - accuracy: 0.12 - ETA: 1:55 - loss: 3.4510 - accuracy: 0.12 - ETA: 1:55 - loss: 3.4514 - accuracy: 0.12 - ETA: 1:54 - loss: 3.4516 - accuracy: 0.12 - ETA: 1:53 - loss: 3.4512 - accuracy: 0.12 - ETA: 1:53 - loss: 3.4508 - accuracy: 0.12 - ETA: 1:52 - loss: 3.4508 - accuracy: 0.12 - ETA: 1:52 - loss: 3.4516 - accuracy: 0.12 - ETA: 1:51 - loss: 3.4519 - accuracy: 0.12 - ETA: 1:50 - loss: 3.4521 - accuracy: 0.12 - ETA: 1:50 - loss: 3.4530 - accuracy: 0.12 - ETA: 1:49 - loss: 3.4542 - accuracy: 0.12 - ETA: 1:49 - loss: 3.4553 - accuracy: 0.12 - ETA: 1:48 - loss: 3.4550 - accuracy: 0.12 - ETA: 1:47 - loss: 3.4557 - accuracy: 0.12 - ETA: 1:47 - loss: 3.4553 - accuracy: 0.12 - ETA: 1:46 - loss: 3.4566 - accuracy: 0.12 - ETA: 1:46 - loss: 3.4563 - accuracy: 0.12 - ETA: 1:45 - loss: 3.4560 - accuracy: 0.12 - ETA: 1:45 - loss: 3.4549 - accuracy: 0.12 - ETA: 1:44 - loss: 3.4548 - accuracy: 0.12 - ETA: 1:43 - loss: 3.4551 - accuracy: 0.12 - ETA: 1:43 - loss: 3.4549 - accuracy: 0.12 - ETA: 1:42 - loss: 3.4549 - accuracy: 0.12 - ETA: 1:42 - loss: 3.4552 - accuracy: 0.12 - ETA: 1:41 - loss: 3.4556 - accuracy: 0.12 - ETA: 1:41 - loss: 3.4557 - accuracy: 0.12 - ETA: 1:40 - loss: 3.4565 - accuracy: 0.12 - ETA: 1:39 - loss: 3.4565 - accuracy: 0.12 - ETA: 1:39 - loss: 3.4565 - accuracy: 0.12 - ETA: 1:38 - loss: 3.4559 - accuracy: 0.12 - ETA: 1:38 - loss: 3.4563 - accuracy: 0.12 - ETA: 1:37 - loss: 3.4561 - accuracy: 0.12 - ETA: 1:36 - loss: 3.4570 - accuracy: 0.12 - ETA: 1:36 - loss: 3.4572 - accuracy: 0.12 - ETA: 1:35 - loss: 3.4573 - accuracy: 0.12 - ETA: 1:35 - loss: 3.4571 - accuracy: 0.12 - ETA: 1:34 - loss: 3.4566 - accuracy: 0.12 - ETA: 1:33 - loss: 3.4576 - accuracy: 0.12 - ETA: 1:33 - loss: 3.4572 - accuracy: 0.12 - ETA: 1:32 - loss: 3.4577 - accuracy: 0.12 - ETA: 1:32 - loss: 3.4572 - accuracy: 0.12 - ETA: 1:31 - loss: 3.4582 - accuracy: 0.12 - ETA: 1:31 - loss: 3.4575 - accuracy: 0.12 - ETA: 1:30 - loss: 3.4571 - accuracy: 0.12 - ETA: 1:29 - loss: 3.4587 - accuracy: 0.12 - ETA: 1:29 - loss: 3.4583 - accuracy: 0.12 - ETA: 1:28 - loss: 3.4579 - accuracy: 0.12 - ETA: 1:28 - loss: 3.4583 - accuracy: 0.12 - ETA: 1:27 - loss: 3.4578 - accuracy: 0.12 - ETA: 1:26 - loss: 3.4585 - accuracy: 0.12 - ETA: 1:26 - loss: 3.4587 - accuracy: 0.12 - ETA: 1:25 - loss: 3.4588 - accuracy: 0.12 - ETA: 1:25 - loss: 3.4591 - accuracy: 0.12 - ETA: 1:24 - loss: 3.4587 - accuracy: 0.12 - ETA: 1:24 - loss: 3.4590 - accuracy: 0.12 - ETA: 1:23 - loss: 3.4581 - accuracy: 0.1272"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:23 - loss: 3.4581 - accuracy: 0.12 - ETA: 1:22 - loss: 3.4579 - accuracy: 0.12 - ETA: 1:21 - loss: 3.4577 - accuracy: 0.12 - ETA: 1:21 - loss: 3.4576 - accuracy: 0.12 - ETA: 1:20 - loss: 3.4582 - accuracy: 0.12 - ETA: 1:20 - loss: 3.4578 - accuracy: 0.12 - ETA: 1:19 - loss: 3.4572 - accuracy: 0.12 - ETA: 1:19 - loss: 3.4574 - accuracy: 0.12 - ETA: 1:18 - loss: 3.4563 - accuracy: 0.12 - ETA: 1:17 - loss: 3.4555 - accuracy: 0.12 - ETA: 1:17 - loss: 3.4549 - accuracy: 0.12 - ETA: 1:16 - loss: 3.4544 - accuracy: 0.12 - ETA: 1:16 - loss: 3.4551 - accuracy: 0.12 - ETA: 1:15 - loss: 3.4553 - accuracy: 0.12 - ETA: 1:14 - loss: 3.4546 - accuracy: 0.12 - ETA: 1:14 - loss: 3.4552 - accuracy: 0.12 - ETA: 1:13 - loss: 3.4548 - accuracy: 0.12 - ETA: 1:13 - loss: 3.4549 - accuracy: 0.12 - ETA: 1:12 - loss: 3.4553 - accuracy: 0.12 - ETA: 1:11 - loss: 3.4552 - accuracy: 0.12 - ETA: 1:11 - loss: 3.4559 - accuracy: 0.12 - ETA: 1:10 - loss: 3.4554 - accuracy: 0.12 - ETA: 1:10 - loss: 3.4547 - accuracy: 0.12 - ETA: 1:09 - loss: 3.4545 - accuracy: 0.12 - ETA: 1:09 - loss: 3.4543 - accuracy: 0.12 - ETA: 1:08 - loss: 3.4540 - accuracy: 0.12 - ETA: 1:08 - loss: 3.4537 - accuracy: 0.12 - ETA: 1:07 - loss: 3.4539 - accuracy: 0.12 - ETA: 1:06 - loss: 3.4542 - accuracy: 0.12 - ETA: 1:06 - loss: 3.4548 - accuracy: 0.12 - ETA: 1:05 - loss: 3.4540 - accuracy: 0.12 - ETA: 1:05 - loss: 3.4533 - accuracy: 0.12 - ETA: 1:04 - loss: 3.4527 - accuracy: 0.12 - ETA: 1:03 - loss: 3.4530 - accuracy: 0.12 - ETA: 1:03 - loss: 3.4528 - accuracy: 0.12 - ETA: 1:02 - loss: 3.4529 - accuracy: 0.12 - ETA: 1:02 - loss: 3.4533 - accuracy: 0.12 - ETA: 1:01 - loss: 3.4536 - accuracy: 0.12 - ETA: 1:01 - loss: 3.4535 - accuracy: 0.12 - ETA: 1:00 - loss: 3.4534 - accuracy: 0.12 - ETA: 59s - loss: 3.4534 - accuracy: 0.1271 - ETA: 59s - loss: 3.4535 - accuracy: 0.127 - ETA: 58s - loss: 3.4543 - accuracy: 0.127 - ETA: 58s - loss: 3.4540 - accuracy: 0.127 - ETA: 57s - loss: 3.4531 - accuracy: 0.127 - ETA: 56s - loss: 3.4533 - accuracy: 0.127 - ETA: 56s - loss: 3.4532 - accuracy: 0.127 - ETA: 55s - loss: 3.4524 - accuracy: 0.127 - ETA: 55s - loss: 3.4535 - accuracy: 0.127 - ETA: 54s - loss: 3.4533 - accuracy: 0.127 - ETA: 54s - loss: 3.4522 - accuracy: 0.127 - ETA: 53s - loss: 3.4531 - accuracy: 0.127 - ETA: 52s - loss: 3.4525 - accuracy: 0.127 - ETA: 52s - loss: 3.4528 - accuracy: 0.127 - ETA: 51s - loss: 3.4527 - accuracy: 0.127 - ETA: 51s - loss: 3.4529 - accuracy: 0.127 - ETA: 50s - loss: 3.4522 - accuracy: 0.127 - ETA: 50s - loss: 3.4519 - accuracy: 0.127 - ETA: 49s - loss: 3.4520 - accuracy: 0.128 - ETA: 48s - loss: 3.4524 - accuracy: 0.127 - ETA: 48s - loss: 3.4526 - accuracy: 0.127 - ETA: 47s - loss: 3.4528 - accuracy: 0.127 - ETA: 47s - loss: 3.4532 - accuracy: 0.127 - ETA: 46s - loss: 3.4536 - accuracy: 0.127 - ETA: 46s - loss: 3.4536 - accuracy: 0.127 - ETA: 45s - loss: 3.4541 - accuracy: 0.127 - ETA: 44s - loss: 3.4542 - accuracy: 0.127 - ETA: 44s - loss: 3.4544 - accuracy: 0.127 - ETA: 43s - loss: 3.4540 - accuracy: 0.127 - ETA: 43s - loss: 3.4549 - accuracy: 0.127 - ETA: 42s - loss: 3.4545 - accuracy: 0.127 - ETA: 41s - loss: 3.4545 - accuracy: 0.127 - ETA: 41s - loss: 3.4554 - accuracy: 0.127 - ETA: 40s - loss: 3.4548 - accuracy: 0.127 - ETA: 40s - loss: 3.4548 - accuracy: 0.127 - ETA: 39s - loss: 3.4541 - accuracy: 0.127 - ETA: 39s - loss: 3.4544 - accuracy: 0.127 - ETA: 38s - loss: 3.4543 - accuracy: 0.127 - ETA: 37s - loss: 3.4542 - accuracy: 0.127 - ETA: 37s - loss: 3.4538 - accuracy: 0.127 - ETA: 36s - loss: 3.4537 - accuracy: 0.127 - ETA: 36s - loss: 3.4537 - accuracy: 0.127 - ETA: 35s - loss: 3.4534 - accuracy: 0.127 - ETA: 35s - loss: 3.4527 - accuracy: 0.128 - ETA: 34s - loss: 3.4530 - accuracy: 0.128 - ETA: 33s - loss: 3.4531 - accuracy: 0.128 - ETA: 33s - loss: 3.4536 - accuracy: 0.127 - ETA: 32s - loss: 3.4536 - accuracy: 0.127 - ETA: 32s - loss: 3.4534 - accuracy: 0.127 - ETA: 31s - loss: 3.4531 - accuracy: 0.128 - ETA: 31s - loss: 3.4528 - accuracy: 0.128 - ETA: 30s - loss: 3.4525 - accuracy: 0.128 - ETA: 29s - loss: 3.4535 - accuracy: 0.127 - ETA: 29s - loss: 3.4531 - accuracy: 0.127 - ETA: 28s - loss: 3.4532 - accuracy: 0.127 - ETA: 28s - loss: 3.4529 - accuracy: 0.128 - ETA: 27s - loss: 3.4528 - accuracy: 0.127 - ETA: 27s - loss: 3.4531 - accuracy: 0.127 - ETA: 26s - loss: 3.4524 - accuracy: 0.128 - ETA: 25s - loss: 3.4527 - accuracy: 0.128 - ETA: 25s - loss: 3.4532 - accuracy: 0.127 - ETA: 24s - loss: 3.4524 - accuracy: 0.128 - ETA: 24s - loss: 3.4522 - accuracy: 0.128 - ETA: 23s - loss: 3.4524 - accuracy: 0.128 - ETA: 22s - loss: 3.4527 - accuracy: 0.128 - ETA: 22s - loss: 3.4524 - accuracy: 0.128 - ETA: 21s - loss: 3.4526 - accuracy: 0.128 - ETA: 21s - loss: 3.4524 - accuracy: 0.128 - ETA: 20s - loss: 3.4521 - accuracy: 0.128 - ETA: 20s - loss: 3.4520 - accuracy: 0.128 - ETA: 19s - loss: 3.4523 - accuracy: 0.128 - ETA: 18s - loss: 3.4527 - accuracy: 0.128 - ETA: 18s - loss: 3.4527 - accuracy: 0.128 - ETA: 17s - loss: 3.4518 - accuracy: 0.128 - ETA: 17s - loss: 3.4516 - accuracy: 0.128 - ETA: 16s - loss: 3.4509 - accuracy: 0.128 - ETA: 16s - loss: 3.4512 - accuracy: 0.128 - ETA: 15s - loss: 3.4514 - accuracy: 0.128 - ETA: 14s - loss: 3.4516 - accuracy: 0.128 - ETA: 14s - loss: 3.4518 - accuracy: 0.128 - ETA: 13s - loss: 3.4515 - accuracy: 0.128 - ETA: 13s - loss: 3.4512 - accuracy: 0.128 - ETA: 12s - loss: 3.4509 - accuracy: 0.129 - ETA: 12s - loss: 3.4510 - accuracy: 0.129 - ETA: 11s - loss: 3.4508 - accuracy: 0.129 - ETA: 10s - loss: 3.4514 - accuracy: 0.129 - ETA: 10s - loss: 3.4517 - accuracy: 0.128 - ETA: 9s - loss: 3.4515 - accuracy: 0.129 - ETA: 9s - loss: 3.4510 - accuracy: 0.12 - ETA: 8s - loss: 3.4509 - accuracy: 0.12 - ETA: 8s - loss: 3.4512 - accuracy: 0.12 - ETA: 7s - loss: 3.4516 - accuracy: 0.12 - ETA: 6s - loss: 3.4517 - accuracy: 0.12 - ETA: 6s - loss: 3.4519 - accuracy: 0.12 - ETA: 5s - loss: 3.4515 - accuracy: 0.12 - ETA: 5s - loss: 3.4510 - accuracy: 0.12 - ETA: 4s - loss: 3.4507 - accuracy: 0.12 - ETA: 4s - loss: 3.4508 - accuracy: 0.12 - ETA: 3s - loss: 3.4512 - accuracy: 0.12 - ETA: 2s - loss: 3.4509 - accuracy: 0.12 - ETA: 2s - loss: 3.4508 - accuracy: 0.12 - ETA: 1s - loss: 3.4508 - accuracy: 0.12 - ETA: 1s - loss: 3.4508 - accuracy: 0.12 - ETA: 0s - loss: 3.4506 - accuracy: 0.12 - ETA: 0s - loss: 3.4506 - accuracy: 0.12 - 203s 5ms/step - loss: 3.4505 - accuracy: 0.1288 - val_loss: 3.9076 - val_accuracy: 0.0320\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:25 - loss: 3.5380 - accuracy: 0.07 - ETA: 3:12 - loss: 3.4704 - accuracy: 0.10 - ETA: 3:09 - loss: 3.4426 - accuracy: 0.11 - ETA: 3:07 - loss: 3.4161 - accuracy: 0.13 - ETA: 3:06 - loss: 3.4273 - accuracy: 0.12 - ETA: 3:04 - loss: 3.4058 - accuracy: 0.12 - ETA: 3:02 - loss: 3.4182 - accuracy: 0.12 - ETA: 3:02 - loss: 3.4096 - accuracy: 0.13 - ETA: 3:00 - loss: 3.4083 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3849 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3820 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3767 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3766 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3789 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3834 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3929 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3907 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3987 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3910 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3941 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3960 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3960 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3984 - accuracy: 0.13 - ETA: 2:54 - loss: 3.4005 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3946 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3951 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3954 - accuracy: 0.13 - ETA: 2:53 - loss: 3.4003 - accuracy: 0.13 - ETA: 2:52 - loss: 3.4018 - accuracy: 0.13 - ETA: 2:52 - loss: 3.4033 - accuracy: 0.13 - ETA: 2:51 - loss: 3.4054 - accuracy: 0.13 - ETA: 2:50 - loss: 3.4053 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3984 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3952 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3939 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3920 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3932 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3966 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3994 - accuracy: 0.13 - ETA: 2:45 - loss: 3.4036 - accuracy: 0.13 - ETA: 2:44 - loss: 3.4049 - accuracy: 0.13 - ETA: 2:44 - loss: 3.4038 - accuracy: 0.13 - ETA: 2:43 - loss: 3.4039 - accuracy: 0.13 - ETA: 2:42 - loss: 3.4054 - accuracy: 0.13 - ETA: 2:42 - loss: 3.4001 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3977 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3986 - accuracy: 0.13 - ETA: 2:40 - loss: 3.4010 - accuracy: 0.13 - ETA: 2:40 - loss: 3.4005 - accuracy: 0.13 - ETA: 2:39 - loss: 3.4000 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3994 - accuracy: 0.13 - ETA: 2:38 - loss: 3.4002 - accuracy: 0.13 - ETA: 2:38 - loss: 3.4030 - accuracy: 0.13 - ETA: 2:37 - loss: 3.4007 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3988 - accuracy: 0.13 - ETA: 2:36 - loss: 3.4005 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3984 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3974 - accuracy: 0.13 - ETA: 2:34 - loss: 3.4001 - accuracy: 0.13 - ETA: 2:34 - loss: 3.4014 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3994 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3977 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3977 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3994 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3985 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3976 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3979 - accuracy: 0.13 - ETA: 2:30 - loss: 3.4005 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3994 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3992 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3993 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3986 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3985 - accuracy: 0.13 - ETA: 2:26 - loss: 3.4010 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3986 - accuracy: 0.13 - ETA: 2:25 - loss: 3.4003 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3965 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3970 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3987 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3994 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3991 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3995 - accuracy: 0.13 - ETA: 2:22 - loss: 3.4019 - accuracy: 0.13 - ETA: 2:21 - loss: 3.4028 - accuracy: 0.13 - ETA: 2:21 - loss: 3.4034 - accuracy: 0.13 - ETA: 2:20 - loss: 3.4042 - accuracy: 0.13 - ETA: 2:19 - loss: 3.4054 - accuracy: 0.13 - ETA: 2:19 - loss: 3.4053 - accuracy: 0.13 - ETA: 2:18 - loss: 3.4044 - accuracy: 0.13 - ETA: 2:18 - loss: 3.4056 - accuracy: 0.13 - ETA: 2:17 - loss: 3.4070 - accuracy: 0.13 - ETA: 2:16 - loss: 3.4084 - accuracy: 0.13 - ETA: 2:16 - loss: 3.4074 - accuracy: 0.13 - ETA: 2:15 - loss: 3.4086 - accuracy: 0.13 - ETA: 2:15 - loss: 3.4089 - accuracy: 0.13 - ETA: 2:14 - loss: 3.4085 - accuracy: 0.13 - ETA: 2:13 - loss: 3.4096 - accuracy: 0.13 - ETA: 2:13 - loss: 3.4116 - accuracy: 0.13 - ETA: 2:12 - loss: 3.4119 - accuracy: 0.13 - ETA: 2:12 - loss: 3.4118 - accuracy: 0.13 - ETA: 2:11 - loss: 3.4114 - accuracy: 0.13 - ETA: 2:10 - loss: 3.4125 - accuracy: 0.13 - ETA: 2:10 - loss: 3.4127 - accuracy: 0.13 - ETA: 2:09 - loss: 3.4140 - accuracy: 0.13 - ETA: 2:09 - loss: 3.4142 - accuracy: 0.13 - ETA: 2:08 - loss: 3.4153 - accuracy: 0.13 - ETA: 2:07 - loss: 3.4151 - accuracy: 0.13 - ETA: 2:07 - loss: 3.4157 - accuracy: 0.13 - ETA: 2:06 - loss: 3.4151 - accuracy: 0.13 - ETA: 2:06 - loss: 3.4160 - accuracy: 0.13 - ETA: 2:05 - loss: 3.4173 - accuracy: 0.13 - ETA: 2:05 - loss: 3.4167 - accuracy: 0.13 - ETA: 2:04 - loss: 3.4163 - accuracy: 0.13 - ETA: 2:04 - loss: 3.4156 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4159 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4162 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4169 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4172 - accuracy: 0.13 - ETA: 2:01 - loss: 3.4170 - accuracy: 0.13 - ETA: 2:00 - loss: 3.4178 - accuracy: 0.13 - ETA: 2:00 - loss: 3.4178 - accuracy: 0.13 - ETA: 1:59 - loss: 3.4193 - accuracy: 0.13 - ETA: 1:59 - loss: 3.4190 - accuracy: 0.13 - ETA: 1:58 - loss: 3.4176 - accuracy: 0.13 - ETA: 1:57 - loss: 3.4185 - accuracy: 0.13 - ETA: 1:57 - loss: 3.4187 - accuracy: 0.13 - ETA: 1:56 - loss: 3.4188 - accuracy: 0.13 - ETA: 1:56 - loss: 3.4194 - accuracy: 0.13 - ETA: 1:55 - loss: 3.4203 - accuracy: 0.13 - ETA: 1:54 - loss: 3.4201 - accuracy: 0.13 - ETA: 1:54 - loss: 3.4201 - accuracy: 0.13 - ETA: 1:53 - loss: 3.4205 - accuracy: 0.13 - ETA: 1:53 - loss: 3.4199 - accuracy: 0.13 - ETA: 1:52 - loss: 3.4199 - accuracy: 0.13 - ETA: 1:52 - loss: 3.4195 - accuracy: 0.13 - ETA: 1:51 - loss: 3.4205 - accuracy: 0.13 - ETA: 1:51 - loss: 3.4221 - accuracy: 0.13 - ETA: 1:50 - loss: 3.4233 - accuracy: 0.13 - ETA: 1:49 - loss: 3.4237 - accuracy: 0.13 - ETA: 1:49 - loss: 3.4223 - accuracy: 0.13 - ETA: 1:48 - loss: 3.4226 - accuracy: 0.13 - ETA: 1:48 - loss: 3.4220 - accuracy: 0.13 - ETA: 1:47 - loss: 3.4207 - accuracy: 0.13 - ETA: 1:47 - loss: 3.4205 - accuracy: 0.13 - ETA: 1:46 - loss: 3.4206 - accuracy: 0.13 - ETA: 1:46 - loss: 3.4214 - accuracy: 0.13 - ETA: 1:45 - loss: 3.4224 - accuracy: 0.13 - ETA: 1:44 - loss: 3.4215 - accuracy: 0.13 - ETA: 1:44 - loss: 3.4209 - accuracy: 0.13 - ETA: 1:43 - loss: 3.4207 - accuracy: 0.13 - ETA: 1:43 - loss: 3.4213 - accuracy: 0.13 - ETA: 1:42 - loss: 3.4213 - accuracy: 0.13 - ETA: 1:41 - loss: 3.4221 - accuracy: 0.13 - ETA: 1:41 - loss: 3.4212 - accuracy: 0.13 - ETA: 1:40 - loss: 3.4204 - accuracy: 0.13 - ETA: 1:40 - loss: 3.4210 - accuracy: 0.13 - ETA: 1:39 - loss: 3.4205 - accuracy: 0.13 - ETA: 1:39 - loss: 3.4201 - accuracy: 0.13 - ETA: 1:38 - loss: 3.4214 - accuracy: 0.13 - ETA: 1:37 - loss: 3.4199 - accuracy: 0.13 - ETA: 1:37 - loss: 3.4199 - accuracy: 0.13 - ETA: 1:36 - loss: 3.4191 - accuracy: 0.13 - ETA: 1:36 - loss: 3.4181 - accuracy: 0.13 - ETA: 1:35 - loss: 3.4190 - accuracy: 0.13 - ETA: 1:35 - loss: 3.4185 - accuracy: 0.13 - ETA: 1:34 - loss: 3.4184 - accuracy: 0.13 - ETA: 1:33 - loss: 3.4182 - accuracy: 0.13 - ETA: 1:33 - loss: 3.4184 - accuracy: 0.13 - ETA: 1:32 - loss: 3.4186 - accuracy: 0.13 - ETA: 1:32 - loss: 3.4188 - accuracy: 0.13 - ETA: 1:31 - loss: 3.4195 - accuracy: 0.13 - ETA: 1:31 - loss: 3.4189 - accuracy: 0.13 - ETA: 1:30 - loss: 3.4190 - accuracy: 0.13 - ETA: 1:29 - loss: 3.4184 - accuracy: 0.13 - ETA: 1:29 - loss: 3.4193 - accuracy: 0.13 - ETA: 1:28 - loss: 3.4188 - accuracy: 0.13 - ETA: 1:28 - loss: 3.4191 - accuracy: 0.13 - ETA: 1:27 - loss: 3.4189 - accuracy: 0.13 - ETA: 1:27 - loss: 3.4187 - accuracy: 0.13 - ETA: 1:26 - loss: 3.4195 - accuracy: 0.13 - ETA: 1:26 - loss: 3.4209 - accuracy: 0.13 - ETA: 1:25 - loss: 3.4211 - accuracy: 0.13 - ETA: 1:24 - loss: 3.4207 - accuracy: 0.13 - ETA: 1:24 - loss: 3.4211 - accuracy: 0.13 - ETA: 1:23 - loss: 3.4208 - accuracy: 0.13 - ETA: 1:23 - loss: 3.4207 - accuracy: 0.1321"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:22 - loss: 3.4215 - accuracy: 0.13 - ETA: 1:21 - loss: 3.4220 - accuracy: 0.13 - ETA: 1:21 - loss: 3.4206 - accuracy: 0.13 - ETA: 1:20 - loss: 3.4210 - accuracy: 0.13 - ETA: 1:20 - loss: 3.4208 - accuracy: 0.13 - ETA: 1:19 - loss: 3.4205 - accuracy: 0.13 - ETA: 1:19 - loss: 3.4204 - accuracy: 0.13 - ETA: 1:18 - loss: 3.4202 - accuracy: 0.13 - ETA: 1:18 - loss: 3.4199 - accuracy: 0.13 - ETA: 1:17 - loss: 3.4210 - accuracy: 0.13 - ETA: 1:16 - loss: 3.4205 - accuracy: 0.13 - ETA: 1:16 - loss: 3.4203 - accuracy: 0.13 - ETA: 1:15 - loss: 3.4200 - accuracy: 0.13 - ETA: 1:15 - loss: 3.4207 - accuracy: 0.13 - ETA: 1:14 - loss: 3.4200 - accuracy: 0.13 - ETA: 1:13 - loss: 3.4199 - accuracy: 0.13 - ETA: 1:13 - loss: 3.4192 - accuracy: 0.13 - ETA: 1:12 - loss: 3.4195 - accuracy: 0.13 - ETA: 1:12 - loss: 3.4188 - accuracy: 0.13 - ETA: 1:11 - loss: 3.4175 - accuracy: 0.13 - ETA: 1:10 - loss: 3.4178 - accuracy: 0.13 - ETA: 1:10 - loss: 3.4192 - accuracy: 0.13 - ETA: 1:09 - loss: 3.4188 - accuracy: 0.13 - ETA: 1:09 - loss: 3.4192 - accuracy: 0.13 - ETA: 1:08 - loss: 3.4191 - accuracy: 0.13 - ETA: 1:08 - loss: 3.4185 - accuracy: 0.13 - ETA: 1:07 - loss: 3.4188 - accuracy: 0.13 - ETA: 1:06 - loss: 3.4178 - accuracy: 0.13 - ETA: 1:06 - loss: 3.4178 - accuracy: 0.13 - ETA: 1:05 - loss: 3.4182 - accuracy: 0.13 - ETA: 1:05 - loss: 3.4181 - accuracy: 0.13 - ETA: 1:04 - loss: 3.4179 - accuracy: 0.13 - ETA: 1:04 - loss: 3.4188 - accuracy: 0.13 - ETA: 1:03 - loss: 3.4193 - accuracy: 0.13 - ETA: 1:02 - loss: 3.4193 - accuracy: 0.13 - ETA: 1:02 - loss: 3.4195 - accuracy: 0.13 - ETA: 1:01 - loss: 3.4195 - accuracy: 0.13 - ETA: 1:01 - loss: 3.4198 - accuracy: 0.13 - ETA: 1:00 - loss: 3.4202 - accuracy: 0.13 - ETA: 1:00 - loss: 3.4203 - accuracy: 0.13 - ETA: 59s - loss: 3.4206 - accuracy: 0.1322 - ETA: 58s - loss: 3.4205 - accuracy: 0.132 - ETA: 58s - loss: 3.4202 - accuracy: 0.132 - ETA: 57s - loss: 3.4204 - accuracy: 0.132 - ETA: 57s - loss: 3.4205 - accuracy: 0.132 - ETA: 56s - loss: 3.4207 - accuracy: 0.132 - ETA: 56s - loss: 3.4210 - accuracy: 0.132 - ETA: 55s - loss: 3.4214 - accuracy: 0.132 - ETA: 54s - loss: 3.4212 - accuracy: 0.132 - ETA: 54s - loss: 3.4208 - accuracy: 0.132 - ETA: 53s - loss: 3.4208 - accuracy: 0.132 - ETA: 53s - loss: 3.4209 - accuracy: 0.132 - ETA: 52s - loss: 3.4213 - accuracy: 0.132 - ETA: 51s - loss: 3.4206 - accuracy: 0.132 - ETA: 51s - loss: 3.4212 - accuracy: 0.132 - ETA: 50s - loss: 3.4214 - accuracy: 0.132 - ETA: 50s - loss: 3.4216 - accuracy: 0.132 - ETA: 49s - loss: 3.4213 - accuracy: 0.132 - ETA: 49s - loss: 3.4208 - accuracy: 0.132 - ETA: 48s - loss: 3.4208 - accuracy: 0.132 - ETA: 47s - loss: 3.4206 - accuracy: 0.132 - ETA: 47s - loss: 3.4209 - accuracy: 0.132 - ETA: 46s - loss: 3.4207 - accuracy: 0.132 - ETA: 46s - loss: 3.4211 - accuracy: 0.132 - ETA: 45s - loss: 3.4210 - accuracy: 0.132 - ETA: 45s - loss: 3.4208 - accuracy: 0.132 - ETA: 44s - loss: 3.4213 - accuracy: 0.132 - ETA: 44s - loss: 3.4215 - accuracy: 0.132 - ETA: 43s - loss: 3.4211 - accuracy: 0.132 - ETA: 42s - loss: 3.4205 - accuracy: 0.132 - ETA: 42s - loss: 3.4206 - accuracy: 0.132 - ETA: 41s - loss: 3.4208 - accuracy: 0.133 - ETA: 41s - loss: 3.4207 - accuracy: 0.133 - ETA: 40s - loss: 3.4207 - accuracy: 0.133 - ETA: 40s - loss: 3.4207 - accuracy: 0.133 - ETA: 39s - loss: 3.4207 - accuracy: 0.133 - ETA: 38s - loss: 3.4206 - accuracy: 0.133 - ETA: 38s - loss: 3.4204 - accuracy: 0.133 - ETA: 37s - loss: 3.4207 - accuracy: 0.133 - ETA: 37s - loss: 3.4202 - accuracy: 0.133 - ETA: 36s - loss: 3.4204 - accuracy: 0.133 - ETA: 35s - loss: 3.4207 - accuracy: 0.133 - ETA: 35s - loss: 3.4206 - accuracy: 0.133 - ETA: 34s - loss: 3.4206 - accuracy: 0.132 - ETA: 34s - loss: 3.4204 - accuracy: 0.132 - ETA: 33s - loss: 3.4204 - accuracy: 0.132 - ETA: 33s - loss: 3.4198 - accuracy: 0.132 - ETA: 32s - loss: 3.4193 - accuracy: 0.133 - ETA: 31s - loss: 3.4192 - accuracy: 0.133 - ETA: 31s - loss: 3.4192 - accuracy: 0.133 - ETA: 30s - loss: 3.4192 - accuracy: 0.133 - ETA: 30s - loss: 3.4195 - accuracy: 0.132 - ETA: 29s - loss: 3.4193 - accuracy: 0.133 - ETA: 29s - loss: 3.4194 - accuracy: 0.132 - ETA: 28s - loss: 3.4196 - accuracy: 0.132 - ETA: 28s - loss: 3.4201 - accuracy: 0.132 - ETA: 27s - loss: 3.4205 - accuracy: 0.132 - ETA: 26s - loss: 3.4202 - accuracy: 0.132 - ETA: 26s - loss: 3.4198 - accuracy: 0.132 - ETA: 25s - loss: 3.4198 - accuracy: 0.132 - ETA: 25s - loss: 3.4192 - accuracy: 0.132 - ETA: 24s - loss: 3.4191 - accuracy: 0.133 - ETA: 24s - loss: 3.4193 - accuracy: 0.133 - ETA: 23s - loss: 3.4190 - accuracy: 0.133 - ETA: 22s - loss: 3.4181 - accuracy: 0.133 - ETA: 22s - loss: 3.4179 - accuracy: 0.133 - ETA: 21s - loss: 3.4186 - accuracy: 0.133 - ETA: 21s - loss: 3.4187 - accuracy: 0.133 - ETA: 20s - loss: 3.4193 - accuracy: 0.133 - ETA: 20s - loss: 3.4195 - accuracy: 0.133 - ETA: 19s - loss: 3.4197 - accuracy: 0.133 - ETA: 18s - loss: 3.4193 - accuracy: 0.133 - ETA: 18s - loss: 3.4197 - accuracy: 0.133 - ETA: 17s - loss: 3.4201 - accuracy: 0.132 - ETA: 17s - loss: 3.4202 - accuracy: 0.132 - ETA: 16s - loss: 3.4200 - accuracy: 0.132 - ETA: 16s - loss: 3.4198 - accuracy: 0.133 - ETA: 15s - loss: 3.4196 - accuracy: 0.133 - ETA: 14s - loss: 3.4196 - accuracy: 0.132 - ETA: 14s - loss: 3.4200 - accuracy: 0.132 - ETA: 13s - loss: 3.4202 - accuracy: 0.132 - ETA: 13s - loss: 3.4203 - accuracy: 0.132 - ETA: 12s - loss: 3.4208 - accuracy: 0.132 - ETA: 12s - loss: 3.4197 - accuracy: 0.132 - ETA: 11s - loss: 3.4193 - accuracy: 0.132 - ETA: 10s - loss: 3.4197 - accuracy: 0.132 - ETA: 10s - loss: 3.4195 - accuracy: 0.132 - ETA: 9s - loss: 3.4200 - accuracy: 0.132 - ETA: 9s - loss: 3.4199 - accuracy: 0.13 - ETA: 8s - loss: 3.4193 - accuracy: 0.13 - ETA: 8s - loss: 3.4186 - accuracy: 0.13 - ETA: 7s - loss: 3.4188 - accuracy: 0.13 - ETA: 6s - loss: 3.4190 - accuracy: 0.13 - ETA: 6s - loss: 3.4189 - accuracy: 0.13 - ETA: 5s - loss: 3.4187 - accuracy: 0.13 - ETA: 5s - loss: 3.4184 - accuracy: 0.13 - ETA: 4s - loss: 3.4178 - accuracy: 0.13 - ETA: 4s - loss: 3.4176 - accuracy: 0.13 - ETA: 3s - loss: 3.4175 - accuracy: 0.13 - ETA: 2s - loss: 3.4175 - accuracy: 0.13 - ETA: 2s - loss: 3.4169 - accuracy: 0.13 - ETA: 1s - loss: 3.4164 - accuracy: 0.13 - ETA: 1s - loss: 3.4161 - accuracy: 0.13 - ETA: 0s - loss: 3.4156 - accuracy: 0.13 - ETA: 0s - loss: 3.4152 - accuracy: 0.13 - 201s 5ms/step - loss: 3.4152 - accuracy: 0.1334 - val_loss: 3.8714 - val_accuracy: 0.0299\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 2:58 - loss: 3.2347 - accuracy: 0.21 - ETA: 2:58 - loss: 3.3807 - accuracy: 0.16 - ETA: 3:05 - loss: 3.4156 - accuracy: 0.15 - ETA: 3:06 - loss: 3.4491 - accuracy: 0.14 - ETA: 3:05 - loss: 3.4361 - accuracy: 0.13 - ETA: 3:05 - loss: 3.4450 - accuracy: 0.13 - ETA: 3:03 - loss: 3.4259 - accuracy: 0.13 - ETA: 3:03 - loss: 3.4065 - accuracy: 0.13 - ETA: 3:01 - loss: 3.4022 - accuracy: 0.13 - ETA: 3:00 - loss: 3.4006 - accuracy: 0.13 - ETA: 2:59 - loss: 3.4223 - accuracy: 0.13 - ETA: 3:00 - loss: 3.4234 - accuracy: 0.13 - ETA: 2:59 - loss: 3.4142 - accuracy: 0.13 - ETA: 2:59 - loss: 3.4179 - accuracy: 0.14 - ETA: 2:58 - loss: 3.4222 - accuracy: 0.13 - ETA: 2:57 - loss: 3.4220 - accuracy: 0.13 - ETA: 2:58 - loss: 3.4237 - accuracy: 0.13 - ETA: 2:57 - loss: 3.4347 - accuracy: 0.13 - ETA: 2:56 - loss: 3.4333 - accuracy: 0.13 - ETA: 2:56 - loss: 3.4317 - accuracy: 0.13 - ETA: 2:55 - loss: 3.4302 - accuracy: 0.13 - ETA: 2:55 - loss: 3.4263 - accuracy: 0.13 - ETA: 2:54 - loss: 3.4338 - accuracy: 0.14 - ETA: 2:53 - loss: 3.4328 - accuracy: 0.14 - ETA: 2:53 - loss: 3.4387 - accuracy: 0.13 - ETA: 2:52 - loss: 3.4378 - accuracy: 0.13 - ETA: 2:52 - loss: 3.4424 - accuracy: 0.13 - ETA: 2:51 - loss: 3.4418 - accuracy: 0.13 - ETA: 2:50 - loss: 3.4437 - accuracy: 0.13 - ETA: 2:50 - loss: 3.4440 - accuracy: 0.13 - ETA: 2:50 - loss: 3.4420 - accuracy: 0.13 - ETA: 2:49 - loss: 3.4411 - accuracy: 0.13 - ETA: 2:49 - loss: 3.4417 - accuracy: 0.13 - ETA: 2:49 - loss: 3.4386 - accuracy: 0.13 - ETA: 2:48 - loss: 3.4358 - accuracy: 0.13 - ETA: 2:48 - loss: 3.4425 - accuracy: 0.13 - ETA: 2:47 - loss: 3.4462 - accuracy: 0.13 - ETA: 2:46 - loss: 3.4457 - accuracy: 0.13 - ETA: 2:46 - loss: 3.4389 - accuracy: 0.13 - ETA: 2:45 - loss: 3.4380 - accuracy: 0.13 - ETA: 2:45 - loss: 3.4347 - accuracy: 0.13 - ETA: 2:44 - loss: 3.4322 - accuracy: 0.13 - ETA: 2:43 - loss: 3.4340 - accuracy: 0.13 - ETA: 2:43 - loss: 3.4319 - accuracy: 0.13 - ETA: 2:42 - loss: 3.4293 - accuracy: 0.13 - ETA: 2:41 - loss: 3.4289 - accuracy: 0.13 - ETA: 2:41 - loss: 3.4268 - accuracy: 0.13 - ETA: 2:40 - loss: 3.4283 - accuracy: 0.13 - ETA: 2:40 - loss: 3.4281 - accuracy: 0.13 - ETA: 2:39 - loss: 3.4292 - accuracy: 0.13 - ETA: 2:39 - loss: 3.4300 - accuracy: 0.13 - ETA: 2:38 - loss: 3.4269 - accuracy: 0.13 - ETA: 2:38 - loss: 3.4255 - accuracy: 0.13 - ETA: 2:37 - loss: 3.4273 - accuracy: 0.13 - ETA: 2:37 - loss: 3.4264 - accuracy: 0.13 - ETA: 2:37 - loss: 3.4297 - accuracy: 0.13 - ETA: 2:36 - loss: 3.4279 - accuracy: 0.13 - ETA: 2:35 - loss: 3.4228 - accuracy: 0.13 - ETA: 2:35 - loss: 3.4258 - accuracy: 0.13 - ETA: 2:35 - loss: 3.4275 - accuracy: 0.13 - ETA: 2:34 - loss: 3.4250 - accuracy: 0.13 - ETA: 2:34 - loss: 3.4273 - accuracy: 0.13 - ETA: 2:33 - loss: 3.4272 - accuracy: 0.13 - ETA: 2:33 - loss: 3.4259 - accuracy: 0.13 - ETA: 2:32 - loss: 3.4267 - accuracy: 0.13 - ETA: 2:31 - loss: 3.4287 - accuracy: 0.13 - ETA: 2:31 - loss: 3.4268 - accuracy: 0.13 - ETA: 2:30 - loss: 3.4275 - accuracy: 0.13 - ETA: 2:29 - loss: 3.4267 - accuracy: 0.13 - ETA: 2:29 - loss: 3.4265 - accuracy: 0.13 - ETA: 2:28 - loss: 3.4271 - accuracy: 0.13 - ETA: 2:27 - loss: 3.4227 - accuracy: 0.13 - ETA: 2:27 - loss: 3.4211 - accuracy: 0.13 - ETA: 2:26 - loss: 3.4202 - accuracy: 0.13 - ETA: 2:26 - loss: 3.4213 - accuracy: 0.13 - ETA: 2:25 - loss: 3.4217 - accuracy: 0.13 - ETA: 2:24 - loss: 3.4220 - accuracy: 0.13 - ETA: 2:24 - loss: 3.4238 - accuracy: 0.13 - ETA: 2:23 - loss: 3.4195 - accuracy: 0.13 - ETA: 2:22 - loss: 3.4160 - accuracy: 0.13 - ETA: 2:22 - loss: 3.4154 - accuracy: 0.13 - ETA: 2:21 - loss: 3.4141 - accuracy: 0.13 - ETA: 2:21 - loss: 3.4143 - accuracy: 0.13 - ETA: 2:20 - loss: 3.4146 - accuracy: 0.13 - ETA: 2:19 - loss: 3.4136 - accuracy: 0.13 - ETA: 2:19 - loss: 3.4139 - accuracy: 0.13 - ETA: 2:18 - loss: 3.4130 - accuracy: 0.13 - ETA: 2:18 - loss: 3.4149 - accuracy: 0.13 - ETA: 2:18 - loss: 3.4143 - accuracy: 0.13 - ETA: 2:17 - loss: 3.4142 - accuracy: 0.13 - ETA: 2:16 - loss: 3.4162 - accuracy: 0.13 - ETA: 2:16 - loss: 3.4163 - accuracy: 0.13 - ETA: 2:15 - loss: 3.4175 - accuracy: 0.13 - ETA: 2:15 - loss: 3.4150 - accuracy: 0.13 - ETA: 2:14 - loss: 3.4169 - accuracy: 0.13 - ETA: 2:13 - loss: 3.4165 - accuracy: 0.13 - ETA: 2:13 - loss: 3.4146 - accuracy: 0.13 - ETA: 2:12 - loss: 3.4158 - accuracy: 0.13 - ETA: 2:11 - loss: 3.4171 - accuracy: 0.13 - ETA: 2:11 - loss: 3.4164 - accuracy: 0.13 - ETA: 2:10 - loss: 3.4161 - accuracy: 0.13 - ETA: 2:10 - loss: 3.4158 - accuracy: 0.13 - ETA: 2:09 - loss: 3.4141 - accuracy: 0.13 - ETA: 2:09 - loss: 3.4135 - accuracy: 0.13 - ETA: 2:08 - loss: 3.4142 - accuracy: 0.13 - ETA: 2:07 - loss: 3.4126 - accuracy: 0.13 - ETA: 2:07 - loss: 3.4134 - accuracy: 0.13 - ETA: 2:06 - loss: 3.4137 - accuracy: 0.13 - ETA: 2:06 - loss: 3.4130 - accuracy: 0.13 - ETA: 2:05 - loss: 3.4134 - accuracy: 0.13 - ETA: 2:05 - loss: 3.4117 - accuracy: 0.13 - ETA: 2:04 - loss: 3.4125 - accuracy: 0.13 - ETA: 2:04 - loss: 3.4130 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4127 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4118 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4113 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4107 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4108 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4117 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4115 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4114 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4130 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4130 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4125 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4125 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4117 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4099 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4105 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4108 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4111 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4108 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4104 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4121 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4117 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4109 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4101 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4100 - accuracy: 0.13 - ETA: 2:01 - loss: 3.4107 - accuracy: 0.13 - ETA: 2:01 - loss: 3.4108 - accuracy: 0.13 - ETA: 2:01 - loss: 3.4094 - accuracy: 0.13 - ETA: 2:01 - loss: 3.4104 - accuracy: 0.13 - ETA: 2:01 - loss: 3.4088 - accuracy: 0.13 - ETA: 2:01 - loss: 3.4087 - accuracy: 0.13 - ETA: 2:00 - loss: 3.4089 - accuracy: 0.13 - ETA: 2:00 - loss: 3.4082 - accuracy: 0.13 - ETA: 2:00 - loss: 3.4086 - accuracy: 0.13 - ETA: 2:00 - loss: 3.4069 - accuracy: 0.13 - ETA: 2:00 - loss: 3.4065 - accuracy: 0.13 - ETA: 1:59 - loss: 3.4043 - accuracy: 0.13 - ETA: 1:59 - loss: 3.4038 - accuracy: 0.13 - ETA: 1:59 - loss: 3.4043 - accuracy: 0.13 - ETA: 1:58 - loss: 3.4036 - accuracy: 0.13 - ETA: 1:58 - loss: 3.4024 - accuracy: 0.13 - ETA: 1:58 - loss: 3.4030 - accuracy: 0.13 - ETA: 1:57 - loss: 3.4038 - accuracy: 0.13 - ETA: 1:57 - loss: 3.4027 - accuracy: 0.13 - ETA: 1:57 - loss: 3.4029 - accuracy: 0.13 - ETA: 1:56 - loss: 3.4046 - accuracy: 0.13 - ETA: 1:56 - loss: 3.4040 - accuracy: 0.13 - ETA: 1:56 - loss: 3.4032 - accuracy: 0.13 - ETA: 1:55 - loss: 3.4034 - accuracy: 0.13 - ETA: 1:55 - loss: 3.4030 - accuracy: 0.13 - ETA: 1:55 - loss: 3.4037 - accuracy: 0.13 - ETA: 1:54 - loss: 3.4038 - accuracy: 0.13 - ETA: 1:54 - loss: 3.4039 - accuracy: 0.13 - ETA: 1:53 - loss: 3.4033 - accuracy: 0.13 - ETA: 1:53 - loss: 3.4033 - accuracy: 0.13 - ETA: 1:52 - loss: 3.4021 - accuracy: 0.13 - ETA: 1:52 - loss: 3.4015 - accuracy: 0.13 - ETA: 1:52 - loss: 3.4012 - accuracy: 0.13 - ETA: 1:51 - loss: 3.4003 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3999 - accuracy: 0.13 - ETA: 1:50 - loss: 3.4001 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3997 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3991 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3986 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3980 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3972 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3978 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3969 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3968 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3971 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3965 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3965 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3969 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3966 - accuracy: 0.1397"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:43 - loss: 3.3962 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3961 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3959 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3957 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3965 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3963 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3979 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3981 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3987 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3989 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3994 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3986 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3981 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3980 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3982 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3991 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3982 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3988 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3985 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3989 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3989 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3983 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3978 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3979 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3970 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3970 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3974 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3980 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3973 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3973 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3982 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3984 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3994 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3991 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3991 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3992 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3987 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3982 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3989 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3987 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3985 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3990 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3992 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3988 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3983 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3977 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3979 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3979 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3982 - accuracy: 0.13 - ETA: 1:13 - loss: 3.3979 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3981 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3983 - accuracy: 0.13 - ETA: 1:11 - loss: 3.3985 - accuracy: 0.13 - ETA: 1:10 - loss: 3.3983 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3972 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3972 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3974 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3976 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3975 - accuracy: 0.13 - ETA: 1:06 - loss: 3.3972 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3970 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3966 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3965 - accuracy: 0.13 - ETA: 1:03 - loss: 3.3964 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3964 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3964 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3964 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3960 - accuracy: 0.13 - ETA: 59s - loss: 3.3959 - accuracy: 0.1389 - ETA: 59s - loss: 3.3962 - accuracy: 0.138 - ETA: 58s - loss: 3.3952 - accuracy: 0.138 - ETA: 57s - loss: 3.3949 - accuracy: 0.138 - ETA: 57s - loss: 3.3953 - accuracy: 0.138 - ETA: 56s - loss: 3.3956 - accuracy: 0.138 - ETA: 55s - loss: 3.3957 - accuracy: 0.138 - ETA: 54s - loss: 3.3956 - accuracy: 0.138 - ETA: 54s - loss: 3.3958 - accuracy: 0.138 - ETA: 53s - loss: 3.3959 - accuracy: 0.138 - ETA: 52s - loss: 3.3963 - accuracy: 0.138 - ETA: 51s - loss: 3.3963 - accuracy: 0.138 - ETA: 51s - loss: 3.3959 - accuracy: 0.138 - ETA: 50s - loss: 3.3952 - accuracy: 0.138 - ETA: 49s - loss: 3.3958 - accuracy: 0.138 - ETA: 48s - loss: 3.3959 - accuracy: 0.138 - ETA: 47s - loss: 3.3963 - accuracy: 0.138 - ETA: 47s - loss: 3.3963 - accuracy: 0.138 - ETA: 46s - loss: 3.3961 - accuracy: 0.138 - ETA: 45s - loss: 3.3957 - accuracy: 0.138 - ETA: 44s - loss: 3.3952 - accuracy: 0.138 - ETA: 44s - loss: 3.3952 - accuracy: 0.138 - ETA: 43s - loss: 3.3961 - accuracy: 0.138 - ETA: 42s - loss: 3.3965 - accuracy: 0.138 - ETA: 41s - loss: 3.3960 - accuracy: 0.138 - ETA: 41s - loss: 3.3955 - accuracy: 0.138 - ETA: 40s - loss: 3.3960 - accuracy: 0.138 - ETA: 39s - loss: 3.3954 - accuracy: 0.138 - ETA: 38s - loss: 3.3952 - accuracy: 0.138 - ETA: 37s - loss: 3.3948 - accuracy: 0.138 - ETA: 37s - loss: 3.3944 - accuracy: 0.138 - ETA: 36s - loss: 3.3943 - accuracy: 0.138 - ETA: 35s - loss: 3.3941 - accuracy: 0.138 - ETA: 34s - loss: 3.3939 - accuracy: 0.139 - ETA: 34s - loss: 3.3935 - accuracy: 0.139 - ETA: 33s - loss: 3.3936 - accuracy: 0.139 - ETA: 32s - loss: 3.3940 - accuracy: 0.139 - ETA: 31s - loss: 3.3941 - accuracy: 0.139 - ETA: 30s - loss: 3.3941 - accuracy: 0.139 - ETA: 30s - loss: 3.3945 - accuracy: 0.139 - ETA: 29s - loss: 3.3947 - accuracy: 0.138 - ETA: 28s - loss: 3.3948 - accuracy: 0.138 - ETA: 27s - loss: 3.3947 - accuracy: 0.139 - ETA: 26s - loss: 3.3946 - accuracy: 0.139 - ETA: 26s - loss: 3.3946 - accuracy: 0.139 - ETA: 25s - loss: 3.3947 - accuracy: 0.139 - ETA: 24s - loss: 3.3948 - accuracy: 0.139 - ETA: 23s - loss: 3.3946 - accuracy: 0.138 - ETA: 22s - loss: 3.3953 - accuracy: 0.138 - ETA: 22s - loss: 3.3952 - accuracy: 0.138 - ETA: 21s - loss: 3.3956 - accuracy: 0.138 - ETA: 20s - loss: 3.3968 - accuracy: 0.138 - ETA: 19s - loss: 3.3971 - accuracy: 0.138 - ETA: 18s - loss: 3.3972 - accuracy: 0.138 - ETA: 18s - loss: 3.3967 - accuracy: 0.138 - ETA: 17s - loss: 3.3967 - accuracy: 0.138 - ETA: 16s - loss: 3.3969 - accuracy: 0.138 - ETA: 15s - loss: 3.3972 - accuracy: 0.138 - ETA: 14s - loss: 3.3977 - accuracy: 0.138 - ETA: 14s - loss: 3.3981 - accuracy: 0.138 - ETA: 13s - loss: 3.3986 - accuracy: 0.138 - ETA: 12s - loss: 3.3992 - accuracy: 0.138 - ETA: 11s - loss: 3.3993 - accuracy: 0.138 - ETA: 10s - loss: 3.3994 - accuracy: 0.138 - ETA: 9s - loss: 3.3995 - accuracy: 0.138 - ETA: 9s - loss: 3.3997 - accuracy: 0.13 - ETA: 8s - loss: 3.4002 - accuracy: 0.13 - ETA: 7s - loss: 3.4007 - accuracy: 0.13 - ETA: 6s - loss: 3.4002 - accuracy: 0.13 - ETA: 5s - loss: 3.3998 - accuracy: 0.13 - ETA: 5s - loss: 3.3998 - accuracy: 0.13 - ETA: 4s - loss: 3.4000 - accuracy: 0.13 - ETA: 3s - loss: 3.3997 - accuracy: 0.13 - ETA: 2s - loss: 3.4002 - accuracy: 0.13 - ETA: 1s - loss: 3.3999 - accuracy: 0.13 - ETA: 0s - loss: 3.4000 - accuracy: 0.13 - ETA: 0s - loss: 3.3999 - accuracy: 0.13 - 299s 7ms/step - loss: 3.3999 - accuracy: 0.1377 - val_loss: 3.9073 - val_accuracy: 0.0332\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:25 - loss: 3.5221 - accuracy: 0.17 - ETA: 5:13 - loss: 3.4810 - accuracy: 0.14 - ETA: 5:08 - loss: 3.4331 - accuracy: 0.14 - ETA: 5:09 - loss: 3.5205 - accuracy: 0.14 - ETA: 5:10 - loss: 3.4988 - accuracy: 0.14 - ETA: 5:09 - loss: 3.4549 - accuracy: 0.14 - ETA: 5:11 - loss: 3.4546 - accuracy: 0.14 - ETA: 5:08 - loss: 3.4394 - accuracy: 0.14 - ETA: 5:04 - loss: 3.4244 - accuracy: 0.14 - ETA: 5:04 - loss: 3.4369 - accuracy: 0.14 - ETA: 5:03 - loss: 3.4298 - accuracy: 0.14 - ETA: 5:03 - loss: 3.4388 - accuracy: 0.14 - ETA: 5:03 - loss: 3.4397 - accuracy: 0.14 - ETA: 5:02 - loss: 3.4326 - accuracy: 0.14 - ETA: 5:03 - loss: 3.4264 - accuracy: 0.14 - ETA: 5:02 - loss: 3.4291 - accuracy: 0.13 - ETA: 5:02 - loss: 3.4201 - accuracy: 0.14 - ETA: 5:03 - loss: 3.4222 - accuracy: 0.13 - ETA: 5:02 - loss: 3.4153 - accuracy: 0.14 - ETA: 5:01 - loss: 3.4168 - accuracy: 0.14 - ETA: 4:59 - loss: 3.4157 - accuracy: 0.13 - ETA: 4:58 - loss: 3.4175 - accuracy: 0.13 - ETA: 4:57 - loss: 3.4233 - accuracy: 0.13 - ETA: 4:56 - loss: 3.4192 - accuracy: 0.13 - ETA: 4:54 - loss: 3.4188 - accuracy: 0.13 - ETA: 4:52 - loss: 3.4187 - accuracy: 0.13 - ETA: 4:51 - loss: 3.4214 - accuracy: 0.13 - ETA: 4:50 - loss: 3.4253 - accuracy: 0.13 - ETA: 4:50 - loss: 3.4287 - accuracy: 0.13 - ETA: 4:49 - loss: 3.4290 - accuracy: 0.13 - ETA: 4:48 - loss: 3.4254 - accuracy: 0.13 - ETA: 4:47 - loss: 3.4244 - accuracy: 0.13 - ETA: 4:45 - loss: 3.4201 - accuracy: 0.13 - ETA: 4:44 - loss: 3.4231 - accuracy: 0.13 - ETA: 4:44 - loss: 3.4229 - accuracy: 0.13 - ETA: 4:43 - loss: 3.4208 - accuracy: 0.13 - ETA: 4:42 - loss: 3.4176 - accuracy: 0.13 - ETA: 4:41 - loss: 3.4178 - accuracy: 0.13 - ETA: 4:41 - loss: 3.4163 - accuracy: 0.13 - ETA: 4:40 - loss: 3.4173 - accuracy: 0.13 - ETA: 4:40 - loss: 3.4164 - accuracy: 0.13 - ETA: 4:39 - loss: 3.4172 - accuracy: 0.13 - ETA: 4:38 - loss: 3.4164 - accuracy: 0.13 - ETA: 4:37 - loss: 3.4164 - accuracy: 0.13 - ETA: 4:37 - loss: 3.4152 - accuracy: 0.13 - ETA: 4:36 - loss: 3.4170 - accuracy: 0.13 - ETA: 4:35 - loss: 3.4171 - accuracy: 0.13 - ETA: 4:34 - loss: 3.4159 - accuracy: 0.13 - ETA: 4:33 - loss: 3.4176 - accuracy: 0.13 - ETA: 4:32 - loss: 3.4182 - accuracy: 0.13 - ETA: 4:31 - loss: 3.4200 - accuracy: 0.13 - ETA: 4:29 - loss: 3.4199 - accuracy: 0.13 - ETA: 4:28 - loss: 3.4188 - accuracy: 0.13 - ETA: 4:27 - loss: 3.4229 - accuracy: 0.13 - ETA: 4:26 - loss: 3.4235 - accuracy: 0.13 - ETA: 4:25 - loss: 3.4251 - accuracy: 0.13 - ETA: 4:24 - loss: 3.4234 - accuracy: 0.13 - ETA: 4:23 - loss: 3.4231 - accuracy: 0.13 - ETA: 4:22 - loss: 3.4226 - accuracy: 0.13 - ETA: 4:21 - loss: 3.4224 - accuracy: 0.13 - ETA: 4:20 - loss: 3.4209 - accuracy: 0.13 - ETA: 4:19 - loss: 3.4223 - accuracy: 0.13 - ETA: 4:18 - loss: 3.4206 - accuracy: 0.13 - ETA: 4:18 - loss: 3.4221 - accuracy: 0.13 - ETA: 4:17 - loss: 3.4245 - accuracy: 0.13 - ETA: 4:16 - loss: 3.4254 - accuracy: 0.13 - ETA: 4:15 - loss: 3.4252 - accuracy: 0.13 - ETA: 4:14 - loss: 3.4267 - accuracy: 0.13 - ETA: 4:13 - loss: 3.4270 - accuracy: 0.13 - ETA: 4:12 - loss: 3.4254 - accuracy: 0.13 - ETA: 4:11 - loss: 3.4256 - accuracy: 0.13 - ETA: 4:10 - loss: 3.4250 - accuracy: 0.13 - ETA: 4:09 - loss: 3.4244 - accuracy: 0.13 - ETA: 4:08 - loss: 3.4257 - accuracy: 0.13 - ETA: 4:07 - loss: 3.4241 - accuracy: 0.13 - ETA: 4:06 - loss: 3.4233 - accuracy: 0.13 - ETA: 4:05 - loss: 3.4231 - accuracy: 0.13 - ETA: 4:04 - loss: 3.4244 - accuracy: 0.13 - ETA: 4:03 - loss: 3.4209 - accuracy: 0.13 - ETA: 4:02 - loss: 3.4188 - accuracy: 0.13 - ETA: 4:01 - loss: 3.4180 - accuracy: 0.13 - ETA: 4:00 - loss: 3.4187 - accuracy: 0.13 - ETA: 3:59 - loss: 3.4173 - accuracy: 0.13 - ETA: 3:58 - loss: 3.4159 - accuracy: 0.13 - ETA: 3:57 - loss: 3.4152 - accuracy: 0.13 - ETA: 3:57 - loss: 3.4154 - accuracy: 0.13 - ETA: 3:56 - loss: 3.4160 - accuracy: 0.13 - ETA: 3:55 - loss: 3.4152 - accuracy: 0.13 - ETA: 3:54 - loss: 3.4143 - accuracy: 0.13 - ETA: 3:53 - loss: 3.4140 - accuracy: 0.13 - ETA: 3:52 - loss: 3.4148 - accuracy: 0.13 - ETA: 3:50 - loss: 3.4150 - accuracy: 0.13 - ETA: 3:49 - loss: 3.4150 - accuracy: 0.13 - ETA: 3:49 - loss: 3.4168 - accuracy: 0.13 - ETA: 3:48 - loss: 3.4182 - accuracy: 0.13 - ETA: 3:46 - loss: 3.4181 - accuracy: 0.13 - ETA: 3:46 - loss: 3.4209 - accuracy: 0.13 - ETA: 3:45 - loss: 3.4210 - accuracy: 0.13 - ETA: 3:44 - loss: 3.4204 - accuracy: 0.13 - ETA: 3:43 - loss: 3.4204 - accuracy: 0.13 - ETA: 3:42 - loss: 3.4195 - accuracy: 0.13 - ETA: 3:41 - loss: 3.4188 - accuracy: 0.13 - ETA: 3:40 - loss: 3.4179 - accuracy: 0.13 - ETA: 3:39 - loss: 3.4175 - accuracy: 0.13 - ETA: 3:38 - loss: 3.4191 - accuracy: 0.13 - ETA: 3:37 - loss: 3.4195 - accuracy: 0.13 - ETA: 3:36 - loss: 3.4189 - accuracy: 0.13 - ETA: 3:35 - loss: 3.4178 - accuracy: 0.13 - ETA: 3:34 - loss: 3.4160 - accuracy: 0.13 - ETA: 3:33 - loss: 3.4152 - accuracy: 0.13 - ETA: 3:32 - loss: 3.4147 - accuracy: 0.13 - ETA: 3:31 - loss: 3.4140 - accuracy: 0.13 - ETA: 3:30 - loss: 3.4142 - accuracy: 0.13 - ETA: 3:29 - loss: 3.4138 - accuracy: 0.13 - ETA: 3:28 - loss: 3.4135 - accuracy: 0.13 - ETA: 3:27 - loss: 3.4137 - accuracy: 0.13 - ETA: 3:26 - loss: 3.4136 - accuracy: 0.13 - ETA: 3:26 - loss: 3.4143 - accuracy: 0.13 - ETA: 3:25 - loss: 3.4147 - accuracy: 0.13 - ETA: 3:24 - loss: 3.4130 - accuracy: 0.13 - ETA: 3:23 - loss: 3.4137 - accuracy: 0.13 - ETA: 3:22 - loss: 3.4150 - accuracy: 0.13 - ETA: 3:21 - loss: 3.4155 - accuracy: 0.13 - ETA: 3:20 - loss: 3.4142 - accuracy: 0.13 - ETA: 3:19 - loss: 3.4129 - accuracy: 0.13 - ETA: 3:18 - loss: 3.4124 - accuracy: 0.13 - ETA: 3:17 - loss: 3.4136 - accuracy: 0.13 - ETA: 3:16 - loss: 3.4137 - accuracy: 0.13 - ETA: 3:15 - loss: 3.4134 - accuracy: 0.13 - ETA: 3:14 - loss: 3.4138 - accuracy: 0.13 - ETA: 3:13 - loss: 3.4140 - accuracy: 0.13 - ETA: 3:12 - loss: 3.4134 - accuracy: 0.13 - ETA: 3:11 - loss: 3.4132 - accuracy: 0.13 - ETA: 3:10 - loss: 3.4134 - accuracy: 0.13 - ETA: 3:09 - loss: 3.4144 - accuracy: 0.13 - ETA: 3:08 - loss: 3.4130 - accuracy: 0.13 - ETA: 3:07 - loss: 3.4126 - accuracy: 0.13 - ETA: 3:06 - loss: 3.4124 - accuracy: 0.13 - ETA: 3:05 - loss: 3.4110 - accuracy: 0.13 - ETA: 3:04 - loss: 3.4112 - accuracy: 0.13 - ETA: 3:03 - loss: 3.4115 - accuracy: 0.13 - ETA: 3:02 - loss: 3.4119 - accuracy: 0.13 - ETA: 3:01 - loss: 3.4120 - accuracy: 0.13 - ETA: 3:00 - loss: 3.4129 - accuracy: 0.13 - ETA: 2:59 - loss: 3.4125 - accuracy: 0.13 - ETA: 2:58 - loss: 3.4115 - accuracy: 0.13 - ETA: 2:57 - loss: 3.4117 - accuracy: 0.13 - ETA: 2:56 - loss: 3.4118 - accuracy: 0.13 - ETA: 2:55 - loss: 3.4113 - accuracy: 0.13 - ETA: 2:54 - loss: 3.4117 - accuracy: 0.13 - ETA: 2:54 - loss: 3.4118 - accuracy: 0.13 - ETA: 2:53 - loss: 3.4125 - accuracy: 0.13 - ETA: 2:52 - loss: 3.4112 - accuracy: 0.13 - ETA: 2:51 - loss: 3.4104 - accuracy: 0.13 - ETA: 2:50 - loss: 3.4109 - accuracy: 0.13 - ETA: 2:49 - loss: 3.4111 - accuracy: 0.13 - ETA: 2:48 - loss: 3.4114 - accuracy: 0.13 - ETA: 2:47 - loss: 3.4111 - accuracy: 0.13 - ETA: 2:46 - loss: 3.4108 - accuracy: 0.13 - ETA: 2:45 - loss: 3.4119 - accuracy: 0.13 - ETA: 2:44 - loss: 3.4123 - accuracy: 0.13 - ETA: 2:43 - loss: 3.4122 - accuracy: 0.13 - ETA: 2:42 - loss: 3.4106 - accuracy: 0.13 - ETA: 2:41 - loss: 3.4104 - accuracy: 0.13 - ETA: 2:40 - loss: 3.4109 - accuracy: 0.13 - ETA: 2:39 - loss: 3.4107 - accuracy: 0.13 - ETA: 2:38 - loss: 3.4105 - accuracy: 0.13 - ETA: 2:37 - loss: 3.4096 - accuracy: 0.13 - ETA: 2:36 - loss: 3.4086 - accuracy: 0.13 - ETA: 2:35 - loss: 3.4086 - accuracy: 0.13 - ETA: 2:34 - loss: 3.4086 - accuracy: 0.13 - ETA: 2:33 - loss: 3.4092 - accuracy: 0.13 - ETA: 2:32 - loss: 3.4086 - accuracy: 0.13 - ETA: 2:31 - loss: 3.4083 - accuracy: 0.13 - ETA: 2:30 - loss: 3.4079 - accuracy: 0.13 - ETA: 2:29 - loss: 3.4075 - accuracy: 0.13 - ETA: 2:28 - loss: 3.4080 - accuracy: 0.13 - ETA: 2:27 - loss: 3.4077 - accuracy: 0.13 - ETA: 2:26 - loss: 3.4077 - accuracy: 0.13 - ETA: 2:25 - loss: 3.4089 - accuracy: 0.13 - ETA: 2:25 - loss: 3.4081 - accuracy: 0.13 - ETA: 2:24 - loss: 3.4088 - accuracy: 0.13 - ETA: 2:23 - loss: 3.4079 - accuracy: 0.13 - ETA: 2:22 - loss: 3.4087 - accuracy: 0.13 - ETA: 2:21 - loss: 3.4091 - accuracy: 0.13 - ETA: 2:20 - loss: 3.4099 - accuracy: 0.1325"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:19 - loss: 3.4095 - accuracy: 0.13 - ETA: 2:18 - loss: 3.4096 - accuracy: 0.13 - ETA: 2:17 - loss: 3.4101 - accuracy: 0.13 - ETA: 2:16 - loss: 3.4103 - accuracy: 0.13 - ETA: 2:15 - loss: 3.4104 - accuracy: 0.13 - ETA: 2:14 - loss: 3.4107 - accuracy: 0.13 - ETA: 2:13 - loss: 3.4108 - accuracy: 0.13 - ETA: 2:12 - loss: 3.4104 - accuracy: 0.13 - ETA: 2:11 - loss: 3.4107 - accuracy: 0.13 - ETA: 2:10 - loss: 3.4107 - accuracy: 0.13 - ETA: 2:09 - loss: 3.4112 - accuracy: 0.13 - ETA: 2:08 - loss: 3.4118 - accuracy: 0.13 - ETA: 2:07 - loss: 3.4105 - accuracy: 0.13 - ETA: 2:06 - loss: 3.4107 - accuracy: 0.13 - ETA: 2:05 - loss: 3.4114 - accuracy: 0.13 - ETA: 2:04 - loss: 3.4116 - accuracy: 0.13 - ETA: 2:03 - loss: 3.4123 - accuracy: 0.13 - ETA: 2:02 - loss: 3.4126 - accuracy: 0.13 - ETA: 2:01 - loss: 3.4127 - accuracy: 0.13 - ETA: 2:00 - loss: 3.4127 - accuracy: 0.13 - ETA: 1:59 - loss: 3.4138 - accuracy: 0.13 - ETA: 1:58 - loss: 3.4143 - accuracy: 0.13 - ETA: 1:57 - loss: 3.4144 - accuracy: 0.13 - ETA: 1:56 - loss: 3.4148 - accuracy: 0.13 - ETA: 1:55 - loss: 3.4146 - accuracy: 0.13 - ETA: 1:54 - loss: 3.4143 - accuracy: 0.13 - ETA: 1:54 - loss: 3.4137 - accuracy: 0.13 - ETA: 1:53 - loss: 3.4140 - accuracy: 0.13 - ETA: 1:52 - loss: 3.4139 - accuracy: 0.13 - ETA: 1:51 - loss: 3.4142 - accuracy: 0.13 - ETA: 1:50 - loss: 3.4138 - accuracy: 0.13 - ETA: 1:49 - loss: 3.4131 - accuracy: 0.13 - ETA: 1:48 - loss: 3.4126 - accuracy: 0.13 - ETA: 1:47 - loss: 3.4130 - accuracy: 0.13 - ETA: 1:46 - loss: 3.4124 - accuracy: 0.13 - ETA: 1:45 - loss: 3.4121 - accuracy: 0.13 - ETA: 1:44 - loss: 3.4114 - accuracy: 0.13 - ETA: 1:43 - loss: 3.4116 - accuracy: 0.13 - ETA: 1:42 - loss: 3.4117 - accuracy: 0.13 - ETA: 1:41 - loss: 3.4112 - accuracy: 0.13 - ETA: 1:40 - loss: 3.4103 - accuracy: 0.13 - ETA: 1:39 - loss: 3.4094 - accuracy: 0.13 - ETA: 1:38 - loss: 3.4093 - accuracy: 0.13 - ETA: 1:37 - loss: 3.4097 - accuracy: 0.13 - ETA: 1:36 - loss: 3.4089 - accuracy: 0.13 - ETA: 1:35 - loss: 3.4086 - accuracy: 0.13 - ETA: 1:34 - loss: 3.4080 - accuracy: 0.13 - ETA: 1:33 - loss: 3.4081 - accuracy: 0.13 - ETA: 1:32 - loss: 3.4082 - accuracy: 0.13 - ETA: 1:31 - loss: 3.4082 - accuracy: 0.13 - ETA: 1:30 - loss: 3.4072 - accuracy: 0.13 - ETA: 1:29 - loss: 3.4066 - accuracy: 0.13 - ETA: 1:28 - loss: 3.4056 - accuracy: 0.13 - ETA: 1:28 - loss: 3.4055 - accuracy: 0.13 - ETA: 1:27 - loss: 3.4053 - accuracy: 0.13 - ETA: 1:26 - loss: 3.4042 - accuracy: 0.13 - ETA: 1:25 - loss: 3.4039 - accuracy: 0.13 - ETA: 1:24 - loss: 3.4040 - accuracy: 0.13 - ETA: 1:23 - loss: 3.4037 - accuracy: 0.13 - ETA: 1:22 - loss: 3.4034 - accuracy: 0.13 - ETA: 1:21 - loss: 3.4029 - accuracy: 0.13 - ETA: 1:20 - loss: 3.4026 - accuracy: 0.13 - ETA: 1:19 - loss: 3.4022 - accuracy: 0.13 - ETA: 1:18 - loss: 3.4027 - accuracy: 0.13 - ETA: 1:17 - loss: 3.4027 - accuracy: 0.13 - ETA: 1:16 - loss: 3.4025 - accuracy: 0.13 - ETA: 1:15 - loss: 3.4029 - accuracy: 0.13 - ETA: 1:14 - loss: 3.4031 - accuracy: 0.13 - ETA: 1:13 - loss: 3.4031 - accuracy: 0.13 - ETA: 1:12 - loss: 3.4023 - accuracy: 0.13 - ETA: 1:11 - loss: 3.4024 - accuracy: 0.13 - ETA: 1:10 - loss: 3.4017 - accuracy: 0.13 - ETA: 1:09 - loss: 3.4021 - accuracy: 0.13 - ETA: 1:08 - loss: 3.4018 - accuracy: 0.13 - ETA: 1:07 - loss: 3.4019 - accuracy: 0.13 - ETA: 1:06 - loss: 3.4016 - accuracy: 0.13 - ETA: 1:05 - loss: 3.4022 - accuracy: 0.13 - ETA: 1:04 - loss: 3.4026 - accuracy: 0.13 - ETA: 1:03 - loss: 3.4023 - accuracy: 0.13 - ETA: 1:02 - loss: 3.4015 - accuracy: 0.13 - ETA: 1:01 - loss: 3.4018 - accuracy: 0.13 - ETA: 1:00 - loss: 3.4015 - accuracy: 0.13 - ETA: 59s - loss: 3.4014 - accuracy: 0.1341 - ETA: 59s - loss: 3.4012 - accuracy: 0.134 - ETA: 58s - loss: 3.4016 - accuracy: 0.134 - ETA: 57s - loss: 3.4017 - accuracy: 0.134 - ETA: 56s - loss: 3.4023 - accuracy: 0.133 - ETA: 55s - loss: 3.4015 - accuracy: 0.134 - ETA: 54s - loss: 3.4014 - accuracy: 0.134 - ETA: 53s - loss: 3.4017 - accuracy: 0.134 - ETA: 52s - loss: 3.4022 - accuracy: 0.134 - ETA: 51s - loss: 3.4017 - accuracy: 0.134 - ETA: 50s - loss: 3.4016 - accuracy: 0.134 - ETA: 49s - loss: 3.4019 - accuracy: 0.134 - ETA: 48s - loss: 3.4017 - accuracy: 0.134 - ETA: 47s - loss: 3.4021 - accuracy: 0.134 - ETA: 46s - loss: 3.4018 - accuracy: 0.134 - ETA: 45s - loss: 3.4021 - accuracy: 0.134 - ETA: 44s - loss: 3.4023 - accuracy: 0.134 - ETA: 43s - loss: 3.4019 - accuracy: 0.134 - ETA: 42s - loss: 3.4012 - accuracy: 0.134 - ETA: 41s - loss: 3.4011 - accuracy: 0.134 - ETA: 40s - loss: 3.4014 - accuracy: 0.134 - ETA: 39s - loss: 3.4014 - accuracy: 0.134 - ETA: 38s - loss: 3.4013 - accuracy: 0.134 - ETA: 37s - loss: 3.4010 - accuracy: 0.134 - ETA: 36s - loss: 3.4004 - accuracy: 0.134 - ETA: 35s - loss: 3.4009 - accuracy: 0.134 - ETA: 34s - loss: 3.4009 - accuracy: 0.134 - ETA: 33s - loss: 3.4011 - accuracy: 0.134 - ETA: 32s - loss: 3.4009 - accuracy: 0.134 - ETA: 31s - loss: 3.4009 - accuracy: 0.134 - ETA: 30s - loss: 3.4007 - accuracy: 0.134 - ETA: 30s - loss: 3.3998 - accuracy: 0.134 - ETA: 29s - loss: 3.3992 - accuracy: 0.134 - ETA: 28s - loss: 3.3988 - accuracy: 0.134 - ETA: 27s - loss: 3.3987 - accuracy: 0.134 - ETA: 26s - loss: 3.3986 - accuracy: 0.134 - ETA: 25s - loss: 3.3984 - accuracy: 0.134 - ETA: 24s - loss: 3.3983 - accuracy: 0.134 - ETA: 23s - loss: 3.3989 - accuracy: 0.134 - ETA: 22s - loss: 3.3989 - accuracy: 0.134 - ETA: 21s - loss: 3.3994 - accuracy: 0.134 - ETA: 20s - loss: 3.3999 - accuracy: 0.134 - ETA: 19s - loss: 3.4001 - accuracy: 0.134 - ETA: 18s - loss: 3.3998 - accuracy: 0.134 - ETA: 17s - loss: 3.3989 - accuracy: 0.134 - ETA: 16s - loss: 3.3991 - accuracy: 0.134 - ETA: 15s - loss: 3.4000 - accuracy: 0.134 - ETA: 14s - loss: 3.3997 - accuracy: 0.134 - ETA: 13s - loss: 3.3990 - accuracy: 0.134 - ETA: 12s - loss: 3.3990 - accuracy: 0.134 - ETA: 11s - loss: 3.3991 - accuracy: 0.134 - ETA: 10s - loss: 3.3993 - accuracy: 0.134 - ETA: 9s - loss: 3.3990 - accuracy: 0.134 - ETA: 8s - loss: 3.3990 - accuracy: 0.13 - ETA: 7s - loss: 3.3992 - accuracy: 0.13 - ETA: 6s - loss: 3.3993 - accuracy: 0.13 - ETA: 5s - loss: 3.3992 - accuracy: 0.13 - ETA: 4s - loss: 3.3987 - accuracy: 0.13 - ETA: 3s - loss: 3.3984 - accuracy: 0.13 - ETA: 2s - loss: 3.3980 - accuracy: 0.13 - ETA: 2s - loss: 3.3980 - accuracy: 0.13 - ETA: 1s - loss: 3.3981 - accuracy: 0.13 - ETA: 0s - loss: 3.3982 - accuracy: 0.13 - 345s 8ms/step - loss: 3.3983 - accuracy: 0.1348 - val_loss: 3.9353 - val_accuracy: 0.0343\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:02 - loss: 3.3267 - accuracy: 0.16 - ETA: 4:59 - loss: 3.4175 - accuracy: 0.15 - ETA: 5:03 - loss: 3.4460 - accuracy: 0.14 - ETA: 5:09 - loss: 3.3631 - accuracy: 0.15 - ETA: 5:09 - loss: 3.3826 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3783 - accuracy: 0.14 - ETA: 5:14 - loss: 3.3702 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3960 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3965 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3973 - accuracy: 0.14 - ETA: 5:12 - loss: 3.4095 - accuracy: 0.14 - ETA: 5:13 - loss: 3.3847 - accuracy: 0.14 - ETA: 5:13 - loss: 3.3805 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3860 - accuracy: 0.14 - ETA: 5:08 - loss: 3.3869 - accuracy: 0.14 - ETA: 5:06 - loss: 3.3848 - accuracy: 0.14 - ETA: 5:04 - loss: 3.3892 - accuracy: 0.14 - ETA: 5:03 - loss: 3.3791 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3733 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3694 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3713 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3751 - accuracy: 0.14 - ETA: 4:56 - loss: 3.3733 - accuracy: 0.14 - ETA: 4:55 - loss: 3.3713 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3730 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3761 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3699 - accuracy: 0.14 - ETA: 4:53 - loss: 3.3698 - accuracy: 0.14 - ETA: 4:53 - loss: 3.3694 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3720 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3755 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3687 - accuracy: 0.14 - ETA: 4:48 - loss: 3.3626 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3596 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3552 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3539 - accuracy: 0.14 - ETA: 4:43 - loss: 3.3610 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3616 - accuracy: 0.14 - ETA: 4:40 - loss: 3.3615 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3635 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3575 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3565 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3551 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3514 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3522 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3524 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3492 - accuracy: 0.14 - ETA: 4:33 - loss: 3.3481 - accuracy: 0.14 - ETA: 4:32 - loss: 3.3492 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3480 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3470 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3489 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3488 - accuracy: 0.14 - ETA: 4:27 - loss: 3.3494 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3498 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3500 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3509 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3511 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3524 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3506 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3523 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3526 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3513 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3523 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3498 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3521 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3509 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3509 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3481 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3466 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3467 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3477 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3447 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3443 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3451 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3456 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3471 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3482 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3470 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3471 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3480 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3496 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3504 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3496 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3494 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3487 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3485 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3477 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3470 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3537 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3540 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3549 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3546 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3561 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3558 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3569 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3568 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3555 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3566 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3578 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3580 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3569 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3559 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3547 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3547 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3549 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3535 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3536 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3532 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3532 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3542 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3557 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3535 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3530 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3540 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3539 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3538 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3539 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3543 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3548 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3536 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3539 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3540 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3543 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3549 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3561 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3559 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3545 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3526 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3510 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3510 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3516 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3499 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3495 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3499 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3487 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3492 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3493 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3496 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3496 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3494 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3485 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3485 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3497 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3505 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3515 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3515 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3516 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3523 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3531 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3525 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3528 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3522 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3523 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3532 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3528 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3524 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3536 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3534 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3531 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3533 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3526 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3513 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3515 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3512 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3523 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3526 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3530 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3527 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3527 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3519 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3525 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3522 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3528 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3534 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3536 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3541 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3530 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3523 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3524 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3536 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3533 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3535 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3538 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3545 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3552 - accuracy: 0.1437"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.3557 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3541 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3537 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3536 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3529 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3536 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3541 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3537 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3543 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3551 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3550 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3557 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3549 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3549 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3550 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3549 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3551 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3539 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3537 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3537 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3541 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3547 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3545 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3543 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3552 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3559 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3558 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3565 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3567 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3570 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3575 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3574 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3570 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3573 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3578 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3581 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3582 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3575 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3572 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3564 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3574 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3577 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3586 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3587 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3587 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3589 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3581 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3584 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3590 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3592 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3593 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3600 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3599 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3601 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3598 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3598 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3594 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3597 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3600 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3602 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3601 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3603 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3593 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3588 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3585 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3588 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3589 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3589 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3587 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3589 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3584 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3586 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3584 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3581 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3579 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3576 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3578 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3567 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3569 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3567 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3565 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3567 - accuracy: 0.14 - ETA: 59s - loss: 3.3572 - accuracy: 0.1436 - ETA: 58s - loss: 3.3559 - accuracy: 0.143 - ETA: 57s - loss: 3.3556 - accuracy: 0.144 - ETA: 56s - loss: 3.3556 - accuracy: 0.144 - ETA: 55s - loss: 3.3555 - accuracy: 0.144 - ETA: 54s - loss: 3.3554 - accuracy: 0.144 - ETA: 53s - loss: 3.3553 - accuracy: 0.144 - ETA: 53s - loss: 3.3552 - accuracy: 0.144 - ETA: 52s - loss: 3.3552 - accuracy: 0.144 - ETA: 51s - loss: 3.3552 - accuracy: 0.144 - ETA: 50s - loss: 3.3549 - accuracy: 0.144 - ETA: 49s - loss: 3.3546 - accuracy: 0.144 - ETA: 48s - loss: 3.3545 - accuracy: 0.144 - ETA: 47s - loss: 3.3549 - accuracy: 0.144 - ETA: 46s - loss: 3.3544 - accuracy: 0.144 - ETA: 45s - loss: 3.3545 - accuracy: 0.144 - ETA: 44s - loss: 3.3543 - accuracy: 0.144 - ETA: 43s - loss: 3.3548 - accuracy: 0.144 - ETA: 42s - loss: 3.3547 - accuracy: 0.144 - ETA: 41s - loss: 3.3545 - accuracy: 0.144 - ETA: 40s - loss: 3.3556 - accuracy: 0.144 - ETA: 39s - loss: 3.3558 - accuracy: 0.144 - ETA: 38s - loss: 3.3563 - accuracy: 0.144 - ETA: 37s - loss: 3.3565 - accuracy: 0.143 - ETA: 36s - loss: 3.3561 - accuracy: 0.144 - ETA: 35s - loss: 3.3557 - accuracy: 0.144 - ETA: 34s - loss: 3.3555 - accuracy: 0.144 - ETA: 33s - loss: 3.3559 - accuracy: 0.144 - ETA: 32s - loss: 3.3551 - accuracy: 0.144 - ETA: 31s - loss: 3.3555 - accuracy: 0.144 - ETA: 30s - loss: 3.3554 - accuracy: 0.144 - ETA: 29s - loss: 3.3551 - accuracy: 0.144 - ETA: 28s - loss: 3.3550 - accuracy: 0.144 - ETA: 28s - loss: 3.3551 - accuracy: 0.144 - ETA: 27s - loss: 3.3550 - accuracy: 0.144 - ETA: 26s - loss: 3.3555 - accuracy: 0.143 - ETA: 25s - loss: 3.3559 - accuracy: 0.143 - ETA: 24s - loss: 3.3565 - accuracy: 0.143 - ETA: 23s - loss: 3.3563 - accuracy: 0.144 - ETA: 22s - loss: 3.3563 - accuracy: 0.144 - ETA: 21s - loss: 3.3567 - accuracy: 0.143 - ETA: 20s - loss: 3.3567 - accuracy: 0.144 - ETA: 19s - loss: 3.3570 - accuracy: 0.144 - ETA: 18s - loss: 3.3568 - accuracy: 0.144 - ETA: 17s - loss: 3.3570 - accuracy: 0.144 - ETA: 16s - loss: 3.3574 - accuracy: 0.144 - ETA: 15s - loss: 3.3570 - accuracy: 0.144 - ETA: 14s - loss: 3.3571 - accuracy: 0.144 - ETA: 13s - loss: 3.3568 - accuracy: 0.144 - ETA: 12s - loss: 3.3565 - accuracy: 0.144 - ETA: 11s - loss: 3.3561 - accuracy: 0.144 - ETA: 10s - loss: 3.3562 - accuracy: 0.144 - ETA: 9s - loss: 3.3553 - accuracy: 0.144 - ETA: 8s - loss: 3.3554 - accuracy: 0.14 - ETA: 7s - loss: 3.3554 - accuracy: 0.14 - ETA: 6s - loss: 3.3554 - accuracy: 0.14 - ETA: 5s - loss: 3.3556 - accuracy: 0.14 - ETA: 4s - loss: 3.3556 - accuracy: 0.14 - ETA: 3s - loss: 3.3553 - accuracy: 0.14 - ETA: 2s - loss: 3.3554 - accuracy: 0.14 - ETA: 2s - loss: 3.3552 - accuracy: 0.14 - ETA: 1s - loss: 3.3548 - accuracy: 0.14 - ETA: 0s - loss: 3.3550 - accuracy: 0.14 - 343s 8ms/step - loss: 3.3551 - accuracy: 0.1440 - val_loss: 3.9315 - val_accuracy: 0.0242\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:59 - loss: 3.4818 - accuracy: 0.13 - ETA: 5:08 - loss: 3.4318 - accuracy: 0.13 - ETA: 5:15 - loss: 3.4000 - accuracy: 0.13 - ETA: 5:11 - loss: 3.3757 - accuracy: 0.13 - ETA: 5:07 - loss: 3.3783 - accuracy: 0.13 - ETA: 5:04 - loss: 3.3931 - accuracy: 0.12 - ETA: 5:09 - loss: 3.3786 - accuracy: 0.13 - ETA: 5:07 - loss: 3.3661 - accuracy: 0.13 - ETA: 5:05 - loss: 3.3698 - accuracy: 0.13 - ETA: 5:06 - loss: 3.3761 - accuracy: 0.13 - ETA: 5:05 - loss: 3.3598 - accuracy: 0.13 - ETA: 5:06 - loss: 3.3546 - accuracy: 0.13 - ETA: 5:06 - loss: 3.3556 - accuracy: 0.13 - ETA: 5:06 - loss: 3.3580 - accuracy: 0.13 - ETA: 5:05 - loss: 3.3571 - accuracy: 0.13 - ETA: 5:03 - loss: 3.3491 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3408 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3351 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3412 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3391 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3365 - accuracy: 0.14 - ETA: 4:58 - loss: 3.3417 - accuracy: 0.14 - ETA: 4:58 - loss: 3.3414 - accuracy: 0.14 - ETA: 4:57 - loss: 3.3475 - accuracy: 0.14 - ETA: 4:56 - loss: 3.3476 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3475 - accuracy: 0.14 - ETA: 4:52 - loss: 3.3421 - accuracy: 0.14 - ETA: 4:52 - loss: 3.3428 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3432 - accuracy: 0.14 - ETA: 4:50 - loss: 3.3400 - accuracy: 0.14 - ETA: 4:49 - loss: 3.3372 - accuracy: 0.14 - ETA: 4:49 - loss: 3.3349 - accuracy: 0.14 - ETA: 4:48 - loss: 3.3393 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3450 - accuracy: 0.14 - ETA: 4:46 - loss: 3.3474 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3454 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3442 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3488 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3490 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3478 - accuracy: 0.14 - ETA: 4:40 - loss: 3.3481 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3482 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3484 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3500 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3528 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3509 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3501 - accuracy: 0.14 - ETA: 4:32 - loss: 3.3501 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3471 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3462 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3462 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3449 - accuracy: 0.14 - ETA: 4:27 - loss: 3.3473 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3487 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3471 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3479 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3483 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3512 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3468 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3456 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3433 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3451 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3450 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3442 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3449 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3453 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3432 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3449 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3471 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3479 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3497 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3470 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3481 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3500 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3483 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3473 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3474 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3461 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3444 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3440 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3427 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3427 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3432 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3440 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3440 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3425 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3419 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3420 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3429 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3407 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3412 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3409 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3417 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3402 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3409 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3411 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3405 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3388 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3369 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3368 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3373 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3364 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3380 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3389 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3386 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3373 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3374 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3381 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3372 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3370 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3357 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3362 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3346 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3356 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3356 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3362 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3352 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3355 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3354 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3348 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3351 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3347 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3355 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3362 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3381 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3366 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3374 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3386 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3370 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3383 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3383 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3378 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3384 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3375 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3373 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3365 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3379 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3382 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3383 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3386 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3386 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3376 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3363 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3355 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3375 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3375 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3371 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3374 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3374 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3373 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3374 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3372 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3365 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3357 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3365 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3366 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3355 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3354 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3363 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3361 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3369 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3368 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3375 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3377 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3368 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3363 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3363 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3367 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3372 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3376 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3379 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3380 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3379 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3380 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3376 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3385 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3387 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3388 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3382 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3381 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3388 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3387 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3376 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3378 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3373 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3368 - accuracy: 0.1462"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.3358 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3363 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3367 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3363 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3369 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3371 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3372 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3370 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3370 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3373 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3371 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3374 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3382 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3380 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3384 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3387 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3397 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3405 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3404 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3404 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3399 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3401 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3408 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3415 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3405 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3396 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3389 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3391 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3393 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3386 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3386 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3385 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3378 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3387 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3386 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3394 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3387 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3383 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3385 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3390 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3390 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3392 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3396 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3394 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3399 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3409 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3405 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3397 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3401 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3401 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3400 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3407 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3415 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3423 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3425 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3424 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3427 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3429 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3429 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3434 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3441 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3445 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3444 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3449 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3453 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3457 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3458 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3453 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3451 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3454 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3453 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3454 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3454 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3451 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3448 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3453 - accuracy: 0.14 - ETA: 59s - loss: 3.3450 - accuracy: 0.1430 - ETA: 58s - loss: 3.3451 - accuracy: 0.143 - ETA: 57s - loss: 3.3449 - accuracy: 0.143 - ETA: 56s - loss: 3.3450 - accuracy: 0.143 - ETA: 55s - loss: 3.3450 - accuracy: 0.143 - ETA: 54s - loss: 3.3446 - accuracy: 0.143 - ETA: 53s - loss: 3.3449 - accuracy: 0.143 - ETA: 53s - loss: 3.3450 - accuracy: 0.143 - ETA: 52s - loss: 3.3444 - accuracy: 0.143 - ETA: 51s - loss: 3.3445 - accuracy: 0.143 - ETA: 50s - loss: 3.3445 - accuracy: 0.143 - ETA: 49s - loss: 3.3445 - accuracy: 0.143 - ETA: 48s - loss: 3.3449 - accuracy: 0.143 - ETA: 47s - loss: 3.3441 - accuracy: 0.143 - ETA: 46s - loss: 3.3445 - accuracy: 0.143 - ETA: 45s - loss: 3.3439 - accuracy: 0.143 - ETA: 44s - loss: 3.3439 - accuracy: 0.143 - ETA: 43s - loss: 3.3439 - accuracy: 0.143 - ETA: 42s - loss: 3.3441 - accuracy: 0.143 - ETA: 41s - loss: 3.3439 - accuracy: 0.143 - ETA: 40s - loss: 3.3439 - accuracy: 0.143 - ETA: 39s - loss: 3.3435 - accuracy: 0.143 - ETA: 38s - loss: 3.3438 - accuracy: 0.143 - ETA: 37s - loss: 3.3435 - accuracy: 0.143 - ETA: 36s - loss: 3.3431 - accuracy: 0.144 - ETA: 35s - loss: 3.3428 - accuracy: 0.144 - ETA: 34s - loss: 3.3431 - accuracy: 0.144 - ETA: 33s - loss: 3.3431 - accuracy: 0.144 - ETA: 32s - loss: 3.3429 - accuracy: 0.144 - ETA: 31s - loss: 3.3424 - accuracy: 0.144 - ETA: 30s - loss: 3.3425 - accuracy: 0.144 - ETA: 29s - loss: 3.3421 - accuracy: 0.144 - ETA: 28s - loss: 3.3414 - accuracy: 0.144 - ETA: 27s - loss: 3.3416 - accuracy: 0.144 - ETA: 26s - loss: 3.3411 - accuracy: 0.144 - ETA: 26s - loss: 3.3410 - accuracy: 0.144 - ETA: 25s - loss: 3.3412 - accuracy: 0.144 - ETA: 24s - loss: 3.3406 - accuracy: 0.144 - ETA: 23s - loss: 3.3402 - accuracy: 0.144 - ETA: 22s - loss: 3.3403 - accuracy: 0.144 - ETA: 21s - loss: 3.3413 - accuracy: 0.144 - ETA: 20s - loss: 3.3417 - accuracy: 0.144 - ETA: 19s - loss: 3.3414 - accuracy: 0.144 - ETA: 18s - loss: 3.3412 - accuracy: 0.144 - ETA: 17s - loss: 3.3411 - accuracy: 0.144 - ETA: 16s - loss: 3.3412 - accuracy: 0.144 - ETA: 15s - loss: 3.3410 - accuracy: 0.144 - ETA: 14s - loss: 3.3409 - accuracy: 0.144 - ETA: 13s - loss: 3.3415 - accuracy: 0.144 - ETA: 12s - loss: 3.3413 - accuracy: 0.144 - ETA: 11s - loss: 3.3413 - accuracy: 0.144 - ETA: 10s - loss: 3.3409 - accuracy: 0.144 - ETA: 9s - loss: 3.3408 - accuracy: 0.144 - ETA: 8s - loss: 3.3403 - accuracy: 0.14 - ETA: 7s - loss: 3.3404 - accuracy: 0.14 - ETA: 6s - loss: 3.3407 - accuracy: 0.14 - ETA: 5s - loss: 3.3407 - accuracy: 0.14 - ETA: 4s - loss: 3.3410 - accuracy: 0.14 - ETA: 3s - loss: 3.3410 - accuracy: 0.14 - ETA: 2s - loss: 3.3410 - accuracy: 0.14 - ETA: 1s - loss: 3.3411 - accuracy: 0.14 - ETA: 1s - loss: 3.3415 - accuracy: 0.14 - ETA: 0s - loss: 3.3417 - accuracy: 0.14 - 343s 8ms/step - loss: 3.3415 - accuracy: 0.1448 - val_loss: 3.8776 - val_accuracy: 0.0303\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:20 - loss: 3.3008 - accuracy: 0.16 - ETA: 5:05 - loss: 3.2905 - accuracy: 0.16 - ETA: 5:08 - loss: 3.2657 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2968 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2989 - accuracy: 0.15 - ETA: 5:08 - loss: 3.3063 - accuracy: 0.15 - ETA: 5:07 - loss: 3.4041 - accuracy: 0.14 - ETA: 5:06 - loss: 3.3995 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3772 - accuracy: 0.15 - ETA: 5:03 - loss: 3.3910 - accuracy: 0.14 - ETA: 5:01 - loss: 3.3928 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3952 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3773 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3697 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3837 - accuracy: 0.14 - ETA: 4:58 - loss: 3.3829 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3807 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3789 - accuracy: 0.14 - ETA: 4:57 - loss: 3.3697 - accuracy: 0.14 - ETA: 4:56 - loss: 3.3736 - accuracy: 0.14 - ETA: 4:55 - loss: 3.3737 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3827 - accuracy: 0.13 - ETA: 4:54 - loss: 3.3731 - accuracy: 0.14 - ETA: 4:53 - loss: 3.3741 - accuracy: 0.14 - ETA: 4:53 - loss: 3.3710 - accuracy: 0.14 - ETA: 4:53 - loss: 3.3693 - accuracy: 0.14 - ETA: 4:52 - loss: 3.3619 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3618 - accuracy: 0.14 - ETA: 4:50 - loss: 3.3632 - accuracy: 0.14 - ETA: 4:49 - loss: 3.3603 - accuracy: 0.14 - ETA: 4:49 - loss: 3.3673 - accuracy: 0.14 - ETA: 4:48 - loss: 3.3652 - accuracy: 0.14 - ETA: 4:48 - loss: 3.3677 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3629 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3635 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3587 - accuracy: 0.14 - ETA: 4:43 - loss: 3.3536 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3541 - accuracy: 0.14 - ETA: 4:41 - loss: 3.3539 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3535 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3547 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3538 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3528 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3560 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3583 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3586 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3601 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3625 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3613 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3617 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3603 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3606 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3608 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3589 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3606 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3624 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3592 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3539 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3537 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3493 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3495 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3514 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3490 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3524 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3527 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3537 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3541 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3537 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3557 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3569 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3581 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3563 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3570 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3556 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3550 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3554 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3557 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3548 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3555 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3548 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3553 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3570 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3568 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3570 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3556 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3547 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3548 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3532 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3512 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3518 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3519 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3512 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3514 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3505 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3497 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3499 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3496 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3476 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3490 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3482 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3478 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3470 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3467 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3464 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3461 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3443 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3441 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3440 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3444 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3439 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3424 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3402 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3401 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3433 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3437 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3432 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3444 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3436 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3434 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3421 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3427 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3414 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3404 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3415 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3408 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3417 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3424 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3403 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3405 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3397 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3393 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3389 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3386 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3389 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3398 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3403 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3414 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3409 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3407 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3417 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3440 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3423 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3427 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3430 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3427 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3431 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3435 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3432 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3428 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3424 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3428 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3426 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3420 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3419 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3410 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3410 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3418 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3418 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3427 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3434 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3425 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3428 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3410 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3415 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3412 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3415 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3411 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3411 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3400 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3392 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3394 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3395 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3389 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3390 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3395 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3404 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3409 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3413 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3411 - accuracy: 0.1431"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:16 - loss: 3.3407 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3406 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3391 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3391 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3387 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3392 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3395 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3396 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3397 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3411 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3413 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3413 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3419 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3420 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3419 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3422 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3434 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3447 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3442 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3442 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3447 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3450 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3450 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3439 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3435 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3431 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3426 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3425 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3418 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3415 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3422 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3420 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3427 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3422 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3422 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3422 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3416 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3414 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3410 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3411 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3403 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3409 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3410 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3405 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3409 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3400 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3393 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3392 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3396 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3394 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3390 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3379 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3387 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3386 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3383 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3385 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3385 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3376 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3368 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3366 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3373 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3376 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3382 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3379 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3385 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3385 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3393 - accuracy: 0.14 - ETA: 59s - loss: 3.3391 - accuracy: 0.1434 - ETA: 58s - loss: 3.3393 - accuracy: 0.143 - ETA: 57s - loss: 3.3394 - accuracy: 0.143 - ETA: 56s - loss: 3.3395 - accuracy: 0.143 - ETA: 55s - loss: 3.3395 - accuracy: 0.143 - ETA: 54s - loss: 3.3393 - accuracy: 0.143 - ETA: 53s - loss: 3.3397 - accuracy: 0.143 - ETA: 52s - loss: 3.3391 - accuracy: 0.143 - ETA: 51s - loss: 3.3387 - accuracy: 0.143 - ETA: 50s - loss: 3.3388 - accuracy: 0.143 - ETA: 49s - loss: 3.3387 - accuracy: 0.143 - ETA: 48s - loss: 3.3391 - accuracy: 0.143 - ETA: 47s - loss: 3.3382 - accuracy: 0.143 - ETA: 46s - loss: 3.3380 - accuracy: 0.143 - ETA: 45s - loss: 3.3381 - accuracy: 0.143 - ETA: 44s - loss: 3.3378 - accuracy: 0.143 - ETA: 43s - loss: 3.3377 - accuracy: 0.143 - ETA: 43s - loss: 3.3380 - accuracy: 0.143 - ETA: 42s - loss: 3.3382 - accuracy: 0.143 - ETA: 41s - loss: 3.3385 - accuracy: 0.142 - ETA: 40s - loss: 3.3384 - accuracy: 0.142 - ETA: 39s - loss: 3.3382 - accuracy: 0.142 - ETA: 38s - loss: 3.3376 - accuracy: 0.142 - ETA: 37s - loss: 3.3375 - accuracy: 0.143 - ETA: 36s - loss: 3.3377 - accuracy: 0.143 - ETA: 35s - loss: 3.3375 - accuracy: 0.143 - ETA: 34s - loss: 3.3372 - accuracy: 0.143 - ETA: 33s - loss: 3.3373 - accuracy: 0.143 - ETA: 32s - loss: 3.3371 - accuracy: 0.143 - ETA: 31s - loss: 3.3370 - accuracy: 0.143 - ETA: 30s - loss: 3.3366 - accuracy: 0.143 - ETA: 29s - loss: 3.3370 - accuracy: 0.143 - ETA: 28s - loss: 3.3370 - accuracy: 0.143 - ETA: 27s - loss: 3.3370 - accuracy: 0.143 - ETA: 26s - loss: 3.3370 - accuracy: 0.143 - ETA: 25s - loss: 3.3372 - accuracy: 0.143 - ETA: 24s - loss: 3.3375 - accuracy: 0.143 - ETA: 23s - loss: 3.3372 - accuracy: 0.143 - ETA: 23s - loss: 3.3368 - accuracy: 0.143 - ETA: 22s - loss: 3.3374 - accuracy: 0.143 - ETA: 21s - loss: 3.3370 - accuracy: 0.143 - ETA: 20s - loss: 3.3379 - accuracy: 0.143 - ETA: 19s - loss: 3.3380 - accuracy: 0.143 - ETA: 18s - loss: 3.3388 - accuracy: 0.143 - ETA: 17s - loss: 3.3387 - accuracy: 0.143 - ETA: 16s - loss: 3.3386 - accuracy: 0.143 - ETA: 15s - loss: 3.3389 - accuracy: 0.143 - ETA: 14s - loss: 3.3390 - accuracy: 0.143 - ETA: 13s - loss: 3.3384 - accuracy: 0.143 - ETA: 12s - loss: 3.3385 - accuracy: 0.143 - ETA: 11s - loss: 3.3387 - accuracy: 0.143 - ETA: 10s - loss: 3.3385 - accuracy: 0.143 - ETA: 9s - loss: 3.3383 - accuracy: 0.143 - ETA: 8s - loss: 3.3385 - accuracy: 0.14 - ETA: 7s - loss: 3.3387 - accuracy: 0.14 - ETA: 6s - loss: 3.3388 - accuracy: 0.14 - ETA: 5s - loss: 3.3385 - accuracy: 0.14 - ETA: 4s - loss: 3.3383 - accuracy: 0.14 - ETA: 3s - loss: 3.3384 - accuracy: 0.14 - ETA: 2s - loss: 3.3381 - accuracy: 0.14 - ETA: 1s - loss: 3.3383 - accuracy: 0.14 - ETA: 1s - loss: 3.3383 - accuracy: 0.14 - ETA: 0s - loss: 3.3386 - accuracy: 0.14 - 341s 8ms/step - loss: 3.3386 - accuracy: 0.1432 - val_loss: 3.9483 - val_accuracy: 0.0295\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:25 - loss: 3.4879 - accuracy: 0.10 - ETA: 5:22 - loss: 3.4414 - accuracy: 0.13 - ETA: 5:15 - loss: 3.4089 - accuracy: 0.13 - ETA: 5:18 - loss: 3.3571 - accuracy: 0.14 - ETA: 5:15 - loss: 3.3639 - accuracy: 0.14 - ETA: 5:20 - loss: 3.3376 - accuracy: 0.14 - ETA: 5:19 - loss: 3.3308 - accuracy: 0.14 - ETA: 5:18 - loss: 3.3507 - accuracy: 0.14 - ETA: 5:16 - loss: 3.3556 - accuracy: 0.14 - ETA: 5:13 - loss: 3.3515 - accuracy: 0.14 - ETA: 5:12 - loss: 3.3365 - accuracy: 0.14 - ETA: 5:10 - loss: 3.3310 - accuracy: 0.14 - ETA: 5:06 - loss: 3.3344 - accuracy: 0.14 - ETA: 5:06 - loss: 3.3400 - accuracy: 0.14 - ETA: 5:03 - loss: 3.3399 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3478 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3485 - accuracy: 0.14 - ETA: 4:58 - loss: 3.3447 - accuracy: 0.14 - ETA: 4:58 - loss: 3.3515 - accuracy: 0.14 - ETA: 4:56 - loss: 3.3536 - accuracy: 0.14 - ETA: 4:55 - loss: 3.3538 - accuracy: 0.14 - ETA: 4:55 - loss: 3.3520 - accuracy: 0.14 - ETA: 4:55 - loss: 3.3529 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3462 - accuracy: 0.14 - ETA: 4:52 - loss: 3.3476 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3514 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3486 - accuracy: 0.14 - ETA: 4:50 - loss: 3.3491 - accuracy: 0.13 - ETA: 4:48 - loss: 3.3423 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3422 - accuracy: 0.14 - ETA: 4:46 - loss: 3.3429 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3452 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3450 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3537 - accuracy: 0.14 - ETA: 4:41 - loss: 3.3531 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3563 - accuracy: 0.13 - ETA: 4:39 - loss: 3.3510 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3530 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3506 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3565 - accuracy: 0.13 - ETA: 4:36 - loss: 3.3586 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3541 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3551 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3542 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3561 - accuracy: 0.14 - ETA: 4:33 - loss: 3.3576 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3562 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3566 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3596 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3571 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3567 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3554 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3559 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3556 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3554 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3553 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3583 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3573 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3570 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3560 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3567 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3533 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3533 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3507 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3526 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3481 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3466 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3437 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3406 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3399 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3378 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3381 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3385 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3374 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3356 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3361 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3344 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3304 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3319 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3309 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3325 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3312 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3281 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3285 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3316 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3320 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3325 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3314 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3333 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3328 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3330 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3323 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3319 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3318 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3329 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3327 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3336 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3333 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3354 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3357 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3328 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3339 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3326 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3335 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3325 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3324 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3324 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3323 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3318 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3327 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3338 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3361 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3349 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3363 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3339 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3341 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3354 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3348 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3334 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3330 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3326 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3306 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3319 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3313 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3313 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3328 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3334 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3320 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3320 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3310 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3307 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3306 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3306 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3319 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3324 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3327 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3330 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3326 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3326 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3312 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3313 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3319 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3319 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3315 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3333 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3318 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3329 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3324 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3330 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3339 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3334 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3324 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3341 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3340 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3342 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3347 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3347 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3348 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3339 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3338 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3347 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3354 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3365 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3372 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3384 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3389 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3397 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3396 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3404 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3399 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3391 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3394 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3401 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3400 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3404 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3413 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3415 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3417 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3415 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3424 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3417 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3412 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3417 - accuracy: 0.1434"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.3427 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3418 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3419 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3417 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3418 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3410 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3410 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3411 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3415 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3417 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3415 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3420 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3429 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3445 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3444 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3442 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3439 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3443 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3440 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3431 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3434 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3436 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3429 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3432 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3430 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3428 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3428 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3427 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3425 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3430 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3433 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3434 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3442 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3436 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3441 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3447 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3448 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3447 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3443 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3437 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3435 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3427 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3428 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3420 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3421 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3416 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3421 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3414 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3411 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3415 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3418 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3413 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3408 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3406 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3403 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3406 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3398 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3393 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3381 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3375 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3364 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3357 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3361 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3369 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3367 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3368 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3368 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3375 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3379 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3379 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3387 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3383 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3386 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3383 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3386 - accuracy: 0.14 - ETA: 59s - loss: 3.3385 - accuracy: 0.1437 - ETA: 58s - loss: 3.3383 - accuracy: 0.143 - ETA: 57s - loss: 3.3384 - accuracy: 0.143 - ETA: 56s - loss: 3.3378 - accuracy: 0.143 - ETA: 55s - loss: 3.3379 - accuracy: 0.143 - ETA: 54s - loss: 3.3377 - accuracy: 0.143 - ETA: 53s - loss: 3.3376 - accuracy: 0.143 - ETA: 53s - loss: 3.3378 - accuracy: 0.143 - ETA: 52s - loss: 3.3379 - accuracy: 0.143 - ETA: 51s - loss: 3.3376 - accuracy: 0.143 - ETA: 50s - loss: 3.3370 - accuracy: 0.143 - ETA: 49s - loss: 3.3358 - accuracy: 0.144 - ETA: 48s - loss: 3.3365 - accuracy: 0.144 - ETA: 47s - loss: 3.3361 - accuracy: 0.144 - ETA: 46s - loss: 3.3367 - accuracy: 0.143 - ETA: 45s - loss: 3.3364 - accuracy: 0.143 - ETA: 44s - loss: 3.3369 - accuracy: 0.143 - ETA: 43s - loss: 3.3369 - accuracy: 0.143 - ETA: 42s - loss: 3.3361 - accuracy: 0.143 - ETA: 41s - loss: 3.3356 - accuracy: 0.143 - ETA: 40s - loss: 3.3366 - accuracy: 0.143 - ETA: 39s - loss: 3.3368 - accuracy: 0.143 - ETA: 38s - loss: 3.3370 - accuracy: 0.143 - ETA: 37s - loss: 3.3373 - accuracy: 0.143 - ETA: 36s - loss: 3.3368 - accuracy: 0.143 - ETA: 35s - loss: 3.3372 - accuracy: 0.143 - ETA: 34s - loss: 3.3367 - accuracy: 0.143 - ETA: 33s - loss: 3.3378 - accuracy: 0.143 - ETA: 32s - loss: 3.3380 - accuracy: 0.143 - ETA: 31s - loss: 3.3380 - accuracy: 0.143 - ETA: 30s - loss: 3.3376 - accuracy: 0.143 - ETA: 29s - loss: 3.3372 - accuracy: 0.143 - ETA: 28s - loss: 3.3369 - accuracy: 0.143 - ETA: 28s - loss: 3.3368 - accuracy: 0.143 - ETA: 27s - loss: 3.3369 - accuracy: 0.143 - ETA: 26s - loss: 3.3364 - accuracy: 0.143 - ETA: 25s - loss: 3.3362 - accuracy: 0.143 - ETA: 24s - loss: 3.3362 - accuracy: 0.143 - ETA: 23s - loss: 3.3367 - accuracy: 0.143 - ETA: 22s - loss: 3.3372 - accuracy: 0.143 - ETA: 21s - loss: 3.3371 - accuracy: 0.143 - ETA: 20s - loss: 3.3372 - accuracy: 0.143 - ETA: 19s - loss: 3.3366 - accuracy: 0.143 - ETA: 18s - loss: 3.3361 - accuracy: 0.143 - ETA: 17s - loss: 3.3355 - accuracy: 0.144 - ETA: 16s - loss: 3.3350 - accuracy: 0.144 - ETA: 15s - loss: 3.3349 - accuracy: 0.144 - ETA: 14s - loss: 3.3348 - accuracy: 0.144 - ETA: 13s - loss: 3.3347 - accuracy: 0.144 - ETA: 12s - loss: 3.3351 - accuracy: 0.144 - ETA: 11s - loss: 3.3356 - accuracy: 0.144 - ETA: 10s - loss: 3.3352 - accuracy: 0.144 - ETA: 9s - loss: 3.3353 - accuracy: 0.144 - ETA: 8s - loss: 3.3358 - accuracy: 0.14 - ETA: 7s - loss: 3.3356 - accuracy: 0.14 - ETA: 6s - loss: 3.3355 - accuracy: 0.14 - ETA: 5s - loss: 3.3357 - accuracy: 0.14 - ETA: 4s - loss: 3.3358 - accuracy: 0.14 - ETA: 3s - loss: 3.3359 - accuracy: 0.14 - ETA: 2s - loss: 3.3362 - accuracy: 0.14 - ETA: 2s - loss: 3.3353 - accuracy: 0.14 - ETA: 1s - loss: 3.3355 - accuracy: 0.14 - ETA: 0s - loss: 3.3352 - accuracy: 0.14 - 343s 8ms/step - loss: 3.3353 - accuracy: 0.1442 - val_loss: 3.9828 - val_accuracy: 0.0293\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:14 - loss: 3.2038 - accuracy: 0.14 - ETA: 5:22 - loss: 3.2048 - accuracy: 0.16 - ETA: 5:27 - loss: 3.2066 - accuracy: 0.16 - ETA: 5:26 - loss: 3.2631 - accuracy: 0.16 - ETA: 5:20 - loss: 3.2704 - accuracy: 0.16 - ETA: 5:16 - loss: 3.2787 - accuracy: 0.15 - ETA: 5:17 - loss: 3.3027 - accuracy: 0.15 - ETA: 5:17 - loss: 3.3055 - accuracy: 0.15 - ETA: 5:14 - loss: 3.3073 - accuracy: 0.15 - ETA: 5:14 - loss: 3.3131 - accuracy: 0.15 - ETA: 5:12 - loss: 3.3112 - accuracy: 0.15 - ETA: 5:11 - loss: 3.3052 - accuracy: 0.16 - ETA: 5:09 - loss: 3.3026 - accuracy: 0.15 - ETA: 5:07 - loss: 3.3031 - accuracy: 0.15 - ETA: 5:06 - loss: 3.3204 - accuracy: 0.15 - ETA: 5:06 - loss: 3.3246 - accuracy: 0.15 - ETA: 5:04 - loss: 3.3237 - accuracy: 0.15 - ETA: 5:03 - loss: 3.3406 - accuracy: 0.14 - ETA: 5:01 - loss: 3.3483 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3586 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3646 - accuracy: 0.14 - ETA: 4:57 - loss: 3.3591 - accuracy: 0.14 - ETA: 4:55 - loss: 3.3539 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3479 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3490 - accuracy: 0.14 - ETA: 4:53 - loss: 3.3548 - accuracy: 0.14 - ETA: 4:52 - loss: 3.3534 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3538 - accuracy: 0.14 - ETA: 4:50 - loss: 3.3467 - accuracy: 0.14 - ETA: 4:48 - loss: 3.3451 - accuracy: 0.14 - ETA: 4:48 - loss: 3.3458 - accuracy: 0.14 - ETA: 4:48 - loss: 3.3439 - accuracy: 0.14 - ETA: 4:46 - loss: 3.3416 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3430 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3440 - accuracy: 0.14 - ETA: 4:43 - loss: 3.3470 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3462 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3450 - accuracy: 0.14 - ETA: 4:41 - loss: 3.3497 - accuracy: 0.14 - ETA: 4:40 - loss: 3.3496 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3468 - accuracy: 0.13 - ETA: 4:38 - loss: 3.3458 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3458 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3459 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3464 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3446 - accuracy: 0.14 - ETA: 4:33 - loss: 3.3405 - accuracy: 0.14 - ETA: 4:32 - loss: 3.3395 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3418 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3456 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3452 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3430 - accuracy: 0.14 - ETA: 4:27 - loss: 3.3433 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3420 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3444 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3475 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3434 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3436 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3428 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3414 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3437 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3452 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3462 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3439 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3431 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3420 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3454 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3447 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3437 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3433 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3451 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3410 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3421 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3413 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3435 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3427 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3447 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3459 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3461 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3441 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3436 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3425 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3395 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3397 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3398 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3417 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3418 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3433 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3428 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3476 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3467 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3457 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3463 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3442 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3448 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3478 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3486 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3494 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3488 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3500 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3512 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3529 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3525 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3527 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3508 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3506 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3501 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3503 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3509 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3509 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3501 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3492 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3491 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3496 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3473 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3483 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3479 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3499 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3503 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3515 - accuracy: 0.13 - ETA: 3:22 - loss: 3.3519 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3518 - accuracy: 0.13 - ETA: 3:20 - loss: 3.3516 - accuracy: 0.13 - ETA: 3:19 - loss: 3.3513 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3505 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3499 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3498 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3497 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3499 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3505 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3509 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3507 - accuracy: 0.13 - ETA: 3:11 - loss: 3.3491 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3488 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3477 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3475 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3475 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3459 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3453 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3453 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3452 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3460 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3449 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3442 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3448 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3440 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3434 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3415 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3405 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3396 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3408 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3410 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3410 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3426 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3422 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3418 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3424 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3425 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3423 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3418 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3427 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3427 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3420 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3411 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3411 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3408 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3419 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3419 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3431 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3424 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3424 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3430 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3436 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3431 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3434 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3436 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3440 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3444 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3446 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3438 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3446 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3431 - accuracy: 0.1424"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3411 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3412 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3406 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3382 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3384 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3390 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3387 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3380 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3381 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3379 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3385 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3391 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3387 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3389 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3397 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3419 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3426 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3417 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3408 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3411 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3417 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3416 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3413 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3409 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3407 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3399 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3408 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3403 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3407 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3405 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3407 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3408 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3402 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3398 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3398 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3409 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3408 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3399 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3399 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3404 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3400 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3405 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3391 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3391 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3381 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3378 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3387 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3381 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3389 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3391 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3389 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3383 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3387 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3385 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3379 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3378 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3375 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3370 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3369 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3362 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3364 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3369 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3369 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3369 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3368 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3371 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3371 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3367 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3366 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3364 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3359 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3358 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3359 - accuracy: 0.14 - ETA: 59s - loss: 3.3365 - accuracy: 0.1425 - ETA: 58s - loss: 3.3365 - accuracy: 0.142 - ETA: 57s - loss: 3.3366 - accuracy: 0.142 - ETA: 56s - loss: 3.3362 - accuracy: 0.142 - ETA: 55s - loss: 3.3358 - accuracy: 0.142 - ETA: 54s - loss: 3.3357 - accuracy: 0.142 - ETA: 54s - loss: 3.3359 - accuracy: 0.142 - ETA: 53s - loss: 3.3358 - accuracy: 0.142 - ETA: 52s - loss: 3.3362 - accuracy: 0.142 - ETA: 51s - loss: 3.3355 - accuracy: 0.142 - ETA: 50s - loss: 3.3360 - accuracy: 0.142 - ETA: 49s - loss: 3.3362 - accuracy: 0.142 - ETA: 48s - loss: 3.3366 - accuracy: 0.142 - ETA: 47s - loss: 3.3369 - accuracy: 0.142 - ETA: 46s - loss: 3.3364 - accuracy: 0.142 - ETA: 45s - loss: 3.3363 - accuracy: 0.142 - ETA: 44s - loss: 3.3365 - accuracy: 0.142 - ETA: 43s - loss: 3.3371 - accuracy: 0.142 - ETA: 42s - loss: 3.3370 - accuracy: 0.142 - ETA: 41s - loss: 3.3374 - accuracy: 0.142 - ETA: 40s - loss: 3.3375 - accuracy: 0.141 - ETA: 39s - loss: 3.3375 - accuracy: 0.142 - ETA: 38s - loss: 3.3378 - accuracy: 0.142 - ETA: 37s - loss: 3.3385 - accuracy: 0.141 - ETA: 36s - loss: 3.3392 - accuracy: 0.141 - ETA: 35s - loss: 3.3397 - accuracy: 0.141 - ETA: 34s - loss: 3.3398 - accuracy: 0.141 - ETA: 33s - loss: 3.3400 - accuracy: 0.141 - ETA: 32s - loss: 3.3402 - accuracy: 0.141 - ETA: 31s - loss: 3.3410 - accuracy: 0.141 - ETA: 30s - loss: 3.3410 - accuracy: 0.141 - ETA: 29s - loss: 3.3405 - accuracy: 0.141 - ETA: 28s - loss: 3.3411 - accuracy: 0.141 - ETA: 27s - loss: 3.3410 - accuracy: 0.141 - ETA: 27s - loss: 3.3412 - accuracy: 0.141 - ETA: 26s - loss: 3.3418 - accuracy: 0.141 - ETA: 25s - loss: 3.3418 - accuracy: 0.141 - ETA: 24s - loss: 3.3407 - accuracy: 0.141 - ETA: 23s - loss: 3.3401 - accuracy: 0.141 - ETA: 22s - loss: 3.3403 - accuracy: 0.141 - ETA: 21s - loss: 3.3406 - accuracy: 0.141 - ETA: 20s - loss: 3.3407 - accuracy: 0.141 - ETA: 19s - loss: 3.3412 - accuracy: 0.141 - ETA: 18s - loss: 3.3413 - accuracy: 0.141 - ETA: 17s - loss: 3.3411 - accuracy: 0.141 - ETA: 16s - loss: 3.3415 - accuracy: 0.141 - ETA: 15s - loss: 3.3413 - accuracy: 0.141 - ETA: 14s - loss: 3.3411 - accuracy: 0.141 - ETA: 13s - loss: 3.3413 - accuracy: 0.141 - ETA: 12s - loss: 3.3413 - accuracy: 0.141 - ETA: 11s - loss: 3.3417 - accuracy: 0.141 - ETA: 10s - loss: 3.3422 - accuracy: 0.141 - ETA: 9s - loss: 3.3422 - accuracy: 0.141 - ETA: 8s - loss: 3.3417 - accuracy: 0.14 - ETA: 7s - loss: 3.3413 - accuracy: 0.14 - ETA: 6s - loss: 3.3416 - accuracy: 0.14 - ETA: 5s - loss: 3.3420 - accuracy: 0.14 - ETA: 4s - loss: 3.3421 - accuracy: 0.14 - ETA: 3s - loss: 3.3418 - accuracy: 0.14 - ETA: 2s - loss: 3.3415 - accuracy: 0.14 - ETA: 2s - loss: 3.3416 - accuracy: 0.14 - ETA: 1s - loss: 3.3417 - accuracy: 0.14 - ETA: 0s - loss: 3.3418 - accuracy: 0.14 - 343s 8ms/step - loss: 3.3419 - accuracy: 0.1413 - val_loss: 3.9190 - val_accuracy: 0.0282\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:53 - loss: 3.1279 - accuracy: 0.21 - ETA: 5:36 - loss: 3.2771 - accuracy: 0.18 - ETA: 5:26 - loss: 3.2686 - accuracy: 0.16 - ETA: 5:20 - loss: 3.2483 - accuracy: 0.16 - ETA: 5:14 - loss: 3.2806 - accuracy: 0.15 - ETA: 5:11 - loss: 3.3060 - accuracy: 0.14 - ETA: 5:10 - loss: 3.2953 - accuracy: 0.15 - ETA: 5:10 - loss: 3.2908 - accuracy: 0.15 - ETA: 5:08 - loss: 3.2781 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2713 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2676 - accuracy: 0.16 - ETA: 5:06 - loss: 3.2776 - accuracy: 0.15 - ETA: 5:06 - loss: 3.2744 - accuracy: 0.15 - ETA: 5:04 - loss: 3.2741 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2730 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2761 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2734 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2760 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2789 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2845 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2862 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2957 - accuracy: 0.15 - ETA: 4:56 - loss: 3.3022 - accuracy: 0.15 - ETA: 4:55 - loss: 3.3014 - accuracy: 0.15 - ETA: 4:55 - loss: 3.3084 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3099 - accuracy: 0.14 - ETA: 4:53 - loss: 3.3112 - accuracy: 0.14 - ETA: 4:53 - loss: 3.3138 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3140 - accuracy: 0.14 - ETA: 4:50 - loss: 3.3138 - accuracy: 0.14 - ETA: 4:48 - loss: 3.3137 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3109 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3139 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3141 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3110 - accuracy: 0.14 - ETA: 4:43 - loss: 3.3104 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3132 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3146 - accuracy: 0.14 - ETA: 4:40 - loss: 3.3157 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3134 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3127 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3100 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3134 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3143 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3169 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3198 - accuracy: 0.14 - ETA: 4:33 - loss: 3.3220 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3243 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3260 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3252 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3260 - accuracy: 0.14 - ETA: 4:27 - loss: 3.3260 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3239 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3254 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3297 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3301 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3300 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3353 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3359 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3336 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3352 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3322 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3303 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3261 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3247 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3256 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3277 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3294 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3305 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3328 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3304 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3305 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3296 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3283 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3249 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3230 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3234 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3238 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3241 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3257 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3260 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3269 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3260 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3269 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3270 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3286 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3278 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3287 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3276 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3277 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3293 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3300 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3294 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3280 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3263 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3267 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3259 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3257 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3256 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3238 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3250 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3259 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3267 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3273 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3273 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3268 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3271 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3262 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3265 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3280 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3284 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3284 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3276 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3275 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3278 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3269 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3258 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3269 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3261 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3253 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3249 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3250 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3258 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3255 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3258 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3248 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3251 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3245 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3280 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3283 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3284 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3272 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3257 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3246 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3244 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3255 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3251 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3247 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3244 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3244 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3241 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3246 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3243 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3243 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3251 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3268 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3272 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3265 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3275 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3285 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3294 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3305 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3301 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3298 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3293 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3283 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3291 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3303 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3314 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3316 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3319 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3320 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3320 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3322 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3327 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3340 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3344 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3334 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3337 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3339 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3342 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3349 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3345 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3343 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3352 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3352 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3355 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3363 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3358 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3357 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3359 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3363 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3364 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3353 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3349 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3351 - accuracy: 0.1429"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:19 - loss: 3.3349 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3349 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3341 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3349 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3339 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3336 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3343 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3350 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3354 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3352 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3351 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3356 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3356 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3355 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3347 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3346 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3350 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3346 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3343 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3341 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3340 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3343 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3346 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3346 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3341 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3341 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3334 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3343 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3343 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3345 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3351 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3355 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3354 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3348 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3349 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3348 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3346 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3349 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3349 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3346 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3348 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3341 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3338 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3344 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3347 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3347 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3344 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3347 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3357 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3353 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3356 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3353 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3359 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3362 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3367 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3378 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3382 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3381 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3364 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3369 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3369 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3373 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3378 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3382 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3382 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3387 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3373 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3381 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3385 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3385 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3382 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3386 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3383 - accuracy: 0.14 - ETA: 59s - loss: 3.3384 - accuracy: 0.1414 - ETA: 58s - loss: 3.3386 - accuracy: 0.141 - ETA: 57s - loss: 3.3379 - accuracy: 0.141 - ETA: 57s - loss: 3.3383 - accuracy: 0.141 - ETA: 56s - loss: 3.3381 - accuracy: 0.141 - ETA: 55s - loss: 3.3377 - accuracy: 0.141 - ETA: 54s - loss: 3.3379 - accuracy: 0.141 - ETA: 53s - loss: 3.3381 - accuracy: 0.141 - ETA: 52s - loss: 3.3378 - accuracy: 0.141 - ETA: 51s - loss: 3.3377 - accuracy: 0.141 - ETA: 50s - loss: 3.3376 - accuracy: 0.141 - ETA: 49s - loss: 3.3375 - accuracy: 0.141 - ETA: 48s - loss: 3.3372 - accuracy: 0.141 - ETA: 47s - loss: 3.3368 - accuracy: 0.141 - ETA: 46s - loss: 3.3369 - accuracy: 0.141 - ETA: 45s - loss: 3.3364 - accuracy: 0.141 - ETA: 44s - loss: 3.3372 - accuracy: 0.141 - ETA: 43s - loss: 3.3375 - accuracy: 0.141 - ETA: 42s - loss: 3.3372 - accuracy: 0.141 - ETA: 41s - loss: 3.3374 - accuracy: 0.141 - ETA: 40s - loss: 3.3372 - accuracy: 0.141 - ETA: 39s - loss: 3.3367 - accuracy: 0.142 - ETA: 38s - loss: 3.3368 - accuracy: 0.142 - ETA: 37s - loss: 3.3368 - accuracy: 0.141 - ETA: 36s - loss: 3.3369 - accuracy: 0.141 - ETA: 35s - loss: 3.3369 - accuracy: 0.141 - ETA: 34s - loss: 3.3372 - accuracy: 0.141 - ETA: 33s - loss: 3.3371 - accuracy: 0.141 - ETA: 32s - loss: 3.3374 - accuracy: 0.141 - ETA: 31s - loss: 3.3375 - accuracy: 0.141 - ETA: 30s - loss: 3.3377 - accuracy: 0.141 - ETA: 29s - loss: 3.3377 - accuracy: 0.141 - ETA: 29s - loss: 3.3379 - accuracy: 0.141 - ETA: 28s - loss: 3.3378 - accuracy: 0.141 - ETA: 27s - loss: 3.3379 - accuracy: 0.141 - ETA: 26s - loss: 3.3385 - accuracy: 0.141 - ETA: 25s - loss: 3.3386 - accuracy: 0.141 - ETA: 24s - loss: 3.3384 - accuracy: 0.141 - ETA: 23s - loss: 3.3380 - accuracy: 0.141 - ETA: 22s - loss: 3.3378 - accuracy: 0.141 - ETA: 21s - loss: 3.3375 - accuracy: 0.141 - ETA: 20s - loss: 3.3379 - accuracy: 0.141 - ETA: 19s - loss: 3.3377 - accuracy: 0.141 - ETA: 18s - loss: 3.3375 - accuracy: 0.141 - ETA: 17s - loss: 3.3378 - accuracy: 0.141 - ETA: 16s - loss: 3.3375 - accuracy: 0.141 - ETA: 15s - loss: 3.3377 - accuracy: 0.141 - ETA: 14s - loss: 3.3377 - accuracy: 0.141 - ETA: 13s - loss: 3.3374 - accuracy: 0.141 - ETA: 12s - loss: 3.3372 - accuracy: 0.141 - ETA: 11s - loss: 3.3373 - accuracy: 0.141 - ETA: 10s - loss: 3.3373 - accuracy: 0.141 - ETA: 9s - loss: 3.3378 - accuracy: 0.141 - ETA: 8s - loss: 3.3377 - accuracy: 0.14 - ETA: 7s - loss: 3.3379 - accuracy: 0.14 - ETA: 6s - loss: 3.3384 - accuracy: 0.14 - ETA: 5s - loss: 3.3388 - accuracy: 0.14 - ETA: 4s - loss: 3.3392 - accuracy: 0.14 - ETA: 3s - loss: 3.3393 - accuracy: 0.14 - ETA: 2s - loss: 3.3392 - accuracy: 0.14 - ETA: 2s - loss: 3.3394 - accuracy: 0.14 - ETA: 1s - loss: 3.3396 - accuracy: 0.14 - ETA: 0s - loss: 3.3398 - accuracy: 0.14 - 343s 8ms/step - loss: 3.3399 - accuracy: 0.1412 - val_loss: 3.9603 - val_accuracy: 0.0331\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:20 - loss: 3.4486 - accuracy: 0.12 - ETA: 5:24 - loss: 3.4414 - accuracy: 0.13 - ETA: 5:17 - loss: 3.4336 - accuracy: 0.12 - ETA: 5:13 - loss: 3.3907 - accuracy: 0.13 - ETA: 5:13 - loss: 3.4176 - accuracy: 0.12 - ETA: 5:09 - loss: 3.4164 - accuracy: 0.12 - ETA: 5:06 - loss: 3.4212 - accuracy: 0.12 - ETA: 5:02 - loss: 3.4210 - accuracy: 0.12 - ETA: 5:02 - loss: 3.4029 - accuracy: 0.12 - ETA: 5:02 - loss: 3.3819 - accuracy: 0.13 - ETA: 5:02 - loss: 3.3957 - accuracy: 0.13 - ETA: 5:03 - loss: 3.3981 - accuracy: 0.13 - ETA: 5:03 - loss: 3.3991 - accuracy: 0.13 - ETA: 5:02 - loss: 3.4100 - accuracy: 0.12 - ETA: 5:00 - loss: 3.4224 - accuracy: 0.12 - ETA: 4:59 - loss: 3.4191 - accuracy: 0.12 - ETA: 4:58 - loss: 3.4250 - accuracy: 0.12 - ETA: 4:56 - loss: 3.4254 - accuracy: 0.12 - ETA: 4:55 - loss: 3.4237 - accuracy: 0.12 - ETA: 4:55 - loss: 3.4259 - accuracy: 0.12 - ETA: 4:54 - loss: 3.4210 - accuracy: 0.12 - ETA: 4:52 - loss: 3.4198 - accuracy: 0.12 - ETA: 4:52 - loss: 3.4255 - accuracy: 0.12 - ETA: 4:50 - loss: 3.4204 - accuracy: 0.12 - ETA: 4:49 - loss: 3.4091 - accuracy: 0.13 - ETA: 4:48 - loss: 3.4133 - accuracy: 0.12 - ETA: 4:47 - loss: 3.4135 - accuracy: 0.12 - ETA: 4:47 - loss: 3.4122 - accuracy: 0.12 - ETA: 4:47 - loss: 3.4058 - accuracy: 0.12 - ETA: 4:46 - loss: 3.4047 - accuracy: 0.12 - ETA: 4:45 - loss: 3.4086 - accuracy: 0.12 - ETA: 4:45 - loss: 3.4041 - accuracy: 0.12 - ETA: 4:44 - loss: 3.3995 - accuracy: 0.12 - ETA: 4:44 - loss: 3.4028 - accuracy: 0.12 - ETA: 4:43 - loss: 3.4045 - accuracy: 0.12 - ETA: 4:42 - loss: 3.4006 - accuracy: 0.12 - ETA: 4:41 - loss: 3.4006 - accuracy: 0.12 - ETA: 4:40 - loss: 3.4012 - accuracy: 0.12 - ETA: 4:40 - loss: 3.3978 - accuracy: 0.12 - ETA: 4:38 - loss: 3.3949 - accuracy: 0.13 - ETA: 4:37 - loss: 3.3969 - accuracy: 0.13 - ETA: 4:36 - loss: 3.3953 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3963 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3949 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3938 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3928 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3897 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3838 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3815 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3773 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3735 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3760 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3724 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3700 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3708 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3706 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3688 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3678 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3639 - accuracy: 0.13 - ETA: 4:19 - loss: 3.3621 - accuracy: 0.13 - ETA: 4:18 - loss: 3.3598 - accuracy: 0.13 - ETA: 4:17 - loss: 3.3620 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3592 - accuracy: 0.13 - ETA: 4:15 - loss: 3.3586 - accuracy: 0.13 - ETA: 4:14 - loss: 3.3572 - accuracy: 0.13 - ETA: 4:13 - loss: 3.3584 - accuracy: 0.13 - ETA: 4:12 - loss: 3.3587 - accuracy: 0.13 - ETA: 4:11 - loss: 3.3580 - accuracy: 0.13 - ETA: 4:11 - loss: 3.3567 - accuracy: 0.13 - ETA: 4:10 - loss: 3.3560 - accuracy: 0.13 - ETA: 4:09 - loss: 3.3579 - accuracy: 0.13 - ETA: 4:08 - loss: 3.3555 - accuracy: 0.13 - ETA: 4:07 - loss: 3.3567 - accuracy: 0.13 - ETA: 4:06 - loss: 3.3569 - accuracy: 0.13 - ETA: 4:05 - loss: 3.3578 - accuracy: 0.13 - ETA: 4:03 - loss: 3.3571 - accuracy: 0.13 - ETA: 4:02 - loss: 3.3575 - accuracy: 0.13 - ETA: 4:02 - loss: 3.3574 - accuracy: 0.13 - ETA: 4:01 - loss: 3.3569 - accuracy: 0.13 - ETA: 4:00 - loss: 3.3551 - accuracy: 0.13 - ETA: 3:59 - loss: 3.3556 - accuracy: 0.13 - ETA: 3:58 - loss: 3.3541 - accuracy: 0.13 - ETA: 3:57 - loss: 3.3535 - accuracy: 0.13 - ETA: 3:56 - loss: 3.3532 - accuracy: 0.13 - ETA: 3:55 - loss: 3.3555 - accuracy: 0.13 - ETA: 3:54 - loss: 3.3539 - accuracy: 0.13 - ETA: 3:53 - loss: 3.3537 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3541 - accuracy: 0.13 - ETA: 3:51 - loss: 3.3549 - accuracy: 0.13 - ETA: 3:50 - loss: 3.3552 - accuracy: 0.13 - ETA: 3:49 - loss: 3.3560 - accuracy: 0.13 - ETA: 3:48 - loss: 3.3558 - accuracy: 0.13 - ETA: 3:46 - loss: 3.3565 - accuracy: 0.13 - ETA: 3:46 - loss: 3.3557 - accuracy: 0.13 - ETA: 3:44 - loss: 3.3566 - accuracy: 0.13 - ETA: 3:43 - loss: 3.3547 - accuracy: 0.13 - ETA: 3:43 - loss: 3.3540 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3545 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3541 - accuracy: 0.13 - ETA: 3:40 - loss: 3.3533 - accuracy: 0.13 - ETA: 3:39 - loss: 3.3531 - accuracy: 0.13 - ETA: 3:38 - loss: 3.3542 - accuracy: 0.13 - ETA: 3:37 - loss: 3.3547 - accuracy: 0.13 - ETA: 3:36 - loss: 3.3557 - accuracy: 0.13 - ETA: 3:35 - loss: 3.3549 - accuracy: 0.13 - ETA: 3:34 - loss: 3.3554 - accuracy: 0.13 - ETA: 3:33 - loss: 3.3553 - accuracy: 0.13 - ETA: 3:32 - loss: 3.3551 - accuracy: 0.13 - ETA: 3:31 - loss: 3.3539 - accuracy: 0.13 - ETA: 3:30 - loss: 3.3544 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3552 - accuracy: 0.13 - ETA: 3:28 - loss: 3.3554 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3538 - accuracy: 0.13 - ETA: 3:26 - loss: 3.3534 - accuracy: 0.13 - ETA: 3:25 - loss: 3.3540 - accuracy: 0.13 - ETA: 3:24 - loss: 3.3544 - accuracy: 0.13 - ETA: 3:24 - loss: 3.3539 - accuracy: 0.13 - ETA: 3:23 - loss: 3.3541 - accuracy: 0.13 - ETA: 3:22 - loss: 3.3548 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3542 - accuracy: 0.13 - ETA: 3:20 - loss: 3.3523 - accuracy: 0.13 - ETA: 3:19 - loss: 3.3512 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3514 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3506 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3503 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3505 - accuracy: 0.13 - ETA: 3:14 - loss: 3.3495 - accuracy: 0.13 - ETA: 3:13 - loss: 3.3488 - accuracy: 0.13 - ETA: 3:12 - loss: 3.3491 - accuracy: 0.13 - ETA: 3:11 - loss: 3.3478 - accuracy: 0.13 - ETA: 3:10 - loss: 3.3475 - accuracy: 0.13 - ETA: 3:09 - loss: 3.3480 - accuracy: 0.13 - ETA: 3:08 - loss: 3.3484 - accuracy: 0.13 - ETA: 3:07 - loss: 3.3482 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3468 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3467 - accuracy: 0.13 - ETA: 3:05 - loss: 3.3478 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3474 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3491 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3469 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3474 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3479 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3484 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3492 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3501 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3505 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3492 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3490 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3483 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3490 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3484 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3482 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3474 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3478 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3471 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3466 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3467 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3473 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3470 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3479 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3468 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3459 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3454 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3447 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3434 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3439 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3444 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3434 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3437 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3428 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3420 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3420 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3410 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3402 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3410 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3422 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3425 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3426 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3432 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3426 - accuracy: 0.1414"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3429 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3438 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3441 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3434 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3432 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3430 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3425 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3438 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3438 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3438 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3437 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3431 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3436 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3428 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3429 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3428 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3430 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3434 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3429 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3425 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3433 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3427 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3419 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3423 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3425 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3426 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3430 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3430 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3432 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3433 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3427 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3421 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3416 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3416 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3419 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3414 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3417 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3418 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3413 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3410 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3406 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3400 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3392 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3397 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3395 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3389 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3386 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3390 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3393 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3387 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3389 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3389 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3381 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3383 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3372 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3371 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3371 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3372 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3375 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3375 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3378 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3375 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3370 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3365 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3360 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3359 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3361 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3359 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3357 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3362 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3370 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3371 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3370 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3364 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3364 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3365 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3366 - accuracy: 0.14 - ETA: 59s - loss: 3.3360 - accuracy: 0.1431 - ETA: 58s - loss: 3.3362 - accuracy: 0.143 - ETA: 57s - loss: 3.3364 - accuracy: 0.143 - ETA: 56s - loss: 3.3359 - accuracy: 0.143 - ETA: 55s - loss: 3.3350 - accuracy: 0.143 - ETA: 54s - loss: 3.3350 - accuracy: 0.143 - ETA: 53s - loss: 3.3347 - accuracy: 0.143 - ETA: 52s - loss: 3.3353 - accuracy: 0.143 - ETA: 51s - loss: 3.3355 - accuracy: 0.143 - ETA: 50s - loss: 3.3350 - accuracy: 0.143 - ETA: 49s - loss: 3.3354 - accuracy: 0.143 - ETA: 48s - loss: 3.3350 - accuracy: 0.143 - ETA: 47s - loss: 3.3352 - accuracy: 0.143 - ETA: 46s - loss: 3.3350 - accuracy: 0.143 - ETA: 46s - loss: 3.3351 - accuracy: 0.143 - ETA: 45s - loss: 3.3348 - accuracy: 0.143 - ETA: 44s - loss: 3.3339 - accuracy: 0.143 - ETA: 43s - loss: 3.3333 - accuracy: 0.143 - ETA: 42s - loss: 3.3329 - accuracy: 0.143 - ETA: 41s - loss: 3.3333 - accuracy: 0.143 - ETA: 40s - loss: 3.3326 - accuracy: 0.143 - ETA: 39s - loss: 3.3322 - accuracy: 0.143 - ETA: 38s - loss: 3.3326 - accuracy: 0.143 - ETA: 37s - loss: 3.3327 - accuracy: 0.143 - ETA: 36s - loss: 3.3326 - accuracy: 0.143 - ETA: 35s - loss: 3.3321 - accuracy: 0.143 - ETA: 34s - loss: 3.3318 - accuracy: 0.143 - ETA: 33s - loss: 3.3324 - accuracy: 0.143 - ETA: 32s - loss: 3.3326 - accuracy: 0.143 - ETA: 31s - loss: 3.3332 - accuracy: 0.143 - ETA: 30s - loss: 3.3332 - accuracy: 0.143 - ETA: 29s - loss: 3.3329 - accuracy: 0.143 - ETA: 28s - loss: 3.3330 - accuracy: 0.143 - ETA: 27s - loss: 3.3332 - accuracy: 0.143 - ETA: 26s - loss: 3.3331 - accuracy: 0.143 - ETA: 25s - loss: 3.3330 - accuracy: 0.143 - ETA: 24s - loss: 3.3329 - accuracy: 0.143 - ETA: 24s - loss: 3.3327 - accuracy: 0.143 - ETA: 23s - loss: 3.3335 - accuracy: 0.143 - ETA: 22s - loss: 3.3334 - accuracy: 0.143 - ETA: 21s - loss: 3.3333 - accuracy: 0.143 - ETA: 20s - loss: 3.3334 - accuracy: 0.143 - ETA: 19s - loss: 3.3341 - accuracy: 0.143 - ETA: 18s - loss: 3.3345 - accuracy: 0.143 - ETA: 17s - loss: 3.3349 - accuracy: 0.143 - ETA: 16s - loss: 3.3351 - accuracy: 0.143 - ETA: 15s - loss: 3.3350 - accuracy: 0.143 - ETA: 14s - loss: 3.3352 - accuracy: 0.143 - ETA: 13s - loss: 3.3352 - accuracy: 0.143 - ETA: 12s - loss: 3.3353 - accuracy: 0.143 - ETA: 11s - loss: 3.3350 - accuracy: 0.143 - ETA: 10s - loss: 3.3346 - accuracy: 0.143 - ETA: 9s - loss: 3.3346 - accuracy: 0.143 - ETA: 8s - loss: 3.3352 - accuracy: 0.14 - ETA: 7s - loss: 3.3356 - accuracy: 0.14 - ETA: 6s - loss: 3.3357 - accuracy: 0.14 - ETA: 5s - loss: 3.3359 - accuracy: 0.14 - ETA: 4s - loss: 3.3359 - accuracy: 0.14 - ETA: 3s - loss: 3.3364 - accuracy: 0.14 - ETA: 2s - loss: 3.3364 - accuracy: 0.14 - ETA: 1s - loss: 3.3364 - accuracy: 0.14 - ETA: 1s - loss: 3.3356 - accuracy: 0.14 - ETA: 0s - loss: 3.3356 - accuracy: 0.14 - 342s 8ms/step - loss: 3.3356 - accuracy: 0.1432 - val_loss: 4.0665 - val_accuracy: 0.0253\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:52 - loss: 3.4079 - accuracy: 0.11 - ETA: 4:48 - loss: 3.5184 - accuracy: 0.12 - ETA: 4:52 - loss: 3.5462 - accuracy: 0.12 - ETA: 4:57 - loss: 3.5113 - accuracy: 0.12 - ETA: 5:00 - loss: 3.4498 - accuracy: 0.13 - ETA: 5:04 - loss: 3.4277 - accuracy: 0.14 - ETA: 5:06 - loss: 3.4202 - accuracy: 0.13 - ETA: 5:04 - loss: 3.4327 - accuracy: 0.13 - ETA: 5:04 - loss: 3.4175 - accuracy: 0.13 - ETA: 5:04 - loss: 3.4182 - accuracy: 0.13 - ETA: 5:05 - loss: 3.4179 - accuracy: 0.13 - ETA: 5:02 - loss: 3.4237 - accuracy: 0.13 - ETA: 5:00 - loss: 3.4293 - accuracy: 0.13 - ETA: 5:00 - loss: 3.4335 - accuracy: 0.12 - ETA: 5:00 - loss: 3.4226 - accuracy: 0.13 - ETA: 4:58 - loss: 3.4196 - accuracy: 0.13 - ETA: 4:59 - loss: 3.4217 - accuracy: 0.13 - ETA: 4:59 - loss: 3.4198 - accuracy: 0.13 - ETA: 4:58 - loss: 3.4148 - accuracy: 0.13 - ETA: 4:57 - loss: 3.4184 - accuracy: 0.13 - ETA: 4:57 - loss: 3.4114 - accuracy: 0.13 - ETA: 4:55 - loss: 3.4136 - accuracy: 0.13 - ETA: 4:54 - loss: 3.4016 - accuracy: 0.13 - ETA: 4:53 - loss: 3.3963 - accuracy: 0.13 - ETA: 4:51 - loss: 3.3931 - accuracy: 0.13 - ETA: 4:51 - loss: 3.3927 - accuracy: 0.13 - ETA: 4:50 - loss: 3.3914 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3930 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3962 - accuracy: 0.13 - ETA: 4:47 - loss: 3.3969 - accuracy: 0.13 - ETA: 4:46 - loss: 3.4022 - accuracy: 0.13 - ETA: 4:45 - loss: 3.4035 - accuracy: 0.13 - ETA: 4:44 - loss: 3.4030 - accuracy: 0.13 - ETA: 4:43 - loss: 3.4053 - accuracy: 0.13 - ETA: 4:42 - loss: 3.4057 - accuracy: 0.13 - ETA: 4:40 - loss: 3.4061 - accuracy: 0.13 - ETA: 4:40 - loss: 3.4052 - accuracy: 0.13 - ETA: 4:39 - loss: 3.4068 - accuracy: 0.12 - ETA: 4:38 - loss: 3.4023 - accuracy: 0.12 - ETA: 4:38 - loss: 3.3975 - accuracy: 0.12 - ETA: 4:37 - loss: 3.3954 - accuracy: 0.13 - ETA: 4:36 - loss: 3.3954 - accuracy: 0.13 - ETA: 4:36 - loss: 3.3975 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3964 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3946 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3935 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3974 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3955 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3983 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3962 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3935 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3930 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3917 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3901 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3878 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3882 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3854 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3828 - accuracy: 0.13 - ETA: 4:19 - loss: 3.3818 - accuracy: 0.13 - ETA: 4:18 - loss: 3.3828 - accuracy: 0.13 - ETA: 4:17 - loss: 3.3815 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3811 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3797 - accuracy: 0.13 - ETA: 4:14 - loss: 3.3780 - accuracy: 0.13 - ETA: 4:14 - loss: 3.3762 - accuracy: 0.13 - ETA: 4:13 - loss: 3.3757 - accuracy: 0.13 - ETA: 4:12 - loss: 3.3755 - accuracy: 0.13 - ETA: 4:11 - loss: 3.3750 - accuracy: 0.13 - ETA: 4:10 - loss: 3.3743 - accuracy: 0.13 - ETA: 4:09 - loss: 3.3746 - accuracy: 0.13 - ETA: 4:08 - loss: 3.3755 - accuracy: 0.13 - ETA: 4:07 - loss: 3.3758 - accuracy: 0.13 - ETA: 4:06 - loss: 3.3756 - accuracy: 0.13 - ETA: 4:05 - loss: 3.3749 - accuracy: 0.13 - ETA: 4:04 - loss: 3.3751 - accuracy: 0.13 - ETA: 4:03 - loss: 3.3721 - accuracy: 0.13 - ETA: 4:03 - loss: 3.3729 - accuracy: 0.13 - ETA: 4:02 - loss: 3.3727 - accuracy: 0.13 - ETA: 4:01 - loss: 3.3692 - accuracy: 0.13 - ETA: 4:00 - loss: 3.3685 - accuracy: 0.13 - ETA: 3:59 - loss: 3.3671 - accuracy: 0.13 - ETA: 3:58 - loss: 3.3638 - accuracy: 0.13 - ETA: 3:57 - loss: 3.3630 - accuracy: 0.13 - ETA: 3:56 - loss: 3.3630 - accuracy: 0.13 - ETA: 3:55 - loss: 3.3628 - accuracy: 0.13 - ETA: 3:54 - loss: 3.3606 - accuracy: 0.13 - ETA: 3:53 - loss: 3.3597 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3584 - accuracy: 0.13 - ETA: 3:51 - loss: 3.3581 - accuracy: 0.13 - ETA: 3:50 - loss: 3.3589 - accuracy: 0.13 - ETA: 3:50 - loss: 3.3581 - accuracy: 0.13 - ETA: 3:49 - loss: 3.3571 - accuracy: 0.13 - ETA: 3:48 - loss: 3.3574 - accuracy: 0.13 - ETA: 3:47 - loss: 3.3590 - accuracy: 0.13 - ETA: 3:46 - loss: 3.3594 - accuracy: 0.13 - ETA: 3:45 - loss: 3.3581 - accuracy: 0.13 - ETA: 3:44 - loss: 3.3581 - accuracy: 0.13 - ETA: 3:43 - loss: 3.3575 - accuracy: 0.13 - ETA: 3:42 - loss: 3.3582 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3589 - accuracy: 0.13 - ETA: 3:40 - loss: 3.3598 - accuracy: 0.13 - ETA: 3:39 - loss: 3.3604 - accuracy: 0.13 - ETA: 3:38 - loss: 3.3610 - accuracy: 0.13 - ETA: 3:37 - loss: 3.3598 - accuracy: 0.13 - ETA: 3:36 - loss: 3.3597 - accuracy: 0.13 - ETA: 3:35 - loss: 3.3610 - accuracy: 0.13 - ETA: 3:34 - loss: 3.3606 - accuracy: 0.13 - ETA: 3:33 - loss: 3.3584 - accuracy: 0.13 - ETA: 3:33 - loss: 3.3585 - accuracy: 0.13 - ETA: 3:32 - loss: 3.3587 - accuracy: 0.13 - ETA: 3:31 - loss: 3.3594 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3589 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3589 - accuracy: 0.13 - ETA: 3:28 - loss: 3.3574 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3559 - accuracy: 0.13 - ETA: 3:26 - loss: 3.3543 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3536 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3534 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3528 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3519 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3512 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3499 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3488 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3487 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3486 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3480 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3472 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3477 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3476 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3485 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3500 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3498 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3513 - accuracy: 0.13 - ETA: 3:08 - loss: 3.3495 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3490 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3486 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3486 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3491 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3481 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3490 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3497 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3485 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3489 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3504 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3496 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3490 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3493 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3483 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3479 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3478 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3479 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3481 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3475 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3476 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3479 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3483 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3485 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3466 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3453 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3445 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3445 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3439 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3439 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3424 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3407 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3417 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3424 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3419 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3419 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3432 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3430 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3428 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3424 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3425 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3427 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3422 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3433 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3434 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3441 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3435 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3429 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3429 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3428 - accuracy: 0.1406"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3425 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3419 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3411 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3413 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3409 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3403 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3400 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3388 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3397 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3393 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3398 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3384 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3386 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3383 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3383 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3392 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3384 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3398 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3392 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3398 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3404 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3410 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3408 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3404 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3404 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3399 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3392 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3387 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3388 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3387 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3365 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3357 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3359 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3364 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3376 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3381 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3381 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3383 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3386 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3379 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3385 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3382 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3381 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3383 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3370 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3368 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3372 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3378 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3376 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3375 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3371 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3373 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3382 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3378 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3375 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3366 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3358 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3362 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3365 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3369 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3366 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3363 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3362 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3365 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3368 - accuracy: 0.14 - ETA: 59s - loss: 3.3367 - accuracy: 0.1409 - ETA: 58s - loss: 3.3370 - accuracy: 0.141 - ETA: 57s - loss: 3.3372 - accuracy: 0.141 - ETA: 56s - loss: 3.3366 - accuracy: 0.141 - ETA: 55s - loss: 3.3363 - accuracy: 0.141 - ETA: 54s - loss: 3.3363 - accuracy: 0.141 - ETA: 53s - loss: 3.3366 - accuracy: 0.141 - ETA: 52s - loss: 3.3371 - accuracy: 0.141 - ETA: 51s - loss: 3.3374 - accuracy: 0.140 - ETA: 50s - loss: 3.3370 - accuracy: 0.141 - ETA: 49s - loss: 3.3371 - accuracy: 0.141 - ETA: 48s - loss: 3.3369 - accuracy: 0.141 - ETA: 47s - loss: 3.3372 - accuracy: 0.140 - ETA: 46s - loss: 3.3376 - accuracy: 0.140 - ETA: 46s - loss: 3.3381 - accuracy: 0.140 - ETA: 45s - loss: 3.3382 - accuracy: 0.140 - ETA: 44s - loss: 3.3380 - accuracy: 0.140 - ETA: 43s - loss: 3.3379 - accuracy: 0.140 - ETA: 42s - loss: 3.3386 - accuracy: 0.140 - ETA: 41s - loss: 3.3390 - accuracy: 0.140 - ETA: 40s - loss: 3.3393 - accuracy: 0.140 - ETA: 39s - loss: 3.3392 - accuracy: 0.140 - ETA: 38s - loss: 3.3391 - accuracy: 0.140 - ETA: 37s - loss: 3.3397 - accuracy: 0.140 - ETA: 36s - loss: 3.3400 - accuracy: 0.140 - ETA: 35s - loss: 3.3398 - accuracy: 0.140 - ETA: 34s - loss: 3.3402 - accuracy: 0.140 - ETA: 33s - loss: 3.3405 - accuracy: 0.140 - ETA: 32s - loss: 3.3407 - accuracy: 0.140 - ETA: 31s - loss: 3.3406 - accuracy: 0.140 - ETA: 30s - loss: 3.3407 - accuracy: 0.140 - ETA: 29s - loss: 3.3403 - accuracy: 0.140 - ETA: 28s - loss: 3.3404 - accuracy: 0.140 - ETA: 27s - loss: 3.3412 - accuracy: 0.140 - ETA: 26s - loss: 3.3411 - accuracy: 0.140 - ETA: 25s - loss: 3.3414 - accuracy: 0.140 - ETA: 24s - loss: 3.3416 - accuracy: 0.140 - ETA: 24s - loss: 3.3419 - accuracy: 0.140 - ETA: 23s - loss: 3.3416 - accuracy: 0.140 - ETA: 22s - loss: 3.3419 - accuracy: 0.139 - ETA: 21s - loss: 3.3418 - accuracy: 0.139 - ETA: 20s - loss: 3.3414 - accuracy: 0.140 - ETA: 19s - loss: 3.3407 - accuracy: 0.140 - ETA: 18s - loss: 3.3400 - accuracy: 0.140 - ETA: 17s - loss: 3.3402 - accuracy: 0.140 - ETA: 16s - loss: 3.3402 - accuracy: 0.140 - ETA: 15s - loss: 3.3400 - accuracy: 0.140 - ETA: 14s - loss: 3.3399 - accuracy: 0.140 - ETA: 13s - loss: 3.3399 - accuracy: 0.140 - ETA: 12s - loss: 3.3398 - accuracy: 0.140 - ETA: 11s - loss: 3.3405 - accuracy: 0.139 - ETA: 10s - loss: 3.3407 - accuracy: 0.139 - ETA: 9s - loss: 3.3406 - accuracy: 0.139 - ETA: 8s - loss: 3.3408 - accuracy: 0.13 - ETA: 7s - loss: 3.3408 - accuracy: 0.13 - ETA: 6s - loss: 3.3407 - accuracy: 0.14 - ETA: 5s - loss: 3.3409 - accuracy: 0.14 - ETA: 4s - loss: 3.3410 - accuracy: 0.14 - ETA: 3s - loss: 3.3405 - accuracy: 0.14 - ETA: 2s - loss: 3.3408 - accuracy: 0.14 - ETA: 1s - loss: 3.3408 - accuracy: 0.14 - ETA: 1s - loss: 3.3412 - accuracy: 0.14 - ETA: 0s - loss: 3.3411 - accuracy: 0.14 - 341s 8ms/step - loss: 3.3412 - accuracy: 0.1401 - val_loss: 3.8982 - val_accuracy: 0.0235\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:13 - loss: 3.0037 - accuracy: 0.21 - ETA: 5:13 - loss: 3.1393 - accuracy: 0.19 - ETA: 5:15 - loss: 3.2319 - accuracy: 0.16 - ETA: 5:11 - loss: 3.2759 - accuracy: 0.16 - ETA: 5:08 - loss: 3.3042 - accuracy: 0.15 - ETA: 5:10 - loss: 3.3214 - accuracy: 0.15 - ETA: 5:13 - loss: 3.3864 - accuracy: 0.14 - ETA: 5:14 - loss: 3.3963 - accuracy: 0.13 - ETA: 5:11 - loss: 3.4095 - accuracy: 0.13 - ETA: 5:10 - loss: 3.3946 - accuracy: 0.13 - ETA: 5:08 - loss: 3.4004 - accuracy: 0.13 - ETA: 5:07 - loss: 3.3921 - accuracy: 0.13 - ETA: 5:03 - loss: 3.3878 - accuracy: 0.13 - ETA: 5:02 - loss: 3.3813 - accuracy: 0.13 - ETA: 5:00 - loss: 3.3806 - accuracy: 0.13 - ETA: 4:59 - loss: 3.3864 - accuracy: 0.13 - ETA: 5:00 - loss: 3.3848 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3812 - accuracy: 0.13 - ETA: 4:57 - loss: 3.3798 - accuracy: 0.13 - ETA: 4:57 - loss: 3.3755 - accuracy: 0.13 - ETA: 4:55 - loss: 3.3680 - accuracy: 0.13 - ETA: 4:55 - loss: 3.3730 - accuracy: 0.13 - ETA: 4:54 - loss: 3.3733 - accuracy: 0.13 - ETA: 4:53 - loss: 3.3733 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3704 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3752 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3771 - accuracy: 0.13 - ETA: 4:50 - loss: 3.3743 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3747 - accuracy: 0.13 - ETA: 4:48 - loss: 3.3781 - accuracy: 0.13 - ETA: 4:47 - loss: 3.3805 - accuracy: 0.13 - ETA: 4:45 - loss: 3.3786 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3775 - accuracy: 0.13 - ETA: 4:43 - loss: 3.3759 - accuracy: 0.13 - ETA: 4:42 - loss: 3.3789 - accuracy: 0.13 - ETA: 4:41 - loss: 3.3778 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3797 - accuracy: 0.13 - ETA: 4:39 - loss: 3.3799 - accuracy: 0.13 - ETA: 4:38 - loss: 3.3801 - accuracy: 0.13 - ETA: 4:37 - loss: 3.3808 - accuracy: 0.13 - ETA: 4:36 - loss: 3.3834 - accuracy: 0.13 - ETA: 4:36 - loss: 3.3797 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3807 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3824 - accuracy: 0.12 - ETA: 4:33 - loss: 3.3799 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3795 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3787 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3781 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3740 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3703 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3703 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3684 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3655 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3629 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3608 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3614 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3632 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3674 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3671 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3684 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3665 - accuracy: 0.13 - ETA: 4:19 - loss: 3.3662 - accuracy: 0.13 - ETA: 4:17 - loss: 3.3652 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3678 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3679 - accuracy: 0.13 - ETA: 4:14 - loss: 3.3686 - accuracy: 0.13 - ETA: 4:13 - loss: 3.3667 - accuracy: 0.13 - ETA: 4:13 - loss: 3.3669 - accuracy: 0.13 - ETA: 4:12 - loss: 3.3698 - accuracy: 0.13 - ETA: 4:11 - loss: 3.3676 - accuracy: 0.13 - ETA: 4:10 - loss: 3.3677 - accuracy: 0.13 - ETA: 4:09 - loss: 3.3659 - accuracy: 0.13 - ETA: 4:08 - loss: 3.3658 - accuracy: 0.13 - ETA: 4:07 - loss: 3.3648 - accuracy: 0.13 - ETA: 4:07 - loss: 3.3635 - accuracy: 0.13 - ETA: 4:06 - loss: 3.3637 - accuracy: 0.13 - ETA: 4:05 - loss: 3.3635 - accuracy: 0.13 - ETA: 4:04 - loss: 3.3634 - accuracy: 0.13 - ETA: 4:03 - loss: 3.3633 - accuracy: 0.13 - ETA: 4:02 - loss: 3.3649 - accuracy: 0.13 - ETA: 4:01 - loss: 3.3646 - accuracy: 0.13 - ETA: 4:00 - loss: 3.3628 - accuracy: 0.13 - ETA: 3:59 - loss: 3.3623 - accuracy: 0.13 - ETA: 3:58 - loss: 3.3615 - accuracy: 0.13 - ETA: 3:57 - loss: 3.3605 - accuracy: 0.13 - ETA: 3:56 - loss: 3.3624 - accuracy: 0.13 - ETA: 3:55 - loss: 3.3613 - accuracy: 0.13 - ETA: 3:55 - loss: 3.3611 - accuracy: 0.13 - ETA: 3:54 - loss: 3.3605 - accuracy: 0.13 - ETA: 3:53 - loss: 3.3581 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3568 - accuracy: 0.13 - ETA: 3:51 - loss: 3.3567 - accuracy: 0.13 - ETA: 3:50 - loss: 3.3564 - accuracy: 0.13 - ETA: 3:49 - loss: 3.3558 - accuracy: 0.13 - ETA: 3:48 - loss: 3.3560 - accuracy: 0.13 - ETA: 3:47 - loss: 3.3543 - accuracy: 0.13 - ETA: 3:46 - loss: 3.3546 - accuracy: 0.13 - ETA: 3:45 - loss: 3.3542 - accuracy: 0.13 - ETA: 3:44 - loss: 3.3526 - accuracy: 0.13 - ETA: 3:43 - loss: 3.3515 - accuracy: 0.13 - ETA: 3:42 - loss: 3.3506 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3505 - accuracy: 0.13 - ETA: 3:40 - loss: 3.3492 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3485 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3490 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3503 - accuracy: 0.13 - ETA: 3:36 - loss: 3.3499 - accuracy: 0.13 - ETA: 3:35 - loss: 3.3495 - accuracy: 0.13 - ETA: 3:34 - loss: 3.3498 - accuracy: 0.13 - ETA: 3:33 - loss: 3.3508 - accuracy: 0.13 - ETA: 3:32 - loss: 3.3505 - accuracy: 0.13 - ETA: 3:31 - loss: 3.3509 - accuracy: 0.13 - ETA: 3:30 - loss: 3.3495 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3504 - accuracy: 0.13 - ETA: 3:28 - loss: 3.3499 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3488 - accuracy: 0.13 - ETA: 3:26 - loss: 3.3497 - accuracy: 0.13 - ETA: 3:25 - loss: 3.3490 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3494 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3505 - accuracy: 0.13 - ETA: 3:22 - loss: 3.3511 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3497 - accuracy: 0.13 - ETA: 3:20 - loss: 3.3504 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3499 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3495 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3505 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3497 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3497 - accuracy: 0.13 - ETA: 3:14 - loss: 3.3494 - accuracy: 0.13 - ETA: 3:13 - loss: 3.3486 - accuracy: 0.13 - ETA: 3:12 - loss: 3.3491 - accuracy: 0.13 - ETA: 3:11 - loss: 3.3496 - accuracy: 0.13 - ETA: 3:10 - loss: 3.3492 - accuracy: 0.13 - ETA: 3:09 - loss: 3.3495 - accuracy: 0.13 - ETA: 3:09 - loss: 3.3487 - accuracy: 0.13 - ETA: 3:08 - loss: 3.3482 - accuracy: 0.13 - ETA: 3:07 - loss: 3.3469 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3473 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3483 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3485 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3479 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3477 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3473 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3475 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3466 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3464 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3456 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3472 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3491 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3501 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3496 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3495 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3495 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3497 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3501 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3509 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3503 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3500 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3497 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3501 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3497 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3494 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3488 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3481 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3486 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3490 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3488 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3497 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3520 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3518 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3534 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3533 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3516 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3512 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3506 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3513 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3510 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3501 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3500 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3494 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3502 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3507 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3509 - accuracy: 0.13 - ETA: 2:21 - loss: 3.3517 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3522 - accuracy: 0.13 - ETA: 2:19 - loss: 3.3528 - accuracy: 0.1387"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.3532 - accuracy: 0.13 - ETA: 2:17 - loss: 3.3529 - accuracy: 0.13 - ETA: 2:16 - loss: 3.3528 - accuracy: 0.13 - ETA: 2:15 - loss: 3.3533 - accuracy: 0.13 - ETA: 2:14 - loss: 3.3546 - accuracy: 0.13 - ETA: 2:13 - loss: 3.3553 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3545 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3549 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3549 - accuracy: 0.13 - ETA: 2:10 - loss: 3.3546 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3552 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3542 - accuracy: 0.13 - ETA: 2:07 - loss: 3.3549 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3544 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3544 - accuracy: 0.13 - ETA: 2:04 - loss: 3.3540 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3551 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3556 - accuracy: 0.13 - ETA: 2:01 - loss: 3.3558 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3554 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3557 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3564 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3568 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3572 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3572 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3571 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3570 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3564 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3561 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3555 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3553 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3551 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3547 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3545 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3543 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3535 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3532 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3537 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3540 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3537 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3545 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3534 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3532 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3534 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3532 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3530 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3529 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3522 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3521 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3523 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3520 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3518 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3516 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3522 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3517 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3515 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3517 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3522 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3522 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3517 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3523 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3522 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3516 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3518 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3515 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3517 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3523 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3518 - accuracy: 0.13 - ETA: 1:13 - loss: 3.3529 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3528 - accuracy: 0.13 - ETA: 1:11 - loss: 3.3521 - accuracy: 0.13 - ETA: 1:10 - loss: 3.3522 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3517 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3509 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3514 - accuracy: 0.13 - ETA: 1:06 - loss: 3.3504 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3501 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3503 - accuracy: 0.13 - ETA: 1:03 - loss: 3.3504 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3500 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3498 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3489 - accuracy: 0.13 - ETA: 59s - loss: 3.3482 - accuracy: 0.1387 - ETA: 58s - loss: 3.3483 - accuracy: 0.138 - ETA: 57s - loss: 3.3481 - accuracy: 0.138 - ETA: 56s - loss: 3.3471 - accuracy: 0.138 - ETA: 55s - loss: 3.3472 - accuracy: 0.138 - ETA: 55s - loss: 3.3462 - accuracy: 0.138 - ETA: 54s - loss: 3.3460 - accuracy: 0.138 - ETA: 53s - loss: 3.3461 - accuracy: 0.138 - ETA: 52s - loss: 3.3459 - accuracy: 0.138 - ETA: 51s - loss: 3.3454 - accuracy: 0.139 - ETA: 50s - loss: 3.3448 - accuracy: 0.139 - ETA: 49s - loss: 3.3443 - accuracy: 0.139 - ETA: 48s - loss: 3.3447 - accuracy: 0.139 - ETA: 47s - loss: 3.3448 - accuracy: 0.139 - ETA: 46s - loss: 3.3446 - accuracy: 0.139 - ETA: 45s - loss: 3.3445 - accuracy: 0.139 - ETA: 44s - loss: 3.3449 - accuracy: 0.139 - ETA: 43s - loss: 3.3452 - accuracy: 0.139 - ETA: 42s - loss: 3.3445 - accuracy: 0.139 - ETA: 41s - loss: 3.3444 - accuracy: 0.139 - ETA: 40s - loss: 3.3448 - accuracy: 0.138 - ETA: 39s - loss: 3.3447 - accuracy: 0.139 - ETA: 38s - loss: 3.3450 - accuracy: 0.138 - ETA: 37s - loss: 3.3455 - accuracy: 0.138 - ETA: 36s - loss: 3.3453 - accuracy: 0.138 - ETA: 35s - loss: 3.3466 - accuracy: 0.138 - ETA: 34s - loss: 3.3463 - accuracy: 0.138 - ETA: 33s - loss: 3.3473 - accuracy: 0.138 - ETA: 32s - loss: 3.3474 - accuracy: 0.138 - ETA: 31s - loss: 3.3471 - accuracy: 0.138 - ETA: 30s - loss: 3.3465 - accuracy: 0.139 - ETA: 29s - loss: 3.3453 - accuracy: 0.139 - ETA: 28s - loss: 3.3445 - accuracy: 0.139 - ETA: 27s - loss: 3.3443 - accuracy: 0.139 - ETA: 27s - loss: 3.3441 - accuracy: 0.139 - ETA: 26s - loss: 3.3439 - accuracy: 0.139 - ETA: 25s - loss: 3.3440 - accuracy: 0.139 - ETA: 24s - loss: 3.3441 - accuracy: 0.139 - ETA: 23s - loss: 3.3437 - accuracy: 0.139 - ETA: 22s - loss: 3.3439 - accuracy: 0.139 - ETA: 21s - loss: 3.3441 - accuracy: 0.139 - ETA: 20s - loss: 3.3440 - accuracy: 0.139 - ETA: 19s - loss: 3.3438 - accuracy: 0.139 - ETA: 18s - loss: 3.3439 - accuracy: 0.139 - ETA: 17s - loss: 3.3442 - accuracy: 0.139 - ETA: 16s - loss: 3.3447 - accuracy: 0.139 - ETA: 15s - loss: 3.3441 - accuracy: 0.139 - ETA: 14s - loss: 3.3443 - accuracy: 0.139 - ETA: 13s - loss: 3.3448 - accuracy: 0.139 - ETA: 12s - loss: 3.3451 - accuracy: 0.139 - ETA: 11s - loss: 3.3453 - accuracy: 0.138 - ETA: 10s - loss: 3.3456 - accuracy: 0.139 - ETA: 9s - loss: 3.3457 - accuracy: 0.138 - ETA: 8s - loss: 3.3453 - accuracy: 0.13 - ETA: 7s - loss: 3.3459 - accuracy: 0.13 - ETA: 6s - loss: 3.3461 - accuracy: 0.13 - ETA: 5s - loss: 3.3462 - accuracy: 0.13 - ETA: 4s - loss: 3.3463 - accuracy: 0.13 - ETA: 3s - loss: 3.3459 - accuracy: 0.13 - ETA: 2s - loss: 3.3458 - accuracy: 0.13 - ETA: 1s - loss: 3.3457 - accuracy: 0.13 - ETA: 1s - loss: 3.3456 - accuracy: 0.13 - ETA: 0s - loss: 3.3456 - accuracy: 0.13 - 343s 8ms/step - loss: 3.3457 - accuracy: 0.1389 - val_loss: 3.9068 - val_accuracy: 0.0231\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:45 - loss: 3.1384 - accuracy: 0.19 - ETA: 5:48 - loss: 3.2497 - accuracy: 0.17 - ETA: 5:35 - loss: 3.3530 - accuracy: 0.15 - ETA: 5:32 - loss: 3.3364 - accuracy: 0.14 - ETA: 5:24 - loss: 3.3468 - accuracy: 0.14 - ETA: 5:18 - loss: 3.3614 - accuracy: 0.14 - ETA: 5:14 - loss: 3.3590 - accuracy: 0.14 - ETA: 5:13 - loss: 3.3396 - accuracy: 0.14 - ETA: 5:12 - loss: 3.3441 - accuracy: 0.14 - ETA: 5:14 - loss: 3.3464 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3483 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3520 - accuracy: 0.14 - ETA: 5:09 - loss: 3.3544 - accuracy: 0.14 - ETA: 5:07 - loss: 3.3445 - accuracy: 0.14 - ETA: 5:05 - loss: 3.3379 - accuracy: 0.14 - ETA: 5:05 - loss: 3.3329 - accuracy: 0.14 - ETA: 5:05 - loss: 3.3257 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3319 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3395 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3383 - accuracy: 0.14 - ETA: 4:58 - loss: 3.3383 - accuracy: 0.14 - ETA: 4:56 - loss: 3.3320 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3254 - accuracy: 0.14 - ETA: 4:52 - loss: 3.3208 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3243 - accuracy: 0.14 - ETA: 4:50 - loss: 3.3268 - accuracy: 0.14 - ETA: 4:49 - loss: 3.3322 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3308 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3290 - accuracy: 0.14 - ETA: 4:46 - loss: 3.3307 - accuracy: 0.14 - ETA: 4:46 - loss: 3.3268 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3270 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3294 - accuracy: 0.14 - ETA: 4:43 - loss: 3.3270 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3278 - accuracy: 0.14 - ETA: 4:41 - loss: 3.3303 - accuracy: 0.14 - ETA: 4:40 - loss: 3.3218 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3273 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3305 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3283 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3289 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3265 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3279 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3329 - accuracy: 0.14 - ETA: 4:33 - loss: 3.3338 - accuracy: 0.14 - ETA: 4:32 - loss: 3.3321 - accuracy: 0.14 - ETA: 4:32 - loss: 3.3340 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3323 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3322 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3317 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3296 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3291 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3305 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3305 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3310 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3294 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3317 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3316 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3309 - accuracy: 0.13 - ETA: 4:19 - loss: 3.3310 - accuracy: 0.13 - ETA: 4:19 - loss: 3.3291 - accuracy: 0.13 - ETA: 4:18 - loss: 3.3270 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3228 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3222 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3213 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3218 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3181 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3159 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3160 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3166 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3162 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3136 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3123 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3146 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3150 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3146 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3152 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3137 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3161 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3173 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3171 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3165 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3179 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3181 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3170 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3157 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3146 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3139 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3119 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3122 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3119 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3130 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3111 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3102 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3095 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3098 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3121 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3102 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3090 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3074 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3094 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3086 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3079 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3067 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3067 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3068 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3077 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3068 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3087 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3100 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3097 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3108 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3107 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3109 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3119 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3136 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3131 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3148 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3126 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3125 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3122 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3144 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3148 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3162 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3155 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3159 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3178 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3186 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3199 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3202 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3197 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3185 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3182 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3182 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3184 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3170 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3163 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3169 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3179 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3171 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3167 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3166 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3157 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3159 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3163 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3167 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3177 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3183 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3176 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3168 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3165 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3161 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3163 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3163 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3164 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3167 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3166 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3164 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3162 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3156 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3149 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3147 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3139 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3138 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3127 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3130 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3115 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3103 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3115 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3121 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3119 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3115 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3098 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3096 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3100 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3113 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3115 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3109 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3113 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3119 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3102 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3105 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3111 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3106 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3099 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3105 - accuracy: 0.1444"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.3119 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3124 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3122 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3115 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3121 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3126 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3129 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3137 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3143 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3150 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3153 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3160 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3161 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3163 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3167 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3169 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3172 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3181 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3181 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3177 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3178 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3172 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3176 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3167 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3177 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3172 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3172 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3180 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3177 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3178 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3183 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3186 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3193 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3202 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3209 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3216 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3215 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3218 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3226 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3225 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3231 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3234 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3239 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3239 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3241 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3247 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3249 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3243 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3238 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3240 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3232 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3228 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3226 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3228 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3226 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3227 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3233 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3229 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3230 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3230 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3235 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3236 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3231 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3230 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3222 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3229 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3232 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3228 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3233 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3229 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3235 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3236 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3229 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3230 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3222 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3217 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3215 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3217 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3217 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3215 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3217 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3216 - accuracy: 0.14 - ETA: 59s - loss: 3.3213 - accuracy: 0.1441 - ETA: 58s - loss: 3.3213 - accuracy: 0.144 - ETA: 57s - loss: 3.3217 - accuracy: 0.144 - ETA: 56s - loss: 3.3222 - accuracy: 0.144 - ETA: 55s - loss: 3.3225 - accuracy: 0.143 - ETA: 54s - loss: 3.3222 - accuracy: 0.144 - ETA: 53s - loss: 3.3220 - accuracy: 0.144 - ETA: 52s - loss: 3.3224 - accuracy: 0.144 - ETA: 51s - loss: 3.3232 - accuracy: 0.144 - ETA: 50s - loss: 3.3233 - accuracy: 0.144 - ETA: 49s - loss: 3.3234 - accuracy: 0.144 - ETA: 48s - loss: 3.3236 - accuracy: 0.144 - ETA: 47s - loss: 3.3239 - accuracy: 0.144 - ETA: 46s - loss: 3.3239 - accuracy: 0.143 - ETA: 45s - loss: 3.3234 - accuracy: 0.144 - ETA: 45s - loss: 3.3228 - accuracy: 0.144 - ETA: 44s - loss: 3.3225 - accuracy: 0.144 - ETA: 43s - loss: 3.3226 - accuracy: 0.144 - ETA: 42s - loss: 3.3220 - accuracy: 0.144 - ETA: 41s - loss: 3.3215 - accuracy: 0.144 - ETA: 40s - loss: 3.3214 - accuracy: 0.144 - ETA: 39s - loss: 3.3215 - accuracy: 0.144 - ETA: 38s - loss: 3.3215 - accuracy: 0.144 - ETA: 37s - loss: 3.3212 - accuracy: 0.144 - ETA: 36s - loss: 3.3223 - accuracy: 0.144 - ETA: 35s - loss: 3.3229 - accuracy: 0.144 - ETA: 34s - loss: 3.3231 - accuracy: 0.144 - ETA: 33s - loss: 3.3234 - accuracy: 0.144 - ETA: 32s - loss: 3.3232 - accuracy: 0.144 - ETA: 31s - loss: 3.3229 - accuracy: 0.144 - ETA: 30s - loss: 3.3230 - accuracy: 0.144 - ETA: 29s - loss: 3.3232 - accuracy: 0.144 - ETA: 28s - loss: 3.3232 - accuracy: 0.144 - ETA: 27s - loss: 3.3227 - accuracy: 0.144 - ETA: 26s - loss: 3.3223 - accuracy: 0.144 - ETA: 25s - loss: 3.3226 - accuracy: 0.144 - ETA: 24s - loss: 3.3220 - accuracy: 0.145 - ETA: 24s - loss: 3.3224 - accuracy: 0.145 - ETA: 23s - loss: 3.3226 - accuracy: 0.145 - ETA: 22s - loss: 3.3223 - accuracy: 0.145 - ETA: 21s - loss: 3.3221 - accuracy: 0.145 - ETA: 20s - loss: 3.3223 - accuracy: 0.144 - ETA: 19s - loss: 3.3222 - accuracy: 0.145 - ETA: 18s - loss: 3.3223 - accuracy: 0.145 - ETA: 17s - loss: 3.3220 - accuracy: 0.145 - ETA: 16s - loss: 3.3225 - accuracy: 0.144 - ETA: 15s - loss: 3.3221 - accuracy: 0.145 - ETA: 14s - loss: 3.3226 - accuracy: 0.144 - ETA: 13s - loss: 3.3227 - accuracy: 0.144 - ETA: 12s - loss: 3.3243 - accuracy: 0.144 - ETA: 11s - loss: 3.3235 - accuracy: 0.145 - ETA: 10s - loss: 3.3238 - accuracy: 0.145 - ETA: 9s - loss: 3.3232 - accuracy: 0.145 - ETA: 8s - loss: 3.3232 - accuracy: 0.14 - ETA: 7s - loss: 3.3235 - accuracy: 0.14 - ETA: 6s - loss: 3.3232 - accuracy: 0.14 - ETA: 5s - loss: 3.3230 - accuracy: 0.14 - ETA: 4s - loss: 3.3226 - accuracy: 0.14 - ETA: 3s - loss: 3.3226 - accuracy: 0.14 - ETA: 2s - loss: 3.3226 - accuracy: 0.14 - ETA: 1s - loss: 3.3221 - accuracy: 0.14 - ETA: 1s - loss: 3.3225 - accuracy: 0.14 - ETA: 0s - loss: 3.3224 - accuracy: 0.14 - 341s 8ms/step - loss: 3.3225 - accuracy: 0.1455 - val_loss: 3.9034 - val_accuracy: 0.0225\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:51 - loss: 3.3097 - accuracy: 0.11 - ETA: 5:07 - loss: 3.3252 - accuracy: 0.12 - ETA: 5:07 - loss: 3.2769 - accuracy: 0.14 - ETA: 5:01 - loss: 3.3250 - accuracy: 0.13 - ETA: 5:03 - loss: 3.3047 - accuracy: 0.14 - ETA: 5:01 - loss: 3.3179 - accuracy: 0.14 - ETA: 5:01 - loss: 3.3051 - accuracy: 0.14 - ETA: 5:05 - loss: 3.2863 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2725 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2559 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2828 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2684 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2821 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2810 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2791 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2913 - accuracy: 0.14 - ETA: 4:55 - loss: 3.2829 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2865 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2921 - accuracy: 0.14 - ETA: 4:52 - loss: 3.3009 - accuracy: 0.14 - ETA: 4:51 - loss: 3.2966 - accuracy: 0.14 - ETA: 4:50 - loss: 3.2936 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2988 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2991 - accuracy: 0.15 - ETA: 4:46 - loss: 3.3041 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3029 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3089 - accuracy: 0.14 - ETA: 4:46 - loss: 3.3159 - accuracy: 0.14 - ETA: 4:46 - loss: 3.3133 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3181 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3174 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3189 - accuracy: 0.14 - ETA: 4:43 - loss: 3.3142 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3113 - accuracy: 0.14 - ETA: 4:40 - loss: 3.3091 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3017 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3036 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3223 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3200 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3172 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3168 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3148 - accuracy: 0.14 - ETA: 4:33 - loss: 3.3131 - accuracy: 0.14 - ETA: 4:32 - loss: 3.3131 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3135 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3127 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3122 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3172 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3148 - accuracy: 0.14 - ETA: 4:27 - loss: 3.3166 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3171 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3186 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3206 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3225 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3212 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3220 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3231 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3241 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3268 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3274 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3264 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3252 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3249 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3260 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3297 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3293 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3284 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3252 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3245 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3228 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3187 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3191 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3208 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3205 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3215 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3236 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3228 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3230 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3231 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3247 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3255 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3258 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3283 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3288 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3309 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3312 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3346 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3352 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3356 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3377 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3386 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3386 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3373 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3377 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3373 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3362 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3372 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3360 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3360 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3363 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3356 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3334 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3339 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3326 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3322 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3325 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3331 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3307 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3317 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3300 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3309 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3311 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3316 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3317 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3319 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3326 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3333 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3336 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3345 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3346 - accuracy: 0.13 - ETA: 3:20 - loss: 3.3345 - accuracy: 0.13 - ETA: 3:19 - loss: 3.3351 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3340 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3356 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3364 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3349 - accuracy: 0.13 - ETA: 3:14 - loss: 3.3348 - accuracy: 0.13 - ETA: 3:13 - loss: 3.3350 - accuracy: 0.13 - ETA: 3:12 - loss: 3.3362 - accuracy: 0.13 - ETA: 3:11 - loss: 3.3352 - accuracy: 0.13 - ETA: 3:10 - loss: 3.3345 - accuracy: 0.13 - ETA: 3:09 - loss: 3.3321 - accuracy: 0.13 - ETA: 3:08 - loss: 3.3329 - accuracy: 0.13 - ETA: 3:07 - loss: 3.3329 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3320 - accuracy: 0.13 - ETA: 3:05 - loss: 3.3311 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3314 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3315 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3328 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3336 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3342 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3355 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3361 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3360 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3355 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3341 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3334 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3321 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3312 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3306 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3306 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3298 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3299 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3300 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3300 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3303 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3304 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3300 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3303 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3300 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3309 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3315 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3309 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3302 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3305 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3313 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3314 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3325 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3322 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3322 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3325 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3320 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3316 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3317 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3322 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3328 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3329 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3327 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3325 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3323 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3320 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3314 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3309 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3294 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3294 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3298 - accuracy: 0.1403"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3296 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3301 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3302 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3306 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3307 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3304 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3303 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3306 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3306 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3304 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3307 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3302 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3295 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3292 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3296 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3295 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3292 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3285 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3281 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3276 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3269 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3267 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3259 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3258 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3246 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3242 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3241 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3241 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3232 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3232 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3228 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3227 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3225 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3222 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3210 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3198 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3192 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3195 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3181 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3173 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3172 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3167 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3179 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3171 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3171 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3163 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3165 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3168 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3175 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3165 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3162 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3160 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3156 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3150 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3148 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3145 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3142 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3142 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3137 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3137 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3137 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3136 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3138 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3140 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3141 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3138 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3139 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3132 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3133 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3136 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3130 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3126 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3122 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3126 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3123 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3114 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3115 - accuracy: 0.14 - ETA: 59s - loss: 3.3111 - accuracy: 0.1440 - ETA: 58s - loss: 3.3119 - accuracy: 0.144 - ETA: 57s - loss: 3.3118 - accuracy: 0.143 - ETA: 56s - loss: 3.3117 - accuracy: 0.144 - ETA: 55s - loss: 3.3114 - accuracy: 0.144 - ETA: 54s - loss: 3.3105 - accuracy: 0.144 - ETA: 53s - loss: 3.3102 - accuracy: 0.144 - ETA: 52s - loss: 3.3106 - accuracy: 0.144 - ETA: 51s - loss: 3.3102 - accuracy: 0.144 - ETA: 50s - loss: 3.3103 - accuracy: 0.144 - ETA: 49s - loss: 3.3108 - accuracy: 0.144 - ETA: 48s - loss: 3.3105 - accuracy: 0.144 - ETA: 47s - loss: 3.3104 - accuracy: 0.144 - ETA: 46s - loss: 3.3107 - accuracy: 0.144 - ETA: 45s - loss: 3.3108 - accuracy: 0.144 - ETA: 45s - loss: 3.3107 - accuracy: 0.144 - ETA: 44s - loss: 3.3109 - accuracy: 0.144 - ETA: 43s - loss: 3.3114 - accuracy: 0.143 - ETA: 42s - loss: 3.3113 - accuracy: 0.144 - ETA: 41s - loss: 3.3114 - accuracy: 0.144 - ETA: 40s - loss: 3.3109 - accuracy: 0.144 - ETA: 39s - loss: 3.3109 - accuracy: 0.144 - ETA: 38s - loss: 3.3113 - accuracy: 0.144 - ETA: 37s - loss: 3.3112 - accuracy: 0.144 - ETA: 36s - loss: 3.3106 - accuracy: 0.144 - ETA: 35s - loss: 3.3107 - accuracy: 0.144 - ETA: 34s - loss: 3.3112 - accuracy: 0.144 - ETA: 33s - loss: 3.3105 - accuracy: 0.144 - ETA: 32s - loss: 3.3100 - accuracy: 0.144 - ETA: 31s - loss: 3.3098 - accuracy: 0.145 - ETA: 30s - loss: 3.3098 - accuracy: 0.145 - ETA: 29s - loss: 3.3086 - accuracy: 0.145 - ETA: 28s - loss: 3.3089 - accuracy: 0.145 - ETA: 27s - loss: 3.3092 - accuracy: 0.145 - ETA: 26s - loss: 3.3087 - accuracy: 0.145 - ETA: 25s - loss: 3.3089 - accuracy: 0.145 - ETA: 24s - loss: 3.3093 - accuracy: 0.145 - ETA: 23s - loss: 3.3094 - accuracy: 0.145 - ETA: 23s - loss: 3.3087 - accuracy: 0.145 - ETA: 22s - loss: 3.3082 - accuracy: 0.145 - ETA: 21s - loss: 3.3079 - accuracy: 0.145 - ETA: 20s - loss: 3.3078 - accuracy: 0.145 - ETA: 19s - loss: 3.3082 - accuracy: 0.145 - ETA: 18s - loss: 3.3085 - accuracy: 0.145 - ETA: 17s - loss: 3.3082 - accuracy: 0.145 - ETA: 16s - loss: 3.3078 - accuracy: 0.145 - ETA: 15s - loss: 3.3069 - accuracy: 0.146 - ETA: 14s - loss: 3.3056 - accuracy: 0.146 - ETA: 13s - loss: 3.3055 - accuracy: 0.146 - ETA: 12s - loss: 3.3049 - accuracy: 0.146 - ETA: 11s - loss: 3.3048 - accuracy: 0.146 - ETA: 10s - loss: 3.3045 - accuracy: 0.146 - ETA: 9s - loss: 3.3042 - accuracy: 0.146 - ETA: 8s - loss: 3.3041 - accuracy: 0.14 - ETA: 7s - loss: 3.3041 - accuracy: 0.14 - ETA: 6s - loss: 3.3038 - accuracy: 0.14 - ETA: 5s - loss: 3.3042 - accuracy: 0.14 - ETA: 4s - loss: 3.3038 - accuracy: 0.14 - ETA: 3s - loss: 3.3038 - accuracy: 0.14 - ETA: 2s - loss: 3.3040 - accuracy: 0.14 - ETA: 1s - loss: 3.3038 - accuracy: 0.14 - ETA: 1s - loss: 3.3034 - accuracy: 0.14 - ETA: 0s - loss: 3.3034 - accuracy: 0.14 - 341s 8ms/step - loss: 3.3033 - accuracy: 0.1467 - val_loss: 3.8832 - val_accuracy: 0.0241\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:21 - loss: 3.4014 - accuracy: 0.08 - ETA: 5:21 - loss: 3.3313 - accuracy: 0.12 - ETA: 5:17 - loss: 3.3461 - accuracy: 0.12 - ETA: 5:13 - loss: 3.3477 - accuracy: 0.11 - ETA: 5:15 - loss: 3.3293 - accuracy: 0.12 - ETA: 5:12 - loss: 3.3227 - accuracy: 0.13 - ETA: 5:14 - loss: 3.2881 - accuracy: 0.14 - ETA: 5:10 - loss: 3.3066 - accuracy: 0.13 - ETA: 5:11 - loss: 3.3172 - accuracy: 0.13 - ETA: 5:10 - loss: 3.3070 - accuracy: 0.13 - ETA: 5:07 - loss: 3.3245 - accuracy: 0.13 - ETA: 5:07 - loss: 3.3355 - accuracy: 0.13 - ETA: 5:05 - loss: 3.3343 - accuracy: 0.13 - ETA: 5:05 - loss: 3.3424 - accuracy: 0.13 - ETA: 5:05 - loss: 3.3455 - accuracy: 0.13 - ETA: 5:02 - loss: 3.3422 - accuracy: 0.13 - ETA: 5:03 - loss: 3.3478 - accuracy: 0.13 - ETA: 5:02 - loss: 3.3482 - accuracy: 0.13 - ETA: 5:01 - loss: 3.3420 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3375 - accuracy: 0.13 - ETA: 4:57 - loss: 3.3344 - accuracy: 0.13 - ETA: 4:56 - loss: 3.3301 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3289 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3269 - accuracy: 0.14 - ETA: 4:53 - loss: 3.3277 - accuracy: 0.14 - ETA: 4:53 - loss: 3.3236 - accuracy: 0.14 - ETA: 4:52 - loss: 3.3188 - accuracy: 0.14 - ETA: 4:50 - loss: 3.3224 - accuracy: 0.14 - ETA: 4:49 - loss: 3.3212 - accuracy: 0.14 - ETA: 4:48 - loss: 3.3211 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3199 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3238 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3248 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3284 - accuracy: 0.14 - ETA: 4:43 - loss: 3.3313 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3338 - accuracy: 0.13 - ETA: 4:42 - loss: 3.3299 - accuracy: 0.14 - ETA: 4:41 - loss: 3.3283 - accuracy: 0.14 - ETA: 4:41 - loss: 3.3290 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3289 - accuracy: 0.13 - ETA: 4:38 - loss: 3.3278 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3283 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3268 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3231 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3256 - accuracy: 0.14 - ETA: 4:33 - loss: 3.3280 - accuracy: 0.14 - ETA: 4:32 - loss: 3.3252 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3258 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3236 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3229 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3247 - accuracy: 0.14 - ETA: 4:27 - loss: 3.3264 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3269 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3282 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3263 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3240 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3206 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3218 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3224 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3184 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3185 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3217 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3218 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3209 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3219 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3225 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3237 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3252 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3244 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3241 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3259 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3250 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3242 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3241 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3250 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3258 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3259 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3277 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3272 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3262 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3265 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3240 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3253 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3262 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3237 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3235 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3226 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3215 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3219 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3201 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3175 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3163 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3167 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3159 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3164 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3158 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3176 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3178 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3165 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3153 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3166 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3180 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3172 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3180 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3171 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3161 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3146 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3128 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3122 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3115 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3094 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3089 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3075 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3082 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3084 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3081 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3085 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3083 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3076 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3085 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3082 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3071 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3084 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3107 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3099 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3110 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3115 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3110 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3142 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3148 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3154 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3155 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3149 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3144 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3124 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3131 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3132 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3132 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3150 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3158 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3154 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3166 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3162 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3156 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3153 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3155 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3160 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3160 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3159 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3163 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3162 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3164 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3155 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3149 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3142 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3138 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3136 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3141 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3155 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3166 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3157 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3162 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3167 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3171 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3177 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3183 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3178 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3176 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3188 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3193 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3192 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3189 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3191 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3201 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3206 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3206 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3211 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3205 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3204 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3206 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3202 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3202 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3203 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3199 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3191 - accuracy: 0.1465"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.3183 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3181 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3184 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3193 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3198 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3189 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3185 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3189 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3184 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3194 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3187 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3182 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3190 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3198 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3193 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3204 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3195 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3196 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3191 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3179 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3186 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3190 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3184 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3186 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3182 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3179 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3175 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3162 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3160 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3159 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3160 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3160 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3153 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3144 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3148 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3152 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3149 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3149 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3156 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3150 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3152 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3148 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3153 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3150 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3156 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3136 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3137 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3138 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3130 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3129 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3126 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3125 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3122 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3125 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3130 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3120 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3117 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3117 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3118 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3116 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3117 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3115 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3114 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3118 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3120 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3115 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3122 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3121 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3120 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3123 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3118 - accuracy: 0.14 - ETA: 59s - loss: 3.3113 - accuracy: 0.1466 - ETA: 58s - loss: 3.3116 - accuracy: 0.146 - ETA: 57s - loss: 3.3124 - accuracy: 0.146 - ETA: 56s - loss: 3.3127 - accuracy: 0.146 - ETA: 55s - loss: 3.3121 - accuracy: 0.146 - ETA: 54s - loss: 3.3121 - accuracy: 0.146 - ETA: 53s - loss: 3.3115 - accuracy: 0.146 - ETA: 52s - loss: 3.3113 - accuracy: 0.146 - ETA: 51s - loss: 3.3111 - accuracy: 0.146 - ETA: 50s - loss: 3.3114 - accuracy: 0.146 - ETA: 50s - loss: 3.3119 - accuracy: 0.146 - ETA: 49s - loss: 3.3120 - accuracy: 0.146 - ETA: 48s - loss: 3.3117 - accuracy: 0.146 - ETA: 47s - loss: 3.3112 - accuracy: 0.146 - ETA: 46s - loss: 3.3111 - accuracy: 0.146 - ETA: 45s - loss: 3.3110 - accuracy: 0.146 - ETA: 44s - loss: 3.3109 - accuracy: 0.147 - ETA: 43s - loss: 3.3114 - accuracy: 0.146 - ETA: 42s - loss: 3.3116 - accuracy: 0.146 - ETA: 41s - loss: 3.3118 - accuracy: 0.146 - ETA: 40s - loss: 3.3116 - accuracy: 0.146 - ETA: 39s - loss: 3.3115 - accuracy: 0.146 - ETA: 38s - loss: 3.3117 - accuracy: 0.146 - ETA: 37s - loss: 3.3119 - accuracy: 0.146 - ETA: 36s - loss: 3.3117 - accuracy: 0.146 - ETA: 35s - loss: 3.3124 - accuracy: 0.146 - ETA: 34s - loss: 3.3129 - accuracy: 0.146 - ETA: 33s - loss: 3.3129 - accuracy: 0.146 - ETA: 32s - loss: 3.3127 - accuracy: 0.146 - ETA: 31s - loss: 3.3128 - accuracy: 0.146 - ETA: 30s - loss: 3.3131 - accuracy: 0.146 - ETA: 29s - loss: 3.3134 - accuracy: 0.146 - ETA: 28s - loss: 3.3139 - accuracy: 0.146 - ETA: 27s - loss: 3.3136 - accuracy: 0.146 - ETA: 26s - loss: 3.3137 - accuracy: 0.145 - ETA: 26s - loss: 3.3137 - accuracy: 0.145 - ETA: 25s - loss: 3.3138 - accuracy: 0.145 - ETA: 24s - loss: 3.3142 - accuracy: 0.145 - ETA: 23s - loss: 3.3144 - accuracy: 0.145 - ETA: 22s - loss: 3.3143 - accuracy: 0.145 - ETA: 21s - loss: 3.3140 - accuracy: 0.145 - ETA: 20s - loss: 3.3137 - accuracy: 0.145 - ETA: 19s - loss: 3.3136 - accuracy: 0.145 - ETA: 18s - loss: 3.3135 - accuracy: 0.145 - ETA: 17s - loss: 3.3131 - accuracy: 0.145 - ETA: 16s - loss: 3.3136 - accuracy: 0.145 - ETA: 15s - loss: 3.3136 - accuracy: 0.145 - ETA: 14s - loss: 3.3144 - accuracy: 0.145 - ETA: 13s - loss: 3.3147 - accuracy: 0.145 - ETA: 12s - loss: 3.3140 - accuracy: 0.145 - ETA: 11s - loss: 3.3142 - accuracy: 0.145 - ETA: 10s - loss: 3.3142 - accuracy: 0.145 - ETA: 9s - loss: 3.3143 - accuracy: 0.145 - ETA: 8s - loss: 3.3142 - accuracy: 0.14 - ETA: 7s - loss: 3.3143 - accuracy: 0.14 - ETA: 6s - loss: 3.3143 - accuracy: 0.14 - ETA: 5s - loss: 3.3140 - accuracy: 0.14 - ETA: 4s - loss: 3.3140 - accuracy: 0.14 - ETA: 3s - loss: 3.3133 - accuracy: 0.14 - ETA: 2s - loss: 3.3130 - accuracy: 0.14 - ETA: 1s - loss: 3.3135 - accuracy: 0.14 - ETA: 1s - loss: 3.3134 - accuracy: 0.14 - ETA: 0s - loss: 3.3134 - accuracy: 0.14 - 342s 8ms/step - loss: 3.3133 - accuracy: 0.1456 - val_loss: 3.9156 - val_accuracy: 0.0253\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:57 - loss: 3.3215 - accuracy: 0.17 - ETA: 5:17 - loss: 3.3282 - accuracy: 0.16 - ETA: 5:23 - loss: 3.3085 - accuracy: 0.16 - ETA: 5:16 - loss: 3.3294 - accuracy: 0.15 - ETA: 5:15 - loss: 3.3226 - accuracy: 0.15 - ETA: 5:10 - loss: 3.3305 - accuracy: 0.14 - ETA: 5:09 - loss: 3.3167 - accuracy: 0.14 - ETA: 5:10 - loss: 3.3053 - accuracy: 0.15 - ETA: 5:09 - loss: 3.2954 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2827 - accuracy: 0.15 - ETA: 5:08 - loss: 3.2774 - accuracy: 0.15 - ETA: 5:09 - loss: 3.2828 - accuracy: 0.15 - ETA: 5:08 - loss: 3.2927 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2892 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2869 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2722 - accuracy: 0.15 - ETA: 5:04 - loss: 3.2745 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2854 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2801 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2801 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2733 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2687 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2686 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2694 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2755 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2849 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2890 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2857 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2819 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2818 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2778 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2729 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2714 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2709 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2711 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2694 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2723 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2746 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2793 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2748 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2748 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2738 - accuracy: 0.15 - ETA: 4:37 - loss: 3.2733 - accuracy: 0.15 - ETA: 4:36 - loss: 3.2748 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2779 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2819 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2862 - accuracy: 0.14 - ETA: 4:33 - loss: 3.2880 - accuracy: 0.14 - ETA: 4:33 - loss: 3.2872 - accuracy: 0.14 - ETA: 4:32 - loss: 3.2918 - accuracy: 0.14 - ETA: 4:31 - loss: 3.2948 - accuracy: 0.14 - ETA: 4:30 - loss: 3.2935 - accuracy: 0.14 - ETA: 4:29 - loss: 3.2942 - accuracy: 0.14 - ETA: 4:28 - loss: 3.2938 - accuracy: 0.14 - ETA: 4:27 - loss: 3.2925 - accuracy: 0.14 - ETA: 4:25 - loss: 3.2931 - accuracy: 0.14 - ETA: 4:24 - loss: 3.2917 - accuracy: 0.14 - ETA: 4:23 - loss: 3.2918 - accuracy: 0.14 - ETA: 4:22 - loss: 3.2948 - accuracy: 0.14 - ETA: 4:21 - loss: 3.2943 - accuracy: 0.14 - ETA: 4:20 - loss: 3.2911 - accuracy: 0.14 - ETA: 4:19 - loss: 3.2906 - accuracy: 0.14 - ETA: 4:18 - loss: 3.2878 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2892 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2917 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2945 - accuracy: 0.15 - ETA: 4:14 - loss: 3.2954 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2927 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2940 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2954 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2948 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2955 - accuracy: 0.15 - ETA: 4:09 - loss: 3.2960 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2968 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2970 - accuracy: 0.14 - ETA: 4:06 - loss: 3.2975 - accuracy: 0.14 - ETA: 4:05 - loss: 3.2984 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2998 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3012 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3015 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3041 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3040 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3027 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3009 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3027 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3024 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3024 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3015 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3011 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3023 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3040 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3045 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3075 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3077 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3081 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3104 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3117 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3132 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3133 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3125 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3134 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3129 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3127 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3130 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3125 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3144 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3145 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3147 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3162 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3177 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3187 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3191 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3195 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3191 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3197 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3175 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3171 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3178 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3174 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3191 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3197 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3198 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3191 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3209 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3209 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3215 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3209 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3215 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3215 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3222 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3220 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3226 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3223 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3218 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3217 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3221 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3209 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3208 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3207 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3208 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3200 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3203 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3185 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3179 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3180 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3169 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3174 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3164 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3169 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3172 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3175 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3176 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3173 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3171 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3177 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3182 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3180 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3194 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3181 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3191 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3194 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3198 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3209 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3218 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3226 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3241 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3245 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3256 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3254 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3256 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3251 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3249 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3241 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3240 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3246 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3246 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3248 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3251 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3254 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3260 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3262 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3262 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3260 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3255 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3255 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3255 - accuracy: 0.1442"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.3261 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3260 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3266 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3258 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3257 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3253 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3251 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3261 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3251 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3250 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3240 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3241 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3232 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3225 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3228 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3221 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3217 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3224 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3220 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3219 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3217 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3211 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3212 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3204 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3211 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3212 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3210 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3207 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3202 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3207 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3194 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3200 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3209 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3209 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3211 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3216 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3218 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3214 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3216 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3216 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3212 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3207 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3206 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3210 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3214 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3202 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3194 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3194 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3191 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3185 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3185 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3191 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3190 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3185 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3183 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3183 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3176 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3175 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3173 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3167 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3168 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3166 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3168 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3166 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3172 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3166 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3164 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3164 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3166 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3154 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3146 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3141 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3141 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3143 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3144 - accuracy: 0.14 - ETA: 59s - loss: 3.3149 - accuracy: 0.1445 - ETA: 58s - loss: 3.3153 - accuracy: 0.144 - ETA: 57s - loss: 3.3155 - accuracy: 0.144 - ETA: 56s - loss: 3.3151 - accuracy: 0.144 - ETA: 55s - loss: 3.3146 - accuracy: 0.144 - ETA: 54s - loss: 3.3148 - accuracy: 0.144 - ETA: 53s - loss: 3.3150 - accuracy: 0.144 - ETA: 52s - loss: 3.3152 - accuracy: 0.144 - ETA: 51s - loss: 3.3145 - accuracy: 0.144 - ETA: 51s - loss: 3.3149 - accuracy: 0.144 - ETA: 50s - loss: 3.3151 - accuracy: 0.144 - ETA: 49s - loss: 3.3146 - accuracy: 0.144 - ETA: 47s - loss: 3.3152 - accuracy: 0.144 - ETA: 46s - loss: 3.3154 - accuracy: 0.144 - ETA: 45s - loss: 3.3157 - accuracy: 0.144 - ETA: 44s - loss: 3.3161 - accuracy: 0.144 - ETA: 43s - loss: 3.3154 - accuracy: 0.144 - ETA: 42s - loss: 3.3154 - accuracy: 0.144 - ETA: 41s - loss: 3.3155 - accuracy: 0.144 - ETA: 41s - loss: 3.3154 - accuracy: 0.144 - ETA: 40s - loss: 3.3152 - accuracy: 0.144 - ETA: 39s - loss: 3.3151 - accuracy: 0.144 - ETA: 38s - loss: 3.3147 - accuracy: 0.144 - ETA: 37s - loss: 3.3143 - accuracy: 0.144 - ETA: 36s - loss: 3.3148 - accuracy: 0.144 - ETA: 35s - loss: 3.3150 - accuracy: 0.144 - ETA: 34s - loss: 3.3151 - accuracy: 0.144 - ETA: 33s - loss: 3.3149 - accuracy: 0.144 - ETA: 32s - loss: 3.3148 - accuracy: 0.144 - ETA: 31s - loss: 3.3150 - accuracy: 0.144 - ETA: 30s - loss: 3.3145 - accuracy: 0.144 - ETA: 29s - loss: 3.3143 - accuracy: 0.144 - ETA: 28s - loss: 3.3136 - accuracy: 0.144 - ETA: 27s - loss: 3.3136 - accuracy: 0.144 - ETA: 26s - loss: 3.3140 - accuracy: 0.144 - ETA: 25s - loss: 3.3138 - accuracy: 0.144 - ETA: 24s - loss: 3.3136 - accuracy: 0.144 - ETA: 23s - loss: 3.3138 - accuracy: 0.144 - ETA: 22s - loss: 3.3140 - accuracy: 0.144 - ETA: 21s - loss: 3.3135 - accuracy: 0.144 - ETA: 21s - loss: 3.3134 - accuracy: 0.144 - ETA: 20s - loss: 3.3137 - accuracy: 0.144 - ETA: 19s - loss: 3.3139 - accuracy: 0.144 - ETA: 18s - loss: 3.3143 - accuracy: 0.144 - ETA: 17s - loss: 3.3142 - accuracy: 0.144 - ETA: 16s - loss: 3.3141 - accuracy: 0.144 - ETA: 15s - loss: 3.3138 - accuracy: 0.144 - ETA: 14s - loss: 3.3136 - accuracy: 0.144 - ETA: 13s - loss: 3.3136 - accuracy: 0.144 - ETA: 12s - loss: 3.3131 - accuracy: 0.144 - ETA: 11s - loss: 3.3128 - accuracy: 0.144 - ETA: 10s - loss: 3.3131 - accuracy: 0.144 - ETA: 9s - loss: 3.3133 - accuracy: 0.144 - ETA: 8s - loss: 3.3132 - accuracy: 0.14 - ETA: 7s - loss: 3.3137 - accuracy: 0.14 - ETA: 6s - loss: 3.3135 - accuracy: 0.14 - ETA: 5s - loss: 3.3132 - accuracy: 0.14 - ETA: 4s - loss: 3.3128 - accuracy: 0.14 - ETA: 3s - loss: 3.3130 - accuracy: 0.14 - ETA: 2s - loss: 3.3126 - accuracy: 0.14 - ETA: 1s - loss: 3.3126 - accuracy: 0.14 - ETA: 1s - loss: 3.3127 - accuracy: 0.14 - ETA: 0s - loss: 3.3130 - accuracy: 0.14 - 341s 8ms/step - loss: 3.3131 - accuracy: 0.1447 - val_loss: 3.9516 - val_accuracy: 0.0294\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:17 - loss: 3.3486 - accuracy: 0.12 - ETA: 5:07 - loss: 3.2887 - accuracy: 0.13 - ETA: 5:02 - loss: 3.3240 - accuracy: 0.13 - ETA: 5:08 - loss: 3.3162 - accuracy: 0.14 - ETA: 5:04 - loss: 3.3215 - accuracy: 0.13 - ETA: 5:05 - loss: 3.3138 - accuracy: 0.14 - ETA: 5:08 - loss: 3.2938 - accuracy: 0.14 - ETA: 5:05 - loss: 3.3004 - accuracy: 0.14 - ETA: 5:06 - loss: 3.3157 - accuracy: 0.14 - ETA: 5:06 - loss: 3.3098 - accuracy: 0.14 - ETA: 5:07 - loss: 3.3199 - accuracy: 0.14 - ETA: 5:07 - loss: 3.3144 - accuracy: 0.15 - ETA: 5:06 - loss: 3.3203 - accuracy: 0.15 - ETA: 5:05 - loss: 3.3229 - accuracy: 0.14 - ETA: 5:04 - loss: 3.3242 - accuracy: 0.14 - ETA: 5:04 - loss: 3.3198 - accuracy: 0.14 - ETA: 5:03 - loss: 3.3142 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3137 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3019 - accuracy: 0.15 - ETA: 4:58 - loss: 3.3028 - accuracy: 0.15 - ETA: 4:57 - loss: 3.3078 - accuracy: 0.15 - ETA: 4:56 - loss: 3.3158 - accuracy: 0.15 - ETA: 4:55 - loss: 3.3091 - accuracy: 0.15 - ETA: 4:54 - loss: 3.3206 - accuracy: 0.15 - ETA: 4:52 - loss: 3.3298 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3395 - accuracy: 0.14 - ETA: 4:50 - loss: 3.3408 - accuracy: 0.14 - ETA: 4:49 - loss: 3.3444 - accuracy: 0.14 - ETA: 4:48 - loss: 3.3440 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3384 - accuracy: 0.14 - ETA: 4:46 - loss: 3.3417 - accuracy: 0.14 - ETA: 4:45 - loss: 3.3390 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3382 - accuracy: 0.14 - ETA: 4:43 - loss: 3.3411 - accuracy: 0.14 - ETA: 4:41 - loss: 3.3375 - accuracy: 0.14 - ETA: 4:40 - loss: 3.3421 - accuracy: 0.14 - ETA: 4:40 - loss: 3.3462 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3480 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3438 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3426 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3446 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3420 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3464 - accuracy: 0.14 - ETA: 4:33 - loss: 3.3461 - accuracy: 0.14 - ETA: 4:32 - loss: 3.3441 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3494 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3482 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3447 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3455 - accuracy: 0.14 - ETA: 4:27 - loss: 3.3433 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3419 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3392 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3395 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3369 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3356 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3363 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3345 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3318 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3316 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3266 - accuracy: 0.15 - ETA: 4:17 - loss: 3.3262 - accuracy: 0.15 - ETA: 4:17 - loss: 3.3270 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3227 - accuracy: 0.15 - ETA: 4:15 - loss: 3.3234 - accuracy: 0.15 - ETA: 4:14 - loss: 3.3210 - accuracy: 0.15 - ETA: 4:13 - loss: 3.3195 - accuracy: 0.15 - ETA: 4:12 - loss: 3.3164 - accuracy: 0.15 - ETA: 4:11 - loss: 3.3204 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3220 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3243 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3266 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3246 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3236 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3230 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3231 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3218 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3221 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3241 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3224 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3213 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3221 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3204 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3210 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3203 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3183 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3184 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3164 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3151 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3161 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3165 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3148 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3156 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3168 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3177 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3187 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3173 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3166 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3170 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3163 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3168 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3169 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3171 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3182 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3163 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3163 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3155 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3155 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3137 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3138 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3138 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3141 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3138 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3146 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3143 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3136 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3152 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3154 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3140 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3143 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3138 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3134 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3127 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3122 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3133 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3135 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3128 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3116 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3107 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3115 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3132 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3139 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3130 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3134 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3127 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3138 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3135 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3141 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3132 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3143 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3144 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3140 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3143 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3143 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3155 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3149 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3152 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3150 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3143 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3148 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3145 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3144 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3149 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3148 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3141 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3137 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3135 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3133 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3122 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3136 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3143 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3139 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3118 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3118 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3125 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3127 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3135 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3137 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3135 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3130 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3125 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3118 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3118 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3111 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3118 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3127 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3121 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3126 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3132 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3122 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3118 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3118 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3124 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3118 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3121 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3113 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3099 - accuracy: 0.1476"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3101 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3099 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3099 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3105 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3104 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3106 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3100 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3096 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3095 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3091 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3092 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3088 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3093 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3085 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3097 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3100 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3099 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3100 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3099 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3105 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3103 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3108 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3105 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3103 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3101 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3098 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3096 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3098 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3097 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3122 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3122 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3118 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3121 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3129 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3125 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3112 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3116 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3117 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3117 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3118 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3121 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3130 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3132 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3138 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3137 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3134 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3132 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3136 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3136 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3137 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3142 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3152 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3150 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3149 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3147 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3143 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3136 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3141 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3131 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3130 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3129 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3130 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3130 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3132 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3129 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3130 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3134 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3133 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3133 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3132 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3128 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3127 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3132 - accuracy: 0.14 - ETA: 59s - loss: 3.3131 - accuracy: 0.1469 - ETA: 58s - loss: 3.3131 - accuracy: 0.146 - ETA: 57s - loss: 3.3133 - accuracy: 0.146 - ETA: 56s - loss: 3.3133 - accuracy: 0.146 - ETA: 55s - loss: 3.3140 - accuracy: 0.146 - ETA: 54s - loss: 3.3137 - accuracy: 0.146 - ETA: 53s - loss: 3.3132 - accuracy: 0.146 - ETA: 52s - loss: 3.3134 - accuracy: 0.146 - ETA: 51s - loss: 3.3128 - accuracy: 0.146 - ETA: 50s - loss: 3.3129 - accuracy: 0.146 - ETA: 49s - loss: 3.3124 - accuracy: 0.146 - ETA: 48s - loss: 3.3123 - accuracy: 0.146 - ETA: 47s - loss: 3.3119 - accuracy: 0.146 - ETA: 46s - loss: 3.3124 - accuracy: 0.146 - ETA: 45s - loss: 3.3122 - accuracy: 0.146 - ETA: 44s - loss: 3.3126 - accuracy: 0.146 - ETA: 44s - loss: 3.3115 - accuracy: 0.146 - ETA: 43s - loss: 3.3114 - accuracy: 0.146 - ETA: 42s - loss: 3.3111 - accuracy: 0.146 - ETA: 41s - loss: 3.3110 - accuracy: 0.146 - ETA: 40s - loss: 3.3104 - accuracy: 0.146 - ETA: 39s - loss: 3.3102 - accuracy: 0.146 - ETA: 38s - loss: 3.3104 - accuracy: 0.146 - ETA: 37s - loss: 3.3105 - accuracy: 0.146 - ETA: 36s - loss: 3.3103 - accuracy: 0.146 - ETA: 35s - loss: 3.3095 - accuracy: 0.147 - ETA: 34s - loss: 3.3089 - accuracy: 0.147 - ETA: 33s - loss: 3.3090 - accuracy: 0.147 - ETA: 32s - loss: 3.3084 - accuracy: 0.147 - ETA: 31s - loss: 3.3085 - accuracy: 0.147 - ETA: 30s - loss: 3.3082 - accuracy: 0.147 - ETA: 29s - loss: 3.3077 - accuracy: 0.147 - ETA: 28s - loss: 3.3070 - accuracy: 0.147 - ETA: 27s - loss: 3.3070 - accuracy: 0.147 - ETA: 26s - loss: 3.3073 - accuracy: 0.147 - ETA: 25s - loss: 3.3070 - accuracy: 0.147 - ETA: 24s - loss: 3.3066 - accuracy: 0.147 - ETA: 23s - loss: 3.3066 - accuracy: 0.147 - ETA: 23s - loss: 3.3061 - accuracy: 0.147 - ETA: 22s - loss: 3.3064 - accuracy: 0.147 - ETA: 21s - loss: 3.3058 - accuracy: 0.147 - ETA: 20s - loss: 3.3064 - accuracy: 0.147 - ETA: 19s - loss: 3.3064 - accuracy: 0.147 - ETA: 18s - loss: 3.3070 - accuracy: 0.147 - ETA: 17s - loss: 3.3069 - accuracy: 0.147 - ETA: 16s - loss: 3.3069 - accuracy: 0.147 - ETA: 15s - loss: 3.3068 - accuracy: 0.147 - ETA: 14s - loss: 3.3065 - accuracy: 0.147 - ETA: 13s - loss: 3.3063 - accuracy: 0.147 - ETA: 12s - loss: 3.3064 - accuracy: 0.146 - ETA: 11s - loss: 3.3064 - accuracy: 0.147 - ETA: 10s - loss: 3.3065 - accuracy: 0.146 - ETA: 9s - loss: 3.3061 - accuracy: 0.147 - ETA: 8s - loss: 3.3062 - accuracy: 0.14 - ETA: 7s - loss: 3.3066 - accuracy: 0.14 - ETA: 6s - loss: 3.3064 - accuracy: 0.14 - ETA: 5s - loss: 3.3066 - accuracy: 0.14 - ETA: 4s - loss: 3.3067 - accuracy: 0.14 - ETA: 3s - loss: 3.3064 - accuracy: 0.14 - ETA: 2s - loss: 3.3057 - accuracy: 0.14 - ETA: 1s - loss: 3.3055 - accuracy: 0.14 - ETA: 1s - loss: 3.3055 - accuracy: 0.14 - ETA: 0s - loss: 3.3054 - accuracy: 0.14 - 341s 8ms/step - loss: 3.3053 - accuracy: 0.1472 - val_loss: 3.9237 - val_accuracy: 0.0320\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:35 - loss: 3.2254 - accuracy: 0.13 - ETA: 5:38 - loss: 3.2170 - accuracy: 0.15 - ETA: 5:38 - loss: 3.2782 - accuracy: 0.14 - ETA: 5:32 - loss: 3.2793 - accuracy: 0.14 - ETA: 5:26 - loss: 3.2569 - accuracy: 0.15 - ETA: 5:19 - loss: 3.2497 - accuracy: 0.15 - ETA: 5:15 - loss: 3.2641 - accuracy: 0.15 - ETA: 5:15 - loss: 3.2342 - accuracy: 0.15 - ETA: 5:13 - loss: 3.2336 - accuracy: 0.15 - ETA: 5:12 - loss: 3.2267 - accuracy: 0.16 - ETA: 5:09 - loss: 3.2315 - accuracy: 0.16 - ETA: 5:06 - loss: 3.2300 - accuracy: 0.16 - ETA: 5:04 - loss: 3.2308 - accuracy: 0.16 - ETA: 5:01 - loss: 3.2192 - accuracy: 0.16 - ETA: 5:00 - loss: 3.2238 - accuracy: 0.16 - ETA: 4:58 - loss: 3.2276 - accuracy: 0.16 - ETA: 4:56 - loss: 3.2308 - accuracy: 0.16 - ETA: 4:54 - loss: 3.2366 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2453 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2488 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2523 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2562 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2589 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2587 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2573 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2576 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2597 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2643 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2621 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2662 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2646 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2637 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2614 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2619 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2661 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2716 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2757 - accuracy: 0.14 - ETA: 4:38 - loss: 3.2776 - accuracy: 0.14 - ETA: 4:37 - loss: 3.2771 - accuracy: 0.14 - ETA: 4:36 - loss: 3.2796 - accuracy: 0.14 - ETA: 4:35 - loss: 3.2759 - accuracy: 0.14 - ETA: 4:34 - loss: 3.2791 - accuracy: 0.14 - ETA: 4:33 - loss: 3.2754 - accuracy: 0.14 - ETA: 4:32 - loss: 3.2811 - accuracy: 0.14 - ETA: 4:31 - loss: 3.2826 - accuracy: 0.14 - ETA: 4:30 - loss: 3.2838 - accuracy: 0.14 - ETA: 4:28 - loss: 3.2850 - accuracy: 0.14 - ETA: 4:27 - loss: 3.2829 - accuracy: 0.14 - ETA: 4:27 - loss: 3.2831 - accuracy: 0.14 - ETA: 4:26 - loss: 3.2859 - accuracy: 0.14 - ETA: 4:26 - loss: 3.2902 - accuracy: 0.14 - ETA: 4:25 - loss: 3.2891 - accuracy: 0.14 - ETA: 4:24 - loss: 3.2889 - accuracy: 0.14 - ETA: 4:23 - loss: 3.2919 - accuracy: 0.14 - ETA: 4:22 - loss: 3.2899 - accuracy: 0.14 - ETA: 4:21 - loss: 3.2919 - accuracy: 0.14 - ETA: 4:20 - loss: 3.2900 - accuracy: 0.14 - ETA: 4:19 - loss: 3.2935 - accuracy: 0.14 - ETA: 4:18 - loss: 3.2907 - accuracy: 0.14 - ETA: 4:18 - loss: 3.2868 - accuracy: 0.14 - ETA: 4:17 - loss: 3.2864 - accuracy: 0.14 - ETA: 4:16 - loss: 3.2874 - accuracy: 0.14 - ETA: 4:15 - loss: 3.2897 - accuracy: 0.14 - ETA: 4:14 - loss: 3.2882 - accuracy: 0.14 - ETA: 4:13 - loss: 3.2895 - accuracy: 0.14 - ETA: 4:12 - loss: 3.2902 - accuracy: 0.14 - ETA: 4:11 - loss: 3.2912 - accuracy: 0.14 - ETA: 4:10 - loss: 3.2909 - accuracy: 0.14 - ETA: 4:09 - loss: 3.2921 - accuracy: 0.14 - ETA: 4:08 - loss: 3.2940 - accuracy: 0.14 - ETA: 4:08 - loss: 3.2943 - accuracy: 0.14 - ETA: 4:07 - loss: 3.2950 - accuracy: 0.14 - ETA: 4:06 - loss: 3.2922 - accuracy: 0.14 - ETA: 4:05 - loss: 3.2948 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2917 - accuracy: 0.14 - ETA: 4:03 - loss: 3.2913 - accuracy: 0.14 - ETA: 4:03 - loss: 3.2905 - accuracy: 0.14 - ETA: 4:02 - loss: 3.2892 - accuracy: 0.14 - ETA: 4:00 - loss: 3.2885 - accuracy: 0.14 - ETA: 3:59 - loss: 3.2863 - accuracy: 0.14 - ETA: 3:58 - loss: 3.2856 - accuracy: 0.14 - ETA: 3:57 - loss: 3.2871 - accuracy: 0.14 - ETA: 3:56 - loss: 3.2865 - accuracy: 0.14 - ETA: 3:55 - loss: 3.2898 - accuracy: 0.14 - ETA: 3:55 - loss: 3.2916 - accuracy: 0.14 - ETA: 3:54 - loss: 3.2916 - accuracy: 0.14 - ETA: 3:53 - loss: 3.2923 - accuracy: 0.14 - ETA: 3:52 - loss: 3.2925 - accuracy: 0.14 - ETA: 3:51 - loss: 3.2913 - accuracy: 0.14 - ETA: 3:50 - loss: 3.2891 - accuracy: 0.14 - ETA: 3:49 - loss: 3.2895 - accuracy: 0.14 - ETA: 3:48 - loss: 3.2895 - accuracy: 0.14 - ETA: 3:47 - loss: 3.2916 - accuracy: 0.14 - ETA: 3:46 - loss: 3.2918 - accuracy: 0.14 - ETA: 3:45 - loss: 3.2919 - accuracy: 0.14 - ETA: 3:44 - loss: 3.2928 - accuracy: 0.14 - ETA: 3:43 - loss: 3.2907 - accuracy: 0.14 - ETA: 3:42 - loss: 3.2904 - accuracy: 0.14 - ETA: 3:41 - loss: 3.2915 - accuracy: 0.14 - ETA: 3:40 - loss: 3.2920 - accuracy: 0.14 - ETA: 3:39 - loss: 3.2913 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2908 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2915 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2919 - accuracy: 0.14 - ETA: 3:35 - loss: 3.2901 - accuracy: 0.14 - ETA: 3:35 - loss: 3.2871 - accuracy: 0.14 - ETA: 3:34 - loss: 3.2877 - accuracy: 0.14 - ETA: 3:33 - loss: 3.2883 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2872 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2883 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2886 - accuracy: 0.14 - ETA: 3:29 - loss: 3.2883 - accuracy: 0.14 - ETA: 3:28 - loss: 3.2875 - accuracy: 0.14 - ETA: 3:27 - loss: 3.2885 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2886 - accuracy: 0.14 - ETA: 3:25 - loss: 3.2863 - accuracy: 0.14 - ETA: 3:24 - loss: 3.2878 - accuracy: 0.14 - ETA: 3:23 - loss: 3.2894 - accuracy: 0.14 - ETA: 3:23 - loss: 3.2903 - accuracy: 0.14 - ETA: 3:22 - loss: 3.2928 - accuracy: 0.14 - ETA: 3:21 - loss: 3.2927 - accuracy: 0.14 - ETA: 3:20 - loss: 3.2923 - accuracy: 0.14 - ETA: 3:19 - loss: 3.2915 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2909 - accuracy: 0.14 - ETA: 3:17 - loss: 3.2894 - accuracy: 0.14 - ETA: 3:16 - loss: 3.2895 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2883 - accuracy: 0.14 - ETA: 3:14 - loss: 3.2889 - accuracy: 0.14 - ETA: 3:13 - loss: 3.2887 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2885 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2883 - accuracy: 0.14 - ETA: 3:10 - loss: 3.2895 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2887 - accuracy: 0.14 - ETA: 3:08 - loss: 3.2891 - accuracy: 0.14 - ETA: 3:07 - loss: 3.2895 - accuracy: 0.14 - ETA: 3:06 - loss: 3.2899 - accuracy: 0.14 - ETA: 3:05 - loss: 3.2880 - accuracy: 0.14 - ETA: 3:04 - loss: 3.2872 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2866 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2857 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2842 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2848 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2850 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2848 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2836 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2825 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2823 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2837 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2831 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2826 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2826 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2822 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2812 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2810 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2802 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2812 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2803 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2809 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2818 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2828 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2828 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2832 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2831 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2819 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2825 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2830 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2830 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2840 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2830 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2821 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2836 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2847 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2851 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2857 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2870 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2873 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2873 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2871 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2866 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2873 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2875 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2872 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2874 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2870 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2864 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2878 - accuracy: 0.1494"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.2883 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2889 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2893 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2893 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2892 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2892 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2905 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2898 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2903 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2907 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2912 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2904 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2909 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2910 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2913 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2915 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2917 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2924 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2933 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2936 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2945 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2950 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2960 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2957 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2965 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2966 - accuracy: 0.14 - ETA: 1:53 - loss: 3.2969 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2975 - accuracy: 0.14 - ETA: 1:51 - loss: 3.2981 - accuracy: 0.14 - ETA: 1:50 - loss: 3.2983 - accuracy: 0.14 - ETA: 1:49 - loss: 3.2986 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2985 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2982 - accuracy: 0.14 - ETA: 1:46 - loss: 3.2980 - accuracy: 0.14 - ETA: 1:45 - loss: 3.2983 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2981 - accuracy: 0.14 - ETA: 1:43 - loss: 3.2987 - accuracy: 0.14 - ETA: 1:42 - loss: 3.2988 - accuracy: 0.14 - ETA: 1:41 - loss: 3.2990 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2995 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2991 - accuracy: 0.14 - ETA: 1:38 - loss: 3.2991 - accuracy: 0.14 - ETA: 1:37 - loss: 3.2988 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3038 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3037 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3037 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3038 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3052 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3055 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3041 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3041 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3047 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3052 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3041 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3047 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3047 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3051 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3049 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3047 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3043 - accuracy: 0.14 - ETA: 59s - loss: 3.3051 - accuracy: 0.1471 - ETA: 58s - loss: 3.3054 - accuracy: 0.147 - ETA: 57s - loss: 3.3058 - accuracy: 0.146 - ETA: 56s - loss: 3.3057 - accuracy: 0.146 - ETA: 55s - loss: 3.3049 - accuracy: 0.147 - ETA: 54s - loss: 3.3047 - accuracy: 0.147 - ETA: 53s - loss: 3.3054 - accuracy: 0.147 - ETA: 52s - loss: 3.3047 - accuracy: 0.147 - ETA: 51s - loss: 3.3051 - accuracy: 0.146 - ETA: 51s - loss: 3.3047 - accuracy: 0.147 - ETA: 50s - loss: 3.3041 - accuracy: 0.147 - ETA: 49s - loss: 3.3041 - accuracy: 0.147 - ETA: 48s - loss: 3.3041 - accuracy: 0.147 - ETA: 47s - loss: 3.3041 - accuracy: 0.147 - ETA: 46s - loss: 3.3039 - accuracy: 0.147 - ETA: 45s - loss: 3.3046 - accuracy: 0.146 - ETA: 44s - loss: 3.3046 - accuracy: 0.146 - ETA: 43s - loss: 3.3042 - accuracy: 0.147 - ETA: 42s - loss: 3.3041 - accuracy: 0.147 - ETA: 41s - loss: 3.3044 - accuracy: 0.147 - ETA: 40s - loss: 3.3043 - accuracy: 0.147 - ETA: 39s - loss: 3.3045 - accuracy: 0.147 - ETA: 38s - loss: 3.3046 - accuracy: 0.147 - ETA: 37s - loss: 3.3047 - accuracy: 0.147 - ETA: 36s - loss: 3.3048 - accuracy: 0.147 - ETA: 35s - loss: 3.3047 - accuracy: 0.147 - ETA: 34s - loss: 3.3057 - accuracy: 0.147 - ETA: 33s - loss: 3.3053 - accuracy: 0.147 - ETA: 32s - loss: 3.3057 - accuracy: 0.147 - ETA: 31s - loss: 3.3061 - accuracy: 0.147 - ETA: 30s - loss: 3.3064 - accuracy: 0.147 - ETA: 29s - loss: 3.3064 - accuracy: 0.147 - ETA: 28s - loss: 3.3072 - accuracy: 0.146 - ETA: 27s - loss: 3.3073 - accuracy: 0.146 - ETA: 26s - loss: 3.3072 - accuracy: 0.146 - ETA: 26s - loss: 3.3074 - accuracy: 0.146 - ETA: 25s - loss: 3.3072 - accuracy: 0.146 - ETA: 24s - loss: 3.3070 - accuracy: 0.147 - ETA: 23s - loss: 3.3077 - accuracy: 0.146 - ETA: 22s - loss: 3.3077 - accuracy: 0.146 - ETA: 21s - loss: 3.3076 - accuracy: 0.146 - ETA: 20s - loss: 3.3077 - accuracy: 0.146 - ETA: 19s - loss: 3.3074 - accuracy: 0.146 - ETA: 18s - loss: 3.3072 - accuracy: 0.146 - ETA: 17s - loss: 3.3075 - accuracy: 0.146 - ETA: 16s - loss: 3.3075 - accuracy: 0.146 - ETA: 15s - loss: 3.3075 - accuracy: 0.146 - ETA: 14s - loss: 3.3071 - accuracy: 0.146 - ETA: 13s - loss: 3.3076 - accuracy: 0.146 - ETA: 12s - loss: 3.3080 - accuracy: 0.146 - ETA: 11s - loss: 3.3088 - accuracy: 0.146 - ETA: 10s - loss: 3.3089 - accuracy: 0.146 - ETA: 9s - loss: 3.3091 - accuracy: 0.146 - ETA: 8s - loss: 3.3095 - accuracy: 0.14 - ETA: 7s - loss: 3.3093 - accuracy: 0.14 - ETA: 6s - loss: 3.3091 - accuracy: 0.14 - ETA: 5s - loss: 3.3094 - accuracy: 0.14 - ETA: 4s - loss: 3.3095 - accuracy: 0.14 - ETA: 3s - loss: 3.3101 - accuracy: 0.14 - ETA: 2s - loss: 3.3101 - accuracy: 0.14 - ETA: 1s - loss: 3.3102 - accuracy: 0.14 - ETA: 1s - loss: 3.3104 - accuracy: 0.14 - ETA: 0s - loss: 3.3106 - accuracy: 0.14 - 342s 8ms/step - loss: 3.3106 - accuracy: 0.1464 - val_loss: 3.8895 - val_accuracy: 0.0224\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:25 - loss: 3.4150 - accuracy: 0.13 - ETA: 5:28 - loss: 3.3086 - accuracy: 0.14 - ETA: 5:23 - loss: 3.2567 - accuracy: 0.14 - ETA: 5:21 - loss: 3.2531 - accuracy: 0.14 - ETA: 5:16 - loss: 3.2466 - accuracy: 0.15 - ETA: 5:13 - loss: 3.2509 - accuracy: 0.14 - ETA: 5:09 - loss: 3.2847 - accuracy: 0.13 - ETA: 5:10 - loss: 3.3037 - accuracy: 0.13 - ETA: 5:12 - loss: 3.2994 - accuracy: 0.13 - ETA: 5:12 - loss: 3.3160 - accuracy: 0.13 - ETA: 5:11 - loss: 3.3248 - accuracy: 0.13 - ETA: 5:10 - loss: 3.3311 - accuracy: 0.13 - ETA: 5:08 - loss: 3.3311 - accuracy: 0.13 - ETA: 5:10 - loss: 3.3233 - accuracy: 0.13 - ETA: 5:09 - loss: 3.3212 - accuracy: 0.13 - ETA: 5:09 - loss: 3.3182 - accuracy: 0.13 - ETA: 5:08 - loss: 3.3210 - accuracy: 0.13 - ETA: 5:06 - loss: 3.3202 - accuracy: 0.13 - ETA: 5:06 - loss: 3.3038 - accuracy: 0.13 - ETA: 5:05 - loss: 3.3005 - accuracy: 0.13 - ETA: 5:03 - loss: 3.2997 - accuracy: 0.13 - ETA: 5:01 - loss: 3.3019 - accuracy: 0.13 - ETA: 5:00 - loss: 3.3012 - accuracy: 0.13 - ETA: 4:59 - loss: 3.3009 - accuracy: 0.14 - ETA: 4:57 - loss: 3.3006 - accuracy: 0.14 - ETA: 4:57 - loss: 3.2939 - accuracy: 0.14 - ETA: 4:57 - loss: 3.2959 - accuracy: 0.14 - ETA: 4:56 - loss: 3.2973 - accuracy: 0.14 - ETA: 4:55 - loss: 3.2982 - accuracy: 0.14 - ETA: 4:53 - loss: 3.2969 - accuracy: 0.13 - ETA: 4:52 - loss: 3.2988 - accuracy: 0.14 - ETA: 4:50 - loss: 3.2976 - accuracy: 0.14 - ETA: 4:49 - loss: 3.2985 - accuracy: 0.14 - ETA: 4:48 - loss: 3.2984 - accuracy: 0.14 - ETA: 4:47 - loss: 3.2992 - accuracy: 0.14 - ETA: 4:46 - loss: 3.2995 - accuracy: 0.14 - ETA: 4:46 - loss: 3.3058 - accuracy: 0.13 - ETA: 4:45 - loss: 3.3083 - accuracy: 0.14 - ETA: 4:43 - loss: 3.3032 - accuracy: 0.14 - ETA: 4:41 - loss: 3.3029 - accuracy: 0.14 - ETA: 4:40 - loss: 3.3015 - accuracy: 0.14 - ETA: 4:39 - loss: 3.3007 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3006 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3042 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3067 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3089 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3093 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3105 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3088 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3101 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3086 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3082 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3099 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3079 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3054 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3044 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3081 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3070 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3074 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3071 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3052 - accuracy: 0.13 - ETA: 4:19 - loss: 3.3038 - accuracy: 0.13 - ETA: 4:17 - loss: 3.3023 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3024 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3024 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3035 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3048 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3021 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3020 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3023 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3036 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3053 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3048 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3046 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3028 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3062 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3077 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3060 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3037 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3038 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3042 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3031 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3038 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3024 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3012 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3021 - accuracy: 0.14 - ETA: 3:53 - loss: 3.2988 - accuracy: 0.14 - ETA: 3:52 - loss: 3.2973 - accuracy: 0.14 - ETA: 3:51 - loss: 3.2947 - accuracy: 0.14 - ETA: 3:50 - loss: 3.2957 - accuracy: 0.14 - ETA: 3:49 - loss: 3.2961 - accuracy: 0.14 - ETA: 3:48 - loss: 3.2959 - accuracy: 0.14 - ETA: 3:47 - loss: 3.2961 - accuracy: 0.14 - ETA: 3:46 - loss: 3.2981 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3000 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3018 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3018 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3008 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3014 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3018 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3007 - accuracy: 0.14 - ETA: 3:39 - loss: 3.2984 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2991 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2986 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2980 - accuracy: 0.14 - ETA: 3:35 - loss: 3.2982 - accuracy: 0.14 - ETA: 3:34 - loss: 3.2988 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3003 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2989 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2997 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3004 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3005 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3001 - accuracy: 0.14 - ETA: 3:27 - loss: 3.2998 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3005 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3002 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3000 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3002 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3010 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3017 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3029 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3035 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3030 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3034 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3014 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3011 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3012 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3017 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3025 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3046 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3050 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3054 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3057 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3057 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3049 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3039 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3063 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3057 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3061 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3057 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3065 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3063 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3063 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3062 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3061 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3068 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3069 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3075 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3074 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3074 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3075 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3077 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3093 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3093 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3094 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3097 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3087 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3080 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3073 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3069 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3065 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3067 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3057 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3048 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3052 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3046 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3048 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3038 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3054 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3072 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3069 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3070 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3061 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3055 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3058 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3073 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3076 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3075 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3063 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3061 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3062 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3069 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3065 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3061 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3065 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3067 - accuracy: 0.1431"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3063 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3056 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3046 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3045 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3044 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3042 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3043 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3043 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3038 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3038 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3046 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3056 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3058 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3059 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3071 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3069 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3060 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3053 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3058 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3035 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3034 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3029 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3028 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3028 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3028 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3039 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3049 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3054 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3051 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3059 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3062 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3051 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3052 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3051 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3042 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3037 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3030 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3022 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3032 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3024 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3025 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3031 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3028 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3031 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3022 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3024 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3017 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3014 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3009 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3010 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3004 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3003 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3006 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3011 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3002 - accuracy: 0.14 - ETA: 1:19 - loss: 3.2998 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2999 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2996 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2992 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2986 - accuracy: 0.14 - ETA: 1:14 - loss: 3.2984 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2984 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2984 - accuracy: 0.14 - ETA: 1:11 - loss: 3.2981 - accuracy: 0.14 - ETA: 1:10 - loss: 3.2982 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2977 - accuracy: 0.14 - ETA: 1:08 - loss: 3.2977 - accuracy: 0.14 - ETA: 1:08 - loss: 3.2971 - accuracy: 0.14 - ETA: 1:07 - loss: 3.2966 - accuracy: 0.14 - ETA: 1:06 - loss: 3.2965 - accuracy: 0.14 - ETA: 1:05 - loss: 3.2965 - accuracy: 0.14 - ETA: 1:04 - loss: 3.2962 - accuracy: 0.14 - ETA: 1:03 - loss: 3.2964 - accuracy: 0.14 - ETA: 1:02 - loss: 3.2962 - accuracy: 0.14 - ETA: 1:01 - loss: 3.2963 - accuracy: 0.14 - ETA: 1:00 - loss: 3.2969 - accuracy: 0.14 - ETA: 59s - loss: 3.2970 - accuracy: 0.1450 - ETA: 58s - loss: 3.2966 - accuracy: 0.144 - ETA: 57s - loss: 3.2962 - accuracy: 0.145 - ETA: 56s - loss: 3.2953 - accuracy: 0.145 - ETA: 55s - loss: 3.2957 - accuracy: 0.144 - ETA: 54s - loss: 3.2961 - accuracy: 0.144 - ETA: 53s - loss: 3.2955 - accuracy: 0.144 - ETA: 52s - loss: 3.2959 - accuracy: 0.144 - ETA: 51s - loss: 3.2953 - accuracy: 0.144 - ETA: 50s - loss: 3.2952 - accuracy: 0.145 - ETA: 49s - loss: 3.2951 - accuracy: 0.145 - ETA: 48s - loss: 3.2949 - accuracy: 0.145 - ETA: 47s - loss: 3.2952 - accuracy: 0.145 - ETA: 46s - loss: 3.2955 - accuracy: 0.145 - ETA: 45s - loss: 3.2950 - accuracy: 0.145 - ETA: 45s - loss: 3.2951 - accuracy: 0.145 - ETA: 44s - loss: 3.2945 - accuracy: 0.145 - ETA: 43s - loss: 3.2948 - accuracy: 0.145 - ETA: 42s - loss: 3.2954 - accuracy: 0.145 - ETA: 41s - loss: 3.2954 - accuracy: 0.145 - ETA: 40s - loss: 3.2951 - accuracy: 0.145 - ETA: 39s - loss: 3.2953 - accuracy: 0.145 - ETA: 38s - loss: 3.2953 - accuracy: 0.145 - ETA: 37s - loss: 3.2953 - accuracy: 0.145 - ETA: 36s - loss: 3.2960 - accuracy: 0.145 - ETA: 35s - loss: 3.2960 - accuracy: 0.145 - ETA: 34s - loss: 3.2962 - accuracy: 0.145 - ETA: 33s - loss: 3.2963 - accuracy: 0.145 - ETA: 32s - loss: 3.2960 - accuracy: 0.145 - ETA: 31s - loss: 3.2960 - accuracy: 0.145 - ETA: 30s - loss: 3.2958 - accuracy: 0.145 - ETA: 29s - loss: 3.2960 - accuracy: 0.145 - ETA: 28s - loss: 3.2959 - accuracy: 0.145 - ETA: 27s - loss: 3.2967 - accuracy: 0.145 - ETA: 26s - loss: 3.2973 - accuracy: 0.145 - ETA: 25s - loss: 3.2974 - accuracy: 0.145 - ETA: 24s - loss: 3.2972 - accuracy: 0.145 - ETA: 23s - loss: 3.2974 - accuracy: 0.145 - ETA: 23s - loss: 3.2973 - accuracy: 0.145 - ETA: 22s - loss: 3.2972 - accuracy: 0.145 - ETA: 21s - loss: 3.2973 - accuracy: 0.145 - ETA: 20s - loss: 3.2975 - accuracy: 0.145 - ETA: 19s - loss: 3.2976 - accuracy: 0.145 - ETA: 18s - loss: 3.2968 - accuracy: 0.145 - ETA: 17s - loss: 3.2969 - accuracy: 0.145 - ETA: 16s - loss: 3.2972 - accuracy: 0.145 - ETA: 15s - loss: 3.2969 - accuracy: 0.145 - ETA: 14s - loss: 3.2973 - accuracy: 0.145 - ETA: 13s - loss: 3.2975 - accuracy: 0.145 - ETA: 12s - loss: 3.2972 - accuracy: 0.145 - ETA: 11s - loss: 3.2968 - accuracy: 0.145 - ETA: 10s - loss: 3.2968 - accuracy: 0.145 - ETA: 9s - loss: 3.2968 - accuracy: 0.145 - ETA: 8s - loss: 3.2970 - accuracy: 0.14 - ETA: 7s - loss: 3.2965 - accuracy: 0.14 - ETA: 6s - loss: 3.2967 - accuracy: 0.14 - ETA: 5s - loss: 3.2966 - accuracy: 0.14 - ETA: 4s - loss: 3.2967 - accuracy: 0.14 - ETA: 3s - loss: 3.2965 - accuracy: 0.14 - ETA: 2s - loss: 3.2966 - accuracy: 0.14 - ETA: 1s - loss: 3.2963 - accuracy: 0.14 - ETA: 1s - loss: 3.2964 - accuracy: 0.14 - ETA: 0s - loss: 3.2964 - accuracy: 0.14 - 341s 8ms/step - loss: 3.2965 - accuracy: 0.1458 - val_loss: 3.9251 - val_accuracy: 0.0243\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:21 - loss: 3.0410 - accuracy: 0.17 - ETA: 5:17 - loss: 3.2380 - accuracy: 0.14 - ETA: 5:19 - loss: 3.2407 - accuracy: 0.15 - ETA: 5:13 - loss: 3.2548 - accuracy: 0.14 - ETA: 5:13 - loss: 3.2509 - accuracy: 0.14 - ETA: 5:11 - loss: 3.2747 - accuracy: 0.13 - ETA: 5:10 - loss: 3.2646 - accuracy: 0.14 - ETA: 5:10 - loss: 3.2459 - accuracy: 0.14 - ETA: 5:09 - loss: 3.2453 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2377 - accuracy: 0.15 - ETA: 5:06 - loss: 3.2551 - accuracy: 0.14 - ETA: 5:04 - loss: 3.2739 - accuracy: 0.14 - ETA: 5:02 - loss: 3.2833 - accuracy: 0.14 - ETA: 5:03 - loss: 3.2876 - accuracy: 0.14 - ETA: 5:02 - loss: 3.2845 - accuracy: 0.14 - ETA: 5:01 - loss: 3.2848 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3002 - accuracy: 0.14 - ETA: 4:57 - loss: 3.3017 - accuracy: 0.14 - ETA: 4:55 - loss: 3.2982 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3045 - accuracy: 0.14 - ETA: 4:54 - loss: 3.2978 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3055 - accuracy: 0.13 - ETA: 4:54 - loss: 3.2982 - accuracy: 0.14 - ETA: 4:54 - loss: 3.2999 - accuracy: 0.14 - ETA: 4:54 - loss: 3.2975 - accuracy: 0.14 - ETA: 4:54 - loss: 3.2957 - accuracy: 0.14 - ETA: 4:53 - loss: 3.2964 - accuracy: 0.14 - ETA: 4:52 - loss: 3.2996 - accuracy: 0.14 - ETA: 4:51 - loss: 3.3034 - accuracy: 0.14 - ETA: 4:50 - loss: 3.2997 - accuracy: 0.14 - ETA: 4:49 - loss: 3.3003 - accuracy: 0.14 - ETA: 4:48 - loss: 3.2997 - accuracy: 0.14 - ETA: 4:47 - loss: 3.3003 - accuracy: 0.14 - ETA: 4:45 - loss: 3.2997 - accuracy: 0.14 - ETA: 4:43 - loss: 3.2983 - accuracy: 0.14 - ETA: 4:42 - loss: 3.2958 - accuracy: 0.14 - ETA: 4:41 - loss: 3.2954 - accuracy: 0.14 - ETA: 4:40 - loss: 3.2921 - accuracy: 0.14 - ETA: 4:38 - loss: 3.2933 - accuracy: 0.14 - ETA: 4:38 - loss: 3.2948 - accuracy: 0.14 - ETA: 4:37 - loss: 3.2969 - accuracy: 0.14 - ETA: 4:36 - loss: 3.2944 - accuracy: 0.14 - ETA: 4:35 - loss: 3.2927 - accuracy: 0.14 - ETA: 4:34 - loss: 3.2940 - accuracy: 0.14 - ETA: 4:34 - loss: 3.2937 - accuracy: 0.14 - ETA: 4:33 - loss: 3.2941 - accuracy: 0.14 - ETA: 4:32 - loss: 3.2936 - accuracy: 0.14 - ETA: 4:31 - loss: 3.2940 - accuracy: 0.14 - ETA: 4:30 - loss: 3.2909 - accuracy: 0.14 - ETA: 4:29 - loss: 3.2875 - accuracy: 0.14 - ETA: 4:27 - loss: 3.2834 - accuracy: 0.14 - ETA: 4:26 - loss: 3.2844 - accuracy: 0.14 - ETA: 4:25 - loss: 3.2852 - accuracy: 0.14 - ETA: 4:24 - loss: 3.2889 - accuracy: 0.14 - ETA: 4:23 - loss: 3.2910 - accuracy: 0.14 - ETA: 4:22 - loss: 3.2926 - accuracy: 0.14 - ETA: 4:21 - loss: 3.2886 - accuracy: 0.14 - ETA: 4:20 - loss: 3.2889 - accuracy: 0.14 - ETA: 4:19 - loss: 3.2892 - accuracy: 0.14 - ETA: 4:18 - loss: 3.2900 - accuracy: 0.14 - ETA: 4:17 - loss: 3.2892 - accuracy: 0.14 - ETA: 4:16 - loss: 3.2910 - accuracy: 0.14 - ETA: 4:15 - loss: 3.2928 - accuracy: 0.14 - ETA: 4:14 - loss: 3.2919 - accuracy: 0.14 - ETA: 4:13 - loss: 3.2943 - accuracy: 0.14 - ETA: 4:13 - loss: 3.2954 - accuracy: 0.14 - ETA: 4:12 - loss: 3.2932 - accuracy: 0.14 - ETA: 4:11 - loss: 3.2922 - accuracy: 0.14 - ETA: 4:10 - loss: 3.2900 - accuracy: 0.14 - ETA: 4:09 - loss: 3.2896 - accuracy: 0.14 - ETA: 4:08 - loss: 3.2893 - accuracy: 0.14 - ETA: 4:07 - loss: 3.2908 - accuracy: 0.14 - ETA: 4:06 - loss: 3.2926 - accuracy: 0.14 - ETA: 4:05 - loss: 3.2905 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2916 - accuracy: 0.14 - ETA: 4:03 - loss: 3.2918 - accuracy: 0.14 - ETA: 4:02 - loss: 3.2915 - accuracy: 0.14 - ETA: 4:01 - loss: 3.2936 - accuracy: 0.14 - ETA: 4:00 - loss: 3.2943 - accuracy: 0.14 - ETA: 4:00 - loss: 3.2948 - accuracy: 0.14 - ETA: 3:59 - loss: 3.2961 - accuracy: 0.14 - ETA: 3:58 - loss: 3.2969 - accuracy: 0.14 - ETA: 3:57 - loss: 3.2972 - accuracy: 0.14 - ETA: 3:55 - loss: 3.2955 - accuracy: 0.14 - ETA: 3:54 - loss: 3.2973 - accuracy: 0.14 - ETA: 3:53 - loss: 3.2994 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3019 - accuracy: 0.14 - ETA: 3:52 - loss: 3.2996 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3010 - accuracy: 0.14 - ETA: 3:50 - loss: 3.2999 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3008 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3005 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3007 - accuracy: 0.14 - ETA: 3:46 - loss: 3.2994 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3005 - accuracy: 0.14 - ETA: 3:44 - loss: 3.2981 - accuracy: 0.14 - ETA: 3:43 - loss: 3.2983 - accuracy: 0.14 - ETA: 3:42 - loss: 3.2985 - accuracy: 0.14 - ETA: 3:41 - loss: 3.2984 - accuracy: 0.14 - ETA: 3:40 - loss: 3.2993 - accuracy: 0.14 - ETA: 3:39 - loss: 3.2984 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2977 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2973 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2983 - accuracy: 0.14 - ETA: 3:35 - loss: 3.2982 - accuracy: 0.14 - ETA: 3:35 - loss: 3.2982 - accuracy: 0.14 - ETA: 3:34 - loss: 3.2981 - accuracy: 0.14 - ETA: 3:33 - loss: 3.2971 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2959 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2959 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2940 - accuracy: 0.14 - ETA: 3:29 - loss: 3.2928 - accuracy: 0.14 - ETA: 3:28 - loss: 3.2922 - accuracy: 0.14 - ETA: 3:27 - loss: 3.2917 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2911 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2912 - accuracy: 0.14 - ETA: 3:25 - loss: 3.2921 - accuracy: 0.14 - ETA: 3:23 - loss: 3.2925 - accuracy: 0.14 - ETA: 3:22 - loss: 3.2930 - accuracy: 0.14 - ETA: 3:21 - loss: 3.2935 - accuracy: 0.14 - ETA: 3:20 - loss: 3.2943 - accuracy: 0.14 - ETA: 3:20 - loss: 3.2945 - accuracy: 0.14 - ETA: 3:19 - loss: 3.2956 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2957 - accuracy: 0.14 - ETA: 3:17 - loss: 3.2957 - accuracy: 0.14 - ETA: 3:16 - loss: 3.2970 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2977 - accuracy: 0.14 - ETA: 3:14 - loss: 3.2975 - accuracy: 0.14 - ETA: 3:13 - loss: 3.2974 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2969 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2962 - accuracy: 0.14 - ETA: 3:10 - loss: 3.2964 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2967 - accuracy: 0.14 - ETA: 3:08 - loss: 3.2967 - accuracy: 0.14 - ETA: 3:07 - loss: 3.2968 - accuracy: 0.14 - ETA: 3:06 - loss: 3.2958 - accuracy: 0.14 - ETA: 3:05 - loss: 3.2959 - accuracy: 0.14 - ETA: 3:04 - loss: 3.2956 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2964 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2957 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2972 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2972 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2968 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2972 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2978 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2984 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2981 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2979 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2986 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2995 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2999 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2990 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2979 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2974 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2970 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2968 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2959 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2961 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2958 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2967 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2967 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2970 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2960 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2949 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2960 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2944 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2951 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2948 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2945 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2937 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2952 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2954 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2945 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2949 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2943 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2941 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2954 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2961 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2960 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2961 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2962 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2962 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2955 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2949 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2944 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2930 - accuracy: 0.1471"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.2931 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2931 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2926 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2928 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2927 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2925 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2914 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2915 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2923 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2922 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2920 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2929 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2933 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2937 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2941 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2941 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2945 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2934 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2942 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2943 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2943 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2940 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2947 - accuracy: 0.14 - ETA: 1:53 - loss: 3.2951 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2951 - accuracy: 0.14 - ETA: 1:51 - loss: 3.2954 - accuracy: 0.14 - ETA: 1:50 - loss: 3.2953 - accuracy: 0.14 - ETA: 1:49 - loss: 3.2959 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2963 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2967 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2967 - accuracy: 0.14 - ETA: 1:46 - loss: 3.2965 - accuracy: 0.14 - ETA: 1:45 - loss: 3.2968 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2961 - accuracy: 0.14 - ETA: 1:43 - loss: 3.2960 - accuracy: 0.14 - ETA: 1:42 - loss: 3.2957 - accuracy: 0.14 - ETA: 1:41 - loss: 3.2961 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2961 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2958 - accuracy: 0.14 - ETA: 1:38 - loss: 3.2957 - accuracy: 0.14 - ETA: 1:37 - loss: 3.2960 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2962 - accuracy: 0.14 - ETA: 1:35 - loss: 3.2962 - accuracy: 0.14 - ETA: 1:34 - loss: 3.2955 - accuracy: 0.14 - ETA: 1:33 - loss: 3.2957 - accuracy: 0.14 - ETA: 1:32 - loss: 3.2953 - accuracy: 0.14 - ETA: 1:31 - loss: 3.2948 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2942 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2940 - accuracy: 0.14 - ETA: 1:29 - loss: 3.2940 - accuracy: 0.14 - ETA: 1:28 - loss: 3.2945 - accuracy: 0.14 - ETA: 1:27 - loss: 3.2938 - accuracy: 0.14 - ETA: 1:26 - loss: 3.2937 - accuracy: 0.14 - ETA: 1:25 - loss: 3.2940 - accuracy: 0.14 - ETA: 1:24 - loss: 3.2939 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2941 - accuracy: 0.14 - ETA: 1:22 - loss: 3.2940 - accuracy: 0.14 - ETA: 1:21 - loss: 3.2941 - accuracy: 0.14 - ETA: 1:20 - loss: 3.2937 - accuracy: 0.14 - ETA: 1:19 - loss: 3.2939 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2928 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2927 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2919 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2923 - accuracy: 0.14 - ETA: 1:14 - loss: 3.2919 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2919 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2918 - accuracy: 0.14 - ETA: 1:11 - loss: 3.2916 - accuracy: 0.14 - ETA: 1:10 - loss: 3.2907 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2899 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2897 - accuracy: 0.14 - ETA: 1:08 - loss: 3.2892 - accuracy: 0.14 - ETA: 1:07 - loss: 3.2893 - accuracy: 0.14 - ETA: 1:06 - loss: 3.2897 - accuracy: 0.14 - ETA: 1:05 - loss: 3.2897 - accuracy: 0.14 - ETA: 1:04 - loss: 3.2903 - accuracy: 0.14 - ETA: 1:03 - loss: 3.2909 - accuracy: 0.14 - ETA: 1:02 - loss: 3.2908 - accuracy: 0.14 - ETA: 1:01 - loss: 3.2912 - accuracy: 0.14 - ETA: 1:00 - loss: 3.2915 - accuracy: 0.14 - ETA: 59s - loss: 3.2922 - accuracy: 0.1488 - ETA: 58s - loss: 3.2926 - accuracy: 0.148 - ETA: 57s - loss: 3.2919 - accuracy: 0.148 - ETA: 56s - loss: 3.2918 - accuracy: 0.148 - ETA: 55s - loss: 3.2912 - accuracy: 0.149 - ETA: 54s - loss: 3.2913 - accuracy: 0.149 - ETA: 53s - loss: 3.2906 - accuracy: 0.149 - ETA: 52s - loss: 3.2912 - accuracy: 0.149 - ETA: 51s - loss: 3.2910 - accuracy: 0.149 - ETA: 50s - loss: 3.2901 - accuracy: 0.149 - ETA: 49s - loss: 3.2903 - accuracy: 0.149 - ETA: 48s - loss: 3.2903 - accuracy: 0.149 - ETA: 47s - loss: 3.2904 - accuracy: 0.149 - ETA: 46s - loss: 3.2904 - accuracy: 0.149 - ETA: 45s - loss: 3.2910 - accuracy: 0.149 - ETA: 45s - loss: 3.2908 - accuracy: 0.149 - ETA: 44s - loss: 3.2912 - accuracy: 0.149 - ETA: 43s - loss: 3.2912 - accuracy: 0.149 - ETA: 42s - loss: 3.2909 - accuracy: 0.149 - ETA: 41s - loss: 3.2910 - accuracy: 0.149 - ETA: 40s - loss: 3.2908 - accuracy: 0.149 - ETA: 39s - loss: 3.2904 - accuracy: 0.149 - ETA: 38s - loss: 3.2933 - accuracy: 0.149 - ETA: 37s - loss: 3.2935 - accuracy: 0.149 - ETA: 36s - loss: 3.2935 - accuracy: 0.149 - ETA: 35s - loss: 3.2934 - accuracy: 0.149 - ETA: 34s - loss: 3.2931 - accuracy: 0.149 - ETA: 33s - loss: 3.2933 - accuracy: 0.149 - ETA: 32s - loss: 3.2928 - accuracy: 0.149 - ETA: 31s - loss: 3.2926 - accuracy: 0.149 - ETA: 30s - loss: 3.2924 - accuracy: 0.149 - ETA: 29s - loss: 3.2922 - accuracy: 0.149 - ETA: 28s - loss: 3.2922 - accuracy: 0.149 - ETA: 27s - loss: 3.2920 - accuracy: 0.149 - ETA: 26s - loss: 3.2919 - accuracy: 0.149 - ETA: 25s - loss: 3.2920 - accuracy: 0.149 - ETA: 24s - loss: 3.2921 - accuracy: 0.149 - ETA: 23s - loss: 3.2920 - accuracy: 0.149 - ETA: 23s - loss: 3.2922 - accuracy: 0.149 - ETA: 22s - loss: 3.2920 - accuracy: 0.149 - ETA: 21s - loss: 3.2922 - accuracy: 0.149 - ETA: 20s - loss: 3.2920 - accuracy: 0.149 - ETA: 19s - loss: 3.2918 - accuracy: 0.149 - ETA: 18s - loss: 3.2916 - accuracy: 0.149 - ETA: 17s - loss: 3.2913 - accuracy: 0.149 - ETA: 16s - loss: 3.2917 - accuracy: 0.149 - ETA: 15s - loss: 3.2919 - accuracy: 0.149 - ETA: 14s - loss: 3.2916 - accuracy: 0.149 - ETA: 13s - loss: 3.2919 - accuracy: 0.150 - ETA: 12s - loss: 3.2918 - accuracy: 0.149 - ETA: 11s - loss: 3.2915 - accuracy: 0.150 - ETA: 10s - loss: 3.2917 - accuracy: 0.150 - ETA: 9s - loss: 3.2920 - accuracy: 0.150 - ETA: 8s - loss: 3.2919 - accuracy: 0.15 - ETA: 7s - loss: 3.2914 - accuracy: 0.15 - ETA: 6s - loss: 3.2921 - accuracy: 0.14 - ETA: 5s - loss: 3.2919 - accuracy: 0.14 - ETA: 4s - loss: 3.2916 - accuracy: 0.14 - ETA: 3s - loss: 3.2915 - accuracy: 0.14 - ETA: 2s - loss: 3.2914 - accuracy: 0.15 - ETA: 1s - loss: 3.2915 - accuracy: 0.15 - ETA: 1s - loss: 3.2913 - accuracy: 0.15 - ETA: 0s - loss: 3.2913 - accuracy: 0.15 - 341s 8ms/step - loss: 3.2914 - accuracy: 0.1501 - val_loss: 3.9114 - val_accuracy: 0.0224\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:27 - loss: 3.3999 - accuracy: 0.15 - ETA: 5:34 - loss: 3.3464 - accuracy: 0.14 - ETA: 5:27 - loss: 3.3317 - accuracy: 0.13 - ETA: 5:18 - loss: 3.3241 - accuracy: 0.12 - ETA: 5:15 - loss: 3.2992 - accuracy: 0.14 - ETA: 5:14 - loss: 3.2737 - accuracy: 0.14 - ETA: 5:15 - loss: 3.2712 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3532 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3474 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3313 - accuracy: 0.15 - ETA: 5:10 - loss: 3.3405 - accuracy: 0.14 - ETA: 5:07 - loss: 3.3379 - accuracy: 0.14 - ETA: 5:05 - loss: 3.3363 - accuracy: 0.14 - ETA: 5:04 - loss: 3.3378 - accuracy: 0.14 - ETA: 5:03 - loss: 3.3335 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3249 - accuracy: 0.14 - ETA: 5:01 - loss: 3.3167 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3084 - accuracy: 0.14 - ETA: 5:01 - loss: 3.3008 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3079 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3080 - accuracy: 0.14 - ETA: 4:58 - loss: 3.3066 - accuracy: 0.14 - ETA: 4:56 - loss: 3.2990 - accuracy: 0.14 - ETA: 4:55 - loss: 3.2917 - accuracy: 0.14 - ETA: 4:55 - loss: 3.2892 - accuracy: 0.14 - ETA: 4:54 - loss: 3.2866 - accuracy: 0.14 - ETA: 4:53 - loss: 3.2865 - accuracy: 0.14 - ETA: 4:51 - loss: 3.2796 - accuracy: 0.14 - ETA: 4:49 - loss: 3.2774 - accuracy: 0.14 - ETA: 4:48 - loss: 3.2707 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2644 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2640 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2632 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2608 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2600 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2592 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2563 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2502 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2471 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2480 - accuracy: 0.16 - ETA: 4:37 - loss: 3.2454 - accuracy: 0.16 - ETA: 4:36 - loss: 3.2404 - accuracy: 0.16 - ETA: 4:35 - loss: 3.2419 - accuracy: 0.16 - ETA: 4:33 - loss: 3.2464 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2470 - accuracy: 0.15 - ETA: 4:31 - loss: 3.2472 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2494 - accuracy: 0.15 - ETA: 4:29 - loss: 3.2486 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2510 - accuracy: 0.15 - ETA: 4:27 - loss: 3.2508 - accuracy: 0.15 - ETA: 4:27 - loss: 3.2521 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2498 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2520 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2503 - accuracy: 0.16 - ETA: 4:23 - loss: 3.2542 - accuracy: 0.15 - ETA: 4:22 - loss: 3.2570 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2583 - accuracy: 0.15 - ETA: 4:20 - loss: 3.2555 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2581 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2573 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2609 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2602 - accuracy: 0.15 - ETA: 4:15 - loss: 3.2588 - accuracy: 0.15 - ETA: 4:14 - loss: 3.2617 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2607 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2627 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2643 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2658 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2664 - accuracy: 0.15 - ETA: 4:09 - loss: 3.2678 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2668 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2686 - accuracy: 0.15 - ETA: 4:06 - loss: 3.2710 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2732 - accuracy: 0.15 - ETA: 4:04 - loss: 3.2731 - accuracy: 0.15 - ETA: 4:03 - loss: 3.2741 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2742 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2753 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2775 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2763 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2790 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2781 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2776 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2766 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2759 - accuracy: 0.15 - ETA: 3:54 - loss: 3.2784 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2788 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2800 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2799 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2810 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2828 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2843 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2852 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2858 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2876 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2892 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2887 - accuracy: 0.15 - ETA: 3:42 - loss: 3.2896 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2905 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2901 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2911 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2904 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2911 - accuracy: 0.15 - ETA: 3:37 - loss: 3.2896 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2922 - accuracy: 0.14 - ETA: 3:35 - loss: 3.2929 - accuracy: 0.14 - ETA: 3:34 - loss: 3.2922 - accuracy: 0.14 - ETA: 3:33 - loss: 3.2938 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2947 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2955 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2945 - accuracy: 0.14 - ETA: 3:29 - loss: 3.2947 - accuracy: 0.14 - ETA: 3:28 - loss: 3.2957 - accuracy: 0.14 - ETA: 3:27 - loss: 3.2940 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2947 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2937 - accuracy: 0.14 - ETA: 3:25 - loss: 3.2929 - accuracy: 0.14 - ETA: 3:24 - loss: 3.2944 - accuracy: 0.14 - ETA: 3:23 - loss: 3.2947 - accuracy: 0.14 - ETA: 3:22 - loss: 3.2935 - accuracy: 0.14 - ETA: 3:21 - loss: 3.2947 - accuracy: 0.14 - ETA: 3:20 - loss: 3.2942 - accuracy: 0.14 - ETA: 3:19 - loss: 3.2935 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2947 - accuracy: 0.14 - ETA: 3:17 - loss: 3.2966 - accuracy: 0.14 - ETA: 3:16 - loss: 3.2961 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2960 - accuracy: 0.14 - ETA: 3:14 - loss: 3.2964 - accuracy: 0.14 - ETA: 3:13 - loss: 3.2963 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2967 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2960 - accuracy: 0.14 - ETA: 3:10 - loss: 3.2956 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2956 - accuracy: 0.14 - ETA: 3:08 - loss: 3.2955 - accuracy: 0.14 - ETA: 3:07 - loss: 3.2959 - accuracy: 0.14 - ETA: 3:06 - loss: 3.2955 - accuracy: 0.14 - ETA: 3:05 - loss: 3.2972 - accuracy: 0.14 - ETA: 3:04 - loss: 3.2979 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2969 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2965 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2963 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2956 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2954 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2958 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2962 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2959 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2954 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2952 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2948 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2953 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2952 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2958 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2960 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2944 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2948 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2940 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2942 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2935 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2938 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2945 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2948 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2942 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2943 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2941 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2951 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2950 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2942 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2948 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2941 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2949 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2923 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2922 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2920 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2926 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2925 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2923 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2926 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2931 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2940 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2937 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2938 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2935 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2935 - accuracy: 0.1468"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.2930 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2930 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2932 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2925 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2921 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2919 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2916 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2916 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2916 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2907 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2902 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2904 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2904 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2911 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2912 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2910 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2906 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2904 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2901 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2899 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2899 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2892 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2889 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2889 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2886 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2878 - accuracy: 0.14 - ETA: 1:53 - loss: 3.2874 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2874 - accuracy: 0.14 - ETA: 1:51 - loss: 3.2876 - accuracy: 0.14 - ETA: 1:50 - loss: 3.2872 - accuracy: 0.14 - ETA: 1:49 - loss: 3.2874 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2876 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2879 - accuracy: 0.14 - ETA: 1:46 - loss: 3.2864 - accuracy: 0.14 - ETA: 1:45 - loss: 3.2866 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2864 - accuracy: 0.14 - ETA: 1:43 - loss: 3.2861 - accuracy: 0.14 - ETA: 1:42 - loss: 3.2861 - accuracy: 0.14 - ETA: 1:41 - loss: 3.2866 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2866 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2870 - accuracy: 0.14 - ETA: 1:38 - loss: 3.2868 - accuracy: 0.14 - ETA: 1:37 - loss: 3.2864 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2868 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2867 - accuracy: 0.14 - ETA: 1:35 - loss: 3.2864 - accuracy: 0.14 - ETA: 1:34 - loss: 3.2864 - accuracy: 0.14 - ETA: 1:33 - loss: 3.2867 - accuracy: 0.14 - ETA: 1:32 - loss: 3.2864 - accuracy: 0.14 - ETA: 1:31 - loss: 3.2856 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2847 - accuracy: 0.14 - ETA: 1:29 - loss: 3.2856 - accuracy: 0.14 - ETA: 1:28 - loss: 3.2860 - accuracy: 0.14 - ETA: 1:27 - loss: 3.2855 - accuracy: 0.14 - ETA: 1:26 - loss: 3.2850 - accuracy: 0.14 - ETA: 1:25 - loss: 3.2846 - accuracy: 0.14 - ETA: 1:24 - loss: 3.2844 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2839 - accuracy: 0.14 - ETA: 1:22 - loss: 3.2830 - accuracy: 0.14 - ETA: 1:21 - loss: 3.2825 - accuracy: 0.14 - ETA: 1:20 - loss: 3.2830 - accuracy: 0.14 - ETA: 1:19 - loss: 3.2821 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2823 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2831 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2852 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2854 - accuracy: 0.14 - ETA: 1:14 - loss: 3.2857 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2858 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2858 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2865 - accuracy: 0.14 - ETA: 1:11 - loss: 3.2863 - accuracy: 0.14 - ETA: 1:10 - loss: 3.2859 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2856 - accuracy: 0.14 - ETA: 1:08 - loss: 3.2856 - accuracy: 0.14 - ETA: 1:07 - loss: 3.2859 - accuracy: 0.14 - ETA: 1:06 - loss: 3.2859 - accuracy: 0.14 - ETA: 1:05 - loss: 3.2862 - accuracy: 0.14 - ETA: 1:04 - loss: 3.2861 - accuracy: 0.14 - ETA: 1:03 - loss: 3.2860 - accuracy: 0.14 - ETA: 1:02 - loss: 3.2859 - accuracy: 0.14 - ETA: 1:01 - loss: 3.2861 - accuracy: 0.14 - ETA: 1:00 - loss: 3.2857 - accuracy: 0.14 - ETA: 59s - loss: 3.2853 - accuracy: 0.1492 - ETA: 58s - loss: 3.2847 - accuracy: 0.149 - ETA: 57s - loss: 3.2845 - accuracy: 0.149 - ETA: 56s - loss: 3.2845 - accuracy: 0.149 - ETA: 55s - loss: 3.2837 - accuracy: 0.149 - ETA: 54s - loss: 3.2838 - accuracy: 0.149 - ETA: 53s - loss: 3.2843 - accuracy: 0.148 - ETA: 52s - loss: 3.2843 - accuracy: 0.149 - ETA: 51s - loss: 3.2837 - accuracy: 0.149 - ETA: 50s - loss: 3.2838 - accuracy: 0.149 - ETA: 49s - loss: 3.2839 - accuracy: 0.149 - ETA: 49s - loss: 3.2845 - accuracy: 0.149 - ETA: 48s - loss: 3.2848 - accuracy: 0.149 - ETA: 47s - loss: 3.2852 - accuracy: 0.149 - ETA: 46s - loss: 3.2853 - accuracy: 0.149 - ETA: 45s - loss: 3.2852 - accuracy: 0.149 - ETA: 44s - loss: 3.2855 - accuracy: 0.149 - ETA: 43s - loss: 3.2858 - accuracy: 0.149 - ETA: 42s - loss: 3.2859 - accuracy: 0.149 - ETA: 41s - loss: 3.2860 - accuracy: 0.149 - ETA: 40s - loss: 3.2862 - accuracy: 0.148 - ETA: 39s - loss: 3.2859 - accuracy: 0.149 - ETA: 38s - loss: 3.2853 - accuracy: 0.149 - ETA: 37s - loss: 3.2851 - accuracy: 0.149 - ETA: 36s - loss: 3.2844 - accuracy: 0.149 - ETA: 35s - loss: 3.2842 - accuracy: 0.149 - ETA: 34s - loss: 3.2840 - accuracy: 0.149 - ETA: 33s - loss: 3.2837 - accuracy: 0.149 - ETA: 32s - loss: 3.2840 - accuracy: 0.149 - ETA: 31s - loss: 3.2838 - accuracy: 0.149 - ETA: 30s - loss: 3.2837 - accuracy: 0.149 - ETA: 29s - loss: 3.2834 - accuracy: 0.149 - ETA: 28s - loss: 3.2836 - accuracy: 0.148 - ETA: 27s - loss: 3.2836 - accuracy: 0.148 - ETA: 26s - loss: 3.2830 - accuracy: 0.148 - ETA: 25s - loss: 3.2828 - accuracy: 0.148 - ETA: 25s - loss: 3.2828 - accuracy: 0.148 - ETA: 24s - loss: 3.2826 - accuracy: 0.148 - ETA: 23s - loss: 3.2829 - accuracy: 0.148 - ETA: 22s - loss: 3.2824 - accuracy: 0.149 - ETA: 21s - loss: 3.2828 - accuracy: 0.149 - ETA: 20s - loss: 3.2836 - accuracy: 0.148 - ETA: 19s - loss: 3.2838 - accuracy: 0.148 - ETA: 18s - loss: 3.2839 - accuracy: 0.148 - ETA: 17s - loss: 3.2843 - accuracy: 0.148 - ETA: 16s - loss: 3.2850 - accuracy: 0.148 - ETA: 15s - loss: 3.2851 - accuracy: 0.148 - ETA: 14s - loss: 3.2853 - accuracy: 0.148 - ETA: 13s - loss: 3.2860 - accuracy: 0.148 - ETA: 12s - loss: 3.2865 - accuracy: 0.148 - ETA: 11s - loss: 3.2864 - accuracy: 0.148 - ETA: 10s - loss: 3.2866 - accuracy: 0.148 - ETA: 9s - loss: 3.2869 - accuracy: 0.148 - ETA: 8s - loss: 3.2866 - accuracy: 0.14 - ETA: 7s - loss: 3.2867 - accuracy: 0.14 - ETA: 6s - loss: 3.2872 - accuracy: 0.14 - ETA: 5s - loss: 3.2882 - accuracy: 0.14 - ETA: 4s - loss: 3.2886 - accuracy: 0.14 - ETA: 3s - loss: 3.2885 - accuracy: 0.14 - ETA: 2s - loss: 3.2884 - accuracy: 0.14 - ETA: 1s - loss: 3.2880 - accuracy: 0.14 - ETA: 1s - loss: 3.2878 - accuracy: 0.14 - ETA: 0s - loss: 3.2886 - accuracy: 0.14 - 342s 8ms/step - loss: 3.2885 - accuracy: 0.1484 - val_loss: 3.9139 - val_accuracy: 0.0135\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:38 - loss: 3.2167 - accuracy: 0.13 - ETA: 5:33 - loss: 3.3976 - accuracy: 0.11 - ETA: 5:21 - loss: 3.3731 - accuracy: 0.11 - ETA: 5:19 - loss: 3.3436 - accuracy: 0.13 - ETA: 5:11 - loss: 3.3401 - accuracy: 0.14 - ETA: 5:06 - loss: 3.3142 - accuracy: 0.14 - ETA: 5:03 - loss: 3.3210 - accuracy: 0.14 - ETA: 5:03 - loss: 3.3162 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3142 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3319 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3352 - accuracy: 0.13 - ETA: 4:59 - loss: 3.3183 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3088 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3085 - accuracy: 0.15 - ETA: 4:58 - loss: 3.3126 - accuracy: 0.15 - ETA: 4:57 - loss: 3.3175 - accuracy: 0.15 - ETA: 4:57 - loss: 3.3133 - accuracy: 0.15 - ETA: 4:57 - loss: 3.3099 - accuracy: 0.15 - ETA: 4:57 - loss: 3.3085 - accuracy: 0.15 - ETA: 4:56 - loss: 3.3133 - accuracy: 0.15 - ETA: 4:56 - loss: 3.3157 - accuracy: 0.15 - ETA: 4:55 - loss: 3.3158 - accuracy: 0.15 - ETA: 4:54 - loss: 3.3186 - accuracy: 0.15 - ETA: 4:53 - loss: 3.3203 - accuracy: 0.15 - ETA: 4:52 - loss: 3.3197 - accuracy: 0.15 - ETA: 4:50 - loss: 3.3233 - accuracy: 0.15 - ETA: 4:50 - loss: 3.3168 - accuracy: 0.15 - ETA: 4:49 - loss: 3.3155 - accuracy: 0.15 - ETA: 4:48 - loss: 3.3162 - accuracy: 0.15 - ETA: 4:47 - loss: 3.3158 - accuracy: 0.15 - ETA: 4:46 - loss: 3.3180 - accuracy: 0.15 - ETA: 4:45 - loss: 3.3076 - accuracy: 0.15 - ETA: 4:43 - loss: 3.3096 - accuracy: 0.15 - ETA: 4:42 - loss: 3.3038 - accuracy: 0.15 - ETA: 4:41 - loss: 3.3023 - accuracy: 0.15 - ETA: 4:40 - loss: 3.3037 - accuracy: 0.15 - ETA: 4:39 - loss: 3.3065 - accuracy: 0.15 - ETA: 4:38 - loss: 3.3065 - accuracy: 0.15 - ETA: 4:37 - loss: 3.3068 - accuracy: 0.15 - ETA: 4:35 - loss: 3.3088 - accuracy: 0.15 - ETA: 4:35 - loss: 3.3094 - accuracy: 0.15 - ETA: 4:34 - loss: 3.3074 - accuracy: 0.15 - ETA: 4:33 - loss: 3.3034 - accuracy: 0.15 - ETA: 4:33 - loss: 3.3005 - accuracy: 0.15 - ETA: 4:32 - loss: 3.3036 - accuracy: 0.15 - ETA: 4:32 - loss: 3.3085 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3062 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3070 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3004 - accuracy: 0.15 - ETA: 4:28 - loss: 3.3003 - accuracy: 0.15 - ETA: 4:27 - loss: 3.3056 - accuracy: 0.14 - ETA: 4:27 - loss: 3.3025 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3020 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3016 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3006 - accuracy: 0.15 - ETA: 4:23 - loss: 3.3021 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3000 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3009 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3027 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3015 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3001 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3003 - accuracy: 0.14 - ETA: 4:17 - loss: 3.2977 - accuracy: 0.14 - ETA: 4:16 - loss: 3.2983 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3008 - accuracy: 0.14 - ETA: 4:14 - loss: 3.2988 - accuracy: 0.14 - ETA: 4:13 - loss: 3.2963 - accuracy: 0.14 - ETA: 4:12 - loss: 3.2941 - accuracy: 0.14 - ETA: 4:11 - loss: 3.2947 - accuracy: 0.14 - ETA: 4:10 - loss: 3.2956 - accuracy: 0.14 - ETA: 4:09 - loss: 3.2974 - accuracy: 0.14 - ETA: 4:08 - loss: 3.2973 - accuracy: 0.14 - ETA: 4:07 - loss: 3.2985 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3001 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3004 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3013 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3019 - accuracy: 0.14 - ETA: 4:02 - loss: 3.2992 - accuracy: 0.14 - ETA: 4:02 - loss: 3.2998 - accuracy: 0.14 - ETA: 4:01 - loss: 3.2998 - accuracy: 0.14 - ETA: 3:59 - loss: 3.2989 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3019 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3034 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3038 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3043 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3052 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3040 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3049 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3046 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3035 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3032 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3019 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3028 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3052 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3035 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3008 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3003 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3005 - accuracy: 0.14 - ETA: 3:43 - loss: 3.2992 - accuracy: 0.14 - ETA: 3:42 - loss: 3.2996 - accuracy: 0.14 - ETA: 3:42 - loss: 3.2994 - accuracy: 0.14 - ETA: 3:40 - loss: 3.2991 - accuracy: 0.14 - ETA: 3:39 - loss: 3.2988 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2993 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2985 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2987 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3006 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3002 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3004 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2997 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2993 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2993 - accuracy: 0.14 - ETA: 3:29 - loss: 3.2993 - accuracy: 0.14 - ETA: 3:28 - loss: 3.2978 - accuracy: 0.14 - ETA: 3:27 - loss: 3.2973 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2955 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2952 - accuracy: 0.14 - ETA: 3:25 - loss: 3.2942 - accuracy: 0.14 - ETA: 3:24 - loss: 3.2936 - accuracy: 0.14 - ETA: 3:23 - loss: 3.2937 - accuracy: 0.14 - ETA: 3:22 - loss: 3.2920 - accuracy: 0.14 - ETA: 3:21 - loss: 3.2908 - accuracy: 0.14 - ETA: 3:20 - loss: 3.2907 - accuracy: 0.14 - ETA: 3:19 - loss: 3.2906 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2905 - accuracy: 0.14 - ETA: 3:17 - loss: 3.2899 - accuracy: 0.14 - ETA: 3:16 - loss: 3.2890 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2880 - accuracy: 0.14 - ETA: 3:14 - loss: 3.2884 - accuracy: 0.14 - ETA: 3:13 - loss: 3.2903 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2891 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2895 - accuracy: 0.14 - ETA: 3:10 - loss: 3.2884 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2887 - accuracy: 0.14 - ETA: 3:08 - loss: 3.2888 - accuracy: 0.14 - ETA: 3:07 - loss: 3.2889 - accuracy: 0.14 - ETA: 3:06 - loss: 3.2878 - accuracy: 0.14 - ETA: 3:05 - loss: 3.2874 - accuracy: 0.14 - ETA: 3:04 - loss: 3.2881 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2882 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2895 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2891 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2910 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2909 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2899 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2902 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2895 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2886 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2891 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2887 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2886 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2888 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2887 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2878 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2877 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2878 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2887 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2881 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2880 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2883 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2901 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2903 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2912 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2898 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2895 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2885 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2874 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2864 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2859 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2857 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2853 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2849 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2842 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2842 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2843 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2840 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2840 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2846 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2848 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2854 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2851 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2846 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2834 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2831 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2839 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2844 - accuracy: 0.1502"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.2838 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2839 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2847 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2847 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2846 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2849 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2858 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2856 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2849 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2849 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2854 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2855 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2864 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2866 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2866 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2863 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2860 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2852 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2849 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2849 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2847 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2844 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2845 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2853 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2858 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2869 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2880 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2876 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2880 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2880 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2870 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2870 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2870 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2877 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2871 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2871 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2874 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2876 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2872 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2879 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2883 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2884 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2884 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2886 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2890 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2891 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2893 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2894 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2897 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2897 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2887 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2886 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2887 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2887 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2890 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2891 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2894 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2891 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2886 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2885 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2885 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2888 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2890 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2894 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2896 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2901 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2910 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2909 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2915 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2918 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2910 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2909 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2913 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2915 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2908 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2915 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2913 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2909 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2902 - accuracy: 0.15 - ETA: 59s - loss: 3.2897 - accuracy: 0.1513 - ETA: 58s - loss: 3.2899 - accuracy: 0.151 - ETA: 57s - loss: 3.2904 - accuracy: 0.151 - ETA: 56s - loss: 3.2902 - accuracy: 0.151 - ETA: 55s - loss: 3.2904 - accuracy: 0.151 - ETA: 54s - loss: 3.2898 - accuracy: 0.151 - ETA: 53s - loss: 3.2894 - accuracy: 0.151 - ETA: 52s - loss: 3.2891 - accuracy: 0.151 - ETA: 52s - loss: 3.2893 - accuracy: 0.151 - ETA: 51s - loss: 3.2889 - accuracy: 0.151 - ETA: 50s - loss: 3.2893 - accuracy: 0.151 - ETA: 49s - loss: 3.2892 - accuracy: 0.151 - ETA: 48s - loss: 3.2887 - accuracy: 0.151 - ETA: 47s - loss: 3.2885 - accuracy: 0.151 - ETA: 46s - loss: 3.2881 - accuracy: 0.151 - ETA: 45s - loss: 3.2877 - accuracy: 0.151 - ETA: 44s - loss: 3.2876 - accuracy: 0.151 - ETA: 43s - loss: 3.2875 - accuracy: 0.151 - ETA: 42s - loss: 3.2879 - accuracy: 0.151 - ETA: 41s - loss: 3.2880 - accuracy: 0.151 - ETA: 40s - loss: 3.2877 - accuracy: 0.151 - ETA: 39s - loss: 3.2882 - accuracy: 0.151 - ETA: 38s - loss: 3.2876 - accuracy: 0.151 - ETA: 37s - loss: 3.2872 - accuracy: 0.151 - ETA: 36s - loss: 3.2863 - accuracy: 0.151 - ETA: 35s - loss: 3.2855 - accuracy: 0.151 - ETA: 34s - loss: 3.2855 - accuracy: 0.151 - ETA: 33s - loss: 3.2853 - accuracy: 0.151 - ETA: 32s - loss: 3.2850 - accuracy: 0.152 - ETA: 31s - loss: 3.2851 - accuracy: 0.152 - ETA: 30s - loss: 3.2852 - accuracy: 0.152 - ETA: 29s - loss: 3.2851 - accuracy: 0.152 - ETA: 28s - loss: 3.2854 - accuracy: 0.152 - ETA: 27s - loss: 3.2855 - accuracy: 0.151 - ETA: 27s - loss: 3.2855 - accuracy: 0.152 - ETA: 26s - loss: 3.2852 - accuracy: 0.152 - ETA: 25s - loss: 3.2852 - accuracy: 0.151 - ETA: 24s - loss: 3.2849 - accuracy: 0.152 - ETA: 23s - loss: 3.2849 - accuracy: 0.152 - ETA: 22s - loss: 3.2848 - accuracy: 0.152 - ETA: 21s - loss: 3.2848 - accuracy: 0.152 - ETA: 20s - loss: 3.2844 - accuracy: 0.152 - ETA: 19s - loss: 3.2840 - accuracy: 0.152 - ETA: 18s - loss: 3.2843 - accuracy: 0.152 - ETA: 17s - loss: 3.2840 - accuracy: 0.152 - ETA: 16s - loss: 3.2834 - accuracy: 0.152 - ETA: 15s - loss: 3.2832 - accuracy: 0.152 - ETA: 14s - loss: 3.2832 - accuracy: 0.152 - ETA: 13s - loss: 3.2826 - accuracy: 0.152 - ETA: 12s - loss: 3.2820 - accuracy: 0.152 - ETA: 11s - loss: 3.2822 - accuracy: 0.152 - ETA: 10s - loss: 3.2825 - accuracy: 0.152 - ETA: 9s - loss: 3.2828 - accuracy: 0.152 - ETA: 8s - loss: 3.2835 - accuracy: 0.15 - ETA: 7s - loss: 3.2837 - accuracy: 0.15 - ETA: 6s - loss: 3.2830 - accuracy: 0.15 - ETA: 5s - loss: 3.2828 - accuracy: 0.15 - ETA: 4s - loss: 3.2834 - accuracy: 0.15 - ETA: 3s - loss: 3.2839 - accuracy: 0.15 - ETA: 2s - loss: 3.2833 - accuracy: 0.15 - ETA: 1s - loss: 3.2831 - accuracy: 0.15 - ETA: 1s - loss: 3.2833 - accuracy: 0.15 - ETA: 0s - loss: 3.2836 - accuracy: 0.15 - 342s 8ms/step - loss: 3.2837 - accuracy: 0.1518 - val_loss: 3.9375 - val_accuracy: 0.0209\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:06 - loss: 2.9524 - accuracy: 0.25 - ETA: 5:09 - loss: 3.1106 - accuracy: 0.20 - ETA: 5:06 - loss: 3.1598 - accuracy: 0.19 - ETA: 5:03 - loss: 3.1625 - accuracy: 0.19 - ETA: 5:10 - loss: 3.1769 - accuracy: 0.17 - ETA: 5:10 - loss: 3.1943 - accuracy: 0.17 - ETA: 5:13 - loss: 3.2129 - accuracy: 0.16 - ETA: 5:12 - loss: 3.2041 - accuracy: 0.16 - ETA: 5:13 - loss: 3.2140 - accuracy: 0.16 - ETA: 5:13 - loss: 3.2138 - accuracy: 0.16 - ETA: 5:11 - loss: 3.2283 - accuracy: 0.16 - ETA: 5:09 - loss: 3.2385 - accuracy: 0.16 - ETA: 5:10 - loss: 3.2432 - accuracy: 0.16 - ETA: 5:07 - loss: 3.2360 - accuracy: 0.16 - ETA: 5:05 - loss: 3.2421 - accuracy: 0.16 - ETA: 5:04 - loss: 3.2225 - accuracy: 0.16 - ETA: 5:02 - loss: 3.2356 - accuracy: 0.16 - ETA: 5:01 - loss: 3.2478 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2596 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2595 - accuracy: 0.16 - ETA: 4:58 - loss: 3.2493 - accuracy: 0.16 - ETA: 4:56 - loss: 3.2447 - accuracy: 0.16 - ETA: 4:56 - loss: 3.2452 - accuracy: 0.16 - ETA: 4:56 - loss: 3.2354 - accuracy: 0.16 - ETA: 4:54 - loss: 3.2417 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2405 - accuracy: 0.16 - ETA: 4:52 - loss: 3.2382 - accuracy: 0.16 - ETA: 4:51 - loss: 3.2388 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2367 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2447 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2467 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2443 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2489 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2478 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2472 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2495 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2529 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2549 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2546 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2584 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2597 - accuracy: 0.15 - ETA: 4:37 - loss: 3.2580 - accuracy: 0.15 - ETA: 4:36 - loss: 3.2626 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2635 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2644 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2613 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2650 - accuracy: 0.15 - ETA: 4:31 - loss: 3.2668 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2687 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2698 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2691 - accuracy: 0.15 - ETA: 4:27 - loss: 3.2659 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2647 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2641 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2625 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2659 - accuracy: 0.15 - ETA: 4:23 - loss: 3.2685 - accuracy: 0.15 - ETA: 4:22 - loss: 3.2675 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2652 - accuracy: 0.15 - ETA: 4:20 - loss: 3.2650 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2645 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2675 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2657 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2653 - accuracy: 0.15 - ETA: 4:15 - loss: 3.2679 - accuracy: 0.15 - ETA: 4:14 - loss: 3.2659 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2659 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2681 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2699 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2681 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2719 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2724 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2732 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2736 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2757 - accuracy: 0.15 - ETA: 4:04 - loss: 3.2767 - accuracy: 0.15 - ETA: 4:03 - loss: 3.2765 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2761 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2782 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2784 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2780 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2778 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2769 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2756 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2761 - accuracy: 0.15 - ETA: 3:54 - loss: 3.2770 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2782 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2760 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2736 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2723 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2706 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2689 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2704 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2704 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2704 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2694 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2688 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2686 - accuracy: 0.15 - ETA: 3:42 - loss: 3.2684 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2667 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2677 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2707 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2708 - accuracy: 0.15 - ETA: 3:37 - loss: 3.2710 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2695 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2678 - accuracy: 0.15 - ETA: 3:34 - loss: 3.2680 - accuracy: 0.15 - ETA: 3:33 - loss: 3.2660 - accuracy: 0.15 - ETA: 3:32 - loss: 3.2646 - accuracy: 0.15 - ETA: 3:31 - loss: 3.2648 - accuracy: 0.15 - ETA: 3:31 - loss: 3.2645 - accuracy: 0.15 - ETA: 3:30 - loss: 3.2636 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2639 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2637 - accuracy: 0.15 - ETA: 3:27 - loss: 3.2630 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2633 - accuracy: 0.15 - ETA: 3:25 - loss: 3.2640 - accuracy: 0.15 - ETA: 3:24 - loss: 3.2615 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2617 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2591 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2579 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2566 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2560 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2547 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2562 - accuracy: 0.15 - ETA: 3:17 - loss: 3.2552 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2538 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2532 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2531 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2522 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2525 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2527 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2528 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2525 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2518 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2518 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2521 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2528 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2518 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2524 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2527 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2528 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2532 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2540 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2540 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2543 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2544 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2548 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2553 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2575 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2575 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2578 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2579 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2585 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2589 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2580 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2584 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2598 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2606 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2613 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2607 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2616 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2608 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2615 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2609 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2607 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2616 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2619 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2633 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2632 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2630 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2637 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2636 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2627 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2629 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2623 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2635 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2643 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2638 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2641 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2636 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2637 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2641 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2643 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2642 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2653 - accuracy: 0.1548"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.2651 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2650 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2650 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2650 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2647 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2649 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2649 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2653 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2646 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2644 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2645 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2636 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2631 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2628 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2625 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2621 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2631 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2644 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2648 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2643 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2643 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2645 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2650 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2652 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2657 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2651 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2658 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2658 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2657 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2661 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2662 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2666 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2661 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2658 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2658 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2648 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2656 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2646 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2643 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2636 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2633 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2633 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2630 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2624 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2642 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2643 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2641 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2636 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2634 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2642 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2642 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2650 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2646 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2648 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2655 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2657 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2663 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2670 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2666 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2660 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2664 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2661 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2663 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2662 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2654 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2654 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2650 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2646 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2651 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2653 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2650 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2650 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2652 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2647 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2651 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2651 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2657 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2645 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2647 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2652 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2654 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2658 - accuracy: 0.15 - ETA: 59s - loss: 3.2662 - accuracy: 0.1558 - ETA: 58s - loss: 3.2666 - accuracy: 0.155 - ETA: 57s - loss: 3.2667 - accuracy: 0.156 - ETA: 56s - loss: 3.2670 - accuracy: 0.156 - ETA: 55s - loss: 3.2667 - accuracy: 0.156 - ETA: 54s - loss: 3.2672 - accuracy: 0.155 - ETA: 53s - loss: 3.2667 - accuracy: 0.156 - ETA: 52s - loss: 3.2666 - accuracy: 0.156 - ETA: 51s - loss: 3.2671 - accuracy: 0.155 - ETA: 50s - loss: 3.2668 - accuracy: 0.155 - ETA: 49s - loss: 3.2668 - accuracy: 0.155 - ETA: 48s - loss: 3.2669 - accuracy: 0.155 - ETA: 47s - loss: 3.2671 - accuracy: 0.155 - ETA: 46s - loss: 3.2677 - accuracy: 0.155 - ETA: 46s - loss: 3.2682 - accuracy: 0.155 - ETA: 45s - loss: 3.2685 - accuracy: 0.155 - ETA: 44s - loss: 3.2687 - accuracy: 0.155 - ETA: 43s - loss: 3.2685 - accuracy: 0.155 - ETA: 42s - loss: 3.2691 - accuracy: 0.155 - ETA: 41s - loss: 3.2690 - accuracy: 0.155 - ETA: 40s - loss: 3.2690 - accuracy: 0.155 - ETA: 39s - loss: 3.2691 - accuracy: 0.155 - ETA: 38s - loss: 3.2697 - accuracy: 0.155 - ETA: 37s - loss: 3.2695 - accuracy: 0.155 - ETA: 36s - loss: 3.2692 - accuracy: 0.155 - ETA: 35s - loss: 3.2684 - accuracy: 0.155 - ETA: 34s - loss: 3.2687 - accuracy: 0.155 - ETA: 33s - loss: 3.2687 - accuracy: 0.155 - ETA: 32s - loss: 3.2688 - accuracy: 0.155 - ETA: 31s - loss: 3.2692 - accuracy: 0.155 - ETA: 30s - loss: 3.2697 - accuracy: 0.155 - ETA: 29s - loss: 3.2697 - accuracy: 0.155 - ETA: 28s - loss: 3.2696 - accuracy: 0.155 - ETA: 27s - loss: 3.2691 - accuracy: 0.155 - ETA: 26s - loss: 3.2694 - accuracy: 0.155 - ETA: 25s - loss: 3.2693 - accuracy: 0.155 - ETA: 24s - loss: 3.2695 - accuracy: 0.155 - ETA: 24s - loss: 3.2696 - accuracy: 0.155 - ETA: 23s - loss: 3.2700 - accuracy: 0.155 - ETA: 22s - loss: 3.2693 - accuracy: 0.155 - ETA: 21s - loss: 3.2696 - accuracy: 0.155 - ETA: 20s - loss: 3.2696 - accuracy: 0.155 - ETA: 19s - loss: 3.2700 - accuracy: 0.155 - ETA: 18s - loss: 3.2704 - accuracy: 0.155 - ETA: 17s - loss: 3.2699 - accuracy: 0.155 - ETA: 16s - loss: 3.2703 - accuracy: 0.155 - ETA: 15s - loss: 3.2706 - accuracy: 0.155 - ETA: 14s - loss: 3.2700 - accuracy: 0.155 - ETA: 13s - loss: 3.2701 - accuracy: 0.155 - ETA: 12s - loss: 3.2706 - accuracy: 0.155 - ETA: 11s - loss: 3.2709 - accuracy: 0.155 - ETA: 10s - loss: 3.2712 - accuracy: 0.155 - ETA: 9s - loss: 3.2712 - accuracy: 0.155 - ETA: 8s - loss: 3.2722 - accuracy: 0.15 - ETA: 7s - loss: 3.2723 - accuracy: 0.15 - ETA: 6s - loss: 3.2721 - accuracy: 0.15 - ETA: 5s - loss: 3.2720 - accuracy: 0.15 - ETA: 4s - loss: 3.2722 - accuracy: 0.15 - ETA: 3s - loss: 3.2723 - accuracy: 0.15 - ETA: 2s - loss: 3.2723 - accuracy: 0.15 - ETA: 1s - loss: 3.2726 - accuracy: 0.15 - ETA: 1s - loss: 3.2719 - accuracy: 0.15 - ETA: 0s - loss: 3.2716 - accuracy: 0.15 - 342s 8ms/step - loss: 3.2715 - accuracy: 0.1547 - val_loss: 3.9699 - val_accuracy: 0.0229\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:24 - loss: 3.3429 - accuracy: 0.11 - ETA: 5:31 - loss: 3.3172 - accuracy: 0.14 - ETA: 5:21 - loss: 3.3067 - accuracy: 0.14 - ETA: 5:21 - loss: 3.2689 - accuracy: 0.15 - ETA: 5:23 - loss: 3.2386 - accuracy: 0.16 - ETA: 5:16 - loss: 3.2294 - accuracy: 0.16 - ETA: 5:15 - loss: 3.2479 - accuracy: 0.16 - ETA: 5:13 - loss: 3.2736 - accuracy: 0.15 - ETA: 5:11 - loss: 3.2859 - accuracy: 0.15 - ETA: 5:08 - loss: 3.2908 - accuracy: 0.15 - ETA: 5:04 - loss: 3.2892 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2884 - accuracy: 0.15 - ETA: 5:00 - loss: 3.3046 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2945 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2857 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2855 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2794 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2797 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2704 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2670 - accuracy: 0.15 - ETA: 4:55 - loss: 3.2689 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2791 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2776 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2782 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2809 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2794 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2752 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2721 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2772 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2815 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2841 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2849 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2846 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2878 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2914 - accuracy: 0.14 - ETA: 4:40 - loss: 3.2914 - accuracy: 0.14 - ETA: 4:40 - loss: 3.2929 - accuracy: 0.14 - ETA: 4:39 - loss: 3.2896 - accuracy: 0.14 - ETA: 4:38 - loss: 3.2926 - accuracy: 0.14 - ETA: 4:38 - loss: 3.2928 - accuracy: 0.14 - ETA: 4:37 - loss: 3.2963 - accuracy: 0.14 - ETA: 4:36 - loss: 3.2908 - accuracy: 0.14 - ETA: 4:35 - loss: 3.2915 - accuracy: 0.14 - ETA: 4:34 - loss: 3.2888 - accuracy: 0.14 - ETA: 4:33 - loss: 3.2849 - accuracy: 0.15 - ETA: 4:33 - loss: 3.2840 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2790 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2770 - accuracy: 0.15 - ETA: 4:29 - loss: 3.2805 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2816 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2835 - accuracy: 0.14 - ETA: 4:27 - loss: 3.2780 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2776 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2751 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2780 - accuracy: 0.15 - ETA: 4:23 - loss: 3.2765 - accuracy: 0.15 - ETA: 4:22 - loss: 3.2748 - accuracy: 0.15 - ETA: 4:22 - loss: 3.2745 - accuracy: 0.15 - ETA: 4:20 - loss: 3.2740 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2702 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2677 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2670 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2673 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2687 - accuracy: 0.15 - ETA: 4:15 - loss: 3.2669 - accuracy: 0.15 - ETA: 4:14 - loss: 3.2690 - accuracy: 0.15 - ETA: 4:14 - loss: 3.2691 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2708 - accuracy: 0.14 - ETA: 4:12 - loss: 3.2725 - accuracy: 0.14 - ETA: 4:11 - loss: 3.2720 - accuracy: 0.14 - ETA: 4:10 - loss: 3.2689 - accuracy: 0.15 - ETA: 4:09 - loss: 3.2687 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2691 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2698 - accuracy: 0.15 - ETA: 4:06 - loss: 3.2698 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2688 - accuracy: 0.15 - ETA: 4:04 - loss: 3.2677 - accuracy: 0.15 - ETA: 4:03 - loss: 3.2671 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2664 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2679 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2653 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2634 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2648 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2685 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2697 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2674 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2698 - accuracy: 0.15 - ETA: 3:54 - loss: 3.2699 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2705 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2716 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2713 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2713 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2706 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2696 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2719 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2722 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2731 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2745 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2739 - accuracy: 0.15 - ETA: 3:42 - loss: 3.2743 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2759 - accuracy: 0.14 - ETA: 3:40 - loss: 3.2747 - accuracy: 0.14 - ETA: 3:39 - loss: 3.2751 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2736 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2755 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2744 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2742 - accuracy: 0.14 - ETA: 3:34 - loss: 3.2748 - accuracy: 0.14 - ETA: 3:33 - loss: 3.2746 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2747 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2759 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2755 - accuracy: 0.14 - ETA: 3:29 - loss: 3.2768 - accuracy: 0.14 - ETA: 3:28 - loss: 3.2764 - accuracy: 0.14 - ETA: 3:27 - loss: 3.2770 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2779 - accuracy: 0.14 - ETA: 3:25 - loss: 3.2772 - accuracy: 0.14 - ETA: 3:24 - loss: 3.2786 - accuracy: 0.14 - ETA: 3:24 - loss: 3.2791 - accuracy: 0.14 - ETA: 3:23 - loss: 3.2790 - accuracy: 0.14 - ETA: 3:22 - loss: 3.2792 - accuracy: 0.14 - ETA: 3:21 - loss: 3.2801 - accuracy: 0.14 - ETA: 3:20 - loss: 3.2780 - accuracy: 0.14 - ETA: 3:19 - loss: 3.2767 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2767 - accuracy: 0.14 - ETA: 3:17 - loss: 3.2755 - accuracy: 0.14 - ETA: 3:16 - loss: 3.2762 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2761 - accuracy: 0.14 - ETA: 3:14 - loss: 3.2749 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2746 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2738 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2745 - accuracy: 0.14 - ETA: 3:10 - loss: 3.2748 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2743 - accuracy: 0.14 - ETA: 3:08 - loss: 3.2731 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2733 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2737 - accuracy: 0.14 - ETA: 3:05 - loss: 3.2747 - accuracy: 0.14 - ETA: 3:04 - loss: 3.2747 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2750 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2751 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2763 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2756 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2758 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2764 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2757 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2765 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2776 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2787 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2794 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2784 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2775 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2781 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2782 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2792 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2796 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2810 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2820 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2821 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2819 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2820 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2831 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2847 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2852 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2869 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2878 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2884 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2894 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2900 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2917 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2924 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2934 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2941 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2955 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2957 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2957 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2956 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2962 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2973 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2979 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2988 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2991 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2987 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2983 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2975 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2977 - accuracy: 0.1453"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.2972 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2977 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2978 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2980 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2991 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3001 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2994 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2993 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2992 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2996 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2999 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2996 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3000 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3003 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3008 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3006 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3010 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3003 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3010 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2999 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2997 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2994 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2996 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2999 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3003 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3008 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3013 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3006 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3004 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3003 - accuracy: 0.14 - ETA: 1:49 - loss: 3.2995 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2986 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2983 - accuracy: 0.14 - ETA: 1:46 - loss: 3.2982 - accuracy: 0.14 - ETA: 1:45 - loss: 3.2986 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2987 - accuracy: 0.14 - ETA: 1:43 - loss: 3.2990 - accuracy: 0.14 - ETA: 1:42 - loss: 3.2991 - accuracy: 0.14 - ETA: 1:41 - loss: 3.2991 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2993 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2996 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3000 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3003 - accuracy: 0.14 - ETA: 1:37 - loss: 3.2995 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2998 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3003 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3002 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3006 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3002 - accuracy: 0.14 - ETA: 1:31 - loss: 3.2998 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3010 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3013 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3013 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3016 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3018 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3019 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3015 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3016 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3016 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3012 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3013 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3019 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3020 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3023 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3028 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3020 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3017 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3023 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3027 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3023 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3020 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3016 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3012 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3013 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3006 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3007 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3002 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3001 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3001 - accuracy: 0.14 - ETA: 1:02 - loss: 3.2998 - accuracy: 0.14 - ETA: 1:01 - loss: 3.2999 - accuracy: 0.14 - ETA: 1:00 - loss: 3.2996 - accuracy: 0.14 - ETA: 59s - loss: 3.2997 - accuracy: 0.1481 - ETA: 58s - loss: 3.2993 - accuracy: 0.148 - ETA: 57s - loss: 3.2995 - accuracy: 0.148 - ETA: 56s - loss: 3.2994 - accuracy: 0.147 - ETA: 55s - loss: 3.2990 - accuracy: 0.147 - ETA: 54s - loss: 3.2993 - accuracy: 0.147 - ETA: 53s - loss: 3.2991 - accuracy: 0.147 - ETA: 52s - loss: 3.2988 - accuracy: 0.148 - ETA: 51s - loss: 3.2988 - accuracy: 0.147 - ETA: 50s - loss: 3.2982 - accuracy: 0.148 - ETA: 50s - loss: 3.2984 - accuracy: 0.148 - ETA: 49s - loss: 3.2987 - accuracy: 0.147 - ETA: 48s - loss: 3.2976 - accuracy: 0.148 - ETA: 47s - loss: 3.2968 - accuracy: 0.148 - ETA: 46s - loss: 3.2969 - accuracy: 0.148 - ETA: 45s - loss: 3.2972 - accuracy: 0.148 - ETA: 44s - loss: 3.2972 - accuracy: 0.148 - ETA: 43s - loss: 3.2970 - accuracy: 0.148 - ETA: 42s - loss: 3.2974 - accuracy: 0.148 - ETA: 41s - loss: 3.2964 - accuracy: 0.148 - ETA: 40s - loss: 3.2960 - accuracy: 0.148 - ETA: 39s - loss: 3.2958 - accuracy: 0.148 - ETA: 38s - loss: 3.2950 - accuracy: 0.148 - ETA: 37s - loss: 3.2942 - accuracy: 0.148 - ETA: 36s - loss: 3.2941 - accuracy: 0.148 - ETA: 35s - loss: 3.2946 - accuracy: 0.148 - ETA: 34s - loss: 3.2945 - accuracy: 0.148 - ETA: 33s - loss: 3.2941 - accuracy: 0.148 - ETA: 32s - loss: 3.2935 - accuracy: 0.149 - ETA: 31s - loss: 3.2941 - accuracy: 0.148 - ETA: 30s - loss: 3.2943 - accuracy: 0.148 - ETA: 29s - loss: 3.2949 - accuracy: 0.148 - ETA: 28s - loss: 3.2946 - accuracy: 0.149 - ETA: 27s - loss: 3.2948 - accuracy: 0.149 - ETA: 26s - loss: 3.2950 - accuracy: 0.149 - ETA: 26s - loss: 3.2948 - accuracy: 0.149 - ETA: 25s - loss: 3.2947 - accuracy: 0.149 - ETA: 24s - loss: 3.2947 - accuracy: 0.149 - ETA: 23s - loss: 3.2953 - accuracy: 0.148 - ETA: 22s - loss: 3.2947 - accuracy: 0.149 - ETA: 21s - loss: 3.2943 - accuracy: 0.149 - ETA: 20s - loss: 3.2945 - accuracy: 0.149 - ETA: 19s - loss: 3.2946 - accuracy: 0.149 - ETA: 18s - loss: 3.2947 - accuracy: 0.149 - ETA: 17s - loss: 3.2956 - accuracy: 0.149 - ETA: 16s - loss: 3.2957 - accuracy: 0.148 - ETA: 15s - loss: 3.2966 - accuracy: 0.148 - ETA: 14s - loss: 3.2965 - accuracy: 0.148 - ETA: 13s - loss: 3.2963 - accuracy: 0.149 - ETA: 12s - loss: 3.2961 - accuracy: 0.149 - ETA: 11s - loss: 3.2958 - accuracy: 0.149 - ETA: 10s - loss: 3.2954 - accuracy: 0.149 - ETA: 9s - loss: 3.2952 - accuracy: 0.149 - ETA: 8s - loss: 3.2939 - accuracy: 0.14 - ETA: 7s - loss: 3.2935 - accuracy: 0.14 - ETA: 6s - loss: 3.2934 - accuracy: 0.14 - ETA: 5s - loss: 3.2933 - accuracy: 0.14 - ETA: 4s - loss: 3.2937 - accuracy: 0.14 - ETA: 3s - loss: 3.2936 - accuracy: 0.14 - ETA: 2s - loss: 3.2937 - accuracy: 0.14 - ETA: 1s - loss: 3.2943 - accuracy: 0.14 - ETA: 1s - loss: 3.2945 - accuracy: 0.14 - ETA: 0s - loss: 3.2944 - accuracy: 0.14 - 343s 8ms/step - loss: 3.2943 - accuracy: 0.1497 - val_loss: 4.0146 - val_accuracy: 0.0209\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:16 - loss: 3.4183 - accuracy: 0.10 - ETA: 5:09 - loss: 3.3842 - accuracy: 0.11 - ETA: 4:58 - loss: 3.3191 - accuracy: 0.12 - ETA: 4:57 - loss: 3.3322 - accuracy: 0.12 - ETA: 4:59 - loss: 3.3423 - accuracy: 0.12 - ETA: 5:02 - loss: 3.3239 - accuracy: 0.12 - ETA: 5:03 - loss: 3.3307 - accuracy: 0.12 - ETA: 5:04 - loss: 3.3072 - accuracy: 0.12 - ETA: 5:04 - loss: 3.3291 - accuracy: 0.13 - ETA: 5:03 - loss: 3.3072 - accuracy: 0.13 - ETA: 5:03 - loss: 3.2995 - accuracy: 0.13 - ETA: 5:04 - loss: 3.2859 - accuracy: 0.14 - ETA: 5:03 - loss: 3.2961 - accuracy: 0.13 - ETA: 5:04 - loss: 3.2815 - accuracy: 0.14 - ETA: 5:02 - loss: 3.2923 - accuracy: 0.14 - ETA: 5:00 - loss: 3.2804 - accuracy: 0.14 - ETA: 5:00 - loss: 3.2811 - accuracy: 0.14 - ETA: 4:59 - loss: 3.2823 - accuracy: 0.14 - ETA: 4:57 - loss: 3.2734 - accuracy: 0.14 - ETA: 4:55 - loss: 3.2816 - accuracy: 0.14 - ETA: 4:53 - loss: 3.2815 - accuracy: 0.14 - ETA: 4:53 - loss: 3.2798 - accuracy: 0.14 - ETA: 4:52 - loss: 3.2758 - accuracy: 0.14 - ETA: 4:52 - loss: 3.2758 - accuracy: 0.14 - ETA: 4:51 - loss: 3.2766 - accuracy: 0.14 - ETA: 4:51 - loss: 3.2764 - accuracy: 0.14 - ETA: 4:50 - loss: 3.2793 - accuracy: 0.14 - ETA: 4:49 - loss: 3.2821 - accuracy: 0.14 - ETA: 4:48 - loss: 3.2793 - accuracy: 0.14 - ETA: 4:46 - loss: 3.2857 - accuracy: 0.14 - ETA: 4:46 - loss: 3.2818 - accuracy: 0.14 - ETA: 4:45 - loss: 3.2840 - accuracy: 0.14 - ETA: 4:45 - loss: 3.2798 - accuracy: 0.14 - ETA: 4:44 - loss: 3.2778 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2824 - accuracy: 0.14 - ETA: 4:41 - loss: 3.2818 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2848 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2829 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2858 - accuracy: 0.14 - ETA: 4:37 - loss: 3.2877 - accuracy: 0.14 - ETA: 4:36 - loss: 3.2854 - accuracy: 0.14 - ETA: 4:35 - loss: 3.2873 - accuracy: 0.14 - ETA: 4:34 - loss: 3.2838 - accuracy: 0.15 - ETA: 4:33 - loss: 3.2885 - accuracy: 0.14 - ETA: 4:32 - loss: 3.2892 - accuracy: 0.14 - ETA: 4:31 - loss: 3.2894 - accuracy: 0.14 - ETA: 4:30 - loss: 3.2919 - accuracy: 0.14 - ETA: 4:29 - loss: 3.2945 - accuracy: 0.14 - ETA: 4:29 - loss: 3.2907 - accuracy: 0.14 - ETA: 4:28 - loss: 3.2915 - accuracy: 0.14 - ETA: 4:27 - loss: 3.2920 - accuracy: 0.14 - ETA: 4:26 - loss: 3.2889 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2897 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2958 - accuracy: 0.14 - ETA: 4:23 - loss: 3.2965 - accuracy: 0.14 - ETA: 4:22 - loss: 3.2930 - accuracy: 0.14 - ETA: 4:21 - loss: 3.2947 - accuracy: 0.14 - ETA: 4:20 - loss: 3.2979 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2982 - accuracy: 0.14 - ETA: 4:18 - loss: 3.2976 - accuracy: 0.14 - ETA: 4:17 - loss: 3.2951 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2950 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2913 - accuracy: 0.15 - ETA: 4:15 - loss: 3.2882 - accuracy: 0.15 - ETA: 4:14 - loss: 3.2862 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2873 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2862 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2874 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2826 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2821 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2819 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2814 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2804 - accuracy: 0.15 - ETA: 4:06 - loss: 3.2815 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2835 - accuracy: 0.15 - ETA: 4:04 - loss: 3.2852 - accuracy: 0.15 - ETA: 4:03 - loss: 3.2851 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2858 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2867 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2853 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2859 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2841 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2826 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2834 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2810 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2811 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2817 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2845 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2815 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2812 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2817 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2814 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2827 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2838 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2854 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2848 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2848 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2835 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2824 - accuracy: 0.15 - ETA: 3:42 - loss: 3.2836 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2818 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2825 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2822 - accuracy: 0.15 - ETA: 3:37 - loss: 3.2837 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2825 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2821 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2826 - accuracy: 0.15 - ETA: 3:34 - loss: 3.2853 - accuracy: 0.15 - ETA: 3:33 - loss: 3.2859 - accuracy: 0.15 - ETA: 3:32 - loss: 3.2870 - accuracy: 0.15 - ETA: 3:31 - loss: 3.2888 - accuracy: 0.15 - ETA: 3:30 - loss: 3.2883 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2885 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2886 - accuracy: 0.15 - ETA: 3:27 - loss: 3.2882 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2881 - accuracy: 0.15 - ETA: 3:25 - loss: 3.2875 - accuracy: 0.15 - ETA: 3:24 - loss: 3.2882 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2873 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2867 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2864 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2872 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2879 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2879 - accuracy: 0.15 - ETA: 3:17 - loss: 3.2891 - accuracy: 0.15 - ETA: 3:17 - loss: 3.2903 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2914 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2908 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2916 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2917 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2908 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2907 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2907 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2910 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2896 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2895 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2898 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2894 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2888 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2895 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2902 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2892 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2896 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2886 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2880 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2878 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2871 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2856 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2860 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2856 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2856 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2855 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2854 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2872 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2867 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2876 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2884 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2880 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2876 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2874 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2868 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2864 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2846 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2853 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2855 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2864 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2875 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2875 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2881 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2875 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2880 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2893 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2897 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2906 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2908 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2923 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2921 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2914 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2933 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2934 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2931 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2920 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2936 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2930 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2927 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2930 - accuracy: 0.1517"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.2931 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2924 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2924 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2929 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2923 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2925 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2914 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2919 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2915 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2915 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2917 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2912 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2911 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2913 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2918 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2915 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2928 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2919 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2921 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2920 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2921 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2915 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2922 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2934 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2945 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2952 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2954 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2956 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2958 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2958 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2950 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2951 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2958 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2961 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2956 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2945 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2955 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2951 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2955 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2960 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2963 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2958 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2962 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2965 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2965 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2968 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2964 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2958 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2953 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2949 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2948 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2948 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2952 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2952 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2947 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2943 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2942 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2943 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2952 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2956 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2961 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2958 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2959 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2964 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2961 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2962 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2955 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2954 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2961 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2962 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2978 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2978 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2983 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2983 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2980 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2989 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2985 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2987 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2991 - accuracy: 0.15 - ETA: 59s - loss: 3.2994 - accuracy: 0.1501 - ETA: 58s - loss: 3.2994 - accuracy: 0.150 - ETA: 57s - loss: 3.2990 - accuracy: 0.150 - ETA: 56s - loss: 3.2995 - accuracy: 0.150 - ETA: 55s - loss: 3.3003 - accuracy: 0.149 - ETA: 54s - loss: 3.2994 - accuracy: 0.149 - ETA: 53s - loss: 3.2993 - accuracy: 0.150 - ETA: 52s - loss: 3.2996 - accuracy: 0.149 - ETA: 51s - loss: 3.2996 - accuracy: 0.149 - ETA: 50s - loss: 3.2991 - accuracy: 0.150 - ETA: 50s - loss: 3.2985 - accuracy: 0.150 - ETA: 49s - loss: 3.2980 - accuracy: 0.150 - ETA: 48s - loss: 3.2984 - accuracy: 0.150 - ETA: 47s - loss: 3.2984 - accuracy: 0.150 - ETA: 46s - loss: 3.2981 - accuracy: 0.150 - ETA: 45s - loss: 3.2979 - accuracy: 0.150 - ETA: 44s - loss: 3.2977 - accuracy: 0.150 - ETA: 43s - loss: 3.2970 - accuracy: 0.150 - ETA: 42s - loss: 3.2962 - accuracy: 0.150 - ETA: 41s - loss: 3.2958 - accuracy: 0.150 - ETA: 40s - loss: 3.2960 - accuracy: 0.150 - ETA: 39s - loss: 3.2959 - accuracy: 0.150 - ETA: 38s - loss: 3.2958 - accuracy: 0.150 - ETA: 37s - loss: 3.2963 - accuracy: 0.150 - ETA: 36s - loss: 3.2970 - accuracy: 0.149 - ETA: 35s - loss: 3.2961 - accuracy: 0.150 - ETA: 34s - loss: 3.2969 - accuracy: 0.149 - ETA: 33s - loss: 3.2969 - accuracy: 0.149 - ETA: 32s - loss: 3.2968 - accuracy: 0.149 - ETA: 31s - loss: 3.2967 - accuracy: 0.149 - ETA: 30s - loss: 3.2962 - accuracy: 0.150 - ETA: 29s - loss: 3.2963 - accuracy: 0.150 - ETA: 28s - loss: 3.2964 - accuracy: 0.150 - ETA: 27s - loss: 3.2966 - accuracy: 0.150 - ETA: 26s - loss: 3.2968 - accuracy: 0.150 - ETA: 25s - loss: 3.2967 - accuracy: 0.150 - ETA: 25s - loss: 3.2967 - accuracy: 0.150 - ETA: 24s - loss: 3.2964 - accuracy: 0.150 - ETA: 23s - loss: 3.2967 - accuracy: 0.150 - ETA: 22s - loss: 3.2963 - accuracy: 0.150 - ETA: 21s - loss: 3.2967 - accuracy: 0.150 - ETA: 20s - loss: 3.2969 - accuracy: 0.150 - ETA: 19s - loss: 3.2967 - accuracy: 0.150 - ETA: 18s - loss: 3.2967 - accuracy: 0.150 - ETA: 17s - loss: 3.2965 - accuracy: 0.150 - ETA: 16s - loss: 3.2961 - accuracy: 0.150 - ETA: 15s - loss: 3.2965 - accuracy: 0.150 - ETA: 14s - loss: 3.2969 - accuracy: 0.150 - ETA: 13s - loss: 3.2965 - accuracy: 0.150 - ETA: 12s - loss: 3.2965 - accuracy: 0.150 - ETA: 11s - loss: 3.2961 - accuracy: 0.150 - ETA: 10s - loss: 3.2958 - accuracy: 0.150 - ETA: 9s - loss: 3.2958 - accuracy: 0.150 - ETA: 8s - loss: 3.2962 - accuracy: 0.14 - ETA: 7s - loss: 3.2963 - accuracy: 0.14 - ETA: 6s - loss: 3.2963 - accuracy: 0.14 - ETA: 5s - loss: 3.2963 - accuracy: 0.14 - ETA: 4s - loss: 3.2969 - accuracy: 0.14 - ETA: 3s - loss: 3.2965 - accuracy: 0.14 - ETA: 2s - loss: 3.2967 - accuracy: 0.14 - ETA: 1s - loss: 3.2970 - accuracy: 0.14 - ETA: 1s - loss: 3.2975 - accuracy: 0.14 - ETA: 0s - loss: 3.2980 - accuracy: 0.14 - 342s 8ms/step - loss: 3.2978 - accuracy: 0.1495 - val_loss: 3.8703 - val_accuracy: 0.0199\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:05 - loss: 3.1993 - accuracy: 0.15 - ETA: 5:15 - loss: 3.3008 - accuracy: 0.15 - ETA: 5:10 - loss: 3.3432 - accuracy: 0.13 - ETA: 5:10 - loss: 3.2917 - accuracy: 0.15 - ETA: 5:10 - loss: 3.2646 - accuracy: 0.15 - ETA: 5:10 - loss: 3.2619 - accuracy: 0.15 - ETA: 5:12 - loss: 3.2693 - accuracy: 0.15 - ETA: 5:14 - loss: 3.2592 - accuracy: 0.16 - ETA: 5:12 - loss: 3.2678 - accuracy: 0.15 - ETA: 5:11 - loss: 3.2527 - accuracy: 0.16 - ETA: 5:08 - loss: 3.2529 - accuracy: 0.16 - ETA: 5:08 - loss: 3.2754 - accuracy: 0.15 - ETA: 5:08 - loss: 3.2753 - accuracy: 0.15 - ETA: 5:06 - loss: 3.2674 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2626 - accuracy: 0.15 - ETA: 5:04 - loss: 3.2603 - accuracy: 0.15 - ETA: 5:04 - loss: 3.2722 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2751 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2701 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2785 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2724 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2736 - accuracy: 0.15 - ETA: 4:55 - loss: 3.2712 - accuracy: 0.14 - ETA: 4:54 - loss: 3.2744 - accuracy: 0.14 - ETA: 4:53 - loss: 3.2775 - accuracy: 0.14 - ETA: 4:52 - loss: 3.2696 - accuracy: 0.14 - ETA: 4:50 - loss: 3.2791 - accuracy: 0.14 - ETA: 4:49 - loss: 3.2826 - accuracy: 0.14 - ETA: 4:48 - loss: 3.2798 - accuracy: 0.14 - ETA: 4:48 - loss: 3.2816 - accuracy: 0.14 - ETA: 4:46 - loss: 3.2852 - accuracy: 0.14 - ETA: 4:46 - loss: 3.2822 - accuracy: 0.14 - ETA: 4:45 - loss: 3.2832 - accuracy: 0.14 - ETA: 4:45 - loss: 3.2797 - accuracy: 0.14 - ETA: 4:44 - loss: 3.2784 - accuracy: 0.14 - ETA: 4:43 - loss: 3.2778 - accuracy: 0.14 - ETA: 4:41 - loss: 3.2759 - accuracy: 0.14 - ETA: 4:40 - loss: 3.2673 - accuracy: 0.14 - ETA: 4:40 - loss: 3.2674 - accuracy: 0.14 - ETA: 4:38 - loss: 3.2674 - accuracy: 0.14 - ETA: 4:37 - loss: 3.2638 - accuracy: 0.14 - ETA: 4:36 - loss: 3.2659 - accuracy: 0.14 - ETA: 4:36 - loss: 3.2700 - accuracy: 0.14 - ETA: 4:34 - loss: 3.2712 - accuracy: 0.14 - ETA: 4:33 - loss: 3.2677 - accuracy: 0.14 - ETA: 4:32 - loss: 3.2705 - accuracy: 0.14 - ETA: 4:31 - loss: 3.2696 - accuracy: 0.14 - ETA: 4:31 - loss: 3.2690 - accuracy: 0.14 - ETA: 4:30 - loss: 3.2685 - accuracy: 0.14 - ETA: 4:29 - loss: 3.2713 - accuracy: 0.14 - ETA: 4:28 - loss: 3.2690 - accuracy: 0.14 - ETA: 4:27 - loss: 3.2660 - accuracy: 0.14 - ETA: 4:27 - loss: 3.2672 - accuracy: 0.14 - ETA: 4:25 - loss: 3.2637 - accuracy: 0.14 - ETA: 4:25 - loss: 3.2633 - accuracy: 0.14 - ETA: 4:24 - loss: 3.2664 - accuracy: 0.14 - ETA: 4:23 - loss: 3.2662 - accuracy: 0.14 - ETA: 4:22 - loss: 3.2680 - accuracy: 0.14 - ETA: 4:21 - loss: 3.2693 - accuracy: 0.14 - ETA: 4:20 - loss: 3.2688 - accuracy: 0.14 - ETA: 4:18 - loss: 3.2697 - accuracy: 0.14 - ETA: 4:18 - loss: 3.2736 - accuracy: 0.14 - ETA: 4:17 - loss: 3.2744 - accuracy: 0.14 - ETA: 4:16 - loss: 3.2758 - accuracy: 0.14 - ETA: 4:15 - loss: 3.2763 - accuracy: 0.14 - ETA: 4:14 - loss: 3.2754 - accuracy: 0.14 - ETA: 4:13 - loss: 3.2786 - accuracy: 0.14 - ETA: 4:12 - loss: 3.2814 - accuracy: 0.14 - ETA: 4:11 - loss: 3.2805 - accuracy: 0.14 - ETA: 4:10 - loss: 3.2789 - accuracy: 0.14 - ETA: 4:09 - loss: 3.2772 - accuracy: 0.14 - ETA: 4:09 - loss: 3.2781 - accuracy: 0.14 - ETA: 4:07 - loss: 3.2777 - accuracy: 0.14 - ETA: 4:07 - loss: 3.2757 - accuracy: 0.14 - ETA: 4:06 - loss: 3.2735 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2720 - accuracy: 0.14 - ETA: 4:03 - loss: 3.2722 - accuracy: 0.14 - ETA: 4:02 - loss: 3.2713 - accuracy: 0.14 - ETA: 4:01 - loss: 3.2700 - accuracy: 0.14 - ETA: 4:01 - loss: 3.2703 - accuracy: 0.14 - ETA: 4:00 - loss: 3.2698 - accuracy: 0.14 - ETA: 3:59 - loss: 3.2709 - accuracy: 0.14 - ETA: 3:58 - loss: 3.2719 - accuracy: 0.14 - ETA: 3:57 - loss: 3.2714 - accuracy: 0.14 - ETA: 3:56 - loss: 3.2705 - accuracy: 0.14 - ETA: 3:55 - loss: 3.2693 - accuracy: 0.14 - ETA: 3:54 - loss: 3.2702 - accuracy: 0.14 - ETA: 3:53 - loss: 3.2697 - accuracy: 0.14 - ETA: 3:52 - loss: 3.2711 - accuracy: 0.14 - ETA: 3:51 - loss: 3.2701 - accuracy: 0.14 - ETA: 3:50 - loss: 3.2713 - accuracy: 0.14 - ETA: 3:49 - loss: 3.2712 - accuracy: 0.14 - ETA: 3:48 - loss: 3.2713 - accuracy: 0.14 - ETA: 3:47 - loss: 3.2717 - accuracy: 0.14 - ETA: 3:46 - loss: 3.2720 - accuracy: 0.14 - ETA: 3:45 - loss: 3.2712 - accuracy: 0.14 - ETA: 3:44 - loss: 3.2709 - accuracy: 0.14 - ETA: 3:43 - loss: 3.2711 - accuracy: 0.14 - ETA: 3:42 - loss: 3.2707 - accuracy: 0.14 - ETA: 3:41 - loss: 3.2709 - accuracy: 0.14 - ETA: 3:41 - loss: 3.2713 - accuracy: 0.14 - ETA: 3:40 - loss: 3.2716 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2719 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2727 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2734 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2730 - accuracy: 0.14 - ETA: 3:34 - loss: 3.2739 - accuracy: 0.14 - ETA: 3:34 - loss: 3.2736 - accuracy: 0.14 - ETA: 3:33 - loss: 3.2768 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2767 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2750 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2755 - accuracy: 0.14 - ETA: 3:29 - loss: 3.2752 - accuracy: 0.14 - ETA: 3:28 - loss: 3.2745 - accuracy: 0.14 - ETA: 3:27 - loss: 3.2747 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2742 - accuracy: 0.14 - ETA: 3:25 - loss: 3.2752 - accuracy: 0.14 - ETA: 3:24 - loss: 3.2765 - accuracy: 0.14 - ETA: 3:23 - loss: 3.2761 - accuracy: 0.14 - ETA: 3:22 - loss: 3.2759 - accuracy: 0.14 - ETA: 3:21 - loss: 3.2757 - accuracy: 0.14 - ETA: 3:20 - loss: 3.2740 - accuracy: 0.14 - ETA: 3:19 - loss: 3.2720 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2731 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2713 - accuracy: 0.14 - ETA: 3:17 - loss: 3.2724 - accuracy: 0.14 - ETA: 3:16 - loss: 3.2722 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2722 - accuracy: 0.14 - ETA: 3:14 - loss: 3.2707 - accuracy: 0.14 - ETA: 3:13 - loss: 3.2699 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2702 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2715 - accuracy: 0.14 - ETA: 3:10 - loss: 3.2709 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2695 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2705 - accuracy: 0.14 - ETA: 3:07 - loss: 3.2717 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2713 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2720 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2744 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2751 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2746 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2745 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2746 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2750 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2760 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2774 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2774 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2777 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2780 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2786 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2796 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2793 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2799 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2785 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2771 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2780 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2779 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2774 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2775 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2753 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2753 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2754 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2765 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2760 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2761 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2762 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2769 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2780 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2779 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2770 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2760 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2754 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2752 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2745 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2758 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2740 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2735 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2744 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2747 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2743 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2745 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2763 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2763 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2759 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2755 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2750 - accuracy: 0.1530"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.2754 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2752 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2748 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2752 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2747 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2743 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2744 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2742 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2741 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2729 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2731 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2734 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2744 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2745 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2749 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2754 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2752 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2747 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2743 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2734 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2735 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2737 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2739 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2744 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2743 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2732 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2734 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2735 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2729 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2728 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2734 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2738 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2730 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2732 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2733 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2727 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2733 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2728 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2734 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2727 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2724 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2714 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2716 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2710 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2706 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2697 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2694 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2688 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2690 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2697 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2695 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2691 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2695 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2694 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2700 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2692 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2686 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2672 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2681 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2677 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2679 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2680 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2673 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2674 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2674 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2668 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2667 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2659 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2653 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2655 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2646 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2642 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2637 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2638 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2636 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2637 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2630 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2633 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2630 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2634 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2635 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2641 - accuracy: 0.15 - ETA: 59s - loss: 3.2643 - accuracy: 0.1548 - ETA: 58s - loss: 3.2642 - accuracy: 0.154 - ETA: 57s - loss: 3.2647 - accuracy: 0.154 - ETA: 56s - loss: 3.2649 - accuracy: 0.154 - ETA: 55s - loss: 3.2647 - accuracy: 0.154 - ETA: 54s - loss: 3.2649 - accuracy: 0.154 - ETA: 53s - loss: 3.2635 - accuracy: 0.155 - ETA: 52s - loss: 3.2637 - accuracy: 0.155 - ETA: 52s - loss: 3.2633 - accuracy: 0.155 - ETA: 51s - loss: 3.2633 - accuracy: 0.155 - ETA: 50s - loss: 3.2633 - accuracy: 0.155 - ETA: 49s - loss: 3.2631 - accuracy: 0.155 - ETA: 48s - loss: 3.2635 - accuracy: 0.155 - ETA: 47s - loss: 3.2629 - accuracy: 0.155 - ETA: 46s - loss: 3.2626 - accuracy: 0.155 - ETA: 45s - loss: 3.2626 - accuracy: 0.155 - ETA: 44s - loss: 3.2627 - accuracy: 0.155 - ETA: 43s - loss: 3.2623 - accuracy: 0.155 - ETA: 42s - loss: 3.2672 - accuracy: 0.155 - ETA: 41s - loss: 3.2667 - accuracy: 0.155 - ETA: 40s - loss: 3.2664 - accuracy: 0.155 - ETA: 39s - loss: 3.2662 - accuracy: 0.155 - ETA: 38s - loss: 3.2664 - accuracy: 0.155 - ETA: 37s - loss: 3.2665 - accuracy: 0.155 - ETA: 36s - loss: 3.2659 - accuracy: 0.155 - ETA: 35s - loss: 3.2651 - accuracy: 0.155 - ETA: 34s - loss: 3.2650 - accuracy: 0.155 - ETA: 33s - loss: 3.2657 - accuracy: 0.155 - ETA: 32s - loss: 3.2653 - accuracy: 0.155 - ETA: 31s - loss: 3.2657 - accuracy: 0.155 - ETA: 30s - loss: 3.2658 - accuracy: 0.155 - ETA: 29s - loss: 3.2661 - accuracy: 0.155 - ETA: 28s - loss: 3.2655 - accuracy: 0.155 - ETA: 27s - loss: 3.2660 - accuracy: 0.155 - ETA: 26s - loss: 3.2660 - accuracy: 0.155 - ETA: 26s - loss: 3.2662 - accuracy: 0.155 - ETA: 25s - loss: 3.2663 - accuracy: 0.155 - ETA: 24s - loss: 3.2667 - accuracy: 0.155 - ETA: 23s - loss: 3.2670 - accuracy: 0.155 - ETA: 22s - loss: 3.2670 - accuracy: 0.155 - ETA: 21s - loss: 3.2671 - accuracy: 0.155 - ETA: 20s - loss: 3.2666 - accuracy: 0.155 - ETA: 19s - loss: 3.2665 - accuracy: 0.155 - ETA: 18s - loss: 3.2662 - accuracy: 0.155 - ETA: 17s - loss: 3.2657 - accuracy: 0.155 - ETA: 16s - loss: 3.2664 - accuracy: 0.155 - ETA: 15s - loss: 3.2667 - accuracy: 0.155 - ETA: 14s - loss: 3.2666 - accuracy: 0.155 - ETA: 13s - loss: 3.2663 - accuracy: 0.155 - ETA: 12s - loss: 3.2661 - accuracy: 0.155 - ETA: 11s - loss: 3.2648 - accuracy: 0.155 - ETA: 10s - loss: 3.2647 - accuracy: 0.155 - ETA: 9s - loss: 3.2649 - accuracy: 0.155 - ETA: 8s - loss: 3.2652 - accuracy: 0.15 - ETA: 7s - loss: 3.2654 - accuracy: 0.15 - ETA: 6s - loss: 3.2652 - accuracy: 0.15 - ETA: 5s - loss: 3.2656 - accuracy: 0.15 - ETA: 4s - loss: 3.2652 - accuracy: 0.15 - ETA: 3s - loss: 3.2650 - accuracy: 0.15 - ETA: 2s - loss: 3.2655 - accuracy: 0.15 - ETA: 1s - loss: 3.2654 - accuracy: 0.15 - ETA: 1s - loss: 3.2663 - accuracy: 0.15 - ETA: 0s - loss: 3.2665 - accuracy: 0.15 - 343s 8ms/step - loss: 3.2665 - accuracy: 0.1549 - val_loss: 3.8810 - val_accuracy: 0.0181\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:18 - loss: 3.1628 - accuracy: 0.22 - ETA: 5:11 - loss: 3.1916 - accuracy: 0.19 - ETA: 5:07 - loss: 3.3072 - accuracy: 0.15 - ETA: 5:04 - loss: 3.2588 - accuracy: 0.16 - ETA: 5:03 - loss: 3.2826 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2496 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2461 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2391 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2519 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2563 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2476 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2447 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2449 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2416 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2425 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2332 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2352 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2331 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2415 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2371 - accuracy: 0.15 - ETA: 4:55 - loss: 3.2313 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2274 - accuracy: 0.16 - ETA: 4:53 - loss: 3.2191 - accuracy: 0.16 - ETA: 4:53 - loss: 3.2142 - accuracy: 0.16 - ETA: 4:52 - loss: 3.2241 - accuracy: 0.16 - ETA: 4:51 - loss: 3.2180 - accuracy: 0.16 - ETA: 4:50 - loss: 3.2224 - accuracy: 0.16 - ETA: 4:49 - loss: 3.2272 - accuracy: 0.16 - ETA: 4:49 - loss: 3.2286 - accuracy: 0.16 - ETA: 4:48 - loss: 3.2280 - accuracy: 0.16 - ETA: 4:46 - loss: 3.2308 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2332 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2320 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2291 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2256 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2292 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2322 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2307 - accuracy: 0.16 - ETA: 4:38 - loss: 3.2293 - accuracy: 0.16 - ETA: 4:37 - loss: 3.2280 - accuracy: 0.16 - ETA: 4:36 - loss: 3.2315 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2365 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2390 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2367 - accuracy: 0.15 - ETA: 4:33 - loss: 3.2360 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2374 - accuracy: 0.15 - ETA: 4:31 - loss: 3.2363 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2338 - accuracy: 0.16 - ETA: 4:29 - loss: 3.2382 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2422 - accuracy: 0.15 - ETA: 4:27 - loss: 3.2416 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2411 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2401 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2398 - accuracy: 0.15 - ETA: 4:22 - loss: 3.2395 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2402 - accuracy: 0.15 - ETA: 4:20 - loss: 3.2444 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2471 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2474 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2488 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2525 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2545 - accuracy: 0.15 - ETA: 4:15 - loss: 3.2581 - accuracy: 0.15 - ETA: 4:14 - loss: 3.2580 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2582 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2601 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2594 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2581 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2595 - accuracy: 0.15 - ETA: 4:09 - loss: 3.2628 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2633 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2636 - accuracy: 0.15 - ETA: 4:06 - loss: 3.2633 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2611 - accuracy: 0.15 - ETA: 4:04 - loss: 3.2597 - accuracy: 0.15 - ETA: 4:03 - loss: 3.2581 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2595 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2604 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2606 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2592 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2586 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2582 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2566 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2559 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2578 - accuracy: 0.15 - ETA: 3:54 - loss: 3.2577 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2566 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2558 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2548 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2559 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2537 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2549 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2533 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2529 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2525 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2537 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2528 - accuracy: 0.15 - ETA: 3:42 - loss: 3.2538 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2548 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2548 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2549 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2545 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2562 - accuracy: 0.15 - ETA: 3:37 - loss: 3.2554 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2548 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2543 - accuracy: 0.15 - ETA: 3:34 - loss: 3.2552 - accuracy: 0.15 - ETA: 3:33 - loss: 3.2559 - accuracy: 0.15 - ETA: 3:32 - loss: 3.2569 - accuracy: 0.15 - ETA: 3:31 - loss: 3.2565 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2587 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2589 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2611 - accuracy: 0.15 - ETA: 3:25 - loss: 3.2603 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2598 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2613 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2618 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2600 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2587 - accuracy: 0.15 - ETA: 3:17 - loss: 3.2586 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2595 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2607 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2600 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2608 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2610 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2600 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2592 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2587 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2614 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2619 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2617 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2622 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2621 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2620 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2620 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2623 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2620 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2617 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2610 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2604 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2602 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2600 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2598 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2605 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2609 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2591 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2598 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2596 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2594 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2594 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2599 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2607 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2610 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2613 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2616 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2619 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2625 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2631 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2626 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2631 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2619 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2623 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2622 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2621 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2634 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2644 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2644 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2647 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2645 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2651 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2658 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2664 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2677 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2679 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2673 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2673 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2680 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2679 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2683 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2693 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2689 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2686 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2685 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2690 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2686 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2694 - accuracy: 0.1532"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:13 - loss: 3.2700 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2706 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2717 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2712 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2701 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2698 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2705 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2696 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2689 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2687 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2692 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2695 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2691 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2695 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2699 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2694 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2687 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2689 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2689 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2693 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2688 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2686 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2689 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2694 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2688 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2694 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2694 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2704 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2698 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2696 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2700 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2698 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2698 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2703 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2708 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2702 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2702 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2700 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2708 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2708 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2710 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2705 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2706 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2708 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2701 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2701 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2698 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2701 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2700 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2704 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2699 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2704 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2708 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2705 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2707 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2706 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2708 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2713 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2716 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2716 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2709 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2706 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2702 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2698 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2686 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2690 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2689 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2688 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2688 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2682 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2678 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2680 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2684 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2680 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2679 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2680 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2685 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2684 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2681 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2687 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2692 - accuracy: 0.15 - ETA: 59s - loss: 3.2688 - accuracy: 0.1539 - ETA: 58s - loss: 3.2693 - accuracy: 0.153 - ETA: 57s - loss: 3.2684 - accuracy: 0.154 - ETA: 56s - loss: 3.2685 - accuracy: 0.154 - ETA: 55s - loss: 3.2680 - accuracy: 0.154 - ETA: 54s - loss: 3.2680 - accuracy: 0.154 - ETA: 53s - loss: 3.2680 - accuracy: 0.154 - ETA: 52s - loss: 3.2679 - accuracy: 0.154 - ETA: 51s - loss: 3.2676 - accuracy: 0.154 - ETA: 50s - loss: 3.2680 - accuracy: 0.154 - ETA: 49s - loss: 3.2683 - accuracy: 0.154 - ETA: 48s - loss: 3.2676 - accuracy: 0.154 - ETA: 48s - loss: 3.2677 - accuracy: 0.154 - ETA: 47s - loss: 3.2668 - accuracy: 0.154 - ETA: 46s - loss: 3.2667 - accuracy: 0.154 - ETA: 45s - loss: 3.2671 - accuracy: 0.154 - ETA: 44s - loss: 3.2664 - accuracy: 0.154 - ETA: 43s - loss: 3.2671 - accuracy: 0.154 - ETA: 42s - loss: 3.2670 - accuracy: 0.154 - ETA: 41s - loss: 3.2673 - accuracy: 0.154 - ETA: 40s - loss: 3.2671 - accuracy: 0.154 - ETA: 39s - loss: 3.2669 - accuracy: 0.154 - ETA: 38s - loss: 3.2667 - accuracy: 0.154 - ETA: 37s - loss: 3.2663 - accuracy: 0.154 - ETA: 36s - loss: 3.2665 - accuracy: 0.154 - ETA: 35s - loss: 3.2660 - accuracy: 0.154 - ETA: 34s - loss: 3.2662 - accuracy: 0.154 - ETA: 33s - loss: 3.2653 - accuracy: 0.154 - ETA: 33s - loss: 3.2656 - accuracy: 0.154 - ETA: 32s - loss: 3.2650 - accuracy: 0.154 - ETA: 31s - loss: 3.2653 - accuracy: 0.154 - ETA: 30s - loss: 3.2649 - accuracy: 0.154 - ETA: 29s - loss: 3.2654 - accuracy: 0.154 - ETA: 28s - loss: 3.2658 - accuracy: 0.154 - ETA: 27s - loss: 3.2655 - accuracy: 0.154 - ETA: 26s - loss: 3.2657 - accuracy: 0.154 - ETA: 25s - loss: 3.2650 - accuracy: 0.154 - ETA: 24s - loss: 3.2651 - accuracy: 0.154 - ETA: 23s - loss: 3.2649 - accuracy: 0.154 - ETA: 22s - loss: 3.2640 - accuracy: 0.154 - ETA: 21s - loss: 3.2640 - accuracy: 0.154 - ETA: 20s - loss: 3.2646 - accuracy: 0.154 - ETA: 19s - loss: 3.2644 - accuracy: 0.154 - ETA: 18s - loss: 3.2648 - accuracy: 0.154 - ETA: 17s - loss: 3.2651 - accuracy: 0.154 - ETA: 17s - loss: 3.2648 - accuracy: 0.154 - ETA: 16s - loss: 3.2644 - accuracy: 0.154 - ETA: 15s - loss: 3.2646 - accuracy: 0.154 - ETA: 14s - loss: 3.2646 - accuracy: 0.154 - ETA: 13s - loss: 3.2645 - accuracy: 0.154 - ETA: 12s - loss: 3.2646 - accuracy: 0.154 - ETA: 11s - loss: 3.2642 - accuracy: 0.154 - ETA: 10s - loss: 3.2650 - accuracy: 0.154 - ETA: 9s - loss: 3.2651 - accuracy: 0.154 - ETA: 8s - loss: 3.2651 - accuracy: 0.15 - ETA: 7s - loss: 3.2656 - accuracy: 0.15 - ETA: 6s - loss: 3.2658 - accuracy: 0.15 - ETA: 5s - loss: 3.2658 - accuracy: 0.15 - ETA: 4s - loss: 3.2663 - accuracy: 0.15 - ETA: 3s - loss: 3.2663 - accuracy: 0.15 - ETA: 2s - loss: 3.2664 - accuracy: 0.15 - ETA: 1s - loss: 3.2662 - accuracy: 0.15 - ETA: 1s - loss: 3.2657 - accuracy: 0.15 - ETA: 0s - loss: 3.2652 - accuracy: 0.15 - 337s 8ms/step - loss: 3.2653 - accuracy: 0.1539 - val_loss: 3.9146 - val_accuracy: 0.0226\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:11 - loss: 3.3037 - accuracy: 0.12 - ETA: 5:00 - loss: 3.3413 - accuracy: 0.11 - ETA: 5:01 - loss: 3.3136 - accuracy: 0.13 - ETA: 5:00 - loss: 3.2871 - accuracy: 0.14 - ETA: 5:01 - loss: 3.2760 - accuracy: 0.14 - ETA: 5:02 - loss: 3.2652 - accuracy: 0.14 - ETA: 5:00 - loss: 3.2589 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2271 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2338 - accuracy: 0.15 - ETA: 5:06 - loss: 3.2316 - accuracy: 0.16 - ETA: 5:07 - loss: 3.2310 - accuracy: 0.15 - ETA: 5:09 - loss: 3.2432 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2580 - accuracy: 0.15 - ETA: 5:06 - loss: 3.2511 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2431 - accuracy: 0.15 - ETA: 5:04 - loss: 3.2296 - accuracy: 0.16 - ETA: 5:03 - loss: 3.2364 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2400 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2440 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2294 - accuracy: 0.16 - ETA: 4:57 - loss: 3.2278 - accuracy: 0.16 - ETA: 4:56 - loss: 3.2286 - accuracy: 0.15 - ETA: 4:55 - loss: 3.2264 - accuracy: 0.16 - ETA: 4:54 - loss: 3.2375 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2408 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2538 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2570 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2520 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2483 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2532 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2492 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2484 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2481 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2496 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2491 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2482 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2502 - accuracy: 0.15 - ETA: 4:37 - loss: 3.2468 - accuracy: 0.15 - ETA: 4:36 - loss: 3.2470 - accuracy: 0.15 - ETA: 4:36 - loss: 3.2477 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2484 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2466 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2450 - accuracy: 0.15 - ETA: 4:33 - loss: 3.2559 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2557 - accuracy: 0.15 - ETA: 4:31 - loss: 3.2595 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2544 - accuracy: 0.16 - ETA: 4:29 - loss: 3.2549 - accuracy: 0.16 - ETA: 4:28 - loss: 3.2579 - accuracy: 0.16 - ETA: 4:27 - loss: 3.2600 - accuracy: 0.16 - ETA: 4:26 - loss: 3.2589 - accuracy: 0.16 - ETA: 4:25 - loss: 3.2597 - accuracy: 0.16 - ETA: 4:24 - loss: 3.2603 - accuracy: 0.16 - ETA: 4:23 - loss: 3.2593 - accuracy: 0.16 - ETA: 4:22 - loss: 3.2576 - accuracy: 0.16 - ETA: 4:21 - loss: 3.2639 - accuracy: 0.16 - ETA: 4:20 - loss: 3.2643 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2639 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2607 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2594 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2613 - accuracy: 0.15 - ETA: 4:15 - loss: 3.2611 - accuracy: 0.15 - ETA: 4:14 - loss: 3.2595 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2616 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2588 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2594 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2635 - accuracy: 0.15 - ETA: 4:09 - loss: 3.2677 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2688 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2678 - accuracy: 0.15 - ETA: 4:06 - loss: 3.2693 - accuracy: 0.15 - ETA: 4:06 - loss: 3.2708 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2715 - accuracy: 0.15 - ETA: 4:04 - loss: 3.2728 - accuracy: 0.15 - ETA: 4:03 - loss: 3.2732 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2720 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2747 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2750 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2764 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2755 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2756 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2748 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2761 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2756 - accuracy: 0.15 - ETA: 3:54 - loss: 3.2754 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2767 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2769 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2765 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2781 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2797 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2802 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2818 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2828 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2826 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2801 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2799 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2803 - accuracy: 0.15 - ETA: 3:42 - loss: 3.2799 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2791 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2813 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2824 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2837 - accuracy: 0.15 - ETA: 3:37 - loss: 3.2835 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2845 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2846 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2857 - accuracy: 0.15 - ETA: 3:34 - loss: 3.2859 - accuracy: 0.15 - ETA: 3:33 - loss: 3.2871 - accuracy: 0.15 - ETA: 3:32 - loss: 3.2875 - accuracy: 0.15 - ETA: 3:31 - loss: 3.2885 - accuracy: 0.15 - ETA: 3:30 - loss: 3.2890 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2884 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2898 - accuracy: 0.15 - ETA: 3:27 - loss: 3.2879 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2886 - accuracy: 0.15 - ETA: 3:25 - loss: 3.2892 - accuracy: 0.15 - ETA: 3:24 - loss: 3.2889 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2900 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2893 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2892 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2894 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2881 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2880 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2892 - accuracy: 0.15 - ETA: 3:17 - loss: 3.2874 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2879 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2887 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2886 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2885 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2893 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2889 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2895 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2898 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2916 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2920 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2944 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2947 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2956 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2961 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2957 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2956 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2966 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2964 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2971 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2982 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2979 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2991 - accuracy: 0.15 - ETA: 2:55 - loss: 3.3007 - accuracy: 0.15 - ETA: 2:54 - loss: 3.3016 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3014 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3012 - accuracy: 0.15 - ETA: 2:52 - loss: 3.3007 - accuracy: 0.15 - ETA: 2:51 - loss: 3.3004 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2995 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2992 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2997 - accuracy: 0.15 - ETA: 2:47 - loss: 3.3001 - accuracy: 0.15 - ETA: 2:46 - loss: 3.3010 - accuracy: 0.15 - ETA: 2:45 - loss: 3.3020 - accuracy: 0.15 - ETA: 2:44 - loss: 3.3024 - accuracy: 0.15 - ETA: 2:43 - loss: 3.3042 - accuracy: 0.15 - ETA: 2:42 - loss: 3.3057 - accuracy: 0.15 - ETA: 2:41 - loss: 3.3056 - accuracy: 0.15 - ETA: 2:40 - loss: 3.3057 - accuracy: 0.15 - ETA: 2:39 - loss: 3.3054 - accuracy: 0.15 - ETA: 2:38 - loss: 3.3059 - accuracy: 0.15 - ETA: 2:37 - loss: 3.3053 - accuracy: 0.15 - ETA: 2:36 - loss: 3.3045 - accuracy: 0.15 - ETA: 2:35 - loss: 3.3045 - accuracy: 0.15 - ETA: 2:34 - loss: 3.3051 - accuracy: 0.15 - ETA: 2:33 - loss: 3.3050 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3046 - accuracy: 0.15 - ETA: 2:32 - loss: 3.3041 - accuracy: 0.15 - ETA: 2:31 - loss: 3.3035 - accuracy: 0.15 - ETA: 2:30 - loss: 3.3030 - accuracy: 0.15 - ETA: 2:29 - loss: 3.3027 - accuracy: 0.15 - ETA: 2:28 - loss: 3.3030 - accuracy: 0.15 - ETA: 2:27 - loss: 3.3029 - accuracy: 0.15 - ETA: 2:26 - loss: 3.3025 - accuracy: 0.15 - ETA: 2:25 - loss: 3.3020 - accuracy: 0.15 - ETA: 2:24 - loss: 3.3022 - accuracy: 0.15 - ETA: 2:23 - loss: 3.3022 - accuracy: 0.15 - ETA: 2:22 - loss: 3.3020 - accuracy: 0.15 - ETA: 2:21 - loss: 3.3005 - accuracy: 0.15 - ETA: 2:20 - loss: 3.3001 - accuracy: 0.15 - ETA: 2:19 - loss: 3.3006 - accuracy: 0.1512"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.2991 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2990 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2997 - accuracy: 0.15 - ETA: 2:15 - loss: 3.3000 - accuracy: 0.15 - ETA: 2:14 - loss: 3.3000 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2999 - accuracy: 0.15 - ETA: 2:12 - loss: 3.3004 - accuracy: 0.15 - ETA: 2:11 - loss: 3.3001 - accuracy: 0.15 - ETA: 2:10 - loss: 3.3001 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2999 - accuracy: 0.15 - ETA: 2:09 - loss: 3.3002 - accuracy: 0.15 - ETA: 2:08 - loss: 3.3001 - accuracy: 0.15 - ETA: 2:07 - loss: 3.3011 - accuracy: 0.15 - ETA: 2:06 - loss: 3.3014 - accuracy: 0.15 - ETA: 2:05 - loss: 3.3017 - accuracy: 0.15 - ETA: 2:04 - loss: 3.3017 - accuracy: 0.15 - ETA: 2:03 - loss: 3.3016 - accuracy: 0.15 - ETA: 2:02 - loss: 3.3018 - accuracy: 0.15 - ETA: 2:01 - loss: 3.3017 - accuracy: 0.15 - ETA: 2:00 - loss: 3.3018 - accuracy: 0.15 - ETA: 1:59 - loss: 3.3019 - accuracy: 0.15 - ETA: 1:58 - loss: 3.3018 - accuracy: 0.15 - ETA: 1:57 - loss: 3.3013 - accuracy: 0.15 - ETA: 1:56 - loss: 3.3015 - accuracy: 0.15 - ETA: 1:55 - loss: 3.3014 - accuracy: 0.15 - ETA: 1:54 - loss: 3.3024 - accuracy: 0.15 - ETA: 1:53 - loss: 3.3035 - accuracy: 0.15 - ETA: 1:52 - loss: 3.3034 - accuracy: 0.15 - ETA: 1:51 - loss: 3.3033 - accuracy: 0.15 - ETA: 1:50 - loss: 3.3028 - accuracy: 0.15 - ETA: 1:49 - loss: 3.3025 - accuracy: 0.15 - ETA: 1:48 - loss: 3.3018 - accuracy: 0.15 - ETA: 1:47 - loss: 3.3018 - accuracy: 0.15 - ETA: 1:46 - loss: 3.3018 - accuracy: 0.15 - ETA: 1:45 - loss: 3.3020 - accuracy: 0.15 - ETA: 1:44 - loss: 3.3018 - accuracy: 0.15 - ETA: 1:44 - loss: 3.3019 - accuracy: 0.15 - ETA: 1:43 - loss: 3.3018 - accuracy: 0.15 - ETA: 1:42 - loss: 3.3016 - accuracy: 0.15 - ETA: 1:41 - loss: 3.3010 - accuracy: 0.15 - ETA: 1:40 - loss: 3.3005 - accuracy: 0.15 - ETA: 1:39 - loss: 3.3010 - accuracy: 0.15 - ETA: 1:38 - loss: 3.3014 - accuracy: 0.15 - ETA: 1:37 - loss: 3.3008 - accuracy: 0.15 - ETA: 1:36 - loss: 3.3000 - accuracy: 0.15 - ETA: 1:35 - loss: 3.3005 - accuracy: 0.15 - ETA: 1:34 - loss: 3.3005 - accuracy: 0.15 - ETA: 1:33 - loss: 3.3006 - accuracy: 0.15 - ETA: 1:32 - loss: 3.3001 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2996 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2999 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2998 - accuracy: 0.15 - ETA: 1:28 - loss: 3.3000 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2994 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2995 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2997 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2988 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2977 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2974 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2971 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2962 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2965 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2961 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2968 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2964 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2962 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2954 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2952 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2954 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2959 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2962 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2962 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2952 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2952 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2948 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2949 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2947 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2948 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2947 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2944 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2947 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2944 - accuracy: 0.15 - ETA: 59s - loss: 3.2943 - accuracy: 0.1510 - ETA: 58s - loss: 3.2946 - accuracy: 0.151 - ETA: 57s - loss: 3.2946 - accuracy: 0.150 - ETA: 56s - loss: 3.2940 - accuracy: 0.151 - ETA: 55s - loss: 3.2938 - accuracy: 0.151 - ETA: 55s - loss: 3.2938 - accuracy: 0.151 - ETA: 54s - loss: 3.2933 - accuracy: 0.151 - ETA: 53s - loss: 3.2935 - accuracy: 0.151 - ETA: 52s - loss: 3.2932 - accuracy: 0.151 - ETA: 51s - loss: 3.2933 - accuracy: 0.151 - ETA: 50s - loss: 3.2932 - accuracy: 0.151 - ETA: 49s - loss: 3.2931 - accuracy: 0.151 - ETA: 48s - loss: 3.2932 - accuracy: 0.151 - ETA: 47s - loss: 3.2935 - accuracy: 0.151 - ETA: 46s - loss: 3.2936 - accuracy: 0.151 - ETA: 45s - loss: 3.2937 - accuracy: 0.150 - ETA: 44s - loss: 3.2934 - accuracy: 0.150 - ETA: 43s - loss: 3.2934 - accuracy: 0.150 - ETA: 42s - loss: 3.2938 - accuracy: 0.150 - ETA: 41s - loss: 3.2928 - accuracy: 0.151 - ETA: 40s - loss: 3.2924 - accuracy: 0.151 - ETA: 39s - loss: 3.2923 - accuracy: 0.151 - ETA: 38s - loss: 3.2922 - accuracy: 0.151 - ETA: 37s - loss: 3.2925 - accuracy: 0.151 - ETA: 36s - loss: 3.2920 - accuracy: 0.151 - ETA: 35s - loss: 3.2916 - accuracy: 0.151 - ETA: 34s - loss: 3.2921 - accuracy: 0.151 - ETA: 33s - loss: 3.2924 - accuracy: 0.151 - ETA: 32s - loss: 3.2917 - accuracy: 0.151 - ETA: 31s - loss: 3.2918 - accuracy: 0.151 - ETA: 30s - loss: 3.2916 - accuracy: 0.151 - ETA: 30s - loss: 3.2916 - accuracy: 0.151 - ETA: 29s - loss: 3.2910 - accuracy: 0.151 - ETA: 28s - loss: 3.2910 - accuracy: 0.151 - ETA: 27s - loss: 3.2910 - accuracy: 0.151 - ETA: 26s - loss: 3.2906 - accuracy: 0.151 - ETA: 25s - loss: 3.2902 - accuracy: 0.151 - ETA: 24s - loss: 3.2907 - accuracy: 0.151 - ETA: 23s - loss: 3.2906 - accuracy: 0.151 - ETA: 22s - loss: 3.2910 - accuracy: 0.151 - ETA: 21s - loss: 3.2906 - accuracy: 0.151 - ETA: 20s - loss: 3.2904 - accuracy: 0.151 - ETA: 19s - loss: 3.2905 - accuracy: 0.151 - ETA: 18s - loss: 3.2902 - accuracy: 0.151 - ETA: 17s - loss: 3.2905 - accuracy: 0.151 - ETA: 16s - loss: 3.2905 - accuracy: 0.151 - ETA: 15s - loss: 3.2899 - accuracy: 0.151 - ETA: 14s - loss: 3.2898 - accuracy: 0.151 - ETA: 13s - loss: 3.2899 - accuracy: 0.151 - ETA: 12s - loss: 3.2900 - accuracy: 0.151 - ETA: 11s - loss: 3.2901 - accuracy: 0.151 - ETA: 10s - loss: 3.2899 - accuracy: 0.151 - ETA: 9s - loss: 3.2897 - accuracy: 0.151 - ETA: 8s - loss: 3.2897 - accuracy: 0.15 - ETA: 7s - loss: 3.2897 - accuracy: 0.15 - ETA: 6s - loss: 3.2901 - accuracy: 0.15 - ETA: 5s - loss: 3.2906 - accuracy: 0.15 - ETA: 4s - loss: 3.2908 - accuracy: 0.15 - ETA: 3s - loss: 3.2906 - accuracy: 0.15 - ETA: 2s - loss: 3.2894 - accuracy: 0.15 - ETA: 2s - loss: 3.2896 - accuracy: 0.15 - ETA: 1s - loss: 3.2887 - accuracy: 0.15 - ETA: 0s - loss: 3.2889 - accuracy: 0.15 - 344s 8ms/step - loss: 3.2890 - accuracy: 0.1521 - val_loss: 3.9274 - val_accuracy: 0.0174\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:27 - loss: 3.3937 - accuracy: 0.12 - ETA: 5:13 - loss: 3.2180 - accuracy: 0.15 - ETA: 5:22 - loss: 3.2127 - accuracy: 0.15 - ETA: 5:19 - loss: 3.2220 - accuracy: 0.16 - ETA: 5:13 - loss: 3.2315 - accuracy: 0.16 - ETA: 5:11 - loss: 3.2232 - accuracy: 0.16 - ETA: 5:10 - loss: 3.2257 - accuracy: 0.16 - ETA: 5:08 - loss: 3.2304 - accuracy: 0.16 - ETA: 5:08 - loss: 3.2196 - accuracy: 0.16 - ETA: 5:04 - loss: 3.2291 - accuracy: 0.16 - ETA: 5:02 - loss: 3.2213 - accuracy: 0.16 - ETA: 5:01 - loss: 3.2055 - accuracy: 0.16 - ETA: 5:01 - loss: 3.2197 - accuracy: 0.16 - ETA: 5:01 - loss: 3.2308 - accuracy: 0.16 - ETA: 5:00 - loss: 3.2337 - accuracy: 0.16 - ETA: 5:00 - loss: 3.2479 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2414 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2460 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2447 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2622 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2648 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2711 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2751 - accuracy: 0.15 - ETA: 4:55 - loss: 3.2673 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2741 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2787 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2748 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2801 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2802 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2830 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2851 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2909 - accuracy: 0.14 - ETA: 4:45 - loss: 3.2920 - accuracy: 0.14 - ETA: 4:44 - loss: 3.2902 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2903 - accuracy: 0.14 - ETA: 4:42 - loss: 3.2840 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2855 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2873 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2883 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2913 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2953 - accuracy: 0.15 - ETA: 4:37 - loss: 3.3016 - accuracy: 0.15 - ETA: 4:36 - loss: 3.3089 - accuracy: 0.15 - ETA: 4:35 - loss: 3.3155 - accuracy: 0.15 - ETA: 4:34 - loss: 3.3227 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3276 - accuracy: 0.14 - ETA: 4:33 - loss: 3.3314 - accuracy: 0.14 - ETA: 4:32 - loss: 3.3409 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3429 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3439 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3476 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3506 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3493 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3479 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3456 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3486 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3509 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3534 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3526 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3507 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3524 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3496 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3491 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3485 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3481 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3502 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3489 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3447 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3440 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3445 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3425 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3416 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3402 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3393 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3390 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3393 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3374 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3370 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3373 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3378 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3382 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3402 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3401 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3389 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3389 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3391 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3384 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3395 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3395 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3381 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3376 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3368 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3380 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3384 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3366 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3350 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3344 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3347 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3342 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3324 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3304 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3301 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3317 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3313 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3308 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3306 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3327 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3316 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3311 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3313 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3309 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3308 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3303 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3301 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3280 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3262 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3268 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3260 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3264 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3245 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3242 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3236 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3230 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3233 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3241 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3243 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3244 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3240 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3249 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3253 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3248 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3251 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3253 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3251 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3248 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3243 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3249 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3245 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3239 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3231 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3226 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3222 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3220 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3223 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3213 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3198 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3185 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3169 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3162 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3163 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3162 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3149 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3150 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3154 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3155 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3154 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3167 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3167 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3162 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3171 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3169 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3157 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3156 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3151 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3147 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3146 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3141 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3142 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3132 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3133 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3124 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3114 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3116 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3107 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3096 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3084 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3079 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3078 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3068 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3061 - accuracy: 0.15 - ETA: 2:23 - loss: 3.3055 - accuracy: 0.15 - ETA: 2:22 - loss: 3.3054 - accuracy: 0.15 - ETA: 2:21 - loss: 3.3058 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3043 - accuracy: 0.15 - ETA: 2:19 - loss: 3.3040 - accuracy: 0.15 - ETA: 2:18 - loss: 3.3044 - accuracy: 0.1501"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3037 - accuracy: 0.15 - ETA: 2:16 - loss: 3.3034 - accuracy: 0.15 - ETA: 2:15 - loss: 3.3030 - accuracy: 0.15 - ETA: 2:14 - loss: 3.3029 - accuracy: 0.15 - ETA: 2:13 - loss: 3.3020 - accuracy: 0.15 - ETA: 2:12 - loss: 3.3011 - accuracy: 0.15 - ETA: 2:11 - loss: 3.3007 - accuracy: 0.15 - ETA: 2:10 - loss: 3.3009 - accuracy: 0.15 - ETA: 2:09 - loss: 3.3003 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2992 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2981 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2980 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2978 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2963 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2960 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2965 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2960 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2953 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2953 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2950 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2946 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2947 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2951 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2945 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2942 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2939 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2930 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2939 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2939 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2933 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2935 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2923 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2917 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2913 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2921 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2913 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2910 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2907 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2910 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2908 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2920 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2921 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2911 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2910 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2903 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2904 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2909 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2920 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2922 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2924 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2905 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2895 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2896 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2890 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2888 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2884 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2874 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2880 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2877 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2871 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2864 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2860 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2854 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2853 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2851 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2849 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2838 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2839 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2836 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2838 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2838 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2838 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2833 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2825 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2825 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2815 - accuracy: 0.15 - ETA: 59s - loss: 3.2812 - accuracy: 0.1533 - ETA: 58s - loss: 3.2807 - accuracy: 0.153 - ETA: 57s - loss: 3.2805 - accuracy: 0.153 - ETA: 56s - loss: 3.2802 - accuracy: 0.153 - ETA: 55s - loss: 3.2800 - accuracy: 0.153 - ETA: 54s - loss: 3.2800 - accuracy: 0.153 - ETA: 53s - loss: 3.2797 - accuracy: 0.153 - ETA: 52s - loss: 3.2790 - accuracy: 0.154 - ETA: 51s - loss: 3.2792 - accuracy: 0.154 - ETA: 50s - loss: 3.2794 - accuracy: 0.153 - ETA: 49s - loss: 3.2794 - accuracy: 0.153 - ETA: 48s - loss: 3.2797 - accuracy: 0.153 - ETA: 47s - loss: 3.2805 - accuracy: 0.153 - ETA: 46s - loss: 3.2809 - accuracy: 0.153 - ETA: 46s - loss: 3.2808 - accuracy: 0.153 - ETA: 45s - loss: 3.2809 - accuracy: 0.153 - ETA: 44s - loss: 3.2803 - accuracy: 0.153 - ETA: 43s - loss: 3.2798 - accuracy: 0.154 - ETA: 42s - loss: 3.2800 - accuracy: 0.153 - ETA: 41s - loss: 3.2805 - accuracy: 0.153 - ETA: 40s - loss: 3.2805 - accuracy: 0.153 - ETA: 39s - loss: 3.2803 - accuracy: 0.153 - ETA: 38s - loss: 3.2797 - accuracy: 0.153 - ETA: 37s - loss: 3.2797 - accuracy: 0.153 - ETA: 36s - loss: 3.2800 - accuracy: 0.153 - ETA: 35s - loss: 3.2797 - accuracy: 0.153 - ETA: 34s - loss: 3.2801 - accuracy: 0.153 - ETA: 33s - loss: 3.2801 - accuracy: 0.153 - ETA: 32s - loss: 3.2799 - accuracy: 0.153 - ETA: 31s - loss: 3.2799 - accuracy: 0.153 - ETA: 30s - loss: 3.2791 - accuracy: 0.153 - ETA: 29s - loss: 3.2791 - accuracy: 0.153 - ETA: 28s - loss: 3.2794 - accuracy: 0.153 - ETA: 27s - loss: 3.2798 - accuracy: 0.153 - ETA: 26s - loss: 3.2797 - accuracy: 0.153 - ETA: 25s - loss: 3.2799 - accuracy: 0.153 - ETA: 24s - loss: 3.2796 - accuracy: 0.153 - ETA: 23s - loss: 3.2793 - accuracy: 0.153 - ETA: 23s - loss: 3.2789 - accuracy: 0.153 - ETA: 22s - loss: 3.2786 - accuracy: 0.153 - ETA: 21s - loss: 3.2784 - accuracy: 0.153 - ETA: 20s - loss: 3.2780 - accuracy: 0.153 - ETA: 19s - loss: 3.2776 - accuracy: 0.153 - ETA: 18s - loss: 3.2777 - accuracy: 0.153 - ETA: 17s - loss: 3.2773 - accuracy: 0.153 - ETA: 16s - loss: 3.2768 - accuracy: 0.154 - ETA: 15s - loss: 3.2769 - accuracy: 0.154 - ETA: 14s - loss: 3.2772 - accuracy: 0.153 - ETA: 13s - loss: 3.2767 - accuracy: 0.154 - ETA: 12s - loss: 3.2757 - accuracy: 0.154 - ETA: 11s - loss: 3.2760 - accuracy: 0.154 - ETA: 10s - loss: 3.2760 - accuracy: 0.154 - ETA: 9s - loss: 3.2752 - accuracy: 0.154 - ETA: 8s - loss: 3.2751 - accuracy: 0.15 - ETA: 7s - loss: 3.2753 - accuracy: 0.15 - ETA: 6s - loss: 3.2751 - accuracy: 0.15 - ETA: 5s - loss: 3.2750 - accuracy: 0.15 - ETA: 4s - loss: 3.2752 - accuracy: 0.15 - ETA: 3s - loss: 3.2751 - accuracy: 0.15 - ETA: 2s - loss: 3.2752 - accuracy: 0.15 - ETA: 1s - loss: 3.2753 - accuracy: 0.15 - ETA: 1s - loss: 3.2753 - accuracy: 0.15 - ETA: 0s - loss: 3.2756 - accuracy: 0.15 - 341s 8ms/step - loss: 3.2755 - accuracy: 0.1536 - val_loss: 3.8993 - val_accuracy: 0.0244\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:20 - loss: 3.1743 - accuracy: 0.14 - ETA: 5:20 - loss: 3.1742 - accuracy: 0.14 - ETA: 5:19 - loss: 3.2288 - accuracy: 0.13 - ETA: 5:17 - loss: 3.1979 - accuracy: 0.15 - ETA: 5:14 - loss: 3.2132 - accuracy: 0.15 - ETA: 5:09 - loss: 3.2254 - accuracy: 0.15 - ETA: 5:10 - loss: 3.2240 - accuracy: 0.15 - ETA: 5:09 - loss: 3.2227 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2237 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2196 - accuracy: 0.15 - ETA: 5:08 - loss: 3.2310 - accuracy: 0.15 - ETA: 5:09 - loss: 3.2405 - accuracy: 0.15 - ETA: 5:08 - loss: 3.2511 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2472 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2516 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2595 - accuracy: 0.15 - ETA: 5:04 - loss: 3.2600 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2614 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2608 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2599 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2607 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2453 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2428 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2424 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2426 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2448 - accuracy: 0.15 - ETA: 4:55 - loss: 3.2402 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2454 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2414 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2333 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2381 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2405 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2454 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2496 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2502 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2411 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2385 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2356 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2372 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2389 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2451 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2452 - accuracy: 0.15 - ETA: 4:37 - loss: 3.2525 - accuracy: 0.15 - ETA: 4:36 - loss: 3.2542 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2578 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2594 - accuracy: 0.15 - ETA: 4:33 - loss: 3.2589 - accuracy: 0.15 - ETA: 4:33 - loss: 3.2585 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2603 - accuracy: 0.15 - ETA: 4:31 - loss: 3.2576 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2602 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2625 - accuracy: 0.15 - ETA: 4:29 - loss: 3.2644 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2691 - accuracy: 0.15 - ETA: 4:27 - loss: 3.2685 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2712 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2735 - accuracy: 0.15 - ETA: 4:23 - loss: 3.2745 - accuracy: 0.15 - ETA: 4:22 - loss: 3.2749 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2751 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2758 - accuracy: 0.15 - ETA: 4:20 - loss: 3.2772 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2772 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2743 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2776 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2794 - accuracy: 0.15 - ETA: 4:15 - loss: 3.2805 - accuracy: 0.14 - ETA: 4:14 - loss: 3.2785 - accuracy: 0.14 - ETA: 4:13 - loss: 3.2824 - accuracy: 0.14 - ETA: 4:12 - loss: 3.2819 - accuracy: 0.14 - ETA: 4:11 - loss: 3.2836 - accuracy: 0.14 - ETA: 4:10 - loss: 3.2832 - accuracy: 0.14 - ETA: 4:09 - loss: 3.2818 - accuracy: 0.14 - ETA: 4:08 - loss: 3.2827 - accuracy: 0.14 - ETA: 4:07 - loss: 3.2852 - accuracy: 0.14 - ETA: 4:06 - loss: 3.2852 - accuracy: 0.14 - ETA: 4:05 - loss: 3.2886 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2906 - accuracy: 0.14 - ETA: 4:03 - loss: 3.2902 - accuracy: 0.14 - ETA: 4:02 - loss: 3.2899 - accuracy: 0.14 - ETA: 4:01 - loss: 3.2906 - accuracy: 0.14 - ETA: 4:00 - loss: 3.2914 - accuracy: 0.14 - ETA: 3:59 - loss: 3.2910 - accuracy: 0.14 - ETA: 3:58 - loss: 3.2898 - accuracy: 0.14 - ETA: 3:57 - loss: 3.2919 - accuracy: 0.14 - ETA: 3:56 - loss: 3.2922 - accuracy: 0.14 - ETA: 3:55 - loss: 3.2928 - accuracy: 0.14 - ETA: 3:54 - loss: 3.2924 - accuracy: 0.14 - ETA: 3:53 - loss: 3.2921 - accuracy: 0.14 - ETA: 3:52 - loss: 3.2920 - accuracy: 0.14 - ETA: 3:51 - loss: 3.2923 - accuracy: 0.14 - ETA: 3:50 - loss: 3.2932 - accuracy: 0.14 - ETA: 3:49 - loss: 3.2958 - accuracy: 0.14 - ETA: 3:48 - loss: 3.2954 - accuracy: 0.14 - ETA: 3:47 - loss: 3.2946 - accuracy: 0.14 - ETA: 3:46 - loss: 3.2960 - accuracy: 0.14 - ETA: 3:45 - loss: 3.2946 - accuracy: 0.14 - ETA: 3:44 - loss: 3.2953 - accuracy: 0.14 - ETA: 3:43 - loss: 3.2966 - accuracy: 0.14 - ETA: 3:42 - loss: 3.2982 - accuracy: 0.14 - ETA: 3:41 - loss: 3.2998 - accuracy: 0.14 - ETA: 3:40 - loss: 3.2987 - accuracy: 0.14 - ETA: 3:39 - loss: 3.2983 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2985 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2992 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2995 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3004 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3001 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3007 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2992 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2977 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2992 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3004 - accuracy: 0.14 - ETA: 3:29 - loss: 3.2997 - accuracy: 0.14 - ETA: 3:28 - loss: 3.2996 - accuracy: 0.14 - ETA: 3:27 - loss: 3.2986 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2974 - accuracy: 0.14 - ETA: 3:25 - loss: 3.2965 - accuracy: 0.14 - ETA: 3:24 - loss: 3.2971 - accuracy: 0.14 - ETA: 3:23 - loss: 3.2976 - accuracy: 0.14 - ETA: 3:22 - loss: 3.2990 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3000 - accuracy: 0.14 - ETA: 3:20 - loss: 3.2991 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3003 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2997 - accuracy: 0.14 - ETA: 3:17 - loss: 3.2974 - accuracy: 0.14 - ETA: 3:16 - loss: 3.2967 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2978 - accuracy: 0.14 - ETA: 3:14 - loss: 3.2990 - accuracy: 0.14 - ETA: 3:13 - loss: 3.2996 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2993 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2999 - accuracy: 0.14 - ETA: 3:10 - loss: 3.2996 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2991 - accuracy: 0.14 - ETA: 3:08 - loss: 3.2994 - accuracy: 0.14 - ETA: 3:07 - loss: 3.2993 - accuracy: 0.14 - ETA: 3:06 - loss: 3.2991 - accuracy: 0.14 - ETA: 3:05 - loss: 3.2980 - accuracy: 0.14 - ETA: 3:04 - loss: 3.2985 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2982 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2980 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2971 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2983 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2989 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2988 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2988 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2998 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2999 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2998 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2982 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2964 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2945 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2942 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2944 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2940 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2934 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2940 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2938 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2926 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2930 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2932 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2922 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2920 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2927 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2911 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2908 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2892 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2886 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2886 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2884 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2888 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2881 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2878 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2866 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2865 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2853 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2848 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2840 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2839 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2829 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2831 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2837 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2825 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2813 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2803 - accuracy: 0.1491"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.2805 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2804 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2799 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2803 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2803 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2808 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2805 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2814 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2807 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2818 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2818 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2813 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2821 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2811 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2803 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2797 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2799 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2791 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2787 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2785 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2791 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2789 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2797 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2794 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2787 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2780 - accuracy: 0.14 - ETA: 1:53 - loss: 3.2782 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2773 - accuracy: 0.14 - ETA: 1:51 - loss: 3.2772 - accuracy: 0.14 - ETA: 1:50 - loss: 3.2772 - accuracy: 0.14 - ETA: 1:49 - loss: 3.2761 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2763 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2756 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2752 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2758 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2755 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2745 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2738 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2735 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2730 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2735 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2729 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2733 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2721 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2713 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2715 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2711 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2715 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2715 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2711 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2701 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2710 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2708 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2702 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2690 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2687 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2690 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2690 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2686 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2683 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2681 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2682 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2673 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2666 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2669 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2676 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2675 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2672 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2667 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2663 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2659 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2652 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2657 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2658 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2666 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2659 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2660 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2660 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2659 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2657 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2653 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2647 - accuracy: 0.15 - ETA: 59s - loss: 3.2645 - accuracy: 0.1533 - ETA: 58s - loss: 3.2649 - accuracy: 0.153 - ETA: 57s - loss: 3.2646 - accuracy: 0.153 - ETA: 56s - loss: 3.2654 - accuracy: 0.153 - ETA: 55s - loss: 3.2652 - accuracy: 0.153 - ETA: 54s - loss: 3.2654 - accuracy: 0.153 - ETA: 53s - loss: 3.2658 - accuracy: 0.153 - ETA: 52s - loss: 3.2663 - accuracy: 0.153 - ETA: 52s - loss: 3.2660 - accuracy: 0.153 - ETA: 51s - loss: 3.2660 - accuracy: 0.153 - ETA: 50s - loss: 3.2659 - accuracy: 0.153 - ETA: 49s - loss: 3.2656 - accuracy: 0.153 - ETA: 48s - loss: 3.2659 - accuracy: 0.153 - ETA: 47s - loss: 3.2660 - accuracy: 0.153 - ETA: 46s - loss: 3.2659 - accuracy: 0.153 - ETA: 45s - loss: 3.2660 - accuracy: 0.153 - ETA: 44s - loss: 3.2655 - accuracy: 0.153 - ETA: 43s - loss: 3.2657 - accuracy: 0.153 - ETA: 42s - loss: 3.2659 - accuracy: 0.153 - ETA: 41s - loss: 3.2659 - accuracy: 0.153 - ETA: 40s - loss: 3.2663 - accuracy: 0.153 - ETA: 39s - loss: 3.2666 - accuracy: 0.153 - ETA: 38s - loss: 3.2662 - accuracy: 0.153 - ETA: 37s - loss: 3.2655 - accuracy: 0.153 - ETA: 36s - loss: 3.2659 - accuracy: 0.153 - ETA: 35s - loss: 3.2655 - accuracy: 0.153 - ETA: 34s - loss: 3.2658 - accuracy: 0.153 - ETA: 33s - loss: 3.2657 - accuracy: 0.153 - ETA: 32s - loss: 3.2655 - accuracy: 0.153 - ETA: 31s - loss: 3.2655 - accuracy: 0.153 - ETA: 30s - loss: 3.2665 - accuracy: 0.153 - ETA: 29s - loss: 3.2663 - accuracy: 0.153 - ETA: 28s - loss: 3.2662 - accuracy: 0.153 - ETA: 27s - loss: 3.2665 - accuracy: 0.153 - ETA: 27s - loss: 3.2663 - accuracy: 0.153 - ETA: 26s - loss: 3.2662 - accuracy: 0.153 - ETA: 25s - loss: 3.2662 - accuracy: 0.153 - ETA: 24s - loss: 3.2661 - accuracy: 0.153 - ETA: 23s - loss: 3.2655 - accuracy: 0.153 - ETA: 22s - loss: 3.2653 - accuracy: 0.153 - ETA: 21s - loss: 3.2652 - accuracy: 0.153 - ETA: 20s - loss: 3.2652 - accuracy: 0.153 - ETA: 19s - loss: 3.2650 - accuracy: 0.153 - ETA: 18s - loss: 3.2647 - accuracy: 0.153 - ETA: 17s - loss: 3.2643 - accuracy: 0.153 - ETA: 16s - loss: 3.2643 - accuracy: 0.153 - ETA: 15s - loss: 3.2640 - accuracy: 0.153 - ETA: 14s - loss: 3.2637 - accuracy: 0.153 - ETA: 13s - loss: 3.2638 - accuracy: 0.153 - ETA: 12s - loss: 3.2634 - accuracy: 0.154 - ETA: 11s - loss: 3.2641 - accuracy: 0.154 - ETA: 10s - loss: 3.2638 - accuracy: 0.154 - ETA: 9s - loss: 3.2631 - accuracy: 0.154 - ETA: 8s - loss: 3.2624 - accuracy: 0.15 - ETA: 7s - loss: 3.2624 - accuracy: 0.15 - ETA: 6s - loss: 3.2624 - accuracy: 0.15 - ETA: 5s - loss: 3.2624 - accuracy: 0.15 - ETA: 4s - loss: 3.2628 - accuracy: 0.15 - ETA: 3s - loss: 3.2633 - accuracy: 0.15 - ETA: 2s - loss: 3.2640 - accuracy: 0.15 - ETA: 1s - loss: 3.2644 - accuracy: 0.15 - ETA: 1s - loss: 3.2648 - accuracy: 0.15 - ETA: 0s - loss: 3.2646 - accuracy: 0.15 - 343s 8ms/step - loss: 3.2646 - accuracy: 0.1542 - val_loss: 3.8849 - val_accuracy: 0.0192\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:04 - loss: 3.0706 - accuracy: 0.18 - ETA: 5:10 - loss: 3.1832 - accuracy: 0.16 - ETA: 5:12 - loss: 3.2203 - accuracy: 0.16 - ETA: 5:14 - loss: 3.1959 - accuracy: 0.16 - ETA: 5:11 - loss: 3.2099 - accuracy: 0.16 - ETA: 5:08 - loss: 3.2218 - accuracy: 0.16 - ETA: 5:11 - loss: 3.2403 - accuracy: 0.16 - ETA: 5:10 - loss: 3.2334 - accuracy: 0.15 - ETA: 5:12 - loss: 3.2219 - accuracy: 0.15 - ETA: 5:11 - loss: 3.2266 - accuracy: 0.15 - ETA: 5:11 - loss: 3.2354 - accuracy: 0.15 - ETA: 5:11 - loss: 3.2370 - accuracy: 0.15 - ETA: 5:08 - loss: 3.2454 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2529 - accuracy: 0.15 - ETA: 5:06 - loss: 3.2622 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2612 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2561 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2532 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2509 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2405 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2401 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2417 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2431 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2456 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2487 - accuracy: 0.15 - ETA: 4:55 - loss: 3.2540 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2468 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2491 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2454 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2421 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2391 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2373 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2354 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2392 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2406 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2439 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2418 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2391 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2333 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2338 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2275 - accuracy: 0.16 - ETA: 4:37 - loss: 3.2281 - accuracy: 0.16 - ETA: 4:36 - loss: 3.2345 - accuracy: 0.16 - ETA: 4:35 - loss: 3.2384 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2430 - accuracy: 0.15 - ETA: 4:33 - loss: 3.2409 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2391 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2413 - accuracy: 0.15 - ETA: 4:29 - loss: 3.2435 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2421 - accuracy: 0.16 - ETA: 4:27 - loss: 3.2429 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2431 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2447 - accuracy: 0.16 - ETA: 4:24 - loss: 3.2446 - accuracy: 0.16 - ETA: 4:23 - loss: 3.2424 - accuracy: 0.16 - ETA: 4:22 - loss: 3.2430 - accuracy: 0.16 - ETA: 4:21 - loss: 3.2434 - accuracy: 0.16 - ETA: 4:20 - loss: 3.2426 - accuracy: 0.16 - ETA: 4:19 - loss: 3.2377 - accuracy: 0.16 - ETA: 4:18 - loss: 3.2363 - accuracy: 0.16 - ETA: 4:17 - loss: 3.2358 - accuracy: 0.16 - ETA: 4:16 - loss: 3.2371 - accuracy: 0.16 - ETA: 4:15 - loss: 3.2410 - accuracy: 0.16 - ETA: 4:14 - loss: 3.2403 - accuracy: 0.16 - ETA: 4:13 - loss: 3.2387 - accuracy: 0.16 - ETA: 4:12 - loss: 3.2398 - accuracy: 0.16 - ETA: 4:11 - loss: 3.2404 - accuracy: 0.16 - ETA: 4:10 - loss: 3.2407 - accuracy: 0.16 - ETA: 4:09 - loss: 3.2386 - accuracy: 0.16 - ETA: 4:08 - loss: 3.2361 - accuracy: 0.16 - ETA: 4:07 - loss: 3.2337 - accuracy: 0.16 - ETA: 4:06 - loss: 3.2349 - accuracy: 0.16 - ETA: 4:05 - loss: 3.2328 - accuracy: 0.16 - ETA: 4:05 - loss: 3.2332 - accuracy: 0.16 - ETA: 4:04 - loss: 3.2320 - accuracy: 0.16 - ETA: 4:02 - loss: 3.2328 - accuracy: 0.16 - ETA: 4:02 - loss: 3.2341 - accuracy: 0.16 - ETA: 4:01 - loss: 3.2356 - accuracy: 0.16 - ETA: 4:00 - loss: 3.2366 - accuracy: 0.16 - ETA: 3:59 - loss: 3.2372 - accuracy: 0.16 - ETA: 3:58 - loss: 3.2374 - accuracy: 0.16 - ETA: 3:57 - loss: 3.2367 - accuracy: 0.16 - ETA: 3:56 - loss: 3.2350 - accuracy: 0.16 - ETA: 3:55 - loss: 3.2372 - accuracy: 0.16 - ETA: 3:54 - loss: 3.2404 - accuracy: 0.16 - ETA: 3:53 - loss: 3.2417 - accuracy: 0.16 - ETA: 3:52 - loss: 3.2409 - accuracy: 0.16 - ETA: 3:51 - loss: 3.2409 - accuracy: 0.16 - ETA: 3:50 - loss: 3.2384 - accuracy: 0.16 - ETA: 3:50 - loss: 3.2373 - accuracy: 0.16 - ETA: 3:49 - loss: 3.2392 - accuracy: 0.16 - ETA: 3:48 - loss: 3.2385 - accuracy: 0.16 - ETA: 3:47 - loss: 3.2384 - accuracy: 0.16 - ETA: 3:46 - loss: 3.2395 - accuracy: 0.16 - ETA: 3:45 - loss: 3.2403 - accuracy: 0.16 - ETA: 3:44 - loss: 3.2404 - accuracy: 0.16 - ETA: 3:43 - loss: 3.2390 - accuracy: 0.16 - ETA: 3:42 - loss: 3.2399 - accuracy: 0.16 - ETA: 3:41 - loss: 3.2401 - accuracy: 0.16 - ETA: 3:40 - loss: 3.2409 - accuracy: 0.16 - ETA: 3:40 - loss: 3.2398 - accuracy: 0.16 - ETA: 3:39 - loss: 3.2407 - accuracy: 0.16 - ETA: 3:38 - loss: 3.2419 - accuracy: 0.16 - ETA: 3:37 - loss: 3.2438 - accuracy: 0.16 - ETA: 3:36 - loss: 3.2426 - accuracy: 0.16 - ETA: 3:35 - loss: 3.2421 - accuracy: 0.16 - ETA: 3:34 - loss: 3.2426 - accuracy: 0.16 - ETA: 3:33 - loss: 3.2430 - accuracy: 0.16 - ETA: 3:32 - loss: 3.2431 - accuracy: 0.16 - ETA: 3:31 - loss: 3.2435 - accuracy: 0.16 - ETA: 3:30 - loss: 3.2431 - accuracy: 0.16 - ETA: 3:29 - loss: 3.2408 - accuracy: 0.16 - ETA: 3:28 - loss: 3.2406 - accuracy: 0.16 - ETA: 3:27 - loss: 3.2397 - accuracy: 0.16 - ETA: 3:26 - loss: 3.2384 - accuracy: 0.16 - ETA: 3:25 - loss: 3.2360 - accuracy: 0.16 - ETA: 3:24 - loss: 3.2363 - accuracy: 0.16 - ETA: 3:23 - loss: 3.2352 - accuracy: 0.16 - ETA: 3:22 - loss: 3.2358 - accuracy: 0.16 - ETA: 3:21 - loss: 3.2355 - accuracy: 0.16 - ETA: 3:20 - loss: 3.2351 - accuracy: 0.16 - ETA: 3:19 - loss: 3.2351 - accuracy: 0.16 - ETA: 3:18 - loss: 3.2352 - accuracy: 0.16 - ETA: 3:17 - loss: 3.2348 - accuracy: 0.16 - ETA: 3:16 - loss: 3.2344 - accuracy: 0.16 - ETA: 3:15 - loss: 3.2352 - accuracy: 0.16 - ETA: 3:14 - loss: 3.2358 - accuracy: 0.16 - ETA: 3:13 - loss: 3.2362 - accuracy: 0.16 - ETA: 3:12 - loss: 3.2370 - accuracy: 0.16 - ETA: 3:12 - loss: 3.2370 - accuracy: 0.16 - ETA: 3:11 - loss: 3.2366 - accuracy: 0.16 - ETA: 3:09 - loss: 3.2369 - accuracy: 0.16 - ETA: 3:08 - loss: 3.2373 - accuracy: 0.16 - ETA: 3:08 - loss: 3.2368 - accuracy: 0.16 - ETA: 3:07 - loss: 3.2350 - accuracy: 0.16 - ETA: 3:06 - loss: 3.2352 - accuracy: 0.16 - ETA: 3:05 - loss: 3.2349 - accuracy: 0.16 - ETA: 3:04 - loss: 3.2341 - accuracy: 0.16 - ETA: 3:03 - loss: 3.2336 - accuracy: 0.16 - ETA: 3:02 - loss: 3.2343 - accuracy: 0.16 - ETA: 3:01 - loss: 3.2332 - accuracy: 0.16 - ETA: 3:00 - loss: 3.2318 - accuracy: 0.16 - ETA: 2:59 - loss: 3.2314 - accuracy: 0.16 - ETA: 2:58 - loss: 3.2310 - accuracy: 0.16 - ETA: 2:57 - loss: 3.2307 - accuracy: 0.16 - ETA: 2:57 - loss: 3.2302 - accuracy: 0.16 - ETA: 2:56 - loss: 3.2294 - accuracy: 0.16 - ETA: 2:55 - loss: 3.2305 - accuracy: 0.16 - ETA: 2:54 - loss: 3.2300 - accuracy: 0.16 - ETA: 2:53 - loss: 3.2295 - accuracy: 0.16 - ETA: 2:52 - loss: 3.2298 - accuracy: 0.16 - ETA: 2:51 - loss: 3.2307 - accuracy: 0.16 - ETA: 2:50 - loss: 3.2307 - accuracy: 0.16 - ETA: 2:49 - loss: 3.2301 - accuracy: 0.16 - ETA: 2:48 - loss: 3.2310 - accuracy: 0.16 - ETA: 2:47 - loss: 3.2321 - accuracy: 0.16 - ETA: 2:46 - loss: 3.2326 - accuracy: 0.16 - ETA: 2:45 - loss: 3.2310 - accuracy: 0.16 - ETA: 2:44 - loss: 3.2321 - accuracy: 0.16 - ETA: 2:43 - loss: 3.2327 - accuracy: 0.16 - ETA: 2:42 - loss: 3.2312 - accuracy: 0.16 - ETA: 2:41 - loss: 3.2307 - accuracy: 0.16 - ETA: 2:40 - loss: 3.2313 - accuracy: 0.16 - ETA: 2:39 - loss: 3.2319 - accuracy: 0.16 - ETA: 2:38 - loss: 3.2301 - accuracy: 0.16 - ETA: 2:37 - loss: 3.2294 - accuracy: 0.16 - ETA: 2:36 - loss: 3.2293 - accuracy: 0.16 - ETA: 2:35 - loss: 3.2301 - accuracy: 0.16 - ETA: 2:34 - loss: 3.2297 - accuracy: 0.16 - ETA: 2:33 - loss: 3.2303 - accuracy: 0.16 - ETA: 2:32 - loss: 3.2311 - accuracy: 0.16 - ETA: 2:32 - loss: 3.2315 - accuracy: 0.16 - ETA: 2:31 - loss: 3.2320 - accuracy: 0.16 - ETA: 2:29 - loss: 3.2316 - accuracy: 0.16 - ETA: 2:29 - loss: 3.2323 - accuracy: 0.16 - ETA: 2:28 - loss: 3.2326 - accuracy: 0.16 - ETA: 2:27 - loss: 3.2338 - accuracy: 0.16 - ETA: 2:26 - loss: 3.2336 - accuracy: 0.16 - ETA: 2:25 - loss: 3.2335 - accuracy: 0.16 - ETA: 2:24 - loss: 3.2340 - accuracy: 0.16 - ETA: 2:23 - loss: 3.2334 - accuracy: 0.16 - ETA: 2:22 - loss: 3.2342 - accuracy: 0.16 - ETA: 2:21 - loss: 3.2343 - accuracy: 0.16 - ETA: 2:20 - loss: 3.2350 - accuracy: 0.16 - ETA: 2:19 - loss: 3.2349 - accuracy: 0.16 - ETA: 2:18 - loss: 3.2345 - accuracy: 0.1628"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.2345 - accuracy: 0.16 - ETA: 2:16 - loss: 3.2350 - accuracy: 0.16 - ETA: 2:15 - loss: 3.2346 - accuracy: 0.16 - ETA: 2:14 - loss: 3.2347 - accuracy: 0.16 - ETA: 2:13 - loss: 3.2349 - accuracy: 0.16 - ETA: 2:12 - loss: 3.2349 - accuracy: 0.16 - ETA: 2:11 - loss: 3.2355 - accuracy: 0.16 - ETA: 2:10 - loss: 3.2366 - accuracy: 0.16 - ETA: 2:10 - loss: 3.2374 - accuracy: 0.16 - ETA: 2:09 - loss: 3.2379 - accuracy: 0.16 - ETA: 2:08 - loss: 3.2379 - accuracy: 0.16 - ETA: 2:07 - loss: 3.2376 - accuracy: 0.16 - ETA: 2:06 - loss: 3.2373 - accuracy: 0.16 - ETA: 2:05 - loss: 3.2368 - accuracy: 0.16 - ETA: 2:04 - loss: 3.2363 - accuracy: 0.16 - ETA: 2:03 - loss: 3.2360 - accuracy: 0.16 - ETA: 2:02 - loss: 3.2363 - accuracy: 0.16 - ETA: 2:01 - loss: 3.2366 - accuracy: 0.16 - ETA: 2:00 - loss: 3.2359 - accuracy: 0.16 - ETA: 1:59 - loss: 3.2366 - accuracy: 0.16 - ETA: 1:58 - loss: 3.2372 - accuracy: 0.16 - ETA: 1:57 - loss: 3.2376 - accuracy: 0.16 - ETA: 1:56 - loss: 3.2371 - accuracy: 0.16 - ETA: 1:55 - loss: 3.2376 - accuracy: 0.16 - ETA: 1:54 - loss: 3.2384 - accuracy: 0.16 - ETA: 1:53 - loss: 3.2379 - accuracy: 0.16 - ETA: 1:52 - loss: 3.2384 - accuracy: 0.16 - ETA: 1:51 - loss: 3.2400 - accuracy: 0.16 - ETA: 1:50 - loss: 3.2411 - accuracy: 0.16 - ETA: 1:49 - loss: 3.2423 - accuracy: 0.16 - ETA: 1:48 - loss: 3.2429 - accuracy: 0.16 - ETA: 1:47 - loss: 3.2436 - accuracy: 0.16 - ETA: 1:46 - loss: 3.2430 - accuracy: 0.16 - ETA: 1:46 - loss: 3.2422 - accuracy: 0.16 - ETA: 1:45 - loss: 3.2418 - accuracy: 0.16 - ETA: 1:44 - loss: 3.2418 - accuracy: 0.16 - ETA: 1:43 - loss: 3.2418 - accuracy: 0.16 - ETA: 1:42 - loss: 3.2415 - accuracy: 0.16 - ETA: 1:41 - loss: 3.2407 - accuracy: 0.16 - ETA: 1:40 - loss: 3.2414 - accuracy: 0.16 - ETA: 1:39 - loss: 3.2422 - accuracy: 0.16 - ETA: 1:38 - loss: 3.2425 - accuracy: 0.16 - ETA: 1:37 - loss: 3.2428 - accuracy: 0.16 - ETA: 1:36 - loss: 3.2429 - accuracy: 0.16 - ETA: 1:35 - loss: 3.2423 - accuracy: 0.16 - ETA: 1:34 - loss: 3.2422 - accuracy: 0.16 - ETA: 1:33 - loss: 3.2422 - accuracy: 0.16 - ETA: 1:32 - loss: 3.2421 - accuracy: 0.16 - ETA: 1:31 - loss: 3.2416 - accuracy: 0.16 - ETA: 1:30 - loss: 3.2415 - accuracy: 0.16 - ETA: 1:29 - loss: 3.2413 - accuracy: 0.16 - ETA: 1:28 - loss: 3.2407 - accuracy: 0.16 - ETA: 1:27 - loss: 3.2405 - accuracy: 0.16 - ETA: 1:27 - loss: 3.2416 - accuracy: 0.16 - ETA: 1:26 - loss: 3.2422 - accuracy: 0.16 - ETA: 1:25 - loss: 3.2422 - accuracy: 0.16 - ETA: 1:24 - loss: 3.2415 - accuracy: 0.16 - ETA: 1:23 - loss: 3.2420 - accuracy: 0.16 - ETA: 1:22 - loss: 3.2419 - accuracy: 0.16 - ETA: 1:21 - loss: 3.2420 - accuracy: 0.16 - ETA: 1:20 - loss: 3.2418 - accuracy: 0.16 - ETA: 1:19 - loss: 3.2426 - accuracy: 0.16 - ETA: 1:18 - loss: 3.2424 - accuracy: 0.16 - ETA: 1:17 - loss: 3.2420 - accuracy: 0.16 - ETA: 1:16 - loss: 3.2421 - accuracy: 0.16 - ETA: 1:15 - loss: 3.2415 - accuracy: 0.16 - ETA: 1:14 - loss: 3.2413 - accuracy: 0.16 - ETA: 1:13 - loss: 3.2417 - accuracy: 0.16 - ETA: 1:12 - loss: 3.2414 - accuracy: 0.16 - ETA: 1:11 - loss: 3.2408 - accuracy: 0.16 - ETA: 1:10 - loss: 3.2404 - accuracy: 0.16 - ETA: 1:09 - loss: 3.2405 - accuracy: 0.16 - ETA: 1:08 - loss: 3.2394 - accuracy: 0.16 - ETA: 1:08 - loss: 3.2394 - accuracy: 0.16 - ETA: 1:07 - loss: 3.2383 - accuracy: 0.16 - ETA: 1:06 - loss: 3.2380 - accuracy: 0.16 - ETA: 1:05 - loss: 3.2382 - accuracy: 0.16 - ETA: 1:04 - loss: 3.2385 - accuracy: 0.16 - ETA: 1:03 - loss: 3.2387 - accuracy: 0.16 - ETA: 1:02 - loss: 3.2391 - accuracy: 0.16 - ETA: 1:01 - loss: 3.2389 - accuracy: 0.16 - ETA: 1:00 - loss: 3.2392 - accuracy: 0.16 - ETA: 59s - loss: 3.2401 - accuracy: 0.1618 - ETA: 58s - loss: 3.2404 - accuracy: 0.161 - ETA: 57s - loss: 3.2405 - accuracy: 0.161 - ETA: 56s - loss: 3.2404 - accuracy: 0.161 - ETA: 55s - loss: 3.2401 - accuracy: 0.161 - ETA: 54s - loss: 3.2405 - accuracy: 0.161 - ETA: 53s - loss: 3.2400 - accuracy: 0.162 - ETA: 52s - loss: 3.2397 - accuracy: 0.162 - ETA: 51s - loss: 3.2405 - accuracy: 0.162 - ETA: 50s - loss: 3.2407 - accuracy: 0.161 - ETA: 49s - loss: 3.2400 - accuracy: 0.162 - ETA: 48s - loss: 3.2396 - accuracy: 0.162 - ETA: 47s - loss: 3.2393 - accuracy: 0.162 - ETA: 46s - loss: 3.2396 - accuracy: 0.162 - ETA: 45s - loss: 3.2397 - accuracy: 0.162 - ETA: 44s - loss: 3.2395 - accuracy: 0.161 - ETA: 43s - loss: 3.2400 - accuracy: 0.161 - ETA: 43s - loss: 3.2403 - accuracy: 0.161 - ETA: 42s - loss: 3.2404 - accuracy: 0.161 - ETA: 41s - loss: 3.2402 - accuracy: 0.161 - ETA: 40s - loss: 3.2394 - accuracy: 0.161 - ETA: 39s - loss: 3.2393 - accuracy: 0.161 - ETA: 38s - loss: 3.2387 - accuracy: 0.162 - ETA: 37s - loss: 3.2386 - accuracy: 0.162 - ETA: 36s - loss: 3.2389 - accuracy: 0.162 - ETA: 35s - loss: 3.2383 - accuracy: 0.162 - ETA: 34s - loss: 3.2384 - accuracy: 0.162 - ETA: 33s - loss: 3.2386 - accuracy: 0.162 - ETA: 32s - loss: 3.2383 - accuracy: 0.162 - ETA: 31s - loss: 3.2381 - accuracy: 0.162 - ETA: 30s - loss: 3.2384 - accuracy: 0.162 - ETA: 29s - loss: 3.2395 - accuracy: 0.161 - ETA: 28s - loss: 3.2396 - accuracy: 0.161 - ETA: 27s - loss: 3.2394 - accuracy: 0.161 - ETA: 26s - loss: 3.2393 - accuracy: 0.161 - ETA: 25s - loss: 3.2395 - accuracy: 0.162 - ETA: 24s - loss: 3.2394 - accuracy: 0.162 - ETA: 24s - loss: 3.2393 - accuracy: 0.162 - ETA: 23s - loss: 3.2396 - accuracy: 0.162 - ETA: 22s - loss: 3.2403 - accuracy: 0.161 - ETA: 21s - loss: 3.2404 - accuracy: 0.162 - ETA: 20s - loss: 3.2405 - accuracy: 0.162 - ETA: 19s - loss: 3.2418 - accuracy: 0.161 - ETA: 18s - loss: 3.2416 - accuracy: 0.162 - ETA: 17s - loss: 3.2416 - accuracy: 0.161 - ETA: 16s - loss: 3.2420 - accuracy: 0.161 - ETA: 15s - loss: 3.2425 - accuracy: 0.161 - ETA: 14s - loss: 3.2422 - accuracy: 0.161 - ETA: 13s - loss: 3.2424 - accuracy: 0.161 - ETA: 12s - loss: 3.2426 - accuracy: 0.161 - ETA: 11s - loss: 3.2425 - accuracy: 0.161 - ETA: 10s - loss: 3.2422 - accuracy: 0.161 - ETA: 9s - loss: 3.2430 - accuracy: 0.161 - ETA: 8s - loss: 3.2434 - accuracy: 0.16 - ETA: 7s - loss: 3.2438 - accuracy: 0.16 - ETA: 6s - loss: 3.2440 - accuracy: 0.16 - ETA: 5s - loss: 3.2438 - accuracy: 0.16 - ETA: 4s - loss: 3.2440 - accuracy: 0.16 - ETA: 3s - loss: 3.2438 - accuracy: 0.16 - ETA: 2s - loss: 3.2439 - accuracy: 0.16 - ETA: 1s - loss: 3.2436 - accuracy: 0.16 - ETA: 1s - loss: 3.2436 - accuracy: 0.16 - ETA: 0s - loss: 3.2436 - accuracy: 0.16 - 341s 8ms/step - loss: 3.2437 - accuracy: 0.1618 - val_loss: 3.8996 - val_accuracy: 0.0254\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:27 - loss: 3.2231 - accuracy: 0.16 - ETA: 5:23 - loss: 3.2559 - accuracy: 0.15 - ETA: 5:24 - loss: 3.2918 - accuracy: 0.17 - ETA: 5:25 - loss: 3.3326 - accuracy: 0.16 - ETA: 5:19 - loss: 3.3558 - accuracy: 0.15 - ETA: 5:16 - loss: 3.3619 - accuracy: 0.15 - ETA: 5:14 - loss: 3.3686 - accuracy: 0.15 - ETA: 5:11 - loss: 3.3398 - accuracy: 0.15 - ETA: 5:07 - loss: 3.3424 - accuracy: 0.15 - ETA: 5:03 - loss: 3.3432 - accuracy: 0.15 - ETA: 5:03 - loss: 3.3444 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3485 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3603 - accuracy: 0.14 - ETA: 4:59 - loss: 3.3546 - accuracy: 0.15 - ETA: 4:58 - loss: 3.3533 - accuracy: 0.15 - ETA: 4:58 - loss: 3.3569 - accuracy: 0.15 - ETA: 4:58 - loss: 3.3488 - accuracy: 0.15 - ETA: 4:57 - loss: 3.3542 - accuracy: 0.15 - ETA: 4:57 - loss: 3.3479 - accuracy: 0.15 - ETA: 4:56 - loss: 3.3461 - accuracy: 0.15 - ETA: 4:54 - loss: 3.3531 - accuracy: 0.15 - ETA: 4:54 - loss: 3.3512 - accuracy: 0.15 - ETA: 4:53 - loss: 3.3543 - accuracy: 0.15 - ETA: 4:52 - loss: 3.3505 - accuracy: 0.15 - ETA: 4:52 - loss: 3.3522 - accuracy: 0.15 - ETA: 4:50 - loss: 3.3501 - accuracy: 0.15 - ETA: 4:49 - loss: 3.3464 - accuracy: 0.15 - ETA: 4:48 - loss: 3.3431 - accuracy: 0.15 - ETA: 4:47 - loss: 3.3370 - accuracy: 0.15 - ETA: 4:46 - loss: 3.3341 - accuracy: 0.15 - ETA: 4:45 - loss: 3.3304 - accuracy: 0.15 - ETA: 4:44 - loss: 3.3333 - accuracy: 0.15 - ETA: 4:43 - loss: 3.3311 - accuracy: 0.15 - ETA: 4:42 - loss: 3.3325 - accuracy: 0.15 - ETA: 4:41 - loss: 3.3364 - accuracy: 0.15 - ETA: 4:40 - loss: 3.3376 - accuracy: 0.15 - ETA: 4:39 - loss: 3.3401 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3400 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3357 - accuracy: 0.15 - ETA: 4:36 - loss: 3.3345 - accuracy: 0.15 - ETA: 4:36 - loss: 3.3317 - accuracy: 0.15 - ETA: 4:34 - loss: 3.3331 - accuracy: 0.15 - ETA: 4:33 - loss: 3.3306 - accuracy: 0.15 - ETA: 4:32 - loss: 3.3310 - accuracy: 0.15 - ETA: 4:31 - loss: 3.3333 - accuracy: 0.15 - ETA: 4:30 - loss: 3.3288 - accuracy: 0.15 - ETA: 4:29 - loss: 3.3282 - accuracy: 0.15 - ETA: 4:28 - loss: 3.3274 - accuracy: 0.15 - ETA: 4:27 - loss: 3.3262 - accuracy: 0.15 - ETA: 4:26 - loss: 3.3241 - accuracy: 0.15 - ETA: 4:25 - loss: 3.3217 - accuracy: 0.15 - ETA: 4:24 - loss: 3.3217 - accuracy: 0.15 - ETA: 4:23 - loss: 3.3252 - accuracy: 0.15 - ETA: 4:22 - loss: 3.3232 - accuracy: 0.15 - ETA: 4:21 - loss: 3.3249 - accuracy: 0.15 - ETA: 4:20 - loss: 3.3223 - accuracy: 0.15 - ETA: 4:19 - loss: 3.3200 - accuracy: 0.15 - ETA: 4:18 - loss: 3.3232 - accuracy: 0.15 - ETA: 4:17 - loss: 3.3184 - accuracy: 0.15 - ETA: 4:16 - loss: 3.3171 - accuracy: 0.15 - ETA: 4:15 - loss: 3.3174 - accuracy: 0.15 - ETA: 4:14 - loss: 3.3139 - accuracy: 0.15 - ETA: 4:13 - loss: 3.3132 - accuracy: 0.15 - ETA: 4:12 - loss: 3.3114 - accuracy: 0.15 - ETA: 4:11 - loss: 3.3121 - accuracy: 0.15 - ETA: 4:10 - loss: 3.3137 - accuracy: 0.15 - ETA: 4:09 - loss: 3.3121 - accuracy: 0.15 - ETA: 4:08 - loss: 3.3121 - accuracy: 0.15 - ETA: 4:08 - loss: 3.3105 - accuracy: 0.15 - ETA: 4:06 - loss: 3.3102 - accuracy: 0.15 - ETA: 4:06 - loss: 3.3122 - accuracy: 0.15 - ETA: 4:05 - loss: 3.3130 - accuracy: 0.15 - ETA: 4:04 - loss: 3.3120 - accuracy: 0.15 - ETA: 4:03 - loss: 3.3135 - accuracy: 0.15 - ETA: 4:02 - loss: 3.3146 - accuracy: 0.15 - ETA: 4:01 - loss: 3.3170 - accuracy: 0.15 - ETA: 4:00 - loss: 3.3172 - accuracy: 0.15 - ETA: 3:59 - loss: 3.3171 - accuracy: 0.15 - ETA: 3:58 - loss: 3.3183 - accuracy: 0.15 - ETA: 3:57 - loss: 3.3176 - accuracy: 0.15 - ETA: 3:57 - loss: 3.3197 - accuracy: 0.15 - ETA: 3:56 - loss: 3.3167 - accuracy: 0.15 - ETA: 3:55 - loss: 3.3174 - accuracy: 0.15 - ETA: 3:54 - loss: 3.3185 - accuracy: 0.15 - ETA: 3:53 - loss: 3.3202 - accuracy: 0.15 - ETA: 3:52 - loss: 3.3204 - accuracy: 0.15 - ETA: 3:51 - loss: 3.3215 - accuracy: 0.15 - ETA: 3:50 - loss: 3.3397 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3379 - accuracy: 0.15 - ETA: 3:48 - loss: 3.3367 - accuracy: 0.15 - ETA: 3:47 - loss: 3.3366 - accuracy: 0.15 - ETA: 3:46 - loss: 3.3361 - accuracy: 0.15 - ETA: 3:45 - loss: 3.3359 - accuracy: 0.15 - ETA: 3:44 - loss: 3.3380 - accuracy: 0.15 - ETA: 3:43 - loss: 3.3361 - accuracy: 0.15 - ETA: 3:42 - loss: 3.3338 - accuracy: 0.15 - ETA: 3:41 - loss: 3.3336 - accuracy: 0.15 - ETA: 3:41 - loss: 3.3332 - accuracy: 0.15 - ETA: 3:40 - loss: 3.3319 - accuracy: 0.15 - ETA: 3:39 - loss: 3.3307 - accuracy: 0.15 - ETA: 3:38 - loss: 3.3290 - accuracy: 0.15 - ETA: 3:37 - loss: 3.3284 - accuracy: 0.15 - ETA: 3:36 - loss: 3.3291 - accuracy: 0.15 - ETA: 3:35 - loss: 3.3294 - accuracy: 0.15 - ETA: 3:34 - loss: 3.3300 - accuracy: 0.15 - ETA: 3:33 - loss: 3.3309 - accuracy: 0.15 - ETA: 3:32 - loss: 3.3300 - accuracy: 0.15 - ETA: 3:31 - loss: 3.3296 - accuracy: 0.15 - ETA: 3:30 - loss: 3.3307 - accuracy: 0.15 - ETA: 3:29 - loss: 3.3296 - accuracy: 0.15 - ETA: 3:28 - loss: 3.3310 - accuracy: 0.15 - ETA: 3:27 - loss: 3.3316 - accuracy: 0.15 - ETA: 3:26 - loss: 3.3325 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3313 - accuracy: 0.15 - ETA: 3:25 - loss: 3.3322 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3323 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3317 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3298 - accuracy: 0.15 - ETA: 3:21 - loss: 3.3303 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3302 - accuracy: 0.15 - ETA: 3:19 - loss: 3.3300 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3295 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3292 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3274 - accuracy: 0.15 - ETA: 3:15 - loss: 3.3257 - accuracy: 0.15 - ETA: 3:14 - loss: 3.3239 - accuracy: 0.15 - ETA: 3:13 - loss: 3.3237 - accuracy: 0.15 - ETA: 3:12 - loss: 3.3227 - accuracy: 0.15 - ETA: 3:11 - loss: 3.3221 - accuracy: 0.15 - ETA: 3:10 - loss: 3.3218 - accuracy: 0.15 - ETA: 3:09 - loss: 3.3224 - accuracy: 0.15 - ETA: 3:08 - loss: 3.3230 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3231 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3225 - accuracy: 0.15 - ETA: 3:05 - loss: 3.3226 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3233 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3227 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3232 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3226 - accuracy: 0.15 - ETA: 3:01 - loss: 3.3216 - accuracy: 0.15 - ETA: 3:00 - loss: 3.3212 - accuracy: 0.15 - ETA: 2:59 - loss: 3.3209 - accuracy: 0.15 - ETA: 2:58 - loss: 3.3201 - accuracy: 0.15 - ETA: 2:57 - loss: 3.3190 - accuracy: 0.15 - ETA: 2:56 - loss: 3.3186 - accuracy: 0.15 - ETA: 2:55 - loss: 3.3186 - accuracy: 0.15 - ETA: 2:54 - loss: 3.3181 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3188 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3197 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3210 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3208 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3211 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3210 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3210 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3207 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3207 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3203 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3212 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3211 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3207 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3204 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3201 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3218 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3221 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3226 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3224 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3233 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3230 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3230 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3237 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3229 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3229 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3227 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3230 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3229 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3225 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3224 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3225 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3225 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3223 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3215 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3218 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3222 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3222 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3210 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3201 - accuracy: 0.1486"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:16 - loss: 3.3203 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3199 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3193 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3186 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3189 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3194 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3190 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3183 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3173 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3174 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3168 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3165 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3168 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3172 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3173 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3166 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3165 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3167 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3152 - accuracy: 0.15 - ETA: 1:56 - loss: 3.3150 - accuracy: 0.15 - ETA: 1:55 - loss: 3.3138 - accuracy: 0.15 - ETA: 1:54 - loss: 3.3138 - accuracy: 0.15 - ETA: 1:53 - loss: 3.3131 - accuracy: 0.15 - ETA: 1:52 - loss: 3.3136 - accuracy: 0.15 - ETA: 1:51 - loss: 3.3130 - accuracy: 0.15 - ETA: 1:50 - loss: 3.3129 - accuracy: 0.15 - ETA: 1:49 - loss: 3.3130 - accuracy: 0.15 - ETA: 1:48 - loss: 3.3135 - accuracy: 0.15 - ETA: 1:47 - loss: 3.3134 - accuracy: 0.15 - ETA: 1:47 - loss: 3.3137 - accuracy: 0.15 - ETA: 1:46 - loss: 3.3142 - accuracy: 0.15 - ETA: 1:45 - loss: 3.3140 - accuracy: 0.15 - ETA: 1:44 - loss: 3.3141 - accuracy: 0.15 - ETA: 1:43 - loss: 3.3153 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3159 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3167 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3167 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3163 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3158 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3145 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3136 - accuracy: 0.15 - ETA: 1:35 - loss: 3.3132 - accuracy: 0.15 - ETA: 1:34 - loss: 3.3133 - accuracy: 0.15 - ETA: 1:33 - loss: 3.3123 - accuracy: 0.15 - ETA: 1:32 - loss: 3.3121 - accuracy: 0.15 - ETA: 1:31 - loss: 3.3118 - accuracy: 0.15 - ETA: 1:30 - loss: 3.3105 - accuracy: 0.15 - ETA: 1:29 - loss: 3.3107 - accuracy: 0.15 - ETA: 1:29 - loss: 3.3103 - accuracy: 0.15 - ETA: 1:28 - loss: 3.3102 - accuracy: 0.15 - ETA: 1:27 - loss: 3.3099 - accuracy: 0.15 - ETA: 1:26 - loss: 3.3097 - accuracy: 0.15 - ETA: 1:25 - loss: 3.3098 - accuracy: 0.15 - ETA: 1:24 - loss: 3.3089 - accuracy: 0.15 - ETA: 1:23 - loss: 3.3088 - accuracy: 0.15 - ETA: 1:22 - loss: 3.3091 - accuracy: 0.15 - ETA: 1:21 - loss: 3.3086 - accuracy: 0.15 - ETA: 1:20 - loss: 3.3085 - accuracy: 0.15 - ETA: 1:19 - loss: 3.3083 - accuracy: 0.15 - ETA: 1:18 - loss: 3.3071 - accuracy: 0.15 - ETA: 1:17 - loss: 3.3069 - accuracy: 0.15 - ETA: 1:16 - loss: 3.3069 - accuracy: 0.15 - ETA: 1:15 - loss: 3.3065 - accuracy: 0.15 - ETA: 1:14 - loss: 3.3054 - accuracy: 0.15 - ETA: 1:13 - loss: 3.3055 - accuracy: 0.15 - ETA: 1:12 - loss: 3.3060 - accuracy: 0.15 - ETA: 1:11 - loss: 3.3063 - accuracy: 0.15 - ETA: 1:10 - loss: 3.3061 - accuracy: 0.15 - ETA: 1:10 - loss: 3.3065 - accuracy: 0.15 - ETA: 1:09 - loss: 3.3060 - accuracy: 0.15 - ETA: 1:08 - loss: 3.3052 - accuracy: 0.15 - ETA: 1:07 - loss: 3.3046 - accuracy: 0.15 - ETA: 1:06 - loss: 3.3049 - accuracy: 0.15 - ETA: 1:05 - loss: 3.3043 - accuracy: 0.15 - ETA: 1:04 - loss: 3.3048 - accuracy: 0.15 - ETA: 1:03 - loss: 3.3053 - accuracy: 0.15 - ETA: 1:02 - loss: 3.3053 - accuracy: 0.15 - ETA: 1:01 - loss: 3.3048 - accuracy: 0.15 - ETA: 1:00 - loss: 3.3049 - accuracy: 0.15 - ETA: 59s - loss: 3.3048 - accuracy: 0.1504 - ETA: 58s - loss: 3.3050 - accuracy: 0.150 - ETA: 57s - loss: 3.3047 - accuracy: 0.150 - ETA: 56s - loss: 3.3042 - accuracy: 0.150 - ETA: 55s - loss: 3.3042 - accuracy: 0.150 - ETA: 54s - loss: 3.3049 - accuracy: 0.150 - ETA: 53s - loss: 3.3054 - accuracy: 0.149 - ETA: 53s - loss: 3.3054 - accuracy: 0.149 - ETA: 52s - loss: 3.3055 - accuracy: 0.149 - ETA: 51s - loss: 3.3051 - accuracy: 0.149 - ETA: 50s - loss: 3.3043 - accuracy: 0.150 - ETA: 49s - loss: 3.3046 - accuracy: 0.150 - ETA: 48s - loss: 3.3045 - accuracy: 0.149 - ETA: 47s - loss: 3.3044 - accuracy: 0.149 - ETA: 46s - loss: 3.3038 - accuracy: 0.149 - ETA: 45s - loss: 3.3046 - accuracy: 0.149 - ETA: 44s - loss: 3.3049 - accuracy: 0.149 - ETA: 43s - loss: 3.3049 - accuracy: 0.149 - ETA: 42s - loss: 3.3048 - accuracy: 0.149 - ETA: 41s - loss: 3.3051 - accuracy: 0.149 - ETA: 40s - loss: 3.3045 - accuracy: 0.149 - ETA: 39s - loss: 3.3041 - accuracy: 0.149 - ETA: 38s - loss: 3.3037 - accuracy: 0.149 - ETA: 37s - loss: 3.3030 - accuracy: 0.149 - ETA: 36s - loss: 3.3024 - accuracy: 0.149 - ETA: 36s - loss: 3.3015 - accuracy: 0.149 - ETA: 35s - loss: 3.3016 - accuracy: 0.149 - ETA: 34s - loss: 3.3012 - accuracy: 0.149 - ETA: 33s - loss: 3.3015 - accuracy: 0.149 - ETA: 32s - loss: 3.3017 - accuracy: 0.149 - ETA: 31s - loss: 3.3012 - accuracy: 0.150 - ETA: 30s - loss: 3.3013 - accuracy: 0.150 - ETA: 29s - loss: 3.3008 - accuracy: 0.150 - ETA: 28s - loss: 3.3007 - accuracy: 0.149 - ETA: 27s - loss: 3.3006 - accuracy: 0.149 - ETA: 26s - loss: 3.3003 - accuracy: 0.149 - ETA: 25s - loss: 3.3004 - accuracy: 0.150 - ETA: 24s - loss: 3.3000 - accuracy: 0.149 - ETA: 23s - loss: 3.3002 - accuracy: 0.150 - ETA: 22s - loss: 3.2998 - accuracy: 0.150 - ETA: 21s - loss: 3.3000 - accuracy: 0.150 - ETA: 20s - loss: 3.2999 - accuracy: 0.150 - ETA: 19s - loss: 3.3000 - accuracy: 0.150 - ETA: 19s - loss: 3.3001 - accuracy: 0.150 - ETA: 18s - loss: 3.3003 - accuracy: 0.150 - ETA: 17s - loss: 3.3002 - accuracy: 0.150 - ETA: 16s - loss: 3.3002 - accuracy: 0.150 - ETA: 15s - loss: 3.2995 - accuracy: 0.150 - ETA: 14s - loss: 3.2989 - accuracy: 0.150 - ETA: 13s - loss: 3.2987 - accuracy: 0.150 - ETA: 12s - loss: 3.2991 - accuracy: 0.150 - ETA: 11s - loss: 3.2991 - accuracy: 0.150 - ETA: 10s - loss: 3.2989 - accuracy: 0.150 - ETA: 9s - loss: 3.2991 - accuracy: 0.150 - ETA: 8s - loss: 3.2994 - accuracy: 0.15 - ETA: 7s - loss: 3.2992 - accuracy: 0.15 - ETA: 6s - loss: 3.2991 - accuracy: 0.15 - ETA: 5s - loss: 3.2991 - accuracy: 0.15 - ETA: 4s - loss: 3.2988 - accuracy: 0.15 - ETA: 3s - loss: 3.2992 - accuracy: 0.15 - ETA: 2s - loss: 3.2993 - accuracy: 0.15 - ETA: 1s - loss: 3.2989 - accuracy: 0.15 - ETA: 1s - loss: 3.2982 - accuracy: 0.15 - ETA: 0s - loss: 3.2981 - accuracy: 0.15 - 337s 8ms/step - loss: 3.2981 - accuracy: 0.1507 - val_loss: 3.9100 - val_accuracy: 0.0178\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:12 - loss: 3.3809 - accuracy: 0.10 - ETA: 5:13 - loss: 3.3873 - accuracy: 0.10 - ETA: 5:08 - loss: 3.3708 - accuracy: 0.11 - ETA: 5:04 - loss: 3.3835 - accuracy: 0.11 - ETA: 5:04 - loss: 3.3583 - accuracy: 0.12 - ETA: 5:03 - loss: 3.3140 - accuracy: 0.13 - ETA: 5:01 - loss: 3.3181 - accuracy: 0.13 - ETA: 4:57 - loss: 3.3120 - accuracy: 0.14 - ETA: 4:57 - loss: 3.3096 - accuracy: 0.14 - ETA: 4:58 - loss: 3.3040 - accuracy: 0.14 - ETA: 5:00 - loss: 3.3011 - accuracy: 0.14 - ETA: 5:00 - loss: 3.2899 - accuracy: 0.14 - ETA: 4:58 - loss: 3.2914 - accuracy: 0.14 - ETA: 4:58 - loss: 3.2826 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2886 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2787 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2742 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2647 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2657 - accuracy: 0.15 - ETA: 4:55 - loss: 3.2701 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2711 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2843 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2872 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2855 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2791 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2727 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2685 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2640 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2630 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2622 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2634 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2601 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2596 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2637 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2684 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2681 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2699 - accuracy: 0.15 - ETA: 4:37 - loss: 3.2697 - accuracy: 0.15 - ETA: 4:36 - loss: 3.2722 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2732 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2741 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2806 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2802 - accuracy: 0.15 - ETA: 4:31 - loss: 3.2843 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2890 - accuracy: 0.15 - ETA: 4:29 - loss: 3.2915 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2899 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2929 - accuracy: 0.15 - ETA: 4:27 - loss: 3.2916 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2885 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2875 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2864 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2854 - accuracy: 0.15 - ETA: 4:23 - loss: 3.2838 - accuracy: 0.15 - ETA: 4:22 - loss: 3.2865 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2864 - accuracy: 0.15 - ETA: 4:20 - loss: 3.2875 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2922 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2940 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2970 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2992 - accuracy: 0.15 - ETA: 4:14 - loss: 3.3011 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2992 - accuracy: 0.15 - ETA: 4:13 - loss: 3.3014 - accuracy: 0.15 - ETA: 4:12 - loss: 3.3007 - accuracy: 0.15 - ETA: 4:11 - loss: 3.3002 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2997 - accuracy: 0.15 - ETA: 4:09 - loss: 3.2991 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2999 - accuracy: 0.15 - ETA: 4:08 - loss: 3.3013 - accuracy: 0.15 - ETA: 4:07 - loss: 3.3034 - accuracy: 0.15 - ETA: 4:06 - loss: 3.3014 - accuracy: 0.15 - ETA: 4:05 - loss: 3.3007 - accuracy: 0.15 - ETA: 4:04 - loss: 3.3040 - accuracy: 0.15 - ETA: 4:03 - loss: 3.3023 - accuracy: 0.15 - ETA: 4:02 - loss: 3.3024 - accuracy: 0.15 - ETA: 4:00 - loss: 3.3017 - accuracy: 0.15 - ETA: 4:00 - loss: 3.3017 - accuracy: 0.15 - ETA: 3:59 - loss: 3.3018 - accuracy: 0.15 - ETA: 3:58 - loss: 3.3025 - accuracy: 0.15 - ETA: 3:57 - loss: 3.3016 - accuracy: 0.15 - ETA: 3:56 - loss: 3.3026 - accuracy: 0.15 - ETA: 3:55 - loss: 3.3008 - accuracy: 0.15 - ETA: 3:54 - loss: 3.3000 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2989 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2994 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2974 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2985 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2989 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2971 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2975 - accuracy: 0.14 - ETA: 3:47 - loss: 3.2974 - accuracy: 0.14 - ETA: 3:46 - loss: 3.2993 - accuracy: 0.14 - ETA: 3:45 - loss: 3.2964 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2959 - accuracy: 0.14 - ETA: 3:43 - loss: 3.2966 - accuracy: 0.14 - ETA: 3:42 - loss: 3.2946 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2978 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2981 - accuracy: 0.14 - ETA: 3:39 - loss: 3.2995 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2983 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2987 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2996 - accuracy: 0.14 - ETA: 3:35 - loss: 3.2991 - accuracy: 0.14 - ETA: 3:34 - loss: 3.2978 - accuracy: 0.14 - ETA: 3:33 - loss: 3.2983 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2958 - accuracy: 0.15 - ETA: 3:31 - loss: 3.2940 - accuracy: 0.15 - ETA: 3:30 - loss: 3.2947 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2947 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2953 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2942 - accuracy: 0.15 - ETA: 3:27 - loss: 3.2945 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2942 - accuracy: 0.15 - ETA: 3:25 - loss: 3.2947 - accuracy: 0.15 - ETA: 3:24 - loss: 3.2959 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2961 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2965 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2965 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2968 - accuracy: 0.14 - ETA: 3:19 - loss: 3.2970 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2974 - accuracy: 0.14 - ETA: 3:17 - loss: 3.2958 - accuracy: 0.14 - ETA: 3:16 - loss: 3.2958 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2970 - accuracy: 0.14 - ETA: 3:14 - loss: 3.2951 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2950 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2955 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2959 - accuracy: 0.14 - ETA: 3:10 - loss: 3.2959 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2960 - accuracy: 0.14 - ETA: 3:08 - loss: 3.2961 - accuracy: 0.14 - ETA: 3:07 - loss: 3.2940 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2937 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2943 - accuracy: 0.14 - ETA: 3:05 - loss: 3.2926 - accuracy: 0.14 - ETA: 3:04 - loss: 3.2918 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2923 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2913 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2901 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2903 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2903 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2906 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2903 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2898 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2907 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2910 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2905 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2913 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2919 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2915 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2906 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2911 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2910 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2914 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2911 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2902 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2898 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2900 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2899 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2903 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2908 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2897 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2887 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2898 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2893 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2898 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2946 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2969 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2970 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2970 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2966 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2970 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2972 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2961 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2957 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2953 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2960 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2965 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2968 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2971 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2971 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2980 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2981 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2984 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2993 - accuracy: 0.1499"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:16 - loss: 3.2995 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3000 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3004 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3012 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3027 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3022 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3028 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3037 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3040 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3045 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3040 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3040 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3038 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3037 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3032 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3032 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3030 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3032 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3032 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3023 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3024 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3018 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3020 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3031 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3060 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3057 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3059 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3059 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3055 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3059 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3067 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3063 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3068 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3080 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3069 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3061 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3060 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3057 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3054 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3051 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3051 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3055 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3063 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3059 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3063 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3057 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3055 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3049 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3054 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3052 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3058 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3062 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3054 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3047 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3052 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3049 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3052 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3052 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3042 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3031 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3026 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3027 - accuracy: 0.15 - ETA: 1:01 - loss: 3.3026 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3031 - accuracy: 0.14 - ETA: 59s - loss: 3.3027 - accuracy: 0.1499 - ETA: 58s - loss: 3.3029 - accuracy: 0.149 - ETA: 57s - loss: 3.3025 - accuracy: 0.149 - ETA: 56s - loss: 3.3023 - accuracy: 0.150 - ETA: 56s - loss: 3.3016 - accuracy: 0.150 - ETA: 55s - loss: 3.3008 - accuracy: 0.150 - ETA: 54s - loss: 3.3000 - accuracy: 0.150 - ETA: 53s - loss: 3.2996 - accuracy: 0.150 - ETA: 52s - loss: 3.2996 - accuracy: 0.150 - ETA: 51s - loss: 3.2988 - accuracy: 0.150 - ETA: 50s - loss: 3.2990 - accuracy: 0.150 - ETA: 49s - loss: 3.2992 - accuracy: 0.150 - ETA: 48s - loss: 3.2987 - accuracy: 0.150 - ETA: 47s - loss: 3.2988 - accuracy: 0.150 - ETA: 46s - loss: 3.2984 - accuracy: 0.150 - ETA: 45s - loss: 3.2978 - accuracy: 0.150 - ETA: 44s - loss: 3.2967 - accuracy: 0.151 - ETA: 43s - loss: 3.2964 - accuracy: 0.151 - ETA: 42s - loss: 3.2973 - accuracy: 0.151 - ETA: 41s - loss: 3.2969 - accuracy: 0.151 - ETA: 40s - loss: 3.2969 - accuracy: 0.151 - ETA: 39s - loss: 3.2968 - accuracy: 0.151 - ETA: 38s - loss: 3.2967 - accuracy: 0.151 - ETA: 38s - loss: 3.2969 - accuracy: 0.151 - ETA: 37s - loss: 3.2967 - accuracy: 0.151 - ETA: 36s - loss: 3.2968 - accuracy: 0.151 - ETA: 35s - loss: 3.2965 - accuracy: 0.151 - ETA: 34s - loss: 3.2967 - accuracy: 0.151 - ETA: 33s - loss: 3.2966 - accuracy: 0.151 - ETA: 32s - loss: 3.2964 - accuracy: 0.151 - ETA: 31s - loss: 3.2959 - accuracy: 0.151 - ETA: 30s - loss: 3.2960 - accuracy: 0.151 - ETA: 29s - loss: 3.2955 - accuracy: 0.151 - ETA: 28s - loss: 3.2954 - accuracy: 0.151 - ETA: 27s - loss: 3.2951 - accuracy: 0.151 - ETA: 26s - loss: 3.2950 - accuracy: 0.151 - ETA: 25s - loss: 3.2947 - accuracy: 0.151 - ETA: 24s - loss: 3.2949 - accuracy: 0.151 - ETA: 23s - loss: 3.2950 - accuracy: 0.151 - ETA: 22s - loss: 3.2945 - accuracy: 0.151 - ETA: 21s - loss: 3.2949 - accuracy: 0.150 - ETA: 20s - loss: 3.2948 - accuracy: 0.150 - ETA: 19s - loss: 3.2939 - accuracy: 0.151 - ETA: 19s - loss: 3.2933 - accuracy: 0.151 - ETA: 18s - loss: 3.2929 - accuracy: 0.151 - ETA: 17s - loss: 3.2930 - accuracy: 0.151 - ETA: 16s - loss: 3.2926 - accuracy: 0.151 - ETA: 15s - loss: 3.2927 - accuracy: 0.151 - ETA: 14s - loss: 3.2923 - accuracy: 0.151 - ETA: 13s - loss: 3.2926 - accuracy: 0.151 - ETA: 12s - loss: 3.2914 - accuracy: 0.151 - ETA: 11s - loss: 3.2907 - accuracy: 0.151 - ETA: 10s - loss: 3.2900 - accuracy: 0.152 - ETA: 9s - loss: 3.2899 - accuracy: 0.152 - ETA: 8s - loss: 3.2894 - accuracy: 0.15 - ETA: 7s - loss: 3.2896 - accuracy: 0.15 - ETA: 6s - loss: 3.2898 - accuracy: 0.15 - ETA: 5s - loss: 3.2900 - accuracy: 0.15 - ETA: 4s - loss: 3.2901 - accuracy: 0.15 - ETA: 3s - loss: 3.2894 - accuracy: 0.15 - ETA: 2s - loss: 3.2893 - accuracy: 0.15 - ETA: 1s - loss: 3.2890 - accuracy: 0.15 - ETA: 1s - loss: 3.2891 - accuracy: 0.15 - ETA: 0s - loss: 3.2887 - accuracy: 0.15 - 337s 8ms/step - loss: 3.2888 - accuracy: 0.1522 - val_loss: 4.0086 - val_accuracy: 0.0256\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:32 - loss: 3.2908 - accuracy: 0.14 - ETA: 5:20 - loss: 3.3207 - accuracy: 0.14 - ETA: 5:09 - loss: 3.3065 - accuracy: 0.14 - ETA: 5:11 - loss: 3.3051 - accuracy: 0.14 - ETA: 5:12 - loss: 3.2513 - accuracy: 0.15 - ETA: 5:09 - loss: 3.2474 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2644 - accuracy: 0.14 - ETA: 5:06 - loss: 3.2789 - accuracy: 0.14 - ETA: 5:05 - loss: 3.2594 - accuracy: 0.14 - ETA: 5:05 - loss: 3.2400 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2356 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2444 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2400 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2369 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2426 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2513 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2492 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2505 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2609 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2627 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2574 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2680 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2630 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2654 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2651 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2690 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2726 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2749 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2779 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2811 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2814 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2745 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2705 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2717 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2725 - accuracy: 0.15 - ETA: 4:37 - loss: 3.2714 - accuracy: 0.15 - ETA: 4:36 - loss: 3.2683 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2707 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2714 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2716 - accuracy: 0.15 - ETA: 4:31 - loss: 3.2721 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2720 - accuracy: 0.15 - ETA: 4:29 - loss: 3.2714 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2734 - accuracy: 0.15 - ETA: 4:27 - loss: 3.2681 - accuracy: 0.15 - ETA: 4:27 - loss: 3.2717 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2731 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2720 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2703 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2700 - accuracy: 0.15 - ETA: 4:23 - loss: 3.2725 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2733 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2701 - accuracy: 0.15 - ETA: 4:20 - loss: 3.2702 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2717 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2723 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2688 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2688 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2704 - accuracy: 0.15 - ETA: 4:15 - loss: 3.2714 - accuracy: 0.15 - ETA: 4:14 - loss: 3.2722 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2719 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2726 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2714 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2717 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2711 - accuracy: 0.15 - ETA: 4:09 - loss: 3.2696 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2701 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2697 - accuracy: 0.15 - ETA: 4:06 - loss: 3.2678 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2697 - accuracy: 0.15 - ETA: 4:04 - loss: 3.2683 - accuracy: 0.15 - ETA: 4:03 - loss: 3.2650 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2657 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2669 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2674 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2653 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2635 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2619 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2598 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2626 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2619 - accuracy: 0.15 - ETA: 3:54 - loss: 3.2620 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2638 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2636 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2649 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2651 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2655 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2671 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2667 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2650 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2654 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2641 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2640 - accuracy: 0.15 - ETA: 3:42 - loss: 3.2665 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2651 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2634 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2627 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2619 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2629 - accuracy: 0.15 - ETA: 3:37 - loss: 3.2621 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2619 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2612 - accuracy: 0.15 - ETA: 3:34 - loss: 3.2625 - accuracy: 0.15 - ETA: 3:33 - loss: 3.2626 - accuracy: 0.15 - ETA: 3:32 - loss: 3.2619 - accuracy: 0.15 - ETA: 3:31 - loss: 3.2612 - accuracy: 0.15 - ETA: 3:30 - loss: 3.2601 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2598 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2606 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2615 - accuracy: 0.15 - ETA: 3:27 - loss: 3.2624 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2603 - accuracy: 0.15 - ETA: 3:25 - loss: 3.2603 - accuracy: 0.15 - ETA: 3:24 - loss: 3.2601 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2600 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2607 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2593 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2602 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2612 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2617 - accuracy: 0.15 - ETA: 3:17 - loss: 3.2623 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2611 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2598 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2596 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2608 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2603 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2610 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2596 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2586 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2583 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2569 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2571 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2566 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2589 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2576 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2588 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2576 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2570 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2568 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2576 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2578 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2591 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2629 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2626 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2635 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2632 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2639 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2637 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2637 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2637 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2644 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2645 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2657 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2656 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2661 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2660 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2665 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2653 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2655 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2659 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2654 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2652 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2652 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2662 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2659 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2663 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2661 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2663 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2703 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2713 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2710 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2723 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2721 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2719 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2723 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2733 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2742 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2754 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2761 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2757 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2765 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2766 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2769 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2774 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2776 - accuracy: 0.1534"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:16 - loss: 3.2786 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2786 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2794 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2788 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2778 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2766 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2767 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2766 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2757 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2752 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2744 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2748 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2753 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2746 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2749 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2760 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2760 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2762 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2760 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2754 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2757 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2758 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2764 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2758 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2756 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2761 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2763 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2765 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2762 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2761 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2759 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2752 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2754 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2751 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2746 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2740 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2734 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2737 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2744 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2748 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2751 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2755 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2756 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2757 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2751 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2746 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2746 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2742 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2737 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2737 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2750 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2751 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2753 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2751 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2756 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2755 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2752 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2740 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2743 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2748 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2751 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2754 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2753 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2750 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2750 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2746 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2755 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2750 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2753 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2760 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2761 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2768 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2771 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2767 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2763 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2753 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2756 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2758 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2756 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2757 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2755 - accuracy: 0.15 - ETA: 59s - loss: 3.2755 - accuracy: 0.1535 - ETA: 58s - loss: 3.2758 - accuracy: 0.153 - ETA: 57s - loss: 3.2760 - accuracy: 0.153 - ETA: 56s - loss: 3.2754 - accuracy: 0.153 - ETA: 55s - loss: 3.2755 - accuracy: 0.153 - ETA: 54s - loss: 3.2759 - accuracy: 0.153 - ETA: 54s - loss: 3.2757 - accuracy: 0.153 - ETA: 53s - loss: 3.2758 - accuracy: 0.153 - ETA: 52s - loss: 3.2754 - accuracy: 0.153 - ETA: 51s - loss: 3.2744 - accuracy: 0.153 - ETA: 50s - loss: 3.2742 - accuracy: 0.153 - ETA: 49s - loss: 3.2736 - accuracy: 0.154 - ETA: 48s - loss: 3.2735 - accuracy: 0.154 - ETA: 47s - loss: 3.2729 - accuracy: 0.154 - ETA: 46s - loss: 3.2727 - accuracy: 0.154 - ETA: 45s - loss: 3.2730 - accuracy: 0.154 - ETA: 44s - loss: 3.2730 - accuracy: 0.154 - ETA: 43s - loss: 3.2731 - accuracy: 0.154 - ETA: 42s - loss: 3.2729 - accuracy: 0.154 - ETA: 41s - loss: 3.2728 - accuracy: 0.154 - ETA: 40s - loss: 3.2733 - accuracy: 0.154 - ETA: 39s - loss: 3.2733 - accuracy: 0.154 - ETA: 38s - loss: 3.2731 - accuracy: 0.154 - ETA: 37s - loss: 3.2738 - accuracy: 0.154 - ETA: 36s - loss: 3.2740 - accuracy: 0.154 - ETA: 36s - loss: 3.2736 - accuracy: 0.154 - ETA: 35s - loss: 3.2736 - accuracy: 0.154 - ETA: 34s - loss: 3.2745 - accuracy: 0.154 - ETA: 33s - loss: 3.2743 - accuracy: 0.154 - ETA: 32s - loss: 3.2738 - accuracy: 0.154 - ETA: 31s - loss: 3.2738 - accuracy: 0.154 - ETA: 30s - loss: 3.2749 - accuracy: 0.154 - ETA: 29s - loss: 3.2748 - accuracy: 0.154 - ETA: 28s - loss: 3.2748 - accuracy: 0.154 - ETA: 27s - loss: 3.2746 - accuracy: 0.154 - ETA: 26s - loss: 3.2745 - accuracy: 0.154 - ETA: 25s - loss: 3.2745 - accuracy: 0.154 - ETA: 24s - loss: 3.2740 - accuracy: 0.154 - ETA: 23s - loss: 3.2739 - accuracy: 0.154 - ETA: 22s - loss: 3.2735 - accuracy: 0.154 - ETA: 21s - loss: 3.2734 - accuracy: 0.154 - ETA: 20s - loss: 3.2735 - accuracy: 0.154 - ETA: 19s - loss: 3.2741 - accuracy: 0.154 - ETA: 19s - loss: 3.2739 - accuracy: 0.154 - ETA: 18s - loss: 3.2733 - accuracy: 0.154 - ETA: 17s - loss: 3.2732 - accuracy: 0.154 - ETA: 16s - loss: 3.2739 - accuracy: 0.154 - ETA: 15s - loss: 3.2739 - accuracy: 0.154 - ETA: 14s - loss: 3.2740 - accuracy: 0.154 - ETA: 13s - loss: 3.2736 - accuracy: 0.154 - ETA: 12s - loss: 3.2733 - accuracy: 0.154 - ETA: 11s - loss: 3.2726 - accuracy: 0.154 - ETA: 10s - loss: 3.2720 - accuracy: 0.154 - ETA: 9s - loss: 3.2720 - accuracy: 0.154 - ETA: 8s - loss: 3.2715 - accuracy: 0.15 - ETA: 7s - loss: 3.2712 - accuracy: 0.15 - ETA: 6s - loss: 3.2713 - accuracy: 0.15 - ETA: 5s - loss: 3.2712 - accuracy: 0.15 - ETA: 4s - loss: 3.2714 - accuracy: 0.15 - ETA: 3s - loss: 3.2715 - accuracy: 0.15 - ETA: 2s - loss: 3.2720 - accuracy: 0.15 - ETA: 1s - loss: 3.2720 - accuracy: 0.15 - ETA: 1s - loss: 3.2723 - accuracy: 0.15 - ETA: 0s - loss: 3.2728 - accuracy: 0.15 - 337s 8ms/step - loss: 3.2729 - accuracy: 0.1548 - val_loss: 3.8622 - val_accuracy: 0.0193\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:07 - loss: 3.1391 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2497 - accuracy: 0.14 - ETA: 5:03 - loss: 3.2545 - accuracy: 0.13 - ETA: 5:03 - loss: 3.2611 - accuracy: 0.13 - ETA: 5:06 - loss: 3.2573 - accuracy: 0.14 - ETA: 5:04 - loss: 3.2643 - accuracy: 0.14 - ETA: 5:00 - loss: 3.2441 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2467 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2573 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2786 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2812 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2838 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2729 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2817 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2890 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2851 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2901 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2888 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2911 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2930 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2895 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2869 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2853 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2830 - accuracy: 0.15 - ETA: 4:47 - loss: 3.2790 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2755 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2733 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2677 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2687 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2699 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2734 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2787 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2795 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2805 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2769 - accuracy: 0.15 - ETA: 4:36 - loss: 3.2787 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2799 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2750 - accuracy: 0.15 - ETA: 4:33 - loss: 3.2752 - accuracy: 0.15 - ETA: 4:32 - loss: 3.2750 - accuracy: 0.15 - ETA: 4:31 - loss: 3.2719 - accuracy: 0.15 - ETA: 4:31 - loss: 3.2756 - accuracy: 0.15 - ETA: 4:30 - loss: 3.2709 - accuracy: 0.15 - ETA: 4:29 - loss: 3.2738 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2700 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2740 - accuracy: 0.15 - ETA: 4:27 - loss: 3.2733 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2704 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2684 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2665 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2676 - accuracy: 0.15 - ETA: 4:22 - loss: 3.2651 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2619 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2626 - accuracy: 0.15 - ETA: 4:20 - loss: 3.2633 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2621 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2605 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2599 - accuracy: 0.15 - ETA: 4:17 - loss: 3.2622 - accuracy: 0.15 - ETA: 4:16 - loss: 3.2639 - accuracy: 0.15 - ETA: 4:15 - loss: 3.2621 - accuracy: 0.15 - ETA: 4:14 - loss: 3.2615 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2605 - accuracy: 0.15 - ETA: 4:12 - loss: 3.2600 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2600 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2588 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2615 - accuracy: 0.15 - ETA: 4:09 - loss: 3.2650 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2662 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2678 - accuracy: 0.15 - ETA: 4:06 - loss: 3.2663 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2656 - accuracy: 0.15 - ETA: 4:04 - loss: 3.2688 - accuracy: 0.15 - ETA: 4:03 - loss: 3.2702 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2713 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2708 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2724 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2732 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2761 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2792 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2825 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2843 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2890 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2897 - accuracy: 0.15 - ETA: 3:54 - loss: 3.2921 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2957 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2971 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2972 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2989 - accuracy: 0.15 - ETA: 3:49 - loss: 3.3011 - accuracy: 0.15 - ETA: 3:48 - loss: 3.3030 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3054 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3065 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3072 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3090 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3083 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3097 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3110 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3120 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3136 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3147 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3157 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3188 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3203 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3188 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3202 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3220 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3241 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3251 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3269 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3303 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3302 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3329 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3353 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3361 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3383 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3399 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3420 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3448 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3464 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3463 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3463 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3475 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3486 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3480 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3482 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3482 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3496 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3506 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3511 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3525 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3534 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3544 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3540 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3541 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3544 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3545 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3553 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3556 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3552 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3549 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3563 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3578 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3577 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3582 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3594 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3590 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3598 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3612 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3616 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3614 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3614 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3614 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3626 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3636 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3631 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3631 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3650 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3666 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3673 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3690 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3698 - accuracy: 0.13 - ETA: 2:40 - loss: 3.3695 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3696 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3691 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3697 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3692 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3696 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3689 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3685 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3685 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3700 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3703 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3734 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3723 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3728 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3735 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3740 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3752 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3758 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3773 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3783 - accuracy: 0.13 - ETA: 2:21 - loss: 3.3786 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3788 - accuracy: 0.13 - ETA: 2:19 - loss: 3.3784 - accuracy: 0.13 - ETA: 2:18 - loss: 3.3781 - accuracy: 0.1363"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3780 - accuracy: 0.13 - ETA: 2:16 - loss: 3.3783 - accuracy: 0.13 - ETA: 2:15 - loss: 3.3792 - accuracy: 0.13 - ETA: 2:14 - loss: 3.3789 - accuracy: 0.13 - ETA: 2:13 - loss: 3.3784 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3776 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3763 - accuracy: 0.13 - ETA: 2:10 - loss: 3.3757 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3756 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3755 - accuracy: 0.13 - ETA: 2:07 - loss: 3.3748 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3746 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3749 - accuracy: 0.13 - ETA: 2:04 - loss: 3.3752 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3743 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3751 - accuracy: 0.13 - ETA: 2:01 - loss: 3.3745 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3742 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3758 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3744 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3735 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3738 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3739 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3739 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3740 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3738 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3736 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3738 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3743 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3735 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3742 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3739 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3737 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3730 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3731 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3724 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3724 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3724 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3708 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3710 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3704 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3702 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3699 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3696 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3695 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3698 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3692 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3690 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3681 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3678 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3677 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3670 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3665 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3660 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3658 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3655 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3652 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3656 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3654 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3650 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3644 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3639 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3634 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3632 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3626 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3619 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3614 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3609 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3604 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3597 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3602 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3594 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3590 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3588 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3588 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3583 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3573 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3569 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3565 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3558 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3550 - accuracy: 0.14 - ETA: 59s - loss: 3.3548 - accuracy: 0.1412 - ETA: 59s - loss: 3.3541 - accuracy: 0.141 - ETA: 58s - loss: 3.3538 - accuracy: 0.141 - ETA: 57s - loss: 3.3538 - accuracy: 0.141 - ETA: 56s - loss: 3.3529 - accuracy: 0.141 - ETA: 55s - loss: 3.3525 - accuracy: 0.141 - ETA: 54s - loss: 3.3523 - accuracy: 0.141 - ETA: 53s - loss: 3.3511 - accuracy: 0.142 - ETA: 52s - loss: 3.3505 - accuracy: 0.142 - ETA: 51s - loss: 3.3506 - accuracy: 0.142 - ETA: 50s - loss: 3.3506 - accuracy: 0.141 - ETA: 49s - loss: 3.3500 - accuracy: 0.142 - ETA: 48s - loss: 3.3495 - accuracy: 0.142 - ETA: 47s - loss: 3.3493 - accuracy: 0.142 - ETA: 46s - loss: 3.3490 - accuracy: 0.142 - ETA: 45s - loss: 3.3490 - accuracy: 0.142 - ETA: 44s - loss: 3.3485 - accuracy: 0.142 - ETA: 43s - loss: 3.3478 - accuracy: 0.142 - ETA: 42s - loss: 3.3476 - accuracy: 0.142 - ETA: 41s - loss: 3.3476 - accuracy: 0.142 - ETA: 40s - loss: 3.3473 - accuracy: 0.142 - ETA: 40s - loss: 3.3469 - accuracy: 0.142 - ETA: 39s - loss: 3.3469 - accuracy: 0.142 - ETA: 38s - loss: 3.3460 - accuracy: 0.142 - ETA: 37s - loss: 3.3464 - accuracy: 0.142 - ETA: 36s - loss: 3.3460 - accuracy: 0.142 - ETA: 35s - loss: 3.3448 - accuracy: 0.142 - ETA: 34s - loss: 3.3452 - accuracy: 0.142 - ETA: 33s - loss: 3.3449 - accuracy: 0.142 - ETA: 32s - loss: 3.3461 - accuracy: 0.142 - ETA: 31s - loss: 3.3458 - accuracy: 0.143 - ETA: 30s - loss: 3.3458 - accuracy: 0.143 - ETA: 29s - loss: 3.3459 - accuracy: 0.142 - ETA: 28s - loss: 3.3452 - accuracy: 0.143 - ETA: 27s - loss: 3.3445 - accuracy: 0.143 - ETA: 26s - loss: 3.3440 - accuracy: 0.143 - ETA: 25s - loss: 3.3442 - accuracy: 0.143 - ETA: 24s - loss: 3.3433 - accuracy: 0.143 - ETA: 23s - loss: 3.3436 - accuracy: 0.143 - ETA: 22s - loss: 3.3434 - accuracy: 0.143 - ETA: 21s - loss: 3.3437 - accuracy: 0.143 - ETA: 20s - loss: 3.3441 - accuracy: 0.143 - ETA: 20s - loss: 3.3440 - accuracy: 0.143 - ETA: 19s - loss: 3.3439 - accuracy: 0.143 - ETA: 18s - loss: 3.3439 - accuracy: 0.143 - ETA: 17s - loss: 3.3438 - accuracy: 0.143 - ETA: 16s - loss: 3.3431 - accuracy: 0.143 - ETA: 15s - loss: 3.3427 - accuracy: 0.143 - ETA: 14s - loss: 3.3422 - accuracy: 0.143 - ETA: 13s - loss: 3.3415 - accuracy: 0.143 - ETA: 12s - loss: 3.3416 - accuracy: 0.143 - ETA: 11s - loss: 3.3413 - accuracy: 0.143 - ETA: 10s - loss: 3.3411 - accuracy: 0.143 - ETA: 9s - loss: 3.3407 - accuracy: 0.143 - ETA: 8s - loss: 3.3403 - accuracy: 0.14 - ETA: 7s - loss: 3.3403 - accuracy: 0.14 - ETA: 6s - loss: 3.3398 - accuracy: 0.14 - ETA: 5s - loss: 3.3388 - accuracy: 0.14 - ETA: 4s - loss: 3.3385 - accuracy: 0.14 - ETA: 3s - loss: 3.3382 - accuracy: 0.14 - ETA: 2s - loss: 3.3387 - accuracy: 0.14 - ETA: 1s - loss: 3.3391 - accuracy: 0.14 - ETA: 1s - loss: 3.3392 - accuracy: 0.14 - ETA: 0s - loss: 3.3385 - accuracy: 0.14 - 338s 8ms/step - loss: 3.3386 - accuracy: 0.1440 - val_loss: 3.9589 - val_accuracy: 0.0187\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:54 - loss: 3.2856 - accuracy: 0.16 - ETA: 5:05 - loss: 3.2245 - accuracy: 0.17 - ETA: 5:07 - loss: 3.2306 - accuracy: 0.17 - ETA: 5:05 - loss: 3.2620 - accuracy: 0.15 - ETA: 5:07 - loss: 3.2414 - accuracy: 0.16 - ETA: 5:04 - loss: 3.2491 - accuracy: 0.16 - ETA: 5:08 - loss: 3.2510 - accuracy: 0.16 - ETA: 5:09 - loss: 3.2460 - accuracy: 0.16 - ETA: 5:10 - loss: 3.2511 - accuracy: 0.15 - ETA: 5:12 - loss: 3.2296 - accuracy: 0.16 - ETA: 5:10 - loss: 3.2158 - accuracy: 0.16 - ETA: 5:10 - loss: 3.2343 - accuracy: 0.16 - ETA: 5:08 - loss: 3.2273 - accuracy: 0.16 - ETA: 5:08 - loss: 3.2263 - accuracy: 0.16 - ETA: 5:06 - loss: 3.2202 - accuracy: 0.16 - ETA: 5:03 - loss: 3.2279 - accuracy: 0.16 - ETA: 5:00 - loss: 3.2200 - accuracy: 0.16 - ETA: 4:59 - loss: 3.2182 - accuracy: 0.16 - ETA: 4:58 - loss: 3.2210 - accuracy: 0.16 - ETA: 4:57 - loss: 3.2194 - accuracy: 0.16 - ETA: 4:56 - loss: 3.2282 - accuracy: 0.16 - ETA: 4:55 - loss: 3.2247 - accuracy: 0.16 - ETA: 4:53 - loss: 3.2303 - accuracy: 0.16 - ETA: 4:52 - loss: 3.2292 - accuracy: 0.16 - ETA: 4:50 - loss: 3.2270 - accuracy: 0.16 - ETA: 4:49 - loss: 3.2248 - accuracy: 0.16 - ETA: 4:49 - loss: 3.2247 - accuracy: 0.16 - ETA: 4:47 - loss: 3.2210 - accuracy: 0.16 - ETA: 4:46 - loss: 3.2171 - accuracy: 0.16 - ETA: 4:46 - loss: 3.2182 - accuracy: 0.16 - ETA: 4:46 - loss: 3.2166 - accuracy: 0.16 - ETA: 4:45 - loss: 3.2165 - accuracy: 0.16 - ETA: 4:44 - loss: 3.2145 - accuracy: 0.16 - ETA: 4:44 - loss: 3.2145 - accuracy: 0.16 - ETA: 4:43 - loss: 3.2398 - accuracy: 0.16 - ETA: 4:42 - loss: 3.2366 - accuracy: 0.16 - ETA: 4:41 - loss: 3.2370 - accuracy: 0.16 - ETA: 4:40 - loss: 3.2394 - accuracy: 0.16 - ETA: 4:39 - loss: 3.2340 - accuracy: 0.16 - ETA: 4:38 - loss: 3.2396 - accuracy: 0.16 - ETA: 4:36 - loss: 3.2365 - accuracy: 0.16 - ETA: 4:35 - loss: 3.2357 - accuracy: 0.16 - ETA: 4:34 - loss: 3.2363 - accuracy: 0.16 - ETA: 4:33 - loss: 3.2357 - accuracy: 0.16 - ETA: 4:32 - loss: 3.2353 - accuracy: 0.16 - ETA: 4:31 - loss: 3.2389 - accuracy: 0.16 - ETA: 4:30 - loss: 3.2403 - accuracy: 0.16 - ETA: 4:29 - loss: 3.2395 - accuracy: 0.16 - ETA: 4:28 - loss: 3.2418 - accuracy: 0.16 - ETA: 4:27 - loss: 3.2413 - accuracy: 0.16 - ETA: 4:25 - loss: 3.2397 - accuracy: 0.16 - ETA: 4:25 - loss: 3.2371 - accuracy: 0.16 - ETA: 4:24 - loss: 3.2391 - accuracy: 0.16 - ETA: 4:23 - loss: 3.2394 - accuracy: 0.16 - ETA: 4:22 - loss: 3.2382 - accuracy: 0.16 - ETA: 4:22 - loss: 3.2389 - accuracy: 0.16 - ETA: 4:21 - loss: 3.2388 - accuracy: 0.16 - ETA: 4:20 - loss: 3.2378 - accuracy: 0.16 - ETA: 4:19 - loss: 3.2389 - accuracy: 0.16 - ETA: 4:18 - loss: 3.2390 - accuracy: 0.16 - ETA: 4:17 - loss: 3.2390 - accuracy: 0.16 - ETA: 4:16 - loss: 3.2363 - accuracy: 0.16 - ETA: 4:15 - loss: 3.2349 - accuracy: 0.16 - ETA: 4:15 - loss: 3.2369 - accuracy: 0.16 - ETA: 4:14 - loss: 3.2379 - accuracy: 0.16 - ETA: 4:12 - loss: 3.2364 - accuracy: 0.16 - ETA: 4:11 - loss: 3.2382 - accuracy: 0.16 - ETA: 4:10 - loss: 3.2398 - accuracy: 0.16 - ETA: 4:09 - loss: 3.2390 - accuracy: 0.16 - ETA: 4:08 - loss: 3.2407 - accuracy: 0.16 - ETA: 4:07 - loss: 3.2405 - accuracy: 0.16 - ETA: 4:06 - loss: 3.2393 - accuracy: 0.16 - ETA: 4:05 - loss: 3.2396 - accuracy: 0.16 - ETA: 4:04 - loss: 3.2386 - accuracy: 0.16 - ETA: 4:03 - loss: 3.2395 - accuracy: 0.16 - ETA: 4:02 - loss: 3.2395 - accuracy: 0.16 - ETA: 4:01 - loss: 3.2367 - accuracy: 0.16 - ETA: 4:00 - loss: 3.2371 - accuracy: 0.16 - ETA: 3:59 - loss: 3.2365 - accuracy: 0.16 - ETA: 3:58 - loss: 3.2369 - accuracy: 0.16 - ETA: 3:57 - loss: 3.2390 - accuracy: 0.16 - ETA: 3:56 - loss: 3.2403 - accuracy: 0.16 - ETA: 3:55 - loss: 3.2397 - accuracy: 0.16 - ETA: 3:54 - loss: 3.2416 - accuracy: 0.16 - ETA: 3:53 - loss: 3.2415 - accuracy: 0.16 - ETA: 3:52 - loss: 3.2395 - accuracy: 0.16 - ETA: 3:51 - loss: 3.2394 - accuracy: 0.16 - ETA: 3:50 - loss: 3.2367 - accuracy: 0.16 - ETA: 3:49 - loss: 3.2345 - accuracy: 0.16 - ETA: 3:48 - loss: 3.2333 - accuracy: 0.16 - ETA: 3:47 - loss: 3.2313 - accuracy: 0.16 - ETA: 3:46 - loss: 3.2313 - accuracy: 0.16 - ETA: 3:45 - loss: 3.2319 - accuracy: 0.16 - ETA: 3:44 - loss: 3.2317 - accuracy: 0.16 - ETA: 3:43 - loss: 3.2316 - accuracy: 0.16 - ETA: 3:43 - loss: 3.2321 - accuracy: 0.16 - ETA: 3:42 - loss: 3.2289 - accuracy: 0.16 - ETA: 3:41 - loss: 3.2294 - accuracy: 0.16 - ETA: 3:40 - loss: 3.2309 - accuracy: 0.16 - ETA: 3:39 - loss: 3.2303 - accuracy: 0.16 - ETA: 3:38 - loss: 3.2309 - accuracy: 0.16 - ETA: 3:37 - loss: 3.2311 - accuracy: 0.16 - ETA: 3:36 - loss: 3.2318 - accuracy: 0.16 - ETA: 3:35 - loss: 3.2307 - accuracy: 0.16 - ETA: 3:34 - loss: 3.2332 - accuracy: 0.16 - ETA: 3:33 - loss: 3.2334 - accuracy: 0.16 - ETA: 3:32 - loss: 3.2329 - accuracy: 0.16 - ETA: 3:31 - loss: 3.2340 - accuracy: 0.16 - ETA: 3:30 - loss: 3.2335 - accuracy: 0.16 - ETA: 3:29 - loss: 3.2338 - accuracy: 0.16 - ETA: 3:29 - loss: 3.2341 - accuracy: 0.16 - ETA: 3:27 - loss: 3.2337 - accuracy: 0.16 - ETA: 3:26 - loss: 3.2337 - accuracy: 0.16 - ETA: 3:25 - loss: 3.2349 - accuracy: 0.16 - ETA: 3:25 - loss: 3.2332 - accuracy: 0.16 - ETA: 3:24 - loss: 3.2336 - accuracy: 0.16 - ETA: 3:23 - loss: 3.2340 - accuracy: 0.16 - ETA: 3:22 - loss: 3.2343 - accuracy: 0.16 - ETA: 3:21 - loss: 3.2344 - accuracy: 0.16 - ETA: 3:20 - loss: 3.2338 - accuracy: 0.16 - ETA: 3:19 - loss: 3.2335 - accuracy: 0.16 - ETA: 3:18 - loss: 3.2337 - accuracy: 0.16 - ETA: 3:17 - loss: 3.2341 - accuracy: 0.16 - ETA: 3:16 - loss: 3.2347 - accuracy: 0.16 - ETA: 3:15 - loss: 3.2338 - accuracy: 0.16 - ETA: 3:14 - loss: 3.2338 - accuracy: 0.16 - ETA: 3:13 - loss: 3.2343 - accuracy: 0.16 - ETA: 3:13 - loss: 3.2354 - accuracy: 0.16 - ETA: 3:12 - loss: 3.2360 - accuracy: 0.16 - ETA: 3:11 - loss: 3.2370 - accuracy: 0.16 - ETA: 3:10 - loss: 3.2376 - accuracy: 0.16 - ETA: 3:09 - loss: 3.2375 - accuracy: 0.16 - ETA: 3:08 - loss: 3.2375 - accuracy: 0.16 - ETA: 3:07 - loss: 3.2389 - accuracy: 0.16 - ETA: 3:06 - loss: 3.2381 - accuracy: 0.16 - ETA: 3:05 - loss: 3.2375 - accuracy: 0.16 - ETA: 3:04 - loss: 3.2377 - accuracy: 0.16 - ETA: 3:03 - loss: 3.2397 - accuracy: 0.16 - ETA: 3:02 - loss: 3.2406 - accuracy: 0.16 - ETA: 3:01 - loss: 3.2419 - accuracy: 0.16 - ETA: 3:00 - loss: 3.2411 - accuracy: 0.16 - ETA: 2:59 - loss: 3.2414 - accuracy: 0.16 - ETA: 2:58 - loss: 3.2427 - accuracy: 0.16 - ETA: 2:57 - loss: 3.2418 - accuracy: 0.16 - ETA: 2:56 - loss: 3.2428 - accuracy: 0.16 - ETA: 2:55 - loss: 3.2420 - accuracy: 0.16 - ETA: 2:54 - loss: 3.2418 - accuracy: 0.16 - ETA: 2:53 - loss: 3.2417 - accuracy: 0.16 - ETA: 2:52 - loss: 3.2413 - accuracy: 0.16 - ETA: 2:51 - loss: 3.2419 - accuracy: 0.16 - ETA: 2:50 - loss: 3.2428 - accuracy: 0.16 - ETA: 2:49 - loss: 3.2427 - accuracy: 0.16 - ETA: 2:48 - loss: 3.2424 - accuracy: 0.16 - ETA: 2:47 - loss: 3.2423 - accuracy: 0.16 - ETA: 2:47 - loss: 3.2426 - accuracy: 0.16 - ETA: 2:46 - loss: 3.2428 - accuracy: 0.16 - ETA: 2:45 - loss: 3.2420 - accuracy: 0.16 - ETA: 2:44 - loss: 3.2416 - accuracy: 0.16 - ETA: 2:43 - loss: 3.2409 - accuracy: 0.16 - ETA: 2:42 - loss: 3.2416 - accuracy: 0.16 - ETA: 2:41 - loss: 3.2412 - accuracy: 0.16 - ETA: 2:40 - loss: 3.2423 - accuracy: 0.16 - ETA: 2:39 - loss: 3.2429 - accuracy: 0.16 - ETA: 2:38 - loss: 3.2425 - accuracy: 0.16 - ETA: 2:37 - loss: 3.2417 - accuracy: 0.16 - ETA: 2:36 - loss: 3.2428 - accuracy: 0.16 - ETA: 2:35 - loss: 3.2437 - accuracy: 0.16 - ETA: 2:34 - loss: 3.2445 - accuracy: 0.16 - ETA: 2:33 - loss: 3.2438 - accuracy: 0.16 - ETA: 2:32 - loss: 3.2445 - accuracy: 0.16 - ETA: 2:31 - loss: 3.2446 - accuracy: 0.16 - ETA: 2:30 - loss: 3.2455 - accuracy: 0.16 - ETA: 2:29 - loss: 3.2455 - accuracy: 0.16 - ETA: 2:29 - loss: 3.2448 - accuracy: 0.16 - ETA: 2:28 - loss: 3.2455 - accuracy: 0.16 - ETA: 2:27 - loss: 3.2461 - accuracy: 0.16 - ETA: 2:26 - loss: 3.2476 - accuracy: 0.16 - ETA: 2:25 - loss: 3.2484 - accuracy: 0.16 - ETA: 2:24 - loss: 3.2500 - accuracy: 0.16 - ETA: 2:23 - loss: 3.2509 - accuracy: 0.16 - ETA: 2:22 - loss: 3.2515 - accuracy: 0.16 - ETA: 2:21 - loss: 3.2514 - accuracy: 0.16 - ETA: 2:20 - loss: 3.2511 - accuracy: 0.16 - ETA: 2:19 - loss: 3.2517 - accuracy: 0.16 - ETA: 2:18 - loss: 3.2520 - accuracy: 0.16 - ETA: 2:17 - loss: 3.2515 - accuracy: 0.1614"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:16 - loss: 3.2519 - accuracy: 0.16 - ETA: 2:15 - loss: 3.2522 - accuracy: 0.16 - ETA: 2:14 - loss: 3.2535 - accuracy: 0.16 - ETA: 2:13 - loss: 3.2548 - accuracy: 0.16 - ETA: 2:12 - loss: 3.2549 - accuracy: 0.16 - ETA: 2:11 - loss: 3.2556 - accuracy: 0.16 - ETA: 2:10 - loss: 3.2548 - accuracy: 0.16 - ETA: 2:09 - loss: 3.2551 - accuracy: 0.16 - ETA: 2:08 - loss: 3.2554 - accuracy: 0.16 - ETA: 2:08 - loss: 3.2549 - accuracy: 0.16 - ETA: 2:07 - loss: 3.2551 - accuracy: 0.16 - ETA: 2:06 - loss: 3.2547 - accuracy: 0.16 - ETA: 2:05 - loss: 3.2550 - accuracy: 0.16 - ETA: 2:04 - loss: 3.2553 - accuracy: 0.16 - ETA: 2:03 - loss: 3.2552 - accuracy: 0.16 - ETA: 2:02 - loss: 3.2553 - accuracy: 0.16 - ETA: 2:01 - loss: 3.2549 - accuracy: 0.16 - ETA: 2:00 - loss: 3.2543 - accuracy: 0.16 - ETA: 1:59 - loss: 3.2541 - accuracy: 0.16 - ETA: 1:58 - loss: 3.2551 - accuracy: 0.16 - ETA: 1:57 - loss: 3.2544 - accuracy: 0.16 - ETA: 1:56 - loss: 3.2539 - accuracy: 0.16 - ETA: 1:55 - loss: 3.2540 - accuracy: 0.16 - ETA: 1:54 - loss: 3.2544 - accuracy: 0.16 - ETA: 1:53 - loss: 3.2558 - accuracy: 0.16 - ETA: 1:52 - loss: 3.2561 - accuracy: 0.16 - ETA: 1:51 - loss: 3.2569 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2566 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2570 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2575 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2578 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2575 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2564 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2566 - accuracy: 0.16 - ETA: 1:44 - loss: 3.2567 - accuracy: 0.16 - ETA: 1:43 - loss: 3.2566 - accuracy: 0.16 - ETA: 1:42 - loss: 3.2574 - accuracy: 0.16 - ETA: 1:41 - loss: 3.2583 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2591 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2596 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2596 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2595 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2593 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2597 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2591 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2587 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2593 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2596 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2596 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2595 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2599 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2602 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2607 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2596 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2596 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2592 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2603 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2608 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2615 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2614 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2607 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2602 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2607 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2609 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2607 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2606 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2606 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2607 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2614 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2623 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2627 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2628 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2624 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2627 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2629 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2630 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2627 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2631 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2633 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2635 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2629 - accuracy: 0.15 - ETA: 59s - loss: 3.2626 - accuracy: 0.1587 - ETA: 58s - loss: 3.2622 - accuracy: 0.158 - ETA: 57s - loss: 3.2617 - accuracy: 0.158 - ETA: 56s - loss: 3.2619 - accuracy: 0.158 - ETA: 56s - loss: 3.2613 - accuracy: 0.158 - ETA: 55s - loss: 3.2613 - accuracy: 0.158 - ETA: 54s - loss: 3.2611 - accuracy: 0.158 - ETA: 53s - loss: 3.2612 - accuracy: 0.159 - ETA: 52s - loss: 3.2614 - accuracy: 0.159 - ETA: 51s - loss: 3.2615 - accuracy: 0.158 - ETA: 50s - loss: 3.2621 - accuracy: 0.158 - ETA: 49s - loss: 3.2619 - accuracy: 0.158 - ETA: 48s - loss: 3.2625 - accuracy: 0.158 - ETA: 47s - loss: 3.2625 - accuracy: 0.158 - ETA: 46s - loss: 3.2630 - accuracy: 0.158 - ETA: 45s - loss: 3.2625 - accuracy: 0.158 - ETA: 44s - loss: 3.2618 - accuracy: 0.159 - ETA: 43s - loss: 3.2618 - accuracy: 0.159 - ETA: 42s - loss: 3.2619 - accuracy: 0.159 - ETA: 41s - loss: 3.2625 - accuracy: 0.158 - ETA: 40s - loss: 3.2628 - accuracy: 0.158 - ETA: 39s - loss: 3.2629 - accuracy: 0.158 - ETA: 38s - loss: 3.2630 - accuracy: 0.158 - ETA: 37s - loss: 3.2629 - accuracy: 0.158 - ETA: 37s - loss: 3.2622 - accuracy: 0.158 - ETA: 36s - loss: 3.2616 - accuracy: 0.158 - ETA: 35s - loss: 3.2618 - accuracy: 0.158 - ETA: 34s - loss: 3.2611 - accuracy: 0.159 - ETA: 33s - loss: 3.2612 - accuracy: 0.159 - ETA: 32s - loss: 3.2613 - accuracy: 0.159 - ETA: 31s - loss: 3.2613 - accuracy: 0.158 - ETA: 30s - loss: 3.2609 - accuracy: 0.159 - ETA: 29s - loss: 3.2609 - accuracy: 0.159 - ETA: 28s - loss: 3.2605 - accuracy: 0.159 - ETA: 27s - loss: 3.2599 - accuracy: 0.159 - ETA: 26s - loss: 3.2601 - accuracy: 0.159 - ETA: 25s - loss: 3.2607 - accuracy: 0.159 - ETA: 24s - loss: 3.2606 - accuracy: 0.159 - ETA: 23s - loss: 3.2613 - accuracy: 0.159 - ETA: 22s - loss: 3.2610 - accuracy: 0.159 - ETA: 21s - loss: 3.2609 - accuracy: 0.159 - ETA: 20s - loss: 3.2610 - accuracy: 0.159 - ETA: 19s - loss: 3.2610 - accuracy: 0.159 - ETA: 19s - loss: 3.2617 - accuracy: 0.158 - ETA: 18s - loss: 3.2619 - accuracy: 0.158 - ETA: 17s - loss: 3.2624 - accuracy: 0.158 - ETA: 16s - loss: 3.2626 - accuracy: 0.158 - ETA: 15s - loss: 3.2628 - accuracy: 0.158 - ETA: 14s - loss: 3.2633 - accuracy: 0.158 - ETA: 13s - loss: 3.2627 - accuracy: 0.158 - ETA: 12s - loss: 3.2626 - accuracy: 0.158 - ETA: 11s - loss: 3.2624 - accuracy: 0.158 - ETA: 10s - loss: 3.2618 - accuracy: 0.158 - ETA: 9s - loss: 3.2614 - accuracy: 0.158 - ETA: 8s - loss: 3.2616 - accuracy: 0.15 - ETA: 7s - loss: 3.2614 - accuracy: 0.15 - ETA: 6s - loss: 3.2608 - accuracy: 0.15 - ETA: 5s - loss: 3.2608 - accuracy: 0.15 - ETA: 4s - loss: 3.2607 - accuracy: 0.15 - ETA: 3s - loss: 3.2607 - accuracy: 0.15 - ETA: 2s - loss: 3.2606 - accuracy: 0.15 - ETA: 1s - loss: 3.2600 - accuracy: 0.15 - ETA: 1s - loss: 3.2599 - accuracy: 0.15 - ETA: 0s - loss: 3.2598 - accuracy: 0.15 - 338s 8ms/step - loss: 3.2598 - accuracy: 0.1592 - val_loss: 4.0091 - val_accuracy: 0.0206\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:03 - loss: 3.1740 - accuracy: 0.20 - ETA: 5:04 - loss: 3.2629 - accuracy: 0.17 - ETA: 5:11 - loss: 3.2749 - accuracy: 0.16 - ETA: 5:12 - loss: 3.3497 - accuracy: 0.16 - ETA: 5:05 - loss: 3.3390 - accuracy: 0.15 - ETA: 5:02 - loss: 3.3125 - accuracy: 0.15 - ETA: 5:03 - loss: 3.3122 - accuracy: 0.14 - ETA: 5:03 - loss: 3.2997 - accuracy: 0.14 - ETA: 5:03 - loss: 3.2908 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2841 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2821 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2904 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2820 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2858 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2743 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2694 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2762 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2755 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2780 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2745 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2698 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2663 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2594 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2576 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2560 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2527 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2489 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2418 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2361 - accuracy: 0.16 - ETA: 4:46 - loss: 3.2365 - accuracy: 0.16 - ETA: 4:45 - loss: 3.2360 - accuracy: 0.16 - ETA: 4:44 - loss: 3.2380 - accuracy: 0.16 - ETA: 4:43 - loss: 3.2303 - accuracy: 0.16 - ETA: 4:43 - loss: 3.2274 - accuracy: 0.16 - ETA: 4:42 - loss: 3.2250 - accuracy: 0.16 - ETA: 4:41 - loss: 3.2254 - accuracy: 0.16 - ETA: 4:40 - loss: 3.2290 - accuracy: 0.16 - ETA: 4:40 - loss: 3.2315 - accuracy: 0.16 - ETA: 4:39 - loss: 3.2351 - accuracy: 0.16 - ETA: 4:38 - loss: 3.2293 - accuracy: 0.16 - ETA: 4:37 - loss: 3.2281 - accuracy: 0.16 - ETA: 4:36 - loss: 3.2280 - accuracy: 0.16 - ETA: 4:35 - loss: 3.2283 - accuracy: 0.16 - ETA: 4:34 - loss: 3.2301 - accuracy: 0.16 - ETA: 4:33 - loss: 3.2343 - accuracy: 0.16 - ETA: 4:32 - loss: 3.2330 - accuracy: 0.16 - ETA: 4:32 - loss: 3.2283 - accuracy: 0.16 - ETA: 4:31 - loss: 3.2301 - accuracy: 0.16 - ETA: 4:30 - loss: 3.2286 - accuracy: 0.16 - ETA: 4:30 - loss: 3.2265 - accuracy: 0.16 - ETA: 4:29 - loss: 3.2268 - accuracy: 0.16 - ETA: 4:28 - loss: 3.2269 - accuracy: 0.16 - ETA: 4:27 - loss: 3.2310 - accuracy: 0.16 - ETA: 4:26 - loss: 3.2313 - accuracy: 0.16 - ETA: 4:25 - loss: 3.2302 - accuracy: 0.16 - ETA: 4:24 - loss: 3.2331 - accuracy: 0.16 - ETA: 4:23 - loss: 3.2336 - accuracy: 0.16 - ETA: 4:22 - loss: 3.2357 - accuracy: 0.16 - ETA: 4:22 - loss: 3.2357 - accuracy: 0.16 - ETA: 4:21 - loss: 3.2352 - accuracy: 0.16 - ETA: 4:19 - loss: 3.2355 - accuracy: 0.16 - ETA: 4:18 - loss: 3.2322 - accuracy: 0.16 - ETA: 4:17 - loss: 3.2333 - accuracy: 0.16 - ETA: 4:16 - loss: 3.2332 - accuracy: 0.16 - ETA: 4:14 - loss: 3.2340 - accuracy: 0.16 - ETA: 4:14 - loss: 3.2346 - accuracy: 0.16 - ETA: 4:13 - loss: 3.2345 - accuracy: 0.16 - ETA: 4:12 - loss: 3.2336 - accuracy: 0.16 - ETA: 4:11 - loss: 3.2331 - accuracy: 0.16 - ETA: 4:10 - loss: 3.2302 - accuracy: 0.16 - ETA: 4:09 - loss: 3.2314 - accuracy: 0.16 - ETA: 4:09 - loss: 3.2328 - accuracy: 0.16 - ETA: 4:08 - loss: 3.2323 - accuracy: 0.16 - ETA: 4:07 - loss: 3.2321 - accuracy: 0.16 - ETA: 4:06 - loss: 3.2341 - accuracy: 0.16 - ETA: 4:05 - loss: 3.2352 - accuracy: 0.16 - ETA: 4:04 - loss: 3.2363 - accuracy: 0.16 - ETA: 4:03 - loss: 3.2392 - accuracy: 0.16 - ETA: 4:02 - loss: 3.2396 - accuracy: 0.16 - ETA: 4:01 - loss: 3.2400 - accuracy: 0.16 - ETA: 4:00 - loss: 3.2389 - accuracy: 0.16 - ETA: 3:59 - loss: 3.2406 - accuracy: 0.16 - ETA: 3:58 - loss: 3.2412 - accuracy: 0.16 - ETA: 3:57 - loss: 3.2414 - accuracy: 0.16 - ETA: 3:56 - loss: 3.2423 - accuracy: 0.16 - ETA: 3:55 - loss: 3.2387 - accuracy: 0.16 - ETA: 3:54 - loss: 3.2420 - accuracy: 0.16 - ETA: 3:53 - loss: 3.2410 - accuracy: 0.16 - ETA: 3:52 - loss: 3.2401 - accuracy: 0.16 - ETA: 3:51 - loss: 3.2401 - accuracy: 0.16 - ETA: 3:50 - loss: 3.2415 - accuracy: 0.16 - ETA: 3:49 - loss: 3.2407 - accuracy: 0.16 - ETA: 3:48 - loss: 3.2394 - accuracy: 0.16 - ETA: 3:47 - loss: 3.2418 - accuracy: 0.16 - ETA: 3:46 - loss: 3.2416 - accuracy: 0.16 - ETA: 3:45 - loss: 3.2422 - accuracy: 0.16 - ETA: 3:44 - loss: 3.2397 - accuracy: 0.16 - ETA: 3:43 - loss: 3.2413 - accuracy: 0.16 - ETA: 3:42 - loss: 3.2440 - accuracy: 0.16 - ETA: 3:42 - loss: 3.2450 - accuracy: 0.16 - ETA: 3:41 - loss: 3.2462 - accuracy: 0.16 - ETA: 3:40 - loss: 3.2458 - accuracy: 0.16 - ETA: 3:39 - loss: 3.2445 - accuracy: 0.16 - ETA: 3:38 - loss: 3.2455 - accuracy: 0.16 - ETA: 3:37 - loss: 3.2448 - accuracy: 0.16 - ETA: 3:36 - loss: 3.2451 - accuracy: 0.16 - ETA: 3:35 - loss: 3.2460 - accuracy: 0.16 - ETA: 3:34 - loss: 3.2463 - accuracy: 0.16 - ETA: 3:33 - loss: 3.2451 - accuracy: 0.16 - ETA: 3:32 - loss: 3.2461 - accuracy: 0.16 - ETA: 3:31 - loss: 3.2487 - accuracy: 0.16 - ETA: 3:30 - loss: 3.2498 - accuracy: 0.16 - ETA: 3:29 - loss: 3.2494 - accuracy: 0.16 - ETA: 3:28 - loss: 3.2499 - accuracy: 0.16 - ETA: 3:27 - loss: 3.2490 - accuracy: 0.16 - ETA: 3:26 - loss: 3.2490 - accuracy: 0.16 - ETA: 3:26 - loss: 3.2489 - accuracy: 0.16 - ETA: 3:25 - loss: 3.2487 - accuracy: 0.16 - ETA: 3:24 - loss: 3.2488 - accuracy: 0.16 - ETA: 3:23 - loss: 3.2496 - accuracy: 0.16 - ETA: 3:22 - loss: 3.2496 - accuracy: 0.16 - ETA: 3:21 - loss: 3.2479 - accuracy: 0.16 - ETA: 3:20 - loss: 3.2492 - accuracy: 0.16 - ETA: 3:19 - loss: 3.2483 - accuracy: 0.16 - ETA: 3:18 - loss: 3.2481 - accuracy: 0.16 - ETA: 3:17 - loss: 3.2484 - accuracy: 0.16 - ETA: 3:16 - loss: 3.2497 - accuracy: 0.16 - ETA: 3:15 - loss: 3.2500 - accuracy: 0.16 - ETA: 3:14 - loss: 3.2493 - accuracy: 0.16 - ETA: 3:13 - loss: 3.2493 - accuracy: 0.16 - ETA: 3:12 - loss: 3.2483 - accuracy: 0.16 - ETA: 3:11 - loss: 3.2473 - accuracy: 0.16 - ETA: 3:10 - loss: 3.2481 - accuracy: 0.16 - ETA: 3:09 - loss: 3.2471 - accuracy: 0.16 - ETA: 3:08 - loss: 3.2480 - accuracy: 0.16 - ETA: 3:07 - loss: 3.2465 - accuracy: 0.16 - ETA: 3:06 - loss: 3.2483 - accuracy: 0.16 - ETA: 3:05 - loss: 3.2488 - accuracy: 0.16 - ETA: 3:04 - loss: 3.2483 - accuracy: 0.16 - ETA: 3:03 - loss: 3.2494 - accuracy: 0.16 - ETA: 3:02 - loss: 3.2497 - accuracy: 0.16 - ETA: 3:01 - loss: 3.2483 - accuracy: 0.16 - ETA: 3:01 - loss: 3.2470 - accuracy: 0.16 - ETA: 3:00 - loss: 3.2473 - accuracy: 0.16 - ETA: 2:59 - loss: 3.2468 - accuracy: 0.16 - ETA: 2:58 - loss: 3.2475 - accuracy: 0.16 - ETA: 2:57 - loss: 3.2471 - accuracy: 0.16 - ETA: 2:56 - loss: 3.2477 - accuracy: 0.16 - ETA: 2:55 - loss: 3.2481 - accuracy: 0.16 - ETA: 2:54 - loss: 3.2475 - accuracy: 0.16 - ETA: 2:53 - loss: 3.2477 - accuracy: 0.16 - ETA: 2:52 - loss: 3.2491 - accuracy: 0.16 - ETA: 2:51 - loss: 3.2498 - accuracy: 0.16 - ETA: 2:50 - loss: 3.2491 - accuracy: 0.16 - ETA: 2:49 - loss: 3.2472 - accuracy: 0.16 - ETA: 2:48 - loss: 3.2475 - accuracy: 0.16 - ETA: 2:47 - loss: 3.2474 - accuracy: 0.16 - ETA: 2:46 - loss: 3.2472 - accuracy: 0.16 - ETA: 2:45 - loss: 3.2473 - accuracy: 0.16 - ETA: 2:44 - loss: 3.2465 - accuracy: 0.16 - ETA: 2:44 - loss: 3.2461 - accuracy: 0.16 - ETA: 2:43 - loss: 3.2456 - accuracy: 0.16 - ETA: 2:42 - loss: 3.2467 - accuracy: 0.16 - ETA: 2:41 - loss: 3.2471 - accuracy: 0.16 - ETA: 2:40 - loss: 3.2472 - accuracy: 0.16 - ETA: 2:39 - loss: 3.2467 - accuracy: 0.16 - ETA: 2:38 - loss: 3.2467 - accuracy: 0.16 - ETA: 2:37 - loss: 3.2452 - accuracy: 0.16 - ETA: 2:36 - loss: 3.2457 - accuracy: 0.16 - ETA: 2:35 - loss: 3.2454 - accuracy: 0.16 - ETA: 2:34 - loss: 3.2454 - accuracy: 0.16 - ETA: 2:33 - loss: 3.2445 - accuracy: 0.16 - ETA: 2:32 - loss: 3.2448 - accuracy: 0.16 - ETA: 2:31 - loss: 3.2452 - accuracy: 0.16 - ETA: 2:30 - loss: 3.2457 - accuracy: 0.16 - ETA: 2:29 - loss: 3.2456 - accuracy: 0.16 - ETA: 2:28 - loss: 3.2457 - accuracy: 0.16 - ETA: 2:27 - loss: 3.2449 - accuracy: 0.16 - ETA: 2:26 - loss: 3.2450 - accuracy: 0.16 - ETA: 2:25 - loss: 3.2448 - accuracy: 0.16 - ETA: 2:24 - loss: 3.2448 - accuracy: 0.16 - ETA: 2:23 - loss: 3.2449 - accuracy: 0.16 - ETA: 2:22 - loss: 3.2453 - accuracy: 0.16 - ETA: 2:21 - loss: 3.2445 - accuracy: 0.16 - ETA: 2:21 - loss: 3.2445 - accuracy: 0.16 - ETA: 2:20 - loss: 3.2448 - accuracy: 0.1622"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:19 - loss: 3.2442 - accuracy: 0.16 - ETA: 2:18 - loss: 3.2437 - accuracy: 0.16 - ETA: 2:17 - loss: 3.2434 - accuracy: 0.16 - ETA: 2:16 - loss: 3.2431 - accuracy: 0.16 - ETA: 2:15 - loss: 3.2427 - accuracy: 0.16 - ETA: 2:14 - loss: 3.2434 - accuracy: 0.16 - ETA: 2:13 - loss: 3.2438 - accuracy: 0.16 - ETA: 2:12 - loss: 3.2423 - accuracy: 0.16 - ETA: 2:11 - loss: 3.2434 - accuracy: 0.16 - ETA: 2:10 - loss: 3.2433 - accuracy: 0.16 - ETA: 2:09 - loss: 3.2433 - accuracy: 0.16 - ETA: 2:08 - loss: 3.2447 - accuracy: 0.16 - ETA: 2:07 - loss: 3.2441 - accuracy: 0.16 - ETA: 2:06 - loss: 3.2451 - accuracy: 0.16 - ETA: 2:05 - loss: 3.2449 - accuracy: 0.16 - ETA: 2:04 - loss: 3.2457 - accuracy: 0.16 - ETA: 2:03 - loss: 3.2458 - accuracy: 0.16 - ETA: 2:02 - loss: 3.2462 - accuracy: 0.16 - ETA: 2:01 - loss: 3.2475 - accuracy: 0.16 - ETA: 2:00 - loss: 3.2475 - accuracy: 0.16 - ETA: 1:59 - loss: 3.2480 - accuracy: 0.16 - ETA: 1:58 - loss: 3.2484 - accuracy: 0.16 - ETA: 1:57 - loss: 3.2484 - accuracy: 0.16 - ETA: 1:56 - loss: 3.2487 - accuracy: 0.16 - ETA: 1:55 - loss: 3.2495 - accuracy: 0.16 - ETA: 1:54 - loss: 3.2500 - accuracy: 0.16 - ETA: 1:53 - loss: 3.2499 - accuracy: 0.16 - ETA: 1:52 - loss: 3.2495 - accuracy: 0.16 - ETA: 1:51 - loss: 3.2508 - accuracy: 0.16 - ETA: 1:50 - loss: 3.2513 - accuracy: 0.16 - ETA: 1:49 - loss: 3.2512 - accuracy: 0.16 - ETA: 1:48 - loss: 3.2516 - accuracy: 0.16 - ETA: 1:47 - loss: 3.2516 - accuracy: 0.16 - ETA: 1:47 - loss: 3.2516 - accuracy: 0.16 - ETA: 1:46 - loss: 3.2520 - accuracy: 0.16 - ETA: 1:45 - loss: 3.2530 - accuracy: 0.16 - ETA: 1:44 - loss: 3.2539 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2544 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2539 - accuracy: 0.16 - ETA: 1:41 - loss: 3.2533 - accuracy: 0.16 - ETA: 1:40 - loss: 3.2533 - accuracy: 0.16 - ETA: 1:39 - loss: 3.2536 - accuracy: 0.16 - ETA: 1:38 - loss: 3.2541 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2543 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2541 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2538 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2532 - accuracy: 0.16 - ETA: 1:33 - loss: 3.2534 - accuracy: 0.16 - ETA: 1:32 - loss: 3.2539 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2542 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2546 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2541 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2542 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2548 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2548 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2546 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2541 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2543 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2542 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2541 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2540 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2540 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2545 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2546 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2536 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2530 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2525 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2529 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2528 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2521 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2529 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2526 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2523 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2516 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2511 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2516 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2513 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2513 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2515 - accuracy: 0.16 - ETA: 1:02 - loss: 3.2510 - accuracy: 0.16 - ETA: 1:01 - loss: 3.2507 - accuracy: 0.16 - ETA: 1:00 - loss: 3.2510 - accuracy: 0.16 - ETA: 59s - loss: 3.2512 - accuracy: 0.1600 - ETA: 58s - loss: 3.2508 - accuracy: 0.159 - ETA: 57s - loss: 3.2511 - accuracy: 0.159 - ETA: 57s - loss: 3.2519 - accuracy: 0.159 - ETA: 56s - loss: 3.2520 - accuracy: 0.159 - ETA: 55s - loss: 3.2514 - accuracy: 0.159 - ETA: 54s - loss: 3.2516 - accuracy: 0.159 - ETA: 53s - loss: 3.2514 - accuracy: 0.159 - ETA: 52s - loss: 3.2519 - accuracy: 0.159 - ETA: 51s - loss: 3.2512 - accuracy: 0.159 - ETA: 50s - loss: 3.2509 - accuracy: 0.159 - ETA: 49s - loss: 3.2508 - accuracy: 0.159 - ETA: 48s - loss: 3.2511 - accuracy: 0.159 - ETA: 47s - loss: 3.2500 - accuracy: 0.159 - ETA: 46s - loss: 3.2498 - accuracy: 0.159 - ETA: 45s - loss: 3.2501 - accuracy: 0.159 - ETA: 44s - loss: 3.2505 - accuracy: 0.159 - ETA: 43s - loss: 3.2503 - accuracy: 0.159 - ETA: 42s - loss: 3.2502 - accuracy: 0.159 - ETA: 41s - loss: 3.2505 - accuracy: 0.159 - ETA: 40s - loss: 3.2498 - accuracy: 0.160 - ETA: 39s - loss: 3.2491 - accuracy: 0.160 - ETA: 38s - loss: 3.2494 - accuracy: 0.160 - ETA: 37s - loss: 3.2488 - accuracy: 0.160 - ETA: 36s - loss: 3.2490 - accuracy: 0.160 - ETA: 35s - loss: 3.2491 - accuracy: 0.160 - ETA: 34s - loss: 3.2485 - accuracy: 0.160 - ETA: 33s - loss: 3.2488 - accuracy: 0.160 - ETA: 32s - loss: 3.2486 - accuracy: 0.160 - ETA: 31s - loss: 3.2488 - accuracy: 0.160 - ETA: 30s - loss: 3.2494 - accuracy: 0.159 - ETA: 30s - loss: 3.2499 - accuracy: 0.159 - ETA: 29s - loss: 3.2503 - accuracy: 0.159 - ETA: 28s - loss: 3.2507 - accuracy: 0.159 - ETA: 27s - loss: 3.2505 - accuracy: 0.159 - ETA: 26s - loss: 3.2507 - accuracy: 0.159 - ETA: 25s - loss: 3.2514 - accuracy: 0.159 - ETA: 24s - loss: 3.2515 - accuracy: 0.159 - ETA: 23s - loss: 3.2519 - accuracy: 0.159 - ETA: 22s - loss: 3.2525 - accuracy: 0.159 - ETA: 21s - loss: 3.2527 - accuracy: 0.159 - ETA: 20s - loss: 3.2536 - accuracy: 0.159 - ETA: 19s - loss: 3.2541 - accuracy: 0.159 - ETA: 18s - loss: 3.2548 - accuracy: 0.158 - ETA: 17s - loss: 3.2551 - accuracy: 0.158 - ETA: 16s - loss: 3.2552 - accuracy: 0.158 - ETA: 15s - loss: 3.2553 - accuracy: 0.159 - ETA: 14s - loss: 3.2549 - accuracy: 0.159 - ETA: 13s - loss: 3.2553 - accuracy: 0.158 - ETA: 12s - loss: 3.2560 - accuracy: 0.158 - ETA: 11s - loss: 3.2564 - accuracy: 0.158 - ETA: 10s - loss: 3.2565 - accuracy: 0.158 - ETA: 9s - loss: 3.2567 - accuracy: 0.158 - ETA: 8s - loss: 3.2568 - accuracy: 0.15 - ETA: 7s - loss: 3.2563 - accuracy: 0.15 - ETA: 6s - loss: 3.2571 - accuracy: 0.15 - ETA: 5s - loss: 3.2584 - accuracy: 0.15 - ETA: 4s - loss: 3.2591 - accuracy: 0.15 - ETA: 3s - loss: 3.2592 - accuracy: 0.15 - ETA: 2s - loss: 3.2595 - accuracy: 0.15 - ETA: 2s - loss: 3.2600 - accuracy: 0.15 - ETA: 1s - loss: 3.2598 - accuracy: 0.15 - ETA: 0s - loss: 3.2604 - accuracy: 0.15 - 345s 8ms/step - loss: 3.2604 - accuracy: 0.1583 - val_loss: 3.9876 - val_accuracy: 0.0170\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:33 - loss: 3.2780 - accuracy: 0.15 - ETA: 5:27 - loss: 3.2973 - accuracy: 0.18 - ETA: 5:18 - loss: 3.3411 - accuracy: 0.17 - ETA: 5:12 - loss: 3.3154 - accuracy: 0.17 - ETA: 5:07 - loss: 3.3464 - accuracy: 0.16 - ETA: 5:07 - loss: 3.3231 - accuracy: 0.16 - ETA: 5:06 - loss: 3.3131 - accuracy: 0.16 - ETA: 5:07 - loss: 3.3061 - accuracy: 0.17 - ETA: 5:08 - loss: 3.3343 - accuracy: 0.16 - ETA: 5:09 - loss: 3.3449 - accuracy: 0.15 - ETA: 5:11 - loss: 3.3319 - accuracy: 0.15 - ETA: 5:12 - loss: 3.3208 - accuracy: 0.15 - ETA: 5:12 - loss: 3.3145 - accuracy: 0.15 - ETA: 5:10 - loss: 3.3194 - accuracy: 0.15 - ETA: 5:07 - loss: 3.3155 - accuracy: 0.15 - ETA: 5:06 - loss: 3.3154 - accuracy: 0.15 - ETA: 5:05 - loss: 3.3111 - accuracy: 0.15 - ETA: 5:03 - loss: 3.3139 - accuracy: 0.15 - ETA: 5:03 - loss: 3.3085 - accuracy: 0.15 - ETA: 5:01 - loss: 3.3056 - accuracy: 0.15 - ETA: 5:00 - loss: 3.3094 - accuracy: 0.15 - ETA: 4:59 - loss: 3.3061 - accuracy: 0.15 - ETA: 4:58 - loss: 3.3085 - accuracy: 0.15 - ETA: 4:57 - loss: 3.3054 - accuracy: 0.15 - ETA: 4:56 - loss: 3.2987 - accuracy: 0.15 - ETA: 4:55 - loss: 3.2969 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2944 - accuracy: 0.15 - ETA: 4:54 - loss: 3.2949 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2909 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2917 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2930 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2944 - accuracy: 0.15 - ETA: 4:51 - loss: 3.2895 - accuracy: 0.15 - ETA: 4:50 - loss: 3.2951 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2935 - accuracy: 0.15 - ETA: 4:48 - loss: 3.2956 - accuracy: 0.15 - ETA: 4:46 - loss: 3.3000 - accuracy: 0.15 - ETA: 4:45 - loss: 3.3069 - accuracy: 0.15 - ETA: 4:43 - loss: 3.3067 - accuracy: 0.15 - ETA: 4:43 - loss: 3.3037 - accuracy: 0.15 - ETA: 4:41 - loss: 3.3034 - accuracy: 0.15 - ETA: 4:40 - loss: 3.3017 - accuracy: 0.15 - ETA: 4:40 - loss: 3.3001 - accuracy: 0.15 - ETA: 4:39 - loss: 3.3044 - accuracy: 0.15 - ETA: 4:37 - loss: 3.3087 - accuracy: 0.15 - ETA: 4:36 - loss: 3.3117 - accuracy: 0.15 - ETA: 4:35 - loss: 3.3115 - accuracy: 0.15 - ETA: 4:34 - loss: 3.3129 - accuracy: 0.15 - ETA: 4:33 - loss: 3.3124 - accuracy: 0.15 - ETA: 4:32 - loss: 3.3137 - accuracy: 0.15 - ETA: 4:31 - loss: 3.3141 - accuracy: 0.15 - ETA: 4:30 - loss: 3.3127 - accuracy: 0.15 - ETA: 4:29 - loss: 3.3156 - accuracy: 0.15 - ETA: 4:28 - loss: 3.3184 - accuracy: 0.15 - ETA: 4:27 - loss: 3.3206 - accuracy: 0.15 - ETA: 4:25 - loss: 3.3204 - accuracy: 0.15 - ETA: 4:25 - loss: 3.3213 - accuracy: 0.15 - ETA: 4:24 - loss: 3.3219 - accuracy: 0.15 - ETA: 4:23 - loss: 3.3246 - accuracy: 0.15 - ETA: 4:22 - loss: 3.3247 - accuracy: 0.15 - ETA: 4:21 - loss: 3.3262 - accuracy: 0.15 - ETA: 4:20 - loss: 3.3269 - accuracy: 0.15 - ETA: 4:19 - loss: 3.3269 - accuracy: 0.15 - ETA: 4:18 - loss: 3.3272 - accuracy: 0.15 - ETA: 4:17 - loss: 3.3298 - accuracy: 0.15 - ETA: 4:16 - loss: 3.3315 - accuracy: 0.15 - ETA: 4:15 - loss: 3.3311 - accuracy: 0.15 - ETA: 4:15 - loss: 3.3298 - accuracy: 0.15 - ETA: 4:14 - loss: 3.3308 - accuracy: 0.15 - ETA: 4:12 - loss: 3.3299 - accuracy: 0.15 - ETA: 4:11 - loss: 3.3293 - accuracy: 0.15 - ETA: 4:10 - loss: 3.3286 - accuracy: 0.15 - ETA: 4:09 - loss: 3.3287 - accuracy: 0.15 - ETA: 4:08 - loss: 3.3313 - accuracy: 0.15 - ETA: 4:08 - loss: 3.3334 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3344 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3373 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3369 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3351 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3327 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3325 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3315 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3337 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3336 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3310 - accuracy: 0.15 - ETA: 3:57 - loss: 3.3304 - accuracy: 0.15 - ETA: 3:56 - loss: 3.3300 - accuracy: 0.15 - ETA: 3:55 - loss: 3.3285 - accuracy: 0.15 - ETA: 3:54 - loss: 3.3303 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3297 - accuracy: 0.15 - ETA: 3:52 - loss: 3.3284 - accuracy: 0.15 - ETA: 3:51 - loss: 3.3271 - accuracy: 0.15 - ETA: 3:51 - loss: 3.3286 - accuracy: 0.15 - ETA: 3:50 - loss: 3.3294 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3296 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3297 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3315 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3312 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3331 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3329 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3341 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3347 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3337 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3349 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3353 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3348 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3332 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3329 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3334 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3346 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3359 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3369 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3384 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3389 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3391 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3412 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3435 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3427 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3418 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3426 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3444 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3452 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3460 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3485 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3491 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3506 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3513 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3519 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3526 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3536 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3554 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3564 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3577 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3579 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3590 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3586 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3608 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3624 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3630 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3632 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3632 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3633 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3630 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3631 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3630 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3620 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3621 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3629 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3629 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3627 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3642 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3651 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3659 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3670 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3680 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3682 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3677 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3686 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3693 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3702 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3697 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3698 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3705 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3701 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3699 - accuracy: 0.13 - ETA: 2:40 - loss: 3.3707 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3715 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3713 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3716 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3726 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3721 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3716 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3719 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3725 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3729 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3719 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3719 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3718 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3719 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3717 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3722 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3715 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3720 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3719 - accuracy: 0.13 - ETA: 2:21 - loss: 3.3714 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3708 - accuracy: 0.1385"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:19 - loss: 3.3701 - accuracy: 0.13 - ETA: 2:18 - loss: 3.3710 - accuracy: 0.13 - ETA: 2:17 - loss: 3.3704 - accuracy: 0.13 - ETA: 2:16 - loss: 3.3700 - accuracy: 0.13 - ETA: 2:15 - loss: 3.3700 - accuracy: 0.13 - ETA: 2:14 - loss: 3.3687 - accuracy: 0.13 - ETA: 2:13 - loss: 3.3686 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3679 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3685 - accuracy: 0.13 - ETA: 2:10 - loss: 3.3675 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3672 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3678 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3671 - accuracy: 0.13 - ETA: 2:07 - loss: 3.3670 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3666 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3665 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3667 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3671 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3679 - accuracy: 0.13 - ETA: 2:01 - loss: 3.3680 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3680 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3693 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3699 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3693 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3693 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3697 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3696 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3696 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3698 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3707 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3703 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3706 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3701 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3702 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3700 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3706 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3706 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3712 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3718 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3717 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3716 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3722 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3716 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3717 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3716 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3721 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3717 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3717 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3716 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3726 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3725 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3727 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3738 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3733 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3730 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3730 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3725 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3730 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3726 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3715 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3707 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3706 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3707 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3707 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3701 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3692 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3687 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3684 - accuracy: 0.13 - ETA: 1:13 - loss: 3.3689 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3680 - accuracy: 0.13 - ETA: 1:11 - loss: 3.3682 - accuracy: 0.13 - ETA: 1:10 - loss: 3.3677 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3675 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3676 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3673 - accuracy: 0.13 - ETA: 1:06 - loss: 3.3676 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3672 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3671 - accuracy: 0.13 - ETA: 1:03 - loss: 3.3669 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3667 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3672 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3661 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3657 - accuracy: 0.13 - ETA: 59s - loss: 3.3646 - accuracy: 0.1400 - ETA: 58s - loss: 3.3640 - accuracy: 0.140 - ETA: 57s - loss: 3.3634 - accuracy: 0.139 - ETA: 56s - loss: 3.3627 - accuracy: 0.140 - ETA: 55s - loss: 3.3623 - accuracy: 0.140 - ETA: 54s - loss: 3.3620 - accuracy: 0.140 - ETA: 53s - loss: 3.3622 - accuracy: 0.139 - ETA: 52s - loss: 3.3619 - accuracy: 0.140 - ETA: 51s - loss: 3.3609 - accuracy: 0.140 - ETA: 50s - loss: 3.3598 - accuracy: 0.140 - ETA: 49s - loss: 3.3594 - accuracy: 0.140 - ETA: 48s - loss: 3.3595 - accuracy: 0.140 - ETA: 47s - loss: 3.3592 - accuracy: 0.140 - ETA: 46s - loss: 3.3589 - accuracy: 0.140 - ETA: 45s - loss: 3.3581 - accuracy: 0.140 - ETA: 44s - loss: 3.3568 - accuracy: 0.141 - ETA: 43s - loss: 3.3560 - accuracy: 0.141 - ETA: 42s - loss: 3.3557 - accuracy: 0.141 - ETA: 41s - loss: 3.3549 - accuracy: 0.141 - ETA: 40s - loss: 3.3545 - accuracy: 0.141 - ETA: 39s - loss: 3.3558 - accuracy: 0.141 - ETA: 38s - loss: 3.3558 - accuracy: 0.141 - ETA: 37s - loss: 3.3547 - accuracy: 0.141 - ETA: 36s - loss: 3.3545 - accuracy: 0.141 - ETA: 35s - loss: 3.3548 - accuracy: 0.141 - ETA: 34s - loss: 3.3550 - accuracy: 0.141 - ETA: 33s - loss: 3.3547 - accuracy: 0.141 - ETA: 32s - loss: 3.3542 - accuracy: 0.141 - ETA: 31s - loss: 3.3542 - accuracy: 0.141 - ETA: 31s - loss: 3.3537 - accuracy: 0.141 - ETA: 30s - loss: 3.3535 - accuracy: 0.141 - ETA: 29s - loss: 3.3533 - accuracy: 0.141 - ETA: 28s - loss: 3.3535 - accuracy: 0.141 - ETA: 27s - loss: 3.3534 - accuracy: 0.141 - ETA: 26s - loss: 3.3531 - accuracy: 0.141 - ETA: 25s - loss: 3.3532 - accuracy: 0.141 - ETA: 24s - loss: 3.3529 - accuracy: 0.141 - ETA: 23s - loss: 3.3527 - accuracy: 0.141 - ETA: 22s - loss: 3.3527 - accuracy: 0.141 - ETA: 21s - loss: 3.3522 - accuracy: 0.141 - ETA: 20s - loss: 3.3518 - accuracy: 0.141 - ETA: 19s - loss: 3.3517 - accuracy: 0.141 - ETA: 18s - loss: 3.3514 - accuracy: 0.141 - ETA: 17s - loss: 3.3509 - accuracy: 0.141 - ETA: 16s - loss: 3.3507 - accuracy: 0.141 - ETA: 15s - loss: 3.3511 - accuracy: 0.141 - ETA: 14s - loss: 3.3510 - accuracy: 0.141 - ETA: 13s - loss: 3.3508 - accuracy: 0.141 - ETA: 12s - loss: 3.3510 - accuracy: 0.141 - ETA: 11s - loss: 3.3507 - accuracy: 0.141 - ETA: 10s - loss: 3.3505 - accuracy: 0.141 - ETA: 9s - loss: 3.3500 - accuracy: 0.142 - ETA: 8s - loss: 3.3501 - accuracy: 0.14 - ETA: 7s - loss: 3.3503 - accuracy: 0.14 - ETA: 6s - loss: 3.3494 - accuracy: 0.14 - ETA: 5s - loss: 3.3490 - accuracy: 0.14 - ETA: 4s - loss: 3.3493 - accuracy: 0.14 - ETA: 3s - loss: 3.3492 - accuracy: 0.14 - ETA: 2s - loss: 3.3489 - accuracy: 0.14 - ETA: 2s - loss: 3.3482 - accuracy: 0.14 - ETA: 1s - loss: 3.3476 - accuracy: 0.14 - ETA: 0s - loss: 3.3472 - accuracy: 0.14 - 344s 8ms/step - loss: 3.3471 - accuracy: 0.1427 - val_loss: 3.9346 - val_accuracy: 0.0227\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:12 - loss: 3.3235 - accuracy: 0.14 - ETA: 4:59 - loss: 3.2603 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2743 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2864 - accuracy: 0.16 - ETA: 5:03 - loss: 3.2899 - accuracy: 0.15 - ETA: 5:08 - loss: 3.2512 - accuracy: 0.16 - ETA: 5:11 - loss: 3.2537 - accuracy: 0.16 - ETA: 5:08 - loss: 3.2403 - accuracy: 0.17 - ETA: 5:07 - loss: 3.2409 - accuracy: 0.16 - ETA: 5:07 - loss: 3.2529 - accuracy: 0.16 - ETA: 5:07 - loss: 3.2508 - accuracy: 0.15 - ETA: 5:05 - loss: 3.2551 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2591 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2735 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2754 - accuracy: 0.15 - ETA: 5:03 - loss: 3.2822 - accuracy: 0.15 - ETA: 5:02 - loss: 3.2895 - accuracy: 0.15 - ETA: 5:01 - loss: 3.2897 - accuracy: 0.15 - ETA: 5:00 - loss: 3.2873 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2922 - accuracy: 0.15 - ETA: 4:59 - loss: 3.2916 - accuracy: 0.15 - ETA: 4:58 - loss: 3.2949 - accuracy: 0.15 - ETA: 4:57 - loss: 3.2899 - accuracy: 0.15 - ETA: 4:55 - loss: 3.2879 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2904 - accuracy: 0.15 - ETA: 4:52 - loss: 3.2964 - accuracy: 0.14 - ETA: 4:51 - loss: 3.2944 - accuracy: 0.15 - ETA: 4:51 - loss: 3.3004 - accuracy: 0.14 - ETA: 4:49 - loss: 3.2952 - accuracy: 0.15 - ETA: 4:47 - loss: 3.3005 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2982 - accuracy: 0.15 - ETA: 4:45 - loss: 3.3002 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3048 - accuracy: 0.14 - ETA: 4:44 - loss: 3.3003 - accuracy: 0.15 - ETA: 4:43 - loss: 3.3006 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2970 - accuracy: 0.15 - ETA: 4:42 - loss: 3.2966 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2939 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2933 - accuracy: 0.15 - ETA: 4:40 - loss: 3.2950 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2965 - accuracy: 0.15 - ETA: 4:38 - loss: 3.2999 - accuracy: 0.15 - ETA: 4:36 - loss: 3.2996 - accuracy: 0.15 - ETA: 4:36 - loss: 3.3001 - accuracy: 0.15 - ETA: 4:35 - loss: 3.3011 - accuracy: 0.15 - ETA: 4:33 - loss: 3.3000 - accuracy: 0.15 - ETA: 4:32 - loss: 3.3024 - accuracy: 0.15 - ETA: 4:31 - loss: 3.3051 - accuracy: 0.15 - ETA: 4:30 - loss: 3.3043 - accuracy: 0.15 - ETA: 4:29 - loss: 3.3012 - accuracy: 0.15 - ETA: 4:28 - loss: 3.3068 - accuracy: 0.15 - ETA: 4:27 - loss: 3.3086 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3089 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3123 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3142 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3086 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3039 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3029 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3021 - accuracy: 0.15 - ETA: 4:20 - loss: 3.3003 - accuracy: 0.15 - ETA: 4:19 - loss: 3.3026 - accuracy: 0.15 - ETA: 4:18 - loss: 3.3054 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3067 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3066 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3039 - accuracy: 0.15 - ETA: 4:14 - loss: 3.3028 - accuracy: 0.15 - ETA: 4:13 - loss: 3.3023 - accuracy: 0.15 - ETA: 4:12 - loss: 3.3008 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2989 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2975 - accuracy: 0.15 - ETA: 4:09 - loss: 3.2946 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2954 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2940 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2922 - accuracy: 0.15 - ETA: 4:06 - loss: 3.2924 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2913 - accuracy: 0.15 - ETA: 4:04 - loss: 3.2887 - accuracy: 0.15 - ETA: 4:03 - loss: 3.2888 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2889 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2885 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2914 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2918 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2910 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2888 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2885 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2871 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2874 - accuracy: 0.15 - ETA: 3:54 - loss: 3.2886 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2876 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2865 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2867 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2868 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2871 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2882 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2874 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2876 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2865 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2866 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2852 - accuracy: 0.15 - ETA: 3:42 - loss: 3.2836 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2845 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2815 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2816 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2835 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2844 - accuracy: 0.15 - ETA: 3:37 - loss: 3.2849 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2853 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2873 - accuracy: 0.15 - ETA: 3:34 - loss: 3.2881 - accuracy: 0.15 - ETA: 3:33 - loss: 3.2879 - accuracy: 0.15 - ETA: 3:32 - loss: 3.2881 - accuracy: 0.15 - ETA: 3:31 - loss: 3.2884 - accuracy: 0.15 - ETA: 3:30 - loss: 3.2882 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2863 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2854 - accuracy: 0.15 - ETA: 3:27 - loss: 3.2851 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2850 - accuracy: 0.15 - ETA: 3:25 - loss: 3.2858 - accuracy: 0.15 - ETA: 3:24 - loss: 3.2869 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2867 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2866 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2867 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2864 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2874 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2876 - accuracy: 0.15 - ETA: 3:17 - loss: 3.2887 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2877 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2867 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2882 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2888 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2890 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2893 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2883 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2879 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2862 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2860 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2861 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2871 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2877 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2877 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2884 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2896 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2888 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2900 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2921 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2921 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2938 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2936 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2920 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2923 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2928 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2924 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2928 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2921 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2916 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2931 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2929 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2946 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2946 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2951 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2956 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2955 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2954 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2963 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2969 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2975 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2976 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2980 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2981 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2985 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2983 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2981 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2981 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2966 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2963 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2961 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2961 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2965 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2972 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2976 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2970 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2969 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2968 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2970 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2977 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2981 - accuracy: 0.1513"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.2988 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2989 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2996 - accuracy: 0.15 - ETA: 2:16 - loss: 3.3007 - accuracy: 0.15 - ETA: 2:15 - loss: 3.3010 - accuracy: 0.15 - ETA: 2:14 - loss: 3.3009 - accuracy: 0.15 - ETA: 2:13 - loss: 3.3010 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3000 - accuracy: 0.15 - ETA: 2:11 - loss: 3.3003 - accuracy: 0.15 - ETA: 2:10 - loss: 3.3012 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3016 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3017 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3012 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3005 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2998 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2997 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2990 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2997 - accuracy: 0.15 - ETA: 2:01 - loss: 3.3010 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3014 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3019 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3024 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3026 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3032 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3028 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3021 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3017 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3015 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3012 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3016 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3008 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3006 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3003 - accuracy: 0.15 - ETA: 1:47 - loss: 3.3000 - accuracy: 0.15 - ETA: 1:46 - loss: 3.3001 - accuracy: 0.15 - ETA: 1:45 - loss: 3.3003 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2998 - accuracy: 0.15 - ETA: 1:43 - loss: 3.3001 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2997 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2996 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2992 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2990 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2987 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2985 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2989 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2996 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2991 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2993 - accuracy: 0.15 - ETA: 1:32 - loss: 3.3000 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2998 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2998 - accuracy: 0.15 - ETA: 1:29 - loss: 3.3004 - accuracy: 0.15 - ETA: 1:28 - loss: 3.3008 - accuracy: 0.15 - ETA: 1:28 - loss: 3.3005 - accuracy: 0.15 - ETA: 1:27 - loss: 3.3002 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2991 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2985 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2984 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2982 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2976 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2982 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2986 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2992 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2991 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2994 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2993 - accuracy: 0.15 - ETA: 1:15 - loss: 3.3003 - accuracy: 0.15 - ETA: 1:14 - loss: 3.3011 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3012 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3014 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3014 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3018 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3020 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3027 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3033 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3034 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3040 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3041 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3042 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3049 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3059 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3063 - accuracy: 0.14 - ETA: 59s - loss: 3.3068 - accuracy: 0.1486 - ETA: 57s - loss: 3.3074 - accuracy: 0.148 - ETA: 56s - loss: 3.3083 - accuracy: 0.148 - ETA: 55s - loss: 3.3085 - accuracy: 0.148 - ETA: 1:24:22 - loss: 3.3089 - accuracy: 0.148 - ETA: 1:22:37 - loss: 3.3095 - accuracy: 0.147 - ETA: 1:20:52 - loss: 3.3104 - accuracy: 0.147 - ETA: 1:19:09 - loss: 3.3113 - accuracy: 0.147 - ETA: 1:17:26 - loss: 3.3111 - accuracy: 0.147 - ETA: 1:15:44 - loss: 3.3116 - accuracy: 0.147 - ETA: 1:14:03 - loss: 3.3113 - accuracy: 0.147 - ETA: 1:12:22 - loss: 3.3121 - accuracy: 0.147 - ETA: 1:10:42 - loss: 3.3126 - accuracy: 0.147 - ETA: 1:09:03 - loss: 3.3134 - accuracy: 0.147 - ETA: 1:07:24 - loss: 3.3135 - accuracy: 0.147 - ETA: 1:05:46 - loss: 3.3137 - accuracy: 0.146 - ETA: 1:04:09 - loss: 3.3136 - accuracy: 0.146 - ETA: 1:02:32 - loss: 3.3140 - accuracy: 0.146 - ETA: 1:00:56 - loss: 3.3143 - accuracy: 0.146 - ETA: 59:21 - loss: 3.3142 - accuracy: 0.1465  - ETA: 57:47 - loss: 3.3141 - accuracy: 0.146 - ETA: 56:13 - loss: 3.3141 - accuracy: 0.146 - ETA: 54:39 - loss: 3.3143 - accuracy: 0.146 - ETA: 53:07 - loss: 3.3151 - accuracy: 0.146 - ETA: 51:35 - loss: 3.3153 - accuracy: 0.146 - ETA: 50:03 - loss: 3.3153 - accuracy: 0.146 - ETA: 48:32 - loss: 3.3151 - accuracy: 0.146 - ETA: 47:02 - loss: 3.3152 - accuracy: 0.146 - ETA: 45:33 - loss: 3.3152 - accuracy: 0.146 - ETA: 44:04 - loss: 3.3154 - accuracy: 0.146 - ETA: 42:35 - loss: 3.3157 - accuracy: 0.146 - ETA: 41:07 - loss: 3.3157 - accuracy: 0.146 - ETA: 39:40 - loss: 3.3156 - accuracy: 0.146 - ETA: 38:13 - loss: 3.3157 - accuracy: 0.146 - ETA: 36:47 - loss: 3.3151 - accuracy: 0.146 - ETA: 35:22 - loss: 3.3156 - accuracy: 0.146 - ETA: 33:57 - loss: 3.3157 - accuracy: 0.146 - ETA: 32:32 - loss: 3.3160 - accuracy: 0.146 - ETA: 31:08 - loss: 3.3159 - accuracy: 0.146 - ETA: 29:45 - loss: 3.3162 - accuracy: 0.146 - ETA: 28:22 - loss: 3.3159 - accuracy: 0.146 - ETA: 27:00 - loss: 3.3161 - accuracy: 0.145 - ETA: 25:38 - loss: 3.3159 - accuracy: 0.146 - ETA: 24:17 - loss: 3.3157 - accuracy: 0.146 - ETA: 22:56 - loss: 3.3159 - accuracy: 0.146 - ETA: 21:36 - loss: 3.3155 - accuracy: 0.146 - ETA: 20:16 - loss: 3.3153 - accuracy: 0.146 - ETA: 18:57 - loss: 3.3153 - accuracy: 0.146 - ETA: 17:38 - loss: 3.3155 - accuracy: 0.146 - ETA: 16:20 - loss: 3.3161 - accuracy: 0.146 - ETA: 15:02 - loss: 3.3163 - accuracy: 0.146 - ETA: 13:45 - loss: 3.3165 - accuracy: 0.146 - ETA: 12:28 - loss: 3.3160 - accuracy: 0.146 - ETA: 11:12 - loss: 3.3162 - accuracy: 0.146 - ETA: 9:56 - loss: 3.3167 - accuracy: 0.145 - ETA: 8:40 - loss: 3.3168 - accuracy: 0.14 - ETA: 7:25 - loss: 3.3169 - accuracy: 0.14 - ETA: 6:11 - loss: 3.3174 - accuracy: 0.14 - ETA: 4:57 - loss: 3.3172 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3166 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3169 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3168 - accuracy: 0.14 - ETA: 5s - loss: 3.3167 - accuracy: 0.1458 - 23860s 563ms/step - loss: 3.3167 - accuracy: 0.1458 - val_loss: 3.9064 - val_accuracy: 0.0204\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:41 - loss: 3.3881 - accuracy: 0.13 - ETA: 3:42 - loss: 3.2912 - accuracy: 0.16 - ETA: 3:36 - loss: 3.3636 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3293 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3009 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2909 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2589 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2659 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2544 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2520 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2476 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2540 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2355 - accuracy: 0.16 - ETA: 3:14 - loss: 3.2331 - accuracy: 0.16 - ETA: 3:12 - loss: 3.2412 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2476 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2503 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2526 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2478 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2468 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2542 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2587 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2620 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2572 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2511 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2496 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2471 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2418 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2467 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2470 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2512 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2582 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2657 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2663 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2691 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2683 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2646 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2637 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2662 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2670 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2689 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2677 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2708 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2695 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2736 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2719 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2754 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2740 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2754 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2751 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2703 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2702 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2703 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2713 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2704 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2711 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2739 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2733 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2730 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2718 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2712 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2672 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2693 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2714 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2726 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2729 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2748 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2755 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2759 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2743 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2757 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2787 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2772 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2786 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2788 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2804 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2829 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2845 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2845 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2854 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2854 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2861 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2864 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2847 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2842 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2859 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2882 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2877 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2879 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2891 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2875 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2912 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2967 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2974 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2967 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2985 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2971 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2973 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2976 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2973 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2990 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2996 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3003 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2999 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3007 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2992 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2993 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2996 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2993 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3000 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3015 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3032 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3038 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3034 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3045 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3051 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3058 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3054 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3048 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3032 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3027 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3039 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3031 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3039 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3051 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3054 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3060 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3075 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3081 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3061 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3062 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3053 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3053 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3040 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3039 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3035 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3030 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3032 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3031 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3042 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3041 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3049 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3057 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3055 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3060 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3073 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3081 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3089 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3092 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3093 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3085 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3077 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3087 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3077 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3073 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3065 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3058 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3052 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3058 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3061 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3059 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3057 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3057 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3059 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3057 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3059 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3054 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3054 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3069 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3075 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3081 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3079 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3075 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3082 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3083 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3076 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3071 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3069 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3071 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3074 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3075 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3073 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3071 - accuracy: 0.1473"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:25 - loss: 3.3073 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3066 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3066 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3054 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3054 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3038 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3038 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3040 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3039 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3038 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3037 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3042 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3037 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3030 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3040 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3053 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3055 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3051 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3049 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3049 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3055 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3065 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3055 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3062 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3063 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3051 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3049 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3055 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3047 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3036 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3030 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3037 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3029 - accuracy: 0.14 - ETA: 59s - loss: 3.3031 - accuracy: 0.1471 - ETA: 59s - loss: 3.3031 - accuracy: 0.147 - ETA: 58s - loss: 3.3024 - accuracy: 0.147 - ETA: 58s - loss: 3.3027 - accuracy: 0.147 - ETA: 57s - loss: 3.3021 - accuracy: 0.147 - ETA: 56s - loss: 3.3014 - accuracy: 0.147 - ETA: 56s - loss: 3.3013 - accuracy: 0.147 - ETA: 55s - loss: 3.3015 - accuracy: 0.147 - ETA: 55s - loss: 3.3016 - accuracy: 0.147 - ETA: 54s - loss: 3.3017 - accuracy: 0.147 - ETA: 53s - loss: 3.3013 - accuracy: 0.147 - ETA: 53s - loss: 3.3010 - accuracy: 0.147 - ETA: 52s - loss: 3.3018 - accuracy: 0.147 - ETA: 52s - loss: 3.3022 - accuracy: 0.147 - ETA: 51s - loss: 3.3025 - accuracy: 0.147 - ETA: 50s - loss: 3.3024 - accuracy: 0.147 - ETA: 50s - loss: 3.3020 - accuracy: 0.147 - ETA: 49s - loss: 3.3020 - accuracy: 0.147 - ETA: 49s - loss: 3.3018 - accuracy: 0.147 - ETA: 48s - loss: 3.3014 - accuracy: 0.147 - ETA: 47s - loss: 3.3012 - accuracy: 0.147 - ETA: 47s - loss: 3.3016 - accuracy: 0.147 - ETA: 46s - loss: 3.3013 - accuracy: 0.147 - ETA: 46s - loss: 3.3010 - accuracy: 0.147 - ETA: 45s - loss: 3.3008 - accuracy: 0.147 - ETA: 44s - loss: 3.3005 - accuracy: 0.147 - ETA: 44s - loss: 3.3012 - accuracy: 0.147 - ETA: 43s - loss: 3.3010 - accuracy: 0.147 - ETA: 43s - loss: 3.3010 - accuracy: 0.147 - ETA: 42s - loss: 3.3007 - accuracy: 0.147 - ETA: 42s - loss: 3.3005 - accuracy: 0.147 - ETA: 41s - loss: 3.3010 - accuracy: 0.147 - ETA: 40s - loss: 3.3001 - accuracy: 0.147 - ETA: 40s - loss: 3.2988 - accuracy: 0.147 - ETA: 39s - loss: 3.2984 - accuracy: 0.147 - ETA: 39s - loss: 3.2972 - accuracy: 0.147 - ETA: 38s - loss: 3.2979 - accuracy: 0.147 - ETA: 37s - loss: 3.2983 - accuracy: 0.147 - ETA: 37s - loss: 3.2993 - accuracy: 0.147 - ETA: 36s - loss: 3.2989 - accuracy: 0.147 - ETA: 36s - loss: 3.2991 - accuracy: 0.147 - ETA: 35s - loss: 3.2990 - accuracy: 0.147 - ETA: 34s - loss: 3.2992 - accuracy: 0.147 - ETA: 34s - loss: 3.2990 - accuracy: 0.147 - ETA: 33s - loss: 3.2986 - accuracy: 0.147 - ETA: 33s - loss: 3.2987 - accuracy: 0.147 - ETA: 32s - loss: 3.2987 - accuracy: 0.147 - ETA: 31s - loss: 3.2988 - accuracy: 0.147 - ETA: 31s - loss: 3.2991 - accuracy: 0.147 - ETA: 30s - loss: 3.2990 - accuracy: 0.147 - ETA: 30s - loss: 3.2994 - accuracy: 0.147 - ETA: 29s - loss: 3.2989 - accuracy: 0.147 - ETA: 28s - loss: 3.2986 - accuracy: 0.147 - ETA: 28s - loss: 3.2990 - accuracy: 0.146 - ETA: 27s - loss: 3.2987 - accuracy: 0.146 - ETA: 27s - loss: 3.2993 - accuracy: 0.146 - ETA: 26s - loss: 3.2994 - accuracy: 0.146 - ETA: 25s - loss: 3.2992 - accuracy: 0.146 - ETA: 25s - loss: 3.2991 - accuracy: 0.146 - ETA: 24s - loss: 3.2998 - accuracy: 0.146 - ETA: 24s - loss: 3.2997 - accuracy: 0.146 - ETA: 23s - loss: 3.2990 - accuracy: 0.146 - ETA: 22s - loss: 3.2986 - accuracy: 0.146 - ETA: 22s - loss: 3.2990 - accuracy: 0.146 - ETA: 21s - loss: 3.2988 - accuracy: 0.146 - ETA: 21s - loss: 3.2988 - accuracy: 0.146 - ETA: 20s - loss: 3.2985 - accuracy: 0.146 - ETA: 19s - loss: 3.2984 - accuracy: 0.146 - ETA: 19s - loss: 3.2982 - accuracy: 0.146 - ETA: 18s - loss: 3.2987 - accuracy: 0.146 - ETA: 18s - loss: 3.2983 - accuracy: 0.146 - ETA: 17s - loss: 3.2981 - accuracy: 0.146 - ETA: 16s - loss: 3.2975 - accuracy: 0.146 - ETA: 16s - loss: 3.2976 - accuracy: 0.146 - ETA: 15s - loss: 3.2965 - accuracy: 0.147 - ETA: 15s - loss: 3.2968 - accuracy: 0.146 - ETA: 14s - loss: 3.2963 - accuracy: 0.147 - ETA: 13s - loss: 3.2962 - accuracy: 0.147 - ETA: 13s - loss: 3.2962 - accuracy: 0.147 - ETA: 12s - loss: 3.2963 - accuracy: 0.146 - ETA: 12s - loss: 3.2964 - accuracy: 0.146 - ETA: 11s - loss: 3.2965 - accuracy: 0.146 - ETA: 10s - loss: 3.2968 - accuracy: 0.146 - ETA: 10s - loss: 3.2970 - accuracy: 0.146 - ETA: 9s - loss: 3.2966 - accuracy: 0.146 - ETA: 9s - loss: 3.2968 - accuracy: 0.14 - ETA: 8s - loss: 3.2972 - accuracy: 0.14 - ETA: 7s - loss: 3.2976 - accuracy: 0.14 - ETA: 7s - loss: 3.2977 - accuracy: 0.14 - ETA: 6s - loss: 3.2975 - accuracy: 0.14 - ETA: 6s - loss: 3.2979 - accuracy: 0.14 - ETA: 5s - loss: 3.2977 - accuracy: 0.14 - ETA: 4s - loss: 3.2977 - accuracy: 0.14 - ETA: 4s - loss: 3.2980 - accuracy: 0.14 - ETA: 3s - loss: 3.2974 - accuracy: 0.14 - ETA: 3s - loss: 3.2978 - accuracy: 0.14 - ETA: 2s - loss: 3.2975 - accuracy: 0.14 - ETA: 1s - loss: 3.2974 - accuracy: 0.14 - ETA: 1s - loss: 3.2973 - accuracy: 0.14 - ETA: 0s - loss: 3.2971 - accuracy: 0.14 - ETA: 0s - loss: 3.2969 - accuracy: 0.14 - 215s 5ms/step - loss: 3.2969 - accuracy: 0.1471 - val_loss: 3.9177 - val_accuracy: 0.0207\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:32 - loss: 3.2316 - accuracy: 0.16 - ETA: 3:23 - loss: 3.3422 - accuracy: 0.15 - ETA: 3:22 - loss: 3.3358 - accuracy: 0.15 - ETA: 3:21 - loss: 3.3406 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3572 - accuracy: 0.15 - ETA: 3:17 - loss: 3.3212 - accuracy: 0.15 - ETA: 3:16 - loss: 3.3414 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3140 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3005 - accuracy: 0.14 - ETA: 3:13 - loss: 3.2925 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3057 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3007 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3096 - accuracy: 0.13 - ETA: 3:23 - loss: 3.3208 - accuracy: 0.13 - ETA: 3:23 - loss: 3.3207 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3339 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3327 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3255 - accuracy: 0.13 - ETA: 3:26 - loss: 3.3215 - accuracy: 0.13 - ETA: 3:26 - loss: 3.3212 - accuracy: 0.13 - ETA: 3:24 - loss: 3.3177 - accuracy: 0.13 - ETA: 3:22 - loss: 3.3091 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3076 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3030 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3082 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3160 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3203 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3230 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3187 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3209 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3209 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3248 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3213 - accuracy: 0.13 - ETA: 3:14 - loss: 3.3148 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3111 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3088 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3129 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3120 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3116 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3135 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3120 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3078 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3082 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3113 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3127 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3147 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3119 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3132 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3114 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3120 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3104 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3123 - accuracy: 0.13 - ETA: 3:19 - loss: 3.3102 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3103 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3131 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3117 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3115 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3107 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3077 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3095 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3110 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3106 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3097 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3107 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3115 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3121 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3123 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3118 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3130 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3122 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3099 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3100 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3120 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3113 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3126 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3132 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3128 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3121 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3119 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3112 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3094 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3099 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3097 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3114 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3125 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3151 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3155 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3150 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3156 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3162 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3153 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3132 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3125 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3102 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3092 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3088 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3084 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3081 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3079 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3089 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3092 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3070 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3049 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3058 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3078 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3080 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3091 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3097 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3078 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3150 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3157 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3140 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3124 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3115 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3110 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3119 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3122 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3129 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3126 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3122 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3139 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3139 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3131 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3127 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3131 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3124 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3120 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3113 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3117 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3133 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3135 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3139 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3150 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3161 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3163 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3170 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3181 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3175 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3185 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3186 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3185 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3180 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3190 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3185 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3182 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3180 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3187 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3197 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3198 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3195 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3212 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3218 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3214 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3216 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3211 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3209 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3201 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3189 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3194 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3188 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3193 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3188 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3194 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3197 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3185 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3178 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3180 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3186 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3182 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3183 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3183 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3181 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3169 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3166 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3164 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3163 - accuracy: 0.1422"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:51 - loss: 3.3159 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3153 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3161 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3157 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3145 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3137 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3142 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3138 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3142 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3143 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3138 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3134 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3138 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3132 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3126 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3122 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3121 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3121 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3110 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3108 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3103 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3096 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3089 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3083 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3077 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3079 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3083 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3085 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3078 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3089 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3091 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3089 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3082 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3077 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3077 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3076 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3082 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3087 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3089 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3095 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3097 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3095 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3101 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3100 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3095 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3092 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3091 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3094 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3092 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3091 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3085 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3078 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3075 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3072 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3076 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3079 - accuracy: 0.14 - ETA: 59s - loss: 3.3078 - accuracy: 0.1441 - ETA: 59s - loss: 3.3074 - accuracy: 0.144 - ETA: 58s - loss: 3.3081 - accuracy: 0.144 - ETA: 57s - loss: 3.3081 - accuracy: 0.144 - ETA: 56s - loss: 3.3077 - accuracy: 0.144 - ETA: 55s - loss: 3.3074 - accuracy: 0.144 - ETA: 55s - loss: 3.3074 - accuracy: 0.144 - ETA: 54s - loss: 3.3072 - accuracy: 0.144 - ETA: 53s - loss: 3.3067 - accuracy: 0.144 - ETA: 52s - loss: 3.3072 - accuracy: 0.144 - ETA: 52s - loss: 3.3076 - accuracy: 0.144 - ETA: 51s - loss: 3.3075 - accuracy: 0.144 - ETA: 50s - loss: 3.3079 - accuracy: 0.144 - ETA: 49s - loss: 3.3082 - accuracy: 0.144 - ETA: 48s - loss: 3.3083 - accuracy: 0.144 - ETA: 48s - loss: 3.3083 - accuracy: 0.144 - ETA: 47s - loss: 3.3076 - accuracy: 0.144 - ETA: 46s - loss: 3.3075 - accuracy: 0.144 - ETA: 45s - loss: 3.3069 - accuracy: 0.144 - ETA: 45s - loss: 3.3066 - accuracy: 0.144 - ETA: 44s - loss: 3.3067 - accuracy: 0.144 - ETA: 43s - loss: 3.3066 - accuracy: 0.144 - ETA: 42s - loss: 3.3067 - accuracy: 0.144 - ETA: 41s - loss: 3.3065 - accuracy: 0.144 - ETA: 41s - loss: 3.3070 - accuracy: 0.144 - ETA: 40s - loss: 3.3065 - accuracy: 0.144 - ETA: 39s - loss: 3.3062 - accuracy: 0.145 - ETA: 38s - loss: 3.3060 - accuracy: 0.145 - ETA: 38s - loss: 3.3067 - accuracy: 0.144 - ETA: 37s - loss: 3.3070 - accuracy: 0.144 - ETA: 36s - loss: 3.3073 - accuracy: 0.144 - ETA: 35s - loss: 3.3078 - accuracy: 0.144 - ETA: 34s - loss: 3.3073 - accuracy: 0.144 - ETA: 34s - loss: 3.3078 - accuracy: 0.144 - ETA: 33s - loss: 3.3078 - accuracy: 0.144 - ETA: 32s - loss: 3.3081 - accuracy: 0.144 - ETA: 31s - loss: 3.3079 - accuracy: 0.144 - ETA: 31s - loss: 3.3074 - accuracy: 0.144 - ETA: 30s - loss: 3.3075 - accuracy: 0.144 - ETA: 29s - loss: 3.3072 - accuracy: 0.144 - ETA: 28s - loss: 3.3072 - accuracy: 0.144 - ETA: 28s - loss: 3.3071 - accuracy: 0.144 - ETA: 27s - loss: 3.3073 - accuracy: 0.144 - ETA: 26s - loss: 3.3065 - accuracy: 0.144 - ETA: 25s - loss: 3.3061 - accuracy: 0.144 - ETA: 24s - loss: 3.3062 - accuracy: 0.144 - ETA: 24s - loss: 3.3050 - accuracy: 0.144 - ETA: 23s - loss: 3.3044 - accuracy: 0.145 - ETA: 22s - loss: 3.3048 - accuracy: 0.145 - ETA: 21s - loss: 3.3041 - accuracy: 0.145 - ETA: 21s - loss: 3.3040 - accuracy: 0.145 - ETA: 20s - loss: 3.3036 - accuracy: 0.145 - ETA: 19s - loss: 3.3038 - accuracy: 0.145 - ETA: 18s - loss: 3.3041 - accuracy: 0.145 - ETA: 17s - loss: 3.3044 - accuracy: 0.145 - ETA: 17s - loss: 3.3044 - accuracy: 0.145 - ETA: 16s - loss: 3.3040 - accuracy: 0.145 - ETA: 15s - loss: 3.3038 - accuracy: 0.145 - ETA: 14s - loss: 3.3032 - accuracy: 0.145 - ETA: 13s - loss: 3.3030 - accuracy: 0.145 - ETA: 13s - loss: 3.3023 - accuracy: 0.145 - ETA: 12s - loss: 3.3016 - accuracy: 0.145 - ETA: 11s - loss: 3.3009 - accuracy: 0.146 - ETA: 10s - loss: 3.3012 - accuracy: 0.145 - ETA: 10s - loss: 3.3012 - accuracy: 0.146 - ETA: 9s - loss: 3.3011 - accuracy: 0.146 - ETA: 8s - loss: 3.3012 - accuracy: 0.14 - ETA: 7s - loss: 3.3009 - accuracy: 0.14 - ETA: 6s - loss: 3.3009 - accuracy: 0.14 - ETA: 6s - loss: 3.3014 - accuracy: 0.14 - ETA: 5s - loss: 3.3015 - accuracy: 0.14 - ETA: 4s - loss: 3.3017 - accuracy: 0.14 - ETA: 3s - loss: 3.3020 - accuracy: 0.14 - ETA: 3s - loss: 3.3018 - accuracy: 0.14 - ETA: 2s - loss: 3.3018 - accuracy: 0.14 - ETA: 1s - loss: 3.3018 - accuracy: 0.14 - ETA: 0s - loss: 3.3021 - accuracy: 0.14 - ETA: 0s - loss: 3.3025 - accuracy: 0.14 - 267s 6ms/step - loss: 3.3025 - accuracy: 0.1459 - val_loss: 3.9012 - val_accuracy: 0.0186\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:20 - loss: 3.3362 - accuracy: 0.14 - ETA: 3:10 - loss: 3.2097 - accuracy: 0.17 - ETA: 3:07 - loss: 3.2316 - accuracy: 0.16 - ETA: 3:06 - loss: 3.2463 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2503 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2631 - accuracy: 0.14 - ETA: 3:06 - loss: 3.2757 - accuracy: 0.14 - ETA: 3:06 - loss: 3.2974 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3085 - accuracy: 0.14 - ETA: 3:07 - loss: 3.2797 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2824 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2803 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2842 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2836 - accuracy: 0.15 - ETA: 3:02 - loss: 3.3005 - accuracy: 0.15 - ETA: 3:01 - loss: 3.3017 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2874 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2929 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2871 - accuracy: 0.15 - ETA: 3:03 - loss: 3.3040 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2933 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2873 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2794 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2873 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2871 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2871 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2888 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2888 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2931 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2868 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2865 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2835 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2924 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2923 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2938 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2938 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2936 - accuracy: 0.15 - ETA: 3:18 - loss: 3.3016 - accuracy: 0.15 - ETA: 3:18 - loss: 3.3021 - accuracy: 0.15 - ETA: 3:17 - loss: 3.3047 - accuracy: 0.15 - ETA: 3:16 - loss: 3.3007 - accuracy: 0.15 - ETA: 3:16 - loss: 3.3037 - accuracy: 0.15 - ETA: 3:16 - loss: 3.3061 - accuracy: 0.15 - ETA: 3:16 - loss: 3.3100 - accuracy: 0.15 - ETA: 3:16 - loss: 3.3044 - accuracy: 0.15 - ETA: 3:15 - loss: 3.3066 - accuracy: 0.15 - ETA: 3:15 - loss: 3.3066 - accuracy: 0.15 - ETA: 3:15 - loss: 3.3050 - accuracy: 0.15 - ETA: 3:15 - loss: 3.3003 - accuracy: 0.15 - ETA: 3:14 - loss: 3.3007 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2992 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2978 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2975 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2982 - accuracy: 0.15 - ETA: 3:11 - loss: 3.3008 - accuracy: 0.15 - ETA: 3:11 - loss: 3.3015 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2983 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2938 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2946 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2939 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2958 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2988 - accuracy: 0.15 - ETA: 3:06 - loss: 3.3018 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2987 - accuracy: 0.15 - ETA: 3:05 - loss: 3.3006 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2997 - accuracy: 0.15 - ETA: 3:05 - loss: 3.3005 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2990 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2968 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2977 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2979 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2996 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2966 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2960 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2977 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2981 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2968 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2956 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2962 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2964 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2951 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2940 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2928 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2916 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2933 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2944 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2940 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2964 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2967 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2966 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2951 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2940 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2945 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2919 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2929 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2939 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2931 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2933 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2928 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2925 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2909 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2920 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2926 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2924 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2920 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2911 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2904 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2898 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2908 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2895 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2888 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2889 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2887 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2887 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2873 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2875 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2870 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2868 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2851 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2857 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2853 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2870 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2854 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2849 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2853 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2854 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2841 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2844 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2849 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2863 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2858 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2861 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2851 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2857 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2860 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2845 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2863 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2864 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2851 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2841 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2834 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2843 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2834 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2837 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2846 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2848 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2855 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2847 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2845 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2834 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2827 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2824 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2821 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2819 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2810 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2799 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2812 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2815 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2821 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2798 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2794 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2787 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2782 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2791 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2783 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2777 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2771 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2770 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2773 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2770 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2767 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2770 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2765 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2767 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2756 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2750 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2740 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2743 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2736 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2738 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2739 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2730 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2718 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2724 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2718 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2710 - accuracy: 0.1557"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:46 - loss: 3.2703 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2697 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2697 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2688 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2683 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2691 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2687 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2686 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2686 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2687 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2681 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2682 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2683 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2678 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2679 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2678 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2675 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2682 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2672 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2676 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2684 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2692 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2690 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2691 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2696 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2695 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2698 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2689 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2693 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2702 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2703 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2712 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2712 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2710 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2712 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2721 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2722 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2728 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2724 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2718 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2722 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2716 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2713 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2719 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2717 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2716 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2718 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2719 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2720 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2718 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2735 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2732 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2723 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2723 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2721 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2720 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2723 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2723 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2713 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2718 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2722 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2721 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2720 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2728 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2721 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2722 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2728 - accuracy: 0.15 - ETA: 59s - loss: 3.2726 - accuracy: 0.1538 - ETA: 58s - loss: 3.2726 - accuracy: 0.153 - ETA: 58s - loss: 3.2731 - accuracy: 0.153 - ETA: 57s - loss: 3.2732 - accuracy: 0.153 - ETA: 56s - loss: 3.2735 - accuracy: 0.153 - ETA: 55s - loss: 3.2737 - accuracy: 0.153 - ETA: 55s - loss: 3.2742 - accuracy: 0.153 - ETA: 54s - loss: 3.2742 - accuracy: 0.153 - ETA: 53s - loss: 3.2742 - accuracy: 0.153 - ETA: 52s - loss: 3.2747 - accuracy: 0.153 - ETA: 52s - loss: 3.2746 - accuracy: 0.153 - ETA: 51s - loss: 3.2766 - accuracy: 0.153 - ETA: 50s - loss: 3.2769 - accuracy: 0.153 - ETA: 50s - loss: 3.2767 - accuracy: 0.153 - ETA: 49s - loss: 3.2766 - accuracy: 0.153 - ETA: 48s - loss: 3.2758 - accuracy: 0.153 - ETA: 47s - loss: 3.2752 - accuracy: 0.153 - ETA: 47s - loss: 3.2753 - accuracy: 0.153 - ETA: 46s - loss: 3.2751 - accuracy: 0.153 - ETA: 45s - loss: 3.2751 - accuracy: 0.153 - ETA: 44s - loss: 3.2748 - accuracy: 0.153 - ETA: 44s - loss: 3.2752 - accuracy: 0.153 - ETA: 43s - loss: 3.2749 - accuracy: 0.153 - ETA: 42s - loss: 3.2742 - accuracy: 0.153 - ETA: 41s - loss: 3.2746 - accuracy: 0.153 - ETA: 40s - loss: 3.2743 - accuracy: 0.153 - ETA: 40s - loss: 3.2747 - accuracy: 0.153 - ETA: 39s - loss: 3.2750 - accuracy: 0.153 - ETA: 38s - loss: 3.2744 - accuracy: 0.153 - ETA: 37s - loss: 3.2736 - accuracy: 0.153 - ETA: 37s - loss: 3.2732 - accuracy: 0.154 - ETA: 36s - loss: 3.2736 - accuracy: 0.153 - ETA: 35s - loss: 3.2737 - accuracy: 0.153 - ETA: 34s - loss: 3.2738 - accuracy: 0.153 - ETA: 34s - loss: 3.2743 - accuracy: 0.153 - ETA: 33s - loss: 3.2745 - accuracy: 0.153 - ETA: 32s - loss: 3.2745 - accuracy: 0.153 - ETA: 31s - loss: 3.2746 - accuracy: 0.153 - ETA: 30s - loss: 3.2751 - accuracy: 0.153 - ETA: 30s - loss: 3.2750 - accuracy: 0.153 - ETA: 29s - loss: 3.2748 - accuracy: 0.153 - ETA: 28s - loss: 3.2751 - accuracy: 0.153 - ETA: 27s - loss: 3.2747 - accuracy: 0.153 - ETA: 26s - loss: 3.2745 - accuracy: 0.153 - ETA: 26s - loss: 3.2745 - accuracy: 0.153 - ETA: 25s - loss: 3.2744 - accuracy: 0.153 - ETA: 24s - loss: 3.2747 - accuracy: 0.153 - ETA: 23s - loss: 3.2750 - accuracy: 0.153 - ETA: 23s - loss: 3.2750 - accuracy: 0.153 - ETA: 22s - loss: 3.2754 - accuracy: 0.153 - ETA: 21s - loss: 3.2753 - accuracy: 0.153 - ETA: 20s - loss: 3.2749 - accuracy: 0.153 - ETA: 19s - loss: 3.2757 - accuracy: 0.153 - ETA: 19s - loss: 3.2761 - accuracy: 0.153 - ETA: 18s - loss: 3.2759 - accuracy: 0.153 - ETA: 17s - loss: 3.2762 - accuracy: 0.153 - ETA: 16s - loss: 3.2760 - accuracy: 0.153 - ETA: 15s - loss: 3.2757 - accuracy: 0.153 - ETA: 15s - loss: 3.2759 - accuracy: 0.153 - ETA: 14s - loss: 3.2758 - accuracy: 0.153 - ETA: 13s - loss: 3.2759 - accuracy: 0.153 - ETA: 12s - loss: 3.2764 - accuracy: 0.153 - ETA: 11s - loss: 3.2759 - accuracy: 0.153 - ETA: 11s - loss: 3.2763 - accuracy: 0.152 - ETA: 10s - loss: 3.2767 - accuracy: 0.152 - ETA: 9s - loss: 3.2765 - accuracy: 0.152 - ETA: 8s - loss: 3.2762 - accuracy: 0.15 - ETA: 7s - loss: 3.2760 - accuracy: 0.15 - ETA: 7s - loss: 3.2755 - accuracy: 0.15 - ETA: 6s - loss: 3.2757 - accuracy: 0.15 - ETA: 5s - loss: 3.2755 - accuracy: 0.15 - ETA: 4s - loss: 3.2752 - accuracy: 0.15 - ETA: 4s - loss: 3.2749 - accuracy: 0.15 - ETA: 3s - loss: 3.2751 - accuracy: 0.15 - ETA: 2s - loss: 3.2753 - accuracy: 0.15 - ETA: 1s - loss: 3.2755 - accuracy: 0.15 - ETA: 0s - loss: 3.2755 - accuracy: 0.15 - ETA: 0s - loss: 3.2750 - accuracy: 0.15 - 277s 7ms/step - loss: 3.2751 - accuracy: 0.1531 - val_loss: 3.9007 - val_accuracy: 0.0157\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:04 - loss: 3.1530 - accuracy: 0.16 - ETA: 4:09 - loss: 3.1586 - accuracy: 0.16 - ETA: 4:08 - loss: 3.2552 - accuracy: 0.13 - ETA: 4:13 - loss: 3.2688 - accuracy: 0.13 - ETA: 4:14 - loss: 3.2608 - accuracy: 0.13 - ETA: 4:12 - loss: 3.2598 - accuracy: 0.13 - ETA: 4:10 - loss: 3.2778 - accuracy: 0.13 - ETA: 4:07 - loss: 3.2657 - accuracy: 0.13 - ETA: 4:05 - loss: 3.2623 - accuracy: 0.13 - ETA: 4:04 - loss: 3.2531 - accuracy: 0.13 - ETA: 4:03 - loss: 3.2519 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2340 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2309 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2446 - accuracy: 0.14 - ETA: 4:21 - loss: 3.2570 - accuracy: 0.14 - ETA: 4:38 - loss: 3.2508 - accuracy: 0.14 - ETA: 4:40 - loss: 3.2560 - accuracy: 0.14 - ETA: 4:38 - loss: 3.2500 - accuracy: 0.14 - ETA: 4:36 - loss: 3.2469 - accuracy: 0.14 - ETA: 4:33 - loss: 3.2461 - accuracy: 0.14 - ETA: 4:30 - loss: 3.2471 - accuracy: 0.14 - ETA: 4:27 - loss: 3.2421 - accuracy: 0.14 - ETA: 4:25 - loss: 3.2364 - accuracy: 0.15 - ETA: 4:22 - loss: 3.2381 - accuracy: 0.15 - ETA: 4:20 - loss: 3.2421 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2449 - accuracy: 0.14 - ETA: 4:16 - loss: 3.2456 - accuracy: 0.14 - ETA: 4:14 - loss: 3.2426 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2398 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2418 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2431 - accuracy: 0.14 - ETA: 4:09 - loss: 3.2492 - accuracy: 0.14 - ETA: 4:08 - loss: 3.2477 - accuracy: 0.15 - ETA: 4:07 - loss: 3.2507 - accuracy: 0.15 - ETA: 4:05 - loss: 3.2533 - accuracy: 0.15 - ETA: 4:03 - loss: 3.2512 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2536 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2558 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2535 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2582 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2583 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2543 - accuracy: 0.15 - ETA: 3:56 - loss: 3.2566 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2587 - accuracy: 0.15 - ETA: 3:54 - loss: 3.2551 - accuracy: 0.15 - ETA: 3:53 - loss: 3.2548 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2527 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2503 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2544 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2585 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2584 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2606 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2626 - accuracy: 0.14 - ETA: 3:48 - loss: 3.2615 - accuracy: 0.14 - ETA: 3:48 - loss: 3.2593 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2593 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2602 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2606 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2612 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2648 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2648 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2670 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2691 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2675 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2682 - accuracy: 0.14 - ETA: 3:35 - loss: 3.2696 - accuracy: 0.14 - ETA: 3:34 - loss: 3.2727 - accuracy: 0.14 - ETA: 3:33 - loss: 3.2709 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2701 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2723 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2733 - accuracy: 0.14 - ETA: 3:29 - loss: 3.2718 - accuracy: 0.14 - ETA: 3:28 - loss: 3.2724 - accuracy: 0.14 - ETA: 3:27 - loss: 3.2725 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2711 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2719 - accuracy: 0.14 - ETA: 3:25 - loss: 3.2705 - accuracy: 0.14 - ETA: 3:24 - loss: 3.2703 - accuracy: 0.14 - ETA: 3:23 - loss: 3.2710 - accuracy: 0.14 - ETA: 3:22 - loss: 3.2716 - accuracy: 0.14 - ETA: 3:21 - loss: 3.2703 - accuracy: 0.14 - ETA: 3:20 - loss: 3.2699 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2707 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2708 - accuracy: 0.14 - ETA: 3:17 - loss: 3.2721 - accuracy: 0.14 - ETA: 3:16 - loss: 3.2731 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2746 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2744 - accuracy: 0.14 - ETA: 3:14 - loss: 3.2745 - accuracy: 0.14 - ETA: 3:13 - loss: 3.2755 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2754 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2775 - accuracy: 0.14 - ETA: 3:10 - loss: 3.2757 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2766 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2773 - accuracy: 0.14 - ETA: 3:08 - loss: 3.2764 - accuracy: 0.14 - ETA: 3:07 - loss: 3.2760 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2769 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2756 - accuracy: 0.14 - ETA: 3:04 - loss: 3.2739 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2735 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2742 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2762 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2754 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2744 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2739 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2741 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2728 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2721 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2712 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2716 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2714 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2709 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2702 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2715 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2721 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2718 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2727 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2738 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2746 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2749 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2741 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2727 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2735 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2729 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2732 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2728 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2731 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2721 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2709 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2712 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2714 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2713 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2719 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2731 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2748 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2762 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2748 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2747 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2748 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2751 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2753 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2748 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2748 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2743 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2728 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2713 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2723 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2718 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2718 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2709 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2697 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2696 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2707 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2702 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2693 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2694 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2687 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2687 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2687 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2686 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2680 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2680 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2685 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2679 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2669 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2674 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2686 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2694 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2695 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2689 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2683 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2685 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2679 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2674 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2674 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2675 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2670 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2667 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2659 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2659 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2647 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2642 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2644 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2632 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2623 - accuracy: 0.1501"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:54 - loss: 3.2622 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2626 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2625 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2625 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2627 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2629 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2635 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2636 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2635 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2635 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2645 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2648 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2650 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2647 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2650 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2646 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2638 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2645 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2636 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2634 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2631 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2635 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2645 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2656 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2665 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2674 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2687 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2698 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2700 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2717 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2721 - accuracy: 0.14 - ETA: 1:29 - loss: 3.2720 - accuracy: 0.14 - ETA: 1:28 - loss: 3.2715 - accuracy: 0.14 - ETA: 1:27 - loss: 3.2718 - accuracy: 0.14 - ETA: 1:26 - loss: 3.2721 - accuracy: 0.14 - ETA: 1:25 - loss: 3.2714 - accuracy: 0.14 - ETA: 1:25 - loss: 3.2718 - accuracy: 0.14 - ETA: 1:24 - loss: 3.2726 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2724 - accuracy: 0.14 - ETA: 1:22 - loss: 3.2728 - accuracy: 0.14 - ETA: 1:21 - loss: 3.2729 - accuracy: 0.14 - ETA: 1:21 - loss: 3.2733 - accuracy: 0.14 - ETA: 1:20 - loss: 3.2741 - accuracy: 0.14 - ETA: 1:19 - loss: 3.2743 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2745 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2745 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2743 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2742 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2746 - accuracy: 0.14 - ETA: 1:14 - loss: 3.2750 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2751 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2752 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2747 - accuracy: 0.14 - ETA: 1:11 - loss: 3.2746 - accuracy: 0.14 - ETA: 1:10 - loss: 3.2755 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2757 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2751 - accuracy: 0.14 - ETA: 1:08 - loss: 3.2748 - accuracy: 0.14 - ETA: 1:07 - loss: 3.2743 - accuracy: 0.14 - ETA: 1:06 - loss: 3.2742 - accuracy: 0.14 - ETA: 1:05 - loss: 3.2740 - accuracy: 0.14 - ETA: 1:05 - loss: 3.2733 - accuracy: 0.14 - ETA: 1:04 - loss: 3.2735 - accuracy: 0.14 - ETA: 1:03 - loss: 3.2741 - accuracy: 0.14 - ETA: 1:02 - loss: 3.2747 - accuracy: 0.14 - ETA: 1:01 - loss: 3.2741 - accuracy: 0.14 - ETA: 1:01 - loss: 3.2749 - accuracy: 0.14 - ETA: 1:00 - loss: 3.2783 - accuracy: 0.14 - ETA: 59s - loss: 3.2784 - accuracy: 0.1493 - ETA: 58s - loss: 3.2780 - accuracy: 0.149 - ETA: 57s - loss: 3.2780 - accuracy: 0.149 - ETA: 57s - loss: 3.2783 - accuracy: 0.149 - ETA: 56s - loss: 3.2783 - accuracy: 0.149 - ETA: 55s - loss: 3.2779 - accuracy: 0.149 - ETA: 54s - loss: 3.2788 - accuracy: 0.149 - ETA: 53s - loss: 3.2788 - accuracy: 0.149 - ETA: 53s - loss: 3.2795 - accuracy: 0.148 - ETA: 52s - loss: 3.2801 - accuracy: 0.148 - ETA: 51s - loss: 3.2794 - accuracy: 0.148 - ETA: 51s - loss: 3.2798 - accuracy: 0.148 - ETA: 50s - loss: 3.2798 - accuracy: 0.148 - ETA: 49s - loss: 3.2802 - accuracy: 0.148 - ETA: 48s - loss: 3.2805 - accuracy: 0.148 - ETA: 47s - loss: 3.2809 - accuracy: 0.148 - ETA: 47s - loss: 3.2809 - accuracy: 0.147 - ETA: 46s - loss: 3.2813 - accuracy: 0.147 - ETA: 45s - loss: 3.2811 - accuracy: 0.148 - ETA: 44s - loss: 3.2809 - accuracy: 0.148 - ETA: 43s - loss: 3.2806 - accuracy: 0.148 - ETA: 43s - loss: 3.2801 - accuracy: 0.148 - ETA: 42s - loss: 3.2798 - accuracy: 0.148 - ETA: 41s - loss: 3.2795 - accuracy: 0.148 - ETA: 41s - loss: 3.2796 - accuracy: 0.148 - ETA: 40s - loss: 3.2801 - accuracy: 0.148 - ETA: 39s - loss: 3.2811 - accuracy: 0.148 - ETA: 38s - loss: 3.2823 - accuracy: 0.148 - ETA: 37s - loss: 3.2822 - accuracy: 0.148 - ETA: 37s - loss: 3.2818 - accuracy: 0.148 - ETA: 36s - loss: 3.2825 - accuracy: 0.148 - ETA: 35s - loss: 3.2826 - accuracy: 0.148 - ETA: 34s - loss: 3.2832 - accuracy: 0.148 - ETA: 33s - loss: 3.2839 - accuracy: 0.148 - ETA: 33s - loss: 3.2839 - accuracy: 0.148 - ETA: 32s - loss: 3.2841 - accuracy: 0.148 - ETA: 31s - loss: 3.2843 - accuracy: 0.148 - ETA: 30s - loss: 3.2849 - accuracy: 0.148 - ETA: 29s - loss: 3.2852 - accuracy: 0.148 - ETA: 29s - loss: 3.2858 - accuracy: 0.148 - ETA: 28s - loss: 3.2858 - accuracy: 0.148 - ETA: 27s - loss: 3.2857 - accuracy: 0.148 - ETA: 26s - loss: 3.2857 - accuracy: 0.148 - ETA: 26s - loss: 3.2860 - accuracy: 0.148 - ETA: 25s - loss: 3.2866 - accuracy: 0.148 - ETA: 24s - loss: 3.2867 - accuracy: 0.148 - ETA: 23s - loss: 3.2870 - accuracy: 0.148 - ETA: 22s - loss: 3.2869 - accuracy: 0.148 - ETA: 22s - loss: 3.2868 - accuracy: 0.148 - ETA: 21s - loss: 3.2866 - accuracy: 0.148 - ETA: 20s - loss: 3.2866 - accuracy: 0.148 - ETA: 19s - loss: 3.2868 - accuracy: 0.148 - ETA: 18s - loss: 3.2878 - accuracy: 0.148 - ETA: 18s - loss: 3.2880 - accuracy: 0.147 - ETA: 17s - loss: 3.2878 - accuracy: 0.148 - ETA: 16s - loss: 3.2880 - accuracy: 0.148 - ETA: 15s - loss: 3.2880 - accuracy: 0.148 - ETA: 15s - loss: 3.2883 - accuracy: 0.148 - ETA: 14s - loss: 3.2887 - accuracy: 0.148 - ETA: 13s - loss: 3.2889 - accuracy: 0.148 - ETA: 12s - loss: 3.2894 - accuracy: 0.148 - ETA: 11s - loss: 3.2890 - accuracy: 0.148 - ETA: 11s - loss: 3.2890 - accuracy: 0.148 - ETA: 10s - loss: 3.2884 - accuracy: 0.148 - ETA: 9s - loss: 3.2878 - accuracy: 0.148 - ETA: 8s - loss: 3.2885 - accuracy: 0.14 - ETA: 7s - loss: 3.2889 - accuracy: 0.14 - ETA: 7s - loss: 3.2885 - accuracy: 0.14 - ETA: 6s - loss: 3.2890 - accuracy: 0.14 - ETA: 5s - loss: 3.2889 - accuracy: 0.14 - ETA: 4s - loss: 3.2889 - accuracy: 0.14 - ETA: 3s - loss: 3.2888 - accuracy: 0.14 - ETA: 3s - loss: 3.2893 - accuracy: 0.14 - ETA: 2s - loss: 3.2894 - accuracy: 0.14 - ETA: 1s - loss: 3.2889 - accuracy: 0.14 - ETA: 0s - loss: 3.2891 - accuracy: 0.14 - ETA: 0s - loss: 3.2888 - accuracy: 0.14 - 276s 7ms/step - loss: 3.2887 - accuracy: 0.1480 - val_loss: 3.9673 - val_accuracy: 0.0198\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:20 - loss: 3.4107 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3507 - accuracy: 0.14 - ETA: 4:19 - loss: 3.2891 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2947 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2978 - accuracy: 0.15 - ETA: 4:12 - loss: 3.3022 - accuracy: 0.15 - ETA: 4:10 - loss: 3.3032 - accuracy: 0.15 - ETA: 4:10 - loss: 3.3013 - accuracy: 0.15 - ETA: 4:11 - loss: 3.3055 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3108 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3272 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3330 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3324 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3407 - accuracy: 0.13 - ETA: 4:04 - loss: 3.3453 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3461 - accuracy: 0.13 - ETA: 4:01 - loss: 3.3496 - accuracy: 0.13 - ETA: 3:59 - loss: 3.3590 - accuracy: 0.13 - ETA: 3:58 - loss: 3.3583 - accuracy: 0.13 - ETA: 3:57 - loss: 3.3607 - accuracy: 0.13 - ETA: 3:57 - loss: 3.3727 - accuracy: 0.13 - ETA: 3:55 - loss: 3.3781 - accuracy: 0.12 - ETA: 3:54 - loss: 3.3704 - accuracy: 0.13 - ETA: 3:53 - loss: 3.3664 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3577 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3523 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3523 - accuracy: 0.13 - ETA: 3:51 - loss: 3.3461 - accuracy: 0.13 - ETA: 3:51 - loss: 3.3465 - accuracy: 0.13 - ETA: 3:51 - loss: 3.3408 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3362 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3380 - accuracy: 0.13 - ETA: 3:50 - loss: 3.3377 - accuracy: 0.13 - ETA: 3:49 - loss: 3.3419 - accuracy: 0.13 - ETA: 3:48 - loss: 3.3414 - accuracy: 0.13 - ETA: 3:47 - loss: 3.3396 - accuracy: 0.13 - ETA: 3:46 - loss: 3.3369 - accuracy: 0.13 - ETA: 3:45 - loss: 3.3340 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3311 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3287 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3291 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3310 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3272 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3274 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3230 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3265 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3253 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3242 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3272 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3299 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3307 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3308 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3283 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3282 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3294 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3273 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3257 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3264 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3260 - accuracy: 0.14 - ETA: 3:36 - loss: 3.3260 - accuracy: 0.14 - ETA: 3:35 - loss: 3.3240 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3219 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3232 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3215 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3215 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3212 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3187 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3195 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3192 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3186 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3203 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3193 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3171 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3185 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3165 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3156 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3143 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3126 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3147 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3143 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3130 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3103 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3088 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3086 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3082 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3079 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3058 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3054 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3050 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3054 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3057 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3021 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3016 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3013 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3005 - accuracy: 0.14 - ETA: 3:05 - loss: 3.2991 - accuracy: 0.14 - ETA: 3:04 - loss: 3.2982 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2987 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2987 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2978 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2984 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2973 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2964 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2971 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2973 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2957 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2962 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2969 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2953 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2963 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2954 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2942 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2949 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2953 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2962 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2980 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2978 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2976 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2978 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2965 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2969 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2954 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2956 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2968 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2965 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2959 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2953 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2948 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2955 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2944 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2931 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2923 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2919 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2922 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2915 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2916 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2911 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2909 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2910 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2900 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2896 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2891 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2896 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2908 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2924 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2916 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2912 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2910 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2908 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2899 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2896 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2888 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2884 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2882 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2865 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2859 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2852 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2848 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2843 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2848 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2844 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2839 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2835 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2821 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2836 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2841 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2839 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2828 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2822 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2821 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2811 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2805 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2803 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2796 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2792 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2795 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2798 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2808 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2808 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2800 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2801 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2806 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2802 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2804 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2799 - accuracy: 0.1511"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:54 - loss: 3.2790 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2796 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2793 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2785 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2785 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2777 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2776 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2774 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2778 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2777 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2774 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2777 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2784 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2782 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2788 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2780 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2782 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2789 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2780 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2782 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2784 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2791 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2794 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2796 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2806 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2799 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2794 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2803 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2800 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2801 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2804 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2801 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2806 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2808 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2814 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2821 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2819 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2820 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2809 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2803 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2798 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2796 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2796 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2801 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2807 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2799 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2806 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2803 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2803 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2794 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2794 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2786 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2785 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2793 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2798 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2808 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2816 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2814 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2816 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2815 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2817 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2824 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2820 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2823 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2812 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2809 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2812 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2814 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2802 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2811 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2811 - accuracy: 0.15 - ETA: 59s - loss: 3.2811 - accuracy: 0.1509 - ETA: 59s - loss: 3.2811 - accuracy: 0.150 - ETA: 58s - loss: 3.2813 - accuracy: 0.150 - ETA: 57s - loss: 3.2809 - accuracy: 0.150 - ETA: 56s - loss: 3.2809 - accuracy: 0.150 - ETA: 55s - loss: 3.2806 - accuracy: 0.150 - ETA: 54s - loss: 3.2805 - accuracy: 0.150 - ETA: 54s - loss: 3.2809 - accuracy: 0.150 - ETA: 53s - loss: 3.2814 - accuracy: 0.150 - ETA: 52s - loss: 3.2822 - accuracy: 0.150 - ETA: 51s - loss: 3.2829 - accuracy: 0.150 - ETA: 50s - loss: 3.2829 - accuracy: 0.150 - ETA: 49s - loss: 3.2830 - accuracy: 0.150 - ETA: 49s - loss: 3.2824 - accuracy: 0.150 - ETA: 48s - loss: 3.2825 - accuracy: 0.150 - ETA: 47s - loss: 3.2824 - accuracy: 0.150 - ETA: 46s - loss: 3.2822 - accuracy: 0.150 - ETA: 45s - loss: 3.2824 - accuracy: 0.150 - ETA: 45s - loss: 3.2822 - accuracy: 0.150 - ETA: 44s - loss: 3.2823 - accuracy: 0.150 - ETA: 43s - loss: 3.2825 - accuracy: 0.150 - ETA: 42s - loss: 3.2821 - accuracy: 0.150 - ETA: 41s - loss: 3.2825 - accuracy: 0.150 - ETA: 40s - loss: 3.2822 - accuracy: 0.150 - ETA: 40s - loss: 3.2822 - accuracy: 0.150 - ETA: 39s - loss: 3.2824 - accuracy: 0.150 - ETA: 38s - loss: 3.2831 - accuracy: 0.150 - ETA: 37s - loss: 3.2830 - accuracy: 0.150 - ETA: 36s - loss: 3.2836 - accuracy: 0.150 - ETA: 36s - loss: 3.2834 - accuracy: 0.150 - ETA: 35s - loss: 3.2832 - accuracy: 0.150 - ETA: 34s - loss: 3.2826 - accuracy: 0.150 - ETA: 33s - loss: 3.2825 - accuracy: 0.150 - ETA: 32s - loss: 3.2827 - accuracy: 0.150 - ETA: 31s - loss: 3.2828 - accuracy: 0.150 - ETA: 31s - loss: 3.2826 - accuracy: 0.150 - ETA: 30s - loss: 3.2828 - accuracy: 0.150 - ETA: 29s - loss: 3.2822 - accuracy: 0.150 - ETA: 28s - loss: 3.2826 - accuracy: 0.150 - ETA: 27s - loss: 3.2829 - accuracy: 0.150 - ETA: 27s - loss: 3.2829 - accuracy: 0.150 - ETA: 26s - loss: 3.2827 - accuracy: 0.150 - ETA: 25s - loss: 3.2826 - accuracy: 0.150 - ETA: 24s - loss: 3.2826 - accuracy: 0.149 - ETA: 23s - loss: 3.2828 - accuracy: 0.150 - ETA: 22s - loss: 3.2831 - accuracy: 0.149 - ETA: 22s - loss: 3.2828 - accuracy: 0.150 - ETA: 21s - loss: 3.2830 - accuracy: 0.150 - ETA: 20s - loss: 3.2828 - accuracy: 0.150 - ETA: 19s - loss: 3.2831 - accuracy: 0.150 - ETA: 18s - loss: 3.2837 - accuracy: 0.149 - ETA: 18s - loss: 3.2833 - accuracy: 0.149 - ETA: 17s - loss: 3.2833 - accuracy: 0.149 - ETA: 16s - loss: 3.2828 - accuracy: 0.149 - ETA: 15s - loss: 3.2824 - accuracy: 0.150 - ETA: 14s - loss: 3.2820 - accuracy: 0.150 - ETA: 13s - loss: 3.2817 - accuracy: 0.150 - ETA: 13s - loss: 3.2813 - accuracy: 0.150 - ETA: 12s - loss: 3.2814 - accuracy: 0.150 - ETA: 11s - loss: 3.2813 - accuracy: 0.150 - ETA: 10s - loss: 3.2815 - accuracy: 0.150 - ETA: 9s - loss: 3.2813 - accuracy: 0.150 - ETA: 9s - loss: 3.2812 - accuracy: 0.15 - ETA: 8s - loss: 3.2814 - accuracy: 0.15 - ETA: 7s - loss: 3.2814 - accuracy: 0.15 - ETA: 6s - loss: 3.2811 - accuracy: 0.15 - ETA: 5s - loss: 3.2810 - accuracy: 0.15 - ETA: 4s - loss: 3.2810 - accuracy: 0.15 - ETA: 4s - loss: 3.2810 - accuracy: 0.15 - ETA: 3s - loss: 3.2806 - accuracy: 0.15 - ETA: 2s - loss: 3.2811 - accuracy: 0.15 - ETA: 1s - loss: 3.2812 - accuracy: 0.15 - ETA: 0s - loss: 3.2812 - accuracy: 0.15 - ETA: 0s - loss: 3.2809 - accuracy: 0.15 - 285s 7ms/step - loss: 3.2810 - accuracy: 0.1503 - val_loss: 3.9732 - val_accuracy: 0.0151\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:29 - loss: 3.3793 - accuracy: 0.10 - ETA: 4:16 - loss: 3.3655 - accuracy: 0.10 - ETA: 4:10 - loss: 3.3494 - accuracy: 0.11 - ETA: 4:08 - loss: 3.3278 - accuracy: 0.12 - ETA: 4:07 - loss: 3.3031 - accuracy: 0.13 - ETA: 4:09 - loss: 3.3122 - accuracy: 0.13 - ETA: 4:10 - loss: 3.2930 - accuracy: 0.13 - ETA: 4:08 - loss: 3.2727 - accuracy: 0.13 - ETA: 4:06 - loss: 3.2781 - accuracy: 0.14 - ETA: 4:05 - loss: 3.2688 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2849 - accuracy: 0.14 - ETA: 4:05 - loss: 3.2756 - accuracy: 0.14 - ETA: 4:06 - loss: 3.2858 - accuracy: 0.14 - ETA: 4:06 - loss: 3.2708 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2733 - accuracy: 0.14 - ETA: 4:03 - loss: 3.2725 - accuracy: 0.14 - ETA: 4:02 - loss: 3.2570 - accuracy: 0.15 - ETA: 4:02 - loss: 3.2647 - accuracy: 0.15 - ETA: 4:01 - loss: 3.2690 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2693 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2778 - accuracy: 0.15 - ETA: 3:58 - loss: 3.2812 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2756 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2740 - accuracy: 0.15 - ETA: 3:54 - loss: 3.2719 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2776 - accuracy: 0.15 - ETA: 3:52 - loss: 3.2709 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2750 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2744 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2790 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2795 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2802 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2867 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2919 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2955 - accuracy: 0.15 - ETA: 3:46 - loss: 3.3005 - accuracy: 0.15 - ETA: 3:45 - loss: 3.3054 - accuracy: 0.15 - ETA: 3:44 - loss: 3.3054 - accuracy: 0.15 - ETA: 3:43 - loss: 3.3046 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3075 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3090 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3082 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3034 - accuracy: 0.15 - ETA: 3:40 - loss: 3.3037 - accuracy: 0.15 - ETA: 3:39 - loss: 3.3031 - accuracy: 0.15 - ETA: 3:38 - loss: 3.3056 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3022 - accuracy: 0.15 - ETA: 3:36 - loss: 3.3019 - accuracy: 0.15 - ETA: 3:35 - loss: 3.3036 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3002 - accuracy: 0.14 - ETA: 3:33 - loss: 3.2994 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3023 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3044 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3059 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3064 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3061 - accuracy: 0.14 - ETA: 3:29 - loss: 3.3066 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3086 - accuracy: 0.14 - ETA: 3:28 - loss: 3.3102 - accuracy: 0.14 - ETA: 3:27 - loss: 3.3118 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3096 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3094 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3086 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3076 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3063 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3105 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3099 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3113 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3095 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3082 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3094 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3096 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3069 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3045 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3025 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3029 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3037 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3042 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3052 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3048 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3029 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3034 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3053 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3072 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3078 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3071 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3050 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3036 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3008 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2999 - accuracy: 0.15 - ETA: 3:04 - loss: 3.3014 - accuracy: 0.15 - ETA: 3:03 - loss: 3.3012 - accuracy: 0.15 - ETA: 3:02 - loss: 3.3018 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2991 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2985 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2991 - accuracy: 0.15 - ETA: 2:59 - loss: 3.3012 - accuracy: 0.15 - ETA: 2:59 - loss: 3.3011 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3019 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3014 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3014 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3023 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3004 - accuracy: 0.15 - ETA: 2:54 - loss: 3.3010 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3014 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2997 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2973 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2964 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2974 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2976 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2985 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2996 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2988 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2986 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2986 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2987 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3012 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3019 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3028 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3030 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3024 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3031 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3021 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3019 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3023 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3024 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3011 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3000 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3007 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3004 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3009 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3016 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3015 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3021 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3028 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3024 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3021 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3016 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3019 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3021 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3019 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3026 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3018 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3018 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3019 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3024 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3017 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3020 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3022 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3015 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3019 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3010 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3006 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2996 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2987 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2997 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2995 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2987 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2984 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2979 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2985 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2977 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2980 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2973 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2968 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2977 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2968 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2960 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2947 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2959 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2959 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2954 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2956 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2950 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2951 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2954 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2959 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2968 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2967 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2945 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2946 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2938 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2932 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2932 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2930 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2935 - accuracy: 0.1498"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:53 - loss: 3.2929 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2925 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2927 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2940 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2941 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2936 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2932 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2933 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2928 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2928 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2933 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2932 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2940 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2945 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2947 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2944 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2949 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2949 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2939 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2934 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2936 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2940 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2938 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2949 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2939 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2936 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2934 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2937 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2937 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2943 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2935 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2938 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2945 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2946 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2936 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2936 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2942 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2939 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2942 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2943 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2937 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2939 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2936 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2930 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2923 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2920 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2911 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2917 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2922 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2917 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2915 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2913 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2906 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2902 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2900 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2910 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2913 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2905 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2908 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2902 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2897 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2896 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2898 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2900 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2898 - accuracy: 0.15 - ETA: 59s - loss: 3.2899 - accuracy: 0.1518 - ETA: 58s - loss: 3.2899 - accuracy: 0.151 - ETA: 57s - loss: 3.2900 - accuracy: 0.151 - ETA: 56s - loss: 3.2901 - accuracy: 0.151 - ETA: 56s - loss: 3.2901 - accuracy: 0.151 - ETA: 55s - loss: 3.2900 - accuracy: 0.151 - ETA: 54s - loss: 3.2902 - accuracy: 0.151 - ETA: 53s - loss: 3.2899 - accuracy: 0.151 - ETA: 52s - loss: 3.2903 - accuracy: 0.151 - ETA: 52s - loss: 3.2902 - accuracy: 0.151 - ETA: 51s - loss: 3.2901 - accuracy: 0.151 - ETA: 50s - loss: 3.2899 - accuracy: 0.151 - ETA: 49s - loss: 3.2906 - accuracy: 0.151 - ETA: 48s - loss: 3.2902 - accuracy: 0.151 - ETA: 48s - loss: 3.2900 - accuracy: 0.151 - ETA: 47s - loss: 3.2899 - accuracy: 0.151 - ETA: 46s - loss: 3.2901 - accuracy: 0.151 - ETA: 45s - loss: 3.2908 - accuracy: 0.151 - ETA: 44s - loss: 3.2905 - accuracy: 0.151 - ETA: 44s - loss: 3.2906 - accuracy: 0.151 - ETA: 43s - loss: 3.2906 - accuracy: 0.151 - ETA: 42s - loss: 3.2912 - accuracy: 0.150 - ETA: 41s - loss: 3.2908 - accuracy: 0.151 - ETA: 40s - loss: 3.2911 - accuracy: 0.151 - ETA: 40s - loss: 3.2915 - accuracy: 0.150 - ETA: 39s - loss: 3.2910 - accuracy: 0.151 - ETA: 38s - loss: 3.2905 - accuracy: 0.151 - ETA: 37s - loss: 3.2904 - accuracy: 0.151 - ETA: 36s - loss: 3.2904 - accuracy: 0.151 - ETA: 36s - loss: 3.2904 - accuracy: 0.151 - ETA: 35s - loss: 3.2906 - accuracy: 0.151 - ETA: 34s - loss: 3.2912 - accuracy: 0.151 - ETA: 33s - loss: 3.2917 - accuracy: 0.151 - ETA: 32s - loss: 3.2914 - accuracy: 0.151 - ETA: 32s - loss: 3.2917 - accuracy: 0.151 - ETA: 31s - loss: 3.2919 - accuracy: 0.150 - ETA: 30s - loss: 3.2921 - accuracy: 0.150 - ETA: 29s - loss: 3.2922 - accuracy: 0.150 - ETA: 29s - loss: 3.2917 - accuracy: 0.150 - ETA: 28s - loss: 3.2920 - accuracy: 0.150 - ETA: 27s - loss: 3.2920 - accuracy: 0.150 - ETA: 26s - loss: 3.2922 - accuracy: 0.150 - ETA: 25s - loss: 3.2918 - accuracy: 0.150 - ETA: 25s - loss: 3.2917 - accuracy: 0.150 - ETA: 24s - loss: 3.2914 - accuracy: 0.150 - ETA: 23s - loss: 3.2907 - accuracy: 0.151 - ETA: 22s - loss: 3.2908 - accuracy: 0.150 - ETA: 21s - loss: 3.2915 - accuracy: 0.150 - ETA: 21s - loss: 3.2915 - accuracy: 0.150 - ETA: 20s - loss: 3.2914 - accuracy: 0.150 - ETA: 19s - loss: 3.2916 - accuracy: 0.150 - ETA: 18s - loss: 3.2913 - accuracy: 0.150 - ETA: 18s - loss: 3.2915 - accuracy: 0.150 - ETA: 17s - loss: 3.2912 - accuracy: 0.150 - ETA: 16s - loss: 3.2912 - accuracy: 0.150 - ETA: 15s - loss: 3.2912 - accuracy: 0.150 - ETA: 14s - loss: 3.2911 - accuracy: 0.150 - ETA: 14s - loss: 3.2913 - accuracy: 0.150 - ETA: 13s - loss: 3.2917 - accuracy: 0.150 - ETA: 12s - loss: 3.2920 - accuracy: 0.150 - ETA: 11s - loss: 3.2921 - accuracy: 0.150 - ETA: 10s - loss: 3.2922 - accuracy: 0.150 - ETA: 10s - loss: 3.2928 - accuracy: 0.150 - ETA: 9s - loss: 3.2929 - accuracy: 0.150 - ETA: 8s - loss: 3.2927 - accuracy: 0.15 - ETA: 7s - loss: 3.2928 - accuracy: 0.15 - ETA: 7s - loss: 3.2931 - accuracy: 0.15 - ETA: 6s - loss: 3.2926 - accuracy: 0.15 - ETA: 5s - loss: 3.2927 - accuracy: 0.15 - ETA: 4s - loss: 3.2931 - accuracy: 0.15 - ETA: 3s - loss: 3.2935 - accuracy: 0.15 - ETA: 3s - loss: 3.2934 - accuracy: 0.15 - ETA: 2s - loss: 3.2938 - accuracy: 0.14 - ETA: 1s - loss: 3.2938 - accuracy: 0.14 - ETA: 0s - loss: 3.2938 - accuracy: 0.14 - ETA: 0s - loss: 3.2935 - accuracy: 0.14 - 273s 6ms/step - loss: 3.2939 - accuracy: 0.1498 - val_loss: 3.8880 - val_accuracy: 0.0139\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:09 - loss: 3.2302 - accuracy: 0.17 - ETA: 4:00 - loss: 3.1981 - accuracy: 0.19 - ETA: 3:59 - loss: 3.2461 - accuracy: 0.16 - ETA: 3:59 - loss: 3.2338 - accuracy: 0.16 - ETA: 3:59 - loss: 3.2470 - accuracy: 0.16 - ETA: 3:59 - loss: 3.2329 - accuracy: 0.17 - ETA: 4:39 - loss: 3.2299 - accuracy: 0.17 - ETA: 4:35 - loss: 3.2354 - accuracy: 0.17 - ETA: 4:33 - loss: 3.2648 - accuracy: 0.16 - ETA: 4:32 - loss: 3.2647 - accuracy: 0.16 - ETA: 4:29 - loss: 3.2727 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2814 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2820 - accuracy: 0.15 - ETA: 4:20 - loss: 3.2831 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2857 - accuracy: 0.15 - ETA: 4:15 - loss: 3.2808 - accuracy: 0.15 - ETA: 4:13 - loss: 3.2827 - accuracy: 0.15 - ETA: 4:11 - loss: 3.2890 - accuracy: 0.15 - ETA: 4:08 - loss: 3.2953 - accuracy: 0.15 - ETA: 4:06 - loss: 3.3000 - accuracy: 0.15 - ETA: 4:04 - loss: 3.2986 - accuracy: 0.15 - ETA: 4:03 - loss: 3.3056 - accuracy: 0.15 - ETA: 4:01 - loss: 3.3131 - accuracy: 0.15 - ETA: 4:00 - loss: 3.3157 - accuracy: 0.15 - ETA: 3:59 - loss: 3.3137 - accuracy: 0.15 - ETA: 3:57 - loss: 3.3180 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3164 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3127 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3078 - accuracy: 0.15 - ETA: 3:52 - loss: 3.3115 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3071 - accuracy: 0.15 - ETA: 3:50 - loss: 3.3101 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3137 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3113 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3070 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3047 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3006 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3000 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3049 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3056 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3061 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3070 - accuracy: 0.14 - ETA: 3:40 - loss: 3.3055 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3039 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3008 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2989 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2983 - accuracy: 0.14 - ETA: 3:35 - loss: 3.2985 - accuracy: 0.15 - ETA: 3:34 - loss: 3.2977 - accuracy: 0.14 - ETA: 3:33 - loss: 3.2988 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2976 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2956 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2916 - accuracy: 0.15 - ETA: 3:30 - loss: 3.2872 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2881 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2904 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2907 - accuracy: 0.15 - ETA: 3:27 - loss: 3.2924 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2933 - accuracy: 0.15 - ETA: 3:25 - loss: 3.2934 - accuracy: 0.15 - ETA: 3:24 - loss: 3.2957 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2961 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2955 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2910 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2914 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2918 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2898 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2884 - accuracy: 0.15 - ETA: 3:17 - loss: 3.2901 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2908 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2912 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2919 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2920 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2920 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2913 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2898 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2896 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2874 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2851 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2840 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2833 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2825 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2826 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2833 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2824 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2817 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2820 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2843 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2857 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2867 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2896 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2901 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2913 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2904 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2887 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2868 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2878 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2869 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2870 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2889 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2859 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2860 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2863 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2865 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2866 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2859 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2870 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2857 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2850 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2836 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2828 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2831 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2817 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2824 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2818 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2827 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2806 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2805 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2807 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2813 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2821 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2824 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2833 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2865 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2877 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2889 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2896 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2911 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2930 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2929 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2925 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2916 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2908 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2903 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2912 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2909 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2914 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2913 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2909 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2918 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2907 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2900 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2896 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2888 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2884 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2890 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2889 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2891 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2901 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2903 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2899 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2902 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2903 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2903 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2916 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2911 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2910 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2907 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2911 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2905 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2921 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2905 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2897 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2912 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2920 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2926 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2932 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2921 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2918 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2919 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2926 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2925 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2923 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2918 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2923 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2920 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2916 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2923 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2921 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2922 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2916 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2911 - accuracy: 0.1538"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:38 - loss: 3.2907 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2904 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2902 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2899 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2893 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2890 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2889 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2881 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2882 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2880 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2887 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2890 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2885 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2884 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2880 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2881 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2876 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2879 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2876 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2880 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2871 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2870 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2862 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2857 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2856 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2856 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2861 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2867 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2874 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2866 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2863 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2866 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2865 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2859 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2866 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2867 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2873 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2873 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2876 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2873 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2873 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2869 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2869 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2866 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2862 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2863 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2860 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2864 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2866 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2857 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2861 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2856 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2846 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2840 - accuracy: 0.15 - ETA: 59s - loss: 3.2839 - accuracy: 0.1544 - ETA: 59s - loss: 3.2835 - accuracy: 0.154 - ETA: 58s - loss: 3.2830 - accuracy: 0.154 - ETA: 57s - loss: 3.2833 - accuracy: 0.154 - ETA: 56s - loss: 3.2836 - accuracy: 0.154 - ETA: 56s - loss: 3.2834 - accuracy: 0.154 - ETA: 55s - loss: 3.2833 - accuracy: 0.154 - ETA: 54s - loss: 3.2829 - accuracy: 0.154 - ETA: 54s - loss: 3.2825 - accuracy: 0.154 - ETA: 53s - loss: 3.2822 - accuracy: 0.153 - ETA: 52s - loss: 3.2825 - accuracy: 0.153 - ETA: 52s - loss: 3.2820 - accuracy: 0.153 - ETA: 51s - loss: 3.2814 - accuracy: 0.154 - ETA: 50s - loss: 3.2821 - accuracy: 0.153 - ETA: 50s - loss: 3.2819 - accuracy: 0.153 - ETA: 49s - loss: 3.2819 - accuracy: 0.153 - ETA: 48s - loss: 3.2820 - accuracy: 0.153 - ETA: 48s - loss: 3.2823 - accuracy: 0.153 - ETA: 47s - loss: 3.2831 - accuracy: 0.153 - ETA: 46s - loss: 3.2827 - accuracy: 0.153 - ETA: 45s - loss: 3.2825 - accuracy: 0.154 - ETA: 45s - loss: 3.2824 - accuracy: 0.154 - ETA: 44s - loss: 3.2813 - accuracy: 0.154 - ETA: 43s - loss: 3.2810 - accuracy: 0.154 - ETA: 43s - loss: 3.2807 - accuracy: 0.154 - ETA: 42s - loss: 3.2811 - accuracy: 0.153 - ETA: 41s - loss: 3.2812 - accuracy: 0.154 - ETA: 41s - loss: 3.2821 - accuracy: 0.153 - ETA: 40s - loss: 3.2821 - accuracy: 0.153 - ETA: 39s - loss: 3.2826 - accuracy: 0.153 - ETA: 39s - loss: 3.2828 - accuracy: 0.153 - ETA: 38s - loss: 3.2829 - accuracy: 0.153 - ETA: 37s - loss: 3.2827 - accuracy: 0.153 - ETA: 37s - loss: 3.2831 - accuracy: 0.153 - ETA: 36s - loss: 3.2825 - accuracy: 0.153 - ETA: 35s - loss: 3.2825 - accuracy: 0.153 - ETA: 35s - loss: 3.2824 - accuracy: 0.153 - ETA: 34s - loss: 3.2826 - accuracy: 0.153 - ETA: 33s - loss: 3.2828 - accuracy: 0.153 - ETA: 33s - loss: 3.2834 - accuracy: 0.153 - ETA: 32s - loss: 3.2835 - accuracy: 0.153 - ETA: 31s - loss: 3.2827 - accuracy: 0.153 - ETA: 31s - loss: 3.2825 - accuracy: 0.153 - ETA: 30s - loss: 3.2829 - accuracy: 0.153 - ETA: 29s - loss: 3.2836 - accuracy: 0.152 - ETA: 29s - loss: 3.2839 - accuracy: 0.152 - ETA: 28s - loss: 3.2842 - accuracy: 0.152 - ETA: 27s - loss: 3.2846 - accuracy: 0.152 - ETA: 27s - loss: 3.2843 - accuracy: 0.152 - ETA: 26s - loss: 3.2848 - accuracy: 0.152 - ETA: 25s - loss: 3.2845 - accuracy: 0.152 - ETA: 25s - loss: 3.2846 - accuracy: 0.152 - ETA: 24s - loss: 3.2853 - accuracy: 0.152 - ETA: 23s - loss: 3.2852 - accuracy: 0.153 - ETA: 23s - loss: 3.2857 - accuracy: 0.152 - ETA: 22s - loss: 3.2865 - accuracy: 0.152 - ETA: 22s - loss: 3.2873 - accuracy: 0.152 - ETA: 21s - loss: 3.2877 - accuracy: 0.152 - ETA: 20s - loss: 3.2881 - accuracy: 0.152 - ETA: 20s - loss: 3.2884 - accuracy: 0.152 - ETA: 19s - loss: 3.2882 - accuracy: 0.152 - ETA: 18s - loss: 3.2886 - accuracy: 0.152 - ETA: 18s - loss: 3.2892 - accuracy: 0.152 - ETA: 17s - loss: 3.2897 - accuracy: 0.152 - ETA: 16s - loss: 3.2904 - accuracy: 0.152 - ETA: 16s - loss: 3.2910 - accuracy: 0.151 - ETA: 15s - loss: 3.2916 - accuracy: 0.151 - ETA: 14s - loss: 3.2913 - accuracy: 0.151 - ETA: 14s - loss: 3.2915 - accuracy: 0.151 - ETA: 13s - loss: 3.2919 - accuracy: 0.151 - ETA: 12s - loss: 3.2919 - accuracy: 0.151 - ETA: 12s - loss: 3.2921 - accuracy: 0.151 - ETA: 11s - loss: 3.2921 - accuracy: 0.151 - ETA: 10s - loss: 3.2924 - accuracy: 0.151 - ETA: 10s - loss: 3.2926 - accuracy: 0.151 - ETA: 9s - loss: 3.2935 - accuracy: 0.151 - ETA: 9s - loss: 3.2939 - accuracy: 0.15 - ETA: 8s - loss: 3.2939 - accuracy: 0.15 - ETA: 7s - loss: 3.2939 - accuracy: 0.15 - ETA: 7s - loss: 3.2944 - accuracy: 0.15 - ETA: 6s - loss: 3.2950 - accuracy: 0.15 - ETA: 5s - loss: 3.2952 - accuracy: 0.15 - ETA: 5s - loss: 3.2955 - accuracy: 0.15 - ETA: 4s - loss: 3.2959 - accuracy: 0.15 - ETA: 3s - loss: 3.2958 - accuracy: 0.15 - ETA: 3s - loss: 3.2960 - accuracy: 0.15 - ETA: 2s - loss: 3.2955 - accuracy: 0.15 - ETA: 1s - loss: 3.2960 - accuracy: 0.15 - ETA: 1s - loss: 3.2957 - accuracy: 0.15 - ETA: 0s - loss: 3.2955 - accuracy: 0.15 - ETA: 0s - loss: 3.2953 - accuracy: 0.15 - 224s 5ms/step - loss: 3.2954 - accuracy: 0.1506 - val_loss: 3.9152 - val_accuracy: 0.0137\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:17 - loss: 3.3446 - accuracy: 0.11 - ETA: 3:08 - loss: 3.4221 - accuracy: 0.10 - ETA: 3:06 - loss: 3.3837 - accuracy: 0.12 - ETA: 3:08 - loss: 3.3609 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3317 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3421 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3508 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3552 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3595 - accuracy: 0.12 - ETA: 3:01 - loss: 3.3524 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3427 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3278 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3238 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3300 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3233 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3217 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3160 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3152 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3261 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3329 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3190 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3215 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3215 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3181 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3255 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3251 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3188 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3202 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3148 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3184 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3139 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3123 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3105 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3048 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3039 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3171 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3290 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3361 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3356 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3362 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3349 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3351 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3279 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3317 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3270 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3266 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3284 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3283 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3303 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3293 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3308 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3328 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3347 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3344 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3353 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3362 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3403 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3407 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3436 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3449 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3477 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3480 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3480 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3482 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3459 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3439 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3415 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3450 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3437 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3446 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3453 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3446 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3471 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3487 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3470 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3470 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3448 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3466 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3473 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3475 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3498 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3491 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3481 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3467 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3481 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3477 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3500 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3490 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3497 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3496 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3493 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3508 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3518 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3520 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3512 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3501 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3501 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3505 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3518 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3512 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3523 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3522 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3503 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3517 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3523 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3524 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3522 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3532 - accuracy: 0.13 - ETA: 2:04 - loss: 3.3530 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3524 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3516 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3521 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3528 - accuracy: 0.13 - ETA: 2:01 - loss: 3.3528 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3542 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3554 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3547 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3557 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3563 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3569 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3564 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3573 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3568 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3547 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3551 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3550 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3551 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3567 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3576 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3576 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3578 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3586 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3600 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3600 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3617 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3624 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3614 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3619 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3633 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3646 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3648 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3636 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3631 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3639 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3640 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3632 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3633 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3632 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3633 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3631 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3635 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3625 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3619 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3618 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3618 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3622 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3621 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3619 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3607 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3605 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3614 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3617 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3609 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3600 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3595 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3590 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3600 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3609 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3612 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3605 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3601 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3607 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3608 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3617 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3610 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3606 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3603 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3591 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3589 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3586 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3579 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3575 - accuracy: 0.1398"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:22 - loss: 3.3574 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3568 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3573 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3572 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3563 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3562 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3564 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3562 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3562 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3566 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3573 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3564 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3554 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3549 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3538 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3533 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3533 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3520 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3524 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3522 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3518 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3516 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3510 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3511 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3507 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3494 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3492 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3490 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3483 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3469 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3464 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3462 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3458 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3452 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3457 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3451 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3461 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3473 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3479 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3487 - accuracy: 0.14 - ETA: 59s - loss: 3.3486 - accuracy: 0.1412 - ETA: 58s - loss: 3.3493 - accuracy: 0.141 - ETA: 58s - loss: 3.3497 - accuracy: 0.141 - ETA: 57s - loss: 3.3496 - accuracy: 0.140 - ETA: 57s - loss: 3.3497 - accuracy: 0.140 - ETA: 56s - loss: 3.3500 - accuracy: 0.140 - ETA: 56s - loss: 3.3498 - accuracy: 0.140 - ETA: 55s - loss: 3.3496 - accuracy: 0.140 - ETA: 54s - loss: 3.3500 - accuracy: 0.140 - ETA: 54s - loss: 3.3500 - accuracy: 0.140 - ETA: 53s - loss: 3.3500 - accuracy: 0.140 - ETA: 53s - loss: 3.3494 - accuracy: 0.140 - ETA: 52s - loss: 3.3491 - accuracy: 0.140 - ETA: 52s - loss: 3.3495 - accuracy: 0.140 - ETA: 51s - loss: 3.3499 - accuracy: 0.140 - ETA: 50s - loss: 3.3510 - accuracy: 0.140 - ETA: 50s - loss: 3.3511 - accuracy: 0.140 - ETA: 49s - loss: 3.3516 - accuracy: 0.140 - ETA: 49s - loss: 3.3515 - accuracy: 0.140 - ETA: 48s - loss: 3.3512 - accuracy: 0.140 - ETA: 48s - loss: 3.3503 - accuracy: 0.140 - ETA: 47s - loss: 3.3503 - accuracy: 0.140 - ETA: 46s - loss: 3.3505 - accuracy: 0.140 - ETA: 46s - loss: 3.3513 - accuracy: 0.140 - ETA: 45s - loss: 3.3526 - accuracy: 0.140 - ETA: 45s - loss: 3.3532 - accuracy: 0.140 - ETA: 44s - loss: 3.3544 - accuracy: 0.140 - ETA: 44s - loss: 3.3550 - accuracy: 0.139 - ETA: 43s - loss: 3.3552 - accuracy: 0.139 - ETA: 42s - loss: 3.3543 - accuracy: 0.140 - ETA: 42s - loss: 3.3539 - accuracy: 0.139 - ETA: 41s - loss: 3.3538 - accuracy: 0.139 - ETA: 41s - loss: 3.3535 - accuracy: 0.139 - ETA: 40s - loss: 3.3538 - accuracy: 0.139 - ETA: 40s - loss: 3.3534 - accuracy: 0.139 - ETA: 39s - loss: 3.3533 - accuracy: 0.139 - ETA: 38s - loss: 3.3531 - accuracy: 0.139 - ETA: 38s - loss: 3.3528 - accuracy: 0.139 - ETA: 37s - loss: 3.3541 - accuracy: 0.139 - ETA: 37s - loss: 3.3542 - accuracy: 0.139 - ETA: 36s - loss: 3.3543 - accuracy: 0.139 - ETA: 36s - loss: 3.3546 - accuracy: 0.139 - ETA: 35s - loss: 3.3549 - accuracy: 0.139 - ETA: 34s - loss: 3.3550 - accuracy: 0.139 - ETA: 34s - loss: 3.3552 - accuracy: 0.139 - ETA: 33s - loss: 3.3551 - accuracy: 0.139 - ETA: 33s - loss: 3.3552 - accuracy: 0.139 - ETA: 32s - loss: 3.3543 - accuracy: 0.139 - ETA: 32s - loss: 3.3540 - accuracy: 0.139 - ETA: 31s - loss: 3.3542 - accuracy: 0.139 - ETA: 30s - loss: 3.3540 - accuracy: 0.139 - ETA: 30s - loss: 3.3537 - accuracy: 0.139 - ETA: 29s - loss: 3.3538 - accuracy: 0.139 - ETA: 29s - loss: 3.3538 - accuracy: 0.139 - ETA: 28s - loss: 3.3536 - accuracy: 0.139 - ETA: 28s - loss: 3.3531 - accuracy: 0.139 - ETA: 27s - loss: 3.3527 - accuracy: 0.139 - ETA: 26s - loss: 3.3526 - accuracy: 0.139 - ETA: 26s - loss: 3.3528 - accuracy: 0.139 - ETA: 25s - loss: 3.3525 - accuracy: 0.139 - ETA: 25s - loss: 3.3523 - accuracy: 0.139 - ETA: 24s - loss: 3.3524 - accuracy: 0.139 - ETA: 24s - loss: 3.3521 - accuracy: 0.139 - ETA: 23s - loss: 3.3518 - accuracy: 0.139 - ETA: 22s - loss: 3.3518 - accuracy: 0.139 - ETA: 22s - loss: 3.3518 - accuracy: 0.139 - ETA: 21s - loss: 3.3511 - accuracy: 0.139 - ETA: 21s - loss: 3.3511 - accuracy: 0.139 - ETA: 20s - loss: 3.3505 - accuracy: 0.140 - ETA: 20s - loss: 3.3504 - accuracy: 0.140 - ETA: 19s - loss: 3.3498 - accuracy: 0.140 - ETA: 18s - loss: 3.3496 - accuracy: 0.140 - ETA: 18s - loss: 3.3483 - accuracy: 0.140 - ETA: 17s - loss: 3.3483 - accuracy: 0.140 - ETA: 17s - loss: 3.3478 - accuracy: 0.140 - ETA: 16s - loss: 3.3482 - accuracy: 0.140 - ETA: 16s - loss: 3.3487 - accuracy: 0.140 - ETA: 15s - loss: 3.3510 - accuracy: 0.140 - ETA: 14s - loss: 3.3526 - accuracy: 0.140 - ETA: 14s - loss: 3.3530 - accuracy: 0.140 - ETA: 13s - loss: 3.3535 - accuracy: 0.140 - ETA: 13s - loss: 3.3539 - accuracy: 0.140 - ETA: 12s - loss: 3.3540 - accuracy: 0.140 - ETA: 12s - loss: 3.3541 - accuracy: 0.140 - ETA: 11s - loss: 3.3541 - accuracy: 0.140 - ETA: 10s - loss: 3.3538 - accuracy: 0.140 - ETA: 10s - loss: 3.3538 - accuracy: 0.140 - ETA: 9s - loss: 3.3533 - accuracy: 0.140 - ETA: 9s - loss: 3.3531 - accuracy: 0.14 - ETA: 8s - loss: 3.3532 - accuracy: 0.14 - ETA: 8s - loss: 3.3531 - accuracy: 0.14 - ETA: 7s - loss: 3.3536 - accuracy: 0.14 - ETA: 6s - loss: 3.3537 - accuracy: 0.14 - ETA: 6s - loss: 3.3539 - accuracy: 0.14 - ETA: 5s - loss: 3.3536 - accuracy: 0.14 - ETA: 5s - loss: 3.3539 - accuracy: 0.14 - ETA: 4s - loss: 3.3540 - accuracy: 0.14 - ETA: 4s - loss: 3.3539 - accuracy: 0.14 - ETA: 3s - loss: 3.3538 - accuracy: 0.14 - ETA: 2s - loss: 3.3536 - accuracy: 0.14 - ETA: 2s - loss: 3.3532 - accuracy: 0.14 - ETA: 1s - loss: 3.3529 - accuracy: 0.14 - ETA: 1s - loss: 3.3528 - accuracy: 0.14 - ETA: 0s - loss: 3.3527 - accuracy: 0.14 - ETA: 0s - loss: 3.3527 - accuracy: 0.14 - 202s 5ms/step - loss: 3.3526 - accuracy: 0.1403 - val_loss: 3.9151 - val_accuracy: 0.0178\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:16 - loss: 3.2327 - accuracy: 0.16 - ETA: 3:07 - loss: 3.1965 - accuracy: 0.16 - ETA: 3:09 - loss: 3.2515 - accuracy: 0.14 - ETA: 3:06 - loss: 3.2575 - accuracy: 0.14 - ETA: 3:07 - loss: 3.2779 - accuracy: 0.14 - ETA: 3:04 - loss: 3.2988 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2881 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2663 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2543 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2638 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2714 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2689 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2713 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2896 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2932 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2936 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2917 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2887 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2978 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2902 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2865 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2853 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2885 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2896 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2893 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2872 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2876 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2830 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2820 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2852 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2815 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2834 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2914 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2949 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2894 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2911 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2875 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2857 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2837 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2842 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2837 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2849 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2890 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2910 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2888 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2878 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2852 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2851 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2849 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2860 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2856 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2852 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2847 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2852 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2844 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2837 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2840 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2813 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2817 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2830 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2843 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2822 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2816 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2813 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2842 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2864 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2886 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2868 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2876 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2891 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2882 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2873 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2883 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2883 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2881 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2882 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2871 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2871 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2886 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2907 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2909 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2934 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2946 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2965 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2985 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3030 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3025 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3005 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2994 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2993 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2989 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3003 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3002 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3002 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2986 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2969 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2978 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2975 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2968 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2961 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2960 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2963 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2964 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2966 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2964 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2952 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2929 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2919 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2919 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2906 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2910 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2911 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2912 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2906 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2915 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2908 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2920 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2925 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2924 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2946 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2947 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2936 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2928 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2929 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2933 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2938 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2934 - accuracy: 0.14 - ETA: 1:53 - loss: 3.2940 - accuracy: 0.14 - ETA: 1:53 - loss: 3.2937 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2943 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2949 - accuracy: 0.14 - ETA: 1:51 - loss: 3.2956 - accuracy: 0.14 - ETA: 1:50 - loss: 3.2954 - accuracy: 0.14 - ETA: 1:50 - loss: 3.2945 - accuracy: 0.14 - ETA: 1:49 - loss: 3.2944 - accuracy: 0.14 - ETA: 1:49 - loss: 3.2946 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2951 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2941 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2940 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2930 - accuracy: 0.14 - ETA: 1:46 - loss: 3.2936 - accuracy: 0.14 - ETA: 1:46 - loss: 3.2934 - accuracy: 0.14 - ETA: 1:45 - loss: 3.2925 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2927 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2933 - accuracy: 0.14 - ETA: 1:43 - loss: 3.2941 - accuracy: 0.14 - ETA: 1:43 - loss: 3.2929 - accuracy: 0.14 - ETA: 1:42 - loss: 3.2931 - accuracy: 0.14 - ETA: 1:41 - loss: 3.2930 - accuracy: 0.14 - ETA: 1:41 - loss: 3.2937 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2929 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2923 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2926 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2936 - accuracy: 0.14 - ETA: 1:38 - loss: 3.2943 - accuracy: 0.14 - ETA: 1:37 - loss: 3.2932 - accuracy: 0.14 - ETA: 1:37 - loss: 3.2927 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2933 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2937 - accuracy: 0.14 - ETA: 1:35 - loss: 3.2931 - accuracy: 0.14 - ETA: 1:35 - loss: 3.2937 - accuracy: 0.14 - ETA: 1:34 - loss: 3.2944 - accuracy: 0.14 - ETA: 1:34 - loss: 3.2951 - accuracy: 0.14 - ETA: 1:33 - loss: 3.2958 - accuracy: 0.14 - ETA: 1:33 - loss: 3.2968 - accuracy: 0.14 - ETA: 1:32 - loss: 3.2971 - accuracy: 0.14 - ETA: 1:31 - loss: 3.2979 - accuracy: 0.14 - ETA: 1:31 - loss: 3.2974 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2975 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2984 - accuracy: 0.14 - ETA: 1:29 - loss: 3.2976 - accuracy: 0.14 - ETA: 1:29 - loss: 3.2992 - accuracy: 0.14 - ETA: 1:28 - loss: 3.2988 - accuracy: 0.14 - ETA: 1:28 - loss: 3.2988 - accuracy: 0.14 - ETA: 1:27 - loss: 3.2990 - accuracy: 0.14 - ETA: 1:26 - loss: 3.2986 - accuracy: 0.14 - ETA: 1:26 - loss: 3.2979 - accuracy: 0.14 - ETA: 1:25 - loss: 3.2969 - accuracy: 0.14 - ETA: 1:25 - loss: 3.2967 - accuracy: 0.14 - ETA: 1:24 - loss: 3.2955 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2954 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2961 - accuracy: 0.14 - ETA: 1:22 - loss: 3.2962 - accuracy: 0.14 - ETA: 1:22 - loss: 3.2957 - accuracy: 0.1485"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.2952 - accuracy: 0.14 - ETA: 1:21 - loss: 3.2948 - accuracy: 0.14 - ETA: 1:20 - loss: 3.2953 - accuracy: 0.14 - ETA: 1:19 - loss: 3.2958 - accuracy: 0.14 - ETA: 1:19 - loss: 3.2964 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2962 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2967 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2970 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2971 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2966 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2969 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2969 - accuracy: 0.14 - ETA: 1:14 - loss: 3.2971 - accuracy: 0.14 - ETA: 1:14 - loss: 3.2973 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2972 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2968 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2972 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2969 - accuracy: 0.14 - ETA: 1:11 - loss: 3.2959 - accuracy: 0.14 - ETA: 1:10 - loss: 3.2969 - accuracy: 0.14 - ETA: 1:10 - loss: 3.2963 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2965 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2968 - accuracy: 0.14 - ETA: 1:08 - loss: 3.2965 - accuracy: 0.14 - ETA: 1:08 - loss: 3.2965 - accuracy: 0.14 - ETA: 1:07 - loss: 3.2960 - accuracy: 0.14 - ETA: 1:06 - loss: 3.2959 - accuracy: 0.14 - ETA: 1:06 - loss: 3.2963 - accuracy: 0.14 - ETA: 1:05 - loss: 3.2958 - accuracy: 0.14 - ETA: 1:05 - loss: 3.2951 - accuracy: 0.14 - ETA: 1:04 - loss: 3.2954 - accuracy: 0.14 - ETA: 1:04 - loss: 3.2959 - accuracy: 0.14 - ETA: 1:03 - loss: 3.2960 - accuracy: 0.14 - ETA: 1:02 - loss: 3.2956 - accuracy: 0.14 - ETA: 1:02 - loss: 3.2950 - accuracy: 0.14 - ETA: 1:01 - loss: 3.2942 - accuracy: 0.14 - ETA: 1:01 - loss: 3.2943 - accuracy: 0.14 - ETA: 1:00 - loss: 3.2942 - accuracy: 0.14 - ETA: 1:00 - loss: 3.2943 - accuracy: 0.14 - ETA: 59s - loss: 3.2938 - accuracy: 0.1490 - ETA: 58s - loss: 3.2934 - accuracy: 0.149 - ETA: 58s - loss: 3.2935 - accuracy: 0.148 - ETA: 57s - loss: 3.2938 - accuracy: 0.148 - ETA: 57s - loss: 3.2940 - accuracy: 0.148 - ETA: 56s - loss: 3.2940 - accuracy: 0.148 - ETA: 56s - loss: 3.2944 - accuracy: 0.148 - ETA: 55s - loss: 3.2946 - accuracy: 0.148 - ETA: 54s - loss: 3.2948 - accuracy: 0.148 - ETA: 54s - loss: 3.2941 - accuracy: 0.148 - ETA: 53s - loss: 3.2945 - accuracy: 0.148 - ETA: 53s - loss: 3.2946 - accuracy: 0.148 - ETA: 52s - loss: 3.2945 - accuracy: 0.148 - ETA: 52s - loss: 3.2944 - accuracy: 0.148 - ETA: 51s - loss: 3.2948 - accuracy: 0.148 - ETA: 50s - loss: 3.2950 - accuracy: 0.148 - ETA: 50s - loss: 3.2952 - accuracy: 0.148 - ETA: 49s - loss: 3.2949 - accuracy: 0.148 - ETA: 49s - loss: 3.2951 - accuracy: 0.148 - ETA: 48s - loss: 3.2945 - accuracy: 0.148 - ETA: 48s - loss: 3.2943 - accuracy: 0.148 - ETA: 47s - loss: 3.2947 - accuracy: 0.148 - ETA: 46s - loss: 3.2948 - accuracy: 0.148 - ETA: 46s - loss: 3.2937 - accuracy: 0.148 - ETA: 45s - loss: 3.2943 - accuracy: 0.148 - ETA: 45s - loss: 3.2943 - accuracy: 0.148 - ETA: 44s - loss: 3.2948 - accuracy: 0.148 - ETA: 44s - loss: 3.2951 - accuracy: 0.148 - ETA: 43s - loss: 3.2956 - accuracy: 0.148 - ETA: 43s - loss: 3.2956 - accuracy: 0.148 - ETA: 42s - loss: 3.2954 - accuracy: 0.149 - ETA: 41s - loss: 3.2960 - accuracy: 0.148 - ETA: 41s - loss: 3.2959 - accuracy: 0.148 - ETA: 40s - loss: 3.2953 - accuracy: 0.149 - ETA: 40s - loss: 3.2948 - accuracy: 0.149 - ETA: 39s - loss: 3.2947 - accuracy: 0.149 - ETA: 39s - loss: 3.2948 - accuracy: 0.149 - ETA: 38s - loss: 3.2944 - accuracy: 0.149 - ETA: 37s - loss: 3.2944 - accuracy: 0.149 - ETA: 37s - loss: 3.2941 - accuracy: 0.149 - ETA: 36s - loss: 3.2945 - accuracy: 0.149 - ETA: 36s - loss: 3.2939 - accuracy: 0.149 - ETA: 35s - loss: 3.2933 - accuracy: 0.149 - ETA: 35s - loss: 3.2937 - accuracy: 0.149 - ETA: 34s - loss: 3.2946 - accuracy: 0.149 - ETA: 33s - loss: 3.2938 - accuracy: 0.149 - ETA: 33s - loss: 3.2941 - accuracy: 0.149 - ETA: 32s - loss: 3.2952 - accuracy: 0.149 - ETA: 32s - loss: 3.2950 - accuracy: 0.149 - ETA: 31s - loss: 3.2949 - accuracy: 0.149 - ETA: 31s - loss: 3.2945 - accuracy: 0.149 - ETA: 30s - loss: 3.2938 - accuracy: 0.149 - ETA: 30s - loss: 3.2940 - accuracy: 0.149 - ETA: 29s - loss: 3.2937 - accuracy: 0.149 - ETA: 28s - loss: 3.2939 - accuracy: 0.149 - ETA: 28s - loss: 3.2930 - accuracy: 0.149 - ETA: 27s - loss: 3.2921 - accuracy: 0.149 - ETA: 27s - loss: 3.2921 - accuracy: 0.149 - ETA: 26s - loss: 3.2916 - accuracy: 0.149 - ETA: 26s - loss: 3.2915 - accuracy: 0.149 - ETA: 25s - loss: 3.2920 - accuracy: 0.149 - ETA: 24s - loss: 3.2924 - accuracy: 0.149 - ETA: 24s - loss: 3.2927 - accuracy: 0.149 - ETA: 23s - loss: 3.2930 - accuracy: 0.149 - ETA: 23s - loss: 3.2930 - accuracy: 0.149 - ETA: 22s - loss: 3.2923 - accuracy: 0.149 - ETA: 22s - loss: 3.2923 - accuracy: 0.149 - ETA: 21s - loss: 3.2923 - accuracy: 0.149 - ETA: 20s - loss: 3.2920 - accuracy: 0.149 - ETA: 20s - loss: 3.2916 - accuracy: 0.149 - ETA: 19s - loss: 3.2912 - accuracy: 0.149 - ETA: 19s - loss: 3.2909 - accuracy: 0.149 - ETA: 18s - loss: 3.2905 - accuracy: 0.149 - ETA: 18s - loss: 3.2908 - accuracy: 0.149 - ETA: 17s - loss: 3.2914 - accuracy: 0.149 - ETA: 17s - loss: 3.2918 - accuracy: 0.149 - ETA: 16s - loss: 3.2915 - accuracy: 0.149 - ETA: 15s - loss: 3.2915 - accuracy: 0.149 - ETA: 15s - loss: 3.2916 - accuracy: 0.149 - ETA: 14s - loss: 3.2915 - accuracy: 0.149 - ETA: 14s - loss: 3.2917 - accuracy: 0.149 - ETA: 13s - loss: 3.2912 - accuracy: 0.149 - ETA: 13s - loss: 3.2918 - accuracy: 0.149 - ETA: 12s - loss: 3.2921 - accuracy: 0.149 - ETA: 11s - loss: 3.2919 - accuracy: 0.149 - ETA: 11s - loss: 3.2916 - accuracy: 0.149 - ETA: 10s - loss: 3.2914 - accuracy: 0.149 - ETA: 10s - loss: 3.2915 - accuracy: 0.149 - ETA: 9s - loss: 3.2913 - accuracy: 0.149 - ETA: 9s - loss: 3.2911 - accuracy: 0.14 - ETA: 8s - loss: 3.2911 - accuracy: 0.14 - ETA: 7s - loss: 3.2905 - accuracy: 0.14 - ETA: 7s - loss: 3.2903 - accuracy: 0.14 - ETA: 6s - loss: 3.2907 - accuracy: 0.14 - ETA: 6s - loss: 3.2904 - accuracy: 0.14 - ETA: 5s - loss: 3.2908 - accuracy: 0.14 - ETA: 5s - loss: 3.2910 - accuracy: 0.14 - ETA: 4s - loss: 3.2909 - accuracy: 0.14 - ETA: 4s - loss: 3.2904 - accuracy: 0.14 - ETA: 3s - loss: 3.2904 - accuracy: 0.14 - ETA: 2s - loss: 3.2902 - accuracy: 0.14 - ETA: 2s - loss: 3.2902 - accuracy: 0.14 - ETA: 1s - loss: 3.2901 - accuracy: 0.14 - ETA: 1s - loss: 3.2906 - accuracy: 0.14 - ETA: 0s - loss: 3.2915 - accuracy: 0.14 - ETA: 0s - loss: 3.2938 - accuracy: 0.14 - 200s 5ms/step - loss: 3.2940 - accuracy: 0.1494 - val_loss: 3.9816 - val_accuracy: 0.0166\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:25 - loss: 3.3736 - accuracy: 0.15 - ETA: 3:11 - loss: 3.3489 - accuracy: 0.16 - ETA: 3:10 - loss: 3.3603 - accuracy: 0.15 - ETA: 3:07 - loss: 3.3246 - accuracy: 0.15 - ETA: 3:05 - loss: 3.3026 - accuracy: 0.15 - ETA: 3:07 - loss: 3.3219 - accuracy: 0.15 - ETA: 3:06 - loss: 3.3126 - accuracy: 0.15 - ETA: 3:04 - loss: 3.3067 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3303 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3197 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3120 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3051 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2915 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2885 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2974 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3002 - accuracy: 0.13 - ETA: 3:00 - loss: 3.2984 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3159 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3067 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3168 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3179 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3224 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3273 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3329 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3364 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3349 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3364 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3350 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3291 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3277 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3270 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3303 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3305 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3354 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3380 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3391 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3397 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3397 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3413 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3439 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3440 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3450 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3426 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3387 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3381 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3380 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3376 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3438 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3387 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3365 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3349 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3313 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3316 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3278 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3285 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3298 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3288 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3270 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3280 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3265 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3253 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3264 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3261 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3248 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3246 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3231 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3229 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3232 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3235 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3263 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3245 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3242 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3228 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3233 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3225 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3204 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3190 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3205 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3188 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3195 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3191 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3193 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3185 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3192 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3191 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3203 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3218 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3210 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3246 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3258 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3274 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3274 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3264 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3260 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3234 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3232 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3224 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3241 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3233 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3221 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3230 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3223 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3222 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3230 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3240 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3239 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3218 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3231 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3216 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3218 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3210 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3212 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3203 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3197 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3196 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3187 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3193 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3187 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3180 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3187 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3200 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3196 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3198 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3202 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3213 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3201 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3185 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3169 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3152 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3144 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3139 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3138 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3116 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3120 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3116 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3118 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3113 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3115 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3113 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3111 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3108 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3115 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3114 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3114 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3108 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3107 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3110 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3117 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3115 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3101 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3103 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3095 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3095 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3098 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3096 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3084 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3073 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3080 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3079 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3071 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3071 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3068 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3070 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3062 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3065 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3061 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3070 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3065 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3062 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3069 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3078 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3080 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3086 - accuracy: 0.1468"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:26 - loss: 3.3081 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3082 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3087 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3090 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3087 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3094 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3095 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3094 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3094 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3106 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3097 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3101 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3100 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3096 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3098 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3102 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3108 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3103 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3109 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3116 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3115 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3117 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3111 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3111 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3112 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3115 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3105 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3106 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3109 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3110 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3116 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3117 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3115 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3116 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3113 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3112 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3120 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3117 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3124 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3120 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3126 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3129 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3125 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3123 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3133 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3151 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3153 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3173 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3174 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3182 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3181 - accuracy: 0.14 - ETA: 59s - loss: 3.3181 - accuracy: 0.1444 - ETA: 59s - loss: 3.3181 - accuracy: 0.144 - ETA: 58s - loss: 3.3179 - accuracy: 0.144 - ETA: 57s - loss: 3.3183 - accuracy: 0.144 - ETA: 57s - loss: 3.3173 - accuracy: 0.144 - ETA: 56s - loss: 3.3168 - accuracy: 0.144 - ETA: 56s - loss: 3.3167 - accuracy: 0.144 - ETA: 55s - loss: 3.3169 - accuracy: 0.144 - ETA: 54s - loss: 3.3166 - accuracy: 0.144 - ETA: 54s - loss: 3.3159 - accuracy: 0.144 - ETA: 53s - loss: 3.3157 - accuracy: 0.144 - ETA: 53s - loss: 3.3158 - accuracy: 0.144 - ETA: 52s - loss: 3.3157 - accuracy: 0.145 - ETA: 51s - loss: 3.3157 - accuracy: 0.144 - ETA: 51s - loss: 3.3157 - accuracy: 0.145 - ETA: 50s - loss: 3.3156 - accuracy: 0.144 - ETA: 49s - loss: 3.3161 - accuracy: 0.144 - ETA: 49s - loss: 3.3159 - accuracy: 0.144 - ETA: 48s - loss: 3.3168 - accuracy: 0.144 - ETA: 47s - loss: 3.3174 - accuracy: 0.144 - ETA: 47s - loss: 3.3180 - accuracy: 0.144 - ETA: 46s - loss: 3.3182 - accuracy: 0.144 - ETA: 46s - loss: 3.3187 - accuracy: 0.144 - ETA: 45s - loss: 3.3183 - accuracy: 0.144 - ETA: 44s - loss: 3.3175 - accuracy: 0.144 - ETA: 44s - loss: 3.3175 - accuracy: 0.144 - ETA: 43s - loss: 3.3179 - accuracy: 0.144 - ETA: 42s - loss: 3.3179 - accuracy: 0.144 - ETA: 42s - loss: 3.3169 - accuracy: 0.145 - ETA: 41s - loss: 3.3173 - accuracy: 0.144 - ETA: 41s - loss: 3.3175 - accuracy: 0.144 - ETA: 40s - loss: 3.3169 - accuracy: 0.144 - ETA: 39s - loss: 3.3163 - accuracy: 0.145 - ETA: 39s - loss: 3.3156 - accuracy: 0.145 - ETA: 38s - loss: 3.3157 - accuracy: 0.145 - ETA: 37s - loss: 3.3156 - accuracy: 0.145 - ETA: 37s - loss: 3.3161 - accuracy: 0.145 - ETA: 36s - loss: 3.3160 - accuracy: 0.145 - ETA: 35s - loss: 3.3159 - accuracy: 0.145 - ETA: 35s - loss: 3.3157 - accuracy: 0.145 - ETA: 34s - loss: 3.3148 - accuracy: 0.145 - ETA: 33s - loss: 3.3144 - accuracy: 0.145 - ETA: 33s - loss: 3.3143 - accuracy: 0.145 - ETA: 32s - loss: 3.3137 - accuracy: 0.145 - ETA: 31s - loss: 3.3136 - accuracy: 0.145 - ETA: 31s - loss: 3.3130 - accuracy: 0.145 - ETA: 30s - loss: 3.3129 - accuracy: 0.145 - ETA: 29s - loss: 3.3122 - accuracy: 0.146 - ETA: 29s - loss: 3.3119 - accuracy: 0.146 - ETA: 28s - loss: 3.3117 - accuracy: 0.146 - ETA: 27s - loss: 3.3110 - accuracy: 0.146 - ETA: 27s - loss: 3.3105 - accuracy: 0.146 - ETA: 26s - loss: 3.3102 - accuracy: 0.146 - ETA: 25s - loss: 3.3103 - accuracy: 0.146 - ETA: 24s - loss: 3.3099 - accuracy: 0.146 - ETA: 24s - loss: 3.3102 - accuracy: 0.146 - ETA: 23s - loss: 3.3102 - accuracy: 0.146 - ETA: 22s - loss: 3.3096 - accuracy: 0.146 - ETA: 22s - loss: 3.3095 - accuracy: 0.146 - ETA: 21s - loss: 3.3092 - accuracy: 0.146 - ETA: 20s - loss: 3.3096 - accuracy: 0.146 - ETA: 20s - loss: 3.3096 - accuracy: 0.146 - ETA: 19s - loss: 3.3098 - accuracy: 0.146 - ETA: 18s - loss: 3.3099 - accuracy: 0.146 - ETA: 18s - loss: 3.3102 - accuracy: 0.146 - ETA: 17s - loss: 3.3093 - accuracy: 0.146 - ETA: 16s - loss: 3.3094 - accuracy: 0.146 - ETA: 15s - loss: 3.3093 - accuracy: 0.146 - ETA: 15s - loss: 3.3090 - accuracy: 0.146 - ETA: 14s - loss: 3.3092 - accuracy: 0.146 - ETA: 13s - loss: 3.3096 - accuracy: 0.146 - ETA: 13s - loss: 3.3103 - accuracy: 0.146 - ETA: 12s - loss: 3.3103 - accuracy: 0.146 - ETA: 11s - loss: 3.3111 - accuracy: 0.146 - ETA: 10s - loss: 3.3108 - accuracy: 0.146 - ETA: 10s - loss: 3.3108 - accuracy: 0.146 - ETA: 9s - loss: 3.3103 - accuracy: 0.146 - ETA: 8s - loss: 3.3099 - accuracy: 0.14 - ETA: 8s - loss: 3.3095 - accuracy: 0.14 - ETA: 7s - loss: 3.3098 - accuracy: 0.14 - ETA: 6s - loss: 3.3087 - accuracy: 0.14 - ETA: 5s - loss: 3.3082 - accuracy: 0.14 - ETA: 5s - loss: 3.3077 - accuracy: 0.14 - ETA: 4s - loss: 3.3080 - accuracy: 0.14 - ETA: 3s - loss: 3.3080 - accuracy: 0.14 - ETA: 2s - loss: 3.3083 - accuracy: 0.14 - ETA: 2s - loss: 3.3080 - accuracy: 0.14 - ETA: 1s - loss: 3.3083 - accuracy: 0.14 - ETA: 0s - loss: 3.3080 - accuracy: 0.14 - ETA: 0s - loss: 3.3076 - accuracy: 0.14 - 260s 6ms/step - loss: 3.3076 - accuracy: 0.1469 - val_loss: 3.9116 - val_accuracy: 0.0122\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:02 - loss: 3.0925 - accuracy: 0.18 - ETA: 4:53 - loss: 3.1605 - accuracy: 0.15 - ETA: 4:49 - loss: 3.2287 - accuracy: 0.14 - ETA: 4:55 - loss: 3.2731 - accuracy: 0.13 - ETA: 4:55 - loss: 3.2529 - accuracy: 0.14 - ETA: 4:54 - loss: 3.2415 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2543 - accuracy: 0.14 - ETA: 4:53 - loss: 3.2557 - accuracy: 0.14 - ETA: 4:53 - loss: 3.2532 - accuracy: 0.14 - ETA: 4:51 - loss: 3.2650 - accuracy: 0.14 - ETA: 4:48 - loss: 3.2580 - accuracy: 0.14 - ETA: 4:46 - loss: 3.2606 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2654 - accuracy: 0.15 - ETA: 4:43 - loss: 3.2762 - accuracy: 0.14 - ETA: 4:42 - loss: 3.2806 - accuracy: 0.14 - ETA: 4:40 - loss: 3.2783 - accuracy: 0.14 - ETA: 4:38 - loss: 3.2878 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3014 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3095 - accuracy: 0.14 - ETA: 4:37 - loss: 3.3086 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3093 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3129 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3157 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3204 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3209 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3219 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3251 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3237 - accuracy: 0.14 - ETA: 4:32 - loss: 3.3241 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3287 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3285 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3306 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3345 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3366 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3370 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3380 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3431 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3476 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3464 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3424 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3411 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3391 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3368 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3373 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3366 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3330 - accuracy: 0.13 - ETA: 4:19 - loss: 3.3318 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3335 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3310 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3305 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3328 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3353 - accuracy: 0.13 - ETA: 4:13 - loss: 3.3368 - accuracy: 0.13 - ETA: 4:12 - loss: 3.3348 - accuracy: 0.13 - ETA: 4:11 - loss: 3.3345 - accuracy: 0.13 - ETA: 4:10 - loss: 3.3352 - accuracy: 0.13 - ETA: 4:09 - loss: 3.3349 - accuracy: 0.13 - ETA: 4:08 - loss: 3.3354 - accuracy: 0.13 - ETA: 4:08 - loss: 3.3345 - accuracy: 0.13 - ETA: 4:07 - loss: 3.3346 - accuracy: 0.13 - ETA: 4:06 - loss: 3.3342 - accuracy: 0.13 - ETA: 4:05 - loss: 3.3357 - accuracy: 0.13 - ETA: 4:04 - loss: 3.3322 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3323 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3321 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3317 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3318 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3321 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3324 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3339 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3353 - accuracy: 0.13 - ETA: 3:55 - loss: 3.3353 - accuracy: 0.13 - ETA: 3:54 - loss: 3.3314 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3381 - accuracy: 0.13 - ETA: 3:53 - loss: 3.3404 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3421 - accuracy: 0.13 - ETA: 3:51 - loss: 3.3416 - accuracy: 0.13 - ETA: 3:50 - loss: 3.3414 - accuracy: 0.13 - ETA: 3:49 - loss: 3.3391 - accuracy: 0.13 - ETA: 3:48 - loss: 3.3377 - accuracy: 0.13 - ETA: 3:47 - loss: 3.3370 - accuracy: 0.13 - ETA: 3:46 - loss: 3.3367 - accuracy: 0.13 - ETA: 3:45 - loss: 3.3355 - accuracy: 0.13 - ETA: 3:44 - loss: 3.3353 - accuracy: 0.13 - ETA: 3:43 - loss: 3.3332 - accuracy: 0.14 - ETA: 3:42 - loss: 3.3330 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3324 - accuracy: 0.13 - ETA: 3:40 - loss: 3.3298 - accuracy: 0.14 - ETA: 3:39 - loss: 3.3290 - accuracy: 0.14 - ETA: 3:38 - loss: 3.3283 - accuracy: 0.14 - ETA: 3:37 - loss: 3.3290 - accuracy: 0.13 - ETA: 3:36 - loss: 3.3292 - accuracy: 0.13 - ETA: 3:35 - loss: 3.3272 - accuracy: 0.14 - ETA: 3:34 - loss: 3.3296 - accuracy: 0.14 - ETA: 3:33 - loss: 3.3331 - accuracy: 0.14 - ETA: 3:32 - loss: 3.3324 - accuracy: 0.14 - ETA: 3:31 - loss: 3.3346 - accuracy: 0.14 - ETA: 3:30 - loss: 3.3355 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3349 - accuracy: 0.13 - ETA: 3:28 - loss: 3.3356 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3381 - accuracy: 0.13 - ETA: 3:26 - loss: 3.3368 - accuracy: 0.14 - ETA: 3:26 - loss: 3.3356 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3355 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3367 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3359 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3360 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3359 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3352 - accuracy: 0.13 - ETA: 3:20 - loss: 3.3348 - accuracy: 0.13 - ETA: 3:19 - loss: 3.3338 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3336 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3336 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3334 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3332 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3330 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3332 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3337 - accuracy: 0.13 - ETA: 3:11 - loss: 3.3311 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3306 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3305 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3304 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3301 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3299 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3282 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3276 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3297 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3279 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3280 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3280 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3267 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3270 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3268 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3273 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3279 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3280 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3283 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3279 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3277 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3282 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3281 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3280 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3284 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3287 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3293 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3293 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3307 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3317 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3317 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3328 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3332 - accuracy: 0.13 - ETA: 2:40 - loss: 3.3329 - accuracy: 0.13 - ETA: 2:40 - loss: 3.3334 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3337 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3338 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3392 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3396 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3403 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3419 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3422 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3420 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3427 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3437 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3440 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3437 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3439 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3445 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3452 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3453 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3452 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3461 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3468 - accuracy: 0.13 - ETA: 2:21 - loss: 3.3466 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3459 - accuracy: 0.13 - ETA: 2:19 - loss: 3.3451 - accuracy: 0.13 - ETA: 2:18 - loss: 3.3457 - accuracy: 0.13 - ETA: 2:17 - loss: 3.3464 - accuracy: 0.13 - ETA: 2:16 - loss: 3.3508 - accuracy: 0.13 - ETA: 2:15 - loss: 3.3525 - accuracy: 0.13 - ETA: 2:14 - loss: 3.3541 - accuracy: 0.13 - ETA: 2:13 - loss: 3.3561 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3574 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3582 - accuracy: 0.13 - ETA: 2:10 - loss: 3.3580 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3578 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3584 - accuracy: 0.1355"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:07 - loss: 3.3580 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3585 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3582 - accuracy: 0.13 - ETA: 2:04 - loss: 3.3589 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3589 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3592 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3592 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3590 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3590 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3596 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3604 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3602 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3603 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3617 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3618 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3614 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3605 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3607 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3612 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3612 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3613 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3613 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3613 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3613 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3608 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3608 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3606 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3600 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3591 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3598 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3596 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3594 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3594 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3604 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3600 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3602 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3599 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3595 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3587 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3583 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3578 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3577 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3575 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3569 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3571 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3573 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3571 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3571 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3568 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3568 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3573 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3583 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3586 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3580 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3573 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3568 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3573 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3574 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3570 - accuracy: 0.13 - ETA: 1:13 - loss: 3.3572 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3569 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3569 - accuracy: 0.13 - ETA: 1:11 - loss: 3.3572 - accuracy: 0.13 - ETA: 1:10 - loss: 3.3574 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3583 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3582 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3579 - accuracy: 0.13 - ETA: 1:06 - loss: 3.3576 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3575 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3570 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3560 - accuracy: 0.13 - ETA: 1:03 - loss: 3.3551 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3547 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3549 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3548 - accuracy: 0.13 - ETA: 59s - loss: 3.3544 - accuracy: 0.1357 - ETA: 58s - loss: 3.3545 - accuracy: 0.135 - ETA: 58s - loss: 3.3545 - accuracy: 0.135 - ETA: 57s - loss: 3.3542 - accuracy: 0.135 - ETA: 56s - loss: 3.3544 - accuracy: 0.135 - ETA: 55s - loss: 3.3542 - accuracy: 0.135 - ETA: 54s - loss: 3.3537 - accuracy: 0.135 - ETA: 53s - loss: 3.3541 - accuracy: 0.135 - ETA: 52s - loss: 3.3543 - accuracy: 0.135 - ETA: 51s - loss: 3.3540 - accuracy: 0.135 - ETA: 51s - loss: 3.3538 - accuracy: 0.135 - ETA: 50s - loss: 3.3534 - accuracy: 0.135 - ETA: 49s - loss: 3.3533 - accuracy: 0.135 - ETA: 48s - loss: 3.3527 - accuracy: 0.136 - ETA: 47s - loss: 3.3523 - accuracy: 0.136 - ETA: 46s - loss: 3.3520 - accuracy: 0.136 - ETA: 45s - loss: 3.3521 - accuracy: 0.136 - ETA: 44s - loss: 3.3524 - accuracy: 0.136 - ETA: 44s - loss: 3.3526 - accuracy: 0.136 - ETA: 43s - loss: 3.3517 - accuracy: 0.136 - ETA: 42s - loss: 3.3528 - accuracy: 0.136 - ETA: 41s - loss: 3.3535 - accuracy: 0.136 - ETA: 40s - loss: 3.3531 - accuracy: 0.136 - ETA: 39s - loss: 3.3534 - accuracy: 0.136 - ETA: 38s - loss: 3.3550 - accuracy: 0.136 - ETA: 37s - loss: 3.3555 - accuracy: 0.136 - ETA: 37s - loss: 3.3564 - accuracy: 0.136 - ETA: 36s - loss: 3.3562 - accuracy: 0.136 - ETA: 35s - loss: 3.3555 - accuracy: 0.136 - ETA: 34s - loss: 3.3557 - accuracy: 0.136 - ETA: 33s - loss: 3.3558 - accuracy: 0.136 - ETA: 32s - loss: 3.3557 - accuracy: 0.136 - ETA: 31s - loss: 3.3564 - accuracy: 0.136 - ETA: 30s - loss: 3.3567 - accuracy: 0.136 - ETA: 30s - loss: 3.3569 - accuracy: 0.136 - ETA: 29s - loss: 3.3566 - accuracy: 0.136 - ETA: 28s - loss: 3.3565 - accuracy: 0.136 - ETA: 27s - loss: 3.3565 - accuracy: 0.136 - ETA: 26s - loss: 3.3560 - accuracy: 0.136 - ETA: 25s - loss: 3.3559 - accuracy: 0.136 - ETA: 24s - loss: 3.3552 - accuracy: 0.137 - ETA: 24s - loss: 3.3554 - accuracy: 0.136 - ETA: 23s - loss: 3.3553 - accuracy: 0.136 - ETA: 22s - loss: 3.3550 - accuracy: 0.137 - ETA: 21s - loss: 3.3551 - accuracy: 0.137 - ETA: 20s - loss: 3.3549 - accuracy: 0.137 - ETA: 19s - loss: 3.3552 - accuracy: 0.137 - ETA: 18s - loss: 3.3547 - accuracy: 0.137 - ETA: 18s - loss: 3.3548 - accuracy: 0.137 - ETA: 17s - loss: 3.3546 - accuracy: 0.137 - ETA: 16s - loss: 3.3542 - accuracy: 0.137 - ETA: 15s - loss: 3.3542 - accuracy: 0.137 - ETA: 14s - loss: 3.3540 - accuracy: 0.137 - ETA: 13s - loss: 3.3532 - accuracy: 0.137 - ETA: 12s - loss: 3.3531 - accuracy: 0.137 - ETA: 12s - loss: 3.3530 - accuracy: 0.137 - ETA: 11s - loss: 3.3525 - accuracy: 0.137 - ETA: 10s - loss: 3.3522 - accuracy: 0.137 - ETA: 9s - loss: 3.3523 - accuracy: 0.137 - ETA: 8s - loss: 3.3513 - accuracy: 0.13 - ETA: 7s - loss: 3.3512 - accuracy: 0.13 - ETA: 6s - loss: 3.3509 - accuracy: 0.13 - ETA: 6s - loss: 3.3507 - accuracy: 0.13 - ETA: 5s - loss: 3.3503 - accuracy: 0.13 - ETA: 4s - loss: 3.3500 - accuracy: 0.13 - ETA: 3s - loss: 3.3496 - accuracy: 0.13 - ETA: 2s - loss: 3.3498 - accuracy: 0.13 - ETA: 1s - loss: 3.3495 - accuracy: 0.13 - ETA: 0s - loss: 3.3496 - accuracy: 0.13 - ETA: 0s - loss: 3.3491 - accuracy: 0.13 - 298s 7ms/step - loss: 3.3491 - accuracy: 0.1386 - val_loss: 3.9428 - val_accuracy: 0.0153\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:21 - loss: 3.1588 - accuracy: 0.17 - ETA: 4:13 - loss: 3.1939 - accuracy: 0.14 - ETA: 4:19 - loss: 3.2697 - accuracy: 0.13 - ETA: 4:18 - loss: 3.2695 - accuracy: 0.13 - ETA: 4:18 - loss: 3.2600 - accuracy: 0.13 - ETA: 4:17 - loss: 3.2620 - accuracy: 0.14 - ETA: 4:14 - loss: 3.2690 - accuracy: 0.14 - ETA: 4:11 - loss: 3.2697 - accuracy: 0.14 - ETA: 4:10 - loss: 3.2692 - accuracy: 0.15 - ETA: 4:10 - loss: 3.2461 - accuracy: 0.16 - ETA: 4:11 - loss: 3.2557 - accuracy: 0.16 - ETA: 4:11 - loss: 3.2429 - accuracy: 0.16 - ETA: 4:11 - loss: 3.2288 - accuracy: 0.16 - ETA: 4:11 - loss: 3.2382 - accuracy: 0.16 - ETA: 4:11 - loss: 3.2365 - accuracy: 0.16 - ETA: 4:10 - loss: 3.2385 - accuracy: 0.16 - ETA: 4:09 - loss: 3.2474 - accuracy: 0.16 - ETA: 4:08 - loss: 3.2515 - accuracy: 0.16 - ETA: 4:07 - loss: 3.2456 - accuracy: 0.16 - ETA: 4:05 - loss: 3.2388 - accuracy: 0.16 - ETA: 4:04 - loss: 3.2393 - accuracy: 0.16 - ETA: 4:02 - loss: 3.2446 - accuracy: 0.16 - ETA: 4:01 - loss: 3.2448 - accuracy: 0.16 - ETA: 4:00 - loss: 3.2509 - accuracy: 0.15 - ETA: 4:00 - loss: 3.2493 - accuracy: 0.15 - ETA: 3:59 - loss: 3.2462 - accuracy: 0.16 - ETA: 3:58 - loss: 3.2475 - accuracy: 0.15 - ETA: 3:57 - loss: 3.2402 - accuracy: 0.16 - ETA: 3:56 - loss: 3.2372 - accuracy: 0.16 - ETA: 3:56 - loss: 3.2422 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2438 - accuracy: 0.15 - ETA: 3:55 - loss: 3.2420 - accuracy: 0.16 - ETA: 3:54 - loss: 3.2428 - accuracy: 0.16 - ETA: 3:54 - loss: 3.2382 - accuracy: 0.16 - ETA: 3:54 - loss: 3.2442 - accuracy: 0.16 - ETA: 3:54 - loss: 3.2429 - accuracy: 0.16 - ETA: 3:53 - loss: 3.2429 - accuracy: 0.16 - ETA: 3:52 - loss: 3.2442 - accuracy: 0.15 - ETA: 3:51 - loss: 3.2463 - accuracy: 0.15 - ETA: 3:50 - loss: 3.2469 - accuracy: 0.15 - ETA: 3:49 - loss: 3.2488 - accuracy: 0.15 - ETA: 3:48 - loss: 3.2500 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2478 - accuracy: 0.15 - ETA: 3:47 - loss: 3.2534 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2583 - accuracy: 0.15 - ETA: 3:46 - loss: 3.2596 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2614 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2615 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2607 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2584 - accuracy: 0.15 - ETA: 3:42 - loss: 3.2600 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2601 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2585 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2550 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2556 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2584 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2579 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2579 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2620 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2624 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2622 - accuracy: 0.15 - ETA: 3:37 - loss: 3.2629 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2630 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2623 - accuracy: 0.15 - ETA: 3:34 - loss: 3.2606 - accuracy: 0.15 - ETA: 3:34 - loss: 3.2591 - accuracy: 0.15 - ETA: 3:33 - loss: 3.2624 - accuracy: 0.15 - ETA: 3:32 - loss: 3.2640 - accuracy: 0.15 - ETA: 3:31 - loss: 3.2641 - accuracy: 0.15 - ETA: 3:30 - loss: 3.2628 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2597 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2603 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2606 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2622 - accuracy: 0.15 - ETA: 3:27 - loss: 3.2616 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2626 - accuracy: 0.15 - ETA: 3:25 - loss: 3.2643 - accuracy: 0.15 - ETA: 3:24 - loss: 3.2644 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2651 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2684 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2680 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2686 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2688 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2727 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2735 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2723 - accuracy: 0.15 - ETA: 3:17 - loss: 3.2739 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2740 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2745 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2743 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2740 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2720 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2711 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2721 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2713 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2715 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2724 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2738 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2747 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2729 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2737 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2740 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2728 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2736 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2749 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2736 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2750 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2748 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2761 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2737 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2725 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2725 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2724 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2720 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2707 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2721 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2716 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2717 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2705 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2712 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2708 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2713 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2710 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2700 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2704 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2711 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2715 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2712 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2721 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2729 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2726 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2725 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2727 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2732 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2735 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2732 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2728 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2716 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2698 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2680 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2668 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2664 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2649 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2643 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2656 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2651 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2662 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2652 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2636 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2639 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2627 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2621 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2618 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2617 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2633 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2639 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2652 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2640 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2641 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2648 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2652 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2658 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2662 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2671 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2668 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2675 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2678 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2681 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2676 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2666 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2678 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2685 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2680 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2678 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2678 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2673 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2674 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2676 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2686 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2685 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2682 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2689 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2681 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2686 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2684 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2687 - accuracy: 0.1549"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:56 - loss: 3.2686 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2681 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2679 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2689 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2692 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2709 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2713 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2721 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2723 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2728 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2734 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2730 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2734 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2745 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2755 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2758 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2758 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2759 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2759 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2760 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2763 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2764 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2778 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2776 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2783 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2787 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2791 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2799 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2804 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2808 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2806 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2805 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2806 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2806 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2806 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2803 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2801 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2799 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2797 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2797 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2801 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2798 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2803 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2805 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2809 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2821 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2814 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2811 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2812 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2814 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2819 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2820 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2820 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2825 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2822 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2824 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2839 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2830 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2828 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2825 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2823 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2828 - accuracy: 0.15 - ETA: 59s - loss: 3.2826 - accuracy: 0.1515 - ETA: 58s - loss: 3.2830 - accuracy: 0.151 - ETA: 58s - loss: 3.2831 - accuracy: 0.151 - ETA: 57s - loss: 3.2830 - accuracy: 0.151 - ETA: 56s - loss: 3.2833 - accuracy: 0.151 - ETA: 55s - loss: 3.2820 - accuracy: 0.151 - ETA: 54s - loss: 3.2820 - accuracy: 0.151 - ETA: 54s - loss: 3.2810 - accuracy: 0.152 - ETA: 53s - loss: 3.2816 - accuracy: 0.151 - ETA: 52s - loss: 3.2816 - accuracy: 0.152 - ETA: 51s - loss: 3.2813 - accuracy: 0.152 - ETA: 50s - loss: 3.2802 - accuracy: 0.152 - ETA: 50s - loss: 3.2806 - accuracy: 0.152 - ETA: 49s - loss: 3.2804 - accuracy: 0.152 - ETA: 48s - loss: 3.2805 - accuracy: 0.152 - ETA: 47s - loss: 3.2810 - accuracy: 0.152 - ETA: 46s - loss: 3.2818 - accuracy: 0.152 - ETA: 46s - loss: 3.2816 - accuracy: 0.152 - ETA: 45s - loss: 3.2823 - accuracy: 0.152 - ETA: 44s - loss: 3.2822 - accuracy: 0.152 - ETA: 43s - loss: 3.2818 - accuracy: 0.152 - ETA: 42s - loss: 3.2811 - accuracy: 0.152 - ETA: 42s - loss: 3.2811 - accuracy: 0.152 - ETA: 41s - loss: 3.2807 - accuracy: 0.152 - ETA: 40s - loss: 3.2802 - accuracy: 0.152 - ETA: 39s - loss: 3.2807 - accuracy: 0.152 - ETA: 38s - loss: 3.2814 - accuracy: 0.152 - ETA: 37s - loss: 3.2812 - accuracy: 0.152 - ETA: 37s - loss: 3.2811 - accuracy: 0.152 - ETA: 36s - loss: 3.2808 - accuracy: 0.152 - ETA: 35s - loss: 3.2807 - accuracy: 0.152 - ETA: 34s - loss: 3.2804 - accuracy: 0.152 - ETA: 33s - loss: 3.2804 - accuracy: 0.152 - ETA: 33s - loss: 3.2802 - accuracy: 0.152 - ETA: 32s - loss: 3.2795 - accuracy: 0.152 - ETA: 31s - loss: 3.2794 - accuracy: 0.152 - ETA: 30s - loss: 3.2793 - accuracy: 0.152 - ETA: 29s - loss: 3.2795 - accuracy: 0.152 - ETA: 29s - loss: 3.2799 - accuracy: 0.152 - ETA: 28s - loss: 3.2794 - accuracy: 0.152 - ETA: 27s - loss: 3.2797 - accuracy: 0.152 - ETA: 26s - loss: 3.2800 - accuracy: 0.152 - ETA: 25s - loss: 3.2807 - accuracy: 0.152 - ETA: 25s - loss: 3.2812 - accuracy: 0.152 - ETA: 24s - loss: 3.2810 - accuracy: 0.152 - ETA: 23s - loss: 3.2815 - accuracy: 0.152 - ETA: 22s - loss: 3.2816 - accuracy: 0.152 - ETA: 21s - loss: 3.2815 - accuracy: 0.152 - ETA: 21s - loss: 3.2813 - accuracy: 0.152 - ETA: 20s - loss: 3.2815 - accuracy: 0.152 - ETA: 19s - loss: 3.2809 - accuracy: 0.152 - ETA: 18s - loss: 3.2808 - accuracy: 0.152 - ETA: 17s - loss: 3.2809 - accuracy: 0.152 - ETA: 16s - loss: 3.2806 - accuracy: 0.152 - ETA: 16s - loss: 3.2802 - accuracy: 0.152 - ETA: 15s - loss: 3.2804 - accuracy: 0.152 - ETA: 14s - loss: 3.2806 - accuracy: 0.152 - ETA: 13s - loss: 3.2809 - accuracy: 0.152 - ETA: 12s - loss: 3.2810 - accuracy: 0.152 - ETA: 12s - loss: 3.2824 - accuracy: 0.152 - ETA: 11s - loss: 3.2819 - accuracy: 0.152 - ETA: 10s - loss: 3.2817 - accuracy: 0.152 - ETA: 9s - loss: 3.2819 - accuracy: 0.152 - ETA: 8s - loss: 3.2817 - accuracy: 0.15 - ETA: 8s - loss: 3.2817 - accuracy: 0.15 - ETA: 7s - loss: 3.2819 - accuracy: 0.15 - ETA: 6s - loss: 3.2820 - accuracy: 0.15 - ETA: 5s - loss: 3.2820 - accuracy: 0.15 - ETA: 4s - loss: 3.2822 - accuracy: 0.15 - ETA: 4s - loss: 3.2822 - accuracy: 0.15 - ETA: 3s - loss: 3.2821 - accuracy: 0.15 - ETA: 2s - loss: 3.2819 - accuracy: 0.15 - ETA: 1s - loss: 3.2819 - accuracy: 0.15 - ETA: 0s - loss: 3.2817 - accuracy: 0.15 - ETA: 0s - loss: 3.2818 - accuracy: 0.15 - 282s 7ms/step - loss: 3.2819 - accuracy: 0.1521 - val_loss: 4.0030 - val_accuracy: 0.0169\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:35 - loss: 3.4732 - accuracy: 0.10 - ETA: 4:34 - loss: 3.3485 - accuracy: 0.14 - ETA: 4:31 - loss: 3.3160 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3360 - accuracy: 0.13 - ETA: 4:19 - loss: 3.2858 - accuracy: 0.14 - ETA: 4:16 - loss: 3.2780 - accuracy: 0.14 - ETA: 4:13 - loss: 3.2800 - accuracy: 0.14 - ETA: 4:12 - loss: 3.2942 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3097 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3104 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3167 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3349 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3266 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3361 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3362 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3404 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3359 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3363 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3357 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3363 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3266 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3234 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3178 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3210 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3306 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3274 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3266 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3252 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3245 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3211 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3189 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3138 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3130 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3153 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3130 - accuracy: 0.15 - ETA: 3:52 - loss: 3.3083 - accuracy: 0.15 - ETA: 3:50 - loss: 3.3053 - accuracy: 0.15 - ETA: 3:49 - loss: 3.3044 - accuracy: 0.15 - ETA: 3:48 - loss: 3.3034 - accuracy: 0.15 - ETA: 3:48 - loss: 3.3058 - accuracy: 0.15 - ETA: 3:47 - loss: 3.3056 - accuracy: 0.15 - ETA: 3:46 - loss: 3.3005 - accuracy: 0.15 - ETA: 3:45 - loss: 3.2955 - accuracy: 0.15 - ETA: 3:44 - loss: 3.2925 - accuracy: 0.15 - ETA: 3:43 - loss: 3.2927 - accuracy: 0.15 - ETA: 3:42 - loss: 3.2924 - accuracy: 0.15 - ETA: 3:41 - loss: 3.2903 - accuracy: 0.15 - ETA: 3:40 - loss: 3.2869 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2855 - accuracy: 0.15 - ETA: 3:39 - loss: 3.2885 - accuracy: 0.15 - ETA: 3:38 - loss: 3.2906 - accuracy: 0.15 - ETA: 3:37 - loss: 3.2931 - accuracy: 0.15 - ETA: 3:36 - loss: 3.2939 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2929 - accuracy: 0.15 - ETA: 3:35 - loss: 3.2917 - accuracy: 0.15 - ETA: 3:34 - loss: 3.2925 - accuracy: 0.15 - ETA: 3:33 - loss: 3.2913 - accuracy: 0.15 - ETA: 3:32 - loss: 3.2892 - accuracy: 0.15 - ETA: 3:31 - loss: 3.2901 - accuracy: 0.15 - ETA: 3:30 - loss: 3.2933 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2927 - accuracy: 0.15 - ETA: 3:29 - loss: 3.2920 - accuracy: 0.15 - ETA: 3:28 - loss: 3.2912 - accuracy: 0.15 - ETA: 3:27 - loss: 3.2943 - accuracy: 0.15 - ETA: 3:26 - loss: 3.2934 - accuracy: 0.15 - ETA: 3:25 - loss: 3.2947 - accuracy: 0.15 - ETA: 3:24 - loss: 3.2906 - accuracy: 0.15 - ETA: 3:23 - loss: 3.2875 - accuracy: 0.15 - ETA: 3:22 - loss: 3.2854 - accuracy: 0.15 - ETA: 3:21 - loss: 3.2859 - accuracy: 0.15 - ETA: 3:20 - loss: 3.2849 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2828 - accuracy: 0.15 - ETA: 3:19 - loss: 3.2836 - accuracy: 0.15 - ETA: 3:18 - loss: 3.2868 - accuracy: 0.15 - ETA: 3:17 - loss: 3.2853 - accuracy: 0.15 - ETA: 3:16 - loss: 3.2859 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2868 - accuracy: 0.15 - ETA: 3:14 - loss: 3.2864 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2851 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2863 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2869 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2864 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2865 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2838 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2867 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2859 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2876 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2880 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2882 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2879 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2895 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2882 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2863 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2871 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2881 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2872 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2889 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2873 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2868 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2873 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2881 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2879 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2885 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2900 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2918 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2929 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2928 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2922 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2918 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2930 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2928 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2933 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2937 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2935 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2940 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2949 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2946 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2943 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2947 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2966 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2961 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2961 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2953 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2942 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2936 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2943 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2951 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2953 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2939 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2924 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2930 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2933 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2933 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2934 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2946 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2941 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2945 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2942 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2927 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2926 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2925 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2929 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2922 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2923 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2929 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2913 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2908 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2907 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2907 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2912 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2898 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2913 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2902 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2900 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2908 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2913 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2901 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2903 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2911 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2901 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2892 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2889 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2881 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2885 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2881 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2882 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2890 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2885 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2882 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2886 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2880 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2886 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2878 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2878 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2875 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2864 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2856 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2867 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2881 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2876 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2878 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2878 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2869 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2870 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2867 - accuracy: 0.1511"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:48 - loss: 3.2867 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2865 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2872 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2872 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2874 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2867 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2864 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2865 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2868 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2864 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2866 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2865 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2862 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2850 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2853 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2850 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2858 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2862 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2859 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2854 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2851 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2852 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2849 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2836 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2839 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2836 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2838 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2843 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2848 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2859 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2851 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2859 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2857 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2854 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2854 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2851 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2849 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2839 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2841 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2835 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2822 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2824 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2815 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2822 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2824 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2825 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2826 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2822 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2823 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2821 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2821 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2821 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2807 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2802 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2806 - accuracy: 0.15 - ETA: 59s - loss: 3.2800 - accuracy: 0.1504 - ETA: 58s - loss: 3.2793 - accuracy: 0.150 - ETA: 58s - loss: 3.2789 - accuracy: 0.150 - ETA: 57s - loss: 3.2789 - accuracy: 0.150 - ETA: 56s - loss: 3.2780 - accuracy: 0.150 - ETA: 55s - loss: 3.2775 - accuracy: 0.151 - ETA: 55s - loss: 3.2775 - accuracy: 0.151 - ETA: 54s - loss: 3.2780 - accuracy: 0.151 - ETA: 53s - loss: 3.2775 - accuracy: 0.151 - ETA: 52s - loss: 3.2776 - accuracy: 0.151 - ETA: 52s - loss: 3.2768 - accuracy: 0.151 - ETA: 51s - loss: 3.2772 - accuracy: 0.151 - ETA: 50s - loss: 3.2763 - accuracy: 0.151 - ETA: 49s - loss: 3.2762 - accuracy: 0.151 - ETA: 49s - loss: 3.2757 - accuracy: 0.151 - ETA: 48s - loss: 3.2754 - accuracy: 0.151 - ETA: 47s - loss: 3.2749 - accuracy: 0.151 - ETA: 46s - loss: 3.2741 - accuracy: 0.151 - ETA: 46s - loss: 3.2737 - accuracy: 0.151 - ETA: 45s - loss: 3.2736 - accuracy: 0.151 - ETA: 44s - loss: 3.2732 - accuracy: 0.151 - ETA: 43s - loss: 3.2738 - accuracy: 0.151 - ETA: 43s - loss: 3.2732 - accuracy: 0.151 - ETA: 42s - loss: 3.2736 - accuracy: 0.151 - ETA: 41s - loss: 3.2734 - accuracy: 0.151 - ETA: 40s - loss: 3.2734 - accuracy: 0.151 - ETA: 39s - loss: 3.2727 - accuracy: 0.151 - ETA: 39s - loss: 3.2724 - accuracy: 0.151 - ETA: 38s - loss: 3.2723 - accuracy: 0.151 - ETA: 37s - loss: 3.2721 - accuracy: 0.151 - ETA: 36s - loss: 3.2728 - accuracy: 0.151 - ETA: 36s - loss: 3.2724 - accuracy: 0.151 - ETA: 35s - loss: 3.2724 - accuracy: 0.151 - ETA: 34s - loss: 3.2723 - accuracy: 0.151 - ETA: 33s - loss: 3.2719 - accuracy: 0.151 - ETA: 33s - loss: 3.2714 - accuracy: 0.151 - ETA: 32s - loss: 3.2714 - accuracy: 0.151 - ETA: 31s - loss: 3.2723 - accuracy: 0.151 - ETA: 30s - loss: 3.2720 - accuracy: 0.152 - ETA: 30s - loss: 3.2724 - accuracy: 0.151 - ETA: 29s - loss: 3.2724 - accuracy: 0.151 - ETA: 28s - loss: 3.2726 - accuracy: 0.151 - ETA: 28s - loss: 3.2714 - accuracy: 0.152 - ETA: 27s - loss: 3.2708 - accuracy: 0.152 - ETA: 26s - loss: 3.2709 - accuracy: 0.152 - ETA: 25s - loss: 3.2712 - accuracy: 0.152 - ETA: 25s - loss: 3.2721 - accuracy: 0.152 - ETA: 24s - loss: 3.2725 - accuracy: 0.151 - ETA: 23s - loss: 3.2726 - accuracy: 0.151 - ETA: 22s - loss: 3.2727 - accuracy: 0.151 - ETA: 22s - loss: 3.2727 - accuracy: 0.151 - ETA: 21s - loss: 3.2729 - accuracy: 0.151 - ETA: 20s - loss: 3.2724 - accuracy: 0.152 - ETA: 19s - loss: 3.2723 - accuracy: 0.152 - ETA: 19s - loss: 3.2725 - accuracy: 0.151 - ETA: 18s - loss: 3.2721 - accuracy: 0.152 - ETA: 17s - loss: 3.2721 - accuracy: 0.152 - ETA: 16s - loss: 3.2724 - accuracy: 0.152 - ETA: 16s - loss: 3.2723 - accuracy: 0.152 - ETA: 15s - loss: 3.2728 - accuracy: 0.152 - ETA: 14s - loss: 3.2729 - accuracy: 0.152 - ETA: 13s - loss: 3.2725 - accuracy: 0.152 - ETA: 13s - loss: 3.2728 - accuracy: 0.152 - ETA: 12s - loss: 3.2722 - accuracy: 0.152 - ETA: 11s - loss: 3.2724 - accuracy: 0.152 - ETA: 11s - loss: 3.2725 - accuracy: 0.152 - ETA: 10s - loss: 3.2721 - accuracy: 0.152 - ETA: 9s - loss: 3.2715 - accuracy: 0.152 - ETA: 8s - loss: 3.2712 - accuracy: 0.15 - ETA: 8s - loss: 3.2706 - accuracy: 0.15 - ETA: 7s - loss: 3.2702 - accuracy: 0.15 - ETA: 6s - loss: 3.2701 - accuracy: 0.15 - ETA: 5s - loss: 3.2702 - accuracy: 0.15 - ETA: 5s - loss: 3.2706 - accuracy: 0.15 - ETA: 4s - loss: 3.2711 - accuracy: 0.15 - ETA: 3s - loss: 3.2712 - accuracy: 0.15 - ETA: 2s - loss: 3.2711 - accuracy: 0.15 - ETA: 2s - loss: 3.2711 - accuracy: 0.15 - ETA: 1s - loss: 3.2712 - accuracy: 0.15 - ETA: 0s - loss: 3.2710 - accuracy: 0.15 - ETA: 0s - loss: 3.2709 - accuracy: 0.15 - 256s 6ms/step - loss: 3.2709 - accuracy: 0.1526 - val_loss: 3.9973 - val_accuracy: 0.0150\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:01 - loss: 3.2387 - accuracy: 0.20 - ETA: 3:52 - loss: 3.2967 - accuracy: 0.17 - ETA: 3:44 - loss: 3.2126 - accuracy: 0.17 - ETA: 3:41 - loss: 3.2198 - accuracy: 0.17 - ETA: 3:39 - loss: 3.2445 - accuracy: 0.16 - ETA: 3:37 - loss: 3.2369 - accuracy: 0.17 - ETA: 3:36 - loss: 3.2215 - accuracy: 0.17 - ETA: 3:35 - loss: 3.2243 - accuracy: 0.17 - ETA: 3:34 - loss: 3.3352 - accuracy: 0.17 - ETA: 3:34 - loss: 3.3239 - accuracy: 0.17 - ETA: 3:34 - loss: 3.3426 - accuracy: 0.16 - ETA: 3:34 - loss: 3.3387 - accuracy: 0.16 - ETA: 3:33 - loss: 3.3519 - accuracy: 0.16 - ETA: 3:32 - loss: 3.3435 - accuracy: 0.16 - ETA: 3:31 - loss: 3.3296 - accuracy: 0.16 - ETA: 3:32 - loss: 3.3334 - accuracy: 0.15 - ETA: 3:31 - loss: 3.3287 - accuracy: 0.15 - ETA: 3:30 - loss: 3.3246 - accuracy: 0.15 - ETA: 3:29 - loss: 3.3265 - accuracy: 0.15 - ETA: 3:28 - loss: 3.3142 - accuracy: 0.15 - ETA: 3:27 - loss: 3.3230 - accuracy: 0.15 - ETA: 3:28 - loss: 3.3264 - accuracy: 0.15 - ETA: 3:27 - loss: 3.3242 - accuracy: 0.15 - ETA: 3:27 - loss: 3.3241 - accuracy: 0.15 - ETA: 3:27 - loss: 3.3276 - accuracy: 0.15 - ETA: 3:25 - loss: 3.3296 - accuracy: 0.14 - ETA: 3:25 - loss: 3.3306 - accuracy: 0.14 - ETA: 3:24 - loss: 3.3254 - accuracy: 0.15 - ETA: 3:23 - loss: 3.3311 - accuracy: 0.14 - ETA: 3:23 - loss: 3.3288 - accuracy: 0.14 - ETA: 3:22 - loss: 3.3274 - accuracy: 0.14 - ETA: 3:21 - loss: 3.3236 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3198 - accuracy: 0.15 - ETA: 3:20 - loss: 3.3255 - accuracy: 0.14 - ETA: 3:19 - loss: 3.3281 - accuracy: 0.14 - ETA: 3:18 - loss: 3.3326 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3346 - accuracy: 0.14 - ETA: 3:16 - loss: 3.3352 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3341 - accuracy: 0.14 - ETA: 3:15 - loss: 3.3319 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3322 - accuracy: 0.14 - ETA: 3:14 - loss: 3.3346 - accuracy: 0.14 - ETA: 3:13 - loss: 3.3333 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3313 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3326 - accuracy: 0.14 - ETA: 3:11 - loss: 3.3337 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3366 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3358 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3341 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3352 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3396 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3381 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3384 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3396 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3421 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3389 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3414 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3453 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3447 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3441 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3429 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3425 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3434 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3424 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3431 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3426 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3408 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3397 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3393 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3402 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3393 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3387 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3394 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3404 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3420 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3419 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3402 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3379 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3373 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3368 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3378 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3375 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3362 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3379 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3391 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3376 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3371 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3381 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3382 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3369 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3361 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3360 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3355 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3340 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3338 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3341 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3339 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3322 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3326 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3340 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3342 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3336 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3333 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3333 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3330 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3339 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3310 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3301 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3287 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3275 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3278 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3300 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3279 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3270 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3269 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3269 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3269 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3268 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3269 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3270 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3281 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3274 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3275 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3292 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3301 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3296 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3297 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3296 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3291 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3294 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3297 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3286 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3308 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3305 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3323 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3327 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3327 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3334 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3330 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3331 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3329 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3322 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3325 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3333 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3328 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3333 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3328 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3340 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3356 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3347 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3338 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3330 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3339 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3346 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3342 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3336 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3342 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3349 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3347 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3337 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3330 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3329 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3338 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3337 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3342 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3335 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3333 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3332 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3328 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3333 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3330 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3335 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3351 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3343 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3345 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3350 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3335 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3334 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3331 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3332 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3321 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3322 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3319 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3321 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3321 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3328 - accuracy: 0.1421"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:36 - loss: 3.3329 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3320 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3323 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3319 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3319 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3322 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3313 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3319 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3328 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3328 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3325 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3316 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3312 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3312 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3307 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3308 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3311 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3306 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3308 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3299 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3293 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3288 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3281 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3283 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3280 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3278 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3270 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3269 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3271 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3271 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3272 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3270 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3271 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3269 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3271 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3265 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3271 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3269 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3266 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3273 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3275 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3275 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3272 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3279 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3281 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3280 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3277 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3275 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3268 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3278 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3275 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3272 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3267 - accuracy: 0.14 - ETA: 59s - loss: 3.3261 - accuracy: 0.1444 - ETA: 58s - loss: 3.3255 - accuracy: 0.144 - ETA: 58s - loss: 3.3254 - accuracy: 0.144 - ETA: 57s - loss: 3.3249 - accuracy: 0.144 - ETA: 56s - loss: 3.3244 - accuracy: 0.144 - ETA: 56s - loss: 3.3242 - accuracy: 0.144 - ETA: 55s - loss: 3.3248 - accuracy: 0.144 - ETA: 54s - loss: 3.3250 - accuracy: 0.144 - ETA: 54s - loss: 3.3242 - accuracy: 0.144 - ETA: 53s - loss: 3.3235 - accuracy: 0.145 - ETA: 52s - loss: 3.3230 - accuracy: 0.145 - ETA: 52s - loss: 3.3226 - accuracy: 0.145 - ETA: 51s - loss: 3.3228 - accuracy: 0.145 - ETA: 50s - loss: 3.3224 - accuracy: 0.145 - ETA: 50s - loss: 3.3222 - accuracy: 0.145 - ETA: 49s - loss: 3.3213 - accuracy: 0.145 - ETA: 48s - loss: 3.3210 - accuracy: 0.145 - ETA: 48s - loss: 3.3202 - accuracy: 0.145 - ETA: 47s - loss: 3.3196 - accuracy: 0.145 - ETA: 46s - loss: 3.3189 - accuracy: 0.146 - ETA: 46s - loss: 3.3186 - accuracy: 0.146 - ETA: 45s - loss: 3.3189 - accuracy: 0.145 - ETA: 44s - loss: 3.3191 - accuracy: 0.145 - ETA: 44s - loss: 3.3188 - accuracy: 0.145 - ETA: 43s - loss: 3.3181 - accuracy: 0.146 - ETA: 42s - loss: 3.3180 - accuracy: 0.146 - ETA: 42s - loss: 3.3182 - accuracy: 0.146 - ETA: 41s - loss: 3.3185 - accuracy: 0.146 - ETA: 40s - loss: 3.3183 - accuracy: 0.146 - ETA: 40s - loss: 3.3178 - accuracy: 0.146 - ETA: 39s - loss: 3.3176 - accuracy: 0.146 - ETA: 38s - loss: 3.3177 - accuracy: 0.146 - ETA: 38s - loss: 3.3175 - accuracy: 0.146 - ETA: 37s - loss: 3.3169 - accuracy: 0.146 - ETA: 36s - loss: 3.3170 - accuracy: 0.146 - ETA: 36s - loss: 3.3165 - accuracy: 0.146 - ETA: 35s - loss: 3.3154 - accuracy: 0.146 - ETA: 34s - loss: 3.3153 - accuracy: 0.146 - ETA: 34s - loss: 3.3152 - accuracy: 0.146 - ETA: 33s - loss: 3.3156 - accuracy: 0.146 - ETA: 32s - loss: 3.3151 - accuracy: 0.146 - ETA: 32s - loss: 3.3152 - accuracy: 0.146 - ETA: 31s - loss: 3.3152 - accuracy: 0.146 - ETA: 30s - loss: 3.3151 - accuracy: 0.146 - ETA: 30s - loss: 3.3149 - accuracy: 0.146 - ETA: 29s - loss: 3.3147 - accuracy: 0.146 - ETA: 28s - loss: 3.3146 - accuracy: 0.146 - ETA: 28s - loss: 3.3142 - accuracy: 0.146 - ETA: 27s - loss: 3.3144 - accuracy: 0.146 - ETA: 26s - loss: 3.3142 - accuracy: 0.146 - ETA: 26s - loss: 3.3137 - accuracy: 0.146 - ETA: 25s - loss: 3.3127 - accuracy: 0.147 - ETA: 24s - loss: 3.3131 - accuracy: 0.146 - ETA: 24s - loss: 3.3131 - accuracy: 0.146 - ETA: 23s - loss: 3.3133 - accuracy: 0.146 - ETA: 23s - loss: 3.3130 - accuracy: 0.146 - ETA: 22s - loss: 3.3126 - accuracy: 0.146 - ETA: 21s - loss: 3.3132 - accuracy: 0.146 - ETA: 21s - loss: 3.3128 - accuracy: 0.146 - ETA: 20s - loss: 3.3128 - accuracy: 0.146 - ETA: 19s - loss: 3.3122 - accuracy: 0.146 - ETA: 19s - loss: 3.3121 - accuracy: 0.146 - ETA: 18s - loss: 3.3116 - accuracy: 0.146 - ETA: 17s - loss: 3.3114 - accuracy: 0.146 - ETA: 17s - loss: 3.3108 - accuracy: 0.146 - ETA: 16s - loss: 3.3106 - accuracy: 0.146 - ETA: 15s - loss: 3.3106 - accuracy: 0.146 - ETA: 15s - loss: 3.3104 - accuracy: 0.146 - ETA: 14s - loss: 3.3118 - accuracy: 0.146 - ETA: 14s - loss: 3.3115 - accuracy: 0.146 - ETA: 13s - loss: 3.3118 - accuracy: 0.146 - ETA: 12s - loss: 3.3121 - accuracy: 0.146 - ETA: 12s - loss: 3.3119 - accuracy: 0.146 - ETA: 11s - loss: 3.3120 - accuracy: 0.146 - ETA: 10s - loss: 3.3112 - accuracy: 0.146 - ETA: 10s - loss: 3.3114 - accuracy: 0.146 - ETA: 9s - loss: 3.3113 - accuracy: 0.147 - ETA: 8s - loss: 3.3107 - accuracy: 0.14 - ETA: 8s - loss: 3.3104 - accuracy: 0.14 - ETA: 7s - loss: 3.3099 - accuracy: 0.14 - ETA: 7s - loss: 3.3092 - accuracy: 0.14 - ETA: 6s - loss: 3.3092 - accuracy: 0.14 - ETA: 5s - loss: 3.3086 - accuracy: 0.14 - ETA: 5s - loss: 3.3080 - accuracy: 0.14 - ETA: 4s - loss: 3.3075 - accuracy: 0.14 - ETA: 3s - loss: 3.3068 - accuracy: 0.14 - ETA: 3s - loss: 3.3068 - accuracy: 0.14 - ETA: 2s - loss: 3.3063 - accuracy: 0.14 - ETA: 1s - loss: 3.3060 - accuracy: 0.14 - ETA: 1s - loss: 3.3059 - accuracy: 0.14 - ETA: 0s - loss: 3.3059 - accuracy: 0.14 - ETA: 0s - loss: 3.3054 - accuracy: 0.14 - 221s 5ms/step - loss: 3.3054 - accuracy: 0.1483 - val_loss: 3.9684 - val_accuracy: 0.0137\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:22 - loss: 3.2097 - accuracy: 0.16 - ETA: 3:14 - loss: 3.3125 - accuracy: 0.15 - ETA: 3:15 - loss: 3.2397 - accuracy: 0.15 - ETA: 3:17 - loss: 3.3015 - accuracy: 0.13 - ETA: 3:15 - loss: 3.2712 - accuracy: 0.14 - ETA: 3:13 - loss: 3.2605 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2771 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2825 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3008 - accuracy: 0.14 - ETA: 3:06 - loss: 3.2867 - accuracy: 0.15 - ETA: 3:05 - loss: 3.3022 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2966 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3175 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3230 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3198 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3152 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3155 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3049 - accuracy: 0.13 - ETA: 2:57 - loss: 3.2933 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2875 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2863 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2843 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2916 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2858 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2865 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2916 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2883 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2889 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2935 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2960 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3032 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3011 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3002 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3033 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3039 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3076 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3085 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3072 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3053 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3058 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3118 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3089 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3091 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3066 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3066 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3101 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3107 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3096 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3089 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3093 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3100 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3090 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3069 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3067 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3059 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3066 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3070 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3074 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3061 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3041 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3064 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3068 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3088 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3086 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3082 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3101 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3099 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3089 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3062 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3086 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3098 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3107 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3111 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3123 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3104 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3083 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3070 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3088 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3119 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3142 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3126 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3124 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3126 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3122 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3131 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3129 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3122 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3101 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3095 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3075 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3090 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3098 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3115 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3118 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3161 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3155 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3167 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3179 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3174 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3172 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3179 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3191 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3187 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3218 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3232 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3240 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3237 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3237 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3252 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3247 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3246 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3246 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3246 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3254 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3241 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3228 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3236 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3256 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3259 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3244 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3242 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3263 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3265 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3284 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3285 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3300 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3291 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3290 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3301 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3295 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3304 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3314 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3312 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3311 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3305 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3303 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3297 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3286 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3297 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3293 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3303 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3307 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3305 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3307 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3308 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3305 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3304 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3303 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3294 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3286 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3275 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3275 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3283 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3270 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3271 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3274 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3278 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3274 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3270 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3270 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3279 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3275 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3268 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3264 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3261 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3251 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3256 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3245 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3246 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3230 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3225 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3212 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3211 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3201 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3191 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3182 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3179 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3167 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3157 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3162 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3157 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3140 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3131 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3145 - accuracy: 0.1463"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:22 - loss: 3.3140 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3145 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3151 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3151 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3142 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3149 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3141 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3142 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3130 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3113 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3103 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3114 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3114 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3110 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3100 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3092 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3084 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3089 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3097 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3088 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3082 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3067 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3066 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3056 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3052 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3047 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3035 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3028 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3033 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3031 - accuracy: 0.14 - ETA: 59s - loss: 3.3048 - accuracy: 0.1484 - ETA: 59s - loss: 3.3050 - accuracy: 0.148 - ETA: 58s - loss: 3.3052 - accuracy: 0.148 - ETA: 58s - loss: 3.3051 - accuracy: 0.147 - ETA: 57s - loss: 3.3057 - accuracy: 0.147 - ETA: 57s - loss: 3.3049 - accuracy: 0.148 - ETA: 56s - loss: 3.3046 - accuracy: 0.148 - ETA: 55s - loss: 3.3038 - accuracy: 0.148 - ETA: 55s - loss: 3.3044 - accuracy: 0.148 - ETA: 54s - loss: 3.3038 - accuracy: 0.148 - ETA: 54s - loss: 3.3042 - accuracy: 0.148 - ETA: 53s - loss: 3.3043 - accuracy: 0.148 - ETA: 53s - loss: 3.3044 - accuracy: 0.148 - ETA: 52s - loss: 3.3040 - accuracy: 0.148 - ETA: 51s - loss: 3.3034 - accuracy: 0.148 - ETA: 51s - loss: 3.3032 - accuracy: 0.148 - ETA: 50s - loss: 3.3038 - accuracy: 0.148 - ETA: 50s - loss: 3.3037 - accuracy: 0.148 - ETA: 49s - loss: 3.3044 - accuracy: 0.147 - ETA: 48s - loss: 3.3045 - accuracy: 0.147 - ETA: 48s - loss: 3.3040 - accuracy: 0.147 - ETA: 47s - loss: 3.3037 - accuracy: 0.147 - ETA: 47s - loss: 3.3036 - accuracy: 0.147 - ETA: 46s - loss: 3.3038 - accuracy: 0.147 - ETA: 46s - loss: 3.3034 - accuracy: 0.147 - ETA: 45s - loss: 3.3041 - accuracy: 0.147 - ETA: 44s - loss: 3.3037 - accuracy: 0.147 - ETA: 44s - loss: 3.3029 - accuracy: 0.147 - ETA: 43s - loss: 3.3021 - accuracy: 0.148 - ETA: 43s - loss: 3.3018 - accuracy: 0.148 - ETA: 42s - loss: 3.3017 - accuracy: 0.148 - ETA: 42s - loss: 3.3016 - accuracy: 0.148 - ETA: 41s - loss: 3.3014 - accuracy: 0.148 - ETA: 40s - loss: 3.3015 - accuracy: 0.148 - ETA: 40s - loss: 3.3013 - accuracy: 0.148 - ETA: 39s - loss: 3.3008 - accuracy: 0.148 - ETA: 39s - loss: 3.3002 - accuracy: 0.148 - ETA: 38s - loss: 3.3000 - accuracy: 0.148 - ETA: 37s - loss: 3.2993 - accuracy: 0.148 - ETA: 37s - loss: 3.2995 - accuracy: 0.148 - ETA: 36s - loss: 3.2995 - accuracy: 0.148 - ETA: 36s - loss: 3.2989 - accuracy: 0.148 - ETA: 35s - loss: 3.2987 - accuracy: 0.148 - ETA: 35s - loss: 3.2978 - accuracy: 0.148 - ETA: 34s - loss: 3.2987 - accuracy: 0.148 - ETA: 33s - loss: 3.2990 - accuracy: 0.148 - ETA: 33s - loss: 3.2988 - accuracy: 0.148 - ETA: 32s - loss: 3.2989 - accuracy: 0.148 - ETA: 32s - loss: 3.2985 - accuracy: 0.148 - ETA: 31s - loss: 3.2986 - accuracy: 0.148 - ETA: 31s - loss: 3.2986 - accuracy: 0.148 - ETA: 30s - loss: 3.2984 - accuracy: 0.148 - ETA: 29s - loss: 3.2974 - accuracy: 0.148 - ETA: 29s - loss: 3.2976 - accuracy: 0.148 - ETA: 28s - loss: 3.2976 - accuracy: 0.148 - ETA: 28s - loss: 3.2971 - accuracy: 0.148 - ETA: 27s - loss: 3.2971 - accuracy: 0.148 - ETA: 27s - loss: 3.2971 - accuracy: 0.148 - ETA: 26s - loss: 3.2968 - accuracy: 0.148 - ETA: 25s - loss: 3.2971 - accuracy: 0.148 - ETA: 25s - loss: 3.2968 - accuracy: 0.148 - ETA: 24s - loss: 3.2968 - accuracy: 0.148 - ETA: 24s - loss: 3.2965 - accuracy: 0.148 - ETA: 23s - loss: 3.2965 - accuracy: 0.148 - ETA: 23s - loss: 3.2966 - accuracy: 0.148 - ETA: 22s - loss: 3.2967 - accuracy: 0.148 - ETA: 21s - loss: 3.2961 - accuracy: 0.148 - ETA: 21s - loss: 3.2965 - accuracy: 0.148 - ETA: 20s - loss: 3.2962 - accuracy: 0.148 - ETA: 20s - loss: 3.2958 - accuracy: 0.148 - ETA: 19s - loss: 3.2953 - accuracy: 0.148 - ETA: 19s - loss: 3.2950 - accuracy: 0.148 - ETA: 18s - loss: 3.2950 - accuracy: 0.148 - ETA: 17s - loss: 3.2946 - accuracy: 0.148 - ETA: 17s - loss: 3.2946 - accuracy: 0.148 - ETA: 16s - loss: 3.2939 - accuracy: 0.148 - ETA: 16s - loss: 3.2944 - accuracy: 0.148 - ETA: 15s - loss: 3.2946 - accuracy: 0.148 - ETA: 14s - loss: 3.2943 - accuracy: 0.149 - ETA: 14s - loss: 3.2941 - accuracy: 0.149 - ETA: 13s - loss: 3.2946 - accuracy: 0.149 - ETA: 13s - loss: 3.2938 - accuracy: 0.149 - ETA: 12s - loss: 3.2931 - accuracy: 0.149 - ETA: 12s - loss: 3.2931 - accuracy: 0.149 - ETA: 11s - loss: 3.2932 - accuracy: 0.149 - ETA: 10s - loss: 3.2928 - accuracy: 0.149 - ETA: 10s - loss: 3.2926 - accuracy: 0.149 - ETA: 9s - loss: 3.2922 - accuracy: 0.149 - ETA: 9s - loss: 3.2923 - accuracy: 0.14 - ETA: 8s - loss: 3.2922 - accuracy: 0.14 - ETA: 8s - loss: 3.2922 - accuracy: 0.14 - ETA: 7s - loss: 3.2922 - accuracy: 0.14 - ETA: 6s - loss: 3.2921 - accuracy: 0.14 - ETA: 6s - loss: 3.2916 - accuracy: 0.14 - ETA: 5s - loss: 3.2916 - accuracy: 0.14 - ETA: 5s - loss: 3.2916 - accuracy: 0.14 - ETA: 4s - loss: 3.2908 - accuracy: 0.14 - ETA: 4s - loss: 3.2901 - accuracy: 0.15 - ETA: 3s - loss: 3.2900 - accuracy: 0.15 - ETA: 2s - loss: 3.2895 - accuracy: 0.15 - ETA: 2s - loss: 3.2893 - accuracy: 0.15 - ETA: 1s - loss: 3.2890 - accuracy: 0.15 - ETA: 1s - loss: 3.2890 - accuracy: 0.15 - ETA: 0s - loss: 3.2889 - accuracy: 0.15 - ETA: 0s - loss: 3.2891 - accuracy: 0.15 - 202s 5ms/step - loss: 3.2889 - accuracy: 0.1501 - val_loss: 3.9117 - val_accuracy: 0.0134\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:24 - loss: 3.2723 - accuracy: 0.10 - ETA: 3:12 - loss: 3.3982 - accuracy: 0.10 - ETA: 3:08 - loss: 3.3126 - accuracy: 0.11 - ETA: 3:08 - loss: 3.2901 - accuracy: 0.12 - ETA: 3:08 - loss: 3.3062 - accuracy: 0.12 - ETA: 3:11 - loss: 3.2942 - accuracy: 0.12 - ETA: 3:11 - loss: 3.2887 - accuracy: 0.12 - ETA: 3:10 - loss: 3.2898 - accuracy: 0.12 - ETA: 3:08 - loss: 3.2801 - accuracy: 0.12 - ETA: 3:07 - loss: 3.2755 - accuracy: 0.13 - ETA: 3:05 - loss: 3.2646 - accuracy: 0.13 - ETA: 3:04 - loss: 3.2723 - accuracy: 0.13 - ETA: 3:04 - loss: 3.2836 - accuracy: 0.13 - ETA: 3:05 - loss: 3.2674 - accuracy: 0.13 - ETA: 3:05 - loss: 3.2645 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2606 - accuracy: 0.14 - ETA: 3:02 - loss: 3.2643 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2664 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2735 - accuracy: 0.13 - ETA: 2:59 - loss: 3.2756 - accuracy: 0.13 - ETA: 2:58 - loss: 3.2706 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2699 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2715 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2752 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2778 - accuracy: 0.13 - ETA: 2:53 - loss: 3.2812 - accuracy: 0.13 - ETA: 2:53 - loss: 3.2798 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2755 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2676 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2669 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2663 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2646 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2632 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2586 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2555 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2568 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2501 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2527 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2529 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2497 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2511 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2509 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2499 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2470 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2464 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2516 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2529 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2519 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2501 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2507 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2477 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2491 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2469 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2461 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2450 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2470 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2471 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2470 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2467 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2466 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2503 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2518 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2532 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2512 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2504 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2516 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2525 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2553 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2562 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2580 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2561 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2567 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2570 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2557 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2552 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2540 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2529 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2524 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2544 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2562 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2562 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2582 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2569 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2574 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2585 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2603 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2597 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2586 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2602 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2608 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2588 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2580 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2568 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2575 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2595 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2593 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2604 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2619 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2647 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2664 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2654 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2667 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2681 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2698 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2686 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2691 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2688 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2699 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2705 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2709 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2719 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2737 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2738 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2740 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2745 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2744 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2730 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2734 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2743 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2753 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2762 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2763 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2754 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2768 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2774 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2781 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2794 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2804 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2817 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2813 - accuracy: 0.14 - ETA: 1:53 - loss: 3.2824 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2840 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2832 - accuracy: 0.14 - ETA: 1:51 - loss: 3.2816 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2810 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2815 - accuracy: 0.14 - ETA: 1:50 - loss: 3.2820 - accuracy: 0.14 - ETA: 1:49 - loss: 3.2822 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2818 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2833 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2854 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2862 - accuracy: 0.14 - ETA: 1:46 - loss: 3.2864 - accuracy: 0.14 - ETA: 1:46 - loss: 3.2853 - accuracy: 0.14 - ETA: 1:45 - loss: 3.2870 - accuracy: 0.14 - ETA: 1:45 - loss: 3.2863 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2856 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2860 - accuracy: 0.14 - ETA: 1:43 - loss: 3.2865 - accuracy: 0.14 - ETA: 1:42 - loss: 3.2878 - accuracy: 0.14 - ETA: 1:42 - loss: 3.2887 - accuracy: 0.14 - ETA: 1:41 - loss: 3.2892 - accuracy: 0.14 - ETA: 1:41 - loss: 3.2902 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2905 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2903 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2904 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2902 - accuracy: 0.14 - ETA: 1:38 - loss: 3.2891 - accuracy: 0.14 - ETA: 1:38 - loss: 3.2895 - accuracy: 0.14 - ETA: 1:37 - loss: 3.2896 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2889 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2883 - accuracy: 0.14 - ETA: 1:35 - loss: 3.2883 - accuracy: 0.14 - ETA: 1:35 - loss: 3.2884 - accuracy: 0.14 - ETA: 1:34 - loss: 3.2882 - accuracy: 0.14 - ETA: 1:33 - loss: 3.2880 - accuracy: 0.14 - ETA: 1:33 - loss: 3.2873 - accuracy: 0.14 - ETA: 1:32 - loss: 3.2881 - accuracy: 0.14 - ETA: 1:32 - loss: 3.2895 - accuracy: 0.14 - ETA: 1:31 - loss: 3.2900 - accuracy: 0.14 - ETA: 1:31 - loss: 3.2911 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2908 - accuracy: 0.14 - ETA: 1:29 - loss: 3.2901 - accuracy: 0.14 - ETA: 1:29 - loss: 3.2908 - accuracy: 0.14 - ETA: 1:28 - loss: 3.2901 - accuracy: 0.14 - ETA: 1:28 - loss: 3.2903 - accuracy: 0.14 - ETA: 1:27 - loss: 3.2899 - accuracy: 0.14 - ETA: 1:26 - loss: 3.2906 - accuracy: 0.14 - ETA: 1:26 - loss: 3.2905 - accuracy: 0.14 - ETA: 1:25 - loss: 3.2898 - accuracy: 0.14 - ETA: 1:25 - loss: 3.2899 - accuracy: 0.14 - ETA: 1:24 - loss: 3.2903 - accuracy: 0.14 - ETA: 1:24 - loss: 3.2907 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2907 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2901 - accuracy: 0.14 - ETA: 1:22 - loss: 3.2900 - accuracy: 0.1465"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.2901 - accuracy: 0.14 - ETA: 1:21 - loss: 3.2901 - accuracy: 0.14 - ETA: 1:20 - loss: 3.2894 - accuracy: 0.14 - ETA: 1:20 - loss: 3.2896 - accuracy: 0.14 - ETA: 1:19 - loss: 3.2889 - accuracy: 0.14 - ETA: 1:19 - loss: 3.2883 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2890 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2879 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2874 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2875 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2883 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2881 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2883 - accuracy: 0.14 - ETA: 1:14 - loss: 3.2883 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2886 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2873 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2873 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2873 - accuracy: 0.14 - ETA: 1:11 - loss: 3.2868 - accuracy: 0.14 - ETA: 1:10 - loss: 3.2865 - accuracy: 0.14 - ETA: 1:10 - loss: 3.2868 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2872 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2870 - accuracy: 0.14 - ETA: 1:08 - loss: 3.2868 - accuracy: 0.14 - ETA: 1:08 - loss: 3.2870 - accuracy: 0.14 - ETA: 1:07 - loss: 3.2873 - accuracy: 0.14 - ETA: 1:07 - loss: 3.2871 - accuracy: 0.14 - ETA: 1:06 - loss: 3.2873 - accuracy: 0.14 - ETA: 1:05 - loss: 3.2881 - accuracy: 0.14 - ETA: 1:05 - loss: 3.2872 - accuracy: 0.14 - ETA: 1:04 - loss: 3.2881 - accuracy: 0.14 - ETA: 1:04 - loss: 3.2882 - accuracy: 0.14 - ETA: 1:03 - loss: 3.2887 - accuracy: 0.14 - ETA: 1:03 - loss: 3.2891 - accuracy: 0.14 - ETA: 1:02 - loss: 3.2894 - accuracy: 0.14 - ETA: 1:01 - loss: 3.2890 - accuracy: 0.14 - ETA: 1:01 - loss: 3.2892 - accuracy: 0.14 - ETA: 1:00 - loss: 3.2888 - accuracy: 0.14 - ETA: 1:00 - loss: 3.2889 - accuracy: 0.14 - ETA: 59s - loss: 3.2891 - accuracy: 0.1462 - ETA: 59s - loss: 3.2904 - accuracy: 0.145 - ETA: 58s - loss: 3.2904 - accuracy: 0.145 - ETA: 57s - loss: 3.2912 - accuracy: 0.145 - ETA: 57s - loss: 3.2916 - accuracy: 0.145 - ETA: 56s - loss: 3.2916 - accuracy: 0.145 - ETA: 56s - loss: 3.2920 - accuracy: 0.145 - ETA: 55s - loss: 3.2923 - accuracy: 0.145 - ETA: 55s - loss: 3.2925 - accuracy: 0.145 - ETA: 54s - loss: 3.2928 - accuracy: 0.144 - ETA: 53s - loss: 3.2931 - accuracy: 0.144 - ETA: 53s - loss: 3.2935 - accuracy: 0.144 - ETA: 52s - loss: 3.2936 - accuracy: 0.144 - ETA: 52s - loss: 3.2942 - accuracy: 0.144 - ETA: 51s - loss: 3.2948 - accuracy: 0.144 - ETA: 51s - loss: 3.2947 - accuracy: 0.144 - ETA: 50s - loss: 3.2957 - accuracy: 0.144 - ETA: 49s - loss: 3.2960 - accuracy: 0.144 - ETA: 49s - loss: 3.2964 - accuracy: 0.143 - ETA: 48s - loss: 3.2967 - accuracy: 0.143 - ETA: 48s - loss: 3.2970 - accuracy: 0.143 - ETA: 47s - loss: 3.2976 - accuracy: 0.143 - ETA: 47s - loss: 3.2980 - accuracy: 0.143 - ETA: 46s - loss: 3.2984 - accuracy: 0.143 - ETA: 46s - loss: 3.2993 - accuracy: 0.143 - ETA: 45s - loss: 3.2998 - accuracy: 0.143 - ETA: 44s - loss: 3.3001 - accuracy: 0.143 - ETA: 44s - loss: 3.3008 - accuracy: 0.143 - ETA: 43s - loss: 3.3014 - accuracy: 0.142 - ETA: 43s - loss: 3.3015 - accuracy: 0.143 - ETA: 42s - loss: 3.3017 - accuracy: 0.143 - ETA: 42s - loss: 3.3021 - accuracy: 0.143 - ETA: 41s - loss: 3.3031 - accuracy: 0.142 - ETA: 40s - loss: 3.3039 - accuracy: 0.142 - ETA: 40s - loss: 3.3047 - accuracy: 0.142 - ETA: 39s - loss: 3.3053 - accuracy: 0.142 - ETA: 39s - loss: 3.3061 - accuracy: 0.142 - ETA: 38s - loss: 3.3064 - accuracy: 0.142 - ETA: 38s - loss: 3.3071 - accuracy: 0.142 - ETA: 37s - loss: 3.3075 - accuracy: 0.142 - ETA: 36s - loss: 3.3081 - accuracy: 0.142 - ETA: 36s - loss: 3.3084 - accuracy: 0.142 - ETA: 35s - loss: 3.3085 - accuracy: 0.142 - ETA: 35s - loss: 3.3091 - accuracy: 0.142 - ETA: 34s - loss: 3.3090 - accuracy: 0.142 - ETA: 34s - loss: 3.3099 - accuracy: 0.141 - ETA: 33s - loss: 3.3108 - accuracy: 0.141 - ETA: 32s - loss: 3.3106 - accuracy: 0.141 - ETA: 32s - loss: 3.3111 - accuracy: 0.141 - ETA: 31s - loss: 3.3119 - accuracy: 0.141 - ETA: 31s - loss: 3.3113 - accuracy: 0.141 - ETA: 30s - loss: 3.3115 - accuracy: 0.141 - ETA: 30s - loss: 3.3121 - accuracy: 0.141 - ETA: 29s - loss: 3.3124 - accuracy: 0.141 - ETA: 28s - loss: 3.3124 - accuracy: 0.141 - ETA: 28s - loss: 3.3133 - accuracy: 0.141 - ETA: 27s - loss: 3.3134 - accuracy: 0.141 - ETA: 27s - loss: 3.3138 - accuracy: 0.141 - ETA: 26s - loss: 3.3143 - accuracy: 0.141 - ETA: 26s - loss: 3.3148 - accuracy: 0.141 - ETA: 25s - loss: 3.3148 - accuracy: 0.140 - ETA: 25s - loss: 3.3147 - accuracy: 0.140 - ETA: 24s - loss: 3.3151 - accuracy: 0.140 - ETA: 23s - loss: 3.3152 - accuracy: 0.140 - ETA: 23s - loss: 3.3160 - accuracy: 0.140 - ETA: 22s - loss: 3.3167 - accuracy: 0.140 - ETA: 22s - loss: 3.3166 - accuracy: 0.140 - ETA: 21s - loss: 3.3172 - accuracy: 0.140 - ETA: 21s - loss: 3.3172 - accuracy: 0.140 - ETA: 20s - loss: 3.3173 - accuracy: 0.140 - ETA: 19s - loss: 3.3175 - accuracy: 0.140 - ETA: 19s - loss: 3.3179 - accuracy: 0.140 - ETA: 18s - loss: 3.3181 - accuracy: 0.140 - ETA: 18s - loss: 3.3181 - accuracy: 0.140 - ETA: 17s - loss: 3.3186 - accuracy: 0.140 - ETA: 17s - loss: 3.3183 - accuracy: 0.140 - ETA: 16s - loss: 3.3181 - accuracy: 0.140 - ETA: 15s - loss: 3.3185 - accuracy: 0.140 - ETA: 15s - loss: 3.3185 - accuracy: 0.140 - ETA: 14s - loss: 3.3182 - accuracy: 0.140 - ETA: 14s - loss: 3.3187 - accuracy: 0.140 - ETA: 13s - loss: 3.3190 - accuracy: 0.140 - ETA: 13s - loss: 3.3192 - accuracy: 0.140 - ETA: 12s - loss: 3.3196 - accuracy: 0.140 - ETA: 11s - loss: 3.3196 - accuracy: 0.140 - ETA: 11s - loss: 3.3199 - accuracy: 0.140 - ETA: 10s - loss: 3.3198 - accuracy: 0.140 - ETA: 10s - loss: 3.3201 - accuracy: 0.140 - ETA: 9s - loss: 3.3199 - accuracy: 0.140 - ETA: 9s - loss: 3.3200 - accuracy: 0.14 - ETA: 8s - loss: 3.3199 - accuracy: 0.14 - ETA: 7s - loss: 3.3197 - accuracy: 0.14 - ETA: 7s - loss: 3.3199 - accuracy: 0.14 - ETA: 6s - loss: 3.3197 - accuracy: 0.14 - ETA: 6s - loss: 3.3198 - accuracy: 0.14 - ETA: 5s - loss: 3.3206 - accuracy: 0.14 - ETA: 5s - loss: 3.3210 - accuracy: 0.14 - ETA: 4s - loss: 3.3214 - accuracy: 0.14 - ETA: 4s - loss: 3.3220 - accuracy: 0.13 - ETA: 3s - loss: 3.3228 - accuracy: 0.13 - ETA: 2s - loss: 3.3234 - accuracy: 0.13 - ETA: 2s - loss: 3.3233 - accuracy: 0.13 - ETA: 1s - loss: 3.3234 - accuracy: 0.13 - ETA: 1s - loss: 3.3236 - accuracy: 0.13 - ETA: 0s - loss: 3.3242 - accuracy: 0.13 - ETA: 0s - loss: 3.3248 - accuracy: 0.13 - 201s 5ms/step - loss: 3.3249 - accuracy: 0.1392 - val_loss: 4.0142 - val_accuracy: 0.0185\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:18 - loss: 3.3934 - accuracy: 0.14 - ETA: 3:08 - loss: 3.4075 - accuracy: 0.14 - ETA: 3:06 - loss: 3.4181 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3967 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3721 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3498 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3608 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3695 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3641 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3724 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3600 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3629 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3567 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3668 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3664 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3693 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3716 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3648 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3641 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3639 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3662 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3620 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3646 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3689 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3682 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3602 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3533 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3552 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3606 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3579 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3592 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3614 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3632 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3693 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3680 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3760 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3736 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3744 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3772 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3799 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3835 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3818 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3804 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3789 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3740 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3708 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3693 - accuracy: 0.13 - ETA: 2:43 - loss: 3.4212 - accuracy: 0.13 - ETA: 2:42 - loss: 3.4196 - accuracy: 0.13 - ETA: 2:42 - loss: 3.4172 - accuracy: 0.13 - ETA: 2:42 - loss: 3.4139 - accuracy: 0.13 - ETA: 2:41 - loss: 3.4120 - accuracy: 0.13 - ETA: 2:41 - loss: 3.4120 - accuracy: 0.13 - ETA: 2:41 - loss: 3.4097 - accuracy: 0.13 - ETA: 2:40 - loss: 3.4083 - accuracy: 0.13 - ETA: 2:40 - loss: 3.4034 - accuracy: 0.13 - ETA: 2:40 - loss: 3.4002 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3975 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3950 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3958 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3927 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3898 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3877 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3867 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3852 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3824 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3836 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3828 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3814 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3794 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3778 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3761 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3739 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3725 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3723 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3721 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3696 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3678 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3674 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3656 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3669 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3682 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3663 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3648 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3652 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3661 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3646 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3653 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3656 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3653 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3651 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3642 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3632 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3615 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3623 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3600 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3580 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3583 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3569 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3566 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3552 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3546 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3543 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3535 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3523 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3516 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3522 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3532 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3516 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3510 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3499 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3499 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3493 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3467 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3458 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3450 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3460 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3447 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3447 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3449 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3441 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3429 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3427 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3418 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3409 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3402 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3396 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3376 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3374 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3379 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3377 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3361 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3361 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3350 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3352 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3360 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3360 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3361 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3360 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3368 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3364 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3352 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3330 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3324 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3319 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3316 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3322 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3326 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3313 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3308 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3307 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3301 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3291 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3291 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3281 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3273 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3285 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3288 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3283 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3288 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3284 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3287 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3282 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3285 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3297 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3296 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3293 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3298 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3295 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3290 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3282 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3275 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3271 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3265 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3253 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3254 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3257 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3256 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3248 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3243 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3246 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3237 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3236 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3233 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3229 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3218 - accuracy: 0.1455"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:24 - loss: 3.3220 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3217 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3217 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3223 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3225 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3227 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3230 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3229 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3222 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3218 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3214 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3206 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3204 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3187 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3189 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3186 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3187 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3193 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3187 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3187 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3180 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3175 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3166 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3164 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3158 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3160 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3146 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3147 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3150 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3146 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3149 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3140 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3144 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3141 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3143 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3142 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3149 - accuracy: 0.14 - ETA: 59s - loss: 3.3154 - accuracy: 0.1465 - ETA: 59s - loss: 3.3153 - accuracy: 0.146 - ETA: 58s - loss: 3.3157 - accuracy: 0.146 - ETA: 58s - loss: 3.3151 - accuracy: 0.146 - ETA: 57s - loss: 3.3152 - accuracy: 0.146 - ETA: 56s - loss: 3.3151 - accuracy: 0.146 - ETA: 56s - loss: 3.3143 - accuracy: 0.146 - ETA: 55s - loss: 3.3141 - accuracy: 0.146 - ETA: 55s - loss: 3.3140 - accuracy: 0.146 - ETA: 54s - loss: 3.3140 - accuracy: 0.146 - ETA: 53s - loss: 3.3136 - accuracy: 0.146 - ETA: 53s - loss: 3.3135 - accuracy: 0.146 - ETA: 52s - loss: 3.3128 - accuracy: 0.147 - ETA: 52s - loss: 3.3126 - accuracy: 0.147 - ETA: 51s - loss: 3.3116 - accuracy: 0.147 - ETA: 50s - loss: 3.3122 - accuracy: 0.147 - ETA: 50s - loss: 3.3131 - accuracy: 0.146 - ETA: 49s - loss: 3.3131 - accuracy: 0.146 - ETA: 49s - loss: 3.3131 - accuracy: 0.146 - ETA: 48s - loss: 3.3127 - accuracy: 0.146 - ETA: 48s - loss: 3.3144 - accuracy: 0.146 - ETA: 47s - loss: 3.3145 - accuracy: 0.146 - ETA: 46s - loss: 3.3149 - accuracy: 0.146 - ETA: 46s - loss: 3.3158 - accuracy: 0.146 - ETA: 45s - loss: 3.3159 - accuracy: 0.146 - ETA: 45s - loss: 3.3158 - accuracy: 0.146 - ETA: 44s - loss: 3.3159 - accuracy: 0.146 - ETA: 44s - loss: 3.3159 - accuracy: 0.146 - ETA: 43s - loss: 3.3161 - accuracy: 0.146 - ETA: 42s - loss: 3.3155 - accuracy: 0.146 - ETA: 42s - loss: 3.3155 - accuracy: 0.146 - ETA: 41s - loss: 3.3153 - accuracy: 0.146 - ETA: 41s - loss: 3.3152 - accuracy: 0.146 - ETA: 40s - loss: 3.3152 - accuracy: 0.146 - ETA: 39s - loss: 3.3153 - accuracy: 0.146 - ETA: 39s - loss: 3.3152 - accuracy: 0.146 - ETA: 38s - loss: 3.3152 - accuracy: 0.146 - ETA: 38s - loss: 3.3150 - accuracy: 0.146 - ETA: 37s - loss: 3.3151 - accuracy: 0.145 - ETA: 37s - loss: 3.3152 - accuracy: 0.146 - ETA: 36s - loss: 3.3155 - accuracy: 0.145 - ETA: 35s - loss: 3.3156 - accuracy: 0.145 - ETA: 35s - loss: 3.3159 - accuracy: 0.145 - ETA: 34s - loss: 3.3156 - accuracy: 0.145 - ETA: 34s - loss: 3.3153 - accuracy: 0.145 - ETA: 33s - loss: 3.3155 - accuracy: 0.145 - ETA: 32s - loss: 3.3152 - accuracy: 0.145 - ETA: 32s - loss: 3.3153 - accuracy: 0.145 - ETA: 31s - loss: 3.3150 - accuracy: 0.145 - ETA: 31s - loss: 3.3144 - accuracy: 0.145 - ETA: 30s - loss: 3.3143 - accuracy: 0.145 - ETA: 30s - loss: 3.3144 - accuracy: 0.145 - ETA: 29s - loss: 3.3150 - accuracy: 0.145 - ETA: 28s - loss: 3.3150 - accuracy: 0.145 - ETA: 28s - loss: 3.3147 - accuracy: 0.145 - ETA: 27s - loss: 3.3148 - accuracy: 0.145 - ETA: 27s - loss: 3.3152 - accuracy: 0.145 - ETA: 26s - loss: 3.3145 - accuracy: 0.145 - ETA: 26s - loss: 3.3144 - accuracy: 0.145 - ETA: 25s - loss: 3.3136 - accuracy: 0.145 - ETA: 24s - loss: 3.3136 - accuracy: 0.145 - ETA: 24s - loss: 3.3137 - accuracy: 0.145 - ETA: 23s - loss: 3.3142 - accuracy: 0.145 - ETA: 23s - loss: 3.3135 - accuracy: 0.145 - ETA: 22s - loss: 3.3132 - accuracy: 0.145 - ETA: 21s - loss: 3.3134 - accuracy: 0.146 - ETA: 21s - loss: 3.3130 - accuracy: 0.146 - ETA: 20s - loss: 3.3133 - accuracy: 0.146 - ETA: 20s - loss: 3.3132 - accuracy: 0.146 - ETA: 19s - loss: 3.3130 - accuracy: 0.146 - ETA: 19s - loss: 3.3131 - accuracy: 0.146 - ETA: 18s - loss: 3.3132 - accuracy: 0.146 - ETA: 17s - loss: 3.3131 - accuracy: 0.146 - ETA: 17s - loss: 3.3131 - accuracy: 0.146 - ETA: 16s - loss: 3.3130 - accuracy: 0.146 - ETA: 16s - loss: 3.3133 - accuracy: 0.146 - ETA: 15s - loss: 3.3133 - accuracy: 0.146 - ETA: 15s - loss: 3.3133 - accuracy: 0.146 - ETA: 14s - loss: 3.3132 - accuracy: 0.146 - ETA: 14s - loss: 3.3129 - accuracy: 0.146 - ETA: 13s - loss: 3.3134 - accuracy: 0.146 - ETA: 12s - loss: 3.3131 - accuracy: 0.146 - ETA: 12s - loss: 3.3135 - accuracy: 0.146 - ETA: 11s - loss: 3.3125 - accuracy: 0.146 - ETA: 11s - loss: 3.3128 - accuracy: 0.146 - ETA: 10s - loss: 3.3127 - accuracy: 0.146 - ETA: 10s - loss: 3.3128 - accuracy: 0.146 - ETA: 9s - loss: 3.3133 - accuracy: 0.146 - ETA: 8s - loss: 3.3134 - accuracy: 0.14 - ETA: 8s - loss: 3.3140 - accuracy: 0.14 - ETA: 7s - loss: 3.3139 - accuracy: 0.14 - ETA: 7s - loss: 3.3137 - accuracy: 0.14 - ETA: 6s - loss: 3.3135 - accuracy: 0.14 - ETA: 6s - loss: 3.3133 - accuracy: 0.14 - ETA: 5s - loss: 3.3130 - accuracy: 0.14 - ETA: 4s - loss: 3.3132 - accuracy: 0.14 - ETA: 4s - loss: 3.3132 - accuracy: 0.14 - ETA: 3s - loss: 3.3130 - accuracy: 0.14 - ETA: 3s - loss: 3.3126 - accuracy: 0.14 - ETA: 2s - loss: 3.3123 - accuracy: 0.14 - ETA: 1s - loss: 3.3121 - accuracy: 0.14 - ETA: 1s - loss: 3.3119 - accuracy: 0.14 - ETA: 0s - loss: 3.3122 - accuracy: 0.14 - ETA: 0s - loss: 3.3121 - accuracy: 0.14 - 227s 5ms/step - loss: 3.3120 - accuracy: 0.1468 - val_loss: 4.0246 - val_accuracy: 0.0186\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:09 - loss: 3.3447 - accuracy: 0.16 - ETA: 4:59 - loss: 3.3275 - accuracy: 0.14 - ETA: 5:02 - loss: 3.3341 - accuracy: 0.13 - ETA: 5:09 - loss: 3.3362 - accuracy: 0.12 - ETA: 5:05 - loss: 3.3363 - accuracy: 0.12 - ETA: 5:05 - loss: 3.3298 - accuracy: 0.12 - ETA: 5:07 - loss: 3.3146 - accuracy: 0.12 - ETA: 5:04 - loss: 3.3237 - accuracy: 0.12 - ETA: 5:04 - loss: 3.3067 - accuracy: 0.12 - ETA: 5:06 - loss: 3.2949 - accuracy: 0.12 - ETA: 5:05 - loss: 3.2801 - accuracy: 0.13 - ETA: 5:02 - loss: 3.2803 - accuracy: 0.13 - ETA: 5:01 - loss: 3.2619 - accuracy: 0.14 - ETA: 4:59 - loss: 3.2602 - accuracy: 0.14 - ETA: 4:58 - loss: 3.2606 - accuracy: 0.14 - ETA: 4:57 - loss: 3.2608 - accuracy: 0.14 - ETA: 4:57 - loss: 3.2572 - accuracy: 0.14 - ETA: 4:57 - loss: 3.2484 - accuracy: 0.14 - ETA: 4:56 - loss: 3.2449 - accuracy: 0.14 - ETA: 4:54 - loss: 3.2441 - accuracy: 0.14 - ETA: 4:53 - loss: 3.2552 - accuracy: 0.14 - ETA: 4:52 - loss: 3.2579 - accuracy: 0.14 - ETA: 4:51 - loss: 3.2517 - accuracy: 0.14 - ETA: 4:50 - loss: 3.2596 - accuracy: 0.14 - ETA: 4:50 - loss: 3.2609 - accuracy: 0.14 - ETA: 4:49 - loss: 3.2578 - accuracy: 0.14 - ETA: 4:48 - loss: 3.2568 - accuracy: 0.14 - ETA: 4:48 - loss: 3.2571 - accuracy: 0.14 - ETA: 4:47 - loss: 3.2561 - accuracy: 0.15 - ETA: 4:46 - loss: 3.2560 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2569 - accuracy: 0.15 - ETA: 4:45 - loss: 3.2599 - accuracy: 0.15 - ETA: 4:44 - loss: 3.2638 - accuracy: 0.14 - ETA: 4:44 - loss: 3.2643 - accuracy: 0.14 - ETA: 4:43 - loss: 3.2616 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2610 - accuracy: 0.15 - ETA: 4:41 - loss: 3.2658 - accuracy: 0.15 - ETA: 4:39 - loss: 3.2700 - accuracy: 0.14 - ETA: 4:38 - loss: 3.2700 - accuracy: 0.14 - ETA: 4:37 - loss: 3.2713 - accuracy: 0.14 - ETA: 4:36 - loss: 3.2723 - accuracy: 0.15 - ETA: 4:36 - loss: 3.2705 - accuracy: 0.15 - ETA: 4:35 - loss: 3.2685 - accuracy: 0.15 - ETA: 4:34 - loss: 3.2703 - accuracy: 0.14 - ETA: 4:33 - loss: 3.2732 - accuracy: 0.14 - ETA: 4:32 - loss: 3.2731 - accuracy: 0.14 - ETA: 4:31 - loss: 3.2712 - accuracy: 0.14 - ETA: 4:29 - loss: 3.2673 - accuracy: 0.15 - ETA: 4:28 - loss: 3.2702 - accuracy: 0.14 - ETA: 4:27 - loss: 3.2685 - accuracy: 0.14 - ETA: 4:26 - loss: 3.2659 - accuracy: 0.15 - ETA: 4:26 - loss: 3.2666 - accuracy: 0.15 - ETA: 4:25 - loss: 3.2651 - accuracy: 0.15 - ETA: 4:24 - loss: 3.2653 - accuracy: 0.15 - ETA: 4:23 - loss: 3.2630 - accuracy: 0.15 - ETA: 4:23 - loss: 3.2660 - accuracy: 0.15 - ETA: 4:22 - loss: 3.2668 - accuracy: 0.15 - ETA: 4:21 - loss: 3.2684 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2693 - accuracy: 0.15 - ETA: 4:19 - loss: 3.2703 - accuracy: 0.15 - ETA: 4:18 - loss: 3.2732 - accuracy: 0.14 - ETA: 4:17 - loss: 3.2737 - accuracy: 0.14 - ETA: 4:16 - loss: 3.2712 - accuracy: 0.14 - ETA: 4:15 - loss: 3.2701 - accuracy: 0.14 - ETA: 4:14 - loss: 3.2703 - accuracy: 0.14 - ETA: 4:13 - loss: 3.2713 - accuracy: 0.14 - ETA: 4:12 - loss: 3.2719 - accuracy: 0.14 - ETA: 4:11 - loss: 3.2730 - accuracy: 0.14 - ETA: 4:10 - loss: 3.2739 - accuracy: 0.14 - ETA: 4:09 - loss: 3.2717 - accuracy: 0.14 - ETA: 4:08 - loss: 3.2712 - accuracy: 0.14 - ETA: 4:07 - loss: 3.2699 - accuracy: 0.14 - ETA: 4:07 - loss: 3.2692 - accuracy: 0.14 - ETA: 4:05 - loss: 3.2701 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2713 - accuracy: 0.14 - ETA: 4:04 - loss: 3.2726 - accuracy: 0.14 - ETA: 4:03 - loss: 3.2751 - accuracy: 0.14 - ETA: 4:02 - loss: 3.2751 - accuracy: 0.14 - ETA: 4:01 - loss: 3.2748 - accuracy: 0.14 - ETA: 4:00 - loss: 3.2755 - accuracy: 0.14 - ETA: 3:59 - loss: 3.2745 - accuracy: 0.14 - ETA: 3:58 - loss: 3.2756 - accuracy: 0.14 - ETA: 3:57 - loss: 3.2752 - accuracy: 0.14 - ETA: 3:56 - loss: 3.2790 - accuracy: 0.14 - ETA: 3:55 - loss: 3.2783 - accuracy: 0.14 - ETA: 3:54 - loss: 3.2758 - accuracy: 0.14 - ETA: 3:53 - loss: 3.2762 - accuracy: 0.14 - ETA: 3:52 - loss: 3.2770 - accuracy: 0.14 - ETA: 3:51 - loss: 3.2753 - accuracy: 0.14 - ETA: 3:50 - loss: 3.2746 - accuracy: 0.14 - ETA: 3:49 - loss: 3.2762 - accuracy: 0.14 - ETA: 3:48 - loss: 3.2772 - accuracy: 0.14 - ETA: 3:47 - loss: 3.2770 - accuracy: 0.14 - ETA: 3:46 - loss: 3.2770 - accuracy: 0.14 - ETA: 3:45 - loss: 3.2755 - accuracy: 0.14 - ETA: 3:44 - loss: 3.2749 - accuracy: 0.14 - ETA: 3:43 - loss: 3.2748 - accuracy: 0.14 - ETA: 3:42 - loss: 3.2756 - accuracy: 0.14 - ETA: 3:41 - loss: 3.2759 - accuracy: 0.14 - ETA: 3:41 - loss: 3.2759 - accuracy: 0.14 - ETA: 3:39 - loss: 3.2757 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2767 - accuracy: 0.14 - ETA: 3:38 - loss: 3.2749 - accuracy: 0.14 - ETA: 3:37 - loss: 3.2740 - accuracy: 0.14 - ETA: 3:36 - loss: 3.2740 - accuracy: 0.14 - ETA: 3:35 - loss: 3.2739 - accuracy: 0.14 - ETA: 3:34 - loss: 3.2735 - accuracy: 0.14 - ETA: 3:33 - loss: 3.2752 - accuracy: 0.14 - ETA: 3:32 - loss: 3.2765 - accuracy: 0.14 - ETA: 3:31 - loss: 3.2749 - accuracy: 0.14 - ETA: 3:30 - loss: 3.2756 - accuracy: 0.14 - ETA: 3:29 - loss: 3.2751 - accuracy: 0.14 - ETA: 3:28 - loss: 3.2758 - accuracy: 0.14 - ETA: 3:27 - loss: 3.2758 - accuracy: 0.14 - ETA: 3:26 - loss: 3.2761 - accuracy: 0.14 - ETA: 3:25 - loss: 3.2751 - accuracy: 0.14 - ETA: 3:24 - loss: 3.2756 - accuracy: 0.14 - ETA: 3:23 - loss: 3.2763 - accuracy: 0.14 - ETA: 3:22 - loss: 3.2757 - accuracy: 0.14 - ETA: 3:22 - loss: 3.2758 - accuracy: 0.14 - ETA: 3:21 - loss: 3.2757 - accuracy: 0.14 - ETA: 3:20 - loss: 3.2753 - accuracy: 0.14 - ETA: 3:19 - loss: 3.2733 - accuracy: 0.14 - ETA: 3:18 - loss: 3.2697 - accuracy: 0.14 - ETA: 3:17 - loss: 3.2707 - accuracy: 0.14 - ETA: 3:16 - loss: 3.2693 - accuracy: 0.14 - ETA: 3:15 - loss: 3.2693 - accuracy: 0.14 - ETA: 3:14 - loss: 3.2680 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2678 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2686 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2687 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2680 - accuracy: 0.15 - ETA: 3:09 - loss: 3.2678 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2687 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2699 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2695 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2753 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2746 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2740 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2732 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2715 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2711 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2707 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2702 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2694 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2696 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2687 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2694 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2695 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2706 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2701 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2695 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2710 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2701 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2699 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2703 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2709 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2711 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2712 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2723 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2724 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2731 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2729 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2730 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2738 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2735 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2747 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2753 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2760 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2767 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2777 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2785 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2785 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2784 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2793 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2796 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2809 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2809 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2811 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2809 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2819 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2818 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2823 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2817 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2821 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2828 - accuracy: 0.1499"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.2825 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2818 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2819 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2820 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2828 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2851 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2863 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2877 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2896 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2900 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2902 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2902 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2901 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2899 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2892 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2895 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2901 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2893 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2890 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2888 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2884 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2891 - accuracy: 0.14 - ETA: 1:53 - loss: 3.2891 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2894 - accuracy: 0.14 - ETA: 1:50 - loss: 3.2899 - accuracy: 0.14 - ETA: 1:49 - loss: 3.2898 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2901 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2908 - accuracy: 0.14 - ETA: 1:46 - loss: 3.2913 - accuracy: 0.14 - ETA: 1:45 - loss: 3.2918 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2925 - accuracy: 0.14 - ETA: 1:43 - loss: 3.2929 - accuracy: 0.14 - ETA: 1:42 - loss: 3.2939 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2947 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2950 - accuracy: 0.14 - ETA: 1:38 - loss: 3.2951 - accuracy: 0.14 - ETA: 1:37 - loss: 3.2949 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2958 - accuracy: 0.14 - ETA: 1:35 - loss: 3.2968 - accuracy: 0.14 - ETA: 1:34 - loss: 3.2972 - accuracy: 0.14 - ETA: 1:33 - loss: 3.2977 - accuracy: 0.14 - ETA: 1:32 - loss: 3.2978 - accuracy: 0.14 - ETA: 1:31 - loss: 3.2982 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2990 - accuracy: 0.14 - ETA: 1:29 - loss: 3.2986 - accuracy: 0.14 - ETA: 1:28 - loss: 3.2995 - accuracy: 0.14 - ETA: 1:27 - loss: 3.2998 - accuracy: 0.14 - ETA: 1:26 - loss: 3.2997 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3002 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3007 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3005 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3005 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3008 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3007 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3010 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3012 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3017 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3015 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3015 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3014 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3010 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3010 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3012 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3016 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3008 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3010 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3013 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3009 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3012 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3013 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3014 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3012 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3022 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3027 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3017 - accuracy: 0.14 - ETA: 59s - loss: 3.3018 - accuracy: 0.1469 - ETA: 58s - loss: 3.3022 - accuracy: 0.146 - ETA: 57s - loss: 3.3014 - accuracy: 0.147 - ETA: 56s - loss: 3.3017 - accuracy: 0.147 - ETA: 55s - loss: 3.3018 - accuracy: 0.147 - ETA: 54s - loss: 3.3023 - accuracy: 0.146 - ETA: 53s - loss: 3.3019 - accuracy: 0.147 - ETA: 52s - loss: 3.3021 - accuracy: 0.146 - ETA: 51s - loss: 3.3016 - accuracy: 0.147 - ETA: 50s - loss: 3.3010 - accuracy: 0.147 - ETA: 49s - loss: 3.3014 - accuracy: 0.147 - ETA: 48s - loss: 3.3014 - accuracy: 0.147 - ETA: 48s - loss: 3.3013 - accuracy: 0.147 - ETA: 47s - loss: 3.3005 - accuracy: 0.147 - ETA: 46s - loss: 3.3003 - accuracy: 0.147 - ETA: 45s - loss: 3.3005 - accuracy: 0.147 - ETA: 44s - loss: 3.3009 - accuracy: 0.147 - ETA: 43s - loss: 3.3008 - accuracy: 0.147 - ETA: 42s - loss: 3.3012 - accuracy: 0.147 - ETA: 41s - loss: 3.3007 - accuracy: 0.147 - ETA: 40s - loss: 3.3009 - accuracy: 0.147 - ETA: 40s - loss: 3.3006 - accuracy: 0.147 - ETA: 39s - loss: 3.3010 - accuracy: 0.147 - ETA: 38s - loss: 3.3038 - accuracy: 0.147 - ETA: 37s - loss: 3.3035 - accuracy: 0.147 - ETA: 36s - loss: 3.3036 - accuracy: 0.147 - ETA: 35s - loss: 3.3037 - accuracy: 0.147 - ETA: 34s - loss: 3.3034 - accuracy: 0.147 - ETA: 33s - loss: 3.3035 - accuracy: 0.147 - ETA: 33s - loss: 3.3032 - accuracy: 0.147 - ETA: 32s - loss: 3.3030 - accuracy: 0.147 - ETA: 31s - loss: 3.3035 - accuracy: 0.147 - ETA: 30s - loss: 3.3033 - accuracy: 0.147 - ETA: 29s - loss: 3.3036 - accuracy: 0.147 - ETA: 28s - loss: 3.3032 - accuracy: 0.147 - ETA: 27s - loss: 3.3037 - accuracy: 0.147 - ETA: 27s - loss: 3.3040 - accuracy: 0.147 - ETA: 26s - loss: 3.3037 - accuracy: 0.147 - ETA: 25s - loss: 3.3038 - accuracy: 0.147 - ETA: 24s - loss: 3.3041 - accuracy: 0.147 - ETA: 23s - loss: 3.3040 - accuracy: 0.147 - ETA: 22s - loss: 3.3045 - accuracy: 0.147 - ETA: 22s - loss: 3.3046 - accuracy: 0.147 - ETA: 21s - loss: 3.3046 - accuracy: 0.146 - ETA: 20s - loss: 3.3047 - accuracy: 0.146 - ETA: 19s - loss: 3.3046 - accuracy: 0.146 - ETA: 18s - loss: 3.3043 - accuracy: 0.147 - ETA: 17s - loss: 3.3049 - accuracy: 0.146 - ETA: 17s - loss: 3.3054 - accuracy: 0.146 - ETA: 16s - loss: 3.3056 - accuracy: 0.146 - ETA: 15s - loss: 3.3052 - accuracy: 0.146 - ETA: 14s - loss: 3.3048 - accuracy: 0.146 - ETA: 13s - loss: 3.3049 - accuracy: 0.146 - ETA: 12s - loss: 3.3052 - accuracy: 0.146 - ETA: 12s - loss: 3.3052 - accuracy: 0.146 - ETA: 11s - loss: 3.3051 - accuracy: 0.146 - ETA: 10s - loss: 3.3050 - accuracy: 0.146 - ETA: 9s - loss: 3.3048 - accuracy: 0.146 - ETA: 8s - loss: 3.3046 - accuracy: 0.14 - ETA: 8s - loss: 3.3048 - accuracy: 0.14 - ETA: 7s - loss: 3.3044 - accuracy: 0.14 - ETA: 6s - loss: 3.3042 - accuracy: 0.14 - ETA: 5s - loss: 3.3041 - accuracy: 0.14 - ETA: 4s - loss: 3.3048 - accuracy: 0.14 - ETA: 4s - loss: 3.3039 - accuracy: 0.14 - ETA: 3s - loss: 3.3039 - accuracy: 0.14 - ETA: 2s - loss: 3.3038 - accuracy: 0.14 - ETA: 1s - loss: 3.3035 - accuracy: 0.14 - ETA: 0s - loss: 3.3032 - accuracy: 0.14 - ETA: 0s - loss: 3.3034 - accuracy: 0.14 - 276s 7ms/step - loss: 3.3034 - accuracy: 0.1470 - val_loss: 3.9269 - val_accuracy: 0.0150\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:15 - loss: 3.3743 - accuracy: 0.12 - ETA: 3:09 - loss: 3.2995 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3318 - accuracy: 0.11 - ETA: 3:02 - loss: 3.3296 - accuracy: 0.12 - ETA: 3:02 - loss: 3.2965 - accuracy: 0.12 - ETA: 3:02 - loss: 3.2824 - accuracy: 0.13 - ETA: 3:02 - loss: 3.2837 - accuracy: 0.13 - ETA: 3:03 - loss: 3.2909 - accuracy: 0.13 - ETA: 3:02 - loss: 3.2972 - accuracy: 0.13 - ETA: 3:01 - loss: 3.2963 - accuracy: 0.13 - ETA: 3:00 - loss: 3.2988 - accuracy: 0.13 - ETA: 2:59 - loss: 3.2947 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2907 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2804 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2682 - accuracy: 0.14 - ETA: 3:00 - loss: 3.2680 - accuracy: 0.14 - ETA: 2:59 - loss: 3.2694 - accuracy: 0.14 - ETA: 2:58 - loss: 3.2621 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2522 - accuracy: 0.14 - ETA: 2:57 - loss: 3.2523 - accuracy: 0.14 - ETA: 2:56 - loss: 3.2609 - accuracy: 0.14 - ETA: 2:55 - loss: 3.2617 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2731 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2763 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2732 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2668 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2666 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2604 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2627 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2643 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2677 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2717 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2766 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2748 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2703 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2759 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2804 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2825 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2845 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2858 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2823 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2834 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2890 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2912 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2906 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2896 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2899 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2880 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2886 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2891 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2917 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2923 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2922 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2929 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2944 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2985 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2988 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2958 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2945 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2957 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2950 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2955 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2976 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2983 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3001 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3002 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3019 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3013 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3017 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3025 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3013 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3012 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3018 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3012 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3020 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3003 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3005 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3008 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3007 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2990 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2984 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3010 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3011 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3013 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3006 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3000 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3009 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3010 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3001 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3010 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2996 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2989 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2974 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2969 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2953 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2967 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2942 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2949 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2945 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2934 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2944 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2924 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2924 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2919 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2924 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2913 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2905 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2905 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2895 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2906 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2899 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2889 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2885 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2893 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2893 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2892 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2881 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2880 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2875 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2866 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2858 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2855 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2853 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2858 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2865 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2857 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2863 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2848 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2836 - accuracy: 0.14 - ETA: 1:53 - loss: 3.2826 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2833 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2846 - accuracy: 0.14 - ETA: 1:51 - loss: 3.2838 - accuracy: 0.14 - ETA: 1:51 - loss: 3.2822 - accuracy: 0.14 - ETA: 1:50 - loss: 3.2816 - accuracy: 0.14 - ETA: 1:50 - loss: 3.2822 - accuracy: 0.14 - ETA: 1:49 - loss: 3.2825 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2831 - accuracy: 0.14 - ETA: 1:48 - loss: 3.2834 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2847 - accuracy: 0.14 - ETA: 1:47 - loss: 3.2850 - accuracy: 0.14 - ETA: 1:46 - loss: 3.2857 - accuracy: 0.14 - ETA: 1:45 - loss: 3.2866 - accuracy: 0.14 - ETA: 1:45 - loss: 3.2863 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2863 - accuracy: 0.14 - ETA: 1:44 - loss: 3.2873 - accuracy: 0.14 - ETA: 1:43 - loss: 3.2872 - accuracy: 0.14 - ETA: 1:43 - loss: 3.2863 - accuracy: 0.14 - ETA: 1:42 - loss: 3.2863 - accuracy: 0.14 - ETA: 1:41 - loss: 3.2857 - accuracy: 0.14 - ETA: 1:41 - loss: 3.2853 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2854 - accuracy: 0.14 - ETA: 1:40 - loss: 3.2840 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2834 - accuracy: 0.14 - ETA: 1:39 - loss: 3.2825 - accuracy: 0.14 - ETA: 1:38 - loss: 3.2829 - accuracy: 0.14 - ETA: 1:37 - loss: 3.2836 - accuracy: 0.14 - ETA: 1:37 - loss: 3.2830 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2830 - accuracy: 0.14 - ETA: 1:36 - loss: 3.2839 - accuracy: 0.14 - ETA: 1:35 - loss: 3.2849 - accuracy: 0.14 - ETA: 1:35 - loss: 3.2846 - accuracy: 0.14 - ETA: 1:34 - loss: 3.2858 - accuracy: 0.14 - ETA: 1:33 - loss: 3.2865 - accuracy: 0.14 - ETA: 1:33 - loss: 3.2867 - accuracy: 0.14 - ETA: 1:32 - loss: 3.2866 - accuracy: 0.14 - ETA: 1:32 - loss: 3.2870 - accuracy: 0.14 - ETA: 1:31 - loss: 3.2880 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2880 - accuracy: 0.14 - ETA: 1:30 - loss: 3.2885 - accuracy: 0.14 - ETA: 1:29 - loss: 3.2881 - accuracy: 0.14 - ETA: 1:29 - loss: 3.2876 - accuracy: 0.14 - ETA: 1:28 - loss: 3.2878 - accuracy: 0.14 - ETA: 1:28 - loss: 3.2878 - accuracy: 0.14 - ETA: 1:27 - loss: 3.2886 - accuracy: 0.14 - ETA: 1:27 - loss: 3.2887 - accuracy: 0.14 - ETA: 1:26 - loss: 3.2886 - accuracy: 0.14 - ETA: 1:25 - loss: 3.2881 - accuracy: 0.14 - ETA: 1:25 - loss: 3.2873 - accuracy: 0.14 - ETA: 1:24 - loss: 3.2875 - accuracy: 0.14 - ETA: 1:24 - loss: 3.2881 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2888 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2895 - accuracy: 0.14 - ETA: 1:22 - loss: 3.2898 - accuracy: 0.1444"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:22 - loss: 3.2909 - accuracy: 0.14 - ETA: 1:21 - loss: 3.2921 - accuracy: 0.14 - ETA: 1:20 - loss: 3.2930 - accuracy: 0.14 - ETA: 1:20 - loss: 3.2938 - accuracy: 0.14 - ETA: 1:19 - loss: 3.2951 - accuracy: 0.14 - ETA: 1:19 - loss: 3.2952 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2967 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2970 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2971 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2981 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2987 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2996 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2997 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3004 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3012 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3013 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3017 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3018 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3028 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3030 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3029 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3034 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3044 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3042 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3040 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3032 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3042 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3039 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3049 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3055 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3062 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3066 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3066 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3071 - accuracy: 0.14 - ETA: 59s - loss: 3.3066 - accuracy: 0.1431 - ETA: 59s - loss: 3.3067 - accuracy: 0.143 - ETA: 58s - loss: 3.3061 - accuracy: 0.143 - ETA: 58s - loss: 3.3066 - accuracy: 0.143 - ETA: 57s - loss: 3.3072 - accuracy: 0.143 - ETA: 56s - loss: 3.3076 - accuracy: 0.143 - ETA: 56s - loss: 3.3084 - accuracy: 0.143 - ETA: 55s - loss: 3.3083 - accuracy: 0.142 - ETA: 55s - loss: 3.3090 - accuracy: 0.142 - ETA: 54s - loss: 3.3093 - accuracy: 0.142 - ETA: 54s - loss: 3.3096 - accuracy: 0.142 - ETA: 53s - loss: 3.3103 - accuracy: 0.142 - ETA: 52s - loss: 3.3107 - accuracy: 0.142 - ETA: 52s - loss: 3.3118 - accuracy: 0.142 - ETA: 51s - loss: 3.3131 - accuracy: 0.142 - ETA: 51s - loss: 3.3138 - accuracy: 0.142 - ETA: 50s - loss: 3.3140 - accuracy: 0.142 - ETA: 50s - loss: 3.3139 - accuracy: 0.142 - ETA: 49s - loss: 3.3143 - accuracy: 0.142 - ETA: 48s - loss: 3.3150 - accuracy: 0.141 - ETA: 48s - loss: 3.3156 - accuracy: 0.141 - ETA: 47s - loss: 3.3164 - accuracy: 0.141 - ETA: 47s - loss: 3.3172 - accuracy: 0.141 - ETA: 46s - loss: 3.3180 - accuracy: 0.141 - ETA: 46s - loss: 3.3189 - accuracy: 0.141 - ETA: 45s - loss: 3.3195 - accuracy: 0.140 - ETA: 44s - loss: 3.3205 - accuracy: 0.140 - ETA: 44s - loss: 3.3216 - accuracy: 0.140 - ETA: 43s - loss: 3.3225 - accuracy: 0.140 - ETA: 43s - loss: 3.3235 - accuracy: 0.140 - ETA: 42s - loss: 3.3242 - accuracy: 0.140 - ETA: 42s - loss: 3.3249 - accuracy: 0.139 - ETA: 41s - loss: 3.3253 - accuracy: 0.139 - ETA: 40s - loss: 3.3257 - accuracy: 0.140 - ETA: 40s - loss: 3.3262 - accuracy: 0.139 - ETA: 39s - loss: 3.3266 - accuracy: 0.139 - ETA: 39s - loss: 3.3278 - accuracy: 0.139 - ETA: 38s - loss: 3.3286 - accuracy: 0.139 - ETA: 38s - loss: 3.3291 - accuracy: 0.139 - ETA: 37s - loss: 3.3298 - accuracy: 0.139 - ETA: 36s - loss: 3.3306 - accuracy: 0.139 - ETA: 36s - loss: 3.3313 - accuracy: 0.139 - ETA: 35s - loss: 3.3316 - accuracy: 0.139 - ETA: 35s - loss: 3.3315 - accuracy: 0.139 - ETA: 34s - loss: 3.3315 - accuracy: 0.139 - ETA: 34s - loss: 3.3321 - accuracy: 0.139 - ETA: 33s - loss: 3.3324 - accuracy: 0.138 - ETA: 32s - loss: 3.3325 - accuracy: 0.138 - ETA: 32s - loss: 3.3334 - accuracy: 0.138 - ETA: 31s - loss: 3.3328 - accuracy: 0.138 - ETA: 31s - loss: 3.3335 - accuracy: 0.138 - ETA: 30s - loss: 3.3337 - accuracy: 0.138 - ETA: 30s - loss: 3.3341 - accuracy: 0.138 - ETA: 29s - loss: 3.3343 - accuracy: 0.138 - ETA: 28s - loss: 3.3343 - accuracy: 0.138 - ETA: 28s - loss: 3.3346 - accuracy: 0.138 - ETA: 27s - loss: 3.3349 - accuracy: 0.138 - ETA: 27s - loss: 3.3347 - accuracy: 0.138 - ETA: 26s - loss: 3.3358 - accuracy: 0.138 - ETA: 26s - loss: 3.3360 - accuracy: 0.138 - ETA: 25s - loss: 3.3363 - accuracy: 0.138 - ETA: 25s - loss: 3.3372 - accuracy: 0.138 - ETA: 24s - loss: 3.3376 - accuracy: 0.138 - ETA: 23s - loss: 3.3382 - accuracy: 0.137 - ETA: 23s - loss: 3.3379 - accuracy: 0.138 - ETA: 22s - loss: 3.3382 - accuracy: 0.137 - ETA: 22s - loss: 3.3386 - accuracy: 0.137 - ETA: 21s - loss: 3.3385 - accuracy: 0.137 - ETA: 21s - loss: 3.3385 - accuracy: 0.137 - ETA: 20s - loss: 3.3390 - accuracy: 0.137 - ETA: 19s - loss: 3.3394 - accuracy: 0.137 - ETA: 19s - loss: 3.3397 - accuracy: 0.137 - ETA: 18s - loss: 3.3399 - accuracy: 0.137 - ETA: 18s - loss: 3.3405 - accuracy: 0.137 - ETA: 17s - loss: 3.3406 - accuracy: 0.137 - ETA: 17s - loss: 3.3405 - accuracy: 0.137 - ETA: 16s - loss: 3.3404 - accuracy: 0.137 - ETA: 15s - loss: 3.3406 - accuracy: 0.137 - ETA: 15s - loss: 3.3401 - accuracy: 0.137 - ETA: 14s - loss: 3.3394 - accuracy: 0.137 - ETA: 14s - loss: 3.3397 - accuracy: 0.137 - ETA: 13s - loss: 3.3393 - accuracy: 0.137 - ETA: 13s - loss: 3.3397 - accuracy: 0.137 - ETA: 12s - loss: 3.3398 - accuracy: 0.137 - ETA: 11s - loss: 3.3401 - accuracy: 0.137 - ETA: 11s - loss: 3.3408 - accuracy: 0.137 - ETA: 10s - loss: 3.3409 - accuracy: 0.137 - ETA: 10s - loss: 3.3416 - accuracy: 0.137 - ETA: 9s - loss: 3.3424 - accuracy: 0.137 - ETA: 9s - loss: 3.3429 - accuracy: 0.13 - ETA: 8s - loss: 3.3430 - accuracy: 0.13 - ETA: 7s - loss: 3.3429 - accuracy: 0.13 - ETA: 7s - loss: 3.3434 - accuracy: 0.13 - ETA: 6s - loss: 3.3435 - accuracy: 0.13 - ETA: 6s - loss: 3.3438 - accuracy: 0.13 - ETA: 5s - loss: 3.3437 - accuracy: 0.13 - ETA: 5s - loss: 3.3439 - accuracy: 0.13 - ETA: 4s - loss: 3.3437 - accuracy: 0.13 - ETA: 4s - loss: 3.3441 - accuracy: 0.13 - ETA: 3s - loss: 3.3447 - accuracy: 0.13 - ETA: 2s - loss: 3.3451 - accuracy: 0.13 - ETA: 2s - loss: 3.3449 - accuracy: 0.13 - ETA: 1s - loss: 3.3448 - accuracy: 0.13 - ETA: 1s - loss: 3.3451 - accuracy: 0.13 - ETA: 0s - loss: 3.3450 - accuracy: 0.13 - ETA: 0s - loss: 3.3449 - accuracy: 0.13 - 200s 5ms/step - loss: 3.3449 - accuracy: 0.1373 - val_loss: 4.0716 - val_accuracy: 0.0151\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:25 - loss: 3.2507 - accuracy: 0.20 - ETA: 3:12 - loss: 3.3297 - accuracy: 0.18 - ETA: 3:08 - loss: 3.2803 - accuracy: 0.19 - ETA: 3:05 - loss: 3.3093 - accuracy: 0.17 - ETA: 3:04 - loss: 3.3098 - accuracy: 0.16 - ETA: 3:04 - loss: 3.3298 - accuracy: 0.15 - ETA: 3:03 - loss: 3.3380 - accuracy: 0.15 - ETA: 3:02 - loss: 3.3274 - accuracy: 0.15 - ETA: 3:01 - loss: 3.3178 - accuracy: 0.15 - ETA: 3:00 - loss: 3.3294 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3282 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3268 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3446 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3377 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3344 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3350 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3294 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3283 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3315 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3348 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3398 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3351 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3269 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3142 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3236 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3239 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3279 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3262 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3204 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3178 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3173 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3195 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3223 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3199 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3187 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3212 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3226 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3222 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3160 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3114 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3131 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3131 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3175 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3188 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3203 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3214 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3206 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3202 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3183 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3145 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3188 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3185 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3192 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3198 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3187 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3211 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3219 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3226 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3187 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3198 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3228 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3262 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3315 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3316 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3336 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3314 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3331 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3348 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3361 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3368 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3355 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3369 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3360 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3361 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3374 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3395 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3402 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3405 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3404 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3426 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3426 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3452 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3455 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3466 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3463 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3454 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3457 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3474 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3470 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3478 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3476 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3486 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3492 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3509 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3532 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3539 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3541 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3540 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3542 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3535 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3710 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3710 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3712 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3705 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3704 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3713 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3710 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3696 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3698 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3715 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3712 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3695 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3692 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3690 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3673 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3664 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3671 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3664 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3659 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3649 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3638 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3623 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3608 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3601 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3596 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3593 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3594 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3601 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3610 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3591 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3563 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3569 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3568 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3555 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3539 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3529 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3537 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3532 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3525 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3516 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3520 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3512 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3510 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3514 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3508 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3506 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3506 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3505 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3498 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3498 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3502 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3501 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3502 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3489 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3484 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3499 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3500 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3495 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3499 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3506 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3506 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3498 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3495 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3488 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3479 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3480 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3476 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3469 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3476 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3473 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3470 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3460 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3464 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3460 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3455 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3441 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3444 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3442 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3431 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3424 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3418 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3412 - accuracy: 0.1447"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:22 - loss: 3.3429 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3441 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3446 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3436 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3456 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3459 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3466 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3471 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3471 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3470 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3468 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3466 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3462 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3460 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3470 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3476 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3480 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3475 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3474 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3474 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3475 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3481 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3483 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3466 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3465 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3466 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3463 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3463 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3461 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3470 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3470 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3474 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3475 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3473 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3469 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3466 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3468 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3462 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3454 - accuracy: 0.14 - ETA: 59s - loss: 3.3454 - accuracy: 0.1428 - ETA: 59s - loss: 3.3446 - accuracy: 0.142 - ETA: 58s - loss: 3.3437 - accuracy: 0.142 - ETA: 58s - loss: 3.3441 - accuracy: 0.142 - ETA: 57s - loss: 3.3429 - accuracy: 0.143 - ETA: 56s - loss: 3.3428 - accuracy: 0.143 - ETA: 56s - loss: 3.3432 - accuracy: 0.143 - ETA: 55s - loss: 3.3417 - accuracy: 0.143 - ETA: 55s - loss: 3.3418 - accuracy: 0.143 - ETA: 54s - loss: 3.3408 - accuracy: 0.143 - ETA: 54s - loss: 3.3407 - accuracy: 0.143 - ETA: 53s - loss: 3.3410 - accuracy: 0.143 - ETA: 52s - loss: 3.3412 - accuracy: 0.143 - ETA: 52s - loss: 3.3412 - accuracy: 0.143 - ETA: 51s - loss: 3.3410 - accuracy: 0.143 - ETA: 51s - loss: 3.3407 - accuracy: 0.143 - ETA: 50s - loss: 3.3398 - accuracy: 0.143 - ETA: 50s - loss: 3.3392 - accuracy: 0.143 - ETA: 49s - loss: 3.3389 - accuracy: 0.143 - ETA: 48s - loss: 3.3390 - accuracy: 0.143 - ETA: 48s - loss: 3.3391 - accuracy: 0.143 - ETA: 47s - loss: 3.3388 - accuracy: 0.144 - ETA: 47s - loss: 3.3378 - accuracy: 0.144 - ETA: 46s - loss: 3.3382 - accuracy: 0.144 - ETA: 46s - loss: 3.3376 - accuracy: 0.144 - ETA: 45s - loss: 3.3372 - accuracy: 0.144 - ETA: 44s - loss: 3.3364 - accuracy: 0.144 - ETA: 44s - loss: 3.3361 - accuracy: 0.144 - ETA: 43s - loss: 3.3354 - accuracy: 0.144 - ETA: 43s - loss: 3.3355 - accuracy: 0.144 - ETA: 42s - loss: 3.3352 - accuracy: 0.144 - ETA: 42s - loss: 3.3351 - accuracy: 0.144 - ETA: 41s - loss: 3.3356 - accuracy: 0.144 - ETA: 40s - loss: 3.3359 - accuracy: 0.144 - ETA: 40s - loss: 3.3362 - accuracy: 0.143 - ETA: 39s - loss: 3.3362 - accuracy: 0.143 - ETA: 39s - loss: 3.3365 - accuracy: 0.143 - ETA: 38s - loss: 3.3370 - accuracy: 0.143 - ETA: 38s - loss: 3.3366 - accuracy: 0.144 - ETA: 37s - loss: 3.3367 - accuracy: 0.143 - ETA: 36s - loss: 3.3368 - accuracy: 0.143 - ETA: 36s - loss: 3.3371 - accuracy: 0.143 - ETA: 35s - loss: 3.3368 - accuracy: 0.143 - ETA: 35s - loss: 3.3367 - accuracy: 0.143 - ETA: 34s - loss: 3.3367 - accuracy: 0.143 - ETA: 34s - loss: 3.3368 - accuracy: 0.143 - ETA: 33s - loss: 3.3367 - accuracy: 0.143 - ETA: 32s - loss: 3.3368 - accuracy: 0.143 - ETA: 32s - loss: 3.3373 - accuracy: 0.143 - ETA: 31s - loss: 3.3375 - accuracy: 0.143 - ETA: 31s - loss: 3.3377 - accuracy: 0.143 - ETA: 30s - loss: 3.3372 - accuracy: 0.143 - ETA: 30s - loss: 3.3373 - accuracy: 0.143 - ETA: 29s - loss: 3.3375 - accuracy: 0.143 - ETA: 28s - loss: 3.3377 - accuracy: 0.143 - ETA: 28s - loss: 3.3372 - accuracy: 0.143 - ETA: 27s - loss: 3.3372 - accuracy: 0.143 - ETA: 27s - loss: 3.3376 - accuracy: 0.143 - ETA: 26s - loss: 3.3377 - accuracy: 0.143 - ETA: 26s - loss: 3.3375 - accuracy: 0.143 - ETA: 25s - loss: 3.3381 - accuracy: 0.143 - ETA: 25s - loss: 3.3385 - accuracy: 0.143 - ETA: 24s - loss: 3.3376 - accuracy: 0.143 - ETA: 23s - loss: 3.3379 - accuracy: 0.143 - ETA: 23s - loss: 3.3378 - accuracy: 0.143 - ETA: 22s - loss: 3.3378 - accuracy: 0.144 - ETA: 22s - loss: 3.3375 - accuracy: 0.144 - ETA: 21s - loss: 3.3370 - accuracy: 0.144 - ETA: 21s - loss: 3.3366 - accuracy: 0.144 - ETA: 20s - loss: 3.3364 - accuracy: 0.144 - ETA: 19s - loss: 3.3361 - accuracy: 0.144 - ETA: 19s - loss: 3.3355 - accuracy: 0.144 - ETA: 18s - loss: 3.3355 - accuracy: 0.144 - ETA: 18s - loss: 3.3351 - accuracy: 0.144 - ETA: 17s - loss: 3.3346 - accuracy: 0.144 - ETA: 17s - loss: 3.3352 - accuracy: 0.144 - ETA: 16s - loss: 3.3342 - accuracy: 0.144 - ETA: 15s - loss: 3.3338 - accuracy: 0.144 - ETA: 15s - loss: 3.3339 - accuracy: 0.144 - ETA: 14s - loss: 3.3339 - accuracy: 0.144 - ETA: 14s - loss: 3.3345 - accuracy: 0.144 - ETA: 13s - loss: 3.3351 - accuracy: 0.144 - ETA: 13s - loss: 3.3346 - accuracy: 0.144 - ETA: 12s - loss: 3.3341 - accuracy: 0.144 - ETA: 11s - loss: 3.3338 - accuracy: 0.144 - ETA: 11s - loss: 3.3331 - accuracy: 0.144 - ETA: 10s - loss: 3.3332 - accuracy: 0.144 - ETA: 10s - loss: 3.3334 - accuracy: 0.144 - ETA: 9s - loss: 3.3332 - accuracy: 0.144 - ETA: 9s - loss: 3.3330 - accuracy: 0.14 - ETA: 8s - loss: 3.3328 - accuracy: 0.14 - ETA: 8s - loss: 3.3326 - accuracy: 0.14 - ETA: 7s - loss: 3.3331 - accuracy: 0.14 - ETA: 6s - loss: 3.3330 - accuracy: 0.14 - ETA: 6s - loss: 3.3326 - accuracy: 0.14 - ETA: 5s - loss: 3.3324 - accuracy: 0.14 - ETA: 5s - loss: 3.3322 - accuracy: 0.14 - ETA: 4s - loss: 3.3321 - accuracy: 0.14 - ETA: 4s - loss: 3.3323 - accuracy: 0.14 - ETA: 3s - loss: 3.3320 - accuracy: 0.14 - ETA: 2s - loss: 3.3321 - accuracy: 0.14 - ETA: 2s - loss: 3.3327 - accuracy: 0.14 - ETA: 1s - loss: 3.3331 - accuracy: 0.14 - ETA: 1s - loss: 3.3329 - accuracy: 0.14 - ETA: 0s - loss: 3.3326 - accuracy: 0.14 - ETA: 0s - loss: 3.3322 - accuracy: 0.14 - 201s 5ms/step - loss: 3.3322 - accuracy: 0.1449 - val_loss: 3.9592 - val_accuracy: 0.0122\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:17 - loss: 3.2917 - accuracy: 0.13 - ETA: 3:08 - loss: 3.2866 - accuracy: 0.15 - ETA: 3:05 - loss: 3.3971 - accuracy: 0.15 - ETA: 3:03 - loss: 3.3410 - accuracy: 0.15 - ETA: 3:02 - loss: 3.3478 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3267 - accuracy: 0.15 - ETA: 3:02 - loss: 3.3196 - accuracy: 0.15 - ETA: 3:01 - loss: 3.3250 - accuracy: 0.15 - ETA: 3:00 - loss: 3.3056 - accuracy: 0.15 - ETA: 2:59 - loss: 3.3036 - accuracy: 0.15 - ETA: 2:58 - loss: 3.3097 - accuracy: 0.15 - ETA: 2:58 - loss: 3.3058 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2963 - accuracy: 0.15 - ETA: 3:00 - loss: 3.3011 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2997 - accuracy: 0.15 - ETA: 3:00 - loss: 3.3090 - accuracy: 0.15 - ETA: 3:00 - loss: 3.3100 - accuracy: 0.15 - ETA: 2:59 - loss: 3.3052 - accuracy: 0.15 - ETA: 2:58 - loss: 3.3086 - accuracy: 0.15 - ETA: 2:57 - loss: 3.3020 - accuracy: 0.15 - ETA: 2:57 - loss: 3.3049 - accuracy: 0.15 - ETA: 2:56 - loss: 3.3041 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2977 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2955 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2954 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2943 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2937 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2946 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2893 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2861 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2877 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2912 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2875 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2875 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2895 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2862 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2914 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2904 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2903 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2876 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2849 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2860 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2887 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2899 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2873 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2893 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2896 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2869 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2826 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2880 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2861 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2859 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2839 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2838 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2839 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2860 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2877 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2843 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2828 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2825 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2846 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2839 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2826 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2831 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2827 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2810 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2807 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2788 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2826 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2835 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2849 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2822 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2799 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2790 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2805 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2802 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2794 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2809 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2808 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2825 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2821 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2815 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2822 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2829 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2823 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2817 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2833 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2831 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2833 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2834 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2837 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2854 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2852 - accuracy: 0.14 - ETA: 2:14 - loss: 3.2855 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2863 - accuracy: 0.14 - ETA: 2:13 - loss: 3.2845 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2868 - accuracy: 0.14 - ETA: 2:12 - loss: 3.2866 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2862 - accuracy: 0.14 - ETA: 2:11 - loss: 3.2863 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2866 - accuracy: 0.14 - ETA: 2:10 - loss: 3.2855 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2841 - accuracy: 0.14 - ETA: 2:09 - loss: 3.2849 - accuracy: 0.14 - ETA: 2:08 - loss: 3.2870 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2894 - accuracy: 0.14 - ETA: 2:07 - loss: 3.2889 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2874 - accuracy: 0.14 - ETA: 2:06 - loss: 3.2891 - accuracy: 0.14 - ETA: 2:05 - loss: 3.2883 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2879 - accuracy: 0.14 - ETA: 2:04 - loss: 3.2872 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2861 - accuracy: 0.14 - ETA: 2:03 - loss: 3.2847 - accuracy: 0.14 - ETA: 2:02 - loss: 3.2862 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2871 - accuracy: 0.14 - ETA: 2:01 - loss: 3.2872 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2879 - accuracy: 0.14 - ETA: 2:00 - loss: 3.2891 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2891 - accuracy: 0.14 - ETA: 1:59 - loss: 3.2911 - accuracy: 0.14 - ETA: 1:58 - loss: 3.2903 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2911 - accuracy: 0.14 - ETA: 1:57 - loss: 3.2905 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2899 - accuracy: 0.14 - ETA: 1:56 - loss: 3.2902 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2906 - accuracy: 0.14 - ETA: 1:55 - loss: 3.2916 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2910 - accuracy: 0.14 - ETA: 1:54 - loss: 3.2918 - accuracy: 0.14 - ETA: 1:53 - loss: 3.2919 - accuracy: 0.14 - ETA: 1:52 - loss: 3.2926 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3099 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3097 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3105 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3120 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3118 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3113 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3112 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3107 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3098 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3094 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3087 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3096 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3097 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3089 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3100 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3103 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3111 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3111 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3118 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3120 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3116 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3114 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3109 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3094 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3101 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3096 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3094 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3102 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3105 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3100 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3100 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3111 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3109 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3111 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3100 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3103 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3099 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3103 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3099 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3096 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3087 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3091 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3083 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3088 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3080 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3077 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3075 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3066 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3062 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3061 - accuracy: 0.1465"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.3059 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3056 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3053 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3047 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3048 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3045 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3042 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3046 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3047 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3050 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3053 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3041 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3033 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3038 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3036 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3040 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3039 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3041 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3056 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3043 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3216 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3228 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3227 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3218 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3218 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3215 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3220 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3214 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3210 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3222 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3223 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3226 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3227 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3234 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3230 - accuracy: 0.14 - ETA: 59s - loss: 3.3230 - accuracy: 0.1472 - ETA: 58s - loss: 3.3236 - accuracy: 0.147 - ETA: 58s - loss: 3.3236 - accuracy: 0.146 - ETA: 57s - loss: 3.3234 - accuracy: 0.146 - ETA: 57s - loss: 3.3227 - accuracy: 0.147 - ETA: 56s - loss: 3.3227 - accuracy: 0.147 - ETA: 56s - loss: 3.3226 - accuracy: 0.146 - ETA: 55s - loss: 3.3231 - accuracy: 0.146 - ETA: 54s - loss: 3.3240 - accuracy: 0.146 - ETA: 54s - loss: 3.3243 - accuracy: 0.146 - ETA: 53s - loss: 3.3241 - accuracy: 0.146 - ETA: 53s - loss: 3.3244 - accuracy: 0.146 - ETA: 52s - loss: 3.3241 - accuracy: 0.146 - ETA: 52s - loss: 3.3238 - accuracy: 0.146 - ETA: 51s - loss: 3.3232 - accuracy: 0.146 - ETA: 51s - loss: 3.3229 - accuracy: 0.146 - ETA: 50s - loss: 3.3231 - accuracy: 0.146 - ETA: 49s - loss: 3.3222 - accuracy: 0.146 - ETA: 49s - loss: 3.3220 - accuracy: 0.146 - ETA: 48s - loss: 3.3215 - accuracy: 0.146 - ETA: 48s - loss: 3.3217 - accuracy: 0.146 - ETA: 47s - loss: 3.3221 - accuracy: 0.146 - ETA: 47s - loss: 3.3223 - accuracy: 0.146 - ETA: 46s - loss: 3.3223 - accuracy: 0.146 - ETA: 45s - loss: 3.3230 - accuracy: 0.146 - ETA: 45s - loss: 3.3224 - accuracy: 0.146 - ETA: 44s - loss: 3.3225 - accuracy: 0.146 - ETA: 44s - loss: 3.3220 - accuracy: 0.146 - ETA: 43s - loss: 3.3220 - accuracy: 0.146 - ETA: 43s - loss: 3.3216 - accuracy: 0.146 - ETA: 42s - loss: 3.3217 - accuracy: 0.146 - ETA: 41s - loss: 3.3211 - accuracy: 0.146 - ETA: 41s - loss: 3.3209 - accuracy: 0.146 - ETA: 40s - loss: 3.3199 - accuracy: 0.146 - ETA: 40s - loss: 3.3199 - accuracy: 0.146 - ETA: 39s - loss: 3.3192 - accuracy: 0.146 - ETA: 39s - loss: 3.3192 - accuracy: 0.146 - ETA: 38s - loss: 3.3193 - accuracy: 0.146 - ETA: 37s - loss: 3.3196 - accuracy: 0.146 - ETA: 37s - loss: 3.3199 - accuracy: 0.146 - ETA: 36s - loss: 3.3200 - accuracy: 0.146 - ETA: 36s - loss: 3.3206 - accuracy: 0.146 - ETA: 35s - loss: 3.3204 - accuracy: 0.146 - ETA: 35s - loss: 3.3212 - accuracy: 0.146 - ETA: 34s - loss: 3.3214 - accuracy: 0.146 - ETA: 34s - loss: 3.3206 - accuracy: 0.146 - ETA: 33s - loss: 3.3206 - accuracy: 0.146 - ETA: 32s - loss: 3.3199 - accuracy: 0.146 - ETA: 32s - loss: 3.3200 - accuracy: 0.146 - ETA: 31s - loss: 3.3210 - accuracy: 0.146 - ETA: 31s - loss: 3.3201 - accuracy: 0.146 - ETA: 30s - loss: 3.3200 - accuracy: 0.146 - ETA: 30s - loss: 3.3201 - accuracy: 0.146 - ETA: 29s - loss: 3.3203 - accuracy: 0.146 - ETA: 28s - loss: 3.3214 - accuracy: 0.146 - ETA: 28s - loss: 3.3220 - accuracy: 0.146 - ETA: 27s - loss: 3.3221 - accuracy: 0.146 - ETA: 27s - loss: 3.3218 - accuracy: 0.146 - ETA: 26s - loss: 3.3221 - accuracy: 0.146 - ETA: 26s - loss: 3.3219 - accuracy: 0.146 - ETA: 25s - loss: 3.3218 - accuracy: 0.146 - ETA: 24s - loss: 3.3220 - accuracy: 0.146 - ETA: 24s - loss: 3.3222 - accuracy: 0.146 - ETA: 23s - loss: 3.3224 - accuracy: 0.146 - ETA: 23s - loss: 3.3224 - accuracy: 0.146 - ETA: 22s - loss: 3.3228 - accuracy: 0.146 - ETA: 22s - loss: 3.3229 - accuracy: 0.146 - ETA: 21s - loss: 3.3225 - accuracy: 0.146 - ETA: 21s - loss: 3.3221 - accuracy: 0.146 - ETA: 20s - loss: 3.3219 - accuracy: 0.146 - ETA: 19s - loss: 3.3218 - accuracy: 0.146 - ETA: 19s - loss: 3.3215 - accuracy: 0.146 - ETA: 18s - loss: 3.3214 - accuracy: 0.146 - ETA: 18s - loss: 3.3216 - accuracy: 0.146 - ETA: 17s - loss: 3.3216 - accuracy: 0.146 - ETA: 17s - loss: 3.3218 - accuracy: 0.146 - ETA: 16s - loss: 3.3209 - accuracy: 0.146 - ETA: 15s - loss: 3.3205 - accuracy: 0.146 - ETA: 15s - loss: 3.3204 - accuracy: 0.146 - ETA: 14s - loss: 3.3201 - accuracy: 0.146 - ETA: 14s - loss: 3.3198 - accuracy: 0.146 - ETA: 13s - loss: 3.3203 - accuracy: 0.146 - ETA: 13s - loss: 3.3201 - accuracy: 0.146 - ETA: 12s - loss: 3.3202 - accuracy: 0.146 - ETA: 11s - loss: 3.3202 - accuracy: 0.146 - ETA: 11s - loss: 3.3206 - accuracy: 0.146 - ETA: 10s - loss: 3.3205 - accuracy: 0.146 - ETA: 10s - loss: 3.3209 - accuracy: 0.146 - ETA: 9s - loss: 3.3211 - accuracy: 0.146 - ETA: 9s - loss: 3.3215 - accuracy: 0.14 - ETA: 8s - loss: 3.3212 - accuracy: 0.14 - ETA: 7s - loss: 3.3215 - accuracy: 0.14 - ETA: 7s - loss: 3.3210 - accuracy: 0.14 - ETA: 6s - loss: 3.3211 - accuracy: 0.14 - ETA: 6s - loss: 3.3204 - accuracy: 0.14 - ETA: 5s - loss: 3.3201 - accuracy: 0.14 - ETA: 5s - loss: 3.3206 - accuracy: 0.14 - ETA: 4s - loss: 3.3203 - accuracy: 0.14 - ETA: 4s - loss: 3.3201 - accuracy: 0.14 - ETA: 3s - loss: 3.3199 - accuracy: 0.14 - ETA: 2s - loss: 3.3197 - accuracy: 0.14 - ETA: 2s - loss: 3.3196 - accuracy: 0.14 - ETA: 1s - loss: 3.3193 - accuracy: 0.14 - ETA: 1s - loss: 3.3195 - accuracy: 0.14 - ETA: 0s - loss: 3.3194 - accuracy: 0.14 - ETA: 0s - loss: 3.3202 - accuracy: 0.14 - 200s 5ms/step - loss: 3.3203 - accuracy: 0.1465 - val_loss: 3.9840 - val_accuracy: 0.0149\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:11 - loss: 3.0838 - accuracy: 0.18 - ETA: 3:02 - loss: 3.1568 - accuracy: 0.17 - ETA: 3:03 - loss: 3.2066 - accuracy: 0.17 - ETA: 3:02 - loss: 3.2554 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2596 - accuracy: 0.16 - ETA: 3:00 - loss: 3.2716 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2895 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3040 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3151 - accuracy: 0.13 - ETA: 2:58 - loss: 3.2997 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3060 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3192 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3183 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3167 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3158 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3103 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3081 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3046 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3001 - accuracy: 0.14 - ETA: 2:54 - loss: 3.2962 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2934 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2953 - accuracy: 0.15 - ETA: 2:52 - loss: 3.3008 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3015 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3008 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3026 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3000 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2987 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2991 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3007 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2989 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3020 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3038 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3016 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3020 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2993 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2957 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2967 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2976 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3014 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2996 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2987 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2960 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2916 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2899 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2868 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2854 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2815 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2833 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2817 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2817 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2808 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2846 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2828 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2830 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2805 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2818 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2828 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2861 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2872 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2835 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2838 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2835 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2815 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2784 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2762 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2773 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2759 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2717 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2729 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2745 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2762 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2741 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2712 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2720 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2732 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2742 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2743 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2748 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2759 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2727 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2721 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2723 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2737 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2728 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2738 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2742 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2727 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2726 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2727 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2737 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2740 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2730 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2746 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2741 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2743 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2732 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2729 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2725 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2740 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2734 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2733 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2716 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2723 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2728 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2738 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2733 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2752 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2736 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2736 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2739 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2753 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2760 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2766 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2750 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2752 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2737 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2750 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2760 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2752 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2752 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2751 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2749 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2743 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2754 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2749 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2757 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2752 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2759 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2760 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2767 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2757 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2757 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2739 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2743 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2739 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2736 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2722 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2723 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2716 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2717 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2731 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2718 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2705 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2706 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2699 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2703 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2709 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2707 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2707 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2703 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2702 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2688 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2688 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2718 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2719 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2729 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2725 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2725 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2727 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2730 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2732 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2731 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2712 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2716 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2717 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2704 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2712 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2714 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2729 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2744 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2737 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2732 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2736 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2737 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2733 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2738 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2747 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2745 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2741 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2737 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2745 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2744 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2748 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2768 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2768 - accuracy: 0.1523"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.2769 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2773 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2774 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2771 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2784 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2790 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2793 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2792 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2785 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2792 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2794 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2803 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2823 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2847 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2848 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2845 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2843 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2841 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2844 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2831 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2844 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2844 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2840 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2836 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2837 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2835 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2851 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2847 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2836 - accuracy: 0.15 - ETA: 59s - loss: 3.2833 - accuracy: 0.1510 - ETA: 59s - loss: 3.2835 - accuracy: 0.150 - ETA: 58s - loss: 3.2838 - accuracy: 0.150 - ETA: 57s - loss: 3.2842 - accuracy: 0.150 - ETA: 57s - loss: 3.2839 - accuracy: 0.150 - ETA: 56s - loss: 3.2839 - accuracy: 0.150 - ETA: 56s - loss: 3.2842 - accuracy: 0.150 - ETA: 55s - loss: 3.2851 - accuracy: 0.150 - ETA: 55s - loss: 3.2854 - accuracy: 0.150 - ETA: 54s - loss: 3.2852 - accuracy: 0.150 - ETA: 53s - loss: 3.2845 - accuracy: 0.150 - ETA: 53s - loss: 3.2846 - accuracy: 0.150 - ETA: 52s - loss: 3.2840 - accuracy: 0.150 - ETA: 52s - loss: 3.2848 - accuracy: 0.150 - ETA: 51s - loss: 3.2848 - accuracy: 0.150 - ETA: 51s - loss: 3.2844 - accuracy: 0.150 - ETA: 50s - loss: 3.2847 - accuracy: 0.150 - ETA: 49s - loss: 3.2842 - accuracy: 0.150 - ETA: 49s - loss: 3.2848 - accuracy: 0.150 - ETA: 48s - loss: 3.2856 - accuracy: 0.150 - ETA: 48s - loss: 3.2852 - accuracy: 0.150 - ETA: 47s - loss: 3.2853 - accuracy: 0.150 - ETA: 47s - loss: 3.2853 - accuracy: 0.150 - ETA: 46s - loss: 3.2853 - accuracy: 0.150 - ETA: 45s - loss: 3.2848 - accuracy: 0.150 - ETA: 45s - loss: 3.2852 - accuracy: 0.150 - ETA: 44s - loss: 3.2848 - accuracy: 0.150 - ETA: 44s - loss: 3.2848 - accuracy: 0.150 - ETA: 43s - loss: 3.2852 - accuracy: 0.150 - ETA: 43s - loss: 3.2858 - accuracy: 0.150 - ETA: 42s - loss: 3.2859 - accuracy: 0.150 - ETA: 41s - loss: 3.2861 - accuracy: 0.150 - ETA: 41s - loss: 3.2864 - accuracy: 0.149 - ETA: 40s - loss: 3.2866 - accuracy: 0.149 - ETA: 40s - loss: 3.2877 - accuracy: 0.149 - ETA: 39s - loss: 3.2879 - accuracy: 0.149 - ETA: 39s - loss: 3.2882 - accuracy: 0.149 - ETA: 38s - loss: 3.2888 - accuracy: 0.149 - ETA: 38s - loss: 3.2888 - accuracy: 0.149 - ETA: 37s - loss: 3.2888 - accuracy: 0.149 - ETA: 36s - loss: 3.2891 - accuracy: 0.149 - ETA: 36s - loss: 3.2889 - accuracy: 0.149 - ETA: 35s - loss: 3.2892 - accuracy: 0.149 - ETA: 35s - loss: 3.2886 - accuracy: 0.149 - ETA: 34s - loss: 3.2886 - accuracy: 0.149 - ETA: 34s - loss: 3.2887 - accuracy: 0.149 - ETA: 33s - loss: 3.2885 - accuracy: 0.149 - ETA: 32s - loss: 3.2882 - accuracy: 0.149 - ETA: 32s - loss: 3.2879 - accuracy: 0.149 - ETA: 31s - loss: 3.2875 - accuracy: 0.149 - ETA: 31s - loss: 3.2868 - accuracy: 0.150 - ETA: 30s - loss: 3.2874 - accuracy: 0.150 - ETA: 30s - loss: 3.2867 - accuracy: 0.150 - ETA: 29s - loss: 3.2862 - accuracy: 0.150 - ETA: 28s - loss: 3.2866 - accuracy: 0.150 - ETA: 28s - loss: 3.2866 - accuracy: 0.150 - ETA: 27s - loss: 3.2869 - accuracy: 0.150 - ETA: 27s - loss: 3.2864 - accuracy: 0.150 - ETA: 26s - loss: 3.2872 - accuracy: 0.149 - ETA: 26s - loss: 3.2876 - accuracy: 0.150 - ETA: 25s - loss: 3.2875 - accuracy: 0.150 - ETA: 25s - loss: 3.2869 - accuracy: 0.150 - ETA: 24s - loss: 3.2873 - accuracy: 0.150 - ETA: 23s - loss: 3.2877 - accuracy: 0.150 - ETA: 23s - loss: 3.2875 - accuracy: 0.149 - ETA: 22s - loss: 3.2871 - accuracy: 0.150 - ETA: 22s - loss: 3.2866 - accuracy: 0.150 - ETA: 21s - loss: 3.2862 - accuracy: 0.150 - ETA: 21s - loss: 3.2855 - accuracy: 0.150 - ETA: 20s - loss: 3.2854 - accuracy: 0.150 - ETA: 19s - loss: 3.2853 - accuracy: 0.150 - ETA: 19s - loss: 3.2859 - accuracy: 0.150 - ETA: 18s - loss: 3.2862 - accuracy: 0.149 - ETA: 18s - loss: 3.2860 - accuracy: 0.149 - ETA: 17s - loss: 3.2863 - accuracy: 0.149 - ETA: 17s - loss: 3.2862 - accuracy: 0.149 - ETA: 16s - loss: 3.2864 - accuracy: 0.149 - ETA: 15s - loss: 3.2865 - accuracy: 0.149 - ETA: 15s - loss: 3.2868 - accuracy: 0.149 - ETA: 14s - loss: 3.2861 - accuracy: 0.149 - ETA: 14s - loss: 3.2862 - accuracy: 0.149 - ETA: 13s - loss: 3.2860 - accuracy: 0.149 - ETA: 13s - loss: 3.2861 - accuracy: 0.149 - ETA: 12s - loss: 3.2859 - accuracy: 0.149 - ETA: 11s - loss: 3.2861 - accuracy: 0.149 - ETA: 11s - loss: 3.2867 - accuracy: 0.149 - ETA: 10s - loss: 3.2871 - accuracy: 0.149 - ETA: 10s - loss: 3.2871 - accuracy: 0.149 - ETA: 9s - loss: 3.2873 - accuracy: 0.149 - ETA: 9s - loss: 3.2874 - accuracy: 0.14 - ETA: 8s - loss: 3.2874 - accuracy: 0.14 - ETA: 7s - loss: 3.2873 - accuracy: 0.14 - ETA: 7s - loss: 3.2879 - accuracy: 0.14 - ETA: 6s - loss: 3.2884 - accuracy: 0.14 - ETA: 6s - loss: 3.2895 - accuracy: 0.14 - ETA: 5s - loss: 3.2897 - accuracy: 0.14 - ETA: 5s - loss: 3.2919 - accuracy: 0.14 - ETA: 4s - loss: 3.2925 - accuracy: 0.14 - ETA: 4s - loss: 3.2936 - accuracy: 0.14 - ETA: 3s - loss: 3.2940 - accuracy: 0.14 - ETA: 2s - loss: 3.2940 - accuracy: 0.14 - ETA: 2s - loss: 3.2944 - accuracy: 0.14 - ETA: 1s - loss: 3.2946 - accuracy: 0.14 - ETA: 1s - loss: 3.2949 - accuracy: 0.14 - ETA: 0s - loss: 3.2950 - accuracy: 0.14 - ETA: 0s - loss: 3.2952 - accuracy: 0.14 - 201s 5ms/step - loss: 3.2952 - accuracy: 0.1485 - val_loss: 3.9697 - val_accuracy: 0.0102\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:21 - loss: 3.2141 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2753 - accuracy: 0.12 - ETA: 3:05 - loss: 3.2920 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3249 - accuracy: 0.12 - ETA: 3:04 - loss: 3.2991 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3191 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3082 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3170 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3156 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3209 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3105 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2918 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2930 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2877 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2854 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2821 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2866 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2858 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2867 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2841 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2735 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2765 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2783 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2804 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2811 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2826 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2841 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2920 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2882 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2856 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2852 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2832 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2798 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2815 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2814 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2792 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2777 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2826 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2824 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2815 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2845 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2824 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2850 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2828 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2848 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2888 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2905 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2892 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2878 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2895 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2903 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2924 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2929 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2927 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2929 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2926 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2952 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2913 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2893 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2905 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2904 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2907 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2898 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2888 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2896 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2925 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2934 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2950 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2936 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2929 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2957 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2937 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2935 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2948 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2948 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2941 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2950 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2958 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2982 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2964 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2959 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2953 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2969 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2957 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2964 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2986 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2976 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2976 - accuracy: 0.14 - ETA: 2:17 - loss: 3.2976 - accuracy: 0.14 - ETA: 2:16 - loss: 3.2991 - accuracy: 0.14 - ETA: 2:15 - loss: 3.2991 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3001 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3003 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3016 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3025 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3039 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3045 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3046 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3064 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3071 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3066 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3065 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3066 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3081 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3075 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3076 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3096 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3139 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3189 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3254 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3291 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3295 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3307 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3302 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3284 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3283 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3296 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3285 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3294 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3304 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3295 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3300 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3299 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3325 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3332 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3342 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3339 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3327 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3342 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3354 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3346 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3354 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3350 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3338 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3348 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3338 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3335 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3337 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3336 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3331 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3339 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3334 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3335 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3336 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3340 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3341 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3336 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3347 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3337 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3330 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3322 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3323 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3322 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3317 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3317 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3315 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3314 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3312 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3309 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3313 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3304 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3298 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3307 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3302 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3304 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3306 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3308 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3306 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3297 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3294 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3292 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3277 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3299 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3303 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3306 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3340 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3355 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3363 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3366 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3370 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3376 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3382 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3380 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3386 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3389 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3400 - accuracy: 0.1436"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.3403 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3412 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3410 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3411 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3421 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3425 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3425 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3425 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3424 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3422 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3429 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3436 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3443 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3449 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3453 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3451 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3461 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3463 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3468 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3472 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3478 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3477 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3474 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3483 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3487 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3491 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3500 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3492 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3482 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3481 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3479 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3480 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3486 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3488 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3491 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3496 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3491 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3482 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3486 - accuracy: 0.14 - ETA: 59s - loss: 3.3489 - accuracy: 0.1422 - ETA: 59s - loss: 3.3491 - accuracy: 0.142 - ETA: 58s - loss: 3.3492 - accuracy: 0.142 - ETA: 57s - loss: 3.3488 - accuracy: 0.142 - ETA: 57s - loss: 3.3482 - accuracy: 0.142 - ETA: 56s - loss: 3.3484 - accuracy: 0.142 - ETA: 56s - loss: 3.3484 - accuracy: 0.142 - ETA: 55s - loss: 3.3483 - accuracy: 0.142 - ETA: 55s - loss: 3.3481 - accuracy: 0.142 - ETA: 54s - loss: 3.3481 - accuracy: 0.142 - ETA: 53s - loss: 3.3475 - accuracy: 0.142 - ETA: 53s - loss: 3.3476 - accuracy: 0.142 - ETA: 52s - loss: 3.3477 - accuracy: 0.142 - ETA: 52s - loss: 3.3476 - accuracy: 0.142 - ETA: 51s - loss: 3.3467 - accuracy: 0.142 - ETA: 51s - loss: 3.3470 - accuracy: 0.142 - ETA: 50s - loss: 3.3472 - accuracy: 0.142 - ETA: 49s - loss: 3.3466 - accuracy: 0.142 - ETA: 49s - loss: 3.3461 - accuracy: 0.142 - ETA: 48s - loss: 3.3456 - accuracy: 0.142 - ETA: 48s - loss: 3.3458 - accuracy: 0.142 - ETA: 47s - loss: 3.3458 - accuracy: 0.143 - ETA: 47s - loss: 3.3456 - accuracy: 0.142 - ETA: 46s - loss: 3.3455 - accuracy: 0.142 - ETA: 45s - loss: 3.3463 - accuracy: 0.142 - ETA: 45s - loss: 3.3467 - accuracy: 0.142 - ETA: 44s - loss: 3.3462 - accuracy: 0.142 - ETA: 44s - loss: 3.3455 - accuracy: 0.142 - ETA: 43s - loss: 3.3458 - accuracy: 0.142 - ETA: 43s - loss: 3.3451 - accuracy: 0.142 - ETA: 42s - loss: 3.3451 - accuracy: 0.142 - ETA: 41s - loss: 3.3446 - accuracy: 0.143 - ETA: 41s - loss: 3.3441 - accuracy: 0.143 - ETA: 40s - loss: 3.3438 - accuracy: 0.143 - ETA: 40s - loss: 3.3438 - accuracy: 0.143 - ETA: 39s - loss: 3.3439 - accuracy: 0.143 - ETA: 39s - loss: 3.3439 - accuracy: 0.142 - ETA: 38s - loss: 3.3442 - accuracy: 0.142 - ETA: 37s - loss: 3.3430 - accuracy: 0.143 - ETA: 37s - loss: 3.3422 - accuracy: 0.143 - ETA: 36s - loss: 3.3423 - accuracy: 0.143 - ETA: 36s - loss: 3.3418 - accuracy: 0.143 - ETA: 35s - loss: 3.3420 - accuracy: 0.143 - ETA: 35s - loss: 3.3424 - accuracy: 0.143 - ETA: 34s - loss: 3.3415 - accuracy: 0.143 - ETA: 34s - loss: 3.3420 - accuracy: 0.143 - ETA: 33s - loss: 3.3421 - accuracy: 0.143 - ETA: 32s - loss: 3.3420 - accuracy: 0.143 - ETA: 32s - loss: 3.3420 - accuracy: 0.143 - ETA: 31s - loss: 3.3417 - accuracy: 0.143 - ETA: 31s - loss: 3.3416 - accuracy: 0.143 - ETA: 30s - loss: 3.3417 - accuracy: 0.143 - ETA: 30s - loss: 3.3419 - accuracy: 0.143 - ETA: 29s - loss: 3.3423 - accuracy: 0.143 - ETA: 28s - loss: 3.3417 - accuracy: 0.143 - ETA: 28s - loss: 3.3414 - accuracy: 0.143 - ETA: 27s - loss: 3.3418 - accuracy: 0.143 - ETA: 27s - loss: 3.3414 - accuracy: 0.143 - ETA: 26s - loss: 3.3414 - accuracy: 0.143 - ETA: 26s - loss: 3.3406 - accuracy: 0.143 - ETA: 25s - loss: 3.3412 - accuracy: 0.143 - ETA: 25s - loss: 3.3412 - accuracy: 0.143 - ETA: 24s - loss: 3.3412 - accuracy: 0.143 - ETA: 23s - loss: 3.3413 - accuracy: 0.143 - ETA: 23s - loss: 3.3410 - accuracy: 0.143 - ETA: 22s - loss: 3.3411 - accuracy: 0.143 - ETA: 22s - loss: 3.3406 - accuracy: 0.143 - ETA: 21s - loss: 3.3404 - accuracy: 0.143 - ETA: 21s - loss: 3.3400 - accuracy: 0.144 - ETA: 20s - loss: 3.3402 - accuracy: 0.144 - ETA: 19s - loss: 3.3404 - accuracy: 0.143 - ETA: 19s - loss: 3.3408 - accuracy: 0.143 - ETA: 18s - loss: 3.3407 - accuracy: 0.143 - ETA: 18s - loss: 3.3405 - accuracy: 0.143 - ETA: 17s - loss: 3.3401 - accuracy: 0.144 - ETA: 17s - loss: 3.3405 - accuracy: 0.144 - ETA: 16s - loss: 3.3400 - accuracy: 0.144 - ETA: 15s - loss: 3.3400 - accuracy: 0.144 - ETA: 15s - loss: 3.3402 - accuracy: 0.143 - ETA: 14s - loss: 3.3403 - accuracy: 0.143 - ETA: 14s - loss: 3.3405 - accuracy: 0.143 - ETA: 13s - loss: 3.3401 - accuracy: 0.144 - ETA: 13s - loss: 3.3399 - accuracy: 0.144 - ETA: 12s - loss: 3.3399 - accuracy: 0.144 - ETA: 11s - loss: 3.3400 - accuracy: 0.144 - ETA: 11s - loss: 3.3403 - accuracy: 0.144 - ETA: 10s - loss: 3.3402 - accuracy: 0.144 - ETA: 10s - loss: 3.3407 - accuracy: 0.143 - ETA: 9s - loss: 3.3408 - accuracy: 0.143 - ETA: 9s - loss: 3.3402 - accuracy: 0.14 - ETA: 8s - loss: 3.3404 - accuracy: 0.14 - ETA: 7s - loss: 3.3397 - accuracy: 0.14 - ETA: 7s - loss: 3.3394 - accuracy: 0.14 - ETA: 6s - loss: 3.3390 - accuracy: 0.14 - ETA: 6s - loss: 3.3387 - accuracy: 0.14 - ETA: 5s - loss: 3.3386 - accuracy: 0.14 - ETA: 5s - loss: 3.3379 - accuracy: 0.14 - ETA: 4s - loss: 3.3378 - accuracy: 0.14 - ETA: 4s - loss: 3.3377 - accuracy: 0.14 - ETA: 3s - loss: 3.3375 - accuracy: 0.14 - ETA: 2s - loss: 3.3376 - accuracy: 0.14 - ETA: 2s - loss: 3.3380 - accuracy: 0.14 - ETA: 1s - loss: 3.3378 - accuracy: 0.14 - ETA: 1s - loss: 3.3375 - accuracy: 0.14 - ETA: 0s - loss: 3.3380 - accuracy: 0.14 - ETA: 0s - loss: 3.3375 - accuracy: 0.14 - 201s 5ms/step - loss: 3.3374 - accuracy: 0.1447 - val_loss: 3.8953 - val_accuracy: 0.0158\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:22 - loss: 3.3407 - accuracy: 0.17 - ETA: 3:08 - loss: 3.4158 - accuracy: 0.15 - ETA: 3:04 - loss: 3.3345 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3562 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3335 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3648 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3476 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3207 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3188 - accuracy: 0.15 - ETA: 2:58 - loss: 3.3132 - accuracy: 0.15 - ETA: 2:58 - loss: 3.3031 - accuracy: 0.15 - ETA: 2:57 - loss: 3.3016 - accuracy: 0.15 - ETA: 2:56 - loss: 3.3022 - accuracy: 0.15 - ETA: 2:57 - loss: 3.3007 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3010 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3055 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3092 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3138 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3182 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3249 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3345 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3316 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3260 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3220 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3205 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3109 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3023 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2982 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2924 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2958 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2992 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2962 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2980 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2965 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3000 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3027 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3033 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3034 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2973 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2942 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2984 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2987 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2933 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2959 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2950 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2968 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2967 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2967 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2952 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2967 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2962 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2943 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2922 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2914 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2918 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2919 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2879 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2927 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2932 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2931 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2938 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2955 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2966 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2954 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2953 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2951 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2947 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2936 - accuracy: 0.14 - ETA: 2:28 - loss: 3.2928 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2918 - accuracy: 0.14 - ETA: 2:27 - loss: 3.2914 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2892 - accuracy: 0.14 - ETA: 2:26 - loss: 3.2878 - accuracy: 0.14 - ETA: 2:25 - loss: 3.2875 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2886 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2880 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2863 - accuracy: 0.14 - ETA: 2:23 - loss: 3.2879 - accuracy: 0.14 - ETA: 2:22 - loss: 3.2878 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2880 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2881 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2876 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2904 - accuracy: 0.14 - ETA: 2:20 - loss: 3.2870 - accuracy: 0.14 - ETA: 2:19 - loss: 3.2882 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2876 - accuracy: 0.14 - ETA: 2:18 - loss: 3.2852 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2837 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2834 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2808 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2802 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2802 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2786 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2778 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2792 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2774 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2770 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2771 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2771 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2758 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2761 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2762 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2742 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2751 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2753 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2751 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2759 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2753 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2746 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2728 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2754 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2764 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2767 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2775 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2773 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2781 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2791 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2801 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2802 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2810 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2796 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2797 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2802 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2809 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2815 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2820 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2819 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2826 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2831 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2819 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2831 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2828 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2823 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2818 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2820 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2821 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2819 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2835 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2835 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2841 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2844 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2840 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2846 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2830 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2822 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2837 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2836 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2839 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2843 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2835 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2841 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2849 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2857 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2847 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2845 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2850 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2857 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2864 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2871 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2868 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2862 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2868 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2873 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2872 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2874 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2878 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2890 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2890 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2890 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2887 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2887 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2885 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2892 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2897 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2907 - accuracy: 0.14 - ETA: 1:24 - loss: 3.2913 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2917 - accuracy: 0.14 - ETA: 1:23 - loss: 3.2923 - accuracy: 0.14 - ETA: 1:22 - loss: 3.2922 - accuracy: 0.14 - ETA: 1:22 - loss: 3.2909 - accuracy: 0.1500"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.2919 - accuracy: 0.14 - ETA: 1:21 - loss: 3.2912 - accuracy: 0.14 - ETA: 1:20 - loss: 3.2906 - accuracy: 0.14 - ETA: 1:20 - loss: 3.2900 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2901 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2909 - accuracy: 0.14 - ETA: 1:18 - loss: 3.2909 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2906 - accuracy: 0.14 - ETA: 1:17 - loss: 3.2914 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2909 - accuracy: 0.14 - ETA: 1:16 - loss: 3.2901 - accuracy: 0.14 - ETA: 1:15 - loss: 3.2904 - accuracy: 0.14 - ETA: 1:14 - loss: 3.2908 - accuracy: 0.14 - ETA: 1:14 - loss: 3.2909 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2919 - accuracy: 0.14 - ETA: 1:13 - loss: 3.2923 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2919 - accuracy: 0.14 - ETA: 1:12 - loss: 3.2919 - accuracy: 0.14 - ETA: 1:11 - loss: 3.2921 - accuracy: 0.14 - ETA: 1:10 - loss: 3.2919 - accuracy: 0.14 - ETA: 1:10 - loss: 3.2936 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2942 - accuracy: 0.14 - ETA: 1:09 - loss: 3.2941 - accuracy: 0.14 - ETA: 1:08 - loss: 3.2934 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2931 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2929 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2927 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2929 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2922 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2921 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2916 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2910 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2916 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2908 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2908 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2914 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2906 - accuracy: 0.15 - ETA: 59s - loss: 3.2913 - accuracy: 0.1509 - ETA: 59s - loss: 3.2912 - accuracy: 0.150 - ETA: 58s - loss: 3.2915 - accuracy: 0.150 - ETA: 57s - loss: 3.2915 - accuracy: 0.150 - ETA: 57s - loss: 3.2912 - accuracy: 0.150 - ETA: 56s - loss: 3.2921 - accuracy: 0.150 - ETA: 56s - loss: 3.2930 - accuracy: 0.150 - ETA: 55s - loss: 3.2932 - accuracy: 0.150 - ETA: 55s - loss: 3.2940 - accuracy: 0.150 - ETA: 54s - loss: 3.2951 - accuracy: 0.149 - ETA: 53s - loss: 3.2950 - accuracy: 0.149 - ETA: 53s - loss: 3.2952 - accuracy: 0.149 - ETA: 52s - loss: 3.2950 - accuracy: 0.149 - ETA: 52s - loss: 3.2947 - accuracy: 0.149 - ETA: 51s - loss: 3.2949 - accuracy: 0.149 - ETA: 51s - loss: 3.2946 - accuracy: 0.149 - ETA: 50s - loss: 3.2950 - accuracy: 0.149 - ETA: 49s - loss: 3.2935 - accuracy: 0.150 - ETA: 49s - loss: 3.2934 - accuracy: 0.150 - ETA: 48s - loss: 3.2933 - accuracy: 0.150 - ETA: 48s - loss: 3.2925 - accuracy: 0.150 - ETA: 47s - loss: 3.2921 - accuracy: 0.150 - ETA: 47s - loss: 3.2922 - accuracy: 0.150 - ETA: 46s - loss: 3.2918 - accuracy: 0.150 - ETA: 45s - loss: 3.2915 - accuracy: 0.150 - ETA: 45s - loss: 3.2909 - accuracy: 0.150 - ETA: 44s - loss: 3.2900 - accuracy: 0.150 - ETA: 44s - loss: 3.2900 - accuracy: 0.150 - ETA: 43s - loss: 3.2902 - accuracy: 0.150 - ETA: 43s - loss: 3.2906 - accuracy: 0.150 - ETA: 42s - loss: 3.2917 - accuracy: 0.150 - ETA: 42s - loss: 3.2911 - accuracy: 0.150 - ETA: 41s - loss: 3.2915 - accuracy: 0.150 - ETA: 40s - loss: 3.2919 - accuracy: 0.150 - ETA: 40s - loss: 3.2920 - accuracy: 0.150 - ETA: 39s - loss: 3.2917 - accuracy: 0.150 - ETA: 39s - loss: 3.2909 - accuracy: 0.150 - ETA: 38s - loss: 3.2914 - accuracy: 0.150 - ETA: 38s - loss: 3.2915 - accuracy: 0.150 - ETA: 37s - loss: 3.2915 - accuracy: 0.150 - ETA: 36s - loss: 3.2916 - accuracy: 0.150 - ETA: 36s - loss: 3.2919 - accuracy: 0.150 - ETA: 35s - loss: 3.2916 - accuracy: 0.150 - ETA: 35s - loss: 3.2925 - accuracy: 0.150 - ETA: 34s - loss: 3.2925 - accuracy: 0.150 - ETA: 34s - loss: 3.2927 - accuracy: 0.150 - ETA: 33s - loss: 3.2922 - accuracy: 0.150 - ETA: 32s - loss: 3.2920 - accuracy: 0.150 - ETA: 32s - loss: 3.2910 - accuracy: 0.150 - ETA: 31s - loss: 3.2910 - accuracy: 0.150 - ETA: 31s - loss: 3.2921 - accuracy: 0.150 - ETA: 30s - loss: 3.2929 - accuracy: 0.150 - ETA: 30s - loss: 3.2937 - accuracy: 0.150 - ETA: 29s - loss: 3.2944 - accuracy: 0.150 - ETA: 29s - loss: 3.2944 - accuracy: 0.150 - ETA: 28s - loss: 3.2944 - accuracy: 0.150 - ETA: 27s - loss: 3.2951 - accuracy: 0.150 - ETA: 27s - loss: 3.2947 - accuracy: 0.150 - ETA: 26s - loss: 3.2946 - accuracy: 0.150 - ETA: 26s - loss: 3.2952 - accuracy: 0.150 - ETA: 25s - loss: 3.2953 - accuracy: 0.150 - ETA: 25s - loss: 3.2951 - accuracy: 0.150 - ETA: 24s - loss: 3.2951 - accuracy: 0.150 - ETA: 23s - loss: 3.2944 - accuracy: 0.150 - ETA: 23s - loss: 3.2946 - accuracy: 0.150 - ETA: 22s - loss: 3.2945 - accuracy: 0.150 - ETA: 22s - loss: 3.2940 - accuracy: 0.150 - ETA: 21s - loss: 3.2943 - accuracy: 0.150 - ETA: 21s - loss: 3.2950 - accuracy: 0.150 - ETA: 20s - loss: 3.2950 - accuracy: 0.149 - ETA: 19s - loss: 3.2952 - accuracy: 0.150 - ETA: 19s - loss: 3.2961 - accuracy: 0.149 - ETA: 18s - loss: 3.2953 - accuracy: 0.150 - ETA: 18s - loss: 3.2962 - accuracy: 0.150 - ETA: 17s - loss: 3.2957 - accuracy: 0.150 - ETA: 17s - loss: 3.2955 - accuracy: 0.150 - ETA: 16s - loss: 3.2954 - accuracy: 0.150 - ETA: 15s - loss: 3.2951 - accuracy: 0.150 - ETA: 15s - loss: 3.2943 - accuracy: 0.150 - ETA: 14s - loss: 3.2946 - accuracy: 0.150 - ETA: 14s - loss: 3.2948 - accuracy: 0.150 - ETA: 13s - loss: 3.2947 - accuracy: 0.150 - ETA: 13s - loss: 3.2948 - accuracy: 0.150 - ETA: 12s - loss: 3.2950 - accuracy: 0.150 - ETA: 11s - loss: 3.2952 - accuracy: 0.150 - ETA: 11s - loss: 3.2959 - accuracy: 0.149 - ETA: 10s - loss: 3.2957 - accuracy: 0.150 - ETA: 10s - loss: 3.2955 - accuracy: 0.150 - ETA: 9s - loss: 3.2959 - accuracy: 0.150 - ETA: 9s - loss: 3.2965 - accuracy: 0.15 - ETA: 8s - loss: 3.2968 - accuracy: 0.15 - ETA: 7s - loss: 3.2968 - accuracy: 0.15 - ETA: 7s - loss: 3.2967 - accuracy: 0.15 - ETA: 6s - loss: 3.2970 - accuracy: 0.15 - ETA: 6s - loss: 3.2972 - accuracy: 0.15 - ETA: 5s - loss: 3.2970 - accuracy: 0.15 - ETA: 5s - loss: 3.2971 - accuracy: 0.15 - ETA: 4s - loss: 3.2970 - accuracy: 0.15 - ETA: 4s - loss: 3.2971 - accuracy: 0.15 - ETA: 3s - loss: 3.2973 - accuracy: 0.15 - ETA: 2s - loss: 3.2967 - accuracy: 0.15 - ETA: 2s - loss: 3.2969 - accuracy: 0.15 - ETA: 1s - loss: 3.2974 - accuracy: 0.15 - ETA: 1s - loss: 3.2973 - accuracy: 0.15 - ETA: 0s - loss: 3.2979 - accuracy: 0.15 - ETA: 0s - loss: 3.2976 - accuracy: 0.15 - 200s 5ms/step - loss: 3.2977 - accuracy: 0.1504 - val_loss: 3.9497 - val_accuracy: 0.0131\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:42 - loss: 3.1244 - accuracy: 0.14 - ETA: 3:19 - loss: 3.1986 - accuracy: 0.15 - ETA: 3:10 - loss: 3.2715 - accuracy: 0.14 - ETA: 3:11 - loss: 3.2883 - accuracy: 0.14 - ETA: 3:12 - loss: 3.3178 - accuracy: 0.14 - ETA: 3:09 - loss: 3.2984 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3001 - accuracy: 0.15 - ETA: 3:05 - loss: 3.3010 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3247 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3218 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3288 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3225 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3183 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3100 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3204 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3115 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3286 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3249 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3193 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3129 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3064 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3054 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3111 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3129 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3091 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3101 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3063 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3050 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3068 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3050 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3058 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3042 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3061 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3036 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3067 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3076 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3052 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3022 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3005 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2978 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2993 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2997 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2965 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2960 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2977 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2988 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3008 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2996 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2964 - accuracy: 0.14 - ETA: 2:40 - loss: 3.2947 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2907 - accuracy: 0.14 - ETA: 2:39 - loss: 3.2943 - accuracy: 0.14 - ETA: 2:38 - loss: 3.2940 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2926 - accuracy: 0.14 - ETA: 2:37 - loss: 3.2926 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2925 - accuracy: 0.14 - ETA: 2:36 - loss: 3.2893 - accuracy: 0.14 - ETA: 2:35 - loss: 3.2915 - accuracy: 0.14 - ETA: 2:34 - loss: 3.2920 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2917 - accuracy: 0.14 - ETA: 2:33 - loss: 3.2900 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2940 - accuracy: 0.14 - ETA: 2:32 - loss: 3.2925 - accuracy: 0.14 - ETA: 2:31 - loss: 3.2929 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2931 - accuracy: 0.14 - ETA: 2:30 - loss: 3.2917 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2938 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2918 - accuracy: 0.14 - ETA: 2:29 - loss: 3.2921 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2942 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2934 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2967 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2946 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2929 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2944 - accuracy: 0.14 - ETA: 2:24 - loss: 3.2949 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2974 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2994 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2985 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2959 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2970 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2980 - accuracy: 0.14 - ETA: 2:21 - loss: 3.2983 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3005 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3014 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3041 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3044 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3052 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3054 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3061 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3070 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3073 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3046 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3035 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3055 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3072 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3065 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3052 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3054 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3051 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3054 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3051 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3054 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3057 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3051 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3042 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3046 - accuracy: 0.15 - ETA: 2:06 - loss: 3.3034 - accuracy: 0.15 - ETA: 2:05 - loss: 3.3007 - accuracy: 0.15 - ETA: 2:05 - loss: 3.3004 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2996 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2985 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2991 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2987 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2989 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2969 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2964 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2974 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2957 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2958 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2970 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2989 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2985 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2967 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2969 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2967 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2977 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2979 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2982 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2971 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2968 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2961 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2969 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2987 - accuracy: 0.15 - ETA: 1:51 - loss: 3.3004 - accuracy: 0.15 - ETA: 1:50 - loss: 3.3033 - accuracy: 0.15 - ETA: 1:50 - loss: 3.3025 - accuracy: 0.15 - ETA: 1:49 - loss: 3.3056 - accuracy: 0.15 - ETA: 1:48 - loss: 3.3058 - accuracy: 0.15 - ETA: 1:48 - loss: 3.3064 - accuracy: 0.15 - ETA: 1:47 - loss: 3.3056 - accuracy: 0.15 - ETA: 1:47 - loss: 3.3057 - accuracy: 0.15 - ETA: 1:46 - loss: 3.3042 - accuracy: 0.15 - ETA: 1:46 - loss: 3.3031 - accuracy: 0.15 - ETA: 1:45 - loss: 3.3038 - accuracy: 0.15 - ETA: 1:44 - loss: 3.3035 - accuracy: 0.15 - ETA: 1:44 - loss: 3.3045 - accuracy: 0.15 - ETA: 1:43 - loss: 3.3050 - accuracy: 0.15 - ETA: 1:43 - loss: 3.3039 - accuracy: 0.15 - ETA: 1:42 - loss: 3.3040 - accuracy: 0.15 - ETA: 1:42 - loss: 3.3029 - accuracy: 0.15 - ETA: 1:41 - loss: 3.3035 - accuracy: 0.15 - ETA: 1:41 - loss: 3.3042 - accuracy: 0.15 - ETA: 1:40 - loss: 3.3041 - accuracy: 0.15 - ETA: 1:40 - loss: 3.3045 - accuracy: 0.15 - ETA: 1:39 - loss: 3.3047 - accuracy: 0.15 - ETA: 1:38 - loss: 3.3043 - accuracy: 0.15 - ETA: 1:38 - loss: 3.3044 - accuracy: 0.15 - ETA: 1:37 - loss: 3.3050 - accuracy: 0.15 - ETA: 1:37 - loss: 3.3066 - accuracy: 0.15 - ETA: 1:36 - loss: 3.3060 - accuracy: 0.15 - ETA: 1:36 - loss: 3.3073 - accuracy: 0.15 - ETA: 1:35 - loss: 3.3082 - accuracy: 0.15 - ETA: 1:34 - loss: 3.3085 - accuracy: 0.15 - ETA: 1:34 - loss: 3.3088 - accuracy: 0.15 - ETA: 1:33 - loss: 3.3091 - accuracy: 0.15 - ETA: 1:33 - loss: 3.3090 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3085 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3088 - accuracy: 0.15 - ETA: 1:31 - loss: 3.3087 - accuracy: 0.15 - ETA: 1:30 - loss: 3.3084 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3085 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3091 - accuracy: 0.15 - ETA: 1:29 - loss: 3.3095 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3093 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3086 - accuracy: 0.15 - ETA: 1:27 - loss: 3.3088 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3085 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3085 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3079 - accuracy: 0.15 - ETA: 1:25 - loss: 3.3080 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3084 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3091 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3094 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3095 - accuracy: 0.1494"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.3092 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3091 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3098 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3101 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3102 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3099 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3092 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3088 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3089 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3087 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3087 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3087 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3079 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3073 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3077 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3078 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3075 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3075 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3083 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3086 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3079 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3078 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3083 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3084 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3084 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3080 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3088 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3089 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3092 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3082 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3083 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3079 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3078 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3074 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3072 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3071 - accuracy: 0.14 - ETA: 59s - loss: 3.3058 - accuracy: 0.1487 - ETA: 59s - loss: 3.3062 - accuracy: 0.148 - ETA: 58s - loss: 3.3056 - accuracy: 0.148 - ETA: 57s - loss: 3.3052 - accuracy: 0.148 - ETA: 57s - loss: 3.3046 - accuracy: 0.149 - ETA: 56s - loss: 3.3038 - accuracy: 0.149 - ETA: 56s - loss: 3.3039 - accuracy: 0.149 - ETA: 55s - loss: 3.3036 - accuracy: 0.149 - ETA: 55s - loss: 3.3034 - accuracy: 0.149 - ETA: 54s - loss: 3.3031 - accuracy: 0.149 - ETA: 53s - loss: 3.3032 - accuracy: 0.149 - ETA: 53s - loss: 3.3035 - accuracy: 0.149 - ETA: 52s - loss: 3.3039 - accuracy: 0.148 - ETA: 52s - loss: 3.3040 - accuracy: 0.149 - ETA: 51s - loss: 3.3035 - accuracy: 0.149 - ETA: 51s - loss: 3.3039 - accuracy: 0.148 - ETA: 50s - loss: 3.3036 - accuracy: 0.148 - ETA: 49s - loss: 3.3043 - accuracy: 0.148 - ETA: 49s - loss: 3.3041 - accuracy: 0.148 - ETA: 48s - loss: 3.3038 - accuracy: 0.148 - ETA: 48s - loss: 3.3040 - accuracy: 0.148 - ETA: 47s - loss: 3.3043 - accuracy: 0.148 - ETA: 47s - loss: 3.3047 - accuracy: 0.148 - ETA: 46s - loss: 3.3040 - accuracy: 0.148 - ETA: 45s - loss: 3.3046 - accuracy: 0.148 - ETA: 45s - loss: 3.3043 - accuracy: 0.148 - ETA: 44s - loss: 3.3039 - accuracy: 0.149 - ETA: 44s - loss: 3.3041 - accuracy: 0.148 - ETA: 43s - loss: 3.3041 - accuracy: 0.148 - ETA: 43s - loss: 3.3037 - accuracy: 0.148 - ETA: 42s - loss: 3.3031 - accuracy: 0.148 - ETA: 42s - loss: 3.3028 - accuracy: 0.148 - ETA: 41s - loss: 3.3026 - accuracy: 0.148 - ETA: 40s - loss: 3.3019 - accuracy: 0.148 - ETA: 40s - loss: 3.3013 - accuracy: 0.149 - ETA: 39s - loss: 3.3015 - accuracy: 0.149 - ETA: 39s - loss: 3.3017 - accuracy: 0.148 - ETA: 38s - loss: 3.3023 - accuracy: 0.148 - ETA: 38s - loss: 3.3022 - accuracy: 0.148 - ETA: 37s - loss: 3.3021 - accuracy: 0.148 - ETA: 36s - loss: 3.3014 - accuracy: 0.148 - ETA: 36s - loss: 3.3012 - accuracy: 0.148 - ETA: 35s - loss: 3.3009 - accuracy: 0.148 - ETA: 35s - loss: 3.3011 - accuracy: 0.149 - ETA: 34s - loss: 3.3012 - accuracy: 0.149 - ETA: 34s - loss: 3.3006 - accuracy: 0.149 - ETA: 33s - loss: 3.3007 - accuracy: 0.149 - ETA: 32s - loss: 3.3007 - accuracy: 0.149 - ETA: 32s - loss: 3.3010 - accuracy: 0.148 - ETA: 31s - loss: 3.3017 - accuracy: 0.148 - ETA: 31s - loss: 3.3008 - accuracy: 0.149 - ETA: 30s - loss: 3.3014 - accuracy: 0.149 - ETA: 30s - loss: 3.3014 - accuracy: 0.149 - ETA: 29s - loss: 3.3015 - accuracy: 0.149 - ETA: 28s - loss: 3.3021 - accuracy: 0.149 - ETA: 28s - loss: 3.3020 - accuracy: 0.149 - ETA: 27s - loss: 3.3025 - accuracy: 0.149 - ETA: 27s - loss: 3.3026 - accuracy: 0.149 - ETA: 26s - loss: 3.3028 - accuracy: 0.149 - ETA: 26s - loss: 3.3040 - accuracy: 0.148 - ETA: 25s - loss: 3.3047 - accuracy: 0.148 - ETA: 24s - loss: 3.3048 - accuracy: 0.148 - ETA: 24s - loss: 3.3040 - accuracy: 0.148 - ETA: 23s - loss: 3.3036 - accuracy: 0.148 - ETA: 23s - loss: 3.3043 - accuracy: 0.148 - ETA: 22s - loss: 3.3041 - accuracy: 0.148 - ETA: 22s - loss: 3.3042 - accuracy: 0.148 - ETA: 21s - loss: 3.3045 - accuracy: 0.148 - ETA: 21s - loss: 3.3049 - accuracy: 0.148 - ETA: 20s - loss: 3.3042 - accuracy: 0.148 - ETA: 19s - loss: 3.3046 - accuracy: 0.148 - ETA: 19s - loss: 3.3047 - accuracy: 0.148 - ETA: 18s - loss: 3.3046 - accuracy: 0.148 - ETA: 18s - loss: 3.3046 - accuracy: 0.148 - ETA: 17s - loss: 3.3047 - accuracy: 0.148 - ETA: 17s - loss: 3.3046 - accuracy: 0.148 - ETA: 16s - loss: 3.3044 - accuracy: 0.148 - ETA: 15s - loss: 3.3047 - accuracy: 0.148 - ETA: 15s - loss: 3.3049 - accuracy: 0.148 - ETA: 14s - loss: 3.3050 - accuracy: 0.148 - ETA: 14s - loss: 3.3049 - accuracy: 0.148 - ETA: 13s - loss: 3.3049 - accuracy: 0.148 - ETA: 13s - loss: 3.3049 - accuracy: 0.148 - ETA: 12s - loss: 3.3047 - accuracy: 0.148 - ETA: 11s - loss: 3.3043 - accuracy: 0.148 - ETA: 11s - loss: 3.3042 - accuracy: 0.148 - ETA: 10s - loss: 3.3039 - accuracy: 0.148 - ETA: 10s - loss: 3.3035 - accuracy: 0.148 - ETA: 9s - loss: 3.3038 - accuracy: 0.148 - ETA: 9s - loss: 3.3039 - accuracy: 0.14 - ETA: 8s - loss: 3.3039 - accuracy: 0.14 - ETA: 7s - loss: 3.3033 - accuracy: 0.14 - ETA: 7s - loss: 3.3033 - accuracy: 0.14 - ETA: 6s - loss: 3.3036 - accuracy: 0.14 - ETA: 6s - loss: 3.3031 - accuracy: 0.14 - ETA: 5s - loss: 3.3030 - accuracy: 0.14 - ETA: 5s - loss: 3.3028 - accuracy: 0.14 - ETA: 4s - loss: 3.3026 - accuracy: 0.14 - ETA: 4s - loss: 3.3028 - accuracy: 0.14 - ETA: 3s - loss: 3.3026 - accuracy: 0.14 - ETA: 2s - loss: 3.3019 - accuracy: 0.14 - ETA: 2s - loss: 3.3013 - accuracy: 0.14 - ETA: 1s - loss: 3.3007 - accuracy: 0.14 - ETA: 1s - loss: 3.3008 - accuracy: 0.14 - ETA: 0s - loss: 3.3000 - accuracy: 0.14 - ETA: 0s - loss: 3.3003 - accuracy: 0.14 - 201s 5ms/step - loss: 3.3004 - accuracy: 0.1493 - val_loss: 4.0136 - val_accuracy: 0.0178\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:17 - loss: 3.5156 - accuracy: 0.13 - ETA: 3:07 - loss: 3.3262 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3237 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2902 - accuracy: 0.16 - ETA: 3:03 - loss: 3.3248 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2908 - accuracy: 0.16 - ETA: 3:01 - loss: 3.3069 - accuracy: 0.16 - ETA: 3:00 - loss: 3.3024 - accuracy: 0.16 - ETA: 2:59 - loss: 3.3043 - accuracy: 0.16 - ETA: 2:58 - loss: 3.2987 - accuracy: 0.16 - ETA: 2:57 - loss: 3.3008 - accuracy: 0.16 - ETA: 2:57 - loss: 3.3076 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2946 - accuracy: 0.16 - ETA: 2:56 - loss: 3.2906 - accuracy: 0.16 - ETA: 2:56 - loss: 3.2844 - accuracy: 0.16 - ETA: 2:55 - loss: 3.2954 - accuracy: 0.16 - ETA: 2:54 - loss: 3.2925 - accuracy: 0.15 - ETA: 2:54 - loss: 3.3001 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2985 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3051 - accuracy: 0.15 - ETA: 2:52 - loss: 3.3070 - accuracy: 0.15 - ETA: 2:52 - loss: 3.3051 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2962 - accuracy: 0.16 - ETA: 2:52 - loss: 3.2906 - accuracy: 0.16 - ETA: 2:52 - loss: 3.2943 - accuracy: 0.16 - ETA: 2:52 - loss: 3.2973 - accuracy: 0.16 - ETA: 2:52 - loss: 3.2956 - accuracy: 0.16 - ETA: 2:51 - loss: 3.2992 - accuracy: 0.16 - ETA: 2:51 - loss: 3.2934 - accuracy: 0.16 - ETA: 2:50 - loss: 3.2929 - accuracy: 0.16 - ETA: 2:49 - loss: 3.2966 - accuracy: 0.16 - ETA: 2:49 - loss: 3.2997 - accuracy: 0.16 - ETA: 2:48 - loss: 3.2961 - accuracy: 0.16 - ETA: 2:48 - loss: 3.3035 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2954 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2941 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2960 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2965 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2997 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2966 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2977 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2932 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2940 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2966 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2976 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2992 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2978 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2965 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2962 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2939 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2939 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2929 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2940 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2942 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2947 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2929 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2962 - accuracy: 0.15 - ETA: 2:34 - loss: 3.3019 - accuracy: 0.15 - ETA: 2:33 - loss: 3.3010 - accuracy: 0.15 - ETA: 2:33 - loss: 3.3019 - accuracy: 0.15 - ETA: 2:32 - loss: 3.3017 - accuracy: 0.15 - ETA: 2:31 - loss: 3.3060 - accuracy: 0.15 - ETA: 2:31 - loss: 3.3057 - accuracy: 0.15 - ETA: 2:30 - loss: 3.3097 - accuracy: 0.15 - ETA: 2:30 - loss: 3.3074 - accuracy: 0.15 - ETA: 2:29 - loss: 3.3054 - accuracy: 0.15 - ETA: 2:28 - loss: 3.3066 - accuracy: 0.15 - ETA: 2:28 - loss: 3.3029 - accuracy: 0.15 - ETA: 2:27 - loss: 3.3048 - accuracy: 0.15 - ETA: 2:27 - loss: 3.3055 - accuracy: 0.15 - ETA: 2:26 - loss: 3.3070 - accuracy: 0.15 - ETA: 2:26 - loss: 3.3058 - accuracy: 0.15 - ETA: 2:25 - loss: 3.3089 - accuracy: 0.15 - ETA: 2:24 - loss: 3.3082 - accuracy: 0.15 - ETA: 2:24 - loss: 3.3058 - accuracy: 0.15 - ETA: 2:23 - loss: 3.3086 - accuracy: 0.15 - ETA: 2:23 - loss: 3.3102 - accuracy: 0.15 - ETA: 2:22 - loss: 3.3096 - accuracy: 0.15 - ETA: 2:22 - loss: 3.3100 - accuracy: 0.15 - ETA: 2:21 - loss: 3.3111 - accuracy: 0.15 - ETA: 2:21 - loss: 3.3116 - accuracy: 0.15 - ETA: 2:20 - loss: 3.3130 - accuracy: 0.15 - ETA: 2:20 - loss: 3.3099 - accuracy: 0.15 - ETA: 2:19 - loss: 3.3093 - accuracy: 0.15 - ETA: 2:19 - loss: 3.3076 - accuracy: 0.15 - ETA: 2:18 - loss: 3.3074 - accuracy: 0.15 - ETA: 2:18 - loss: 3.3074 - accuracy: 0.15 - ETA: 2:17 - loss: 3.3087 - accuracy: 0.15 - ETA: 2:16 - loss: 3.3084 - accuracy: 0.15 - ETA: 2:16 - loss: 3.3072 - accuracy: 0.15 - ETA: 2:15 - loss: 3.3066 - accuracy: 0.15 - ETA: 2:15 - loss: 3.3072 - accuracy: 0.15 - ETA: 2:14 - loss: 3.3059 - accuracy: 0.15 - ETA: 2:13 - loss: 3.3064 - accuracy: 0.15 - ETA: 2:13 - loss: 3.3062 - accuracy: 0.15 - ETA: 2:12 - loss: 3.3042 - accuracy: 0.15 - ETA: 2:12 - loss: 3.3043 - accuracy: 0.15 - ETA: 2:11 - loss: 3.3051 - accuracy: 0.15 - ETA: 2:11 - loss: 3.3035 - accuracy: 0.15 - ETA: 2:10 - loss: 3.3031 - accuracy: 0.15 - ETA: 2:09 - loss: 3.3035 - accuracy: 0.15 - ETA: 2:09 - loss: 3.3034 - accuracy: 0.15 - ETA: 2:08 - loss: 3.3041 - accuracy: 0.15 - ETA: 2:08 - loss: 3.3041 - accuracy: 0.15 - ETA: 2:07 - loss: 3.3022 - accuracy: 0.15 - ETA: 2:07 - loss: 3.3009 - accuracy: 0.15 - ETA: 2:06 - loss: 3.3013 - accuracy: 0.15 - ETA: 2:06 - loss: 3.3022 - accuracy: 0.15 - ETA: 2:05 - loss: 3.3006 - accuracy: 0.15 - ETA: 2:05 - loss: 3.3007 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2991 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2979 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2965 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2959 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2954 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2955 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2923 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2916 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2912 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2900 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2902 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2905 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2891 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2890 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2892 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2888 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2882 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2872 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2889 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2875 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2884 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2883 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2888 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2894 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2893 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2892 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2883 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2882 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2873 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2870 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2872 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2870 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2875 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2867 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2873 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2879 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2877 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2882 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2876 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2875 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2865 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2849 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2851 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2850 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2838 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2830 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2822 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2835 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2826 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2825 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2812 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2809 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2806 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2807 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2808 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2823 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2817 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2814 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2841 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2831 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2816 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2814 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2806 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2800 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2807 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2818 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2812 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2813 - accuracy: 0.1543"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.2817 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2818 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2825 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2818 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2831 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2831 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2837 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2823 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2823 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2847 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2844 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2825 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2825 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2821 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2817 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2811 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2809 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2814 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2818 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2815 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2807 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2819 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2822 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2825 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2818 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2819 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2818 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2816 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2819 - accuracy: 0.15 - ETA: 59s - loss: 3.2820 - accuracy: 0.1543 - ETA: 58s - loss: 3.2817 - accuracy: 0.154 - ETA: 58s - loss: 3.2816 - accuracy: 0.154 - ETA: 57s - loss: 3.2819 - accuracy: 0.154 - ETA: 57s - loss: 3.2826 - accuracy: 0.154 - ETA: 56s - loss: 3.2830 - accuracy: 0.153 - ETA: 56s - loss: 3.2831 - accuracy: 0.154 - ETA: 55s - loss: 3.2823 - accuracy: 0.154 - ETA: 54s - loss: 3.2822 - accuracy: 0.154 - ETA: 54s - loss: 3.2817 - accuracy: 0.154 - ETA: 53s - loss: 3.2816 - accuracy: 0.154 - ETA: 53s - loss: 3.2813 - accuracy: 0.154 - ETA: 52s - loss: 3.2814 - accuracy: 0.154 - ETA: 52s - loss: 3.2815 - accuracy: 0.154 - ETA: 51s - loss: 3.2824 - accuracy: 0.154 - ETA: 50s - loss: 3.2830 - accuracy: 0.154 - ETA: 50s - loss: 3.2831 - accuracy: 0.154 - ETA: 49s - loss: 3.2834 - accuracy: 0.154 - ETA: 49s - loss: 3.2845 - accuracy: 0.153 - ETA: 48s - loss: 3.2842 - accuracy: 0.153 - ETA: 48s - loss: 3.2835 - accuracy: 0.153 - ETA: 47s - loss: 3.2836 - accuracy: 0.154 - ETA: 46s - loss: 3.2830 - accuracy: 0.154 - ETA: 46s - loss: 3.2824 - accuracy: 0.154 - ETA: 45s - loss: 3.2833 - accuracy: 0.154 - ETA: 45s - loss: 3.2837 - accuracy: 0.153 - ETA: 44s - loss: 3.2841 - accuracy: 0.153 - ETA: 44s - loss: 3.2838 - accuracy: 0.153 - ETA: 43s - loss: 3.2836 - accuracy: 0.153 - ETA: 43s - loss: 3.2832 - accuracy: 0.154 - ETA: 42s - loss: 3.2832 - accuracy: 0.154 - ETA: 41s - loss: 3.2833 - accuracy: 0.154 - ETA: 41s - loss: 3.2827 - accuracy: 0.154 - ETA: 40s - loss: 3.2819 - accuracy: 0.154 - ETA: 40s - loss: 3.2814 - accuracy: 0.154 - ETA: 39s - loss: 3.2815 - accuracy: 0.154 - ETA: 39s - loss: 3.2815 - accuracy: 0.154 - ETA: 38s - loss: 3.2812 - accuracy: 0.154 - ETA: 37s - loss: 3.2811 - accuracy: 0.154 - ETA: 37s - loss: 3.2810 - accuracy: 0.154 - ETA: 36s - loss: 3.2809 - accuracy: 0.154 - ETA: 36s - loss: 3.2803 - accuracy: 0.154 - ETA: 35s - loss: 3.2802 - accuracy: 0.154 - ETA: 35s - loss: 3.2794 - accuracy: 0.154 - ETA: 34s - loss: 3.2799 - accuracy: 0.154 - ETA: 34s - loss: 3.2798 - accuracy: 0.155 - ETA: 33s - loss: 3.2799 - accuracy: 0.154 - ETA: 32s - loss: 3.2799 - accuracy: 0.154 - ETA: 32s - loss: 3.2794 - accuracy: 0.154 - ETA: 31s - loss: 3.2798 - accuracy: 0.154 - ETA: 31s - loss: 3.2793 - accuracy: 0.155 - ETA: 30s - loss: 3.2837 - accuracy: 0.155 - ETA: 30s - loss: 3.2836 - accuracy: 0.155 - ETA: 29s - loss: 3.2838 - accuracy: 0.155 - ETA: 28s - loss: 3.2842 - accuracy: 0.155 - ETA: 28s - loss: 3.2836 - accuracy: 0.154 - ETA: 27s - loss: 3.2835 - accuracy: 0.154 - ETA: 27s - loss: 3.2833 - accuracy: 0.154 - ETA: 26s - loss: 3.2840 - accuracy: 0.154 - ETA: 26s - loss: 3.2840 - accuracy: 0.154 - ETA: 25s - loss: 3.2846 - accuracy: 0.154 - ETA: 24s - loss: 3.2843 - accuracy: 0.154 - ETA: 24s - loss: 3.2850 - accuracy: 0.154 - ETA: 23s - loss: 3.2860 - accuracy: 0.154 - ETA: 23s - loss: 3.2858 - accuracy: 0.154 - ETA: 22s - loss: 3.2860 - accuracy: 0.154 - ETA: 22s - loss: 3.2865 - accuracy: 0.154 - ETA: 21s - loss: 3.2871 - accuracy: 0.154 - ETA: 20s - loss: 3.2878 - accuracy: 0.154 - ETA: 20s - loss: 3.2883 - accuracy: 0.154 - ETA: 19s - loss: 3.2896 - accuracy: 0.154 - ETA: 19s - loss: 3.2895 - accuracy: 0.154 - ETA: 18s - loss: 3.2898 - accuracy: 0.154 - ETA: 18s - loss: 3.2906 - accuracy: 0.154 - ETA: 17s - loss: 3.2902 - accuracy: 0.154 - ETA: 17s - loss: 3.2910 - accuracy: 0.154 - ETA: 16s - loss: 3.2914 - accuracy: 0.154 - ETA: 15s - loss: 3.2926 - accuracy: 0.153 - ETA: 15s - loss: 3.2930 - accuracy: 0.153 - ETA: 14s - loss: 3.2938 - accuracy: 0.153 - ETA: 14s - loss: 3.2940 - accuracy: 0.153 - ETA: 13s - loss: 3.2936 - accuracy: 0.153 - ETA: 13s - loss: 3.2941 - accuracy: 0.153 - ETA: 12s - loss: 3.2942 - accuracy: 0.153 - ETA: 11s - loss: 3.2949 - accuracy: 0.153 - ETA: 11s - loss: 3.2955 - accuracy: 0.153 - ETA: 10s - loss: 3.2958 - accuracy: 0.153 - ETA: 10s - loss: 3.2965 - accuracy: 0.153 - ETA: 9s - loss: 3.2969 - accuracy: 0.153 - ETA: 9s - loss: 3.2969 - accuracy: 0.15 - ETA: 8s - loss: 3.2975 - accuracy: 0.15 - ETA: 7s - loss: 3.2982 - accuracy: 0.15 - ETA: 7s - loss: 3.2985 - accuracy: 0.15 - ETA: 6s - loss: 3.2987 - accuracy: 0.15 - ETA: 6s - loss: 3.2989 - accuracy: 0.15 - ETA: 5s - loss: 3.2993 - accuracy: 0.15 - ETA: 5s - loss: 3.2998 - accuracy: 0.15 - ETA: 4s - loss: 3.2999 - accuracy: 0.15 - ETA: 4s - loss: 3.2998 - accuracy: 0.15 - ETA: 3s - loss: 3.3003 - accuracy: 0.15 - ETA: 2s - loss: 3.3005 - accuracy: 0.15 - ETA: 2s - loss: 3.3005 - accuracy: 0.15 - ETA: 1s - loss: 3.3007 - accuracy: 0.15 - ETA: 1s - loss: 3.3009 - accuracy: 0.15 - ETA: 0s - loss: 3.3012 - accuracy: 0.15 - ETA: 0s - loss: 3.3014 - accuracy: 0.15 - 200s 5ms/step - loss: 3.3015 - accuracy: 0.1516 - val_loss: 3.9753 - val_accuracy: 0.0125\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:26 - loss: 3.3769 - accuracy: 0.17 - ETA: 3:11 - loss: 3.3495 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3497 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3534 - accuracy: 0.13 - ETA: 3:05 - loss: 3.3174 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3170 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3261 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3434 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3819 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3677 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3651 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3730 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3740 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3740 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3729 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3699 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3549 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3580 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3583 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3504 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3527 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3581 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3511 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3513 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3538 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3443 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3361 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3344 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3297 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3342 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3274 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3225 - accuracy: 0.15 - ETA: 2:50 - loss: 3.3257 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3295 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3340 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3314 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3340 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3346 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3279 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3275 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3289 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3284 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3284 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3286 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3285 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3302 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3307 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3281 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3292 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3304 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3307 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3282 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3279 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3268 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3258 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3222 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3216 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3252 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3275 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3264 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3246 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3243 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3233 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3226 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3230 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3222 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3229 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3235 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3239 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3242 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3206 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3168 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3163 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3144 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3127 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3127 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3115 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3124 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3130 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3116 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3113 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3116 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3117 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3110 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3107 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3108 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3080 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3053 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3057 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3060 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3052 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3048 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3048 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3062 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3082 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3100 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3178 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3206 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3204 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3211 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3210 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3209 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3208 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3217 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3209 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3210 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3210 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3204 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3213 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3200 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3203 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3197 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3196 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3182 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3185 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3177 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3167 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3157 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3151 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3153 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3159 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3159 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3168 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3176 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3173 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3170 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3183 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3194 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3190 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3185 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3195 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3189 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3182 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3171 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3170 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3176 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3184 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3190 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3190 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3202 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3204 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3197 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3183 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3186 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3182 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3186 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3197 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3204 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3216 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3200 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3197 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3194 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3196 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3198 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3204 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3207 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3195 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3191 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3194 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3195 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3196 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3194 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3207 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3193 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3200 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3200 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3201 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3205 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3204 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3194 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3185 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3180 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3174 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3178 - accuracy: 0.1474"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.3174 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3179 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3174 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3166 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3172 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3169 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3155 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3148 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3148 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3146 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3147 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3137 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3134 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3133 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3135 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3127 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3130 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3119 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3115 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3109 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3102 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3099 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3102 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3105 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3101 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3103 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3106 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3111 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3113 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3110 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3104 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3105 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3107 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3108 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3110 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3094 - accuracy: 0.14 - ETA: 59s - loss: 3.3099 - accuracy: 0.1482 - ETA: 59s - loss: 3.3094 - accuracy: 0.148 - ETA: 58s - loss: 3.3094 - accuracy: 0.148 - ETA: 57s - loss: 3.3103 - accuracy: 0.148 - ETA: 57s - loss: 3.3103 - accuracy: 0.148 - ETA: 56s - loss: 3.3099 - accuracy: 0.148 - ETA: 56s - loss: 3.3095 - accuracy: 0.148 - ETA: 55s - loss: 3.3092 - accuracy: 0.148 - ETA: 55s - loss: 3.3086 - accuracy: 0.148 - ETA: 54s - loss: 3.3082 - accuracy: 0.148 - ETA: 54s - loss: 3.3077 - accuracy: 0.148 - ETA: 53s - loss: 3.3076 - accuracy: 0.148 - ETA: 52s - loss: 3.3080 - accuracy: 0.148 - ETA: 52s - loss: 3.3084 - accuracy: 0.148 - ETA: 51s - loss: 3.3084 - accuracy: 0.148 - ETA: 51s - loss: 3.3080 - accuracy: 0.148 - ETA: 50s - loss: 3.3080 - accuracy: 0.148 - ETA: 50s - loss: 3.3083 - accuracy: 0.148 - ETA: 49s - loss: 3.3065 - accuracy: 0.149 - ETA: 48s - loss: 3.3062 - accuracy: 0.149 - ETA: 48s - loss: 3.3061 - accuracy: 0.149 - ETA: 47s - loss: 3.3056 - accuracy: 0.149 - ETA: 47s - loss: 3.3057 - accuracy: 0.149 - ETA: 46s - loss: 3.3063 - accuracy: 0.149 - ETA: 46s - loss: 3.3068 - accuracy: 0.149 - ETA: 45s - loss: 3.3052 - accuracy: 0.149 - ETA: 44s - loss: 3.3053 - accuracy: 0.149 - ETA: 44s - loss: 3.3051 - accuracy: 0.149 - ETA: 43s - loss: 3.3048 - accuracy: 0.149 - ETA: 43s - loss: 3.3049 - accuracy: 0.149 - ETA: 42s - loss: 3.3050 - accuracy: 0.149 - ETA: 42s - loss: 3.3048 - accuracy: 0.149 - ETA: 41s - loss: 3.3050 - accuracy: 0.149 - ETA: 41s - loss: 3.3049 - accuracy: 0.149 - ETA: 40s - loss: 3.3051 - accuracy: 0.149 - ETA: 39s - loss: 3.3052 - accuracy: 0.149 - ETA: 39s - loss: 3.3053 - accuracy: 0.149 - ETA: 38s - loss: 3.3059 - accuracy: 0.149 - ETA: 38s - loss: 3.3054 - accuracy: 0.149 - ETA: 37s - loss: 3.3045 - accuracy: 0.149 - ETA: 37s - loss: 3.3041 - accuracy: 0.150 - ETA: 36s - loss: 3.3041 - accuracy: 0.149 - ETA: 35s - loss: 3.3044 - accuracy: 0.149 - ETA: 35s - loss: 3.3038 - accuracy: 0.150 - ETA: 34s - loss: 3.3039 - accuracy: 0.149 - ETA: 34s - loss: 3.3041 - accuracy: 0.149 - ETA: 33s - loss: 3.3039 - accuracy: 0.150 - ETA: 33s - loss: 3.3033 - accuracy: 0.150 - ETA: 32s - loss: 3.3036 - accuracy: 0.149 - ETA: 31s - loss: 3.3034 - accuracy: 0.149 - ETA: 31s - loss: 3.3032 - accuracy: 0.149 - ETA: 30s - loss: 3.3027 - accuracy: 0.150 - ETA: 30s - loss: 3.3028 - accuracy: 0.150 - ETA: 29s - loss: 3.3028 - accuracy: 0.150 - ETA: 29s - loss: 3.3027 - accuracy: 0.150 - ETA: 28s - loss: 3.3027 - accuracy: 0.150 - ETA: 27s - loss: 3.3026 - accuracy: 0.150 - ETA: 27s - loss: 3.3025 - accuracy: 0.150 - ETA: 26s - loss: 3.3023 - accuracy: 0.150 - ETA: 26s - loss: 3.3017 - accuracy: 0.150 - ETA: 25s - loss: 3.3022 - accuracy: 0.150 - ETA: 25s - loss: 3.3021 - accuracy: 0.150 - ETA: 24s - loss: 3.3018 - accuracy: 0.150 - ETA: 23s - loss: 3.3023 - accuracy: 0.150 - ETA: 23s - loss: 3.3022 - accuracy: 0.150 - ETA: 22s - loss: 3.3014 - accuracy: 0.150 - ETA: 22s - loss: 3.3009 - accuracy: 0.150 - ETA: 21s - loss: 3.3010 - accuracy: 0.150 - ETA: 21s - loss: 3.3008 - accuracy: 0.150 - ETA: 20s - loss: 3.3008 - accuracy: 0.150 - ETA: 19s - loss: 3.3003 - accuracy: 0.150 - ETA: 19s - loss: 3.3001 - accuracy: 0.150 - ETA: 18s - loss: 3.2997 - accuracy: 0.150 - ETA: 18s - loss: 3.2997 - accuracy: 0.150 - ETA: 17s - loss: 3.2994 - accuracy: 0.151 - ETA: 17s - loss: 3.3000 - accuracy: 0.151 - ETA: 16s - loss: 3.3000 - accuracy: 0.151 - ETA: 15s - loss: 3.3002 - accuracy: 0.150 - ETA: 15s - loss: 3.2995 - accuracy: 0.150 - ETA: 14s - loss: 3.2987 - accuracy: 0.151 - ETA: 14s - loss: 3.2978 - accuracy: 0.151 - ETA: 13s - loss: 3.2976 - accuracy: 0.151 - ETA: 13s - loss: 3.2975 - accuracy: 0.151 - ETA: 12s - loss: 3.2973 - accuracy: 0.151 - ETA: 11s - loss: 3.2973 - accuracy: 0.151 - ETA: 11s - loss: 3.2970 - accuracy: 0.151 - ETA: 10s - loss: 3.2968 - accuracy: 0.151 - ETA: 10s - loss: 3.2965 - accuracy: 0.151 - ETA: 9s - loss: 3.2968 - accuracy: 0.151 - ETA: 9s - loss: 3.2969 - accuracy: 0.15 - ETA: 8s - loss: 3.2971 - accuracy: 0.15 - ETA: 7s - loss: 3.2970 - accuracy: 0.15 - ETA: 7s - loss: 3.2970 - accuracy: 0.15 - ETA: 6s - loss: 3.2970 - accuracy: 0.15 - ETA: 6s - loss: 3.2973 - accuracy: 0.15 - ETA: 5s - loss: 3.2969 - accuracy: 0.15 - ETA: 5s - loss: 3.2970 - accuracy: 0.15 - ETA: 4s - loss: 3.2970 - accuracy: 0.15 - ETA: 4s - loss: 3.2963 - accuracy: 0.15 - ETA: 3s - loss: 3.2961 - accuracy: 0.15 - ETA: 2s - loss: 3.2960 - accuracy: 0.15 - ETA: 2s - loss: 3.2960 - accuracy: 0.15 - ETA: 1s - loss: 3.2961 - accuracy: 0.15 - ETA: 1s - loss: 3.2964 - accuracy: 0.15 - ETA: 0s - loss: 3.2960 - accuracy: 0.15 - ETA: 0s - loss: 3.2956 - accuracy: 0.15 - 201s 5ms/step - loss: 3.2954 - accuracy: 0.1514 - val_loss: 3.8985 - val_accuracy: 0.0142\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:20 - loss: 3.3692 - accuracy: 0.12 - ETA: 3:12 - loss: 3.2370 - accuracy: 0.15 - ETA: 3:08 - loss: 3.2719 - accuracy: 0.15 - ETA: 3:07 - loss: 3.3235 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3024 - accuracy: 0.15 - ETA: 3:03 - loss: 3.3121 - accuracy: 0.15 - ETA: 3:02 - loss: 3.3106 - accuracy: 0.15 - ETA: 3:01 - loss: 3.3024 - accuracy: 0.14 - ETA: 3:01 - loss: 3.2953 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2916 - accuracy: 0.15 - ETA: 3:03 - loss: 3.3040 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2740 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2537 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2501 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2525 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2452 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2442 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2448 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2470 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2473 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2432 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2583 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2595 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2536 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2538 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2540 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2499 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2470 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2554 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2806 - accuracy: 0.15 - ETA: 2:53 - loss: 3.2820 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2824 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2790 - accuracy: 0.15 - ETA: 2:51 - loss: 3.2791 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2797 - accuracy: 0.15 - ETA: 2:50 - loss: 3.2803 - accuracy: 0.15 - ETA: 2:49 - loss: 3.2814 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2787 - accuracy: 0.15 - ETA: 2:48 - loss: 3.2783 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2728 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2743 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2765 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2795 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2805 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2788 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2823 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2809 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2841 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2814 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2800 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2753 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2734 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2751 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2743 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2738 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2725 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2703 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2668 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2653 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2665 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2663 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2648 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2642 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2651 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2676 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2655 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2644 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2654 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2649 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2615 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2608 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2593 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2575 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2588 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2614 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2605 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2603 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2579 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2583 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2567 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2547 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2539 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2544 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2525 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2521 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2505 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2511 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2510 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2521 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2499 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2506 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2510 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2511 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2523 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2522 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2531 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2539 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2545 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2541 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2557 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2556 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2568 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2560 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2563 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2567 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2573 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2588 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2593 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2602 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2612 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2614 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2616 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2609 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2595 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2577 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2561 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2558 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2569 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2578 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2568 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2574 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2589 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2594 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2600 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2601 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2617 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2591 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2589 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2616 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2628 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2638 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2639 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2630 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2627 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2621 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2626 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2635 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2629 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2638 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2647 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2659 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2661 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2658 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2657 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2652 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2648 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2654 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2648 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2639 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2638 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2638 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2645 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2645 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2658 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2657 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2665 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2671 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2663 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2671 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2669 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2677 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2679 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2680 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2669 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2667 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2660 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2657 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2656 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2660 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2664 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2670 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2685 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2690 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2700 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2688 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2692 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2701 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2699 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2705 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2704 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2710 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2706 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2714 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2719 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2714 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2721 - accuracy: 0.1553"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.2714 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2720 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2719 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2719 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2718 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2729 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2726 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2729 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2735 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2741 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2741 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2738 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2740 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2741 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2734 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2728 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2733 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2740 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2741 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2748 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2741 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2735 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2727 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2729 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2739 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2744 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2745 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2743 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2743 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2744 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2739 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2740 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2737 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2742 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2751 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2752 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2759 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2757 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2765 - accuracy: 0.15 - ETA: 59s - loss: 3.2764 - accuracy: 0.1546 - ETA: 59s - loss: 3.2762 - accuracy: 0.154 - ETA: 58s - loss: 3.2769 - accuracy: 0.154 - ETA: 57s - loss: 3.2759 - accuracy: 0.154 - ETA: 57s - loss: 3.2758 - accuracy: 0.154 - ETA: 56s - loss: 3.2755 - accuracy: 0.154 - ETA: 56s - loss: 3.2758 - accuracy: 0.154 - ETA: 55s - loss: 3.2750 - accuracy: 0.154 - ETA: 55s - loss: 3.2746 - accuracy: 0.155 - ETA: 54s - loss: 3.2736 - accuracy: 0.155 - ETA: 53s - loss: 3.2743 - accuracy: 0.155 - ETA: 53s - loss: 3.2740 - accuracy: 0.155 - ETA: 52s - loss: 3.2740 - accuracy: 0.154 - ETA: 52s - loss: 3.2748 - accuracy: 0.154 - ETA: 51s - loss: 3.2742 - accuracy: 0.154 - ETA: 51s - loss: 3.2751 - accuracy: 0.154 - ETA: 50s - loss: 3.2747 - accuracy: 0.154 - ETA: 49s - loss: 3.2751 - accuracy: 0.154 - ETA: 49s - loss: 3.2757 - accuracy: 0.154 - ETA: 48s - loss: 3.2752 - accuracy: 0.154 - ETA: 48s - loss: 3.2760 - accuracy: 0.154 - ETA: 47s - loss: 3.2764 - accuracy: 0.154 - ETA: 47s - loss: 3.2768 - accuracy: 0.154 - ETA: 46s - loss: 3.2763 - accuracy: 0.154 - ETA: 46s - loss: 3.2756 - accuracy: 0.154 - ETA: 45s - loss: 3.2752 - accuracy: 0.154 - ETA: 44s - loss: 3.2765 - accuracy: 0.154 - ETA: 44s - loss: 3.2765 - accuracy: 0.154 - ETA: 43s - loss: 3.2760 - accuracy: 0.154 - ETA: 43s - loss: 3.2757 - accuracy: 0.154 - ETA: 42s - loss: 3.2752 - accuracy: 0.154 - ETA: 42s - loss: 3.2755 - accuracy: 0.154 - ETA: 41s - loss: 3.2752 - accuracy: 0.154 - ETA: 40s - loss: 3.2750 - accuracy: 0.154 - ETA: 40s - loss: 3.2754 - accuracy: 0.154 - ETA: 39s - loss: 3.2745 - accuracy: 0.154 - ETA: 39s - loss: 3.2744 - accuracy: 0.154 - ETA: 38s - loss: 3.2743 - accuracy: 0.154 - ETA: 38s - loss: 3.2742 - accuracy: 0.154 - ETA: 37s - loss: 3.2743 - accuracy: 0.154 - ETA: 36s - loss: 3.2755 - accuracy: 0.154 - ETA: 36s - loss: 3.2751 - accuracy: 0.154 - ETA: 35s - loss: 3.2747 - accuracy: 0.154 - ETA: 35s - loss: 3.2754 - accuracy: 0.154 - ETA: 34s - loss: 3.2752 - accuracy: 0.154 - ETA: 34s - loss: 3.2749 - accuracy: 0.154 - ETA: 33s - loss: 3.2746 - accuracy: 0.154 - ETA: 32s - loss: 3.2743 - accuracy: 0.154 - ETA: 32s - loss: 3.2740 - accuracy: 0.154 - ETA: 31s - loss: 3.2742 - accuracy: 0.154 - ETA: 31s - loss: 3.2735 - accuracy: 0.154 - ETA: 30s - loss: 3.2738 - accuracy: 0.154 - ETA: 30s - loss: 3.2738 - accuracy: 0.154 - ETA: 29s - loss: 3.2737 - accuracy: 0.154 - ETA: 29s - loss: 3.2739 - accuracy: 0.154 - ETA: 28s - loss: 3.2736 - accuracy: 0.154 - ETA: 27s - loss: 3.2732 - accuracy: 0.154 - ETA: 27s - loss: 3.2729 - accuracy: 0.154 - ETA: 26s - loss: 3.2731 - accuracy: 0.154 - ETA: 26s - loss: 3.2729 - accuracy: 0.153 - ETA: 25s - loss: 3.2726 - accuracy: 0.154 - ETA: 25s - loss: 3.2727 - accuracy: 0.154 - ETA: 24s - loss: 3.2725 - accuracy: 0.154 - ETA: 23s - loss: 3.2719 - accuracy: 0.154 - ETA: 23s - loss: 3.2720 - accuracy: 0.154 - ETA: 22s - loss: 3.2723 - accuracy: 0.154 - ETA: 22s - loss: 3.2726 - accuracy: 0.154 - ETA: 21s - loss: 3.2739 - accuracy: 0.154 - ETA: 21s - loss: 3.2742 - accuracy: 0.154 - ETA: 20s - loss: 3.2757 - accuracy: 0.154 - ETA: 19s - loss: 3.2763 - accuracy: 0.154 - ETA: 19s - loss: 3.2774 - accuracy: 0.153 - ETA: 18s - loss: 3.2775 - accuracy: 0.154 - ETA: 18s - loss: 3.2788 - accuracy: 0.153 - ETA: 17s - loss: 3.2791 - accuracy: 0.153 - ETA: 17s - loss: 3.2791 - accuracy: 0.154 - ETA: 16s - loss: 3.2788 - accuracy: 0.154 - ETA: 15s - loss: 3.2783 - accuracy: 0.154 - ETA: 15s - loss: 3.2783 - accuracy: 0.154 - ETA: 14s - loss: 3.2783 - accuracy: 0.154 - ETA: 14s - loss: 3.2778 - accuracy: 0.154 - ETA: 13s - loss: 3.2786 - accuracy: 0.154 - ETA: 13s - loss: 3.2785 - accuracy: 0.154 - ETA: 12s - loss: 3.2785 - accuracy: 0.154 - ETA: 11s - loss: 3.2791 - accuracy: 0.153 - ETA: 11s - loss: 3.2791 - accuracy: 0.153 - ETA: 10s - loss: 3.2785 - accuracy: 0.153 - ETA: 10s - loss: 3.2789 - accuracy: 0.153 - ETA: 9s - loss: 3.2786 - accuracy: 0.153 - ETA: 9s - loss: 3.2794 - accuracy: 0.15 - ETA: 8s - loss: 3.2798 - accuracy: 0.15 - ETA: 7s - loss: 3.2794 - accuracy: 0.15 - ETA: 7s - loss: 3.2793 - accuracy: 0.15 - ETA: 6s - loss: 3.2798 - accuracy: 0.15 - ETA: 6s - loss: 3.2808 - accuracy: 0.15 - ETA: 5s - loss: 3.2811 - accuracy: 0.15 - ETA: 5s - loss: 3.2816 - accuracy: 0.15 - ETA: 4s - loss: 3.2814 - accuracy: 0.15 - ETA: 4s - loss: 3.2814 - accuracy: 0.15 - ETA: 3s - loss: 3.2813 - accuracy: 0.15 - ETA: 2s - loss: 3.2817 - accuracy: 0.15 - ETA: 2s - loss: 3.2818 - accuracy: 0.15 - ETA: 1s - loss: 3.2818 - accuracy: 0.15 - ETA: 1s - loss: 3.2818 - accuracy: 0.15 - ETA: 0s - loss: 3.2821 - accuracy: 0.15 - ETA: 0s - loss: 3.2823 - accuracy: 0.15 - 200s 5ms/step - loss: 3.2822 - accuracy: 0.1530 - val_loss: 3.9216 - val_accuracy: 0.0135\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:19 - loss: 3.0815 - accuracy: 0.19 - ETA: 3:08 - loss: 3.1842 - accuracy: 0.16 - ETA: 3:11 - loss: 3.2421 - accuracy: 0.15 - ETA: 3:07 - loss: 3.2557 - accuracy: 0.14 - ETA: 3:06 - loss: 3.2637 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2870 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3024 - accuracy: 0.14 - ETA: 3:03 - loss: 3.2611 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2707 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2699 - accuracy: 0.15 - ETA: 3:06 - loss: 3.2686 - accuracy: 0.15 - ETA: 3:05 - loss: 3.2603 - accuracy: 0.15 - ETA: 3:04 - loss: 3.2405 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2396 - accuracy: 0.16 - ETA: 3:02 - loss: 3.2401 - accuracy: 0.16 - ETA: 3:01 - loss: 3.2476 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2571 - accuracy: 0.15 - ETA: 3:00 - loss: 3.2616 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2612 - accuracy: 0.15 - ETA: 2:59 - loss: 3.2659 - accuracy: 0.15 - ETA: 2:58 - loss: 3.2714 - accuracy: 0.15 - ETA: 2:57 - loss: 3.2688 - accuracy: 0.15 - ETA: 2:56 - loss: 3.2749 - accuracy: 0.15 - ETA: 2:55 - loss: 3.2809 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2836 - accuracy: 0.15 - ETA: 2:54 - loss: 3.2908 - accuracy: 0.14 - ETA: 2:53 - loss: 3.2881 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2921 - accuracy: 0.14 - ETA: 2:52 - loss: 3.2912 - accuracy: 0.14 - ETA: 2:51 - loss: 3.2908 - accuracy: 0.14 - ETA: 2:50 - loss: 3.2904 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2932 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2963 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2955 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2964 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2990 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2973 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2955 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2948 - accuracy: 0.14 - ETA: 2:46 - loss: 3.2954 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2933 - accuracy: 0.14 - ETA: 2:45 - loss: 3.2935 - accuracy: 0.14 - ETA: 2:44 - loss: 3.2960 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:43 - loss: 3.2947 - accuracy: 0.14 - ETA: 2:42 - loss: 3.2939 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2910 - accuracy: 0.14 - ETA: 2:41 - loss: 3.2884 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2873 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2882 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2880 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2867 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2864 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2823 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2829 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2836 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2820 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2824 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2820 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2831 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2830 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2833 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2824 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2787 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2794 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2802 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2803 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2800 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2827 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2876 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2878 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2891 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2940 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2934 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2940 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2918 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2903 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2915 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2901 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2908 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2907 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2910 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2926 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2917 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2923 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2922 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2901 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2904 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2896 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2890 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2881 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2863 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2864 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2862 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2885 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2892 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2881 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2881 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2887 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2882 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2874 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2883 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2893 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2892 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2892 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2878 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2860 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2876 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2877 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2884 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2885 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2881 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2873 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2882 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2896 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2896 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2897 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2912 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2911 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2905 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2895 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2893 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2882 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2868 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2863 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2865 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2856 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2840 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2838 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2840 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2852 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2836 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2841 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2847 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2843 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2835 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2855 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2860 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2854 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2850 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2856 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2840 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2849 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2848 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2856 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2857 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2848 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2845 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2843 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2846 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2850 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2849 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2850 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2850 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2851 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2850 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2849 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2841 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2846 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2845 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2845 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2852 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2843 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2847 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2848 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2849 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2851 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2845 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2840 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2841 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2842 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2847 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2844 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2848 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2848 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2841 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2846 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2837 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2826 - accuracy: 0.1547"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.2828 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2822 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2826 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2822 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2826 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2819 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2820 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2822 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2814 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2812 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2812 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2813 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2820 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2820 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2818 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2831 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2828 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2826 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2823 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2835 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2838 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2836 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2834 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2829 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2832 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2827 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2830 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2826 - accuracy: 0.15 - ETA: 59s - loss: 3.2828 - accuracy: 0.1537 - ETA: 59s - loss: 3.2841 - accuracy: 0.153 - ETA: 58s - loss: 3.2847 - accuracy: 0.153 - ETA: 57s - loss: 3.2852 - accuracy: 0.153 - ETA: 57s - loss: 3.2848 - accuracy: 0.153 - ETA: 56s - loss: 3.2849 - accuracy: 0.153 - ETA: 56s - loss: 3.2845 - accuracy: 0.153 - ETA: 55s - loss: 3.2854 - accuracy: 0.153 - ETA: 55s - loss: 3.2863 - accuracy: 0.153 - ETA: 54s - loss: 3.2861 - accuracy: 0.153 - ETA: 54s - loss: 3.2864 - accuracy: 0.153 - ETA: 53s - loss: 3.2868 - accuracy: 0.153 - ETA: 52s - loss: 3.2871 - accuracy: 0.153 - ETA: 52s - loss: 3.2874 - accuracy: 0.153 - ETA: 51s - loss: 3.2874 - accuracy: 0.153 - ETA: 51s - loss: 3.2873 - accuracy: 0.153 - ETA: 50s - loss: 3.2877 - accuracy: 0.154 - ETA: 50s - loss: 3.2880 - accuracy: 0.153 - ETA: 49s - loss: 3.2873 - accuracy: 0.154 - ETA: 48s - loss: 3.2866 - accuracy: 0.154 - ETA: 48s - loss: 3.2860 - accuracy: 0.154 - ETA: 47s - loss: 3.2854 - accuracy: 0.154 - ETA: 47s - loss: 3.2856 - accuracy: 0.154 - ETA: 46s - loss: 3.2860 - accuracy: 0.154 - ETA: 46s - loss: 3.2855 - accuracy: 0.154 - ETA: 45s - loss: 3.2850 - accuracy: 0.154 - ETA: 44s - loss: 3.2842 - accuracy: 0.154 - ETA: 44s - loss: 3.2837 - accuracy: 0.154 - ETA: 43s - loss: 3.2837 - accuracy: 0.154 - ETA: 43s - loss: 3.2834 - accuracy: 0.154 - ETA: 42s - loss: 3.2832 - accuracy: 0.154 - ETA: 42s - loss: 3.2836 - accuracy: 0.154 - ETA: 41s - loss: 3.2834 - accuracy: 0.154 - ETA: 40s - loss: 3.2842 - accuracy: 0.154 - ETA: 40s - loss: 3.2835 - accuracy: 0.154 - ETA: 39s - loss: 3.2836 - accuracy: 0.154 - ETA: 39s - loss: 3.2834 - accuracy: 0.154 - ETA: 38s - loss: 3.2838 - accuracy: 0.154 - ETA: 38s - loss: 3.2842 - accuracy: 0.154 - ETA: 37s - loss: 3.2837 - accuracy: 0.154 - ETA: 37s - loss: 3.2834 - accuracy: 0.154 - ETA: 36s - loss: 3.2828 - accuracy: 0.154 - ETA: 35s - loss: 3.2827 - accuracy: 0.154 - ETA: 35s - loss: 3.2827 - accuracy: 0.154 - ETA: 34s - loss: 3.2824 - accuracy: 0.154 - ETA: 34s - loss: 3.2827 - accuracy: 0.154 - ETA: 33s - loss: 3.2828 - accuracy: 0.154 - ETA: 33s - loss: 3.2823 - accuracy: 0.154 - ETA: 32s - loss: 3.2829 - accuracy: 0.154 - ETA: 31s - loss: 3.2831 - accuracy: 0.154 - ETA: 31s - loss: 3.2836 - accuracy: 0.154 - ETA: 30s - loss: 3.2836 - accuracy: 0.154 - ETA: 30s - loss: 3.2838 - accuracy: 0.153 - ETA: 29s - loss: 3.2835 - accuracy: 0.154 - ETA: 29s - loss: 3.2839 - accuracy: 0.153 - ETA: 28s - loss: 3.2837 - accuracy: 0.154 - ETA: 27s - loss: 3.2840 - accuracy: 0.154 - ETA: 27s - loss: 3.2845 - accuracy: 0.154 - ETA: 26s - loss: 3.2846 - accuracy: 0.154 - ETA: 26s - loss: 3.2843 - accuracy: 0.154 - ETA: 25s - loss: 3.2842 - accuracy: 0.154 - ETA: 25s - loss: 3.2850 - accuracy: 0.153 - ETA: 24s - loss: 3.2854 - accuracy: 0.153 - ETA: 23s - loss: 3.2852 - accuracy: 0.153 - ETA: 23s - loss: 3.2846 - accuracy: 0.154 - ETA: 22s - loss: 3.2842 - accuracy: 0.153 - ETA: 22s - loss: 3.2843 - accuracy: 0.153 - ETA: 21s - loss: 3.2845 - accuracy: 0.153 - ETA: 21s - loss: 3.2843 - accuracy: 0.153 - ETA: 20s - loss: 3.2841 - accuracy: 0.153 - ETA: 19s - loss: 3.2844 - accuracy: 0.153 - ETA: 19s - loss: 3.2845 - accuracy: 0.153 - ETA: 18s - loss: 3.2843 - accuracy: 0.153 - ETA: 18s - loss: 3.2848 - accuracy: 0.153 - ETA: 17s - loss: 3.2854 - accuracy: 0.153 - ETA: 17s - loss: 3.2851 - accuracy: 0.153 - ETA: 16s - loss: 3.2855 - accuracy: 0.153 - ETA: 15s - loss: 3.2854 - accuracy: 0.153 - ETA: 15s - loss: 3.2857 - accuracy: 0.153 - ETA: 14s - loss: 3.2858 - accuracy: 0.153 - ETA: 14s - loss: 3.2861 - accuracy: 0.153 - ETA: 13s - loss: 3.2860 - accuracy: 0.153 - ETA: 13s - loss: 3.2860 - accuracy: 0.153 - ETA: 12s - loss: 3.2861 - accuracy: 0.153 - ETA: 11s - loss: 3.2857 - accuracy: 0.153 - ETA: 11s - loss: 3.2867 - accuracy: 0.153 - ETA: 10s - loss: 3.2869 - accuracy: 0.153 - ETA: 10s - loss: 3.2868 - accuracy: 0.153 - ETA: 9s - loss: 3.2870 - accuracy: 0.153 - ETA: 9s - loss: 3.2880 - accuracy: 0.15 - ETA: 8s - loss: 3.2877 - accuracy: 0.15 - ETA: 7s - loss: 3.2879 - accuracy: 0.15 - ETA: 7s - loss: 3.2882 - accuracy: 0.15 - ETA: 6s - loss: 3.2875 - accuracy: 0.15 - ETA: 6s - loss: 3.2877 - accuracy: 0.15 - ETA: 5s - loss: 3.2880 - accuracy: 0.15 - ETA: 5s - loss: 3.2878 - accuracy: 0.15 - ETA: 4s - loss: 3.2878 - accuracy: 0.15 - ETA: 4s - loss: 3.2874 - accuracy: 0.15 - ETA: 3s - loss: 3.2875 - accuracy: 0.15 - ETA: 2s - loss: 3.2875 - accuracy: 0.15 - ETA: 2s - loss: 3.2870 - accuracy: 0.15 - ETA: 1s - loss: 3.2870 - accuracy: 0.15 - ETA: 1s - loss: 3.2866 - accuracy: 0.15 - ETA: 0s - loss: 3.2866 - accuracy: 0.15 - ETA: 0s - loss: 3.2872 - accuracy: 0.15 - 200s 5ms/step - loss: 3.2874 - accuracy: 0.1531 - val_loss: 4.0580 - val_accuracy: 0.0181\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:22 - loss: 3.4392 - accuracy: 0.14 - ETA: 3:12 - loss: 3.2739 - accuracy: 0.16 - ETA: 3:09 - loss: 3.2614 - accuracy: 0.16 - ETA: 3:06 - loss: 3.2660 - accuracy: 0.16 - ETA: 3:06 - loss: 3.2689 - accuracy: 0.16 - ETA: 3:08 - loss: 3.2702 - accuracy: 0.16 - ETA: 3:07 - loss: 3.3096 - accuracy: 0.15 - ETA: 3:06 - loss: 3.3241 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3248 - accuracy: 0.14 - ETA: 3:06 - loss: 3.3313 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3211 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3023 - accuracy: 0.15 - ETA: 3:04 - loss: 3.3059 - accuracy: 0.15 - ETA: 3:03 - loss: 3.2956 - accuracy: 0.15 - ETA: 3:02 - loss: 3.2869 - accuracy: 0.15 - ETA: 3:01 - loss: 3.2897 - accuracy: 0.15 - ETA: 3:00 - loss: 3.3101 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3318 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3344 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3422 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3491 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3445 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3453 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3352 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3176 - accuracy: 0.15 - ETA: 2:55 - loss: 3.3225 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3214 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3185 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3158 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3201 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3183 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3114 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3115 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3156 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3110 - accuracy: 0.15 - ETA: 2:48 - loss: 3.3009 - accuracy: 0.15 - ETA: 2:48 - loss: 3.3004 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2996 - accuracy: 0.15 - ETA: 2:46 - loss: 3.3026 - accuracy: 0.15 - ETA: 2:45 - loss: 3.3026 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2965 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2992 - accuracy: 0.15 - ETA: 2:43 - loss: 3.3039 - accuracy: 0.15 - ETA: 2:43 - loss: 3.3050 - accuracy: 0.15 - ETA: 2:42 - loss: 3.3070 - accuracy: 0.15 - ETA: 2:42 - loss: 3.3061 - accuracy: 0.15 - ETA: 2:41 - loss: 3.3036 - accuracy: 0.15 - ETA: 2:41 - loss: 3.3030 - accuracy: 0.15 - ETA: 2:40 - loss: 3.3002 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2968 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2949 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2967 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2969 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2987 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2979 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2988 - accuracy: 0.15 - ETA: 2:36 - loss: 3.3000 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2954 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2970 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2946 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2932 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2958 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2937 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2923 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2893 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2900 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2892 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2872 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2875 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2851 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2822 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2827 - accuracy: 0.15 - ETA: 2:26 - loss: 3.2841 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2839 - accuracy: 0.15 - ETA: 2:25 - loss: 3.2839 - accuracy: 0.15 - ETA: 2:24 - loss: 3.2851 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2837 - accuracy: 0.15 - ETA: 2:23 - loss: 3.2835 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2829 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2810 - accuracy: 0.15 - ETA: 2:22 - loss: 3.2823 - accuracy: 0.15 - ETA: 2:21 - loss: 3.2805 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2800 - accuracy: 0.15 - ETA: 2:20 - loss: 3.2806 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2825 - accuracy: 0.15 - ETA: 2:19 - loss: 3.2810 - accuracy: 0.15 - ETA: 2:18 - loss: 3.2811 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2799 - accuracy: 0.15 - ETA: 2:17 - loss: 3.2794 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2800 - accuracy: 0.15 - ETA: 2:16 - loss: 3.2818 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2801 - accuracy: 0.15 - ETA: 2:15 - loss: 3.2789 - accuracy: 0.15 - ETA: 2:14 - loss: 3.2787 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2784 - accuracy: 0.15 - ETA: 2:13 - loss: 3.2765 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2763 - accuracy: 0.15 - ETA: 2:12 - loss: 3.2761 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2769 - accuracy: 0.15 - ETA: 2:11 - loss: 3.2771 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2752 - accuracy: 0.15 - ETA: 2:10 - loss: 3.2753 - accuracy: 0.15 - ETA: 2:09 - loss: 3.2741 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2750 - accuracy: 0.15 - ETA: 2:08 - loss: 3.2741 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2753 - accuracy: 0.15 - ETA: 2:07 - loss: 3.2742 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2748 - accuracy: 0.15 - ETA: 2:06 - loss: 3.2740 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2748 - accuracy: 0.15 - ETA: 2:05 - loss: 3.2730 - accuracy: 0.15 - ETA: 2:04 - loss: 3.2728 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2710 - accuracy: 0.15 - ETA: 2:03 - loss: 3.2715 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2708 - accuracy: 0.15 - ETA: 2:02 - loss: 3.2692 - accuracy: 0.15 - ETA: 2:01 - loss: 3.2694 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2690 - accuracy: 0.15 - ETA: 2:00 - loss: 3.2678 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2684 - accuracy: 0.15 - ETA: 1:59 - loss: 3.2686 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2678 - accuracy: 0.15 - ETA: 1:58 - loss: 3.2676 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2673 - accuracy: 0.15 - ETA: 1:57 - loss: 3.2675 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2667 - accuracy: 0.15 - ETA: 1:56 - loss: 3.2662 - accuracy: 0.15 - ETA: 1:55 - loss: 3.2662 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2682 - accuracy: 0.15 - ETA: 1:54 - loss: 3.2673 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2670 - accuracy: 0.15 - ETA: 1:53 - loss: 3.2671 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2667 - accuracy: 0.15 - ETA: 1:52 - loss: 3.2663 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2663 - accuracy: 0.15 - ETA: 1:51 - loss: 3.2663 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2653 - accuracy: 0.15 - ETA: 1:50 - loss: 3.2661 - accuracy: 0.15 - ETA: 1:49 - loss: 3.2660 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2657 - accuracy: 0.15 - ETA: 1:48 - loss: 3.2656 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2658 - accuracy: 0.15 - ETA: 1:47 - loss: 3.2651 - accuracy: 0.15 - ETA: 1:46 - loss: 3.2660 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2654 - accuracy: 0.15 - ETA: 1:45 - loss: 3.2653 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2650 - accuracy: 0.15 - ETA: 1:44 - loss: 3.2643 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2640 - accuracy: 0.15 - ETA: 1:43 - loss: 3.2643 - accuracy: 0.15 - ETA: 1:42 - loss: 3.2631 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2635 - accuracy: 0.15 - ETA: 1:41 - loss: 3.2652 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2646 - accuracy: 0.15 - ETA: 1:40 - loss: 3.2644 - accuracy: 0.15 - ETA: 1:39 - loss: 3.2648 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2641 - accuracy: 0.15 - ETA: 1:38 - loss: 3.2632 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2633 - accuracy: 0.15 - ETA: 1:37 - loss: 3.2629 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2616 - accuracy: 0.15 - ETA: 1:36 - loss: 3.2610 - accuracy: 0.15 - ETA: 1:35 - loss: 3.2610 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2600 - accuracy: 0.15 - ETA: 1:34 - loss: 3.2606 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2607 - accuracy: 0.15 - ETA: 1:33 - loss: 3.2605 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2590 - accuracy: 0.15 - ETA: 1:32 - loss: 3.2592 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2596 - accuracy: 0.15 - ETA: 1:31 - loss: 3.2592 - accuracy: 0.15 - ETA: 1:30 - loss: 3.2573 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2571 - accuracy: 0.15 - ETA: 1:29 - loss: 3.2566 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2567 - accuracy: 0.15 - ETA: 1:28 - loss: 3.2574 - accuracy: 0.15 - ETA: 1:27 - loss: 3.2572 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2569 - accuracy: 0.15 - ETA: 1:26 - loss: 3.2570 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2561 - accuracy: 0.15 - ETA: 1:25 - loss: 3.2566 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2575 - accuracy: 0.15 - ETA: 1:24 - loss: 3.2577 - accuracy: 0.15 - ETA: 1:23 - loss: 3.2581 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2592 - accuracy: 0.15 - ETA: 1:22 - loss: 3.2591 - accuracy: 0.1594"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.2595 - accuracy: 0.15 - ETA: 1:21 - loss: 3.2590 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2601 - accuracy: 0.15 - ETA: 1:20 - loss: 3.2598 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2590 - accuracy: 0.15 - ETA: 1:19 - loss: 3.2594 - accuracy: 0.15 - ETA: 1:18 - loss: 3.2602 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2605 - accuracy: 0.15 - ETA: 1:17 - loss: 3.2603 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2621 - accuracy: 0.15 - ETA: 1:16 - loss: 3.2626 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2623 - accuracy: 0.15 - ETA: 1:15 - loss: 3.2626 - accuracy: 0.15 - ETA: 1:14 - loss: 3.2637 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2628 - accuracy: 0.15 - ETA: 1:13 - loss: 3.2628 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2623 - accuracy: 0.15 - ETA: 1:12 - loss: 3.2629 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2640 - accuracy: 0.15 - ETA: 1:11 - loss: 3.2639 - accuracy: 0.15 - ETA: 1:10 - loss: 3.2639 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2643 - accuracy: 0.15 - ETA: 1:09 - loss: 3.2636 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2637 - accuracy: 0.15 - ETA: 1:08 - loss: 3.2640 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2635 - accuracy: 0.15 - ETA: 1:07 - loss: 3.2634 - accuracy: 0.15 - ETA: 1:06 - loss: 3.2630 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2632 - accuracy: 0.15 - ETA: 1:05 - loss: 3.2636 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2632 - accuracy: 0.15 - ETA: 1:04 - loss: 3.2634 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2624 - accuracy: 0.15 - ETA: 1:03 - loss: 3.2634 - accuracy: 0.15 - ETA: 1:02 - loss: 3.2636 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2635 - accuracy: 0.15 - ETA: 1:01 - loss: 3.2638 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2643 - accuracy: 0.15 - ETA: 1:00 - loss: 3.2644 - accuracy: 0.15 - ETA: 59s - loss: 3.2639 - accuracy: 0.1585 - ETA: 59s - loss: 3.2640 - accuracy: 0.158 - ETA: 58s - loss: 3.2641 - accuracy: 0.158 - ETA: 57s - loss: 3.2640 - accuracy: 0.158 - ETA: 57s - loss: 3.2635 - accuracy: 0.158 - ETA: 56s - loss: 3.2637 - accuracy: 0.158 - ETA: 56s - loss: 3.2628 - accuracy: 0.158 - ETA: 55s - loss: 3.2625 - accuracy: 0.158 - ETA: 55s - loss: 3.2616 - accuracy: 0.159 - ETA: 54s - loss: 3.2612 - accuracy: 0.159 - ETA: 53s - loss: 3.2614 - accuracy: 0.159 - ETA: 53s - loss: 3.2606 - accuracy: 0.159 - ETA: 52s - loss: 3.2601 - accuracy: 0.159 - ETA: 52s - loss: 3.2600 - accuracy: 0.159 - ETA: 51s - loss: 3.2597 - accuracy: 0.159 - ETA: 51s - loss: 3.2603 - accuracy: 0.159 - ETA: 50s - loss: 3.2611 - accuracy: 0.159 - ETA: 50s - loss: 3.2604 - accuracy: 0.159 - ETA: 49s - loss: 3.2599 - accuracy: 0.159 - ETA: 48s - loss: 3.2598 - accuracy: 0.159 - ETA: 48s - loss: 3.2592 - accuracy: 0.159 - ETA: 47s - loss: 3.2600 - accuracy: 0.159 - ETA: 47s - loss: 3.2602 - accuracy: 0.159 - ETA: 46s - loss: 3.2599 - accuracy: 0.159 - ETA: 46s - loss: 3.2600 - accuracy: 0.159 - ETA: 45s - loss: 3.2598 - accuracy: 0.159 - ETA: 44s - loss: 3.2603 - accuracy: 0.159 - ETA: 44s - loss: 3.2601 - accuracy: 0.159 - ETA: 43s - loss: 3.2604 - accuracy: 0.159 - ETA: 43s - loss: 3.2603 - accuracy: 0.159 - ETA: 42s - loss: 3.2607 - accuracy: 0.159 - ETA: 42s - loss: 3.2603 - accuracy: 0.159 - ETA: 41s - loss: 3.2599 - accuracy: 0.159 - ETA: 40s - loss: 3.2598 - accuracy: 0.159 - ETA: 40s - loss: 3.2600 - accuracy: 0.159 - ETA: 39s - loss: 3.2596 - accuracy: 0.159 - ETA: 39s - loss: 3.2592 - accuracy: 0.159 - ETA: 38s - loss: 3.2589 - accuracy: 0.159 - ETA: 38s - loss: 3.2580 - accuracy: 0.159 - ETA: 37s - loss: 3.2577 - accuracy: 0.159 - ETA: 36s - loss: 3.2575 - accuracy: 0.159 - ETA: 36s - loss: 3.2578 - accuracy: 0.159 - ETA: 35s - loss: 3.2581 - accuracy: 0.159 - ETA: 35s - loss: 3.2584 - accuracy: 0.159 - ETA: 34s - loss: 3.2585 - accuracy: 0.159 - ETA: 34s - loss: 3.2594 - accuracy: 0.159 - ETA: 33s - loss: 3.2593 - accuracy: 0.159 - ETA: 32s - loss: 3.2598 - accuracy: 0.159 - ETA: 32s - loss: 3.2598 - accuracy: 0.159 - ETA: 31s - loss: 3.2595 - accuracy: 0.159 - ETA: 31s - loss: 3.2596 - accuracy: 0.159 - ETA: 30s - loss: 3.2600 - accuracy: 0.159 - ETA: 30s - loss: 3.2589 - accuracy: 0.159 - ETA: 29s - loss: 3.2589 - accuracy: 0.159 - ETA: 29s - loss: 3.2588 - accuracy: 0.159 - ETA: 28s - loss: 3.2583 - accuracy: 0.159 - ETA: 27s - loss: 3.2582 - accuracy: 0.159 - ETA: 27s - loss: 3.2581 - accuracy: 0.159 - ETA: 26s - loss: 3.2590 - accuracy: 0.159 - ETA: 26s - loss: 3.2596 - accuracy: 0.159 - ETA: 25s - loss: 3.2601 - accuracy: 0.159 - ETA: 25s - loss: 3.2608 - accuracy: 0.158 - ETA: 24s - loss: 3.2607 - accuracy: 0.158 - ETA: 23s - loss: 3.2608 - accuracy: 0.158 - ETA: 23s - loss: 3.2606 - accuracy: 0.159 - ETA: 22s - loss: 3.2608 - accuracy: 0.159 - ETA: 22s - loss: 3.2606 - accuracy: 0.159 - ETA: 21s - loss: 3.2608 - accuracy: 0.159 - ETA: 21s - loss: 3.2610 - accuracy: 0.159 - ETA: 20s - loss: 3.2614 - accuracy: 0.159 - ETA: 19s - loss: 3.2619 - accuracy: 0.159 - ETA: 19s - loss: 3.2626 - accuracy: 0.159 - ETA: 18s - loss: 3.2629 - accuracy: 0.158 - ETA: 18s - loss: 3.2636 - accuracy: 0.158 - ETA: 17s - loss: 3.2638 - accuracy: 0.158 - ETA: 17s - loss: 3.2643 - accuracy: 0.158 - ETA: 16s - loss: 3.2645 - accuracy: 0.158 - ETA: 15s - loss: 3.2646 - accuracy: 0.158 - ETA: 15s - loss: 3.2653 - accuracy: 0.158 - ETA: 14s - loss: 3.2651 - accuracy: 0.158 - ETA: 14s - loss: 3.2656 - accuracy: 0.158 - ETA: 13s - loss: 3.2655 - accuracy: 0.158 - ETA: 13s - loss: 3.2658 - accuracy: 0.157 - ETA: 12s - loss: 3.2659 - accuracy: 0.157 - ETA: 11s - loss: 3.2660 - accuracy: 0.157 - ETA: 11s - loss: 3.2664 - accuracy: 0.157 - ETA: 10s - loss: 3.2672 - accuracy: 0.157 - ETA: 10s - loss: 3.2677 - accuracy: 0.157 - ETA: 9s - loss: 3.2703 - accuracy: 0.157 - ETA: 9s - loss: 3.2710 - accuracy: 0.15 - ETA: 8s - loss: 3.2713 - accuracy: 0.15 - ETA: 7s - loss: 3.2711 - accuracy: 0.15 - ETA: 7s - loss: 3.2714 - accuracy: 0.15 - ETA: 6s - loss: 3.2719 - accuracy: 0.15 - ETA: 6s - loss: 3.2716 - accuracy: 0.15 - ETA: 5s - loss: 3.2719 - accuracy: 0.15 - ETA: 5s - loss: 3.2724 - accuracy: 0.15 - ETA: 4s - loss: 3.2723 - accuracy: 0.15 - ETA: 4s - loss: 3.2726 - accuracy: 0.15 - ETA: 3s - loss: 3.2725 - accuracy: 0.15 - ETA: 2s - loss: 3.2730 - accuracy: 0.15 - ETA: 2s - loss: 3.2733 - accuracy: 0.15 - ETA: 1s - loss: 3.2736 - accuracy: 0.15 - ETA: 1s - loss: 3.2741 - accuracy: 0.15 - ETA: 0s - loss: 3.2746 - accuracy: 0.15 - ETA: 0s - loss: 3.2744 - accuracy: 0.15 - 200s 5ms/step - loss: 3.2744 - accuracy: 0.1569 - val_loss: 3.9155 - val_accuracy: 0.0126\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:27 - loss: 3.3221 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3166 - accuracy: 0.14 - ETA: 3:17 - loss: 3.3019 - accuracy: 0.15 - ETA: 3:13 - loss: 3.2942 - accuracy: 0.15 - ETA: 3:12 - loss: 3.2749 - accuracy: 0.16 - ETA: 3:10 - loss: 3.2635 - accuracy: 0.16 - ETA: 3:10 - loss: 3.2794 - accuracy: 0.15 - ETA: 3:11 - loss: 3.2995 - accuracy: 0.15 - ETA: 3:11 - loss: 3.3059 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3103 - accuracy: 0.14 - ETA: 3:10 - loss: 3.3175 - accuracy: 0.14 - ETA: 3:09 - loss: 3.3223 - accuracy: 0.14 - ETA: 3:07 - loss: 3.3235 - accuracy: 0.14 - ETA: 3:05 - loss: 3.3265 - accuracy: 0.14 - ETA: 3:04 - loss: 3.3305 - accuracy: 0.14 - ETA: 3:03 - loss: 3.3255 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3145 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3096 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3135 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3124 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3148 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3172 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3171 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3174 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3166 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3187 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3244 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3285 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3237 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3322 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3364 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3300 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3303 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3351 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3302 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3293 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3306 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3306 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3372 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3386 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3372 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3347 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3376 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3392 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3386 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3432 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3446 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3443 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3435 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3456 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3433 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3425 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3397 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3395 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3408 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3396 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3376 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3371 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3358 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3367 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3382 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3386 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3392 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3428 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3432 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3430 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3415 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3405 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3429 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3421 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3400 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3388 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3401 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3417 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3416 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3410 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3419 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3404 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3381 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3360 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3376 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3390 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3361 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3366 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3345 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3340 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3355 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3350 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3352 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3350 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3356 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3348 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3340 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3355 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3359 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3350 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3328 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3333 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3344 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3339 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3358 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3346 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3353 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3322 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3314 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3310 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3325 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3288 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3290 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3286 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3284 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3287 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3298 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3285 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3289 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3293 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3276 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3266 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3262 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3244 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3243 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3232 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3233 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3234 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3241 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3216 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3204 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3206 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3191 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3191 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3182 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3170 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3150 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3154 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3157 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3162 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3151 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3151 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3146 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3127 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3112 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3113 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3108 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3120 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3143 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3154 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3182 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3188 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3193 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3201 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3197 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3202 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3211 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3196 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3198 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3198 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3197 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3190 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3192 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3202 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3200 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3204 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3209 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3211 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3212 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3213 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3216 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3213 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3218 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3219 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3212 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3218 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3215 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3212 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3219 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3212 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3210 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3206 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3208 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3198 - accuracy: 0.1484"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:22 - loss: 3.3207 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3210 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3206 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3197 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3209 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3219 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3215 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3213 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3201 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3206 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3202 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3206 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3195 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3191 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3187 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3184 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3181 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3186 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3187 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3180 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3178 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3176 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3173 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3186 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3196 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3198 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3201 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3200 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3199 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3196 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3201 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3204 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3205 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3210 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3205 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3203 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3212 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3204 - accuracy: 0.14 - ETA: 59s - loss: 3.3199 - accuracy: 0.1480 - ETA: 59s - loss: 3.3194 - accuracy: 0.148 - ETA: 58s - loss: 3.3198 - accuracy: 0.148 - ETA: 57s - loss: 3.3193 - accuracy: 0.148 - ETA: 57s - loss: 3.3187 - accuracy: 0.148 - ETA: 56s - loss: 3.3189 - accuracy: 0.148 - ETA: 56s - loss: 3.3183 - accuracy: 0.148 - ETA: 55s - loss: 3.3182 - accuracy: 0.148 - ETA: 55s - loss: 3.3176 - accuracy: 0.148 - ETA: 54s - loss: 3.3178 - accuracy: 0.148 - ETA: 54s - loss: 3.3179 - accuracy: 0.148 - ETA: 53s - loss: 3.3176 - accuracy: 0.148 - ETA: 53s - loss: 3.3174 - accuracy: 0.148 - ETA: 52s - loss: 3.3169 - accuracy: 0.148 - ETA: 51s - loss: 3.3167 - accuracy: 0.148 - ETA: 51s - loss: 3.3173 - accuracy: 0.148 - ETA: 50s - loss: 3.3178 - accuracy: 0.148 - ETA: 50s - loss: 3.3176 - accuracy: 0.148 - ETA: 49s - loss: 3.3176 - accuracy: 0.148 - ETA: 49s - loss: 3.3173 - accuracy: 0.148 - ETA: 48s - loss: 3.3168 - accuracy: 0.148 - ETA: 47s - loss: 3.3162 - accuracy: 0.148 - ETA: 47s - loss: 3.3156 - accuracy: 0.148 - ETA: 46s - loss: 3.3161 - accuracy: 0.148 - ETA: 46s - loss: 3.3159 - accuracy: 0.148 - ETA: 45s - loss: 3.3162 - accuracy: 0.148 - ETA: 44s - loss: 3.3165 - accuracy: 0.148 - ETA: 44s - loss: 3.3166 - accuracy: 0.148 - ETA: 43s - loss: 3.3159 - accuracy: 0.148 - ETA: 43s - loss: 3.3167 - accuracy: 0.148 - ETA: 42s - loss: 3.3166 - accuracy: 0.148 - ETA: 42s - loss: 3.3169 - accuracy: 0.148 - ETA: 41s - loss: 3.3169 - accuracy: 0.148 - ETA: 40s - loss: 3.3166 - accuracy: 0.148 - ETA: 40s - loss: 3.3164 - accuracy: 0.148 - ETA: 39s - loss: 3.3169 - accuracy: 0.148 - ETA: 39s - loss: 3.3170 - accuracy: 0.148 - ETA: 38s - loss: 3.3168 - accuracy: 0.148 - ETA: 38s - loss: 3.3170 - accuracy: 0.148 - ETA: 37s - loss: 3.3169 - accuracy: 0.147 - ETA: 37s - loss: 3.3172 - accuracy: 0.148 - ETA: 36s - loss: 3.3174 - accuracy: 0.147 - ETA: 35s - loss: 3.3168 - accuracy: 0.148 - ETA: 35s - loss: 3.3169 - accuracy: 0.148 - ETA: 34s - loss: 3.3169 - accuracy: 0.148 - ETA: 34s - loss: 3.3173 - accuracy: 0.148 - ETA: 33s - loss: 3.3168 - accuracy: 0.148 - ETA: 33s - loss: 3.3157 - accuracy: 0.148 - ETA: 32s - loss: 3.3152 - accuracy: 0.148 - ETA: 31s - loss: 3.3153 - accuracy: 0.148 - ETA: 31s - loss: 3.3154 - accuracy: 0.148 - ETA: 30s - loss: 3.3147 - accuracy: 0.148 - ETA: 30s - loss: 3.3148 - accuracy: 0.148 - ETA: 29s - loss: 3.3147 - accuracy: 0.148 - ETA: 29s - loss: 3.3148 - accuracy: 0.148 - ETA: 28s - loss: 3.3149 - accuracy: 0.148 - ETA: 27s - loss: 3.3149 - accuracy: 0.148 - ETA: 27s - loss: 3.3144 - accuracy: 0.149 - ETA: 26s - loss: 3.3145 - accuracy: 0.149 - ETA: 26s - loss: 3.3145 - accuracy: 0.149 - ETA: 25s - loss: 3.3146 - accuracy: 0.149 - ETA: 25s - loss: 3.3142 - accuracy: 0.149 - ETA: 24s - loss: 3.3138 - accuracy: 0.149 - ETA: 23s - loss: 3.3141 - accuracy: 0.149 - ETA: 23s - loss: 3.3135 - accuracy: 0.149 - ETA: 22s - loss: 3.3140 - accuracy: 0.149 - ETA: 22s - loss: 3.3139 - accuracy: 0.149 - ETA: 21s - loss: 3.3140 - accuracy: 0.149 - ETA: 21s - loss: 3.3143 - accuracy: 0.149 - ETA: 20s - loss: 3.3147 - accuracy: 0.149 - ETA: 19s - loss: 3.3148 - accuracy: 0.149 - ETA: 19s - loss: 3.3140 - accuracy: 0.149 - ETA: 18s - loss: 3.3141 - accuracy: 0.149 - ETA: 18s - loss: 3.3138 - accuracy: 0.149 - ETA: 17s - loss: 3.3136 - accuracy: 0.149 - ETA: 17s - loss: 3.3131 - accuracy: 0.149 - ETA: 16s - loss: 3.3127 - accuracy: 0.149 - ETA: 15s - loss: 3.3131 - accuracy: 0.149 - ETA: 15s - loss: 3.3128 - accuracy: 0.149 - ETA: 14s - loss: 3.3126 - accuracy: 0.149 - ETA: 14s - loss: 3.3186 - accuracy: 0.149 - ETA: 13s - loss: 3.3181 - accuracy: 0.149 - ETA: 13s - loss: 3.3176 - accuracy: 0.149 - ETA: 12s - loss: 3.3164 - accuracy: 0.149 - ETA: 11s - loss: 3.3161 - accuracy: 0.149 - ETA: 11s - loss: 3.3161 - accuracy: 0.149 - ETA: 10s - loss: 3.3159 - accuracy: 0.149 - ETA: 10s - loss: 3.3157 - accuracy: 0.149 - ETA: 9s - loss: 3.3155 - accuracy: 0.149 - ETA: 9s - loss: 3.3153 - accuracy: 0.15 - ETA: 8s - loss: 3.3154 - accuracy: 0.14 - ETA: 7s - loss: 3.3149 - accuracy: 0.15 - ETA: 7s - loss: 3.3150 - accuracy: 0.14 - ETA: 6s - loss: 3.3140 - accuracy: 0.15 - ETA: 6s - loss: 3.3132 - accuracy: 0.15 - ETA: 5s - loss: 3.3137 - accuracy: 0.15 - ETA: 5s - loss: 3.3138 - accuracy: 0.15 - ETA: 4s - loss: 3.3138 - accuracy: 0.15 - ETA: 4s - loss: 3.3137 - accuracy: 0.15 - ETA: 3s - loss: 3.3141 - accuracy: 0.15 - ETA: 2s - loss: 3.3139 - accuracy: 0.15 - ETA: 2s - loss: 3.3136 - accuracy: 0.15 - ETA: 1s - loss: 3.3135 - accuracy: 0.15 - ETA: 1s - loss: 3.3132 - accuracy: 0.15 - ETA: 0s - loss: 3.3134 - accuracy: 0.15 - ETA: 0s - loss: 3.3129 - accuracy: 0.15 - 201s 5ms/step - loss: 3.3131 - accuracy: 0.1500 - val_loss: 3.9530 - val_accuracy: 0.0126\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:37 - loss: 3.3795 - accuracy: 0.17 - ETA: 3:17 - loss: 3.3667 - accuracy: 0.14 - ETA: 3:08 - loss: 3.3733 - accuracy: 0.14 - ETA: 3:05 - loss: 3.4036 - accuracy: 0.14 - ETA: 3:03 - loss: 3.4070 - accuracy: 0.13 - ETA: 3:03 - loss: 3.4008 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3848 - accuracy: 0.14 - ETA: 3:02 - loss: 3.3676 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3587 - accuracy: 0.14 - ETA: 3:01 - loss: 3.3447 - accuracy: 0.14 - ETA: 3:00 - loss: 3.3580 - accuracy: 0.14 - ETA: 2:59 - loss: 3.3414 - accuracy: 0.14 - ETA: 2:58 - loss: 3.3387 - accuracy: 0.14 - ETA: 2:57 - loss: 3.3329 - accuracy: 0.15 - ETA: 2:56 - loss: 3.3235 - accuracy: 0.15 - ETA: 2:56 - loss: 3.3236 - accuracy: 0.15 - ETA: 2:55 - loss: 3.3182 - accuracy: 0.15 - ETA: 2:55 - loss: 3.3178 - accuracy: 0.15 - ETA: 2:54 - loss: 3.3246 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3179 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3178 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3167 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3158 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3119 - accuracy: 0.15 - ETA: 2:53 - loss: 3.3087 - accuracy: 0.15 - ETA: 2:52 - loss: 3.2988 - accuracy: 0.15 - ETA: 2:52 - loss: 3.3017 - accuracy: 0.15 - ETA: 2:51 - loss: 3.3005 - accuracy: 0.15 - ETA: 2:51 - loss: 3.3017 - accuracy: 0.15 - ETA: 2:50 - loss: 3.3032 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3001 - accuracy: 0.14 - ETA: 2:49 - loss: 3.2974 - accuracy: 0.14 - ETA: 2:48 - loss: 3.2961 - accuracy: 0.14 - ETA: 2:47 - loss: 3.2976 - accuracy: 0.15 - ETA: 2:47 - loss: 3.2940 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2947 - accuracy: 0.15 - ETA: 2:46 - loss: 3.2918 - accuracy: 0.15 - ETA: 2:45 - loss: 3.2919 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2923 - accuracy: 0.15 - ETA: 2:44 - loss: 3.2895 - accuracy: 0.15 - ETA: 2:43 - loss: 3.2942 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2941 - accuracy: 0.15 - ETA: 2:42 - loss: 3.2901 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2946 - accuracy: 0.15 - ETA: 2:41 - loss: 3.2959 - accuracy: 0.15 - ETA: 2:40 - loss: 3.2959 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2889 - accuracy: 0.15 - ETA: 2:39 - loss: 3.2877 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2901 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2898 - accuracy: 0.15 - ETA: 2:38 - loss: 3.2900 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2881 - accuracy: 0.15 - ETA: 2:37 - loss: 3.2893 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2893 - accuracy: 0.15 - ETA: 2:36 - loss: 3.2894 - accuracy: 0.15 - ETA: 2:35 - loss: 3.2905 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2898 - accuracy: 0.15 - ETA: 2:34 - loss: 3.2919 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2914 - accuracy: 0.15 - ETA: 2:33 - loss: 3.2880 - accuracy: 0.15 - ETA: 2:32 - loss: 3.2904 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2892 - accuracy: 0.15 - ETA: 2:31 - loss: 3.2904 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2901 - accuracy: 0.15 - ETA: 2:30 - loss: 3.2876 - accuracy: 0.15 - ETA: 2:29 - loss: 3.2893 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2902 - accuracy: 0.15 - ETA: 2:28 - loss: 3.2915 - accuracy: 0.15 - ETA: 2:27 - loss: 3.2937 - accuracy: 0.15 - ETA: 2:27 - loss: 3.3100 - accuracy: 0.15 - ETA: 2:26 - loss: 3.3180 - accuracy: 0.15 - ETA: 2:25 - loss: 3.3291 - accuracy: 0.15 - ETA: 2:25 - loss: 3.3294 - accuracy: 0.15 - ETA: 2:24 - loss: 3.3309 - accuracy: 0.15 - ETA: 2:24 - loss: 3.3306 - accuracy: 0.15 - ETA: 2:23 - loss: 3.3328 - accuracy: 0.15 - ETA: 2:23 - loss: 3.3334 - accuracy: 0.15 - ETA: 2:22 - loss: 3.3367 - accuracy: 0.15 - ETA: 2:22 - loss: 3.3387 - accuracy: 0.15 - ETA: 2:21 - loss: 3.3376 - accuracy: 0.15 - ETA: 2:21 - loss: 3.3346 - accuracy: 0.15 - ETA: 2:20 - loss: 3.3333 - accuracy: 0.15 - ETA: 2:20 - loss: 3.3364 - accuracy: 0.15 - ETA: 2:19 - loss: 3.3364 - accuracy: 0.15 - ETA: 2:19 - loss: 3.3350 - accuracy: 0.15 - ETA: 2:18 - loss: 3.3324 - accuracy: 0.15 - ETA: 2:17 - loss: 3.3316 - accuracy: 0.15 - ETA: 2:17 - loss: 3.3336 - accuracy: 0.15 - ETA: 2:16 - loss: 3.3371 - accuracy: 0.15 - ETA: 2:16 - loss: 3.3404 - accuracy: 0.14 - ETA: 2:15 - loss: 3.3436 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3478 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3496 - accuracy: 0.15 - ETA: 2:13 - loss: 3.3502 - accuracy: 0.15 - ETA: 2:13 - loss: 3.3533 - accuracy: 0.15 - ETA: 2:12 - loss: 3.3527 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3530 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3543 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3542 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3533 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3535 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3523 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3521 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3522 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3533 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3553 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3557 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3534 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3538 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3547 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3562 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3553 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3561 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3560 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3574 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3606 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3615 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3615 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3604 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3600 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3613 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3607 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3599 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3604 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3600 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3604 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3613 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3617 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3618 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3622 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3614 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3618 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3619 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3622 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3617 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3608 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3619 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3606 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3600 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3595 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3592 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3596 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3599 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3603 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3587 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3588 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3580 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3591 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3595 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3592 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3596 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3600 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3594 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3600 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3585 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3594 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3603 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3613 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3606 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3601 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3601 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3601 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3603 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3589 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3588 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3585 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3579 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3567 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3568 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3561 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3546 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3541 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3556 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3555 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3565 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3553 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3554 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3563 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3559 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3558 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3552 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3552 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3560 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3558 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3557 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3560 - accuracy: 0.1433"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 1:21 - loss: 3.3560 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3550 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3554 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3552 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3553 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3542 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3543 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3542 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3533 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3545 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3542 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3535 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3535 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3535 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3539 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3532 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3527 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3521 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3522 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3518 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3519 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3520 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3512 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3508 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3504 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3502 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3500 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3498 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3488 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3484 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3475 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3472 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3466 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3455 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3461 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3463 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3462 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3456 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3450 - accuracy: 0.14 - ETA: 59s - loss: 3.3446 - accuracy: 0.1429 - ETA: 58s - loss: 3.3444 - accuracy: 0.143 - ETA: 58s - loss: 3.3441 - accuracy: 0.142 - ETA: 57s - loss: 3.3444 - accuracy: 0.142 - ETA: 57s - loss: 3.3434 - accuracy: 0.143 - ETA: 56s - loss: 3.3427 - accuracy: 0.143 - ETA: 56s - loss: 3.3426 - accuracy: 0.143 - ETA: 55s - loss: 3.3427 - accuracy: 0.143 - ETA: 55s - loss: 3.3422 - accuracy: 0.143 - ETA: 54s - loss: 3.3418 - accuracy: 0.143 - ETA: 53s - loss: 3.3418 - accuracy: 0.143 - ETA: 53s - loss: 3.3410 - accuracy: 0.143 - ETA: 52s - loss: 3.3406 - accuracy: 0.143 - ETA: 52s - loss: 3.3399 - accuracy: 0.143 - ETA: 51s - loss: 3.3406 - accuracy: 0.143 - ETA: 51s - loss: 3.3409 - accuracy: 0.143 - ETA: 50s - loss: 3.3413 - accuracy: 0.143 - ETA: 49s - loss: 3.3410 - accuracy: 0.143 - ETA: 49s - loss: 3.3410 - accuracy: 0.143 - ETA: 48s - loss: 3.3415 - accuracy: 0.143 - ETA: 48s - loss: 3.3414 - accuracy: 0.143 - ETA: 47s - loss: 3.3410 - accuracy: 0.143 - ETA: 47s - loss: 3.3408 - accuracy: 0.143 - ETA: 46s - loss: 3.3413 - accuracy: 0.143 - ETA: 46s - loss: 3.3401 - accuracy: 0.143 - ETA: 45s - loss: 3.3397 - accuracy: 0.143 - ETA: 44s - loss: 3.3393 - accuracy: 0.143 - ETA: 44s - loss: 3.3391 - accuracy: 0.143 - ETA: 43s - loss: 3.3389 - accuracy: 0.143 - ETA: 43s - loss: 3.3389 - accuracy: 0.143 - ETA: 42s - loss: 3.3380 - accuracy: 0.143 - ETA: 42s - loss: 3.3376 - accuracy: 0.143 - ETA: 41s - loss: 3.3368 - accuracy: 0.143 - ETA: 40s - loss: 3.3366 - accuracy: 0.144 - ETA: 40s - loss: 3.3368 - accuracy: 0.144 - ETA: 39s - loss: 3.3371 - accuracy: 0.143 - ETA: 39s - loss: 3.3372 - accuracy: 0.143 - ETA: 38s - loss: 3.3372 - accuracy: 0.143 - ETA: 38s - loss: 3.3374 - accuracy: 0.143 - ETA: 37s - loss: 3.3368 - accuracy: 0.143 - ETA: 36s - loss: 3.3379 - accuracy: 0.143 - ETA: 36s - loss: 3.3378 - accuracy: 0.143 - ETA: 35s - loss: 3.3372 - accuracy: 0.143 - ETA: 35s - loss: 3.3363 - accuracy: 0.143 - ETA: 34s - loss: 3.3371 - accuracy: 0.143 - ETA: 34s - loss: 3.3364 - accuracy: 0.143 - ETA: 33s - loss: 3.3364 - accuracy: 0.143 - ETA: 32s - loss: 3.3360 - accuracy: 0.143 - ETA: 32s - loss: 3.3348 - accuracy: 0.143 - ETA: 31s - loss: 3.3344 - accuracy: 0.143 - ETA: 31s - loss: 3.3337 - accuracy: 0.144 - ETA: 30s - loss: 3.3337 - accuracy: 0.144 - ETA: 30s - loss: 3.3325 - accuracy: 0.144 - ETA: 29s - loss: 3.3320 - accuracy: 0.144 - ETA: 28s - loss: 3.3325 - accuracy: 0.144 - ETA: 28s - loss: 3.3323 - accuracy: 0.144 - ETA: 27s - loss: 3.3322 - accuracy: 0.144 - ETA: 27s - loss: 3.3328 - accuracy: 0.144 - ETA: 26s - loss: 3.3329 - accuracy: 0.144 - ETA: 26s - loss: 3.3333 - accuracy: 0.144 - ETA: 25s - loss: 3.3335 - accuracy: 0.144 - ETA: 25s - loss: 3.3347 - accuracy: 0.144 - ETA: 24s - loss: 3.3350 - accuracy: 0.144 - ETA: 23s - loss: 3.3351 - accuracy: 0.144 - ETA: 23s - loss: 3.3349 - accuracy: 0.144 - ETA: 22s - loss: 3.3349 - accuracy: 0.144 - ETA: 22s - loss: 3.3352 - accuracy: 0.144 - ETA: 21s - loss: 3.3348 - accuracy: 0.144 - ETA: 21s - loss: 3.3344 - accuracy: 0.144 - ETA: 20s - loss: 3.3340 - accuracy: 0.144 - ETA: 19s - loss: 3.3337 - accuracy: 0.144 - ETA: 19s - loss: 3.3341 - accuracy: 0.144 - ETA: 18s - loss: 3.3336 - accuracy: 0.144 - ETA: 18s - loss: 3.3332 - accuracy: 0.144 - ETA: 17s - loss: 3.3331 - accuracy: 0.144 - ETA: 17s - loss: 3.3330 - accuracy: 0.144 - ETA: 16s - loss: 3.3330 - accuracy: 0.144 - ETA: 15s - loss: 3.3327 - accuracy: 0.144 - ETA: 15s - loss: 3.3328 - accuracy: 0.144 - ETA: 14s - loss: 3.3327 - accuracy: 0.144 - ETA: 14s - loss: 3.3329 - accuracy: 0.144 - ETA: 13s - loss: 3.3332 - accuracy: 0.144 - ETA: 13s - loss: 3.3336 - accuracy: 0.144 - ETA: 12s - loss: 3.3335 - accuracy: 0.144 - ETA: 11s - loss: 3.3337 - accuracy: 0.144 - ETA: 11s - loss: 3.3349 - accuracy: 0.144 - ETA: 10s - loss: 3.3346 - accuracy: 0.144 - ETA: 10s - loss: 3.3340 - accuracy: 0.144 - ETA: 9s - loss: 3.3341 - accuracy: 0.144 - ETA: 9s - loss: 3.3339 - accuracy: 0.14 - ETA: 8s - loss: 3.3340 - accuracy: 0.14 - ETA: 7s - loss: 3.3338 - accuracy: 0.14 - ETA: 7s - loss: 3.3336 - accuracy: 0.14 - ETA: 6s - loss: 3.3337 - accuracy: 0.14 - ETA: 6s - loss: 3.3338 - accuracy: 0.14 - ETA: 5s - loss: 3.3338 - accuracy: 0.14 - ETA: 5s - loss: 3.3340 - accuracy: 0.14 - ETA: 4s - loss: 3.3338 - accuracy: 0.14 - ETA: 4s - loss: 3.3335 - accuracy: 0.14 - ETA: 3s - loss: 3.3334 - accuracy: 0.14 - ETA: 2s - loss: 3.3335 - accuracy: 0.14 - ETA: 2s - loss: 3.3331 - accuracy: 0.14 - ETA: 1s - loss: 3.3333 - accuracy: 0.14 - ETA: 1s - loss: 3.3332 - accuracy: 0.14 - ETA: 0s - loss: 3.3332 - accuracy: 0.14 - ETA: 0s - loss: 3.3337 - accuracy: 0.14 - 202s 5ms/step - loss: 3.3337 - accuracy: 0.1449 - val_loss: 3.9402 - val_accuracy: 0.0128\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 3:43 - loss: 3.2325 - accuracy: 0.13 - ETA: 3:39 - loss: 3.2293 - accuracy: 0.16 - ETA: 3:38 - loss: 3.2723 - accuracy: 0.15 - ETA: 3:46 - loss: 3.3059 - accuracy: 0.15 - ETA: 4:01 - loss: 3.3072 - accuracy: 0.15 - ETA: 4:09 - loss: 3.2994 - accuracy: 0.15 - ETA: 4:14 - loss: 3.3094 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3073 - accuracy: 0.15 - ETA: 4:21 - loss: 3.3082 - accuracy: 0.15 - ETA: 4:25 - loss: 3.3037 - accuracy: 0.15 - ETA: 4:27 - loss: 3.3081 - accuracy: 0.15 - ETA: 4:27 - loss: 3.3013 - accuracy: 0.15 - ETA: 4:29 - loss: 3.2988 - accuracy: 0.15 - ETA: 4:30 - loss: 3.3027 - accuracy: 0.15 - ETA: 4:32 - loss: 3.4944 - accuracy: 0.15 - ETA: 4:33 - loss: 3.4884 - accuracy: 0.15 - ETA: 4:33 - loss: 3.4737 - accuracy: 0.15 - ETA: 4:34 - loss: 3.4662 - accuracy: 0.15 - ETA: 4:35 - loss: 3.4620 - accuracy: 0.15 - ETA: 4:35 - loss: 3.4612 - accuracy: 0.14 - ETA: 4:35 - loss: 3.4562 - accuracy: 0.14 - ETA: 4:34 - loss: 3.4396 - accuracy: 0.14 - ETA: 4:33 - loss: 3.4329 - accuracy: 0.14 - ETA: 4:32 - loss: 3.4249 - accuracy: 0.15 - ETA: 4:31 - loss: 3.4224 - accuracy: 0.14 - ETA: 4:32 - loss: 3.4178 - accuracy: 0.14 - ETA: 4:31 - loss: 3.4113 - accuracy: 0.14 - ETA: 4:31 - loss: 3.4102 - accuracy: 0.14 - ETA: 4:31 - loss: 3.4063 - accuracy: 0.14 - ETA: 4:30 - loss: 3.4017 - accuracy: 0.14 - ETA: 4:30 - loss: 3.3949 - accuracy: 0.14 - ETA: 4:29 - loss: 3.3879 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3862 - accuracy: 0.14 - ETA: 4:28 - loss: 3.3934 - accuracy: 0.14 - ETA: 4:27 - loss: 3.3970 - accuracy: 0.14 - ETA: 4:27 - loss: 3.3946 - accuracy: 0.14 - ETA: 4:26 - loss: 3.3967 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3892 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3910 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3896 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3864 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3839 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3844 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3818 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3825 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3802 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3795 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3850 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3862 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3877 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3843 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3866 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3852 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3866 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3892 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3890 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3860 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3829 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3808 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3796 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3743 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3752 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3708 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3684 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3667 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3680 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3645 - accuracy: 0.15 - ETA: 4:03 - loss: 3.3640 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3623 - accuracy: 0.15 - ETA: 4:01 - loss: 3.3625 - accuracy: 0.15 - ETA: 4:01 - loss: 3.3610 - accuracy: 0.15 - ETA: 4:00 - loss: 3.3606 - accuracy: 0.15 - ETA: 3:59 - loss: 3.3584 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3590 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3592 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3590 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3578 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3577 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3556 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3559 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3537 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3536 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3536 - accuracy: 0.14 - ETA: 3:50 - loss: 3.3509 - accuracy: 0.15 - ETA: 3:49 - loss: 3.3519 - accuracy: 0.15 - ETA: 3:48 - loss: 3.3532 - accuracy: 0.15 - ETA: 3:47 - loss: 3.3514 - accuracy: 0.15 - ETA: 3:46 - loss: 3.3518 - accuracy: 0.15 - ETA: 3:45 - loss: 3.3513 - accuracy: 0.15 - ETA: 3:44 - loss: 3.3664 - accuracy: 0.15 - ETA: 3:43 - loss: 3.3648 - accuracy: 0.15 - ETA: 3:42 - loss: 3.3623 - accuracy: 0.15 - ETA: 3:42 - loss: 3.3608 - accuracy: 0.15 - ETA: 3:41 - loss: 3.3602 - accuracy: 0.15 - ETA: 3:40 - loss: 3.3580 - accuracy: 0.15 - ETA: 3:39 - loss: 3.3572 - accuracy: 0.15 - ETA: 3:38 - loss: 3.3587 - accuracy: 0.15 - ETA: 3:37 - loss: 3.3571 - accuracy: 0.15 - ETA: 3:36 - loss: 3.3579 - accuracy: 0.15 - ETA: 3:35 - loss: 3.3579 - accuracy: 0.15 - ETA: 3:34 - loss: 3.3567 - accuracy: 0.15 - ETA: 3:33 - loss: 3.3567 - accuracy: 0.15 - ETA: 3:33 - loss: 3.3556 - accuracy: 0.15 - ETA: 3:32 - loss: 3.3554 - accuracy: 0.15 - ETA: 3:31 - loss: 3.3543 - accuracy: 0.15 - ETA: 3:30 - loss: 3.3540 - accuracy: 0.15 - ETA: 3:29 - loss: 3.3518 - accuracy: 0.15 - ETA: 3:28 - loss: 3.3514 - accuracy: 0.15 - ETA: 3:27 - loss: 3.3507 - accuracy: 0.15 - ETA: 3:26 - loss: 3.3503 - accuracy: 0.15 - ETA: 3:26 - loss: 3.3517 - accuracy: 0.15 - ETA: 3:25 - loss: 3.3519 - accuracy: 0.15 - ETA: 3:24 - loss: 3.3513 - accuracy: 0.15 - ETA: 3:22 - loss: 3.3494 - accuracy: 0.15 - ETA: 3:21 - loss: 3.3490 - accuracy: 0.15 - ETA: 3:21 - loss: 3.3478 - accuracy: 0.15 - ETA: 3:20 - loss: 3.3475 - accuracy: 0.15 - ETA: 3:19 - loss: 3.3454 - accuracy: 0.15 - ETA: 3:18 - loss: 3.3443 - accuracy: 0.15 - ETA: 3:17 - loss: 3.3433 - accuracy: 0.15 - ETA: 3:16 - loss: 3.3428 - accuracy: 0.15 - ETA: 3:15 - loss: 3.3430 - accuracy: 0.15 - ETA: 3:14 - loss: 3.3416 - accuracy: 0.15 - ETA: 3:13 - loss: 3.3414 - accuracy: 0.15 - ETA: 3:12 - loss: 3.3419 - accuracy: 0.15 - ETA: 3:11 - loss: 3.3430 - accuracy: 0.15 - ETA: 3:10 - loss: 3.3437 - accuracy: 0.15 - ETA: 3:09 - loss: 3.3442 - accuracy: 0.15 - ETA: 3:09 - loss: 3.3446 - accuracy: 0.15 - ETA: 3:08 - loss: 3.3447 - accuracy: 0.15 - ETA: 3:07 - loss: 3.3438 - accuracy: 0.15 - ETA: 3:06 - loss: 3.3437 - accuracy: 0.15 - ETA: 3:05 - loss: 3.3432 - accuracy: 0.15 - ETA: 3:04 - loss: 3.3430 - accuracy: 0.15 - ETA: 3:03 - loss: 3.3428 - accuracy: 0.15 - ETA: 3:03 - loss: 3.3418 - accuracy: 0.15 - ETA: 3:02 - loss: 3.3424 - accuracy: 0.15 - ETA: 3:01 - loss: 3.3459 - accuracy: 0.15 - ETA: 3:00 - loss: 3.3470 - accuracy: 0.15 - ETA: 2:59 - loss: 3.3461 - accuracy: 0.15 - ETA: 2:58 - loss: 3.3452 - accuracy: 0.15 - ETA: 2:57 - loss: 3.3453 - accuracy: 0.14 - ETA: 2:56 - loss: 3.3459 - accuracy: 0.14 - ETA: 2:55 - loss: 3.3446 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3442 - accuracy: 0.14 - ETA: 2:54 - loss: 3.3443 - accuracy: 0.14 - ETA: 2:53 - loss: 3.3444 - accuracy: 0.14 - ETA: 2:52 - loss: 3.3450 - accuracy: 0.14 - ETA: 2:51 - loss: 3.3457 - accuracy: 0.14 - ETA: 2:50 - loss: 3.3461 - accuracy: 0.14 - ETA: 2:49 - loss: 3.3478 - accuracy: 0.14 - ETA: 2:48 - loss: 3.3488 - accuracy: 0.14 - ETA: 2:47 - loss: 3.3493 - accuracy: 0.14 - ETA: 2:46 - loss: 3.3508 - accuracy: 0.14 - ETA: 2:45 - loss: 3.3506 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3497 - accuracy: 0.14 - ETA: 2:44 - loss: 3.3493 - accuracy: 0.14 - ETA: 2:43 - loss: 3.3498 - accuracy: 0.14 - ETA: 2:42 - loss: 3.3493 - accuracy: 0.14 - ETA: 2:41 - loss: 3.3506 - accuracy: 0.14 - ETA: 2:40 - loss: 3.3513 - accuracy: 0.14 - ETA: 2:39 - loss: 3.3514 - accuracy: 0.14 - ETA: 2:38 - loss: 3.3527 - accuracy: 0.14 - ETA: 2:37 - loss: 3.3536 - accuracy: 0.14 - ETA: 2:36 - loss: 3.3538 - accuracy: 0.14 - ETA: 2:35 - loss: 3.3543 - accuracy: 0.14 - ETA: 2:34 - loss: 3.3548 - accuracy: 0.14 - ETA: 2:33 - loss: 3.3539 - accuracy: 0.14 - ETA: 2:32 - loss: 3.3540 - accuracy: 0.14 - ETA: 2:31 - loss: 3.3538 - accuracy: 0.14 - ETA: 2:30 - loss: 3.3533 - accuracy: 0.14 - ETA: 2:29 - loss: 3.3528 - accuracy: 0.14 - ETA: 2:28 - loss: 3.3542 - accuracy: 0.14 - ETA: 2:27 - loss: 3.3549 - accuracy: 0.14 - ETA: 2:26 - loss: 3.3541 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3533 - accuracy: 0.14 - ETA: 2:25 - loss: 3.3531 - accuracy: 0.14 - ETA: 2:24 - loss: 3.3529 - accuracy: 0.14 - ETA: 2:23 - loss: 3.3531 - accuracy: 0.14 - ETA: 2:22 - loss: 3.3530 - accuracy: 0.14 - ETA: 2:21 - loss: 3.3525 - accuracy: 0.14 - ETA: 2:20 - loss: 3.3531 - accuracy: 0.14 - ETA: 2:19 - loss: 3.3528 - accuracy: 0.14 - ETA: 2:18 - loss: 3.3520 - accuracy: 0.14 - ETA: 2:17 - loss: 3.3522 - accuracy: 0.14 - ETA: 2:16 - loss: 3.3519 - accuracy: 0.1457"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:15 - loss: 3.3519 - accuracy: 0.14 - ETA: 2:14 - loss: 3.3519 - accuracy: 0.14 - ETA: 2:13 - loss: 3.3519 - accuracy: 0.14 - ETA: 2:12 - loss: 3.3519 - accuracy: 0.14 - ETA: 2:11 - loss: 3.3517 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3513 - accuracy: 0.14 - ETA: 2:10 - loss: 3.3506 - accuracy: 0.14 - ETA: 2:09 - loss: 3.3512 - accuracy: 0.14 - ETA: 2:08 - loss: 3.3512 - accuracy: 0.14 - ETA: 2:07 - loss: 3.3510 - accuracy: 0.14 - ETA: 2:06 - loss: 3.3509 - accuracy: 0.14 - ETA: 2:05 - loss: 3.3510 - accuracy: 0.14 - ETA: 2:04 - loss: 3.3522 - accuracy: 0.14 - ETA: 2:03 - loss: 3.3523 - accuracy: 0.14 - ETA: 2:02 - loss: 3.3519 - accuracy: 0.14 - ETA: 2:01 - loss: 3.3517 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3517 - accuracy: 0.14 - ETA: 2:00 - loss: 3.3518 - accuracy: 0.14 - ETA: 1:59 - loss: 3.3519 - accuracy: 0.14 - ETA: 1:58 - loss: 3.3519 - accuracy: 0.14 - ETA: 1:57 - loss: 3.3536 - accuracy: 0.14 - ETA: 1:56 - loss: 3.3534 - accuracy: 0.14 - ETA: 1:55 - loss: 3.3535 - accuracy: 0.14 - ETA: 1:54 - loss: 3.3538 - accuracy: 0.14 - ETA: 1:53 - loss: 3.3546 - accuracy: 0.14 - ETA: 1:52 - loss: 3.3550 - accuracy: 0.14 - ETA: 1:51 - loss: 3.3554 - accuracy: 0.14 - ETA: 1:50 - loss: 3.3554 - accuracy: 0.14 - ETA: 1:49 - loss: 3.3559 - accuracy: 0.14 - ETA: 1:48 - loss: 3.3559 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3556 - accuracy: 0.14 - ETA: 1:47 - loss: 3.3559 - accuracy: 0.14 - ETA: 1:46 - loss: 3.3559 - accuracy: 0.14 - ETA: 1:45 - loss: 3.3561 - accuracy: 0.14 - ETA: 1:44 - loss: 3.3565 - accuracy: 0.14 - ETA: 1:43 - loss: 3.3560 - accuracy: 0.14 - ETA: 1:42 - loss: 3.3562 - accuracy: 0.14 - ETA: 1:41 - loss: 3.3561 - accuracy: 0.14 - ETA: 1:40 - loss: 3.3560 - accuracy: 0.14 - ETA: 1:39 - loss: 3.3554 - accuracy: 0.14 - ETA: 1:38 - loss: 3.3553 - accuracy: 0.14 - ETA: 1:37 - loss: 3.3552 - accuracy: 0.14 - ETA: 1:36 - loss: 3.3553 - accuracy: 0.14 - ETA: 1:35 - loss: 3.3548 - accuracy: 0.14 - ETA: 1:34 - loss: 3.3540 - accuracy: 0.14 - ETA: 1:33 - loss: 3.3546 - accuracy: 0.14 - ETA: 1:32 - loss: 3.3541 - accuracy: 0.14 - ETA: 1:31 - loss: 3.3543 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3536 - accuracy: 0.14 - ETA: 1:30 - loss: 3.3533 - accuracy: 0.14 - ETA: 1:29 - loss: 3.3534 - accuracy: 0.14 - ETA: 1:28 - loss: 3.3535 - accuracy: 0.14 - ETA: 1:27 - loss: 3.3535 - accuracy: 0.14 - ETA: 1:26 - loss: 3.3535 - accuracy: 0.14 - ETA: 1:25 - loss: 3.3533 - accuracy: 0.14 - ETA: 1:24 - loss: 3.3536 - accuracy: 0.14 - ETA: 1:23 - loss: 3.3544 - accuracy: 0.14 - ETA: 1:22 - loss: 3.3544 - accuracy: 0.14 - ETA: 1:21 - loss: 3.3539 - accuracy: 0.14 - ETA: 1:20 - loss: 3.3538 - accuracy: 0.14 - ETA: 1:19 - loss: 3.3534 - accuracy: 0.14 - ETA: 1:18 - loss: 3.3534 - accuracy: 0.14 - ETA: 1:17 - loss: 3.3535 - accuracy: 0.14 - ETA: 1:16 - loss: 3.3533 - accuracy: 0.14 - ETA: 1:15 - loss: 3.3534 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3540 - accuracy: 0.14 - ETA: 1:14 - loss: 3.3535 - accuracy: 0.14 - ETA: 1:13 - loss: 3.3541 - accuracy: 0.14 - ETA: 1:12 - loss: 3.3538 - accuracy: 0.14 - ETA: 1:11 - loss: 3.3540 - accuracy: 0.14 - ETA: 1:10 - loss: 3.3543 - accuracy: 0.14 - ETA: 1:09 - loss: 3.3545 - accuracy: 0.14 - ETA: 1:08 - loss: 3.3542 - accuracy: 0.14 - ETA: 1:07 - loss: 3.3547 - accuracy: 0.14 - ETA: 1:06 - loss: 3.3546 - accuracy: 0.14 - ETA: 1:05 - loss: 3.3550 - accuracy: 0.14 - ETA: 1:04 - loss: 3.3554 - accuracy: 0.14 - ETA: 1:03 - loss: 3.3559 - accuracy: 0.14 - ETA: 1:02 - loss: 3.3558 - accuracy: 0.14 - ETA: 1:01 - loss: 3.3564 - accuracy: 0.14 - ETA: 1:00 - loss: 3.3564 - accuracy: 0.14 - ETA: 59s - loss: 3.3567 - accuracy: 0.1412 - ETA: 58s - loss: 3.3570 - accuracy: 0.141 - ETA: 57s - loss: 3.3571 - accuracy: 0.141 - ETA: 56s - loss: 3.3574 - accuracy: 0.141 - ETA: 56s - loss: 3.3575 - accuracy: 0.141 - ETA: 55s - loss: 3.3574 - accuracy: 0.141 - ETA: 54s - loss: 3.3572 - accuracy: 0.141 - ETA: 53s - loss: 3.3568 - accuracy: 0.141 - ETA: 52s - loss: 3.3566 - accuracy: 0.141 - ETA: 51s - loss: 3.3572 - accuracy: 0.141 - ETA: 50s - loss: 3.3578 - accuracy: 0.140 - ETA: 49s - loss: 3.3584 - accuracy: 0.140 - ETA: 48s - loss: 3.3580 - accuracy: 0.140 - ETA: 47s - loss: 3.3588 - accuracy: 0.140 - ETA: 46s - loss: 3.3591 - accuracy: 0.140 - ETA: 45s - loss: 3.3587 - accuracy: 0.140 - ETA: 44s - loss: 3.3589 - accuracy: 0.140 - ETA: 43s - loss: 3.3591 - accuracy: 0.140 - ETA: 42s - loss: 3.3600 - accuracy: 0.140 - ETA: 41s - loss: 3.3598 - accuracy: 0.140 - ETA: 40s - loss: 3.3598 - accuracy: 0.140 - ETA: 39s - loss: 3.3596 - accuracy: 0.140 - ETA: 38s - loss: 3.3602 - accuracy: 0.140 - ETA: 38s - loss: 3.3602 - accuracy: 0.140 - ETA: 37s - loss: 3.3605 - accuracy: 0.140 - ETA: 36s - loss: 3.3601 - accuracy: 0.140 - ETA: 35s - loss: 3.3601 - accuracy: 0.140 - ETA: 34s - loss: 3.3596 - accuracy: 0.140 - ETA: 33s - loss: 3.3599 - accuracy: 0.140 - ETA: 32s - loss: 3.3596 - accuracy: 0.140 - ETA: 31s - loss: 3.3591 - accuracy: 0.140 - ETA: 30s - loss: 3.3649 - accuracy: 0.140 - ETA: 29s - loss: 3.3651 - accuracy: 0.140 - ETA: 28s - loss: 3.3647 - accuracy: 0.140 - ETA: 27s - loss: 3.3651 - accuracy: 0.140 - ETA: 26s - loss: 3.3649 - accuracy: 0.140 - ETA: 25s - loss: 3.3646 - accuracy: 0.140 - ETA: 24s - loss: 3.3648 - accuracy: 0.140 - ETA: 23s - loss: 3.3652 - accuracy: 0.140 - ETA: 22s - loss: 3.3651 - accuracy: 0.140 - ETA: 21s - loss: 3.3650 - accuracy: 0.140 - ETA: 20s - loss: 3.3647 - accuracy: 0.139 - ETA: 19s - loss: 3.3643 - accuracy: 0.140 - ETA: 19s - loss: 3.3643 - accuracy: 0.140 - ETA: 18s - loss: 3.3640 - accuracy: 0.140 - ETA: 17s - loss: 3.3634 - accuracy: 0.140 - ETA: 16s - loss: 3.3635 - accuracy: 0.140 - ETA: 15s - loss: 3.3636 - accuracy: 0.140 - ETA: 14s - loss: 3.3635 - accuracy: 0.140 - ETA: 13s - loss: 3.3637 - accuracy: 0.139 - ETA: 12s - loss: 3.3638 - accuracy: 0.139 - ETA: 11s - loss: 3.3641 - accuracy: 0.139 - ETA: 10s - loss: 3.3640 - accuracy: 0.139 - ETA: 9s - loss: 3.3642 - accuracy: 0.139 - ETA: 8s - loss: 3.3641 - accuracy: 0.13 - ETA: 7s - loss: 3.3645 - accuracy: 0.13 - ETA: 6s - loss: 3.3646 - accuracy: 0.13 - ETA: 5s - loss: 3.3647 - accuracy: 0.13 - ETA: 4s - loss: 3.3644 - accuracy: 0.13 - ETA: 3s - loss: 3.3642 - accuracy: 0.13 - ETA: 2s - loss: 3.3636 - accuracy: 0.13 - ETA: 1s - loss: 3.3640 - accuracy: 0.13 - ETA: 1s - loss: 3.3637 - accuracy: 0.13 - ETA: 0s - loss: 3.3634 - accuracy: 0.13 - 338s 8ms/step - loss: 3.3634 - accuracy: 0.1394 - val_loss: 3.8794 - val_accuracy: 0.0125\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:51 - loss: 3.3531 - accuracy: 0.15 - ETA: 4:53 - loss: 3.2756 - accuracy: 0.16 - ETA: 4:54 - loss: 3.2770 - accuracy: 0.17 - ETA: 5:06 - loss: 3.3083 - accuracy: 0.16 - ETA: 5:01 - loss: 3.3379 - accuracy: 0.15 - ETA: 5:00 - loss: 3.3417 - accuracy: 0.14 - ETA: 4:58 - loss: 3.3206 - accuracy: 0.15 - ETA: 5:00 - loss: 3.3033 - accuracy: 0.15 - ETA: 5:02 - loss: 3.3143 - accuracy: 0.15 - ETA: 4:59 - loss: 3.3145 - accuracy: 0.15 - ETA: 4:58 - loss: 3.3091 - accuracy: 0.15 - ETA: 4:57 - loss: 3.3247 - accuracy: 0.15 - ETA: 4:57 - loss: 3.3325 - accuracy: 0.14 - ETA: 4:57 - loss: 3.3380 - accuracy: 0.15 - ETA: 4:58 - loss: 3.3400 - accuracy: 0.14 - ETA: 4:57 - loss: 3.3431 - accuracy: 0.14 - ETA: 4:56 - loss: 3.3474 - accuracy: 0.14 - ETA: 4:54 - loss: 3.3436 - accuracy: 0.14 - ETA: 4:52 - loss: 3.3435 - accuracy: 0.14 - ETA: 4:50 - loss: 3.3506 - accuracy: 0.14 - ETA: 4:49 - loss: 3.3583 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3604 - accuracy: 0.13 - ETA: 4:47 - loss: 3.3604 - accuracy: 0.13 - ETA: 4:47 - loss: 3.3564 - accuracy: 0.13 - ETA: 4:45 - loss: 3.3611 - accuracy: 0.13 - ETA: 4:43 - loss: 3.3673 - accuracy: 0.13 - ETA: 4:43 - loss: 3.3633 - accuracy: 0.13 - ETA: 4:42 - loss: 3.3675 - accuracy: 0.13 - ETA: 4:42 - loss: 3.3713 - accuracy: 0.13 - ETA: 4:41 - loss: 3.3748 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3663 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3651 - accuracy: 0.13 - ETA: 4:39 - loss: 3.3622 - accuracy: 0.13 - ETA: 4:38 - loss: 3.3626 - accuracy: 0.13 - ETA: 4:37 - loss: 3.3691 - accuracy: 0.13 - ETA: 4:36 - loss: 3.3649 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3632 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3635 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3627 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3661 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3660 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3642 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3681 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3696 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3704 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3694 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3709 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3714 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3738 - accuracy: 0.12 - ETA: 4:23 - loss: 3.3719 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3711 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3715 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3766 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3800 - accuracy: 0.12 - ETA: 4:19 - loss: 3.3791 - accuracy: 0.13 - ETA: 4:18 - loss: 3.3804 - accuracy: 0.13 - ETA: 4:17 - loss: 3.3797 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3810 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3812 - accuracy: 0.13 - ETA: 4:15 - loss: 3.3794 - accuracy: 0.13 - ETA: 4:14 - loss: 3.3786 - accuracy: 0.13 - ETA: 4:13 - loss: 3.3793 - accuracy: 0.13 - ETA: 4:12 - loss: 3.3800 - accuracy: 0.13 - ETA: 4:11 - loss: 3.3780 - accuracy: 0.13 - ETA: 4:10 - loss: 3.3757 - accuracy: 0.13 - ETA: 4:09 - loss: 3.3758 - accuracy: 0.13 - ETA: 4:08 - loss: 3.3740 - accuracy: 0.13 - ETA: 4:07 - loss: 3.3711 - accuracy: 0.13 - ETA: 4:06 - loss: 3.3716 - accuracy: 0.13 - ETA: 4:05 - loss: 3.3757 - accuracy: 0.13 - ETA: 4:04 - loss: 3.3735 - accuracy: 0.13 - ETA: 4:03 - loss: 3.3756 - accuracy: 0.13 - ETA: 4:02 - loss: 3.3747 - accuracy: 0.13 - ETA: 4:02 - loss: 3.3728 - accuracy: 0.13 - ETA: 4:01 - loss: 3.3713 - accuracy: 0.13 - ETA: 4:00 - loss: 3.3724 - accuracy: 0.13 - ETA: 3:59 - loss: 3.3724 - accuracy: 0.13 - ETA: 3:58 - loss: 3.3689 - accuracy: 0.13 - ETA: 3:57 - loss: 3.3719 - accuracy: 0.13 - ETA: 3:56 - loss: 3.3714 - accuracy: 0.13 - ETA: 3:55 - loss: 3.3722 - accuracy: 0.13 - ETA: 3:54 - loss: 3.3735 - accuracy: 0.13 - ETA: 3:54 - loss: 3.3739 - accuracy: 0.13 - ETA: 3:53 - loss: 3.3741 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3737 - accuracy: 0.13 - ETA: 3:50 - loss: 3.3740 - accuracy: 0.13 - ETA: 3:49 - loss: 3.3760 - accuracy: 0.13 - ETA: 3:48 - loss: 3.3764 - accuracy: 0.13 - ETA: 3:47 - loss: 3.3755 - accuracy: 0.13 - ETA: 3:46 - loss: 3.3757 - accuracy: 0.13 - ETA: 3:46 - loss: 3.3761 - accuracy: 0.13 - ETA: 3:45 - loss: 3.3764 - accuracy: 0.13 - ETA: 3:43 - loss: 3.3759 - accuracy: 0.13 - ETA: 3:42 - loss: 3.3762 - accuracy: 0.13 - ETA: 3:42 - loss: 3.3766 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3763 - accuracy: 0.13 - ETA: 3:40 - loss: 3.3746 - accuracy: 0.13 - ETA: 3:39 - loss: 3.3745 - accuracy: 0.13 - ETA: 3:38 - loss: 3.3735 - accuracy: 0.13 - ETA: 3:37 - loss: 3.3747 - accuracy: 0.13 - ETA: 3:36 - loss: 3.3721 - accuracy: 0.13 - ETA: 3:35 - loss: 3.3704 - accuracy: 0.13 - ETA: 3:34 - loss: 3.3714 - accuracy: 0.13 - ETA: 3:33 - loss: 3.3709 - accuracy: 0.13 - ETA: 3:32 - loss: 3.3680 - accuracy: 0.13 - ETA: 3:31 - loss: 3.3662 - accuracy: 0.13 - ETA: 3:30 - loss: 3.3654 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3658 - accuracy: 0.13 - ETA: 3:28 - loss: 3.3640 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3623 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3614 - accuracy: 0.13 - ETA: 3:26 - loss: 3.3613 - accuracy: 0.13 - ETA: 3:25 - loss: 3.3611 - accuracy: 0.13 - ETA: 3:24 - loss: 3.3596 - accuracy: 0.13 - ETA: 3:23 - loss: 3.3602 - accuracy: 0.13 - ETA: 3:22 - loss: 3.3592 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3586 - accuracy: 0.13 - ETA: 3:20 - loss: 3.3586 - accuracy: 0.13 - ETA: 3:19 - loss: 3.3584 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3561 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3567 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3555 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3556 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3561 - accuracy: 0.13 - ETA: 3:14 - loss: 3.3559 - accuracy: 0.13 - ETA: 3:13 - loss: 3.3553 - accuracy: 0.13 - ETA: 3:12 - loss: 3.3560 - accuracy: 0.13 - ETA: 3:11 - loss: 3.3563 - accuracy: 0.13 - ETA: 3:10 - loss: 3.3563 - accuracy: 0.13 - ETA: 3:09 - loss: 3.3572 - accuracy: 0.13 - ETA: 3:08 - loss: 3.3560 - accuracy: 0.13 - ETA: 3:07 - loss: 3.3553 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3540 - accuracy: 0.13 - ETA: 3:05 - loss: 3.3539 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3548 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3549 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3544 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3535 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3544 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3551 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3528 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3534 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3518 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3516 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3514 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3520 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3515 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3523 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3513 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3504 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3494 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3486 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3489 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3504 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3496 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3495 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3492 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3494 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3498 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3500 - accuracy: 0.13 - ETA: 2:40 - loss: 3.3498 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3499 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3499 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3504 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3504 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3512 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3527 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3522 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3529 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3532 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3533 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3551 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3563 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3570 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3571 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3573 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3575 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3577 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3586 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3590 - accuracy: 0.13 - ETA: 2:21 - loss: 3.3589 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3596 - accuracy: 0.13 - ETA: 2:19 - loss: 3.3593 - accuracy: 0.13 - ETA: 2:18 - loss: 3.3591 - accuracy: 0.13 - ETA: 2:17 - loss: 3.3602 - accuracy: 0.13 - ETA: 2:16 - loss: 3.3612 - accuracy: 0.1347"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:15 - loss: 3.3623 - accuracy: 0.13 - ETA: 2:14 - loss: 3.3622 - accuracy: 0.13 - ETA: 2:13 - loss: 3.3631 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3633 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3641 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3644 - accuracy: 0.13 - ETA: 2:10 - loss: 3.3649 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3658 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3652 - accuracy: 0.13 - ETA: 2:07 - loss: 3.3655 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3667 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3665 - accuracy: 0.13 - ETA: 2:04 - loss: 3.3661 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3662 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3656 - accuracy: 0.13 - ETA: 2:01 - loss: 3.3664 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3672 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3663 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3661 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3650 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3649 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3661 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3667 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3659 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3663 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3661 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3659 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3670 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3661 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3663 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3670 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3674 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3678 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3675 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3673 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3666 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3670 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3677 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3673 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3673 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3675 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3671 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3672 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3681 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3690 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3690 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3683 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3674 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3666 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3671 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3680 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3677 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3675 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3680 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3678 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3670 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3693 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3697 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3696 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3705 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3700 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3702 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3696 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3697 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3698 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3701 - accuracy: 0.13 - ETA: 1:13 - loss: 3.3705 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3707 - accuracy: 0.13 - ETA: 1:11 - loss: 3.3704 - accuracy: 0.13 - ETA: 1:10 - loss: 3.3710 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3716 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3717 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3716 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3710 - accuracy: 0.13 - ETA: 1:06 - loss: 3.3710 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3713 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3709 - accuracy: 0.13 - ETA: 1:03 - loss: 3.3710 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3715 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3708 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3702 - accuracy: 0.13 - ETA: 59s - loss: 3.3699 - accuracy: 0.1333 - ETA: 58s - loss: 3.3700 - accuracy: 0.133 - ETA: 57s - loss: 3.3698 - accuracy: 0.133 - ETA: 56s - loss: 3.3695 - accuracy: 0.133 - ETA: 55s - loss: 3.3694 - accuracy: 0.133 - ETA: 54s - loss: 3.3694 - accuracy: 0.133 - ETA: 53s - loss: 3.3692 - accuracy: 0.133 - ETA: 52s - loss: 3.3683 - accuracy: 0.133 - ETA: 51s - loss: 3.3681 - accuracy: 0.133 - ETA: 51s - loss: 3.3679 - accuracy: 0.133 - ETA: 50s - loss: 3.3677 - accuracy: 0.134 - ETA: 49s - loss: 3.3672 - accuracy: 0.134 - ETA: 48s - loss: 3.3679 - accuracy: 0.133 - ETA: 47s - loss: 3.3681 - accuracy: 0.133 - ETA: 46s - loss: 3.3684 - accuracy: 0.133 - ETA: 45s - loss: 3.3686 - accuracy: 0.133 - ETA: 44s - loss: 3.3691 - accuracy: 0.133 - ETA: 43s - loss: 3.3693 - accuracy: 0.133 - ETA: 42s - loss: 3.3697 - accuracy: 0.133 - ETA: 41s - loss: 3.3698 - accuracy: 0.133 - ETA: 40s - loss: 3.3706 - accuracy: 0.133 - ETA: 39s - loss: 3.3704 - accuracy: 0.133 - ETA: 38s - loss: 3.3703 - accuracy: 0.133 - ETA: 37s - loss: 3.3701 - accuracy: 0.133 - ETA: 36s - loss: 3.3703 - accuracy: 0.133 - ETA: 35s - loss: 3.3709 - accuracy: 0.133 - ETA: 35s - loss: 3.3706 - accuracy: 0.133 - ETA: 34s - loss: 3.3708 - accuracy: 0.132 - ETA: 33s - loss: 3.3709 - accuracy: 0.132 - ETA: 32s - loss: 3.3715 - accuracy: 0.132 - ETA: 31s - loss: 3.3715 - accuracy: 0.132 - ETA: 30s - loss: 3.3710 - accuracy: 0.132 - ETA: 29s - loss: 3.3714 - accuracy: 0.132 - ETA: 28s - loss: 3.3710 - accuracy: 0.132 - ETA: 27s - loss: 3.3709 - accuracy: 0.132 - ETA: 26s - loss: 3.3708 - accuracy: 0.133 - ETA: 25s - loss: 3.3707 - accuracy: 0.133 - ETA: 24s - loss: 3.3706 - accuracy: 0.133 - ETA: 23s - loss: 3.3705 - accuracy: 0.133 - ETA: 22s - loss: 3.3709 - accuracy: 0.133 - ETA: 21s - loss: 3.3713 - accuracy: 0.133 - ETA: 20s - loss: 3.3713 - accuracy: 0.132 - ETA: 19s - loss: 3.3709 - accuracy: 0.133 - ETA: 18s - loss: 3.3709 - accuracy: 0.133 - ETA: 18s - loss: 3.3706 - accuracy: 0.133 - ETA: 17s - loss: 3.3710 - accuracy: 0.133 - ETA: 16s - loss: 3.3710 - accuracy: 0.133 - ETA: 15s - loss: 3.3708 - accuracy: 0.133 - ETA: 14s - loss: 3.3707 - accuracy: 0.132 - ETA: 13s - loss: 3.3707 - accuracy: 0.132 - ETA: 12s - loss: 3.3710 - accuracy: 0.132 - ETA: 11s - loss: 3.3711 - accuracy: 0.132 - ETA: 10s - loss: 3.3706 - accuracy: 0.132 - ETA: 9s - loss: 3.3706 - accuracy: 0.132 - ETA: 8s - loss: 3.3711 - accuracy: 0.13 - ETA: 7s - loss: 3.3707 - accuracy: 0.13 - ETA: 6s - loss: 3.3709 - accuracy: 0.13 - ETA: 5s - loss: 3.3707 - accuracy: 0.13 - ETA: 4s - loss: 3.3705 - accuracy: 0.13 - ETA: 3s - loss: 3.3707 - accuracy: 0.13 - ETA: 2s - loss: 3.3714 - accuracy: 0.13 - ETA: 1s - loss: 3.3713 - accuracy: 0.13 - ETA: 1s - loss: 3.3710 - accuracy: 0.13 - ETA: 0s - loss: 3.3707 - accuracy: 0.13 - 337s 8ms/step - loss: 3.3710 - accuracy: 0.1331 - val_loss: 3.8902 - val_accuracy: 0.0112\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:12 - loss: 3.4587 - accuracy: 0.09 - ETA: 5:06 - loss: 3.4396 - accuracy: 0.09 - ETA: 5:13 - loss: 3.4545 - accuracy: 0.09 - ETA: 5:15 - loss: 3.4122 - accuracy: 0.11 - ETA: 5:15 - loss: 3.4002 - accuracy: 0.12 - ETA: 5:11 - loss: 3.3987 - accuracy: 0.12 - ETA: 5:10 - loss: 3.3820 - accuracy: 0.13 - ETA: 5:09 - loss: 3.3736 - accuracy: 0.13 - ETA: 5:05 - loss: 3.3808 - accuracy: 0.13 - ETA: 5:04 - loss: 3.3919 - accuracy: 0.13 - ETA: 5:03 - loss: 3.3919 - accuracy: 0.13 - ETA: 5:04 - loss: 3.3718 - accuracy: 0.13 - ETA: 5:04 - loss: 3.3679 - accuracy: 0.13 - ETA: 5:02 - loss: 3.3660 - accuracy: 0.13 - ETA: 5:00 - loss: 3.3590 - accuracy: 0.13 - ETA: 4:59 - loss: 3.3538 - accuracy: 0.13 - ETA: 4:56 - loss: 3.3597 - accuracy: 0.13 - ETA: 4:54 - loss: 3.3591 - accuracy: 0.13 - ETA: 4:53 - loss: 3.3579 - accuracy: 0.13 - ETA: 4:53 - loss: 3.3584 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3689 - accuracy: 0.13 - ETA: 4:50 - loss: 3.3654 - accuracy: 0.13 - ETA: 4:50 - loss: 3.3630 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3704 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3669 - accuracy: 0.13 - ETA: 4:48 - loss: 3.3657 - accuracy: 0.13 - ETA: 4:47 - loss: 3.3582 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3536 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3488 - accuracy: 0.13 - ETA: 4:45 - loss: 3.3488 - accuracy: 0.13 - ETA: 4:45 - loss: 3.3479 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3457 - accuracy: 0.13 - ETA: 4:42 - loss: 3.3460 - accuracy: 0.13 - ETA: 4:41 - loss: 3.3432 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3391 - accuracy: 0.13 - ETA: 4:39 - loss: 3.3393 - accuracy: 0.13 - ETA: 4:39 - loss: 3.3398 - accuracy: 0.13 - ETA: 4:38 - loss: 3.3385 - accuracy: 0.13 - ETA: 4:37 - loss: 3.3388 - accuracy: 0.13 - ETA: 4:36 - loss: 3.3441 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3405 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3358 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3368 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3414 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3448 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3434 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3425 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3430 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3432 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3453 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3445 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3411 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3410 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3400 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3425 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3416 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3416 - accuracy: 0.13 - ETA: 4:19 - loss: 3.3443 - accuracy: 0.13 - ETA: 4:18 - loss: 3.3445 - accuracy: 0.13 - ETA: 4:17 - loss: 3.3457 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3427 - accuracy: 0.13 - ETA: 4:15 - loss: 3.3404 - accuracy: 0.13 - ETA: 4:14 - loss: 3.3416 - accuracy: 0.13 - ETA: 4:13 - loss: 3.3417 - accuracy: 0.13 - ETA: 4:12 - loss: 3.3420 - accuracy: 0.13 - ETA: 4:11 - loss: 3.3406 - accuracy: 0.13 - ETA: 4:10 - loss: 3.3380 - accuracy: 0.13 - ETA: 4:09 - loss: 3.3389 - accuracy: 0.13 - ETA: 4:08 - loss: 3.3364 - accuracy: 0.13 - ETA: 4:07 - loss: 3.3361 - accuracy: 0.13 - ETA: 4:06 - loss: 3.3362 - accuracy: 0.13 - ETA: 4:05 - loss: 3.3361 - accuracy: 0.13 - ETA: 4:04 - loss: 3.3381 - accuracy: 0.13 - ETA: 4:02 - loss: 3.3403 - accuracy: 0.13 - ETA: 4:01 - loss: 3.3426 - accuracy: 0.13 - ETA: 4:00 - loss: 3.3428 - accuracy: 0.13 - ETA: 4:00 - loss: 3.3418 - accuracy: 0.13 - ETA: 3:59 - loss: 3.3420 - accuracy: 0.13 - ETA: 3:58 - loss: 3.3420 - accuracy: 0.13 - ETA: 3:57 - loss: 3.3423 - accuracy: 0.13 - ETA: 3:56 - loss: 3.3425 - accuracy: 0.13 - ETA: 3:55 - loss: 3.3410 - accuracy: 0.13 - ETA: 3:54 - loss: 3.3430 - accuracy: 0.13 - ETA: 3:53 - loss: 3.3430 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3441 - accuracy: 0.13 - ETA: 3:51 - loss: 3.3433 - accuracy: 0.13 - ETA: 3:50 - loss: 3.3427 - accuracy: 0.13 - ETA: 3:49 - loss: 3.3420 - accuracy: 0.13 - ETA: 3:49 - loss: 3.3439 - accuracy: 0.13 - ETA: 3:48 - loss: 3.3457 - accuracy: 0.13 - ETA: 3:47 - loss: 3.3461 - accuracy: 0.13 - ETA: 3:46 - loss: 3.3470 - accuracy: 0.13 - ETA: 3:45 - loss: 3.3460 - accuracy: 0.13 - ETA: 3:44 - loss: 3.3486 - accuracy: 0.13 - ETA: 3:42 - loss: 3.3503 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3505 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3529 - accuracy: 0.13 - ETA: 3:40 - loss: 3.3569 - accuracy: 0.13 - ETA: 3:39 - loss: 3.3588 - accuracy: 0.13 - ETA: 3:38 - loss: 3.3597 - accuracy: 0.13 - ETA: 3:37 - loss: 3.3599 - accuracy: 0.13 - ETA: 3:36 - loss: 3.3602 - accuracy: 0.13 - ETA: 3:35 - loss: 3.3614 - accuracy: 0.13 - ETA: 3:34 - loss: 3.3611 - accuracy: 0.13 - ETA: 3:33 - loss: 3.3603 - accuracy: 0.13 - ETA: 3:32 - loss: 3.3606 - accuracy: 0.13 - ETA: 3:31 - loss: 3.3606 - accuracy: 0.13 - ETA: 3:30 - loss: 3.3601 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3612 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3611 - accuracy: 0.13 - ETA: 3:28 - loss: 3.3616 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3621 - accuracy: 0.13 - ETA: 3:26 - loss: 3.3617 - accuracy: 0.13 - ETA: 3:25 - loss: 3.3616 - accuracy: 0.13 - ETA: 3:24 - loss: 3.3609 - accuracy: 0.13 - ETA: 3:23 - loss: 3.3612 - accuracy: 0.13 - ETA: 3:22 - loss: 3.3609 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3608 - accuracy: 0.13 - ETA: 3:20 - loss: 3.3617 - accuracy: 0.13 - ETA: 3:19 - loss: 3.3626 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3633 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3633 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3626 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3627 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3644 - accuracy: 0.13 - ETA: 3:14 - loss: 3.3636 - accuracy: 0.13 - ETA: 3:13 - loss: 3.3635 - accuracy: 0.13 - ETA: 3:12 - loss: 3.3637 - accuracy: 0.13 - ETA: 3:11 - loss: 3.3636 - accuracy: 0.13 - ETA: 3:10 - loss: 3.3647 - accuracy: 0.13 - ETA: 3:09 - loss: 3.3648 - accuracy: 0.13 - ETA: 3:08 - loss: 3.3641 - accuracy: 0.13 - ETA: 3:07 - loss: 3.3643 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3645 - accuracy: 0.13 - ETA: 3:05 - loss: 3.3656 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3660 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3654 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3642 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3637 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3641 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3645 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3640 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3629 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3628 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3632 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3642 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3728 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3728 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3731 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3744 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3746 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3742 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3748 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3745 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3741 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3741 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3743 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3738 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3733 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3735 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3729 - accuracy: 0.13 - ETA: 2:40 - loss: 3.3729 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3722 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3717 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3713 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3709 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3692 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3688 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3691 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3685 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3689 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3679 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3668 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3666 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3675 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3676 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3679 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3674 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3678 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3688 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3688 - accuracy: 0.13 - ETA: 2:21 - loss: 3.3682 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3697 - accuracy: 0.13 - ETA: 2:19 - loss: 3.3695 - accuracy: 0.13 - ETA: 2:18 - loss: 3.3693 - accuracy: 0.13 - ETA: 2:17 - loss: 3.3696 - accuracy: 0.1321"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:16 - loss: 3.3701 - accuracy: 0.13 - ETA: 2:15 - loss: 3.3709 - accuracy: 0.13 - ETA: 2:15 - loss: 3.3711 - accuracy: 0.13 - ETA: 2:14 - loss: 3.3712 - accuracy: 0.13 - ETA: 2:13 - loss: 3.3715 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3700 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3701 - accuracy: 0.13 - ETA: 2:10 - loss: 3.3698 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3701 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3695 - accuracy: 0.13 - ETA: 2:07 - loss: 3.3694 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3702 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3701 - accuracy: 0.13 - ETA: 2:04 - loss: 3.3704 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3708 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3710 - accuracy: 0.13 - ETA: 2:01 - loss: 3.3720 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3722 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3724 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3718 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3719 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3725 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3725 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3719 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3720 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3716 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3719 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3719 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3720 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3718 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3717 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3718 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3715 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3718 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3720 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3716 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3713 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3709 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3705 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3704 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3705 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3707 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3702 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3703 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3705 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3709 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3703 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3708 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3709 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3709 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3717 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3723 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3729 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3723 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3726 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3719 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3714 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3712 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3717 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3713 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3706 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3708 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3709 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3716 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3708 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3709 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3713 - accuracy: 0.13 - ETA: 1:13 - loss: 3.3710 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3711 - accuracy: 0.13 - ETA: 1:11 - loss: 3.3707 - accuracy: 0.13 - ETA: 1:10 - loss: 3.3703 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3702 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3707 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3706 - accuracy: 0.13 - ETA: 1:06 - loss: 3.3705 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3705 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3702 - accuracy: 0.13 - ETA: 1:03 - loss: 3.3705 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3704 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3699 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3692 - accuracy: 0.13 - ETA: 59s - loss: 3.3691 - accuracy: 0.1319 - ETA: 58s - loss: 3.3690 - accuracy: 0.131 - ETA: 58s - loss: 3.3688 - accuracy: 0.131 - ETA: 57s - loss: 3.3686 - accuracy: 0.131 - ETA: 56s - loss: 3.3691 - accuracy: 0.131 - ETA: 55s - loss: 3.3686 - accuracy: 0.131 - ETA: 54s - loss: 3.3688 - accuracy: 0.131 - ETA: 53s - loss: 3.3680 - accuracy: 0.131 - ETA: 52s - loss: 3.3675 - accuracy: 0.131 - ETA: 51s - loss: 3.3675 - accuracy: 0.131 - ETA: 50s - loss: 3.3677 - accuracy: 0.131 - ETA: 49s - loss: 3.3674 - accuracy: 0.131 - ETA: 48s - loss: 3.3673 - accuracy: 0.131 - ETA: 47s - loss: 3.3670 - accuracy: 0.132 - ETA: 46s - loss: 3.3673 - accuracy: 0.131 - ETA: 45s - loss: 3.3665 - accuracy: 0.132 - ETA: 44s - loss: 3.3669 - accuracy: 0.132 - ETA: 43s - loss: 3.3662 - accuracy: 0.132 - ETA: 42s - loss: 3.3661 - accuracy: 0.132 - ETA: 41s - loss: 3.3656 - accuracy: 0.132 - ETA: 40s - loss: 3.3653 - accuracy: 0.132 - ETA: 39s - loss: 3.3659 - accuracy: 0.132 - ETA: 39s - loss: 3.3664 - accuracy: 0.132 - ETA: 38s - loss: 3.3667 - accuracy: 0.132 - ETA: 37s - loss: 3.3667 - accuracy: 0.132 - ETA: 36s - loss: 3.3668 - accuracy: 0.132 - ETA: 35s - loss: 3.3673 - accuracy: 0.132 - ETA: 34s - loss: 3.3669 - accuracy: 0.132 - ETA: 33s - loss: 3.3664 - accuracy: 0.132 - ETA: 32s - loss: 3.3663 - accuracy: 0.132 - ETA: 31s - loss: 3.3661 - accuracy: 0.132 - ETA: 30s - loss: 3.3663 - accuracy: 0.132 - ETA: 29s - loss: 3.3665 - accuracy: 0.132 - ETA: 28s - loss: 3.3666 - accuracy: 0.132 - ETA: 27s - loss: 3.3664 - accuracy: 0.132 - ETA: 26s - loss: 3.3665 - accuracy: 0.132 - ETA: 25s - loss: 3.3666 - accuracy: 0.132 - ETA: 24s - loss: 3.3665 - accuracy: 0.132 - ETA: 23s - loss: 3.3664 - accuracy: 0.132 - ETA: 22s - loss: 3.3665 - accuracy: 0.132 - ETA: 21s - loss: 3.3669 - accuracy: 0.132 - ETA: 20s - loss: 3.3674 - accuracy: 0.132 - ETA: 20s - loss: 3.3674 - accuracy: 0.132 - ETA: 19s - loss: 3.3679 - accuracy: 0.132 - ETA: 18s - loss: 3.3675 - accuracy: 0.132 - ETA: 17s - loss: 3.3679 - accuracy: 0.132 - ETA: 16s - loss: 3.3678 - accuracy: 0.132 - ETA: 15s - loss: 3.3672 - accuracy: 0.132 - ETA: 14s - loss: 3.3672 - accuracy: 0.132 - ETA: 13s - loss: 3.3677 - accuracy: 0.132 - ETA: 12s - loss: 3.3682 - accuracy: 0.132 - ETA: 11s - loss: 3.3688 - accuracy: 0.132 - ETA: 10s - loss: 3.3689 - accuracy: 0.132 - ETA: 9s - loss: 3.3695 - accuracy: 0.132 - ETA: 8s - loss: 3.3699 - accuracy: 0.13 - ETA: 7s - loss: 3.3701 - accuracy: 0.13 - ETA: 6s - loss: 3.3702 - accuracy: 0.13 - ETA: 5s - loss: 3.3703 - accuracy: 0.13 - ETA: 4s - loss: 3.3705 - accuracy: 0.13 - ETA: 3s - loss: 3.3709 - accuracy: 0.13 - ETA: 2s - loss: 3.3717 - accuracy: 0.13 - ETA: 1s - loss: 3.3717 - accuracy: 0.13 - ETA: 1s - loss: 3.3720 - accuracy: 0.13 - ETA: 0s - loss: 3.3722 - accuracy: 0.13 - 340s 8ms/step - loss: 3.3722 - accuracy: 0.1319 - val_loss: 3.8556 - val_accuracy: 0.0080\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:08 - loss: 3.4617 - accuracy: 0.11 - ETA: 5:04 - loss: 3.4077 - accuracy: 0.11 - ETA: 5:07 - loss: 3.4761 - accuracy: 0.10 - ETA: 5:11 - loss: 3.4502 - accuracy: 0.10 - ETA: 5:11 - loss: 3.4465 - accuracy: 0.11 - ETA: 5:10 - loss: 3.4847 - accuracy: 0.10 - ETA: 5:10 - loss: 3.4632 - accuracy: 0.11 - ETA: 5:10 - loss: 3.4514 - accuracy: 0.11 - ETA: 5:09 - loss: 3.4478 - accuracy: 0.11 - ETA: 5:05 - loss: 3.4279 - accuracy: 0.11 - ETA: 5:03 - loss: 3.4133 - accuracy: 0.11 - ETA: 5:02 - loss: 3.4157 - accuracy: 0.11 - ETA: 5:03 - loss: 3.4122 - accuracy: 0.12 - ETA: 5:01 - loss: 3.4099 - accuracy: 0.12 - ETA: 5:00 - loss: 3.4171 - accuracy: 0.12 - ETA: 4:59 - loss: 3.4233 - accuracy: 0.12 - ETA: 4:58 - loss: 3.4107 - accuracy: 0.12 - ETA: 4:58 - loss: 3.4081 - accuracy: 0.12 - ETA: 4:57 - loss: 3.4030 - accuracy: 0.12 - ETA: 4:56 - loss: 3.4023 - accuracy: 0.12 - ETA: 4:56 - loss: 3.4106 - accuracy: 0.12 - ETA: 4:54 - loss: 3.4164 - accuracy: 0.12 - ETA: 4:52 - loss: 3.4194 - accuracy: 0.12 - ETA: 4:51 - loss: 3.4197 - accuracy: 0.12 - ETA: 4:51 - loss: 3.4152 - accuracy: 0.12 - ETA: 4:49 - loss: 3.4178 - accuracy: 0.12 - ETA: 4:47 - loss: 3.4179 - accuracy: 0.12 - ETA: 4:46 - loss: 3.4191 - accuracy: 0.12 - ETA: 4:46 - loss: 3.4177 - accuracy: 0.12 - ETA: 4:45 - loss: 3.4179 - accuracy: 0.12 - ETA: 4:44 - loss: 3.4150 - accuracy: 0.12 - ETA: 4:43 - loss: 3.4162 - accuracy: 0.12 - ETA: 4:43 - loss: 3.4188 - accuracy: 0.12 - ETA: 4:42 - loss: 3.4145 - accuracy: 0.12 - ETA: 4:41 - loss: 3.4118 - accuracy: 0.12 - ETA: 4:40 - loss: 3.4125 - accuracy: 0.12 - ETA: 4:39 - loss: 3.4103 - accuracy: 0.12 - ETA: 4:38 - loss: 3.4094 - accuracy: 0.12 - ETA: 4:36 - loss: 3.4044 - accuracy: 0.12 - ETA: 4:35 - loss: 3.4049 - accuracy: 0.12 - ETA: 4:34 - loss: 3.4026 - accuracy: 0.12 - ETA: 4:33 - loss: 3.4040 - accuracy: 0.12 - ETA: 4:32 - loss: 3.4037 - accuracy: 0.12 - ETA: 4:31 - loss: 3.4022 - accuracy: 0.12 - ETA: 4:30 - loss: 3.4012 - accuracy: 0.12 - ETA: 4:29 - loss: 3.4019 - accuracy: 0.12 - ETA: 4:27 - loss: 3.4057 - accuracy: 0.12 - ETA: 4:26 - loss: 3.4078 - accuracy: 0.12 - ETA: 4:25 - loss: 3.4094 - accuracy: 0.12 - ETA: 4:25 - loss: 3.4080 - accuracy: 0.12 - ETA: 4:24 - loss: 3.4087 - accuracy: 0.12 - ETA: 4:23 - loss: 3.4098 - accuracy: 0.12 - ETA: 4:22 - loss: 3.4094 - accuracy: 0.12 - ETA: 4:21 - loss: 3.4090 - accuracy: 0.12 - ETA: 4:20 - loss: 3.4049 - accuracy: 0.12 - ETA: 4:19 - loss: 3.4054 - accuracy: 0.12 - ETA: 4:18 - loss: 3.4023 - accuracy: 0.12 - ETA: 4:17 - loss: 3.4029 - accuracy: 0.12 - ETA: 4:17 - loss: 3.4021 - accuracy: 0.12 - ETA: 4:16 - loss: 3.4023 - accuracy: 0.12 - ETA: 4:15 - loss: 3.4011 - accuracy: 0.12 - ETA: 4:13 - loss: 3.4021 - accuracy: 0.12 - ETA: 4:13 - loss: 3.4001 - accuracy: 0.12 - ETA: 4:12 - loss: 3.3983 - accuracy: 0.12 - ETA: 4:11 - loss: 3.3986 - accuracy: 0.12 - ETA: 4:10 - loss: 3.3979 - accuracy: 0.12 - ETA: 4:09 - loss: 3.3989 - accuracy: 0.12 - ETA: 4:09 - loss: 3.4014 - accuracy: 0.12 - ETA: 4:08 - loss: 3.4015 - accuracy: 0.12 - ETA: 4:07 - loss: 3.4007 - accuracy: 0.12 - ETA: 4:06 - loss: 3.3999 - accuracy: 0.12 - ETA: 4:05 - loss: 3.4009 - accuracy: 0.12 - ETA: 4:04 - loss: 3.3975 - accuracy: 0.12 - ETA: 4:03 - loss: 3.3970 - accuracy: 0.12 - ETA: 4:02 - loss: 3.3975 - accuracy: 0.12 - ETA: 4:01 - loss: 3.3964 - accuracy: 0.12 - ETA: 4:00 - loss: 3.3978 - accuracy: 0.12 - ETA: 3:59 - loss: 3.3956 - accuracy: 0.12 - ETA: 3:58 - loss: 3.3956 - accuracy: 0.12 - ETA: 3:57 - loss: 3.3951 - accuracy: 0.12 - ETA: 3:56 - loss: 3.3951 - accuracy: 0.12 - ETA: 3:56 - loss: 3.3938 - accuracy: 0.12 - ETA: 3:55 - loss: 3.3918 - accuracy: 0.12 - ETA: 3:54 - loss: 3.3931 - accuracy: 0.12 - ETA: 3:53 - loss: 3.3915 - accuracy: 0.12 - ETA: 3:52 - loss: 3.3901 - accuracy: 0.12 - ETA: 3:51 - loss: 3.3897 - accuracy: 0.12 - ETA: 3:50 - loss: 3.3895 - accuracy: 0.12 - ETA: 3:49 - loss: 3.3879 - accuracy: 0.12 - ETA: 3:48 - loss: 3.3873 - accuracy: 0.12 - ETA: 3:47 - loss: 3.3863 - accuracy: 0.12 - ETA: 3:46 - loss: 3.3862 - accuracy: 0.12 - ETA: 3:46 - loss: 3.3857 - accuracy: 0.12 - ETA: 3:45 - loss: 3.3837 - accuracy: 0.12 - ETA: 3:44 - loss: 3.3853 - accuracy: 0.12 - ETA: 3:42 - loss: 3.3827 - accuracy: 0.12 - ETA: 3:42 - loss: 3.3820 - accuracy: 0.12 - ETA: 3:41 - loss: 3.3823 - accuracy: 0.12 - ETA: 3:40 - loss: 3.3825 - accuracy: 0.12 - ETA: 3:39 - loss: 3.3832 - accuracy: 0.12 - ETA: 3:39 - loss: 3.3838 - accuracy: 0.12 - ETA: 3:38 - loss: 3.3820 - accuracy: 0.12 - ETA: 3:37 - loss: 3.3824 - accuracy: 0.12 - ETA: 3:36 - loss: 3.3810 - accuracy: 0.12 - ETA: 3:35 - loss: 3.3821 - accuracy: 0.12 - ETA: 3:34 - loss: 3.3822 - accuracy: 0.12 - ETA: 3:33 - loss: 3.3811 - accuracy: 0.12 - ETA: 3:32 - loss: 3.3829 - accuracy: 0.12 - ETA: 3:31 - loss: 3.3828 - accuracy: 0.12 - ETA: 3:30 - loss: 3.3816 - accuracy: 0.12 - ETA: 3:29 - loss: 3.3799 - accuracy: 0.12 - ETA: 3:28 - loss: 3.3788 - accuracy: 0.12 - ETA: 3:27 - loss: 3.3784 - accuracy: 0.12 - ETA: 3:26 - loss: 3.3789 - accuracy: 0.12 - ETA: 3:25 - loss: 3.3791 - accuracy: 0.12 - ETA: 3:24 - loss: 3.3781 - accuracy: 0.12 - ETA: 3:23 - loss: 3.3782 - accuracy: 0.12 - ETA: 3:22 - loss: 3.3771 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3758 - accuracy: 0.13 - ETA: 3:20 - loss: 3.3745 - accuracy: 0.13 - ETA: 3:19 - loss: 3.3755 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3742 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3724 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3730 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3729 - accuracy: 0.13 - ETA: 3:14 - loss: 3.3722 - accuracy: 0.13 - ETA: 3:13 - loss: 3.3733 - accuracy: 0.13 - ETA: 3:12 - loss: 3.3739 - accuracy: 0.13 - ETA: 3:11 - loss: 3.3735 - accuracy: 0.13 - ETA: 3:10 - loss: 3.3725 - accuracy: 0.13 - ETA: 3:09 - loss: 3.3735 - accuracy: 0.13 - ETA: 3:08 - loss: 3.3727 - accuracy: 0.13 - ETA: 3:07 - loss: 3.3720 - accuracy: 0.13 - ETA: 3:07 - loss: 3.3722 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3731 - accuracy: 0.13 - ETA: 3:05 - loss: 3.3733 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3728 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3716 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3718 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3701 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3695 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3702 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3714 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3721 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3719 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3716 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3715 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3706 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3699 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3698 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3696 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3689 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3678 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3689 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3675 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3675 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3666 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3660 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3653 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3654 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3650 - accuracy: 0.13 - ETA: 2:40 - loss: 3.3649 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3651 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3640 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3629 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3624 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3615 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3605 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3601 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3598 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3606 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3603 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3613 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3622 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3616 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3612 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3611 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3612 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3611 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3606 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3600 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3606 - accuracy: 0.13 - ETA: 2:21 - loss: 3.3602 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3588 - accuracy: 0.13 - ETA: 2:19 - loss: 3.3571 - accuracy: 0.13 - ETA: 2:18 - loss: 3.3567 - accuracy: 0.1337"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3564 - accuracy: 0.13 - ETA: 2:16 - loss: 3.3564 - accuracy: 0.13 - ETA: 2:15 - loss: 3.3555 - accuracy: 0.13 - ETA: 2:14 - loss: 3.3549 - accuracy: 0.13 - ETA: 2:13 - loss: 3.3543 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3533 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3536 - accuracy: 0.13 - ETA: 2:10 - loss: 3.3534 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3528 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3521 - accuracy: 0.13 - ETA: 2:07 - loss: 3.3512 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3504 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3507 - accuracy: 0.13 - ETA: 2:04 - loss: 3.3506 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3504 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3498 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3506 - accuracy: 0.13 - ETA: 2:01 - loss: 3.3516 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3534 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3548 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3556 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3566 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3577 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3588 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3598 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3592 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3594 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3593 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3596 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3598 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3607 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3608 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3609 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3611 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3617 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3619 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3619 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3628 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3627 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3627 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3633 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3633 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3634 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3624 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3622 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3619 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3622 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3617 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3619 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3624 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3623 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3629 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3624 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3627 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3631 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3634 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3638 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3634 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3642 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3641 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3636 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3634 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3629 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3627 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3628 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3631 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3632 - accuracy: 0.13 - ETA: 1:13 - loss: 3.3635 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3635 - accuracy: 0.13 - ETA: 1:11 - loss: 3.3633 - accuracy: 0.13 - ETA: 1:10 - loss: 3.3633 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3638 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3635 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3632 - accuracy: 0.13 - ETA: 1:06 - loss: 3.3631 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3637 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3633 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3641 - accuracy: 0.13 - ETA: 1:03 - loss: 3.3643 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3645 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3646 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3649 - accuracy: 0.13 - ETA: 59s - loss: 3.3651 - accuracy: 0.1321 - ETA: 58s - loss: 3.3652 - accuracy: 0.132 - ETA: 57s - loss: 3.3655 - accuracy: 0.132 - ETA: 56s - loss: 3.3657 - accuracy: 0.132 - ETA: 55s - loss: 3.3654 - accuracy: 0.132 - ETA: 54s - loss: 3.3649 - accuracy: 0.132 - ETA: 53s - loss: 3.3648 - accuracy: 0.132 - ETA: 52s - loss: 3.3647 - accuracy: 0.132 - ETA: 51s - loss: 3.3646 - accuracy: 0.132 - ETA: 50s - loss: 3.3645 - accuracy: 0.132 - ETA: 49s - loss: 3.3645 - accuracy: 0.133 - ETA: 48s - loss: 3.3643 - accuracy: 0.132 - ETA: 47s - loss: 3.3642 - accuracy: 0.132 - ETA: 46s - loss: 3.3641 - accuracy: 0.132 - ETA: 45s - loss: 3.3643 - accuracy: 0.133 - ETA: 44s - loss: 3.3645 - accuracy: 0.132 - ETA: 43s - loss: 3.3642 - accuracy: 0.132 - ETA: 43s - loss: 3.3642 - accuracy: 0.132 - ETA: 42s - loss: 3.3647 - accuracy: 0.132 - ETA: 41s - loss: 3.3644 - accuracy: 0.132 - ETA: 40s - loss: 3.3648 - accuracy: 0.132 - ETA: 39s - loss: 3.3648 - accuracy: 0.132 - ETA: 38s - loss: 3.3650 - accuracy: 0.132 - ETA: 37s - loss: 3.3648 - accuracy: 0.132 - ETA: 36s - loss: 3.3651 - accuracy: 0.132 - ETA: 35s - loss: 3.3656 - accuracy: 0.132 - ETA: 34s - loss: 3.3657 - accuracy: 0.132 - ETA: 33s - loss: 3.3655 - accuracy: 0.132 - ETA: 32s - loss: 3.3646 - accuracy: 0.132 - ETA: 31s - loss: 3.3645 - accuracy: 0.132 - ETA: 30s - loss: 3.3651 - accuracy: 0.132 - ETA: 29s - loss: 3.3651 - accuracy: 0.132 - ETA: 28s - loss: 3.3647 - accuracy: 0.132 - ETA: 27s - loss: 3.3645 - accuracy: 0.132 - ETA: 26s - loss: 3.3642 - accuracy: 0.132 - ETA: 25s - loss: 3.3641 - accuracy: 0.132 - ETA: 24s - loss: 3.3645 - accuracy: 0.132 - ETA: 23s - loss: 3.3641 - accuracy: 0.132 - ETA: 23s - loss: 3.3636 - accuracy: 0.132 - ETA: 22s - loss: 3.3636 - accuracy: 0.132 - ETA: 21s - loss: 3.3630 - accuracy: 0.132 - ETA: 20s - loss: 3.3628 - accuracy: 0.132 - ETA: 19s - loss: 3.3630 - accuracy: 0.132 - ETA: 18s - loss: 3.3627 - accuracy: 0.132 - ETA: 17s - loss: 3.3626 - accuracy: 0.132 - ETA: 16s - loss: 3.3624 - accuracy: 0.133 - ETA: 15s - loss: 3.3624 - accuracy: 0.132 - ETA: 14s - loss: 3.3625 - accuracy: 0.132 - ETA: 13s - loss: 3.3619 - accuracy: 0.132 - ETA: 12s - loss: 3.3620 - accuracy: 0.132 - ETA: 11s - loss: 3.3621 - accuracy: 0.132 - ETA: 10s - loss: 3.3613 - accuracy: 0.132 - ETA: 9s - loss: 3.3616 - accuracy: 0.132 - ETA: 8s - loss: 3.3612 - accuracy: 0.13 - ETA: 7s - loss: 3.3611 - accuracy: 0.13 - ETA: 6s - loss: 3.3607 - accuracy: 0.13 - ETA: 5s - loss: 3.3609 - accuracy: 0.13 - ETA: 4s - loss: 3.3611 - accuracy: 0.13 - ETA: 3s - loss: 3.3614 - accuracy: 0.13 - ETA: 2s - loss: 3.3610 - accuracy: 0.13 - ETA: 1s - loss: 3.3610 - accuracy: 0.13 - ETA: 1s - loss: 3.3606 - accuracy: 0.13 - ETA: 0s - loss: 3.3603 - accuracy: 0.13 - 340s 8ms/step - loss: 3.3603 - accuracy: 0.1325 - val_loss: 3.9579 - val_accuracy: 0.0114\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:22 - loss: 3.3255 - accuracy: 0.12 - ETA: 5:23 - loss: 3.2895 - accuracy: 0.12 - ETA: 4:57 - loss: 3.2946 - accuracy: 0.12 - ETA: 4:53 - loss: 3.2901 - accuracy: 0.14 - ETA: 4:55 - loss: 3.3344 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3597 - accuracy: 0.12 - ETA: 4:53 - loss: 3.3456 - accuracy: 0.13 - ETA: 4:50 - loss: 3.3412 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3477 - accuracy: 0.13 - ETA: 4:53 - loss: 3.3301 - accuracy: 0.13 - ETA: 4:54 - loss: 3.3373 - accuracy: 0.13 - ETA: 4:56 - loss: 3.3525 - accuracy: 0.13 - ETA: 4:56 - loss: 3.3591 - accuracy: 0.12 - ETA: 4:55 - loss: 3.3658 - accuracy: 0.12 - ETA: 4:55 - loss: 3.3624 - accuracy: 0.12 - ETA: 4:55 - loss: 3.3633 - accuracy: 0.12 - ETA: 4:55 - loss: 3.3612 - accuracy: 0.13 - ETA: 4:56 - loss: 3.3651 - accuracy: 0.13 - ETA: 4:56 - loss: 3.3567 - accuracy: 0.13 - ETA: 4:55 - loss: 3.3576 - accuracy: 0.13 - ETA: 4:54 - loss: 3.3430 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3402 - accuracy: 0.13 - ETA: 4:51 - loss: 3.3345 - accuracy: 0.13 - ETA: 4:50 - loss: 3.3372 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3438 - accuracy: 0.13 - ETA: 4:48 - loss: 3.3463 - accuracy: 0.13 - ETA: 4:47 - loss: 3.3361 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3328 - accuracy: 0.13 - ETA: 4:45 - loss: 3.3282 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3288 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3291 - accuracy: 0.13 - ETA: 4:43 - loss: 3.3306 - accuracy: 0.13 - ETA: 4:42 - loss: 3.3335 - accuracy: 0.13 - ETA: 4:42 - loss: 3.3364 - accuracy: 0.13 - ETA: 4:41 - loss: 3.3418 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3427 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3382 - accuracy: 0.13 - ETA: 4:38 - loss: 3.3370 - accuracy: 0.13 - ETA: 4:37 - loss: 3.3350 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3318 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3311 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3312 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3230 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3226 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3236 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3237 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3216 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3203 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3196 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3212 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3193 - accuracy: 0.14 - ETA: 4:25 - loss: 3.3271 - accuracy: 0.14 - ETA: 4:24 - loss: 3.3244 - accuracy: 0.14 - ETA: 4:23 - loss: 3.3258 - accuracy: 0.14 - ETA: 4:22 - loss: 3.3227 - accuracy: 0.14 - ETA: 4:21 - loss: 3.3264 - accuracy: 0.14 - ETA: 4:20 - loss: 3.3258 - accuracy: 0.14 - ETA: 4:19 - loss: 3.3263 - accuracy: 0.14 - ETA: 4:18 - loss: 3.3267 - accuracy: 0.14 - ETA: 4:17 - loss: 3.3267 - accuracy: 0.14 - ETA: 4:16 - loss: 3.3252 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3272 - accuracy: 0.14 - ETA: 4:15 - loss: 3.3274 - accuracy: 0.14 - ETA: 4:14 - loss: 3.3268 - accuracy: 0.14 - ETA: 4:13 - loss: 3.3262 - accuracy: 0.14 - ETA: 4:12 - loss: 3.3267 - accuracy: 0.14 - ETA: 4:11 - loss: 3.3273 - accuracy: 0.14 - ETA: 4:10 - loss: 3.3266 - accuracy: 0.14 - ETA: 4:09 - loss: 3.3239 - accuracy: 0.14 - ETA: 4:08 - loss: 3.3239 - accuracy: 0.14 - ETA: 4:07 - loss: 3.3262 - accuracy: 0.14 - ETA: 4:06 - loss: 3.3272 - accuracy: 0.14 - ETA: 4:05 - loss: 3.3263 - accuracy: 0.14 - ETA: 4:04 - loss: 3.3254 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3262 - accuracy: 0.14 - ETA: 4:03 - loss: 3.3236 - accuracy: 0.14 - ETA: 4:02 - loss: 3.3222 - accuracy: 0.14 - ETA: 4:01 - loss: 3.3265 - accuracy: 0.14 - ETA: 4:00 - loss: 3.3245 - accuracy: 0.14 - ETA: 3:59 - loss: 3.3266 - accuracy: 0.14 - ETA: 3:58 - loss: 3.3270 - accuracy: 0.14 - ETA: 3:57 - loss: 3.3287 - accuracy: 0.14 - ETA: 3:56 - loss: 3.3288 - accuracy: 0.14 - ETA: 3:55 - loss: 3.3301 - accuracy: 0.14 - ETA: 3:54 - loss: 3.3302 - accuracy: 0.14 - ETA: 3:53 - loss: 3.3302 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3311 - accuracy: 0.14 - ETA: 3:52 - loss: 3.3294 - accuracy: 0.14 - ETA: 3:51 - loss: 3.3308 - accuracy: 0.14 - ETA: 3:49 - loss: 3.3305 - accuracy: 0.14 - ETA: 3:48 - loss: 3.3311 - accuracy: 0.14 - ETA: 3:47 - loss: 3.3326 - accuracy: 0.14 - ETA: 3:46 - loss: 3.3333 - accuracy: 0.14 - ETA: 3:45 - loss: 3.3339 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3354 - accuracy: 0.14 - ETA: 3:44 - loss: 3.3353 - accuracy: 0.14 - ETA: 3:43 - loss: 3.3363 - accuracy: 0.13 - ETA: 3:42 - loss: 3.3351 - accuracy: 0.14 - ETA: 3:41 - loss: 3.3363 - accuracy: 0.13 - ETA: 3:40 - loss: 3.3364 - accuracy: 0.13 - ETA: 3:39 - loss: 3.3361 - accuracy: 0.13 - ETA: 3:38 - loss: 3.3367 - accuracy: 0.13 - ETA: 3:37 - loss: 3.3356 - accuracy: 0.13 - ETA: 3:36 - loss: 3.3360 - accuracy: 0.13 - ETA: 3:35 - loss: 3.3354 - accuracy: 0.13 - ETA: 3:34 - loss: 3.3366 - accuracy: 0.13 - ETA: 3:33 - loss: 3.3370 - accuracy: 0.13 - ETA: 3:32 - loss: 3.3369 - accuracy: 0.13 - ETA: 3:31 - loss: 3.3369 - accuracy: 0.13 - ETA: 3:30 - loss: 3.3369 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3370 - accuracy: 0.13 - ETA: 3:28 - loss: 3.3363 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3372 - accuracy: 0.13 - ETA: 3:26 - loss: 3.3376 - accuracy: 0.13 - ETA: 3:25 - loss: 3.3382 - accuracy: 0.13 - ETA: 3:24 - loss: 3.3389 - accuracy: 0.13 - ETA: 3:23 - loss: 3.3383 - accuracy: 0.13 - ETA: 3:22 - loss: 3.3380 - accuracy: 0.13 - ETA: 3:22 - loss: 3.3368 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3373 - accuracy: 0.13 - ETA: 3:20 - loss: 3.3367 - accuracy: 0.13 - ETA: 3:19 - loss: 3.3358 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3360 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3373 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3371 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3368 - accuracy: 0.13 - ETA: 3:14 - loss: 3.3358 - accuracy: 0.13 - ETA: 3:13 - loss: 3.3362 - accuracy: 0.13 - ETA: 3:12 - loss: 3.3367 - accuracy: 0.13 - ETA: 3:11 - loss: 3.3371 - accuracy: 0.13 - ETA: 3:10 - loss: 3.3372 - accuracy: 0.13 - ETA: 3:09 - loss: 3.3360 - accuracy: 0.13 - ETA: 3:08 - loss: 3.3359 - accuracy: 0.13 - ETA: 3:07 - loss: 3.3357 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3346 - accuracy: 0.13 - ETA: 3:05 - loss: 3.3342 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3347 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3352 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3355 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3353 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3355 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3352 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3357 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3360 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3363 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3361 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3370 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3367 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3376 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3389 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3377 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3378 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3378 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3375 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3377 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3380 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3379 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3382 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3381 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3373 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3377 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3373 - accuracy: 0.13 - ETA: 2:40 - loss: 3.3372 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3374 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3380 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3389 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3395 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3400 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3402 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3397 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3406 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3408 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3413 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3409 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3404 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3399 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3416 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3416 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3414 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3400 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3391 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3389 - accuracy: 0.13 - ETA: 2:21 - loss: 3.3387 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3389 - accuracy: 0.13 - ETA: 2:19 - loss: 3.3388 - accuracy: 0.13 - ETA: 2:18 - loss: 3.3390 - accuracy: 0.1379"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3394 - accuracy: 0.13 - ETA: 2:16 - loss: 3.3400 - accuracy: 0.13 - ETA: 2:15 - loss: 3.3404 - accuracy: 0.13 - ETA: 2:14 - loss: 3.3404 - accuracy: 0.13 - ETA: 2:13 - loss: 3.3402 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3396 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3390 - accuracy: 0.13 - ETA: 2:10 - loss: 3.3388 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3387 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3387 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3391 - accuracy: 0.13 - ETA: 2:07 - loss: 3.3393 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3392 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3396 - accuracy: 0.13 - ETA: 2:04 - loss: 3.3390 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3386 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3372 - accuracy: 0.13 - ETA: 2:01 - loss: 3.3381 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3383 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3373 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3366 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3359 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3351 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3350 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3353 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3349 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3349 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3346 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3348 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3354 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3364 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3367 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3371 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3372 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3377 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3380 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3384 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3389 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3395 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3397 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3397 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3402 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3403 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3404 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3403 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3405 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3408 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3411 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3410 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3417 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3423 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3427 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3436 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3440 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3442 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3458 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3456 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3459 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3464 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3469 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3471 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3469 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3471 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3476 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3470 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3478 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3479 - accuracy: 0.13 - ETA: 1:13 - loss: 3.3486 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3487 - accuracy: 0.13 - ETA: 1:11 - loss: 3.3487 - accuracy: 0.13 - ETA: 1:10 - loss: 3.3485 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3492 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3497 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3506 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3505 - accuracy: 0.13 - ETA: 1:06 - loss: 3.3515 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3523 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3531 - accuracy: 0.13 - ETA: 1:03 - loss: 3.3531 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3530 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3531 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3538 - accuracy: 0.13 - ETA: 59s - loss: 3.3538 - accuracy: 0.1357 - ETA: 58s - loss: 3.3544 - accuracy: 0.135 - ETA: 57s - loss: 3.3556 - accuracy: 0.135 - ETA: 56s - loss: 3.3563 - accuracy: 0.135 - ETA: 55s - loss: 3.3571 - accuracy: 0.134 - ETA: 54s - loss: 3.3574 - accuracy: 0.134 - ETA: 53s - loss: 3.3576 - accuracy: 0.134 - ETA: 52s - loss: 3.3578 - accuracy: 0.134 - ETA: 51s - loss: 3.3582 - accuracy: 0.134 - ETA: 50s - loss: 3.3591 - accuracy: 0.134 - ETA: 49s - loss: 3.3593 - accuracy: 0.134 - ETA: 48s - loss: 3.3594 - accuracy: 0.134 - ETA: 47s - loss: 3.3599 - accuracy: 0.134 - ETA: 46s - loss: 3.3598 - accuracy: 0.134 - ETA: 45s - loss: 3.3603 - accuracy: 0.134 - ETA: 44s - loss: 3.3602 - accuracy: 0.134 - ETA: 44s - loss: 3.3599 - accuracy: 0.134 - ETA: 43s - loss: 3.3603 - accuracy: 0.134 - ETA: 42s - loss: 3.3609 - accuracy: 0.134 - ETA: 41s - loss: 3.3612 - accuracy: 0.134 - ETA: 40s - loss: 3.3615 - accuracy: 0.134 - ETA: 39s - loss: 3.3617 - accuracy: 0.134 - ETA: 38s - loss: 3.3619 - accuracy: 0.134 - ETA: 37s - loss: 3.3618 - accuracy: 0.134 - ETA: 36s - loss: 3.3620 - accuracy: 0.134 - ETA: 35s - loss: 3.3621 - accuracy: 0.134 - ETA: 34s - loss: 3.3622 - accuracy: 0.134 - ETA: 33s - loss: 3.3617 - accuracy: 0.134 - ETA: 32s - loss: 3.3618 - accuracy: 0.134 - ETA: 31s - loss: 3.3620 - accuracy: 0.134 - ETA: 30s - loss: 3.3622 - accuracy: 0.133 - ETA: 29s - loss: 3.3621 - accuracy: 0.134 - ETA: 28s - loss: 3.3621 - accuracy: 0.134 - ETA: 27s - loss: 3.3623 - accuracy: 0.133 - ETA: 26s - loss: 3.3624 - accuracy: 0.133 - ETA: 25s - loss: 3.3625 - accuracy: 0.133 - ETA: 24s - loss: 3.3624 - accuracy: 0.133 - ETA: 23s - loss: 3.3620 - accuracy: 0.134 - ETA: 23s - loss: 3.3624 - accuracy: 0.133 - ETA: 22s - loss: 3.3629 - accuracy: 0.133 - ETA: 21s - loss: 3.3628 - accuracy: 0.133 - ETA: 20s - loss: 3.3625 - accuracy: 0.133 - ETA: 19s - loss: 3.3621 - accuracy: 0.133 - ETA: 18s - loss: 3.3622 - accuracy: 0.134 - ETA: 17s - loss: 3.3618 - accuracy: 0.134 - ETA: 16s - loss: 3.3617 - accuracy: 0.134 - ETA: 15s - loss: 3.3621 - accuracy: 0.134 - ETA: 14s - loss: 3.3626 - accuracy: 0.133 - ETA: 13s - loss: 3.3630 - accuracy: 0.133 - ETA: 12s - loss: 3.3636 - accuracy: 0.133 - ETA: 11s - loss: 3.3639 - accuracy: 0.133 - ETA: 10s - loss: 3.3637 - accuracy: 0.133 - ETA: 9s - loss: 3.3644 - accuracy: 0.133 - ETA: 8s - loss: 3.3645 - accuracy: 0.13 - ETA: 7s - loss: 3.3651 - accuracy: 0.13 - ETA: 6s - loss: 3.3655 - accuracy: 0.13 - ETA: 5s - loss: 3.3658 - accuracy: 0.13 - ETA: 4s - loss: 3.3661 - accuracy: 0.13 - ETA: 3s - loss: 3.3663 - accuracy: 0.13 - ETA: 2s - loss: 3.3665 - accuracy: 0.13 - ETA: 1s - loss: 3.3667 - accuracy: 0.13 - ETA: 1s - loss: 3.3668 - accuracy: 0.13 - ETA: 0s - loss: 3.3668 - accuracy: 0.13 - 341s 8ms/step - loss: 3.3667 - accuracy: 0.1331 - val_loss: 3.9974 - val_accuracy: 0.0139\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:03 - loss: 3.4594 - accuracy: 0.16 - ETA: 5:16 - loss: 3.4365 - accuracy: 0.13 - ETA: 5:23 - loss: 3.4012 - accuracy: 0.13 - ETA: 5:25 - loss: 3.4056 - accuracy: 0.13 - ETA: 5:20 - loss: 3.4169 - accuracy: 0.13 - ETA: 5:18 - loss: 3.3957 - accuracy: 0.13 - ETA: 5:17 - loss: 3.4107 - accuracy: 0.13 - ETA: 5:16 - loss: 3.4088 - accuracy: 0.13 - ETA: 5:13 - loss: 3.4041 - accuracy: 0.13 - ETA: 5:11 - loss: 3.4021 - accuracy: 0.12 - ETA: 5:07 - loss: 3.4045 - accuracy: 0.12 - ETA: 5:07 - loss: 3.3952 - accuracy: 0.12 - ETA: 5:04 - loss: 3.3850 - accuracy: 0.12 - ETA: 5:03 - loss: 3.3909 - accuracy: 0.13 - ETA: 5:03 - loss: 3.3962 - accuracy: 0.12 - ETA: 5:01 - loss: 3.3990 - accuracy: 0.12 - ETA: 4:59 - loss: 3.4003 - accuracy: 0.12 - ETA: 4:57 - loss: 3.3935 - accuracy: 0.12 - ETA: 4:57 - loss: 3.3807 - accuracy: 0.13 - ETA: 4:56 - loss: 3.3811 - accuracy: 0.13 - ETA: 4:56 - loss: 3.3857 - accuracy: 0.12 - ETA: 4:55 - loss: 3.3914 - accuracy: 0.13 - ETA: 4:54 - loss: 3.3960 - accuracy: 0.13 - ETA: 4:53 - loss: 3.3939 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3933 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3941 - accuracy: 0.13 - ETA: 4:51 - loss: 3.3982 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3945 - accuracy: 0.12 - ETA: 4:49 - loss: 3.3969 - accuracy: 0.12 - ETA: 4:47 - loss: 3.4013 - accuracy: 0.12 - ETA: 4:45 - loss: 3.3970 - accuracy: 0.12 - ETA: 4:44 - loss: 3.3992 - accuracy: 0.12 - ETA: 4:43 - loss: 3.4002 - accuracy: 0.12 - ETA: 4:42 - loss: 3.4040 - accuracy: 0.12 - ETA: 4:41 - loss: 3.4052 - accuracy: 0.12 - ETA: 4:40 - loss: 3.4023 - accuracy: 0.12 - ETA: 4:39 - loss: 3.3989 - accuracy: 0.12 - ETA: 4:38 - loss: 3.3998 - accuracy: 0.12 - ETA: 4:36 - loss: 3.3973 - accuracy: 0.12 - ETA: 4:35 - loss: 3.3998 - accuracy: 0.12 - ETA: 4:35 - loss: 3.3956 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3951 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3943 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3937 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3903 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3894 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3853 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3864 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3849 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3881 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3917 - accuracy: 0.13 - ETA: 4:25 - loss: 3.4027 - accuracy: 0.13 - ETA: 4:24 - loss: 3.4152 - accuracy: 0.13 - ETA: 4:23 - loss: 3.4208 - accuracy: 0.13 - ETA: 4:22 - loss: 3.4283 - accuracy: 0.13 - ETA: 4:21 - loss: 3.4335 - accuracy: 0.13 - ETA: 4:20 - loss: 3.4382 - accuracy: 0.13 - ETA: 4:19 - loss: 3.4393 - accuracy: 0.13 - ETA: 4:18 - loss: 3.4385 - accuracy: 0.13 - ETA: 4:17 - loss: 3.4379 - accuracy: 0.13 - ETA: 4:16 - loss: 3.4415 - accuracy: 0.13 - ETA: 4:15 - loss: 3.4417 - accuracy: 0.13 - ETA: 4:15 - loss: 3.4448 - accuracy: 0.12 - ETA: 4:14 - loss: 3.4463 - accuracy: 0.12 - ETA: 4:13 - loss: 3.4504 - accuracy: 0.12 - ETA: 4:12 - loss: 3.4514 - accuracy: 0.12 - ETA: 4:11 - loss: 3.4513 - accuracy: 0.12 - ETA: 4:10 - loss: 3.4524 - accuracy: 0.12 - ETA: 4:09 - loss: 3.4543 - accuracy: 0.12 - ETA: 4:08 - loss: 3.4544 - accuracy: 0.12 - ETA: 4:07 - loss: 3.4552 - accuracy: 0.12 - ETA: 4:06 - loss: 3.4547 - accuracy: 0.12 - ETA: 4:05 - loss: 3.4559 - accuracy: 0.12 - ETA: 4:04 - loss: 3.4548 - accuracy: 0.12 - ETA: 4:04 - loss: 3.4550 - accuracy: 0.12 - ETA: 4:03 - loss: 3.4562 - accuracy: 0.12 - ETA: 4:02 - loss: 3.4567 - accuracy: 0.12 - ETA: 4:01 - loss: 3.4586 - accuracy: 0.12 - ETA: 4:00 - loss: 3.4582 - accuracy: 0.12 - ETA: 3:59 - loss: 3.4588 - accuracy: 0.12 - ETA: 3:58 - loss: 3.4616 - accuracy: 0.12 - ETA: 3:57 - loss: 3.4611 - accuracy: 0.12 - ETA: 3:56 - loss: 3.4622 - accuracy: 0.12 - ETA: 3:55 - loss: 3.4595 - accuracy: 0.12 - ETA: 3:54 - loss: 3.4590 - accuracy: 0.12 - ETA: 3:53 - loss: 3.4577 - accuracy: 0.12 - ETA: 3:52 - loss: 3.4572 - accuracy: 0.12 - ETA: 3:51 - loss: 3.4559 - accuracy: 0.12 - ETA: 3:50 - loss: 3.4565 - accuracy: 0.12 - ETA: 3:49 - loss: 3.4556 - accuracy: 0.12 - ETA: 3:48 - loss: 3.4544 - accuracy: 0.12 - ETA: 3:47 - loss: 3.4540 - accuracy: 0.12 - ETA: 3:46 - loss: 3.4534 - accuracy: 0.12 - ETA: 3:45 - loss: 3.4546 - accuracy: 0.12 - ETA: 3:44 - loss: 3.4555 - accuracy: 0.12 - ETA: 3:43 - loss: 3.4549 - accuracy: 0.12 - ETA: 3:42 - loss: 3.4544 - accuracy: 0.12 - ETA: 3:41 - loss: 3.4542 - accuracy: 0.12 - ETA: 3:40 - loss: 3.4554 - accuracy: 0.12 - ETA: 3:40 - loss: 3.4554 - accuracy: 0.12 - ETA: 3:38 - loss: 3.4542 - accuracy: 0.12 - ETA: 3:38 - loss: 3.4545 - accuracy: 0.12 - ETA: 3:36 - loss: 3.4537 - accuracy: 0.12 - ETA: 3:36 - loss: 3.4543 - accuracy: 0.12 - ETA: 3:34 - loss: 3.4551 - accuracy: 0.12 - ETA: 3:34 - loss: 3.4552 - accuracy: 0.12 - ETA: 3:33 - loss: 3.4545 - accuracy: 0.12 - ETA: 3:32 - loss: 3.4554 - accuracy: 0.12 - ETA: 3:31 - loss: 3.4573 - accuracy: 0.12 - ETA: 3:30 - loss: 3.4574 - accuracy: 0.12 - ETA: 3:29 - loss: 3.4585 - accuracy: 0.12 - ETA: 3:28 - loss: 3.4579 - accuracy: 0.12 - ETA: 3:27 - loss: 3.4581 - accuracy: 0.12 - ETA: 3:26 - loss: 3.4581 - accuracy: 0.12 - ETA: 3:25 - loss: 3.4568 - accuracy: 0.12 - ETA: 3:24 - loss: 3.4575 - accuracy: 0.12 - ETA: 3:24 - loss: 3.4575 - accuracy: 0.12 - ETA: 3:22 - loss: 3.4565 - accuracy: 0.12 - ETA: 3:22 - loss: 3.4559 - accuracy: 0.12 - ETA: 3:21 - loss: 3.4564 - accuracy: 0.12 - ETA: 3:20 - loss: 3.4555 - accuracy: 0.12 - ETA: 3:19 - loss: 3.4555 - accuracy: 0.12 - ETA: 3:18 - loss: 3.4561 - accuracy: 0.12 - ETA: 3:17 - loss: 3.4552 - accuracy: 0.12 - ETA: 3:16 - loss: 3.4557 - accuracy: 0.12 - ETA: 3:15 - loss: 3.4547 - accuracy: 0.12 - ETA: 3:14 - loss: 3.4540 - accuracy: 0.12 - ETA: 3:13 - loss: 3.4547 - accuracy: 0.12 - ETA: 3:12 - loss: 3.4537 - accuracy: 0.12 - ETA: 3:11 - loss: 3.4532 - accuracy: 0.12 - ETA: 3:11 - loss: 3.4530 - accuracy: 0.12 - ETA: 3:09 - loss: 3.4526 - accuracy: 0.12 - ETA: 3:09 - loss: 3.4526 - accuracy: 0.12 - ETA: 3:08 - loss: 3.4525 - accuracy: 0.12 - ETA: 3:06 - loss: 3.4527 - accuracy: 0.12 - ETA: 3:05 - loss: 3.4521 - accuracy: 0.12 - ETA: 3:04 - loss: 3.4525 - accuracy: 0.12 - ETA: 3:04 - loss: 3.4533 - accuracy: 0.12 - ETA: 3:03 - loss: 3.4529 - accuracy: 0.12 - ETA: 3:02 - loss: 3.4531 - accuracy: 0.12 - ETA: 3:01 - loss: 3.4529 - accuracy: 0.12 - ETA: 3:00 - loss: 3.4531 - accuracy: 0.12 - ETA: 2:59 - loss: 3.4524 - accuracy: 0.12 - ETA: 2:58 - loss: 3.4512 - accuracy: 0.12 - ETA: 2:57 - loss: 3.4507 - accuracy: 0.12 - ETA: 2:56 - loss: 3.4499 - accuracy: 0.12 - ETA: 2:55 - loss: 3.4492 - accuracy: 0.12 - ETA: 2:54 - loss: 3.4490 - accuracy: 0.12 - ETA: 2:53 - loss: 3.4485 - accuracy: 0.12 - ETA: 2:52 - loss: 3.4479 - accuracy: 0.12 - ETA: 2:51 - loss: 3.4459 - accuracy: 0.12 - ETA: 2:50 - loss: 3.4445 - accuracy: 0.12 - ETA: 2:49 - loss: 3.4449 - accuracy: 0.12 - ETA: 2:48 - loss: 3.4440 - accuracy: 0.12 - ETA: 2:47 - loss: 3.4443 - accuracy: 0.12 - ETA: 2:46 - loss: 3.4443 - accuracy: 0.12 - ETA: 2:45 - loss: 3.4439 - accuracy: 0.12 - ETA: 2:45 - loss: 3.4435 - accuracy: 0.12 - ETA: 2:44 - loss: 3.4432 - accuracy: 0.12 - ETA: 2:43 - loss: 3.4432 - accuracy: 0.12 - ETA: 2:42 - loss: 3.4441 - accuracy: 0.12 - ETA: 2:41 - loss: 3.4444 - accuracy: 0.12 - ETA: 2:40 - loss: 3.4435 - accuracy: 0.12 - ETA: 2:39 - loss: 3.4431 - accuracy: 0.12 - ETA: 2:38 - loss: 3.4428 - accuracy: 0.12 - ETA: 2:37 - loss: 3.4427 - accuracy: 0.12 - ETA: 2:36 - loss: 3.4425 - accuracy: 0.12 - ETA: 2:35 - loss: 3.4422 - accuracy: 0.12 - ETA: 2:34 - loss: 3.4418 - accuracy: 0.12 - ETA: 2:33 - loss: 3.4431 - accuracy: 0.12 - ETA: 2:32 - loss: 3.4434 - accuracy: 0.12 - ETA: 2:31 - loss: 3.4438 - accuracy: 0.12 - ETA: 2:30 - loss: 3.4434 - accuracy: 0.12 - ETA: 2:29 - loss: 3.4438 - accuracy: 0.12 - ETA: 2:29 - loss: 3.4444 - accuracy: 0.12 - ETA: 2:28 - loss: 3.4438 - accuracy: 0.12 - ETA: 2:27 - loss: 3.4434 - accuracy: 0.12 - ETA: 2:26 - loss: 3.4428 - accuracy: 0.12 - ETA: 2:25 - loss: 3.4432 - accuracy: 0.12 - ETA: 2:24 - loss: 3.4433 - accuracy: 0.12 - ETA: 2:23 - loss: 3.4424 - accuracy: 0.12 - ETA: 2:22 - loss: 3.4421 - accuracy: 0.12 - ETA: 2:21 - loss: 3.4424 - accuracy: 0.12 - ETA: 2:20 - loss: 3.4427 - accuracy: 0.12 - ETA: 2:19 - loss: 3.4424 - accuracy: 0.12 - ETA: 2:18 - loss: 3.4419 - accuracy: 0.1234"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.4422 - accuracy: 0.12 - ETA: 2:16 - loss: 3.4425 - accuracy: 0.12 - ETA: 2:15 - loss: 3.4417 - accuracy: 0.12 - ETA: 2:14 - loss: 3.4419 - accuracy: 0.12 - ETA: 2:13 - loss: 3.4416 - accuracy: 0.12 - ETA: 2:12 - loss: 3.4407 - accuracy: 0.12 - ETA: 2:11 - loss: 3.4409 - accuracy: 0.12 - ETA: 2:10 - loss: 3.4414 - accuracy: 0.12 - ETA: 2:09 - loss: 3.4411 - accuracy: 0.12 - ETA: 2:08 - loss: 3.4409 - accuracy: 0.12 - ETA: 2:07 - loss: 3.4407 - accuracy: 0.12 - ETA: 2:06 - loss: 3.4404 - accuracy: 0.12 - ETA: 2:06 - loss: 3.4399 - accuracy: 0.12 - ETA: 2:05 - loss: 3.4399 - accuracy: 0.12 - ETA: 2:04 - loss: 3.4386 - accuracy: 0.12 - ETA: 2:03 - loss: 3.4372 - accuracy: 0.12 - ETA: 2:02 - loss: 3.4392 - accuracy: 0.12 - ETA: 2:01 - loss: 3.4397 - accuracy: 0.12 - ETA: 2:00 - loss: 3.4389 - accuracy: 0.12 - ETA: 1:59 - loss: 3.4379 - accuracy: 0.12 - ETA: 1:58 - loss: 3.4372 - accuracy: 0.12 - ETA: 1:57 - loss: 3.4368 - accuracy: 0.12 - ETA: 1:56 - loss: 3.4372 - accuracy: 0.12 - ETA: 1:55 - loss: 3.4375 - accuracy: 0.12 - ETA: 1:54 - loss: 3.4370 - accuracy: 0.12 - ETA: 1:53 - loss: 3.4359 - accuracy: 0.12 - ETA: 1:52 - loss: 3.4354 - accuracy: 0.12 - ETA: 1:51 - loss: 3.4345 - accuracy: 0.12 - ETA: 1:50 - loss: 3.4347 - accuracy: 0.12 - ETA: 1:49 - loss: 3.4351 - accuracy: 0.12 - ETA: 1:48 - loss: 3.4351 - accuracy: 0.12 - ETA: 1:47 - loss: 3.4340 - accuracy: 0.12 - ETA: 1:46 - loss: 3.4335 - accuracy: 0.12 - ETA: 1:45 - loss: 3.4331 - accuracy: 0.12 - ETA: 1:44 - loss: 3.4330 - accuracy: 0.12 - ETA: 1:44 - loss: 3.4323 - accuracy: 0.12 - ETA: 1:43 - loss: 3.4324 - accuracy: 0.12 - ETA: 1:42 - loss: 3.4324 - accuracy: 0.12 - ETA: 1:41 - loss: 3.4324 - accuracy: 0.12 - ETA: 1:40 - loss: 3.4323 - accuracy: 0.12 - ETA: 1:39 - loss: 3.4324 - accuracy: 0.12 - ETA: 1:38 - loss: 3.4323 - accuracy: 0.12 - ETA: 1:37 - loss: 3.4325 - accuracy: 0.12 - ETA: 1:36 - loss: 3.4330 - accuracy: 0.12 - ETA: 1:35 - loss: 3.4329 - accuracy: 0.12 - ETA: 1:34 - loss: 3.4330 - accuracy: 0.12 - ETA: 1:33 - loss: 3.4331 - accuracy: 0.12 - ETA: 1:32 - loss: 3.4332 - accuracy: 0.12 - ETA: 1:31 - loss: 3.4332 - accuracy: 0.12 - ETA: 1:30 - loss: 3.4332 - accuracy: 0.12 - ETA: 1:29 - loss: 3.4327 - accuracy: 0.12 - ETA: 1:28 - loss: 3.4317 - accuracy: 0.12 - ETA: 1:27 - loss: 3.4316 - accuracy: 0.12 - ETA: 1:26 - loss: 3.4317 - accuracy: 0.12 - ETA: 1:25 - loss: 3.4314 - accuracy: 0.12 - ETA: 1:24 - loss: 3.4313 - accuracy: 0.12 - ETA: 1:24 - loss: 3.4317 - accuracy: 0.12 - ETA: 1:23 - loss: 3.4314 - accuracy: 0.12 - ETA: 1:22 - loss: 3.4319 - accuracy: 0.12 - ETA: 1:21 - loss: 3.4319 - accuracy: 0.12 - ETA: 1:20 - loss: 3.4313 - accuracy: 0.12 - ETA: 1:19 - loss: 3.4317 - accuracy: 0.12 - ETA: 1:18 - loss: 3.4314 - accuracy: 0.12 - ETA: 1:17 - loss: 3.4319 - accuracy: 0.12 - ETA: 1:16 - loss: 3.4325 - accuracy: 0.12 - ETA: 1:15 - loss: 3.4325 - accuracy: 0.12 - ETA: 1:14 - loss: 3.4329 - accuracy: 0.12 - ETA: 1:13 - loss: 3.4321 - accuracy: 0.12 - ETA: 1:12 - loss: 3.4323 - accuracy: 0.12 - ETA: 1:11 - loss: 3.4321 - accuracy: 0.12 - ETA: 1:10 - loss: 3.4326 - accuracy: 0.12 - ETA: 1:09 - loss: 3.4334 - accuracy: 0.12 - ETA: 1:08 - loss: 3.4343 - accuracy: 0.12 - ETA: 1:07 - loss: 3.4353 - accuracy: 0.12 - ETA: 1:06 - loss: 3.4359 - accuracy: 0.12 - ETA: 1:05 - loss: 3.4369 - accuracy: 0.12 - ETA: 1:04 - loss: 3.4382 - accuracy: 0.12 - ETA: 1:03 - loss: 3.4385 - accuracy: 0.12 - ETA: 1:03 - loss: 3.4392 - accuracy: 0.12 - ETA: 1:02 - loss: 3.4393 - accuracy: 0.12 - ETA: 1:01 - loss: 3.4397 - accuracy: 0.12 - ETA: 1:00 - loss: 3.4397 - accuracy: 0.12 - ETA: 59s - loss: 3.4397 - accuracy: 0.1224 - ETA: 58s - loss: 3.4396 - accuracy: 0.122 - ETA: 57s - loss: 3.4402 - accuracy: 0.122 - ETA: 56s - loss: 3.4401 - accuracy: 0.122 - ETA: 55s - loss: 3.4404 - accuracy: 0.122 - ETA: 54s - loss: 3.4404 - accuracy: 0.122 - ETA: 53s - loss: 3.4403 - accuracy: 0.122 - ETA: 52s - loss: 3.4402 - accuracy: 0.122 - ETA: 51s - loss: 3.4398 - accuracy: 0.122 - ETA: 50s - loss: 3.4401 - accuracy: 0.122 - ETA: 49s - loss: 3.4405 - accuracy: 0.122 - ETA: 48s - loss: 3.4402 - accuracy: 0.122 - ETA: 47s - loss: 3.4400 - accuracy: 0.122 - ETA: 46s - loss: 3.4402 - accuracy: 0.122 - ETA: 45s - loss: 3.4398 - accuracy: 0.122 - ETA: 44s - loss: 3.4389 - accuracy: 0.122 - ETA: 43s - loss: 3.4390 - accuracy: 0.122 - ETA: 42s - loss: 3.4389 - accuracy: 0.122 - ETA: 42s - loss: 3.4394 - accuracy: 0.122 - ETA: 41s - loss: 3.4393 - accuracy: 0.122 - ETA: 40s - loss: 3.4388 - accuracy: 0.122 - ETA: 39s - loss: 3.4380 - accuracy: 0.122 - ETA: 38s - loss: 3.4379 - accuracy: 0.122 - ETA: 37s - loss: 3.4378 - accuracy: 0.122 - ETA: 36s - loss: 3.4380 - accuracy: 0.121 - ETA: 35s - loss: 3.4377 - accuracy: 0.121 - ETA: 34s - loss: 3.4379 - accuracy: 0.121 - ETA: 33s - loss: 3.4374 - accuracy: 0.121 - ETA: 32s - loss: 3.4376 - accuracy: 0.121 - ETA: 31s - loss: 3.4371 - accuracy: 0.121 - ETA: 30s - loss: 3.4371 - accuracy: 0.121 - ETA: 29s - loss: 3.4368 - accuracy: 0.122 - ETA: 28s - loss: 3.4367 - accuracy: 0.121 - ETA: 27s - loss: 3.4367 - accuracy: 0.121 - ETA: 26s - loss: 3.4366 - accuracy: 0.121 - ETA: 25s - loss: 3.4358 - accuracy: 0.122 - ETA: 24s - loss: 3.4355 - accuracy: 0.122 - ETA: 23s - loss: 3.4355 - accuracy: 0.122 - ETA: 22s - loss: 3.4355 - accuracy: 0.122 - ETA: 21s - loss: 3.4353 - accuracy: 0.122 - ETA: 21s - loss: 3.4353 - accuracy: 0.122 - ETA: 20s - loss: 3.4354 - accuracy: 0.122 - ETA: 19s - loss: 3.4348 - accuracy: 0.122 - ETA: 18s - loss: 3.4346 - accuracy: 0.122 - ETA: 17s - loss: 3.4337 - accuracy: 0.122 - ETA: 16s - loss: 3.4339 - accuracy: 0.122 - ETA: 15s - loss: 3.4336 - accuracy: 0.122 - ETA: 14s - loss: 3.4329 - accuracy: 0.122 - ETA: 13s - loss: 3.4330 - accuracy: 0.122 - ETA: 12s - loss: 3.4323 - accuracy: 0.122 - ETA: 11s - loss: 3.4316 - accuracy: 0.123 - ETA: 10s - loss: 3.4315 - accuracy: 0.123 - ETA: 9s - loss: 3.4313 - accuracy: 0.123 - ETA: 8s - loss: 3.4312 - accuracy: 0.12 - ETA: 7s - loss: 3.4310 - accuracy: 0.12 - ETA: 6s - loss: 3.4304 - accuracy: 0.12 - ETA: 5s - loss: 3.4297 - accuracy: 0.12 - ETA: 4s - loss: 3.4298 - accuracy: 0.12 - ETA: 3s - loss: 3.4297 - accuracy: 0.12 - ETA: 2s - loss: 3.4291 - accuracy: 0.12 - ETA: 1s - loss: 3.4289 - accuracy: 0.12 - ETA: 1s - loss: 3.4285 - accuracy: 0.12 - ETA: 0s - loss: 3.4284 - accuracy: 0.12 - 340s 8ms/step - loss: 3.4284 - accuracy: 0.1237 - val_loss: 3.8907 - val_accuracy: 0.0136\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:48 - loss: 3.2910 - accuracy: 0.18 - ETA: 5:36 - loss: 3.3649 - accuracy: 0.14 - ETA: 5:29 - loss: 3.3209 - accuracy: 0.15 - ETA: 5:24 - loss: 3.3960 - accuracy: 0.14 - ETA: 5:27 - loss: 3.3871 - accuracy: 0.13 - ETA: 5:22 - loss: 3.3698 - accuracy: 0.13 - ETA: 5:22 - loss: 3.3768 - accuracy: 0.13 - ETA: 5:19 - loss: 3.3666 - accuracy: 0.13 - ETA: 5:17 - loss: 3.3819 - accuracy: 0.13 - ETA: 5:16 - loss: 3.3895 - accuracy: 0.13 - ETA: 5:12 - loss: 3.4048 - accuracy: 0.12 - ETA: 5:10 - loss: 3.4004 - accuracy: 0.12 - ETA: 5:08 - loss: 3.4052 - accuracy: 0.12 - ETA: 5:06 - loss: 3.4110 - accuracy: 0.12 - ETA: 5:05 - loss: 3.3937 - accuracy: 0.12 - ETA: 5:05 - loss: 3.3950 - accuracy: 0.13 - ETA: 5:04 - loss: 3.4033 - accuracy: 0.12 - ETA: 5:04 - loss: 3.4036 - accuracy: 0.12 - ETA: 5:03 - loss: 3.4040 - accuracy: 0.12 - ETA: 5:01 - loss: 3.4131 - accuracy: 0.12 - ETA: 4:59 - loss: 3.4053 - accuracy: 0.12 - ETA: 4:58 - loss: 3.4004 - accuracy: 0.12 - ETA: 4:56 - loss: 3.4017 - accuracy: 0.12 - ETA: 4:55 - loss: 3.4061 - accuracy: 0.12 - ETA: 4:53 - loss: 3.4037 - accuracy: 0.12 - ETA: 4:53 - loss: 3.3929 - accuracy: 0.12 - ETA: 4:52 - loss: 3.3910 - accuracy: 0.12 - ETA: 4:51 - loss: 3.3864 - accuracy: 0.13 - ETA: 4:50 - loss: 3.3827 - accuracy: 0.13 - ETA: 4:48 - loss: 3.3812 - accuracy: 0.13 - ETA: 4:47 - loss: 3.3843 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3889 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3945 - accuracy: 0.13 - ETA: 4:43 - loss: 3.4083 - accuracy: 0.13 - ETA: 4:42 - loss: 3.4117 - accuracy: 0.13 - ETA: 4:41 - loss: 3.4216 - accuracy: 0.13 - ETA: 4:41 - loss: 3.4265 - accuracy: 0.13 - ETA: 4:39 - loss: 3.4365 - accuracy: 0.13 - ETA: 4:38 - loss: 3.4405 - accuracy: 0.13 - ETA: 4:37 - loss: 3.4402 - accuracy: 0.13 - ETA: 4:36 - loss: 3.4426 - accuracy: 0.13 - ETA: 4:35 - loss: 3.4406 - accuracy: 0.13 - ETA: 4:34 - loss: 3.4397 - accuracy: 0.13 - ETA: 4:33 - loss: 3.4362 - accuracy: 0.13 - ETA: 4:33 - loss: 3.4334 - accuracy: 0.13 - ETA: 4:32 - loss: 3.4340 - accuracy: 0.13 - ETA: 4:31 - loss: 3.4324 - accuracy: 0.13 - ETA: 4:30 - loss: 3.4303 - accuracy: 0.13 - ETA: 4:29 - loss: 3.4306 - accuracy: 0.13 - ETA: 4:28 - loss: 3.4315 - accuracy: 0.13 - ETA: 4:27 - loss: 3.4309 - accuracy: 0.13 - ETA: 4:26 - loss: 3.4291 - accuracy: 0.13 - ETA: 4:25 - loss: 3.4299 - accuracy: 0.13 - ETA: 4:24 - loss: 3.4282 - accuracy: 0.13 - ETA: 4:23 - loss: 3.4290 - accuracy: 0.13 - ETA: 4:22 - loss: 3.4285 - accuracy: 0.13 - ETA: 4:21 - loss: 3.4261 - accuracy: 0.13 - ETA: 4:20 - loss: 3.4268 - accuracy: 0.13 - ETA: 4:19 - loss: 3.4234 - accuracy: 0.13 - ETA: 4:18 - loss: 3.4220 - accuracy: 0.13 - ETA: 4:17 - loss: 3.4204 - accuracy: 0.13 - ETA: 4:17 - loss: 3.4238 - accuracy: 0.13 - ETA: 4:16 - loss: 3.4200 - accuracy: 0.13 - ETA: 4:15 - loss: 3.4217 - accuracy: 0.13 - ETA: 4:14 - loss: 3.4235 - accuracy: 0.13 - ETA: 4:13 - loss: 3.4215 - accuracy: 0.13 - ETA: 4:12 - loss: 3.4183 - accuracy: 0.13 - ETA: 4:11 - loss: 3.4177 - accuracy: 0.13 - ETA: 4:10 - loss: 3.4151 - accuracy: 0.13 - ETA: 4:09 - loss: 3.4132 - accuracy: 0.13 - ETA: 4:08 - loss: 3.4142 - accuracy: 0.13 - ETA: 4:07 - loss: 3.4140 - accuracy: 0.13 - ETA: 4:06 - loss: 3.4135 - accuracy: 0.13 - ETA: 4:05 - loss: 3.4136 - accuracy: 0.13 - ETA: 4:05 - loss: 3.4116 - accuracy: 0.13 - ETA: 4:04 - loss: 3.4115 - accuracy: 0.13 - ETA: 4:03 - loss: 3.4105 - accuracy: 0.13 - ETA: 4:02 - loss: 3.4107 - accuracy: 0.13 - ETA: 4:01 - loss: 3.4117 - accuracy: 0.13 - ETA: 4:00 - loss: 3.4121 - accuracy: 0.13 - ETA: 3:59 - loss: 3.4116 - accuracy: 0.13 - ETA: 3:58 - loss: 3.4078 - accuracy: 0.13 - ETA: 3:57 - loss: 3.4091 - accuracy: 0.13 - ETA: 3:56 - loss: 3.4086 - accuracy: 0.13 - ETA: 3:55 - loss: 3.4105 - accuracy: 0.13 - ETA: 3:54 - loss: 3.4097 - accuracy: 0.13 - ETA: 3:53 - loss: 3.4081 - accuracy: 0.13 - ETA: 3:53 - loss: 3.4068 - accuracy: 0.13 - ETA: 3:52 - loss: 3.4055 - accuracy: 0.13 - ETA: 3:51 - loss: 3.4061 - accuracy: 0.13 - ETA: 3:50 - loss: 3.4062 - accuracy: 0.13 - ETA: 3:49 - loss: 3.4051 - accuracy: 0.13 - ETA: 3:48 - loss: 3.4024 - accuracy: 0.13 - ETA: 3:47 - loss: 3.4023 - accuracy: 0.13 - ETA: 3:46 - loss: 3.4016 - accuracy: 0.12 - ETA: 3:45 - loss: 3.4009 - accuracy: 0.13 - ETA: 3:44 - loss: 3.4001 - accuracy: 0.13 - ETA: 3:43 - loss: 3.4009 - accuracy: 0.12 - ETA: 3:42 - loss: 3.3996 - accuracy: 0.12 - ETA: 3:41 - loss: 3.3998 - accuracy: 0.12 - ETA: 3:40 - loss: 3.4011 - accuracy: 0.12 - ETA: 3:39 - loss: 3.4007 - accuracy: 0.12 - ETA: 3:38 - loss: 3.4011 - accuracy: 0.12 - ETA: 3:37 - loss: 3.4008 - accuracy: 0.12 - ETA: 3:36 - loss: 3.4000 - accuracy: 0.12 - ETA: 3:35 - loss: 3.3999 - accuracy: 0.12 - ETA: 3:34 - loss: 3.3985 - accuracy: 0.12 - ETA: 3:33 - loss: 3.3980 - accuracy: 0.12 - ETA: 3:32 - loss: 3.3959 - accuracy: 0.12 - ETA: 3:32 - loss: 3.3979 - accuracy: 0.12 - ETA: 3:31 - loss: 3.3967 - accuracy: 0.12 - ETA: 3:30 - loss: 3.3955 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3971 - accuracy: 0.12 - ETA: 3:28 - loss: 3.3968 - accuracy: 0.12 - ETA: 3:27 - loss: 3.3949 - accuracy: 0.12 - ETA: 3:26 - loss: 3.3947 - accuracy: 0.12 - ETA: 3:25 - loss: 3.3946 - accuracy: 0.12 - ETA: 3:24 - loss: 3.3938 - accuracy: 0.12 - ETA: 3:23 - loss: 3.3934 - accuracy: 0.12 - ETA: 3:22 - loss: 3.3937 - accuracy: 0.12 - ETA: 3:21 - loss: 3.3922 - accuracy: 0.12 - ETA: 3:20 - loss: 3.3927 - accuracy: 0.12 - ETA: 3:19 - loss: 3.3922 - accuracy: 0.12 - ETA: 3:18 - loss: 3.3930 - accuracy: 0.12 - ETA: 3:17 - loss: 3.3930 - accuracy: 0.12 - ETA: 3:16 - loss: 3.3931 - accuracy: 0.12 - ETA: 3:15 - loss: 3.3930 - accuracy: 0.12 - ETA: 3:14 - loss: 3.3932 - accuracy: 0.12 - ETA: 3:13 - loss: 3.3947 - accuracy: 0.12 - ETA: 3:12 - loss: 3.3955 - accuracy: 0.12 - ETA: 3:11 - loss: 3.3955 - accuracy: 0.12 - ETA: 3:10 - loss: 3.3941 - accuracy: 0.12 - ETA: 3:09 - loss: 3.3935 - accuracy: 0.12 - ETA: 3:08 - loss: 3.3931 - accuracy: 0.12 - ETA: 3:08 - loss: 3.3924 - accuracy: 0.12 - ETA: 3:07 - loss: 3.3910 - accuracy: 0.12 - ETA: 3:06 - loss: 3.3904 - accuracy: 0.12 - ETA: 3:05 - loss: 3.3903 - accuracy: 0.12 - ETA: 3:04 - loss: 3.3909 - accuracy: 0.12 - ETA: 3:03 - loss: 3.3908 - accuracy: 0.12 - ETA: 3:02 - loss: 3.3906 - accuracy: 0.12 - ETA: 3:01 - loss: 3.3895 - accuracy: 0.12 - ETA: 3:00 - loss: 3.3888 - accuracy: 0.12 - ETA: 2:59 - loss: 3.3875 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3864 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3854 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3845 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3854 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3860 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3859 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3861 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3845 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3839 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3839 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3846 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3845 - accuracy: 0.12 - ETA: 2:46 - loss: 3.3844 - accuracy: 0.12 - ETA: 2:45 - loss: 3.3848 - accuracy: 0.12 - ETA: 2:44 - loss: 3.3839 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3825 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3829 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3832 - accuracy: 0.13 - ETA: 2:40 - loss: 3.3838 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3839 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3835 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3820 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3829 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3824 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3808 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3806 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3793 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3786 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3789 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3788 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3783 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3777 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3777 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3774 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3793 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3792 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3779 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3776 - accuracy: 0.13 - ETA: 2:21 - loss: 3.3768 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3764 - accuracy: 0.13 - ETA: 2:19 - loss: 3.3768 - accuracy: 0.13 - ETA: 2:18 - loss: 3.3767 - accuracy: 0.1313"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3762 - accuracy: 0.13 - ETA: 2:16 - loss: 3.3751 - accuracy: 0.13 - ETA: 2:16 - loss: 3.3752 - accuracy: 0.13 - ETA: 2:15 - loss: 3.3755 - accuracy: 0.13 - ETA: 2:14 - loss: 3.3746 - accuracy: 0.13 - ETA: 2:13 - loss: 3.3755 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3755 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3746 - accuracy: 0.13 - ETA: 2:10 - loss: 3.3748 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3743 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3734 - accuracy: 0.13 - ETA: 2:07 - loss: 3.3733 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3733 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3731 - accuracy: 0.13 - ETA: 2:04 - loss: 3.3733 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3730 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3731 - accuracy: 0.13 - ETA: 2:01 - loss: 3.3733 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3736 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3745 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3746 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3736 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3738 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3741 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3738 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3739 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3738 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3737 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3740 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3736 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3738 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3744 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3741 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3750 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3746 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3747 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3745 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3736 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3743 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3748 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3747 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3744 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3743 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3743 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3745 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3738 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3742 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3738 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3737 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3731 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3728 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3726 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3718 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3721 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3722 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3723 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3720 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3727 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3722 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3719 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3720 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3722 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3716 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3713 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3705 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3697 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3693 - accuracy: 0.13 - ETA: 1:13 - loss: 3.3686 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3685 - accuracy: 0.13 - ETA: 1:11 - loss: 3.3683 - accuracy: 0.13 - ETA: 1:10 - loss: 3.3681 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3679 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3680 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3673 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3671 - accuracy: 0.13 - ETA: 1:06 - loss: 3.3675 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3667 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3664 - accuracy: 0.13 - ETA: 1:03 - loss: 3.3666 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3661 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3660 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3658 - accuracy: 0.13 - ETA: 59s - loss: 3.3668 - accuracy: 0.1330 - ETA: 58s - loss: 3.3663 - accuracy: 0.133 - ETA: 57s - loss: 3.3655 - accuracy: 0.133 - ETA: 56s - loss: 3.3656 - accuracy: 0.133 - ETA: 55s - loss: 3.3656 - accuracy: 0.133 - ETA: 54s - loss: 3.3650 - accuracy: 0.133 - ETA: 53s - loss: 3.3644 - accuracy: 0.133 - ETA: 52s - loss: 3.3639 - accuracy: 0.133 - ETA: 51s - loss: 3.3630 - accuracy: 0.134 - ETA: 50s - loss: 3.3631 - accuracy: 0.134 - ETA: 49s - loss: 3.3631 - accuracy: 0.134 - ETA: 48s - loss: 3.3630 - accuracy: 0.134 - ETA: 47s - loss: 3.3632 - accuracy: 0.134 - ETA: 46s - loss: 3.3626 - accuracy: 0.134 - ETA: 45s - loss: 3.3618 - accuracy: 0.134 - ETA: 45s - loss: 3.3617 - accuracy: 0.134 - ETA: 44s - loss: 3.3617 - accuracy: 0.134 - ETA: 43s - loss: 3.3609 - accuracy: 0.134 - ETA: 42s - loss: 3.3600 - accuracy: 0.134 - ETA: 41s - loss: 3.3597 - accuracy: 0.134 - ETA: 40s - loss: 3.3594 - accuracy: 0.134 - ETA: 39s - loss: 3.3593 - accuracy: 0.134 - ETA: 38s - loss: 3.3596 - accuracy: 0.134 - ETA: 37s - loss: 3.3599 - accuracy: 0.134 - ETA: 36s - loss: 3.3606 - accuracy: 0.134 - ETA: 35s - loss: 3.3608 - accuracy: 0.134 - ETA: 34s - loss: 3.3610 - accuracy: 0.134 - ETA: 33s - loss: 3.3604 - accuracy: 0.134 - ETA: 32s - loss: 3.3600 - accuracy: 0.134 - ETA: 31s - loss: 3.3602 - accuracy: 0.134 - ETA: 30s - loss: 3.3602 - accuracy: 0.134 - ETA: 29s - loss: 3.3597 - accuracy: 0.134 - ETA: 28s - loss: 3.3598 - accuracy: 0.134 - ETA: 27s - loss: 3.3592 - accuracy: 0.134 - ETA: 26s - loss: 3.3596 - accuracy: 0.134 - ETA: 25s - loss: 3.3596 - accuracy: 0.135 - ETA: 24s - loss: 3.3592 - accuracy: 0.135 - ETA: 23s - loss: 3.3589 - accuracy: 0.135 - ETA: 23s - loss: 3.3594 - accuracy: 0.135 - ETA: 22s - loss: 3.3593 - accuracy: 0.135 - ETA: 21s - loss: 3.3587 - accuracy: 0.135 - ETA: 20s - loss: 3.3585 - accuracy: 0.135 - ETA: 19s - loss: 3.3594 - accuracy: 0.135 - ETA: 18s - loss: 3.3593 - accuracy: 0.135 - ETA: 17s - loss: 3.3595 - accuracy: 0.134 - ETA: 16s - loss: 3.3598 - accuracy: 0.135 - ETA: 15s - loss: 3.3596 - accuracy: 0.135 - ETA: 14s - loss: 3.3596 - accuracy: 0.135 - ETA: 13s - loss: 3.3601 - accuracy: 0.134 - ETA: 12s - loss: 3.3599 - accuracy: 0.134 - ETA: 11s - loss: 3.3596 - accuracy: 0.135 - ETA: 10s - loss: 3.3595 - accuracy: 0.135 - ETA: 9s - loss: 3.3590 - accuracy: 0.135 - ETA: 8s - loss: 3.3591 - accuracy: 0.13 - ETA: 7s - loss: 3.3594 - accuracy: 0.13 - ETA: 6s - loss: 3.3593 - accuracy: 0.13 - ETA: 5s - loss: 3.3590 - accuracy: 0.13 - ETA: 4s - loss: 3.3591 - accuracy: 0.13 - ETA: 3s - loss: 3.3590 - accuracy: 0.13 - ETA: 2s - loss: 3.3591 - accuracy: 0.13 - ETA: 1s - loss: 3.3588 - accuracy: 0.13 - ETA: 1s - loss: 3.3584 - accuracy: 0.13 - ETA: 0s - loss: 3.3581 - accuracy: 0.13 - 341s 8ms/step - loss: 3.3581 - accuracy: 0.1356 - val_loss: 3.9887 - val_accuracy: 0.0141\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:04 - loss: 3.2321 - accuracy: 0.13 - ETA: 4:59 - loss: 3.3234 - accuracy: 0.14 - ETA: 5:03 - loss: 3.3376 - accuracy: 0.13 - ETA: 5:11 - loss: 3.3786 - accuracy: 0.12 - ETA: 5:04 - loss: 3.3702 - accuracy: 0.12 - ETA: 5:07 - loss: 3.3642 - accuracy: 0.12 - ETA: 5:05 - loss: 3.3620 - accuracy: 0.13 - ETA: 5:02 - loss: 3.3703 - accuracy: 0.13 - ETA: 4:59 - loss: 3.3792 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3875 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3802 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3923 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3923 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3901 - accuracy: 0.13 - ETA: 4:59 - loss: 3.3822 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3833 - accuracy: 0.13 - ETA: 4:59 - loss: 3.3724 - accuracy: 0.13 - ETA: 4:59 - loss: 3.3730 - accuracy: 0.13 - ETA: 4:57 - loss: 3.3777 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3668 - accuracy: 0.13 - ETA: 4:57 - loss: 3.3680 - accuracy: 0.13 - ETA: 4:56 - loss: 3.3626 - accuracy: 0.13 - ETA: 4:55 - loss: 3.3590 - accuracy: 0.13 - ETA: 4:54 - loss: 3.3603 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3678 - accuracy: 0.13 - ETA: 4:51 - loss: 3.3636 - accuracy: 0.13 - ETA: 4:50 - loss: 3.3625 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3654 - accuracy: 0.13 - ETA: 4:48 - loss: 3.3604 - accuracy: 0.13 - ETA: 4:48 - loss: 3.3600 - accuracy: 0.13 - ETA: 4:47 - loss: 3.3631 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3691 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3712 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3785 - accuracy: 0.13 - ETA: 4:43 - loss: 3.3812 - accuracy: 0.12 - ETA: 4:43 - loss: 3.3861 - accuracy: 0.12 - ETA: 4:42 - loss: 3.3895 - accuracy: 0.12 - ETA: 4:41 - loss: 3.3941 - accuracy: 0.12 - ETA: 4:40 - loss: 3.3942 - accuracy: 0.12 - ETA: 4:39 - loss: 3.3922 - accuracy: 0.12 - ETA: 4:38 - loss: 3.3973 - accuracy: 0.12 - ETA: 4:36 - loss: 3.4021 - accuracy: 0.12 - ETA: 4:36 - loss: 3.4048 - accuracy: 0.12 - ETA: 4:34 - loss: 3.4066 - accuracy: 0.12 - ETA: 4:33 - loss: 3.4079 - accuracy: 0.12 - ETA: 4:32 - loss: 3.4085 - accuracy: 0.12 - ETA: 4:32 - loss: 3.4091 - accuracy: 0.12 - ETA: 4:31 - loss: 3.4122 - accuracy: 0.12 - ETA: 4:30 - loss: 3.4154 - accuracy: 0.12 - ETA: 4:29 - loss: 3.4164 - accuracy: 0.12 - ETA: 4:28 - loss: 3.4176 - accuracy: 0.12 - ETA: 4:27 - loss: 3.4158 - accuracy: 0.12 - ETA: 4:26 - loss: 3.4161 - accuracy: 0.12 - ETA: 4:25 - loss: 3.4176 - accuracy: 0.12 - ETA: 4:25 - loss: 3.4202 - accuracy: 0.12 - ETA: 4:24 - loss: 3.4195 - accuracy: 0.12 - ETA: 4:22 - loss: 3.4197 - accuracy: 0.12 - ETA: 4:21 - loss: 3.4234 - accuracy: 0.12 - ETA: 4:20 - loss: 3.4222 - accuracy: 0.12 - ETA: 4:19 - loss: 3.4216 - accuracy: 0.12 - ETA: 4:18 - loss: 3.4228 - accuracy: 0.12 - ETA: 4:17 - loss: 3.4250 - accuracy: 0.12 - ETA: 4:16 - loss: 3.4261 - accuracy: 0.12 - ETA: 4:15 - loss: 3.4246 - accuracy: 0.12 - ETA: 4:14 - loss: 3.4245 - accuracy: 0.12 - ETA: 4:13 - loss: 3.4274 - accuracy: 0.12 - ETA: 4:12 - loss: 3.4301 - accuracy: 0.12 - ETA: 4:11 - loss: 3.4299 - accuracy: 0.12 - ETA: 4:10 - loss: 3.4288 - accuracy: 0.12 - ETA: 4:09 - loss: 3.4293 - accuracy: 0.12 - ETA: 4:08 - loss: 3.4300 - accuracy: 0.12 - ETA: 4:07 - loss: 3.4302 - accuracy: 0.12 - ETA: 4:06 - loss: 3.4319 - accuracy: 0.12 - ETA: 4:05 - loss: 3.4331 - accuracy: 0.12 - ETA: 4:03 - loss: 3.4329 - accuracy: 0.12 - ETA: 4:02 - loss: 3.4338 - accuracy: 0.12 - ETA: 4:02 - loss: 3.4328 - accuracy: 0.12 - ETA: 4:01 - loss: 3.4338 - accuracy: 0.12 - ETA: 4:00 - loss: 3.4351 - accuracy: 0.12 - ETA: 3:59 - loss: 3.4355 - accuracy: 0.12 - ETA: 3:58 - loss: 3.4356 - accuracy: 0.12 - ETA: 3:57 - loss: 3.4374 - accuracy: 0.11 - ETA: 3:56 - loss: 3.4377 - accuracy: 0.11 - ETA: 3:55 - loss: 3.4372 - accuracy: 0.11 - ETA: 3:54 - loss: 3.4359 - accuracy: 0.11 - ETA: 3:53 - loss: 3.4366 - accuracy: 0.11 - ETA: 3:52 - loss: 3.4370 - accuracy: 0.11 - ETA: 3:51 - loss: 3.4356 - accuracy: 0.11 - ETA: 3:51 - loss: 3.4367 - accuracy: 0.11 - ETA: 3:50 - loss: 3.4386 - accuracy: 0.11 - ETA: 3:49 - loss: 3.4388 - accuracy: 0.11 - ETA: 3:47 - loss: 3.4398 - accuracy: 0.11 - ETA: 3:46 - loss: 3.4406 - accuracy: 0.11 - ETA: 3:46 - loss: 3.4418 - accuracy: 0.11 - ETA: 3:45 - loss: 3.4419 - accuracy: 0.11 - ETA: 3:44 - loss: 3.4419 - accuracy: 0.11 - ETA: 3:43 - loss: 3.4439 - accuracy: 0.11 - ETA: 3:42 - loss: 3.4435 - accuracy: 0.11 - ETA: 3:41 - loss: 3.4429 - accuracy: 0.11 - ETA: 3:40 - loss: 3.4439 - accuracy: 0.11 - ETA: 3:39 - loss: 3.4429 - accuracy: 0.11 - ETA: 3:38 - loss: 3.4446 - accuracy: 0.11 - ETA: 3:37 - loss: 3.4455 - accuracy: 0.11 - ETA: 3:36 - loss: 3.4457 - accuracy: 0.11 - ETA: 3:35 - loss: 3.4466 - accuracy: 0.11 - ETA: 3:34 - loss: 3.4464 - accuracy: 0.11 - ETA: 3:33 - loss: 3.4445 - accuracy: 0.11 - ETA: 3:32 - loss: 3.4457 - accuracy: 0.11 - ETA: 3:31 - loss: 3.4452 - accuracy: 0.11 - ETA: 3:30 - loss: 3.4456 - accuracy: 0.11 - ETA: 3:29 - loss: 3.4462 - accuracy: 0.11 - ETA: 3:28 - loss: 3.4464 - accuracy: 0.11 - ETA: 3:27 - loss: 3.4468 - accuracy: 0.11 - ETA: 3:26 - loss: 3.4467 - accuracy: 0.11 - ETA: 3:26 - loss: 3.4482 - accuracy: 0.11 - ETA: 3:25 - loss: 3.4482 - accuracy: 0.11 - ETA: 3:24 - loss: 3.4497 - accuracy: 0.11 - ETA: 3:23 - loss: 3.4498 - accuracy: 0.11 - ETA: 3:22 - loss: 3.4501 - accuracy: 0.11 - ETA: 3:21 - loss: 3.4488 - accuracy: 0.11 - ETA: 3:20 - loss: 3.4497 - accuracy: 0.11 - ETA: 3:19 - loss: 3.4493 - accuracy: 0.11 - ETA: 3:18 - loss: 3.4500 - accuracy: 0.11 - ETA: 3:17 - loss: 3.4500 - accuracy: 0.11 - ETA: 3:16 - loss: 3.4496 - accuracy: 0.11 - ETA: 3:15 - loss: 3.4492 - accuracy: 0.11 - ETA: 3:14 - loss: 3.4491 - accuracy: 0.11 - ETA: 3:13 - loss: 3.4501 - accuracy: 0.11 - ETA: 3:12 - loss: 3.4511 - accuracy: 0.11 - ETA: 3:11 - loss: 3.4514 - accuracy: 0.11 - ETA: 3:10 - loss: 3.4513 - accuracy: 0.11 - ETA: 3:10 - loss: 3.4518 - accuracy: 0.11 - ETA: 3:09 - loss: 3.4527 - accuracy: 0.11 - ETA: 3:08 - loss: 3.4522 - accuracy: 0.11 - ETA: 3:07 - loss: 3.4530 - accuracy: 0.11 - ETA: 3:06 - loss: 3.4546 - accuracy: 0.11 - ETA: 3:05 - loss: 3.4551 - accuracy: 0.11 - ETA: 3:04 - loss: 3.4559 - accuracy: 0.11 - ETA: 3:03 - loss: 3.4554 - accuracy: 0.11 - ETA: 3:02 - loss: 3.4561 - accuracy: 0.11 - ETA: 3:01 - loss: 3.4565 - accuracy: 0.11 - ETA: 3:00 - loss: 3.4566 - accuracy: 0.11 - ETA: 2:59 - loss: 3.4558 - accuracy: 0.11 - ETA: 2:58 - loss: 3.4559 - accuracy: 0.11 - ETA: 2:57 - loss: 3.4562 - accuracy: 0.11 - ETA: 2:56 - loss: 3.4560 - accuracy: 0.11 - ETA: 2:55 - loss: 3.4562 - accuracy: 0.11 - ETA: 2:54 - loss: 3.4556 - accuracy: 0.11 - ETA: 2:53 - loss: 3.4548 - accuracy: 0.11 - ETA: 2:52 - loss: 3.4549 - accuracy: 0.11 - ETA: 2:51 - loss: 3.4542 - accuracy: 0.11 - ETA: 2:51 - loss: 3.4533 - accuracy: 0.11 - ETA: 2:50 - loss: 3.4524 - accuracy: 0.11 - ETA: 2:49 - loss: 3.4523 - accuracy: 0.11 - ETA: 2:48 - loss: 3.4532 - accuracy: 0.11 - ETA: 2:47 - loss: 3.4531 - accuracy: 0.11 - ETA: 2:46 - loss: 3.4533 - accuracy: 0.11 - ETA: 2:45 - loss: 3.4538 - accuracy: 0.11 - ETA: 2:44 - loss: 3.4539 - accuracy: 0.11 - ETA: 2:43 - loss: 3.4540 - accuracy: 0.11 - ETA: 2:42 - loss: 3.4537 - accuracy: 0.11 - ETA: 2:41 - loss: 3.4532 - accuracy: 0.11 - ETA: 2:40 - loss: 3.4537 - accuracy: 0.11 - ETA: 2:39 - loss: 3.4543 - accuracy: 0.11 - ETA: 2:38 - loss: 3.4540 - accuracy: 0.11 - ETA: 2:37 - loss: 3.4535 - accuracy: 0.11 - ETA: 2:36 - loss: 3.4530 - accuracy: 0.11 - ETA: 2:35 - loss: 3.4545 - accuracy: 0.11 - ETA: 2:34 - loss: 3.4550 - accuracy: 0.11 - ETA: 2:33 - loss: 3.4554 - accuracy: 0.11 - ETA: 2:32 - loss: 3.4544 - accuracy: 0.11 - ETA: 2:32 - loss: 3.4539 - accuracy: 0.11 - ETA: 2:31 - loss: 3.4535 - accuracy: 0.11 - ETA: 2:30 - loss: 3.4531 - accuracy: 0.11 - ETA: 2:29 - loss: 3.4539 - accuracy: 0.11 - ETA: 2:28 - loss: 3.4541 - accuracy: 0.11 - ETA: 2:27 - loss: 3.4547 - accuracy: 0.11 - ETA: 2:26 - loss: 3.4543 - accuracy: 0.11 - ETA: 2:25 - loss: 3.4543 - accuracy: 0.11 - ETA: 2:24 - loss: 3.4548 - accuracy: 0.11 - ETA: 2:23 - loss: 3.4550 - accuracy: 0.11 - ETA: 2:22 - loss: 3.4550 - accuracy: 0.11 - ETA: 2:21 - loss: 3.4539 - accuracy: 0.11 - ETA: 2:20 - loss: 3.4540 - accuracy: 0.11 - ETA: 2:19 - loss: 3.4536 - accuracy: 0.11 - ETA: 2:18 - loss: 3.4541 - accuracy: 0.1165"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.4542 - accuracy: 0.11 - ETA: 2:16 - loss: 3.4546 - accuracy: 0.11 - ETA: 2:15 - loss: 3.4548 - accuracy: 0.11 - ETA: 2:14 - loss: 3.4556 - accuracy: 0.11 - ETA: 2:14 - loss: 3.4548 - accuracy: 0.11 - ETA: 2:12 - loss: 3.4550 - accuracy: 0.11 - ETA: 2:12 - loss: 3.4553 - accuracy: 0.11 - ETA: 2:11 - loss: 3.4561 - accuracy: 0.11 - ETA: 2:10 - loss: 3.4557 - accuracy: 0.11 - ETA: 2:09 - loss: 3.4554 - accuracy: 0.11 - ETA: 2:08 - loss: 3.4556 - accuracy: 0.11 - ETA: 2:07 - loss: 3.4559 - accuracy: 0.11 - ETA: 2:06 - loss: 3.4552 - accuracy: 0.11 - ETA: 2:05 - loss: 3.4553 - accuracy: 0.11 - ETA: 2:04 - loss: 3.4557 - accuracy: 0.11 - ETA: 2:03 - loss: 3.4553 - accuracy: 0.11 - ETA: 2:02 - loss: 3.4556 - accuracy: 0.11 - ETA: 2:01 - loss: 3.4557 - accuracy: 0.11 - ETA: 2:00 - loss: 3.4550 - accuracy: 0.11 - ETA: 1:59 - loss: 3.4535 - accuracy: 0.11 - ETA: 1:58 - loss: 3.4528 - accuracy: 0.11 - ETA: 1:57 - loss: 3.4525 - accuracy: 0.11 - ETA: 1:56 - loss: 3.4523 - accuracy: 0.11 - ETA: 1:55 - loss: 3.4525 - accuracy: 0.11 - ETA: 1:54 - loss: 3.4521 - accuracy: 0.11 - ETA: 1:53 - loss: 3.4522 - accuracy: 0.11 - ETA: 1:52 - loss: 3.4528 - accuracy: 0.11 - ETA: 1:51 - loss: 3.4525 - accuracy: 0.11 - ETA: 1:50 - loss: 3.4523 - accuracy: 0.11 - ETA: 1:50 - loss: 3.4525 - accuracy: 0.11 - ETA: 1:49 - loss: 3.4522 - accuracy: 0.11 - ETA: 1:48 - loss: 3.4530 - accuracy: 0.11 - ETA: 1:47 - loss: 3.4530 - accuracy: 0.11 - ETA: 1:46 - loss: 3.4529 - accuracy: 0.11 - ETA: 1:45 - loss: 3.4525 - accuracy: 0.11 - ETA: 1:44 - loss: 3.4527 - accuracy: 0.11 - ETA: 1:43 - loss: 3.4516 - accuracy: 0.11 - ETA: 1:42 - loss: 3.4521 - accuracy: 0.11 - ETA: 1:41 - loss: 3.4521 - accuracy: 0.11 - ETA: 1:40 - loss: 3.4520 - accuracy: 0.11 - ETA: 1:39 - loss: 3.4515 - accuracy: 0.11 - ETA: 1:38 - loss: 3.4510 - accuracy: 0.11 - ETA: 1:37 - loss: 3.4508 - accuracy: 0.11 - ETA: 1:36 - loss: 3.4505 - accuracy: 0.11 - ETA: 1:35 - loss: 3.4498 - accuracy: 0.11 - ETA: 1:34 - loss: 3.4502 - accuracy: 0.11 - ETA: 1:33 - loss: 3.4495 - accuracy: 0.11 - ETA: 1:32 - loss: 3.4490 - accuracy: 0.11 - ETA: 1:31 - loss: 3.4495 - accuracy: 0.11 - ETA: 1:30 - loss: 3.4492 - accuracy: 0.11 - ETA: 1:29 - loss: 3.4491 - accuracy: 0.11 - ETA: 1:29 - loss: 3.4483 - accuracy: 0.11 - ETA: 1:28 - loss: 3.4485 - accuracy: 0.11 - ETA: 1:27 - loss: 3.4490 - accuracy: 0.11 - ETA: 1:26 - loss: 3.4487 - accuracy: 0.11 - ETA: 1:25 - loss: 3.4495 - accuracy: 0.11 - ETA: 1:24 - loss: 3.4495 - accuracy: 0.11 - ETA: 1:23 - loss: 3.4499 - accuracy: 0.11 - ETA: 1:22 - loss: 3.4502 - accuracy: 0.11 - ETA: 1:21 - loss: 3.4498 - accuracy: 0.11 - ETA: 1:20 - loss: 3.4494 - accuracy: 0.11 - ETA: 1:19 - loss: 3.4498 - accuracy: 0.11 - ETA: 1:18 - loss: 3.4502 - accuracy: 0.11 - ETA: 1:17 - loss: 3.4510 - accuracy: 0.11 - ETA: 1:16 - loss: 3.4514 - accuracy: 0.11 - ETA: 1:15 - loss: 3.4519 - accuracy: 0.11 - ETA: 1:14 - loss: 3.4524 - accuracy: 0.11 - ETA: 1:13 - loss: 3.4531 - accuracy: 0.11 - ETA: 1:12 - loss: 3.4533 - accuracy: 0.11 - ETA: 1:11 - loss: 3.4539 - accuracy: 0.11 - ETA: 1:10 - loss: 3.4542 - accuracy: 0.11 - ETA: 1:09 - loss: 3.4549 - accuracy: 0.11 - ETA: 1:09 - loss: 3.4551 - accuracy: 0.11 - ETA: 1:08 - loss: 3.4557 - accuracy: 0.11 - ETA: 1:07 - loss: 3.4561 - accuracy: 0.11 - ETA: 1:06 - loss: 3.4566 - accuracy: 0.11 - ETA: 1:05 - loss: 3.4569 - accuracy: 0.11 - ETA: 1:04 - loss: 3.4576 - accuracy: 0.11 - ETA: 1:03 - loss: 3.4578 - accuracy: 0.11 - ETA: 1:02 - loss: 3.4582 - accuracy: 0.11 - ETA: 1:01 - loss: 3.4584 - accuracy: 0.11 - ETA: 1:00 - loss: 3.4590 - accuracy: 0.11 - ETA: 59s - loss: 3.4596 - accuracy: 0.1152 - ETA: 58s - loss: 3.4605 - accuracy: 0.115 - ETA: 57s - loss: 3.4608 - accuracy: 0.115 - ETA: 56s - loss: 3.4612 - accuracy: 0.114 - ETA: 55s - loss: 3.4615 - accuracy: 0.114 - ETA: 54s - loss: 3.4618 - accuracy: 0.114 - ETA: 53s - loss: 3.4623 - accuracy: 0.114 - ETA: 52s - loss: 3.4627 - accuracy: 0.114 - ETA: 51s - loss: 3.4633 - accuracy: 0.114 - ETA: 50s - loss: 3.4641 - accuracy: 0.114 - ETA: 49s - loss: 3.4645 - accuracy: 0.114 - ETA: 48s - loss: 3.4644 - accuracy: 0.114 - ETA: 47s - loss: 3.4655 - accuracy: 0.113 - ETA: 46s - loss: 3.4658 - accuracy: 0.113 - ETA: 46s - loss: 3.4668 - accuracy: 0.113 - ETA: 45s - loss: 3.4676 - accuracy: 0.113 - ETA: 44s - loss: 3.4680 - accuracy: 0.113 - ETA: 43s - loss: 3.4685 - accuracy: 0.113 - ETA: 42s - loss: 3.4691 - accuracy: 0.113 - ETA: 41s - loss: 3.4696 - accuracy: 0.113 - ETA: 40s - loss: 3.4700 - accuracy: 0.113 - ETA: 39s - loss: 3.4707 - accuracy: 0.112 - ETA: 38s - loss: 3.4713 - accuracy: 0.112 - ETA: 37s - loss: 3.4721 - accuracy: 0.112 - ETA: 36s - loss: 3.4722 - accuracy: 0.112 - ETA: 35s - loss: 3.4725 - accuracy: 0.112 - ETA: 34s - loss: 3.4722 - accuracy: 0.112 - ETA: 33s - loss: 3.4728 - accuracy: 0.112 - ETA: 32s - loss: 3.4733 - accuracy: 0.112 - ETA: 31s - loss: 3.4736 - accuracy: 0.112 - ETA: 30s - loss: 3.4737 - accuracy: 0.112 - ETA: 29s - loss: 3.4736 - accuracy: 0.112 - ETA: 28s - loss: 3.4737 - accuracy: 0.112 - ETA: 27s - loss: 3.4742 - accuracy: 0.112 - ETA: 26s - loss: 3.4742 - accuracy: 0.112 - ETA: 25s - loss: 3.4744 - accuracy: 0.112 - ETA: 24s - loss: 3.4749 - accuracy: 0.112 - ETA: 23s - loss: 3.4752 - accuracy: 0.112 - ETA: 23s - loss: 3.4759 - accuracy: 0.112 - ETA: 22s - loss: 3.4763 - accuracy: 0.112 - ETA: 21s - loss: 3.4766 - accuracy: 0.112 - ETA: 20s - loss: 3.4774 - accuracy: 0.112 - ETA: 19s - loss: 3.4775 - accuracy: 0.112 - ETA: 18s - loss: 3.4780 - accuracy: 0.111 - ETA: 17s - loss: 3.4786 - accuracy: 0.111 - ETA: 16s - loss: 3.4790 - accuracy: 0.111 - ETA: 15s - loss: 3.4797 - accuracy: 0.111 - ETA: 14s - loss: 3.4803 - accuracy: 0.111 - ETA: 13s - loss: 3.4813 - accuracy: 0.111 - ETA: 12s - loss: 3.4819 - accuracy: 0.111 - ETA: 11s - loss: 3.4824 - accuracy: 0.111 - ETA: 10s - loss: 3.4832 - accuracy: 0.110 - ETA: 9s - loss: 3.4838 - accuracy: 0.110 - ETA: 8s - loss: 3.4847 - accuracy: 0.11 - ETA: 7s - loss: 3.4856 - accuracy: 0.11 - ETA: 6s - loss: 3.4861 - accuracy: 0.11 - ETA: 5s - loss: 3.4864 - accuracy: 0.11 - ETA: 4s - loss: 3.4871 - accuracy: 0.11 - ETA: 3s - loss: 3.4876 - accuracy: 0.11 - ETA: 2s - loss: 3.4879 - accuracy: 0.11 - ETA: 1s - loss: 3.4883 - accuracy: 0.11 - ETA: 1s - loss: 3.4891 - accuracy: 0.10 - ETA: 0s - loss: 3.4892 - accuracy: 0.10 - 341s 8ms/step - loss: 3.4892 - accuracy: 0.1098 - val_loss: 3.9135 - val_accuracy: 0.0089\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:00 - loss: 3.5421 - accuracy: 0.12 - ETA: 4:57 - loss: 3.6139 - accuracy: 0.10 - ETA: 4:53 - loss: 3.6526 - accuracy: 0.08 - ETA: 4:58 - loss: 3.6062 - accuracy: 0.09 - ETA: 5:01 - loss: 3.5954 - accuracy: 0.10 - ETA: 5:04 - loss: 3.5999 - accuracy: 0.10 - ETA: 5:02 - loss: 3.5869 - accuracy: 0.10 - ETA: 5:03 - loss: 3.5979 - accuracy: 0.09 - ETA: 5:04 - loss: 3.6036 - accuracy: 0.09 - ETA: 5:05 - loss: 3.5876 - accuracy: 0.09 - ETA: 5:02 - loss: 3.5915 - accuracy: 0.09 - ETA: 5:02 - loss: 3.6066 - accuracy: 0.09 - ETA: 5:05 - loss: 3.6224 - accuracy: 0.09 - ETA: 5:04 - loss: 3.6247 - accuracy: 0.08 - ETA: 5:03 - loss: 3.6195 - accuracy: 0.09 - ETA: 5:00 - loss: 3.6170 - accuracy: 0.09 - ETA: 5:01 - loss: 3.6099 - accuracy: 0.09 - ETA: 4:59 - loss: 3.6050 - accuracy: 0.09 - ETA: 4:57 - loss: 3.6028 - accuracy: 0.09 - ETA: 4:56 - loss: 3.6022 - accuracy: 0.09 - ETA: 4:55 - loss: 3.6035 - accuracy: 0.10 - ETA: 4:54 - loss: 3.6013 - accuracy: 0.09 - ETA: 4:53 - loss: 3.6042 - accuracy: 0.09 - ETA: 4:53 - loss: 3.6078 - accuracy: 0.09 - ETA: 4:53 - loss: 3.6080 - accuracy: 0.09 - ETA: 4:52 - loss: 3.6083 - accuracy: 0.09 - ETA: 4:51 - loss: 3.6119 - accuracy: 0.09 - ETA: 4:51 - loss: 3.6108 - accuracy: 0.09 - ETA: 4:49 - loss: 3.6127 - accuracy: 0.09 - ETA: 4:48 - loss: 3.6107 - accuracy: 0.09 - ETA: 4:47 - loss: 3.6133 - accuracy: 0.09 - ETA: 4:45 - loss: 3.6087 - accuracy: 0.09 - ETA: 4:44 - loss: 3.6079 - accuracy: 0.09 - ETA: 4:43 - loss: 3.6064 - accuracy: 0.09 - ETA: 4:43 - loss: 3.6027 - accuracy: 0.09 - ETA: 4:42 - loss: 3.6022 - accuracy: 0.09 - ETA: 4:41 - loss: 3.6010 - accuracy: 0.09 - ETA: 4:40 - loss: 3.5990 - accuracy: 0.09 - ETA: 4:40 - loss: 3.5974 - accuracy: 0.09 - ETA: 4:39 - loss: 3.5927 - accuracy: 0.09 - ETA: 4:38 - loss: 3.5936 - accuracy: 0.09 - ETA: 4:37 - loss: 3.5997 - accuracy: 0.09 - ETA: 4:36 - loss: 3.6082 - accuracy: 0.09 - ETA: 4:36 - loss: 3.6181 - accuracy: 0.09 - ETA: 4:34 - loss: 3.6438 - accuracy: 0.09 - ETA: 4:33 - loss: 3.6431 - accuracy: 0.09 - ETA: 4:32 - loss: 3.6448 - accuracy: 0.09 - ETA: 4:31 - loss: 3.6448 - accuracy: 0.09 - ETA: 4:30 - loss: 3.6444 - accuracy: 0.09 - ETA: 4:29 - loss: 3.6389 - accuracy: 0.09 - ETA: 4:28 - loss: 3.6388 - accuracy: 0.09 - ETA: 4:27 - loss: 3.6385 - accuracy: 0.09 - ETA: 4:26 - loss: 3.6389 - accuracy: 0.09 - ETA: 4:24 - loss: 3.6382 - accuracy: 0.09 - ETA: 4:23 - loss: 3.6339 - accuracy: 0.09 - ETA: 4:22 - loss: 3.6313 - accuracy: 0.09 - ETA: 4:21 - loss: 3.6320 - accuracy: 0.09 - ETA: 4:20 - loss: 3.6280 - accuracy: 0.09 - ETA: 4:18 - loss: 3.6254 - accuracy: 0.09 - ETA: 4:18 - loss: 3.6242 - accuracy: 0.09 - ETA: 4:17 - loss: 3.6257 - accuracy: 0.09 - ETA: 4:16 - loss: 3.6257 - accuracy: 0.09 - ETA: 4:15 - loss: 3.6254 - accuracy: 0.09 - ETA: 4:14 - loss: 3.6256 - accuracy: 0.09 - ETA: 4:13 - loss: 3.6256 - accuracy: 0.09 - ETA: 4:13 - loss: 3.6252 - accuracy: 0.09 - ETA: 4:12 - loss: 3.6232 - accuracy: 0.09 - ETA: 4:11 - loss: 3.6247 - accuracy: 0.09 - ETA: 4:09 - loss: 3.6214 - accuracy: 0.09 - ETA: 4:08 - loss: 3.6214 - accuracy: 0.09 - ETA: 4:07 - loss: 3.6220 - accuracy: 0.09 - ETA: 4:07 - loss: 3.6227 - accuracy: 0.09 - ETA: 4:06 - loss: 3.6222 - accuracy: 0.09 - ETA: 4:04 - loss: 3.6236 - accuracy: 0.09 - ETA: 4:03 - loss: 3.6248 - accuracy: 0.09 - ETA: 4:02 - loss: 3.6234 - accuracy: 0.09 - ETA: 4:01 - loss: 3.6225 - accuracy: 0.09 - ETA: 4:00 - loss: 3.6210 - accuracy: 0.09 - ETA: 3:59 - loss: 3.6224 - accuracy: 0.09 - ETA: 3:58 - loss: 3.6217 - accuracy: 0.09 - ETA: 3:58 - loss: 3.6214 - accuracy: 0.09 - ETA: 3:57 - loss: 3.6197 - accuracy: 0.09 - ETA: 3:55 - loss: 3.6200 - accuracy: 0.09 - ETA: 3:54 - loss: 3.6196 - accuracy: 0.09 - ETA: 3:53 - loss: 3.6185 - accuracy: 0.09 - ETA: 3:52 - loss: 3.6195 - accuracy: 0.09 - ETA: 3:51 - loss: 3.6185 - accuracy: 0.09 - ETA: 3:50 - loss: 3.6181 - accuracy: 0.09 - ETA: 3:49 - loss: 3.6192 - accuracy: 0.09 - ETA: 3:48 - loss: 3.6198 - accuracy: 0.09 - ETA: 3:47 - loss: 3.6192 - accuracy: 0.09 - ETA: 3:46 - loss: 3.6193 - accuracy: 0.09 - ETA: 3:46 - loss: 3.6195 - accuracy: 0.09 - ETA: 3:45 - loss: 3.6186 - accuracy: 0.09 - ETA: 3:44 - loss: 3.6184 - accuracy: 0.09 - ETA: 3:43 - loss: 3.6172 - accuracy: 0.09 - ETA: 3:42 - loss: 3.6166 - accuracy: 0.09 - ETA: 3:41 - loss: 3.6165 - accuracy: 0.09 - ETA: 3:40 - loss: 3.6156 - accuracy: 0.09 - ETA: 3:39 - loss: 3.6147 - accuracy: 0.09 - ETA: 3:38 - loss: 3.6139 - accuracy: 0.09 - ETA: 3:37 - loss: 3.6133 - accuracy: 0.09 - ETA: 3:36 - loss: 3.6130 - accuracy: 0.09 - ETA: 3:35 - loss: 3.6141 - accuracy: 0.09 - ETA: 3:35 - loss: 3.6143 - accuracy: 0.09 - ETA: 3:34 - loss: 3.6143 - accuracy: 0.09 - ETA: 3:33 - loss: 3.6137 - accuracy: 0.09 - ETA: 3:32 - loss: 3.6144 - accuracy: 0.09 - ETA: 3:31 - loss: 3.6134 - accuracy: 0.09 - ETA: 3:30 - loss: 3.6122 - accuracy: 0.09 - ETA: 3:30 - loss: 3.6121 - accuracy: 0.09 - ETA: 3:29 - loss: 3.6120 - accuracy: 0.09 - ETA: 3:28 - loss: 3.6120 - accuracy: 0.09 - ETA: 3:27 - loss: 3.6115 - accuracy: 0.09 - ETA: 3:26 - loss: 3.6091 - accuracy: 0.09 - ETA: 3:25 - loss: 3.6092 - accuracy: 0.09 - ETA: 3:24 - loss: 3.6094 - accuracy: 0.09 - ETA: 3:23 - loss: 3.6080 - accuracy: 0.09 - ETA: 3:22 - loss: 3.6074 - accuracy: 0.09 - ETA: 3:21 - loss: 3.6073 - accuracy: 0.09 - ETA: 3:20 - loss: 3.6068 - accuracy: 0.09 - ETA: 3:19 - loss: 3.6064 - accuracy: 0.09 - ETA: 3:18 - loss: 3.6061 - accuracy: 0.09 - ETA: 3:17 - loss: 3.6050 - accuracy: 0.09 - ETA: 3:16 - loss: 3.6056 - accuracy: 0.09 - ETA: 3:15 - loss: 3.6039 - accuracy: 0.09 - ETA: 3:14 - loss: 3.6042 - accuracy: 0.09 - ETA: 3:13 - loss: 3.6036 - accuracy: 0.09 - ETA: 3:12 - loss: 3.6032 - accuracy: 0.09 - ETA: 3:11 - loss: 3.6025 - accuracy: 0.09 - ETA: 3:10 - loss: 3.6022 - accuracy: 0.09 - ETA: 3:09 - loss: 3.6020 - accuracy: 0.09 - ETA: 3:08 - loss: 3.6018 - accuracy: 0.09 - ETA: 3:07 - loss: 3.6005 - accuracy: 0.09 - ETA: 3:06 - loss: 3.6001 - accuracy: 0.09 - ETA: 3:05 - loss: 3.5972 - accuracy: 0.09 - ETA: 3:04 - loss: 3.5969 - accuracy: 0.09 - ETA: 3:03 - loss: 3.5971 - accuracy: 0.09 - ETA: 3:02 - loss: 3.5955 - accuracy: 0.09 - ETA: 3:02 - loss: 3.5949 - accuracy: 0.09 - ETA: 3:01 - loss: 3.5955 - accuracy: 0.09 - ETA: 3:00 - loss: 3.5947 - accuracy: 0.09 - ETA: 2:59 - loss: 3.5957 - accuracy: 0.09 - ETA: 2:58 - loss: 3.5949 - accuracy: 0.09 - ETA: 2:57 - loss: 3.5944 - accuracy: 0.09 - ETA: 2:56 - loss: 3.5940 - accuracy: 0.09 - ETA: 2:55 - loss: 3.5928 - accuracy: 0.09 - ETA: 2:54 - loss: 3.5936 - accuracy: 0.09 - ETA: 2:53 - loss: 3.5931 - accuracy: 0.09 - ETA: 2:52 - loss: 3.5922 - accuracy: 0.09 - ETA: 2:51 - loss: 3.5923 - accuracy: 0.09 - ETA: 2:50 - loss: 3.5918 - accuracy: 0.09 - ETA: 2:49 - loss: 3.5917 - accuracy: 0.09 - ETA: 2:48 - loss: 3.5900 - accuracy: 0.09 - ETA: 2:47 - loss: 3.5899 - accuracy: 0.09 - ETA: 2:46 - loss: 3.5899 - accuracy: 0.09 - ETA: 2:45 - loss: 3.5883 - accuracy: 0.09 - ETA: 2:44 - loss: 3.5870 - accuracy: 0.09 - ETA: 2:43 - loss: 3.5878 - accuracy: 0.09 - ETA: 2:42 - loss: 3.5870 - accuracy: 0.09 - ETA: 2:42 - loss: 3.5872 - accuracy: 0.09 - ETA: 2:41 - loss: 3.5863 - accuracy: 0.09 - ETA: 2:40 - loss: 3.5865 - accuracy: 0.09 - ETA: 2:39 - loss: 3.5864 - accuracy: 0.09 - ETA: 2:38 - loss: 3.5865 - accuracy: 0.09 - ETA: 2:37 - loss: 3.5861 - accuracy: 0.09 - ETA: 2:36 - loss: 3.5859 - accuracy: 0.09 - ETA: 2:35 - loss: 3.5856 - accuracy: 0.09 - ETA: 2:34 - loss: 3.5851 - accuracy: 0.09 - ETA: 2:33 - loss: 3.5840 - accuracy: 0.09 - ETA: 2:32 - loss: 3.5834 - accuracy: 0.09 - ETA: 2:31 - loss: 3.5834 - accuracy: 0.09 - ETA: 2:30 - loss: 3.5825 - accuracy: 0.09 - ETA: 2:29 - loss: 3.5822 - accuracy: 0.09 - ETA: 2:28 - loss: 3.5829 - accuracy: 0.09 - ETA: 2:27 - loss: 3.5824 - accuracy: 0.09 - ETA: 2:27 - loss: 3.5814 - accuracy: 0.09 - ETA: 2:26 - loss: 3.5812 - accuracy: 0.09 - ETA: 2:25 - loss: 3.5810 - accuracy: 0.09 - ETA: 2:24 - loss: 3.5805 - accuracy: 0.09 - ETA: 2:23 - loss: 3.5796 - accuracy: 0.09 - ETA: 2:22 - loss: 3.5787 - accuracy: 0.09 - ETA: 2:21 - loss: 3.5779 - accuracy: 0.09 - ETA: 2:20 - loss: 3.5778 - accuracy: 0.09 - ETA: 2:19 - loss: 3.5764 - accuracy: 0.09 - ETA: 2:18 - loss: 3.5754 - accuracy: 0.0962"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.5757 - accuracy: 0.09 - ETA: 2:16 - loss: 3.5772 - accuracy: 0.09 - ETA: 2:15 - loss: 3.5771 - accuracy: 0.09 - ETA: 2:14 - loss: 3.5773 - accuracy: 0.09 - ETA: 2:13 - loss: 3.5780 - accuracy: 0.09 - ETA: 2:12 - loss: 3.5800 - accuracy: 0.09 - ETA: 2:11 - loss: 3.5813 - accuracy: 0.09 - ETA: 2:10 - loss: 3.5830 - accuracy: 0.09 - ETA: 2:09 - loss: 3.5852 - accuracy: 0.09 - ETA: 2:08 - loss: 3.5861 - accuracy: 0.09 - ETA: 2:07 - loss: 3.5859 - accuracy: 0.09 - ETA: 2:06 - loss: 3.5862 - accuracy: 0.09 - ETA: 2:05 - loss: 3.5864 - accuracy: 0.09 - ETA: 2:05 - loss: 3.5864 - accuracy: 0.09 - ETA: 2:04 - loss: 3.5864 - accuracy: 0.09 - ETA: 2:03 - loss: 3.5861 - accuracy: 0.09 - ETA: 2:02 - loss: 3.5867 - accuracy: 0.09 - ETA: 2:01 - loss: 3.5864 - accuracy: 0.09 - ETA: 2:00 - loss: 3.5868 - accuracy: 0.09 - ETA: 1:59 - loss: 3.5864 - accuracy: 0.09 - ETA: 1:58 - loss: 3.5866 - accuracy: 0.09 - ETA: 1:57 - loss: 3.5866 - accuracy: 0.09 - ETA: 1:56 - loss: 3.5864 - accuracy: 0.09 - ETA: 1:55 - loss: 3.5864 - accuracy: 0.09 - ETA: 1:54 - loss: 3.5858 - accuracy: 0.09 - ETA: 1:53 - loss: 3.5860 - accuracy: 0.09 - ETA: 1:52 - loss: 3.5864 - accuracy: 0.09 - ETA: 1:51 - loss: 3.5869 - accuracy: 0.09 - ETA: 1:50 - loss: 3.5865 - accuracy: 0.09 - ETA: 1:49 - loss: 3.5851 - accuracy: 0.09 - ETA: 1:48 - loss: 3.5850 - accuracy: 0.09 - ETA: 1:47 - loss: 3.5847 - accuracy: 0.09 - ETA: 1:46 - loss: 3.5841 - accuracy: 0.09 - ETA: 1:45 - loss: 3.5834 - accuracy: 0.09 - ETA: 1:44 - loss: 3.5832 - accuracy: 0.09 - ETA: 1:43 - loss: 3.5830 - accuracy: 0.09 - ETA: 1:43 - loss: 3.5828 - accuracy: 0.09 - ETA: 1:42 - loss: 3.5823 - accuracy: 0.09 - ETA: 1:41 - loss: 3.5822 - accuracy: 0.09 - ETA: 1:40 - loss: 3.5822 - accuracy: 0.09 - ETA: 1:39 - loss: 3.5819 - accuracy: 0.09 - ETA: 1:38 - loss: 3.5818 - accuracy: 0.09 - ETA: 1:37 - loss: 3.5818 - accuracy: 0.09 - ETA: 1:36 - loss: 3.5816 - accuracy: 0.09 - ETA: 1:35 - loss: 3.5812 - accuracy: 0.09 - ETA: 1:34 - loss: 3.5815 - accuracy: 0.09 - ETA: 1:33 - loss: 3.5815 - accuracy: 0.09 - ETA: 1:32 - loss: 3.5811 - accuracy: 0.09 - ETA: 1:31 - loss: 3.5796 - accuracy: 0.09 - ETA: 1:30 - loss: 3.5793 - accuracy: 0.09 - ETA: 1:29 - loss: 3.5791 - accuracy: 0.09 - ETA: 1:28 - loss: 3.5782 - accuracy: 0.09 - ETA: 1:27 - loss: 3.5785 - accuracy: 0.09 - ETA: 1:26 - loss: 3.5772 - accuracy: 0.09 - ETA: 1:25 - loss: 3.5775 - accuracy: 0.09 - ETA: 1:25 - loss: 3.5778 - accuracy: 0.09 - ETA: 1:24 - loss: 3.5779 - accuracy: 0.09 - ETA: 1:23 - loss: 3.5780 - accuracy: 0.09 - ETA: 1:22 - loss: 3.5778 - accuracy: 0.09 - ETA: 1:21 - loss: 3.5781 - accuracy: 0.09 - ETA: 1:20 - loss: 3.5778 - accuracy: 0.09 - ETA: 1:19 - loss: 3.5771 - accuracy: 0.09 - ETA: 1:18 - loss: 3.5771 - accuracy: 0.09 - ETA: 1:17 - loss: 3.5769 - accuracy: 0.09 - ETA: 1:16 - loss: 3.5762 - accuracy: 0.09 - ETA: 1:15 - loss: 3.5766 - accuracy: 0.09 - ETA: 1:14 - loss: 3.5762 - accuracy: 0.09 - ETA: 1:13 - loss: 3.5758 - accuracy: 0.09 - ETA: 1:12 - loss: 3.5757 - accuracy: 0.09 - ETA: 1:11 - loss: 3.5757 - accuracy: 0.09 - ETA: 1:10 - loss: 3.5754 - accuracy: 0.09 - ETA: 1:09 - loss: 3.5748 - accuracy: 0.09 - ETA: 1:08 - loss: 3.5746 - accuracy: 0.09 - ETA: 1:07 - loss: 3.5746 - accuracy: 0.09 - ETA: 1:06 - loss: 3.5748 - accuracy: 0.09 - ETA: 1:05 - loss: 3.5745 - accuracy: 0.09 - ETA: 1:04 - loss: 3.5744 - accuracy: 0.09 - ETA: 1:04 - loss: 3.5734 - accuracy: 0.09 - ETA: 1:03 - loss: 3.5732 - accuracy: 0.09 - ETA: 1:02 - loss: 3.5724 - accuracy: 0.09 - ETA: 1:01 - loss: 3.5723 - accuracy: 0.09 - ETA: 1:00 - loss: 3.5723 - accuracy: 0.09 - ETA: 59s - loss: 3.5722 - accuracy: 0.0978 - ETA: 58s - loss: 3.5721 - accuracy: 0.097 - ETA: 57s - loss: 3.5721 - accuracy: 0.097 - ETA: 56s - loss: 3.5721 - accuracy: 0.097 - ETA: 55s - loss: 3.5715 - accuracy: 0.098 - ETA: 54s - loss: 3.5710 - accuracy: 0.098 - ETA: 53s - loss: 3.5711 - accuracy: 0.098 - ETA: 52s - loss: 3.5707 - accuracy: 0.098 - ETA: 51s - loss: 3.5707 - accuracy: 0.098 - ETA: 50s - loss: 3.5706 - accuracy: 0.098 - ETA: 49s - loss: 3.5704 - accuracy: 0.098 - ETA: 48s - loss: 3.5704 - accuracy: 0.098 - ETA: 47s - loss: 3.5703 - accuracy: 0.098 - ETA: 46s - loss: 3.5697 - accuracy: 0.098 - ETA: 45s - loss: 3.5697 - accuracy: 0.098 - ETA: 44s - loss: 3.5697 - accuracy: 0.098 - ETA: 43s - loss: 3.5697 - accuracy: 0.098 - ETA: 43s - loss: 3.5692 - accuracy: 0.098 - ETA: 42s - loss: 3.5693 - accuracy: 0.098 - ETA: 41s - loss: 3.5696 - accuracy: 0.098 - ETA: 40s - loss: 3.5695 - accuracy: 0.098 - ETA: 39s - loss: 3.5695 - accuracy: 0.098 - ETA: 38s - loss: 3.5686 - accuracy: 0.098 - ETA: 37s - loss: 3.5681 - accuracy: 0.098 - ETA: 36s - loss: 3.5677 - accuracy: 0.098 - ETA: 35s - loss: 3.5671 - accuracy: 0.099 - ETA: 34s - loss: 3.5667 - accuracy: 0.099 - ETA: 33s - loss: 3.5662 - accuracy: 0.099 - ETA: 32s - loss: 3.5660 - accuracy: 0.099 - ETA: 31s - loss: 3.5659 - accuracy: 0.099 - ETA: 30s - loss: 3.5661 - accuracy: 0.099 - ETA: 29s - loss: 3.5659 - accuracy: 0.099 - ETA: 28s - loss: 3.5659 - accuracy: 0.099 - ETA: 27s - loss: 3.5661 - accuracy: 0.099 - ETA: 26s - loss: 3.5657 - accuracy: 0.099 - ETA: 25s - loss: 3.5662 - accuracy: 0.099 - ETA: 24s - loss: 3.5657 - accuracy: 0.099 - ETA: 23s - loss: 3.5663 - accuracy: 0.099 - ETA: 22s - loss: 3.5664 - accuracy: 0.099 - ETA: 22s - loss: 3.5658 - accuracy: 0.099 - ETA: 21s - loss: 3.5659 - accuracy: 0.099 - ETA: 20s - loss: 3.5653 - accuracy: 0.099 - ETA: 19s - loss: 3.5657 - accuracy: 0.099 - ETA: 18s - loss: 3.5652 - accuracy: 0.099 - ETA: 17s - loss: 3.5652 - accuracy: 0.099 - ETA: 16s - loss: 3.5651 - accuracy: 0.099 - ETA: 15s - loss: 3.5649 - accuracy: 0.099 - ETA: 14s - loss: 3.5648 - accuracy: 0.099 - ETA: 13s - loss: 3.5645 - accuracy: 0.099 - ETA: 12s - loss: 3.5643 - accuracy: 0.099 - ETA: 11s - loss: 3.5642 - accuracy: 0.099 - ETA: 10s - loss: 3.5639 - accuracy: 0.099 - ETA: 9s - loss: 3.5633 - accuracy: 0.100 - ETA: 8s - loss: 3.5628 - accuracy: 0.10 - ETA: 7s - loss: 3.5623 - accuracy: 0.10 - ETA: 6s - loss: 3.5620 - accuracy: 0.10 - ETA: 5s - loss: 3.5618 - accuracy: 0.10 - ETA: 4s - loss: 3.5615 - accuracy: 0.10 - ETA: 3s - loss: 3.5611 - accuracy: 0.10 - ETA: 2s - loss: 3.5624 - accuracy: 0.10 - ETA: 1s - loss: 3.5627 - accuracy: 0.10 - ETA: 1s - loss: 3.5627 - accuracy: 0.10 - ETA: 0s - loss: 3.5624 - accuracy: 0.10 - 341s 8ms/step - loss: 3.5624 - accuracy: 0.1002 - val_loss: 3.9602 - val_accuracy: 0.0085\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:35 - loss: 3.3837 - accuracy: 0.10 - ETA: 5:28 - loss: 3.4429 - accuracy: 0.10 - ETA: 5:16 - loss: 3.4842 - accuracy: 0.10 - ETA: 5:15 - loss: 3.4603 - accuracy: 0.10 - ETA: 5:10 - loss: 3.4719 - accuracy: 0.11 - ETA: 5:08 - loss: 3.4641 - accuracy: 0.10 - ETA: 5:10 - loss: 3.4637 - accuracy: 0.10 - ETA: 5:10 - loss: 3.4703 - accuracy: 0.10 - ETA: 5:10 - loss: 3.4623 - accuracy: 0.11 - ETA: 5:12 - loss: 3.4578 - accuracy: 0.11 - ETA: 5:13 - loss: 3.4647 - accuracy: 0.11 - ETA: 5:10 - loss: 3.4760 - accuracy: 0.10 - ETA: 5:09 - loss: 3.4854 - accuracy: 0.10 - ETA: 5:06 - loss: 3.4843 - accuracy: 0.10 - ETA: 5:04 - loss: 3.4797 - accuracy: 0.10 - ETA: 5:03 - loss: 3.4774 - accuracy: 0.10 - ETA: 5:03 - loss: 3.4726 - accuracy: 0.10 - ETA: 5:01 - loss: 3.4743 - accuracy: 0.10 - ETA: 5:01 - loss: 3.4744 - accuracy: 0.10 - ETA: 5:00 - loss: 3.4879 - accuracy: 0.10 - ETA: 4:59 - loss: 3.4823 - accuracy: 0.10 - ETA: 4:59 - loss: 3.4845 - accuracy: 0.10 - ETA: 4:57 - loss: 3.4869 - accuracy: 0.10 - ETA: 4:56 - loss: 3.4854 - accuracy: 0.10 - ETA: 4:55 - loss: 3.4838 - accuracy: 0.10 - ETA: 4:54 - loss: 3.4867 - accuracy: 0.10 - ETA: 4:54 - loss: 3.4888 - accuracy: 0.10 - ETA: 4:53 - loss: 3.4880 - accuracy: 0.10 - ETA: 4:51 - loss: 3.4904 - accuracy: 0.10 - ETA: 4:50 - loss: 3.4880 - accuracy: 0.10 - ETA: 4:49 - loss: 3.4924 - accuracy: 0.10 - ETA: 4:47 - loss: 3.5047 - accuracy: 0.10 - ETA: 4:46 - loss: 3.5002 - accuracy: 0.10 - ETA: 4:45 - loss: 3.5004 - accuracy: 0.10 - ETA: 4:43 - loss: 3.5067 - accuracy: 0.10 - ETA: 4:43 - loss: 3.5058 - accuracy: 0.10 - ETA: 4:41 - loss: 3.5057 - accuracy: 0.10 - ETA: 4:41 - loss: 3.5031 - accuracy: 0.10 - ETA: 4:39 - loss: 3.5020 - accuracy: 0.10 - ETA: 4:38 - loss: 3.5026 - accuracy: 0.10 - ETA: 4:37 - loss: 3.5001 - accuracy: 0.10 - ETA: 4:36 - loss: 3.4991 - accuracy: 0.10 - ETA: 4:35 - loss: 3.4999 - accuracy: 0.10 - ETA: 4:35 - loss: 3.5008 - accuracy: 0.10 - ETA: 4:34 - loss: 3.5014 - accuracy: 0.10 - ETA: 4:33 - loss: 3.5057 - accuracy: 0.10 - ETA: 4:31 - loss: 3.5110 - accuracy: 0.10 - ETA: 4:30 - loss: 3.5185 - accuracy: 0.10 - ETA: 4:29 - loss: 3.5220 - accuracy: 0.10 - ETA: 4:28 - loss: 3.5216 - accuracy: 0.10 - ETA: 4:27 - loss: 3.5256 - accuracy: 0.10 - ETA: 4:26 - loss: 3.5251 - accuracy: 0.10 - ETA: 4:25 - loss: 3.5246 - accuracy: 0.10 - ETA: 4:24 - loss: 3.5247 - accuracy: 0.10 - ETA: 4:23 - loss: 3.5194 - accuracy: 0.10 - ETA: 4:22 - loss: 3.5180 - accuracy: 0.10 - ETA: 4:21 - loss: 3.5191 - accuracy: 0.10 - ETA: 4:21 - loss: 3.5218 - accuracy: 0.10 - ETA: 4:19 - loss: 3.5226 - accuracy: 0.10 - ETA: 4:19 - loss: 3.5236 - accuracy: 0.10 - ETA: 4:18 - loss: 3.5257 - accuracy: 0.10 - ETA: 4:17 - loss: 3.5297 - accuracy: 0.10 - ETA: 4:16 - loss: 3.5288 - accuracy: 0.10 - ETA: 4:14 - loss: 3.5324 - accuracy: 0.10 - ETA: 4:13 - loss: 3.5346 - accuracy: 0.10 - ETA: 4:12 - loss: 3.5329 - accuracy: 0.10 - ETA: 4:11 - loss: 3.5347 - accuracy: 0.10 - ETA: 4:10 - loss: 3.5359 - accuracy: 0.10 - ETA: 4:10 - loss: 3.5386 - accuracy: 0.10 - ETA: 4:09 - loss: 3.5402 - accuracy: 0.10 - ETA: 4:08 - loss: 3.5392 - accuracy: 0.10 - ETA: 4:07 - loss: 3.5408 - accuracy: 0.10 - ETA: 4:06 - loss: 3.5408 - accuracy: 0.10 - ETA: 4:05 - loss: 3.5410 - accuracy: 0.10 - ETA: 4:04 - loss: 3.5402 - accuracy: 0.10 - ETA: 4:03 - loss: 3.5398 - accuracy: 0.10 - ETA: 4:01 - loss: 3.5439 - accuracy: 0.10 - ETA: 4:01 - loss: 3.5435 - accuracy: 0.10 - ETA: 4:00 - loss: 3.5425 - accuracy: 0.10 - ETA: 3:59 - loss: 3.5420 - accuracy: 0.10 - ETA: 3:58 - loss: 3.5428 - accuracy: 0.10 - ETA: 3:57 - loss: 3.5410 - accuracy: 0.10 - ETA: 3:56 - loss: 3.5418 - accuracy: 0.10 - ETA: 3:55 - loss: 3.5426 - accuracy: 0.10 - ETA: 3:54 - loss: 3.5421 - accuracy: 0.10 - ETA: 3:53 - loss: 3.5433 - accuracy: 0.10 - ETA: 3:52 - loss: 3.5440 - accuracy: 0.10 - ETA: 3:52 - loss: 3.5437 - accuracy: 0.10 - ETA: 3:51 - loss: 3.5438 - accuracy: 0.10 - ETA: 3:50 - loss: 3.5439 - accuracy: 0.10 - ETA: 3:49 - loss: 3.5448 - accuracy: 0.10 - ETA: 3:48 - loss: 3.5455 - accuracy: 0.09 - ETA: 3:47 - loss: 3.5443 - accuracy: 0.10 - ETA: 3:46 - loss: 3.5419 - accuracy: 0.10 - ETA: 3:45 - loss: 3.5424 - accuracy: 0.10 - ETA: 3:44 - loss: 3.5426 - accuracy: 0.10 - ETA: 3:43 - loss: 3.5423 - accuracy: 0.10 - ETA: 3:42 - loss: 3.5427 - accuracy: 0.10 - ETA: 3:41 - loss: 3.5436 - accuracy: 0.10 - ETA: 3:40 - loss: 3.5448 - accuracy: 0.09 - ETA: 3:39 - loss: 3.5438 - accuracy: 0.09 - ETA: 3:38 - loss: 3.5449 - accuracy: 0.09 - ETA: 3:37 - loss: 3.5436 - accuracy: 0.09 - ETA: 3:37 - loss: 3.5444 - accuracy: 0.09 - ETA: 3:36 - loss: 3.5455 - accuracy: 0.09 - ETA: 3:35 - loss: 3.5459 - accuracy: 0.09 - ETA: 3:34 - loss: 3.5464 - accuracy: 0.09 - ETA: 3:33 - loss: 3.5473 - accuracy: 0.09 - ETA: 3:32 - loss: 3.5475 - accuracy: 0.09 - ETA: 3:31 - loss: 3.5476 - accuracy: 0.09 - ETA: 3:30 - loss: 3.5497 - accuracy: 0.09 - ETA: 3:29 - loss: 3.5503 - accuracy: 0.09 - ETA: 3:28 - loss: 3.5497 - accuracy: 0.09 - ETA: 3:27 - loss: 3.5493 - accuracy: 0.09 - ETA: 3:26 - loss: 3.5489 - accuracy: 0.09 - ETA: 3:25 - loss: 3.5491 - accuracy: 0.09 - ETA: 3:24 - loss: 3.5494 - accuracy: 0.09 - ETA: 3:23 - loss: 3.5497 - accuracy: 0.09 - ETA: 3:22 - loss: 3.5505 - accuracy: 0.09 - ETA: 3:21 - loss: 3.5493 - accuracy: 0.09 - ETA: 3:20 - loss: 3.5494 - accuracy: 0.09 - ETA: 3:19 - loss: 3.5486 - accuracy: 0.09 - ETA: 3:18 - loss: 3.5494 - accuracy: 0.09 - ETA: 3:17 - loss: 3.5489 - accuracy: 0.09 - ETA: 3:16 - loss: 3.5492 - accuracy: 0.09 - ETA: 3:15 - loss: 3.5495 - accuracy: 0.09 - ETA: 3:14 - loss: 3.5493 - accuracy: 0.09 - ETA: 3:13 - loss: 3.5495 - accuracy: 0.09 - ETA: 3:12 - loss: 3.5489 - accuracy: 0.09 - ETA: 3:11 - loss: 3.5478 - accuracy: 0.09 - ETA: 3:10 - loss: 3.5484 - accuracy: 0.09 - ETA: 3:09 - loss: 3.5489 - accuracy: 0.09 - ETA: 3:08 - loss: 3.5489 - accuracy: 0.09 - ETA: 3:07 - loss: 3.5495 - accuracy: 0.09 - ETA: 3:06 - loss: 3.5490 - accuracy: 0.09 - ETA: 3:05 - loss: 3.5482 - accuracy: 0.09 - ETA: 3:04 - loss: 3.5472 - accuracy: 0.09 - ETA: 3:03 - loss: 3.5472 - accuracy: 0.09 - ETA: 3:02 - loss: 3.5466 - accuracy: 0.09 - ETA: 3:01 - loss: 3.5468 - accuracy: 0.09 - ETA: 3:01 - loss: 3.5467 - accuracy: 0.09 - ETA: 3:00 - loss: 3.5462 - accuracy: 0.09 - ETA: 2:59 - loss: 3.5455 - accuracy: 0.09 - ETA: 2:58 - loss: 3.5452 - accuracy: 0.09 - ETA: 2:57 - loss: 3.5460 - accuracy: 0.09 - ETA: 2:56 - loss: 3.5464 - accuracy: 0.09 - ETA: 2:55 - loss: 3.5459 - accuracy: 0.09 - ETA: 2:54 - loss: 3.5461 - accuracy: 0.09 - ETA: 2:53 - loss: 3.5457 - accuracy: 0.09 - ETA: 2:52 - loss: 3.5450 - accuracy: 0.09 - ETA: 2:51 - loss: 3.5457 - accuracy: 0.09 - ETA: 2:50 - loss: 3.5447 - accuracy: 0.09 - ETA: 2:49 - loss: 3.5449 - accuracy: 0.09 - ETA: 2:48 - loss: 3.5464 - accuracy: 0.09 - ETA: 2:47 - loss: 3.5457 - accuracy: 0.09 - ETA: 2:46 - loss: 3.5459 - accuracy: 0.09 - ETA: 2:45 - loss: 3.5468 - accuracy: 0.09 - ETA: 2:45 - loss: 3.5468 - accuracy: 0.09 - ETA: 2:44 - loss: 3.5471 - accuracy: 0.09 - ETA: 2:43 - loss: 3.5463 - accuracy: 0.09 - ETA: 2:42 - loss: 3.5459 - accuracy: 0.09 - ETA: 2:41 - loss: 3.5448 - accuracy: 0.09 - ETA: 2:40 - loss: 3.5448 - accuracy: 0.09 - ETA: 2:39 - loss: 3.5453 - accuracy: 0.09 - ETA: 2:38 - loss: 3.5448 - accuracy: 0.09 - ETA: 2:37 - loss: 3.5456 - accuracy: 0.09 - ETA: 2:36 - loss: 3.5458 - accuracy: 0.09 - ETA: 2:35 - loss: 3.5453 - accuracy: 0.09 - ETA: 2:34 - loss: 3.5455 - accuracy: 0.09 - ETA: 2:33 - loss: 3.5458 - accuracy: 0.09 - ETA: 2:32 - loss: 3.5463 - accuracy: 0.09 - ETA: 2:31 - loss: 3.5466 - accuracy: 0.09 - ETA: 2:30 - loss: 3.5461 - accuracy: 0.09 - ETA: 2:29 - loss: 3.5462 - accuracy: 0.09 - ETA: 2:29 - loss: 3.5466 - accuracy: 0.09 - ETA: 2:27 - loss: 3.5471 - accuracy: 0.09 - ETA: 2:27 - loss: 3.5460 - accuracy: 0.09 - ETA: 2:26 - loss: 3.5464 - accuracy: 0.09 - ETA: 2:25 - loss: 3.5463 - accuracy: 0.09 - ETA: 2:24 - loss: 3.5459 - accuracy: 0.09 - ETA: 2:23 - loss: 3.5459 - accuracy: 0.09 - ETA: 2:22 - loss: 3.5455 - accuracy: 0.09 - ETA: 2:21 - loss: 3.5449 - accuracy: 0.09 - ETA: 2:20 - loss: 3.5440 - accuracy: 0.09 - ETA: 2:19 - loss: 3.5442 - accuracy: 0.09 - ETA: 2:18 - loss: 3.5434 - accuracy: 0.0991"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.5423 - accuracy: 0.09 - ETA: 2:16 - loss: 3.5418 - accuracy: 0.09 - ETA: 2:15 - loss: 3.5423 - accuracy: 0.09 - ETA: 2:14 - loss: 3.5414 - accuracy: 0.09 - ETA: 2:13 - loss: 3.5416 - accuracy: 0.09 - ETA: 2:12 - loss: 3.5418 - accuracy: 0.09 - ETA: 2:11 - loss: 3.5417 - accuracy: 0.09 - ETA: 2:10 - loss: 3.5422 - accuracy: 0.09 - ETA: 2:09 - loss: 3.5419 - accuracy: 0.09 - ETA: 2:08 - loss: 3.5419 - accuracy: 0.09 - ETA: 2:07 - loss: 3.5416 - accuracy: 0.09 - ETA: 2:06 - loss: 3.5419 - accuracy: 0.09 - ETA: 2:05 - loss: 3.5419 - accuracy: 0.09 - ETA: 2:04 - loss: 3.5423 - accuracy: 0.09 - ETA: 2:04 - loss: 3.5427 - accuracy: 0.09 - ETA: 2:03 - loss: 3.5426 - accuracy: 0.09 - ETA: 2:02 - loss: 3.5418 - accuracy: 0.09 - ETA: 2:01 - loss: 3.5424 - accuracy: 0.09 - ETA: 2:00 - loss: 3.5430 - accuracy: 0.09 - ETA: 1:59 - loss: 3.5431 - accuracy: 0.09 - ETA: 1:58 - loss: 3.5428 - accuracy: 0.09 - ETA: 1:57 - loss: 3.5429 - accuracy: 0.09 - ETA: 1:56 - loss: 3.5431 - accuracy: 0.09 - ETA: 1:55 - loss: 3.5421 - accuracy: 0.09 - ETA: 1:54 - loss: 3.5421 - accuracy: 0.09 - ETA: 1:53 - loss: 3.5423 - accuracy: 0.09 - ETA: 1:52 - loss: 3.5423 - accuracy: 0.09 - ETA: 1:51 - loss: 3.5416 - accuracy: 0.09 - ETA: 1:50 - loss: 3.5412 - accuracy: 0.09 - ETA: 1:49 - loss: 3.5411 - accuracy: 0.09 - ETA: 1:48 - loss: 3.5408 - accuracy: 0.09 - ETA: 1:47 - loss: 3.5405 - accuracy: 0.09 - ETA: 1:46 - loss: 3.5408 - accuracy: 0.09 - ETA: 1:45 - loss: 3.5409 - accuracy: 0.09 - ETA: 1:44 - loss: 3.5410 - accuracy: 0.09 - ETA: 1:43 - loss: 3.5412 - accuracy: 0.09 - ETA: 1:42 - loss: 3.5412 - accuracy: 0.09 - ETA: 1:41 - loss: 3.5408 - accuracy: 0.09 - ETA: 1:41 - loss: 3.5398 - accuracy: 0.09 - ETA: 1:40 - loss: 3.5396 - accuracy: 0.09 - ETA: 1:39 - loss: 3.5412 - accuracy: 0.09 - ETA: 1:38 - loss: 3.5406 - accuracy: 0.10 - ETA: 1:37 - loss: 3.5405 - accuracy: 0.10 - ETA: 1:36 - loss: 3.5402 - accuracy: 0.10 - ETA: 1:35 - loss: 3.5400 - accuracy: 0.10 - ETA: 1:34 - loss: 3.5396 - accuracy: 0.10 - ETA: 1:33 - loss: 3.5395 - accuracy: 0.10 - ETA: 1:32 - loss: 3.5397 - accuracy: 0.10 - ETA: 1:31 - loss: 3.5398 - accuracy: 0.10 - ETA: 1:30 - loss: 3.5397 - accuracy: 0.10 - ETA: 1:29 - loss: 3.5394 - accuracy: 0.10 - ETA: 1:28 - loss: 3.5393 - accuracy: 0.10 - ETA: 1:27 - loss: 3.5393 - accuracy: 0.10 - ETA: 1:26 - loss: 3.5395 - accuracy: 0.10 - ETA: 1:25 - loss: 3.5389 - accuracy: 0.10 - ETA: 1:24 - loss: 3.5387 - accuracy: 0.10 - ETA: 1:23 - loss: 3.5382 - accuracy: 0.10 - ETA: 1:23 - loss: 3.5383 - accuracy: 0.10 - ETA: 1:22 - loss: 3.5378 - accuracy: 0.10 - ETA: 1:21 - loss: 3.5377 - accuracy: 0.10 - ETA: 1:20 - loss: 3.5369 - accuracy: 0.10 - ETA: 1:19 - loss: 3.5366 - accuracy: 0.10 - ETA: 1:18 - loss: 3.5367 - accuracy: 0.10 - ETA: 1:17 - loss: 3.5365 - accuracy: 0.10 - ETA: 1:16 - loss: 3.5366 - accuracy: 0.10 - ETA: 1:15 - loss: 3.5359 - accuracy: 0.10 - ETA: 1:14 - loss: 3.5359 - accuracy: 0.10 - ETA: 1:13 - loss: 3.5363 - accuracy: 0.10 - ETA: 1:12 - loss: 3.5364 - accuracy: 0.10 - ETA: 1:11 - loss: 3.5392 - accuracy: 0.10 - ETA: 1:10 - loss: 3.5397 - accuracy: 0.10 - ETA: 1:09 - loss: 3.5396 - accuracy: 0.10 - ETA: 1:08 - loss: 3.5403 - accuracy: 0.10 - ETA: 1:07 - loss: 3.5403 - accuracy: 0.10 - ETA: 1:06 - loss: 3.5404 - accuracy: 0.10 - ETA: 1:05 - loss: 3.5396 - accuracy: 0.10 - ETA: 1:04 - loss: 3.5392 - accuracy: 0.10 - ETA: 1:03 - loss: 3.5388 - accuracy: 0.10 - ETA: 1:03 - loss: 3.5388 - accuracy: 0.10 - ETA: 1:02 - loss: 3.5391 - accuracy: 0.10 - ETA: 1:01 - loss: 3.5396 - accuracy: 0.10 - ETA: 1:00 - loss: 3.5404 - accuracy: 0.10 - ETA: 59s - loss: 3.5406 - accuracy: 0.1014 - ETA: 58s - loss: 3.5401 - accuracy: 0.101 - ETA: 57s - loss: 3.5405 - accuracy: 0.101 - ETA: 56s - loss: 3.5413 - accuracy: 0.101 - ETA: 55s - loss: 3.5419 - accuracy: 0.101 - ETA: 54s - loss: 3.5416 - accuracy: 0.101 - ETA: 53s - loss: 3.5418 - accuracy: 0.101 - ETA: 52s - loss: 3.5421 - accuracy: 0.100 - ETA: 51s - loss: 3.5421 - accuracy: 0.101 - ETA: 50s - loss: 3.5426 - accuracy: 0.100 - ETA: 49s - loss: 3.5425 - accuracy: 0.101 - ETA: 48s - loss: 3.5432 - accuracy: 0.100 - ETA: 47s - loss: 3.5435 - accuracy: 0.100 - ETA: 46s - loss: 3.5440 - accuracy: 0.100 - ETA: 45s - loss: 3.5438 - accuracy: 0.100 - ETA: 44s - loss: 3.5440 - accuracy: 0.100 - ETA: 43s - loss: 3.5442 - accuracy: 0.100 - ETA: 43s - loss: 3.5444 - accuracy: 0.100 - ETA: 42s - loss: 3.5445 - accuracy: 0.100 - ETA: 41s - loss: 3.5443 - accuracy: 0.100 - ETA: 40s - loss: 3.5445 - accuracy: 0.100 - ETA: 39s - loss: 3.5445 - accuracy: 0.100 - ETA: 38s - loss: 3.5447 - accuracy: 0.100 - ETA: 37s - loss: 3.5450 - accuracy: 0.100 - ETA: 36s - loss: 3.5456 - accuracy: 0.100 - ETA: 35s - loss: 3.5461 - accuracy: 0.100 - ETA: 34s - loss: 3.5464 - accuracy: 0.099 - ETA: 33s - loss: 3.5466 - accuracy: 0.099 - ETA: 32s - loss: 3.5467 - accuracy: 0.099 - ETA: 31s - loss: 3.5472 - accuracy: 0.099 - ETA: 30s - loss: 3.5473 - accuracy: 0.099 - ETA: 29s - loss: 3.5475 - accuracy: 0.099 - ETA: 28s - loss: 3.5477 - accuracy: 0.099 - ETA: 27s - loss: 3.5478 - accuracy: 0.099 - ETA: 26s - loss: 3.5475 - accuracy: 0.099 - ETA: 25s - loss: 3.5474 - accuracy: 0.099 - ETA: 24s - loss: 3.5476 - accuracy: 0.100 - ETA: 23s - loss: 3.5472 - accuracy: 0.100 - ETA: 22s - loss: 3.5476 - accuracy: 0.100 - ETA: 22s - loss: 3.5476 - accuracy: 0.100 - ETA: 21s - loss: 3.5474 - accuracy: 0.100 - ETA: 20s - loss: 3.5476 - accuracy: 0.100 - ETA: 19s - loss: 3.5472 - accuracy: 0.100 - ETA: 18s - loss: 3.5476 - accuracy: 0.100 - ETA: 17s - loss: 3.5478 - accuracy: 0.100 - ETA: 16s - loss: 3.5475 - accuracy: 0.100 - ETA: 15s - loss: 3.5475 - accuracy: 0.100 - ETA: 14s - loss: 3.5476 - accuracy: 0.100 - ETA: 13s - loss: 3.5476 - accuracy: 0.100 - ETA: 12s - loss: 3.5471 - accuracy: 0.100 - ETA: 11s - loss: 3.5465 - accuracy: 0.100 - ETA: 10s - loss: 3.5467 - accuracy: 0.100 - ETA: 9s - loss: 3.5473 - accuracy: 0.100 - ETA: 8s - loss: 3.5474 - accuracy: 0.10 - ETA: 7s - loss: 3.5477 - accuracy: 0.10 - ETA: 6s - loss: 3.5477 - accuracy: 0.10 - ETA: 5s - loss: 3.5473 - accuracy: 0.10 - ETA: 4s - loss: 3.5480 - accuracy: 0.10 - ETA: 3s - loss: 3.5484 - accuracy: 0.09 - ETA: 2s - loss: 3.5482 - accuracy: 0.10 - ETA: 1s - loss: 3.5479 - accuracy: 0.10 - ETA: 1s - loss: 3.5476 - accuracy: 0.10 - ETA: 0s - loss: 3.5479 - accuracy: 0.10 - 340s 8ms/step - loss: 3.5479 - accuracy: 0.1001 - val_loss: 3.9421 - val_accuracy: 0.0112\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:27 - loss: 3.5474 - accuracy: 0.08 - ETA: 5:11 - loss: 3.5445 - accuracy: 0.10 - ETA: 5:12 - loss: 3.5759 - accuracy: 0.08 - ETA: 5:06 - loss: 3.5537 - accuracy: 0.09 - ETA: 5:01 - loss: 3.5413 - accuracy: 0.09 - ETA: 5:01 - loss: 3.5415 - accuracy: 0.10 - ETA: 4:58 - loss: 3.5544 - accuracy: 0.09 - ETA: 4:58 - loss: 3.5465 - accuracy: 0.09 - ETA: 5:01 - loss: 3.5425 - accuracy: 0.09 - ETA: 5:00 - loss: 3.5456 - accuracy: 0.10 - ETA: 5:01 - loss: 3.5485 - accuracy: 0.09 - ETA: 5:01 - loss: 3.5572 - accuracy: 0.09 - ETA: 5:01 - loss: 3.5548 - accuracy: 0.09 - ETA: 5:00 - loss: 3.5587 - accuracy: 0.09 - ETA: 5:00 - loss: 3.5592 - accuracy: 0.09 - ETA: 5:01 - loss: 3.5566 - accuracy: 0.09 - ETA: 4:59 - loss: 3.5563 - accuracy: 0.09 - ETA: 4:58 - loss: 3.5518 - accuracy: 0.09 - ETA: 4:58 - loss: 3.5443 - accuracy: 0.10 - ETA: 4:57 - loss: 3.5448 - accuracy: 0.10 - ETA: 4:57 - loss: 3.5447 - accuracy: 0.10 - ETA: 4:57 - loss: 3.5408 - accuracy: 0.10 - ETA: 4:55 - loss: 3.5358 - accuracy: 0.10 - ETA: 4:55 - loss: 3.5422 - accuracy: 0.10 - ETA: 4:53 - loss: 3.5419 - accuracy: 0.10 - ETA: 4:51 - loss: 3.5406 - accuracy: 0.10 - ETA: 4:50 - loss: 3.5466 - accuracy: 0.10 - ETA: 4:49 - loss: 3.5422 - accuracy: 0.09 - ETA: 4:47 - loss: 3.5371 - accuracy: 0.10 - ETA: 4:47 - loss: 3.5319 - accuracy: 0.10 - ETA: 4:46 - loss: 3.5301 - accuracy: 0.10 - ETA: 4:45 - loss: 3.5319 - accuracy: 0.10 - ETA: 4:44 - loss: 3.5290 - accuracy: 0.10 - ETA: 4:44 - loss: 3.5293 - accuracy: 0.10 - ETA: 4:43 - loss: 3.5281 - accuracy: 0.10 - ETA: 4:42 - loss: 3.5271 - accuracy: 0.10 - ETA: 4:41 - loss: 3.5285 - accuracy: 0.10 - ETA: 4:40 - loss: 3.5266 - accuracy: 0.10 - ETA: 4:39 - loss: 3.5276 - accuracy: 0.10 - ETA: 4:38 - loss: 3.5294 - accuracy: 0.10 - ETA: 4:38 - loss: 3.5251 - accuracy: 0.10 - ETA: 4:37 - loss: 3.5271 - accuracy: 0.10 - ETA: 4:35 - loss: 3.5312 - accuracy: 0.10 - ETA: 4:34 - loss: 3.5320 - accuracy: 0.10 - ETA: 4:32 - loss: 3.5354 - accuracy: 0.10 - ETA: 4:31 - loss: 3.5323 - accuracy: 0.10 - ETA: 4:30 - loss: 3.5297 - accuracy: 0.10 - ETA: 4:29 - loss: 3.5294 - accuracy: 0.10 - ETA: 4:28 - loss: 3.5293 - accuracy: 0.10 - ETA: 4:27 - loss: 3.5283 - accuracy: 0.10 - ETA: 4:26 - loss: 3.5267 - accuracy: 0.10 - ETA: 4:25 - loss: 3.5252 - accuracy: 0.10 - ETA: 4:24 - loss: 3.5252 - accuracy: 0.10 - ETA: 4:23 - loss: 3.5259 - accuracy: 0.10 - ETA: 4:22 - loss: 3.5275 - accuracy: 0.10 - ETA: 4:21 - loss: 3.5284 - accuracy: 0.10 - ETA: 4:20 - loss: 3.5258 - accuracy: 0.10 - ETA: 4:19 - loss: 3.5289 - accuracy: 0.10 - ETA: 4:18 - loss: 3.5282 - accuracy: 0.10 - ETA: 4:17 - loss: 3.5290 - accuracy: 0.10 - ETA: 4:16 - loss: 3.5281 - accuracy: 0.10 - ETA: 4:15 - loss: 3.5279 - accuracy: 0.10 - ETA: 4:14 - loss: 3.5284 - accuracy: 0.10 - ETA: 4:13 - loss: 3.5297 - accuracy: 0.10 - ETA: 4:12 - loss: 3.5298 - accuracy: 0.10 - ETA: 4:11 - loss: 3.5285 - accuracy: 0.10 - ETA: 4:10 - loss: 3.5288 - accuracy: 0.10 - ETA: 4:10 - loss: 3.5280 - accuracy: 0.10 - ETA: 4:09 - loss: 3.5290 - accuracy: 0.10 - ETA: 4:08 - loss: 3.5284 - accuracy: 0.10 - ETA: 4:07 - loss: 3.5286 - accuracy: 0.10 - ETA: 4:06 - loss: 3.5290 - accuracy: 0.10 - ETA: 4:05 - loss: 3.5292 - accuracy: 0.10 - ETA: 4:04 - loss: 3.5276 - accuracy: 0.10 - ETA: 4:03 - loss: 3.5261 - accuracy: 0.10 - ETA: 4:02 - loss: 3.5263 - accuracy: 0.10 - ETA: 4:01 - loss: 3.5263 - accuracy: 0.10 - ETA: 4:00 - loss: 3.5265 - accuracy: 0.10 - ETA: 4:00 - loss: 3.5241 - accuracy: 0.10 - ETA: 3:59 - loss: 3.5263 - accuracy: 0.10 - ETA: 3:58 - loss: 3.5269 - accuracy: 0.10 - ETA: 3:57 - loss: 3.5260 - accuracy: 0.10 - ETA: 3:56 - loss: 3.5232 - accuracy: 0.10 - ETA: 3:55 - loss: 3.5229 - accuracy: 0.10 - ETA: 3:54 - loss: 3.5237 - accuracy: 0.10 - ETA: 3:53 - loss: 3.5242 - accuracy: 0.10 - ETA: 3:52 - loss: 3.5238 - accuracy: 0.10 - ETA: 3:51 - loss: 3.5236 - accuracy: 0.10 - ETA: 3:50 - loss: 3.5241 - accuracy: 0.10 - ETA: 3:49 - loss: 3.5252 - accuracy: 0.10 - ETA: 3:49 - loss: 3.5250 - accuracy: 0.10 - ETA: 3:48 - loss: 3.5241 - accuracy: 0.10 - ETA: 3:47 - loss: 3.5237 - accuracy: 0.10 - ETA: 3:45 - loss: 3.5251 - accuracy: 0.10 - ETA: 3:45 - loss: 3.5253 - accuracy: 0.10 - ETA: 3:44 - loss: 3.5258 - accuracy: 0.10 - ETA: 3:43 - loss: 3.5251 - accuracy: 0.10 - ETA: 3:42 - loss: 3.5248 - accuracy: 0.10 - ETA: 3:41 - loss: 3.5242 - accuracy: 0.10 - ETA: 3:40 - loss: 3.5238 - accuracy: 0.10 - ETA: 3:39 - loss: 3.5214 - accuracy: 0.10 - ETA: 3:38 - loss: 3.5220 - accuracy: 0.10 - ETA: 3:37 - loss: 3.5218 - accuracy: 0.10 - ETA: 3:36 - loss: 3.5224 - accuracy: 0.10 - ETA: 3:35 - loss: 3.5224 - accuracy: 0.10 - ETA: 3:34 - loss: 3.5226 - accuracy: 0.10 - ETA: 3:33 - loss: 3.5230 - accuracy: 0.10 - ETA: 3:32 - loss: 3.5234 - accuracy: 0.10 - ETA: 3:31 - loss: 3.5229 - accuracy: 0.10 - ETA: 3:30 - loss: 3.5228 - accuracy: 0.10 - ETA: 3:29 - loss: 3.5237 - accuracy: 0.10 - ETA: 3:28 - loss: 3.5238 - accuracy: 0.10 - ETA: 3:27 - loss: 3.5239 - accuracy: 0.10 - ETA: 3:26 - loss: 3.5240 - accuracy: 0.10 - ETA: 3:25 - loss: 3.5243 - accuracy: 0.10 - ETA: 3:24 - loss: 3.5254 - accuracy: 0.10 - ETA: 3:23 - loss: 3.5250 - accuracy: 0.10 - ETA: 3:22 - loss: 3.5260 - accuracy: 0.10 - ETA: 3:21 - loss: 3.5273 - accuracy: 0.10 - ETA: 3:20 - loss: 3.5273 - accuracy: 0.10 - ETA: 3:19 - loss: 3.5267 - accuracy: 0.10 - ETA: 3:18 - loss: 3.5259 - accuracy: 0.10 - ETA: 3:17 - loss: 3.5257 - accuracy: 0.10 - ETA: 3:16 - loss: 3.5251 - accuracy: 0.10 - ETA: 3:15 - loss: 3.5253 - accuracy: 0.10 - ETA: 3:15 - loss: 3.5241 - accuracy: 0.10 - ETA: 3:14 - loss: 3.5221 - accuracy: 0.10 - ETA: 3:12 - loss: 3.5226 - accuracy: 0.10 - ETA: 3:11 - loss: 3.5226 - accuracy: 0.10 - ETA: 3:10 - loss: 3.5219 - accuracy: 0.10 - ETA: 3:09 - loss: 3.5222 - accuracy: 0.10 - ETA: 3:08 - loss: 3.5204 - accuracy: 0.10 - ETA: 3:07 - loss: 3.5204 - accuracy: 0.10 - ETA: 3:07 - loss: 3.5194 - accuracy: 0.10 - ETA: 3:06 - loss: 3.5191 - accuracy: 0.10 - ETA: 3:05 - loss: 3.5199 - accuracy: 0.10 - ETA: 3:04 - loss: 3.5194 - accuracy: 0.10 - ETA: 3:03 - loss: 3.5175 - accuracy: 0.10 - ETA: 3:02 - loss: 3.5171 - accuracy: 0.10 - ETA: 3:01 - loss: 3.5171 - accuracy: 0.10 - ETA: 3:00 - loss: 3.5173 - accuracy: 0.10 - ETA: 2:59 - loss: 3.5175 - accuracy: 0.10 - ETA: 2:58 - loss: 3.5175 - accuracy: 0.10 - ETA: 2:57 - loss: 3.5159 - accuracy: 0.10 - ETA: 2:56 - loss: 3.5161 - accuracy: 0.10 - ETA: 2:55 - loss: 3.5160 - accuracy: 0.10 - ETA: 2:54 - loss: 3.5158 - accuracy: 0.10 - ETA: 2:53 - loss: 3.5146 - accuracy: 0.10 - ETA: 2:52 - loss: 3.5151 - accuracy: 0.10 - ETA: 2:52 - loss: 3.5147 - accuracy: 0.10 - ETA: 2:51 - loss: 3.5148 - accuracy: 0.10 - ETA: 2:50 - loss: 3.5146 - accuracy: 0.10 - ETA: 2:49 - loss: 3.5147 - accuracy: 0.10 - ETA: 2:48 - loss: 3.5138 - accuracy: 0.10 - ETA: 2:47 - loss: 3.5138 - accuracy: 0.10 - ETA: 2:46 - loss: 3.5142 - accuracy: 0.10 - ETA: 2:45 - loss: 3.5141 - accuracy: 0.10 - ETA: 2:44 - loss: 3.5145 - accuracy: 0.10 - ETA: 2:43 - loss: 3.5149 - accuracy: 0.10 - ETA: 2:42 - loss: 3.5156 - accuracy: 0.10 - ETA: 2:41 - loss: 3.5160 - accuracy: 0.10 - ETA: 2:40 - loss: 3.5164 - accuracy: 0.10 - ETA: 2:39 - loss: 3.5167 - accuracy: 0.10 - ETA: 2:38 - loss: 3.5164 - accuracy: 0.10 - ETA: 2:37 - loss: 3.5174 - accuracy: 0.10 - ETA: 2:36 - loss: 3.5178 - accuracy: 0.10 - ETA: 2:35 - loss: 3.5176 - accuracy: 0.10 - ETA: 2:34 - loss: 3.5167 - accuracy: 0.10 - ETA: 2:34 - loss: 3.5169 - accuracy: 0.10 - ETA: 2:33 - loss: 3.5170 - accuracy: 0.10 - ETA: 2:32 - loss: 3.5175 - accuracy: 0.10 - ETA: 2:31 - loss: 3.5174 - accuracy: 0.10 - ETA: 2:30 - loss: 3.5167 - accuracy: 0.10 - ETA: 2:29 - loss: 3.5163 - accuracy: 0.10 - ETA: 2:28 - loss: 3.5163 - accuracy: 0.10 - ETA: 2:27 - loss: 3.5167 - accuracy: 0.10 - ETA: 2:26 - loss: 3.5170 - accuracy: 0.10 - ETA: 2:25 - loss: 3.5176 - accuracy: 0.10 - ETA: 2:24 - loss: 3.5170 - accuracy: 0.10 - ETA: 2:23 - loss: 3.5168 - accuracy: 0.10 - ETA: 2:22 - loss: 3.5174 - accuracy: 0.10 - ETA: 2:21 - loss: 3.5180 - accuracy: 0.10 - ETA: 2:20 - loss: 3.5186 - accuracy: 0.10 - ETA: 2:19 - loss: 3.5188 - accuracy: 0.10 - ETA: 2:18 - loss: 3.5186 - accuracy: 0.10 - ETA: 2:17 - loss: 3.5193 - accuracy: 0.1049"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:16 - loss: 3.5181 - accuracy: 0.10 - ETA: 2:15 - loss: 3.5184 - accuracy: 0.10 - ETA: 2:14 - loss: 3.5182 - accuracy: 0.10 - ETA: 2:13 - loss: 3.5184 - accuracy: 0.10 - ETA: 2:13 - loss: 3.5187 - accuracy: 0.10 - ETA: 2:12 - loss: 3.5191 - accuracy: 0.10 - ETA: 2:11 - loss: 3.5193 - accuracy: 0.10 - ETA: 2:10 - loss: 3.5193 - accuracy: 0.10 - ETA: 2:09 - loss: 3.5203 - accuracy: 0.10 - ETA: 2:08 - loss: 3.5199 - accuracy: 0.10 - ETA: 2:07 - loss: 3.5195 - accuracy: 0.10 - ETA: 2:06 - loss: 3.5189 - accuracy: 0.10 - ETA: 2:05 - loss: 3.5177 - accuracy: 0.10 - ETA: 2:04 - loss: 3.5178 - accuracy: 0.10 - ETA: 2:03 - loss: 3.5172 - accuracy: 0.10 - ETA: 2:02 - loss: 3.5179 - accuracy: 0.10 - ETA: 2:01 - loss: 3.5176 - accuracy: 0.10 - ETA: 2:00 - loss: 3.5177 - accuracy: 0.10 - ETA: 1:59 - loss: 3.5175 - accuracy: 0.10 - ETA: 1:58 - loss: 3.5173 - accuracy: 0.10 - ETA: 1:57 - loss: 3.5171 - accuracy: 0.10 - ETA: 1:56 - loss: 3.5169 - accuracy: 0.10 - ETA: 1:55 - loss: 3.5169 - accuracy: 0.10 - ETA: 1:54 - loss: 3.5172 - accuracy: 0.10 - ETA: 1:53 - loss: 3.5177 - accuracy: 0.10 - ETA: 1:51 - loss: 3.5181 - accuracy: 0.10 - ETA: 1:50 - loss: 3.5172 - accuracy: 0.10 - ETA: 1:49 - loss: 3.5179 - accuracy: 0.10 - ETA: 1:48 - loss: 3.5181 - accuracy: 0.10 - ETA: 1:47 - loss: 3.5181 - accuracy: 0.10 - ETA: 1:46 - loss: 3.5183 - accuracy: 0.10 - ETA: 1:46 - loss: 3.5183 - accuracy: 0.10 - ETA: 1:45 - loss: 3.5177 - accuracy: 0.10 - ETA: 1:44 - loss: 3.5171 - accuracy: 0.10 - ETA: 1:43 - loss: 3.5166 - accuracy: 0.10 - ETA: 1:42 - loss: 3.5164 - accuracy: 0.10 - ETA: 1:41 - loss: 3.5165 - accuracy: 0.10 - ETA: 1:40 - loss: 3.5164 - accuracy: 0.10 - ETA: 1:39 - loss: 3.5163 - accuracy: 0.10 - ETA: 1:38 - loss: 3.5164 - accuracy: 0.10 - ETA: 1:37 - loss: 3.5165 - accuracy: 0.10 - ETA: 1:36 - loss: 3.5169 - accuracy: 0.10 - ETA: 1:35 - loss: 3.5168 - accuracy: 0.10 - ETA: 1:35 - loss: 3.5167 - accuracy: 0.10 - ETA: 1:34 - loss: 3.5158 - accuracy: 0.10 - ETA: 1:33 - loss: 3.5155 - accuracy: 0.10 - ETA: 1:32 - loss: 3.5156 - accuracy: 0.10 - ETA: 1:31 - loss: 3.5153 - accuracy: 0.10 - ETA: 1:30 - loss: 3.5160 - accuracy: 0.10 - ETA: 1:29 - loss: 3.5156 - accuracy: 0.10 - ETA: 1:28 - loss: 3.5154 - accuracy: 0.10 - ETA: 1:27 - loss: 3.5156 - accuracy: 0.10 - ETA: 1:26 - loss: 3.5151 - accuracy: 0.10 - ETA: 1:25 - loss: 3.5156 - accuracy: 0.10 - ETA: 1:24 - loss: 3.5156 - accuracy: 0.10 - ETA: 1:23 - loss: 3.5154 - accuracy: 0.10 - ETA: 1:22 - loss: 3.5159 - accuracy: 0.10 - ETA: 1:21 - loss: 3.5156 - accuracy: 0.10 - ETA: 1:21 - loss: 3.5147 - accuracy: 0.10 - ETA: 1:20 - loss: 3.5150 - accuracy: 0.10 - ETA: 1:19 - loss: 3.5151 - accuracy: 0.10 - ETA: 1:18 - loss: 3.5147 - accuracy: 0.10 - ETA: 1:17 - loss: 3.5147 - accuracy: 0.10 - ETA: 1:16 - loss: 3.5153 - accuracy: 0.10 - ETA: 1:15 - loss: 3.5161 - accuracy: 0.10 - ETA: 1:14 - loss: 3.5159 - accuracy: 0.10 - ETA: 1:13 - loss: 3.5165 - accuracy: 0.10 - ETA: 1:12 - loss: 3.5155 - accuracy: 0.10 - ETA: 1:11 - loss: 3.5155 - accuracy: 0.10 - ETA: 1:10 - loss: 3.5160 - accuracy: 0.10 - ETA: 1:09 - loss: 3.5161 - accuracy: 0.10 - ETA: 1:08 - loss: 3.5153 - accuracy: 0.10 - ETA: 1:07 - loss: 3.5155 - accuracy: 0.10 - ETA: 1:06 - loss: 3.5155 - accuracy: 0.10 - ETA: 1:06 - loss: 3.5155 - accuracy: 0.10 - ETA: 1:05 - loss: 3.5149 - accuracy: 0.10 - ETA: 1:04 - loss: 3.5145 - accuracy: 0.10 - ETA: 1:03 - loss: 3.5145 - accuracy: 0.10 - ETA: 1:02 - loss: 3.5149 - accuracy: 0.10 - ETA: 1:01 - loss: 3.5150 - accuracy: 0.10 - ETA: 1:00 - loss: 3.5151 - accuracy: 0.10 - ETA: 59s - loss: 3.5154 - accuracy: 0.1059 - ETA: 58s - loss: 3.5152 - accuracy: 0.105 - ETA: 57s - loss: 3.5146 - accuracy: 0.106 - ETA: 56s - loss: 3.5148 - accuracy: 0.106 - ETA: 55s - loss: 3.5152 - accuracy: 0.106 - ETA: 54s - loss: 3.5154 - accuracy: 0.105 - ETA: 53s - loss: 3.5156 - accuracy: 0.105 - ETA: 52s - loss: 3.5146 - accuracy: 0.106 - ETA: 51s - loss: 3.5142 - accuracy: 0.106 - ETA: 50s - loss: 3.5147 - accuracy: 0.106 - ETA: 50s - loss: 3.5146 - accuracy: 0.106 - ETA: 49s - loss: 3.5145 - accuracy: 0.106 - ETA: 48s - loss: 3.5139 - accuracy: 0.106 - ETA: 47s - loss: 3.5139 - accuracy: 0.106 - ETA: 46s - loss: 3.5142 - accuracy: 0.106 - ETA: 45s - loss: 3.5138 - accuracy: 0.106 - ETA: 44s - loss: 3.5139 - accuracy: 0.106 - ETA: 43s - loss: 3.5136 - accuracy: 0.106 - ETA: 42s - loss: 3.5139 - accuracy: 0.106 - ETA: 41s - loss: 3.5143 - accuracy: 0.106 - ETA: 40s - loss: 3.5136 - accuracy: 0.106 - ETA: 39s - loss: 3.5139 - accuracy: 0.106 - ETA: 38s - loss: 3.5137 - accuracy: 0.106 - ETA: 37s - loss: 3.5132 - accuracy: 0.106 - ETA: 36s - loss: 3.5128 - accuracy: 0.106 - ETA: 35s - loss: 3.5126 - accuracy: 0.106 - ETA: 35s - loss: 3.5123 - accuracy: 0.106 - ETA: 34s - loss: 3.5114 - accuracy: 0.106 - ETA: 33s - loss: 3.5118 - accuracy: 0.106 - ETA: 32s - loss: 3.5115 - accuracy: 0.106 - ETA: 31s - loss: 3.5116 - accuracy: 0.106 - ETA: 30s - loss: 3.5113 - accuracy: 0.106 - ETA: 29s - loss: 3.5109 - accuracy: 0.106 - ETA: 28s - loss: 3.5102 - accuracy: 0.106 - ETA: 27s - loss: 3.5103 - accuracy: 0.106 - ETA: 26s - loss: 3.5129 - accuracy: 0.106 - ETA: 25s - loss: 3.5122 - accuracy: 0.106 - ETA: 24s - loss: 3.5122 - accuracy: 0.106 - ETA: 23s - loss: 3.5120 - accuracy: 0.106 - ETA: 22s - loss: 3.5118 - accuracy: 0.106 - ETA: 21s - loss: 3.5112 - accuracy: 0.106 - ETA: 20s - loss: 3.5114 - accuracy: 0.106 - ETA: 19s - loss: 3.5112 - accuracy: 0.106 - ETA: 18s - loss: 3.5110 - accuracy: 0.106 - ETA: 18s - loss: 3.5114 - accuracy: 0.106 - ETA: 17s - loss: 3.5115 - accuracy: 0.106 - ETA: 16s - loss: 3.5114 - accuracy: 0.106 - ETA: 15s - loss: 3.5114 - accuracy: 0.106 - ETA: 14s - loss: 3.5114 - accuracy: 0.106 - ETA: 13s - loss: 3.5114 - accuracy: 0.106 - ETA: 12s - loss: 3.5107 - accuracy: 0.106 - ETA: 11s - loss: 3.5105 - accuracy: 0.106 - ETA: 10s - loss: 3.5105 - accuracy: 0.106 - ETA: 9s - loss: 3.5104 - accuracy: 0.107 - ETA: 8s - loss: 3.5101 - accuracy: 0.10 - ETA: 7s - loss: 3.5099 - accuracy: 0.10 - ETA: 6s - loss: 3.5097 - accuracy: 0.10 - ETA: 5s - loss: 3.5092 - accuracy: 0.10 - ETA: 4s - loss: 3.5086 - accuracy: 0.10 - ETA: 3s - loss: 3.5082 - accuracy: 0.10 - ETA: 2s - loss: 3.5084 - accuracy: 0.10 - ETA: 1s - loss: 3.5084 - accuracy: 0.10 - ETA: 1s - loss: 3.5083 - accuracy: 0.10 - ETA: 0s - loss: 3.5082 - accuracy: 0.10 - 337s 8ms/step - loss: 3.5082 - accuracy: 0.1072 - val_loss: 3.9894 - val_accuracy: 0.0218\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:39 - loss: 3.5418 - accuracy: 0.08 - ETA: 5:39 - loss: 3.5482 - accuracy: 0.08 - ETA: 5:34 - loss: 3.5197 - accuracy: 0.09 - ETA: 5:33 - loss: 3.5544 - accuracy: 0.09 - ETA: 5:32 - loss: 3.5144 - accuracy: 0.09 - ETA: 5:27 - loss: 3.5006 - accuracy: 0.09 - ETA: 5:23 - loss: 3.5121 - accuracy: 0.09 - ETA: 5:18 - loss: 3.5145 - accuracy: 0.09 - ETA: 5:13 - loss: 3.5069 - accuracy: 0.09 - ETA: 5:09 - loss: 3.4998 - accuracy: 0.09 - ETA: 5:08 - loss: 3.5039 - accuracy: 0.09 - ETA: 5:07 - loss: 3.5071 - accuracy: 0.09 - ETA: 5:04 - loss: 3.5037 - accuracy: 0.09 - ETA: 5:02 - loss: 3.4981 - accuracy: 0.10 - ETA: 5:00 - loss: 3.5020 - accuracy: 0.10 - ETA: 4:59 - loss: 3.5015 - accuracy: 0.10 - ETA: 4:59 - loss: 3.4972 - accuracy: 0.10 - ETA: 4:58 - loss: 3.5022 - accuracy: 0.10 - ETA: 4:56 - loss: 3.4924 - accuracy: 0.10 - ETA: 4:56 - loss: 3.4873 - accuracy: 0.10 - ETA: 4:55 - loss: 3.4836 - accuracy: 0.10 - ETA: 4:54 - loss: 3.4763 - accuracy: 0.11 - ETA: 4:53 - loss: 3.4793 - accuracy: 0.11 - ETA: 4:51 - loss: 3.4762 - accuracy: 0.11 - ETA: 4:51 - loss: 3.4776 - accuracy: 0.11 - ETA: 4:49 - loss: 3.4753 - accuracy: 0.11 - ETA: 4:47 - loss: 3.4764 - accuracy: 0.11 - ETA: 4:46 - loss: 3.4769 - accuracy: 0.11 - ETA: 4:45 - loss: 3.4770 - accuracy: 0.11 - ETA: 4:45 - loss: 3.4747 - accuracy: 0.11 - ETA: 4:44 - loss: 3.4728 - accuracy: 0.11 - ETA: 4:43 - loss: 3.4696 - accuracy: 0.11 - ETA: 4:42 - loss: 3.4710 - accuracy: 0.11 - ETA: 4:42 - loss: 3.4657 - accuracy: 0.11 - ETA: 4:41 - loss: 3.4669 - accuracy: 0.11 - ETA: 4:41 - loss: 3.4700 - accuracy: 0.11 - ETA: 4:40 - loss: 3.4687 - accuracy: 0.11 - ETA: 4:39 - loss: 3.4686 - accuracy: 0.11 - ETA: 4:38 - loss: 3.4678 - accuracy: 0.11 - ETA: 4:37 - loss: 3.4669 - accuracy: 0.11 - ETA: 4:36 - loss: 3.4695 - accuracy: 0.11 - ETA: 4:35 - loss: 3.4709 - accuracy: 0.11 - ETA: 4:34 - loss: 3.4734 - accuracy: 0.11 - ETA: 4:33 - loss: 3.4747 - accuracy: 0.11 - ETA: 4:31 - loss: 3.4742 - accuracy: 0.11 - ETA: 4:30 - loss: 3.4768 - accuracy: 0.11 - ETA: 4:29 - loss: 3.4792 - accuracy: 0.11 - ETA: 4:28 - loss: 3.4782 - accuracy: 0.11 - ETA: 4:27 - loss: 3.4807 - accuracy: 0.11 - ETA: 4:26 - loss: 3.4785 - accuracy: 0.11 - ETA: 4:26 - loss: 3.4777 - accuracy: 0.11 - ETA: 4:25 - loss: 3.4754 - accuracy: 0.11 - ETA: 4:24 - loss: 3.4761 - accuracy: 0.11 - ETA: 4:23 - loss: 3.4753 - accuracy: 0.11 - ETA: 4:23 - loss: 3.4787 - accuracy: 0.11 - ETA: 4:22 - loss: 3.4794 - accuracy: 0.11 - ETA: 4:21 - loss: 3.4797 - accuracy: 0.11 - ETA: 4:20 - loss: 3.4824 - accuracy: 0.11 - ETA: 4:18 - loss: 3.4856 - accuracy: 0.11 - ETA: 4:17 - loss: 3.4845 - accuracy: 0.11 - ETA: 4:17 - loss: 3.4850 - accuracy: 0.11 - ETA: 4:16 - loss: 3.4862 - accuracy: 0.11 - ETA: 4:15 - loss: 3.4875 - accuracy: 0.11 - ETA: 4:14 - loss: 3.4893 - accuracy: 0.11 - ETA: 4:13 - loss: 3.4910 - accuracy: 0.11 - ETA: 4:12 - loss: 3.4916 - accuracy: 0.11 - ETA: 4:11 - loss: 3.4935 - accuracy: 0.11 - ETA: 4:10 - loss: 3.4957 - accuracy: 0.11 - ETA: 4:10 - loss: 3.4959 - accuracy: 0.10 - ETA: 4:08 - loss: 3.4976 - accuracy: 0.10 - ETA: 4:08 - loss: 3.4991 - accuracy: 0.10 - ETA: 4:07 - loss: 3.4976 - accuracy: 0.11 - ETA: 4:06 - loss: 3.4963 - accuracy: 0.11 - ETA: 4:05 - loss: 3.4966 - accuracy: 0.11 - ETA: 4:04 - loss: 3.4986 - accuracy: 0.11 - ETA: 4:03 - loss: 3.4992 - accuracy: 0.10 - ETA: 4:02 - loss: 3.5026 - accuracy: 0.10 - ETA: 4:01 - loss: 3.5046 - accuracy: 0.10 - ETA: 4:00 - loss: 3.5038 - accuracy: 0.10 - ETA: 3:59 - loss: 3.5054 - accuracy: 0.10 - ETA: 3:58 - loss: 3.5053 - accuracy: 0.10 - ETA: 3:57 - loss: 3.5062 - accuracy: 0.10 - ETA: 3:56 - loss: 3.5064 - accuracy: 0.10 - ETA: 3:55 - loss: 3.5070 - accuracy: 0.10 - ETA: 3:54 - loss: 3.5085 - accuracy: 0.10 - ETA: 3:54 - loss: 3.5092 - accuracy: 0.10 - ETA: 3:53 - loss: 3.5100 - accuracy: 0.10 - ETA: 3:52 - loss: 3.5106 - accuracy: 0.10 - ETA: 3:51 - loss: 3.5125 - accuracy: 0.10 - ETA: 3:50 - loss: 3.5141 - accuracy: 0.10 - ETA: 3:49 - loss: 3.5143 - accuracy: 0.10 - ETA: 3:48 - loss: 3.5143 - accuracy: 0.10 - ETA: 3:47 - loss: 3.5152 - accuracy: 0.10 - ETA: 3:46 - loss: 3.5151 - accuracy: 0.10 - ETA: 3:45 - loss: 3.5147 - accuracy: 0.10 - ETA: 3:44 - loss: 3.5149 - accuracy: 0.10 - ETA: 3:43 - loss: 3.5147 - accuracy: 0.10 - ETA: 3:42 - loss: 3.5149 - accuracy: 0.10 - ETA: 3:41 - loss: 3.5156 - accuracy: 0.10 - ETA: 3:40 - loss: 3.5159 - accuracy: 0.10 - ETA: 3:39 - loss: 3.5173 - accuracy: 0.10 - ETA: 3:38 - loss: 3.5180 - accuracy: 0.10 - ETA: 3:37 - loss: 3.5192 - accuracy: 0.10 - ETA: 3:36 - loss: 3.5193 - accuracy: 0.10 - ETA: 3:35 - loss: 3.5205 - accuracy: 0.10 - ETA: 3:34 - loss: 3.5210 - accuracy: 0.10 - ETA: 3:33 - loss: 3.5194 - accuracy: 0.10 - ETA: 3:32 - loss: 3.5198 - accuracy: 0.10 - ETA: 3:31 - loss: 3.5217 - accuracy: 0.10 - ETA: 3:30 - loss: 3.5218 - accuracy: 0.10 - ETA: 3:29 - loss: 3.5214 - accuracy: 0.10 - ETA: 3:28 - loss: 3.5218 - accuracy: 0.10 - ETA: 3:27 - loss: 3.5229 - accuracy: 0.10 - ETA: 3:26 - loss: 3.5234 - accuracy: 0.10 - ETA: 3:25 - loss: 3.5240 - accuracy: 0.10 - ETA: 3:25 - loss: 3.5242 - accuracy: 0.10 - ETA: 3:24 - loss: 3.5240 - accuracy: 0.10 - ETA: 3:23 - loss: 3.5246 - accuracy: 0.10 - ETA: 3:22 - loss: 3.5259 - accuracy: 0.10 - ETA: 3:21 - loss: 3.5262 - accuracy: 0.10 - ETA: 3:20 - loss: 3.5263 - accuracy: 0.10 - ETA: 3:19 - loss: 3.5267 - accuracy: 0.10 - ETA: 3:18 - loss: 3.5274 - accuracy: 0.10 - ETA: 3:17 - loss: 3.5264 - accuracy: 0.10 - ETA: 3:16 - loss: 3.5267 - accuracy: 0.10 - ETA: 3:15 - loss: 3.5263 - accuracy: 0.10 - ETA: 3:14 - loss: 3.5270 - accuracy: 0.10 - ETA: 3:13 - loss: 3.5262 - accuracy: 0.10 - ETA: 3:12 - loss: 3.5280 - accuracy: 0.10 - ETA: 3:11 - loss: 3.5283 - accuracy: 0.10 - ETA: 3:10 - loss: 3.5275 - accuracy: 0.10 - ETA: 3:09 - loss: 3.5269 - accuracy: 0.10 - ETA: 3:09 - loss: 3.5271 - accuracy: 0.10 - ETA: 3:08 - loss: 3.5269 - accuracy: 0.10 - ETA: 3:07 - loss: 3.5281 - accuracy: 0.10 - ETA: 3:06 - loss: 3.5286 - accuracy: 0.10 - ETA: 3:05 - loss: 3.5293 - accuracy: 0.10 - ETA: 3:04 - loss: 3.5296 - accuracy: 0.10 - ETA: 3:03 - loss: 3.5304 - accuracy: 0.10 - ETA: 3:02 - loss: 3.5308 - accuracy: 0.10 - ETA: 3:01 - loss: 3.5321 - accuracy: 0.10 - ETA: 3:00 - loss: 3.5324 - accuracy: 0.10 - ETA: 2:59 - loss: 3.5322 - accuracy: 0.10 - ETA: 2:58 - loss: 3.5324 - accuracy: 0.10 - ETA: 2:57 - loss: 3.5333 - accuracy: 0.10 - ETA: 2:57 - loss: 3.5337 - accuracy: 0.10 - ETA: 2:56 - loss: 3.5336 - accuracy: 0.10 - ETA: 2:55 - loss: 3.5332 - accuracy: 0.10 - ETA: 2:54 - loss: 3.5329 - accuracy: 0.10 - ETA: 2:53 - loss: 3.5319 - accuracy: 0.10 - ETA: 2:52 - loss: 3.5318 - accuracy: 0.10 - ETA: 2:51 - loss: 3.5317 - accuracy: 0.10 - ETA: 2:50 - loss: 3.5308 - accuracy: 0.10 - ETA: 2:49 - loss: 3.5312 - accuracy: 0.10 - ETA: 2:48 - loss: 3.5318 - accuracy: 0.10 - ETA: 2:47 - loss: 3.5315 - accuracy: 0.10 - ETA: 2:46 - loss: 3.5318 - accuracy: 0.10 - ETA: 2:45 - loss: 3.5330 - accuracy: 0.10 - ETA: 2:44 - loss: 3.5330 - accuracy: 0.10 - ETA: 2:43 - loss: 3.5362 - accuracy: 0.10 - ETA: 2:42 - loss: 3.5356 - accuracy: 0.10 - ETA: 2:41 - loss: 3.5367 - accuracy: 0.10 - ETA: 2:40 - loss: 3.5365 - accuracy: 0.10 - ETA: 2:39 - loss: 3.5377 - accuracy: 0.10 - ETA: 2:38 - loss: 3.5368 - accuracy: 0.10 - ETA: 2:37 - loss: 3.5364 - accuracy: 0.10 - ETA: 2:36 - loss: 3.5366 - accuracy: 0.10 - ETA: 2:35 - loss: 3.5360 - accuracy: 0.10 - ETA: 2:34 - loss: 3.5348 - accuracy: 0.10 - ETA: 2:34 - loss: 3.5345 - accuracy: 0.10 - ETA: 2:33 - loss: 3.5343 - accuracy: 0.10 - ETA: 2:32 - loss: 3.5347 - accuracy: 0.10 - ETA: 2:31 - loss: 3.5352 - accuracy: 0.10 - ETA: 2:30 - loss: 3.5347 - accuracy: 0.10 - ETA: 2:29 - loss: 3.5347 - accuracy: 0.10 - ETA: 2:28 - loss: 3.5347 - accuracy: 0.10 - ETA: 2:27 - loss: 3.5338 - accuracy: 0.10 - ETA: 2:26 - loss: 3.5329 - accuracy: 0.10 - ETA: 2:25 - loss: 3.5324 - accuracy: 0.10 - ETA: 2:24 - loss: 3.5320 - accuracy: 0.10 - ETA: 2:23 - loss: 3.5322 - accuracy: 0.10 - ETA: 2:22 - loss: 3.5316 - accuracy: 0.10 - ETA: 2:21 - loss: 3.5314 - accuracy: 0.10 - ETA: 2:20 - loss: 3.5307 - accuracy: 0.10 - ETA: 2:19 - loss: 3.5301 - accuracy: 0.10 - ETA: 2:18 - loss: 3.5307 - accuracy: 0.1033"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.5308 - accuracy: 0.10 - ETA: 2:16 - loss: 3.5316 - accuracy: 0.10 - ETA: 2:15 - loss: 3.5314 - accuracy: 0.10 - ETA: 2:14 - loss: 3.5311 - accuracy: 0.10 - ETA: 2:13 - loss: 3.5322 - accuracy: 0.10 - ETA: 2:12 - loss: 3.5330 - accuracy: 0.10 - ETA: 2:11 - loss: 3.5326 - accuracy: 0.10 - ETA: 2:10 - loss: 3.5330 - accuracy: 0.10 - ETA: 2:09 - loss: 3.5334 - accuracy: 0.10 - ETA: 2:09 - loss: 3.5332 - accuracy: 0.10 - ETA: 2:08 - loss: 3.5336 - accuracy: 0.10 - ETA: 2:07 - loss: 3.5343 - accuracy: 0.10 - ETA: 2:06 - loss: 3.5339 - accuracy: 0.10 - ETA: 2:05 - loss: 3.5339 - accuracy: 0.10 - ETA: 2:04 - loss: 3.5338 - accuracy: 0.10 - ETA: 2:03 - loss: 3.5332 - accuracy: 0.10 - ETA: 2:02 - loss: 3.5330 - accuracy: 0.10 - ETA: 2:01 - loss: 3.5320 - accuracy: 0.10 - ETA: 2:00 - loss: 3.5316 - accuracy: 0.10 - ETA: 1:59 - loss: 3.5319 - accuracy: 0.10 - ETA: 1:58 - loss: 3.5322 - accuracy: 0.10 - ETA: 1:57 - loss: 3.5318 - accuracy: 0.10 - ETA: 1:56 - loss: 3.5318 - accuracy: 0.10 - ETA: 1:55 - loss: 3.5313 - accuracy: 0.10 - ETA: 1:54 - loss: 3.5312 - accuracy: 0.10 - ETA: 1:53 - loss: 3.5314 - accuracy: 0.10 - ETA: 1:52 - loss: 3.5320 - accuracy: 0.10 - ETA: 1:51 - loss: 3.5319 - accuracy: 0.10 - ETA: 1:50 - loss: 3.5315 - accuracy: 0.10 - ETA: 1:50 - loss: 3.5318 - accuracy: 0.10 - ETA: 1:49 - loss: 3.5318 - accuracy: 0.10 - ETA: 1:48 - loss: 3.5320 - accuracy: 0.10 - ETA: 1:47 - loss: 3.5327 - accuracy: 0.10 - ETA: 1:46 - loss: 3.5326 - accuracy: 0.10 - ETA: 1:45 - loss: 3.5323 - accuracy: 0.10 - ETA: 1:44 - loss: 3.5324 - accuracy: 0.10 - ETA: 1:43 - loss: 3.5320 - accuracy: 0.10 - ETA: 1:42 - loss: 3.5323 - accuracy: 0.10 - ETA: 1:41 - loss: 3.5324 - accuracy: 0.10 - ETA: 1:40 - loss: 3.5320 - accuracy: 0.10 - ETA: 1:39 - loss: 3.5322 - accuracy: 0.10 - ETA: 1:38 - loss: 3.5323 - accuracy: 0.10 - ETA: 1:37 - loss: 3.5320 - accuracy: 0.10 - ETA: 1:36 - loss: 3.5314 - accuracy: 0.10 - ETA: 1:35 - loss: 3.5305 - accuracy: 0.10 - ETA: 1:34 - loss: 3.5312 - accuracy: 0.10 - ETA: 1:33 - loss: 3.5309 - accuracy: 0.10 - ETA: 1:32 - loss: 3.5310 - accuracy: 0.10 - ETA: 1:31 - loss: 3.5311 - accuracy: 0.10 - ETA: 1:30 - loss: 3.5314 - accuracy: 0.10 - ETA: 1:30 - loss: 3.5311 - accuracy: 0.10 - ETA: 1:29 - loss: 3.5311 - accuracy: 0.10 - ETA: 1:28 - loss: 3.5306 - accuracy: 0.10 - ETA: 1:27 - loss: 3.5310 - accuracy: 0.10 - ETA: 1:26 - loss: 3.5317 - accuracy: 0.10 - ETA: 1:25 - loss: 3.5317 - accuracy: 0.10 - ETA: 1:24 - loss: 3.5309 - accuracy: 0.10 - ETA: 1:23 - loss: 3.5309 - accuracy: 0.10 - ETA: 1:22 - loss: 3.5312 - accuracy: 0.10 - ETA: 1:21 - loss: 3.5309 - accuracy: 0.10 - ETA: 1:20 - loss: 3.5309 - accuracy: 0.10 - ETA: 1:19 - loss: 3.5312 - accuracy: 0.10 - ETA: 1:18 - loss: 3.5308 - accuracy: 0.10 - ETA: 1:17 - loss: 3.5306 - accuracy: 0.10 - ETA: 1:16 - loss: 3.5305 - accuracy: 0.10 - ETA: 1:15 - loss: 3.5307 - accuracy: 0.10 - ETA: 1:14 - loss: 3.5306 - accuracy: 0.10 - ETA: 1:13 - loss: 3.5305 - accuracy: 0.10 - ETA: 1:12 - loss: 3.5299 - accuracy: 0.10 - ETA: 1:11 - loss: 3.5298 - accuracy: 0.10 - ETA: 1:10 - loss: 3.5298 - accuracy: 0.10 - ETA: 1:09 - loss: 3.5295 - accuracy: 0.10 - ETA: 1:08 - loss: 3.5297 - accuracy: 0.10 - ETA: 1:07 - loss: 3.5297 - accuracy: 0.10 - ETA: 1:06 - loss: 3.5301 - accuracy: 0.10 - ETA: 1:06 - loss: 3.5299 - accuracy: 0.10 - ETA: 1:05 - loss: 3.5300 - accuracy: 0.10 - ETA: 1:04 - loss: 3.5296 - accuracy: 0.10 - ETA: 1:03 - loss: 3.5296 - accuracy: 0.10 - ETA: 1:02 - loss: 3.5293 - accuracy: 0.10 - ETA: 1:01 - loss: 3.5289 - accuracy: 0.10 - ETA: 1:00 - loss: 3.5289 - accuracy: 0.10 - ETA: 59s - loss: 3.5286 - accuracy: 0.1039 - ETA: 58s - loss: 3.5282 - accuracy: 0.104 - ETA: 57s - loss: 3.5283 - accuracy: 0.104 - ETA: 56s - loss: 3.5285 - accuracy: 0.103 - ETA: 55s - loss: 3.5289 - accuracy: 0.103 - ETA: 54s - loss: 3.5284 - accuracy: 0.103 - ETA: 53s - loss: 3.5288 - accuracy: 0.103 - ETA: 52s - loss: 3.5289 - accuracy: 0.103 - ETA: 51s - loss: 3.5286 - accuracy: 0.103 - ETA: 50s - loss: 3.5282 - accuracy: 0.103 - ETA: 49s - loss: 3.5282 - accuracy: 0.103 - ETA: 48s - loss: 3.5285 - accuracy: 0.103 - ETA: 47s - loss: 3.5287 - accuracy: 0.103 - ETA: 46s - loss: 3.5283 - accuracy: 0.103 - ETA: 45s - loss: 3.5284 - accuracy: 0.103 - ETA: 44s - loss: 3.5286 - accuracy: 0.103 - ETA: 44s - loss: 3.5291 - accuracy: 0.103 - ETA: 43s - loss: 3.5287 - accuracy: 0.103 - ETA: 42s - loss: 3.5287 - accuracy: 0.103 - ETA: 41s - loss: 3.5288 - accuracy: 0.103 - ETA: 40s - loss: 3.5292 - accuracy: 0.103 - ETA: 39s - loss: 3.5292 - accuracy: 0.103 - ETA: 38s - loss: 3.5291 - accuracy: 0.103 - ETA: 37s - loss: 3.5292 - accuracy: 0.103 - ETA: 36s - loss: 3.5291 - accuracy: 0.103 - ETA: 35s - loss: 3.5289 - accuracy: 0.103 - ETA: 34s - loss: 3.5293 - accuracy: 0.103 - ETA: 33s - loss: 3.5293 - accuracy: 0.103 - ETA: 32s - loss: 3.5283 - accuracy: 0.103 - ETA: 31s - loss: 3.5286 - accuracy: 0.103 - ETA: 30s - loss: 3.5282 - accuracy: 0.103 - ETA: 29s - loss: 3.5272 - accuracy: 0.103 - ETA: 28s - loss: 3.5273 - accuracy: 0.103 - ETA: 27s - loss: 3.5273 - accuracy: 0.103 - ETA: 26s - loss: 3.5276 - accuracy: 0.103 - ETA: 25s - loss: 3.5277 - accuracy: 0.103 - ETA: 24s - loss: 3.5278 - accuracy: 0.103 - ETA: 23s - loss: 3.5279 - accuracy: 0.103 - ETA: 23s - loss: 3.5285 - accuracy: 0.103 - ETA: 22s - loss: 3.5285 - accuracy: 0.103 - ETA: 21s - loss: 3.5287 - accuracy: 0.103 - ETA: 20s - loss: 3.5286 - accuracy: 0.103 - ETA: 19s - loss: 3.5288 - accuracy: 0.103 - ETA: 18s - loss: 3.5287 - accuracy: 0.103 - ETA: 17s - loss: 3.5286 - accuracy: 0.103 - ETA: 16s - loss: 3.5279 - accuracy: 0.103 - ETA: 15s - loss: 3.5280 - accuracy: 0.103 - ETA: 14s - loss: 3.5277 - accuracy: 0.103 - ETA: 13s - loss: 3.5277 - accuracy: 0.103 - ETA: 12s - loss: 3.5278 - accuracy: 0.103 - ETA: 11s - loss: 3.5279 - accuracy: 0.103 - ETA: 10s - loss: 3.5284 - accuracy: 0.103 - ETA: 9s - loss: 3.5281 - accuracy: 0.104 - ETA: 8s - loss: 3.5283 - accuracy: 0.10 - ETA: 7s - loss: 3.5290 - accuracy: 0.10 - ETA: 6s - loss: 3.5292 - accuracy: 0.10 - ETA: 5s - loss: 3.5290 - accuracy: 0.10 - ETA: 4s - loss: 3.5289 - accuracy: 0.10 - ETA: 3s - loss: 3.5289 - accuracy: 0.10 - ETA: 2s - loss: 3.5289 - accuracy: 0.10 - ETA: 1s - loss: 3.5285 - accuracy: 0.10 - ETA: 1s - loss: 3.5286 - accuracy: 0.10 - ETA: 0s - loss: 3.5286 - accuracy: 0.10 - 341s 8ms/step - loss: 3.5287 - accuracy: 0.1035 - val_loss: 3.9804 - val_accuracy: 0.0118\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:33 - loss: 3.5403 - accuracy: 0.05 - ETA: 5:21 - loss: 3.5825 - accuracy: 0.07 - ETA: 5:13 - loss: 3.5861 - accuracy: 0.08 - ETA: 5:05 - loss: 3.5660 - accuracy: 0.09 - ETA: 5:09 - loss: 3.5550 - accuracy: 0.08 - ETA: 5:06 - loss: 3.5679 - accuracy: 0.08 - ETA: 5:07 - loss: 3.5445 - accuracy: 0.08 - ETA: 5:08 - loss: 3.5619 - accuracy: 0.07 - ETA: 5:08 - loss: 3.5603 - accuracy: 0.08 - ETA: 5:09 - loss: 3.5496 - accuracy: 0.08 - ETA: 5:07 - loss: 3.5433 - accuracy: 0.08 - ETA: 5:08 - loss: 3.5429 - accuracy: 0.08 - ETA: 5:09 - loss: 3.5431 - accuracy: 0.08 - ETA: 5:06 - loss: 3.5459 - accuracy: 0.08 - ETA: 5:04 - loss: 3.5479 - accuracy: 0.08 - ETA: 5:03 - loss: 3.5501 - accuracy: 0.08 - ETA: 5:02 - loss: 3.5486 - accuracy: 0.08 - ETA: 5:01 - loss: 3.5479 - accuracy: 0.09 - ETA: 4:59 - loss: 3.5407 - accuracy: 0.09 - ETA: 4:58 - loss: 3.5390 - accuracy: 0.09 - ETA: 4:58 - loss: 3.5369 - accuracy: 0.09 - ETA: 4:57 - loss: 3.5426 - accuracy: 0.09 - ETA: 4:57 - loss: 3.5483 - accuracy: 0.09 - ETA: 4:56 - loss: 3.5519 - accuracy: 0.09 - ETA: 4:56 - loss: 3.5503 - accuracy: 0.09 - ETA: 4:55 - loss: 3.5483 - accuracy: 0.09 - ETA: 4:55 - loss: 3.5519 - accuracy: 0.09 - ETA: 4:54 - loss: 3.5504 - accuracy: 0.09 - ETA: 4:53 - loss: 3.5462 - accuracy: 0.09 - ETA: 4:52 - loss: 3.5459 - accuracy: 0.09 - ETA: 4:51 - loss: 3.5500 - accuracy: 0.09 - ETA: 4:49 - loss: 3.5482 - accuracy: 0.09 - ETA: 4:48 - loss: 3.5456 - accuracy: 0.09 - ETA: 4:47 - loss: 3.5421 - accuracy: 0.09 - ETA: 4:46 - loss: 3.5396 - accuracy: 0.09 - ETA: 4:44 - loss: 3.5394 - accuracy: 0.09 - ETA: 4:43 - loss: 3.5380 - accuracy: 0.10 - ETA: 4:42 - loss: 3.5356 - accuracy: 0.10 - ETA: 4:41 - loss: 3.5335 - accuracy: 0.09 - ETA: 4:40 - loss: 3.5308 - accuracy: 0.10 - ETA: 4:39 - loss: 3.5303 - accuracy: 0.10 - ETA: 4:37 - loss: 3.5301 - accuracy: 0.10 - ETA: 4:37 - loss: 3.5286 - accuracy: 0.10 - ETA: 4:36 - loss: 3.5330 - accuracy: 0.10 - ETA: 4:35 - loss: 3.5339 - accuracy: 0.10 - ETA: 4:34 - loss: 3.5344 - accuracy: 0.09 - ETA: 4:33 - loss: 3.5313 - accuracy: 0.10 - ETA: 4:32 - loss: 3.5286 - accuracy: 0.10 - ETA: 4:31 - loss: 3.5259 - accuracy: 0.10 - ETA: 4:30 - loss: 3.5240 - accuracy: 0.10 - ETA: 4:29 - loss: 3.5262 - accuracy: 0.10 - ETA: 4:28 - loss: 3.5227 - accuracy: 0.10 - ETA: 4:26 - loss: 3.5264 - accuracy: 0.10 - ETA: 4:25 - loss: 3.5259 - accuracy: 0.10 - ETA: 4:24 - loss: 3.5279 - accuracy: 0.10 - ETA: 4:23 - loss: 3.5269 - accuracy: 0.10 - ETA: 4:22 - loss: 3.5272 - accuracy: 0.10 - ETA: 4:21 - loss: 3.5251 - accuracy: 0.10 - ETA: 4:20 - loss: 3.5250 - accuracy: 0.10 - ETA: 4:20 - loss: 3.5250 - accuracy: 0.10 - ETA: 4:19 - loss: 3.5234 - accuracy: 0.10 - ETA: 4:18 - loss: 3.5222 - accuracy: 0.10 - ETA: 4:17 - loss: 3.5212 - accuracy: 0.10 - ETA: 4:16 - loss: 3.5202 - accuracy: 0.10 - ETA: 4:15 - loss: 3.5224 - accuracy: 0.10 - ETA: 4:14 - loss: 3.5215 - accuracy: 0.10 - ETA: 4:13 - loss: 3.5223 - accuracy: 0.10 - ETA: 4:12 - loss: 3.5252 - accuracy: 0.10 - ETA: 4:11 - loss: 3.5270 - accuracy: 0.10 - ETA: 4:10 - loss: 3.5272 - accuracy: 0.10 - ETA: 4:09 - loss: 3.5261 - accuracy: 0.10 - ETA: 4:08 - loss: 3.5239 - accuracy: 0.10 - ETA: 4:07 - loss: 3.5241 - accuracy: 0.10 - ETA: 4:06 - loss: 3.5236 - accuracy: 0.10 - ETA: 4:05 - loss: 3.5234 - accuracy: 0.10 - ETA: 4:04 - loss: 3.5242 - accuracy: 0.10 - ETA: 4:03 - loss: 3.5251 - accuracy: 0.10 - ETA: 4:02 - loss: 3.5227 - accuracy: 0.10 - ETA: 4:01 - loss: 3.5214 - accuracy: 0.10 - ETA: 4:00 - loss: 3.5220 - accuracy: 0.10 - ETA: 3:59 - loss: 3.5214 - accuracy: 0.10 - ETA: 3:58 - loss: 3.5206 - accuracy: 0.10 - ETA: 3:57 - loss: 3.5193 - accuracy: 0.10 - ETA: 3:56 - loss: 3.5185 - accuracy: 0.10 - ETA: 3:55 - loss: 3.5182 - accuracy: 0.10 - ETA: 3:54 - loss: 3.5160 - accuracy: 0.10 - ETA: 3:53 - loss: 3.5172 - accuracy: 0.10 - ETA: 3:52 - loss: 3.5163 - accuracy: 0.10 - ETA: 3:51 - loss: 3.5166 - accuracy: 0.10 - ETA: 3:50 - loss: 3.5159 - accuracy: 0.10 - ETA: 3:49 - loss: 3.5145 - accuracy: 0.10 - ETA: 3:48 - loss: 3.5140 - accuracy: 0.10 - ETA: 3:47 - loss: 3.5131 - accuracy: 0.10 - ETA: 3:46 - loss: 3.5129 - accuracy: 0.10 - ETA: 3:45 - loss: 3.5131 - accuracy: 0.10 - ETA: 3:44 - loss: 3.5115 - accuracy: 0.10 - ETA: 3:44 - loss: 3.5104 - accuracy: 0.10 - ETA: 3:42 - loss: 3.5097 - accuracy: 0.10 - ETA: 3:41 - loss: 3.5096 - accuracy: 0.10 - ETA: 3:41 - loss: 3.5096 - accuracy: 0.10 - ETA: 3:40 - loss: 3.5101 - accuracy: 0.10 - ETA: 3:39 - loss: 3.5104 - accuracy: 0.10 - ETA: 3:38 - loss: 3.5109 - accuracy: 0.10 - ETA: 3:36 - loss: 3.5114 - accuracy: 0.10 - ETA: 3:35 - loss: 3.5114 - accuracy: 0.10 - ETA: 3:34 - loss: 3.5122 - accuracy: 0.10 - ETA: 3:34 - loss: 3.5153 - accuracy: 0.10 - ETA: 3:33 - loss: 3.5150 - accuracy: 0.10 - ETA: 3:32 - loss: 3.5143 - accuracy: 0.10 - ETA: 3:31 - loss: 3.5147 - accuracy: 0.10 - ETA: 3:30 - loss: 3.5156 - accuracy: 0.10 - ETA: 3:29 - loss: 3.5150 - accuracy: 0.10 - ETA: 3:28 - loss: 3.5158 - accuracy: 0.10 - ETA: 3:27 - loss: 3.5168 - accuracy: 0.10 - ETA: 3:26 - loss: 3.5180 - accuracy: 0.10 - ETA: 3:25 - loss: 3.5175 - accuracy: 0.10 - ETA: 3:24 - loss: 3.5173 - accuracy: 0.10 - ETA: 3:23 - loss: 3.5185 - accuracy: 0.10 - ETA: 3:23 - loss: 3.5175 - accuracy: 0.10 - ETA: 3:22 - loss: 3.5180 - accuracy: 0.10 - ETA: 3:21 - loss: 3.5194 - accuracy: 0.10 - ETA: 3:20 - loss: 3.5204 - accuracy: 0.10 - ETA: 3:19 - loss: 3.5210 - accuracy: 0.10 - ETA: 3:18 - loss: 3.5207 - accuracy: 0.10 - ETA: 3:17 - loss: 3.5207 - accuracy: 0.10 - ETA: 3:16 - loss: 3.5213 - accuracy: 0.10 - ETA: 3:15 - loss: 3.5219 - accuracy: 0.10 - ETA: 3:14 - loss: 3.5227 - accuracy: 0.10 - ETA: 3:13 - loss: 3.5234 - accuracy: 0.10 - ETA: 3:12 - loss: 3.5236 - accuracy: 0.10 - ETA: 3:11 - loss: 3.5244 - accuracy: 0.10 - ETA: 3:10 - loss: 3.5248 - accuracy: 0.10 - ETA: 3:09 - loss: 3.5255 - accuracy: 0.10 - ETA: 3:08 - loss: 3.5259 - accuracy: 0.10 - ETA: 3:07 - loss: 3.5249 - accuracy: 0.10 - ETA: 3:06 - loss: 3.5249 - accuracy: 0.10 - ETA: 3:05 - loss: 3.5259 - accuracy: 0.10 - ETA: 3:04 - loss: 3.5266 - accuracy: 0.10 - ETA: 3:03 - loss: 3.5280 - accuracy: 0.10 - ETA: 3:02 - loss: 3.5274 - accuracy: 0.10 - ETA: 3:01 - loss: 3.5273 - accuracy: 0.10 - ETA: 3:00 - loss: 3.5274 - accuracy: 0.10 - ETA: 2:59 - loss: 3.5274 - accuracy: 0.10 - ETA: 2:58 - loss: 3.5281 - accuracy: 0.10 - ETA: 2:57 - loss: 3.5278 - accuracy: 0.10 - ETA: 2:56 - loss: 3.5275 - accuracy: 0.10 - ETA: 2:55 - loss: 3.5283 - accuracy: 0.10 - ETA: 2:55 - loss: 3.5285 - accuracy: 0.10 - ETA: 2:54 - loss: 3.5287 - accuracy: 0.10 - ETA: 2:53 - loss: 3.5286 - accuracy: 0.10 - ETA: 2:52 - loss: 3.5297 - accuracy: 0.10 - ETA: 2:51 - loss: 3.5305 - accuracy: 0.10 - ETA: 2:50 - loss: 3.5301 - accuracy: 0.10 - ETA: 2:49 - loss: 3.5308 - accuracy: 0.10 - ETA: 2:48 - loss: 3.5301 - accuracy: 0.10 - ETA: 2:47 - loss: 3.5299 - accuracy: 0.10 - ETA: 2:46 - loss: 3.5330 - accuracy: 0.10 - ETA: 2:45 - loss: 3.5339 - accuracy: 0.10 - ETA: 2:44 - loss: 3.5334 - accuracy: 0.10 - ETA: 2:43 - loss: 3.5336 - accuracy: 0.10 - ETA: 2:42 - loss: 3.5333 - accuracy: 0.10 - ETA: 2:41 - loss: 3.5322 - accuracy: 0.10 - ETA: 2:40 - loss: 3.5317 - accuracy: 0.10 - ETA: 2:39 - loss: 3.5320 - accuracy: 0.10 - ETA: 2:39 - loss: 3.5315 - accuracy: 0.10 - ETA: 2:38 - loss: 3.5321 - accuracy: 0.10 - ETA: 2:37 - loss: 3.5312 - accuracy: 0.10 - ETA: 2:36 - loss: 3.5314 - accuracy: 0.10 - ETA: 2:35 - loss: 3.5314 - accuracy: 0.10 - ETA: 2:34 - loss: 3.5322 - accuracy: 0.10 - ETA: 2:33 - loss: 3.5328 - accuracy: 0.10 - ETA: 2:32 - loss: 3.5329 - accuracy: 0.10 - ETA: 2:31 - loss: 3.5330 - accuracy: 0.10 - ETA: 2:30 - loss: 3.5327 - accuracy: 0.10 - ETA: 2:29 - loss: 3.5322 - accuracy: 0.10 - ETA: 2:28 - loss: 3.5327 - accuracy: 0.10 - ETA: 2:27 - loss: 3.5323 - accuracy: 0.10 - ETA: 2:26 - loss: 3.5328 - accuracy: 0.10 - ETA: 2:25 - loss: 3.5327 - accuracy: 0.10 - ETA: 2:24 - loss: 3.5331 - accuracy: 0.10 - ETA: 2:23 - loss: 3.5336 - accuracy: 0.10 - ETA: 2:22 - loss: 3.5336 - accuracy: 0.10 - ETA: 2:21 - loss: 3.5332 - accuracy: 0.10 - ETA: 2:21 - loss: 3.5328 - accuracy: 0.10 - ETA: 2:20 - loss: 3.5332 - accuracy: 0.10 - ETA: 2:19 - loss: 3.5336 - accuracy: 0.1037"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.5332 - accuracy: 0.10 - ETA: 2:17 - loss: 3.5334 - accuracy: 0.10 - ETA: 2:16 - loss: 3.5331 - accuracy: 0.10 - ETA: 2:15 - loss: 3.5334 - accuracy: 0.10 - ETA: 2:14 - loss: 3.5333 - accuracy: 0.10 - ETA: 2:13 - loss: 3.5331 - accuracy: 0.10 - ETA: 2:12 - loss: 3.5331 - accuracy: 0.10 - ETA: 2:11 - loss: 3.5327 - accuracy: 0.10 - ETA: 2:10 - loss: 3.5325 - accuracy: 0.10 - ETA: 2:09 - loss: 3.5324 - accuracy: 0.10 - ETA: 2:08 - loss: 3.5330 - accuracy: 0.10 - ETA: 2:07 - loss: 3.5326 - accuracy: 0.10 - ETA: 2:06 - loss: 3.5329 - accuracy: 0.10 - ETA: 2:05 - loss: 3.5320 - accuracy: 0.10 - ETA: 2:04 - loss: 3.5315 - accuracy: 0.10 - ETA: 2:03 - loss: 3.5320 - accuracy: 0.10 - ETA: 2:02 - loss: 3.5327 - accuracy: 0.10 - ETA: 2:01 - loss: 3.5330 - accuracy: 0.10 - ETA: 2:00 - loss: 3.5336 - accuracy: 0.10 - ETA: 1:59 - loss: 3.5335 - accuracy: 0.10 - ETA: 1:58 - loss: 3.5331 - accuracy: 0.10 - ETA: 1:58 - loss: 3.5330 - accuracy: 0.10 - ETA: 1:57 - loss: 3.5328 - accuracy: 0.10 - ETA: 1:56 - loss: 3.5335 - accuracy: 0.10 - ETA: 1:55 - loss: 3.5341 - accuracy: 0.10 - ETA: 1:54 - loss: 3.5344 - accuracy: 0.10 - ETA: 1:53 - loss: 3.5341 - accuracy: 0.10 - ETA: 1:52 - loss: 3.5344 - accuracy: 0.10 - ETA: 1:51 - loss: 3.5339 - accuracy: 0.10 - ETA: 1:50 - loss: 3.5337 - accuracy: 0.10 - ETA: 1:49 - loss: 3.5331 - accuracy: 0.10 - ETA: 1:48 - loss: 3.5333 - accuracy: 0.10 - ETA: 1:47 - loss: 3.5332 - accuracy: 0.10 - ETA: 1:46 - loss: 3.5327 - accuracy: 0.10 - ETA: 1:45 - loss: 3.5325 - accuracy: 0.10 - ETA: 1:44 - loss: 3.5323 - accuracy: 0.10 - ETA: 1:43 - loss: 3.5333 - accuracy: 0.10 - ETA: 1:42 - loss: 3.5335 - accuracy: 0.10 - ETA: 1:41 - loss: 3.5340 - accuracy: 0.10 - ETA: 1:40 - loss: 3.5332 - accuracy: 0.10 - ETA: 1:39 - loss: 3.5339 - accuracy: 0.10 - ETA: 1:38 - loss: 3.5345 - accuracy: 0.10 - ETA: 1:37 - loss: 3.5348 - accuracy: 0.10 - ETA: 1:37 - loss: 3.5349 - accuracy: 0.10 - ETA: 1:36 - loss: 3.5350 - accuracy: 0.10 - ETA: 1:35 - loss: 3.5347 - accuracy: 0.10 - ETA: 1:34 - loss: 3.5344 - accuracy: 0.10 - ETA: 1:33 - loss: 3.5341 - accuracy: 0.10 - ETA: 1:32 - loss: 3.5341 - accuracy: 0.10 - ETA: 1:31 - loss: 3.5334 - accuracy: 0.10 - ETA: 1:30 - loss: 3.5333 - accuracy: 0.10 - ETA: 1:29 - loss: 3.5335 - accuracy: 0.10 - ETA: 1:28 - loss: 3.5336 - accuracy: 0.10 - ETA: 1:27 - loss: 3.5332 - accuracy: 0.10 - ETA: 1:26 - loss: 3.5337 - accuracy: 0.10 - ETA: 1:25 - loss: 3.5329 - accuracy: 0.10 - ETA: 1:24 - loss: 3.5326 - accuracy: 0.10 - ETA: 1:23 - loss: 3.5327 - accuracy: 0.10 - ETA: 1:22 - loss: 3.5323 - accuracy: 0.10 - ETA: 1:21 - loss: 3.5331 - accuracy: 0.10 - ETA: 1:20 - loss: 3.5351 - accuracy: 0.10 - ETA: 1:19 - loss: 3.5345 - accuracy: 0.10 - ETA: 1:18 - loss: 3.5341 - accuracy: 0.10 - ETA: 1:17 - loss: 3.5341 - accuracy: 0.10 - ETA: 1:16 - loss: 3.5335 - accuracy: 0.10 - ETA: 1:15 - loss: 3.5329 - accuracy: 0.10 - ETA: 1:14 - loss: 3.5331 - accuracy: 0.10 - ETA: 1:13 - loss: 3.5330 - accuracy: 0.10 - ETA: 1:12 - loss: 3.5329 - accuracy: 0.10 - ETA: 1:11 - loss: 3.5325 - accuracy: 0.10 - ETA: 1:11 - loss: 3.5320 - accuracy: 0.10 - ETA: 1:10 - loss: 3.5320 - accuracy: 0.10 - ETA: 1:09 - loss: 3.5315 - accuracy: 0.10 - ETA: 1:08 - loss: 3.5316 - accuracy: 0.10 - ETA: 1:07 - loss: 3.5315 - accuracy: 0.10 - ETA: 1:06 - loss: 3.5320 - accuracy: 0.10 - ETA: 1:05 - loss: 3.5321 - accuracy: 0.10 - ETA: 1:04 - loss: 3.5326 - accuracy: 0.10 - ETA: 1:03 - loss: 3.5324 - accuracy: 0.10 - ETA: 1:02 - loss: 3.5332 - accuracy: 0.10 - ETA: 1:01 - loss: 3.5335 - accuracy: 0.10 - ETA: 1:00 - loss: 3.5342 - accuracy: 0.10 - ETA: 59s - loss: 3.5343 - accuracy: 0.1050 - ETA: 58s - loss: 3.5348 - accuracy: 0.104 - ETA: 57s - loss: 3.5356 - accuracy: 0.104 - ETA: 56s - loss: 3.5359 - accuracy: 0.104 - ETA: 55s - loss: 3.5364 - accuracy: 0.104 - ETA: 54s - loss: 3.5360 - accuracy: 0.105 - ETA: 53s - loss: 3.5354 - accuracy: 0.105 - ETA: 52s - loss: 3.5353 - accuracy: 0.105 - ETA: 51s - loss: 3.5354 - accuracy: 0.105 - ETA: 50s - loss: 3.5353 - accuracy: 0.105 - ETA: 50s - loss: 3.5349 - accuracy: 0.105 - ETA: 49s - loss: 3.5342 - accuracy: 0.105 - ETA: 48s - loss: 3.5341 - accuracy: 0.105 - ETA: 47s - loss: 3.5341 - accuracy: 0.105 - ETA: 46s - loss: 3.5341 - accuracy: 0.105 - ETA: 45s - loss: 3.5336 - accuracy: 0.105 - ETA: 44s - loss: 3.5339 - accuracy: 0.105 - ETA: 43s - loss: 3.5337 - accuracy: 0.105 - ETA: 42s - loss: 3.5336 - accuracy: 0.105 - ETA: 41s - loss: 3.5335 - accuracy: 0.105 - ETA: 40s - loss: 3.5329 - accuracy: 0.106 - ETA: 39s - loss: 3.5331 - accuracy: 0.105 - ETA: 38s - loss: 3.5333 - accuracy: 0.105 - ETA: 37s - loss: 3.5334 - accuracy: 0.105 - ETA: 36s - loss: 3.5326 - accuracy: 0.105 - ETA: 35s - loss: 3.5320 - accuracy: 0.105 - ETA: 34s - loss: 3.5321 - accuracy: 0.105 - ETA: 33s - loss: 3.5316 - accuracy: 0.105 - ETA: 32s - loss: 3.5312 - accuracy: 0.105 - ETA: 31s - loss: 3.5312 - accuracy: 0.105 - ETA: 30s - loss: 3.5310 - accuracy: 0.105 - ETA: 29s - loss: 3.5305 - accuracy: 0.105 - ETA: 28s - loss: 3.5305 - accuracy: 0.105 - ETA: 27s - loss: 3.5304 - accuracy: 0.105 - ETA: 26s - loss: 3.5307 - accuracy: 0.105 - ETA: 25s - loss: 3.5303 - accuracy: 0.106 - ETA: 25s - loss: 3.5300 - accuracy: 0.106 - ETA: 24s - loss: 3.5298 - accuracy: 0.106 - ETA: 23s - loss: 3.5300 - accuracy: 0.106 - ETA: 22s - loss: 3.5296 - accuracy: 0.106 - ETA: 21s - loss: 3.5290 - accuracy: 0.105 - ETA: 20s - loss: 3.5286 - accuracy: 0.105 - ETA: 19s - loss: 3.5285 - accuracy: 0.106 - ETA: 18s - loss: 3.5281 - accuracy: 0.105 - ETA: 17s - loss: 3.5276 - accuracy: 0.106 - ETA: 16s - loss: 3.5275 - accuracy: 0.106 - ETA: 15s - loss: 3.5273 - accuracy: 0.106 - ETA: 14s - loss: 3.5270 - accuracy: 0.106 - ETA: 13s - loss: 3.5269 - accuracy: 0.106 - ETA: 12s - loss: 3.5269 - accuracy: 0.106 - ETA: 11s - loss: 3.5269 - accuracy: 0.106 - ETA: 10s - loss: 3.5265 - accuracy: 0.106 - ETA: 9s - loss: 3.5262 - accuracy: 0.106 - ETA: 8s - loss: 3.5262 - accuracy: 0.10 - ETA: 7s - loss: 3.5265 - accuracy: 0.10 - ETA: 6s - loss: 3.5266 - accuracy: 0.10 - ETA: 5s - loss: 3.5269 - accuracy: 0.10 - ETA: 4s - loss: 3.5261 - accuracy: 0.10 - ETA: 3s - loss: 3.5256 - accuracy: 0.10 - ETA: 2s - loss: 3.5245 - accuracy: 0.10 - ETA: 1s - loss: 3.5245 - accuracy: 0.10 - ETA: 1s - loss: 3.5238 - accuracy: 0.10 - ETA: 0s - loss: 3.5235 - accuracy: 0.10 - 343s 8ms/step - loss: 3.5235 - accuracy: 0.1069 - val_loss: 3.9618 - val_accuracy: 0.0126\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:40 - loss: 3.4694 - accuracy: 0.11 - ETA: 5:39 - loss: 3.5237 - accuracy: 0.10 - ETA: 5:31 - loss: 3.4561 - accuracy: 0.11 - ETA: 5:30 - loss: 3.4643 - accuracy: 0.11 - ETA: 5:27 - loss: 3.4541 - accuracy: 0.11 - ETA: 5:27 - loss: 3.4399 - accuracy: 0.12 - ETA: 5:27 - loss: 3.4321 - accuracy: 0.12 - ETA: 5:27 - loss: 3.4253 - accuracy: 0.12 - ETA: 5:24 - loss: 3.4102 - accuracy: 0.12 - ETA: 5:21 - loss: 3.4066 - accuracy: 0.12 - ETA: 5:20 - loss: 3.4152 - accuracy: 0.12 - ETA: 5:17 - loss: 3.4120 - accuracy: 0.12 - ETA: 5:14 - loss: 3.4190 - accuracy: 0.12 - ETA: 5:12 - loss: 3.4221 - accuracy: 0.12 - ETA: 5:09 - loss: 3.4182 - accuracy: 0.12 - ETA: 5:07 - loss: 3.4210 - accuracy: 0.12 - ETA: 5:06 - loss: 3.4195 - accuracy: 0.12 - ETA: 5:05 - loss: 3.4216 - accuracy: 0.12 - ETA: 5:05 - loss: 3.4205 - accuracy: 0.12 - ETA: 5:03 - loss: 3.4246 - accuracy: 0.12 - ETA: 5:02 - loss: 3.4272 - accuracy: 0.12 - ETA: 5:01 - loss: 3.4279 - accuracy: 0.12 - ETA: 5:01 - loss: 3.4256 - accuracy: 0.12 - ETA: 4:59 - loss: 3.4173 - accuracy: 0.12 - ETA: 4:58 - loss: 3.4167 - accuracy: 0.12 - ETA: 4:57 - loss: 3.4136 - accuracy: 0.12 - ETA: 4:56 - loss: 3.4124 - accuracy: 0.12 - ETA: 4:54 - loss: 3.4123 - accuracy: 0.12 - ETA: 4:53 - loss: 3.4050 - accuracy: 0.12 - ETA: 4:51 - loss: 3.3994 - accuracy: 0.12 - ETA: 4:50 - loss: 3.4009 - accuracy: 0.12 - ETA: 4:48 - loss: 3.3997 - accuracy: 0.12 - ETA: 4:48 - loss: 3.3988 - accuracy: 0.12 - ETA: 4:47 - loss: 3.3995 - accuracy: 0.12 - ETA: 4:46 - loss: 3.3969 - accuracy: 0.12 - ETA: 4:45 - loss: 3.4021 - accuracy: 0.12 - ETA: 4:44 - loss: 3.4063 - accuracy: 0.12 - ETA: 4:43 - loss: 3.4070 - accuracy: 0.12 - ETA: 4:42 - loss: 3.4045 - accuracy: 0.12 - ETA: 4:41 - loss: 3.3986 - accuracy: 0.12 - ETA: 4:41 - loss: 3.3988 - accuracy: 0.12 - ETA: 4:41 - loss: 3.4013 - accuracy: 0.12 - ETA: 4:41 - loss: 3.3993 - accuracy: 0.12 - ETA: 4:40 - loss: 3.3965 - accuracy: 0.12 - ETA: 4:39 - loss: 3.4004 - accuracy: 0.12 - ETA: 4:38 - loss: 3.4006 - accuracy: 0.12 - ETA: 4:36 - loss: 3.3997 - accuracy: 0.12 - ETA: 4:35 - loss: 3.4030 - accuracy: 0.12 - ETA: 4:34 - loss: 3.4041 - accuracy: 0.12 - ETA: 4:33 - loss: 3.4078 - accuracy: 0.12 - ETA: 4:32 - loss: 3.4096 - accuracy: 0.12 - ETA: 4:31 - loss: 3.4087 - accuracy: 0.12 - ETA: 4:30 - loss: 3.4057 - accuracy: 0.12 - ETA: 4:29 - loss: 3.4048 - accuracy: 0.12 - ETA: 4:28 - loss: 3.4013 - accuracy: 0.12 - ETA: 4:27 - loss: 3.4034 - accuracy: 0.12 - ETA: 4:26 - loss: 3.4048 - accuracy: 0.12 - ETA: 4:25 - loss: 3.4020 - accuracy: 0.12 - ETA: 4:24 - loss: 3.4016 - accuracy: 0.12 - ETA: 4:23 - loss: 3.4021 - accuracy: 0.12 - ETA: 4:22 - loss: 3.3982 - accuracy: 0.12 - ETA: 4:20 - loss: 3.3966 - accuracy: 0.12 - ETA: 4:19 - loss: 3.3978 - accuracy: 0.12 - ETA: 4:18 - loss: 3.4002 - accuracy: 0.12 - ETA: 4:17 - loss: 3.3996 - accuracy: 0.12 - ETA: 4:16 - loss: 3.4013 - accuracy: 0.12 - ETA: 4:15 - loss: 3.4011 - accuracy: 0.12 - ETA: 4:13 - loss: 3.4007 - accuracy: 0.12 - ETA: 4:13 - loss: 3.3996 - accuracy: 0.12 - ETA: 4:11 - loss: 3.3996 - accuracy: 0.12 - ETA: 4:11 - loss: 3.4000 - accuracy: 0.12 - ETA: 4:10 - loss: 3.3990 - accuracy: 0.12 - ETA: 4:09 - loss: 3.3970 - accuracy: 0.12 - ETA: 4:08 - loss: 3.3960 - accuracy: 0.12 - ETA: 4:07 - loss: 3.3957 - accuracy: 0.12 - ETA: 4:06 - loss: 3.3953 - accuracy: 0.12 - ETA: 4:05 - loss: 3.3962 - accuracy: 0.12 - ETA: 4:04 - loss: 3.3972 - accuracy: 0.12 - ETA: 4:02 - loss: 3.4003 - accuracy: 0.12 - ETA: 4:01 - loss: 3.4022 - accuracy: 0.12 - ETA: 4:00 - loss: 3.4060 - accuracy: 0.12 - ETA: 3:59 - loss: 3.4075 - accuracy: 0.12 - ETA: 3:58 - loss: 3.4086 - accuracy: 0.12 - ETA: 3:57 - loss: 3.4094 - accuracy: 0.12 - ETA: 3:56 - loss: 3.4090 - accuracy: 0.12 - ETA: 3:55 - loss: 3.4104 - accuracy: 0.12 - ETA: 3:54 - loss: 3.4092 - accuracy: 0.12 - ETA: 3:53 - loss: 3.4103 - accuracy: 0.12 - ETA: 3:52 - loss: 3.4102 - accuracy: 0.12 - ETA: 3:51 - loss: 3.4095 - accuracy: 0.12 - ETA: 3:50 - loss: 3.4095 - accuracy: 0.12 - ETA: 3:49 - loss: 3.4079 - accuracy: 0.12 - ETA: 3:48 - loss: 3.4084 - accuracy: 0.12 - ETA: 3:47 - loss: 3.4089 - accuracy: 0.12 - ETA: 3:47 - loss: 3.4094 - accuracy: 0.12 - ETA: 3:45 - loss: 3.4073 - accuracy: 0.12 - ETA: 3:44 - loss: 3.4047 - accuracy: 0.12 - ETA: 3:43 - loss: 3.4049 - accuracy: 0.12 - ETA: 3:42 - loss: 3.4057 - accuracy: 0.12 - ETA: 3:41 - loss: 3.4065 - accuracy: 0.12 - ETA: 3:41 - loss: 3.4066 - accuracy: 0.12 - ETA: 3:40 - loss: 3.4072 - accuracy: 0.12 - ETA: 3:39 - loss: 3.4075 - accuracy: 0.12 - ETA: 3:37 - loss: 3.4075 - accuracy: 0.12 - ETA: 3:37 - loss: 3.4069 - accuracy: 0.12 - ETA: 3:36 - loss: 3.4072 - accuracy: 0.12 - ETA: 3:35 - loss: 3.4071 - accuracy: 0.12 - ETA: 3:34 - loss: 3.4060 - accuracy: 0.12 - ETA: 3:33 - loss: 3.4060 - accuracy: 0.12 - ETA: 3:32 - loss: 3.4042 - accuracy: 0.12 - ETA: 3:31 - loss: 3.4035 - accuracy: 0.12 - ETA: 3:30 - loss: 3.4039 - accuracy: 0.12 - ETA: 3:29 - loss: 3.4040 - accuracy: 0.12 - ETA: 3:28 - loss: 3.4032 - accuracy: 0.12 - ETA: 3:27 - loss: 3.4019 - accuracy: 0.12 - ETA: 3:26 - loss: 3.4018 - accuracy: 0.12 - ETA: 3:25 - loss: 3.4007 - accuracy: 0.12 - ETA: 3:24 - loss: 3.4014 - accuracy: 0.12 - ETA: 3:23 - loss: 3.4034 - accuracy: 0.12 - ETA: 3:22 - loss: 3.4023 - accuracy: 0.12 - ETA: 3:21 - loss: 3.4027 - accuracy: 0.12 - ETA: 3:20 - loss: 3.4027 - accuracy: 0.12 - ETA: 3:19 - loss: 3.4020 - accuracy: 0.12 - ETA: 3:18 - loss: 3.4014 - accuracy: 0.12 - ETA: 3:18 - loss: 3.4032 - accuracy: 0.12 - ETA: 3:16 - loss: 3.4030 - accuracy: 0.12 - ETA: 3:15 - loss: 3.4024 - accuracy: 0.12 - ETA: 3:15 - loss: 3.4031 - accuracy: 0.12 - ETA: 3:14 - loss: 3.4025 - accuracy: 0.12 - ETA: 3:12 - loss: 3.4034 - accuracy: 0.12 - ETA: 3:11 - loss: 3.4031 - accuracy: 0.12 - ETA: 3:11 - loss: 3.4031 - accuracy: 0.12 - ETA: 3:09 - loss: 3.4029 - accuracy: 0.12 - ETA: 3:09 - loss: 3.4033 - accuracy: 0.12 - ETA: 3:08 - loss: 3.4038 - accuracy: 0.12 - ETA: 3:07 - loss: 3.4030 - accuracy: 0.12 - ETA: 3:06 - loss: 3.4039 - accuracy: 0.12 - ETA: 3:05 - loss: 3.4042 - accuracy: 0.12 - ETA: 3:04 - loss: 3.4035 - accuracy: 0.12 - ETA: 3:03 - loss: 3.4026 - accuracy: 0.12 - ETA: 3:02 - loss: 3.4020 - accuracy: 0.12 - ETA: 3:01 - loss: 3.4014 - accuracy: 0.12 - ETA: 3:00 - loss: 3.4019 - accuracy: 0.12 - ETA: 2:59 - loss: 3.4023 - accuracy: 0.12 - ETA: 2:58 - loss: 3.4028 - accuracy: 0.12 - ETA: 2:57 - loss: 3.4022 - accuracy: 0.12 - ETA: 2:56 - loss: 3.4026 - accuracy: 0.12 - ETA: 2:55 - loss: 3.4030 - accuracy: 0.12 - ETA: 2:54 - loss: 3.4026 - accuracy: 0.12 - ETA: 2:53 - loss: 3.4024 - accuracy: 0.12 - ETA: 2:52 - loss: 3.4020 - accuracy: 0.12 - ETA: 2:51 - loss: 3.4023 - accuracy: 0.12 - ETA: 2:50 - loss: 3.4023 - accuracy: 0.12 - ETA: 2:49 - loss: 3.4024 - accuracy: 0.12 - ETA: 2:48 - loss: 3.4026 - accuracy: 0.12 - ETA: 2:48 - loss: 3.4020 - accuracy: 0.12 - ETA: 2:47 - loss: 3.4023 - accuracy: 0.12 - ETA: 2:46 - loss: 3.4010 - accuracy: 0.12 - ETA: 2:45 - loss: 3.3999 - accuracy: 0.12 - ETA: 2:44 - loss: 3.4003 - accuracy: 0.12 - ETA: 2:43 - loss: 3.3996 - accuracy: 0.12 - ETA: 2:42 - loss: 3.3995 - accuracy: 0.12 - ETA: 2:41 - loss: 3.4002 - accuracy: 0.12 - ETA: 2:40 - loss: 3.3993 - accuracy: 0.12 - ETA: 2:39 - loss: 3.3993 - accuracy: 0.12 - ETA: 2:38 - loss: 3.3986 - accuracy: 0.12 - ETA: 2:37 - loss: 3.3981 - accuracy: 0.12 - ETA: 2:36 - loss: 3.3974 - accuracy: 0.12 - ETA: 2:35 - loss: 3.3972 - accuracy: 0.12 - ETA: 2:34 - loss: 3.3965 - accuracy: 0.12 - ETA: 2:33 - loss: 3.3959 - accuracy: 0.12 - ETA: 2:32 - loss: 3.3957 - accuracy: 0.12 - ETA: 2:31 - loss: 3.3961 - accuracy: 0.12 - ETA: 2:30 - loss: 3.3958 - accuracy: 0.12 - ETA: 2:29 - loss: 3.3952 - accuracy: 0.12 - ETA: 2:28 - loss: 3.3947 - accuracy: 0.12 - ETA: 2:27 - loss: 3.3935 - accuracy: 0.12 - ETA: 2:26 - loss: 3.3934 - accuracy: 0.12 - ETA: 2:26 - loss: 3.3936 - accuracy: 0.12 - ETA: 2:25 - loss: 3.3939 - accuracy: 0.12 - ETA: 2:24 - loss: 3.3941 - accuracy: 0.12 - ETA: 2:23 - loss: 3.3938 - accuracy: 0.12 - ETA: 2:22 - loss: 3.3946 - accuracy: 0.12 - ETA: 2:21 - loss: 3.3940 - accuracy: 0.12 - ETA: 2:20 - loss: 3.3948 - accuracy: 0.12 - ETA: 2:19 - loss: 3.3946 - accuracy: 0.1281"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.3947 - accuracy: 0.12 - ETA: 2:17 - loss: 3.3945 - accuracy: 0.12 - ETA: 2:16 - loss: 3.3945 - accuracy: 0.12 - ETA: 2:15 - loss: 3.3945 - accuracy: 0.12 - ETA: 2:14 - loss: 3.3941 - accuracy: 0.12 - ETA: 2:13 - loss: 3.3932 - accuracy: 0.12 - ETA: 2:12 - loss: 3.3932 - accuracy: 0.12 - ETA: 2:11 - loss: 3.3934 - accuracy: 0.12 - ETA: 2:10 - loss: 3.3932 - accuracy: 0.12 - ETA: 2:09 - loss: 3.3937 - accuracy: 0.12 - ETA: 2:08 - loss: 3.3943 - accuracy: 0.12 - ETA: 2:07 - loss: 3.3944 - accuracy: 0.12 - ETA: 2:06 - loss: 3.3947 - accuracy: 0.12 - ETA: 2:05 - loss: 3.3942 - accuracy: 0.12 - ETA: 2:04 - loss: 3.3943 - accuracy: 0.12 - ETA: 2:04 - loss: 3.3946 - accuracy: 0.12 - ETA: 2:03 - loss: 3.3949 - accuracy: 0.12 - ETA: 2:02 - loss: 3.3961 - accuracy: 0.12 - ETA: 2:01 - loss: 3.3953 - accuracy: 0.12 - ETA: 2:00 - loss: 3.3950 - accuracy: 0.12 - ETA: 1:59 - loss: 3.3952 - accuracy: 0.12 - ETA: 1:58 - loss: 3.3954 - accuracy: 0.12 - ETA: 1:57 - loss: 3.3958 - accuracy: 0.12 - ETA: 1:56 - loss: 3.3966 - accuracy: 0.12 - ETA: 1:55 - loss: 3.3962 - accuracy: 0.12 - ETA: 1:54 - loss: 3.3961 - accuracy: 0.12 - ETA: 1:53 - loss: 3.3961 - accuracy: 0.12 - ETA: 1:52 - loss: 3.3949 - accuracy: 0.12 - ETA: 1:51 - loss: 3.3947 - accuracy: 0.12 - ETA: 1:50 - loss: 3.3946 - accuracy: 0.12 - ETA: 1:49 - loss: 3.3946 - accuracy: 0.12 - ETA: 1:48 - loss: 3.3953 - accuracy: 0.12 - ETA: 1:47 - loss: 3.3949 - accuracy: 0.12 - ETA: 1:46 - loss: 3.3941 - accuracy: 0.12 - ETA: 1:45 - loss: 3.3941 - accuracy: 0.12 - ETA: 1:44 - loss: 3.3947 - accuracy: 0.12 - ETA: 1:43 - loss: 3.3951 - accuracy: 0.12 - ETA: 1:42 - loss: 3.3952 - accuracy: 0.12 - ETA: 1:41 - loss: 3.3951 - accuracy: 0.12 - ETA: 1:40 - loss: 3.3957 - accuracy: 0.12 - ETA: 1:40 - loss: 3.3955 - accuracy: 0.12 - ETA: 1:39 - loss: 3.3953 - accuracy: 0.12 - ETA: 1:38 - loss: 3.3952 - accuracy: 0.12 - ETA: 1:37 - loss: 3.3954 - accuracy: 0.12 - ETA: 1:36 - loss: 3.3955 - accuracy: 0.12 - ETA: 1:35 - loss: 3.3953 - accuracy: 0.12 - ETA: 1:34 - loss: 3.3945 - accuracy: 0.12 - ETA: 1:33 - loss: 3.3945 - accuracy: 0.12 - ETA: 1:32 - loss: 3.3946 - accuracy: 0.12 - ETA: 1:31 - loss: 3.3941 - accuracy: 0.12 - ETA: 1:30 - loss: 3.3935 - accuracy: 0.12 - ETA: 1:29 - loss: 3.3937 - accuracy: 0.12 - ETA: 1:28 - loss: 3.3935 - accuracy: 0.12 - ETA: 1:27 - loss: 3.3934 - accuracy: 0.12 - ETA: 1:26 - loss: 3.3935 - accuracy: 0.12 - ETA: 1:25 - loss: 3.3933 - accuracy: 0.12 - ETA: 1:24 - loss: 3.3929 - accuracy: 0.12 - ETA: 1:23 - loss: 3.3930 - accuracy: 0.12 - ETA: 1:22 - loss: 3.3937 - accuracy: 0.12 - ETA: 1:21 - loss: 3.3939 - accuracy: 0.12 - ETA: 1:20 - loss: 3.3933 - accuracy: 0.12 - ETA: 1:19 - loss: 3.3939 - accuracy: 0.12 - ETA: 1:18 - loss: 3.3941 - accuracy: 0.12 - ETA: 1:17 - loss: 3.3938 - accuracy: 0.12 - ETA: 1:16 - loss: 3.3935 - accuracy: 0.12 - ETA: 1:15 - loss: 3.3930 - accuracy: 0.12 - ETA: 1:14 - loss: 3.3925 - accuracy: 0.12 - ETA: 1:13 - loss: 3.3918 - accuracy: 0.12 - ETA: 1:13 - loss: 3.3912 - accuracy: 0.12 - ETA: 1:12 - loss: 3.3911 - accuracy: 0.12 - ETA: 1:11 - loss: 3.3909 - accuracy: 0.12 - ETA: 1:10 - loss: 3.3909 - accuracy: 0.12 - ETA: 1:09 - loss: 3.3905 - accuracy: 0.12 - ETA: 1:08 - loss: 3.3906 - accuracy: 0.12 - ETA: 1:07 - loss: 3.3899 - accuracy: 0.12 - ETA: 1:06 - loss: 3.3897 - accuracy: 0.12 - ETA: 1:05 - loss: 3.3901 - accuracy: 0.12 - ETA: 1:04 - loss: 3.3902 - accuracy: 0.12 - ETA: 1:03 - loss: 3.3899 - accuracy: 0.12 - ETA: 1:02 - loss: 3.3894 - accuracy: 0.12 - ETA: 1:01 - loss: 3.3890 - accuracy: 0.12 - ETA: 1:00 - loss: 3.3888 - accuracy: 0.12 - ETA: 59s - loss: 3.3892 - accuracy: 0.1294 - ETA: 58s - loss: 3.3895 - accuracy: 0.129 - ETA: 57s - loss: 3.3895 - accuracy: 0.129 - ETA: 56s - loss: 3.3894 - accuracy: 0.129 - ETA: 55s - loss: 3.3896 - accuracy: 0.129 - ETA: 54s - loss: 3.3896 - accuracy: 0.129 - ETA: 53s - loss: 3.3896 - accuracy: 0.129 - ETA: 52s - loss: 3.3896 - accuracy: 0.129 - ETA: 51s - loss: 3.3893 - accuracy: 0.129 - ETA: 50s - loss: 3.3890 - accuracy: 0.129 - ETA: 49s - loss: 3.3883 - accuracy: 0.129 - ETA: 48s - loss: 3.3881 - accuracy: 0.129 - ETA: 48s - loss: 3.3878 - accuracy: 0.129 - ETA: 47s - loss: 3.3887 - accuracy: 0.129 - ETA: 46s - loss: 3.3881 - accuracy: 0.129 - ETA: 45s - loss: 3.3878 - accuracy: 0.129 - ETA: 44s - loss: 3.3882 - accuracy: 0.129 - ETA: 43s - loss: 3.3879 - accuracy: 0.129 - ETA: 42s - loss: 3.3880 - accuracy: 0.129 - ETA: 41s - loss: 3.3881 - accuracy: 0.129 - ETA: 40s - loss: 3.3878 - accuracy: 0.129 - ETA: 39s - loss: 3.3875 - accuracy: 0.129 - ETA: 38s - loss: 3.3871 - accuracy: 0.129 - ETA: 37s - loss: 3.3871 - accuracy: 0.129 - ETA: 36s - loss: 3.3866 - accuracy: 0.129 - ETA: 35s - loss: 3.3869 - accuracy: 0.129 - ETA: 34s - loss: 3.3860 - accuracy: 0.129 - ETA: 33s - loss: 3.3860 - accuracy: 0.129 - ETA: 32s - loss: 3.3862 - accuracy: 0.129 - ETA: 31s - loss: 3.3861 - accuracy: 0.129 - ETA: 30s - loss: 3.3857 - accuracy: 0.129 - ETA: 29s - loss: 3.3857 - accuracy: 0.129 - ETA: 28s - loss: 3.3857 - accuracy: 0.129 - ETA: 27s - loss: 3.3857 - accuracy: 0.129 - ETA: 26s - loss: 3.3851 - accuracy: 0.130 - ETA: 25s - loss: 3.3850 - accuracy: 0.130 - ETA: 24s - loss: 3.3849 - accuracy: 0.130 - ETA: 24s - loss: 3.3850 - accuracy: 0.130 - ETA: 23s - loss: 3.3846 - accuracy: 0.130 - ETA: 22s - loss: 3.3842 - accuracy: 0.130 - ETA: 21s - loss: 3.3843 - accuracy: 0.130 - ETA: 20s - loss: 3.3847 - accuracy: 0.130 - ETA: 19s - loss: 3.3844 - accuracy: 0.130 - ETA: 18s - loss: 3.3840 - accuracy: 0.130 - ETA: 17s - loss: 3.3836 - accuracy: 0.130 - ETA: 16s - loss: 3.3837 - accuracy: 0.130 - ETA: 15s - loss: 3.3839 - accuracy: 0.130 - ETA: 14s - loss: 3.3833 - accuracy: 0.130 - ETA: 13s - loss: 3.3829 - accuracy: 0.130 - ETA: 12s - loss: 3.3828 - accuracy: 0.130 - ETA: 11s - loss: 3.3829 - accuracy: 0.130 - ETA: 10s - loss: 3.3830 - accuracy: 0.130 - ETA: 9s - loss: 3.3829 - accuracy: 0.130 - ETA: 8s - loss: 3.3828 - accuracy: 0.13 - ETA: 7s - loss: 3.3824 - accuracy: 0.13 - ETA: 6s - loss: 3.3825 - accuracy: 0.13 - ETA: 5s - loss: 3.3822 - accuracy: 0.13 - ETA: 4s - loss: 3.3822 - accuracy: 0.13 - ETA: 3s - loss: 3.3818 - accuracy: 0.13 - ETA: 2s - loss: 3.3820 - accuracy: 0.13 - ETA: 1s - loss: 3.3819 - accuracy: 0.13 - ETA: 1s - loss: 3.3822 - accuracy: 0.13 - ETA: 0s - loss: 3.3822 - accuracy: 0.13 - 341s 8ms/step - loss: 3.3822 - accuracy: 0.1309 - val_loss: 3.9693 - val_accuracy: 0.0130\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:49 - loss: 3.4012 - accuracy: 0.13 - ETA: 4:52 - loss: 3.4017 - accuracy: 0.11 - ETA: 4:56 - loss: 3.4150 - accuracy: 0.11 - ETA: 5:03 - loss: 3.4024 - accuracy: 0.12 - ETA: 4:58 - loss: 3.4077 - accuracy: 0.12 - ETA: 4:59 - loss: 3.4146 - accuracy: 0.11 - ETA: 4:59 - loss: 3.4032 - accuracy: 0.12 - ETA: 4:58 - loss: 3.4116 - accuracy: 0.12 - ETA: 4:57 - loss: 3.4215 - accuracy: 0.11 - ETA: 4:58 - loss: 3.4247 - accuracy: 0.11 - ETA: 4:56 - loss: 3.4165 - accuracy: 0.11 - ETA: 4:54 - loss: 3.4070 - accuracy: 0.12 - ETA: 4:56 - loss: 3.4026 - accuracy: 0.12 - ETA: 4:56 - loss: 3.4105 - accuracy: 0.12 - ETA: 4:56 - loss: 3.3974 - accuracy: 0.12 - ETA: 4:56 - loss: 3.3877 - accuracy: 0.12 - ETA: 4:55 - loss: 3.3717 - accuracy: 0.13 - ETA: 4:54 - loss: 3.3675 - accuracy: 0.13 - ETA: 4:55 - loss: 3.3648 - accuracy: 0.13 - ETA: 4:53 - loss: 3.3635 - accuracy: 0.13 - ETA: 4:52 - loss: 3.3772 - accuracy: 0.13 - ETA: 4:51 - loss: 3.3787 - accuracy: 0.13 - ETA: 4:51 - loss: 3.3784 - accuracy: 0.13 - ETA: 4:49 - loss: 3.3789 - accuracy: 0.13 - ETA: 4:48 - loss: 3.3727 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3732 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3700 - accuracy: 0.13 - ETA: 4:45 - loss: 3.3679 - accuracy: 0.13 - ETA: 4:45 - loss: 3.3668 - accuracy: 0.13 - ETA: 4:45 - loss: 3.3654 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3597 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3619 - accuracy: 0.13 - ETA: 4:43 - loss: 3.3623 - accuracy: 0.13 - ETA: 4:42 - loss: 3.3571 - accuracy: 0.14 - ETA: 4:42 - loss: 3.3562 - accuracy: 0.14 - ETA: 4:41 - loss: 3.3549 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3583 - accuracy: 0.13 - ETA: 4:39 - loss: 3.3594 - accuracy: 0.13 - ETA: 4:39 - loss: 3.3591 - accuracy: 0.14 - ETA: 4:38 - loss: 3.3599 - accuracy: 0.14 - ETA: 4:36 - loss: 3.3637 - accuracy: 0.14 - ETA: 4:35 - loss: 3.3655 - accuracy: 0.14 - ETA: 4:34 - loss: 3.3658 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3668 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3727 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3715 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3718 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3701 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3695 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3690 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3699 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3696 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3704 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3697 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3677 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3690 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3696 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3691 - accuracy: 0.13 - ETA: 4:18 - loss: 3.3694 - accuracy: 0.13 - ETA: 4:17 - loss: 3.3693 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3703 - accuracy: 0.13 - ETA: 4:15 - loss: 3.3687 - accuracy: 0.13 - ETA: 4:14 - loss: 3.3666 - accuracy: 0.13 - ETA: 4:14 - loss: 3.3667 - accuracy: 0.13 - ETA: 4:13 - loss: 3.3675 - accuracy: 0.13 - ETA: 4:12 - loss: 3.3702 - accuracy: 0.13 - ETA: 4:11 - loss: 3.3703 - accuracy: 0.13 - ETA: 4:10 - loss: 3.3714 - accuracy: 0.13 - ETA: 4:10 - loss: 3.3737 - accuracy: 0.13 - ETA: 4:08 - loss: 3.3773 - accuracy: 0.13 - ETA: 4:07 - loss: 3.3776 - accuracy: 0.13 - ETA: 4:07 - loss: 3.3758 - accuracy: 0.13 - ETA: 4:06 - loss: 3.3756 - accuracy: 0.13 - ETA: 4:05 - loss: 3.3767 - accuracy: 0.13 - ETA: 4:04 - loss: 3.3771 - accuracy: 0.13 - ETA: 4:03 - loss: 3.3763 - accuracy: 0.13 - ETA: 4:02 - loss: 3.3759 - accuracy: 0.13 - ETA: 4:01 - loss: 3.3763 - accuracy: 0.13 - ETA: 4:00 - loss: 3.3755 - accuracy: 0.13 - ETA: 3:59 - loss: 3.3752 - accuracy: 0.13 - ETA: 3:58 - loss: 3.3747 - accuracy: 0.13 - ETA: 3:57 - loss: 3.3714 - accuracy: 0.13 - ETA: 3:57 - loss: 3.3709 - accuracy: 0.13 - ETA: 3:56 - loss: 3.3703 - accuracy: 0.13 - ETA: 3:55 - loss: 3.3698 - accuracy: 0.13 - ETA: 3:54 - loss: 3.3709 - accuracy: 0.13 - ETA: 3:53 - loss: 3.3703 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3710 - accuracy: 0.13 - ETA: 3:51 - loss: 3.3725 - accuracy: 0.13 - ETA: 3:50 - loss: 3.3724 - accuracy: 0.13 - ETA: 3:49 - loss: 3.3746 - accuracy: 0.13 - ETA: 3:48 - loss: 3.3761 - accuracy: 0.13 - ETA: 3:47 - loss: 3.3762 - accuracy: 0.13 - ETA: 3:45 - loss: 3.3782 - accuracy: 0.13 - ETA: 3:44 - loss: 3.3796 - accuracy: 0.13 - ETA: 3:44 - loss: 3.3802 - accuracy: 0.13 - ETA: 3:43 - loss: 3.3808 - accuracy: 0.13 - ETA: 3:42 - loss: 3.3801 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3817 - accuracy: 0.13 - ETA: 3:40 - loss: 3.3842 - accuracy: 0.13 - ETA: 3:40 - loss: 3.3855 - accuracy: 0.13 - ETA: 3:39 - loss: 3.3861 - accuracy: 0.13 - ETA: 3:38 - loss: 3.3868 - accuracy: 0.13 - ETA: 3:37 - loss: 3.3875 - accuracy: 0.13 - ETA: 3:36 - loss: 3.3893 - accuracy: 0.13 - ETA: 3:35 - loss: 3.3913 - accuracy: 0.13 - ETA: 3:34 - loss: 3.3916 - accuracy: 0.13 - ETA: 3:33 - loss: 3.3937 - accuracy: 0.13 - ETA: 3:32 - loss: 3.3950 - accuracy: 0.13 - ETA: 3:31 - loss: 3.3958 - accuracy: 0.13 - ETA: 3:30 - loss: 3.3970 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3984 - accuracy: 0.13 - ETA: 3:28 - loss: 3.3994 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3992 - accuracy: 0.13 - ETA: 3:26 - loss: 3.4010 - accuracy: 0.12 - ETA: 3:25 - loss: 3.4024 - accuracy: 0.12 - ETA: 3:24 - loss: 3.4032 - accuracy: 0.12 - ETA: 3:23 - loss: 3.4041 - accuracy: 0.12 - ETA: 3:23 - loss: 3.4053 - accuracy: 0.12 - ETA: 3:22 - loss: 3.4060 - accuracy: 0.12 - ETA: 3:21 - loss: 3.4079 - accuracy: 0.12 - ETA: 3:20 - loss: 3.4096 - accuracy: 0.12 - ETA: 3:19 - loss: 3.4113 - accuracy: 0.12 - ETA: 3:18 - loss: 3.4131 - accuracy: 0.12 - ETA: 3:17 - loss: 3.4129 - accuracy: 0.12 - ETA: 3:16 - loss: 3.4139 - accuracy: 0.12 - ETA: 3:15 - loss: 3.4152 - accuracy: 0.12 - ETA: 3:14 - loss: 3.4164 - accuracy: 0.12 - ETA: 3:13 - loss: 3.4164 - accuracy: 0.12 - ETA: 3:12 - loss: 3.4160 - accuracy: 0.12 - ETA: 3:11 - loss: 3.4172 - accuracy: 0.12 - ETA: 3:10 - loss: 3.4179 - accuracy: 0.12 - ETA: 3:09 - loss: 3.4193 - accuracy: 0.12 - ETA: 3:08 - loss: 3.4189 - accuracy: 0.12 - ETA: 3:08 - loss: 3.4195 - accuracy: 0.12 - ETA: 3:07 - loss: 3.4215 - accuracy: 0.12 - ETA: 3:06 - loss: 3.4233 - accuracy: 0.12 - ETA: 3:05 - loss: 3.4233 - accuracy: 0.12 - ETA: 3:04 - loss: 3.4239 - accuracy: 0.12 - ETA: 3:03 - loss: 3.4239 - accuracy: 0.12 - ETA: 3:02 - loss: 3.4232 - accuracy: 0.12 - ETA: 3:01 - loss: 3.4241 - accuracy: 0.12 - ETA: 3:00 - loss: 3.4250 - accuracy: 0.12 - ETA: 2:59 - loss: 3.4262 - accuracy: 0.12 - ETA: 2:58 - loss: 3.4267 - accuracy: 0.12 - ETA: 2:57 - loss: 3.4267 - accuracy: 0.12 - ETA: 2:56 - loss: 3.4260 - accuracy: 0.12 - ETA: 2:55 - loss: 3.4279 - accuracy: 0.12 - ETA: 2:54 - loss: 3.4286 - accuracy: 0.12 - ETA: 2:53 - loss: 3.4281 - accuracy: 0.12 - ETA: 2:52 - loss: 3.4280 - accuracy: 0.12 - ETA: 2:51 - loss: 3.4284 - accuracy: 0.12 - ETA: 2:50 - loss: 3.4285 - accuracy: 0.12 - ETA: 2:49 - loss: 3.4284 - accuracy: 0.12 - ETA: 2:48 - loss: 3.4295 - accuracy: 0.12 - ETA: 2:47 - loss: 3.4297 - accuracy: 0.12 - ETA: 2:46 - loss: 3.4298 - accuracy: 0.12 - ETA: 2:45 - loss: 3.4306 - accuracy: 0.12 - ETA: 2:44 - loss: 3.4311 - accuracy: 0.12 - ETA: 2:43 - loss: 3.4313 - accuracy: 0.12 - ETA: 2:42 - loss: 3.4313 - accuracy: 0.12 - ETA: 2:41 - loss: 3.4317 - accuracy: 0.12 - ETA: 2:40 - loss: 3.4304 - accuracy: 0.12 - ETA: 2:39 - loss: 3.4312 - accuracy: 0.12 - ETA: 2:39 - loss: 3.4307 - accuracy: 0.12 - ETA: 2:38 - loss: 3.4311 - accuracy: 0.12 - ETA: 2:37 - loss: 3.4305 - accuracy: 0.12 - ETA: 2:36 - loss: 3.4301 - accuracy: 0.12 - ETA: 2:35 - loss: 3.4301 - accuracy: 0.12 - ETA: 2:34 - loss: 3.4308 - accuracy: 0.12 - ETA: 2:33 - loss: 3.4319 - accuracy: 0.12 - ETA: 2:32 - loss: 3.4322 - accuracy: 0.12 - ETA: 2:31 - loss: 3.4322 - accuracy: 0.12 - ETA: 2:30 - loss: 3.4320 - accuracy: 0.12 - ETA: 2:29 - loss: 3.4321 - accuracy: 0.12 - ETA: 2:28 - loss: 3.4331 - accuracy: 0.12 - ETA: 2:27 - loss: 3.4339 - accuracy: 0.12 - ETA: 2:26 - loss: 3.4350 - accuracy: 0.12 - ETA: 2:25 - loss: 3.4354 - accuracy: 0.12 - ETA: 2:24 - loss: 3.4357 - accuracy: 0.12 - ETA: 2:23 - loss: 3.4357 - accuracy: 0.12 - ETA: 2:22 - loss: 3.4355 - accuracy: 0.12 - ETA: 2:22 - loss: 3.4356 - accuracy: 0.12 - ETA: 2:21 - loss: 3.4356 - accuracy: 0.12 - ETA: 2:20 - loss: 3.4348 - accuracy: 0.12 - ETA: 2:19 - loss: 3.4363 - accuracy: 0.1226"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.4364 - accuracy: 0.12 - ETA: 2:17 - loss: 3.4363 - accuracy: 0.12 - ETA: 2:16 - loss: 3.4365 - accuracy: 0.12 - ETA: 2:15 - loss: 3.4362 - accuracy: 0.12 - ETA: 2:14 - loss: 3.4362 - accuracy: 0.12 - ETA: 2:13 - loss: 3.4361 - accuracy: 0.12 - ETA: 2:12 - loss: 3.4361 - accuracy: 0.12 - ETA: 2:11 - loss: 3.4368 - accuracy: 0.12 - ETA: 2:10 - loss: 3.4382 - accuracy: 0.12 - ETA: 2:09 - loss: 3.4390 - accuracy: 0.12 - ETA: 2:08 - loss: 3.4392 - accuracy: 0.12 - ETA: 2:07 - loss: 3.4389 - accuracy: 0.12 - ETA: 2:06 - loss: 3.4395 - accuracy: 0.12 - ETA: 2:05 - loss: 3.4387 - accuracy: 0.12 - ETA: 2:04 - loss: 3.4392 - accuracy: 0.12 - ETA: 2:03 - loss: 3.4394 - accuracy: 0.12 - ETA: 2:02 - loss: 3.4397 - accuracy: 0.12 - ETA: 2:01 - loss: 3.4401 - accuracy: 0.12 - ETA: 2:00 - loss: 3.4400 - accuracy: 0.12 - ETA: 1:59 - loss: 3.4388 - accuracy: 0.12 - ETA: 1:58 - loss: 3.4388 - accuracy: 0.12 - ETA: 1:57 - loss: 3.4388 - accuracy: 0.12 - ETA: 1:56 - loss: 3.4393 - accuracy: 0.12 - ETA: 1:55 - loss: 3.4393 - accuracy: 0.12 - ETA: 1:54 - loss: 3.4385 - accuracy: 0.12 - ETA: 1:53 - loss: 3.4390 - accuracy: 0.12 - ETA: 1:52 - loss: 3.4394 - accuracy: 0.12 - ETA: 1:51 - loss: 3.4394 - accuracy: 0.12 - ETA: 1:50 - loss: 3.4395 - accuracy: 0.12 - ETA: 1:49 - loss: 3.4394 - accuracy: 0.12 - ETA: 1:49 - loss: 3.4395 - accuracy: 0.12 - ETA: 1:48 - loss: 3.4399 - accuracy: 0.12 - ETA: 1:47 - loss: 3.4393 - accuracy: 0.12 - ETA: 1:46 - loss: 3.4395 - accuracy: 0.12 - ETA: 1:45 - loss: 3.4394 - accuracy: 0.12 - ETA: 1:44 - loss: 3.4397 - accuracy: 0.12 - ETA: 1:43 - loss: 3.4395 - accuracy: 0.12 - ETA: 1:42 - loss: 3.4402 - accuracy: 0.12 - ETA: 1:41 - loss: 3.4402 - accuracy: 0.12 - ETA: 1:40 - loss: 3.4405 - accuracy: 0.12 - ETA: 1:39 - loss: 3.4408 - accuracy: 0.12 - ETA: 1:38 - loss: 3.4412 - accuracy: 0.12 - ETA: 1:37 - loss: 3.4421 - accuracy: 0.12 - ETA: 1:36 - loss: 3.4428 - accuracy: 0.12 - ETA: 1:35 - loss: 3.4431 - accuracy: 0.12 - ETA: 1:34 - loss: 3.4430 - accuracy: 0.12 - ETA: 1:33 - loss: 3.4428 - accuracy: 0.12 - ETA: 1:32 - loss: 3.4426 - accuracy: 0.12 - ETA: 1:31 - loss: 3.4430 - accuracy: 0.12 - ETA: 1:30 - loss: 3.4431 - accuracy: 0.12 - ETA: 1:29 - loss: 3.4435 - accuracy: 0.12 - ETA: 1:28 - loss: 3.4444 - accuracy: 0.12 - ETA: 1:27 - loss: 3.4447 - accuracy: 0.12 - ETA: 1:27 - loss: 3.4449 - accuracy: 0.12 - ETA: 1:26 - loss: 3.4448 - accuracy: 0.12 - ETA: 1:25 - loss: 3.4449 - accuracy: 0.12 - ETA: 1:24 - loss: 3.4444 - accuracy: 0.12 - ETA: 1:23 - loss: 3.4444 - accuracy: 0.12 - ETA: 1:22 - loss: 3.4451 - accuracy: 0.11 - ETA: 1:21 - loss: 3.4456 - accuracy: 0.11 - ETA: 1:20 - loss: 3.4452 - accuracy: 0.11 - ETA: 1:19 - loss: 3.4448 - accuracy: 0.12 - ETA: 1:18 - loss: 3.4449 - accuracy: 0.12 - ETA: 1:17 - loss: 3.4457 - accuracy: 0.11 - ETA: 1:16 - loss: 3.4458 - accuracy: 0.11 - ETA: 1:15 - loss: 3.4460 - accuracy: 0.11 - ETA: 1:14 - loss: 3.4464 - accuracy: 0.11 - ETA: 1:13 - loss: 3.4464 - accuracy: 0.11 - ETA: 1:12 - loss: 3.4466 - accuracy: 0.11 - ETA: 1:11 - loss: 3.4465 - accuracy: 0.11 - ETA: 1:10 - loss: 3.4467 - accuracy: 0.11 - ETA: 1:09 - loss: 3.4466 - accuracy: 0.11 - ETA: 1:08 - loss: 3.4467 - accuracy: 0.11 - ETA: 1:07 - loss: 3.4470 - accuracy: 0.11 - ETA: 1:06 - loss: 3.4475 - accuracy: 0.11 - ETA: 1:05 - loss: 3.4485 - accuracy: 0.11 - ETA: 1:05 - loss: 3.4482 - accuracy: 0.11 - ETA: 1:04 - loss: 3.4485 - accuracy: 0.11 - ETA: 1:03 - loss: 3.4486 - accuracy: 0.11 - ETA: 1:02 - loss: 3.4489 - accuracy: 0.11 - ETA: 1:01 - loss: 3.4489 - accuracy: 0.11 - ETA: 1:00 - loss: 3.4493 - accuracy: 0.11 - ETA: 59s - loss: 3.4493 - accuracy: 0.1190 - ETA: 58s - loss: 3.4496 - accuracy: 0.119 - ETA: 57s - loss: 3.4494 - accuracy: 0.119 - ETA: 56s - loss: 3.4495 - accuracy: 0.119 - ETA: 55s - loss: 3.4494 - accuracy: 0.119 - ETA: 54s - loss: 3.4495 - accuracy: 0.119 - ETA: 53s - loss: 3.4493 - accuracy: 0.119 - ETA: 52s - loss: 3.4492 - accuracy: 0.119 - ETA: 51s - loss: 3.4491 - accuracy: 0.119 - ETA: 50s - loss: 3.4495 - accuracy: 0.119 - ETA: 49s - loss: 3.4498 - accuracy: 0.119 - ETA: 48s - loss: 3.4492 - accuracy: 0.119 - ETA: 47s - loss: 3.4491 - accuracy: 0.119 - ETA: 46s - loss: 3.4492 - accuracy: 0.119 - ETA: 45s - loss: 3.4494 - accuracy: 0.119 - ETA: 45s - loss: 3.4494 - accuracy: 0.119 - ETA: 44s - loss: 3.4496 - accuracy: 0.119 - ETA: 43s - loss: 3.4495 - accuracy: 0.119 - ETA: 42s - loss: 3.4501 - accuracy: 0.119 - ETA: 41s - loss: 3.4504 - accuracy: 0.119 - ETA: 40s - loss: 3.4506 - accuracy: 0.119 - ETA: 39s - loss: 3.4508 - accuracy: 0.119 - ETA: 38s - loss: 3.4507 - accuracy: 0.119 - ETA: 37s - loss: 3.4509 - accuracy: 0.119 - ETA: 36s - loss: 3.4508 - accuracy: 0.119 - ETA: 35s - loss: 3.4507 - accuracy: 0.119 - ETA: 34s - loss: 3.4508 - accuracy: 0.119 - ETA: 33s - loss: 3.4510 - accuracy: 0.119 - ETA: 32s - loss: 3.4513 - accuracy: 0.119 - ETA: 31s - loss: 3.4516 - accuracy: 0.119 - ETA: 30s - loss: 3.4518 - accuracy: 0.119 - ETA: 29s - loss: 3.4521 - accuracy: 0.119 - ETA: 28s - loss: 3.4523 - accuracy: 0.119 - ETA: 27s - loss: 3.4524 - accuracy: 0.119 - ETA: 26s - loss: 3.4522 - accuracy: 0.119 - ETA: 25s - loss: 3.4526 - accuracy: 0.119 - ETA: 24s - loss: 3.4523 - accuracy: 0.119 - ETA: 23s - loss: 3.4523 - accuracy: 0.119 - ETA: 23s - loss: 3.4526 - accuracy: 0.118 - ETA: 22s - loss: 3.4529 - accuracy: 0.118 - ETA: 21s - loss: 3.4527 - accuracy: 0.118 - ETA: 20s - loss: 3.4525 - accuracy: 0.118 - ETA: 19s - loss: 3.4529 - accuracy: 0.118 - ETA: 18s - loss: 3.4528 - accuracy: 0.118 - ETA: 17s - loss: 3.4526 - accuracy: 0.118 - ETA: 16s - loss: 3.4529 - accuracy: 0.118 - ETA: 15s - loss: 3.4530 - accuracy: 0.118 - ETA: 14s - loss: 3.4527 - accuracy: 0.118 - ETA: 13s - loss: 3.4527 - accuracy: 0.118 - ETA: 12s - loss: 3.4522 - accuracy: 0.118 - ETA: 11s - loss: 3.4522 - accuracy: 0.118 - ETA: 10s - loss: 3.4525 - accuracy: 0.118 - ETA: 9s - loss: 3.4528 - accuracy: 0.118 - ETA: 8s - loss: 3.4526 - accuracy: 0.11 - ETA: 7s - loss: 3.4530 - accuracy: 0.11 - ETA: 6s - loss: 3.4526 - accuracy: 0.11 - ETA: 5s - loss: 3.4525 - accuracy: 0.11 - ETA: 4s - loss: 3.4524 - accuracy: 0.11 - ETA: 3s - loss: 3.4521 - accuracy: 0.11 - ETA: 2s - loss: 3.4520 - accuracy: 0.11 - ETA: 1s - loss: 3.4522 - accuracy: 0.11 - ETA: 1s - loss: 3.4521 - accuracy: 0.11 - ETA: 0s - loss: 3.4518 - accuracy: 0.11 - 342s 8ms/step - loss: 3.4518 - accuracy: 0.1186 - val_loss: 3.9858 - val_accuracy: 0.0093\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:08 - loss: 3.5627 - accuracy: 0.10 - ETA: 5:05 - loss: 3.5324 - accuracy: 0.12 - ETA: 5:02 - loss: 3.4843 - accuracy: 0.11 - ETA: 5:05 - loss: 3.4774 - accuracy: 0.10 - ETA: 5:10 - loss: 3.4507 - accuracy: 0.11 - ETA: 5:11 - loss: 3.4114 - accuracy: 0.12 - ETA: 5:12 - loss: 3.4238 - accuracy: 0.12 - ETA: 5:10 - loss: 3.4231 - accuracy: 0.12 - ETA: 5:05 - loss: 3.4119 - accuracy: 0.12 - ETA: 5:06 - loss: 3.4341 - accuracy: 0.12 - ETA: 5:03 - loss: 3.4341 - accuracy: 0.12 - ETA: 5:04 - loss: 3.4344 - accuracy: 0.12 - ETA: 5:02 - loss: 3.4332 - accuracy: 0.12 - ETA: 5:03 - loss: 3.4324 - accuracy: 0.12 - ETA: 5:03 - loss: 3.4356 - accuracy: 0.12 - ETA: 5:03 - loss: 3.4340 - accuracy: 0.12 - ETA: 5:03 - loss: 3.4399 - accuracy: 0.11 - ETA: 5:01 - loss: 3.4359 - accuracy: 0.12 - ETA: 4:59 - loss: 3.4385 - accuracy: 0.12 - ETA: 4:57 - loss: 3.4462 - accuracy: 0.11 - ETA: 4:57 - loss: 3.4432 - accuracy: 0.12 - ETA: 4:57 - loss: 3.4441 - accuracy: 0.12 - ETA: 4:56 - loss: 3.4461 - accuracy: 0.12 - ETA: 4:54 - loss: 3.4428 - accuracy: 0.12 - ETA: 4:54 - loss: 3.4412 - accuracy: 0.12 - ETA: 4:54 - loss: 3.4421 - accuracy: 0.12 - ETA: 4:52 - loss: 3.4455 - accuracy: 0.12 - ETA: 4:52 - loss: 3.4443 - accuracy: 0.12 - ETA: 4:52 - loss: 3.4471 - accuracy: 0.12 - ETA: 4:51 - loss: 3.4460 - accuracy: 0.12 - ETA: 4:50 - loss: 3.4534 - accuracy: 0.11 - ETA: 4:50 - loss: 3.4535 - accuracy: 0.11 - ETA: 4:49 - loss: 3.4521 - accuracy: 0.11 - ETA: 4:47 - loss: 3.4578 - accuracy: 0.11 - ETA: 4:46 - loss: 3.4548 - accuracy: 0.11 - ETA: 4:44 - loss: 3.4499 - accuracy: 0.11 - ETA: 4:43 - loss: 3.4471 - accuracy: 0.11 - ETA: 4:42 - loss: 3.4458 - accuracy: 0.11 - ETA: 4:41 - loss: 3.4474 - accuracy: 0.11 - ETA: 4:40 - loss: 3.4528 - accuracy: 0.11 - ETA: 4:38 - loss: 3.4556 - accuracy: 0.11 - ETA: 4:37 - loss: 3.4574 - accuracy: 0.11 - ETA: 4:36 - loss: 3.4598 - accuracy: 0.11 - ETA: 4:34 - loss: 3.4620 - accuracy: 0.11 - ETA: 4:33 - loss: 3.4618 - accuracy: 0.11 - ETA: 4:33 - loss: 3.4650 - accuracy: 0.11 - ETA: 4:32 - loss: 3.4634 - accuracy: 0.11 - ETA: 4:31 - loss: 3.4642 - accuracy: 0.11 - ETA: 4:30 - loss: 3.4623 - accuracy: 0.11 - ETA: 4:29 - loss: 3.4656 - accuracy: 0.11 - ETA: 4:28 - loss: 3.4685 - accuracy: 0.11 - ETA: 4:27 - loss: 3.4653 - accuracy: 0.11 - ETA: 4:25 - loss: 3.4656 - accuracy: 0.11 - ETA: 4:24 - loss: 3.4665 - accuracy: 0.11 - ETA: 4:24 - loss: 3.4779 - accuracy: 0.11 - ETA: 4:22 - loss: 3.4782 - accuracy: 0.11 - ETA: 4:21 - loss: 3.4816 - accuracy: 0.11 - ETA: 4:21 - loss: 3.4797 - accuracy: 0.11 - ETA: 4:20 - loss: 3.4801 - accuracy: 0.11 - ETA: 4:19 - loss: 3.4784 - accuracy: 0.11 - ETA: 4:18 - loss: 3.4788 - accuracy: 0.11 - ETA: 4:18 - loss: 3.4765 - accuracy: 0.11 - ETA: 4:17 - loss: 3.4760 - accuracy: 0.11 - ETA: 4:16 - loss: 3.4762 - accuracy: 0.11 - ETA: 4:15 - loss: 3.4773 - accuracy: 0.11 - ETA: 4:14 - loss: 3.4774 - accuracy: 0.11 - ETA: 4:13 - loss: 3.4790 - accuracy: 0.11 - ETA: 4:12 - loss: 3.4816 - accuracy: 0.11 - ETA: 4:10 - loss: 3.4778 - accuracy: 0.11 - ETA: 4:10 - loss: 3.4765 - accuracy: 0.11 - ETA: 4:09 - loss: 3.4775 - accuracy: 0.11 - ETA: 4:07 - loss: 3.4787 - accuracy: 0.11 - ETA: 4:07 - loss: 3.4809 - accuracy: 0.11 - ETA: 4:06 - loss: 3.4838 - accuracy: 0.11 - ETA: 4:05 - loss: 3.4836 - accuracy: 0.11 - ETA: 4:04 - loss: 3.4852 - accuracy: 0.11 - ETA: 4:03 - loss: 3.4862 - accuracy: 0.11 - ETA: 4:02 - loss: 3.4877 - accuracy: 0.11 - ETA: 4:01 - loss: 3.4885 - accuracy: 0.11 - ETA: 4:00 - loss: 3.4897 - accuracy: 0.11 - ETA: 3:59 - loss: 3.4910 - accuracy: 0.11 - ETA: 3:59 - loss: 3.4934 - accuracy: 0.11 - ETA: 3:58 - loss: 3.4946 - accuracy: 0.11 - ETA: 3:57 - loss: 3.4952 - accuracy: 0.11 - ETA: 3:56 - loss: 3.4942 - accuracy: 0.11 - ETA: 3:55 - loss: 3.4942 - accuracy: 0.11 - ETA: 3:54 - loss: 3.4975 - accuracy: 0.11 - ETA: 3:53 - loss: 3.4984 - accuracy: 0.11 - ETA: 3:52 - loss: 3.4974 - accuracy: 0.11 - ETA: 3:51 - loss: 3.4971 - accuracy: 0.11 - ETA: 3:50 - loss: 3.4993 - accuracy: 0.11 - ETA: 3:49 - loss: 3.4965 - accuracy: 0.11 - ETA: 3:48 - loss: 3.4962 - accuracy: 0.11 - ETA: 3:47 - loss: 3.4963 - accuracy: 0.11 - ETA: 3:46 - loss: 3.4973 - accuracy: 0.11 - ETA: 3:45 - loss: 3.4986 - accuracy: 0.11 - ETA: 3:44 - loss: 3.4990 - accuracy: 0.11 - ETA: 3:44 - loss: 3.5091 - accuracy: 0.11 - ETA: 3:43 - loss: 3.5140 - accuracy: 0.11 - ETA: 3:42 - loss: 3.5150 - accuracy: 0.11 - ETA: 3:41 - loss: 3.5168 - accuracy: 0.11 - ETA: 3:40 - loss: 3.5170 - accuracy: 0.11 - ETA: 3:39 - loss: 3.5175 - accuracy: 0.11 - ETA: 3:37 - loss: 3.5170 - accuracy: 0.11 - ETA: 3:36 - loss: 3.5174 - accuracy: 0.11 - ETA: 3:35 - loss: 3.5185 - accuracy: 0.11 - ETA: 3:35 - loss: 3.5196 - accuracy: 0.11 - ETA: 3:34 - loss: 3.5214 - accuracy: 0.11 - ETA: 3:33 - loss: 3.5226 - accuracy: 0.11 - ETA: 3:32 - loss: 3.5225 - accuracy: 0.11 - ETA: 3:31 - loss: 3.5246 - accuracy: 0.11 - ETA: 3:30 - loss: 3.5249 - accuracy: 0.11 - ETA: 3:29 - loss: 3.5248 - accuracy: 0.11 - ETA: 3:28 - loss: 3.5251 - accuracy: 0.11 - ETA: 3:27 - loss: 3.5263 - accuracy: 0.11 - ETA: 3:26 - loss: 3.5273 - accuracy: 0.11 - ETA: 3:25 - loss: 3.5275 - accuracy: 0.11 - ETA: 3:24 - loss: 3.5277 - accuracy: 0.11 - ETA: 3:23 - loss: 3.5263 - accuracy: 0.11 - ETA: 3:22 - loss: 3.5268 - accuracy: 0.11 - ETA: 3:21 - loss: 3.5273 - accuracy: 0.11 - ETA: 3:20 - loss: 3.5280 - accuracy: 0.11 - ETA: 3:19 - loss: 3.5278 - accuracy: 0.11 - ETA: 3:18 - loss: 3.5278 - accuracy: 0.11 - ETA: 3:17 - loss: 3.5280 - accuracy: 0.11 - ETA: 3:16 - loss: 3.5271 - accuracy: 0.11 - ETA: 3:15 - loss: 3.5279 - accuracy: 0.11 - ETA: 3:15 - loss: 3.5271 - accuracy: 0.11 - ETA: 3:14 - loss: 3.5269 - accuracy: 0.11 - ETA: 3:13 - loss: 3.5275 - accuracy: 0.11 - ETA: 3:12 - loss: 3.5282 - accuracy: 0.11 - ETA: 3:11 - loss: 3.5275 - accuracy: 0.11 - ETA: 3:10 - loss: 3.5280 - accuracy: 0.11 - ETA: 3:09 - loss: 3.5281 - accuracy: 0.11 - ETA: 3:08 - loss: 3.5288 - accuracy: 0.10 - ETA: 3:07 - loss: 3.5303 - accuracy: 0.10 - ETA: 3:06 - loss: 3.5304 - accuracy: 0.10 - ETA: 3:05 - loss: 3.5299 - accuracy: 0.10 - ETA: 3:04 - loss: 3.5295 - accuracy: 0.10 - ETA: 3:03 - loss: 3.5302 - accuracy: 0.10 - ETA: 3:02 - loss: 3.5299 - accuracy: 0.10 - ETA: 3:01 - loss: 3.5297 - accuracy: 0.10 - ETA: 3:00 - loss: 3.5294 - accuracy: 0.10 - ETA: 2:59 - loss: 3.5297 - accuracy: 0.10 - ETA: 2:58 - loss: 3.5297 - accuracy: 0.10 - ETA: 2:57 - loss: 3.5284 - accuracy: 0.10 - ETA: 2:56 - loss: 3.5283 - accuracy: 0.10 - ETA: 2:55 - loss: 3.5274 - accuracy: 0.10 - ETA: 2:54 - loss: 3.5280 - accuracy: 0.10 - ETA: 2:53 - loss: 3.5282 - accuracy: 0.10 - ETA: 2:52 - loss: 3.5283 - accuracy: 0.10 - ETA: 2:51 - loss: 3.5284 - accuracy: 0.10 - ETA: 2:50 - loss: 3.5284 - accuracy: 0.10 - ETA: 2:49 - loss: 3.5300 - accuracy: 0.10 - ETA: 2:48 - loss: 3.5290 - accuracy: 0.10 - ETA: 2:47 - loss: 3.5296 - accuracy: 0.10 - ETA: 2:46 - loss: 3.5286 - accuracy: 0.10 - ETA: 2:45 - loss: 3.5283 - accuracy: 0.10 - ETA: 2:45 - loss: 3.5274 - accuracy: 0.10 - ETA: 2:44 - loss: 3.5276 - accuracy: 0.10 - ETA: 2:43 - loss: 3.5279 - accuracy: 0.10 - ETA: 2:42 - loss: 3.5277 - accuracy: 0.10 - ETA: 2:41 - loss: 3.5291 - accuracy: 0.10 - ETA: 2:40 - loss: 3.5285 - accuracy: 0.10 - ETA: 2:39 - loss: 3.5283 - accuracy: 0.10 - ETA: 2:38 - loss: 3.5283 - accuracy: 0.10 - ETA: 2:37 - loss: 3.5285 - accuracy: 0.10 - ETA: 2:36 - loss: 3.5288 - accuracy: 0.10 - ETA: 2:35 - loss: 3.5293 - accuracy: 0.10 - ETA: 2:34 - loss: 3.5285 - accuracy: 0.10 - ETA: 2:33 - loss: 3.5276 - accuracy: 0.10 - ETA: 2:32 - loss: 3.5267 - accuracy: 0.10 - ETA: 2:31 - loss: 3.5268 - accuracy: 0.10 - ETA: 2:30 - loss: 3.5261 - accuracy: 0.10 - ETA: 2:29 - loss: 3.5264 - accuracy: 0.10 - ETA: 2:28 - loss: 3.5261 - accuracy: 0.10 - ETA: 2:27 - loss: 3.5252 - accuracy: 0.10 - ETA: 2:26 - loss: 3.5239 - accuracy: 0.11 - ETA: 2:25 - loss: 3.5233 - accuracy: 0.11 - ETA: 2:25 - loss: 3.5232 - accuracy: 0.11 - ETA: 2:24 - loss: 3.5228 - accuracy: 0.11 - ETA: 2:23 - loss: 3.5227 - accuracy: 0.11 - ETA: 2:22 - loss: 3.5219 - accuracy: 0.11 - ETA: 2:21 - loss: 3.5221 - accuracy: 0.11 - ETA: 2:20 - loss: 3.5221 - accuracy: 0.11 - ETA: 2:19 - loss: 3.5212 - accuracy: 0.1104"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:18 - loss: 3.5210 - accuracy: 0.11 - ETA: 2:17 - loss: 3.5212 - accuracy: 0.11 - ETA: 2:16 - loss: 3.5198 - accuracy: 0.11 - ETA: 2:15 - loss: 3.5209 - accuracy: 0.11 - ETA: 2:14 - loss: 3.5201 - accuracy: 0.11 - ETA: 2:13 - loss: 3.5205 - accuracy: 0.11 - ETA: 2:12 - loss: 3.5206 - accuracy: 0.11 - ETA: 2:11 - loss: 3.5204 - accuracy: 0.11 - ETA: 2:10 - loss: 3.5200 - accuracy: 0.11 - ETA: 2:09 - loss: 3.5193 - accuracy: 0.11 - ETA: 2:08 - loss: 3.5195 - accuracy: 0.11 - ETA: 2:07 - loss: 3.5199 - accuracy: 0.11 - ETA: 2:06 - loss: 3.5245 - accuracy: 0.11 - ETA: 2:05 - loss: 3.5263 - accuracy: 0.11 - ETA: 2:04 - loss: 3.5295 - accuracy: 0.11 - ETA: 2:03 - loss: 3.5304 - accuracy: 0.11 - ETA: 2:02 - loss: 3.5308 - accuracy: 0.11 - ETA: 2:01 - loss: 3.5316 - accuracy: 0.11 - ETA: 2:00 - loss: 3.5321 - accuracy: 0.11 - ETA: 1:59 - loss: 3.5325 - accuracy: 0.11 - ETA: 1:58 - loss: 3.5325 - accuracy: 0.11 - ETA: 1:58 - loss: 3.5328 - accuracy: 0.11 - ETA: 1:57 - loss: 3.5330 - accuracy: 0.11 - ETA: 1:56 - loss: 3.5328 - accuracy: 0.11 - ETA: 1:55 - loss: 3.5325 - accuracy: 0.11 - ETA: 1:54 - loss: 3.5327 - accuracy: 0.10 - ETA: 1:53 - loss: 3.5328 - accuracy: 0.10 - ETA: 1:52 - loss: 3.5324 - accuracy: 0.10 - ETA: 1:51 - loss: 3.5325 - accuracy: 0.10 - ETA: 1:50 - loss: 3.5326 - accuracy: 0.10 - ETA: 1:49 - loss: 3.5328 - accuracy: 0.10 - ETA: 1:48 - loss: 3.5325 - accuracy: 0.10 - ETA: 1:47 - loss: 3.5328 - accuracy: 0.10 - ETA: 1:46 - loss: 3.5328 - accuracy: 0.10 - ETA: 1:45 - loss: 3.5330 - accuracy: 0.10 - ETA: 1:44 - loss: 3.5327 - accuracy: 0.10 - ETA: 1:43 - loss: 3.5331 - accuracy: 0.10 - ETA: 1:42 - loss: 3.5333 - accuracy: 0.10 - ETA: 1:41 - loss: 3.5333 - accuracy: 0.10 - ETA: 1:40 - loss: 3.5335 - accuracy: 0.10 - ETA: 1:39 - loss: 3.5334 - accuracy: 0.10 - ETA: 1:38 - loss: 3.5343 - accuracy: 0.10 - ETA: 1:37 - loss: 3.5340 - accuracy: 0.10 - ETA: 1:36 - loss: 3.5338 - accuracy: 0.10 - ETA: 1:35 - loss: 3.5337 - accuracy: 0.10 - ETA: 1:34 - loss: 3.5339 - accuracy: 0.10 - ETA: 1:34 - loss: 3.5341 - accuracy: 0.10 - ETA: 1:33 - loss: 3.5341 - accuracy: 0.10 - ETA: 1:32 - loss: 3.5344 - accuracy: 0.10 - ETA: 1:31 - loss: 3.5342 - accuracy: 0.10 - ETA: 1:30 - loss: 3.5341 - accuracy: 0.10 - ETA: 1:29 - loss: 3.5350 - accuracy: 0.10 - ETA: 1:28 - loss: 3.5355 - accuracy: 0.10 - ETA: 1:27 - loss: 3.5353 - accuracy: 0.10 - ETA: 1:26 - loss: 3.5353 - accuracy: 0.10 - ETA: 1:25 - loss: 3.5349 - accuracy: 0.10 - ETA: 1:24 - loss: 3.5347 - accuracy: 0.10 - ETA: 1:23 - loss: 3.5348 - accuracy: 0.10 - ETA: 1:22 - loss: 3.5345 - accuracy: 0.10 - ETA: 1:21 - loss: 3.5347 - accuracy: 0.10 - ETA: 1:20 - loss: 3.5348 - accuracy: 0.10 - ETA: 1:19 - loss: 3.5352 - accuracy: 0.10 - ETA: 1:18 - loss: 3.5357 - accuracy: 0.10 - ETA: 1:17 - loss: 3.5360 - accuracy: 0.10 - ETA: 1:16 - loss: 3.5357 - accuracy: 0.10 - ETA: 1:15 - loss: 3.5358 - accuracy: 0.10 - ETA: 1:14 - loss: 3.5363 - accuracy: 0.10 - ETA: 1:13 - loss: 3.5365 - accuracy: 0.10 - ETA: 1:12 - loss: 3.5368 - accuracy: 0.10 - ETA: 1:11 - loss: 3.5373 - accuracy: 0.10 - ETA: 1:10 - loss: 3.5371 - accuracy: 0.10 - ETA: 1:09 - loss: 3.5372 - accuracy: 0.10 - ETA: 1:08 - loss: 3.5363 - accuracy: 0.10 - ETA: 1:08 - loss: 3.5365 - accuracy: 0.10 - ETA: 1:07 - loss: 3.5366 - accuracy: 0.10 - ETA: 1:06 - loss: 3.5368 - accuracy: 0.10 - ETA: 1:05 - loss: 3.5368 - accuracy: 0.10 - ETA: 1:04 - loss: 3.5365 - accuracy: 0.10 - ETA: 1:03 - loss: 3.5358 - accuracy: 0.10 - ETA: 1:02 - loss: 3.5354 - accuracy: 0.10 - ETA: 1:01 - loss: 3.5350 - accuracy: 0.10 - ETA: 1:00 - loss: 3.5354 - accuracy: 0.10 - ETA: 59s - loss: 3.5354 - accuracy: 0.1073 - ETA: 58s - loss: 3.5354 - accuracy: 0.107 - ETA: 57s - loss: 3.5352 - accuracy: 0.107 - ETA: 56s - loss: 3.5348 - accuracy: 0.107 - ETA: 55s - loss: 3.5350 - accuracy: 0.107 - ETA: 54s - loss: 3.5349 - accuracy: 0.107 - ETA: 53s - loss: 3.5346 - accuracy: 0.107 - ETA: 52s - loss: 3.5346 - accuracy: 0.107 - ETA: 51s - loss: 3.5346 - accuracy: 0.107 - ETA: 50s - loss: 3.5342 - accuracy: 0.107 - ETA: 49s - loss: 3.5341 - accuracy: 0.107 - ETA: 48s - loss: 3.5339 - accuracy: 0.107 - ETA: 47s - loss: 3.5341 - accuracy: 0.107 - ETA: 46s - loss: 3.5342 - accuracy: 0.107 - ETA: 46s - loss: 3.5343 - accuracy: 0.107 - ETA: 45s - loss: 3.5347 - accuracy: 0.107 - ETA: 44s - loss: 3.5348 - accuracy: 0.107 - ETA: 43s - loss: 3.5347 - accuracy: 0.107 - ETA: 42s - loss: 3.5340 - accuracy: 0.107 - ETA: 41s - loss: 3.5333 - accuracy: 0.107 - ETA: 40s - loss: 3.5336 - accuracy: 0.107 - ETA: 39s - loss: 3.5340 - accuracy: 0.107 - ETA: 38s - loss: 3.5342 - accuracy: 0.107 - ETA: 37s - loss: 3.5340 - accuracy: 0.107 - ETA: 36s - loss: 3.5343 - accuracy: 0.107 - ETA: 35s - loss: 3.5341 - accuracy: 0.106 - ETA: 34s - loss: 3.5342 - accuracy: 0.106 - ETA: 33s - loss: 3.5349 - accuracy: 0.106 - ETA: 32s - loss: 3.5352 - accuracy: 0.106 - ETA: 31s - loss: 3.5355 - accuracy: 0.106 - ETA: 30s - loss: 3.5355 - accuracy: 0.106 - ETA: 29s - loss: 3.5356 - accuracy: 0.106 - ETA: 28s - loss: 3.5352 - accuracy: 0.106 - ETA: 27s - loss: 3.5353 - accuracy: 0.106 - ETA: 26s - loss: 3.5356 - accuracy: 0.106 - ETA: 25s - loss: 3.5357 - accuracy: 0.106 - ETA: 24s - loss: 3.5356 - accuracy: 0.106 - ETA: 24s - loss: 3.5355 - accuracy: 0.105 - ETA: 23s - loss: 3.5356 - accuracy: 0.105 - ETA: 22s - loss: 3.5361 - accuracy: 0.105 - ETA: 21s - loss: 3.5360 - accuracy: 0.105 - ETA: 20s - loss: 3.5357 - accuracy: 0.105 - ETA: 19s - loss: 3.5356 - accuracy: 0.105 - ETA: 18s - loss: 3.5357 - accuracy: 0.105 - ETA: 17s - loss: 3.5356 - accuracy: 0.105 - ETA: 16s - loss: 3.5354 - accuracy: 0.105 - ETA: 15s - loss: 3.5354 - accuracy: 0.105 - ETA: 14s - loss: 3.5350 - accuracy: 0.105 - ETA: 13s - loss: 3.5348 - accuracy: 0.105 - ETA: 12s - loss: 3.5348 - accuracy: 0.105 - ETA: 11s - loss: 3.5348 - accuracy: 0.105 - ETA: 10s - loss: 3.5348 - accuracy: 0.105 - ETA: 9s - loss: 3.5346 - accuracy: 0.105 - ETA: 8s - loss: 3.5349 - accuracy: 0.10 - ETA: 7s - loss: 3.5351 - accuracy: 0.10 - ETA: 6s - loss: 3.5353 - accuracy: 0.10 - ETA: 5s - loss: 3.5350 - accuracy: 0.10 - ETA: 4s - loss: 3.5348 - accuracy: 0.10 - ETA: 3s - loss: 3.5346 - accuracy: 0.10 - ETA: 2s - loss: 3.5344 - accuracy: 0.10 - ETA: 1s - loss: 3.5343 - accuracy: 0.10 - ETA: 1s - loss: 3.5343 - accuracy: 0.10 - ETA: 0s - loss: 3.5345 - accuracy: 0.10 - 341s 8ms/step - loss: 3.5345 - accuracy: 0.1056 - val_loss: 3.8923 - val_accuracy: 0.0095\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:45 - loss: 3.4804 - accuracy: 0.11 - ETA: 5:36 - loss: 3.5256 - accuracy: 0.11 - ETA: 5:26 - loss: 3.5617 - accuracy: 0.11 - ETA: 5:28 - loss: 3.5595 - accuracy: 0.10 - ETA: 5:30 - loss: 3.5381 - accuracy: 0.10 - ETA: 5:26 - loss: 3.5539 - accuracy: 0.10 - ETA: 5:25 - loss: 3.5553 - accuracy: 0.10 - ETA: 5:18 - loss: 3.5602 - accuracy: 0.10 - ETA: 5:18 - loss: 3.5397 - accuracy: 0.10 - ETA: 5:17 - loss: 3.5509 - accuracy: 0.10 - ETA: 5:16 - loss: 3.5367 - accuracy: 0.10 - ETA: 5:15 - loss: 3.5327 - accuracy: 0.10 - ETA: 5:11 - loss: 3.5242 - accuracy: 0.11 - ETA: 5:07 - loss: 3.5273 - accuracy: 0.10 - ETA: 5:05 - loss: 3.5255 - accuracy: 0.10 - ETA: 5:04 - loss: 3.5286 - accuracy: 0.10 - ETA: 5:03 - loss: 3.5233 - accuracy: 0.11 - ETA: 5:01 - loss: 3.5162 - accuracy: 0.11 - ETA: 5:01 - loss: 3.5198 - accuracy: 0.11 - ETA: 4:59 - loss: 3.5100 - accuracy: 0.11 - ETA: 4:58 - loss: 3.5071 - accuracy: 0.11 - ETA: 4:57 - loss: 3.4976 - accuracy: 0.11 - ETA: 4:57 - loss: 3.4935 - accuracy: 0.11 - ETA: 4:55 - loss: 3.4891 - accuracy: 0.11 - ETA: 4:54 - loss: 3.4938 - accuracy: 0.11 - ETA: 4:54 - loss: 3.4966 - accuracy: 0.11 - ETA: 4:53 - loss: 3.4990 - accuracy: 0.11 - ETA: 4:52 - loss: 3.4992 - accuracy: 0.11 - ETA: 4:51 - loss: 3.4949 - accuracy: 0.11 - ETA: 4:50 - loss: 3.4981 - accuracy: 0.11 - ETA: 4:49 - loss: 3.4990 - accuracy: 0.11 - ETA: 4:48 - loss: 3.5019 - accuracy: 0.11 - ETA: 4:47 - loss: 3.5059 - accuracy: 0.11 - ETA: 4:47 - loss: 3.5089 - accuracy: 0.11 - ETA: 4:46 - loss: 3.5065 - accuracy: 0.11 - ETA: 4:45 - loss: 3.5109 - accuracy: 0.11 - ETA: 4:44 - loss: 3.5114 - accuracy: 0.11 - ETA: 4:44 - loss: 3.5081 - accuracy: 0.11 - ETA: 4:43 - loss: 3.5074 - accuracy: 0.11 - ETA: 4:42 - loss: 3.5062 - accuracy: 0.11 - ETA: 4:41 - loss: 3.5083 - accuracy: 0.11 - ETA: 4:39 - loss: 3.5100 - accuracy: 0.11 - ETA: 4:38 - loss: 3.5118 - accuracy: 0.11 - ETA: 4:36 - loss: 3.5110 - accuracy: 0.11 - ETA: 4:36 - loss: 3.5121 - accuracy: 0.11 - ETA: 4:34 - loss: 3.5113 - accuracy: 0.10 - ETA: 4:33 - loss: 3.5070 - accuracy: 0.11 - ETA: 4:32 - loss: 3.5083 - accuracy: 0.11 - ETA: 4:31 - loss: 3.5111 - accuracy: 0.11 - ETA: 4:30 - loss: 3.5117 - accuracy: 0.11 - ETA: 4:29 - loss: 3.5108 - accuracy: 0.11 - ETA: 4:28 - loss: 3.5086 - accuracy: 0.11 - ETA: 4:27 - loss: 3.5060 - accuracy: 0.11 - ETA: 4:26 - loss: 3.5046 - accuracy: 0.11 - ETA: 4:24 - loss: 3.5045 - accuracy: 0.11 - ETA: 4:24 - loss: 3.5037 - accuracy: 0.11 - ETA: 4:23 - loss: 3.5021 - accuracy: 0.11 - ETA: 4:22 - loss: 3.5024 - accuracy: 0.11 - ETA: 4:20 - loss: 3.5008 - accuracy: 0.11 - ETA: 4:20 - loss: 3.5020 - accuracy: 0.11 - ETA: 4:19 - loss: 3.5034 - accuracy: 0.11 - ETA: 4:18 - loss: 3.5041 - accuracy: 0.10 - ETA: 4:16 - loss: 3.5024 - accuracy: 0.10 - ETA: 4:15 - loss: 3.5037 - accuracy: 0.10 - ETA: 4:14 - loss: 3.5037 - accuracy: 0.11 - ETA: 4:13 - loss: 3.5050 - accuracy: 0.10 - ETA: 4:12 - loss: 3.5046 - accuracy: 0.11 - ETA: 4:11 - loss: 3.5018 - accuracy: 0.11 - ETA: 4:10 - loss: 3.5057 - accuracy: 0.10 - ETA: 4:09 - loss: 3.5053 - accuracy: 0.11 - ETA: 4:09 - loss: 3.5057 - accuracy: 0.11 - ETA: 4:08 - loss: 3.5028 - accuracy: 0.11 - ETA: 4:07 - loss: 3.5012 - accuracy: 0.11 - ETA: 4:06 - loss: 3.5013 - accuracy: 0.11 - ETA: 4:05 - loss: 3.5011 - accuracy: 0.11 - ETA: 4:04 - loss: 3.5007 - accuracy: 0.11 - ETA: 4:03 - loss: 3.5007 - accuracy: 0.11 - ETA: 4:02 - loss: 3.5012 - accuracy: 0.11 - ETA: 4:01 - loss: 3.5019 - accuracy: 0.11 - ETA: 4:00 - loss: 3.5038 - accuracy: 0.11 - ETA: 3:59 - loss: 3.5143 - accuracy: 0.11 - ETA: 3:57 - loss: 3.5151 - accuracy: 0.11 - ETA: 3:57 - loss: 3.5151 - accuracy: 0.11 - ETA: 3:56 - loss: 3.5160 - accuracy: 0.11 - ETA: 3:55 - loss: 3.5179 - accuracy: 0.11 - ETA: 3:54 - loss: 3.5194 - accuracy: 0.11 - ETA: 3:53 - loss: 3.5199 - accuracy: 0.11 - ETA: 3:52 - loss: 3.5205 - accuracy: 0.11 - ETA: 3:52 - loss: 3.5209 - accuracy: 0.11 - ETA: 3:51 - loss: 3.5195 - accuracy: 0.11 - ETA: 3:50 - loss: 3.5191 - accuracy: 0.11 - ETA: 3:49 - loss: 3.5195 - accuracy: 0.11 - ETA: 3:48 - loss: 3.5182 - accuracy: 0.11 - ETA: 3:47 - loss: 3.5185 - accuracy: 0.11 - ETA: 3:46 - loss: 3.5193 - accuracy: 0.11 - ETA: 3:45 - loss: 3.5200 - accuracy: 0.11 - ETA: 3:43 - loss: 3.5191 - accuracy: 0.11 - ETA: 3:42 - loss: 3.5180 - accuracy: 0.11 - ETA: 3:41 - loss: 3.5194 - accuracy: 0.11 - ETA: 3:40 - loss: 3.5185 - accuracy: 0.10 - ETA: 3:39 - loss: 3.5189 - accuracy: 0.10 - ETA: 3:38 - loss: 3.5190 - accuracy: 0.10 - ETA: 3:37 - loss: 3.5193 - accuracy: 0.10 - ETA: 3:36 - loss: 3.5195 - accuracy: 0.10 - ETA: 3:35 - loss: 3.5193 - accuracy: 0.10 - ETA: 3:34 - loss: 3.5190 - accuracy: 0.10 - ETA: 3:34 - loss: 3.5194 - accuracy: 0.10 - ETA: 3:32 - loss: 3.5197 - accuracy: 0.10 - ETA: 3:32 - loss: 3.5185 - accuracy: 0.10 - ETA: 3:31 - loss: 3.5166 - accuracy: 0.10 - ETA: 3:30 - loss: 3.5170 - accuracy: 0.10 - ETA: 3:29 - loss: 3.5172 - accuracy: 0.10 - ETA: 3:28 - loss: 3.5170 - accuracy: 0.10 - ETA: 3:27 - loss: 3.5178 - accuracy: 0.10 - ETA: 3:26 - loss: 3.5172 - accuracy: 0.10 - ETA: 3:25 - loss: 3.5166 - accuracy: 0.10 - ETA: 3:24 - loss: 3.5170 - accuracy: 0.10 - ETA: 3:23 - loss: 3.5172 - accuracy: 0.10 - ETA: 3:22 - loss: 3.5156 - accuracy: 0.10 - ETA: 3:21 - loss: 3.5158 - accuracy: 0.10 - ETA: 3:20 - loss: 3.5146 - accuracy: 0.10 - ETA: 3:20 - loss: 3.5145 - accuracy: 0.10 - ETA: 3:19 - loss: 3.5149 - accuracy: 0.10 - ETA: 3:18 - loss: 3.5143 - accuracy: 0.10 - ETA: 3:16 - loss: 3.5141 - accuracy: 0.10 - ETA: 3:16 - loss: 3.5132 - accuracy: 0.10 - ETA: 3:15 - loss: 3.5115 - accuracy: 0.10 - ETA: 3:14 - loss: 3.5123 - accuracy: 0.10 - ETA: 3:13 - loss: 3.5115 - accuracy: 0.10 - ETA: 3:12 - loss: 3.5113 - accuracy: 0.10 - ETA: 3:11 - loss: 3.5102 - accuracy: 0.10 - ETA: 3:10 - loss: 3.5105 - accuracy: 0.10 - ETA: 3:09 - loss: 3.5102 - accuracy: 0.10 - ETA: 3:08 - loss: 3.5106 - accuracy: 0.10 - ETA: 3:07 - loss: 3.5107 - accuracy: 0.10 - ETA: 3:06 - loss: 3.5115 - accuracy: 0.10 - ETA: 3:05 - loss: 3.5117 - accuracy: 0.10 - ETA: 3:04 - loss: 3.5122 - accuracy: 0.10 - ETA: 3:03 - loss: 3.5120 - accuracy: 0.10 - ETA: 3:02 - loss: 3.5104 - accuracy: 0.10 - ETA: 3:02 - loss: 3.5105 - accuracy: 0.10 - ETA: 3:01 - loss: 3.5105 - accuracy: 0.10 - ETA: 3:00 - loss: 3.5104 - accuracy: 0.10 - ETA: 2:59 - loss: 3.5095 - accuracy: 0.10 - ETA: 2:58 - loss: 3.5087 - accuracy: 0.10 - ETA: 2:57 - loss: 3.5076 - accuracy: 0.10 - ETA: 2:56 - loss: 3.5077 - accuracy: 0.10 - ETA: 2:55 - loss: 3.5063 - accuracy: 0.10 - ETA: 2:54 - loss: 3.5061 - accuracy: 0.10 - ETA: 2:53 - loss: 3.5065 - accuracy: 0.10 - ETA: 2:52 - loss: 3.5066 - accuracy: 0.10 - ETA: 2:51 - loss: 3.5060 - accuracy: 0.10 - ETA: 2:50 - loss: 3.5057 - accuracy: 0.10 - ETA: 2:49 - loss: 3.5054 - accuracy: 0.10 - ETA: 2:48 - loss: 3.5054 - accuracy: 0.10 - ETA: 2:47 - loss: 3.5039 - accuracy: 0.10 - ETA: 2:46 - loss: 3.5046 - accuracy: 0.10 - ETA: 2:45 - loss: 3.5041 - accuracy: 0.10 - ETA: 2:44 - loss: 3.5038 - accuracy: 0.10 - ETA: 2:43 - loss: 3.5034 - accuracy: 0.10 - ETA: 2:42 - loss: 3.5041 - accuracy: 0.10 - ETA: 2:41 - loss: 3.5045 - accuracy: 0.10 - ETA: 2:40 - loss: 3.5048 - accuracy: 0.10 - ETA: 2:39 - loss: 3.5054 - accuracy: 0.10 - ETA: 2:38 - loss: 3.5051 - accuracy: 0.10 - ETA: 2:37 - loss: 3.5051 - accuracy: 0.10 - ETA: 2:36 - loss: 3.5052 - accuracy: 0.10 - ETA: 2:35 - loss: 3.5058 - accuracy: 0.10 - ETA: 2:34 - loss: 3.5056 - accuracy: 0.10 - ETA: 2:33 - loss: 3.5043 - accuracy: 0.10 - ETA: 2:32 - loss: 3.5043 - accuracy: 0.10 - ETA: 2:31 - loss: 3.5041 - accuracy: 0.10 - ETA: 2:30 - loss: 3.5041 - accuracy: 0.10 - ETA: 2:30 - loss: 3.5030 - accuracy: 0.10 - ETA: 2:29 - loss: 3.5028 - accuracy: 0.10 - ETA: 2:28 - loss: 3.5023 - accuracy: 0.10 - ETA: 2:27 - loss: 3.5026 - accuracy: 0.10 - ETA: 2:26 - loss: 3.5028 - accuracy: 0.10 - ETA: 2:25 - loss: 3.5031 - accuracy: 0.10 - ETA: 2:24 - loss: 3.5034 - accuracy: 0.10 - ETA: 2:23 - loss: 3.5035 - accuracy: 0.10 - ETA: 2:22 - loss: 3.5034 - accuracy: 0.10 - ETA: 2:21 - loss: 3.5033 - accuracy: 0.10 - ETA: 2:20 - loss: 3.5029 - accuracy: 0.10 - ETA: 2:19 - loss: 3.5022 - accuracy: 0.10 - ETA: 2:18 - loss: 3.5022 - accuracy: 0.1095"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.5016 - accuracy: 0.10 - ETA: 2:16 - loss: 3.5007 - accuracy: 0.10 - ETA: 2:15 - loss: 3.4998 - accuracy: 0.10 - ETA: 2:14 - loss: 3.5003 - accuracy: 0.10 - ETA: 2:13 - loss: 3.5003 - accuracy: 0.10 - ETA: 2:12 - loss: 3.5003 - accuracy: 0.10 - ETA: 2:11 - loss: 3.5005 - accuracy: 0.10 - ETA: 2:10 - loss: 3.5004 - accuracy: 0.11 - ETA: 2:09 - loss: 3.5003 - accuracy: 0.10 - ETA: 2:08 - loss: 3.5002 - accuracy: 0.10 - ETA: 2:08 - loss: 3.5010 - accuracy: 0.10 - ETA: 2:07 - loss: 3.5007 - accuracy: 0.10 - ETA: 2:06 - loss: 3.5001 - accuracy: 0.10 - ETA: 2:05 - loss: 3.5005 - accuracy: 0.10 - ETA: 2:04 - loss: 3.5012 - accuracy: 0.10 - ETA: 2:03 - loss: 3.5006 - accuracy: 0.10 - ETA: 2:02 - loss: 3.5003 - accuracy: 0.10 - ETA: 2:01 - loss: 3.5004 - accuracy: 0.10 - ETA: 2:00 - loss: 3.5009 - accuracy: 0.10 - ETA: 1:59 - loss: 3.5014 - accuracy: 0.10 - ETA: 1:58 - loss: 3.5015 - accuracy: 0.10 - ETA: 1:57 - loss: 3.5010 - accuracy: 0.10 - ETA: 1:56 - loss: 3.5001 - accuracy: 0.10 - ETA: 1:55 - loss: 3.4995 - accuracy: 0.10 - ETA: 1:54 - loss: 3.4991 - accuracy: 0.10 - ETA: 1:53 - loss: 3.4995 - accuracy: 0.10 - ETA: 1:52 - loss: 3.4997 - accuracy: 0.10 - ETA: 1:51 - loss: 3.4995 - accuracy: 0.11 - ETA: 1:50 - loss: 3.4991 - accuracy: 0.11 - ETA: 1:49 - loss: 3.4987 - accuracy: 0.11 - ETA: 1:48 - loss: 3.4978 - accuracy: 0.11 - ETA: 1:47 - loss: 3.4979 - accuracy: 0.11 - ETA: 1:46 - loss: 3.4982 - accuracy: 0.11 - ETA: 1:46 - loss: 3.4979 - accuracy: 0.11 - ETA: 1:45 - loss: 3.4985 - accuracy: 0.11 - ETA: 1:44 - loss: 3.4981 - accuracy: 0.11 - ETA: 1:43 - loss: 3.4979 - accuracy: 0.11 - ETA: 1:42 - loss: 3.4975 - accuracy: 0.11 - ETA: 1:41 - loss: 3.4972 - accuracy: 0.11 - ETA: 1:40 - loss: 3.4975 - accuracy: 0.11 - ETA: 1:39 - loss: 3.4974 - accuracy: 0.11 - ETA: 1:38 - loss: 3.4975 - accuracy: 0.11 - ETA: 1:37 - loss: 3.4976 - accuracy: 0.11 - ETA: 1:36 - loss: 3.4969 - accuracy: 0.11 - ETA: 1:35 - loss: 3.4962 - accuracy: 0.11 - ETA: 1:34 - loss: 3.4959 - accuracy: 0.11 - ETA: 1:33 - loss: 3.4958 - accuracy: 0.11 - ETA: 1:32 - loss: 3.4954 - accuracy: 0.11 - ETA: 1:31 - loss: 3.4953 - accuracy: 0.11 - ETA: 1:30 - loss: 3.4947 - accuracy: 0.11 - ETA: 1:29 - loss: 3.4950 - accuracy: 0.11 - ETA: 1:28 - loss: 3.4944 - accuracy: 0.11 - ETA: 1:27 - loss: 3.4941 - accuracy: 0.11 - ETA: 1:27 - loss: 3.4944 - accuracy: 0.11 - ETA: 1:26 - loss: 3.4938 - accuracy: 0.11 - ETA: 1:25 - loss: 3.4933 - accuracy: 0.11 - ETA: 1:24 - loss: 3.4929 - accuracy: 0.11 - ETA: 1:23 - loss: 3.4929 - accuracy: 0.11 - ETA: 1:22 - loss: 3.4920 - accuracy: 0.11 - ETA: 1:21 - loss: 3.4916 - accuracy: 0.11 - ETA: 1:20 - loss: 3.4909 - accuracy: 0.11 - ETA: 1:19 - loss: 3.4907 - accuracy: 0.11 - ETA: 1:18 - loss: 3.4905 - accuracy: 0.11 - ETA: 1:17 - loss: 3.4907 - accuracy: 0.11 - ETA: 1:16 - loss: 3.4898 - accuracy: 0.11 - ETA: 1:15 - loss: 3.4898 - accuracy: 0.11 - ETA: 1:14 - loss: 3.4900 - accuracy: 0.11 - ETA: 1:13 - loss: 3.4900 - accuracy: 0.11 - ETA: 1:12 - loss: 3.4903 - accuracy: 0.11 - ETA: 1:11 - loss: 3.4901 - accuracy: 0.11 - ETA: 1:10 - loss: 3.4899 - accuracy: 0.11 - ETA: 1:09 - loss: 3.4899 - accuracy: 0.11 - ETA: 1:08 - loss: 3.4900 - accuracy: 0.11 - ETA: 1:07 - loss: 3.4892 - accuracy: 0.11 - ETA: 1:06 - loss: 3.4893 - accuracy: 0.11 - ETA: 1:05 - loss: 3.4895 - accuracy: 0.11 - ETA: 1:04 - loss: 3.4891 - accuracy: 0.11 - ETA: 1:03 - loss: 3.4892 - accuracy: 0.11 - ETA: 1:03 - loss: 3.4897 - accuracy: 0.11 - ETA: 1:02 - loss: 3.4899 - accuracy: 0.11 - ETA: 1:01 - loss: 3.4900 - accuracy: 0.11 - ETA: 1:00 - loss: 3.4899 - accuracy: 0.11 - ETA: 59s - loss: 3.4900 - accuracy: 0.1109 - ETA: 58s - loss: 3.4901 - accuracy: 0.110 - ETA: 57s - loss: 3.4898 - accuracy: 0.110 - ETA: 56s - loss: 3.4895 - accuracy: 0.110 - ETA: 55s - loss: 3.4889 - accuracy: 0.110 - ETA: 54s - loss: 3.4886 - accuracy: 0.110 - ETA: 53s - loss: 3.4893 - accuracy: 0.110 - ETA: 52s - loss: 3.4898 - accuracy: 0.110 - ETA: 51s - loss: 3.4893 - accuracy: 0.110 - ETA: 50s - loss: 3.4890 - accuracy: 0.110 - ETA: 49s - loss: 3.4895 - accuracy: 0.110 - ETA: 48s - loss: 3.4896 - accuracy: 0.110 - ETA: 47s - loss: 3.4896 - accuracy: 0.110 - ETA: 46s - loss: 3.4895 - accuracy: 0.110 - ETA: 45s - loss: 3.4893 - accuracy: 0.110 - ETA: 44s - loss: 3.4893 - accuracy: 0.110 - ETA: 43s - loss: 3.4898 - accuracy: 0.110 - ETA: 43s - loss: 3.4898 - accuracy: 0.110 - ETA: 42s - loss: 3.4891 - accuracy: 0.110 - ETA: 41s - loss: 3.4893 - accuracy: 0.110 - ETA: 40s - loss: 3.4892 - accuracy: 0.110 - ETA: 39s - loss: 3.4890 - accuracy: 0.110 - ETA: 38s - loss: 3.4885 - accuracy: 0.110 - ETA: 37s - loss: 3.4884 - accuracy: 0.110 - ETA: 36s - loss: 3.4879 - accuracy: 0.111 - ETA: 35s - loss: 3.4875 - accuracy: 0.111 - ETA: 34s - loss: 3.4870 - accuracy: 0.111 - ETA: 33s - loss: 3.4869 - accuracy: 0.111 - ETA: 32s - loss: 3.4868 - accuracy: 0.111 - ETA: 31s - loss: 3.4865 - accuracy: 0.111 - ETA: 30s - loss: 3.4862 - accuracy: 0.111 - ETA: 29s - loss: 3.4865 - accuracy: 0.111 - ETA: 28s - loss: 3.4865 - accuracy: 0.111 - ETA: 27s - loss: 3.4866 - accuracy: 0.111 - ETA: 26s - loss: 3.4871 - accuracy: 0.110 - ETA: 25s - loss: 3.4874 - accuracy: 0.110 - ETA: 24s - loss: 3.4875 - accuracy: 0.110 - ETA: 23s - loss: 3.4873 - accuracy: 0.110 - ETA: 22s - loss: 3.4870 - accuracy: 0.110 - ETA: 22s - loss: 3.4873 - accuracy: 0.110 - ETA: 21s - loss: 3.4871 - accuracy: 0.110 - ETA: 20s - loss: 3.4869 - accuracy: 0.110 - ETA: 19s - loss: 3.4862 - accuracy: 0.110 - ETA: 18s - loss: 3.4860 - accuracy: 0.111 - ETA: 17s - loss: 3.4860 - accuracy: 0.110 - ETA: 16s - loss: 3.4862 - accuracy: 0.110 - ETA: 15s - loss: 3.4862 - accuracy: 0.110 - ETA: 14s - loss: 3.4861 - accuracy: 0.111 - ETA: 13s - loss: 3.4860 - accuracy: 0.110 - ETA: 12s - loss: 3.4860 - accuracy: 0.110 - ETA: 11s - loss: 3.4861 - accuracy: 0.111 - ETA: 10s - loss: 3.4863 - accuracy: 0.111 - ETA: 9s - loss: 3.4863 - accuracy: 0.111 - ETA: 8s - loss: 3.4861 - accuracy: 0.11 - ETA: 7s - loss: 3.4857 - accuracy: 0.11 - ETA: 6s - loss: 3.4975 - accuracy: 0.11 - ETA: 5s - loss: 3.4976 - accuracy: 0.11 - ETA: 4s - loss: 3.4980 - accuracy: 0.11 - ETA: 3s - loss: 3.4981 - accuracy: 0.11 - ETA: 2s - loss: 3.4984 - accuracy: 0.11 - ETA: 1s - loss: 3.4986 - accuracy: 0.11 - ETA: 1s - loss: 3.4989 - accuracy: 0.11 - ETA: 0s - loss: 3.4986 - accuracy: 0.11 - 342s 8ms/step - loss: 3.4987 - accuracy: 0.1110 - val_loss: 3.9517 - val_accuracy: 0.0084\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 4:56 - loss: 3.4698 - accuracy: 0.13 - ETA: 5:09 - loss: 3.4437 - accuracy: 0.11 - ETA: 5:10 - loss: 3.4621 - accuracy: 0.10 - ETA: 5:07 - loss: 3.4690 - accuracy: 0.10 - ETA: 5:07 - loss: 3.4776 - accuracy: 0.10 - ETA: 5:08 - loss: 3.4720 - accuracy: 0.10 - ETA: 5:09 - loss: 3.4886 - accuracy: 0.10 - ETA: 5:06 - loss: 3.4782 - accuracy: 0.11 - ETA: 5:02 - loss: 3.4754 - accuracy: 0.10 - ETA: 5:01 - loss: 3.4773 - accuracy: 0.11 - ETA: 5:02 - loss: 3.4779 - accuracy: 0.11 - ETA: 5:01 - loss: 3.4797 - accuracy: 0.11 - ETA: 4:59 - loss: 3.4806 - accuracy: 0.11 - ETA: 4:59 - loss: 3.4846 - accuracy: 0.10 - ETA: 4:59 - loss: 3.4807 - accuracy: 0.11 - ETA: 4:58 - loss: 3.4611 - accuracy: 0.11 - ETA: 4:56 - loss: 3.4574 - accuracy: 0.11 - ETA: 4:55 - loss: 3.4601 - accuracy: 0.11 - ETA: 4:55 - loss: 3.4664 - accuracy: 0.11 - ETA: 4:55 - loss: 3.4654 - accuracy: 0.11 - ETA: 4:55 - loss: 3.4620 - accuracy: 0.11 - ETA: 4:55 - loss: 3.4624 - accuracy: 0.11 - ETA: 4:54 - loss: 3.4602 - accuracy: 0.11 - ETA: 4:53 - loss: 3.4606 - accuracy: 0.11 - ETA: 4:51 - loss: 3.4563 - accuracy: 0.12 - ETA: 4:50 - loss: 3.4565 - accuracy: 0.11 - ETA: 4:49 - loss: 3.4551 - accuracy: 0.11 - ETA: 4:47 - loss: 3.4545 - accuracy: 0.11 - ETA: 4:47 - loss: 3.4498 - accuracy: 0.12 - ETA: 4:45 - loss: 3.4476 - accuracy: 0.12 - ETA: 4:44 - loss: 3.4430 - accuracy: 0.12 - ETA: 4:43 - loss: 3.4434 - accuracy: 0.12 - ETA: 4:42 - loss: 3.4410 - accuracy: 0.12 - ETA: 4:40 - loss: 3.4412 - accuracy: 0.12 - ETA: 4:40 - loss: 3.4377 - accuracy: 0.12 - ETA: 4:39 - loss: 3.4407 - accuracy: 0.12 - ETA: 4:39 - loss: 3.4423 - accuracy: 0.12 - ETA: 4:38 - loss: 3.4376 - accuracy: 0.12 - ETA: 4:36 - loss: 3.4358 - accuracy: 0.12 - ETA: 4:35 - loss: 3.4394 - accuracy: 0.12 - ETA: 4:34 - loss: 3.4388 - accuracy: 0.12 - ETA: 4:33 - loss: 3.4357 - accuracy: 0.12 - ETA: 4:32 - loss: 3.4362 - accuracy: 0.12 - ETA: 4:31 - loss: 3.4324 - accuracy: 0.12 - ETA: 4:30 - loss: 3.4340 - accuracy: 0.12 - ETA: 4:30 - loss: 3.4331 - accuracy: 0.12 - ETA: 4:29 - loss: 3.4329 - accuracy: 0.12 - ETA: 4:28 - loss: 3.4328 - accuracy: 0.12 - ETA: 4:27 - loss: 3.4345 - accuracy: 0.12 - ETA: 4:26 - loss: 3.4313 - accuracy: 0.12 - ETA: 4:26 - loss: 3.4309 - accuracy: 0.12 - ETA: 4:25 - loss: 3.4307 - accuracy: 0.12 - ETA: 4:24 - loss: 3.4310 - accuracy: 0.12 - ETA: 4:23 - loss: 3.4318 - accuracy: 0.12 - ETA: 4:22 - loss: 3.4320 - accuracy: 0.11 - ETA: 4:22 - loss: 3.4313 - accuracy: 0.11 - ETA: 4:21 - loss: 3.4322 - accuracy: 0.11 - ETA: 4:20 - loss: 3.4308 - accuracy: 0.11 - ETA: 4:19 - loss: 3.4292 - accuracy: 0.11 - ETA: 4:19 - loss: 3.4295 - accuracy: 0.11 - ETA: 4:18 - loss: 3.4240 - accuracy: 0.11 - ETA: 4:17 - loss: 3.4256 - accuracy: 0.12 - ETA: 4:15 - loss: 3.4316 - accuracy: 0.12 - ETA: 4:14 - loss: 3.4352 - accuracy: 0.12 - ETA: 4:14 - loss: 3.4384 - accuracy: 0.12 - ETA: 4:13 - loss: 3.4358 - accuracy: 0.12 - ETA: 4:12 - loss: 3.4380 - accuracy: 0.12 - ETA: 4:11 - loss: 3.4366 - accuracy: 0.12 - ETA: 4:10 - loss: 3.4354 - accuracy: 0.12 - ETA: 4:09 - loss: 3.4345 - accuracy: 0.12 - ETA: 4:09 - loss: 3.4343 - accuracy: 0.12 - ETA: 4:07 - loss: 3.4315 - accuracy: 0.12 - ETA: 4:07 - loss: 3.4312 - accuracy: 0.12 - ETA: 4:06 - loss: 3.4294 - accuracy: 0.12 - ETA: 4:05 - loss: 3.4298 - accuracy: 0.12 - ETA: 4:03 - loss: 3.4317 - accuracy: 0.12 - ETA: 4:02 - loss: 3.4329 - accuracy: 0.12 - ETA: 4:01 - loss: 3.4316 - accuracy: 0.12 - ETA: 4:00 - loss: 3.4329 - accuracy: 0.12 - ETA: 4:00 - loss: 3.4337 - accuracy: 0.12 - ETA: 3:59 - loss: 3.4318 - accuracy: 0.12 - ETA: 3:58 - loss: 3.4316 - accuracy: 0.12 - ETA: 3:57 - loss: 3.4322 - accuracy: 0.12 - ETA: 3:56 - loss: 3.4337 - accuracy: 0.12 - ETA: 3:55 - loss: 3.4333 - accuracy: 0.12 - ETA: 3:54 - loss: 3.4346 - accuracy: 0.12 - ETA: 3:53 - loss: 3.4359 - accuracy: 0.12 - ETA: 3:52 - loss: 3.4376 - accuracy: 0.12 - ETA: 3:51 - loss: 3.4369 - accuracy: 0.12 - ETA: 3:51 - loss: 3.4378 - accuracy: 0.12 - ETA: 3:50 - loss: 3.4393 - accuracy: 0.12 - ETA: 3:49 - loss: 3.4413 - accuracy: 0.12 - ETA: 3:48 - loss: 3.4407 - accuracy: 0.12 - ETA: 3:47 - loss: 3.4397 - accuracy: 0.12 - ETA: 3:46 - loss: 3.4389 - accuracy: 0.12 - ETA: 3:45 - loss: 3.4402 - accuracy: 0.12 - ETA: 3:44 - loss: 3.4408 - accuracy: 0.12 - ETA: 3:43 - loss: 3.4407 - accuracy: 0.12 - ETA: 3:42 - loss: 3.4407 - accuracy: 0.12 - ETA: 3:41 - loss: 3.4397 - accuracy: 0.12 - ETA: 3:40 - loss: 3.4400 - accuracy: 0.12 - ETA: 3:39 - loss: 3.4409 - accuracy: 0.12 - ETA: 3:38 - loss: 3.4404 - accuracy: 0.12 - ETA: 3:37 - loss: 3.4404 - accuracy: 0.12 - ETA: 3:36 - loss: 3.4394 - accuracy: 0.12 - ETA: 3:35 - loss: 3.4394 - accuracy: 0.12 - ETA: 3:35 - loss: 3.4407 - accuracy: 0.12 - ETA: 3:34 - loss: 3.4408 - accuracy: 0.12 - ETA: 3:32 - loss: 3.4413 - accuracy: 0.12 - ETA: 3:32 - loss: 3.4418 - accuracy: 0.12 - ETA: 3:31 - loss: 3.4419 - accuracy: 0.12 - ETA: 3:30 - loss: 3.4437 - accuracy: 0.12 - ETA: 3:29 - loss: 3.4444 - accuracy: 0.12 - ETA: 3:28 - loss: 3.4453 - accuracy: 0.11 - ETA: 3:27 - loss: 3.4454 - accuracy: 0.11 - ETA: 3:26 - loss: 3.4450 - accuracy: 0.11 - ETA: 3:25 - loss: 3.4441 - accuracy: 0.11 - ETA: 3:24 - loss: 3.4448 - accuracy: 0.12 - ETA: 3:23 - loss: 3.4445 - accuracy: 0.12 - ETA: 3:22 - loss: 3.4453 - accuracy: 0.12 - ETA: 3:21 - loss: 3.4438 - accuracy: 0.12 - ETA: 3:20 - loss: 3.4439 - accuracy: 0.12 - ETA: 3:19 - loss: 3.4437 - accuracy: 0.12 - ETA: 3:18 - loss: 3.4450 - accuracy: 0.12 - ETA: 3:17 - loss: 3.4455 - accuracy: 0.12 - ETA: 3:16 - loss: 3.4462 - accuracy: 0.12 - ETA: 3:15 - loss: 3.4467 - accuracy: 0.12 - ETA: 3:14 - loss: 3.4471 - accuracy: 0.11 - ETA: 3:13 - loss: 3.4461 - accuracy: 0.12 - ETA: 3:12 - loss: 3.4474 - accuracy: 0.11 - ETA: 3:11 - loss: 3.4479 - accuracy: 0.11 - ETA: 3:11 - loss: 3.4477 - accuracy: 0.11 - ETA: 3:10 - loss: 3.4478 - accuracy: 0.11 - ETA: 3:09 - loss: 3.4478 - accuracy: 0.11 - ETA: 3:08 - loss: 3.4477 - accuracy: 0.11 - ETA: 3:07 - loss: 3.4481 - accuracy: 0.11 - ETA: 3:06 - loss: 3.4491 - accuracy: 0.11 - ETA: 3:05 - loss: 3.4480 - accuracy: 0.11 - ETA: 3:04 - loss: 3.4491 - accuracy: 0.11 - ETA: 3:03 - loss: 3.4492 - accuracy: 0.11 - ETA: 3:02 - loss: 3.4491 - accuracy: 0.11 - ETA: 3:01 - loss: 3.4493 - accuracy: 0.11 - ETA: 3:00 - loss: 3.4495 - accuracy: 0.11 - ETA: 2:59 - loss: 3.4503 - accuracy: 0.11 - ETA: 2:58 - loss: 3.4514 - accuracy: 0.11 - ETA: 2:57 - loss: 3.4510 - accuracy: 0.11 - ETA: 2:56 - loss: 3.4509 - accuracy: 0.11 - ETA: 2:55 - loss: 3.4506 - accuracy: 0.11 - ETA: 2:54 - loss: 3.4509 - accuracy: 0.11 - ETA: 2:53 - loss: 3.4505 - accuracy: 0.11 - ETA: 2:52 - loss: 3.4501 - accuracy: 0.11 - ETA: 2:51 - loss: 3.4506 - accuracy: 0.11 - ETA: 2:50 - loss: 3.4520 - accuracy: 0.11 - ETA: 2:49 - loss: 3.4528 - accuracy: 0.11 - ETA: 2:48 - loss: 3.4528 - accuracy: 0.11 - ETA: 2:47 - loss: 3.4529 - accuracy: 0.11 - ETA: 2:46 - loss: 3.4530 - accuracy: 0.11 - ETA: 2:45 - loss: 3.4526 - accuracy: 0.11 - ETA: 2:44 - loss: 3.4527 - accuracy: 0.11 - ETA: 2:43 - loss: 3.4525 - accuracy: 0.11 - ETA: 2:42 - loss: 3.4527 - accuracy: 0.11 - ETA: 2:41 - loss: 3.4532 - accuracy: 0.11 - ETA: 2:41 - loss: 3.4536 - accuracy: 0.11 - ETA: 2:40 - loss: 3.4536 - accuracy: 0.11 - ETA: 2:39 - loss: 3.4524 - accuracy: 0.11 - ETA: 2:38 - loss: 3.4529 - accuracy: 0.11 - ETA: 2:37 - loss: 3.4525 - accuracy: 0.11 - ETA: 2:36 - loss: 3.4526 - accuracy: 0.11 - ETA: 2:35 - loss: 3.4522 - accuracy: 0.11 - ETA: 2:34 - loss: 3.4528 - accuracy: 0.11 - ETA: 2:33 - loss: 3.4528 - accuracy: 0.11 - ETA: 2:32 - loss: 3.4528 - accuracy: 0.11 - ETA: 2:31 - loss: 3.4532 - accuracy: 0.11 - ETA: 2:30 - loss: 3.4534 - accuracy: 0.11 - ETA: 2:29 - loss: 3.4521 - accuracy: 0.11 - ETA: 2:28 - loss: 3.4519 - accuracy: 0.11 - ETA: 2:27 - loss: 3.4508 - accuracy: 0.11 - ETA: 2:26 - loss: 3.4506 - accuracy: 0.11 - ETA: 2:25 - loss: 3.4505 - accuracy: 0.11 - ETA: 2:24 - loss: 3.4506 - accuracy: 0.11 - ETA: 2:23 - loss: 3.4505 - accuracy: 0.11 - ETA: 2:22 - loss: 3.4499 - accuracy: 0.11 - ETA: 2:21 - loss: 3.4498 - accuracy: 0.11 - ETA: 2:20 - loss: 3.4501 - accuracy: 0.11 - ETA: 2:19 - loss: 3.4503 - accuracy: 0.11 - ETA: 2:18 - loss: 3.4502 - accuracy: 0.1182"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.4512 - accuracy: 0.11 - ETA: 2:16 - loss: 3.4510 - accuracy: 0.11 - ETA: 2:15 - loss: 3.4514 - accuracy: 0.11 - ETA: 2:15 - loss: 3.4517 - accuracy: 0.11 - ETA: 2:14 - loss: 3.4523 - accuracy: 0.11 - ETA: 2:13 - loss: 3.4524 - accuracy: 0.11 - ETA: 2:12 - loss: 3.4518 - accuracy: 0.11 - ETA: 2:11 - loss: 3.4523 - accuracy: 0.11 - ETA: 2:10 - loss: 3.4526 - accuracy: 0.11 - ETA: 2:09 - loss: 3.4531 - accuracy: 0.11 - ETA: 2:08 - loss: 3.4528 - accuracy: 0.11 - ETA: 2:07 - loss: 3.4532 - accuracy: 0.11 - ETA: 2:06 - loss: 3.4523 - accuracy: 0.11 - ETA: 2:05 - loss: 3.4526 - accuracy: 0.11 - ETA: 2:04 - loss: 3.4524 - accuracy: 0.11 - ETA: 2:03 - loss: 3.4530 - accuracy: 0.11 - ETA: 2:02 - loss: 3.4527 - accuracy: 0.11 - ETA: 2:01 - loss: 3.4530 - accuracy: 0.11 - ETA: 2:00 - loss: 3.4530 - accuracy: 0.11 - ETA: 1:59 - loss: 3.4534 - accuracy: 0.11 - ETA: 1:58 - loss: 3.4539 - accuracy: 0.11 - ETA: 1:57 - loss: 3.4535 - accuracy: 0.11 - ETA: 1:56 - loss: 3.4533 - accuracy: 0.11 - ETA: 1:55 - loss: 3.4531 - accuracy: 0.11 - ETA: 1:54 - loss: 3.4531 - accuracy: 0.11 - ETA: 1:53 - loss: 3.4537 - accuracy: 0.11 - ETA: 1:52 - loss: 3.4539 - accuracy: 0.11 - ETA: 1:51 - loss: 3.4542 - accuracy: 0.11 - ETA: 1:51 - loss: 3.4545 - accuracy: 0.11 - ETA: 1:50 - loss: 3.4545 - accuracy: 0.11 - ETA: 1:49 - loss: 3.4546 - accuracy: 0.11 - ETA: 1:48 - loss: 3.4536 - accuracy: 0.11 - ETA: 1:47 - loss: 3.4537 - accuracy: 0.11 - ETA: 1:46 - loss: 3.4533 - accuracy: 0.11 - ETA: 1:45 - loss: 3.4534 - accuracy: 0.11 - ETA: 1:44 - loss: 3.4539 - accuracy: 0.11 - ETA: 1:43 - loss: 3.4537 - accuracy: 0.11 - ETA: 1:42 - loss: 3.4533 - accuracy: 0.11 - ETA: 1:41 - loss: 3.4536 - accuracy: 0.11 - ETA: 1:40 - loss: 3.4538 - accuracy: 0.11 - ETA: 1:39 - loss: 3.4542 - accuracy: 0.11 - ETA: 1:38 - loss: 3.4539 - accuracy: 0.11 - ETA: 1:37 - loss: 3.4542 - accuracy: 0.11 - ETA: 1:36 - loss: 3.4540 - accuracy: 0.11 - ETA: 1:35 - loss: 3.4543 - accuracy: 0.11 - ETA: 1:34 - loss: 3.4543 - accuracy: 0.11 - ETA: 1:33 - loss: 3.4546 - accuracy: 0.11 - ETA: 1:32 - loss: 3.4551 - accuracy: 0.11 - ETA: 1:31 - loss: 3.4550 - accuracy: 0.11 - ETA: 1:30 - loss: 3.4560 - accuracy: 0.11 - ETA: 1:29 - loss: 3.4552 - accuracy: 0.11 - ETA: 1:28 - loss: 3.4549 - accuracy: 0.11 - ETA: 1:27 - loss: 3.4549 - accuracy: 0.11 - ETA: 1:26 - loss: 3.4552 - accuracy: 0.11 - ETA: 1:26 - loss: 3.4544 - accuracy: 0.11 - ETA: 1:25 - loss: 3.4547 - accuracy: 0.11 - ETA: 1:24 - loss: 3.4553 - accuracy: 0.11 - ETA: 1:23 - loss: 3.4561 - accuracy: 0.11 - ETA: 1:22 - loss: 3.4556 - accuracy: 0.11 - ETA: 1:21 - loss: 3.4558 - accuracy: 0.11 - ETA: 1:20 - loss: 3.4555 - accuracy: 0.11 - ETA: 1:19 - loss: 3.4558 - accuracy: 0.11 - ETA: 1:18 - loss: 3.4553 - accuracy: 0.11 - ETA: 1:17 - loss: 3.4558 - accuracy: 0.11 - ETA: 1:16 - loss: 3.4555 - accuracy: 0.11 - ETA: 1:15 - loss: 3.4561 - accuracy: 0.11 - ETA: 1:14 - loss: 3.4560 - accuracy: 0.11 - ETA: 1:13 - loss: 3.4564 - accuracy: 0.11 - ETA: 1:12 - loss: 3.4566 - accuracy: 0.11 - ETA: 1:11 - loss: 3.4566 - accuracy: 0.11 - ETA: 1:10 - loss: 3.4561 - accuracy: 0.11 - ETA: 1:09 - loss: 3.4560 - accuracy: 0.11 - ETA: 1:08 - loss: 3.4567 - accuracy: 0.11 - ETA: 1:07 - loss: 3.4571 - accuracy: 0.11 - ETA: 1:06 - loss: 3.4573 - accuracy: 0.11 - ETA: 1:05 - loss: 3.4578 - accuracy: 0.11 - ETA: 1:05 - loss: 3.4574 - accuracy: 0.11 - ETA: 1:04 - loss: 3.4572 - accuracy: 0.11 - ETA: 1:03 - loss: 3.4576 - accuracy: 0.11 - ETA: 1:02 - loss: 3.4577 - accuracy: 0.11 - ETA: 1:01 - loss: 3.4575 - accuracy: 0.11 - ETA: 1:00 - loss: 3.4574 - accuracy: 0.11 - ETA: 59s - loss: 3.4568 - accuracy: 0.1168 - ETA: 58s - loss: 3.4575 - accuracy: 0.116 - ETA: 57s - loss: 3.4589 - accuracy: 0.116 - ETA: 56s - loss: 3.4587 - accuracy: 0.116 - ETA: 55s - loss: 3.4590 - accuracy: 0.116 - ETA: 54s - loss: 3.4592 - accuracy: 0.116 - ETA: 53s - loss: 3.4590 - accuracy: 0.116 - ETA: 52s - loss: 3.4595 - accuracy: 0.116 - ETA: 51s - loss: 3.4602 - accuracy: 0.116 - ETA: 50s - loss: 3.4600 - accuracy: 0.116 - ETA: 49s - loss: 3.4599 - accuracy: 0.116 - ETA: 48s - loss: 3.4593 - accuracy: 0.116 - ETA: 47s - loss: 3.4595 - accuracy: 0.116 - ETA: 46s - loss: 3.4595 - accuracy: 0.116 - ETA: 45s - loss: 3.4600 - accuracy: 0.116 - ETA: 44s - loss: 3.4603 - accuracy: 0.116 - ETA: 44s - loss: 3.4603 - accuracy: 0.116 - ETA: 43s - loss: 3.4604 - accuracy: 0.116 - ETA: 42s - loss: 3.4614 - accuracy: 0.115 - ETA: 41s - loss: 3.4617 - accuracy: 0.115 - ETA: 40s - loss: 3.4620 - accuracy: 0.115 - ETA: 39s - loss: 3.4621 - accuracy: 0.115 - ETA: 38s - loss: 3.4622 - accuracy: 0.115 - ETA: 37s - loss: 3.4614 - accuracy: 0.116 - ETA: 36s - loss: 3.4610 - accuracy: 0.116 - ETA: 35s - loss: 3.4606 - accuracy: 0.116 - ETA: 34s - loss: 3.4609 - accuracy: 0.115 - ETA: 33s - loss: 3.4610 - accuracy: 0.115 - ETA: 32s - loss: 3.4616 - accuracy: 0.115 - ETA: 31s - loss: 3.4619 - accuracy: 0.115 - ETA: 30s - loss: 3.4618 - accuracy: 0.115 - ETA: 29s - loss: 3.4618 - accuracy: 0.115 - ETA: 28s - loss: 3.4613 - accuracy: 0.115 - ETA: 27s - loss: 3.4619 - accuracy: 0.115 - ETA: 26s - loss: 3.4622 - accuracy: 0.115 - ETA: 25s - loss: 3.4624 - accuracy: 0.115 - ETA: 24s - loss: 3.4627 - accuracy: 0.115 - ETA: 23s - loss: 3.4625 - accuracy: 0.115 - ETA: 22s - loss: 3.4632 - accuracy: 0.115 - ETA: 22s - loss: 3.4632 - accuracy: 0.115 - ETA: 21s - loss: 3.4629 - accuracy: 0.115 - ETA: 20s - loss: 3.4628 - accuracy: 0.115 - ETA: 19s - loss: 3.4633 - accuracy: 0.115 - ETA: 18s - loss: 3.4630 - accuracy: 0.115 - ETA: 17s - loss: 3.4629 - accuracy: 0.115 - ETA: 16s - loss: 3.4630 - accuracy: 0.115 - ETA: 15s - loss: 3.4630 - accuracy: 0.115 - ETA: 14s - loss: 3.4636 - accuracy: 0.114 - ETA: 13s - loss: 3.4639 - accuracy: 0.114 - ETA: 12s - loss: 3.4641 - accuracy: 0.114 - ETA: 11s - loss: 3.4633 - accuracy: 0.115 - ETA: 10s - loss: 3.4637 - accuracy: 0.115 - ETA: 9s - loss: 3.4635 - accuracy: 0.115 - ETA: 8s - loss: 3.4636 - accuracy: 0.11 - ETA: 7s - loss: 3.4632 - accuracy: 0.11 - ETA: 6s - loss: 3.4630 - accuracy: 0.11 - ETA: 5s - loss: 3.4630 - accuracy: 0.11 - ETA: 4s - loss: 3.4632 - accuracy: 0.11 - ETA: 3s - loss: 3.4635 - accuracy: 0.11 - ETA: 2s - loss: 3.4636 - accuracy: 0.11 - ETA: 1s - loss: 3.4635 - accuracy: 0.11 - ETA: 1s - loss: 3.4633 - accuracy: 0.11 - ETA: 0s - loss: 3.4639 - accuracy: 0.11 - 341s 8ms/step - loss: 3.4639 - accuracy: 0.1149 - val_loss: 4.0167 - val_accuracy: 0.0076\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:31 - loss: 3.4362 - accuracy: 0.12 - ETA: 5:14 - loss: 3.4657 - accuracy: 0.11 - ETA: 5:13 - loss: 3.4464 - accuracy: 0.11 - ETA: 5:09 - loss: 3.4413 - accuracy: 0.11 - ETA: 5:04 - loss: 3.4633 - accuracy: 0.11 - ETA: 5:04 - loss: 3.4841 - accuracy: 0.10 - ETA: 5:03 - loss: 3.4745 - accuracy: 0.11 - ETA: 5:04 - loss: 3.4683 - accuracy: 0.11 - ETA: 5:04 - loss: 3.4764 - accuracy: 0.10 - ETA: 5:01 - loss: 3.4839 - accuracy: 0.10 - ETA: 5:00 - loss: 3.4687 - accuracy: 0.10 - ETA: 5:00 - loss: 3.4774 - accuracy: 0.10 - ETA: 4:59 - loss: 3.4707 - accuracy: 0.10 - ETA: 4:58 - loss: 3.4561 - accuracy: 0.11 - ETA: 4:58 - loss: 3.4563 - accuracy: 0.11 - ETA: 4:56 - loss: 3.4528 - accuracy: 0.11 - ETA: 4:56 - loss: 3.4676 - accuracy: 0.11 - ETA: 4:55 - loss: 3.4685 - accuracy: 0.10 - ETA: 4:54 - loss: 3.4735 - accuracy: 0.10 - ETA: 4:53 - loss: 3.4663 - accuracy: 0.10 - ETA: 4:51 - loss: 3.4706 - accuracy: 0.10 - ETA: 4:50 - loss: 3.4739 - accuracy: 0.10 - ETA: 4:50 - loss: 3.4772 - accuracy: 0.10 - ETA: 4:49 - loss: 3.4796 - accuracy: 0.10 - ETA: 4:48 - loss: 3.4873 - accuracy: 0.10 - ETA: 4:47 - loss: 3.4869 - accuracy: 0.10 - ETA: 4:48 - loss: 3.4931 - accuracy: 0.10 - ETA: 4:46 - loss: 3.4961 - accuracy: 0.10 - ETA: 4:46 - loss: 3.4971 - accuracy: 0.10 - ETA: 4:45 - loss: 3.5054 - accuracy: 0.10 - ETA: 4:44 - loss: 3.5092 - accuracy: 0.10 - ETA: 4:44 - loss: 3.5104 - accuracy: 0.10 - ETA: 4:43 - loss: 3.5060 - accuracy: 0.10 - ETA: 4:42 - loss: 3.5093 - accuracy: 0.10 - ETA: 4:42 - loss: 3.5119 - accuracy: 0.10 - ETA: 4:41 - loss: 3.5049 - accuracy: 0.10 - ETA: 4:39 - loss: 3.5034 - accuracy: 0.10 - ETA: 4:38 - loss: 3.5065 - accuracy: 0.10 - ETA: 4:37 - loss: 3.5058 - accuracy: 0.10 - ETA: 4:36 - loss: 3.5006 - accuracy: 0.10 - ETA: 4:36 - loss: 3.5034 - accuracy: 0.10 - ETA: 4:35 - loss: 3.5051 - accuracy: 0.10 - ETA: 4:35 - loss: 3.5050 - accuracy: 0.10 - ETA: 4:34 - loss: 3.5078 - accuracy: 0.10 - ETA: 4:33 - loss: 3.5052 - accuracy: 0.10 - ETA: 4:33 - loss: 3.5071 - accuracy: 0.10 - ETA: 4:32 - loss: 3.5052 - accuracy: 0.10 - ETA: 4:31 - loss: 3.5053 - accuracy: 0.10 - ETA: 4:30 - loss: 3.5055 - accuracy: 0.10 - ETA: 4:29 - loss: 3.5055 - accuracy: 0.10 - ETA: 4:28 - loss: 3.5038 - accuracy: 0.10 - ETA: 4:27 - loss: 3.5047 - accuracy: 0.10 - ETA: 4:26 - loss: 3.5021 - accuracy: 0.10 - ETA: 4:24 - loss: 3.5010 - accuracy: 0.10 - ETA: 4:24 - loss: 3.5005 - accuracy: 0.10 - ETA: 4:23 - loss: 3.5022 - accuracy: 0.10 - ETA: 4:21 - loss: 3.5023 - accuracy: 0.10 - ETA: 4:21 - loss: 3.5037 - accuracy: 0.10 - ETA: 4:20 - loss: 3.5046 - accuracy: 0.10 - ETA: 4:19 - loss: 3.5041 - accuracy: 0.10 - ETA: 4:18 - loss: 3.5044 - accuracy: 0.10 - ETA: 4:18 - loss: 3.5052 - accuracy: 0.10 - ETA: 4:16 - loss: 3.5040 - accuracy: 0.10 - ETA: 4:15 - loss: 3.5040 - accuracy: 0.10 - ETA: 4:14 - loss: 3.5010 - accuracy: 0.10 - ETA: 4:14 - loss: 3.5009 - accuracy: 0.10 - ETA: 4:13 - loss: 3.4989 - accuracy: 0.10 - ETA: 4:12 - loss: 3.4977 - accuracy: 0.10 - ETA: 4:11 - loss: 3.4961 - accuracy: 0.10 - ETA: 4:10 - loss: 3.4939 - accuracy: 0.10 - ETA: 4:09 - loss: 3.4929 - accuracy: 0.10 - ETA: 4:08 - loss: 3.4923 - accuracy: 0.10 - ETA: 4:07 - loss: 3.4913 - accuracy: 0.10 - ETA: 4:06 - loss: 3.4923 - accuracy: 0.10 - ETA: 4:05 - loss: 3.4923 - accuracy: 0.10 - ETA: 4:04 - loss: 3.4925 - accuracy: 0.10 - ETA: 4:03 - loss: 3.4912 - accuracy: 0.10 - ETA: 4:03 - loss: 3.4946 - accuracy: 0.10 - ETA: 4:02 - loss: 3.4947 - accuracy: 0.10 - ETA: 4:01 - loss: 3.4927 - accuracy: 0.10 - ETA: 3:59 - loss: 3.4894 - accuracy: 0.11 - ETA: 3:58 - loss: 3.4907 - accuracy: 0.10 - ETA: 3:57 - loss: 3.4904 - accuracy: 0.10 - ETA: 3:56 - loss: 3.4885 - accuracy: 0.10 - ETA: 3:56 - loss: 3.4889 - accuracy: 0.10 - ETA: 3:55 - loss: 3.4889 - accuracy: 0.10 - ETA: 3:54 - loss: 3.4892 - accuracy: 0.10 - ETA: 3:53 - loss: 3.4879 - accuracy: 0.10 - ETA: 3:51 - loss: 3.4868 - accuracy: 0.11 - ETA: 3:51 - loss: 3.4870 - accuracy: 0.11 - ETA: 3:50 - loss: 3.4863 - accuracy: 0.11 - ETA: 3:49 - loss: 3.4866 - accuracy: 0.11 - ETA: 3:48 - loss: 3.4854 - accuracy: 0.11 - ETA: 3:47 - loss: 3.4854 - accuracy: 0.11 - ETA: 3:46 - loss: 3.4840 - accuracy: 0.11 - ETA: 3:45 - loss: 3.4853 - accuracy: 0.11 - ETA: 3:44 - loss: 3.4845 - accuracy: 0.11 - ETA: 3:43 - loss: 3.4848 - accuracy: 0.11 - ETA: 3:41 - loss: 3.4833 - accuracy: 0.11 - ETA: 3:40 - loss: 3.4830 - accuracy: 0.11 - ETA: 3:40 - loss: 3.4821 - accuracy: 0.11 - ETA: 3:38 - loss: 3.4827 - accuracy: 0.11 - ETA: 3:37 - loss: 3.4831 - accuracy: 0.11 - ETA: 3:36 - loss: 3.4826 - accuracy: 0.11 - ETA: 3:35 - loss: 3.4821 - accuracy: 0.11 - ETA: 3:34 - loss: 3.4823 - accuracy: 0.11 - ETA: 3:33 - loss: 3.4824 - accuracy: 0.11 - ETA: 3:33 - loss: 3.4821 - accuracy: 0.11 - ETA: 3:31 - loss: 3.4828 - accuracy: 0.11 - ETA: 3:31 - loss: 3.4833 - accuracy: 0.11 - ETA: 3:30 - loss: 3.4817 - accuracy: 0.11 - ETA: 3:29 - loss: 3.4825 - accuracy: 0.11 - ETA: 3:28 - loss: 3.4831 - accuracy: 0.11 - ETA: 3:27 - loss: 3.4825 - accuracy: 0.11 - ETA: 3:26 - loss: 3.4819 - accuracy: 0.11 - ETA: 3:25 - loss: 3.4816 - accuracy: 0.11 - ETA: 3:24 - loss: 3.4828 - accuracy: 0.11 - ETA: 3:23 - loss: 3.4827 - accuracy: 0.11 - ETA: 3:22 - loss: 3.4815 - accuracy: 0.11 - ETA: 3:21 - loss: 3.4812 - accuracy: 0.11 - ETA: 3:20 - loss: 3.4823 - accuracy: 0.11 - ETA: 3:19 - loss: 3.4822 - accuracy: 0.11 - ETA: 3:18 - loss: 3.4821 - accuracy: 0.11 - ETA: 3:17 - loss: 3.4834 - accuracy: 0.11 - ETA: 3:17 - loss: 3.4830 - accuracy: 0.11 - ETA: 3:16 - loss: 3.4838 - accuracy: 0.11 - ETA: 3:15 - loss: 3.4840 - accuracy: 0.11 - ETA: 3:14 - loss: 3.4836 - accuracy: 0.11 - ETA: 3:13 - loss: 3.4843 - accuracy: 0.11 - ETA: 3:12 - loss: 3.4842 - accuracy: 0.11 - ETA: 3:11 - loss: 3.4848 - accuracy: 0.11 - ETA: 3:10 - loss: 3.4843 - accuracy: 0.11 - ETA: 3:09 - loss: 3.4855 - accuracy: 0.11 - ETA: 3:08 - loss: 3.4850 - accuracy: 0.11 - ETA: 3:07 - loss: 3.4852 - accuracy: 0.11 - ETA: 3:06 - loss: 3.4858 - accuracy: 0.11 - ETA: 3:05 - loss: 3.4864 - accuracy: 0.11 - ETA: 3:04 - loss: 3.4861 - accuracy: 0.11 - ETA: 3:03 - loss: 3.4851 - accuracy: 0.11 - ETA: 3:02 - loss: 3.4860 - accuracy: 0.11 - ETA: 3:01 - loss: 3.4845 - accuracy: 0.11 - ETA: 3:00 - loss: 3.4845 - accuracy: 0.11 - ETA: 2:59 - loss: 3.4844 - accuracy: 0.11 - ETA: 2:58 - loss: 3.4836 - accuracy: 0.11 - ETA: 2:58 - loss: 3.4835 - accuracy: 0.11 - ETA: 2:57 - loss: 3.4836 - accuracy: 0.11 - ETA: 2:56 - loss: 3.4832 - accuracy: 0.11 - ETA: 2:55 - loss: 3.4836 - accuracy: 0.11 - ETA: 2:54 - loss: 3.4828 - accuracy: 0.11 - ETA: 2:53 - loss: 3.4823 - accuracy: 0.11 - ETA: 2:52 - loss: 3.4813 - accuracy: 0.11 - ETA: 2:51 - loss: 3.4827 - accuracy: 0.11 - ETA: 2:50 - loss: 3.4824 - accuracy: 0.11 - ETA: 2:49 - loss: 3.4816 - accuracy: 0.11 - ETA: 2:48 - loss: 3.4827 - accuracy: 0.11 - ETA: 2:47 - loss: 3.4829 - accuracy: 0.11 - ETA: 2:46 - loss: 3.4837 - accuracy: 0.11 - ETA: 2:45 - loss: 3.4842 - accuracy: 0.10 - ETA: 2:44 - loss: 3.4841 - accuracy: 0.10 - ETA: 2:43 - loss: 3.4827 - accuracy: 0.11 - ETA: 2:42 - loss: 3.4820 - accuracy: 0.11 - ETA: 2:41 - loss: 3.4821 - accuracy: 0.11 - ETA: 2:40 - loss: 3.4821 - accuracy: 0.11 - ETA: 2:39 - loss: 3.4824 - accuracy: 0.10 - ETA: 2:38 - loss: 3.4826 - accuracy: 0.10 - ETA: 2:37 - loss: 3.4814 - accuracy: 0.10 - ETA: 2:36 - loss: 3.4806 - accuracy: 0.10 - ETA: 2:36 - loss: 3.4812 - accuracy: 0.10 - ETA: 2:35 - loss: 3.4810 - accuracy: 0.10 - ETA: 2:34 - loss: 3.4814 - accuracy: 0.10 - ETA: 2:33 - loss: 3.4814 - accuracy: 0.10 - ETA: 2:32 - loss: 3.4800 - accuracy: 0.11 - ETA: 2:31 - loss: 3.4794 - accuracy: 0.11 - ETA: 2:30 - loss: 3.4796 - accuracy: 0.11 - ETA: 2:29 - loss: 3.4786 - accuracy: 0.11 - ETA: 2:28 - loss: 3.4788 - accuracy: 0.11 - ETA: 2:27 - loss: 3.4780 - accuracy: 0.11 - ETA: 2:26 - loss: 3.4769 - accuracy: 0.11 - ETA: 2:25 - loss: 3.4757 - accuracy: 0.11 - ETA: 2:24 - loss: 3.4753 - accuracy: 0.11 - ETA: 2:23 - loss: 3.4751 - accuracy: 0.11 - ETA: 2:22 - loss: 3.4742 - accuracy: 0.11 - ETA: 2:21 - loss: 3.4741 - accuracy: 0.11 - ETA: 2:20 - loss: 3.4742 - accuracy: 0.11 - ETA: 2:19 - loss: 3.4743 - accuracy: 0.11 - ETA: 2:18 - loss: 3.4730 - accuracy: 0.1127"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.4726 - accuracy: 0.11 - ETA: 2:16 - loss: 3.4718 - accuracy: 0.11 - ETA: 2:15 - loss: 3.4720 - accuracy: 0.11 - ETA: 2:14 - loss: 3.4720 - accuracy: 0.11 - ETA: 2:13 - loss: 3.4722 - accuracy: 0.11 - ETA: 2:13 - loss: 3.4722 - accuracy: 0.11 - ETA: 2:12 - loss: 3.4728 - accuracy: 0.11 - ETA: 2:11 - loss: 3.4728 - accuracy: 0.11 - ETA: 2:10 - loss: 3.4723 - accuracy: 0.11 - ETA: 2:09 - loss: 3.4727 - accuracy: 0.11 - ETA: 2:08 - loss: 3.4734 - accuracy: 0.11 - ETA: 2:07 - loss: 3.4741 - accuracy: 0.11 - ETA: 2:06 - loss: 3.4742 - accuracy: 0.11 - ETA: 2:05 - loss: 3.4734 - accuracy: 0.11 - ETA: 2:04 - loss: 3.4734 - accuracy: 0.11 - ETA: 2:03 - loss: 3.4730 - accuracy: 0.11 - ETA: 2:02 - loss: 3.4737 - accuracy: 0.11 - ETA: 2:01 - loss: 3.4737 - accuracy: 0.11 - ETA: 2:00 - loss: 3.4727 - accuracy: 0.11 - ETA: 1:59 - loss: 3.4724 - accuracy: 0.11 - ETA: 1:58 - loss: 3.4730 - accuracy: 0.11 - ETA: 1:57 - loss: 3.4726 - accuracy: 0.11 - ETA: 1:56 - loss: 3.4724 - accuracy: 0.11 - ETA: 1:55 - loss: 3.4727 - accuracy: 0.11 - ETA: 1:54 - loss: 3.4730 - accuracy: 0.11 - ETA: 1:53 - loss: 3.4727 - accuracy: 0.11 - ETA: 1:52 - loss: 3.4711 - accuracy: 0.11 - ETA: 1:52 - loss: 3.4713 - accuracy: 0.11 - ETA: 1:51 - loss: 3.4706 - accuracy: 0.11 - ETA: 1:50 - loss: 3.4703 - accuracy: 0.11 - ETA: 1:49 - loss: 3.4704 - accuracy: 0.11 - ETA: 1:48 - loss: 3.4707 - accuracy: 0.11 - ETA: 1:47 - loss: 3.4712 - accuracy: 0.11 - ETA: 1:46 - loss: 3.4712 - accuracy: 0.11 - ETA: 1:45 - loss: 3.4712 - accuracy: 0.11 - ETA: 1:44 - loss: 3.4714 - accuracy: 0.11 - ETA: 1:43 - loss: 3.4712 - accuracy: 0.11 - ETA: 1:42 - loss: 3.4707 - accuracy: 0.11 - ETA: 1:41 - loss: 3.4703 - accuracy: 0.11 - ETA: 1:40 - loss: 3.4698 - accuracy: 0.11 - ETA: 1:39 - loss: 3.4698 - accuracy: 0.11 - ETA: 1:38 - loss: 3.4693 - accuracy: 0.11 - ETA: 1:37 - loss: 3.4699 - accuracy: 0.11 - ETA: 1:36 - loss: 3.4693 - accuracy: 0.11 - ETA: 1:35 - loss: 3.4702 - accuracy: 0.11 - ETA: 1:34 - loss: 3.4706 - accuracy: 0.11 - ETA: 1:33 - loss: 3.4702 - accuracy: 0.11 - ETA: 1:32 - loss: 3.4697 - accuracy: 0.11 - ETA: 1:31 - loss: 3.4707 - accuracy: 0.11 - ETA: 1:30 - loss: 3.4705 - accuracy: 0.11 - ETA: 1:29 - loss: 3.4709 - accuracy: 0.11 - ETA: 1:28 - loss: 3.4702 - accuracy: 0.11 - ETA: 1:28 - loss: 3.4704 - accuracy: 0.11 - ETA: 1:27 - loss: 3.4699 - accuracy: 0.11 - ETA: 1:26 - loss: 3.4695 - accuracy: 0.11 - ETA: 1:25 - loss: 3.4696 - accuracy: 0.11 - ETA: 1:24 - loss: 3.4696 - accuracy: 0.11 - ETA: 1:23 - loss: 3.4698 - accuracy: 0.11 - ETA: 1:22 - loss: 3.4695 - accuracy: 0.11 - ETA: 1:21 - loss: 3.4688 - accuracy: 0.11 - ETA: 1:20 - loss: 3.4688 - accuracy: 0.11 - ETA: 1:19 - loss: 3.4687 - accuracy: 0.11 - ETA: 1:18 - loss: 3.4674 - accuracy: 0.11 - ETA: 1:17 - loss: 3.4673 - accuracy: 0.11 - ETA: 1:16 - loss: 3.4671 - accuracy: 0.11 - ETA: 1:15 - loss: 3.4671 - accuracy: 0.11 - ETA: 1:14 - loss: 3.4673 - accuracy: 0.11 - ETA: 1:13 - loss: 3.4668 - accuracy: 0.11 - ETA: 1:12 - loss: 3.4671 - accuracy: 0.11 - ETA: 1:11 - loss: 3.4669 - accuracy: 0.11 - ETA: 1:10 - loss: 3.4667 - accuracy: 0.11 - ETA: 1:09 - loss: 3.4661 - accuracy: 0.11 - ETA: 1:08 - loss: 3.4659 - accuracy: 0.11 - ETA: 1:07 - loss: 3.4659 - accuracy: 0.11 - ETA: 1:07 - loss: 3.4654 - accuracy: 0.11 - ETA: 1:06 - loss: 3.4651 - accuracy: 0.11 - ETA: 1:05 - loss: 3.4648 - accuracy: 0.11 - ETA: 1:04 - loss: 3.4646 - accuracy: 0.11 - ETA: 1:03 - loss: 3.4643 - accuracy: 0.11 - ETA: 1:02 - loss: 3.4646 - accuracy: 0.11 - ETA: 1:01 - loss: 3.4642 - accuracy: 0.11 - ETA: 1:00 - loss: 3.4639 - accuracy: 0.11 - ETA: 59s - loss: 3.4636 - accuracy: 0.1144 - ETA: 58s - loss: 3.4637 - accuracy: 0.114 - ETA: 57s - loss: 3.4640 - accuracy: 0.114 - ETA: 56s - loss: 3.4639 - accuracy: 0.114 - ETA: 55s - loss: 3.4635 - accuracy: 0.114 - ETA: 54s - loss: 3.4630 - accuracy: 0.114 - ETA: 53s - loss: 3.4633 - accuracy: 0.114 - ETA: 52s - loss: 3.4632 - accuracy: 0.114 - ETA: 51s - loss: 3.4633 - accuracy: 0.114 - ETA: 50s - loss: 3.4626 - accuracy: 0.114 - ETA: 49s - loss: 3.4628 - accuracy: 0.114 - ETA: 48s - loss: 3.4629 - accuracy: 0.114 - ETA: 47s - loss: 3.4633 - accuracy: 0.114 - ETA: 46s - loss: 3.4635 - accuracy: 0.114 - ETA: 46s - loss: 3.4639 - accuracy: 0.114 - ETA: 45s - loss: 3.4632 - accuracy: 0.114 - ETA: 44s - loss: 3.4631 - accuracy: 0.114 - ETA: 43s - loss: 3.4633 - accuracy: 0.114 - ETA: 42s - loss: 3.4631 - accuracy: 0.114 - ETA: 41s - loss: 3.4625 - accuracy: 0.114 - ETA: 40s - loss: 3.4621 - accuracy: 0.114 - ETA: 39s - loss: 3.4617 - accuracy: 0.114 - ETA: 38s - loss: 3.4617 - accuracy: 0.114 - ETA: 37s - loss: 3.4620 - accuracy: 0.114 - ETA: 36s - loss: 3.4620 - accuracy: 0.114 - ETA: 35s - loss: 3.4623 - accuracy: 0.114 - ETA: 34s - loss: 3.4623 - accuracy: 0.114 - ETA: 33s - loss: 3.4625 - accuracy: 0.114 - ETA: 32s - loss: 3.4633 - accuracy: 0.114 - ETA: 31s - loss: 3.4631 - accuracy: 0.114 - ETA: 30s - loss: 3.4624 - accuracy: 0.114 - ETA: 29s - loss: 3.4624 - accuracy: 0.114 - ETA: 28s - loss: 3.4622 - accuracy: 0.114 - ETA: 27s - loss: 3.4624 - accuracy: 0.114 - ETA: 26s - loss: 3.4632 - accuracy: 0.114 - ETA: 25s - loss: 3.4625 - accuracy: 0.114 - ETA: 24s - loss: 3.4621 - accuracy: 0.114 - ETA: 24s - loss: 3.4625 - accuracy: 0.114 - ETA: 23s - loss: 3.4623 - accuracy: 0.114 - ETA: 22s - loss: 3.4615 - accuracy: 0.114 - ETA: 21s - loss: 3.4613 - accuracy: 0.114 - ETA: 20s - loss: 3.4613 - accuracy: 0.114 - ETA: 19s - loss: 3.4616 - accuracy: 0.114 - ETA: 18s - loss: 3.4613 - accuracy: 0.114 - ETA: 17s - loss: 3.4613 - accuracy: 0.114 - ETA: 16s - loss: 3.4611 - accuracy: 0.114 - ETA: 15s - loss: 3.4606 - accuracy: 0.114 - ETA: 14s - loss: 3.4607 - accuracy: 0.114 - ETA: 13s - loss: 3.4599 - accuracy: 0.114 - ETA: 12s - loss: 3.4599 - accuracy: 0.114 - ETA: 11s - loss: 3.4601 - accuracy: 0.114 - ETA: 10s - loss: 3.4601 - accuracy: 0.114 - ETA: 9s - loss: 3.4596 - accuracy: 0.114 - ETA: 8s - loss: 3.4594 - accuracy: 0.11 - ETA: 7s - loss: 3.4594 - accuracy: 0.11 - ETA: 6s - loss: 3.4598 - accuracy: 0.11 - ETA: 5s - loss: 3.4607 - accuracy: 0.11 - ETA: 4s - loss: 3.4606 - accuracy: 0.11 - ETA: 3s - loss: 3.4608 - accuracy: 0.11 - ETA: 2s - loss: 3.4607 - accuracy: 0.11 - ETA: 1s - loss: 3.4607 - accuracy: 0.11 - ETA: 1s - loss: 3.4611 - accuracy: 0.11 - ETA: 0s - loss: 3.4613 - accuracy: 0.11 - 342s 8ms/step - loss: 3.4614 - accuracy: 0.1145 - val_loss: 4.0093 - val_accuracy: 0.0111\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:34 - loss: 3.5072 - accuracy: 0.10 - ETA: 5:19 - loss: 3.5043 - accuracy: 0.08 - ETA: 5:17 - loss: 3.4581 - accuracy: 0.10 - ETA: 5:09 - loss: 3.4385 - accuracy: 0.11 - ETA: 5:08 - loss: 3.4367 - accuracy: 0.11 - ETA: 5:06 - loss: 3.4070 - accuracy: 0.12 - ETA: 5:10 - loss: 3.4129 - accuracy: 0.12 - ETA: 5:10 - loss: 3.4370 - accuracy: 0.11 - ETA: 5:10 - loss: 3.4345 - accuracy: 0.11 - ETA: 5:10 - loss: 3.4456 - accuracy: 0.11 - ETA: 5:09 - loss: 3.4475 - accuracy: 0.11 - ETA: 5:09 - loss: 3.4451 - accuracy: 0.12 - ETA: 5:08 - loss: 3.4750 - accuracy: 0.12 - ETA: 5:04 - loss: 3.4837 - accuracy: 0.12 - ETA: 5:03 - loss: 3.4848 - accuracy: 0.11 - ETA: 5:01 - loss: 3.4907 - accuracy: 0.11 - ETA: 5:00 - loss: 3.5008 - accuracy: 0.11 - ETA: 5:00 - loss: 3.4968 - accuracy: 0.11 - ETA: 5:00 - loss: 3.5001 - accuracy: 0.11 - ETA: 5:00 - loss: 3.4999 - accuracy: 0.11 - ETA: 4:59 - loss: 3.4993 - accuracy: 0.11 - ETA: 4:58 - loss: 3.5018 - accuracy: 0.11 - ETA: 4:58 - loss: 3.5014 - accuracy: 0.11 - ETA: 4:58 - loss: 3.5039 - accuracy: 0.11 - ETA: 4:57 - loss: 3.5039 - accuracy: 0.11 - ETA: 4:55 - loss: 3.5009 - accuracy: 0.11 - ETA: 4:54 - loss: 3.4992 - accuracy: 0.11 - ETA: 4:53 - loss: 3.4939 - accuracy: 0.11 - ETA: 4:52 - loss: 3.4901 - accuracy: 0.11 - ETA: 4:51 - loss: 3.4912 - accuracy: 0.11 - ETA: 4:50 - loss: 3.4907 - accuracy: 0.11 - ETA: 4:49 - loss: 3.4875 - accuracy: 0.11 - ETA: 4:48 - loss: 3.4846 - accuracy: 0.11 - ETA: 4:47 - loss: 3.4844 - accuracy: 0.11 - ETA: 4:46 - loss: 3.4825 - accuracy: 0.11 - ETA: 4:45 - loss: 3.4817 - accuracy: 0.11 - ETA: 4:44 - loss: 3.4795 - accuracy: 0.11 - ETA: 4:44 - loss: 3.4764 - accuracy: 0.11 - ETA: 4:43 - loss: 3.4745 - accuracy: 0.11 - ETA: 4:42 - loss: 3.4759 - accuracy: 0.11 - ETA: 4:41 - loss: 3.4790 - accuracy: 0.11 - ETA: 4:40 - loss: 3.4800 - accuracy: 0.11 - ETA: 4:38 - loss: 3.4768 - accuracy: 0.11 - ETA: 4:37 - loss: 3.4734 - accuracy: 0.11 - ETA: 4:36 - loss: 3.4721 - accuracy: 0.11 - ETA: 4:35 - loss: 3.4700 - accuracy: 0.11 - ETA: 4:34 - loss: 3.4675 - accuracy: 0.11 - ETA: 4:33 - loss: 3.4651 - accuracy: 0.11 - ETA: 4:32 - loss: 3.4624 - accuracy: 0.11 - ETA: 4:31 - loss: 3.4623 - accuracy: 0.11 - ETA: 4:30 - loss: 3.4612 - accuracy: 0.11 - ETA: 4:29 - loss: 3.4587 - accuracy: 0.11 - ETA: 4:28 - loss: 3.4609 - accuracy: 0.11 - ETA: 4:28 - loss: 3.4578 - accuracy: 0.11 - ETA: 4:26 - loss: 3.4554 - accuracy: 0.11 - ETA: 4:25 - loss: 3.4565 - accuracy: 0.11 - ETA: 4:24 - loss: 3.4577 - accuracy: 0.11 - ETA: 4:23 - loss: 3.4571 - accuracy: 0.11 - ETA: 4:22 - loss: 3.4565 - accuracy: 0.11 - ETA: 4:21 - loss: 3.4555 - accuracy: 0.11 - ETA: 4:20 - loss: 3.4558 - accuracy: 0.11 - ETA: 4:20 - loss: 3.4558 - accuracy: 0.11 - ETA: 4:18 - loss: 3.4564 - accuracy: 0.11 - ETA: 4:17 - loss: 3.4556 - accuracy: 0.11 - ETA: 4:16 - loss: 3.4568 - accuracy: 0.11 - ETA: 4:15 - loss: 3.4573 - accuracy: 0.11 - ETA: 4:14 - loss: 3.4561 - accuracy: 0.11 - ETA: 4:13 - loss: 3.4547 - accuracy: 0.11 - ETA: 4:12 - loss: 3.4545 - accuracy: 0.11 - ETA: 4:11 - loss: 3.4552 - accuracy: 0.11 - ETA: 4:10 - loss: 3.4534 - accuracy: 0.11 - ETA: 4:09 - loss: 3.4564 - accuracy: 0.11 - ETA: 4:08 - loss: 3.4565 - accuracy: 0.11 - ETA: 4:07 - loss: 3.4576 - accuracy: 0.11 - ETA: 4:06 - loss: 3.4549 - accuracy: 0.11 - ETA: 4:05 - loss: 3.4563 - accuracy: 0.11 - ETA: 4:04 - loss: 3.4566 - accuracy: 0.11 - ETA: 4:03 - loss: 3.4566 - accuracy: 0.11 - ETA: 4:02 - loss: 3.4581 - accuracy: 0.11 - ETA: 4:01 - loss: 3.4592 - accuracy: 0.11 - ETA: 4:00 - loss: 3.4605 - accuracy: 0.11 - ETA: 3:59 - loss: 3.4596 - accuracy: 0.11 - ETA: 3:58 - loss: 3.4597 - accuracy: 0.11 - ETA: 3:57 - loss: 3.4578 - accuracy: 0.11 - ETA: 3:56 - loss: 3.4578 - accuracy: 0.11 - ETA: 3:55 - loss: 3.4577 - accuracy: 0.11 - ETA: 3:54 - loss: 3.4549 - accuracy: 0.12 - ETA: 3:53 - loss: 3.4557 - accuracy: 0.12 - ETA: 3:52 - loss: 3.4540 - accuracy: 0.12 - ETA: 3:51 - loss: 3.4542 - accuracy: 0.12 - ETA: 3:50 - loss: 3.4528 - accuracy: 0.12 - ETA: 3:49 - loss: 3.4535 - accuracy: 0.12 - ETA: 3:48 - loss: 3.4529 - accuracy: 0.12 - ETA: 3:47 - loss: 3.4527 - accuracy: 0.12 - ETA: 3:46 - loss: 3.4519 - accuracy: 0.12 - ETA: 3:45 - loss: 3.4530 - accuracy: 0.12 - ETA: 3:44 - loss: 3.4509 - accuracy: 0.12 - ETA: 3:43 - loss: 3.4511 - accuracy: 0.12 - ETA: 3:42 - loss: 3.4508 - accuracy: 0.12 - ETA: 3:41 - loss: 3.4512 - accuracy: 0.12 - ETA: 3:40 - loss: 3.4515 - accuracy: 0.12 - ETA: 3:39 - loss: 3.4503 - accuracy: 0.12 - ETA: 3:38 - loss: 3.4503 - accuracy: 0.12 - ETA: 3:37 - loss: 3.4494 - accuracy: 0.12 - ETA: 3:36 - loss: 3.4493 - accuracy: 0.12 - ETA: 3:35 - loss: 3.4493 - accuracy: 0.12 - ETA: 3:34 - loss: 3.4505 - accuracy: 0.12 - ETA: 3:33 - loss: 3.4509 - accuracy: 0.12 - ETA: 3:32 - loss: 3.4506 - accuracy: 0.12 - ETA: 3:31 - loss: 3.4515 - accuracy: 0.12 - ETA: 3:30 - loss: 3.4506 - accuracy: 0.11 - ETA: 3:29 - loss: 3.4498 - accuracy: 0.12 - ETA: 3:28 - loss: 3.4495 - accuracy: 0.12 - ETA: 3:27 - loss: 3.4497 - accuracy: 0.11 - ETA: 3:26 - loss: 3.4510 - accuracy: 0.11 - ETA: 3:25 - loss: 3.4504 - accuracy: 0.12 - ETA: 3:24 - loss: 3.4512 - accuracy: 0.12 - ETA: 3:23 - loss: 3.4525 - accuracy: 0.12 - ETA: 3:22 - loss: 3.4519 - accuracy: 0.12 - ETA: 3:21 - loss: 3.4509 - accuracy: 0.12 - ETA: 3:20 - loss: 3.4534 - accuracy: 0.12 - ETA: 3:19 - loss: 3.4533 - accuracy: 0.12 - ETA: 3:18 - loss: 3.4534 - accuracy: 0.12 - ETA: 3:17 - loss: 3.4530 - accuracy: 0.12 - ETA: 3:17 - loss: 3.4523 - accuracy: 0.12 - ETA: 3:15 - loss: 3.4515 - accuracy: 0.12 - ETA: 3:14 - loss: 3.4508 - accuracy: 0.12 - ETA: 3:13 - loss: 3.4513 - accuracy: 0.12 - ETA: 3:12 - loss: 3.4507 - accuracy: 0.12 - ETA: 3:11 - loss: 3.4508 - accuracy: 0.12 - ETA: 3:10 - loss: 3.4504 - accuracy: 0.12 - ETA: 3:09 - loss: 3.4506 - accuracy: 0.12 - ETA: 3:08 - loss: 3.4502 - accuracy: 0.12 - ETA: 3:07 - loss: 3.4509 - accuracy: 0.12 - ETA: 3:06 - loss: 3.4513 - accuracy: 0.12 - ETA: 3:06 - loss: 3.4501 - accuracy: 0.12 - ETA: 3:05 - loss: 3.4495 - accuracy: 0.12 - ETA: 3:04 - loss: 3.4484 - accuracy: 0.12 - ETA: 3:03 - loss: 3.4485 - accuracy: 0.12 - ETA: 3:02 - loss: 3.4494 - accuracy: 0.12 - ETA: 3:01 - loss: 3.4479 - accuracy: 0.12 - ETA: 3:00 - loss: 3.4481 - accuracy: 0.12 - ETA: 2:59 - loss: 3.4481 - accuracy: 0.12 - ETA: 2:58 - loss: 3.4485 - accuracy: 0.12 - ETA: 2:57 - loss: 3.4479 - accuracy: 0.12 - ETA: 2:56 - loss: 3.4487 - accuracy: 0.12 - ETA: 2:55 - loss: 3.4500 - accuracy: 0.12 - ETA: 2:54 - loss: 3.4495 - accuracy: 0.12 - ETA: 2:53 - loss: 3.4496 - accuracy: 0.12 - ETA: 2:52 - loss: 3.4490 - accuracy: 0.12 - ETA: 2:51 - loss: 3.4489 - accuracy: 0.12 - ETA: 2:51 - loss: 3.4489 - accuracy: 0.12 - ETA: 2:50 - loss: 3.4483 - accuracy: 0.12 - ETA: 2:49 - loss: 3.4484 - accuracy: 0.12 - ETA: 2:48 - loss: 3.4472 - accuracy: 0.12 - ETA: 2:47 - loss: 3.4471 - accuracy: 0.12 - ETA: 2:46 - loss: 3.4476 - accuracy: 0.12 - ETA: 2:45 - loss: 3.4471 - accuracy: 0.12 - ETA: 2:44 - loss: 3.4471 - accuracy: 0.12 - ETA: 2:43 - loss: 3.4473 - accuracy: 0.12 - ETA: 2:42 - loss: 3.4470 - accuracy: 0.12 - ETA: 2:41 - loss: 3.4458 - accuracy: 0.12 - ETA: 2:40 - loss: 3.4452 - accuracy: 0.12 - ETA: 2:39 - loss: 3.4445 - accuracy: 0.12 - ETA: 2:38 - loss: 3.4459 - accuracy: 0.12 - ETA: 2:37 - loss: 3.4459 - accuracy: 0.12 - ETA: 2:36 - loss: 3.4462 - accuracy: 0.12 - ETA: 2:35 - loss: 3.4459 - accuracy: 0.12 - ETA: 2:34 - loss: 3.4458 - accuracy: 0.12 - ETA: 2:33 - loss: 3.4454 - accuracy: 0.12 - ETA: 2:32 - loss: 3.4450 - accuracy: 0.12 - ETA: 2:31 - loss: 3.4456 - accuracy: 0.12 - ETA: 2:30 - loss: 3.4449 - accuracy: 0.12 - ETA: 2:30 - loss: 3.4448 - accuracy: 0.12 - ETA: 2:29 - loss: 3.4439 - accuracy: 0.12 - ETA: 2:28 - loss: 3.4442 - accuracy: 0.12 - ETA: 2:27 - loss: 3.4439 - accuracy: 0.12 - ETA: 2:26 - loss: 3.4438 - accuracy: 0.12 - ETA: 2:25 - loss: 3.4440 - accuracy: 0.12 - ETA: 2:24 - loss: 3.4438 - accuracy: 0.12 - ETA: 2:23 - loss: 3.4438 - accuracy: 0.12 - ETA: 2:22 - loss: 3.4439 - accuracy: 0.12 - ETA: 2:21 - loss: 3.4444 - accuracy: 0.12 - ETA: 2:20 - loss: 3.4439 - accuracy: 0.12 - ETA: 2:19 - loss: 3.4441 - accuracy: 0.12 - ETA: 2:18 - loss: 3.4439 - accuracy: 0.1204"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.4439 - accuracy: 0.12 - ETA: 2:16 - loss: 3.4434 - accuracy: 0.12 - ETA: 2:15 - loss: 3.4431 - accuracy: 0.12 - ETA: 2:14 - loss: 3.4433 - accuracy: 0.12 - ETA: 2:13 - loss: 3.4440 - accuracy: 0.12 - ETA: 2:12 - loss: 3.4442 - accuracy: 0.12 - ETA: 2:11 - loss: 3.4453 - accuracy: 0.12 - ETA: 2:10 - loss: 3.4450 - accuracy: 0.12 - ETA: 2:09 - loss: 3.4439 - accuracy: 0.12 - ETA: 2:08 - loss: 3.4432 - accuracy: 0.12 - ETA: 2:07 - loss: 3.4426 - accuracy: 0.12 - ETA: 2:06 - loss: 3.4427 - accuracy: 0.12 - ETA: 2:05 - loss: 3.4425 - accuracy: 0.12 - ETA: 2:04 - loss: 3.4432 - accuracy: 0.12 - ETA: 2:04 - loss: 3.4429 - accuracy: 0.12 - ETA: 2:03 - loss: 3.4419 - accuracy: 0.12 - ETA: 2:02 - loss: 3.4419 - accuracy: 0.12 - ETA: 2:01 - loss: 3.4411 - accuracy: 0.12 - ETA: 2:00 - loss: 3.4415 - accuracy: 0.12 - ETA: 1:59 - loss: 3.4405 - accuracy: 0.12 - ETA: 1:58 - loss: 3.4400 - accuracy: 0.12 - ETA: 1:57 - loss: 3.4400 - accuracy: 0.12 - ETA: 1:56 - loss: 3.4400 - accuracy: 0.12 - ETA: 1:55 - loss: 3.4400 - accuracy: 0.12 - ETA: 1:54 - loss: 3.4406 - accuracy: 0.12 - ETA: 1:53 - loss: 3.4404 - accuracy: 0.12 - ETA: 1:52 - loss: 3.4404 - accuracy: 0.12 - ETA: 1:51 - loss: 3.4407 - accuracy: 0.12 - ETA: 1:50 - loss: 3.4410 - accuracy: 0.12 - ETA: 1:49 - loss: 3.4407 - accuracy: 0.12 - ETA: 1:48 - loss: 3.4412 - accuracy: 0.12 - ETA: 1:47 - loss: 3.4412 - accuracy: 0.12 - ETA: 1:46 - loss: 3.4400 - accuracy: 0.12 - ETA: 1:46 - loss: 3.4391 - accuracy: 0.12 - ETA: 1:45 - loss: 3.4394 - accuracy: 0.12 - ETA: 1:44 - loss: 3.4396 - accuracy: 0.12 - ETA: 1:43 - loss: 3.4388 - accuracy: 0.12 - ETA: 1:42 - loss: 3.4381 - accuracy: 0.12 - ETA: 1:41 - loss: 3.4377 - accuracy: 0.12 - ETA: 1:40 - loss: 3.4376 - accuracy: 0.12 - ETA: 1:39 - loss: 3.4372 - accuracy: 0.12 - ETA: 1:38 - loss: 3.4371 - accuracy: 0.12 - ETA: 1:37 - loss: 3.4372 - accuracy: 0.12 - ETA: 1:36 - loss: 3.4365 - accuracy: 0.12 - ETA: 1:35 - loss: 3.4365 - accuracy: 0.12 - ETA: 1:34 - loss: 3.4357 - accuracy: 0.12 - ETA: 1:33 - loss: 3.4353 - accuracy: 0.12 - ETA: 1:32 - loss: 3.4350 - accuracy: 0.12 - ETA: 1:31 - loss: 3.4358 - accuracy: 0.12 - ETA: 1:30 - loss: 3.4360 - accuracy: 0.12 - ETA: 1:29 - loss: 3.4352 - accuracy: 0.12 - ETA: 1:28 - loss: 3.4357 - accuracy: 0.12 - ETA: 1:27 - loss: 3.4359 - accuracy: 0.12 - ETA: 1:26 - loss: 3.4361 - accuracy: 0.12 - ETA: 1:26 - loss: 3.4353 - accuracy: 0.12 - ETA: 1:25 - loss: 3.4351 - accuracy: 0.12 - ETA: 1:24 - loss: 3.4343 - accuracy: 0.12 - ETA: 1:23 - loss: 3.4341 - accuracy: 0.12 - ETA: 1:22 - loss: 3.4342 - accuracy: 0.12 - ETA: 1:21 - loss: 3.4341 - accuracy: 0.12 - ETA: 1:20 - loss: 3.4333 - accuracy: 0.12 - ETA: 1:19 - loss: 3.4341 - accuracy: 0.12 - ETA: 1:18 - loss: 3.4332 - accuracy: 0.12 - ETA: 1:17 - loss: 3.4327 - accuracy: 0.12 - ETA: 1:16 - loss: 3.4324 - accuracy: 0.12 - ETA: 1:15 - loss: 3.4320 - accuracy: 0.12 - ETA: 1:14 - loss: 3.4315 - accuracy: 0.12 - ETA: 1:13 - loss: 3.4309 - accuracy: 0.12 - ETA: 1:12 - loss: 3.4308 - accuracy: 0.12 - ETA: 1:11 - loss: 3.4302 - accuracy: 0.12 - ETA: 1:10 - loss: 3.4305 - accuracy: 0.12 - ETA: 1:09 - loss: 3.4297 - accuracy: 0.12 - ETA: 1:08 - loss: 3.4294 - accuracy: 0.12 - ETA: 1:07 - loss: 3.4294 - accuracy: 0.12 - ETA: 1:06 - loss: 3.4300 - accuracy: 0.12 - ETA: 1:05 - loss: 3.4299 - accuracy: 0.12 - ETA: 1:05 - loss: 3.4303 - accuracy: 0.12 - ETA: 1:04 - loss: 3.4301 - accuracy: 0.12 - ETA: 1:03 - loss: 3.4299 - accuracy: 0.12 - ETA: 1:02 - loss: 3.4303 - accuracy: 0.12 - ETA: 1:01 - loss: 3.4299 - accuracy: 0.12 - ETA: 1:00 - loss: 3.4295 - accuracy: 0.12 - ETA: 59s - loss: 3.4295 - accuracy: 0.1244 - ETA: 58s - loss: 3.4300 - accuracy: 0.124 - ETA: 57s - loss: 3.4297 - accuracy: 0.124 - ETA: 56s - loss: 3.4298 - accuracy: 0.124 - ETA: 55s - loss: 3.4302 - accuracy: 0.124 - ETA: 54s - loss: 3.4304 - accuracy: 0.123 - ETA: 53s - loss: 3.4303 - accuracy: 0.124 - ETA: 52s - loss: 3.4306 - accuracy: 0.124 - ETA: 51s - loss: 3.4302 - accuracy: 0.124 - ETA: 50s - loss: 3.4290 - accuracy: 0.124 - ETA: 49s - loss: 3.4292 - accuracy: 0.124 - ETA: 48s - loss: 3.4289 - accuracy: 0.124 - ETA: 47s - loss: 3.4289 - accuracy: 0.124 - ETA: 46s - loss: 3.4291 - accuracy: 0.124 - ETA: 45s - loss: 3.4294 - accuracy: 0.124 - ETA: 44s - loss: 3.4290 - accuracy: 0.124 - ETA: 43s - loss: 3.4288 - accuracy: 0.124 - ETA: 43s - loss: 3.4287 - accuracy: 0.124 - ETA: 42s - loss: 3.4279 - accuracy: 0.124 - ETA: 41s - loss: 3.4282 - accuracy: 0.124 - ETA: 40s - loss: 3.4278 - accuracy: 0.124 - ETA: 39s - loss: 3.4279 - accuracy: 0.124 - ETA: 38s - loss: 3.4278 - accuracy: 0.124 - ETA: 37s - loss: 3.4273 - accuracy: 0.124 - ETA: 36s - loss: 3.4270 - accuracy: 0.124 - ETA: 35s - loss: 3.4261 - accuracy: 0.124 - ETA: 34s - loss: 3.4260 - accuracy: 0.124 - ETA: 33s - loss: 3.4258 - accuracy: 0.124 - ETA: 32s - loss: 3.4255 - accuracy: 0.124 - ETA: 31s - loss: 3.4253 - accuracy: 0.124 - ETA: 30s - loss: 3.4248 - accuracy: 0.124 - ETA: 29s - loss: 3.4250 - accuracy: 0.124 - ETA: 28s - loss: 3.4243 - accuracy: 0.124 - ETA: 27s - loss: 3.4242 - accuracy: 0.124 - ETA: 26s - loss: 3.4255 - accuracy: 0.124 - ETA: 25s - loss: 3.4253 - accuracy: 0.124 - ETA: 24s - loss: 3.4257 - accuracy: 0.124 - ETA: 23s - loss: 3.4257 - accuracy: 0.124 - ETA: 22s - loss: 3.4257 - accuracy: 0.124 - ETA: 22s - loss: 3.4254 - accuracy: 0.124 - ETA: 21s - loss: 3.4253 - accuracy: 0.124 - ETA: 20s - loss: 3.4249 - accuracy: 0.124 - ETA: 19s - loss: 3.4245 - accuracy: 0.125 - ETA: 18s - loss: 3.4241 - accuracy: 0.125 - ETA: 17s - loss: 3.4241 - accuracy: 0.125 - ETA: 16s - loss: 3.4238 - accuracy: 0.125 - ETA: 15s - loss: 3.4237 - accuracy: 0.125 - ETA: 14s - loss: 3.4232 - accuracy: 0.125 - ETA: 13s - loss: 3.4233 - accuracy: 0.124 - ETA: 12s - loss: 3.4236 - accuracy: 0.124 - ETA: 11s - loss: 3.4231 - accuracy: 0.125 - ETA: 10s - loss: 3.4234 - accuracy: 0.125 - ETA: 9s - loss: 3.4229 - accuracy: 0.125 - ETA: 8s - loss: 3.4228 - accuracy: 0.12 - ETA: 7s - loss: 3.4223 - accuracy: 0.12 - ETA: 6s - loss: 3.4222 - accuracy: 0.12 - ETA: 5s - loss: 3.4219 - accuracy: 0.12 - ETA: 4s - loss: 3.4218 - accuracy: 0.12 - ETA: 3s - loss: 3.4212 - accuracy: 0.12 - ETA: 2s - loss: 3.4209 - accuracy: 0.12 - ETA: 1s - loss: 3.4208 - accuracy: 0.12 - ETA: 1s - loss: 3.4206 - accuracy: 0.12 - ETA: 0s - loss: 3.4204 - accuracy: 0.12 - 340s 8ms/step - loss: 3.4205 - accuracy: 0.1255 - val_loss: 4.0298 - val_accuracy: 0.0143\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:17 - loss: 3.4025 - accuracy: 0.14 - ETA: 5:20 - loss: 3.3865 - accuracy: 0.11 - ETA: 5:25 - loss: 3.3968 - accuracy: 0.11 - ETA: 5:16 - loss: 3.4128 - accuracy: 0.11 - ETA: 5:15 - loss: 3.3684 - accuracy: 0.12 - ETA: 5:11 - loss: 3.3958 - accuracy: 0.11 - ETA: 5:13 - loss: 3.3886 - accuracy: 0.12 - ETA: 5:09 - loss: 3.3971 - accuracy: 0.12 - ETA: 5:06 - loss: 3.3968 - accuracy: 0.12 - ETA: 5:03 - loss: 3.4097 - accuracy: 0.12 - ETA: 5:01 - loss: 3.4082 - accuracy: 0.12 - ETA: 5:01 - loss: 3.4110 - accuracy: 0.12 - ETA: 5:00 - loss: 3.3985 - accuracy: 0.12 - ETA: 4:58 - loss: 3.3955 - accuracy: 0.12 - ETA: 4:56 - loss: 3.3974 - accuracy: 0.12 - ETA: 4:55 - loss: 3.3988 - accuracy: 0.12 - ETA: 4:54 - loss: 3.3993 - accuracy: 0.12 - ETA: 4:55 - loss: 3.4002 - accuracy: 0.12 - ETA: 4:55 - loss: 3.3980 - accuracy: 0.12 - ETA: 4:54 - loss: 3.3993 - accuracy: 0.12 - ETA: 4:53 - loss: 3.3935 - accuracy: 0.12 - ETA: 4:53 - loss: 3.3860 - accuracy: 0.12 - ETA: 4:53 - loss: 3.3888 - accuracy: 0.12 - ETA: 4:51 - loss: 3.3856 - accuracy: 0.13 - ETA: 4:50 - loss: 3.3868 - accuracy: 0.12 - ETA: 4:48 - loss: 3.3840 - accuracy: 0.12 - ETA: 4:47 - loss: 3.3787 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3724 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3757 - accuracy: 0.13 - ETA: 4:45 - loss: 3.3705 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3684 - accuracy: 0.13 - ETA: 4:43 - loss: 3.3655 - accuracy: 0.13 - ETA: 4:42 - loss: 3.3656 - accuracy: 0.13 - ETA: 4:41 - loss: 3.3668 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3677 - accuracy: 0.13 - ETA: 4:38 - loss: 3.3692 - accuracy: 0.13 - ETA: 4:37 - loss: 3.3714 - accuracy: 0.13 - ETA: 4:36 - loss: 3.3726 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3751 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3807 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3816 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3856 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3841 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3852 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3859 - accuracy: 0.12 - ETA: 4:29 - loss: 3.3860 - accuracy: 0.12 - ETA: 4:28 - loss: 3.3841 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3843 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3866 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3856 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3899 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3871 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3839 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3832 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3839 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3838 - accuracy: 0.13 - ETA: 4:19 - loss: 3.3829 - accuracy: 0.13 - ETA: 4:18 - loss: 3.3853 - accuracy: 0.13 - ETA: 4:17 - loss: 3.3846 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3824 - accuracy: 0.13 - ETA: 4:15 - loss: 3.3822 - accuracy: 0.13 - ETA: 4:14 - loss: 3.3832 - accuracy: 0.13 - ETA: 4:13 - loss: 3.3844 - accuracy: 0.13 - ETA: 4:12 - loss: 3.3827 - accuracy: 0.13 - ETA: 4:11 - loss: 3.3849 - accuracy: 0.13 - ETA: 4:10 - loss: 3.3862 - accuracy: 0.13 - ETA: 4:09 - loss: 3.3903 - accuracy: 0.13 - ETA: 4:09 - loss: 3.3979 - accuracy: 0.13 - ETA: 4:08 - loss: 3.4018 - accuracy: 0.13 - ETA: 4:07 - loss: 3.4055 - accuracy: 0.13 - ETA: 4:06 - loss: 3.4064 - accuracy: 0.13 - ETA: 4:05 - loss: 3.4092 - accuracy: 0.13 - ETA: 4:05 - loss: 3.4120 - accuracy: 0.13 - ETA: 4:04 - loss: 3.4111 - accuracy: 0.13 - ETA: 4:03 - loss: 3.4115 - accuracy: 0.13 - ETA: 4:02 - loss: 3.4086 - accuracy: 0.13 - ETA: 4:00 - loss: 3.4107 - accuracy: 0.13 - ETA: 4:00 - loss: 3.4122 - accuracy: 0.13 - ETA: 3:58 - loss: 3.4120 - accuracy: 0.13 - ETA: 3:58 - loss: 3.4117 - accuracy: 0.13 - ETA: 3:57 - loss: 3.4109 - accuracy: 0.13 - ETA: 3:56 - loss: 3.4119 - accuracy: 0.13 - ETA: 3:55 - loss: 3.4129 - accuracy: 0.13 - ETA: 3:54 - loss: 3.4129 - accuracy: 0.13 - ETA: 3:53 - loss: 3.4126 - accuracy: 0.13 - ETA: 3:53 - loss: 3.4120 - accuracy: 0.13 - ETA: 3:52 - loss: 3.4123 - accuracy: 0.13 - ETA: 3:51 - loss: 3.4143 - accuracy: 0.13 - ETA: 3:50 - loss: 3.4129 - accuracy: 0.13 - ETA: 3:49 - loss: 3.4144 - accuracy: 0.13 - ETA: 3:48 - loss: 3.4154 - accuracy: 0.13 - ETA: 3:47 - loss: 3.4144 - accuracy: 0.13 - ETA: 3:46 - loss: 3.4148 - accuracy: 0.13 - ETA: 3:45 - loss: 3.4151 - accuracy: 0.13 - ETA: 3:44 - loss: 3.4172 - accuracy: 0.13 - ETA: 3:43 - loss: 3.4170 - accuracy: 0.13 - ETA: 3:42 - loss: 3.4163 - accuracy: 0.13 - ETA: 3:41 - loss: 3.4147 - accuracy: 0.13 - ETA: 3:40 - loss: 3.4145 - accuracy: 0.13 - ETA: 3:39 - loss: 3.4147 - accuracy: 0.13 - ETA: 3:38 - loss: 3.4144 - accuracy: 0.13 - ETA: 3:37 - loss: 3.4142 - accuracy: 0.13 - ETA: 3:36 - loss: 3.4155 - accuracy: 0.13 - ETA: 3:35 - loss: 3.4159 - accuracy: 0.13 - ETA: 3:34 - loss: 3.4170 - accuracy: 0.13 - ETA: 3:33 - loss: 3.4160 - accuracy: 0.13 - ETA: 3:33 - loss: 3.4160 - accuracy: 0.13 - ETA: 3:32 - loss: 3.4147 - accuracy: 0.13 - ETA: 3:31 - loss: 3.4147 - accuracy: 0.13 - ETA: 3:30 - loss: 3.4143 - accuracy: 0.13 - ETA: 3:29 - loss: 3.4147 - accuracy: 0.13 - ETA: 3:28 - loss: 3.4143 - accuracy: 0.13 - ETA: 3:27 - loss: 3.4142 - accuracy: 0.13 - ETA: 3:26 - loss: 3.4137 - accuracy: 0.13 - ETA: 3:25 - loss: 3.4149 - accuracy: 0.13 - ETA: 3:24 - loss: 3.4141 - accuracy: 0.13 - ETA: 3:23 - loss: 3.4154 - accuracy: 0.13 - ETA: 3:22 - loss: 3.4157 - accuracy: 0.13 - ETA: 3:21 - loss: 3.4156 - accuracy: 0.13 - ETA: 3:20 - loss: 3.4154 - accuracy: 0.13 - ETA: 3:19 - loss: 3.4155 - accuracy: 0.13 - ETA: 3:18 - loss: 3.4147 - accuracy: 0.13 - ETA: 3:17 - loss: 3.4139 - accuracy: 0.13 - ETA: 3:16 - loss: 3.4142 - accuracy: 0.13 - ETA: 3:15 - loss: 3.4158 - accuracy: 0.13 - ETA: 3:14 - loss: 3.4153 - accuracy: 0.13 - ETA: 3:13 - loss: 3.4133 - accuracy: 0.13 - ETA: 3:12 - loss: 3.4120 - accuracy: 0.13 - ETA: 3:11 - loss: 3.4122 - accuracy: 0.13 - ETA: 3:10 - loss: 3.4122 - accuracy: 0.13 - ETA: 3:09 - loss: 3.4125 - accuracy: 0.13 - ETA: 3:09 - loss: 3.4132 - accuracy: 0.13 - ETA: 3:08 - loss: 3.4126 - accuracy: 0.13 - ETA: 3:07 - loss: 3.4130 - accuracy: 0.13 - ETA: 3:06 - loss: 3.4143 - accuracy: 0.12 - ETA: 3:05 - loss: 3.4132 - accuracy: 0.12 - ETA: 3:04 - loss: 3.4140 - accuracy: 0.12 - ETA: 3:03 - loss: 3.4140 - accuracy: 0.12 - ETA: 3:02 - loss: 3.4140 - accuracy: 0.12 - ETA: 3:01 - loss: 3.4139 - accuracy: 0.12 - ETA: 3:00 - loss: 3.4153 - accuracy: 0.12 - ETA: 2:59 - loss: 3.4147 - accuracy: 0.12 - ETA: 2:58 - loss: 3.4151 - accuracy: 0.12 - ETA: 2:57 - loss: 3.4151 - accuracy: 0.12 - ETA: 2:56 - loss: 3.4138 - accuracy: 0.13 - ETA: 2:55 - loss: 3.4129 - accuracy: 0.13 - ETA: 2:54 - loss: 3.4137 - accuracy: 0.13 - ETA: 2:53 - loss: 3.4128 - accuracy: 0.13 - ETA: 2:52 - loss: 3.4122 - accuracy: 0.13 - ETA: 2:51 - loss: 3.4108 - accuracy: 0.13 - ETA: 2:50 - loss: 3.4097 - accuracy: 0.13 - ETA: 2:49 - loss: 3.4095 - accuracy: 0.13 - ETA: 2:48 - loss: 3.4087 - accuracy: 0.13 - ETA: 2:47 - loss: 3.4070 - accuracy: 0.13 - ETA: 2:46 - loss: 3.4068 - accuracy: 0.13 - ETA: 2:45 - loss: 3.4071 - accuracy: 0.13 - ETA: 2:44 - loss: 3.4068 - accuracy: 0.13 - ETA: 2:43 - loss: 3.4073 - accuracy: 0.13 - ETA: 2:43 - loss: 3.4069 - accuracy: 0.13 - ETA: 2:42 - loss: 3.4072 - accuracy: 0.13 - ETA: 2:41 - loss: 3.4069 - accuracy: 0.13 - ETA: 2:40 - loss: 3.4068 - accuracy: 0.13 - ETA: 2:39 - loss: 3.4067 - accuracy: 0.13 - ETA: 2:38 - loss: 3.4068 - accuracy: 0.13 - ETA: 2:37 - loss: 3.4073 - accuracy: 0.13 - ETA: 2:36 - loss: 3.4074 - accuracy: 0.13 - ETA: 2:35 - loss: 3.4063 - accuracy: 0.13 - ETA: 2:34 - loss: 3.4041 - accuracy: 0.13 - ETA: 2:33 - loss: 3.4043 - accuracy: 0.13 - ETA: 2:32 - loss: 3.4048 - accuracy: 0.13 - ETA: 2:31 - loss: 3.4047 - accuracy: 0.13 - ETA: 2:30 - loss: 3.4034 - accuracy: 0.13 - ETA: 2:29 - loss: 3.4031 - accuracy: 0.13 - ETA: 2:28 - loss: 3.4024 - accuracy: 0.13 - ETA: 2:27 - loss: 3.4031 - accuracy: 0.13 - ETA: 2:27 - loss: 3.4028 - accuracy: 0.13 - ETA: 2:26 - loss: 3.4022 - accuracy: 0.13 - ETA: 2:25 - loss: 3.4019 - accuracy: 0.13 - ETA: 2:24 - loss: 3.4015 - accuracy: 0.13 - ETA: 2:23 - loss: 3.4014 - accuracy: 0.13 - ETA: 2:22 - loss: 3.4008 - accuracy: 0.13 - ETA: 2:21 - loss: 3.4000 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3996 - accuracy: 0.13 - ETA: 2:19 - loss: 3.3998 - accuracy: 0.13 - ETA: 2:18 - loss: 3.3995 - accuracy: 0.13 - ETA: 2:17 - loss: 3.3997 - accuracy: 0.1321"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:16 - loss: 3.3997 - accuracy: 0.13 - ETA: 2:15 - loss: 3.3991 - accuracy: 0.13 - ETA: 2:14 - loss: 3.3980 - accuracy: 0.13 - ETA: 2:13 - loss: 3.3984 - accuracy: 0.13 - ETA: 2:12 - loss: 3.3982 - accuracy: 0.13 - ETA: 2:11 - loss: 3.3985 - accuracy: 0.13 - ETA: 2:10 - loss: 3.3984 - accuracy: 0.13 - ETA: 2:09 - loss: 3.3990 - accuracy: 0.13 - ETA: 2:08 - loss: 3.3987 - accuracy: 0.13 - ETA: 2:07 - loss: 3.3982 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3982 - accuracy: 0.13 - ETA: 2:06 - loss: 3.3974 - accuracy: 0.13 - ETA: 2:05 - loss: 3.3976 - accuracy: 0.13 - ETA: 2:04 - loss: 3.3976 - accuracy: 0.13 - ETA: 2:03 - loss: 3.3972 - accuracy: 0.13 - ETA: 2:02 - loss: 3.3963 - accuracy: 0.13 - ETA: 2:01 - loss: 3.3964 - accuracy: 0.13 - ETA: 2:00 - loss: 3.3957 - accuracy: 0.13 - ETA: 1:59 - loss: 3.3948 - accuracy: 0.13 - ETA: 1:58 - loss: 3.3951 - accuracy: 0.13 - ETA: 1:57 - loss: 3.3957 - accuracy: 0.13 - ETA: 1:56 - loss: 3.3956 - accuracy: 0.13 - ETA: 1:55 - loss: 3.3953 - accuracy: 0.13 - ETA: 1:54 - loss: 3.3946 - accuracy: 0.13 - ETA: 1:53 - loss: 3.3947 - accuracy: 0.13 - ETA: 1:52 - loss: 3.3940 - accuracy: 0.13 - ETA: 1:51 - loss: 3.3929 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3930 - accuracy: 0.13 - ETA: 1:50 - loss: 3.3926 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3921 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3924 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3927 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3930 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3936 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3940 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3935 - accuracy: 0.13 - ETA: 1:42 - loss: 3.3938 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3942 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3937 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3943 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3948 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3944 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3946 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3948 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3945 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3948 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3946 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3951 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3954 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3954 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3948 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3953 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3956 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3957 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3963 - accuracy: 0.13 - ETA: 1:24 - loss: 3.4030 - accuracy: 0.13 - ETA: 1:23 - loss: 3.4025 - accuracy: 0.13 - ETA: 1:22 - loss: 3.4019 - accuracy: 0.13 - ETA: 1:21 - loss: 3.4022 - accuracy: 0.13 - ETA: 1:20 - loss: 3.4015 - accuracy: 0.13 - ETA: 1:19 - loss: 3.4015 - accuracy: 0.13 - ETA: 1:18 - loss: 3.4012 - accuracy: 0.13 - ETA: 1:17 - loss: 3.4012 - accuracy: 0.13 - ETA: 1:16 - loss: 3.4012 - accuracy: 0.13 - ETA: 1:15 - loss: 3.4008 - accuracy: 0.13 - ETA: 1:15 - loss: 3.4008 - accuracy: 0.13 - ETA: 1:14 - loss: 3.4010 - accuracy: 0.13 - ETA: 1:13 - loss: 3.4011 - accuracy: 0.13 - ETA: 1:12 - loss: 3.4014 - accuracy: 0.13 - ETA: 1:11 - loss: 3.4009 - accuracy: 0.13 - ETA: 1:10 - loss: 3.4007 - accuracy: 0.13 - ETA: 1:09 - loss: 3.4001 - accuracy: 0.13 - ETA: 1:08 - loss: 3.4001 - accuracy: 0.13 - ETA: 1:07 - loss: 3.4001 - accuracy: 0.13 - ETA: 1:06 - loss: 3.4000 - accuracy: 0.13 - ETA: 1:05 - loss: 3.4001 - accuracy: 0.13 - ETA: 1:04 - loss: 3.4002 - accuracy: 0.13 - ETA: 1:03 - loss: 3.4001 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3993 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3995 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3992 - accuracy: 0.13 - ETA: 59s - loss: 3.3997 - accuracy: 0.1312 - ETA: 58s - loss: 3.3996 - accuracy: 0.131 - ETA: 57s - loss: 3.3993 - accuracy: 0.131 - ETA: 56s - loss: 3.3986 - accuracy: 0.131 - ETA: 55s - loss: 3.3984 - accuracy: 0.131 - ETA: 55s - loss: 3.3988 - accuracy: 0.131 - ETA: 54s - loss: 3.3982 - accuracy: 0.131 - ETA: 53s - loss: 3.3982 - accuracy: 0.131 - ETA: 52s - loss: 3.3984 - accuracy: 0.131 - ETA: 51s - loss: 3.3982 - accuracy: 0.131 - ETA: 50s - loss: 3.3984 - accuracy: 0.131 - ETA: 49s - loss: 3.3996 - accuracy: 0.131 - ETA: 48s - loss: 3.4003 - accuracy: 0.130 - ETA: 47s - loss: 3.4007 - accuracy: 0.130 - ETA: 46s - loss: 3.4012 - accuracy: 0.130 - ETA: 45s - loss: 3.4012 - accuracy: 0.130 - ETA: 44s - loss: 3.4011 - accuracy: 0.130 - ETA: 43s - loss: 3.4015 - accuracy: 0.130 - ETA: 42s - loss: 3.4011 - accuracy: 0.130 - ETA: 41s - loss: 3.4008 - accuracy: 0.130 - ETA: 40s - loss: 3.4003 - accuracy: 0.130 - ETA: 39s - loss: 3.3999 - accuracy: 0.130 - ETA: 38s - loss: 3.3991 - accuracy: 0.130 - ETA: 38s - loss: 3.3990 - accuracy: 0.130 - ETA: 37s - loss: 3.3991 - accuracy: 0.130 - ETA: 36s - loss: 3.3988 - accuracy: 0.130 - ETA: 35s - loss: 3.3986 - accuracy: 0.130 - ETA: 34s - loss: 3.3988 - accuracy: 0.130 - ETA: 33s - loss: 3.3981 - accuracy: 0.130 - ETA: 32s - loss: 3.3980 - accuracy: 0.130 - ETA: 31s - loss: 3.3982 - accuracy: 0.130 - ETA: 30s - loss: 3.3981 - accuracy: 0.131 - ETA: 29s - loss: 3.3983 - accuracy: 0.130 - ETA: 28s - loss: 3.3979 - accuracy: 0.131 - ETA: 27s - loss: 3.3972 - accuracy: 0.131 - ETA: 26s - loss: 3.3971 - accuracy: 0.131 - ETA: 25s - loss: 3.3971 - accuracy: 0.131 - ETA: 24s - loss: 3.3978 - accuracy: 0.130 - ETA: 23s - loss: 3.3974 - accuracy: 0.131 - ETA: 22s - loss: 3.3983 - accuracy: 0.130 - ETA: 21s - loss: 3.3983 - accuracy: 0.130 - ETA: 20s - loss: 3.3985 - accuracy: 0.130 - ETA: 20s - loss: 3.3988 - accuracy: 0.130 - ETA: 19s - loss: 3.3987 - accuracy: 0.130 - ETA: 18s - loss: 3.3987 - accuracy: 0.130 - ETA: 17s - loss: 3.3989 - accuracy: 0.130 - ETA: 16s - loss: 3.3985 - accuracy: 0.130 - ETA: 15s - loss: 3.3982 - accuracy: 0.130 - ETA: 14s - loss: 3.3981 - accuracy: 0.130 - ETA: 13s - loss: 3.3984 - accuracy: 0.130 - ETA: 12s - loss: 3.3978 - accuracy: 0.130 - ETA: 11s - loss: 3.3972 - accuracy: 0.130 - ETA: 10s - loss: 3.3974 - accuracy: 0.130 - ETA: 9s - loss: 3.3975 - accuracy: 0.130 - ETA: 8s - loss: 3.3979 - accuracy: 0.13 - ETA: 7s - loss: 3.3979 - accuracy: 0.13 - ETA: 6s - loss: 3.3979 - accuracy: 0.13 - ETA: 5s - loss: 3.3978 - accuracy: 0.13 - ETA: 4s - loss: 3.3976 - accuracy: 0.13 - ETA: 3s - loss: 3.3969 - accuracy: 0.13 - ETA: 2s - loss: 3.3966 - accuracy: 0.13 - ETA: 1s - loss: 3.3968 - accuracy: 0.13 - ETA: 1s - loss: 3.3969 - accuracy: 0.13 - ETA: 0s - loss: 3.3973 - accuracy: 0.13 - 338s 8ms/step - loss: 3.3973 - accuracy: 0.1303 - val_loss: 3.9781 - val_accuracy: 0.0133\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:21 - loss: 3.3969 - accuracy: 0.12 - ETA: 5:08 - loss: 3.4056 - accuracy: 0.10 - ETA: 5:11 - loss: 3.3871 - accuracy: 0.11 - ETA: 5:13 - loss: 3.3666 - accuracy: 0.11 - ETA: 5:10 - loss: 3.3492 - accuracy: 0.11 - ETA: 5:06 - loss: 3.3374 - accuracy: 0.12 - ETA: 5:04 - loss: 3.3604 - accuracy: 0.11 - ETA: 5:01 - loss: 3.3678 - accuracy: 0.12 - ETA: 5:02 - loss: 3.3591 - accuracy: 0.12 - ETA: 5:01 - loss: 3.3686 - accuracy: 0.12 - ETA: 5:00 - loss: 3.3784 - accuracy: 0.11 - ETA: 5:01 - loss: 3.3761 - accuracy: 0.11 - ETA: 5:00 - loss: 3.3598 - accuracy: 0.12 - ETA: 5:01 - loss: 3.3687 - accuracy: 0.12 - ETA: 5:01 - loss: 3.3733 - accuracy: 0.12 - ETA: 5:00 - loss: 3.3789 - accuracy: 0.12 - ETA: 4:58 - loss: 3.3825 - accuracy: 0.12 - ETA: 4:58 - loss: 3.3854 - accuracy: 0.12 - ETA: 4:57 - loss: 3.3828 - accuracy: 0.12 - ETA: 4:57 - loss: 3.3915 - accuracy: 0.12 - ETA: 4:55 - loss: 3.3924 - accuracy: 0.12 - ETA: 4:54 - loss: 3.3972 - accuracy: 0.12 - ETA: 4:52 - loss: 3.4011 - accuracy: 0.12 - ETA: 4:51 - loss: 3.3957 - accuracy: 0.12 - ETA: 4:50 - loss: 3.3977 - accuracy: 0.12 - ETA: 4:48 - loss: 3.4006 - accuracy: 0.12 - ETA: 4:48 - loss: 3.3999 - accuracy: 0.12 - ETA: 4:47 - loss: 3.3949 - accuracy: 0.12 - ETA: 4:46 - loss: 3.3922 - accuracy: 0.12 - ETA: 4:45 - loss: 3.3920 - accuracy: 0.12 - ETA: 4:45 - loss: 3.3878 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3930 - accuracy: 0.12 - ETA: 4:43 - loss: 3.3877 - accuracy: 0.13 - ETA: 4:41 - loss: 3.3918 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3889 - accuracy: 0.13 - ETA: 4:39 - loss: 3.3913 - accuracy: 0.12 - ETA: 4:38 - loss: 3.3927 - accuracy: 0.12 - ETA: 4:37 - loss: 3.3890 - accuracy: 0.12 - ETA: 4:36 - loss: 3.3866 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3861 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3842 - accuracy: 0.13 - ETA: 4:33 - loss: 3.3827 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3833 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3825 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3812 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3809 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3795 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3822 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3800 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3838 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3844 - accuracy: 0.12 - ETA: 4:23 - loss: 3.3840 - accuracy: 0.12 - ETA: 4:21 - loss: 3.3829 - accuracy: 0.12 - ETA: 4:18 - loss: 3.3840 - accuracy: 0.12 - ETA: 4:16 - loss: 3.3854 - accuracy: 0.12 - ETA: 4:14 - loss: 3.3845 - accuracy: 0.12 - ETA: 4:12 - loss: 3.3868 - accuracy: 0.12 - ETA: 4:09 - loss: 3.3849 - accuracy: 0.12 - ETA: 4:07 - loss: 3.3838 - accuracy: 0.12 - ETA: 4:06 - loss: 3.3833 - accuracy: 0.12 - ETA: 4:05 - loss: 3.3832 - accuracy: 0.12 - ETA: 4:04 - loss: 3.3841 - accuracy: 0.12 - ETA: 4:04 - loss: 3.3825 - accuracy: 0.12 - ETA: 4:03 - loss: 3.3807 - accuracy: 0.12 - ETA: 4:02 - loss: 3.3798 - accuracy: 0.12 - ETA: 4:02 - loss: 3.3820 - accuracy: 0.12 - ETA: 4:01 - loss: 3.3863 - accuracy: 0.12 - ETA: 4:00 - loss: 3.3834 - accuracy: 0.12 - ETA: 3:59 - loss: 3.3837 - accuracy: 0.12 - ETA: 3:59 - loss: 3.3827 - accuracy: 0.12 - ETA: 3:58 - loss: 3.3862 - accuracy: 0.12 - ETA: 3:57 - loss: 3.3887 - accuracy: 0.12 - ETA: 3:57 - loss: 3.3915 - accuracy: 0.12 - ETA: 3:56 - loss: 3.3936 - accuracy: 0.12 - ETA: 3:55 - loss: 3.3931 - accuracy: 0.12 - ETA: 3:54 - loss: 3.3940 - accuracy: 0.12 - ETA: 3:53 - loss: 3.3953 - accuracy: 0.12 - ETA: 3:53 - loss: 3.3950 - accuracy: 0.12 - ETA: 3:52 - loss: 3.3938 - accuracy: 0.12 - ETA: 3:51 - loss: 3.3913 - accuracy: 0.12 - ETA: 3:50 - loss: 3.3918 - accuracy: 0.12 - ETA: 3:49 - loss: 3.3910 - accuracy: 0.12 - ETA: 3:48 - loss: 3.3925 - accuracy: 0.12 - ETA: 3:48 - loss: 3.3909 - accuracy: 0.12 - ETA: 3:47 - loss: 3.3910 - accuracy: 0.12 - ETA: 3:46 - loss: 3.3915 - accuracy: 0.12 - ETA: 3:45 - loss: 3.3923 - accuracy: 0.12 - ETA: 3:45 - loss: 3.3916 - accuracy: 0.12 - ETA: 3:44 - loss: 3.3926 - accuracy: 0.12 - ETA: 3:43 - loss: 3.3942 - accuracy: 0.12 - ETA: 3:42 - loss: 3.3961 - accuracy: 0.12 - ETA: 3:41 - loss: 3.3965 - accuracy: 0.12 - ETA: 3:40 - loss: 3.3979 - accuracy: 0.12 - ETA: 3:39 - loss: 3.3981 - accuracy: 0.12 - ETA: 3:38 - loss: 3.3985 - accuracy: 0.12 - ETA: 3:37 - loss: 3.3995 - accuracy: 0.12 - ETA: 3:37 - loss: 3.3988 - accuracy: 0.12 - ETA: 3:36 - loss: 3.4003 - accuracy: 0.12 - ETA: 3:35 - loss: 3.4003 - accuracy: 0.12 - ETA: 3:34 - loss: 3.3989 - accuracy: 0.12 - ETA: 3:33 - loss: 3.3997 - accuracy: 0.12 - ETA: 3:33 - loss: 3.4000 - accuracy: 0.12 - ETA: 3:32 - loss: 3.4009 - accuracy: 0.12 - ETA: 3:31 - loss: 3.4026 - accuracy: 0.12 - ETA: 3:30 - loss: 3.4027 - accuracy: 0.12 - ETA: 3:29 - loss: 3.4037 - accuracy: 0.12 - ETA: 3:28 - loss: 3.4017 - accuracy: 0.12 - ETA: 3:27 - loss: 3.4011 - accuracy: 0.12 - ETA: 3:26 - loss: 3.4004 - accuracy: 0.12 - ETA: 3:25 - loss: 3.4023 - accuracy: 0.12 - ETA: 3:24 - loss: 3.4036 - accuracy: 0.12 - ETA: 3:23 - loss: 3.4020 - accuracy: 0.12 - ETA: 3:23 - loss: 3.4025 - accuracy: 0.12 - ETA: 3:21 - loss: 3.4018 - accuracy: 0.12 - ETA: 3:21 - loss: 3.4008 - accuracy: 0.12 - ETA: 3:20 - loss: 3.4010 - accuracy: 0.12 - ETA: 3:19 - loss: 3.4024 - accuracy: 0.12 - ETA: 3:18 - loss: 3.4019 - accuracy: 0.12 - ETA: 3:17 - loss: 3.4008 - accuracy: 0.12 - ETA: 3:16 - loss: 3.4005 - accuracy: 0.12 - ETA: 3:15 - loss: 3.3989 - accuracy: 0.12 - ETA: 3:14 - loss: 3.3986 - accuracy: 0.12 - ETA: 3:13 - loss: 3.3971 - accuracy: 0.12 - ETA: 3:11 - loss: 3.3970 - accuracy: 0.12 - ETA: 3:10 - loss: 3.3963 - accuracy: 0.12 - ETA: 3:09 - loss: 3.3964 - accuracy: 0.12 - ETA: 3:07 - loss: 3.3969 - accuracy: 0.12 - ETA: 3:06 - loss: 3.3973 - accuracy: 0.12 - ETA: 3:05 - loss: 3.3968 - accuracy: 0.12 - ETA: 3:04 - loss: 3.3962 - accuracy: 0.12 - ETA: 3:03 - loss: 3.3956 - accuracy: 0.12 - ETA: 3:02 - loss: 3.3961 - accuracy: 0.12 - ETA: 3:01 - loss: 3.3946 - accuracy: 0.12 - ETA: 3:00 - loss: 3.3957 - accuracy: 0.12 - ETA: 2:59 - loss: 3.3940 - accuracy: 0.12 - ETA: 2:59 - loss: 3.3934 - accuracy: 0.12 - ETA: 2:58 - loss: 3.3928 - accuracy: 0.12 - ETA: 2:57 - loss: 3.3928 - accuracy: 0.12 - ETA: 2:56 - loss: 3.3928 - accuracy: 0.12 - ETA: 2:55 - loss: 3.3935 - accuracy: 0.12 - ETA: 2:54 - loss: 3.3932 - accuracy: 0.12 - ETA: 2:53 - loss: 3.3928 - accuracy: 0.12 - ETA: 2:52 - loss: 3.3926 - accuracy: 0.12 - ETA: 2:52 - loss: 3.3919 - accuracy: 0.12 - ETA: 2:51 - loss: 3.3915 - accuracy: 0.12 - ETA: 2:50 - loss: 3.3917 - accuracy: 0.12 - ETA: 2:49 - loss: 3.3917 - accuracy: 0.12 - ETA: 2:48 - loss: 3.3919 - accuracy: 0.12 - ETA: 2:47 - loss: 3.3915 - accuracy: 0.12 - ETA: 2:46 - loss: 3.3920 - accuracy: 0.12 - ETA: 2:45 - loss: 3.3918 - accuracy: 0.12 - ETA: 2:44 - loss: 3.3923 - accuracy: 0.12 - ETA: 2:43 - loss: 3.3919 - accuracy: 0.12 - ETA: 2:43 - loss: 3.3916 - accuracy: 0.12 - ETA: 2:42 - loss: 3.3918 - accuracy: 0.12 - ETA: 2:41 - loss: 3.3923 - accuracy: 0.12 - ETA: 2:40 - loss: 3.3930 - accuracy: 0.12 - ETA: 2:39 - loss: 3.3936 - accuracy: 0.12 - ETA: 2:38 - loss: 3.3926 - accuracy: 0.12 - ETA: 2:37 - loss: 3.3928 - accuracy: 0.12 - ETA: 2:36 - loss: 3.3914 - accuracy: 0.12 - ETA: 2:36 - loss: 3.3909 - accuracy: 0.12 - ETA: 2:35 - loss: 3.3914 - accuracy: 0.12 - ETA: 2:34 - loss: 3.3912 - accuracy: 0.12 - ETA: 2:33 - loss: 3.3922 - accuracy: 0.12 - ETA: 2:32 - loss: 3.3922 - accuracy: 0.12 - ETA: 2:31 - loss: 3.3920 - accuracy: 0.12 - ETA: 2:30 - loss: 3.3918 - accuracy: 0.12 - ETA: 2:29 - loss: 3.3919 - accuracy: 0.12 - ETA: 2:28 - loss: 3.3910 - accuracy: 0.12 - ETA: 2:27 - loss: 3.3911 - accuracy: 0.12 - ETA: 2:26 - loss: 3.3904 - accuracy: 0.12 - ETA: 2:26 - loss: 3.3910 - accuracy: 0.12 - ETA: 2:25 - loss: 3.3923 - accuracy: 0.12 - ETA: 2:24 - loss: 3.3924 - accuracy: 0.12 - ETA: 2:23 - loss: 3.3920 - accuracy: 0.12 - ETA: 2:22 - loss: 3.3919 - accuracy: 0.12 - ETA: 2:21 - loss: 3.3913 - accuracy: 0.12 - ETA: 2:20 - loss: 3.3912 - accuracy: 0.12 - ETA: 2:19 - loss: 3.3912 - accuracy: 0.12 - ETA: 2:18 - loss: 3.3908 - accuracy: 0.12 - ETA: 2:17 - loss: 3.3906 - accuracy: 0.12 - ETA: 2:16 - loss: 3.3901 - accuracy: 0.12 - ETA: 2:16 - loss: 3.3899 - accuracy: 0.12 - ETA: 2:15 - loss: 3.3905 - accuracy: 0.12 - ETA: 2:14 - loss: 3.3902 - accuracy: 0.1288"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:13 - loss: 3.3902 - accuracy: 0.12 - ETA: 2:12 - loss: 3.3911 - accuracy: 0.12 - ETA: 2:11 - loss: 3.3912 - accuracy: 0.12 - ETA: 2:10 - loss: 3.3911 - accuracy: 0.12 - ETA: 2:09 - loss: 3.3897 - accuracy: 0.12 - ETA: 2:08 - loss: 3.3890 - accuracy: 0.12 - ETA: 2:07 - loss: 3.3889 - accuracy: 0.12 - ETA: 2:06 - loss: 3.3884 - accuracy: 0.12 - ETA: 2:05 - loss: 3.3880 - accuracy: 0.12 - ETA: 2:05 - loss: 3.3883 - accuracy: 0.12 - ETA: 2:04 - loss: 3.3882 - accuracy: 0.12 - ETA: 2:03 - loss: 3.3878 - accuracy: 0.12 - ETA: 2:02 - loss: 3.3877 - accuracy: 0.12 - ETA: 2:01 - loss: 3.3876 - accuracy: 0.12 - ETA: 2:00 - loss: 3.3873 - accuracy: 0.12 - ETA: 1:59 - loss: 3.3870 - accuracy: 0.12 - ETA: 1:58 - loss: 3.3864 - accuracy: 0.12 - ETA: 1:57 - loss: 3.3861 - accuracy: 0.12 - ETA: 1:56 - loss: 3.3852 - accuracy: 0.12 - ETA: 1:55 - loss: 3.3844 - accuracy: 0.12 - ETA: 1:55 - loss: 3.3838 - accuracy: 0.12 - ETA: 1:54 - loss: 3.3841 - accuracy: 0.12 - ETA: 1:53 - loss: 3.3836 - accuracy: 0.12 - ETA: 1:52 - loss: 3.3836 - accuracy: 0.12 - ETA: 1:51 - loss: 3.3834 - accuracy: 0.12 - ETA: 1:50 - loss: 3.3829 - accuracy: 0.13 - ETA: 1:49 - loss: 3.3822 - accuracy: 0.13 - ETA: 1:48 - loss: 3.3818 - accuracy: 0.13 - ETA: 1:47 - loss: 3.3822 - accuracy: 0.13 - ETA: 1:46 - loss: 3.3816 - accuracy: 0.13 - ETA: 1:45 - loss: 3.3818 - accuracy: 0.13 - ETA: 1:44 - loss: 3.3823 - accuracy: 0.12 - ETA: 1:44 - loss: 3.3821 - accuracy: 0.13 - ETA: 1:43 - loss: 3.3820 - accuracy: 0.12 - ETA: 1:42 - loss: 3.3817 - accuracy: 0.13 - ETA: 1:41 - loss: 3.3819 - accuracy: 0.13 - ETA: 1:40 - loss: 3.3814 - accuracy: 0.13 - ETA: 1:39 - loss: 3.3813 - accuracy: 0.13 - ETA: 1:38 - loss: 3.3811 - accuracy: 0.13 - ETA: 1:37 - loss: 3.3801 - accuracy: 0.13 - ETA: 1:36 - loss: 3.3796 - accuracy: 0.13 - ETA: 1:35 - loss: 3.3802 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3799 - accuracy: 0.13 - ETA: 1:34 - loss: 3.3795 - accuracy: 0.13 - ETA: 1:33 - loss: 3.3803 - accuracy: 0.13 - ETA: 1:32 - loss: 3.3796 - accuracy: 0.13 - ETA: 1:31 - loss: 3.3798 - accuracy: 0.13 - ETA: 1:30 - loss: 3.3794 - accuracy: 0.13 - ETA: 1:29 - loss: 3.3794 - accuracy: 0.13 - ETA: 1:28 - loss: 3.3792 - accuracy: 0.13 - ETA: 1:27 - loss: 3.3794 - accuracy: 0.13 - ETA: 1:26 - loss: 3.3781 - accuracy: 0.13 - ETA: 1:25 - loss: 3.3785 - accuracy: 0.13 - ETA: 1:24 - loss: 3.3780 - accuracy: 0.13 - ETA: 1:23 - loss: 3.3778 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3782 - accuracy: 0.13 - ETA: 1:22 - loss: 3.3782 - accuracy: 0.13 - ETA: 1:21 - loss: 3.3780 - accuracy: 0.13 - ETA: 1:20 - loss: 3.3780 - accuracy: 0.13 - ETA: 1:19 - loss: 3.3781 - accuracy: 0.13 - ETA: 1:18 - loss: 3.3781 - accuracy: 0.13 - ETA: 1:17 - loss: 3.3773 - accuracy: 0.13 - ETA: 1:16 - loss: 3.3770 - accuracy: 0.13 - ETA: 1:15 - loss: 3.3764 - accuracy: 0.13 - ETA: 1:14 - loss: 3.3762 - accuracy: 0.13 - ETA: 1:13 - loss: 3.3760 - accuracy: 0.13 - ETA: 1:12 - loss: 3.3763 - accuracy: 0.13 - ETA: 1:11 - loss: 3.3762 - accuracy: 0.13 - ETA: 1:10 - loss: 3.3764 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3757 - accuracy: 0.13 - ETA: 1:09 - loss: 3.3762 - accuracy: 0.13 - ETA: 1:08 - loss: 3.3760 - accuracy: 0.13 - ETA: 1:07 - loss: 3.3762 - accuracy: 0.13 - ETA: 1:06 - loss: 3.3758 - accuracy: 0.13 - ETA: 1:05 - loss: 3.3759 - accuracy: 0.13 - ETA: 1:04 - loss: 3.3763 - accuracy: 0.13 - ETA: 1:03 - loss: 3.3762 - accuracy: 0.13 - ETA: 1:02 - loss: 3.3757 - accuracy: 0.13 - ETA: 1:01 - loss: 3.3756 - accuracy: 0.13 - ETA: 1:00 - loss: 3.3754 - accuracy: 0.13 - ETA: 59s - loss: 3.3748 - accuracy: 0.1316 - ETA: 58s - loss: 3.3753 - accuracy: 0.131 - ETA: 57s - loss: 3.3755 - accuracy: 0.131 - ETA: 57s - loss: 3.3758 - accuracy: 0.131 - ETA: 56s - loss: 3.3755 - accuracy: 0.131 - ETA: 55s - loss: 3.3749 - accuracy: 0.131 - ETA: 54s - loss: 3.3743 - accuracy: 0.132 - ETA: 53s - loss: 3.3745 - accuracy: 0.131 - ETA: 52s - loss: 3.3740 - accuracy: 0.132 - ETA: 51s - loss: 3.3740 - accuracy: 0.132 - ETA: 50s - loss: 3.3741 - accuracy: 0.132 - ETA: 49s - loss: 3.3737 - accuracy: 0.132 - ETA: 48s - loss: 3.3734 - accuracy: 0.131 - ETA: 47s - loss: 3.3731 - accuracy: 0.131 - ETA: 46s - loss: 3.3734 - accuracy: 0.131 - ETA: 45s - loss: 3.3731 - accuracy: 0.131 - ETA: 44s - loss: 3.3730 - accuracy: 0.131 - ETA: 44s - loss: 3.3731 - accuracy: 0.131 - ETA: 43s - loss: 3.3731 - accuracy: 0.131 - ETA: 42s - loss: 3.3726 - accuracy: 0.131 - ETA: 41s - loss: 3.3722 - accuracy: 0.131 - ETA: 40s - loss: 3.3722 - accuracy: 0.131 - ETA: 39s - loss: 3.3723 - accuracy: 0.131 - ETA: 38s - loss: 3.3721 - accuracy: 0.131 - ETA: 37s - loss: 3.3713 - accuracy: 0.131 - ETA: 36s - loss: 3.3711 - accuracy: 0.131 - ETA: 35s - loss: 3.3707 - accuracy: 0.131 - ETA: 34s - loss: 3.3709 - accuracy: 0.131 - ETA: 33s - loss: 3.3711 - accuracy: 0.131 - ETA: 32s - loss: 3.3713 - accuracy: 0.131 - ETA: 31s - loss: 3.3711 - accuracy: 0.131 - ETA: 30s - loss: 3.3707 - accuracy: 0.131 - ETA: 30s - loss: 3.3707 - accuracy: 0.131 - ETA: 29s - loss: 3.3706 - accuracy: 0.131 - ETA: 28s - loss: 3.3703 - accuracy: 0.131 - ETA: 27s - loss: 3.3701 - accuracy: 0.131 - ETA: 26s - loss: 3.3702 - accuracy: 0.131 - ETA: 25s - loss: 3.3700 - accuracy: 0.131 - ETA: 24s - loss: 3.3699 - accuracy: 0.131 - ETA: 23s - loss: 3.3698 - accuracy: 0.131 - ETA: 22s - loss: 3.3694 - accuracy: 0.131 - ETA: 21s - loss: 3.3693 - accuracy: 0.131 - ETA: 20s - loss: 3.3691 - accuracy: 0.131 - ETA: 19s - loss: 3.3688 - accuracy: 0.131 - ETA: 18s - loss: 3.3686 - accuracy: 0.132 - ETA: 17s - loss: 3.3687 - accuracy: 0.132 - ETA: 16s - loss: 3.3686 - accuracy: 0.132 - ETA: 16s - loss: 3.3679 - accuracy: 0.132 - ETA: 15s - loss: 3.3680 - accuracy: 0.132 - ETA: 14s - loss: 3.3676 - accuracy: 0.132 - ETA: 13s - loss: 3.3672 - accuracy: 0.132 - ETA: 12s - loss: 3.3671 - accuracy: 0.132 - ETA: 11s - loss: 3.3671 - accuracy: 0.132 - ETA: 10s - loss: 3.3668 - accuracy: 0.132 - ETA: 9s - loss: 3.3673 - accuracy: 0.132 - ETA: 8s - loss: 3.3668 - accuracy: 0.13 - ETA: 7s - loss: 3.3667 - accuracy: 0.13 - ETA: 6s - loss: 3.3669 - accuracy: 0.13 - ETA: 5s - loss: 3.3676 - accuracy: 0.13 - ETA: 4s - loss: 3.3671 - accuracy: 0.13 - ETA: 3s - loss: 3.3672 - accuracy: 0.13 - ETA: 2s - loss: 3.3672 - accuracy: 0.13 - ETA: 1s - loss: 3.3666 - accuracy: 0.13 - ETA: 1s - loss: 3.3667 - accuracy: 0.13 - ETA: 0s - loss: 3.3668 - accuracy: 0.13 - 335s 8ms/step - loss: 3.3668 - accuracy: 0.1328 - val_loss: 4.0199 - val_accuracy: 0.0120\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23808/42378 [===============>..............] - ETA: 5:40 - loss: 3.4015 - accuracy: 0.15 - ETA: 5:37 - loss: 3.3294 - accuracy: 0.14 - ETA: 5:33 - loss: 3.3134 - accuracy: 0.13 - ETA: 5:31 - loss: 3.3279 - accuracy: 0.12 - ETA: 5:29 - loss: 3.2950 - accuracy: 0.12 - ETA: 5:28 - loss: 3.3087 - accuracy: 0.12 - ETA: 5:24 - loss: 3.3416 - accuracy: 0.12 - ETA: 5:19 - loss: 3.3331 - accuracy: 0.12 - ETA: 5:16 - loss: 3.3172 - accuracy: 0.12 - ETA: 5:12 - loss: 3.3317 - accuracy: 0.12 - ETA: 5:09 - loss: 3.3436 - accuracy: 0.12 - ETA: 5:08 - loss: 3.3390 - accuracy: 0.13 - ETA: 5:06 - loss: 3.3405 - accuracy: 0.13 - ETA: 5:03 - loss: 3.3411 - accuracy: 0.12 - ETA: 5:02 - loss: 3.3316 - accuracy: 0.13 - ETA: 5:02 - loss: 3.3240 - accuracy: 0.13 - ETA: 5:01 - loss: 3.3231 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3187 - accuracy: 0.13 - ETA: 4:58 - loss: 3.3162 - accuracy: 0.13 - ETA: 4:57 - loss: 3.3221 - accuracy: 0.13 - ETA: 4:57 - loss: 3.3269 - accuracy: 0.12 - ETA: 4:56 - loss: 3.3199 - accuracy: 0.13 - ETA: 4:55 - loss: 3.3171 - accuracy: 0.13 - ETA: 4:54 - loss: 3.3208 - accuracy: 0.13 - ETA: 4:53 - loss: 3.3203 - accuracy: 0.13 - ETA: 4:51 - loss: 3.3177 - accuracy: 0.13 - ETA: 4:50 - loss: 3.3191 - accuracy: 0.13 - ETA: 4:48 - loss: 3.3132 - accuracy: 0.13 - ETA: 4:48 - loss: 3.3137 - accuracy: 0.13 - ETA: 4:47 - loss: 3.3136 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3146 - accuracy: 0.13 - ETA: 4:46 - loss: 3.3130 - accuracy: 0.13 - ETA: 4:44 - loss: 3.3130 - accuracy: 0.13 - ETA: 4:43 - loss: 3.3117 - accuracy: 0.13 - ETA: 4:42 - loss: 3.3137 - accuracy: 0.13 - ETA: 4:41 - loss: 3.3106 - accuracy: 0.13 - ETA: 4:40 - loss: 3.3120 - accuracy: 0.13 - ETA: 4:38 - loss: 3.3121 - accuracy: 0.13 - ETA: 4:37 - loss: 3.3091 - accuracy: 0.13 - ETA: 4:36 - loss: 3.3047 - accuracy: 0.13 - ETA: 4:35 - loss: 3.3064 - accuracy: 0.13 - ETA: 4:34 - loss: 3.3067 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3084 - accuracy: 0.13 - ETA: 4:32 - loss: 3.3069 - accuracy: 0.13 - ETA: 4:31 - loss: 3.3097 - accuracy: 0.13 - ETA: 4:30 - loss: 3.3086 - accuracy: 0.13 - ETA: 4:29 - loss: 3.3103 - accuracy: 0.13 - ETA: 4:28 - loss: 3.3115 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3128 - accuracy: 0.13 - ETA: 4:27 - loss: 3.3110 - accuracy: 0.13 - ETA: 4:26 - loss: 3.3079 - accuracy: 0.13 - ETA: 4:25 - loss: 3.3096 - accuracy: 0.13 - ETA: 4:24 - loss: 3.3079 - accuracy: 0.13 - ETA: 4:23 - loss: 3.3098 - accuracy: 0.13 - ETA: 4:22 - loss: 3.3115 - accuracy: 0.13 - ETA: 4:21 - loss: 3.3102 - accuracy: 0.13 - ETA: 4:20 - loss: 3.3146 - accuracy: 0.13 - ETA: 4:19 - loss: 3.3170 - accuracy: 0.13 - ETA: 4:18 - loss: 3.3174 - accuracy: 0.13 - ETA: 4:17 - loss: 3.3169 - accuracy: 0.13 - ETA: 4:16 - loss: 3.3169 - accuracy: 0.13 - ETA: 4:15 - loss: 3.3163 - accuracy: 0.13 - ETA: 4:14 - loss: 3.3152 - accuracy: 0.13 - ETA: 4:12 - loss: 3.3132 - accuracy: 0.13 - ETA: 4:12 - loss: 3.3126 - accuracy: 0.13 - ETA: 4:11 - loss: 3.3139 - accuracy: 0.13 - ETA: 4:10 - loss: 3.3160 - accuracy: 0.13 - ETA: 4:09 - loss: 3.3170 - accuracy: 0.13 - ETA: 4:08 - loss: 3.3168 - accuracy: 0.13 - ETA: 4:07 - loss: 3.3186 - accuracy: 0.13 - ETA: 4:06 - loss: 3.3176 - accuracy: 0.13 - ETA: 4:05 - loss: 3.3203 - accuracy: 0.13 - ETA: 4:05 - loss: 3.3182 - accuracy: 0.13 - ETA: 4:03 - loss: 3.3164 - accuracy: 0.13 - ETA: 4:03 - loss: 3.3153 - accuracy: 0.13 - ETA: 4:02 - loss: 3.3157 - accuracy: 0.13 - ETA: 4:01 - loss: 3.3178 - accuracy: 0.13 - ETA: 4:00 - loss: 3.3208 - accuracy: 0.13 - ETA: 3:59 - loss: 3.3195 - accuracy: 0.13 - ETA: 3:58 - loss: 3.3194 - accuracy: 0.13 - ETA: 3:57 - loss: 3.3199 - accuracy: 0.13 - ETA: 3:56 - loss: 3.3213 - accuracy: 0.13 - ETA: 3:56 - loss: 3.3212 - accuracy: 0.13 - ETA: 3:55 - loss: 3.3215 - accuracy: 0.13 - ETA: 3:54 - loss: 3.3186 - accuracy: 0.13 - ETA: 3:53 - loss: 3.3184 - accuracy: 0.13 - ETA: 3:52 - loss: 3.3180 - accuracy: 0.13 - ETA: 3:51 - loss: 3.3193 - accuracy: 0.13 - ETA: 3:50 - loss: 3.3209 - accuracy: 0.13 - ETA: 3:49 - loss: 3.3201 - accuracy: 0.13 - ETA: 3:48 - loss: 3.3196 - accuracy: 0.13 - ETA: 3:47 - loss: 3.3205 - accuracy: 0.13 - ETA: 3:46 - loss: 3.3207 - accuracy: 0.13 - ETA: 3:45 - loss: 3.3216 - accuracy: 0.13 - ETA: 3:44 - loss: 3.3246 - accuracy: 0.13 - ETA: 3:43 - loss: 3.3254 - accuracy: 0.13 - ETA: 3:42 - loss: 3.3262 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3269 - accuracy: 0.13 - ETA: 3:41 - loss: 3.3286 - accuracy: 0.13 - ETA: 3:40 - loss: 3.3278 - accuracy: 0.13 - ETA: 3:39 - loss: 3.3283 - accuracy: 0.13 - ETA: 3:38 - loss: 3.3270 - accuracy: 0.13 - ETA: 3:37 - loss: 3.3258 - accuracy: 0.13 - ETA: 3:36 - loss: 3.3269 - accuracy: 0.13 - ETA: 3:35 - loss: 3.3268 - accuracy: 0.13 - ETA: 3:34 - loss: 3.3259 - accuracy: 0.13 - ETA: 3:33 - loss: 3.3268 - accuracy: 0.13 - ETA: 3:32 - loss: 3.3263 - accuracy: 0.13 - ETA: 3:31 - loss: 3.3267 - accuracy: 0.13 - ETA: 3:30 - loss: 3.3260 - accuracy: 0.13 - ETA: 3:29 - loss: 3.3279 - accuracy: 0.13 - ETA: 3:28 - loss: 3.3267 - accuracy: 0.13 - ETA: 3:27 - loss: 3.3266 - accuracy: 0.13 - ETA: 3:26 - loss: 3.3271 - accuracy: 0.13 - ETA: 3:25 - loss: 3.3286 - accuracy: 0.13 - ETA: 3:24 - loss: 3.3287 - accuracy: 0.13 - ETA: 3:24 - loss: 3.3289 - accuracy: 0.13 - ETA: 3:22 - loss: 3.3279 - accuracy: 0.13 - ETA: 3:22 - loss: 3.3275 - accuracy: 0.13 - ETA: 3:21 - loss: 3.3271 - accuracy: 0.14 - ETA: 3:20 - loss: 3.3286 - accuracy: 0.13 - ETA: 3:19 - loss: 3.3303 - accuracy: 0.13 - ETA: 3:18 - loss: 3.3311 - accuracy: 0.13 - ETA: 3:17 - loss: 3.3311 - accuracy: 0.13 - ETA: 3:16 - loss: 3.3310 - accuracy: 0.13 - ETA: 3:15 - loss: 3.3310 - accuracy: 0.13 - ETA: 3:14 - loss: 3.3307 - accuracy: 0.13 - ETA: 3:13 - loss: 3.3318 - accuracy: 0.13 - ETA: 3:12 - loss: 3.3330 - accuracy: 0.13 - ETA: 3:11 - loss: 3.3349 - accuracy: 0.13 - ETA: 3:10 - loss: 3.3366 - accuracy: 0.13 - ETA: 3:09 - loss: 3.3374 - accuracy: 0.13 - ETA: 3:08 - loss: 3.3370 - accuracy: 0.13 - ETA: 3:07 - loss: 3.3374 - accuracy: 0.13 - ETA: 3:06 - loss: 3.3380 - accuracy: 0.13 - ETA: 3:05 - loss: 3.3394 - accuracy: 0.13 - ETA: 3:04 - loss: 3.3398 - accuracy: 0.13 - ETA: 3:03 - loss: 3.3417 - accuracy: 0.13 - ETA: 3:02 - loss: 3.3414 - accuracy: 0.13 - ETA: 3:01 - loss: 3.3423 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3428 - accuracy: 0.13 - ETA: 3:00 - loss: 3.3428 - accuracy: 0.13 - ETA: 2:59 - loss: 3.3447 - accuracy: 0.13 - ETA: 2:58 - loss: 3.3454 - accuracy: 0.13 - ETA: 2:57 - loss: 3.3461 - accuracy: 0.13 - ETA: 2:56 - loss: 3.3467 - accuracy: 0.13 - ETA: 2:55 - loss: 3.3491 - accuracy: 0.13 - ETA: 2:54 - loss: 3.3500 - accuracy: 0.13 - ETA: 2:53 - loss: 3.3520 - accuracy: 0.13 - ETA: 2:52 - loss: 3.3538 - accuracy: 0.13 - ETA: 2:51 - loss: 3.3548 - accuracy: 0.13 - ETA: 2:50 - loss: 3.3561 - accuracy: 0.13 - ETA: 2:49 - loss: 3.3579 - accuracy: 0.13 - ETA: 2:48 - loss: 3.3584 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3594 - accuracy: 0.13 - ETA: 2:47 - loss: 3.3608 - accuracy: 0.13 - ETA: 2:46 - loss: 3.3623 - accuracy: 0.13 - ETA: 2:45 - loss: 3.3634 - accuracy: 0.13 - ETA: 2:44 - loss: 3.3638 - accuracy: 0.13 - ETA: 2:43 - loss: 3.3654 - accuracy: 0.13 - ETA: 2:42 - loss: 3.3644 - accuracy: 0.13 - ETA: 2:41 - loss: 3.3644 - accuracy: 0.13 - ETA: 2:40 - loss: 3.3657 - accuracy: 0.13 - ETA: 2:39 - loss: 3.3669 - accuracy: 0.13 - ETA: 2:38 - loss: 3.3675 - accuracy: 0.13 - ETA: 2:37 - loss: 3.3696 - accuracy: 0.13 - ETA: 2:36 - loss: 3.3703 - accuracy: 0.13 - ETA: 2:35 - loss: 3.3702 - accuracy: 0.13 - ETA: 2:34 - loss: 3.3702 - accuracy: 0.13 - ETA: 2:33 - loss: 3.3699 - accuracy: 0.13 - ETA: 2:32 - loss: 3.3704 - accuracy: 0.13 - ETA: 2:31 - loss: 3.3713 - accuracy: 0.13 - ETA: 2:30 - loss: 3.3721 - accuracy: 0.13 - ETA: 2:29 - loss: 3.3721 - accuracy: 0.13 - ETA: 2:28 - loss: 3.3725 - accuracy: 0.13 - ETA: 2:27 - loss: 3.3733 - accuracy: 0.13 - ETA: 2:26 - loss: 3.3742 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3741 - accuracy: 0.13 - ETA: 2:25 - loss: 3.3745 - accuracy: 0.13 - ETA: 2:24 - loss: 3.3749 - accuracy: 0.13 - ETA: 2:23 - loss: 3.3753 - accuracy: 0.13 - ETA: 2:22 - loss: 3.3761 - accuracy: 0.13 - ETA: 2:21 - loss: 3.3764 - accuracy: 0.13 - ETA: 2:20 - loss: 3.3763 - accuracy: 0.13 - ETA: 2:19 - loss: 3.3764 - accuracy: 0.13 - ETA: 2:18 - loss: 3.3771 - accuracy: 0.1301"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42378/42378 [==============================] - ETA: 2:17 - loss: 3.3775 - accuracy: 0.13 - ETA: 2:16 - loss: 3.3779 - accuracy: 0.12 - ETA: 2:15 - loss: 3.3790 - accuracy: 0.12 - ETA: 2:14 - loss: 3.3793 - accuracy: 0.12 - ETA: 2:13 - loss: 3.3805 - accuracy: 0.12 - ETA: 2:12 - loss: 3.3800 - accuracy: 0.12 - ETA: 2:11 - loss: 3.3800 - accuracy: 0.12 - ETA: 2:10 - loss: 3.3802 - accuracy: 0.12 - ETA: 2:09 - loss: 3.3803 - accuracy: 0.12 - ETA: 2:08 - loss: 3.3806 - accuracy: 0.12 - ETA: 2:07 - loss: 3.3805 - accuracy: 0.12 - ETA: 2:06 - loss: 3.3815 - accuracy: 0.12 - ETA: 2:05 - loss: 3.3820 - accuracy: 0.12 - ETA: 2:04 - loss: 3.3812 - accuracy: 0.12 - ETA: 2:03 - loss: 3.3823 - accuracy: 0.12 - ETA: 2:02 - loss: 3.3821 - accuracy: 0.12 - ETA: 2:02 - loss: 3.3830 - accuracy: 0.12 - ETA: 2:01 - loss: 3.3829 - accuracy: 0.12 - ETA: 2:00 - loss: 3.3837 - accuracy: 0.12 - ETA: 1:59 - loss: 3.3844 - accuracy: 0.12 - ETA: 1:58 - loss: 3.3848 - accuracy: 0.12 - ETA: 1:57 - loss: 3.3854 - accuracy: 0.12 - ETA: 1:56 - loss: 3.3850 - accuracy: 0.12 - ETA: 1:55 - loss: 3.3849 - accuracy: 0.12 - ETA: 1:54 - loss: 3.3855 - accuracy: 0.12 - ETA: 1:53 - loss: 3.3866 - accuracy: 0.12 - ETA: 1:52 - loss: 3.3875 - accuracy: 0.12 - ETA: 1:51 - loss: 3.3877 - accuracy: 0.12 - ETA: 1:50 - loss: 3.3876 - accuracy: 0.12 - ETA: 1:49 - loss: 3.3879 - accuracy: 0.12 - ETA: 1:48 - loss: 3.3875 - accuracy: 0.12 - ETA: 1:47 - loss: 3.3873 - accuracy: 0.12 - ETA: 1:46 - loss: 3.3873 - accuracy: 0.12 - ETA: 1:45 - loss: 3.3884 - accuracy: 0.12 - ETA: 1:44 - loss: 3.3924 - accuracy: 0.12 - ETA: 1:44 - loss: 3.3943 - accuracy: 0.12 - ETA: 1:43 - loss: 3.3947 - accuracy: 0.12 - ETA: 1:42 - loss: 3.3952 - accuracy: 0.12 - ETA: 1:41 - loss: 3.3959 - accuracy: 0.12 - ETA: 1:40 - loss: 3.3969 - accuracy: 0.12 - ETA: 1:39 - loss: 3.3984 - accuracy: 0.12 - ETA: 1:38 - loss: 3.3992 - accuracy: 0.12 - ETA: 1:37 - loss: 3.3996 - accuracy: 0.12 - ETA: 1:36 - loss: 3.3999 - accuracy: 0.12 - ETA: 1:35 - loss: 3.4002 - accuracy: 0.12 - ETA: 1:34 - loss: 3.4012 - accuracy: 0.12 - ETA: 1:33 - loss: 3.4013 - accuracy: 0.12 - ETA: 1:32 - loss: 3.4017 - accuracy: 0.12 - ETA: 1:31 - loss: 3.4017 - accuracy: 0.12 - ETA: 1:30 - loss: 3.4020 - accuracy: 0.12 - ETA: 1:29 - loss: 3.4023 - accuracy: 0.12 - ETA: 1:28 - loss: 3.4028 - accuracy: 0.12 - ETA: 1:27 - loss: 3.4033 - accuracy: 0.12 - ETA: 1:26 - loss: 3.4044 - accuracy: 0.12 - ETA: 1:25 - loss: 3.4053 - accuracy: 0.12 - ETA: 1:24 - loss: 3.4059 - accuracy: 0.12 - ETA: 1:23 - loss: 3.4058 - accuracy: 0.12 - ETA: 1:22 - loss: 3.4057 - accuracy: 0.12 - ETA: 1:22 - loss: 3.4064 - accuracy: 0.12 - ETA: 1:21 - loss: 3.4069 - accuracy: 0.12 - ETA: 1:20 - loss: 3.4067 - accuracy: 0.12 - ETA: 1:19 - loss: 3.4070 - accuracy: 0.12 - ETA: 1:18 - loss: 3.4072 - accuracy: 0.12 - ETA: 1:17 - loss: 3.4077 - accuracy: 0.12 - ETA: 1:16 - loss: 3.4081 - accuracy: 0.12 - ETA: 1:15 - loss: 3.4080 - accuracy: 0.12 - ETA: 1:14 - loss: 3.4076 - accuracy: 0.12 - ETA: 1:13 - loss: 3.4082 - accuracy: 0.12 - ETA: 1:12 - loss: 3.4074 - accuracy: 0.12 - ETA: 1:11 - loss: 3.4082 - accuracy: 0.12 - ETA: 1:10 - loss: 3.4081 - accuracy: 0.12 - ETA: 1:09 - loss: 3.4080 - accuracy: 0.12 - ETA: 1:08 - loss: 3.4087 - accuracy: 0.12 - ETA: 1:07 - loss: 3.4094 - accuracy: 0.12 - ETA: 1:06 - loss: 3.4098 - accuracy: 0.12 - ETA: 1:05 - loss: 3.4096 - accuracy: 0.12 - ETA: 1:04 - loss: 3.4098 - accuracy: 0.12 - ETA: 1:03 - loss: 3.4102 - accuracy: 0.12 - ETA: 1:02 - loss: 3.4104 - accuracy: 0.12 - ETA: 1:01 - loss: 3.4111 - accuracy: 0.12 - ETA: 1:01 - loss: 3.4105 - accuracy: 0.12 - ETA: 1:00 - loss: 3.4111 - accuracy: 0.12 - ETA: 59s - loss: 3.4108 - accuracy: 0.1231 - ETA: 58s - loss: 3.4116 - accuracy: 0.122 - ETA: 57s - loss: 3.4125 - accuracy: 0.122 - ETA: 56s - loss: 3.4133 - accuracy: 0.122 - ETA: 55s - loss: 3.4140 - accuracy: 0.122 - ETA: 54s - loss: 3.4154 - accuracy: 0.122 - ETA: 53s - loss: 3.4152 - accuracy: 0.122 - ETA: 52s - loss: 3.4154 - accuracy: 0.122 - ETA: 51s - loss: 3.4163 - accuracy: 0.122 - ETA: 50s - loss: 3.4165 - accuracy: 0.122 - ETA: 49s - loss: 3.4165 - accuracy: 0.122 - ETA: 48s - loss: 3.4165 - accuracy: 0.122 - ETA: 47s - loss: 3.4166 - accuracy: 0.122 - ETA: 46s - loss: 3.4170 - accuracy: 0.122 - ETA: 45s - loss: 3.4172 - accuracy: 0.122 - ETA: 44s - loss: 3.4176 - accuracy: 0.122 - ETA: 43s - loss: 3.4179 - accuracy: 0.122 - ETA: 42s - loss: 3.4180 - accuracy: 0.122 - ETA: 42s - loss: 3.4180 - accuracy: 0.122 - ETA: 41s - loss: 3.4183 - accuracy: 0.122 - ETA: 40s - loss: 3.4187 - accuracy: 0.122 - ETA: 39s - loss: 3.4183 - accuracy: 0.122 - ETA: 38s - loss: 3.4191 - accuracy: 0.122 - ETA: 37s - loss: 3.4191 - accuracy: 0.122 - ETA: 36s - loss: 3.4193 - accuracy: 0.121 - ETA: 35s - loss: 3.4196 - accuracy: 0.121 - ETA: 34s - loss: 3.4196 - accuracy: 0.121 - ETA: 33s - loss: 3.4195 - accuracy: 0.121 - ETA: 32s - loss: 3.4195 - accuracy: 0.121 - ETA: 31s - loss: 3.4197 - accuracy: 0.121 - ETA: 30s - loss: 3.4199 - accuracy: 0.121 - ETA: 29s - loss: 3.4207 - accuracy: 0.121 - ETA: 28s - loss: 3.4209 - accuracy: 0.121 - ETA: 27s - loss: 3.4212 - accuracy: 0.121 - ETA: 26s - loss: 3.4218 - accuracy: 0.121 - ETA: 25s - loss: 3.4218 - accuracy: 0.121 - ETA: 24s - loss: 3.4216 - accuracy: 0.121 - ETA: 23s - loss: 3.4219 - accuracy: 0.121 - ETA: 22s - loss: 3.4223 - accuracy: 0.121 - ETA: 21s - loss: 3.4225 - accuracy: 0.120 - ETA: 21s - loss: 3.4230 - accuracy: 0.120 - ETA: 20s - loss: 3.4237 - accuracy: 0.120 - ETA: 19s - loss: 3.4240 - accuracy: 0.120 - ETA: 18s - loss: 3.4243 - accuracy: 0.120 - ETA: 17s - loss: 3.4243 - accuracy: 0.120 - ETA: 16s - loss: 3.4248 - accuracy: 0.120 - ETA: 15s - loss: 3.4253 - accuracy: 0.120 - ETA: 14s - loss: 3.4258 - accuracy: 0.120 - ETA: 13s - loss: 3.4294 - accuracy: 0.120 - ETA: 12s - loss: 3.4303 - accuracy: 0.120 - ETA: 11s - loss: 3.4304 - accuracy: 0.119 - ETA: 10s - loss: 3.4306 - accuracy: 0.119 - ETA: 9s - loss: 3.4303 - accuracy: 0.120 - ETA: 8s - loss: 3.4298 - accuracy: 0.12 - ETA: 7s - loss: 3.4299 - accuracy: 0.11 - ETA: 6s - loss: 3.4301 - accuracy: 0.11 - ETA: 5s - loss: 3.4302 - accuracy: 0.11 - ETA: 4s - loss: 3.4305 - accuracy: 0.11 - ETA: 3s - loss: 3.4306 - accuracy: 0.11 - ETA: 2s - loss: 3.4306 - accuracy: 0.11 - ETA: 1s - loss: 3.4302 - accuracy: 0.11 - ETA: 1s - loss: 3.4305 - accuracy: 0.11 - ETA: 0s - loss: 3.4302 - accuracy: 0.11 - 340s 8ms/step - loss: 3.4304 - accuracy: 0.1198 - val_loss: 3.8912 - val_accuracy: 0.0092\n",
      "2020-09-04 03:13:28.077779\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "t5=datetime.datetime.now()\n",
    "print(t5)\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n",
    "t6=datetime.datetime.now()\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Pickle/DenseNet121_history_OF.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(history, '../Pickle/DenseNet121_history_OF.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "history = joblib.load('../Pickle/DenseNet121_history_OF.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [3.92212546818313, 3.9128227724103266, 3.87707962584092, 3.882035503275866, 3.8838214976644294, 3.9076368421719017, 3.8713977223673313, 3.907278381855965, 3.935298120137251, 3.9314711020234685, 3.8776391823833727, 3.948283122233961, 3.982788232081616, 3.9190222451080996, 3.960289171767698, 4.066464425649992, 3.898227517041214, 3.9068450596770496, 3.9033834683709587, 3.883216481905938, 3.9156139398804717, 3.951568993684664, 3.9236810062739518, 3.8894585730013054, 3.9250648504331087, 3.9113755329866158, 3.9138754739905437, 3.937481608700105, 3.969860318708349, 4.01459673495641, 3.870349048065026, 3.8810496801789967, 3.914623855853858, 3.927443263883633, 3.8993269184374286, 3.8849347525261537, 3.8995963152898763, 3.909956542792597, 4.0086125701337485, 3.8621817354748065, 3.9589490914336665, 4.009130969123922, 3.9876220220600245, 3.9345716599996665, 3.906445342221748, 3.9177449001963134, 3.901172537377351, 3.9006709955801115, 3.9672875661112212, 3.9731530746140153, 3.888023212472512, 3.9151951649182766, 3.9150632852372103, 3.981557396072211, 3.9115914748661034, 3.942768218015441, 4.003008894225379, 3.9972943674904586, 3.968412487801809, 3.9116765123787864, 4.014245554491645, 4.024612325843621, 3.926872740817804, 4.071568727357867, 3.9591724508312174, 3.9839940298068095, 3.9696739259720064, 3.8952987555088163, 3.9496818236108666, 4.0135637673548406, 3.9752700215075, 3.8984622632483523, 3.921647134320676, 4.058039447251848, 3.915463042614014, 3.9529622727790286, 3.9402363722018054, 3.8794388010273546, 3.8901946992883896, 3.8555568925605557, 3.95785149330309, 3.997350780608829, 3.890665990472395, 3.9887426799499863, 3.91345805535733, 3.9601854414042323, 3.942063847333481, 3.989393665372655, 3.980400595003592, 3.961825916526887, 3.969307872445478, 3.985835058559386, 3.8922595121935526, 3.9517058259341495, 4.016670682600083, 4.0092786390862925, 4.029817080072526, 3.9780692779569615, 4.0199390141026585, 3.8912118406143024], 'val_accuracy': [0.01806202344596386, 0.03339770436286926, 0.02726343274116516, 0.033965691924095154, 0.02919459342956543, 0.032034534960985184, 0.02987617813050747, 0.033170510083436966, 0.03430648520588875, 0.02419629693031311, 0.030330568552017212, 0.029535384848713875, 0.029308190569281578, 0.028172213584184647, 0.03305691108107567, 0.025332273915410042, 0.02351471036672592, 0.02306031994521618, 0.022492332383990288, 0.024082699790596962, 0.025332273915410042, 0.029421787708997726, 0.032034534960985184, 0.02237873524427414, 0.02430989407002926, 0.02237873524427414, 0.013518119230866432, 0.020901964977383614, 0.02294672280550003, 0.020901964977383614, 0.01987958699464798, 0.01806202344596386, 0.022605929523706436, 0.01738043874502182, 0.024423491209745407, 0.01919800043106079, 0.02544587105512619, 0.017834829166531563, 0.02555946819484234, 0.01931159757077694, 0.01874361000955105, 0.02056117169559002, 0.017039645463228226, 0.022719526663422585, 0.02044757455587387, 0.020674770697951317, 0.0186300128698349, 0.015676474198698997, 0.019765987992286682, 0.015108485706150532, 0.013858911581337452, 0.013745314441621304, 0.017834829166531563, 0.016585255041718483, 0.01215494703501463, 0.015335680916905403, 0.016926048323512077, 0.014994888566434383, 0.013745314441621304, 0.01340452115982771, 0.01851641573011875, 0.0186300128698349, 0.014994888566434383, 0.015108485706150532, 0.01215494703501463, 0.01488129049539566, 0.010223787277936935, 0.015790071338415146, 0.013063727878034115, 0.017834829166531563, 0.012495740316808224, 0.014199704863131046, 0.013518119230866432, 0.01806202344596386, 0.012609337456524372, 0.012609337456524372, 0.012836532667279243, 0.012495740316808224, 0.011246166191995144, 0.007951834239065647, 0.011359763331711292, 0.013858911581337452, 0.01363171637058258, 0.014086106792092323, 0.008860616013407707, 0.008519822731614113, 0.011246166191995144, 0.0218107458204031, 0.01181415468454361, 0.012609337456524372, 0.012950130738317966, 0.00931500643491745, 0.009542201645672321, 0.008406225591897964, 0.007611041888594627, 0.011132568120956421, 0.014313302002847195, 0.013290923088788986, 0.012041349895298481, 0.009201408363878727], 'loss': [4.057358206952804, 3.70344552478883, 3.592719578969146, 3.507616303394535, 3.4681192418144855, 3.4504685392352306, 3.4152258609531567, 3.3998542355188106, 3.398269046421313, 3.3550718047371433, 3.3415449884772848, 3.3385721838847275, 3.335300281389994, 3.341909724424163, 3.3398831730617147, 3.335634298809321, 3.341181530993636, 3.3456833856542043, 3.322533322357289, 3.3033450860188185, 3.313256835356897, 3.313088011745014, 3.30530970121005, 3.3105535439915204, 3.2964624321822478, 3.291354769752139, 3.288549264407078, 3.2836865473786006, 3.2714826266308425, 3.294260585632695, 3.297844415501114, 3.2665223390858364, 3.26528223247592, 3.288960420796744, 3.275549667419069, 3.2645696151745462, 3.2436856462200576, 3.2981487327099317, 3.2887707311877885, 3.2728968407007426, 3.3385760383915613, 3.2598136678795866, 3.260375978002756, 3.34711685090198, 3.316714375323665, 3.2968615743638976, 3.302512834664981, 3.2750952236941213, 3.2887259569797753, 3.2809527268792973, 3.2939218220869857, 3.2953592164985994, 3.3525695107658193, 3.2939968019789996, 3.3076446681414438, 3.3491433487836835, 3.2818639039756996, 3.2708766636287425, 3.3054034969401487, 3.2889076941380937, 3.324895071563638, 3.3120303861517315, 3.3034371744157953, 3.3448885916943447, 3.33224979261155, 3.3202520970484923, 3.295198270230269, 3.337440527707973, 3.2976801326666556, 3.300361673920493, 3.301514090168014, 3.2954289452295664, 3.2822357992874096, 3.2874091010224435, 3.274412269122852, 3.3130875071266734, 3.3337077937629576, 3.3634353089092914, 3.3709655239896104, 3.3722497291363305, 3.3603475095979434, 3.3667249403216366, 3.4283768785495496, 3.3581419202288862, 3.4892469803143418, 3.5623941577799036, 3.5478775335284256, 3.50822499159672, 3.5286638342567374, 3.5235263317537893, 3.3821850424979925, 3.451773895020809, 3.534486950763114, 3.4986653474667944, 3.4639138965115204, 3.4613857048747954, 3.420477808312273, 3.3973025978694547, 3.3667573740587087, 3.43037156479463], 'accuracy': [0.046816744, 0.07836613, 0.10387465, 0.11824532, 0.1249941, 0.12879324, 0.13341828, 0.13773656, 0.13478692, 0.1439898, 0.1447685, 0.14318751, 0.14422578, 0.14125253, 0.14120534, 0.14318751, 0.14009628, 0.13894002, 0.14554721, 0.14665629, 0.145618, 0.14469773, 0.14719902, 0.14637312, 0.1457596, 0.15005428, 0.14844967, 0.15184766, 0.1547265, 0.14972392, 0.14953513, 0.15493888, 0.1539478, 0.15208364, 0.15357025, 0.15416017, 0.16175845, 0.1507386, 0.15224881, 0.1547737, 0.1440134, 0.15916277, 0.15828969, 0.14266837, 0.14580679, 0.14708103, 0.14590117, 0.1531455, 0.14795412, 0.15029025, 0.1498183, 0.15057342, 0.14026146, 0.14936996, 0.14691585, 0.13856246, 0.15208364, 0.15255557, 0.14833169, 0.15010147, 0.13924678, 0.14682147, 0.14701024, 0.1373354, 0.1448865, 0.14649111, 0.14854406, 0.14469773, 0.15036103, 0.14934635, 0.15158808, 0.15135212, 0.15300392, 0.15305111, 0.15689744, 0.14995989, 0.1448865, 0.13941196, 0.13313511, 0.13188447, 0.13252158, 0.13311152, 0.12367266, 0.13556562, 0.10984473, 0.1002171, 0.10009911, 0.107249044, 0.103544295, 0.10694228, 0.13091698, 0.118646465, 0.10562084, 0.11102459, 0.11487092, 0.114469774, 0.12553683, 0.13030346, 0.13278116, 0.11977913]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOydd3yb1b3/30fyHvHecWJn70kWYSQBkpBQoOzVAqVAx23p4ke5Xbe0vdDSSykUKBvKhrAhgQRICGSS6Sxnx3vGe9vS+f1x9FiyLNmyLdmOdd6vV15aj/QcOY/O53znEVJKNBqNRuO/mAZ6ABqNRqMZWLQQaDQajZ+jhUCj0Wj8HC0EGo1G4+doIdBoNBo/RwuBRqPR+DlaCDQaDxFCvCCE+LOHx54SQlzY18/RaPoDLQQajUbj52gh0Gg0Gj9HC4FmSGFzydwthMgSQtQLIZ4VQiQJIdYIIWqFEJ8JIWIcjr9UCHFACFElhNgghJjo8NpMIcQu2/veAEKcznWJEGKP7b2bhRDTejnm24UQx4QQFUKID4QQqbbnhRDiH0KIUiFEte07TbG9tkIIcdA2tgIhxK969QfTaNBCoBmaXAlcBIwDvgWsAf4biEdd8z8FEEKMA14DfgYkAKuBD4UQQUKIIOA94CUgFnjL9rnY3jsLeA64E4gDngQ+EEIE92SgQoglwP3ANUAKkAO8bnt5KXCe7XtEA9cCp22vPQvcKaWMBKYAX/TkvBqNI1oINEORR6WUJVLKAuArYJuUcreUshl4F5hpO+5a4GMp5TopZSvwdyAUOBuYDwQCD0spW6WUq4BvHM5xO/CklHKblNIipXwRaLa9ryfcCDwnpdxlG9+9wAIhRAbQCkQCEwAhpTwkpSyyva8VmCSEGCalrJRS7urheTWadrQQaIYiJQ73G108jrDdT0WtwAGQUlqBPCDN9lqB7NiVMcfh/kjglza3UJUQogpIt72vJziPoQ616k+TUn4B/At4DCgRQjwlhBhmO/RKYAWQI4T4UgixoIfn1Wja0UKg8WcKURM6oHzyqMm8ACgC0mzPGYxwuJ8H/EVKGe3wL0xK+VofxxCOcjUVAEgpH5FSzgYmo1xEd9ue/0ZKeRmQiHJhvdnD82o07Wgh0PgzbwIrhRAXCCECgV+i3DubgS1AG/BTIUSAEOIKYK7De58GfiCEmGcL6oYLIVYKISJ7OIZXgVuFEDNs8YX/RbmyTgkh5tg+PxCoB5oAiy2GcaMQIsrm0qoBLH34O2j8HC0EGr9FSnkYuAl4FChHBZa/JaVskVK2AFcAtwCVqHjCOw7v3YGKE/zL9vox27E9HcPnwO+At1FWyGjgOtvLw1CCU4lyH51GxTEAvgOcEkLUAD+wfQ+NplcIvTGNRqPR+DfaItBoNBo/RwuBRqPR+DlaCDQajcbP0UKg0Wg0fk7AQA+gp8THx8uMjIyBHoZGo9GcUezcubNcSpng6rUzTggyMjLYsWPHQA9Do9FoziiEEDnuXtOuIY1Go/FztBBoNBqNn6OFQKPRaPycMy5G4IrW1lby8/Npamoa6KH4lJCQEIYPH05gYOBAD0Wj0QwhhoQQ5OfnExkZSUZGBh2bRQ4dpJScPn2a/Px8MjMzB3o4Go1mCDEkXENNTU3ExcUNWREAEEIQFxc35K0ejUbT/wwJIQCGtAgY+MN31Gg0/c+QEQKNRuMBed9A4e6BHoVmkKGFwAtUVVXx+OOP9/h9K1asoKqqquuDpITWxl6OTKNxYs3d8OlvBnoUmkGGFgIv4E4ILJauN41avXo10dHRXX94UzWUZUNbc1+GqNEoakugKm+gR6EZZAyJrCFPsFglFquVQLPJ6772X//61xw/fpwZM2YQGBhIREQEKSkp7Nmzh4MHD3L55ZeTl5dHU1MTd911F3fccQdgb5dRV1fHxRdfzDnnnMPmzZtJS0vj/fffJzQ0FNpswWFLKwQEe3XcGj9DSqgvA2kFqwVM5v49f8VJGJaqr+NByJATgj9+eICDhTWdnm+1WGlpsxIe3POvPCl1GH/41mS3rz/wwAPs37+fPXv2sGHDBlauXMn+/fvb0zyfe+45YmNjaWxsZM6cOVx55ZXExcV1+IyjR4/y2muv8fTTT3PNNdfw9ttvc9NNN4GlRR1gbevxuDWaDjRWgrVV3a8rUZNyf9HaCE+cDRf8Aeb/oP/Oq/EIv3MN9cfGnHPnzu2Q6//II48wffp05s+fT15eHkePHu30nszMTGbMmAHA7NmzOXXqlHpBC4HGW9SX2+9XF/TvuetKoLUBKk/273k1HjHkLAJ3K/fT9c0UVDYyIXkYQQG+1b/w8PD2+xs2bOCzzz5jy5YthIWFsWjRIpe1AMHBdnPZbDbT2GgLEGsh0HiL+lL7/eo8SJ/Tf+euK+14qxlU+I1FYLLFBaT0vk0QGRlJbW2ty9eqq6uJiYkhLCyM7Oxstm7d6vkHSwltNlPe2nXgWaPpFsdJuGYALAJQMQrNoGPIWQTuMNniw1Yf+Ibi4uJYuHAhU6ZMITQ0lKSkpPbXli9fzr///W+mTZvG+PHjmT9/vucfbG0DrA73NZo+YEzCwtT/rqHaYnVrCIJmUOE3QmBkCll9YBEAvPrqqy6fDw4OZs2aNS5fM+IA8fHx7N+/v/35X/3qV+pOS739YC0Emr5SX6ZEIHa0cg31J9o1NKjRrqHBjMXmFjIFaNeQpu/UlUJYHESPGDjXUFMVtLX077kHO42VsPXfYBm4xZ4fCYG69YVryGcYgeLAUG0RaHpGZQ40O8Wt6ssgPBGihg9A1pCDJaDjBB1Zcw98cg+c3DBgQ/AbIRBnpEXQokx5c7AWAo1nSAlbHodHZsL6+zu+VlcKEQlKCOpL+7dava5EXcvQMXvJ3zn+BWS9oe6f2tT59frT6v/Ux/iNEJyRFkFbC5iDlGtIWvrlgtCcwbQ2wrs/gE/vVdXDZYc6vm5YBMPS1OP+dA/VlULcGNt9P7UImmrg6Gd2N29rI3z0C4gdBSnT4dTXHY8vzYb/GwcnNvh8aH4kBL4NFvsEi4MQwOC3CsqOwNNL1CpG079ICS9fCVmvw+LfwqTLoPJUx2PqyyDcZhFA39xDdWWw9reeNUSUUlkESVNs4/BTi2DLY/DKlfDU+WrS3/igKrC75B8w+gIo3AXNdfbjD32gfvPlR3w+NJ8LgRDCLITYLYT4yMVrwUKIN4QQx4QQ24QQGT4bh+32jLII2oXA1hNmsAeMs16Hgp1Qsr/7Y73B6eOQs6XrY6rz4av/G9BAXL/QWAk5m+D8X8P5d0NspmouZ1wzzXWqsjfCUQjye3++A+/C5kfhUKefteuxWVsh2SYE/po5VLATIpKgoRJeWAlfPQTTroNRiyDjHDXp522zH5/9sbqtLfL50PrDIrgLOOTmtduASinlGOAfwF99NQhfZg31tg01wMMPP0xDQ0PnF6wW5Q46kyyCo2vVbX8FA7/4E7xze9fHfPMsfH4f7Hiuf8bkTZyDvV1RlaNuk6eq25gMNfnWFKrHxio8PNHeY6imD0Jg7Glw4N3ujzUyhmIyICjSP4PFUkLRHhhzIfzXN7Dov2HkQlj2F/V6+jz1O8+xxQmqC9TxYK/B8CE+FQIhxHBgJfCMm0MuA1603V8FXCB8tA2X8GGMwCdCYGQMBZwhQlBTBMX71P3+WvFVnFA/kq7E/dRX6vaLP59ZK9HcrXD/cHjhEji8BqzWro+vylW30SPUbUyGujXcQ0afoYhElYUWFt8315AhBMfWKd93VxhCEJGkLBJ/LCqrLVICmDIdgsJg0T1w68cQHq9eD46A1Jn2OMERW+1RWPyZLwTAw8D/o708thNpQB6AlLINqAbinA8SQtwhhNghhNhRVta71YQQApMQPrEIHNtQ33333Tz44IPMmTOHadOm8Yc//AGA+vp6Vq5cyfTp05kyZQpvvPEGjzzyCIWFhSxevJjFixd3/FBDCDq4hgaxEBz7zH6/v3zAlTlq1dvkZnOfphoo2AWTLldukc/+p3/G5Q2OrweEat382nXw2Fz7ZO8KZyGIHqluDSEwRDA8Qd1GpfXeNdRSD+WHYfQSdZ0edl0w2Y5x7ogkZZH4SpALdsE7dwxOF2qhbXWfMsP9MRnnKPdRSz1kr1aFfyPm94sQ+KyyWAhxCVAqpdwphFjk7jAXz3WaqaWUTwFPAZx11lldz+Rrfm1fmTqR2dJGgElAQA/7sCdPhYsfcPuyYxvqtWvXsmrVKrZv346UkksvvZSNGzdSVlZGamoqH3+s/H7V1dVERUXx0EMPsX79euLj4zt+qKMQGGl3g/ECNzi6FiJTAdk/WSGNVXYBqCuD0JjOx+RuUe61ObepFfKmh2HWzTBinu/H11cKdkDiRLhzIxx8H977IXz9MFzykOvjq3IhJApCbRsdRQ0HYXawCJyEYNjw3ncCLd6nspLm3K4SBA68C9OvdX+8s0VQ3rn7rlfY8hjsXwWLfq0ycQYTRXvU79hw3bki4xz4+h9w7HM4uVG1625ttLuLfIgvLYKFwKVCiFPA68ASIcTLTsfkA+kAQogAIAqo8OGYfN6Geu3ataxdu5aZM2cya9YssrOzOXr0KFOnTuWzzz7jnnvu4auvviIqKqrrD2prAYRyCwmTuj9YLQJLq0pxG3uRmmj6wyIwfOLg3ud8cqOqwRg+F867W6VNrv7l4BZUUK6ugp2QNhvMgTD1Kph2Dex5FRrc/Dwqc+zWAKj3RQ23/50Mce5gEfTSNWSsblNnwuTLlTXY2MWWq3UlEBAKwZG+swham+DIp+q+8w5s9afh/R9378IysFrh9RuVBelprYWUXbsoi/ZC/HjlFnJH+jwl3l/8WVm641dAZLIKtrd27ljsTXxmEUgp7wXuBbBZBL+SUt7kdNgHwM3AFuAq4AvZV99NFyv3/OJaQgNNjIgLd3tMX5FScu+993LnnXd2em3nzp2sXr2ae++9l6VLl/L73/4Gt9JkZAwZwQ1TwOAVgrxt0FwDY5eq3PT+8MU7pka6E56TGyF9LgSGqMdLfgfv/UCNd+TZPh9ir6k4oX78w8+yPzf/x7D7ZRX0Pu9Xnd9TlQtxozs+FzPSwSIog5BoFXMCJRLN1WpyDBmmNrUvy4ZZ3+l+fIW7ITIFhqXA5G/Dln/B4dUw4wbXx9eWqNiEEOq2sUItHsyB3Z/LU06shxZbcN25j9Lxz9XfbvwKmLCy+88q2QfZtmyoo5/BFU9B0iT3x1st8MZ31Pe77hXXxxTuUdlBXREcqcS1YIdqBZI+T10LAHXF9riPD+j3OgIhxH1CiEttD58F4oQQx4BfAL/27bl9Eyx2bEO9bNkynnvuOerqVD5wQUEBpaWlFBYWEhYWxk033cSvfvUrdu3aBdX5RIYGUVvjYqViaen4QxnM/YaOrgVTIIw6X634HDdA8RWVjhaBi/M1VCgXRuZ59ufGLVO3/WBqd8nul+GJc9wHgAt2qts0ByFImqR88tuf6rxKlVIJgaNFAGricHQNRSTaX3MsKmtrhlW3wgf/pVJCu6Nwt93XnTYbotK7zh6qK1FuIbBbJN6+Rg5+AMFRgOhsERh/g9KDnn3W8fXq9luPqAn4qfNh3yr3x3/5Vzj8sfvrqrZYfU5qF/EBg4xz1O245So2GJFs+wzfBtj7RQiklBuklJfY7v9eSvmB7X6TlPJqKeUYKeVcKeUJX47DJIRPCsoc21CvW7eOG264gQULFjB16lSuuuoqamtr2bdvH3PnzmXGjBn85S9/4bf/fS80VnHHjVdw8cUXuw4WG6s3UBfFYLUIjq6DkQvUiibC5hrydeFeVY79h+/KAsnZBMiOQhAWC4mTIWezb8fWHYfXqFVn1SnXr+fvgMAwSJjQ8fkFP1aT6v53Oj7fUAGt9a6FoL5M1RDUldknYehYS7DrP2oVnTJDFYllvel+7M11qsApdaZ6LIRyDx3/wr3bqs5BhIxbb7oP21rURDzB5kpxtgiMRUOpuyx2J45/AYmTYPbN8MMtkDoLPvipfXXuyJFPlRCExiorrrGy8zGeBIoNRi1StxMuUbeRhhD4tpbAbyqLQbWZ8NX89Oqrr7J//34efPBB7rrrLvbt28e+ffvYsmULo0ePZtmyZWRlZbFnzx6++eYbzpo8BrDyk+9dR/buzaxfv97+YVarmvTNjkIwSF1D1flqpTXmIvU4PFGJWFO1b89beQpiM5QJ7SpGcHIjBIarH7EjI8+G3G3eKTBrroOtT8Ajs2DdHzx/X3GW7dZN4V3BDjXRmp08t6MvgISJKijqeCEbcQBnITAyh6py1cTrSghOH1MVriMXwvc+hYxzVWD62OddjF12XN2OX6muzVw3my51sAhsQuDNhIJTG9X1NukyZZ04Z1e1WwTZ3X9WS4P6HqOXqMcRCXDVc+r/4p07O143FSdVHUvyVFjxoP05Z4r2AqLrQLHBqEXw/S9g/MXqsSEEPk659TMh8I1F0CsaT6tApjB1LtO3OmQMGQxWITAqS8cuVbftKz4fZw5V5qgVb3iCeyEYMb+jVQVKCFrroXhv387/zbPwj8nwya+VGLqbOJ1pqLBPVK4qsNualUsrbXbn14RQVkHJvo59aZxTRw1ibPtmV55SfyNH11BEsrr2vnpITTJLfqdiKde9ooKa79zuetVk1A84rm4N/7lzbyNQq/XGCvuE5guL4OD7EBQBoxZDdHrntFhDCMqP2Fu7uyN3M1iaYbSDhR6VBiv+D/K3q8wzKZWr6PkV6vVrXlIZXuA6E6toD8SPVbUC3SEEDJ9tjw2Gxiq3q7YIvIevYgQ9pq1Z5QqHxapsihangrI2N0Iw2BrPSancCikzINHmxjBWnb4MGFutahUcPdLminISgrpSFfh0dAsZGEFiV50ePT6/BT79jWqidttnKj214nj3RV/gkNosXKc5F+9XFpVjoNiRKVeozJITDhakWyHIULflh9WKOdxBCMwBKuBbX6qqXUcuUM+HRMHc70PDadeb1xTuUWnCkfZd+AiJUjEHVytu4//G2TXkrRWupU21Yhi3TAlZVLqKexj/F20t6nFMpsrEOX286887vl797kY4JRNMvUoFxjfcD89cCG/fpq6977yn2nkYf2tXFkHhHs/cQq4wmZSI+riWYMgIgSfJRr4qKOsxhi81NFalk7U2dpzgLa6EwGwb+yAYv0H+Dig9ALNvsT/XHgz0oRDUFau/UcxIdT5n0Tm5Ud1mntv5vZHJqlCnL3GC8qPQ1ghzb1cbwMeNUQVrtYXdv7fIZomMOt+1a6hgh7p1ZREABIUrF0PedvtzVTkqIyjEKSU5LFa1dMi3fWZEQsfXDffQ4t90fD5xsrotcRFcLdxtjw84kjBBia8zdbYJzHANBYUrl523XEO5m5VoTbpMPY5OV9eGITTVeYC0u1ocA8aNlfDkeSozyOD4ehixoHOapxCw8iElppWnVCD59vWQNsv+vSKSOlsEdaXquvAkUOyOiCQtBJ4QEhLC6dOnu53kB4VFIKUylYMjldsiMAywQptDnnBzrbIAHIRACjOn69sIMQ/0F3Bg5wvqRz31KvtzET7wATtjBP9iMmxZSk7nKtqr/nbJ012/P2OhmkA8WcG7wvDxJ09Tt0Z7ZU8KpYr2qlVr5nlQnds5/z5/h3LbGFk9rkifpzKLDDeHq4whUBd8zEjI/0Y9DncSgqlXw8Kf2SczA8O6c86yaaqB00ddC0HiROV6cc5sa68qdnRLOdWaNNX0PiPu+Hr1WxlzoXocZfs7GNaMMTGPuVC5whzF6tjn6v/j3TtVVk5tsVrYjHZK3DAIi4UfbYafZalAssmpMDUmEypOdXzOEP4UN9eiJ/SDRTAk9iwePnw4+fn5dNd+oqqxlYbmNkR1aD+NzAVtTbYtA+NVFoOlFWpLocyiVhVSKlM2MAwqHS7a1kZCCncwfMIs95/dHe//WBVXzb6579+jqRoOvKMmk+BI+/NhceoH50uLwPD5RmeoXi0tdcq9ZqziKk8pt5FzsNVg5ELl0io9aO+I2ROK9kJACMSPU4/jx6rb08fcTyIGxVlKQJJsgcOSA0qYDAp2KrdQVy230ufC9idVjCF1pq2GYIzrY2My7LEIR9cQKIvGFSFRqvLYOcvGEEBXq9uECerarjzVsZ7BsarYwLGozGpV6ZlBEfDd99Vk2xOqcpSwBtlqg6LTbc/nqr+TsWhImKCqjR3F7djnEDxMXT/v/wim2BY0RqDYFa4q2A1iR3XeO8DIGDIWDb0hMtnnKc9DQggCAwPJzMzs9rgHP83m31/mc/x/V/TDqNzw4V2w7224+6htC0oLPHCxKsZZ8aBKR/vkGrjxbRg70f6+gl3wzr2Q8VrvzluarfLXs1eryburCkdP2PeWcoc4i4rJ7D6Tx1tU5QBC/egdg9NBDv11uiq+MeIEOZt7LwRJk+1CE5miLKPTx7p+X3OdshqmXGU/b8l+uxA0VKhYw0znuksn0m0tMvK2K99zVa7KKHKF49/B2TXUFUmTOlsEhovJnUUAasXdQQgcup62jyPRnoqZu8V+/8VLlRiEd2o35h5nayjKJgTtFsEpZR1GpqgxGuImpUoTHXOhuh5W/wqKstQCLcmD7B5XxGbC3leVqzfQttgs2KEWDCHDeveZ0LG62CiO9DJDwjXkKSEBZixWSaully4Bb1C4W/mVjQvFZFZmo5GNkf2R8us6+7fDbD+Ohl5u+rLPlhveWAF73FQ/eoqUsOMF5at2Ts8E24rPl66hU6qVckBw5wIlKbsXgugRasLozSpLSvuq3kAINfl15xoqOQBISJmmJqawuI4B4/ZCMjfxgfbxpyvXUd42dT20Nrh2DYE9hRQ6WwRdYbh6HLNscrcqy8PomOlIwnh162xF1JWoWJhj9pZjXGf/28r6vfZl5XZ68Vs9KzZzbq0RHKFW7UZRmZFUYDKp2oCKE2pCLT2o4hejl8Cc76ust/pSlb5p6uW02J6lZbNCpFTimeYm8O8pRlFZne/cQ34lBKFByqfX2DpAFbqWNrUyT3JahabOVBNCW7MqNhp7kZrkHDGEoLEXrZisVsh6S60ah8+FzY/0LY++cJdKYZx9i2sXhrMP2NtU5tgnOGNyM87XWKnaXXRXjj/ybCUEPU0eqMpRbjFnn2/8WDWRdYWjv1gIdR04ppDue0stAtxlDDmSPldZBO5qCAyMv0NQRM+swMRJKuhqrNatVrV6H7HA9fHBkUpcnQPGjjUEBhGJNgFrgoPvqSraid+C619X51vtooWGK1ob1f+7o9iBCoI7WgQxttcTJqhmeeVH7Om+o5eo/4vLHlMCPP16z87tilhDCGxxiaocaCj37P+zKyJT1K0Pq4v9SgiCA5UQNPlCCKSEl66Ax8+Gz/6oipacA2Cnj6ocZWchSJmh/Ku7X1IuDlf9UILClYnbG4sgb5sKTE67Fs75mTKnD77X888x2Ph/asKaerXr133ZahjUD8yY4IzVqeGKMuIHnghBfRmUHe7Zudsncyefb9xYtQrtqjlY0V7lejB+2MlTbXGiNrUKPvAuzLje7u/uivR5arIziri6EwJXq/iuSLTVBpQcULdl2arbqzshADXROqeQGn2GHAlPAKSKMTWchilXqudHL1bZP6c8FGhj1R/jLAQj7LUEjtah8Z1KDym3UMIEVSMAaoy3fwFjL+z+vO4wOp4a4mm40vosBL6vLvYrIQgJUF+3udUHrqET61VzK2lVK+7nlnZe2Rg/Kme/tOFz3fh3VTwy9qLOny+Esgp6IwRZbyjze8JKGHexmrQ2/bN3NQk5W1Q5/zk/65yuaOCuyMsVPbVM2prVrlvGj9+5bsEQgthuYkZjl6psk53P9+z8RVkqj99IsTSIHwtI120IDIr32q0BUAuCtiYVF9j9klqBn3WbZ+NIn6tujR44RpDUGUMgeuIWAuXXFia7qyfXtiXoyC6EIHFC58whlxaB7fHWJ1SwdozD5Js2W63yazzojOqufiI6XYlEY6Wy3gyLIW60+n0V7lLxoa6Cwr0hNEa1PTFqCfJ3qDoh52ulp/RDdbFfCUFYgJr4fOIa2vRP5cu780u4+7gquz/wXscUxeJ96kI0sk0MYkepH0RtkYoNuJtgQ2PVfqc9oa1FrTQnrFT+U5MJFv5U+bmdMxxArVqPrnP9WVLCut+pFe38H7k/Z0SC8ls7bsTtirxv4O9jYNMjHn8dtQqU9h93UJhyexh+5faMopGu3m1nWKqyaHb9x32PHFcU7VUrSeegnREgdeceamtWk6qjJWEsCIr2qq6iI8+xp252R/I0NckU7nJdQ2AQGKIKwJxX5d0RGKLqLYyAce4WdX3HdCGwCROVxWtMhFJ27DNkYDwuzlI9dRz/lkZ8xIiXdIU7t1hUuupEalhvhkVgtv329r5mqx52E2DvLUKotieGayj/G9etQnpKP1QX+48QHHiP89ZfxViR733XUOEeNanO/6Hy7YdGqwKWxgq1QjIo2a8mEef2uyaT3efcVZvcsNieWwTH1imTfprDxiHTrlU/6q1O22tKCe/+AF65Cna7CCgf+kBd3Iv/u2t/s7Pf3hV52+Glb6tV29f/6Fxd7Q5Xrh/HPRAqT6rHnpTzn/0TJVg7nvXs3KAmL1c54Ub6prvModJDqkWI43vjx6sf+OZH1Op2jofWAKhryMj/d3aNOHPZo3D+PZ5/toFj5lDuVtWyo6u0VkPEjFYTTdWq8M5Y0Ro41jMYbiGD5CnKBeqpEJiD7MFUA8M6MtpwOF4riRPVuMzBvmlFHpOphLCtWV0rfXULgZoffFxU5j9CEBxJcHM5Hwb9hsj9L3m3VcPmR5XP/Kxb7c8ZF1muQwVr8X736YppswCheqa7Iyyu58HirDeUX3qUQ357QLBKUTz2mdpruH18+9QPPzxBtSQ++L79NUurin0kTIDpbvrOG7SndLrJ/sjdpuIpRkOvnmQyGR07HSe/iMSOMQJP+7YnTVZuiW1P2n37lTnw5s0dK3cNaouVee4cHwAVLI1MgXIHIWhtVD7zsiPKJw0ds40CglS2TfE+9UM3Ok56iuEechcfMBhzoesxd0fiJDWplR1R8YjuJs54I3PIFicw3G7D53Q8zrg+QmNVhbUjATd2kkgAACAASURBVMEqdpLviRDkqtW/c5aPkUJ60rZfteO1YojVSBfVw94gdpQaV+GerluF9BQfF5X5jxCMuYBDl61hu3UCmVt/C29+1zsdKCtPKdfLWbd0NM9jR6kft9HKoL5cpX85B4oNFv4Mbv5QuSzc0VOLoKECDn+i+tM4m6czblDxjKw37M9lvaH85revVylvq25TIrfu9/DCSuXLvvCP3Zu6XfUbqj+tLI6IRLjlY5h8hZootvzLs+rSyhy1mnNcBYYn2NNVeyIEAGf/VInI3tdUCu8zF6pA+us3dhRJUPEBcF8lGjemo2vorVvh8Xnw2Bz4/I/q+nB2rRjXw6ybOzfI6w6jnqA7N1hvSZwISFVBDsoi6IrgCCVKZYfU9f7VQyom5fy+oAi1OJlypevNadJmq/+L7q4HdxXVxnMFO5Xf3vF3aQSMvR0fMIi19TQykjH6mjpqoIXAe5iHJXNz6z0cm/QT5eYwVmmecGqTa/fFlsdVUG3eDzs+L4TKsMixBdmMNMEkN4GjsFjXvXE6HBOnXClG3KG2pGsxy3pD+UJnfbfza3GjIX2+2v5QSvWj27dKBVGj0+HGt9Tqf+1v1Xdsa4JF99o3d+mKrjpM7ntTpXde86ISPSHUZFx5Sv2fdEVTjeojFO20CjSC05ZWlS3SEyHIPE9lbX35V3h+paoYvvpFVW266taOefSGz9mdmMeNUbUEUirROLJG/e2vfBaueFo1KHNevY6Yp3z9van2Tp+nJlVP2hv3BiPIuecVZfG6+96OJExUFsGGB1RjxYv+2PkYIeCO9XDRfa4/I2226hDbXUaXOyEIi1N/U2trZ5HMOBemXdfRVepNDKHf/7aKzUR10SqkJ0Qm+7SOYEhUFntKSKAZiYmDY25jzMlXIOt1GLe0+zee3KgKXRbdqzbGNmipV9W6U69y/R8+8my1MqjKtTcY68uPNjRWreKrclQP+T2vqCyFzHPVCmfmTfb6A2lbyaXNdn/OGTfAhz9VVcvN1epCM34godHw/c+Uzz12dM9Wq2G2VEXnojIpYddLKoDmOKYJK5UFtekRmHS5az90+TF4/XrVPfKyxzq+Fp6gLKXKU+rv0xMhEEIFz1d9T630b3hT/egsrfDO99U+A8v/Vx1bvFf9LdxVicaPVfGYhgoV9wiKhIv+ZN9Q3hWzboaJl/Y8vRPU4uHnB1SigS+IzVTWV1OVCqw699ZxReIElT1Xlq3qTIxCM2e6cmc5BozdbRHZ0qDE312Ppeh0FZ9zvhZChsEVT3b3LXqPka1WV6JqI7yFj6uL/coiaC8os5iVuyT74+43tJZSuUZArbAdYwvZH6uVi6sVNzi0MtiiUkcjknv3gzcwisqeOh/2vq6skMmXqdXnx7+AT+61H5u3zf5jdMfkb6uV056XYe8bSlTGLbe/Hhii3AM9dVkEBKlMFmeLoGiPaurl3ELBZIYF/6UyYBz77Bsc/QyeXqwm++++r3LtHYlIBKQSNOj53q6Tr1ACcMtqe2Bz2tUw9w7Y+pjqUPn8CtXgrCtfe5yt59DRT9UCYM73uhYBUN+9L9dEaHTvK2G7w2S2T+RdpY06kjBRBcUDw9TCqTfEjlbXotGJ1RXtqaNu3GJGnKC7QLq3iUxV4gmdYyN9wcfVxX4lBEYdQVOrVa1825rsm1S74+B7yl+Zeb7KETcmG1DCEDVCuVhckThJXdA5m1Qlrju3kKcMsxUiRaaq1frFD8Clj6puiPN+qLJfjAKjnS+qFenkK9x/XsgwmHSp6n106EMlKt5abUS4KCrb/bJyvRjNvRyZcYOKqXzwk46WRM4WeP0G9YO+Y4Nr95kxkebbArw9FQIhlMvLOdNo6V9Ummx4onL/JU7sOlBupJCu/Z3KBpr/456NYzBiXLNdFZI5Ylh65/ysZ72NHDGZVPJEV5lDhhC4m+iNFts+3PDdJSaT/Zzeig+Az6uL/UsIHCuLh89R/2GOwVJnLK3w+X1qQr/6BaX0Rs+eulIVY5h2tfsVmcmsfMCnvlL+zt40OHMk41y1Ir7zy46tg4WAJb9VovTBT9TYDryjxtZdGuWMG5RbqLXeu35T5/bQrY2qzcXES12vkgND4dpXVEDs1atVDULZEXjtOmXmf/cD9+4EI101/xt7gzFvEBAEy++Hm1bBLR8p8e3KlRg9UglAQ7myeiKT3B97ppBxrhLo7vofGSRPUZv1nPPzvp03bbbaD8GIy7U2dWzZ3V1rDSOFtL+FAJR7SJj7tgeBMz6uLvZTIbCqyXPatXDiy87ZIQY7X1BWwIX/o/yx45apIJClTd1KK0y9puuTjjxbfYalpfddDQ2EUE2xnPsQgZrwL3lI+UVfvFRZO125hQwyzlNmdFR6512Z+kKE04Yxhz5SgtNVZ830OXD18yoo+8aN8Iotq+TGVV23JzaylIr3q4nBE1+2LzAHqFiHMKu4w1Bg5o3wi2x7k0RPSJ/T9/+DtNlqR77iLBV8fnwePHuRPVGiKlctzNxVTCdPU6Kc4GGBnjeZfh2c/V+etQrxFB9XF/tVsNhsEgSZTfbK4mnXqmyR/atUcZGlDfK2qsyPypPKlTHyHPt+vNOuUZktJzdA1pvqYuuuEtRxcu2ra6g7xl6kqmX3vaUyYTzZDMNkUhk8xn1vEZ7YsY5g90tqks7oJjNq/MVwycMqiB0Yplbi3bWLMFwQ0tJ15Wt/MPsWlUQwECtRX+GrGERXGBbvln+pxVpbk1pM5W6GjHNsGUMuaggMxi6FX2b3Lf7SWyZ/W/3zJmFxcPeJnu/X4CF+JQQAwYEme2Vx3Gjlx9v9spq09r5mV1xzkCpHv/iv9iyWsUuVz//Lv6nA5tK/dH/C1JnKLy6t9g1MfMnyB1SB0sK7PH+Pp2Z/T4hIsLmcmuDwajj5JSz6b88mldk3Kwtn2HDPxhYSrVZ/1taBn4AXdNF6Q+M5kcnq///Qh8qSvuo5eHoJ7HnNJgQ5XddPCDEwIuArhOjZPg09xO+EICTQTHObQ6HKtGthzd3KChi3TLWhTZ2h+r07m7cBwSq4uvslFTx0Lo93RUCQCrQ117ounvE24fHw422+P0+347CZ7J/co1xs6fNh3p2ev9+Tv62BEMo9VFs48EKg8R5zb1cFesv/qhYGky9T/btW/E1ZBL3dEF7TCb8TgtBAM40tDkIw+xZVfZh5bueeKK6Ydo0Sgszz7Vk83XHF0yqlzp8wisp2vgAzboRL/uE6tuEtwuO1EAw1zvlZx8fTb1DW+97XVSpxd601NB7jd0IQEmhSwWKDgCCVXeMpI89RF+SMbvrtONLbNLozmYTxqtDpvLtV/KWrZmXewBAeLQRDlxELlDvoq4fUYy0EXsMPhcBMU5sHPW3cYTLBt5/w3oCGKrGj4J6c/gs0GplD/V1ApOk/TCa1ANtwv3qsRd9r+FX6KCgh6OAa0viO/sw2GbFAZSQFR/bfOTX9z/Tr7Pe1ReA1/FIImtoGcPN6jW+YfbNKNdUMbWIyYORC1Rol3A9drj7C/1xDASZKB2rzeo1G03cu/quq1Pd13MmP8DshCA0y+2arSo1G0z8kT/Vd620/xf9cQwFm729VqdFoNGcw/icEzumjGo1G4+f4nxBo15BGo9F0wP+EIMBMS5sVq9WLm9drNBrNGYz/CYGtFXWzTiHVaDQawA+FIDRQfWXtHtJoNBqF3wlBh13KNBqNRqOFQKPRaPwdnwmBECJECLFdCLFXCHFACPFHF8eMEEKsF0LsFkJkCSFW+Go8Bh22q9RoNBqNTy2CZmCJlHI6MANYLoSY73TMb4E3pZQzgeuAx304HkDVEYCOEWg0Go2Bz1pMSCklUGd7GGj755yzKYFhtvtRQKGvxmPQnjWkhUCj0WgAH8cIhBBmIcQeoBRYJ6V03kPxf4CbhBD5wGrgJ24+5w4hxA4hxI6ysrI+jSnUcA31ZU8CjUajGUL4VAiklBYp5QxgODBXCDHF6ZDrgReklMOBFcBLQohOY5JSPiWlPEtKeVZCQt9azxoWQWOLjhFoNBoN9FPWkJSyCtgALHd66TbgTdsxW4AQIN6XYzFiBDprSKPRaBS+zBpKEEJE2+6HAhcC2U6H5QIX2I6ZiBKCvvl+ukG7hjQajaYjvtyPIAV4UQhhRgnOm1LKj4QQ9wE7pJQfAL8EnhZC/BwVOL7FFmT2GcHtriEtBBqNRgO+zRrKAma6eP73DvcPAgt9NQZXGK4h3WtIo9FoFH5XWRxkNmESOkag0Wg0Bn4nBEIIQgLN2jWk0Wg0NvxOCEClkOpgsUaj0Sj8UwgC9HaVGo1GY+CfQqC3q9RoNJp2/FMIAsy615BGo9HY8E8hCNSuIY1GozHwSyEI1a4hjUajaccvhSAkwKzrCDQajcaGfwpBoBYCjUajMfBjIdAxAo1GowG/FQKTtgg0Go3Ghp8KgXYNaTQajYFfCkFooJmmNis+7nit0Wg0ZwR+KQQhgSYsVkmrRQuBRqPR+KkQ6F3KNBqNxsC/hUDHCTQajcY/hWBYaCAAVQ2tAzwSjUajGXj8UghSo0IAKKxqHOCRaDQazcDjn0IQHQpAYVXTAI9Eo9FoBh6/FILEyGDMJkFRtbYINBqNxi+FIMBsIikymALtGtJoNBrPhEAIcZcQYphQPCuE2CWEWOrrwfmS1OhQHSPQaDQaPLcIvielrAGWAgnArcADPhtVP6CEQMcINBqNxlMhELbbFcDzUsq9Ds+dkaRGh1Jc3YTVqquLNRqNf+OpEOwUQqxFCcGnQohI4Izu45wWHUKLxUp5ffNAD0Wj0WgGlAAPj7sNmAGckFI2CCFiUe6hM5aUKHsKaWJkyACPRqPRaAYOTy2CBcBhKWWVEOIm4LdAte+G5XuMWoIiHTDWaDR+jqdC8ATQIISYDvw/IAf4j89G1Q+k2YRAp5BqNBp/x1MhaJOqef9lwD+llP8EIn03LN8zLDSA8CCzzhzSaDR+j6cxglohxL3Ad4BzhRBmINB3w/I9QghSdC2BRqPReGwRXAs0o+oJioE04EGfjaqfSI0O1W0mNBqN3+ORENgm/1eAKCHEJUCTlPKMjhGASiEt0K4hjUbj53jaYuIaYDtwNXANsE0IcZUvB9YfpEaFUl7XrDeo0Wg0fo2nMYLfAHOklKUAQogE4DNgla8G1h+k2DKHiqubyIgPH+DRaDQazcDgaYzAZIiAjdM9eO+gJTXatkGNjhNoNBo/xlOL4BMhxKfAa7bH1wKrfTOk/iNNb1Cj0Wg0ngmBlPJuIcSVwEJUs7mnpJTv+nRk/UCy3rJSo9FoPLYIkFK+Dbztw7H0O8EBZuIjgrUQaDQav6ZLIRBC1AKu+jQLQEoph3Xx3hBgIxBsO88qKeUfXBx3DfA/tvPslVLe4PHovUBadAiF1do1pNFo/JcuhUBK2Zc2Es3AEillnRAiEPhaCLFGSrnVOEAIMRa4F1gopawUQiT24Xy9IjU6lKOldf19Wo1Goxk0+CzzRyqMGTbQ9s/ZurgdeExKWWl7Tyn9jLFlpWqlpNFoNP6HT1NAhRBmIcQeoBRYJ6Xc5nTIOGCcEGKTEGKrEGK5m8+5QwixQwixo6yszKtjTIkKoaHFQnVjq1c/V6PRaM4UfCoEUkqLlHIGMByYK4SY4nRIADAWWARcDzwjhIh28TlPSSnPklKelZCQ4NUxGimk+ZU6YKzRaPyTfikKk1JWARsA5xV/PvC+lLJVSnkSOIwShn7DqCg+WV7fn6fVaDSaQYPPhEAIkWCs7oUQocCFQLbTYe8Bi23HxKNcRSd8NSZXZGoh0Gg0fo7HdQS9IAV40bZ3gQl4U0r5kRDiPmCHlPID4FNgqRDiIGAB7pZSnvbhmDoREmgmLTqUE2U6c0ij0fgnPhMCKWUWMNPF8793uC+BX9j+DRijEsI5oS0CjUbjp5zxjeO8waj4cE6U1esUUo1G45doIQBGJURQ19xGWV3zQA9Fo9Fo+h0tBNgDxifKtHtIo/EXqhtbWf7wRj7OKhrooQw4WghQMQLQQqDR+BN786rILq7l52/sYcvxfs1RGXRoIUBtWRkcYNKZQxqNH3G4uBZQG1Td8dKO9sf+iBYCwGQSZMbrzCGNxp/ILq4lPiKYV26fT1iQmVue305JjX92ItZCYGNUQrguKtNo/IjDJTVMSI4kLTqU52+ZS3ldM8981a/1rIMGLQQ2RsVHkFvRQEubdaCHotFofIzFKjlaUsf4ZNVpf1LqMM4ZE8+a/cV+mUauhcBGZnw4Fqskt6JhoIei0Wh8zKnT9TS3WduFAODiKSnkVzZyoLCmT59d29RK8Rm22ZUWAhv2zCEdMNZohjpGYHiCgxBcNCkJs0mwel/f0knvX5PNJY9+fUZ5F7QQ2BiVEAHo5nMajT+QXVyLEDA20S4EMeFBzB8VyycO7qE2i5U7X9rBD1/eycYjZVit3buNDhTWUF7XzMYj3t07xZdoIbARFRpIfESQriXQaPyAw8U1ZMaFExpk7vD88ikpnCiv50iJ8gy8sPkUnx4o4euj5Xz3ue2c//f1fHawxO3nSik5Ydv69t09Bb77Al5GC4EDKoVUu4Y0mqHO4eLaDvEBg2WTkxAC1uwvIr+ygf9be4QLJiSy43cX8sj1M2lssfDq9ly3n1tW10xtcxuRIQF8drCE2qYzY+dDLQQOjIqP0BaBRjPEaWhpI6eiwaUQJEaGcNbIGNbsK+b37x9ACLjv8ikEB5i5dHoqk1OjKO+iJ9nxUjV/3H7uKJrbrHyyv9hn38ObaCFwYFRCOKfrW6huODNUXKPR9JyjJXVI2TFQ7MjFU1I4XFLLF9ml/HLp+PbtbAHiI4Ipr+1CCGzJJlfOHs7IuDDeO0PcQ1oIHDCazx3TmUMazZDFyBganzzM5evLpyQDMDUtilvOzujwWnxkEOV1LW5rDY6X1REWZCZlWAiXz0hj8/HTZ0QqqRYCB2aOiEEI+PIMivZrNJqekV1cS0igiRGxYS5fT40O5dHrZ/L4jbMwm0SH1xIigmmxWKlpbHP53uNl9YxKCMdkElw+Mw0p4YO9g98q0ELgQEJkMHMzYvlkv25Lq9EMVQ6X1DAuKbLTJO/It6anku5CKBIigwHc7l1yoqyO0bZU9Mz4cGakR/POLi0EZxwXT0nmSEkdx0q1e0ijGYocLq5lfJLr+EB3xEfYhMBFnKCxxUJBVWO7EABcMSuN7OJaDvaxWtnXaCFwYvmUFABtFWg0Q5DyumbK61pcZgx5gmERuMocOllej5T2LgUA35qWSqBZ8M6u/N4NuJ/QQuBEclQIs0ZEs+YMSfvSaDSeY3QOGJMY0c2RrjEsAldCYGQMOVoEMeFBLJmQyHt7CmmzDN6WE1oIXHDxlBQOFNaQe1o3oNNohhLGfgPJUSG9en90aCBmk3DpGjpeVocQ9uxDgytnDVctJ44O3iQULQQuMNLH1mj3kEYzpCitURN4YmTvhMBkEsRHBLmxCOoZHhNKSGDHthWLxicSGx7E2zsHb9BYC4EL0mPDmJoWpd1DGs0Qo7S2mUCzICYssNefER8RTHldS6fnHTOGHAkKMHHp9FTWHSwZtMWqWgjccPHUZPbkVVFY1TjQQ9FoNF6itLaJhIhghHCfOtod8RHBnVxDVqvkRFm9SyEAuGr2cFosVj7MKuz1eX2JFgI3rJyagtkk+Nsn2X65Y5FGMxQprWkmcVjv3EIGCZHBnVxDRTVNNLZa3ArB5NRhjEuK4NVtuewvqKa5zdKnMXgbLQRuGBkXzs8uGMt7ewp5+wwoCNFoNN1TWttEoi0FtLco11BzhwXi8VIjYyjc5XuEEHxvYSYHi2q45NGvmfKHT/nuc9tpbBkcgqCFoAt+tHgM80fF8vv39+udyzSaIUBpbTOJw/oqBEG0WiTVjXZ/v5E6OsqNRQBw3dwRfHn3Iv51w0yuPiudjUfK+PJIaZ/G4i20EHSB2SR4+NqZBAeY+MlruwedOafRaDynuc1CVUNrrzOGDFwVlZ0oq2dYSADxEUFdvndkXDiXTEvlvksnEx0WyKcH3G9y059oIeiG5KgQHrxqOgcKa3hpS85AD0ej0fQSI8DbV9dQQnubCXvm0OGSWsYkRngchA4wm7hgQhKfHyqhdRAUmmkh8IALJyUxPT1axwo0mjOYUkMI+uoacmo8J6XkUFENE1Nct7V2x7LJSdQ0tbHtREWfxuMNtBB4yBUz0zhUVMOhosHdPEqj0bimr8VkBoZFYGxQU1DVSG1TG5NSeyYE541LIDTQzKcHBr5eSQuBh3xreioBJsG7u7VVoNGciZTWqvYSfbUIokIDCTCJdovA6CzaU4sgJNDMeePiWXewBKt1YFPUtRB4SGx4EIvGJ/Le7gIsA/yfptFoek5pTTMmAXHhfRMCk0kQFxHUbhEcKqpFCPdbX3bFssnJFNc0kVVQ3eVxVqvkma9O+Kw9vhaCHnDlrDRKa5vZdKx8oIei0Wi6YG9eFSsf+apDimdpbRPxEcFdbkjjKY5FZYeKasiMCycsKKDHn7NkQiJmk2BtN+6hnIoG/vzxIXbm+CaeoIWgByyZmMiwkIBB31tco/F31h4s5kBhDXvyqtqf80YNgUF8RLDdNdSLQLFBdFgQ80fFdhsn2GezGKamRffqPN2hhaAHBAeYuWR6Kp8eKKG+2fWepRqNZuDZm6cmTsfkjtKa5j4Hig3iI4Ipr22htqmV3IoGJqb0bqMbUO6h42X17Mt37x7al19FcICJsUm920ehO7QQ9JArZqbR2GrRVoFGM0ixWiVZ+coS6CAEtc19riEwSIgM5nR9M4eKagF6nDHkyGUz0ogOC+SBTw657WuWlV/NxJRhBJp9M2X7TAiEECFCiO1CiL1CiANCiD92cexVQggphDjLV+PxFrNHxjA3I5Y/f3yog9mp0WgGB6dO11PT1IbZJNqFoM1i5XS994QgPiKYVotk64nTQM8zhhyJCg3krgvGsunYaTYc6bx5jdUq2V9QzbThUb0+R3f40iJoBpZIKacDM4DlQoj5zgcJISKBnwLbfDgWryGE4ImbZpEQGczt/9lBUbVuU63RDCaybC6WxeMTOV5WT1OrhdP1LUgJCX3sPGpgtJLYeKSM6LBAkvv4uTfOG0lGXBj/+/GhTltaniivp77FwtS0M1AIpMLIdQq0/XNl9/wJ+BvQ5KuxeJu4iGCevXkOjS0WbnthB1UNnTep0Gg0A8Pe/CpCA81cOiMVi1VyrLSufYvKJC+6hgB251UxKWVYn/Y3ALV5za8vnsjR0jre3NHR7byvQHkepg33TaAYfBwjEEKYhRB7gFJgnZRym9PrM4F0KeVHvhyHLxifHMmj188ku7iGGfetY+Z9a7nk0a/4cO/g3HhCo/EX9uZVMSVtGFNsfvuDRTX2qmIvWQRGdbHFKvvkFnJk2eQk5mTE8NC6w9Q5JKPsy68hNNDstsW1N/CpEEgpLVLKGcBwYK4QYorxmhDCBPwD+GV3nyOEuEMIsUMIsaOsbPBsAL14QiJv3rmAe5ZPYMXUFE7XtfDY+mMDPSyNxm9ptVg5UFjD9OHRjIwLJzTQzKGiGnufIS/GCAy8JQRCCO5dMZHyuhbe2pHX/vy+giompQ4jwEeBYuinrCEpZRWwAVju8HQkMAXYIIQ4BcwHPnAVMJZSPiWlPEtKeVZCQkI/jNhzzsqI5YeLRvOXb0/l1oUZZBfXUqC3t9RoBoTDxbU0t1mZlh6N2SQYnxxpEwLlGnKcwPtCVGgggWblDprkJSEAmDUihpkjonlpSw5Wq8RilewvqPFpfAB8mzWUIISItt0PBS4Eso3XpZTVUsp4KWWGlDID2ApcKqXc4asx+ZolE5IA+CJ7cGw2odH4G0ageIbNnz4xZRiHimoprW0mNjyIoADvTHkmkyAuPJhAs2BMondz+29ekMGJ8nq+PlbO8bI6GlstPs0YAt9aBCnAeiFEFvANKkbwkRDiPiHEpT4874AxOiGcjLgwPj80ODab0Gj8jaz8KmLCAkmPDQVgUkok1Y2tZOVXec0tZJAQGczohAiviYvBxVOTiY8I4j9bTrULm6+FoOfNMTxESpkFzHTx/O/dHL/IV2PpL4QQLJmQxMvbcmhoaetV7xGNRtN79uRVMW14dHsWj+G/319Qw7lj4716rruXjcfUx2whVwQHmLl+7gj+tf4YVgnhQWYy431TUWygK4u9zAUTE2lps7Lp2OmBHopGM2Sobmzlq6NlrNqZz+MbjvHOrvxOVbgNLW0cLa1jusPqeYKD/z7JSxlDBueNS+AcL4uLwQ3zRmASgi+yS5mcGuWVRnldoZesXmZORiyRwQF8fqiEiyYlDfRwNJozmjaLlde25/L3tUc6dBIFlSb6h29NxmSbJA8U1mCxSqan2/PtI4IDGBEbRm5Fg9ddQ74kJSqUZZOTWL2vmKk+dguBFgKvExRg4rxxCXyRXYrVKtsvUo1G0zOy8qv4f6uyyC6uZcGoOH60eDTpMWEkRAbzj3VHeObrk1Q1tnL/FVN5d3cBj68/ToBJdBACgIkpkWecEADccnYmq/cVM3tkjM/PpYXAByyZkMjH+4o4UFjTL2qu0Qw1LFbJj1/dRWub5IkbZ7F8SnKH6t3frJxITHgQD356mE8PFNPUamVGejR/u2papxTRiSnD+PRAideKyfqLuZmxrP35eYxJ8G18ALQQ+IRF4xMQAj47VKKFQKPpBZ8fKiGvopHHb5zFxVNTOr0uhODHi8cQHxHEmv3F3Lowk/PGxrts9TDdlkqaHhPm83F7m3FJvW9v3RN0sNgHxEUEc/boOJ7+6gS7cisHejiaQcBHWYX87r39Az2MM4bnN50iLTqUpd3E2a6dM4IXbp3L+eMS3Pb7WTQ+gbd/eLZelHWBFgIf8Y9rZpAQGcwtz23nQGHX+5H2BiklhbqCudc0t1l4cfMpmlot/XK+V7bm8tLWnE4BT0c2HStnwf2fU1Hv300MDxXVlm9oQQAAGMRJREFUsOXEab6zYKRX2ioIIfrFz34mo4XARyQOC+GV788jIjiA7zzbvRjUNLWy/WQFJTVNbjenADhaUsvfPz3M+Q9u4OwHvmDVTr1BTm/48nAZf/jgAK9vz/X5udosVvbaNkrpag+Lt3bkUVTdxJ4831mRd7+1l9te+GZQ77D3wqZThASauG5O+kAPxW/QMQIfMjwmjJe/P49rntzKyke+JiUqRG1skxnLglFxjEmMoL7FwgubTvLUxhPUNKkfZ0RwAOOTI7loUhIrpqSQGh3C2oMlPL/pJN+cqsQkYOGYeEIDzfztk2xWTE3WxWsOlNY2sTu3imWTk90ec7K8HoD/bMnhuwsyfJrdlV1cS0OLsjx251Zy/rjO/bJaLdb21iQHCmra25V4k+rGVt7dXUCbVXLL89t5/ta5RAR3fd20WqxU1Ld4PQffHRX1Lby3p4ArZw8nOiyoX86p0ULgc0YlRPDhTxby6f5iduRUsjOnko+yigDVAMtitVLZ0MqFExO5+qx0SmqaOF5ax67cKh5Yk80Da7KJDAmgtqmN9NhQfrNiIpfPTCMhMpidORVc+cQWnt54krsuHDvA33Tw8MxXSlj3/P4it5OJIQRGT5fzXEzO3sKIE8WFB7E717VFsP1kRftC4EBhjctj+sqGw6W0WSV3njeKZ74+yXef3cYL35vLsJBAt+95auMJ/vXFMbbcu6RfJubXtufS3Gbl1rMzfH4ujR0tBP1ASlQotyzM5JaFmUgpyatoZMuJcrYcP02Lxcod541mRnrnTSfyKhpYs7+Ig4U1rJiawgUTkzpUGM4eGcuKqck8ufE4189NP+PS43yFsQn4sdI6zsqIdXnMifJ6pqdHk1/RwH+2nPKtEORUkhgZzJIJiazeV+SyvmTdwRJCAk2cPTqeA0XejykBrD1QQnxEMPcsn8DMEdH816u7uemZbbxw61xiw11P8qv3FdHYamHdwRKuPsu3rprK+hae/fok546NZ2w/ZctoFDpG0M8IIRgRF8a1c0bw8HUzefzG2S5FACA9Now7zhvNw9fNZOnkZJdl5vcsn0CrxcpD6474euhnBFJK9tviMUdL69wed7K8nglJkVw/dwSfZ5eSV9HgszHtzK1k9sgYZo2IoaapjRM2a8RxzGsPFHPOmARmj4whr6Kxy6CyO8rrmjttc2jQ3GZhw+FSLpqUiMkkWD4lhSe/M5vs4lqufXILxdWdNwgsrGpst04+2V/c4/H0lPvXHKKmsZXfrJzo83NpOqKF4AxnZFw4312QwZs78to36vZncisaqLW5WI65EYLaplbKapvJTAjnxvmqp8tLW3N8Mp7S2ibyKhqZPVL1mQcVJ3DkQGENhdVNLJ2cxGRjV60euoeqG1tZ/OAGbnxmGw0tnQPBm4+fpr7FwtJJ9rjJBROTePHWuRRVN3HlE5s55SRQRhfdxeMT+OpoObVNPRcnT9l64jRv7sjn++eOYkKy9/r7azxDC8EQ4CdLxhATFsT/W5VFq5sVob+wv0BNoKGBZrcWwalytfrPjA9v7+nyxjd5NLZ4P5V0V46KCcwcEcPohAgiQwLY7ZQ5tPZgCSYBF0xIZHKqynXvacrxmn1F1Da3se1kBbc+/00nMVh7oITwIDMLRsd1eH7B6DhevX0eDS1tfOe5bTS32f8G6w6VMio+nB8vHkOLQzDb2zS3WfjNu/sYHhPKXRfoWNdAoIVgCBAdFsSfLp/CvoJqnvzyePvzUko+2V/EM1+d4IVNJ3lpa47bVfJQYX9hNQEmwZIJiRwrqXV5zIly9TfIjFd7wN5ydibVja08t+mk18ezK7eSILOJKWnDMJkEM9Kj2ZXT0SJYd7CE2SNjiIsIJiEymMTI4B5bBO/uLmBUQjj/vG4G35zqKAZWq+SzQyWcPz6BkEBzp/dOGx7Nw9fNJK+ikTe/UVsk1ja1suV4ORdOSmLWiBgSI4N95h568ssTHC+r50+XTyE0qPP4NL5HB4uHCCumpnDJtBT++flRLpiYRHpsGPe8ncXHtgwlgwCT4LZzMvnpBWMJCzKz9UQFr3+TS0pUKPcsH++2OvNMYX9BNeOSIpmUOoyP9xVR29RKpFNWzMnyeoSAEbGq5cDcTBV0/+fnR1k2OdmrO07tyqlk6vAoggPUBDdzRAz/+uIodc1tRAQHkFfRwKGiGn6zwu4Xn5w6rEeZQwVVjWw7WcEvLhrHZTPSAPj5G3u47F+b+PvV07FISVltcwe3kDPnjY1nTkYMj35xjKvPSuero+W0WiQXTkzCZBIsm5zMqp35NLZYvDpZN7VaeGrjCZZPTmbx+ESvfa6mZ2ghGELcd9kUtp44zc/f2EOrxcrJ8nruWT6BG+aOwCIl9c1tPPrFUZ7ceIIP9hYSFmTmeFk9IYEmmlqtmE1w97IJA/01eo2UkgOFNVw4MZGxtsn8eFl9p2D8yfJ60qJDO6yO/+fSyWw6dppfv53Fm3cu8EpdQXObhayCam5eMLL9uVkjorFK1Vlzwag4Hlt/DKBDy/LJqVFsPFpOU6ul0wreaMu8bHJye5bYB3sKAbjcJgKXzUhrdxVe8cRmxiZGYDaJLidaIQS/XDqe657aystbczhYWENMWCCzbHGNi6ck89LWHL48UsryKZ17//SWr46WU9fcxvXzRnjtMzU9R7uGhhCx4UH8+fKpZBfXUt3Yxivfn88PF40mKiyQ2PAg0mPD+NtV03n7h2eTFh1KdFgQf796Ort/t5Tr547gsfXHefZr77tH+oui6iYq6luYkhbVnn541IV76ERZfbtbyCAxMoTfXTKJHTmVvLwth/rmNv6z5RSXPbap11uPHiisoaXN2qG9gSFKu3OreOCTbF7/Jo8fnD+aDIfxTE4dhsUqOVzceeyfZ5fyu/cPcPtLO9v9+e/tLmD2yBhGxNmbqp03LoFPf34eV85Ka2/jHBXmvl4AYP6oOBaOieOJDcf54nApiycktrd4mJsZS0xYIGv2F9NqsbK/oLp9k5j7PjzIve/sY8vx011Wxbvi46xCosMCOdspdqHpX7RFMMRYPiWZF783l4kpkSRGuq4rmD0yhlU/PLvDc3++fAqV9S386aODBJgE188d0au9WNssVnbnVbHxSBmHimq477IppEaH9uq7uOKFTSfZX6hcKTFOue/7ClSAdUpaFOkxoQSZTZ1iIlJKTpbXc+WstE6ffeWsNN7fU8D9q7P5+6eHqWlqI8hs4v412Swen9gjK6HNYmXzsXIAZo2wC0F0WBCjEsJ5auMJqhtbuXHeCO5ZPr7De+0B45pOvfVX7cwnLMjM3rwq/vTRQW6cN5LDJbX86bLJncYQFRrI366azvVzR3hcY/KLi8Zz5RObAbhoot1KCTCbWDopmXd25/PJ/mKa2+xJCWFBZkxC8Nr2XGaOiOZHi8Zw4cTEbt2MTa0WPjtUysqpKQR6oaeQpvdoIRiCuGph0B1mk+Dh62Zw24vf8IcPDvDoF0e5anY6356ZxtjECI8mwaz8Km5+bjuVDa2YBEggM/4kv1k5qRffwjXPbjpJXkUjm46V8/C1M5g3yr6SPFBQjUnAxORhBJhNjEoI7yQEZXXN1DW3dbIIQLlH/vfbU7np2W1MSYviewszya9s4K7X9/DZoRKWdtGyAlRQ9s8fH2L1viJKa5uwShgZF9ZpEp6ZHsPbu/L59sw0/nTZlE4TZnpsKJEhAZ0yh07XNbM+u5TbzskE4MmNJ9iVU0WASbByWqrbcc0c4XnDtdkjY1gyIZFNx8o51+k6+u7ZIymuaWJsYgTT0qOZkjqM5KgQwoICaGq18NaOPJ7ceILb/7ODWxdm8PtLJnUpBoZbaMU077maNL1DC4GmnZBAM//53jw2Hinjte25PP3VCf795XEiQwKYkR7NvMxYLpuRRnps577uVqvkd+8fINBs4vEbZ7FwdDz//e4+3tqZzy+XjneZrSKl5IkvjzN/VFyHVbM7iqtVTv41Zw1n+8kKrn96K79aNp4fLRoDwP7CGsYkRrQHM8ckRpCV33EyPVmmcuUz3Wz2kR4bxpd3L25/PH14FH9fe5jHNxznoklJCCGQUvLq9lziwoNYNlltmGK1Su55O4u3duazbHIS45OGkxwVytzMzt/r1oUZpEWH8JMLxroUWCEEk1I6B4zf31NIm1Vy5ezhjIoPZ29+FVtPVHDhxP/f3p0HV1VfARz/nveSkJCVLQESIASiWSGExVBaENEZoBWsQlEQGWprrbQu05mKbbWjrdNxRdsyitUitYBWBGvRKkJbGDsCkUWIIGEngQikQBAUCOT0j3uzkI1Ekrz47vnMZPLu5b73fj/Oyz3v/u5viW9wZPBX8dTkgRQd/6LOPESZPWNZ8P1h9T4nPNTP9OHJ3DKsN4++s535/91HmN/H7HFpVf9nn7jxqfwsvLO1xJqF2glLBOYifp8wOi2e0WnxHD55hjWFR9lUdIJNB07w1PuFPLmikOEpXZiW15tvZ/eo+sb3jy2H+LjoBE9OHsh4dyGRaXm9eXtrCcu3lDBpcFKd93q34DMef3cHkWF+XvnBVZdMBvn7jgFwa14fHro+k9lvbOHxd3cQHx3OpMFJFBws45v9qxcTT42P5u2tJRf1dKmcYyilniuC+oT4fdwxsh8PvlnAur3HyEvpwh/+tatqJPe3Urvy6+szeGHNHl7fUMw9Y1K577orGn3NrMRYshIbnxs/s2csi9bv50KFVo0oX7KhmAFJsVWLlfxxai4/+9vH3DmqX5Pq0lSdIsPqNLs1VYjfx0PfyeD8BWXemj0g0C2qA4vXH2D30dMMS+7M/JlD8fuEldsOMy67uzULtQOWCEyDEmLCmTykV9UcM8XHv2DZxoMs2VjMTxZtomDUSe4feyVnyit47J+fkpUYw42Dqtveh6d0oV+3SP66dn+dRFB+oYLH39tBSrdIKiqUGX9ez+If5jV6gszfd4yOYX4yejhNP3Om5HDs9Dl+sWwrsRGhHPn8LJk1np+aEIUq7D56qup195aeJszva9Z9i8mDk3h2ZSHP/Wc3nxw6ydPvF3JTbhID3KuFa59eA8Dd1/Tn3haa/C8rMYYz5RW8s7WE6wf2ZNuhk2wrOcnDE6rvBXSN6tDgN/RAEhEenpDJ+YoK5q3eAzi9pX58dT/mrd7NzJfzmXZVbz4/e77RJi3TdiwRmCZL6tSRn45JZdbo/jz0VgHPr97N6bPn6RrVgUNlZ5gzJeeipg4RYdpVfXhk+TYKDpZddJJ/Nb+IvaWnefG2IaT3jOF7z3/I9JfWsfiOvAanGMjfd5zc3p2qerKE+n3MnZrLhLkfcNfCDQBk13iPyvEAu45UJ4I9pafp06VjvfM2NSQ81M/MEX154r0drC48yris7jx2UzYhfh/js3vwzMpCenXuyI9GprTYOIzrMhIY2CuOu1/dxOGTZzh04gyhfmHCwK/HidPnEx69IZuhyZ1J7xFDeg8npmndo7nvtc1s3H/cmoXaEbsmM83m8wm/mZjFj0am8Mra/cxZWcjYzO4X3bitdNPgJMJDfSxcVz2Xz6mz53l2ZSHD+nZmTHo8iXERLPzBVYSF+Jj8/Id8sLO0zuuUfVnOp5+dZGit2UQ7RYbxwvQhhPicj3JGz+okktwlEr9P2Hmkuhvm3tK6XUeb4ta8PnSJDGPUFd145uacqmTULboDj343mztH9WvRwXjR4aG8+sM8xmZ257dvb2fBh/sYk5bwlZtsAsHnE27MTapKAuCMcZgzJYcKVcZlWbNQe2FXBOYrERFmj0sjJiKUVz7czwPj6x+IFhsRysSBiby56RCTBveiZ1w4i9YdoPTUOf50W1rVyTO5ayRL7xrB7S/nM2P+en57Qxa3DKseZLTxwHFUYWhy3fsI6T1imDd9MJuLTlx0gzMsxEdyl47sPOz0HLpQoez/32nGpDd/BGtsRCirfz6ayDB/m42+jgjzM3dqLk+s2MFz/9nN1CAZdDUxJ5GMHjEkdmq5bsXm8lgiMF+ZiDBrdH/uurrxb8PTh/fhtY+KqvqnA4zP7l6nW2NiXASv3zmcnyzaxANLt1L2ZXnVjdD8vccI8Qk5veufsnvkFd3qXVMgNT6aQndQ2cHjX1J+QZt8o7i2S63m1Rp8PuH+sWncOaofsRGNDwj7OrH1BtoXSwTmsl3qG3JWYizv3zeSff/7giOfn+HEF+VMrqcXEThNIi/NGMJPF2/iqRU7uDY9gf7xUeTvO0ZmYmyzl+RMTYhixbbPmPqntZSeOgtA364tN5dQWwmmJGDaH0sEpk2kJkQ3+VtgiN/HIxOz+O+uUh58s4D5M4fycVEZM77R59JPruW6jATW7Czl3PkKEmLCGZAUx4CkxrtuGuM1lghMu9QtugP3j0vjl8sKeGT5Ns5dqGhw2cnGDEiK4++zRrRCCY0JHnbL3rRbtwztzaDecSxadwCgTo8hY0zLsERg2q3Kvuh+n9A/PqpFp1EwxlSzpiHTrmX0jOF3N2YTHYAeO8Z4hf11mXbve+4UF8aY1mFNQ8YY43GWCIwxxuMsERhjjMdZIjDGGI+zRGCMMR5nicAYYzzOEoExxnicJQJjjPE4UdVAl6FZROQosP+SB9avK1B3+avg58V6e7HO4M16e7HO0Px691HVuot28DVMBJdDRD5S1SGBLkdb82K9vVhn8Ga9vVhnaNl6W9OQMcZ4nCUCY4zxOK8lghcCXYAA8WK9vVhn8Ga9vVhnaMF6e+oegTHGmLq8dkVgjDGmFksExhjjcZ5JBCIyVkR2iMguEZkd6PK0BhHpJSL/FpHtIvKJiNzj7u8sIu+LyE73d6dAl7WliYhfRDaJyHJ3u6+IrHPr/JqIBN06lyISJyJLRORTN+bDPRLr+9zPd4GILBaR8GCLt4j8WUSOiEhBjX31xlYcv3fPbVtEJLe57+eJRCAifmAuMA7IAG4RkYzAlqpVnAd+pqrpQB4wy63nbGCVqqYCq9ztYHMPsL3G9mPAHLfOx4HbA1Kq1vUs8K6qpgEDceof1LEWkUTgbmCIqmYBfuBmgi/eLwNja+1rKLbjgFT35w7guea+mScSATAM2KWqe1T1HPAqMDHAZWpxqlqiqhvdx5/jnBgSceq6wD1sAXBDYErYOkQkCfg28KK7LcA1wBL3kGCscwwwEngJQFXPqeoJgjzWrhAgQkRCgI5ACUEWb1VdAxyrtbuh2E4E/qKOtUCciPRozvt5JREkAkU1tovdfUFLRJKBQcA6IEFVS8BJFkB84ErWKp4Bfg5UuNtdgBOqet7dDsZ4pwBHgfluk9iLIhJJkMdaVQ8CTwIHcBJAGbCB4I83NBzbyz6/eSURSD37grbfrIhEAW8A96rqyUCXpzWJyHeAI6q6oebueg4NtniHALnAc6o6CDhNkDUD1cdtF58I9AV6ApE4TSO1BVu8G3PZn3evJIJioFeN7STgUIDK0qpEJBQnCSxU1aXu7sOVl4ru7yOBKl8rGAFMEJF9OE1+1+BcIcS5TQcQnPEuBopVdZ27vQQnMQRzrAGuBfaq6lFVLQeWAt8g+OMNDcf2ss9vXkkE+UCq27MgDOfm0lsBLlOLc9vGXwK2q+rTNf7pLWCG+3gG8Pe2LltrUdUHVDVJVZNx4vovVZ0G/BuY5B4WVHUGUNXPgCIRudLdNQbYRhDH2nUAyBORju7nvbLeQR1vV0OxfQu4ze09lAeUVTYhNZmqeuIHGA8UAruBXwa6PK1Ux2/iXBJuATa7P+Nx2sxXATvd350DXdZWqv/VwHL3cQqwHtgFvA50CHT5WqG+OcBHbrzfBDp5IdbAw8CnQAHwCtAh2OINLMa5B1KO843/9oZii9M0NNc9t23F6VHVrPezKSaMMcbjvNI0ZIwxpgGWCIwxxuMsERhjjMdZIjDGGI+zRGCMMR5nicCYNiQiV1fOkGpMe2GJwBhjPM4SgTH1EJFbRWS9iGwWkXnuegenROQpEdkoIqtEpJt7bI6IrHXngl9WY574/iKyUkQ+dp/Tz335qBrrCCx0R8gaEzCWCIypRUTSgSnACFXNAS4A03AmONuoqrnAauDX7lP+AtyvqgNwRnZW7l8IzFXVgTjz4VQO+x8E3IuzNkYKznxJxgRMyKUPMcZzxgCDgXz3y3oEzgRfFcBr7jF/BZaKSCwQp6qr3f0LgNdFJBpIVNVlAKp6BsB9vfWqWuxubwaSgQ9av1rG1M8SgTF1CbBAVR+4aKfIg7WOa2x+lsaae87WeHwB+zs0AWZNQ8bUtQqYJCLxULVWbB+cv5fKGS6nAh+oahlwXES+5e6fDqxWZx2IYhG5wX2NDiLSsU1rYUwT2TcRY2pR1W0i8itghYj4cGaAnIWz+EumiGzAWRlrivuUGcDz7ol+DzDT3T8dmCcij7ivMbkNq2FMk9nso8Y0kYicUtWoQJfDmJZmTUPGGONxdkVgjDEeZ1cExhjjcZYIjDHG4ywRGGOMx1kiMMYYj7NEYIwxHvd//SUh5r6vDMoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = np.arange(0, len(history.history['loss']))\n",
    "\n",
    "# You can chose the style of your preference\n",
    "# print(plt.style.available) to see the available options\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "plt.figure()\n",
    "plt.plot(N, history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(N, history.history['accuracy'], label = \"train_acc\")\n",
    "plt.plot(N, history.history['val_loss'], label = \"val_loss\")\n",
    "plt.plot(N, history.history['val_accuracy'], label = \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# Make sure there exists a folder called output in the current directory\n",
    "# or replace 'output' with whatever direcory you want to put in the plots\n",
    "plt.show()\n",
    "plt.savefig('../Output/EpochDenseNet121_OF.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
