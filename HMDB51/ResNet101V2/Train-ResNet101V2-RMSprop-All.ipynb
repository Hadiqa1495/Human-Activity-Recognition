{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet_v2 import ResNet101V2\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24136</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24137</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24138</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24139</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24140</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image class\n",
       "24136  winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg  wave\n",
       "24137  winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg  wave\n",
       "24138  winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg  wave\n",
       "24139  winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg  wave\n",
       "24140  winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg  wave"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_2.csv')\n",
    "train.sort_values(by=['class', 'image'])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24141/24141 [01:26<00:00, 279.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/train_frame/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24141, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X = np.array(train_image,np.float16)\n",
    "train_image=[]\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 224, 224, 3)\n",
      "(4829, 224, 224, 3)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained ResNet101V2 model\n",
    "base_model = ResNet101V2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet101v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, None, None, 6 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, None, None, 6 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, None, None, 2 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, None, None, 2 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, None, None, 2 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, None, None, 2 0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, None, None, 2 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, None, None, 5 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, None, None, 5 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, None, None, 5 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, None, None, 5 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, None, None, 5 0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, None, None, 5 0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, None, None, 1 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, None, None, 1 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, None, None, 1 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, None, None, 1 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, None, None, 1 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, None, None, 1 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, None, None, 1 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block7_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, None, None, 2 0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, None, None, 2 0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, None, None, 1 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, None, None, 1 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, None, None, 2 0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, None, None, 2 0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, None, None, 1 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, None, None, 1 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, None, None, 2 0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, None, None, 2 0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, None, None, 1 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, None, None, 1 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, None, None, 1 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, None, None, 2 0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, None, None, 2 0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block10_2_relu[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, None, None, 1 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, None, None, 1 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, None, None, 1 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, None, None, 2 0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, None, None, 2 0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, None, None, 1 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, None, None, 1 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, None, None, 1 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, None, None, 2 0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, None, None, 2 0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, None, None, 1 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, None, None, 1 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, None, None, 1 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, None, None, 2 0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, None, None, 2 0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, None, None, 1 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, None, None, 1 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, None, None, 1 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, None, None, 2 0           conv4_block14_1_bn[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, None, None, 2 0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, None, None, 1 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, None, None, 1 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, None, None, 1 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, None, None, 2 0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, None, None, 2 0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, None, None, 1 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, None, None, 1 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, None, None, 1 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, None, None, 2 0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, None, None, 2 0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, None, None, 1 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, None, None, 1 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, None, None, 1 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, None, None, 2 0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, None, None, 2 0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, None, None, 1 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, None, None, 1 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, None, None, 1 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, None, None, 2 0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, None, None, 2 0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, None, None, 1 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, None, None, 1 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, None, None, 1 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, None, None, 2 0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, None, None, 2 0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, None, None, 1 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, None, None, 1 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, None, None, 1 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, None, None, 2 0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, None, None, 2 0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, None, None, 1 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, None, None, 1 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, None, None, 1 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, None, None, 2 0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block21_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, None, None, 2 0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, None, None, 1 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, None, None, 1 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, None, None, 1 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, None, None, 2 0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, None, None, 2 0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, None, None, 1 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, None, None, 1 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, None, None, 1 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, None, None, 2 0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, None, None, 2 0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, None, None, 1 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, None, None, 1 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, None, None, 2 0           conv5_block1_0_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, None, None, 2 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, None, None, 2 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, None, None, 2 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, None, None, 2 0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 42,626,560\n",
      "Trainable params: 42,528,896\n",
      "Non-trainable params: 97,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'resnet101v2',\n",
       " 'layers': [{'name': 'input_1',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_1'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'conv1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((3, 3), (3, 3)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (7, 7),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'pool1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pool',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'pool1_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool1_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_0_conv', 0, 0, {}],\n",
       "     ['conv2_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}],\n",
       "     ['conv2_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_1',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_1', 0, 0, {}],\n",
       "     ['conv2_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_0_conv', 0, 0, {}],\n",
       "     ['conv3_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}],\n",
       "     ['conv3_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}],\n",
       "     ['conv3_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_2',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}],\n",
       "     ['conv3_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_0_conv', 0, 0, {}],\n",
       "     ['conv4_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}],\n",
       "     ['conv4_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}],\n",
       "     ['conv4_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}],\n",
       "     ['conv4_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block5_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block5_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}],\n",
       "     ['conv4_block5_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block6_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block6_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}],\n",
       "     ['conv4_block6_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block7_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block7_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}],\n",
       "     ['conv4_block7_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block8_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block8_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}],\n",
       "     ['conv4_block8_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block9_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block9_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}],\n",
       "     ['conv4_block9_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block10_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block10_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}],\n",
       "     ['conv4_block10_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block11_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block11_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}],\n",
       "     ['conv4_block11_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block12_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block12_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}],\n",
       "     ['conv4_block12_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block13_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block13_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}],\n",
       "     ['conv4_block13_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block14_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block14_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}],\n",
       "     ['conv4_block14_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block15_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block15_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}],\n",
       "     ['conv4_block15_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block16_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block16_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}],\n",
       "     ['conv4_block16_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block17_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block17_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}],\n",
       "     ['conv4_block17_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block18_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block18_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}],\n",
       "     ['conv4_block18_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block19_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block19_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}],\n",
       "     ['conv4_block19_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block20_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block20_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}],\n",
       "     ['conv4_block20_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block21_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block21_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}],\n",
       "     ['conv4_block21_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block22_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block22_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}],\n",
       "     ['conv4_block22_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block23_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_3',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block23_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_3', 0, 0, {}],\n",
       "     ['conv4_block23_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_0_conv', 0, 0, {}],\n",
       "     ['conv5_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}],\n",
       "     ['conv5_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}],\n",
       "     ['conv5_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'post_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'post_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'post_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'post_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['post_bn', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['post_relu', 0, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1=datetime.datetime.now()\n",
    "print(t1)\n",
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "print(X_train.shape)\n",
    "t2=datetime.datetime.now()\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(19312, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(X_train, '../Pickle/ResNet101V2_X_train_2.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t3=datetime.datetime.now()\n",
    "print(t3)\n",
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "print(X_test.shape)\n",
    "t4=datetime.datetime.now()\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test = X_test.reshape(4829, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib.dump(X_test, '../Pickle/ResNet101V2_X_test_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "X_train = joblib.load('../Pickle/ResNet101V2_X_train_2.pkl') \n",
    "X_test = joblib.load('../Pickle/ResNet101V2_X_test_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 100352)\n",
      "(4829, 100352)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "# shape of images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 51)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 51)                52275     \n",
      "=================================================================\n",
      "Total params: 102,813,747\n",
      "Trainable params: 102,813,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('../Models/weightResNet101V2_3.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='RMSprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-06 01:39:19.778367\n",
      "Train on 19312 samples, validate on 4829 samples\n",
      "Epoch 1/100\n",
      "19312/19312 [==============================] - ETA: 7:10 - loss: 8.2613 - accuracy: 0.03 - ETA: 4:44 - loss: 121.8340 - accuracy: 0.07 - ETA: 3:55 - loss: 157.3534 - accuracy: 0.07 - ETA: 3:30 - loss: 155.7363 - accuracy: 0.07 - ETA: 3:17 - loss: 150.7917 - accuracy: 0.07 - ETA: 3:08 - loss: 142.0922 - accuracy: 0.07 - ETA: 3:00 - loss: 130.6181 - accuracy: 0.08 - ETA: 2:53 - loss: 121.0694 - accuracy: 0.08 - ETA: 2:48 - loss: 111.8639 - accuracy: 0.09 - ETA: 2:45 - loss: 102.8757 - accuracy: 0.10 - ETA: 2:42 - loss: 95.3384 - accuracy: 0.1179 - ETA: 2:39 - loss: 88.4774 - accuracy: 0.131 - ETA: 2:37 - loss: 82.4197 - accuracy: 0.140 - ETA: 2:34 - loss: 77.0307 - accuracy: 0.146 - ETA: 2:31 - loss: 72.2770 - accuracy: 0.158 - ETA: 2:29 - loss: 68.1019 - accuracy: 0.170 - ETA: 2:26 - loss: 64.3274 - accuracy: 0.178 - ETA: 2:25 - loss: 60.9741 - accuracy: 0.182 - ETA: 2:23 - loss: 57.9688 - accuracy: 0.189 - ETA: 2:21 - loss: 55.2517 - accuracy: 0.195 - ETA: 2:20 - loss: 52.7814 - accuracy: 0.200 - ETA: 2:19 - loss: 50.5304 - accuracy: 0.204 - ETA: 2:17 - loss: 48.4895 - accuracy: 0.205 - ETA: 2:16 - loss: 46.6095 - accuracy: 0.210 - ETA: 2:14 - loss: 44.8679 - accuracy: 0.214 - ETA: 2:13 - loss: 43.2653 - accuracy: 0.216 - ETA: 2:12 - loss: 41.7822 - accuracy: 0.220 - ETA: 2:10 - loss: 40.4208 - accuracy: 0.221 - ETA: 2:09 - loss: 39.1535 - accuracy: 0.223 - ETA: 2:07 - loss: 37.9651 - accuracy: 0.226 - ETA: 2:06 - loss: 36.8457 - accuracy: 0.228 - ETA: 2:05 - loss: 35.8068 - accuracy: 0.230 - ETA: 2:03 - loss: 34.8190 - accuracy: 0.231 - ETA: 2:02 - loss: 33.9115 - accuracy: 0.233 - ETA: 2:00 - loss: 33.0261 - accuracy: 0.235 - ETA: 1:59 - loss: 32.1978 - accuracy: 0.238 - ETA: 1:58 - loss: 31.4230 - accuracy: 0.241 - ETA: 1:57 - loss: 30.6774 - accuracy: 0.242 - ETA: 1:56 - loss: 29.9794 - accuracy: 0.244 - ETA: 1:54 - loss: 29.3372 - accuracy: 0.243 - ETA: 1:53 - loss: 28.6900 - accuracy: 0.246 - ETA: 1:52 - loss: 28.0946 - accuracy: 0.247 - ETA: 1:51 - loss: 27.5223 - accuracy: 0.247 - ETA: 1:50 - loss: 26.9623 - accuracy: 0.249 - ETA: 1:48 - loss: 26.4429 - accuracy: 0.250 - ETA: 1:47 - loss: 25.9358 - accuracy: 0.251 - ETA: 1:46 - loss: 25.4651 - accuracy: 0.253 - ETA: 1:45 - loss: 25.0110 - accuracy: 0.253 - ETA: 1:44 - loss: 24.5815 - accuracy: 0.254 - ETA: 1:43 - loss: 24.1749 - accuracy: 0.253 - ETA: 1:42 - loss: 23.7821 - accuracy: 0.254 - ETA: 1:40 - loss: 23.3865 - accuracy: 0.254 - ETA: 1:39 - loss: 23.0081 - accuracy: 0.255 - ETA: 1:38 - loss: 22.6481 - accuracy: 0.256 - ETA: 1:37 - loss: 22.3007 - accuracy: 0.255 - ETA: 1:36 - loss: 21.9622 - accuracy: 0.256 - ETA: 1:35 - loss: 21.6318 - accuracy: 0.257 - ETA: 1:34 - loss: 21.3153 - accuracy: 0.258 - ETA: 1:33 - loss: 21.0048 - accuracy: 0.259 - ETA: 1:32 - loss: 20.7112 - accuracy: 0.260 - ETA: 1:31 - loss: 20.4256 - accuracy: 0.262 - ETA: 1:30 - loss: 20.1442 - accuracy: 0.263 - ETA: 1:29 - loss: 19.8715 - accuracy: 0.265 - ETA: 1:28 - loss: 19.6238 - accuracy: 0.265 - ETA: 1:27 - loss: 19.3739 - accuracy: 0.267 - ETA: 1:26 - loss: 19.1387 - accuracy: 0.268 - ETA: 1:24 - loss: 18.8965 - accuracy: 0.271 - ETA: 1:23 - loss: 18.6702 - accuracy: 0.271 - ETA: 1:22 - loss: 18.4520 - accuracy: 0.272 - ETA: 1:21 - loss: 18.2315 - accuracy: 0.273 - ETA: 1:20 - loss: 18.0237 - accuracy: 0.273 - ETA: 1:20 - loss: 17.8298 - accuracy: 0.272 - ETA: 1:19 - loss: 17.6410 - accuracy: 0.272 - ETA: 1:17 - loss: 17.4545 - accuracy: 0.272 - ETA: 1:16 - loss: 17.2689 - accuracy: 0.273 - ETA: 1:15 - loss: 17.0764 - accuracy: 0.275 - ETA: 1:14 - loss: 16.8930 - accuracy: 0.276 - ETA: 1:13 - loss: 16.7152 - accuracy: 0.277 - ETA: 1:12 - loss: 16.5472 - accuracy: 0.278 - ETA: 1:11 - loss: 16.3758 - accuracy: 0.279 - ETA: 1:10 - loss: 16.2109 - accuracy: 0.280 - ETA: 1:09 - loss: 16.0542 - accuracy: 0.280 - ETA: 1:08 - loss: 15.9013 - accuracy: 0.281 - ETA: 1:07 - loss: 15.7508 - accuracy: 0.282 - ETA: 1:06 - loss: 15.6066 - accuracy: 0.282 - ETA: 1:05 - loss: 15.4630 - accuracy: 0.284 - ETA: 1:04 - loss: 15.3178 - accuracy: 0.284 - ETA: 1:03 - loss: 15.1783 - accuracy: 0.285 - ETA: 1:02 - loss: 15.0427 - accuracy: 0.286 - ETA: 1:01 - loss: 14.9156 - accuracy: 0.286 - ETA: 1:00 - loss: 14.7847 - accuracy: 0.287 - ETA: 59s - loss: 14.6659 - accuracy: 0.286 - ETA: 58s - loss: 14.5436 - accuracy: 0.28 - ETA: 57s - loss: 14.4202 - accuracy: 0.28 - ETA: 56s - loss: 14.2999 - accuracy: 0.28 - ETA: 55s - loss: 14.1834 - accuracy: 0.28 - ETA: 54s - loss: 14.0657 - accuracy: 0.29 - ETA: 53s - loss: 13.9528 - accuracy: 0.29 - ETA: 52s - loss: 13.8430 - accuracy: 0.29 - ETA: 51s - loss: 13.7436 - accuracy: 0.29 - ETA: 50s - loss: 13.6427 - accuracy: 0.29 - ETA: 49s - loss: 13.5372 - accuracy: 0.29 - ETA: 48s - loss: 13.4460 - accuracy: 0.29 - ETA: 47s - loss: 13.3471 - accuracy: 0.29 - ETA: 46s - loss: 13.2611 - accuracy: 0.29 - ETA: 45s - loss: 13.1632 - accuracy: 0.29 - ETA: 44s - loss: 13.0716 - accuracy: 0.29 - ETA: 42s - loss: 12.9844 - accuracy: 0.29 - ETA: 41s - loss: 12.8899 - accuracy: 0.29 - ETA: 40s - loss: 12.8010 - accuracy: 0.29 - ETA: 39s - loss: 12.7109 - accuracy: 0.29 - ETA: 38s - loss: 12.6204 - accuracy: 0.30 - ETA: 37s - loss: 12.5377 - accuracy: 0.30 - ETA: 36s - loss: 12.4621 - accuracy: 0.30 - ETA: 35s - loss: 12.3827 - accuracy: 0.30 - ETA: 34s - loss: 12.3016 - accuracy: 0.30 - ETA: 33s - loss: 12.2232 - accuracy: 0.30 - ETA: 32s - loss: 12.1473 - accuracy: 0.30 - ETA: 31s - loss: 12.0669 - accuracy: 0.30 - ETA: 30s - loss: 11.9904 - accuracy: 0.30 - ETA: 29s - loss: 11.9190 - accuracy: 0.30 - ETA: 28s - loss: 11.8396 - accuracy: 0.30 - ETA: 27s - loss: 11.7694 - accuracy: 0.30 - ETA: 26s - loss: 11.6994 - accuracy: 0.30 - ETA: 25s - loss: 11.6312 - accuracy: 0.30 - ETA: 24s - loss: 11.5610 - accuracy: 0.31 - ETA: 23s - loss: 11.4951 - accuracy: 0.31 - ETA: 22s - loss: 11.4312 - accuracy: 0.31 - ETA: 21s - loss: 11.3629 - accuracy: 0.31 - ETA: 20s - loss: 11.2982 - accuracy: 0.31 - ETA: 19s - loss: 11.2359 - accuracy: 0.31 - ETA: 18s - loss: 11.1687 - accuracy: 0.31 - ETA: 17s - loss: 11.1072 - accuracy: 0.31 - ETA: 16s - loss: 11.0459 - accuracy: 0.31 - ETA: 15s - loss: 10.9844 - accuracy: 0.31 - ETA: 14s - loss: 10.9269 - accuracy: 0.31 - ETA: 13s - loss: 10.8679 - accuracy: 0.31 - ETA: 12s - loss: 10.8088 - accuracy: 0.31 - ETA: 11s - loss: 10.7514 - accuracy: 0.32 - ETA: 10s - loss: 10.6930 - accuracy: 0.32 - ETA: 9s - loss: 10.6383 - accuracy: 0.3224 - ETA: 8s - loss: 10.5882 - accuracy: 0.322 - ETA: 7s - loss: 10.5325 - accuracy: 0.324 - ETA: 6s - loss: 10.4783 - accuracy: 0.325 - ETA: 5s - loss: 10.4237 - accuracy: 0.325 - ETA: 4s - loss: 10.3758 - accuracy: 0.326 - ETA: 3s - loss: 10.3237 - accuracy: 0.327 - ETA: 2s - loss: 10.2719 - accuracy: 0.328 - ETA: 1s - loss: 10.2185 - accuracy: 0.328 - ETA: 0s - loss: 10.1688 - accuracy: 0.329 - 162s 8ms/step - loss: 10.1276 - accuracy: 0.3306 - val_loss: 2.0086 - val_accuracy: 0.5386\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:22 - loss: 2.1375 - accuracy: 0.49 - ETA: 2:23 - loss: 2.2202 - accuracy: 0.48 - ETA: 2:23 - loss: 2.2698 - accuracy: 0.47 - ETA: 2:21 - loss: 2.3906 - accuracy: 0.47 - ETA: 2:19 - loss: 2.4469 - accuracy: 0.46 - ETA: 2:18 - loss: 2.4833 - accuracy: 0.45 - ETA: 2:17 - loss: 2.5248 - accuracy: 0.47 - ETA: 2:17 - loss: 2.6043 - accuracy: 0.47 - ETA: 2:15 - loss: 2.5687 - accuracy: 0.47 - ETA: 2:15 - loss: 2.5449 - accuracy: 0.47 - ETA: 2:13 - loss: 2.5240 - accuracy: 0.47 - ETA: 2:12 - loss: 2.5289 - accuracy: 0.47 - ETA: 2:12 - loss: 2.5218 - accuracy: 0.47 - ETA: 2:11 - loss: 2.5244 - accuracy: 0.47 - ETA: 2:10 - loss: 2.5490 - accuracy: 0.47 - ETA: 2:08 - loss: 2.6068 - accuracy: 0.46 - ETA: 2:08 - loss: 2.6149 - accuracy: 0.46 - ETA: 2:07 - loss: 2.6100 - accuracy: 0.46 - ETA: 2:06 - loss: 2.5985 - accuracy: 0.46 - ETA: 2:06 - loss: 2.6044 - accuracy: 0.46 - ETA: 2:05 - loss: 2.5977 - accuracy: 0.46 - ETA: 2:04 - loss: 2.5858 - accuracy: 0.46 - ETA: 2:02 - loss: 2.5746 - accuracy: 0.46 - ETA: 2:01 - loss: 2.5703 - accuracy: 0.46 - ETA: 2:01 - loss: 2.5716 - accuracy: 0.46 - ETA: 1:59 - loss: 2.5692 - accuracy: 0.46 - ETA: 1:58 - loss: 2.5682 - accuracy: 0.46 - ETA: 1:58 - loss: 2.5719 - accuracy: 0.46 - ETA: 1:57 - loss: 2.5669 - accuracy: 0.47 - ETA: 1:56 - loss: 2.6009 - accuracy: 0.46 - ETA: 1:55 - loss: 2.5867 - accuracy: 0.47 - ETA: 1:54 - loss: 2.5972 - accuracy: 0.47 - ETA: 1:53 - loss: 2.6037 - accuracy: 0.47 - ETA: 1:52 - loss: 2.6173 - accuracy: 0.47 - ETA: 1:51 - loss: 2.6122 - accuracy: 0.47 - ETA: 1:50 - loss: 2.6045 - accuracy: 0.47 - ETA: 1:49 - loss: 2.6000 - accuracy: 0.47 - ETA: 1:48 - loss: 2.5969 - accuracy: 0.47 - ETA: 1:47 - loss: 2.5995 - accuracy: 0.47 - ETA: 1:47 - loss: 2.5936 - accuracy: 0.47 - ETA: 1:46 - loss: 2.5817 - accuracy: 0.47 - ETA: 1:45 - loss: 2.5800 - accuracy: 0.47 - ETA: 1:44 - loss: 2.5821 - accuracy: 0.47 - ETA: 1:43 - loss: 2.5776 - accuracy: 0.47 - ETA: 1:42 - loss: 2.5704 - accuracy: 0.47 - ETA: 1:41 - loss: 2.5650 - accuracy: 0.48 - ETA: 1:40 - loss: 2.5730 - accuracy: 0.48 - ETA: 1:39 - loss: 2.5856 - accuracy: 0.48 - ETA: 1:38 - loss: 2.5759 - accuracy: 0.48 - ETA: 1:37 - loss: 2.5757 - accuracy: 0.48 - ETA: 1:36 - loss: 2.5738 - accuracy: 0.48 - ETA: 1:35 - loss: 2.5669 - accuracy: 0.48 - ETA: 1:35 - loss: 2.5568 - accuracy: 0.48 - ETA: 1:34 - loss: 2.5549 - accuracy: 0.48 - ETA: 1:33 - loss: 2.5471 - accuracy: 0.48 - ETA: 1:32 - loss: 2.5407 - accuracy: 0.48 - ETA: 1:31 - loss: 2.5308 - accuracy: 0.48 - ETA: 1:30 - loss: 2.5389 - accuracy: 0.48 - ETA: 1:29 - loss: 2.5365 - accuracy: 0.48 - ETA: 1:28 - loss: 2.5315 - accuracy: 0.48 - ETA: 1:27 - loss: 2.5346 - accuracy: 0.48 - ETA: 1:26 - loss: 2.5323 - accuracy: 0.48 - ETA: 1:25 - loss: 2.5297 - accuracy: 0.48 - ETA: 1:24 - loss: 2.5289 - accuracy: 0.48 - ETA: 1:23 - loss: 2.5286 - accuracy: 0.48 - ETA: 1:22 - loss: 2.5322 - accuracy: 0.48 - ETA: 1:21 - loss: 2.5298 - accuracy: 0.48 - ETA: 1:20 - loss: 2.5272 - accuracy: 0.48 - ETA: 1:19 - loss: 2.5330 - accuracy: 0.48 - ETA: 1:18 - loss: 2.5301 - accuracy: 0.48 - ETA: 1:17 - loss: 2.5288 - accuracy: 0.48 - ETA: 1:16 - loss: 2.5246 - accuracy: 0.48 - ETA: 1:15 - loss: 2.5238 - accuracy: 0.48 - ETA: 1:14 - loss: 2.5189 - accuracy: 0.48 - ETA: 1:13 - loss: 2.5190 - accuracy: 0.48 - ETA: 1:12 - loss: 2.5192 - accuracy: 0.48 - ETA: 1:11 - loss: 2.5137 - accuracy: 0.48 - ETA: 1:10 - loss: 2.5117 - accuracy: 0.49 - ETA: 1:09 - loss: 2.5134 - accuracy: 0.49 - ETA: 1:08 - loss: 2.5131 - accuracy: 0.49 - ETA: 1:07 - loss: 2.5123 - accuracy: 0.49 - ETA: 1:06 - loss: 2.5165 - accuracy: 0.49 - ETA: 1:05 - loss: 2.5219 - accuracy: 0.49 - ETA: 1:04 - loss: 2.5173 - accuracy: 0.49 - ETA: 1:03 - loss: 2.5194 - accuracy: 0.49 - ETA: 1:02 - loss: 2.5191 - accuracy: 0.49 - ETA: 1:02 - loss: 2.5228 - accuracy: 0.49 - ETA: 1:01 - loss: 2.5167 - accuracy: 0.49 - ETA: 1:00 - loss: 2.5155 - accuracy: 0.49 - ETA: 59s - loss: 2.5187 - accuracy: 0.4949 - ETA: 58s - loss: 2.5141 - accuracy: 0.495 - ETA: 57s - loss: 2.5132 - accuracy: 0.495 - ETA: 56s - loss: 2.5121 - accuracy: 0.496 - ETA: 55s - loss: 2.5095 - accuracy: 0.496 - ETA: 54s - loss: 2.5055 - accuracy: 0.497 - ETA: 53s - loss: 2.5031 - accuracy: 0.498 - ETA: 52s - loss: 2.4996 - accuracy: 0.498 - ETA: 51s - loss: 2.5017 - accuracy: 0.498 - ETA: 50s - loss: 2.4961 - accuracy: 0.499 - ETA: 49s - loss: 2.4984 - accuracy: 0.499 - ETA: 48s - loss: 2.5013 - accuracy: 0.498 - ETA: 47s - loss: 2.5015 - accuracy: 0.498 - ETA: 46s - loss: 2.4960 - accuracy: 0.498 - ETA: 45s - loss: 2.4903 - accuracy: 0.499 - ETA: 44s - loss: 2.4942 - accuracy: 0.499 - ETA: 43s - loss: 2.4920 - accuracy: 0.499 - ETA: 42s - loss: 2.4877 - accuracy: 0.500 - ETA: 41s - loss: 2.4868 - accuracy: 0.500 - ETA: 40s - loss: 2.4915 - accuracy: 0.500 - ETA: 39s - loss: 2.4912 - accuracy: 0.500 - ETA: 38s - loss: 2.4914 - accuracy: 0.500 - ETA: 38s - loss: 2.4895 - accuracy: 0.500 - ETA: 37s - loss: 2.4817 - accuracy: 0.501 - ETA: 36s - loss: 2.4849 - accuracy: 0.500 - ETA: 35s - loss: 2.4835 - accuracy: 0.501 - ETA: 34s - loss: 2.4841 - accuracy: 0.500 - ETA: 33s - loss: 2.4891 - accuracy: 0.500 - ETA: 32s - loss: 2.4883 - accuracy: 0.501 - ETA: 31s - loss: 2.4840 - accuracy: 0.501 - ETA: 30s - loss: 2.4859 - accuracy: 0.501 - ETA: 29s - loss: 2.4836 - accuracy: 0.502 - ETA: 28s - loss: 2.4800 - accuracy: 0.502 - ETA: 27s - loss: 2.4815 - accuracy: 0.502 - ETA: 26s - loss: 2.4842 - accuracy: 0.502 - ETA: 25s - loss: 2.4818 - accuracy: 0.502 - ETA: 24s - loss: 2.4767 - accuracy: 0.503 - ETA: 23s - loss: 2.4813 - accuracy: 0.503 - ETA: 22s - loss: 2.4830 - accuracy: 0.503 - ETA: 21s - loss: 2.4833 - accuracy: 0.502 - ETA: 20s - loss: 2.4821 - accuracy: 0.502 - ETA: 19s - loss: 2.4811 - accuracy: 0.502 - ETA: 18s - loss: 2.4777 - accuracy: 0.503 - ETA: 17s - loss: 2.4772 - accuracy: 0.503 - ETA: 16s - loss: 2.4755 - accuracy: 0.503 - ETA: 15s - loss: 2.4764 - accuracy: 0.503 - ETA: 14s - loss: 2.4797 - accuracy: 0.503 - ETA: 13s - loss: 2.4821 - accuracy: 0.503 - ETA: 12s - loss: 2.4822 - accuracy: 0.503 - ETA: 11s - loss: 2.4819 - accuracy: 0.503 - ETA: 10s - loss: 2.4803 - accuracy: 0.503 - ETA: 9s - loss: 2.4765 - accuracy: 0.503 - ETA: 8s - loss: 2.4752 - accuracy: 0.50 - ETA: 7s - loss: 2.4755 - accuracy: 0.50 - ETA: 6s - loss: 2.4766 - accuracy: 0.50 - ETA: 5s - loss: 2.4713 - accuracy: 0.50 - ETA: 4s - loss: 2.4684 - accuracy: 0.50 - ETA: 3s - loss: 2.4698 - accuracy: 0.50 - ETA: 2s - loss: 2.4659 - accuracy: 0.50 - ETA: 1s - loss: 2.4691 - accuracy: 0.50 - ETA: 0s - loss: 2.4671 - accuracy: 0.50 - 161s 8ms/step - loss: 2.4642 - accuracy: 0.5046 - val_loss: 1.8058 - val_accuracy: 0.6055\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:26 - loss: 2.0484 - accuracy: 0.58 - ETA: 2:26 - loss: 1.9747 - accuracy: 0.58 - ETA: 2:24 - loss: 1.9951 - accuracy: 0.57 - ETA: 2:25 - loss: 1.9560 - accuracy: 0.57 - ETA: 2:24 - loss: 1.9418 - accuracy: 0.58 - ETA: 2:23 - loss: 1.9347 - accuracy: 0.58 - ETA: 2:23 - loss: 2.0119 - accuracy: 0.58 - ETA: 2:23 - loss: 2.0295 - accuracy: 0.58 - ETA: 2:22 - loss: 1.9775 - accuracy: 0.58 - ETA: 2:21 - loss: 1.9568 - accuracy: 0.58 - ETA: 2:19 - loss: 1.9251 - accuracy: 0.59 - ETA: 2:18 - loss: 1.9291 - accuracy: 0.58 - ETA: 2:17 - loss: 1.9360 - accuracy: 0.58 - ETA: 2:15 - loss: 1.9522 - accuracy: 0.58 - ETA: 2:14 - loss: 1.9279 - accuracy: 0.59 - ETA: 2:13 - loss: 1.9149 - accuracy: 0.59 - ETA: 2:13 - loss: 1.9196 - accuracy: 0.58 - ETA: 2:12 - loss: 1.9290 - accuracy: 0.58 - ETA: 2:11 - loss: 1.9212 - accuracy: 0.58 - ETA: 2:10 - loss: 1.9210 - accuracy: 0.58 - ETA: 2:09 - loss: 1.9140 - accuracy: 0.58 - ETA: 2:08 - loss: 1.9060 - accuracy: 0.58 - ETA: 2:07 - loss: 1.9223 - accuracy: 0.58 - ETA: 2:06 - loss: 1.9599 - accuracy: 0.58 - ETA: 2:04 - loss: 1.9650 - accuracy: 0.58 - ETA: 2:03 - loss: 1.9581 - accuracy: 0.58 - ETA: 2:02 - loss: 1.9638 - accuracy: 0.58 - ETA: 2:01 - loss: 1.9643 - accuracy: 0.58 - ETA: 2:00 - loss: 1.9716 - accuracy: 0.58 - ETA: 1:59 - loss: 1.9923 - accuracy: 0.57 - ETA: 1:58 - loss: 1.9910 - accuracy: 0.57 - ETA: 1:57 - loss: 2.0120 - accuracy: 0.57 - ETA: 1:56 - loss: 2.0038 - accuracy: 0.57 - ETA: 1:55 - loss: 1.9960 - accuracy: 0.57 - ETA: 1:54 - loss: 2.0058 - accuracy: 0.57 - ETA: 1:53 - loss: 1.9964 - accuracy: 0.58 - ETA: 1:52 - loss: 1.9961 - accuracy: 0.58 - ETA: 1:51 - loss: 1.9942 - accuracy: 0.57 - ETA: 1:50 - loss: 2.0082 - accuracy: 0.57 - ETA: 1:49 - loss: 2.0012 - accuracy: 0.57 - ETA: 1:48 - loss: 2.0041 - accuracy: 0.57 - ETA: 1:47 - loss: 2.0000 - accuracy: 0.57 - ETA: 1:46 - loss: 1.9976 - accuracy: 0.57 - ETA: 1:45 - loss: 2.0036 - accuracy: 0.57 - ETA: 1:44 - loss: 2.0140 - accuracy: 0.57 - ETA: 1:43 - loss: 2.0142 - accuracy: 0.57 - ETA: 1:42 - loss: 2.0079 - accuracy: 0.57 - ETA: 1:41 - loss: 2.0143 - accuracy: 0.57 - ETA: 1:40 - loss: 2.0185 - accuracy: 0.57 - ETA: 1:39 - loss: 2.0136 - accuracy: 0.57 - ETA: 1:38 - loss: 2.0105 - accuracy: 0.57 - ETA: 1:37 - loss: 2.0139 - accuracy: 0.57 - ETA: 1:36 - loss: 2.0137 - accuracy: 0.57 - ETA: 1:35 - loss: 2.0089 - accuracy: 0.57 - ETA: 1:34 - loss: 2.0098 - accuracy: 0.57 - ETA: 1:33 - loss: 2.0184 - accuracy: 0.57 - ETA: 1:32 - loss: 2.0223 - accuracy: 0.57 - ETA: 1:31 - loss: 2.0234 - accuracy: 0.57 - ETA: 1:30 - loss: 2.0175 - accuracy: 0.57 - ETA: 1:29 - loss: 2.0148 - accuracy: 0.57 - ETA: 1:28 - loss: 2.0124 - accuracy: 0.57 - ETA: 1:27 - loss: 2.0125 - accuracy: 0.57 - ETA: 1:26 - loss: 2.0109 - accuracy: 0.57 - ETA: 1:25 - loss: 2.0111 - accuracy: 0.57 - ETA: 1:24 - loss: 2.0063 - accuracy: 0.57 - ETA: 1:23 - loss: 2.0136 - accuracy: 0.57 - ETA: 1:22 - loss: 2.0151 - accuracy: 0.57 - ETA: 1:21 - loss: 2.0151 - accuracy: 0.57 - ETA: 1:20 - loss: 2.0111 - accuracy: 0.57 - ETA: 1:19 - loss: 2.0110 - accuracy: 0.57 - ETA: 1:18 - loss: 2.0112 - accuracy: 0.57 - ETA: 1:17 - loss: 2.0121 - accuracy: 0.57 - ETA: 1:16 - loss: 2.0070 - accuracy: 0.57 - ETA: 1:15 - loss: 2.0137 - accuracy: 0.57 - ETA: 1:14 - loss: 2.0174 - accuracy: 0.57 - ETA: 1:13 - loss: 2.0167 - accuracy: 0.57 - ETA: 1:12 - loss: 2.0224 - accuracy: 0.57 - ETA: 1:11 - loss: 2.0251 - accuracy: 0.57 - ETA: 1:10 - loss: 2.0283 - accuracy: 0.57 - ETA: 1:09 - loss: 2.0279 - accuracy: 0.57 - ETA: 1:08 - loss: 2.0259 - accuracy: 0.57 - ETA: 1:07 - loss: 2.0240 - accuracy: 0.57 - ETA: 1:06 - loss: 2.0214 - accuracy: 0.57 - ETA: 1:05 - loss: 2.0284 - accuracy: 0.57 - ETA: 1:04 - loss: 2.0311 - accuracy: 0.57 - ETA: 1:03 - loss: 2.0349 - accuracy: 0.57 - ETA: 1:02 - loss: 2.0354 - accuracy: 0.57 - ETA: 1:01 - loss: 2.0327 - accuracy: 0.57 - ETA: 1:01 - loss: 2.0347 - accuracy: 0.57 - ETA: 1:00 - loss: 2.0332 - accuracy: 0.57 - ETA: 59s - loss: 2.0306 - accuracy: 0.5764 - ETA: 58s - loss: 2.0321 - accuracy: 0.576 - ETA: 57s - loss: 2.0272 - accuracy: 0.576 - ETA: 56s - loss: 2.0247 - accuracy: 0.577 - ETA: 55s - loss: 2.0242 - accuracy: 0.576 - ETA: 53s - loss: 2.0247 - accuracy: 0.576 - ETA: 52s - loss: 2.0210 - accuracy: 0.576 - ETA: 52s - loss: 2.0162 - accuracy: 0.577 - ETA: 51s - loss: 2.0144 - accuracy: 0.577 - ETA: 50s - loss: 2.0190 - accuracy: 0.577 - ETA: 49s - loss: 2.0247 - accuracy: 0.577 - ETA: 48s - loss: 2.0217 - accuracy: 0.577 - ETA: 47s - loss: 2.0221 - accuracy: 0.577 - ETA: 46s - loss: 2.0220 - accuracy: 0.577 - ETA: 45s - loss: 2.0235 - accuracy: 0.577 - ETA: 44s - loss: 2.0218 - accuracy: 0.577 - ETA: 43s - loss: 2.0220 - accuracy: 0.577 - ETA: 42s - loss: 2.0205 - accuracy: 0.577 - ETA: 41s - loss: 2.0223 - accuracy: 0.577 - ETA: 40s - loss: 2.0221 - accuracy: 0.577 - ETA: 39s - loss: 2.0188 - accuracy: 0.577 - ETA: 38s - loss: 2.0172 - accuracy: 0.577 - ETA: 37s - loss: 2.0170 - accuracy: 0.577 - ETA: 36s - loss: 2.0176 - accuracy: 0.577 - ETA: 35s - loss: 2.0174 - accuracy: 0.577 - ETA: 34s - loss: 2.0209 - accuracy: 0.576 - ETA: 33s - loss: 2.0180 - accuracy: 0.576 - ETA: 32s - loss: 2.0195 - accuracy: 0.576 - ETA: 31s - loss: 2.0243 - accuracy: 0.576 - ETA: 30s - loss: 2.0222 - accuracy: 0.576 - ETA: 29s - loss: 2.0238 - accuracy: 0.576 - ETA: 28s - loss: 2.0225 - accuracy: 0.576 - ETA: 27s - loss: 2.0195 - accuracy: 0.576 - ETA: 26s - loss: 2.0227 - accuracy: 0.575 - ETA: 25s - loss: 2.0263 - accuracy: 0.575 - ETA: 24s - loss: 2.0254 - accuracy: 0.576 - ETA: 23s - loss: 2.0271 - accuracy: 0.576 - ETA: 22s - loss: 2.0268 - accuracy: 0.575 - ETA: 21s - loss: 2.0263 - accuracy: 0.575 - ETA: 20s - loss: 2.0272 - accuracy: 0.575 - ETA: 19s - loss: 2.0225 - accuracy: 0.576 - ETA: 18s - loss: 2.0247 - accuracy: 0.575 - ETA: 17s - loss: 2.0252 - accuracy: 0.576 - ETA: 16s - loss: 2.0234 - accuracy: 0.576 - ETA: 15s - loss: 2.0211 - accuracy: 0.576 - ETA: 14s - loss: 2.0195 - accuracy: 0.577 - ETA: 13s - loss: 2.0163 - accuracy: 0.577 - ETA: 12s - loss: 2.0181 - accuracy: 0.576 - ETA: 11s - loss: 2.0176 - accuracy: 0.576 - ETA: 10s - loss: 2.0174 - accuracy: 0.576 - ETA: 9s - loss: 2.0183 - accuracy: 0.576 - ETA: 8s - loss: 2.0218 - accuracy: 0.57 - ETA: 7s - loss: 2.0191 - accuracy: 0.57 - ETA: 6s - loss: 2.0197 - accuracy: 0.57 - ETA: 5s - loss: 2.0185 - accuracy: 0.57 - ETA: 4s - loss: 2.0180 - accuracy: 0.57 - ETA: 3s - loss: 2.0175 - accuracy: 0.57 - ETA: 2s - loss: 2.0137 - accuracy: 0.57 - ETA: 1s - loss: 2.0110 - accuracy: 0.57 - ETA: 0s - loss: 2.0106 - accuracy: 0.57 - 160s 8ms/step - loss: 2.0125 - accuracy: 0.5776 - val_loss: 1.7717 - val_accuracy: 0.6270\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:27 - loss: 1.8996 - accuracy: 0.64 - ETA: 2:22 - loss: 1.5974 - accuracy: 0.67 - ETA: 2:19 - loss: 1.7042 - accuracy: 0.65 - ETA: 2:17 - loss: 1.6799 - accuracy: 0.64 - ETA: 2:16 - loss: 1.6873 - accuracy: 0.64 - ETA: 2:15 - loss: 1.7113 - accuracy: 0.63 - ETA: 2:14 - loss: 1.7381 - accuracy: 0.63 - ETA: 2:13 - loss: 1.7089 - accuracy: 0.63 - ETA: 2:12 - loss: 1.7462 - accuracy: 0.63 - ETA: 2:10 - loss: 1.7545 - accuracy: 0.62 - ETA: 2:10 - loss: 1.7223 - accuracy: 0.63 - ETA: 2:09 - loss: 1.6887 - accuracy: 0.63 - ETA: 2:08 - loss: 1.6721 - accuracy: 0.63 - ETA: 2:07 - loss: 1.6888 - accuracy: 0.63 - ETA: 2:07 - loss: 1.7126 - accuracy: 0.63 - ETA: 2:07 - loss: 1.7130 - accuracy: 0.62 - ETA: 2:06 - loss: 1.7293 - accuracy: 0.62 - ETA: 2:05 - loss: 1.7314 - accuracy: 0.62 - ETA: 2:04 - loss: 1.7146 - accuracy: 0.62 - ETA: 2:03 - loss: 1.6995 - accuracy: 0.63 - ETA: 2:02 - loss: 1.7209 - accuracy: 0.62 - ETA: 2:01 - loss: 1.7491 - accuracy: 0.62 - ETA: 2:00 - loss: 1.7496 - accuracy: 0.62 - ETA: 2:00 - loss: 1.7574 - accuracy: 0.62 - ETA: 1:59 - loss: 1.7390 - accuracy: 0.62 - ETA: 1:58 - loss: 1.7336 - accuracy: 0.62 - ETA: 1:57 - loss: 1.7455 - accuracy: 0.62 - ETA: 1:56 - loss: 1.7544 - accuracy: 0.62 - ETA: 1:55 - loss: 1.7494 - accuracy: 0.62 - ETA: 1:54 - loss: 1.7792 - accuracy: 0.62 - ETA: 1:53 - loss: 1.8110 - accuracy: 0.62 - ETA: 1:53 - loss: 1.7991 - accuracy: 0.62 - ETA: 1:52 - loss: 1.8048 - accuracy: 0.62 - ETA: 1:51 - loss: 1.8004 - accuracy: 0.62 - ETA: 1:50 - loss: 1.7969 - accuracy: 0.62 - ETA: 1:49 - loss: 1.7980 - accuracy: 0.62 - ETA: 1:48 - loss: 1.8138 - accuracy: 0.62 - ETA: 1:47 - loss: 1.8097 - accuracy: 0.62 - ETA: 1:46 - loss: 1.8135 - accuracy: 0.62 - ETA: 1:45 - loss: 1.8111 - accuracy: 0.62 - ETA: 1:44 - loss: 1.7997 - accuracy: 0.62 - ETA: 1:43 - loss: 1.8001 - accuracy: 0.62 - ETA: 1:42 - loss: 1.7949 - accuracy: 0.62 - ETA: 1:41 - loss: 1.7870 - accuracy: 0.62 - ETA: 1:41 - loss: 1.7864 - accuracy: 0.62 - ETA: 1:40 - loss: 1.8024 - accuracy: 0.62 - ETA: 1:39 - loss: 1.8099 - accuracy: 0.62 - ETA: 1:38 - loss: 1.8067 - accuracy: 0.62 - ETA: 1:37 - loss: 1.8091 - accuracy: 0.61 - ETA: 1:36 - loss: 1.8137 - accuracy: 0.61 - ETA: 1:35 - loss: 1.8100 - accuracy: 0.62 - ETA: 1:35 - loss: 1.8089 - accuracy: 0.62 - ETA: 1:34 - loss: 1.8085 - accuracy: 0.61 - ETA: 1:33 - loss: 1.8151 - accuracy: 0.61 - ETA: 1:32 - loss: 1.8247 - accuracy: 0.61 - ETA: 1:31 - loss: 1.8217 - accuracy: 0.62 - ETA: 1:30 - loss: 1.8206 - accuracy: 0.62 - ETA: 1:29 - loss: 1.8201 - accuracy: 0.62 - ETA: 1:28 - loss: 1.8238 - accuracy: 0.62 - ETA: 1:27 - loss: 1.8303 - accuracy: 0.62 - ETA: 1:26 - loss: 1.8202 - accuracy: 0.62 - ETA: 1:25 - loss: 1.8220 - accuracy: 0.62 - ETA: 1:24 - loss: 1.8271 - accuracy: 0.62 - ETA: 1:23 - loss: 1.8267 - accuracy: 0.62 - ETA: 1:22 - loss: 1.8286 - accuracy: 0.61 - ETA: 1:21 - loss: 1.8257 - accuracy: 0.61 - ETA: 1:20 - loss: 1.8237 - accuracy: 0.61 - ETA: 1:19 - loss: 1.8218 - accuracy: 0.61 - ETA: 1:18 - loss: 1.8266 - accuracy: 0.61 - ETA: 1:17 - loss: 1.8307 - accuracy: 0.61 - ETA: 1:16 - loss: 1.8455 - accuracy: 0.61 - ETA: 1:15 - loss: 1.8490 - accuracy: 0.61 - ETA: 1:15 - loss: 1.8448 - accuracy: 0.61 - ETA: 1:14 - loss: 1.8424 - accuracy: 0.61 - ETA: 1:13 - loss: 1.8382 - accuracy: 0.61 - ETA: 1:12 - loss: 1.8355 - accuracy: 0.61 - ETA: 1:11 - loss: 1.8400 - accuracy: 0.61 - ETA: 1:10 - loss: 1.8444 - accuracy: 0.61 - ETA: 1:09 - loss: 1.8462 - accuracy: 0.61 - ETA: 1:08 - loss: 1.8472 - accuracy: 0.61 - ETA: 1:07 - loss: 1.8429 - accuracy: 0.61 - ETA: 1:06 - loss: 1.8400 - accuracy: 0.61 - ETA: 1:05 - loss: 1.8490 - accuracy: 0.61 - ETA: 1:04 - loss: 1.8438 - accuracy: 0.61 - ETA: 1:03 - loss: 1.8389 - accuracy: 0.61 - ETA: 1:02 - loss: 1.8391 - accuracy: 0.61 - ETA: 1:01 - loss: 1.8367 - accuracy: 0.61 - ETA: 1:00 - loss: 1.8362 - accuracy: 0.61 - ETA: 59s - loss: 1.8348 - accuracy: 0.6170 - ETA: 58s - loss: 1.8403 - accuracy: 0.616 - ETA: 57s - loss: 1.8402 - accuracy: 0.616 - ETA: 56s - loss: 1.8387 - accuracy: 0.616 - ETA: 55s - loss: 1.8354 - accuracy: 0.616 - ETA: 54s - loss: 1.8384 - accuracy: 0.615 - ETA: 53s - loss: 1.8385 - accuracy: 0.616 - ETA: 52s - loss: 1.8482 - accuracy: 0.614 - ETA: 51s - loss: 1.8443 - accuracy: 0.615 - ETA: 51s - loss: 1.8450 - accuracy: 0.615 - ETA: 50s - loss: 1.8460 - accuracy: 0.615 - ETA: 49s - loss: 1.8510 - accuracy: 0.614 - ETA: 48s - loss: 1.8456 - accuracy: 0.615 - ETA: 47s - loss: 1.8470 - accuracy: 0.615 - ETA: 46s - loss: 1.8478 - accuracy: 0.615 - ETA: 45s - loss: 1.8450 - accuracy: 0.616 - ETA: 44s - loss: 1.8507 - accuracy: 0.616 - ETA: 43s - loss: 1.8506 - accuracy: 0.616 - ETA: 42s - loss: 1.8575 - accuracy: 0.616 - ETA: 41s - loss: 1.8544 - accuracy: 0.616 - ETA: 40s - loss: 1.8541 - accuracy: 0.616 - ETA: 39s - loss: 1.8585 - accuracy: 0.615 - ETA: 38s - loss: 1.8616 - accuracy: 0.614 - ETA: 37s - loss: 1.8593 - accuracy: 0.615 - ETA: 36s - loss: 1.8574 - accuracy: 0.615 - ETA: 35s - loss: 1.8556 - accuracy: 0.615 - ETA: 34s - loss: 1.8553 - accuracy: 0.615 - ETA: 33s - loss: 1.8519 - accuracy: 0.615 - ETA: 32s - loss: 1.8501 - accuracy: 0.615 - ETA: 31s - loss: 1.8539 - accuracy: 0.615 - ETA: 30s - loss: 1.8533 - accuracy: 0.614 - ETA: 29s - loss: 1.8490 - accuracy: 0.615 - ETA: 28s - loss: 1.8466 - accuracy: 0.615 - ETA: 27s - loss: 1.8461 - accuracy: 0.615 - ETA: 26s - loss: 1.8423 - accuracy: 0.616 - ETA: 25s - loss: 1.8406 - accuracy: 0.615 - ETA: 24s - loss: 1.8408 - accuracy: 0.615 - ETA: 24s - loss: 1.8391 - accuracy: 0.615 - ETA: 23s - loss: 1.8378 - accuracy: 0.615 - ETA: 22s - loss: 1.8343 - accuracy: 0.616 - ETA: 21s - loss: 1.8337 - accuracy: 0.616 - ETA: 20s - loss: 1.8345 - accuracy: 0.615 - ETA: 19s - loss: 1.8348 - accuracy: 0.616 - ETA: 18s - loss: 1.8340 - accuracy: 0.616 - ETA: 17s - loss: 1.8339 - accuracy: 0.616 - ETA: 16s - loss: 1.8320 - accuracy: 0.616 - ETA: 15s - loss: 1.8326 - accuracy: 0.616 - ETA: 14s - loss: 1.8321 - accuracy: 0.616 - ETA: 13s - loss: 1.8311 - accuracy: 0.616 - ETA: 12s - loss: 1.8308 - accuracy: 0.616 - ETA: 11s - loss: 1.8284 - accuracy: 0.617 - ETA: 10s - loss: 1.8299 - accuracy: 0.616 - ETA: 9s - loss: 1.8281 - accuracy: 0.616 - ETA: 8s - loss: 1.8250 - accuracy: 0.61 - ETA: 7s - loss: 1.8230 - accuracy: 0.61 - ETA: 6s - loss: 1.8241 - accuracy: 0.61 - ETA: 5s - loss: 1.8272 - accuracy: 0.61 - ETA: 4s - loss: 1.8282 - accuracy: 0.61 - ETA: 3s - loss: 1.8262 - accuracy: 0.61 - ETA: 2s - loss: 1.8282 - accuracy: 0.61 - ETA: 1s - loss: 1.8306 - accuracy: 0.61 - ETA: 0s - loss: 1.8312 - accuracy: 0.61 - 158s 8ms/step - loss: 1.8292 - accuracy: 0.6180 - val_loss: 1.7080 - val_accuracy: 0.6569\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:21 - loss: 1.8491 - accuracy: 0.60 - ETA: 2:22 - loss: 1.6488 - accuracy: 0.64 - ETA: 2:19 - loss: 1.6257 - accuracy: 0.66 - ETA: 2:18 - loss: 1.6503 - accuracy: 0.65 - ETA: 2:19 - loss: 1.6767 - accuracy: 0.65 - ETA: 2:17 - loss: 1.6513 - accuracy: 0.65 - ETA: 2:16 - loss: 1.6024 - accuracy: 0.65 - ETA: 2:16 - loss: 1.6182 - accuracy: 0.64 - ETA: 2:14 - loss: 1.6141 - accuracy: 0.64 - ETA: 2:14 - loss: 1.6295 - accuracy: 0.64 - ETA: 2:13 - loss: 1.6322 - accuracy: 0.64 - ETA: 2:12 - loss: 1.6076 - accuracy: 0.64 - ETA: 2:11 - loss: 1.6266 - accuracy: 0.64 - ETA: 2:10 - loss: 1.6008 - accuracy: 0.64 - ETA: 2:11 - loss: 1.6022 - accuracy: 0.64 - ETA: 2:11 - loss: 1.6243 - accuracy: 0.64 - ETA: 2:11 - loss: 1.6672 - accuracy: 0.64 - ETA: 2:11 - loss: 1.6753 - accuracy: 0.64 - ETA: 2:10 - loss: 1.6848 - accuracy: 0.64 - ETA: 2:10 - loss: 1.6656 - accuracy: 0.64 - ETA: 2:09 - loss: 1.6793 - accuracy: 0.64 - ETA: 2:09 - loss: 1.6867 - accuracy: 0.64 - ETA: 2:07 - loss: 1.6819 - accuracy: 0.64 - ETA: 2:07 - loss: 1.6704 - accuracy: 0.64 - ETA: 2:06 - loss: 1.6776 - accuracy: 0.64 - ETA: 2:05 - loss: 1.6865 - accuracy: 0.64 - ETA: 2:05 - loss: 1.6964 - accuracy: 0.64 - ETA: 2:04 - loss: 1.6957 - accuracy: 0.64 - ETA: 2:03 - loss: 1.6824 - accuracy: 0.65 - ETA: 2:03 - loss: 1.6755 - accuracy: 0.65 - ETA: 2:02 - loss: 1.6656 - accuracy: 0.65 - ETA: 2:02 - loss: 1.6725 - accuracy: 0.65 - ETA: 2:01 - loss: 1.6902 - accuracy: 0.65 - ETA: 2:00 - loss: 1.6819 - accuracy: 0.65 - ETA: 1:59 - loss: 1.6932 - accuracy: 0.64 - ETA: 1:58 - loss: 1.7111 - accuracy: 0.64 - ETA: 1:58 - loss: 1.7071 - accuracy: 0.64 - ETA: 1:57 - loss: 1.7077 - accuracy: 0.64 - ETA: 1:56 - loss: 1.7080 - accuracy: 0.64 - ETA: 1:55 - loss: 1.7095 - accuracy: 0.64 - ETA: 1:54 - loss: 1.7053 - accuracy: 0.64 - ETA: 1:53 - loss: 1.7001 - accuracy: 0.64 - ETA: 1:52 - loss: 1.7011 - accuracy: 0.64 - ETA: 1:52 - loss: 1.7045 - accuracy: 0.64 - ETA: 1:51 - loss: 1.7019 - accuracy: 0.64 - ETA: 1:50 - loss: 1.7005 - accuracy: 0.64 - ETA: 1:49 - loss: 1.6957 - accuracy: 0.64 - ETA: 1:48 - loss: 1.6884 - accuracy: 0.64 - ETA: 1:47 - loss: 1.6896 - accuracy: 0.64 - ETA: 1:46 - loss: 1.6937 - accuracy: 0.64 - ETA: 1:45 - loss: 1.6918 - accuracy: 0.64 - ETA: 1:44 - loss: 1.6903 - accuracy: 0.64 - ETA: 1:43 - loss: 1.6822 - accuracy: 0.64 - ETA: 1:41 - loss: 1.6800 - accuracy: 0.64 - ETA: 1:40 - loss: 1.6766 - accuracy: 0.64 - ETA: 1:39 - loss: 1.6773 - accuracy: 0.64 - ETA: 1:38 - loss: 1.6720 - accuracy: 0.64 - ETA: 1:36 - loss: 1.6742 - accuracy: 0.64 - ETA: 1:35 - loss: 1.6744 - accuracy: 0.64 - ETA: 1:34 - loss: 1.6705 - accuracy: 0.64 - ETA: 1:33 - loss: 1.6784 - accuracy: 0.64 - ETA: 1:32 - loss: 1.6818 - accuracy: 0.65 - ETA: 1:31 - loss: 1.6889 - accuracy: 0.64 - ETA: 1:30 - loss: 1.6889 - accuracy: 0.64 - ETA: 1:29 - loss: 1.6856 - accuracy: 0.64 - ETA: 1:28 - loss: 1.6850 - accuracy: 0.64 - ETA: 1:27 - loss: 1.6835 - accuracy: 0.64 - ETA: 1:25 - loss: 1.6832 - accuracy: 0.65 - ETA: 1:24 - loss: 1.6789 - accuracy: 0.65 - ETA: 1:23 - loss: 1.6797 - accuracy: 0.65 - ETA: 1:22 - loss: 1.6759 - accuracy: 0.65 - ETA: 1:21 - loss: 1.6762 - accuracy: 0.65 - ETA: 1:20 - loss: 1.6744 - accuracy: 0.65 - ETA: 1:19 - loss: 1.6750 - accuracy: 0.65 - ETA: 1:18 - loss: 1.6728 - accuracy: 0.65 - ETA: 1:17 - loss: 1.6788 - accuracy: 0.65 - ETA: 1:16 - loss: 1.6801 - accuracy: 0.65 - ETA: 1:14 - loss: 1.6828 - accuracy: 0.65 - ETA: 1:13 - loss: 1.6822 - accuracy: 0.65 - ETA: 1:12 - loss: 1.6830 - accuracy: 0.65 - ETA: 1:11 - loss: 1.6795 - accuracy: 0.65 - ETA: 1:10 - loss: 1.6789 - accuracy: 0.65 - ETA: 1:09 - loss: 1.6847 - accuracy: 0.65 - ETA: 1:08 - loss: 1.6871 - accuracy: 0.65 - ETA: 1:07 - loss: 1.6868 - accuracy: 0.65 - ETA: 1:06 - loss: 1.6823 - accuracy: 0.65 - ETA: 1:05 - loss: 1.6831 - accuracy: 0.65 - ETA: 1:04 - loss: 1.6811 - accuracy: 0.65 - ETA: 1:03 - loss: 1.6838 - accuracy: 0.65 - ETA: 1:01 - loss: 1.6853 - accuracy: 0.65 - ETA: 1:00 - loss: 1.6805 - accuracy: 0.65 - ETA: 59s - loss: 1.6791 - accuracy: 0.6534 - ETA: 58s - loss: 1.6818 - accuracy: 0.653 - ETA: 57s - loss: 1.6849 - accuracy: 0.652 - ETA: 56s - loss: 1.6908 - accuracy: 0.652 - ETA: 55s - loss: 1.6895 - accuracy: 0.652 - ETA: 54s - loss: 1.6877 - accuracy: 0.652 - ETA: 53s - loss: 1.7007 - accuracy: 0.651 - ETA: 52s - loss: 1.6984 - accuracy: 0.651 - ETA: 51s - loss: 1.7018 - accuracy: 0.651 - ETA: 50s - loss: 1.7044 - accuracy: 0.650 - ETA: 49s - loss: 1.7032 - accuracy: 0.651 - ETA: 48s - loss: 1.6994 - accuracy: 0.651 - ETA: 47s - loss: 1.6979 - accuracy: 0.651 - ETA: 46s - loss: 1.6984 - accuracy: 0.651 - ETA: 45s - loss: 1.6979 - accuracy: 0.651 - ETA: 44s - loss: 1.6962 - accuracy: 0.651 - ETA: 43s - loss: 1.6946 - accuracy: 0.651 - ETA: 42s - loss: 1.6945 - accuracy: 0.650 - ETA: 41s - loss: 1.6963 - accuracy: 0.650 - ETA: 40s - loss: 1.6942 - accuracy: 0.650 - ETA: 39s - loss: 1.6930 - accuracy: 0.650 - ETA: 38s - loss: 1.6902 - accuracy: 0.651 - ETA: 37s - loss: 1.6892 - accuracy: 0.651 - ETA: 36s - loss: 1.6890 - accuracy: 0.651 - ETA: 35s - loss: 1.6852 - accuracy: 0.651 - ETA: 34s - loss: 1.6909 - accuracy: 0.650 - ETA: 33s - loss: 1.6913 - accuracy: 0.650 - ETA: 32s - loss: 1.6932 - accuracy: 0.650 - ETA: 31s - loss: 1.6920 - accuracy: 0.650 - ETA: 30s - loss: 1.6942 - accuracy: 0.650 - ETA: 29s - loss: 1.6942 - accuracy: 0.650 - ETA: 28s - loss: 1.6906 - accuracy: 0.650 - ETA: 27s - loss: 1.6906 - accuracy: 0.650 - ETA: 26s - loss: 1.6927 - accuracy: 0.649 - ETA: 25s - loss: 1.6886 - accuracy: 0.650 - ETA: 24s - loss: 1.6885 - accuracy: 0.650 - ETA: 23s - loss: 1.6874 - accuracy: 0.650 - ETA: 22s - loss: 1.6861 - accuracy: 0.650 - ETA: 21s - loss: 1.6866 - accuracy: 0.650 - ETA: 20s - loss: 1.6883 - accuracy: 0.650 - ETA: 19s - loss: 1.6853 - accuracy: 0.651 - ETA: 18s - loss: 1.6858 - accuracy: 0.651 - ETA: 17s - loss: 1.6860 - accuracy: 0.651 - ETA: 16s - loss: 1.6851 - accuracy: 0.651 - ETA: 14s - loss: 1.6851 - accuracy: 0.651 - ETA: 13s - loss: 1.6902 - accuracy: 0.651 - ETA: 12s - loss: 1.6909 - accuracy: 0.651 - ETA: 11s - loss: 1.6927 - accuracy: 0.651 - ETA: 10s - loss: 1.6950 - accuracy: 0.650 - ETA: 9s - loss: 1.6986 - accuracy: 0.650 - ETA: 8s - loss: 1.6974 - accuracy: 0.65 - ETA: 7s - loss: 1.6961 - accuracy: 0.65 - ETA: 6s - loss: 1.6984 - accuracy: 0.65 - ETA: 5s - loss: 1.6971 - accuracy: 0.65 - ETA: 4s - loss: 1.6986 - accuracy: 0.65 - ETA: 3s - loss: 1.7023 - accuracy: 0.65 - ETA: 2s - loss: 1.7035 - accuracy: 0.64 - ETA: 1s - loss: 1.7043 - accuracy: 0.64 - ETA: 0s - loss: 1.7020 - accuracy: 0.64 - 163s 8ms/step - loss: 1.7018 - accuracy: 0.6498 - val_loss: 1.7384 - val_accuracy: 0.6685\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 1.7988 - accuracy: 0.60 - ETA: 2:21 - loss: 1.5396 - accuracy: 0.65 - ETA: 2:20 - loss: 1.5118 - accuracy: 0.66 - ETA: 2:19 - loss: 1.4023 - accuracy: 0.69 - ETA: 2:18 - loss: 1.4015 - accuracy: 0.70 - ETA: 2:18 - loss: 1.3853 - accuracy: 0.71 - ETA: 2:17 - loss: 1.3482 - accuracy: 0.70 - ETA: 2:16 - loss: 1.3382 - accuracy: 0.70 - ETA: 2:15 - loss: 1.3829 - accuracy: 0.70 - ETA: 2:14 - loss: 1.3931 - accuracy: 0.70 - ETA: 2:13 - loss: 1.4371 - accuracy: 0.69 - ETA: 2:13 - loss: 1.4399 - accuracy: 0.69 - ETA: 2:13 - loss: 1.4402 - accuracy: 0.69 - ETA: 2:11 - loss: 1.4731 - accuracy: 0.68 - ETA: 2:11 - loss: 1.4790 - accuracy: 0.68 - ETA: 2:10 - loss: 1.4720 - accuracy: 0.68 - ETA: 2:09 - loss: 1.4756 - accuracy: 0.68 - ETA: 2:08 - loss: 1.4686 - accuracy: 0.68 - ETA: 2:07 - loss: 1.4733 - accuracy: 0.68 - ETA: 2:06 - loss: 1.4913 - accuracy: 0.68 - ETA: 2:05 - loss: 1.5019 - accuracy: 0.67 - ETA: 2:04 - loss: 1.4927 - accuracy: 0.68 - ETA: 2:03 - loss: 1.4904 - accuracy: 0.67 - ETA: 2:02 - loss: 1.4906 - accuracy: 0.67 - ETA: 2:01 - loss: 1.4803 - accuracy: 0.68 - ETA: 1:59 - loss: 1.4967 - accuracy: 0.67 - ETA: 1:58 - loss: 1.5024 - accuracy: 0.67 - ETA: 1:58 - loss: 1.4999 - accuracy: 0.67 - ETA: 1:57 - loss: 1.4962 - accuracy: 0.67 - ETA: 1:56 - loss: 1.4971 - accuracy: 0.67 - ETA: 1:55 - loss: 1.5050 - accuracy: 0.67 - ETA: 1:54 - loss: 1.4955 - accuracy: 0.67 - ETA: 1:53 - loss: 1.4831 - accuracy: 0.67 - ETA: 1:52 - loss: 1.4909 - accuracy: 0.67 - ETA: 1:51 - loss: 1.5073 - accuracy: 0.67 - ETA: 1:50 - loss: 1.5185 - accuracy: 0.67 - ETA: 1:49 - loss: 1.5120 - accuracy: 0.67 - ETA: 1:48 - loss: 1.5106 - accuracy: 0.67 - ETA: 1:47 - loss: 1.5181 - accuracy: 0.67 - ETA: 1:46 - loss: 1.5321 - accuracy: 0.67 - ETA: 1:45 - loss: 1.5276 - accuracy: 0.67 - ETA: 1:44 - loss: 1.5331 - accuracy: 0.67 - ETA: 1:43 - loss: 1.5283 - accuracy: 0.67 - ETA: 1:42 - loss: 1.5241 - accuracy: 0.67 - ETA: 1:41 - loss: 1.5244 - accuracy: 0.67 - ETA: 1:40 - loss: 1.5197 - accuracy: 0.67 - ETA: 1:39 - loss: 1.5247 - accuracy: 0.67 - ETA: 1:38 - loss: 1.5325 - accuracy: 0.67 - ETA: 1:37 - loss: 1.5324 - accuracy: 0.67 - ETA: 1:36 - loss: 1.5327 - accuracy: 0.67 - ETA: 1:35 - loss: 1.5354 - accuracy: 0.67 - ETA: 1:34 - loss: 1.5464 - accuracy: 0.67 - ETA: 1:33 - loss: 1.5519 - accuracy: 0.67 - ETA: 1:32 - loss: 1.5581 - accuracy: 0.67 - ETA: 1:32 - loss: 1.5594 - accuracy: 0.67 - ETA: 1:31 - loss: 1.5517 - accuracy: 0.67 - ETA: 1:30 - loss: 1.5565 - accuracy: 0.67 - ETA: 1:29 - loss: 1.5575 - accuracy: 0.67 - ETA: 1:28 - loss: 1.5671 - accuracy: 0.67 - ETA: 1:27 - loss: 1.5664 - accuracy: 0.67 - ETA: 1:26 - loss: 1.5679 - accuracy: 0.67 - ETA: 1:25 - loss: 1.5729 - accuracy: 0.67 - ETA: 1:24 - loss: 1.5759 - accuracy: 0.67 - ETA: 1:23 - loss: 1.5729 - accuracy: 0.67 - ETA: 1:22 - loss: 1.5718 - accuracy: 0.67 - ETA: 1:21 - loss: 1.5722 - accuracy: 0.67 - ETA: 1:20 - loss: 1.5737 - accuracy: 0.67 - ETA: 1:19 - loss: 1.5778 - accuracy: 0.67 - ETA: 1:18 - loss: 1.5802 - accuracy: 0.67 - ETA: 1:17 - loss: 1.5726 - accuracy: 0.67 - ETA: 1:16 - loss: 1.5765 - accuracy: 0.67 - ETA: 1:15 - loss: 1.5719 - accuracy: 0.67 - ETA: 1:14 - loss: 1.5705 - accuracy: 0.67 - ETA: 1:13 - loss: 1.5769 - accuracy: 0.67 - ETA: 1:12 - loss: 1.5758 - accuracy: 0.67 - ETA: 1:11 - loss: 1.5771 - accuracy: 0.67 - ETA: 1:11 - loss: 1.5840 - accuracy: 0.66 - ETA: 1:10 - loss: 1.5829 - accuracy: 0.66 - ETA: 1:09 - loss: 1.5900 - accuracy: 0.66 - ETA: 1:08 - loss: 1.5845 - accuracy: 0.67 - ETA: 1:07 - loss: 1.5871 - accuracy: 0.67 - ETA: 1:06 - loss: 1.5910 - accuracy: 0.67 - ETA: 1:05 - loss: 1.5913 - accuracy: 0.66 - ETA: 1:04 - loss: 1.5863 - accuracy: 0.67 - ETA: 1:03 - loss: 1.5874 - accuracy: 0.67 - ETA: 1:02 - loss: 1.5883 - accuracy: 0.67 - ETA: 1:01 - loss: 1.5849 - accuracy: 0.67 - ETA: 1:00 - loss: 1.5822 - accuracy: 0.67 - ETA: 59s - loss: 1.5856 - accuracy: 0.6711 - ETA: 58s - loss: 1.5889 - accuracy: 0.671 - ETA: 57s - loss: 1.5891 - accuracy: 0.670 - ETA: 56s - loss: 1.5882 - accuracy: 0.670 - ETA: 55s - loss: 1.5866 - accuracy: 0.671 - ETA: 54s - loss: 1.5832 - accuracy: 0.671 - ETA: 53s - loss: 1.5806 - accuracy: 0.672 - ETA: 52s - loss: 1.5807 - accuracy: 0.672 - ETA: 51s - loss: 1.5827 - accuracy: 0.672 - ETA: 50s - loss: 1.5803 - accuracy: 0.672 - ETA: 49s - loss: 1.5815 - accuracy: 0.672 - ETA: 48s - loss: 1.5828 - accuracy: 0.672 - ETA: 47s - loss: 1.5803 - accuracy: 0.672 - ETA: 46s - loss: 1.5809 - accuracy: 0.672 - ETA: 46s - loss: 1.5824 - accuracy: 0.671 - ETA: 45s - loss: 1.5809 - accuracy: 0.671 - ETA: 44s - loss: 1.5859 - accuracy: 0.671 - ETA: 43s - loss: 1.5889 - accuracy: 0.671 - ETA: 42s - loss: 1.5938 - accuracy: 0.670 - ETA: 41s - loss: 1.5942 - accuracy: 0.670 - ETA: 40s - loss: 1.5944 - accuracy: 0.670 - ETA: 39s - loss: 1.5929 - accuracy: 0.670 - ETA: 38s - loss: 1.5912 - accuracy: 0.671 - ETA: 37s - loss: 1.5908 - accuracy: 0.670 - ETA: 36s - loss: 1.5899 - accuracy: 0.670 - ETA: 35s - loss: 1.5890 - accuracy: 0.671 - ETA: 34s - loss: 1.5914 - accuracy: 0.671 - ETA: 33s - loss: 1.5893 - accuracy: 0.671 - ETA: 32s - loss: 1.5878 - accuracy: 0.671 - ETA: 31s - loss: 1.5844 - accuracy: 0.671 - ETA: 30s - loss: 1.5809 - accuracy: 0.672 - ETA: 29s - loss: 1.5830 - accuracy: 0.672 - ETA: 28s - loss: 1.5812 - accuracy: 0.672 - ETA: 27s - loss: 1.5837 - accuracy: 0.671 - ETA: 26s - loss: 1.5827 - accuracy: 0.671 - ETA: 25s - loss: 1.5827 - accuracy: 0.671 - ETA: 24s - loss: 1.5811 - accuracy: 0.671 - ETA: 23s - loss: 1.5788 - accuracy: 0.671 - ETA: 22s - loss: 1.5828 - accuracy: 0.670 - ETA: 22s - loss: 1.5824 - accuracy: 0.670 - ETA: 21s - loss: 1.5817 - accuracy: 0.670 - ETA: 20s - loss: 1.5791 - accuracy: 0.671 - ETA: 19s - loss: 1.5807 - accuracy: 0.671 - ETA: 18s - loss: 1.5840 - accuracy: 0.670 - ETA: 17s - loss: 1.5858 - accuracy: 0.670 - ETA: 16s - loss: 1.5856 - accuracy: 0.670 - ETA: 15s - loss: 1.5861 - accuracy: 0.670 - ETA: 14s - loss: 1.5827 - accuracy: 0.670 - ETA: 13s - loss: 1.5819 - accuracy: 0.670 - ETA: 12s - loss: 1.5870 - accuracy: 0.670 - ETA: 11s - loss: 1.5861 - accuracy: 0.670 - ETA: 10s - loss: 1.5871 - accuracy: 0.669 - ETA: 9s - loss: 1.5867 - accuracy: 0.669 - ETA: 8s - loss: 1.5894 - accuracy: 0.66 - ETA: 7s - loss: 1.5902 - accuracy: 0.66 - ETA: 6s - loss: 1.5881 - accuracy: 0.66 - ETA: 5s - loss: 1.5873 - accuracy: 0.66 - ETA: 4s - loss: 1.5859 - accuracy: 0.66 - ETA: 3s - loss: 1.5862 - accuracy: 0.66 - ETA: 2s - loss: 1.5841 - accuracy: 0.66 - ETA: 1s - loss: 1.5864 - accuracy: 0.66 - ETA: 0s - loss: 1.5854 - accuracy: 0.66 - 157s 8ms/step - loss: 1.5841 - accuracy: 0.6695 - val_loss: 1.7007 - val_accuracy: 0.6823\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:21 - loss: 1.4225 - accuracy: 0.69 - ETA: 2:20 - loss: 1.4734 - accuracy: 0.67 - ETA: 2:18 - loss: 1.4623 - accuracy: 0.69 - ETA: 2:17 - loss: 1.4298 - accuracy: 0.69 - ETA: 2:15 - loss: 1.5282 - accuracy: 0.67 - ETA: 2:15 - loss: 1.5593 - accuracy: 0.67 - ETA: 2:13 - loss: 1.5226 - accuracy: 0.67 - ETA: 2:12 - loss: 1.5183 - accuracy: 0.67 - ETA: 2:11 - loss: 1.4913 - accuracy: 0.68 - ETA: 2:11 - loss: 1.4684 - accuracy: 0.69 - ETA: 2:09 - loss: 1.4804 - accuracy: 0.68 - ETA: 2:09 - loss: 1.4869 - accuracy: 0.67 - ETA: 2:10 - loss: 1.4780 - accuracy: 0.68 - ETA: 2:09 - loss: 1.4629 - accuracy: 0.68 - ETA: 2:08 - loss: 1.4865 - accuracy: 0.68 - ETA: 2:07 - loss: 1.4770 - accuracy: 0.68 - ETA: 2:06 - loss: 1.4613 - accuracy: 0.68 - ETA: 2:05 - loss: 1.4799 - accuracy: 0.68 - ETA: 2:04 - loss: 1.4951 - accuracy: 0.68 - ETA: 2:03 - loss: 1.4998 - accuracy: 0.68 - ETA: 2:02 - loss: 1.4995 - accuracy: 0.68 - ETA: 2:02 - loss: 1.4994 - accuracy: 0.68 - ETA: 2:01 - loss: 1.5052 - accuracy: 0.68 - ETA: 1:59 - loss: 1.5133 - accuracy: 0.68 - ETA: 1:59 - loss: 1.5158 - accuracy: 0.68 - ETA: 1:58 - loss: 1.5116 - accuracy: 0.68 - ETA: 1:57 - loss: 1.5180 - accuracy: 0.68 - ETA: 1:57 - loss: 1.5202 - accuracy: 0.68 - ETA: 1:56 - loss: 1.5203 - accuracy: 0.68 - ETA: 1:55 - loss: 1.5190 - accuracy: 0.67 - ETA: 1:54 - loss: 1.5070 - accuracy: 0.68 - ETA: 1:53 - loss: 1.4980 - accuracy: 0.68 - ETA: 1:52 - loss: 1.4959 - accuracy: 0.68 - ETA: 1:51 - loss: 1.4828 - accuracy: 0.68 - ETA: 1:50 - loss: 1.4828 - accuracy: 0.68 - ETA: 1:49 - loss: 1.4774 - accuracy: 0.68 - ETA: 1:49 - loss: 1.4890 - accuracy: 0.68 - ETA: 1:48 - loss: 1.4893 - accuracy: 0.68 - ETA: 1:47 - loss: 1.4937 - accuracy: 0.68 - ETA: 1:46 - loss: 1.4976 - accuracy: 0.68 - ETA: 1:45 - loss: 1.5002 - accuracy: 0.68 - ETA: 1:44 - loss: 1.4981 - accuracy: 0.68 - ETA: 1:43 - loss: 1.5062 - accuracy: 0.68 - ETA: 1:42 - loss: 1.4963 - accuracy: 0.68 - ETA: 1:41 - loss: 1.5020 - accuracy: 0.68 - ETA: 1:40 - loss: 1.5085 - accuracy: 0.68 - ETA: 1:39 - loss: 1.4982 - accuracy: 0.68 - ETA: 1:38 - loss: 1.4947 - accuracy: 0.68 - ETA: 1:37 - loss: 1.4866 - accuracy: 0.68 - ETA: 1:36 - loss: 1.4853 - accuracy: 0.68 - ETA: 1:35 - loss: 1.4735 - accuracy: 0.68 - ETA: 1:35 - loss: 1.4805 - accuracy: 0.68 - ETA: 1:34 - loss: 1.4757 - accuracy: 0.68 - ETA: 1:32 - loss: 1.4768 - accuracy: 0.68 - ETA: 1:31 - loss: 1.4804 - accuracy: 0.68 - ETA: 1:30 - loss: 1.4773 - accuracy: 0.68 - ETA: 1:30 - loss: 1.4716 - accuracy: 0.68 - ETA: 1:28 - loss: 1.4674 - accuracy: 0.68 - ETA: 1:27 - loss: 1.4672 - accuracy: 0.68 - ETA: 1:27 - loss: 1.4734 - accuracy: 0.68 - ETA: 1:26 - loss: 1.4704 - accuracy: 0.68 - ETA: 1:25 - loss: 1.4687 - accuracy: 0.68 - ETA: 1:24 - loss: 1.4694 - accuracy: 0.68 - ETA: 1:23 - loss: 1.4694 - accuracy: 0.68 - ETA: 1:22 - loss: 1.4653 - accuracy: 0.68 - ETA: 1:21 - loss: 1.4678 - accuracy: 0.68 - ETA: 1:20 - loss: 1.4661 - accuracy: 0.68 - ETA: 1:19 - loss: 1.4755 - accuracy: 0.68 - ETA: 1:18 - loss: 1.4825 - accuracy: 0.68 - ETA: 1:17 - loss: 1.4829 - accuracy: 0.68 - ETA: 1:16 - loss: 1.4852 - accuracy: 0.68 - ETA: 1:15 - loss: 1.4837 - accuracy: 0.68 - ETA: 1:14 - loss: 1.4843 - accuracy: 0.68 - ETA: 1:13 - loss: 1.4840 - accuracy: 0.68 - ETA: 1:12 - loss: 1.4900 - accuracy: 0.68 - ETA: 1:11 - loss: 1.4858 - accuracy: 0.68 - ETA: 1:10 - loss: 1.4855 - accuracy: 0.68 - ETA: 1:09 - loss: 1.4830 - accuracy: 0.68 - ETA: 1:08 - loss: 1.4770 - accuracy: 0.68 - ETA: 1:08 - loss: 1.4771 - accuracy: 0.68 - ETA: 1:07 - loss: 1.4756 - accuracy: 0.68 - ETA: 1:06 - loss: 1.4812 - accuracy: 0.68 - ETA: 1:05 - loss: 1.4790 - accuracy: 0.68 - ETA: 1:04 - loss: 1.4791 - accuracy: 0.68 - ETA: 1:03 - loss: 1.4752 - accuracy: 0.68 - ETA: 1:02 - loss: 1.4746 - accuracy: 0.68 - ETA: 1:01 - loss: 1.4795 - accuracy: 0.68 - ETA: 1:00 - loss: 1.4855 - accuracy: 0.68 - ETA: 59s - loss: 1.4856 - accuracy: 0.6887 - ETA: 58s - loss: 1.4850 - accuracy: 0.689 - ETA: 57s - loss: 1.4821 - accuracy: 0.689 - ETA: 56s - loss: 1.4939 - accuracy: 0.689 - ETA: 55s - loss: 1.4931 - accuracy: 0.689 - ETA: 54s - loss: 1.4973 - accuracy: 0.688 - ETA: 54s - loss: 1.4943 - accuracy: 0.689 - ETA: 53s - loss: 1.4937 - accuracy: 0.689 - ETA: 52s - loss: 1.4918 - accuracy: 0.689 - ETA: 51s - loss: 1.4898 - accuracy: 0.689 - ETA: 50s - loss: 1.4898 - accuracy: 0.689 - ETA: 49s - loss: 1.4894 - accuracy: 0.689 - ETA: 48s - loss: 1.4929 - accuracy: 0.689 - ETA: 47s - loss: 1.4918 - accuracy: 0.689 - ETA: 46s - loss: 1.4943 - accuracy: 0.689 - ETA: 45s - loss: 1.4927 - accuracy: 0.689 - ETA: 44s - loss: 1.4957 - accuracy: 0.689 - ETA: 43s - loss: 1.4967 - accuracy: 0.689 - ETA: 42s - loss: 1.4921 - accuracy: 0.689 - ETA: 41s - loss: 1.4878 - accuracy: 0.689 - ETA: 40s - loss: 1.4906 - accuracy: 0.689 - ETA: 39s - loss: 1.4909 - accuracy: 0.689 - ETA: 38s - loss: 1.4900 - accuracy: 0.689 - ETA: 37s - loss: 1.4881 - accuracy: 0.689 - ETA: 36s - loss: 1.4849 - accuracy: 0.690 - ETA: 35s - loss: 1.4842 - accuracy: 0.690 - ETA: 34s - loss: 1.4858 - accuracy: 0.690 - ETA: 33s - loss: 1.4901 - accuracy: 0.690 - ETA: 32s - loss: 1.4881 - accuracy: 0.690 - ETA: 31s - loss: 1.4888 - accuracy: 0.689 - ETA: 30s - loss: 1.4907 - accuracy: 0.689 - ETA: 29s - loss: 1.4881 - accuracy: 0.689 - ETA: 28s - loss: 1.4864 - accuracy: 0.689 - ETA: 27s - loss: 1.4845 - accuracy: 0.689 - ETA: 27s - loss: 1.4818 - accuracy: 0.689 - ETA: 26s - loss: 1.4841 - accuracy: 0.690 - ETA: 25s - loss: 1.4818 - accuracy: 0.690 - ETA: 24s - loss: 1.4836 - accuracy: 0.690 - ETA: 23s - loss: 1.4819 - accuracy: 0.690 - ETA: 22s - loss: 1.4793 - accuracy: 0.690 - ETA: 21s - loss: 1.4807 - accuracy: 0.690 - ETA: 20s - loss: 1.4789 - accuracy: 0.691 - ETA: 19s - loss: 1.4770 - accuracy: 0.691 - ETA: 18s - loss: 1.4782 - accuracy: 0.691 - ETA: 17s - loss: 1.4738 - accuracy: 0.691 - ETA: 16s - loss: 1.4723 - accuracy: 0.692 - ETA: 15s - loss: 1.4785 - accuracy: 0.692 - ETA: 14s - loss: 1.4770 - accuracy: 0.692 - ETA: 13s - loss: 1.4783 - accuracy: 0.692 - ETA: 12s - loss: 1.4781 - accuracy: 0.692 - ETA: 11s - loss: 1.4776 - accuracy: 0.692 - ETA: 10s - loss: 1.4800 - accuracy: 0.692 - ETA: 9s - loss: 1.4821 - accuracy: 0.692 - ETA: 8s - loss: 1.4812 - accuracy: 0.69 - ETA: 7s - loss: 1.4822 - accuracy: 0.69 - ETA: 6s - loss: 1.4811 - accuracy: 0.69 - ETA: 5s - loss: 1.4828 - accuracy: 0.69 - ETA: 4s - loss: 1.4824 - accuracy: 0.69 - ETA: 3s - loss: 1.4807 - accuracy: 0.69 - ETA: 2s - loss: 1.4845 - accuracy: 0.69 - ETA: 1s - loss: 1.4847 - accuracy: 0.69 - ETA: 0s - loss: 1.4886 - accuracy: 0.69 - 158s 8ms/step - loss: 1.4855 - accuracy: 0.6929 - val_loss: 1.6793 - val_accuracy: 0.6923\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:20 - loss: 1.5788 - accuracy: 0.68 - ETA: 2:17 - loss: 1.5138 - accuracy: 0.70 - ETA: 2:16 - loss: 1.2942 - accuracy: 0.73 - ETA: 2:15 - loss: 1.2935 - accuracy: 0.73 - ETA: 2:13 - loss: 1.2843 - accuracy: 0.73 - ETA: 2:11 - loss: 1.3037 - accuracy: 0.72 - ETA: 2:11 - loss: 1.3049 - accuracy: 0.71 - ETA: 2:09 - loss: 1.3232 - accuracy: 0.71 - ETA: 2:09 - loss: 1.3287 - accuracy: 0.71 - ETA: 2:08 - loss: 1.3178 - accuracy: 0.71 - ETA: 2:08 - loss: 1.3319 - accuracy: 0.71 - ETA: 2:09 - loss: 1.3142 - accuracy: 0.71 - ETA: 2:09 - loss: 1.3429 - accuracy: 0.71 - ETA: 2:08 - loss: 1.3240 - accuracy: 0.71 - ETA: 2:07 - loss: 1.3442 - accuracy: 0.71 - ETA: 2:06 - loss: 1.3419 - accuracy: 0.71 - ETA: 2:05 - loss: 1.3803 - accuracy: 0.71 - ETA: 2:04 - loss: 1.3704 - accuracy: 0.71 - ETA: 2:03 - loss: 1.3667 - accuracy: 0.71 - ETA: 2:03 - loss: 1.4112 - accuracy: 0.71 - ETA: 2:02 - loss: 1.4195 - accuracy: 0.71 - ETA: 2:01 - loss: 1.4247 - accuracy: 0.71 - ETA: 2:00 - loss: 1.4508 - accuracy: 0.71 - ETA: 1:59 - loss: 1.4571 - accuracy: 0.71 - ETA: 1:58 - loss: 1.4417 - accuracy: 0.71 - ETA: 1:58 - loss: 1.4453 - accuracy: 0.71 - ETA: 1:57 - loss: 1.4543 - accuracy: 0.71 - ETA: 1:56 - loss: 1.4372 - accuracy: 0.71 - ETA: 1:55 - loss: 1.4314 - accuracy: 0.71 - ETA: 1:54 - loss: 1.4261 - accuracy: 0.71 - ETA: 1:53 - loss: 1.4215 - accuracy: 0.71 - ETA: 1:53 - loss: 1.4243 - accuracy: 0.71 - ETA: 1:52 - loss: 1.4162 - accuracy: 0.71 - ETA: 1:51 - loss: 1.4198 - accuracy: 0.71 - ETA: 1:50 - loss: 1.4186 - accuracy: 0.71 - ETA: 1:49 - loss: 1.4175 - accuracy: 0.71 - ETA: 1:48 - loss: 1.4189 - accuracy: 0.71 - ETA: 1:47 - loss: 1.4192 - accuracy: 0.71 - ETA: 1:46 - loss: 1.4244 - accuracy: 0.71 - ETA: 1:45 - loss: 1.4406 - accuracy: 0.71 - ETA: 1:44 - loss: 1.4605 - accuracy: 0.71 - ETA: 1:44 - loss: 1.4627 - accuracy: 0.71 - ETA: 1:43 - loss: 1.4920 - accuracy: 0.70 - ETA: 1:42 - loss: 1.4919 - accuracy: 0.71 - ETA: 1:41 - loss: 1.4929 - accuracy: 0.70 - ETA: 1:40 - loss: 1.4936 - accuracy: 0.70 - ETA: 1:39 - loss: 1.4865 - accuracy: 0.71 - ETA: 1:38 - loss: 1.4870 - accuracy: 0.71 - ETA: 1:38 - loss: 1.4805 - accuracy: 0.71 - ETA: 1:37 - loss: 1.4737 - accuracy: 0.71 - ETA: 1:36 - loss: 1.4791 - accuracy: 0.71 - ETA: 1:35 - loss: 1.4797 - accuracy: 0.71 - ETA: 1:34 - loss: 1.4777 - accuracy: 0.71 - ETA: 1:33 - loss: 1.4857 - accuracy: 0.71 - ETA: 1:32 - loss: 1.4871 - accuracy: 0.71 - ETA: 1:31 - loss: 1.4840 - accuracy: 0.71 - ETA: 1:30 - loss: 1.4806 - accuracy: 0.71 - ETA: 1:29 - loss: 1.4826 - accuracy: 0.71 - ETA: 1:28 - loss: 1.4773 - accuracy: 0.71 - ETA: 1:27 - loss: 1.4793 - accuracy: 0.71 - ETA: 1:26 - loss: 1.4774 - accuracy: 0.71 - ETA: 1:25 - loss: 1.4709 - accuracy: 0.71 - ETA: 1:24 - loss: 1.4704 - accuracy: 0.71 - ETA: 1:23 - loss: 1.4712 - accuracy: 0.71 - ETA: 1:22 - loss: 1.4729 - accuracy: 0.71 - ETA: 1:21 - loss: 1.4754 - accuracy: 0.70 - ETA: 1:21 - loss: 1.4735 - accuracy: 0.70 - ETA: 1:20 - loss: 1.4788 - accuracy: 0.70 - ETA: 1:19 - loss: 1.4786 - accuracy: 0.70 - ETA: 1:18 - loss: 1.4757 - accuracy: 0.70 - ETA: 1:17 - loss: 1.4713 - accuracy: 0.70 - ETA: 1:16 - loss: 1.4674 - accuracy: 0.70 - ETA: 1:15 - loss: 1.4665 - accuracy: 0.70 - ETA: 1:14 - loss: 1.4623 - accuracy: 0.70 - ETA: 1:13 - loss: 1.4612 - accuracy: 0.71 - ETA: 1:12 - loss: 1.4645 - accuracy: 0.70 - ETA: 1:11 - loss: 1.4593 - accuracy: 0.71 - ETA: 1:10 - loss: 1.4638 - accuracy: 0.71 - ETA: 1:09 - loss: 1.4589 - accuracy: 0.71 - ETA: 1:08 - loss: 1.4602 - accuracy: 0.71 - ETA: 1:07 - loss: 1.4600 - accuracy: 0.71 - ETA: 1:06 - loss: 1.4617 - accuracy: 0.71 - ETA: 1:05 - loss: 1.4596 - accuracy: 0.71 - ETA: 1:04 - loss: 1.4635 - accuracy: 0.71 - ETA: 1:03 - loss: 1.4585 - accuracy: 0.71 - ETA: 1:02 - loss: 1.4593 - accuracy: 0.71 - ETA: 1:01 - loss: 1.4571 - accuracy: 0.71 - ETA: 1:00 - loss: 1.4597 - accuracy: 0.71 - ETA: 59s - loss: 1.4561 - accuracy: 0.7106 - ETA: 59s - loss: 1.4569 - accuracy: 0.710 - ETA: 58s - loss: 1.4550 - accuracy: 0.710 - ETA: 57s - loss: 1.4600 - accuracy: 0.711 - ETA: 56s - loss: 1.4589 - accuracy: 0.710 - ETA: 55s - loss: 1.4574 - accuracy: 0.710 - ETA: 54s - loss: 1.4626 - accuracy: 0.710 - ETA: 53s - loss: 1.4599 - accuracy: 0.710 - ETA: 52s - loss: 1.4617 - accuracy: 0.710 - ETA: 52s - loss: 1.4644 - accuracy: 0.709 - ETA: 51s - loss: 1.4636 - accuracy: 0.709 - ETA: 50s - loss: 1.4597 - accuracy: 0.710 - ETA: 49s - loss: 1.4613 - accuracy: 0.710 - ETA: 48s - loss: 1.4639 - accuracy: 0.710 - ETA: 47s - loss: 1.4647 - accuracy: 0.710 - ETA: 46s - loss: 1.4603 - accuracy: 0.711 - ETA: 45s - loss: 1.4567 - accuracy: 0.711 - ETA: 44s - loss: 1.4556 - accuracy: 0.711 - ETA: 43s - loss: 1.4554 - accuracy: 0.711 - ETA: 42s - loss: 1.4552 - accuracy: 0.711 - ETA: 41s - loss: 1.4501 - accuracy: 0.711 - ETA: 40s - loss: 1.4501 - accuracy: 0.710 - ETA: 39s - loss: 1.4467 - accuracy: 0.711 - ETA: 38s - loss: 1.4471 - accuracy: 0.711 - ETA: 37s - loss: 1.4439 - accuracy: 0.711 - ETA: 36s - loss: 1.4408 - accuracy: 0.711 - ETA: 35s - loss: 1.4420 - accuracy: 0.711 - ETA: 34s - loss: 1.4435 - accuracy: 0.710 - ETA: 33s - loss: 1.4392 - accuracy: 0.711 - ETA: 32s - loss: 1.4364 - accuracy: 0.711 - ETA: 31s - loss: 1.4329 - accuracy: 0.711 - ETA: 30s - loss: 1.4283 - accuracy: 0.712 - ETA: 29s - loss: 1.4276 - accuracy: 0.712 - ETA: 28s - loss: 1.4247 - accuracy: 0.712 - ETA: 27s - loss: 1.4340 - accuracy: 0.711 - ETA: 26s - loss: 1.4315 - accuracy: 0.711 - ETA: 25s - loss: 1.4299 - accuracy: 0.711 - ETA: 24s - loss: 1.4273 - accuracy: 0.711 - ETA: 23s - loss: 1.4281 - accuracy: 0.711 - ETA: 22s - loss: 1.4256 - accuracy: 0.712 - ETA: 21s - loss: 1.4254 - accuracy: 0.711 - ETA: 20s - loss: 1.4264 - accuracy: 0.711 - ETA: 19s - loss: 1.4258 - accuracy: 0.711 - ETA: 18s - loss: 1.4244 - accuracy: 0.711 - ETA: 17s - loss: 1.4202 - accuracy: 0.711 - ETA: 16s - loss: 1.4199 - accuracy: 0.711 - ETA: 15s - loss: 1.4242 - accuracy: 0.711 - ETA: 14s - loss: 1.4225 - accuracy: 0.711 - ETA: 13s - loss: 1.4203 - accuracy: 0.711 - ETA: 12s - loss: 1.4208 - accuracy: 0.711 - ETA: 11s - loss: 1.4196 - accuracy: 0.711 - ETA: 10s - loss: 1.4189 - accuracy: 0.711 - ETA: 9s - loss: 1.4250 - accuracy: 0.711 - ETA: 8s - loss: 1.4222 - accuracy: 0.71 - ETA: 7s - loss: 1.4195 - accuracy: 0.71 - ETA: 6s - loss: 1.4191 - accuracy: 0.71 - ETA: 5s - loss: 1.4205 - accuracy: 0.71 - ETA: 4s - loss: 1.4166 - accuracy: 0.71 - ETA: 3s - loss: 1.4197 - accuracy: 0.71 - ETA: 2s - loss: 1.4212 - accuracy: 0.71 - ETA: 1s - loss: 1.4198 - accuracy: 0.71 - ETA: 0s - loss: 1.4214 - accuracy: 0.71 - 163s 8ms/step - loss: 1.4199 - accuracy: 0.7113 - val_loss: 1.6165 - val_accuracy: 0.6987\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:26 - loss: 1.5147 - accuracy: 0.71 - ETA: 2:20 - loss: 1.6107 - accuracy: 0.72 - ETA: 2:21 - loss: 1.4947 - accuracy: 0.72 - ETA: 2:21 - loss: 1.3873 - accuracy: 0.72 - ETA: 2:20 - loss: 1.3327 - accuracy: 0.72 - ETA: 2:19 - loss: 1.2922 - accuracy: 0.72 - ETA: 2:19 - loss: 1.3265 - accuracy: 0.72 - ETA: 2:19 - loss: 1.3062 - accuracy: 0.72 - ETA: 2:18 - loss: 1.3082 - accuracy: 0.72 - ETA: 2:16 - loss: 1.2773 - accuracy: 0.72 - ETA: 2:15 - loss: 1.3034 - accuracy: 0.73 - ETA: 2:14 - loss: 1.3313 - accuracy: 0.72 - ETA: 2:12 - loss: 1.3531 - accuracy: 0.72 - ETA: 2:11 - loss: 1.3266 - accuracy: 0.72 - ETA: 2:10 - loss: 1.3124 - accuracy: 0.72 - ETA: 2:09 - loss: 1.3188 - accuracy: 0.72 - ETA: 2:08 - loss: 1.3030 - accuracy: 0.73 - ETA: 2:08 - loss: 1.2989 - accuracy: 0.72 - ETA: 2:07 - loss: 1.2819 - accuracy: 0.73 - ETA: 2:06 - loss: 1.2692 - accuracy: 0.73 - ETA: 2:05 - loss: 1.2864 - accuracy: 0.72 - ETA: 2:03 - loss: 1.2940 - accuracy: 0.72 - ETA: 2:02 - loss: 1.2969 - accuracy: 0.72 - ETA: 2:02 - loss: 1.2914 - accuracy: 0.72 - ETA: 2:01 - loss: 1.3027 - accuracy: 0.72 - ETA: 2:00 - loss: 1.3231 - accuracy: 0.72 - ETA: 1:59 - loss: 1.3317 - accuracy: 0.72 - ETA: 1:58 - loss: 1.3361 - accuracy: 0.72 - ETA: 1:57 - loss: 1.3325 - accuracy: 0.72 - ETA: 1:56 - loss: 1.3272 - accuracy: 0.72 - ETA: 1:55 - loss: 1.3164 - accuracy: 0.72 - ETA: 1:54 - loss: 1.3173 - accuracy: 0.72 - ETA: 1:53 - loss: 1.3354 - accuracy: 0.72 - ETA: 1:52 - loss: 1.3388 - accuracy: 0.72 - ETA: 1:51 - loss: 1.3505 - accuracy: 0.72 - ETA: 1:50 - loss: 1.3532 - accuracy: 0.72 - ETA: 1:49 - loss: 1.3600 - accuracy: 0.72 - ETA: 1:48 - loss: 1.3475 - accuracy: 0.72 - ETA: 1:47 - loss: 1.3558 - accuracy: 0.72 - ETA: 1:46 - loss: 1.3604 - accuracy: 0.72 - ETA: 1:45 - loss: 1.3563 - accuracy: 0.72 - ETA: 1:44 - loss: 1.3604 - accuracy: 0.72 - ETA: 1:43 - loss: 1.3564 - accuracy: 0.72 - ETA: 1:42 - loss: 1.3703 - accuracy: 0.72 - ETA: 1:41 - loss: 1.3803 - accuracy: 0.72 - ETA: 1:40 - loss: 1.3885 - accuracy: 0.72 - ETA: 1:39 - loss: 1.3838 - accuracy: 0.72 - ETA: 1:39 - loss: 1.3830 - accuracy: 0.72 - ETA: 1:38 - loss: 1.3970 - accuracy: 0.72 - ETA: 1:37 - loss: 1.3885 - accuracy: 0.72 - ETA: 1:36 - loss: 1.3811 - accuracy: 0.72 - ETA: 1:35 - loss: 1.3843 - accuracy: 0.72 - ETA: 1:34 - loss: 1.3954 - accuracy: 0.72 - ETA: 1:33 - loss: 1.3941 - accuracy: 0.72 - ETA: 1:32 - loss: 1.3952 - accuracy: 0.72 - ETA: 1:31 - loss: 1.3949 - accuracy: 0.72 - ETA: 1:30 - loss: 1.3945 - accuracy: 0.72 - ETA: 1:29 - loss: 1.4020 - accuracy: 0.72 - ETA: 1:28 - loss: 1.4027 - accuracy: 0.72 - ETA: 1:27 - loss: 1.3990 - accuracy: 0.72 - ETA: 1:26 - loss: 1.3996 - accuracy: 0.72 - ETA: 1:25 - loss: 1.3959 - accuracy: 0.72 - ETA: 1:24 - loss: 1.3953 - accuracy: 0.72 - ETA: 1:23 - loss: 1.3984 - accuracy: 0.72 - ETA: 1:22 - loss: 1.3954 - accuracy: 0.72 - ETA: 1:21 - loss: 1.4000 - accuracy: 0.72 - ETA: 1:20 - loss: 1.3938 - accuracy: 0.72 - ETA: 1:19 - loss: 1.3897 - accuracy: 0.72 - ETA: 1:18 - loss: 1.3895 - accuracy: 0.72 - ETA: 1:17 - loss: 1.3852 - accuracy: 0.72 - ETA: 1:16 - loss: 1.3753 - accuracy: 0.72 - ETA: 1:15 - loss: 1.3725 - accuracy: 0.72 - ETA: 1:14 - loss: 1.3718 - accuracy: 0.72 - ETA: 1:14 - loss: 1.3744 - accuracy: 0.72 - ETA: 1:13 - loss: 1.3718 - accuracy: 0.72 - ETA: 1:12 - loss: 1.3732 - accuracy: 0.72 - ETA: 1:11 - loss: 1.3728 - accuracy: 0.72 - ETA: 1:10 - loss: 1.3809 - accuracy: 0.72 - ETA: 1:09 - loss: 1.3805 - accuracy: 0.72 - ETA: 1:08 - loss: 1.3797 - accuracy: 0.72 - ETA: 1:07 - loss: 1.3786 - accuracy: 0.72 - ETA: 1:06 - loss: 1.3799 - accuracy: 0.72 - ETA: 1:05 - loss: 1.3815 - accuracy: 0.72 - ETA: 1:04 - loss: 1.3805 - accuracy: 0.72 - ETA: 1:03 - loss: 1.3795 - accuracy: 0.72 - ETA: 1:02 - loss: 1.3745 - accuracy: 0.72 - ETA: 1:01 - loss: 1.3737 - accuracy: 0.72 - ETA: 1:00 - loss: 1.3727 - accuracy: 0.72 - ETA: 59s - loss: 1.3787 - accuracy: 0.7263 - ETA: 58s - loss: 1.3759 - accuracy: 0.726 - ETA: 57s - loss: 1.3766 - accuracy: 0.726 - ETA: 56s - loss: 1.3767 - accuracy: 0.726 - ETA: 55s - loss: 1.3815 - accuracy: 0.725 - ETA: 54s - loss: 1.3791 - accuracy: 0.725 - ETA: 53s - loss: 1.3746 - accuracy: 0.726 - ETA: 52s - loss: 1.3715 - accuracy: 0.726 - ETA: 51s - loss: 1.3730 - accuracy: 0.726 - ETA: 51s - loss: 1.3696 - accuracy: 0.726 - ETA: 50s - loss: 1.3701 - accuracy: 0.726 - ETA: 49s - loss: 1.3743 - accuracy: 0.725 - ETA: 48s - loss: 1.3707 - accuracy: 0.726 - ETA: 47s - loss: 1.3671 - accuracy: 0.726 - ETA: 46s - loss: 1.3699 - accuracy: 0.726 - ETA: 45s - loss: 1.3679 - accuracy: 0.726 - ETA: 44s - loss: 1.3667 - accuracy: 0.726 - ETA: 43s - loss: 1.3681 - accuracy: 0.726 - ETA: 42s - loss: 1.3740 - accuracy: 0.726 - ETA: 41s - loss: 1.3782 - accuracy: 0.725 - ETA: 40s - loss: 1.3811 - accuracy: 0.725 - ETA: 39s - loss: 1.3836 - accuracy: 0.724 - ETA: 38s - loss: 1.3838 - accuracy: 0.724 - ETA: 37s - loss: 1.3881 - accuracy: 0.723 - ETA: 36s - loss: 1.3864 - accuracy: 0.724 - ETA: 35s - loss: 1.3896 - accuracy: 0.723 - ETA: 34s - loss: 1.3928 - accuracy: 0.722 - ETA: 33s - loss: 1.3945 - accuracy: 0.722 - ETA: 32s - loss: 1.3937 - accuracy: 0.722 - ETA: 31s - loss: 1.3909 - accuracy: 0.722 - ETA: 30s - loss: 1.3924 - accuracy: 0.721 - ETA: 29s - loss: 1.3898 - accuracy: 0.721 - ETA: 28s - loss: 1.3940 - accuracy: 0.721 - ETA: 27s - loss: 1.3946 - accuracy: 0.721 - ETA: 26s - loss: 1.3945 - accuracy: 0.721 - ETA: 26s - loss: 1.3950 - accuracy: 0.722 - ETA: 25s - loss: 1.3932 - accuracy: 0.722 - ETA: 24s - loss: 1.3875 - accuracy: 0.722 - ETA: 23s - loss: 1.3854 - accuracy: 0.723 - ETA: 22s - loss: 1.3909 - accuracy: 0.722 - ETA: 21s - loss: 1.3898 - accuracy: 0.722 - ETA: 20s - loss: 1.3881 - accuracy: 0.723 - ETA: 19s - loss: 1.3900 - accuracy: 0.723 - ETA: 18s - loss: 1.3887 - accuracy: 0.722 - ETA: 17s - loss: 1.3884 - accuracy: 0.722 - ETA: 16s - loss: 1.3905 - accuracy: 0.722 - ETA: 15s - loss: 1.3870 - accuracy: 0.722 - ETA: 14s - loss: 1.3871 - accuracy: 0.722 - ETA: 13s - loss: 1.3901 - accuracy: 0.722 - ETA: 12s - loss: 1.3894 - accuracy: 0.722 - ETA: 11s - loss: 1.3888 - accuracy: 0.723 - ETA: 10s - loss: 1.3894 - accuracy: 0.723 - ETA: 9s - loss: 1.3895 - accuracy: 0.723 - ETA: 8s - loss: 1.3862 - accuracy: 0.72 - ETA: 7s - loss: 1.3844 - accuracy: 0.72 - ETA: 6s - loss: 1.3838 - accuracy: 0.72 - ETA: 5s - loss: 1.3824 - accuracy: 0.72 - ETA: 4s - loss: 1.3810 - accuracy: 0.72 - ETA: 3s - loss: 1.3871 - accuracy: 0.72 - ETA: 2s - loss: 1.3855 - accuracy: 0.72 - ETA: 1s - loss: 1.3873 - accuracy: 0.72 - ETA: 0s - loss: 1.3907 - accuracy: 0.72 - 157s 8ms/step - loss: 1.3905 - accuracy: 0.7224 - val_loss: 1.7560 - val_accuracy: 0.6954\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:27 - loss: 1.4871 - accuracy: 0.67 - ETA: 2:24 - loss: 1.2001 - accuracy: 0.72 - ETA: 2:23 - loss: 1.1687 - accuracy: 0.72 - ETA: 2:23 - loss: 1.2510 - accuracy: 0.71 - ETA: 2:21 - loss: 1.2901 - accuracy: 0.72 - ETA: 2:20 - loss: 1.2409 - accuracy: 0.73 - ETA: 2:20 - loss: 1.2201 - accuracy: 0.73 - ETA: 2:18 - loss: 1.2246 - accuracy: 0.73 - ETA: 2:17 - loss: 1.2051 - accuracy: 0.73 - ETA: 2:18 - loss: 1.2065 - accuracy: 0.73 - ETA: 2:17 - loss: 1.2232 - accuracy: 0.73 - ETA: 2:16 - loss: 1.2244 - accuracy: 0.72 - ETA: 2:14 - loss: 1.2335 - accuracy: 0.73 - ETA: 2:13 - loss: 1.2287 - accuracy: 0.73 - ETA: 2:11 - loss: 1.2148 - accuracy: 0.73 - ETA: 2:10 - loss: 1.2114 - accuracy: 0.73 - ETA: 2:09 - loss: 1.2227 - accuracy: 0.73 - ETA: 2:08 - loss: 1.2264 - accuracy: 0.73 - ETA: 2:07 - loss: 1.2486 - accuracy: 0.73 - ETA: 2:06 - loss: 1.2613 - accuracy: 0.72 - ETA: 2:04 - loss: 1.2529 - accuracy: 0.73 - ETA: 2:03 - loss: 1.2462 - accuracy: 0.73 - ETA: 2:02 - loss: 1.2502 - accuracy: 0.73 - ETA: 2:02 - loss: 1.2459 - accuracy: 0.73 - ETA: 2:00 - loss: 1.2392 - accuracy: 0.73 - ETA: 1:59 - loss: 1.2520 - accuracy: 0.73 - ETA: 1:59 - loss: 1.2665 - accuracy: 0.73 - ETA: 1:58 - loss: 1.2776 - accuracy: 0.73 - ETA: 1:57 - loss: 1.2787 - accuracy: 0.73 - ETA: 1:56 - loss: 1.2858 - accuracy: 0.73 - ETA: 1:55 - loss: 1.3009 - accuracy: 0.73 - ETA: 1:54 - loss: 1.3026 - accuracy: 0.73 - ETA: 1:53 - loss: 1.3149 - accuracy: 0.73 - ETA: 1:52 - loss: 1.3218 - accuracy: 0.72 - ETA: 1:51 - loss: 1.3194 - accuracy: 0.72 - ETA: 1:50 - loss: 1.3148 - accuracy: 0.73 - ETA: 1:49 - loss: 1.3068 - accuracy: 0.73 - ETA: 1:48 - loss: 1.3060 - accuracy: 0.73 - ETA: 1:47 - loss: 1.3050 - accuracy: 0.73 - ETA: 1:46 - loss: 1.3112 - accuracy: 0.73 - ETA: 1:45 - loss: 1.3083 - accuracy: 0.73 - ETA: 1:44 - loss: 1.3254 - accuracy: 0.73 - ETA: 1:43 - loss: 1.3189 - accuracy: 0.73 - ETA: 1:42 - loss: 1.3249 - accuracy: 0.72 - ETA: 1:41 - loss: 1.3204 - accuracy: 0.73 - ETA: 1:40 - loss: 1.3186 - accuracy: 0.73 - ETA: 1:39 - loss: 1.3186 - accuracy: 0.73 - ETA: 1:38 - loss: 1.3119 - accuracy: 0.73 - ETA: 1:37 - loss: 1.3083 - accuracy: 0.73 - ETA: 1:36 - loss: 1.3110 - accuracy: 0.73 - ETA: 1:35 - loss: 1.3143 - accuracy: 0.73 - ETA: 1:34 - loss: 1.3156 - accuracy: 0.73 - ETA: 1:34 - loss: 1.3236 - accuracy: 0.73 - ETA: 1:33 - loss: 1.3247 - accuracy: 0.73 - ETA: 1:32 - loss: 1.3299 - accuracy: 0.73 - ETA: 1:31 - loss: 1.3352 - accuracy: 0.73 - ETA: 1:30 - loss: 1.3319 - accuracy: 0.73 - ETA: 1:29 - loss: 1.3257 - accuracy: 0.73 - ETA: 1:28 - loss: 1.3262 - accuracy: 0.73 - ETA: 1:27 - loss: 1.3304 - accuracy: 0.73 - ETA: 1:26 - loss: 1.3350 - accuracy: 0.73 - ETA: 1:25 - loss: 1.3288 - accuracy: 0.73 - ETA: 1:24 - loss: 1.3277 - accuracy: 0.73 - ETA: 1:23 - loss: 1.3237 - accuracy: 0.73 - ETA: 1:22 - loss: 1.3231 - accuracy: 0.73 - ETA: 1:21 - loss: 1.3221 - accuracy: 0.73 - ETA: 1:20 - loss: 1.3266 - accuracy: 0.73 - ETA: 1:19 - loss: 1.3305 - accuracy: 0.73 - ETA: 1:18 - loss: 1.3215 - accuracy: 0.73 - ETA: 1:17 - loss: 1.3216 - accuracy: 0.73 - ETA: 1:17 - loss: 1.3253 - accuracy: 0.73 - ETA: 1:16 - loss: 1.3219 - accuracy: 0.73 - ETA: 1:15 - loss: 1.3190 - accuracy: 0.73 - ETA: 1:14 - loss: 1.3299 - accuracy: 0.73 - ETA: 1:13 - loss: 1.3257 - accuracy: 0.73 - ETA: 1:12 - loss: 1.3251 - accuracy: 0.73 - ETA: 1:11 - loss: 1.3317 - accuracy: 0.73 - ETA: 1:10 - loss: 1.3264 - accuracy: 0.73 - ETA: 1:09 - loss: 1.3343 - accuracy: 0.73 - ETA: 1:08 - loss: 1.3358 - accuracy: 0.73 - ETA: 1:07 - loss: 1.3336 - accuracy: 0.73 - ETA: 1:06 - loss: 1.3322 - accuracy: 0.73 - ETA: 1:05 - loss: 1.3283 - accuracy: 0.73 - ETA: 1:04 - loss: 1.3262 - accuracy: 0.73 - ETA: 1:03 - loss: 1.3274 - accuracy: 0.73 - ETA: 1:02 - loss: 1.3207 - accuracy: 0.73 - ETA: 1:01 - loss: 1.3207 - accuracy: 0.73 - ETA: 1:00 - loss: 1.3196 - accuracy: 0.73 - ETA: 59s - loss: 1.3211 - accuracy: 0.7341 - ETA: 58s - loss: 1.3260 - accuracy: 0.733 - ETA: 57s - loss: 1.3243 - accuracy: 0.733 - ETA: 56s - loss: 1.3264 - accuracy: 0.733 - ETA: 55s - loss: 1.3222 - accuracy: 0.733 - ETA: 55s - loss: 1.3254 - accuracy: 0.733 - ETA: 54s - loss: 1.3221 - accuracy: 0.733 - ETA: 53s - loss: 1.3280 - accuracy: 0.732 - ETA: 52s - loss: 1.3265 - accuracy: 0.733 - ETA: 51s - loss: 1.3221 - accuracy: 0.733 - ETA: 50s - loss: 1.3179 - accuracy: 0.734 - ETA: 49s - loss: 1.3190 - accuracy: 0.733 - ETA: 48s - loss: 1.3182 - accuracy: 0.733 - ETA: 47s - loss: 1.3237 - accuracy: 0.733 - ETA: 46s - loss: 1.3259 - accuracy: 0.733 - ETA: 45s - loss: 1.3244 - accuracy: 0.733 - ETA: 44s - loss: 1.3266 - accuracy: 0.732 - ETA: 43s - loss: 1.3248 - accuracy: 0.732 - ETA: 42s - loss: 1.3228 - accuracy: 0.732 - ETA: 41s - loss: 1.3274 - accuracy: 0.733 - ETA: 40s - loss: 1.3254 - accuracy: 0.733 - ETA: 39s - loss: 1.3263 - accuracy: 0.732 - ETA: 38s - loss: 1.3247 - accuracy: 0.733 - ETA: 37s - loss: 1.3268 - accuracy: 0.732 - ETA: 36s - loss: 1.3243 - accuracy: 0.733 - ETA: 35s - loss: 1.3255 - accuracy: 0.733 - ETA: 34s - loss: 1.3283 - accuracy: 0.732 - ETA: 33s - loss: 1.3282 - accuracy: 0.733 - ETA: 32s - loss: 1.3265 - accuracy: 0.733 - ETA: 31s - loss: 1.3281 - accuracy: 0.733 - ETA: 30s - loss: 1.3241 - accuracy: 0.733 - ETA: 29s - loss: 1.3235 - accuracy: 0.733 - ETA: 28s - loss: 1.3200 - accuracy: 0.733 - ETA: 27s - loss: 1.3175 - accuracy: 0.733 - ETA: 26s - loss: 1.3213 - accuracy: 0.732 - ETA: 25s - loss: 1.3264 - accuracy: 0.732 - ETA: 25s - loss: 1.3334 - accuracy: 0.732 - ETA: 24s - loss: 1.3336 - accuracy: 0.732 - ETA: 23s - loss: 1.3377 - accuracy: 0.732 - ETA: 22s - loss: 1.3399 - accuracy: 0.732 - ETA: 21s - loss: 1.3417 - accuracy: 0.732 - ETA: 20s - loss: 1.3417 - accuracy: 0.731 - ETA: 19s - loss: 1.3422 - accuracy: 0.732 - ETA: 18s - loss: 1.3382 - accuracy: 0.732 - ETA: 17s - loss: 1.3351 - accuracy: 0.732 - ETA: 16s - loss: 1.3339 - accuracy: 0.733 - ETA: 15s - loss: 1.3322 - accuracy: 0.733 - ETA: 14s - loss: 1.3342 - accuracy: 0.733 - ETA: 13s - loss: 1.3344 - accuracy: 0.733 - ETA: 12s - loss: 1.3341 - accuracy: 0.733 - ETA: 11s - loss: 1.3341 - accuracy: 0.733 - ETA: 10s - loss: 1.3348 - accuracy: 0.733 - ETA: 9s - loss: 1.3345 - accuracy: 0.733 - ETA: 8s - loss: 1.3350 - accuracy: 0.73 - ETA: 7s - loss: 1.3354 - accuracy: 0.73 - ETA: 6s - loss: 1.3343 - accuracy: 0.73 - ETA: 5s - loss: 1.3339 - accuracy: 0.73 - ETA: 4s - loss: 1.3369 - accuracy: 0.73 - ETA: 3s - loss: 1.3349 - accuracy: 0.73 - ETA: 2s - loss: 1.3327 - accuracy: 0.73 - ETA: 1s - loss: 1.3343 - accuracy: 0.73 - ETA: 0s - loss: 1.3420 - accuracy: 0.73 - 158s 8ms/step - loss: 1.3416 - accuracy: 0.7329 - val_loss: 1.8314 - val_accuracy: 0.7057\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:34 - loss: 1.5684 - accuracy: 0.72 - ETA: 2:28 - loss: 1.7265 - accuracy: 0.75 - ETA: 2:26 - loss: 1.6370 - accuracy: 0.74 - ETA: 2:23 - loss: 1.5168 - accuracy: 0.73 - ETA: 2:21 - loss: 1.4083 - accuracy: 0.75 - ETA: 2:20 - loss: 1.3991 - accuracy: 0.74 - ETA: 2:19 - loss: 1.3742 - accuracy: 0.74 - ETA: 2:19 - loss: 1.3315 - accuracy: 0.74 - ETA: 2:18 - loss: 1.3271 - accuracy: 0.74 - ETA: 2:16 - loss: 1.2914 - accuracy: 0.74 - ETA: 2:15 - loss: 1.2657 - accuracy: 0.74 - ETA: 2:15 - loss: 1.2524 - accuracy: 0.74 - ETA: 2:15 - loss: 1.2415 - accuracy: 0.74 - ETA: 2:15 - loss: 1.2405 - accuracy: 0.74 - ETA: 2:14 - loss: 1.2223 - accuracy: 0.74 - ETA: 2:13 - loss: 1.2162 - accuracy: 0.74 - ETA: 2:12 - loss: 1.2242 - accuracy: 0.74 - ETA: 2:10 - loss: 1.2222 - accuracy: 0.74 - ETA: 2:09 - loss: 1.2406 - accuracy: 0.74 - ETA: 2:08 - loss: 1.2602 - accuracy: 0.73 - ETA: 2:06 - loss: 1.2624 - accuracy: 0.74 - ETA: 2:05 - loss: 1.2548 - accuracy: 0.74 - ETA: 2:04 - loss: 1.2683 - accuracy: 0.74 - ETA: 2:03 - loss: 1.2617 - accuracy: 0.74 - ETA: 2:02 - loss: 1.2747 - accuracy: 0.74 - ETA: 2:01 - loss: 1.2774 - accuracy: 0.74 - ETA: 2:00 - loss: 1.2842 - accuracy: 0.74 - ETA: 1:59 - loss: 1.2895 - accuracy: 0.74 - ETA: 1:58 - loss: 1.2998 - accuracy: 0.74 - ETA: 1:57 - loss: 1.2916 - accuracy: 0.74 - ETA: 1:56 - loss: 1.2806 - accuracy: 0.74 - ETA: 1:55 - loss: 1.2711 - accuracy: 0.74 - ETA: 1:54 - loss: 1.2578 - accuracy: 0.74 - ETA: 1:53 - loss: 1.2658 - accuracy: 0.74 - ETA: 1:52 - loss: 1.2730 - accuracy: 0.74 - ETA: 1:51 - loss: 1.2656 - accuracy: 0.74 - ETA: 1:50 - loss: 1.2766 - accuracy: 0.74 - ETA: 1:49 - loss: 1.2698 - accuracy: 0.75 - ETA: 1:48 - loss: 1.2655 - accuracy: 0.75 - ETA: 1:47 - loss: 1.2616 - accuracy: 0.75 - ETA: 1:46 - loss: 1.2605 - accuracy: 0.75 - ETA: 1:45 - loss: 1.2685 - accuracy: 0.74 - ETA: 1:44 - loss: 1.2675 - accuracy: 0.74 - ETA: 1:44 - loss: 1.2834 - accuracy: 0.74 - ETA: 1:43 - loss: 1.2780 - accuracy: 0.75 - ETA: 1:42 - loss: 1.2880 - accuracy: 0.75 - ETA: 1:41 - loss: 1.2906 - accuracy: 0.75 - ETA: 1:40 - loss: 1.2820 - accuracy: 0.75 - ETA: 1:39 - loss: 1.2824 - accuracy: 0.75 - ETA: 1:38 - loss: 1.2879 - accuracy: 0.74 - ETA: 1:38 - loss: 1.2927 - accuracy: 0.74 - ETA: 1:37 - loss: 1.2824 - accuracy: 0.74 - ETA: 1:36 - loss: 1.2818 - accuracy: 0.74 - ETA: 1:35 - loss: 1.2781 - accuracy: 0.74 - ETA: 1:34 - loss: 1.2705 - accuracy: 0.75 - ETA: 1:33 - loss: 1.2833 - accuracy: 0.74 - ETA: 1:32 - loss: 1.2839 - accuracy: 0.74 - ETA: 1:31 - loss: 1.2852 - accuracy: 0.74 - ETA: 1:30 - loss: 1.2974 - accuracy: 0.74 - ETA: 1:29 - loss: 1.2930 - accuracy: 0.74 - ETA: 1:28 - loss: 1.2933 - accuracy: 0.74 - ETA: 1:27 - loss: 1.2918 - accuracy: 0.74 - ETA: 1:26 - loss: 1.2907 - accuracy: 0.74 - ETA: 1:25 - loss: 1.2957 - accuracy: 0.74 - ETA: 1:24 - loss: 1.3028 - accuracy: 0.74 - ETA: 1:23 - loss: 1.3026 - accuracy: 0.74 - ETA: 1:22 - loss: 1.2965 - accuracy: 0.74 - ETA: 1:21 - loss: 1.2939 - accuracy: 0.74 - ETA: 1:20 - loss: 1.2982 - accuracy: 0.74 - ETA: 1:19 - loss: 1.3020 - accuracy: 0.74 - ETA: 1:18 - loss: 1.3033 - accuracy: 0.74 - ETA: 1:17 - loss: 1.3036 - accuracy: 0.74 - ETA: 1:16 - loss: 1.3114 - accuracy: 0.74 - ETA: 1:15 - loss: 1.3139 - accuracy: 0.74 - ETA: 1:14 - loss: 1.3118 - accuracy: 0.74 - ETA: 1:13 - loss: 1.3065 - accuracy: 0.74 - ETA: 1:12 - loss: 1.3064 - accuracy: 0.74 - ETA: 1:11 - loss: 1.3134 - accuracy: 0.74 - ETA: 1:10 - loss: 1.3130 - accuracy: 0.74 - ETA: 1:09 - loss: 1.3146 - accuracy: 0.74 - ETA: 1:08 - loss: 1.3146 - accuracy: 0.74 - ETA: 1:07 - loss: 1.3179 - accuracy: 0.74 - ETA: 1:06 - loss: 1.3144 - accuracy: 0.74 - ETA: 1:05 - loss: 1.3092 - accuracy: 0.74 - ETA: 1:04 - loss: 1.3102 - accuracy: 0.74 - ETA: 1:03 - loss: 1.3071 - accuracy: 0.74 - ETA: 1:02 - loss: 1.3105 - accuracy: 0.74 - ETA: 1:01 - loss: 1.3121 - accuracy: 0.74 - ETA: 1:00 - loss: 1.3202 - accuracy: 0.74 - ETA: 59s - loss: 1.3239 - accuracy: 0.7458 - ETA: 58s - loss: 1.3213 - accuracy: 0.746 - ETA: 57s - loss: 1.3216 - accuracy: 0.745 - ETA: 56s - loss: 1.3237 - accuracy: 0.745 - ETA: 55s - loss: 1.3245 - accuracy: 0.745 - ETA: 54s - loss: 1.3228 - accuracy: 0.745 - ETA: 53s - loss: 1.3221 - accuracy: 0.745 - ETA: 52s - loss: 1.3202 - accuracy: 0.746 - ETA: 51s - loss: 1.3208 - accuracy: 0.745 - ETA: 50s - loss: 1.3196 - accuracy: 0.745 - ETA: 49s - loss: 1.3157 - accuracy: 0.746 - ETA: 48s - loss: 1.3162 - accuracy: 0.746 - ETA: 47s - loss: 1.3203 - accuracy: 0.745 - ETA: 46s - loss: 1.3154 - accuracy: 0.746 - ETA: 45s - loss: 1.3114 - accuracy: 0.746 - ETA: 44s - loss: 1.3087 - accuracy: 0.746 - ETA: 43s - loss: 1.3068 - accuracy: 0.746 - ETA: 42s - loss: 1.3045 - accuracy: 0.746 - ETA: 41s - loss: 1.3071 - accuracy: 0.745 - ETA: 40s - loss: 1.3070 - accuracy: 0.745 - ETA: 39s - loss: 1.3071 - accuracy: 0.745 - ETA: 38s - loss: 1.3053 - accuracy: 0.745 - ETA: 37s - loss: 1.3053 - accuracy: 0.746 - ETA: 36s - loss: 1.3062 - accuracy: 0.746 - ETA: 35s - loss: 1.3078 - accuracy: 0.746 - ETA: 34s - loss: 1.3057 - accuracy: 0.746 - ETA: 33s - loss: 1.3060 - accuracy: 0.746 - ETA: 33s - loss: 1.3076 - accuracy: 0.746 - ETA: 32s - loss: 1.3043 - accuracy: 0.746 - ETA: 31s - loss: 1.3085 - accuracy: 0.746 - ETA: 30s - loss: 1.3084 - accuracy: 0.746 - ETA: 29s - loss: 1.3089 - accuracy: 0.745 - ETA: 28s - loss: 1.3100 - accuracy: 0.746 - ETA: 27s - loss: 1.3079 - accuracy: 0.746 - ETA: 26s - loss: 1.3074 - accuracy: 0.746 - ETA: 25s - loss: 1.3050 - accuracy: 0.746 - ETA: 24s - loss: 1.3042 - accuracy: 0.746 - ETA: 23s - loss: 1.3023 - accuracy: 0.746 - ETA: 22s - loss: 1.3041 - accuracy: 0.746 - ETA: 21s - loss: 1.3015 - accuracy: 0.747 - ETA: 20s - loss: 1.3035 - accuracy: 0.747 - ETA: 19s - loss: 1.3007 - accuracy: 0.747 - ETA: 18s - loss: 1.2985 - accuracy: 0.747 - ETA: 17s - loss: 1.2942 - accuracy: 0.748 - ETA: 16s - loss: 1.2921 - accuracy: 0.748 - ETA: 15s - loss: 1.2932 - accuracy: 0.748 - ETA: 14s - loss: 1.2933 - accuracy: 0.748 - ETA: 13s - loss: 1.2930 - accuracy: 0.748 - ETA: 12s - loss: 1.2916 - accuracy: 0.748 - ETA: 11s - loss: 1.2932 - accuracy: 0.747 - ETA: 10s - loss: 1.2953 - accuracy: 0.747 - ETA: 9s - loss: 1.2951 - accuracy: 0.747 - ETA: 8s - loss: 1.2952 - accuracy: 0.74 - ETA: 7s - loss: 1.2952 - accuracy: 0.74 - ETA: 6s - loss: 1.2971 - accuracy: 0.74 - ETA: 5s - loss: 1.2950 - accuracy: 0.74 - ETA: 4s - loss: 1.2953 - accuracy: 0.74 - ETA: 3s - loss: 1.2951 - accuracy: 0.74 - ETA: 2s - loss: 1.2951 - accuracy: 0.74 - ETA: 1s - loss: 1.2970 - accuracy: 0.74 - ETA: 0s - loss: 1.2950 - accuracy: 0.74 - 158s 8ms/step - loss: 1.2963 - accuracy: 0.7478 - val_loss: 1.8451 - val_accuracy: 0.7177\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:42 - loss: 1.0343 - accuracy: 0.74 - ETA: 2:31 - loss: 1.1071 - accuracy: 0.75 - ETA: 2:28 - loss: 1.1205 - accuracy: 0.75 - ETA: 2:24 - loss: 1.1077 - accuracy: 0.75 - ETA: 2:23 - loss: 1.1614 - accuracy: 0.75 - ETA: 2:21 - loss: 1.3215 - accuracy: 0.74 - ETA: 2:19 - loss: 1.2712 - accuracy: 0.75 - ETA: 2:17 - loss: 1.3179 - accuracy: 0.74 - ETA: 2:18 - loss: 1.3206 - accuracy: 0.74 - ETA: 2:17 - loss: 1.2706 - accuracy: 0.75 - ETA: 2:15 - loss: 1.2883 - accuracy: 0.75 - ETA: 2:14 - loss: 1.2797 - accuracy: 0.75 - ETA: 2:13 - loss: 1.2679 - accuracy: 0.75 - ETA: 2:12 - loss: 1.2382 - accuracy: 0.75 - ETA: 2:12 - loss: 1.2278 - accuracy: 0.75 - ETA: 2:11 - loss: 1.2048 - accuracy: 0.75 - ETA: 2:11 - loss: 1.2164 - accuracy: 0.75 - ETA: 2:10 - loss: 1.2169 - accuracy: 0.75 - ETA: 2:09 - loss: 1.2308 - accuracy: 0.75 - ETA: 2:08 - loss: 1.2393 - accuracy: 0.75 - ETA: 2:07 - loss: 1.2186 - accuracy: 0.75 - ETA: 2:06 - loss: 1.2026 - accuracy: 0.75 - ETA: 2:05 - loss: 1.1932 - accuracy: 0.76 - ETA: 2:04 - loss: 1.2147 - accuracy: 0.76 - ETA: 2:02 - loss: 1.2067 - accuracy: 0.76 - ETA: 2:01 - loss: 1.2078 - accuracy: 0.76 - ETA: 2:00 - loss: 1.2131 - accuracy: 0.75 - ETA: 1:59 - loss: 1.2125 - accuracy: 0.75 - ETA: 1:58 - loss: 1.2157 - accuracy: 0.75 - ETA: 1:57 - loss: 1.2171 - accuracy: 0.75 - ETA: 1:56 - loss: 1.2079 - accuracy: 0.76 - ETA: 1:55 - loss: 1.2016 - accuracy: 0.76 - ETA: 1:54 - loss: 1.2120 - accuracy: 0.76 - ETA: 1:53 - loss: 1.2081 - accuracy: 0.76 - ETA: 1:52 - loss: 1.2180 - accuracy: 0.76 - ETA: 1:51 - loss: 1.2356 - accuracy: 0.75 - ETA: 1:50 - loss: 1.2366 - accuracy: 0.75 - ETA: 1:49 - loss: 1.2342 - accuracy: 0.75 - ETA: 1:48 - loss: 1.2463 - accuracy: 0.75 - ETA: 1:47 - loss: 1.2589 - accuracy: 0.75 - ETA: 1:46 - loss: 1.2538 - accuracy: 0.75 - ETA: 1:45 - loss: 1.2573 - accuracy: 0.75 - ETA: 1:44 - loss: 1.2612 - accuracy: 0.75 - ETA: 1:43 - loss: 1.2602 - accuracy: 0.75 - ETA: 1:42 - loss: 1.2574 - accuracy: 0.75 - ETA: 1:41 - loss: 1.2547 - accuracy: 0.75 - ETA: 1:40 - loss: 1.2644 - accuracy: 0.75 - ETA: 1:39 - loss: 1.2586 - accuracy: 0.75 - ETA: 1:38 - loss: 1.2654 - accuracy: 0.75 - ETA: 1:37 - loss: 1.2705 - accuracy: 0.75 - ETA: 1:36 - loss: 1.2663 - accuracy: 0.75 - ETA: 1:35 - loss: 1.2607 - accuracy: 0.75 - ETA: 1:34 - loss: 1.2615 - accuracy: 0.75 - ETA: 1:33 - loss: 1.2602 - accuracy: 0.75 - ETA: 1:32 - loss: 1.2569 - accuracy: 0.75 - ETA: 1:31 - loss: 1.2541 - accuracy: 0.75 - ETA: 1:30 - loss: 1.2600 - accuracy: 0.75 - ETA: 1:29 - loss: 1.2581 - accuracy: 0.75 - ETA: 1:28 - loss: 1.2610 - accuracy: 0.75 - ETA: 1:27 - loss: 1.2613 - accuracy: 0.75 - ETA: 1:26 - loss: 1.2701 - accuracy: 0.75 - ETA: 1:25 - loss: 1.2714 - accuracy: 0.75 - ETA: 1:24 - loss: 1.2733 - accuracy: 0.75 - ETA: 1:23 - loss: 1.2721 - accuracy: 0.75 - ETA: 1:23 - loss: 1.2721 - accuracy: 0.75 - ETA: 1:22 - loss: 1.2716 - accuracy: 0.75 - ETA: 1:21 - loss: 1.2714 - accuracy: 0.75 - ETA: 1:20 - loss: 1.2678 - accuracy: 0.75 - ETA: 1:19 - loss: 1.2597 - accuracy: 0.75 - ETA: 1:18 - loss: 1.2546 - accuracy: 0.75 - ETA: 1:17 - loss: 1.2560 - accuracy: 0.75 - ETA: 1:16 - loss: 1.2556 - accuracy: 0.75 - ETA: 1:15 - loss: 1.2549 - accuracy: 0.75 - ETA: 1:14 - loss: 1.2564 - accuracy: 0.75 - ETA: 1:13 - loss: 1.2572 - accuracy: 0.75 - ETA: 1:12 - loss: 1.2555 - accuracy: 0.75 - ETA: 1:11 - loss: 1.2525 - accuracy: 0.75 - ETA: 1:10 - loss: 1.2498 - accuracy: 0.75 - ETA: 1:09 - loss: 1.2506 - accuracy: 0.75 - ETA: 1:08 - loss: 1.2564 - accuracy: 0.75 - ETA: 1:07 - loss: 1.2614 - accuracy: 0.75 - ETA: 1:06 - loss: 1.2665 - accuracy: 0.75 - ETA: 1:05 - loss: 1.2685 - accuracy: 0.75 - ETA: 1:04 - loss: 1.2695 - accuracy: 0.75 - ETA: 1:03 - loss: 1.2705 - accuracy: 0.75 - ETA: 1:02 - loss: 1.2763 - accuracy: 0.75 - ETA: 1:01 - loss: 1.2778 - accuracy: 0.75 - ETA: 1:00 - loss: 1.2771 - accuracy: 0.75 - ETA: 1:00 - loss: 1.2773 - accuracy: 0.75 - ETA: 59s - loss: 1.2780 - accuracy: 0.7546 - ETA: 58s - loss: 1.2795 - accuracy: 0.754 - ETA: 57s - loss: 1.2840 - accuracy: 0.754 - ETA: 56s - loss: 1.2871 - accuracy: 0.753 - ETA: 55s - loss: 1.2837 - accuracy: 0.753 - ETA: 54s - loss: 1.2827 - accuracy: 0.754 - ETA: 53s - loss: 1.2856 - accuracy: 0.753 - ETA: 52s - loss: 1.2848 - accuracy: 0.754 - ETA: 51s - loss: 1.2819 - accuracy: 0.754 - ETA: 50s - loss: 1.2804 - accuracy: 0.754 - ETA: 49s - loss: 1.2784 - accuracy: 0.754 - ETA: 48s - loss: 1.2797 - accuracy: 0.753 - ETA: 47s - loss: 1.2759 - accuracy: 0.754 - ETA: 46s - loss: 1.2701 - accuracy: 0.754 - ETA: 45s - loss: 1.2689 - accuracy: 0.754 - ETA: 44s - loss: 1.2647 - accuracy: 0.754 - ETA: 43s - loss: 1.2662 - accuracy: 0.754 - ETA: 42s - loss: 1.2666 - accuracy: 0.754 - ETA: 41s - loss: 1.2640 - accuracy: 0.754 - ETA: 40s - loss: 1.2679 - accuracy: 0.754 - ETA: 39s - loss: 1.2682 - accuracy: 0.754 - ETA: 38s - loss: 1.2759 - accuracy: 0.754 - ETA: 37s - loss: 1.2739 - accuracy: 0.754 - ETA: 36s - loss: 1.2713 - accuracy: 0.754 - ETA: 35s - loss: 1.2696 - accuracy: 0.755 - ETA: 34s - loss: 1.2716 - accuracy: 0.755 - ETA: 33s - loss: 1.2718 - accuracy: 0.755 - ETA: 32s - loss: 1.2698 - accuracy: 0.755 - ETA: 31s - loss: 1.2678 - accuracy: 0.755 - ETA: 30s - loss: 1.2658 - accuracy: 0.755 - ETA: 29s - loss: 1.2633 - accuracy: 0.755 - ETA: 28s - loss: 1.2631 - accuracy: 0.756 - ETA: 27s - loss: 1.2616 - accuracy: 0.756 - ETA: 26s - loss: 1.2587 - accuracy: 0.756 - ETA: 26s - loss: 1.2583 - accuracy: 0.756 - ETA: 25s - loss: 1.2556 - accuracy: 0.757 - ETA: 24s - loss: 1.2535 - accuracy: 0.757 - ETA: 23s - loss: 1.2552 - accuracy: 0.757 - ETA: 22s - loss: 1.2560 - accuracy: 0.756 - ETA: 21s - loss: 1.2536 - accuracy: 0.757 - ETA: 20s - loss: 1.2563 - accuracy: 0.756 - ETA: 19s - loss: 1.2559 - accuracy: 0.757 - ETA: 18s - loss: 1.2546 - accuracy: 0.757 - ETA: 17s - loss: 1.2569 - accuracy: 0.757 - ETA: 16s - loss: 1.2594 - accuracy: 0.756 - ETA: 15s - loss: 1.2549 - accuracy: 0.756 - ETA: 14s - loss: 1.2554 - accuracy: 0.756 - ETA: 13s - loss: 1.2564 - accuracy: 0.756 - ETA: 12s - loss: 1.2593 - accuracy: 0.756 - ETA: 11s - loss: 1.2570 - accuracy: 0.756 - ETA: 10s - loss: 1.2606 - accuracy: 0.756 - ETA: 9s - loss: 1.2614 - accuracy: 0.755 - ETA: 8s - loss: 1.2599 - accuracy: 0.75 - ETA: 7s - loss: 1.2619 - accuracy: 0.75 - ETA: 6s - loss: 1.2661 - accuracy: 0.75 - ETA: 5s - loss: 1.2671 - accuracy: 0.75 - ETA: 4s - loss: 1.2649 - accuracy: 0.75 - ETA: 3s - loss: 1.2669 - accuracy: 0.75 - ETA: 2s - loss: 1.2672 - accuracy: 0.75 - ETA: 1s - loss: 1.2670 - accuracy: 0.75 - ETA: 0s - loss: 1.2662 - accuracy: 0.75 - 157s 8ms/step - loss: 1.2644 - accuracy: 0.7549 - val_loss: 1.8952 - val_accuracy: 0.7180\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:40 - loss: 0.8414 - accuracy: 0.79 - ETA: 2:32 - loss: 0.9643 - accuracy: 0.80 - ETA: 2:28 - loss: 0.9806 - accuracy: 0.80 - ETA: 2:25 - loss: 1.1062 - accuracy: 0.76 - ETA: 2:23 - loss: 1.1442 - accuracy: 0.76 - ETA: 2:20 - loss: 1.1038 - accuracy: 0.77 - ETA: 2:18 - loss: 1.1201 - accuracy: 0.76 - ETA: 2:17 - loss: 1.1679 - accuracy: 0.76 - ETA: 2:18 - loss: 1.1642 - accuracy: 0.76 - ETA: 2:17 - loss: 1.2385 - accuracy: 0.75 - ETA: 2:16 - loss: 1.2172 - accuracy: 0.76 - ETA: 2:14 - loss: 1.1939 - accuracy: 0.76 - ETA: 2:13 - loss: 1.1863 - accuracy: 0.76 - ETA: 2:11 - loss: 1.1860 - accuracy: 0.76 - ETA: 2:10 - loss: 1.1651 - accuracy: 0.76 - ETA: 2:09 - loss: 1.1691 - accuracy: 0.76 - ETA: 2:09 - loss: 1.1440 - accuracy: 0.77 - ETA: 2:08 - loss: 1.1715 - accuracy: 0.76 - ETA: 2:08 - loss: 1.1697 - accuracy: 0.76 - ETA: 2:06 - loss: 1.1669 - accuracy: 0.76 - ETA: 2:05 - loss: 1.1611 - accuracy: 0.76 - ETA: 2:04 - loss: 1.1631 - accuracy: 0.76 - ETA: 2:03 - loss: 1.1558 - accuracy: 0.77 - ETA: 2:02 - loss: 1.1528 - accuracy: 0.77 - ETA: 2:01 - loss: 1.1511 - accuracy: 0.77 - ETA: 2:00 - loss: 1.1548 - accuracy: 0.77 - ETA: 1:59 - loss: 1.1476 - accuracy: 0.77 - ETA: 1:58 - loss: 1.1467 - accuracy: 0.77 - ETA: 1:57 - loss: 1.1316 - accuracy: 0.77 - ETA: 1:56 - loss: 1.1313 - accuracy: 0.77 - ETA: 1:55 - loss: 1.1287 - accuracy: 0.77 - ETA: 1:54 - loss: 1.1332 - accuracy: 0.77 - ETA: 1:53 - loss: 1.1363 - accuracy: 0.77 - ETA: 1:52 - loss: 1.1284 - accuracy: 0.77 - ETA: 1:51 - loss: 1.1318 - accuracy: 0.77 - ETA: 1:51 - loss: 1.1508 - accuracy: 0.77 - ETA: 1:49 - loss: 1.1569 - accuracy: 0.77 - ETA: 1:48 - loss: 1.1486 - accuracy: 0.77 - ETA: 1:48 - loss: 1.1459 - accuracy: 0.77 - ETA: 1:47 - loss: 1.1500 - accuracy: 0.77 - ETA: 1:45 - loss: 1.1528 - accuracy: 0.77 - ETA: 1:45 - loss: 1.1638 - accuracy: 0.76 - ETA: 1:44 - loss: 1.1556 - accuracy: 0.76 - ETA: 1:43 - loss: 1.1690 - accuracy: 0.76 - ETA: 1:42 - loss: 1.1701 - accuracy: 0.76 - ETA: 1:41 - loss: 1.1650 - accuracy: 0.76 - ETA: 1:40 - loss: 1.1600 - accuracy: 0.76 - ETA: 1:39 - loss: 1.1545 - accuracy: 0.76 - ETA: 1:38 - loss: 1.1544 - accuracy: 0.76 - ETA: 1:37 - loss: 1.1579 - accuracy: 0.76 - ETA: 1:36 - loss: 1.1569 - accuracy: 0.76 - ETA: 1:35 - loss: 1.1606 - accuracy: 0.76 - ETA: 1:34 - loss: 1.1662 - accuracy: 0.76 - ETA: 1:33 - loss: 1.1613 - accuracy: 0.76 - ETA: 1:32 - loss: 1.1692 - accuracy: 0.76 - ETA: 1:31 - loss: 1.1730 - accuracy: 0.76 - ETA: 1:30 - loss: 1.1762 - accuracy: 0.76 - ETA: 1:29 - loss: 1.1689 - accuracy: 0.76 - ETA: 1:29 - loss: 1.1703 - accuracy: 0.76 - ETA: 1:28 - loss: 1.1713 - accuracy: 0.76 - ETA: 1:27 - loss: 1.1684 - accuracy: 0.76 - ETA: 1:26 - loss: 1.1634 - accuracy: 0.76 - ETA: 1:25 - loss: 1.1638 - accuracy: 0.76 - ETA: 1:24 - loss: 1.1672 - accuracy: 0.76 - ETA: 1:23 - loss: 1.1760 - accuracy: 0.76 - ETA: 1:22 - loss: 1.1714 - accuracy: 0.76 - ETA: 1:21 - loss: 1.1698 - accuracy: 0.76 - ETA: 1:20 - loss: 1.1702 - accuracy: 0.76 - ETA: 1:19 - loss: 1.1666 - accuracy: 0.76 - ETA: 1:18 - loss: 1.1650 - accuracy: 0.76 - ETA: 1:17 - loss: 1.1673 - accuracy: 0.76 - ETA: 1:16 - loss: 1.1668 - accuracy: 0.76 - ETA: 1:15 - loss: 1.1630 - accuracy: 0.76 - ETA: 1:14 - loss: 1.1688 - accuracy: 0.76 - ETA: 1:13 - loss: 1.1709 - accuracy: 0.76 - ETA: 1:12 - loss: 1.1690 - accuracy: 0.76 - ETA: 1:11 - loss: 1.1633 - accuracy: 0.76 - ETA: 1:10 - loss: 1.1753 - accuracy: 0.76 - ETA: 1:09 - loss: 1.1732 - accuracy: 0.76 - ETA: 1:08 - loss: 1.1728 - accuracy: 0.76 - ETA: 1:07 - loss: 1.1759 - accuracy: 0.76 - ETA: 1:06 - loss: 1.1811 - accuracy: 0.76 - ETA: 1:05 - loss: 1.1860 - accuracy: 0.76 - ETA: 1:04 - loss: 1.1867 - accuracy: 0.76 - ETA: 1:03 - loss: 1.1852 - accuracy: 0.76 - ETA: 1:02 - loss: 1.1872 - accuracy: 0.76 - ETA: 1:01 - loss: 1.1927 - accuracy: 0.76 - ETA: 1:00 - loss: 1.1861 - accuracy: 0.76 - ETA: 59s - loss: 1.1815 - accuracy: 0.7657 - ETA: 58s - loss: 1.1778 - accuracy: 0.766 - ETA: 57s - loss: 1.1810 - accuracy: 0.765 - ETA: 57s - loss: 1.1835 - accuracy: 0.765 - ETA: 56s - loss: 1.1846 - accuracy: 0.766 - ETA: 55s - loss: 1.1820 - accuracy: 0.765 - ETA: 54s - loss: 1.1796 - accuracy: 0.765 - ETA: 53s - loss: 1.1847 - accuracy: 0.764 - ETA: 52s - loss: 1.1834 - accuracy: 0.764 - ETA: 51s - loss: 1.1813 - accuracy: 0.764 - ETA: 50s - loss: 1.1798 - accuracy: 0.764 - ETA: 49s - loss: 1.1765 - accuracy: 0.764 - ETA: 48s - loss: 1.1794 - accuracy: 0.763 - ETA: 47s - loss: 1.1789 - accuracy: 0.763 - ETA: 46s - loss: 1.1748 - accuracy: 0.764 - ETA: 45s - loss: 1.1726 - accuracy: 0.764 - ETA: 44s - loss: 1.1741 - accuracy: 0.764 - ETA: 43s - loss: 1.1758 - accuracy: 0.764 - ETA: 42s - loss: 1.1762 - accuracy: 0.764 - ETA: 41s - loss: 1.1778 - accuracy: 0.763 - ETA: 40s - loss: 1.1853 - accuracy: 0.763 - ETA: 39s - loss: 1.1861 - accuracy: 0.763 - ETA: 38s - loss: 1.1921 - accuracy: 0.762 - ETA: 37s - loss: 1.1908 - accuracy: 0.762 - ETA: 36s - loss: 1.1923 - accuracy: 0.762 - ETA: 35s - loss: 1.1906 - accuracy: 0.762 - ETA: 34s - loss: 1.1917 - accuracy: 0.762 - ETA: 33s - loss: 1.1932 - accuracy: 0.761 - ETA: 32s - loss: 1.1960 - accuracy: 0.761 - ETA: 31s - loss: 1.1926 - accuracy: 0.761 - ETA: 30s - loss: 1.1929 - accuracy: 0.760 - ETA: 29s - loss: 1.1906 - accuracy: 0.761 - ETA: 28s - loss: 1.1888 - accuracy: 0.761 - ETA: 27s - loss: 1.1872 - accuracy: 0.761 - ETA: 27s - loss: 1.1883 - accuracy: 0.760 - ETA: 26s - loss: 1.1860 - accuracy: 0.761 - ETA: 25s - loss: 1.1868 - accuracy: 0.761 - ETA: 24s - loss: 1.1865 - accuracy: 0.761 - ETA: 23s - loss: 1.1847 - accuracy: 0.761 - ETA: 22s - loss: 1.1836 - accuracy: 0.761 - ETA: 21s - loss: 1.1840 - accuracy: 0.761 - ETA: 20s - loss: 1.1848 - accuracy: 0.761 - ETA: 19s - loss: 1.1885 - accuracy: 0.761 - ETA: 18s - loss: 1.1894 - accuracy: 0.760 - ETA: 17s - loss: 1.1906 - accuracy: 0.760 - ETA: 16s - loss: 1.1877 - accuracy: 0.761 - ETA: 15s - loss: 1.1904 - accuracy: 0.761 - ETA: 14s - loss: 1.1899 - accuracy: 0.761 - ETA: 13s - loss: 1.1913 - accuracy: 0.761 - ETA: 12s - loss: 1.1909 - accuracy: 0.761 - ETA: 11s - loss: 1.1923 - accuracy: 0.761 - ETA: 10s - loss: 1.1914 - accuracy: 0.761 - ETA: 9s - loss: 1.1918 - accuracy: 0.761 - ETA: 8s - loss: 1.1909 - accuracy: 0.76 - ETA: 7s - loss: 1.1889 - accuracy: 0.76 - ETA: 6s - loss: 1.1894 - accuracy: 0.76 - ETA: 5s - loss: 1.1892 - accuracy: 0.76 - ETA: 4s - loss: 1.1919 - accuracy: 0.76 - ETA: 3s - loss: 1.1899 - accuracy: 0.76 - ETA: 2s - loss: 1.1878 - accuracy: 0.76 - ETA: 1s - loss: 1.1893 - accuracy: 0.76 - ETA: 0s - loss: 1.1937 - accuracy: 0.76 - 157s 8ms/step - loss: 1.1938 - accuracy: 0.7612 - val_loss: 1.8776 - val_accuracy: 0.7190\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:33 - loss: 1.6247 - accuracy: 0.75 - ETA: 2:27 - loss: 1.2803 - accuracy: 0.75 - ETA: 2:26 - loss: 1.2140 - accuracy: 0.77 - ETA: 2:27 - loss: 1.1484 - accuracy: 0.76 - ETA: 2:26 - loss: 1.2886 - accuracy: 0.75 - ETA: 2:23 - loss: 1.2461 - accuracy: 0.75 - ETA: 2:21 - loss: 1.2638 - accuracy: 0.76 - ETA: 2:19 - loss: 1.2009 - accuracy: 0.77 - ETA: 2:19 - loss: 1.1860 - accuracy: 0.77 - ETA: 2:18 - loss: 1.2088 - accuracy: 0.77 - ETA: 2:18 - loss: 1.2554 - accuracy: 0.76 - ETA: 2:16 - loss: 1.2338 - accuracy: 0.76 - ETA: 2:14 - loss: 1.2095 - accuracy: 0.76 - ETA: 2:13 - loss: 1.1997 - accuracy: 0.76 - ETA: 2:12 - loss: 1.1797 - accuracy: 0.76 - ETA: 2:11 - loss: 1.1835 - accuracy: 0.76 - ETA: 2:10 - loss: 1.1733 - accuracy: 0.77 - ETA: 2:08 - loss: 1.1772 - accuracy: 0.77 - ETA: 2:07 - loss: 1.1535 - accuracy: 0.77 - ETA: 2:06 - loss: 1.1487 - accuracy: 0.77 - ETA: 2:06 - loss: 1.1430 - accuracy: 0.77 - ETA: 2:05 - loss: 1.1526 - accuracy: 0.77 - ETA: 2:04 - loss: 1.1510 - accuracy: 0.77 - ETA: 2:03 - loss: 1.1488 - accuracy: 0.77 - ETA: 2:02 - loss: 1.1438 - accuracy: 0.78 - ETA: 2:02 - loss: 1.1351 - accuracy: 0.78 - ETA: 2:01 - loss: 1.1289 - accuracy: 0.78 - ETA: 2:00 - loss: 1.1346 - accuracy: 0.78 - ETA: 1:59 - loss: 1.1370 - accuracy: 0.78 - ETA: 1:59 - loss: 1.1384 - accuracy: 0.78 - ETA: 1:58 - loss: 1.1328 - accuracy: 0.78 - ETA: 1:57 - loss: 1.1412 - accuracy: 0.78 - ETA: 1:56 - loss: 1.1379 - accuracy: 0.78 - ETA: 1:55 - loss: 1.1462 - accuracy: 0.78 - ETA: 1:54 - loss: 1.1621 - accuracy: 0.77 - ETA: 1:54 - loss: 1.1634 - accuracy: 0.77 - ETA: 1:53 - loss: 1.1667 - accuracy: 0.77 - ETA: 1:52 - loss: 1.1844 - accuracy: 0.77 - ETA: 1:51 - loss: 1.1861 - accuracy: 0.77 - ETA: 1:50 - loss: 1.1845 - accuracy: 0.77 - ETA: 1:48 - loss: 1.1884 - accuracy: 0.77 - ETA: 1:47 - loss: 1.2057 - accuracy: 0.77 - ETA: 1:46 - loss: 1.1967 - accuracy: 0.77 - ETA: 1:45 - loss: 1.2063 - accuracy: 0.77 - ETA: 1:44 - loss: 1.1983 - accuracy: 0.77 - ETA: 1:43 - loss: 1.1994 - accuracy: 0.77 - ETA: 1:42 - loss: 1.2075 - accuracy: 0.77 - ETA: 1:41 - loss: 1.2130 - accuracy: 0.77 - ETA: 1:40 - loss: 1.2451 - accuracy: 0.76 - ETA: 1:39 - loss: 1.2418 - accuracy: 0.76 - ETA: 1:38 - loss: 1.2332 - accuracy: 0.77 - ETA: 1:37 - loss: 1.2289 - accuracy: 0.77 - ETA: 1:36 - loss: 1.2321 - accuracy: 0.76 - ETA: 1:35 - loss: 1.2398 - accuracy: 0.76 - ETA: 1:34 - loss: 1.2386 - accuracy: 0.76 - ETA: 1:33 - loss: 1.2293 - accuracy: 0.76 - ETA: 1:32 - loss: 1.2318 - accuracy: 0.76 - ETA: 1:31 - loss: 1.2274 - accuracy: 0.76 - ETA: 1:30 - loss: 1.2270 - accuracy: 0.76 - ETA: 1:29 - loss: 1.2282 - accuracy: 0.77 - ETA: 1:28 - loss: 1.2315 - accuracy: 0.76 - ETA: 1:27 - loss: 1.2297 - accuracy: 0.77 - ETA: 1:26 - loss: 1.2259 - accuracy: 0.76 - ETA: 1:25 - loss: 1.2239 - accuracy: 0.76 - ETA: 1:24 - loss: 1.2240 - accuracy: 0.76 - ETA: 1:23 - loss: 1.2204 - accuracy: 0.76 - ETA: 1:22 - loss: 1.2218 - accuracy: 0.76 - ETA: 1:21 - loss: 1.2218 - accuracy: 0.76 - ETA: 1:20 - loss: 1.2207 - accuracy: 0.76 - ETA: 1:19 - loss: 1.2194 - accuracy: 0.76 - ETA: 1:18 - loss: 1.2144 - accuracy: 0.76 - ETA: 1:17 - loss: 1.2117 - accuracy: 0.76 - ETA: 1:16 - loss: 1.2111 - accuracy: 0.76 - ETA: 1:15 - loss: 1.2125 - accuracy: 0.76 - ETA: 1:14 - loss: 1.2155 - accuracy: 0.76 - ETA: 1:13 - loss: 1.2101 - accuracy: 0.76 - ETA: 1:12 - loss: 1.2061 - accuracy: 0.76 - ETA: 1:11 - loss: 1.2056 - accuracy: 0.76 - ETA: 1:10 - loss: 1.2044 - accuracy: 0.76 - ETA: 1:09 - loss: 1.2067 - accuracy: 0.76 - ETA: 1:08 - loss: 1.2056 - accuracy: 0.76 - ETA: 1:07 - loss: 1.2121 - accuracy: 0.76 - ETA: 1:06 - loss: 1.2135 - accuracy: 0.76 - ETA: 1:05 - loss: 1.2116 - accuracy: 0.76 - ETA: 1:04 - loss: 1.2109 - accuracy: 0.76 - ETA: 1:03 - loss: 1.2079 - accuracy: 0.76 - ETA: 1:02 - loss: 1.2023 - accuracy: 0.76 - ETA: 1:01 - loss: 1.2059 - accuracy: 0.76 - ETA: 1:00 - loss: 1.2083 - accuracy: 0.76 - ETA: 59s - loss: 1.2060 - accuracy: 0.7675 - ETA: 58s - loss: 1.2045 - accuracy: 0.767 - ETA: 57s - loss: 1.2029 - accuracy: 0.768 - ETA: 56s - loss: 1.2016 - accuracy: 0.768 - ETA: 55s - loss: 1.1996 - accuracy: 0.768 - ETA: 54s - loss: 1.2019 - accuracy: 0.768 - ETA: 53s - loss: 1.2023 - accuracy: 0.768 - ETA: 52s - loss: 1.1999 - accuracy: 0.768 - ETA: 51s - loss: 1.2067 - accuracy: 0.767 - ETA: 50s - loss: 1.2060 - accuracy: 0.767 - ETA: 49s - loss: 1.2055 - accuracy: 0.767 - ETA: 48s - loss: 1.2102 - accuracy: 0.767 - ETA: 47s - loss: 1.2083 - accuracy: 0.767 - ETA: 46s - loss: 1.2049 - accuracy: 0.767 - ETA: 45s - loss: 1.2071 - accuracy: 0.767 - ETA: 44s - loss: 1.2043 - accuracy: 0.767 - ETA: 43s - loss: 1.2030 - accuracy: 0.767 - ETA: 42s - loss: 1.2039 - accuracy: 0.767 - ETA: 41s - loss: 1.2077 - accuracy: 0.767 - ETA: 40s - loss: 1.2045 - accuracy: 0.767 - ETA: 39s - loss: 1.2085 - accuracy: 0.766 - ETA: 38s - loss: 1.2099 - accuracy: 0.766 - ETA: 37s - loss: 1.2105 - accuracy: 0.766 - ETA: 36s - loss: 1.2088 - accuracy: 0.766 - ETA: 35s - loss: 1.2071 - accuracy: 0.766 - ETA: 34s - loss: 1.2057 - accuracy: 0.766 - ETA: 33s - loss: 1.2040 - accuracy: 0.766 - ETA: 32s - loss: 1.2070 - accuracy: 0.766 - ETA: 31s - loss: 1.2065 - accuracy: 0.766 - ETA: 30s - loss: 1.2083 - accuracy: 0.766 - ETA: 29s - loss: 1.2048 - accuracy: 0.766 - ETA: 28s - loss: 1.2040 - accuracy: 0.767 - ETA: 28s - loss: 1.2025 - accuracy: 0.767 - ETA: 27s - loss: 1.2043 - accuracy: 0.766 - ETA: 26s - loss: 1.2039 - accuracy: 0.766 - ETA: 25s - loss: 1.2070 - accuracy: 0.766 - ETA: 24s - loss: 1.2079 - accuracy: 0.766 - ETA: 23s - loss: 1.2074 - accuracy: 0.766 - ETA: 22s - loss: 1.2095 - accuracy: 0.766 - ETA: 21s - loss: 1.2107 - accuracy: 0.766 - ETA: 20s - loss: 1.2099 - accuracy: 0.765 - ETA: 19s - loss: 1.2078 - accuracy: 0.766 - ETA: 18s - loss: 1.2086 - accuracy: 0.766 - ETA: 17s - loss: 1.2082 - accuracy: 0.766 - ETA: 16s - loss: 1.2100 - accuracy: 0.765 - ETA: 15s - loss: 1.2095 - accuracy: 0.765 - ETA: 14s - loss: 1.2093 - accuracy: 0.765 - ETA: 13s - loss: 1.2099 - accuracy: 0.765 - ETA: 12s - loss: 1.2083 - accuracy: 0.765 - ETA: 11s - loss: 1.2054 - accuracy: 0.766 - ETA: 10s - loss: 1.2054 - accuracy: 0.766 - ETA: 9s - loss: 1.2053 - accuracy: 0.766 - ETA: 8s - loss: 1.2053 - accuracy: 0.76 - ETA: 7s - loss: 1.2059 - accuracy: 0.76 - ETA: 6s - loss: 1.2072 - accuracy: 0.76 - ETA: 5s - loss: 1.2050 - accuracy: 0.76 - ETA: 4s - loss: 1.2083 - accuracy: 0.76 - ETA: 3s - loss: 1.2097 - accuracy: 0.76 - ETA: 2s - loss: 1.2104 - accuracy: 0.76 - ETA: 1s - loss: 1.2098 - accuracy: 0.76 - ETA: 0s - loss: 1.2087 - accuracy: 0.76 - 157s 8ms/step - loss: 1.2090 - accuracy: 0.7646 - val_loss: 1.9522 - val_accuracy: 0.7186\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:24 - loss: 1.4985 - accuracy: 0.74 - ETA: 2:23 - loss: 1.1269 - accuracy: 0.77 - ETA: 2:21 - loss: 1.0529 - accuracy: 0.76 - ETA: 2:20 - loss: 1.0553 - accuracy: 0.75 - ETA: 2:22 - loss: 1.0327 - accuracy: 0.75 - ETA: 2:24 - loss: 0.9934 - accuracy: 0.77 - ETA: 2:24 - loss: 1.0623 - accuracy: 0.77 - ETA: 2:23 - loss: 1.0531 - accuracy: 0.78 - ETA: 2:22 - loss: 1.0951 - accuracy: 0.77 - ETA: 2:21 - loss: 1.0883 - accuracy: 0.78 - ETA: 2:19 - loss: 1.0933 - accuracy: 0.78 - ETA: 2:18 - loss: 1.1057 - accuracy: 0.78 - ETA: 2:17 - loss: 1.0667 - accuracy: 0.78 - ETA: 2:15 - loss: 1.0417 - accuracy: 0.79 - ETA: 2:14 - loss: 1.0565 - accuracy: 0.79 - ETA: 2:12 - loss: 1.0454 - accuracy: 0.79 - ETA: 2:10 - loss: 1.0454 - accuracy: 0.79 - ETA: 2:09 - loss: 1.0619 - accuracy: 0.79 - ETA: 2:08 - loss: 1.0721 - accuracy: 0.79 - ETA: 2:07 - loss: 1.0627 - accuracy: 0.79 - ETA: 2:06 - loss: 1.0578 - accuracy: 0.79 - ETA: 2:05 - loss: 1.0529 - accuracy: 0.79 - ETA: 2:05 - loss: 1.0562 - accuracy: 0.79 - ETA: 2:04 - loss: 1.0551 - accuracy: 0.79 - ETA: 2:03 - loss: 1.0617 - accuracy: 0.79 - ETA: 2:01 - loss: 1.0443 - accuracy: 0.79 - ETA: 2:01 - loss: 1.0486 - accuracy: 0.79 - ETA: 2:00 - loss: 1.0471 - accuracy: 0.79 - ETA: 1:59 - loss: 1.0479 - accuracy: 0.79 - ETA: 1:57 - loss: 1.0621 - accuracy: 0.79 - ETA: 1:56 - loss: 1.0554 - accuracy: 0.79 - ETA: 1:55 - loss: 1.0983 - accuracy: 0.79 - ETA: 1:54 - loss: 1.1005 - accuracy: 0.79 - ETA: 1:53 - loss: 1.1047 - accuracy: 0.79 - ETA: 1:52 - loss: 1.1124 - accuracy: 0.79 - ETA: 1:51 - loss: 1.1108 - accuracy: 0.79 - ETA: 1:50 - loss: 1.1123 - accuracy: 0.79 - ETA: 1:49 - loss: 1.1165 - accuracy: 0.79 - ETA: 1:49 - loss: 1.1277 - accuracy: 0.78 - ETA: 1:48 - loss: 1.1301 - accuracy: 0.78 - ETA: 1:47 - loss: 1.1219 - accuracy: 0.78 - ETA: 1:46 - loss: 1.1346 - accuracy: 0.78 - ETA: 1:45 - loss: 1.1357 - accuracy: 0.78 - ETA: 1:44 - loss: 1.1301 - accuracy: 0.78 - ETA: 1:42 - loss: 1.1226 - accuracy: 0.78 - ETA: 1:42 - loss: 1.1294 - accuracy: 0.78 - ETA: 1:41 - loss: 1.1293 - accuracy: 0.78 - ETA: 1:39 - loss: 1.1332 - accuracy: 0.78 - ETA: 1:38 - loss: 1.1334 - accuracy: 0.78 - ETA: 1:37 - loss: 1.1384 - accuracy: 0.78 - ETA: 1:36 - loss: 1.1366 - accuracy: 0.78 - ETA: 1:35 - loss: 1.1343 - accuracy: 0.78 - ETA: 1:34 - loss: 1.1329 - accuracy: 0.78 - ETA: 1:33 - loss: 1.1319 - accuracy: 0.78 - ETA: 1:32 - loss: 1.1301 - accuracy: 0.78 - ETA: 1:32 - loss: 1.1360 - accuracy: 0.78 - ETA: 1:31 - loss: 1.1306 - accuracy: 0.78 - ETA: 1:30 - loss: 1.1388 - accuracy: 0.78 - ETA: 1:29 - loss: 1.1439 - accuracy: 0.78 - ETA: 1:28 - loss: 1.1473 - accuracy: 0.78 - ETA: 1:27 - loss: 1.1451 - accuracy: 0.78 - ETA: 1:26 - loss: 1.1433 - accuracy: 0.78 - ETA: 1:25 - loss: 1.1501 - accuracy: 0.78 - ETA: 1:24 - loss: 1.1475 - accuracy: 0.78 - ETA: 1:23 - loss: 1.1509 - accuracy: 0.78 - ETA: 1:22 - loss: 1.1607 - accuracy: 0.78 - ETA: 1:21 - loss: 1.1571 - accuracy: 0.78 - ETA: 1:20 - loss: 1.1584 - accuracy: 0.78 - ETA: 1:19 - loss: 1.1567 - accuracy: 0.78 - ETA: 1:18 - loss: 1.1531 - accuracy: 0.78 - ETA: 1:17 - loss: 1.1543 - accuracy: 0.78 - ETA: 1:16 - loss: 1.1477 - accuracy: 0.78 - ETA: 1:15 - loss: 1.1482 - accuracy: 0.78 - ETA: 1:14 - loss: 1.1435 - accuracy: 0.78 - ETA: 1:13 - loss: 1.1433 - accuracy: 0.78 - ETA: 1:12 - loss: 1.1396 - accuracy: 0.78 - ETA: 1:11 - loss: 1.1405 - accuracy: 0.77 - ETA: 1:10 - loss: 1.1456 - accuracy: 0.77 - ETA: 1:09 - loss: 1.1439 - accuracy: 0.77 - ETA: 1:08 - loss: 1.1427 - accuracy: 0.77 - ETA: 1:07 - loss: 1.1469 - accuracy: 0.77 - ETA: 1:06 - loss: 1.1482 - accuracy: 0.77 - ETA: 1:05 - loss: 1.1450 - accuracy: 0.77 - ETA: 1:04 - loss: 1.1437 - accuracy: 0.77 - ETA: 1:03 - loss: 1.1458 - accuracy: 0.77 - ETA: 1:02 - loss: 1.1489 - accuracy: 0.77 - ETA: 1:01 - loss: 1.1456 - accuracy: 0.77 - ETA: 1:00 - loss: 1.1447 - accuracy: 0.77 - ETA: 1:00 - loss: 1.1474 - accuracy: 0.77 - ETA: 59s - loss: 1.1490 - accuracy: 0.7777 - ETA: 58s - loss: 1.1508 - accuracy: 0.777 - ETA: 57s - loss: 1.1525 - accuracy: 0.777 - ETA: 56s - loss: 1.1529 - accuracy: 0.778 - ETA: 55s - loss: 1.1493 - accuracy: 0.778 - ETA: 54s - loss: 1.1557 - accuracy: 0.777 - ETA: 53s - loss: 1.1573 - accuracy: 0.777 - ETA: 52s - loss: 1.1609 - accuracy: 0.777 - ETA: 51s - loss: 1.1592 - accuracy: 0.777 - ETA: 50s - loss: 1.1621 - accuracy: 0.777 - ETA: 49s - loss: 1.1666 - accuracy: 0.777 - ETA: 48s - loss: 1.1638 - accuracy: 0.778 - ETA: 47s - loss: 1.1677 - accuracy: 0.778 - ETA: 46s - loss: 1.1651 - accuracy: 0.778 - ETA: 45s - loss: 1.1664 - accuracy: 0.778 - ETA: 44s - loss: 1.1651 - accuracy: 0.777 - ETA: 43s - loss: 1.1694 - accuracy: 0.777 - ETA: 42s - loss: 1.1782 - accuracy: 0.776 - ETA: 41s - loss: 1.1809 - accuracy: 0.776 - ETA: 40s - loss: 1.1777 - accuracy: 0.776 - ETA: 39s - loss: 1.1803 - accuracy: 0.776 - ETA: 38s - loss: 1.1805 - accuracy: 0.776 - ETA: 37s - loss: 1.1793 - accuracy: 0.776 - ETA: 36s - loss: 1.1810 - accuracy: 0.776 - ETA: 35s - loss: 1.1907 - accuracy: 0.775 - ETA: 34s - loss: 1.1928 - accuracy: 0.775 - ETA: 33s - loss: 1.1979 - accuracy: 0.775 - ETA: 32s - loss: 1.2011 - accuracy: 0.775 - ETA: 31s - loss: 1.2028 - accuracy: 0.774 - ETA: 30s - loss: 1.2032 - accuracy: 0.774 - ETA: 29s - loss: 1.2027 - accuracy: 0.774 - ETA: 28s - loss: 1.2017 - accuracy: 0.774 - ETA: 27s - loss: 1.1999 - accuracy: 0.774 - ETA: 27s - loss: 1.2005 - accuracy: 0.774 - ETA: 26s - loss: 1.1974 - accuracy: 0.775 - ETA: 25s - loss: 1.1936 - accuracy: 0.775 - ETA: 24s - loss: 1.1954 - accuracy: 0.775 - ETA: 23s - loss: 1.1939 - accuracy: 0.775 - ETA: 22s - loss: 1.1955 - accuracy: 0.774 - ETA: 21s - loss: 1.1998 - accuracy: 0.774 - ETA: 20s - loss: 1.1981 - accuracy: 0.774 - ETA: 19s - loss: 1.2027 - accuracy: 0.774 - ETA: 18s - loss: 1.2001 - accuracy: 0.775 - ETA: 17s - loss: 1.1978 - accuracy: 0.775 - ETA: 16s - loss: 1.1992 - accuracy: 0.775 - ETA: 15s - loss: 1.1988 - accuracy: 0.775 - ETA: 14s - loss: 1.1975 - accuracy: 0.775 - ETA: 13s - loss: 1.1996 - accuracy: 0.775 - ETA: 12s - loss: 1.2010 - accuracy: 0.775 - ETA: 11s - loss: 1.1999 - accuracy: 0.775 - ETA: 10s - loss: 1.1994 - accuracy: 0.775 - ETA: 9s - loss: 1.1954 - accuracy: 0.775 - ETA: 8s - loss: 1.1979 - accuracy: 0.77 - ETA: 7s - loss: 1.1955 - accuracy: 0.77 - ETA: 6s - loss: 1.1960 - accuracy: 0.77 - ETA: 5s - loss: 1.1947 - accuracy: 0.77 - ETA: 4s - loss: 1.1947 - accuracy: 0.77 - ETA: 3s - loss: 1.1984 - accuracy: 0.77 - ETA: 2s - loss: 1.1955 - accuracy: 0.77 - ETA: 1s - loss: 1.1952 - accuracy: 0.77 - ETA: 0s - loss: 1.1940 - accuracy: 0.77 - 158s 8ms/step - loss: 1.1943 - accuracy: 0.7761 - val_loss: 1.9776 - val_accuracy: 0.7343\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 0.8856 - accuracy: 0.82 - ETA: 2:25 - loss: 0.8517 - accuracy: 0.81 - ETA: 2:24 - loss: 0.8501 - accuracy: 0.80 - ETA: 2:21 - loss: 0.9708 - accuracy: 0.78 - ETA: 2:18 - loss: 1.1941 - accuracy: 0.78 - ETA: 2:18 - loss: 1.1224 - accuracy: 0.79 - ETA: 2:16 - loss: 1.2067 - accuracy: 0.78 - ETA: 2:18 - loss: 1.2060 - accuracy: 0.77 - ETA: 2:17 - loss: 1.1494 - accuracy: 0.78 - ETA: 2:16 - loss: 1.1888 - accuracy: 0.77 - ETA: 2:15 - loss: 1.1761 - accuracy: 0.78 - ETA: 2:13 - loss: 1.1622 - accuracy: 0.78 - ETA: 2:12 - loss: 1.1835 - accuracy: 0.77 - ETA: 2:11 - loss: 1.1784 - accuracy: 0.77 - ETA: 2:10 - loss: 1.1879 - accuracy: 0.77 - ETA: 2:09 - loss: 1.1854 - accuracy: 0.77 - ETA: 2:08 - loss: 1.1649 - accuracy: 0.77 - ETA: 2:07 - loss: 1.1607 - accuracy: 0.77 - ETA: 2:06 - loss: 1.1763 - accuracy: 0.77 - ETA: 2:05 - loss: 1.1919 - accuracy: 0.77 - ETA: 2:04 - loss: 1.1790 - accuracy: 0.77 - ETA: 2:03 - loss: 1.1594 - accuracy: 0.78 - ETA: 2:02 - loss: 1.1574 - accuracy: 0.78 - ETA: 2:01 - loss: 1.1458 - accuracy: 0.78 - ETA: 2:01 - loss: 1.1473 - accuracy: 0.78 - ETA: 2:00 - loss: 1.1399 - accuracy: 0.78 - ETA: 1:59 - loss: 1.1308 - accuracy: 0.77 - ETA: 1:58 - loss: 1.1272 - accuracy: 0.78 - ETA: 1:57 - loss: 1.1503 - accuracy: 0.78 - ETA: 1:56 - loss: 1.1562 - accuracy: 0.77 - ETA: 1:55 - loss: 1.1642 - accuracy: 0.77 - ETA: 1:54 - loss: 1.1725 - accuracy: 0.77 - ETA: 1:53 - loss: 1.1672 - accuracy: 0.77 - ETA: 1:52 - loss: 1.1595 - accuracy: 0.77 - ETA: 1:51 - loss: 1.1503 - accuracy: 0.77 - ETA: 1:50 - loss: 1.1486 - accuracy: 0.77 - ETA: 1:49 - loss: 1.1442 - accuracy: 0.77 - ETA: 1:48 - loss: 1.1439 - accuracy: 0.77 - ETA: 1:47 - loss: 1.1573 - accuracy: 0.77 - ETA: 1:46 - loss: 1.1451 - accuracy: 0.77 - ETA: 1:45 - loss: 1.1413 - accuracy: 0.77 - ETA: 1:44 - loss: 1.1425 - accuracy: 0.77 - ETA: 1:43 - loss: 1.1407 - accuracy: 0.77 - ETA: 1:43 - loss: 1.1462 - accuracy: 0.77 - ETA: 1:42 - loss: 1.1476 - accuracy: 0.77 - ETA: 1:41 - loss: 1.1422 - accuracy: 0.77 - ETA: 1:40 - loss: 1.1359 - accuracy: 0.77 - ETA: 1:39 - loss: 1.1399 - accuracy: 0.77 - ETA: 1:38 - loss: 1.1441 - accuracy: 0.77 - ETA: 1:37 - loss: 1.1425 - accuracy: 0.77 - ETA: 1:37 - loss: 1.1513 - accuracy: 0.77 - ETA: 1:35 - loss: 1.1443 - accuracy: 0.77 - ETA: 1:34 - loss: 1.1414 - accuracy: 0.77 - ETA: 1:33 - loss: 1.1395 - accuracy: 0.77 - ETA: 1:32 - loss: 1.1469 - accuracy: 0.77 - ETA: 1:31 - loss: 1.1449 - accuracy: 0.77 - ETA: 1:30 - loss: 1.1491 - accuracy: 0.77 - ETA: 1:30 - loss: 1.1451 - accuracy: 0.77 - ETA: 1:29 - loss: 1.1390 - accuracy: 0.77 - ETA: 1:28 - loss: 1.1361 - accuracy: 0.77 - ETA: 1:27 - loss: 1.1425 - accuracy: 0.77 - ETA: 1:26 - loss: 1.1457 - accuracy: 0.77 - ETA: 1:25 - loss: 1.1478 - accuracy: 0.77 - ETA: 1:24 - loss: 1.1494 - accuracy: 0.77 - ETA: 1:23 - loss: 1.1591 - accuracy: 0.77 - ETA: 1:22 - loss: 1.1553 - accuracy: 0.77 - ETA: 1:21 - loss: 1.1559 - accuracy: 0.77 - ETA: 1:19 - loss: 1.1518 - accuracy: 0.77 - ETA: 1:19 - loss: 1.1517 - accuracy: 0.77 - ETA: 1:18 - loss: 1.1493 - accuracy: 0.77 - ETA: 1:17 - loss: 1.1504 - accuracy: 0.77 - ETA: 1:16 - loss: 1.1538 - accuracy: 0.77 - ETA: 1:15 - loss: 1.1522 - accuracy: 0.77 - ETA: 1:14 - loss: 1.1571 - accuracy: 0.77 - ETA: 1:13 - loss: 1.1572 - accuracy: 0.77 - ETA: 1:12 - loss: 1.1573 - accuracy: 0.77 - ETA: 1:11 - loss: 1.1591 - accuracy: 0.77 - ETA: 1:10 - loss: 1.1617 - accuracy: 0.77 - ETA: 1:09 - loss: 1.1599 - accuracy: 0.77 - ETA: 1:08 - loss: 1.1562 - accuracy: 0.77 - ETA: 1:07 - loss: 1.1564 - accuracy: 0.77 - ETA: 1:06 - loss: 1.1590 - accuracy: 0.77 - ETA: 1:05 - loss: 1.1632 - accuracy: 0.77 - ETA: 1:04 - loss: 1.1613 - accuracy: 0.77 - ETA: 1:03 - loss: 1.1632 - accuracy: 0.77 - ETA: 1:02 - loss: 1.1659 - accuracy: 0.77 - ETA: 1:02 - loss: 1.1680 - accuracy: 0.77 - ETA: 1:01 - loss: 1.1698 - accuracy: 0.77 - ETA: 1:00 - loss: 1.1669 - accuracy: 0.77 - ETA: 59s - loss: 1.1671 - accuracy: 0.7757 - ETA: 58s - loss: 1.1679 - accuracy: 0.776 - ETA: 57s - loss: 1.1655 - accuracy: 0.776 - ETA: 56s - loss: 1.1629 - accuracy: 0.776 - ETA: 55s - loss: 1.1655 - accuracy: 0.776 - ETA: 54s - loss: 1.1627 - accuracy: 0.777 - ETA: 53s - loss: 1.1612 - accuracy: 0.777 - ETA: 52s - loss: 1.1551 - accuracy: 0.777 - ETA: 51s - loss: 1.1560 - accuracy: 0.778 - ETA: 50s - loss: 1.1549 - accuracy: 0.777 - ETA: 49s - loss: 1.1514 - accuracy: 0.778 - ETA: 48s - loss: 1.1494 - accuracy: 0.778 - ETA: 47s - loss: 1.1502 - accuracy: 0.778 - ETA: 46s - loss: 1.1563 - accuracy: 0.777 - ETA: 45s - loss: 1.1603 - accuracy: 0.776 - ETA: 44s - loss: 1.1570 - accuracy: 0.777 - ETA: 43s - loss: 1.1572 - accuracy: 0.777 - ETA: 42s - loss: 1.1527 - accuracy: 0.777 - ETA: 41s - loss: 1.1505 - accuracy: 0.777 - ETA: 40s - loss: 1.1498 - accuracy: 0.777 - ETA: 39s - loss: 1.1485 - accuracy: 0.777 - ETA: 38s - loss: 1.1493 - accuracy: 0.777 - ETA: 37s - loss: 1.1465 - accuracy: 0.778 - ETA: 36s - loss: 1.1488 - accuracy: 0.777 - ETA: 35s - loss: 1.1475 - accuracy: 0.778 - ETA: 34s - loss: 1.1471 - accuracy: 0.778 - ETA: 33s - loss: 1.1453 - accuracy: 0.778 - ETA: 32s - loss: 1.1459 - accuracy: 0.777 - ETA: 31s - loss: 1.1432 - accuracy: 0.777 - ETA: 30s - loss: 1.1412 - accuracy: 0.777 - ETA: 29s - loss: 1.1437 - accuracy: 0.777 - ETA: 28s - loss: 1.1467 - accuracy: 0.777 - ETA: 27s - loss: 1.1478 - accuracy: 0.777 - ETA: 27s - loss: 1.1458 - accuracy: 0.777 - ETA: 26s - loss: 1.1460 - accuracy: 0.777 - ETA: 25s - loss: 1.1454 - accuracy: 0.777 - ETA: 24s - loss: 1.1456 - accuracy: 0.777 - ETA: 23s - loss: 1.1463 - accuracy: 0.777 - ETA: 22s - loss: 1.1463 - accuracy: 0.777 - ETA: 21s - loss: 1.1466 - accuracy: 0.777 - ETA: 20s - loss: 1.1468 - accuracy: 0.778 - ETA: 19s - loss: 1.1492 - accuracy: 0.778 - ETA: 18s - loss: 1.1470 - accuracy: 0.778 - ETA: 17s - loss: 1.1479 - accuracy: 0.778 - ETA: 16s - loss: 1.1472 - accuracy: 0.778 - ETA: 15s - loss: 1.1477 - accuracy: 0.778 - ETA: 14s - loss: 1.1470 - accuracy: 0.778 - ETA: 13s - loss: 1.1473 - accuracy: 0.778 - ETA: 12s - loss: 1.1445 - accuracy: 0.778 - ETA: 11s - loss: 1.1445 - accuracy: 0.778 - ETA: 10s - loss: 1.1450 - accuracy: 0.778 - ETA: 9s - loss: 1.1469 - accuracy: 0.778 - ETA: 8s - loss: 1.1512 - accuracy: 0.77 - ETA: 7s - loss: 1.1508 - accuracy: 0.77 - ETA: 6s - loss: 1.1526 - accuracy: 0.77 - ETA: 5s - loss: 1.1532 - accuracy: 0.77 - ETA: 4s - loss: 1.1516 - accuracy: 0.77 - ETA: 3s - loss: 1.1486 - accuracy: 0.77 - ETA: 2s - loss: 1.1534 - accuracy: 0.77 - ETA: 1s - loss: 1.1522 - accuracy: 0.77 - ETA: 0s - loss: 1.1530 - accuracy: 0.77 - 158s 8ms/step - loss: 1.1554 - accuracy: 0.7774 - val_loss: 1.9366 - val_accuracy: 0.7349\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:22 - loss: 0.9141 - accuracy: 0.82 - ETA: 2:23 - loss: 0.9528 - accuracy: 0.82 - ETA: 2:22 - loss: 0.9796 - accuracy: 0.80 - ETA: 2:19 - loss: 1.0351 - accuracy: 0.80 - ETA: 2:17 - loss: 1.0525 - accuracy: 0.80 - ETA: 2:17 - loss: 1.0294 - accuracy: 0.79 - ETA: 2:16 - loss: 0.9806 - accuracy: 0.79 - ETA: 2:14 - loss: 0.9905 - accuracy: 0.79 - ETA: 2:13 - loss: 0.9458 - accuracy: 0.79 - ETA: 2:14 - loss: 0.9309 - accuracy: 0.80 - ETA: 2:15 - loss: 0.9418 - accuracy: 0.80 - ETA: 2:16 - loss: 0.9693 - accuracy: 0.80 - ETA: 2:15 - loss: 0.9851 - accuracy: 0.80 - ETA: 2:15 - loss: 0.9741 - accuracy: 0.80 - ETA: 2:15 - loss: 0.9895 - accuracy: 0.80 - ETA: 2:14 - loss: 1.0017 - accuracy: 0.79 - ETA: 2:13 - loss: 1.0098 - accuracy: 0.79 - ETA: 2:12 - loss: 1.0089 - accuracy: 0.79 - ETA: 2:10 - loss: 1.0238 - accuracy: 0.79 - ETA: 2:09 - loss: 1.0178 - accuracy: 0.79 - ETA: 2:08 - loss: 1.0211 - accuracy: 0.79 - ETA: 2:07 - loss: 1.0262 - accuracy: 0.79 - ETA: 2:06 - loss: 1.0290 - accuracy: 0.79 - ETA: 2:05 - loss: 1.0143 - accuracy: 0.79 - ETA: 2:04 - loss: 1.0163 - accuracy: 0.79 - ETA: 2:03 - loss: 1.0233 - accuracy: 0.79 - ETA: 2:02 - loss: 1.0267 - accuracy: 0.79 - ETA: 2:01 - loss: 1.0543 - accuracy: 0.78 - ETA: 2:00 - loss: 1.0346 - accuracy: 0.79 - ETA: 1:59 - loss: 1.0438 - accuracy: 0.78 - ETA: 1:58 - loss: 1.0526 - accuracy: 0.78 - ETA: 1:57 - loss: 1.0432 - accuracy: 0.79 - ETA: 1:56 - loss: 1.0454 - accuracy: 0.78 - ETA: 1:55 - loss: 1.0367 - accuracy: 0.79 - ETA: 1:54 - loss: 1.0338 - accuracy: 0.79 - ETA: 1:52 - loss: 1.0505 - accuracy: 0.78 - ETA: 1:51 - loss: 1.0445 - accuracy: 0.78 - ETA: 1:50 - loss: 1.0495 - accuracy: 0.78 - ETA: 1:49 - loss: 1.0466 - accuracy: 0.78 - ETA: 1:48 - loss: 1.0454 - accuracy: 0.78 - ETA: 1:47 - loss: 1.0464 - accuracy: 0.78 - ETA: 1:46 - loss: 1.0431 - accuracy: 0.78 - ETA: 1:45 - loss: 1.0512 - accuracy: 0.78 - ETA: 1:44 - loss: 1.0436 - accuracy: 0.78 - ETA: 1:43 - loss: 1.0617 - accuracy: 0.78 - ETA: 1:42 - loss: 1.0610 - accuracy: 0.78 - ETA: 1:41 - loss: 1.0603 - accuracy: 0.78 - ETA: 1:40 - loss: 1.0603 - accuracy: 0.78 - ETA: 1:39 - loss: 1.0597 - accuracy: 0.78 - ETA: 1:38 - loss: 1.0626 - accuracy: 0.78 - ETA: 1:37 - loss: 1.0598 - accuracy: 0.78 - ETA: 1:36 - loss: 1.0590 - accuracy: 0.78 - ETA: 1:35 - loss: 1.0553 - accuracy: 0.78 - ETA: 1:34 - loss: 1.0617 - accuracy: 0.78 - ETA: 1:33 - loss: 1.0611 - accuracy: 0.78 - ETA: 1:32 - loss: 1.0615 - accuracy: 0.78 - ETA: 1:31 - loss: 1.0668 - accuracy: 0.78 - ETA: 1:30 - loss: 1.0631 - accuracy: 0.78 - ETA: 1:29 - loss: 1.0705 - accuracy: 0.78 - ETA: 1:28 - loss: 1.0730 - accuracy: 0.78 - ETA: 1:27 - loss: 1.0733 - accuracy: 0.78 - ETA: 1:26 - loss: 1.0689 - accuracy: 0.78 - ETA: 1:25 - loss: 1.0679 - accuracy: 0.78 - ETA: 1:24 - loss: 1.0636 - accuracy: 0.78 - ETA: 1:23 - loss: 1.0639 - accuracy: 0.78 - ETA: 1:22 - loss: 1.0601 - accuracy: 0.78 - ETA: 1:21 - loss: 1.0640 - accuracy: 0.78 - ETA: 1:20 - loss: 1.0634 - accuracy: 0.78 - ETA: 1:19 - loss: 1.0608 - accuracy: 0.78 - ETA: 1:18 - loss: 1.0676 - accuracy: 0.78 - ETA: 1:17 - loss: 1.0739 - accuracy: 0.78 - ETA: 1:16 - loss: 1.0711 - accuracy: 0.78 - ETA: 1:15 - loss: 1.0681 - accuracy: 0.78 - ETA: 1:14 - loss: 1.0697 - accuracy: 0.78 - ETA: 1:13 - loss: 1.0695 - accuracy: 0.78 - ETA: 1:12 - loss: 1.0691 - accuracy: 0.78 - ETA: 1:11 - loss: 1.0658 - accuracy: 0.78 - ETA: 1:10 - loss: 1.0644 - accuracy: 0.78 - ETA: 1:09 - loss: 1.0626 - accuracy: 0.78 - ETA: 1:08 - loss: 1.0663 - accuracy: 0.78 - ETA: 1:07 - loss: 1.0672 - accuracy: 0.78 - ETA: 1:06 - loss: 1.0655 - accuracy: 0.78 - ETA: 1:05 - loss: 1.0637 - accuracy: 0.78 - ETA: 1:04 - loss: 1.0759 - accuracy: 0.78 - ETA: 1:03 - loss: 1.0803 - accuracy: 0.78 - ETA: 1:02 - loss: 1.0850 - accuracy: 0.78 - ETA: 1:02 - loss: 1.0893 - accuracy: 0.78 - ETA: 1:01 - loss: 1.0846 - accuracy: 0.78 - ETA: 1:00 - loss: 1.0823 - accuracy: 0.78 - ETA: 59s - loss: 1.0909 - accuracy: 0.7845 - ETA: 58s - loss: 1.0862 - accuracy: 0.784 - ETA: 57s - loss: 1.0861 - accuracy: 0.785 - ETA: 56s - loss: 1.0876 - accuracy: 0.784 - ETA: 55s - loss: 1.0925 - accuracy: 0.784 - ETA: 54s - loss: 1.0947 - accuracy: 0.785 - ETA: 53s - loss: 1.1037 - accuracy: 0.784 - ETA: 52s - loss: 1.1030 - accuracy: 0.784 - ETA: 51s - loss: 1.1026 - accuracy: 0.784 - ETA: 50s - loss: 1.1002 - accuracy: 0.784 - ETA: 49s - loss: 1.1002 - accuracy: 0.785 - ETA: 48s - loss: 1.1005 - accuracy: 0.785 - ETA: 47s - loss: 1.1053 - accuracy: 0.785 - ETA: 46s - loss: 1.1047 - accuracy: 0.785 - ETA: 45s - loss: 1.1061 - accuracy: 0.785 - ETA: 44s - loss: 1.1052 - accuracy: 0.785 - ETA: 43s - loss: 1.1068 - accuracy: 0.786 - ETA: 42s - loss: 1.1053 - accuracy: 0.786 - ETA: 41s - loss: 1.1079 - accuracy: 0.786 - ETA: 40s - loss: 1.1066 - accuracy: 0.786 - ETA: 39s - loss: 1.1068 - accuracy: 0.786 - ETA: 38s - loss: 1.1054 - accuracy: 0.787 - ETA: 37s - loss: 1.1095 - accuracy: 0.786 - ETA: 36s - loss: 1.1100 - accuracy: 0.786 - ETA: 35s - loss: 1.1163 - accuracy: 0.786 - ETA: 34s - loss: 1.1174 - accuracy: 0.786 - ETA: 33s - loss: 1.1155 - accuracy: 0.786 - ETA: 32s - loss: 1.1171 - accuracy: 0.786 - ETA: 31s - loss: 1.1199 - accuracy: 0.786 - ETA: 30s - loss: 1.1191 - accuracy: 0.786 - ETA: 29s - loss: 1.1198 - accuracy: 0.786 - ETA: 28s - loss: 1.1192 - accuracy: 0.786 - ETA: 27s - loss: 1.1216 - accuracy: 0.786 - ETA: 27s - loss: 1.1214 - accuracy: 0.786 - ETA: 26s - loss: 1.1208 - accuracy: 0.786 - ETA: 25s - loss: 1.1225 - accuracy: 0.786 - ETA: 24s - loss: 1.1203 - accuracy: 0.786 - ETA: 23s - loss: 1.1211 - accuracy: 0.786 - ETA: 22s - loss: 1.1180 - accuracy: 0.786 - ETA: 21s - loss: 1.1173 - accuracy: 0.786 - ETA: 20s - loss: 1.1191 - accuracy: 0.786 - ETA: 19s - loss: 1.1209 - accuracy: 0.786 - ETA: 18s - loss: 1.1182 - accuracy: 0.786 - ETA: 17s - loss: 1.1153 - accuracy: 0.786 - ETA: 16s - loss: 1.1139 - accuracy: 0.786 - ETA: 15s - loss: 1.1149 - accuracy: 0.786 - ETA: 14s - loss: 1.1179 - accuracy: 0.786 - ETA: 13s - loss: 1.1160 - accuracy: 0.786 - ETA: 12s - loss: 1.1186 - accuracy: 0.786 - ETA: 11s - loss: 1.1182 - accuracy: 0.786 - ETA: 10s - loss: 1.1173 - accuracy: 0.787 - ETA: 9s - loss: 1.1181 - accuracy: 0.786 - ETA: 8s - loss: 1.1202 - accuracy: 0.78 - ETA: 7s - loss: 1.1194 - accuracy: 0.78 - ETA: 6s - loss: 1.1209 - accuracy: 0.78 - ETA: 5s - loss: 1.1198 - accuracy: 0.78 - ETA: 4s - loss: 1.1180 - accuracy: 0.78 - ETA: 3s - loss: 1.1211 - accuracy: 0.78 - ETA: 2s - loss: 1.1216 - accuracy: 0.78 - ETA: 1s - loss: 1.1215 - accuracy: 0.78 - ETA: 0s - loss: 1.1205 - accuracy: 0.78 - 157s 8ms/step - loss: 1.1219 - accuracy: 0.7872 - val_loss: 2.0768 - val_accuracy: 0.7372\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 1.5251 - accuracy: 0.71 - ETA: 2:24 - loss: 1.5210 - accuracy: 0.75 - ETA: 2:21 - loss: 1.3491 - accuracy: 0.76 - ETA: 2:21 - loss: 1.2610 - accuracy: 0.78 - ETA: 2:21 - loss: 1.2435 - accuracy: 0.77 - ETA: 2:19 - loss: 1.2271 - accuracy: 0.77 - ETA: 2:17 - loss: 1.1929 - accuracy: 0.78 - ETA: 2:17 - loss: 1.1692 - accuracy: 0.79 - ETA: 2:17 - loss: 1.1634 - accuracy: 0.78 - ETA: 2:17 - loss: 1.1629 - accuracy: 0.78 - ETA: 2:15 - loss: 1.1319 - accuracy: 0.79 - ETA: 2:14 - loss: 1.1028 - accuracy: 0.79 - ETA: 2:14 - loss: 1.1249 - accuracy: 0.79 - ETA: 2:13 - loss: 1.1514 - accuracy: 0.79 - ETA: 2:12 - loss: 1.1487 - accuracy: 0.79 - ETA: 2:11 - loss: 1.1726 - accuracy: 0.79 - ETA: 2:09 - loss: 1.1749 - accuracy: 0.79 - ETA: 2:08 - loss: 1.1783 - accuracy: 0.79 - ETA: 2:07 - loss: 1.1730 - accuracy: 0.79 - ETA: 2:06 - loss: 1.1505 - accuracy: 0.79 - ETA: 2:05 - loss: 1.1465 - accuracy: 0.79 - ETA: 2:03 - loss: 1.1483 - accuracy: 0.79 - ETA: 2:03 - loss: 1.1501 - accuracy: 0.78 - ETA: 2:02 - loss: 1.1424 - accuracy: 0.78 - ETA: 2:01 - loss: 1.1630 - accuracy: 0.78 - ETA: 2:00 - loss: 1.1595 - accuracy: 0.78 - ETA: 1:59 - loss: 1.1629 - accuracy: 0.78 - ETA: 1:58 - loss: 1.1851 - accuracy: 0.78 - ETA: 1:57 - loss: 1.1775 - accuracy: 0.78 - ETA: 1:56 - loss: 1.1960 - accuracy: 0.78 - ETA: 1:56 - loss: 1.2007 - accuracy: 0.78 - ETA: 1:54 - loss: 1.1929 - accuracy: 0.78 - ETA: 1:53 - loss: 1.1870 - accuracy: 0.78 - ETA: 1:53 - loss: 1.1863 - accuracy: 0.78 - ETA: 1:51 - loss: 1.1764 - accuracy: 0.78 - ETA: 1:50 - loss: 1.1746 - accuracy: 0.78 - ETA: 1:49 - loss: 1.1678 - accuracy: 0.78 - ETA: 1:48 - loss: 1.1669 - accuracy: 0.78 - ETA: 1:48 - loss: 1.1612 - accuracy: 0.78 - ETA: 1:47 - loss: 1.1471 - accuracy: 0.78 - ETA: 1:46 - loss: 1.1516 - accuracy: 0.78 - ETA: 1:45 - loss: 1.1450 - accuracy: 0.78 - ETA: 1:43 - loss: 1.1410 - accuracy: 0.78 - ETA: 1:43 - loss: 1.1467 - accuracy: 0.78 - ETA: 1:42 - loss: 1.1410 - accuracy: 0.78 - ETA: 1:41 - loss: 1.1405 - accuracy: 0.78 - ETA: 1:40 - loss: 1.1391 - accuracy: 0.78 - ETA: 1:39 - loss: 1.1408 - accuracy: 0.78 - ETA: 1:38 - loss: 1.1365 - accuracy: 0.78 - ETA: 1:37 - loss: 1.1343 - accuracy: 0.78 - ETA: 1:36 - loss: 1.1303 - accuracy: 0.78 - ETA: 1:35 - loss: 1.1312 - accuracy: 0.78 - ETA: 1:34 - loss: 1.1456 - accuracy: 0.78 - ETA: 1:33 - loss: 1.1476 - accuracy: 0.78 - ETA: 1:32 - loss: 1.1423 - accuracy: 0.78 - ETA: 1:31 - loss: 1.1411 - accuracy: 0.78 - ETA: 1:30 - loss: 1.1439 - accuracy: 0.78 - ETA: 1:29 - loss: 1.1478 - accuracy: 0.78 - ETA: 1:28 - loss: 1.1410 - accuracy: 0.78 - ETA: 1:27 - loss: 1.1392 - accuracy: 0.78 - ETA: 1:26 - loss: 1.1356 - accuracy: 0.78 - ETA: 1:25 - loss: 1.1324 - accuracy: 0.78 - ETA: 1:25 - loss: 1.1282 - accuracy: 0.78 - ETA: 1:24 - loss: 1.1283 - accuracy: 0.78 - ETA: 1:23 - loss: 1.1228 - accuracy: 0.78 - ETA: 1:22 - loss: 1.1203 - accuracy: 0.78 - ETA: 1:21 - loss: 1.1243 - accuracy: 0.78 - ETA: 1:20 - loss: 1.1258 - accuracy: 0.78 - ETA: 1:19 - loss: 1.1306 - accuracy: 0.78 - ETA: 1:18 - loss: 1.1269 - accuracy: 0.78 - ETA: 1:17 - loss: 1.1229 - accuracy: 0.78 - ETA: 1:16 - loss: 1.1271 - accuracy: 0.78 - ETA: 1:15 - loss: 1.1267 - accuracy: 0.78 - ETA: 1:14 - loss: 1.1269 - accuracy: 0.78 - ETA: 1:13 - loss: 1.1215 - accuracy: 0.78 - ETA: 1:12 - loss: 1.1149 - accuracy: 0.78 - ETA: 1:11 - loss: 1.1145 - accuracy: 0.78 - ETA: 1:10 - loss: 1.1164 - accuracy: 0.78 - ETA: 1:09 - loss: 1.1155 - accuracy: 0.78 - ETA: 1:08 - loss: 1.1174 - accuracy: 0.78 - ETA: 1:07 - loss: 1.1171 - accuracy: 0.78 - ETA: 1:06 - loss: 1.1177 - accuracy: 0.78 - ETA: 1:05 - loss: 1.1182 - accuracy: 0.78 - ETA: 1:04 - loss: 1.1273 - accuracy: 0.78 - ETA: 1:03 - loss: 1.1274 - accuracy: 0.78 - ETA: 1:02 - loss: 1.1303 - accuracy: 0.78 - ETA: 1:01 - loss: 1.1302 - accuracy: 0.78 - ETA: 1:00 - loss: 1.1293 - accuracy: 0.78 - ETA: 59s - loss: 1.1311 - accuracy: 0.7841 - ETA: 58s - loss: 1.1294 - accuracy: 0.784 - ETA: 57s - loss: 1.1292 - accuracy: 0.784 - ETA: 56s - loss: 1.1252 - accuracy: 0.785 - ETA: 56s - loss: 1.1239 - accuracy: 0.785 - ETA: 55s - loss: 1.1230 - accuracy: 0.785 - ETA: 54s - loss: 1.1210 - accuracy: 0.785 - ETA: 53s - loss: 1.1209 - accuracy: 0.785 - ETA: 52s - loss: 1.1170 - accuracy: 0.785 - ETA: 51s - loss: 1.1163 - accuracy: 0.785 - ETA: 50s - loss: 1.1154 - accuracy: 0.785 - ETA: 49s - loss: 1.1164 - accuracy: 0.785 - ETA: 48s - loss: 1.1173 - accuracy: 0.785 - ETA: 47s - loss: 1.1153 - accuracy: 0.785 - ETA: 46s - loss: 1.1166 - accuracy: 0.785 - ETA: 45s - loss: 1.1152 - accuracy: 0.785 - ETA: 44s - loss: 1.1134 - accuracy: 0.786 - ETA: 43s - loss: 1.1090 - accuracy: 0.786 - ETA: 42s - loss: 1.1103 - accuracy: 0.786 - ETA: 41s - loss: 1.1090 - accuracy: 0.786 - ETA: 40s - loss: 1.1058 - accuracy: 0.787 - ETA: 39s - loss: 1.1045 - accuracy: 0.787 - ETA: 38s - loss: 1.1073 - accuracy: 0.787 - ETA: 37s - loss: 1.1064 - accuracy: 0.786 - ETA: 36s - loss: 1.1056 - accuracy: 0.786 - ETA: 35s - loss: 1.1086 - accuracy: 0.787 - ETA: 34s - loss: 1.1057 - accuracy: 0.787 - ETA: 33s - loss: 1.1021 - accuracy: 0.787 - ETA: 32s - loss: 1.1041 - accuracy: 0.787 - ETA: 31s - loss: 1.1060 - accuracy: 0.787 - ETA: 30s - loss: 1.1071 - accuracy: 0.787 - ETA: 29s - loss: 1.1038 - accuracy: 0.787 - ETA: 28s - loss: 1.1000 - accuracy: 0.788 - ETA: 27s - loss: 1.0990 - accuracy: 0.788 - ETA: 26s - loss: 1.1019 - accuracy: 0.787 - ETA: 25s - loss: 1.1015 - accuracy: 0.787 - ETA: 25s - loss: 1.1012 - accuracy: 0.787 - ETA: 24s - loss: 1.1015 - accuracy: 0.786 - ETA: 23s - loss: 1.0998 - accuracy: 0.787 - ETA: 22s - loss: 1.1004 - accuracy: 0.787 - ETA: 21s - loss: 1.1000 - accuracy: 0.787 - ETA: 20s - loss: 1.1010 - accuracy: 0.787 - ETA: 19s - loss: 1.1024 - accuracy: 0.787 - ETA: 18s - loss: 1.1020 - accuracy: 0.787 - ETA: 17s - loss: 1.1007 - accuracy: 0.787 - ETA: 16s - loss: 1.0988 - accuracy: 0.787 - ETA: 15s - loss: 1.0948 - accuracy: 0.787 - ETA: 14s - loss: 1.0934 - accuracy: 0.787 - ETA: 13s - loss: 1.0977 - accuracy: 0.788 - ETA: 12s - loss: 1.0989 - accuracy: 0.788 - ETA: 11s - loss: 1.0979 - accuracy: 0.788 - ETA: 10s - loss: 1.0967 - accuracy: 0.788 - ETA: 9s - loss: 1.0961 - accuracy: 0.788 - ETA: 8s - loss: 1.0964 - accuracy: 0.78 - ETA: 7s - loss: 1.0942 - accuracy: 0.78 - ETA: 6s - loss: 1.0946 - accuracy: 0.78 - ETA: 5s - loss: 1.0927 - accuracy: 0.78 - ETA: 4s - loss: 1.0937 - accuracy: 0.78 - ETA: 3s - loss: 1.1001 - accuracy: 0.78 - ETA: 2s - loss: 1.1031 - accuracy: 0.78 - ETA: 1s - loss: 1.1029 - accuracy: 0.78 - ETA: 0s - loss: 1.1045 - accuracy: 0.78 - 157s 8ms/step - loss: 1.1103 - accuracy: 0.7878 - val_loss: 2.1529 - val_accuracy: 0.7382\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:23 - loss: 1.0015 - accuracy: 0.79 - ETA: 2:21 - loss: 0.9244 - accuracy: 0.79 - ETA: 2:22 - loss: 0.9968 - accuracy: 0.79 - ETA: 2:19 - loss: 1.0908 - accuracy: 0.78 - ETA: 2:18 - loss: 1.0977 - accuracy: 0.77 - ETA: 2:16 - loss: 1.1311 - accuracy: 0.77 - ETA: 2:15 - loss: 1.1519 - accuracy: 0.77 - ETA: 2:14 - loss: 1.0932 - accuracy: 0.78 - ETA: 2:14 - loss: 1.0438 - accuracy: 0.79 - ETA: 2:13 - loss: 1.0695 - accuracy: 0.79 - ETA: 2:11 - loss: 1.0428 - accuracy: 0.79 - ETA: 2:10 - loss: 1.0488 - accuracy: 0.79 - ETA: 2:10 - loss: 1.0583 - accuracy: 0.79 - ETA: 2:09 - loss: 1.0491 - accuracy: 0.79 - ETA: 2:08 - loss: 1.0721 - accuracy: 0.79 - ETA: 2:08 - loss: 1.0671 - accuracy: 0.79 - ETA: 2:08 - loss: 1.0749 - accuracy: 0.79 - ETA: 2:06 - loss: 1.0533 - accuracy: 0.79 - ETA: 2:06 - loss: 1.0561 - accuracy: 0.79 - ETA: 2:05 - loss: 1.0717 - accuracy: 0.79 - ETA: 2:04 - loss: 1.0681 - accuracy: 0.79 - ETA: 2:03 - loss: 1.0754 - accuracy: 0.79 - ETA: 2:02 - loss: 1.0769 - accuracy: 0.80 - ETA: 2:01 - loss: 1.0726 - accuracy: 0.80 - ETA: 2:00 - loss: 1.0707 - accuracy: 0.80 - ETA: 1:59 - loss: 1.0684 - accuracy: 0.80 - ETA: 1:58 - loss: 1.0520 - accuracy: 0.80 - ETA: 1:57 - loss: 1.0533 - accuracy: 0.80 - ETA: 1:56 - loss: 1.0499 - accuracy: 0.80 - ETA: 1:55 - loss: 1.0415 - accuracy: 0.80 - ETA: 1:54 - loss: 1.0554 - accuracy: 0.80 - ETA: 1:53 - loss: 1.0437 - accuracy: 0.80 - ETA: 1:52 - loss: 1.0440 - accuracy: 0.80 - ETA: 1:52 - loss: 1.0416 - accuracy: 0.80 - ETA: 1:51 - loss: 1.0475 - accuracy: 0.80 - ETA: 1:50 - loss: 1.0419 - accuracy: 0.80 - ETA: 1:50 - loss: 1.0381 - accuracy: 0.80 - ETA: 1:49 - loss: 1.0303 - accuracy: 0.80 - ETA: 1:47 - loss: 1.0199 - accuracy: 0.80 - ETA: 1:46 - loss: 1.0205 - accuracy: 0.80 - ETA: 1:46 - loss: 1.0267 - accuracy: 0.80 - ETA: 1:45 - loss: 1.0215 - accuracy: 0.80 - ETA: 1:44 - loss: 1.0132 - accuracy: 0.80 - ETA: 1:42 - loss: 1.0187 - accuracy: 0.80 - ETA: 1:41 - loss: 1.0193 - accuracy: 0.80 - ETA: 1:41 - loss: 1.0266 - accuracy: 0.80 - ETA: 1:40 - loss: 1.0214 - accuracy: 0.80 - ETA: 1:39 - loss: 1.0254 - accuracy: 0.80 - ETA: 1:38 - loss: 1.0367 - accuracy: 0.80 - ETA: 1:37 - loss: 1.0317 - accuracy: 0.80 - ETA: 1:36 - loss: 1.0637 - accuracy: 0.80 - ETA: 1:35 - loss: 1.0769 - accuracy: 0.80 - ETA: 1:34 - loss: 1.0779 - accuracy: 0.80 - ETA: 1:33 - loss: 1.0801 - accuracy: 0.80 - ETA: 1:32 - loss: 1.0802 - accuracy: 0.80 - ETA: 1:31 - loss: 1.0819 - accuracy: 0.80 - ETA: 1:30 - loss: 1.0826 - accuracy: 0.80 - ETA: 1:29 - loss: 1.0821 - accuracy: 0.80 - ETA: 1:28 - loss: 1.0793 - accuracy: 0.79 - ETA: 1:27 - loss: 1.0810 - accuracy: 0.79 - ETA: 1:26 - loss: 1.0884 - accuracy: 0.79 - ETA: 1:25 - loss: 1.0855 - accuracy: 0.79 - ETA: 1:24 - loss: 1.0845 - accuracy: 0.79 - ETA: 1:23 - loss: 1.0816 - accuracy: 0.79 - ETA: 1:22 - loss: 1.0809 - accuracy: 0.79 - ETA: 1:21 - loss: 1.0889 - accuracy: 0.79 - ETA: 1:21 - loss: 1.0924 - accuracy: 0.79 - ETA: 1:20 - loss: 1.0887 - accuracy: 0.79 - ETA: 1:19 - loss: 1.0920 - accuracy: 0.79 - ETA: 1:18 - loss: 1.0942 - accuracy: 0.79 - ETA: 1:17 - loss: 1.0956 - accuracy: 0.79 - ETA: 1:16 - loss: 1.0927 - accuracy: 0.79 - ETA: 1:15 - loss: 1.0933 - accuracy: 0.79 - ETA: 1:14 - loss: 1.1004 - accuracy: 0.79 - ETA: 1:13 - loss: 1.0990 - accuracy: 0.79 - ETA: 1:12 - loss: 1.0964 - accuracy: 0.79 - ETA: 1:11 - loss: 1.0936 - accuracy: 0.79 - ETA: 1:10 - loss: 1.1009 - accuracy: 0.79 - ETA: 1:09 - loss: 1.1002 - accuracy: 0.79 - ETA: 1:08 - loss: 1.1123 - accuracy: 0.79 - ETA: 1:07 - loss: 1.1075 - accuracy: 0.79 - ETA: 1:06 - loss: 1.1021 - accuracy: 0.79 - ETA: 1:05 - loss: 1.1116 - accuracy: 0.79 - ETA: 1:04 - loss: 1.1119 - accuracy: 0.79 - ETA: 1:03 - loss: 1.1114 - accuracy: 0.79 - ETA: 1:02 - loss: 1.1098 - accuracy: 0.79 - ETA: 1:01 - loss: 1.1089 - accuracy: 0.79 - ETA: 1:00 - loss: 1.1109 - accuracy: 0.79 - ETA: 59s - loss: 1.1088 - accuracy: 0.7955 - ETA: 58s - loss: 1.1071 - accuracy: 0.795 - ETA: 57s - loss: 1.1077 - accuracy: 0.795 - ETA: 56s - loss: 1.1068 - accuracy: 0.795 - ETA: 55s - loss: 1.1091 - accuracy: 0.795 - ETA: 54s - loss: 1.1092 - accuracy: 0.795 - ETA: 53s - loss: 1.1099 - accuracy: 0.795 - ETA: 53s - loss: 1.1097 - accuracy: 0.795 - ETA: 52s - loss: 1.1092 - accuracy: 0.795 - ETA: 51s - loss: 1.1087 - accuracy: 0.795 - ETA: 50s - loss: 1.1073 - accuracy: 0.794 - ETA: 49s - loss: 1.1083 - accuracy: 0.794 - ETA: 48s - loss: 1.1049 - accuracy: 0.794 - ETA: 47s - loss: 1.1038 - accuracy: 0.794 - ETA: 46s - loss: 1.0987 - accuracy: 0.795 - ETA: 45s - loss: 1.0979 - accuracy: 0.795 - ETA: 44s - loss: 1.0981 - accuracy: 0.795 - ETA: 43s - loss: 1.0999 - accuracy: 0.794 - ETA: 42s - loss: 1.0988 - accuracy: 0.795 - ETA: 41s - loss: 1.0958 - accuracy: 0.795 - ETA: 40s - loss: 1.0999 - accuracy: 0.794 - ETA: 39s - loss: 1.0975 - accuracy: 0.795 - ETA: 38s - loss: 1.1039 - accuracy: 0.794 - ETA: 37s - loss: 1.1067 - accuracy: 0.794 - ETA: 36s - loss: 1.1033 - accuracy: 0.794 - ETA: 35s - loss: 1.1015 - accuracy: 0.795 - ETA: 34s - loss: 1.1027 - accuracy: 0.794 - ETA: 33s - loss: 1.1034 - accuracy: 0.794 - ETA: 32s - loss: 1.1029 - accuracy: 0.794 - ETA: 31s - loss: 1.1042 - accuracy: 0.794 - ETA: 30s - loss: 1.1007 - accuracy: 0.794 - ETA: 29s - loss: 1.0986 - accuracy: 0.795 - ETA: 28s - loss: 1.0978 - accuracy: 0.794 - ETA: 27s - loss: 1.0945 - accuracy: 0.795 - ETA: 26s - loss: 1.0921 - accuracy: 0.795 - ETA: 26s - loss: 1.0957 - accuracy: 0.794 - ETA: 25s - loss: 1.0956 - accuracy: 0.794 - ETA: 24s - loss: 1.0975 - accuracy: 0.794 - ETA: 23s - loss: 1.1001 - accuracy: 0.794 - ETA: 22s - loss: 1.0957 - accuracy: 0.794 - ETA: 21s - loss: 1.0951 - accuracy: 0.794 - ETA: 20s - loss: 1.0939 - accuracy: 0.794 - ETA: 19s - loss: 1.0949 - accuracy: 0.794 - ETA: 18s - loss: 1.0930 - accuracy: 0.794 - ETA: 17s - loss: 1.0909 - accuracy: 0.794 - ETA: 16s - loss: 1.0894 - accuracy: 0.794 - ETA: 15s - loss: 1.0931 - accuracy: 0.794 - ETA: 14s - loss: 1.0908 - accuracy: 0.794 - ETA: 13s - loss: 1.0896 - accuracy: 0.794 - ETA: 12s - loss: 1.0921 - accuracy: 0.794 - ETA: 11s - loss: 1.0900 - accuracy: 0.794 - ETA: 10s - loss: 1.0865 - accuracy: 0.795 - ETA: 9s - loss: 1.0861 - accuracy: 0.795 - ETA: 8s - loss: 1.0886 - accuracy: 0.79 - ETA: 7s - loss: 1.0924 - accuracy: 0.79 - ETA: 6s - loss: 1.0929 - accuracy: 0.79 - ETA: 5s - loss: 1.0960 - accuracy: 0.79 - ETA: 4s - loss: 1.0993 - accuracy: 0.79 - ETA: 3s - loss: 1.1037 - accuracy: 0.79 - ETA: 2s - loss: 1.1017 - accuracy: 0.79 - ETA: 1s - loss: 1.1020 - accuracy: 0.79 - ETA: 0s - loss: 1.1002 - accuracy: 0.79 - 157s 8ms/step - loss: 1.1000 - accuracy: 0.7928 - val_loss: 2.2742 - val_accuracy: 0.7360\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:34 - loss: 0.8478 - accuracy: 0.79 - ETA: 2:33 - loss: 0.7896 - accuracy: 0.82 - ETA: 2:31 - loss: 0.9097 - accuracy: 0.80 - ETA: 2:28 - loss: 0.8768 - accuracy: 0.81 - ETA: 2:26 - loss: 0.8872 - accuracy: 0.81 - ETA: 2:24 - loss: 1.0195 - accuracy: 0.80 - ETA: 2:24 - loss: 1.0266 - accuracy: 0.80 - ETA: 2:23 - loss: 1.1272 - accuracy: 0.79 - ETA: 2:21 - loss: 1.1001 - accuracy: 0.79 - ETA: 2:20 - loss: 1.1456 - accuracy: 0.79 - ETA: 2:19 - loss: 1.1391 - accuracy: 0.79 - ETA: 2:18 - loss: 1.0915 - accuracy: 0.80 - ETA: 2:17 - loss: 1.0943 - accuracy: 0.79 - ETA: 2:15 - loss: 1.0810 - accuracy: 0.80 - ETA: 2:14 - loss: 1.0717 - accuracy: 0.79 - ETA: 2:12 - loss: 1.0815 - accuracy: 0.79 - ETA: 2:11 - loss: 1.0925 - accuracy: 0.79 - ETA: 2:10 - loss: 1.0815 - accuracy: 0.79 - ETA: 2:09 - loss: 1.1050 - accuracy: 0.79 - ETA: 2:08 - loss: 1.0972 - accuracy: 0.79 - ETA: 2:07 - loss: 1.1010 - accuracy: 0.79 - ETA: 2:06 - loss: 1.1172 - accuracy: 0.79 - ETA: 2:05 - loss: 1.1380 - accuracy: 0.79 - ETA: 2:04 - loss: 1.1337 - accuracy: 0.79 - ETA: 2:04 - loss: 1.1330 - accuracy: 0.79 - ETA: 2:03 - loss: 1.1324 - accuracy: 0.79 - ETA: 2:01 - loss: 1.1258 - accuracy: 0.79 - ETA: 2:00 - loss: 1.1333 - accuracy: 0.79 - ETA: 1:59 - loss: 1.1251 - accuracy: 0.79 - ETA: 1:58 - loss: 1.1148 - accuracy: 0.79 - ETA: 1:57 - loss: 1.1199 - accuracy: 0.79 - ETA: 1:56 - loss: 1.1197 - accuracy: 0.79 - ETA: 1:55 - loss: 1.1219 - accuracy: 0.79 - ETA: 1:54 - loss: 1.1161 - accuracy: 0.79 - ETA: 1:53 - loss: 1.1183 - accuracy: 0.79 - ETA: 1:52 - loss: 1.1135 - accuracy: 0.79 - ETA: 1:51 - loss: 1.1151 - accuracy: 0.79 - ETA: 1:50 - loss: 1.1147 - accuracy: 0.79 - ETA: 1:49 - loss: 1.1137 - accuracy: 0.79 - ETA: 1:48 - loss: 1.1122 - accuracy: 0.79 - ETA: 1:47 - loss: 1.1104 - accuracy: 0.79 - ETA: 1:45 - loss: 1.1053 - accuracy: 0.79 - ETA: 1:45 - loss: 1.1096 - accuracy: 0.79 - ETA: 1:43 - loss: 1.1093 - accuracy: 0.79 - ETA: 1:42 - loss: 1.1083 - accuracy: 0.79 - ETA: 1:41 - loss: 1.1072 - accuracy: 0.79 - ETA: 1:41 - loss: 1.1059 - accuracy: 0.79 - ETA: 1:39 - loss: 1.1159 - accuracy: 0.79 - ETA: 1:38 - loss: 1.1164 - accuracy: 0.79 - ETA: 1:37 - loss: 1.1176 - accuracy: 0.79 - ETA: 1:36 - loss: 1.1134 - accuracy: 0.79 - ETA: 1:36 - loss: 1.1130 - accuracy: 0.79 - ETA: 1:35 - loss: 1.1097 - accuracy: 0.79 - ETA: 1:34 - loss: 1.1082 - accuracy: 0.79 - ETA: 1:33 - loss: 1.1044 - accuracy: 0.79 - ETA: 1:32 - loss: 1.1021 - accuracy: 0.79 - ETA: 1:31 - loss: 1.1018 - accuracy: 0.79 - ETA: 1:30 - loss: 1.0928 - accuracy: 0.79 - ETA: 1:29 - loss: 1.0928 - accuracy: 0.79 - ETA: 1:27 - loss: 1.0904 - accuracy: 0.79 - ETA: 1:26 - loss: 1.0898 - accuracy: 0.79 - ETA: 1:25 - loss: 1.0923 - accuracy: 0.79 - ETA: 1:24 - loss: 1.0892 - accuracy: 0.79 - ETA: 1:23 - loss: 1.0878 - accuracy: 0.79 - ETA: 1:23 - loss: 1.0879 - accuracy: 0.79 - ETA: 1:22 - loss: 1.0836 - accuracy: 0.79 - ETA: 1:21 - loss: 1.0790 - accuracy: 0.79 - ETA: 1:20 - loss: 1.0712 - accuracy: 0.79 - ETA: 1:19 - loss: 1.0716 - accuracy: 0.79 - ETA: 1:18 - loss: 1.0761 - accuracy: 0.79 - ETA: 1:17 - loss: 1.0824 - accuracy: 0.79 - ETA: 1:16 - loss: 1.0830 - accuracy: 0.79 - ETA: 1:15 - loss: 1.0818 - accuracy: 0.79 - ETA: 1:14 - loss: 1.0845 - accuracy: 0.79 - ETA: 1:13 - loss: 1.0817 - accuracy: 0.79 - ETA: 1:12 - loss: 1.0822 - accuracy: 0.79 - ETA: 1:11 - loss: 1.0847 - accuracy: 0.79 - ETA: 1:10 - loss: 1.0892 - accuracy: 0.79 - ETA: 1:09 - loss: 1.0865 - accuracy: 0.79 - ETA: 1:08 - loss: 1.0922 - accuracy: 0.79 - ETA: 1:07 - loss: 1.0923 - accuracy: 0.79 - ETA: 1:06 - loss: 1.0935 - accuracy: 0.79 - ETA: 1:05 - loss: 1.0948 - accuracy: 0.79 - ETA: 1:04 - loss: 1.0962 - accuracy: 0.79 - ETA: 1:03 - loss: 1.0937 - accuracy: 0.79 - ETA: 1:02 - loss: 1.0894 - accuracy: 0.79 - ETA: 1:02 - loss: 1.0850 - accuracy: 0.79 - ETA: 1:01 - loss: 1.0840 - accuracy: 0.79 - ETA: 1:00 - loss: 1.0837 - accuracy: 0.79 - ETA: 59s - loss: 1.0815 - accuracy: 0.7937 - ETA: 58s - loss: 1.0851 - accuracy: 0.793 - ETA: 57s - loss: 1.0846 - accuracy: 0.794 - ETA: 56s - loss: 1.0833 - accuracy: 0.794 - ETA: 55s - loss: 1.0809 - accuracy: 0.794 - ETA: 54s - loss: 1.0785 - accuracy: 0.794 - ETA: 53s - loss: 1.0757 - accuracy: 0.794 - ETA: 52s - loss: 1.0743 - accuracy: 0.794 - ETA: 51s - loss: 1.0726 - accuracy: 0.794 - ETA: 50s - loss: 1.0727 - accuracy: 0.794 - ETA: 49s - loss: 1.0693 - accuracy: 0.795 - ETA: 48s - loss: 1.0681 - accuracy: 0.794 - ETA: 47s - loss: 1.0672 - accuracy: 0.795 - ETA: 46s - loss: 1.0699 - accuracy: 0.795 - ETA: 45s - loss: 1.0684 - accuracy: 0.795 - ETA: 44s - loss: 1.0702 - accuracy: 0.795 - ETA: 43s - loss: 1.0748 - accuracy: 0.795 - ETA: 42s - loss: 1.0778 - accuracy: 0.796 - ETA: 41s - loss: 1.0820 - accuracy: 0.796 - ETA: 40s - loss: 1.0832 - accuracy: 0.796 - ETA: 39s - loss: 1.0806 - accuracy: 0.796 - ETA: 38s - loss: 1.0806 - accuracy: 0.796 - ETA: 37s - loss: 1.0817 - accuracy: 0.796 - ETA: 36s - loss: 1.0821 - accuracy: 0.796 - ETA: 35s - loss: 1.0805 - accuracy: 0.796 - ETA: 34s - loss: 1.0790 - accuracy: 0.797 - ETA: 33s - loss: 1.0776 - accuracy: 0.797 - ETA: 32s - loss: 1.0767 - accuracy: 0.797 - ETA: 31s - loss: 1.0750 - accuracy: 0.797 - ETA: 30s - loss: 1.0709 - accuracy: 0.798 - ETA: 29s - loss: 1.0685 - accuracy: 0.798 - ETA: 28s - loss: 1.0672 - accuracy: 0.799 - ETA: 27s - loss: 1.0668 - accuracy: 0.799 - ETA: 26s - loss: 1.0633 - accuracy: 0.800 - ETA: 26s - loss: 1.0629 - accuracy: 0.799 - ETA: 25s - loss: 1.0621 - accuracy: 0.799 - ETA: 24s - loss: 1.0616 - accuracy: 0.799 - ETA: 23s - loss: 1.0618 - accuracy: 0.799 - ETA: 22s - loss: 1.0687 - accuracy: 0.798 - ETA: 21s - loss: 1.0752 - accuracy: 0.798 - ETA: 20s - loss: 1.0786 - accuracy: 0.798 - ETA: 19s - loss: 1.0794 - accuracy: 0.798 - ETA: 18s - loss: 1.0786 - accuracy: 0.798 - ETA: 17s - loss: 1.0816 - accuracy: 0.797 - ETA: 16s - loss: 1.0852 - accuracy: 0.797 - ETA: 15s - loss: 1.0833 - accuracy: 0.797 - ETA: 14s - loss: 1.0838 - accuracy: 0.797 - ETA: 13s - loss: 1.0803 - accuracy: 0.797 - ETA: 12s - loss: 1.0802 - accuracy: 0.798 - ETA: 11s - loss: 1.0803 - accuracy: 0.797 - ETA: 10s - loss: 1.0828 - accuracy: 0.797 - ETA: 9s - loss: 1.0808 - accuracy: 0.797 - ETA: 8s - loss: 1.0833 - accuracy: 0.79 - ETA: 7s - loss: 1.0858 - accuracy: 0.79 - ETA: 6s - loss: 1.0829 - accuracy: 0.79 - ETA: 5s - loss: 1.0805 - accuracy: 0.79 - ETA: 4s - loss: 1.0836 - accuracy: 0.79 - ETA: 3s - loss: 1.0829 - accuracy: 0.79 - ETA: 2s - loss: 1.0817 - accuracy: 0.79 - ETA: 1s - loss: 1.0813 - accuracy: 0.79 - ETA: 0s - loss: 1.0799 - accuracy: 0.79 - 158s 8ms/step - loss: 1.0777 - accuracy: 0.7977 - val_loss: 2.2922 - val_accuracy: 0.7426\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:24 - loss: 1.0629 - accuracy: 0.82 - ETA: 2:22 - loss: 1.0456 - accuracy: 0.80 - ETA: 2:17 - loss: 0.9416 - accuracy: 0.81 - ETA: 2:17 - loss: 1.0319 - accuracy: 0.79 - ETA: 2:20 - loss: 0.9277 - accuracy: 0.80 - ETA: 2:19 - loss: 1.0030 - accuracy: 0.80 - ETA: 2:17 - loss: 1.0064 - accuracy: 0.80 - ETA: 2:16 - loss: 0.9904 - accuracy: 0.80 - ETA: 2:15 - loss: 0.9842 - accuracy: 0.80 - ETA: 2:14 - loss: 0.9679 - accuracy: 0.80 - ETA: 2:13 - loss: 1.0063 - accuracy: 0.80 - ETA: 2:11 - loss: 1.0201 - accuracy: 0.80 - ETA: 2:10 - loss: 0.9960 - accuracy: 0.80 - ETA: 2:09 - loss: 0.9780 - accuracy: 0.80 - ETA: 2:08 - loss: 0.9973 - accuracy: 0.80 - ETA: 2:08 - loss: 0.9970 - accuracy: 0.79 - ETA: 2:07 - loss: 0.9871 - accuracy: 0.80 - ETA: 2:06 - loss: 0.9978 - accuracy: 0.80 - ETA: 2:06 - loss: 0.9981 - accuracy: 0.80 - ETA: 2:04 - loss: 0.9757 - accuracy: 0.80 - ETA: 2:04 - loss: 0.9895 - accuracy: 0.80 - ETA: 2:03 - loss: 0.9953 - accuracy: 0.80 - ETA: 2:03 - loss: 0.9880 - accuracy: 0.80 - ETA: 2:02 - loss: 0.9822 - accuracy: 0.80 - ETA: 2:01 - loss: 0.9794 - accuracy: 0.80 - ETA: 2:00 - loss: 0.9793 - accuracy: 0.80 - ETA: 1:59 - loss: 0.9688 - accuracy: 0.80 - ETA: 1:58 - loss: 0.9732 - accuracy: 0.80 - ETA: 1:57 - loss: 0.9644 - accuracy: 0.80 - ETA: 1:56 - loss: 0.9689 - accuracy: 0.80 - ETA: 1:55 - loss: 0.9635 - accuracy: 0.81 - ETA: 1:54 - loss: 0.9715 - accuracy: 0.81 - ETA: 1:53 - loss: 0.9605 - accuracy: 0.81 - ETA: 1:52 - loss: 0.9628 - accuracy: 0.80 - ETA: 1:51 - loss: 0.9548 - accuracy: 0.80 - ETA: 1:50 - loss: 0.9619 - accuracy: 0.80 - ETA: 1:49 - loss: 0.9674 - accuracy: 0.80 - ETA: 1:49 - loss: 0.9650 - accuracy: 0.80 - ETA: 1:48 - loss: 0.9567 - accuracy: 0.80 - ETA: 1:47 - loss: 0.9508 - accuracy: 0.80 - ETA: 1:46 - loss: 0.9518 - accuracy: 0.80 - ETA: 1:45 - loss: 0.9587 - accuracy: 0.80 - ETA: 1:45 - loss: 0.9594 - accuracy: 0.80 - ETA: 1:44 - loss: 0.9554 - accuracy: 0.81 - ETA: 1:43 - loss: 0.9423 - accuracy: 0.81 - ETA: 1:42 - loss: 0.9441 - accuracy: 0.81 - ETA: 1:42 - loss: 0.9440 - accuracy: 0.81 - ETA: 1:41 - loss: 0.9469 - accuracy: 0.81 - ETA: 1:40 - loss: 0.9463 - accuracy: 0.81 - ETA: 1:39 - loss: 0.9544 - accuracy: 0.81 - ETA: 1:38 - loss: 0.9502 - accuracy: 0.81 - ETA: 1:37 - loss: 0.9655 - accuracy: 0.81 - ETA: 1:36 - loss: 0.9662 - accuracy: 0.81 - ETA: 1:35 - loss: 0.9673 - accuracy: 0.81 - ETA: 1:34 - loss: 0.9636 - accuracy: 0.81 - ETA: 1:33 - loss: 0.9591 - accuracy: 0.81 - ETA: 1:32 - loss: 0.9661 - accuracy: 0.81 - ETA: 1:31 - loss: 0.9665 - accuracy: 0.80 - ETA: 1:30 - loss: 0.9704 - accuracy: 0.80 - ETA: 1:29 - loss: 0.9725 - accuracy: 0.80 - ETA: 1:28 - loss: 0.9696 - accuracy: 0.81 - ETA: 1:27 - loss: 0.9681 - accuracy: 0.81 - ETA: 1:26 - loss: 0.9703 - accuracy: 0.80 - ETA: 1:25 - loss: 0.9844 - accuracy: 0.80 - ETA: 1:24 - loss: 0.9791 - accuracy: 0.80 - ETA: 1:23 - loss: 0.9763 - accuracy: 0.80 - ETA: 1:22 - loss: 0.9717 - accuracy: 0.81 - ETA: 1:20 - loss: 0.9700 - accuracy: 0.81 - ETA: 1:20 - loss: 0.9692 - accuracy: 0.81 - ETA: 1:19 - loss: 0.9712 - accuracy: 0.81 - ETA: 1:18 - loss: 0.9759 - accuracy: 0.81 - ETA: 1:17 - loss: 0.9842 - accuracy: 0.81 - ETA: 1:16 - loss: 0.9836 - accuracy: 0.81 - ETA: 1:15 - loss: 0.9804 - accuracy: 0.81 - ETA: 1:14 - loss: 0.9798 - accuracy: 0.81 - ETA: 1:13 - loss: 0.9812 - accuracy: 0.81 - ETA: 1:12 - loss: 0.9794 - accuracy: 0.81 - ETA: 1:11 - loss: 0.9794 - accuracy: 0.81 - ETA: 1:10 - loss: 0.9807 - accuracy: 0.81 - ETA: 1:09 - loss: 0.9836 - accuracy: 0.81 - ETA: 1:08 - loss: 0.9848 - accuracy: 0.81 - ETA: 1:07 - loss: 0.9877 - accuracy: 0.80 - ETA: 1:06 - loss: 0.9935 - accuracy: 0.81 - ETA: 1:05 - loss: 0.9901 - accuracy: 0.81 - ETA: 1:04 - loss: 0.9933 - accuracy: 0.80 - ETA: 1:03 - loss: 0.9929 - accuracy: 0.81 - ETA: 1:02 - loss: 0.9938 - accuracy: 0.80 - ETA: 1:01 - loss: 0.9910 - accuracy: 0.81 - ETA: 1:00 - loss: 0.9952 - accuracy: 0.81 - ETA: 59s - loss: 0.9962 - accuracy: 0.8102 - ETA: 58s - loss: 0.9929 - accuracy: 0.810 - ETA: 57s - loss: 0.9920 - accuracy: 0.810 - ETA: 56s - loss: 0.9950 - accuracy: 0.810 - ETA: 55s - loss: 0.9926 - accuracy: 0.810 - ETA: 54s - loss: 0.9930 - accuracy: 0.810 - ETA: 53s - loss: 0.9962 - accuracy: 0.809 - ETA: 52s - loss: 0.9955 - accuracy: 0.809 - ETA: 51s - loss: 0.9946 - accuracy: 0.809 - ETA: 50s - loss: 0.9937 - accuracy: 0.809 - ETA: 49s - loss: 0.9922 - accuracy: 0.810 - ETA: 48s - loss: 0.9940 - accuracy: 0.809 - ETA: 47s - loss: 0.9922 - accuracy: 0.810 - ETA: 46s - loss: 0.9889 - accuracy: 0.810 - ETA: 45s - loss: 0.9920 - accuracy: 0.810 - ETA: 44s - loss: 0.9886 - accuracy: 0.810 - ETA: 43s - loss: 0.9930 - accuracy: 0.810 - ETA: 42s - loss: 0.9967 - accuracy: 0.810 - ETA: 41s - loss: 1.0008 - accuracy: 0.810 - ETA: 40s - loss: 1.0060 - accuracy: 0.810 - ETA: 39s - loss: 1.0078 - accuracy: 0.810 - ETA: 38s - loss: 1.0082 - accuracy: 0.810 - ETA: 37s - loss: 1.0136 - accuracy: 0.809 - ETA: 36s - loss: 1.0154 - accuracy: 0.808 - ETA: 35s - loss: 1.0198 - accuracy: 0.808 - ETA: 34s - loss: 1.0291 - accuracy: 0.807 - ETA: 33s - loss: 1.0283 - accuracy: 0.807 - ETA: 33s - loss: 1.0277 - accuracy: 0.807 - ETA: 32s - loss: 1.0297 - accuracy: 0.808 - ETA: 31s - loss: 1.0279 - accuracy: 0.807 - ETA: 30s - loss: 1.0294 - accuracy: 0.807 - ETA: 29s - loss: 1.0282 - accuracy: 0.807 - ETA: 28s - loss: 1.0258 - accuracy: 0.806 - ETA: 27s - loss: 1.0240 - accuracy: 0.806 - ETA: 26s - loss: 1.0245 - accuracy: 0.807 - ETA: 25s - loss: 1.0228 - accuracy: 0.807 - ETA: 24s - loss: 1.0225 - accuracy: 0.807 - ETA: 23s - loss: 1.0201 - accuracy: 0.807 - ETA: 22s - loss: 1.0211 - accuracy: 0.807 - ETA: 21s - loss: 1.0185 - accuracy: 0.807 - ETA: 20s - loss: 1.0260 - accuracy: 0.807 - ETA: 19s - loss: 1.0270 - accuracy: 0.807 - ETA: 18s - loss: 1.0293 - accuracy: 0.807 - ETA: 17s - loss: 1.0277 - accuracy: 0.807 - ETA: 16s - loss: 1.0248 - accuracy: 0.807 - ETA: 15s - loss: 1.0283 - accuracy: 0.807 - ETA: 14s - loss: 1.0281 - accuracy: 0.807 - ETA: 13s - loss: 1.0286 - accuracy: 0.806 - ETA: 12s - loss: 1.0281 - accuracy: 0.806 - ETA: 11s - loss: 1.0269 - accuracy: 0.807 - ETA: 10s - loss: 1.0273 - accuracy: 0.807 - ETA: 9s - loss: 1.0304 - accuracy: 0.806 - ETA: 8s - loss: 1.0327 - accuracy: 0.80 - ETA: 7s - loss: 1.0290 - accuracy: 0.80 - ETA: 6s - loss: 1.0287 - accuracy: 0.80 - ETA: 5s - loss: 1.0297 - accuracy: 0.80 - ETA: 4s - loss: 1.0323 - accuracy: 0.80 - ETA: 3s - loss: 1.0334 - accuracy: 0.80 - ETA: 2s - loss: 1.0327 - accuracy: 0.80 - ETA: 1s - loss: 1.0331 - accuracy: 0.80 - ETA: 0s - loss: 1.0311 - accuracy: 0.80 - 158s 8ms/step - loss: 1.0286 - accuracy: 0.8061 - val_loss: 2.1878 - val_accuracy: 0.7432\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:26 - loss: 0.8251 - accuracy: 0.79 - ETA: 2:20 - loss: 0.9056 - accuracy: 0.82 - ETA: 2:21 - loss: 0.8113 - accuracy: 0.83 - ETA: 2:20 - loss: 0.8210 - accuracy: 0.83 - ETA: 2:20 - loss: 0.8754 - accuracy: 0.83 - ETA: 2:21 - loss: 0.9847 - accuracy: 0.82 - ETA: 2:21 - loss: 1.0848 - accuracy: 0.81 - ETA: 2:20 - loss: 1.0685 - accuracy: 0.81 - ETA: 2:18 - loss: 1.0742 - accuracy: 0.81 - ETA: 2:17 - loss: 1.0968 - accuracy: 0.81 - ETA: 2:16 - loss: 1.0934 - accuracy: 0.81 - ETA: 2:15 - loss: 1.1158 - accuracy: 0.81 - ETA: 2:13 - loss: 1.1039 - accuracy: 0.80 - ETA: 2:12 - loss: 1.0979 - accuracy: 0.80 - ETA: 2:10 - loss: 1.0885 - accuracy: 0.80 - ETA: 2:09 - loss: 1.0948 - accuracy: 0.80 - ETA: 2:08 - loss: 1.0820 - accuracy: 0.81 - ETA: 2:08 - loss: 1.0809 - accuracy: 0.80 - ETA: 2:07 - loss: 1.0879 - accuracy: 0.80 - ETA: 2:05 - loss: 1.0936 - accuracy: 0.80 - ETA: 2:04 - loss: 1.1269 - accuracy: 0.80 - ETA: 2:04 - loss: 1.1429 - accuracy: 0.79 - ETA: 2:03 - loss: 1.1369 - accuracy: 0.80 - ETA: 2:03 - loss: 1.1326 - accuracy: 0.80 - ETA: 2:02 - loss: 1.1272 - accuracy: 0.80 - ETA: 2:00 - loss: 1.1209 - accuracy: 0.80 - ETA: 1:59 - loss: 1.1157 - accuracy: 0.80 - ETA: 1:58 - loss: 1.0980 - accuracy: 0.80 - ETA: 1:57 - loss: 1.0802 - accuracy: 0.80 - ETA: 1:56 - loss: 1.0839 - accuracy: 0.80 - ETA: 1:55 - loss: 1.0782 - accuracy: 0.80 - ETA: 1:54 - loss: 1.0912 - accuracy: 0.80 - ETA: 1:53 - loss: 1.0875 - accuracy: 0.80 - ETA: 1:52 - loss: 1.0980 - accuracy: 0.80 - ETA: 1:51 - loss: 1.1018 - accuracy: 0.80 - ETA: 1:50 - loss: 1.0944 - accuracy: 0.80 - ETA: 1:49 - loss: 1.0905 - accuracy: 0.80 - ETA: 1:48 - loss: 1.0765 - accuracy: 0.80 - ETA: 1:47 - loss: 1.0772 - accuracy: 0.80 - ETA: 1:47 - loss: 1.0657 - accuracy: 0.80 - ETA: 1:46 - loss: 1.0547 - accuracy: 0.80 - ETA: 1:45 - loss: 1.0475 - accuracy: 0.80 - ETA: 1:44 - loss: 1.0434 - accuracy: 0.80 - ETA: 1:43 - loss: 1.0513 - accuracy: 0.80 - ETA: 1:42 - loss: 1.0511 - accuracy: 0.80 - ETA: 1:41 - loss: 1.0560 - accuracy: 0.80 - ETA: 1:40 - loss: 1.0541 - accuracy: 0.80 - ETA: 1:39 - loss: 1.0481 - accuracy: 0.80 - ETA: 1:38 - loss: 1.0457 - accuracy: 0.80 - ETA: 1:37 - loss: 1.0408 - accuracy: 0.80 - ETA: 1:36 - loss: 1.0327 - accuracy: 0.80 - ETA: 1:35 - loss: 1.0292 - accuracy: 0.80 - ETA: 1:34 - loss: 1.0270 - accuracy: 0.80 - ETA: 1:33 - loss: 1.0306 - accuracy: 0.80 - ETA: 1:32 - loss: 1.0290 - accuracy: 0.80 - ETA: 1:31 - loss: 1.0460 - accuracy: 0.80 - ETA: 1:30 - loss: 1.0453 - accuracy: 0.80 - ETA: 1:29 - loss: 1.0428 - accuracy: 0.80 - ETA: 1:28 - loss: 1.0392 - accuracy: 0.80 - ETA: 1:27 - loss: 1.0347 - accuracy: 0.80 - ETA: 1:26 - loss: 1.0422 - accuracy: 0.80 - ETA: 1:25 - loss: 1.0380 - accuracy: 0.80 - ETA: 1:24 - loss: 1.0312 - accuracy: 0.80 - ETA: 1:23 - loss: 1.0334 - accuracy: 0.80 - ETA: 1:22 - loss: 1.0352 - accuracy: 0.80 - ETA: 1:21 - loss: 1.0364 - accuracy: 0.80 - ETA: 1:20 - loss: 1.0371 - accuracy: 0.80 - ETA: 1:19 - loss: 1.0351 - accuracy: 0.80 - ETA: 1:18 - loss: 1.0410 - accuracy: 0.80 - ETA: 1:17 - loss: 1.0372 - accuracy: 0.80 - ETA: 1:17 - loss: 1.0340 - accuracy: 0.80 - ETA: 1:16 - loss: 1.0357 - accuracy: 0.80 - ETA: 1:15 - loss: 1.0303 - accuracy: 0.80 - ETA: 1:14 - loss: 1.0345 - accuracy: 0.80 - ETA: 1:13 - loss: 1.0356 - accuracy: 0.80 - ETA: 1:12 - loss: 1.0322 - accuracy: 0.80 - ETA: 1:11 - loss: 1.0291 - accuracy: 0.80 - ETA: 1:10 - loss: 1.0264 - accuracy: 0.80 - ETA: 1:09 - loss: 1.0261 - accuracy: 0.80 - ETA: 1:08 - loss: 1.0217 - accuracy: 0.80 - ETA: 1:07 - loss: 1.0243 - accuracy: 0.80 - ETA: 1:06 - loss: 1.0229 - accuracy: 0.80 - ETA: 1:05 - loss: 1.0227 - accuracy: 0.80 - ETA: 1:04 - loss: 1.0266 - accuracy: 0.80 - ETA: 1:03 - loss: 1.0234 - accuracy: 0.80 - ETA: 1:02 - loss: 1.0212 - accuracy: 0.80 - ETA: 1:01 - loss: 1.0239 - accuracy: 0.80 - ETA: 1:00 - loss: 1.0242 - accuracy: 0.80 - ETA: 59s - loss: 1.0186 - accuracy: 0.8082 - ETA: 58s - loss: 1.0210 - accuracy: 0.808 - ETA: 57s - loss: 1.0185 - accuracy: 0.808 - ETA: 56s - loss: 1.0195 - accuracy: 0.808 - ETA: 55s - loss: 1.0168 - accuracy: 0.808 - ETA: 54s - loss: 1.0140 - accuracy: 0.808 - ETA: 54s - loss: 1.0136 - accuracy: 0.808 - ETA: 53s - loss: 1.0104 - accuracy: 0.808 - ETA: 52s - loss: 1.0107 - accuracy: 0.808 - ETA: 51s - loss: 1.0108 - accuracy: 0.808 - ETA: 50s - loss: 1.0081 - accuracy: 0.808 - ETA: 49s - loss: 1.0128 - accuracy: 0.807 - ETA: 48s - loss: 1.0138 - accuracy: 0.807 - ETA: 47s - loss: 1.0174 - accuracy: 0.807 - ETA: 46s - loss: 1.0198 - accuracy: 0.806 - ETA: 45s - loss: 1.0199 - accuracy: 0.806 - ETA: 44s - loss: 1.0158 - accuracy: 0.807 - ETA: 43s - loss: 1.0143 - accuracy: 0.807 - ETA: 42s - loss: 1.0101 - accuracy: 0.807 - ETA: 41s - loss: 1.0116 - accuracy: 0.807 - ETA: 40s - loss: 1.0089 - accuracy: 0.808 - ETA: 39s - loss: 1.0091 - accuracy: 0.808 - ETA: 38s - loss: 1.0082 - accuracy: 0.808 - ETA: 37s - loss: 1.0126 - accuracy: 0.808 - ETA: 36s - loss: 1.0118 - accuracy: 0.808 - ETA: 35s - loss: 1.0127 - accuracy: 0.808 - ETA: 34s - loss: 1.0101 - accuracy: 0.808 - ETA: 33s - loss: 1.0129 - accuracy: 0.808 - ETA: 32s - loss: 1.0120 - accuracy: 0.808 - ETA: 31s - loss: 1.0138 - accuracy: 0.808 - ETA: 30s - loss: 1.0111 - accuracy: 0.808 - ETA: 29s - loss: 1.0133 - accuracy: 0.807 - ETA: 28s - loss: 1.0109 - accuracy: 0.808 - ETA: 27s - loss: 1.0164 - accuracy: 0.808 - ETA: 26s - loss: 1.0161 - accuracy: 0.807 - ETA: 25s - loss: 1.0182 - accuracy: 0.807 - ETA: 25s - loss: 1.0195 - accuracy: 0.807 - ETA: 24s - loss: 1.0239 - accuracy: 0.806 - ETA: 23s - loss: 1.0227 - accuracy: 0.806 - ETA: 22s - loss: 1.0262 - accuracy: 0.806 - ETA: 21s - loss: 1.0303 - accuracy: 0.806 - ETA: 20s - loss: 1.0285 - accuracy: 0.806 - ETA: 19s - loss: 1.0278 - accuracy: 0.806 - ETA: 18s - loss: 1.0280 - accuracy: 0.806 - ETA: 17s - loss: 1.0266 - accuracy: 0.806 - ETA: 16s - loss: 1.0243 - accuracy: 0.806 - ETA: 15s - loss: 1.0224 - accuracy: 0.807 - ETA: 14s - loss: 1.0237 - accuracy: 0.807 - ETA: 13s - loss: 1.0236 - accuracy: 0.807 - ETA: 12s - loss: 1.0266 - accuracy: 0.806 - ETA: 11s - loss: 1.0287 - accuracy: 0.806 - ETA: 10s - loss: 1.0294 - accuracy: 0.805 - ETA: 9s - loss: 1.0295 - accuracy: 0.806 - ETA: 8s - loss: 1.0295 - accuracy: 0.80 - ETA: 7s - loss: 1.0289 - accuracy: 0.80 - ETA: 6s - loss: 1.0278 - accuracy: 0.80 - ETA: 5s - loss: 1.0293 - accuracy: 0.80 - ETA: 4s - loss: 1.0284 - accuracy: 0.80 - ETA: 3s - loss: 1.0280 - accuracy: 0.80 - ETA: 2s - loss: 1.0329 - accuracy: 0.80 - ETA: 1s - loss: 1.0306 - accuracy: 0.80 - ETA: 0s - loss: 1.0274 - accuracy: 0.80 - 159s 8ms/step - loss: 1.0273 - accuracy: 0.8065 - val_loss: 2.5053 - val_accuracy: 0.7467\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:36 - loss: 0.5592 - accuracy: 0.85 - ETA: 2:31 - loss: 0.8762 - accuracy: 0.82 - ETA: 2:23 - loss: 0.8768 - accuracy: 0.82 - ETA: 2:22 - loss: 0.9440 - accuracy: 0.81 - ETA: 2:21 - loss: 1.0106 - accuracy: 0.80 - ETA: 2:20 - loss: 0.9846 - accuracy: 0.80 - ETA: 2:18 - loss: 1.0170 - accuracy: 0.80 - ETA: 2:20 - loss: 1.0174 - accuracy: 0.80 - ETA: 2:18 - loss: 0.9830 - accuracy: 0.81 - ETA: 2:17 - loss: 0.9846 - accuracy: 0.80 - ETA: 2:15 - loss: 1.0128 - accuracy: 0.80 - ETA: 2:14 - loss: 1.0386 - accuracy: 0.80 - ETA: 2:13 - loss: 1.0042 - accuracy: 0.81 - ETA: 2:12 - loss: 1.0137 - accuracy: 0.81 - ETA: 2:10 - loss: 1.0560 - accuracy: 0.80 - ETA: 2:09 - loss: 1.0311 - accuracy: 0.81 - ETA: 2:08 - loss: 1.0128 - accuracy: 0.81 - ETA: 2:07 - loss: 1.0166 - accuracy: 0.81 - ETA: 2:06 - loss: 1.0162 - accuracy: 0.80 - ETA: 2:05 - loss: 1.0018 - accuracy: 0.81 - ETA: 2:04 - loss: 0.9963 - accuracy: 0.81 - ETA: 2:03 - loss: 1.0142 - accuracy: 0.81 - ETA: 2:02 - loss: 1.0061 - accuracy: 0.81 - ETA: 2:01 - loss: 1.0057 - accuracy: 0.81 - ETA: 2:01 - loss: 1.0177 - accuracy: 0.81 - ETA: 2:00 - loss: 1.0229 - accuracy: 0.81 - ETA: 1:58 - loss: 1.0326 - accuracy: 0.81 - ETA: 1:57 - loss: 1.0327 - accuracy: 0.81 - ETA: 1:56 - loss: 1.0451 - accuracy: 0.81 - ETA: 1:56 - loss: 1.0292 - accuracy: 0.81 - ETA: 1:55 - loss: 1.0225 - accuracy: 0.81 - ETA: 1:54 - loss: 1.0296 - accuracy: 0.80 - ETA: 1:53 - loss: 1.0241 - accuracy: 0.80 - ETA: 1:52 - loss: 1.0183 - accuracy: 0.81 - ETA: 1:51 - loss: 1.0046 - accuracy: 0.81 - ETA: 1:50 - loss: 1.0090 - accuracy: 0.81 - ETA: 1:49 - loss: 1.0193 - accuracy: 0.81 - ETA: 1:48 - loss: 1.0164 - accuracy: 0.81 - ETA: 1:47 - loss: 1.0174 - accuracy: 0.81 - ETA: 1:46 - loss: 1.0105 - accuracy: 0.81 - ETA: 1:45 - loss: 1.0050 - accuracy: 0.81 - ETA: 1:44 - loss: 0.9992 - accuracy: 0.81 - ETA: 1:43 - loss: 0.9944 - accuracy: 0.81 - ETA: 1:42 - loss: 0.9942 - accuracy: 0.81 - ETA: 1:41 - loss: 0.9903 - accuracy: 0.81 - ETA: 1:40 - loss: 0.9866 - accuracy: 0.81 - ETA: 1:39 - loss: 0.9851 - accuracy: 0.81 - ETA: 1:38 - loss: 0.9825 - accuracy: 0.81 - ETA: 1:37 - loss: 0.9823 - accuracy: 0.81 - ETA: 1:36 - loss: 0.9912 - accuracy: 0.81 - ETA: 1:35 - loss: 0.9869 - accuracy: 0.81 - ETA: 1:34 - loss: 0.9838 - accuracy: 0.81 - ETA: 1:33 - loss: 0.9858 - accuracy: 0.81 - ETA: 1:33 - loss: 0.9796 - accuracy: 0.81 - ETA: 1:32 - loss: 0.9767 - accuracy: 0.81 - ETA: 1:31 - loss: 0.9765 - accuracy: 0.81 - ETA: 1:30 - loss: 0.9751 - accuracy: 0.81 - ETA: 1:29 - loss: 0.9748 - accuracy: 0.81 - ETA: 1:28 - loss: 0.9752 - accuracy: 0.81 - ETA: 1:27 - loss: 0.9805 - accuracy: 0.81 - ETA: 1:26 - loss: 0.9887 - accuracy: 0.81 - ETA: 1:25 - loss: 0.9855 - accuracy: 0.81 - ETA: 1:24 - loss: 0.9879 - accuracy: 0.81 - ETA: 1:23 - loss: 0.9852 - accuracy: 0.81 - ETA: 1:22 - loss: 0.9852 - accuracy: 0.81 - ETA: 1:21 - loss: 0.9874 - accuracy: 0.81 - ETA: 1:20 - loss: 0.9955 - accuracy: 0.81 - ETA: 1:19 - loss: 0.9936 - accuracy: 0.81 - ETA: 1:18 - loss: 0.9969 - accuracy: 0.81 - ETA: 1:18 - loss: 0.9971 - accuracy: 0.81 - ETA: 1:17 - loss: 0.9949 - accuracy: 0.81 - ETA: 1:16 - loss: 0.9930 - accuracy: 0.81 - ETA: 1:15 - loss: 0.9921 - accuracy: 0.81 - ETA: 1:14 - loss: 0.9888 - accuracy: 0.81 - ETA: 1:13 - loss: 0.9938 - accuracy: 0.81 - ETA: 1:12 - loss: 1.0033 - accuracy: 0.81 - ETA: 1:11 - loss: 1.0054 - accuracy: 0.81 - ETA: 1:10 - loss: 1.0022 - accuracy: 0.81 - ETA: 1:09 - loss: 1.0029 - accuracy: 0.81 - ETA: 1:08 - loss: 0.9979 - accuracy: 0.81 - ETA: 1:07 - loss: 0.9971 - accuracy: 0.81 - ETA: 1:06 - loss: 1.0034 - accuracy: 0.81 - ETA: 1:05 - loss: 1.0007 - accuracy: 0.81 - ETA: 1:04 - loss: 1.0015 - accuracy: 0.81 - ETA: 1:03 - loss: 0.9997 - accuracy: 0.81 - ETA: 1:02 - loss: 0.9973 - accuracy: 0.81 - ETA: 1:01 - loss: 0.9959 - accuracy: 0.81 - ETA: 1:00 - loss: 0.9941 - accuracy: 0.81 - ETA: 59s - loss: 0.9932 - accuracy: 0.8136 - ETA: 58s - loss: 0.9898 - accuracy: 0.813 - ETA: 57s - loss: 0.9861 - accuracy: 0.814 - ETA: 56s - loss: 0.9851 - accuracy: 0.814 - ETA: 55s - loss: 0.9816 - accuracy: 0.815 - ETA: 54s - loss: 0.9787 - accuracy: 0.815 - ETA: 53s - loss: 0.9773 - accuracy: 0.815 - ETA: 52s - loss: 0.9757 - accuracy: 0.815 - ETA: 51s - loss: 0.9736 - accuracy: 0.815 - ETA: 50s - loss: 0.9748 - accuracy: 0.815 - ETA: 50s - loss: 0.9743 - accuracy: 0.815 - ETA: 49s - loss: 0.9788 - accuracy: 0.815 - ETA: 48s - loss: 0.9811 - accuracy: 0.815 - ETA: 47s - loss: 0.9807 - accuracy: 0.815 - ETA: 46s - loss: 0.9879 - accuracy: 0.815 - ETA: 45s - loss: 0.9868 - accuracy: 0.814 - ETA: 44s - loss: 0.9871 - accuracy: 0.814 - ETA: 43s - loss: 0.9876 - accuracy: 0.814 - ETA: 42s - loss: 0.9924 - accuracy: 0.814 - ETA: 41s - loss: 0.9935 - accuracy: 0.814 - ETA: 40s - loss: 0.9966 - accuracy: 0.813 - ETA: 39s - loss: 0.9940 - accuracy: 0.814 - ETA: 38s - loss: 0.9944 - accuracy: 0.814 - ETA: 37s - loss: 0.9959 - accuracy: 0.813 - ETA: 36s - loss: 0.9948 - accuracy: 0.813 - ETA: 35s - loss: 0.9969 - accuracy: 0.813 - ETA: 34s - loss: 0.9975 - accuracy: 0.813 - ETA: 33s - loss: 0.9965 - accuracy: 0.813 - ETA: 32s - loss: 0.9980 - accuracy: 0.813 - ETA: 31s - loss: 0.9967 - accuracy: 0.813 - ETA: 30s - loss: 0.9984 - accuracy: 0.813 - ETA: 29s - loss: 0.9937 - accuracy: 0.814 - ETA: 28s - loss: 0.9929 - accuracy: 0.814 - ETA: 27s - loss: 0.9942 - accuracy: 0.814 - ETA: 26s - loss: 0.9970 - accuracy: 0.814 - ETA: 25s - loss: 0.9983 - accuracy: 0.814 - ETA: 24s - loss: 0.9955 - accuracy: 0.814 - ETA: 23s - loss: 0.9969 - accuracy: 0.814 - ETA: 22s - loss: 0.9984 - accuracy: 0.814 - ETA: 22s - loss: 0.9961 - accuracy: 0.815 - ETA: 21s - loss: 0.9944 - accuracy: 0.815 - ETA: 20s - loss: 0.9932 - accuracy: 0.815 - ETA: 19s - loss: 0.9935 - accuracy: 0.815 - ETA: 18s - loss: 0.9964 - accuracy: 0.814 - ETA: 17s - loss: 0.9951 - accuracy: 0.814 - ETA: 16s - loss: 0.9916 - accuracy: 0.815 - ETA: 15s - loss: 0.9921 - accuracy: 0.815 - ETA: 14s - loss: 0.9951 - accuracy: 0.814 - ETA: 13s - loss: 0.9941 - accuracy: 0.814 - ETA: 12s - loss: 0.9954 - accuracy: 0.814 - ETA: 11s - loss: 0.9947 - accuracy: 0.814 - ETA: 10s - loss: 0.9966 - accuracy: 0.814 - ETA: 9s - loss: 0.9950 - accuracy: 0.814 - ETA: 8s - loss: 0.9936 - accuracy: 0.81 - ETA: 7s - loss: 0.9928 - accuracy: 0.81 - ETA: 6s - loss: 0.9936 - accuracy: 0.81 - ETA: 5s - loss: 0.9935 - accuracy: 0.81 - ETA: 4s - loss: 0.9928 - accuracy: 0.81 - ETA: 3s - loss: 0.9921 - accuracy: 0.81 - ETA: 2s - loss: 0.9940 - accuracy: 0.81 - ETA: 1s - loss: 0.9924 - accuracy: 0.81 - ETA: 0s - loss: 0.9974 - accuracy: 0.81 - 157s 8ms/step - loss: 0.9972 - accuracy: 0.8139 - val_loss: 2.3183 - val_accuracy: 0.7438\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:36 - loss: 1.2864 - accuracy: 0.78 - ETA: 2:24 - loss: 1.1426 - accuracy: 0.80 - ETA: 2:23 - loss: 0.9806 - accuracy: 0.82 - ETA: 2:21 - loss: 1.0691 - accuracy: 0.83 - ETA: 2:19 - loss: 1.0685 - accuracy: 0.82 - ETA: 2:17 - loss: 1.0135 - accuracy: 0.81 - ETA: 2:17 - loss: 1.0032 - accuracy: 0.82 - ETA: 2:16 - loss: 0.9628 - accuracy: 0.82 - ETA: 2:15 - loss: 0.9824 - accuracy: 0.81 - ETA: 2:13 - loss: 0.9464 - accuracy: 0.82 - ETA: 2:13 - loss: 0.9251 - accuracy: 0.82 - ETA: 2:13 - loss: 0.9363 - accuracy: 0.81 - ETA: 2:13 - loss: 0.9466 - accuracy: 0.81 - ETA: 2:12 - loss: 0.9475 - accuracy: 0.81 - ETA: 2:11 - loss: 0.9641 - accuracy: 0.81 - ETA: 2:10 - loss: 0.9820 - accuracy: 0.81 - ETA: 2:09 - loss: 0.9631 - accuracy: 0.81 - ETA: 2:08 - loss: 0.9898 - accuracy: 0.81 - ETA: 2:07 - loss: 1.0129 - accuracy: 0.81 - ETA: 2:06 - loss: 0.9940 - accuracy: 0.81 - ETA: 2:05 - loss: 0.9819 - accuracy: 0.81 - ETA: 2:03 - loss: 0.9964 - accuracy: 0.80 - ETA: 2:02 - loss: 0.9931 - accuracy: 0.81 - ETA: 2:01 - loss: 0.9827 - accuracy: 0.81 - ETA: 2:00 - loss: 0.9818 - accuracy: 0.81 - ETA: 1:59 - loss: 0.9802 - accuracy: 0.81 - ETA: 1:58 - loss: 0.9752 - accuracy: 0.81 - ETA: 1:58 - loss: 0.9824 - accuracy: 0.81 - ETA: 1:57 - loss: 0.9990 - accuracy: 0.80 - ETA: 1:56 - loss: 0.9901 - accuracy: 0.80 - ETA: 1:55 - loss: 0.9836 - accuracy: 0.80 - ETA: 1:54 - loss: 0.9849 - accuracy: 0.80 - ETA: 1:53 - loss: 0.9809 - accuracy: 0.80 - ETA: 1:52 - loss: 0.9708 - accuracy: 0.81 - ETA: 1:51 - loss: 0.9708 - accuracy: 0.81 - ETA: 1:50 - loss: 0.9824 - accuracy: 0.81 - ETA: 1:49 - loss: 0.9789 - accuracy: 0.81 - ETA: 1:48 - loss: 0.9837 - accuracy: 0.81 - ETA: 1:47 - loss: 0.9770 - accuracy: 0.81 - ETA: 1:46 - loss: 0.9658 - accuracy: 0.81 - ETA: 1:45 - loss: 0.9729 - accuracy: 0.81 - ETA: 1:44 - loss: 0.9729 - accuracy: 0.81 - ETA: 1:43 - loss: 0.9708 - accuracy: 0.81 - ETA: 1:42 - loss: 0.9690 - accuracy: 0.81 - ETA: 1:42 - loss: 0.9683 - accuracy: 0.81 - ETA: 1:41 - loss: 0.9667 - accuracy: 0.81 - ETA: 1:40 - loss: 0.9776 - accuracy: 0.81 - ETA: 1:39 - loss: 0.9750 - accuracy: 0.80 - ETA: 1:38 - loss: 0.9778 - accuracy: 0.81 - ETA: 1:37 - loss: 0.9755 - accuracy: 0.81 - ETA: 1:36 - loss: 0.9706 - accuracy: 0.81 - ETA: 1:35 - loss: 0.9661 - accuracy: 0.81 - ETA: 1:34 - loss: 0.9700 - accuracy: 0.81 - ETA: 1:33 - loss: 0.9714 - accuracy: 0.81 - ETA: 1:32 - loss: 0.9686 - accuracy: 0.81 - ETA: 1:31 - loss: 0.9642 - accuracy: 0.81 - ETA: 1:30 - loss: 0.9629 - accuracy: 0.81 - ETA: 1:29 - loss: 0.9602 - accuracy: 0.81 - ETA: 1:28 - loss: 0.9533 - accuracy: 0.81 - ETA: 1:27 - loss: 0.9509 - accuracy: 0.81 - ETA: 1:26 - loss: 0.9463 - accuracy: 0.81 - ETA: 1:25 - loss: 0.9521 - accuracy: 0.81 - ETA: 1:24 - loss: 0.9532 - accuracy: 0.81 - ETA: 1:23 - loss: 0.9521 - accuracy: 0.81 - ETA: 1:22 - loss: 0.9564 - accuracy: 0.81 - ETA: 1:21 - loss: 0.9603 - accuracy: 0.81 - ETA: 1:20 - loss: 0.9583 - accuracy: 0.81 - ETA: 1:19 - loss: 0.9621 - accuracy: 0.81 - ETA: 1:18 - loss: 0.9610 - accuracy: 0.81 - ETA: 1:17 - loss: 0.9624 - accuracy: 0.81 - ETA: 1:17 - loss: 0.9631 - accuracy: 0.81 - ETA: 1:16 - loss: 0.9664 - accuracy: 0.81 - ETA: 1:15 - loss: 0.9596 - accuracy: 0.81 - ETA: 1:14 - loss: 0.9595 - accuracy: 0.81 - ETA: 1:13 - loss: 0.9581 - accuracy: 0.81 - ETA: 1:12 - loss: 0.9595 - accuracy: 0.81 - ETA: 1:11 - loss: 0.9580 - accuracy: 0.81 - ETA: 1:10 - loss: 0.9579 - accuracy: 0.81 - ETA: 1:09 - loss: 0.9602 - accuracy: 0.81 - ETA: 1:08 - loss: 0.9592 - accuracy: 0.81 - ETA: 1:07 - loss: 0.9601 - accuracy: 0.81 - ETA: 1:06 - loss: 0.9591 - accuracy: 0.81 - ETA: 1:05 - loss: 0.9572 - accuracy: 0.81 - ETA: 1:04 - loss: 0.9546 - accuracy: 0.81 - ETA: 1:03 - loss: 0.9563 - accuracy: 0.81 - ETA: 1:02 - loss: 0.9593 - accuracy: 0.81 - ETA: 1:01 - loss: 0.9619 - accuracy: 0.81 - ETA: 1:00 - loss: 0.9622 - accuracy: 0.81 - ETA: 59s - loss: 0.9601 - accuracy: 0.8121 - ETA: 58s - loss: 0.9581 - accuracy: 0.812 - ETA: 57s - loss: 0.9552 - accuracy: 0.812 - ETA: 56s - loss: 0.9543 - accuracy: 0.812 - ETA: 55s - loss: 0.9507 - accuracy: 0.812 - ETA: 54s - loss: 0.9584 - accuracy: 0.811 - ETA: 53s - loss: 0.9582 - accuracy: 0.812 - ETA: 52s - loss: 0.9606 - accuracy: 0.812 - ETA: 51s - loss: 0.9581 - accuracy: 0.812 - ETA: 51s - loss: 0.9616 - accuracy: 0.812 - ETA: 50s - loss: 0.9601 - accuracy: 0.812 - ETA: 49s - loss: 0.9573 - accuracy: 0.812 - ETA: 48s - loss: 0.9547 - accuracy: 0.812 - ETA: 47s - loss: 0.9521 - accuracy: 0.813 - ETA: 46s - loss: 0.9575 - accuracy: 0.813 - ETA: 45s - loss: 0.9583 - accuracy: 0.813 - ETA: 44s - loss: 0.9616 - accuracy: 0.813 - ETA: 43s - loss: 0.9595 - accuracy: 0.813 - ETA: 42s - loss: 0.9594 - accuracy: 0.813 - ETA: 41s - loss: 0.9600 - accuracy: 0.813 - ETA: 40s - loss: 0.9623 - accuracy: 0.813 - ETA: 39s - loss: 0.9661 - accuracy: 0.813 - ETA: 38s - loss: 0.9691 - accuracy: 0.813 - ETA: 37s - loss: 0.9661 - accuracy: 0.813 - ETA: 36s - loss: 0.9625 - accuracy: 0.814 - ETA: 35s - loss: 0.9665 - accuracy: 0.814 - ETA: 34s - loss: 0.9699 - accuracy: 0.813 - ETA: 33s - loss: 0.9678 - accuracy: 0.814 - ETA: 32s - loss: 0.9667 - accuracy: 0.813 - ETA: 31s - loss: 0.9703 - accuracy: 0.813 - ETA: 30s - loss: 0.9702 - accuracy: 0.814 - ETA: 29s - loss: 0.9731 - accuracy: 0.813 - ETA: 28s - loss: 0.9742 - accuracy: 0.813 - ETA: 27s - loss: 0.9778 - accuracy: 0.813 - ETA: 26s - loss: 0.9777 - accuracy: 0.813 - ETA: 25s - loss: 0.9874 - accuracy: 0.812 - ETA: 24s - loss: 0.9879 - accuracy: 0.812 - ETA: 24s - loss: 0.9841 - accuracy: 0.812 - ETA: 23s - loss: 0.9818 - accuracy: 0.812 - ETA: 22s - loss: 0.9819 - accuracy: 0.812 - ETA: 21s - loss: 0.9819 - accuracy: 0.812 - ETA: 20s - loss: 0.9791 - accuracy: 0.813 - ETA: 19s - loss: 0.9808 - accuracy: 0.812 - ETA: 18s - loss: 0.9808 - accuracy: 0.812 - ETA: 17s - loss: 0.9824 - accuracy: 0.812 - ETA: 16s - loss: 0.9789 - accuracy: 0.812 - ETA: 15s - loss: 0.9782 - accuracy: 0.812 - ETA: 14s - loss: 0.9775 - accuracy: 0.812 - ETA: 13s - loss: 0.9807 - accuracy: 0.812 - ETA: 12s - loss: 0.9807 - accuracy: 0.812 - ETA: 11s - loss: 0.9789 - accuracy: 0.813 - ETA: 10s - loss: 0.9781 - accuracy: 0.813 - ETA: 9s - loss: 0.9749 - accuracy: 0.813 - ETA: 8s - loss: 0.9733 - accuracy: 0.81 - ETA: 7s - loss: 0.9736 - accuracy: 0.81 - ETA: 6s - loss: 0.9741 - accuracy: 0.81 - ETA: 5s - loss: 0.9735 - accuracy: 0.81 - ETA: 4s - loss: 0.9735 - accuracy: 0.81 - ETA: 3s - loss: 0.9734 - accuracy: 0.81 - ETA: 2s - loss: 0.9737 - accuracy: 0.81 - ETA: 1s - loss: 0.9774 - accuracy: 0.81 - ETA: 0s - loss: 0.9766 - accuracy: 0.81 - 157s 8ms/step - loss: 0.9765 - accuracy: 0.8131 - val_loss: 2.4444 - val_accuracy: 0.7432\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 1.0178 - accuracy: 0.83 - ETA: 2:30 - loss: 1.2433 - accuracy: 0.80 - ETA: 2:25 - loss: 1.2687 - accuracy: 0.81 - ETA: 2:21 - loss: 1.1752 - accuracy: 0.81 - ETA: 2:19 - loss: 1.0843 - accuracy: 0.82 - ETA: 2:18 - loss: 1.0140 - accuracy: 0.82 - ETA: 2:17 - loss: 1.1067 - accuracy: 0.81 - ETA: 2:15 - loss: 1.0423 - accuracy: 0.81 - ETA: 2:15 - loss: 1.0704 - accuracy: 0.81 - ETA: 2:14 - loss: 1.0259 - accuracy: 0.82 - ETA: 2:14 - loss: 1.0061 - accuracy: 0.81 - ETA: 2:13 - loss: 1.0113 - accuracy: 0.81 - ETA: 2:12 - loss: 0.9926 - accuracy: 0.81 - ETA: 2:12 - loss: 0.9989 - accuracy: 0.81 - ETA: 2:11 - loss: 1.0141 - accuracy: 0.81 - ETA: 2:09 - loss: 1.0157 - accuracy: 0.81 - ETA: 2:09 - loss: 1.0359 - accuracy: 0.81 - ETA: 2:08 - loss: 1.0214 - accuracy: 0.81 - ETA: 2:06 - loss: 1.0076 - accuracy: 0.81 - ETA: 2:05 - loss: 1.0171 - accuracy: 0.81 - ETA: 2:04 - loss: 1.0014 - accuracy: 0.81 - ETA: 2:03 - loss: 0.9955 - accuracy: 0.81 - ETA: 2:02 - loss: 1.0001 - accuracy: 0.82 - ETA: 2:01 - loss: 1.0330 - accuracy: 0.81 - ETA: 2:00 - loss: 1.0388 - accuracy: 0.81 - ETA: 1:59 - loss: 1.0280 - accuracy: 0.81 - ETA: 1:58 - loss: 1.0043 - accuracy: 0.81 - ETA: 1:57 - loss: 1.0038 - accuracy: 0.81 - ETA: 1:56 - loss: 0.9936 - accuracy: 0.82 - ETA: 1:56 - loss: 0.9956 - accuracy: 0.82 - ETA: 1:55 - loss: 1.0046 - accuracy: 0.82 - ETA: 1:54 - loss: 1.0035 - accuracy: 0.82 - ETA: 1:53 - loss: 1.0011 - accuracy: 0.82 - ETA: 1:52 - loss: 0.9969 - accuracy: 0.82 - ETA: 1:51 - loss: 0.9935 - accuracy: 0.82 - ETA: 1:50 - loss: 0.9902 - accuracy: 0.82 - ETA: 1:49 - loss: 0.9920 - accuracy: 0.82 - ETA: 1:48 - loss: 1.0006 - accuracy: 0.81 - ETA: 1:47 - loss: 1.0116 - accuracy: 0.81 - ETA: 1:46 - loss: 1.0259 - accuracy: 0.81 - ETA: 1:45 - loss: 1.0156 - accuracy: 0.81 - ETA: 1:44 - loss: 1.0138 - accuracy: 0.81 - ETA: 1:43 - loss: 1.0174 - accuracy: 0.81 - ETA: 1:42 - loss: 1.0190 - accuracy: 0.81 - ETA: 1:41 - loss: 1.0099 - accuracy: 0.81 - ETA: 1:40 - loss: 1.0040 - accuracy: 0.81 - ETA: 1:39 - loss: 1.0023 - accuracy: 0.81 - ETA: 1:39 - loss: 0.9950 - accuracy: 0.81 - ETA: 1:38 - loss: 0.9914 - accuracy: 0.81 - ETA: 1:37 - loss: 0.9929 - accuracy: 0.81 - ETA: 1:36 - loss: 0.9904 - accuracy: 0.81 - ETA: 1:35 - loss: 0.9889 - accuracy: 0.81 - ETA: 1:34 - loss: 0.9898 - accuracy: 0.81 - ETA: 1:33 - loss: 0.9965 - accuracy: 0.81 - ETA: 1:32 - loss: 0.9899 - accuracy: 0.81 - ETA: 1:31 - loss: 0.9837 - accuracy: 0.81 - ETA: 1:30 - loss: 0.9850 - accuracy: 0.81 - ETA: 1:29 - loss: 0.9817 - accuracy: 0.81 - ETA: 1:28 - loss: 0.9835 - accuracy: 0.81 - ETA: 1:27 - loss: 0.9807 - accuracy: 0.81 - ETA: 1:26 - loss: 0.9841 - accuracy: 0.81 - ETA: 1:25 - loss: 0.9865 - accuracy: 0.81 - ETA: 1:24 - loss: 0.9869 - accuracy: 0.81 - ETA: 1:23 - loss: 0.9865 - accuracy: 0.81 - ETA: 1:22 - loss: 0.9782 - accuracy: 0.81 - ETA: 1:21 - loss: 0.9732 - accuracy: 0.81 - ETA: 1:20 - loss: 0.9719 - accuracy: 0.81 - ETA: 1:19 - loss: 0.9679 - accuracy: 0.81 - ETA: 1:18 - loss: 0.9635 - accuracy: 0.82 - ETA: 1:18 - loss: 0.9711 - accuracy: 0.82 - ETA: 1:17 - loss: 0.9719 - accuracy: 0.81 - ETA: 1:16 - loss: 0.9652 - accuracy: 0.82 - ETA: 1:15 - loss: 0.9673 - accuracy: 0.82 - ETA: 1:14 - loss: 0.9722 - accuracy: 0.82 - ETA: 1:13 - loss: 0.9755 - accuracy: 0.82 - ETA: 1:12 - loss: 0.9758 - accuracy: 0.82 - ETA: 1:11 - loss: 0.9787 - accuracy: 0.82 - ETA: 1:10 - loss: 0.9759 - accuracy: 0.82 - ETA: 1:09 - loss: 0.9738 - accuracy: 0.82 - ETA: 1:08 - loss: 0.9725 - accuracy: 0.82 - ETA: 1:07 - loss: 0.9745 - accuracy: 0.82 - ETA: 1:06 - loss: 0.9709 - accuracy: 0.82 - ETA: 1:05 - loss: 0.9677 - accuracy: 0.82 - ETA: 1:04 - loss: 0.9611 - accuracy: 0.82 - ETA: 1:03 - loss: 0.9598 - accuracy: 0.82 - ETA: 1:02 - loss: 0.9567 - accuracy: 0.82 - ETA: 1:01 - loss: 0.9570 - accuracy: 0.82 - ETA: 1:00 - loss: 0.9614 - accuracy: 0.82 - ETA: 59s - loss: 0.9573 - accuracy: 0.8220 - ETA: 59s - loss: 0.9582 - accuracy: 0.821 - ETA: 58s - loss: 0.9622 - accuracy: 0.821 - ETA: 57s - loss: 0.9659 - accuracy: 0.821 - ETA: 56s - loss: 0.9647 - accuracy: 0.821 - ETA: 55s - loss: 0.9639 - accuracy: 0.821 - ETA: 54s - loss: 0.9692 - accuracy: 0.821 - ETA: 53s - loss: 0.9707 - accuracy: 0.820 - ETA: 52s - loss: 0.9721 - accuracy: 0.820 - ETA: 51s - loss: 0.9712 - accuracy: 0.821 - ETA: 50s - loss: 0.9701 - accuracy: 0.821 - ETA: 49s - loss: 0.9723 - accuracy: 0.820 - ETA: 48s - loss: 0.9716 - accuracy: 0.820 - ETA: 47s - loss: 0.9705 - accuracy: 0.820 - ETA: 46s - loss: 0.9690 - accuracy: 0.820 - ETA: 45s - loss: 0.9664 - accuracy: 0.820 - ETA: 44s - loss: 0.9730 - accuracy: 0.820 - ETA: 43s - loss: 0.9708 - accuracy: 0.820 - ETA: 42s - loss: 0.9736 - accuracy: 0.820 - ETA: 41s - loss: 0.9742 - accuracy: 0.820 - ETA: 40s - loss: 0.9731 - accuracy: 0.819 - ETA: 39s - loss: 0.9708 - accuracy: 0.820 - ETA: 38s - loss: 0.9675 - accuracy: 0.820 - ETA: 37s - loss: 0.9663 - accuracy: 0.821 - ETA: 36s - loss: 0.9693 - accuracy: 0.821 - ETA: 35s - loss: 0.9673 - accuracy: 0.821 - ETA: 34s - loss: 0.9663 - accuracy: 0.821 - ETA: 33s - loss: 0.9637 - accuracy: 0.821 - ETA: 32s - loss: 0.9631 - accuracy: 0.821 - ETA: 31s - loss: 0.9630 - accuracy: 0.821 - ETA: 30s - loss: 0.9669 - accuracy: 0.821 - ETA: 29s - loss: 0.9693 - accuracy: 0.821 - ETA: 28s - loss: 0.9685 - accuracy: 0.820 - ETA: 27s - loss: 0.9657 - accuracy: 0.821 - ETA: 27s - loss: 0.9638 - accuracy: 0.821 - ETA: 26s - loss: 0.9670 - accuracy: 0.821 - ETA: 25s - loss: 0.9681 - accuracy: 0.821 - ETA: 24s - loss: 0.9666 - accuracy: 0.821 - ETA: 23s - loss: 0.9638 - accuracy: 0.821 - ETA: 22s - loss: 0.9648 - accuracy: 0.821 - ETA: 21s - loss: 0.9634 - accuracy: 0.821 - ETA: 20s - loss: 0.9662 - accuracy: 0.820 - ETA: 19s - loss: 0.9662 - accuracy: 0.820 - ETA: 18s - loss: 0.9701 - accuracy: 0.820 - ETA: 17s - loss: 0.9767 - accuracy: 0.820 - ETA: 16s - loss: 0.9748 - accuracy: 0.820 - ETA: 15s - loss: 0.9748 - accuracy: 0.820 - ETA: 14s - loss: 0.9766 - accuracy: 0.820 - ETA: 13s - loss: 0.9760 - accuracy: 0.820 - ETA: 12s - loss: 0.9735 - accuracy: 0.820 - ETA: 11s - loss: 0.9707 - accuracy: 0.820 - ETA: 10s - loss: 0.9714 - accuracy: 0.820 - ETA: 9s - loss: 0.9711 - accuracy: 0.820 - ETA: 8s - loss: 0.9700 - accuracy: 0.82 - ETA: 7s - loss: 0.9697 - accuracy: 0.82 - ETA: 6s - loss: 0.9669 - accuracy: 0.82 - ETA: 5s - loss: 0.9636 - accuracy: 0.82 - ETA: 4s - loss: 0.9620 - accuracy: 0.82 - ETA: 3s - loss: 0.9665 - accuracy: 0.82 - ETA: 2s - loss: 0.9691 - accuracy: 0.82 - ETA: 1s - loss: 0.9716 - accuracy: 0.81 - ETA: 0s - loss: 0.9733 - accuracy: 0.81 - 158s 8ms/step - loss: 0.9738 - accuracy: 0.8193 - val_loss: 2.3672 - val_accuracy: 0.7374\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:32 - loss: 0.8670 - accuracy: 0.80 - ETA: 2:24 - loss: 0.9980 - accuracy: 0.79 - ETA: 2:22 - loss: 0.9413 - accuracy: 0.80 - ETA: 2:18 - loss: 0.9698 - accuracy: 0.80 - ETA: 2:17 - loss: 0.9195 - accuracy: 0.81 - ETA: 2:19 - loss: 0.8991 - accuracy: 0.82 - ETA: 2:19 - loss: 0.9293 - accuracy: 0.81 - ETA: 2:18 - loss: 1.0301 - accuracy: 0.80 - ETA: 2:15 - loss: 1.0274 - accuracy: 0.81 - ETA: 2:14 - loss: 1.0191 - accuracy: 0.81 - ETA: 2:13 - loss: 1.0146 - accuracy: 0.81 - ETA: 2:11 - loss: 1.0114 - accuracy: 0.81 - ETA: 2:11 - loss: 1.0047 - accuracy: 0.81 - ETA: 2:10 - loss: 0.9877 - accuracy: 0.81 - ETA: 2:09 - loss: 1.0265 - accuracy: 0.81 - ETA: 2:09 - loss: 1.0118 - accuracy: 0.81 - ETA: 2:08 - loss: 0.9915 - accuracy: 0.81 - ETA: 2:07 - loss: 0.9856 - accuracy: 0.81 - ETA: 2:05 - loss: 0.9703 - accuracy: 0.81 - ETA: 2:05 - loss: 0.9769 - accuracy: 0.81 - ETA: 2:04 - loss: 0.9891 - accuracy: 0.81 - ETA: 2:03 - loss: 0.9954 - accuracy: 0.81 - ETA: 2:02 - loss: 0.9995 - accuracy: 0.81 - ETA: 2:01 - loss: 1.0039 - accuracy: 0.81 - ETA: 2:00 - loss: 1.0234 - accuracy: 0.81 - ETA: 1:59 - loss: 1.0228 - accuracy: 0.81 - ETA: 1:58 - loss: 1.0378 - accuracy: 0.81 - ETA: 1:57 - loss: 1.0403 - accuracy: 0.80 - ETA: 1:56 - loss: 1.0513 - accuracy: 0.80 - ETA: 1:55 - loss: 1.0503 - accuracy: 0.80 - ETA: 1:54 - loss: 1.0552 - accuracy: 0.80 - ETA: 1:53 - loss: 1.0664 - accuracy: 0.80 - ETA: 1:52 - loss: 1.0554 - accuracy: 0.80 - ETA: 1:51 - loss: 1.0683 - accuracy: 0.80 - ETA: 1:50 - loss: 1.0688 - accuracy: 0.80 - ETA: 1:49 - loss: 1.0690 - accuracy: 0.80 - ETA: 1:48 - loss: 1.0779 - accuracy: 0.80 - ETA: 1:48 - loss: 1.0693 - accuracy: 0.80 - ETA: 1:47 - loss: 1.0681 - accuracy: 0.80 - ETA: 1:46 - loss: 1.0615 - accuracy: 0.80 - ETA: 1:45 - loss: 1.0532 - accuracy: 0.80 - ETA: 1:44 - loss: 1.0614 - accuracy: 0.80 - ETA: 1:43 - loss: 1.0570 - accuracy: 0.80 - ETA: 1:42 - loss: 1.0581 - accuracy: 0.80 - ETA: 1:41 - loss: 1.0536 - accuracy: 0.80 - ETA: 1:40 - loss: 1.0589 - accuracy: 0.80 - ETA: 1:39 - loss: 1.0476 - accuracy: 0.80 - ETA: 1:38 - loss: 1.0383 - accuracy: 0.80 - ETA: 1:37 - loss: 1.0359 - accuracy: 0.80 - ETA: 1:37 - loss: 1.0302 - accuracy: 0.81 - ETA: 1:36 - loss: 1.0295 - accuracy: 0.80 - ETA: 1:35 - loss: 1.0353 - accuracy: 0.81 - ETA: 1:34 - loss: 1.0367 - accuracy: 0.81 - ETA: 1:33 - loss: 1.0328 - accuracy: 0.81 - ETA: 1:32 - loss: 1.0309 - accuracy: 0.81 - ETA: 1:31 - loss: 1.0342 - accuracy: 0.81 - ETA: 1:30 - loss: 1.0377 - accuracy: 0.81 - ETA: 1:29 - loss: 1.0588 - accuracy: 0.81 - ETA: 1:28 - loss: 1.0591 - accuracy: 0.81 - ETA: 1:27 - loss: 1.0519 - accuracy: 0.81 - ETA: 1:26 - loss: 1.0535 - accuracy: 0.81 - ETA: 1:25 - loss: 1.0475 - accuracy: 0.81 - ETA: 1:24 - loss: 1.0455 - accuracy: 0.81 - ETA: 1:23 - loss: 1.0443 - accuracy: 0.81 - ETA: 1:22 - loss: 1.0482 - accuracy: 0.81 - ETA: 1:22 - loss: 1.0422 - accuracy: 0.81 - ETA: 1:21 - loss: 1.0368 - accuracy: 0.81 - ETA: 1:20 - loss: 1.0340 - accuracy: 0.81 - ETA: 1:19 - loss: 1.0301 - accuracy: 0.81 - ETA: 1:18 - loss: 1.0285 - accuracy: 0.81 - ETA: 1:17 - loss: 1.0376 - accuracy: 0.81 - ETA: 1:16 - loss: 1.0347 - accuracy: 0.81 - ETA: 1:15 - loss: 1.0374 - accuracy: 0.81 - ETA: 1:14 - loss: 1.0351 - accuracy: 0.81 - ETA: 1:13 - loss: 1.0335 - accuracy: 0.81 - ETA: 1:12 - loss: 1.0263 - accuracy: 0.81 - ETA: 1:11 - loss: 1.0202 - accuracy: 0.81 - ETA: 1:10 - loss: 1.0138 - accuracy: 0.81 - ETA: 1:09 - loss: 1.0091 - accuracy: 0.81 - ETA: 1:08 - loss: 1.0100 - accuracy: 0.81 - ETA: 1:07 - loss: 1.0141 - accuracy: 0.81 - ETA: 1:06 - loss: 1.0174 - accuracy: 0.81 - ETA: 1:05 - loss: 1.0144 - accuracy: 0.81 - ETA: 1:04 - loss: 1.0155 - accuracy: 0.81 - ETA: 1:03 - loss: 1.0142 - accuracy: 0.81 - ETA: 1:02 - loss: 1.0149 - accuracy: 0.81 - ETA: 1:01 - loss: 1.0147 - accuracy: 0.81 - ETA: 1:00 - loss: 1.0109 - accuracy: 0.81 - ETA: 59s - loss: 1.0064 - accuracy: 0.8146 - ETA: 58s - loss: 1.0072 - accuracy: 0.814 - ETA: 57s - loss: 1.0065 - accuracy: 0.814 - ETA: 56s - loss: 1.0026 - accuracy: 0.815 - ETA: 55s - loss: 1.0018 - accuracy: 0.815 - ETA: 54s - loss: 0.9997 - accuracy: 0.815 - ETA: 53s - loss: 1.0007 - accuracy: 0.814 - ETA: 52s - loss: 0.9990 - accuracy: 0.814 - ETA: 51s - loss: 0.9972 - accuracy: 0.814 - ETA: 50s - loss: 0.9997 - accuracy: 0.813 - ETA: 49s - loss: 0.9992 - accuracy: 0.813 - ETA: 49s - loss: 1.0015 - accuracy: 0.813 - ETA: 48s - loss: 1.0020 - accuracy: 0.813 - ETA: 47s - loss: 1.0079 - accuracy: 0.813 - ETA: 46s - loss: 1.0054 - accuracy: 0.813 - ETA: 45s - loss: 1.0047 - accuracy: 0.813 - ETA: 44s - loss: 1.0022 - accuracy: 0.813 - ETA: 43s - loss: 1.0026 - accuracy: 0.813 - ETA: 42s - loss: 1.0032 - accuracy: 0.813 - ETA: 41s - loss: 1.0044 - accuracy: 0.813 - ETA: 40s - loss: 1.0076 - accuracy: 0.813 - ETA: 39s - loss: 1.0071 - accuracy: 0.813 - ETA: 38s - loss: 1.0085 - accuracy: 0.813 - ETA: 37s - loss: 1.0089 - accuracy: 0.813 - ETA: 36s - loss: 1.0072 - accuracy: 0.813 - ETA: 35s - loss: 1.0054 - accuracy: 0.813 - ETA: 34s - loss: 1.0041 - accuracy: 0.813 - ETA: 33s - loss: 1.0020 - accuracy: 0.813 - ETA: 32s - loss: 0.9992 - accuracy: 0.814 - ETA: 31s - loss: 0.9956 - accuracy: 0.814 - ETA: 30s - loss: 0.9952 - accuracy: 0.814 - ETA: 29s - loss: 0.9910 - accuracy: 0.814 - ETA: 28s - loss: 0.9890 - accuracy: 0.814 - ETA: 27s - loss: 0.9889 - accuracy: 0.814 - ETA: 26s - loss: 0.9885 - accuracy: 0.814 - ETA: 25s - loss: 0.9871 - accuracy: 0.815 - ETA: 24s - loss: 0.9867 - accuracy: 0.815 - ETA: 24s - loss: 0.9881 - accuracy: 0.814 - ETA: 23s - loss: 0.9859 - accuracy: 0.815 - ETA: 22s - loss: 0.9839 - accuracy: 0.815 - ETA: 21s - loss: 0.9813 - accuracy: 0.815 - ETA: 20s - loss: 0.9844 - accuracy: 0.815 - ETA: 19s - loss: 0.9851 - accuracy: 0.815 - ETA: 18s - loss: 0.9864 - accuracy: 0.814 - ETA: 17s - loss: 0.9834 - accuracy: 0.815 - ETA: 16s - loss: 0.9805 - accuracy: 0.815 - ETA: 15s - loss: 0.9789 - accuracy: 0.815 - ETA: 14s - loss: 0.9766 - accuracy: 0.816 - ETA: 13s - loss: 0.9788 - accuracy: 0.815 - ETA: 12s - loss: 0.9786 - accuracy: 0.815 - ETA: 11s - loss: 0.9774 - accuracy: 0.816 - ETA: 10s - loss: 0.9748 - accuracy: 0.816 - ETA: 9s - loss: 0.9719 - accuracy: 0.816 - ETA: 8s - loss: 0.9746 - accuracy: 0.81 - ETA: 7s - loss: 0.9754 - accuracy: 0.81 - ETA: 6s - loss: 0.9758 - accuracy: 0.81 - ETA: 5s - loss: 0.9736 - accuracy: 0.81 - ETA: 4s - loss: 0.9728 - accuracy: 0.81 - ETA: 3s - loss: 0.9724 - accuracy: 0.81 - ETA: 2s - loss: 0.9743 - accuracy: 0.81 - ETA: 1s - loss: 0.9754 - accuracy: 0.81 - ETA: 0s - loss: 0.9755 - accuracy: 0.81 - 157s 8ms/step - loss: 0.9751 - accuracy: 0.8163 - val_loss: 2.5408 - val_accuracy: 0.7409\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 0.7209 - accuracy: 0.84 - ETA: 2:34 - loss: 0.7792 - accuracy: 0.83 - ETA: 2:31 - loss: 0.7399 - accuracy: 0.84 - ETA: 2:27 - loss: 0.7601 - accuracy: 0.84 - ETA: 2:24 - loss: 0.7774 - accuracy: 0.84 - ETA: 2:21 - loss: 0.7780 - accuracy: 0.84 - ETA: 2:20 - loss: 0.8125 - accuracy: 0.84 - ETA: 2:19 - loss: 0.8959 - accuracy: 0.83 - ETA: 2:18 - loss: 0.9484 - accuracy: 0.83 - ETA: 2:18 - loss: 0.9316 - accuracy: 0.83 - ETA: 2:17 - loss: 0.9298 - accuracy: 0.83 - ETA: 2:16 - loss: 0.9577 - accuracy: 0.83 - ETA: 2:14 - loss: 0.9532 - accuracy: 0.83 - ETA: 2:12 - loss: 0.9575 - accuracy: 0.82 - ETA: 2:11 - loss: 0.9535 - accuracy: 0.82 - ETA: 2:10 - loss: 0.9392 - accuracy: 0.82 - ETA: 2:09 - loss: 0.9329 - accuracy: 0.82 - ETA: 2:08 - loss: 0.9516 - accuracy: 0.82 - ETA: 2:08 - loss: 0.9465 - accuracy: 0.82 - ETA: 2:08 - loss: 0.9506 - accuracy: 0.82 - ETA: 2:06 - loss: 0.9296 - accuracy: 0.82 - ETA: 2:05 - loss: 0.9261 - accuracy: 0.82 - ETA: 2:04 - loss: 0.9090 - accuracy: 0.82 - ETA: 2:03 - loss: 0.9123 - accuracy: 0.82 - ETA: 2:02 - loss: 0.9074 - accuracy: 0.82 - ETA: 2:01 - loss: 0.9270 - accuracy: 0.82 - ETA: 2:01 - loss: 0.9204 - accuracy: 0.82 - ETA: 2:00 - loss: 0.9373 - accuracy: 0.82 - ETA: 1:59 - loss: 0.9275 - accuracy: 0.82 - ETA: 1:58 - loss: 0.9147 - accuracy: 0.82 - ETA: 1:57 - loss: 0.9014 - accuracy: 0.82 - ETA: 1:55 - loss: 0.9201 - accuracy: 0.82 - ETA: 1:54 - loss: 0.9099 - accuracy: 0.82 - ETA: 1:53 - loss: 0.9264 - accuracy: 0.82 - ETA: 1:52 - loss: 0.9254 - accuracy: 0.82 - ETA: 1:51 - loss: 0.9144 - accuracy: 0.82 - ETA: 1:50 - loss: 0.9209 - accuracy: 0.82 - ETA: 1:49 - loss: 0.9400 - accuracy: 0.82 - ETA: 1:48 - loss: 0.9390 - accuracy: 0.82 - ETA: 1:47 - loss: 0.9356 - accuracy: 0.82 - ETA: 1:46 - loss: 0.9452 - accuracy: 0.82 - ETA: 1:45 - loss: 0.9525 - accuracy: 0.82 - ETA: 1:44 - loss: 0.9520 - accuracy: 0.82 - ETA: 1:43 - loss: 0.9599 - accuracy: 0.82 - ETA: 1:42 - loss: 0.9628 - accuracy: 0.82 - ETA: 1:41 - loss: 0.9720 - accuracy: 0.82 - ETA: 1:40 - loss: 0.9715 - accuracy: 0.82 - ETA: 1:39 - loss: 0.9672 - accuracy: 0.82 - ETA: 1:38 - loss: 0.9677 - accuracy: 0.82 - ETA: 1:37 - loss: 0.9708 - accuracy: 0.82 - ETA: 1:36 - loss: 0.9740 - accuracy: 0.82 - ETA: 1:36 - loss: 0.9718 - accuracy: 0.82 - ETA: 1:35 - loss: 0.9658 - accuracy: 0.82 - ETA: 1:34 - loss: 0.9658 - accuracy: 0.82 - ETA: 1:33 - loss: 0.9649 - accuracy: 0.82 - ETA: 1:32 - loss: 0.9659 - accuracy: 0.82 - ETA: 1:31 - loss: 0.9596 - accuracy: 0.82 - ETA: 1:30 - loss: 0.9617 - accuracy: 0.82 - ETA: 1:29 - loss: 0.9601 - accuracy: 0.82 - ETA: 1:28 - loss: 0.9570 - accuracy: 0.82 - ETA: 1:27 - loss: 0.9591 - accuracy: 0.82 - ETA: 1:26 - loss: 0.9586 - accuracy: 0.82 - ETA: 1:25 - loss: 0.9619 - accuracy: 0.82 - ETA: 1:24 - loss: 0.9578 - accuracy: 0.82 - ETA: 1:23 - loss: 0.9591 - accuracy: 0.82 - ETA: 1:22 - loss: 0.9581 - accuracy: 0.82 - ETA: 1:21 - loss: 0.9582 - accuracy: 0.82 - ETA: 1:20 - loss: 0.9581 - accuracy: 0.82 - ETA: 1:19 - loss: 0.9615 - accuracy: 0.82 - ETA: 1:18 - loss: 0.9651 - accuracy: 0.82 - ETA: 1:17 - loss: 0.9628 - accuracy: 0.82 - ETA: 1:16 - loss: 0.9666 - accuracy: 0.82 - ETA: 1:15 - loss: 0.9695 - accuracy: 0.82 - ETA: 1:14 - loss: 0.9693 - accuracy: 0.82 - ETA: 1:13 - loss: 0.9684 - accuracy: 0.82 - ETA: 1:12 - loss: 0.9664 - accuracy: 0.82 - ETA: 1:11 - loss: 0.9702 - accuracy: 0.82 - ETA: 1:10 - loss: 0.9693 - accuracy: 0.82 - ETA: 1:09 - loss: 0.9676 - accuracy: 0.82 - ETA: 1:08 - loss: 0.9722 - accuracy: 0.82 - ETA: 1:07 - loss: 0.9779 - accuracy: 0.82 - ETA: 1:06 - loss: 0.9746 - accuracy: 0.82 - ETA: 1:05 - loss: 0.9731 - accuracy: 0.82 - ETA: 1:04 - loss: 0.9844 - accuracy: 0.82 - ETA: 1:03 - loss: 0.9812 - accuracy: 0.82 - ETA: 1:02 - loss: 0.9776 - accuracy: 0.82 - ETA: 1:01 - loss: 0.9790 - accuracy: 0.82 - ETA: 1:00 - loss: 0.9743 - accuracy: 0.82 - ETA: 59s - loss: 0.9725 - accuracy: 0.8225 - ETA: 58s - loss: 0.9724 - accuracy: 0.822 - ETA: 57s - loss: 0.9691 - accuracy: 0.822 - ETA: 56s - loss: 0.9676 - accuracy: 0.822 - ETA: 55s - loss: 0.9670 - accuracy: 0.822 - ETA: 55s - loss: 0.9652 - accuracy: 0.822 - ETA: 54s - loss: 0.9675 - accuracy: 0.821 - ETA: 53s - loss: 0.9675 - accuracy: 0.821 - ETA: 52s - loss: 0.9660 - accuracy: 0.821 - ETA: 51s - loss: 0.9696 - accuracy: 0.821 - ETA: 50s - loss: 0.9661 - accuracy: 0.821 - ETA: 49s - loss: 0.9671 - accuracy: 0.821 - ETA: 48s - loss: 0.9681 - accuracy: 0.821 - ETA: 47s - loss: 0.9680 - accuracy: 0.821 - ETA: 46s - loss: 0.9663 - accuracy: 0.821 - ETA: 45s - loss: 0.9655 - accuracy: 0.821 - ETA: 44s - loss: 0.9622 - accuracy: 0.821 - ETA: 43s - loss: 0.9661 - accuracy: 0.821 - ETA: 42s - loss: 0.9658 - accuracy: 0.821 - ETA: 41s - loss: 0.9658 - accuracy: 0.821 - ETA: 40s - loss: 0.9648 - accuracy: 0.821 - ETA: 39s - loss: 0.9686 - accuracy: 0.821 - ETA: 38s - loss: 0.9667 - accuracy: 0.821 - ETA: 37s - loss: 0.9648 - accuracy: 0.821 - ETA: 36s - loss: 0.9639 - accuracy: 0.821 - ETA: 35s - loss: 0.9657 - accuracy: 0.821 - ETA: 34s - loss: 0.9656 - accuracy: 0.821 - ETA: 33s - loss: 0.9673 - accuracy: 0.821 - ETA: 32s - loss: 0.9652 - accuracy: 0.821 - ETA: 31s - loss: 0.9629 - accuracy: 0.821 - ETA: 30s - loss: 0.9629 - accuracy: 0.821 - ETA: 29s - loss: 0.9633 - accuracy: 0.821 - ETA: 28s - loss: 0.9645 - accuracy: 0.821 - ETA: 27s - loss: 0.9668 - accuracy: 0.820 - ETA: 26s - loss: 0.9652 - accuracy: 0.820 - ETA: 26s - loss: 0.9650 - accuracy: 0.820 - ETA: 25s - loss: 0.9639 - accuracy: 0.820 - ETA: 24s - loss: 0.9630 - accuracy: 0.820 - ETA: 23s - loss: 0.9628 - accuracy: 0.820 - ETA: 22s - loss: 0.9628 - accuracy: 0.820 - ETA: 21s - loss: 0.9625 - accuracy: 0.820 - ETA: 20s - loss: 0.9627 - accuracy: 0.820 - ETA: 19s - loss: 0.9636 - accuracy: 0.820 - ETA: 18s - loss: 0.9635 - accuracy: 0.820 - ETA: 17s - loss: 0.9641 - accuracy: 0.820 - ETA: 16s - loss: 0.9638 - accuracy: 0.820 - ETA: 15s - loss: 0.9635 - accuracy: 0.820 - ETA: 14s - loss: 0.9609 - accuracy: 0.821 - ETA: 13s - loss: 0.9614 - accuracy: 0.821 - ETA: 12s - loss: 0.9624 - accuracy: 0.820 - ETA: 11s - loss: 0.9640 - accuracy: 0.820 - ETA: 10s - loss: 0.9636 - accuracy: 0.821 - ETA: 9s - loss: 0.9605 - accuracy: 0.821 - ETA: 8s - loss: 0.9594 - accuracy: 0.82 - ETA: 7s - loss: 0.9608 - accuracy: 0.82 - ETA: 6s - loss: 0.9652 - accuracy: 0.82 - ETA: 5s - loss: 0.9655 - accuracy: 0.82 - ETA: 4s - loss: 0.9688 - accuracy: 0.82 - ETA: 3s - loss: 0.9712 - accuracy: 0.82 - ETA: 2s - loss: 0.9749 - accuracy: 0.82 - ETA: 1s - loss: 0.9736 - accuracy: 0.82 - ETA: 0s - loss: 0.9736 - accuracy: 0.82 - 158s 8ms/step - loss: 0.9763 - accuracy: 0.8196 - val_loss: 2.5738 - val_accuracy: 0.7530\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:33 - loss: 0.7850 - accuracy: 0.82 - ETA: 2:32 - loss: 0.8198 - accuracy: 0.81 - ETA: 2:29 - loss: 0.9065 - accuracy: 0.83 - ETA: 2:26 - loss: 1.0394 - accuracy: 0.81 - ETA: 2:29 - loss: 1.0146 - accuracy: 0.81 - ETA: 2:28 - loss: 1.0319 - accuracy: 0.80 - ETA: 2:25 - loss: 1.0564 - accuracy: 0.80 - ETA: 2:23 - loss: 1.0445 - accuracy: 0.81 - ETA: 2:21 - loss: 1.0672 - accuracy: 0.80 - ETA: 2:20 - loss: 1.0177 - accuracy: 0.81 - ETA: 2:18 - loss: 1.0152 - accuracy: 0.81 - ETA: 2:17 - loss: 1.0483 - accuracy: 0.81 - ETA: 2:16 - loss: 1.0219 - accuracy: 0.81 - ETA: 2:14 - loss: 0.9954 - accuracy: 0.82 - ETA: 2:12 - loss: 0.9705 - accuracy: 0.82 - ETA: 2:11 - loss: 0.9617 - accuracy: 0.82 - ETA: 2:09 - loss: 0.9681 - accuracy: 0.82 - ETA: 2:09 - loss: 0.9394 - accuracy: 0.82 - ETA: 2:07 - loss: 0.9502 - accuracy: 0.82 - ETA: 2:06 - loss: 0.9518 - accuracy: 0.82 - ETA: 2:05 - loss: 0.9416 - accuracy: 0.82 - ETA: 2:05 - loss: 0.9392 - accuracy: 0.82 - ETA: 2:04 - loss: 0.9328 - accuracy: 0.82 - ETA: 2:03 - loss: 0.9206 - accuracy: 0.82 - ETA: 2:02 - loss: 0.9443 - accuracy: 0.82 - ETA: 2:00 - loss: 0.9497 - accuracy: 0.82 - ETA: 1:59 - loss: 0.9482 - accuracy: 0.82 - ETA: 1:58 - loss: 0.9369 - accuracy: 0.82 - ETA: 1:57 - loss: 0.9400 - accuracy: 0.82 - ETA: 1:56 - loss: 0.9317 - accuracy: 0.83 - ETA: 1:55 - loss: 0.9300 - accuracy: 0.82 - ETA: 1:54 - loss: 0.9392 - accuracy: 0.82 - ETA: 1:53 - loss: 0.9427 - accuracy: 0.82 - ETA: 1:52 - loss: 0.9274 - accuracy: 0.83 - ETA: 1:51 - loss: 0.9265 - accuracy: 0.83 - ETA: 1:50 - loss: 0.9296 - accuracy: 0.83 - ETA: 1:49 - loss: 0.9311 - accuracy: 0.82 - ETA: 1:48 - loss: 0.9332 - accuracy: 0.82 - ETA: 1:47 - loss: 0.9418 - accuracy: 0.82 - ETA: 1:46 - loss: 0.9334 - accuracy: 0.82 - ETA: 1:45 - loss: 0.9401 - accuracy: 0.82 - ETA: 1:44 - loss: 0.9396 - accuracy: 0.82 - ETA: 1:43 - loss: 0.9513 - accuracy: 0.82 - ETA: 1:42 - loss: 0.9462 - accuracy: 0.82 - ETA: 1:41 - loss: 0.9416 - accuracy: 0.82 - ETA: 1:40 - loss: 0.9331 - accuracy: 0.83 - ETA: 1:39 - loss: 0.9275 - accuracy: 0.83 - ETA: 1:38 - loss: 0.9437 - accuracy: 0.83 - ETA: 1:37 - loss: 0.9525 - accuracy: 0.83 - ETA: 1:36 - loss: 0.9479 - accuracy: 0.83 - ETA: 1:35 - loss: 0.9389 - accuracy: 0.83 - ETA: 1:34 - loss: 0.9339 - accuracy: 0.83 - ETA: 1:33 - loss: 0.9269 - accuracy: 0.83 - ETA: 1:32 - loss: 0.9240 - accuracy: 0.83 - ETA: 1:31 - loss: 0.9260 - accuracy: 0.83 - ETA: 1:31 - loss: 0.9299 - accuracy: 0.83 - ETA: 1:30 - loss: 0.9301 - accuracy: 0.83 - ETA: 1:29 - loss: 0.9323 - accuracy: 0.83 - ETA: 1:28 - loss: 0.9317 - accuracy: 0.83 - ETA: 1:27 - loss: 0.9300 - accuracy: 0.83 - ETA: 1:26 - loss: 0.9278 - accuracy: 0.83 - ETA: 1:25 - loss: 0.9301 - accuracy: 0.83 - ETA: 1:24 - loss: 0.9283 - accuracy: 0.83 - ETA: 1:23 - loss: 0.9254 - accuracy: 0.83 - ETA: 1:22 - loss: 0.9214 - accuracy: 0.83 - ETA: 1:21 - loss: 0.9200 - accuracy: 0.83 - ETA: 1:20 - loss: 0.9162 - accuracy: 0.83 - ETA: 1:19 - loss: 0.9198 - accuracy: 0.83 - ETA: 1:18 - loss: 0.9197 - accuracy: 0.83 - ETA: 1:17 - loss: 0.9182 - accuracy: 0.83 - ETA: 1:16 - loss: 0.9180 - accuracy: 0.83 - ETA: 1:15 - loss: 0.9124 - accuracy: 0.83 - ETA: 1:14 - loss: 0.9085 - accuracy: 0.83 - ETA: 1:14 - loss: 0.9041 - accuracy: 0.83 - ETA: 1:13 - loss: 0.9091 - accuracy: 0.83 - ETA: 1:12 - loss: 0.9084 - accuracy: 0.83 - ETA: 1:11 - loss: 0.9099 - accuracy: 0.83 - ETA: 1:10 - loss: 0.9094 - accuracy: 0.83 - ETA: 1:09 - loss: 0.9113 - accuracy: 0.83 - ETA: 1:08 - loss: 0.9181 - accuracy: 0.83 - ETA: 1:07 - loss: 0.9174 - accuracy: 0.83 - ETA: 1:06 - loss: 0.9272 - accuracy: 0.83 - ETA: 1:05 - loss: 0.9309 - accuracy: 0.83 - ETA: 1:04 - loss: 0.9293 - accuracy: 0.83 - ETA: 1:03 - loss: 0.9278 - accuracy: 0.83 - ETA: 1:02 - loss: 0.9295 - accuracy: 0.83 - ETA: 1:01 - loss: 0.9366 - accuracy: 0.83 - ETA: 1:00 - loss: 0.9409 - accuracy: 0.83 - ETA: 59s - loss: 0.9425 - accuracy: 0.8298 - ETA: 58s - loss: 0.9430 - accuracy: 0.830 - ETA: 57s - loss: 0.9404 - accuracy: 0.829 - ETA: 56s - loss: 0.9403 - accuracy: 0.829 - ETA: 55s - loss: 0.9434 - accuracy: 0.829 - ETA: 54s - loss: 0.9398 - accuracy: 0.829 - ETA: 53s - loss: 0.9355 - accuracy: 0.830 - ETA: 52s - loss: 0.9371 - accuracy: 0.829 - ETA: 51s - loss: 0.9430 - accuracy: 0.829 - ETA: 51s - loss: 0.9462 - accuracy: 0.829 - ETA: 50s - loss: 0.9480 - accuracy: 0.829 - ETA: 49s - loss: 0.9459 - accuracy: 0.829 - ETA: 48s - loss: 0.9461 - accuracy: 0.829 - ETA: 47s - loss: 0.9498 - accuracy: 0.828 - ETA: 46s - loss: 0.9491 - accuracy: 0.828 - ETA: 45s - loss: 0.9492 - accuracy: 0.828 - ETA: 44s - loss: 0.9515 - accuracy: 0.828 - ETA: 43s - loss: 0.9544 - accuracy: 0.827 - ETA: 42s - loss: 0.9539 - accuracy: 0.827 - ETA: 41s - loss: 0.9534 - accuracy: 0.827 - ETA: 40s - loss: 0.9511 - accuracy: 0.827 - ETA: 39s - loss: 0.9545 - accuracy: 0.827 - ETA: 38s - loss: 0.9575 - accuracy: 0.827 - ETA: 37s - loss: 0.9630 - accuracy: 0.827 - ETA: 36s - loss: 0.9642 - accuracy: 0.827 - ETA: 35s - loss: 0.9605 - accuracy: 0.827 - ETA: 34s - loss: 0.9590 - accuracy: 0.827 - ETA: 33s - loss: 0.9599 - accuracy: 0.827 - ETA: 32s - loss: 0.9626 - accuracy: 0.828 - ETA: 31s - loss: 0.9634 - accuracy: 0.827 - ETA: 30s - loss: 0.9620 - accuracy: 0.827 - ETA: 29s - loss: 0.9588 - accuracy: 0.828 - ETA: 29s - loss: 0.9656 - accuracy: 0.827 - ETA: 28s - loss: 0.9640 - accuracy: 0.828 - ETA: 27s - loss: 0.9647 - accuracy: 0.828 - ETA: 26s - loss: 0.9648 - accuracy: 0.828 - ETA: 25s - loss: 0.9644 - accuracy: 0.828 - ETA: 24s - loss: 0.9625 - accuracy: 0.828 - ETA: 23s - loss: 0.9645 - accuracy: 0.828 - ETA: 22s - loss: 0.9648 - accuracy: 0.828 - ETA: 21s - loss: 0.9640 - accuracy: 0.827 - ETA: 20s - loss: 0.9624 - accuracy: 0.827 - ETA: 19s - loss: 0.9613 - accuracy: 0.827 - ETA: 18s - loss: 0.9614 - accuracy: 0.828 - ETA: 17s - loss: 0.9653 - accuracy: 0.828 - ETA: 16s - loss: 0.9671 - accuracy: 0.827 - ETA: 15s - loss: 0.9658 - accuracy: 0.828 - ETA: 14s - loss: 0.9662 - accuracy: 0.827 - ETA: 13s - loss: 0.9710 - accuracy: 0.827 - ETA: 12s - loss: 0.9739 - accuracy: 0.827 - ETA: 11s - loss: 0.9716 - accuracy: 0.827 - ETA: 10s - loss: 0.9719 - accuracy: 0.827 - ETA: 9s - loss: 0.9745 - accuracy: 0.827 - ETA: 8s - loss: 0.9725 - accuracy: 0.82 - ETA: 7s - loss: 0.9708 - accuracy: 0.82 - ETA: 6s - loss: 0.9742 - accuracy: 0.82 - ETA: 5s - loss: 0.9703 - accuracy: 0.82 - ETA: 4s - loss: 0.9702 - accuracy: 0.82 - ETA: 3s - loss: 0.9735 - accuracy: 0.82 - ETA: 2s - loss: 0.9748 - accuracy: 0.82 - ETA: 1s - loss: 0.9726 - accuracy: 0.82 - ETA: 0s - loss: 0.9734 - accuracy: 0.82 - 158s 8ms/step - loss: 0.9724 - accuracy: 0.8273 - val_loss: 2.6637 - val_accuracy: 0.7540\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:24 - loss: 0.9885 - accuracy: 0.84 - ETA: 2:27 - loss: 0.9569 - accuracy: 0.80 - ETA: 2:21 - loss: 0.7986 - accuracy: 0.83 - ETA: 2:19 - loss: 0.8997 - accuracy: 0.82 - ETA: 2:17 - loss: 0.8855 - accuracy: 0.82 - ETA: 2:17 - loss: 0.8292 - accuracy: 0.82 - ETA: 2:16 - loss: 0.8109 - accuracy: 0.82 - ETA: 2:17 - loss: 0.7989 - accuracy: 0.82 - ETA: 2:16 - loss: 0.8248 - accuracy: 0.82 - ETA: 2:15 - loss: 0.8352 - accuracy: 0.82 - ETA: 2:14 - loss: 0.8400 - accuracy: 0.82 - ETA: 2:13 - loss: 0.8361 - accuracy: 0.83 - ETA: 2:12 - loss: 0.8409 - accuracy: 0.82 - ETA: 2:11 - loss: 0.8240 - accuracy: 0.82 - ETA: 2:09 - loss: 0.8191 - accuracy: 0.82 - ETA: 2:09 - loss: 0.8587 - accuracy: 0.83 - ETA: 2:08 - loss: 0.8764 - accuracy: 0.83 - ETA: 2:07 - loss: 0.8974 - accuracy: 0.82 - ETA: 2:06 - loss: 0.9211 - accuracy: 0.82 - ETA: 2:05 - loss: 0.9292 - accuracy: 0.82 - ETA: 2:04 - loss: 0.9128 - accuracy: 0.82 - ETA: 2:03 - loss: 0.8984 - accuracy: 0.82 - ETA: 2:02 - loss: 0.8927 - accuracy: 0.82 - ETA: 2:01 - loss: 0.8938 - accuracy: 0.82 - ETA: 2:01 - loss: 0.8846 - accuracy: 0.82 - ETA: 2:00 - loss: 0.8985 - accuracy: 0.82 - ETA: 1:59 - loss: 0.9323 - accuracy: 0.82 - ETA: 1:58 - loss: 0.9153 - accuracy: 0.82 - ETA: 1:57 - loss: 0.9073 - accuracy: 0.82 - ETA: 1:56 - loss: 0.8914 - accuracy: 0.82 - ETA: 1:55 - loss: 0.8841 - accuracy: 0.82 - ETA: 1:54 - loss: 0.9033 - accuracy: 0.82 - ETA: 1:53 - loss: 0.9267 - accuracy: 0.82 - ETA: 1:52 - loss: 0.9277 - accuracy: 0.82 - ETA: 1:51 - loss: 0.9122 - accuracy: 0.82 - ETA: 1:50 - loss: 0.9071 - accuracy: 0.82 - ETA: 1:49 - loss: 0.9255 - accuracy: 0.82 - ETA: 1:48 - loss: 0.9453 - accuracy: 0.82 - ETA: 1:47 - loss: 0.9343 - accuracy: 0.82 - ETA: 1:46 - loss: 0.9338 - accuracy: 0.82 - ETA: 1:45 - loss: 0.9236 - accuracy: 0.82 - ETA: 1:44 - loss: 0.9251 - accuracy: 0.82 - ETA: 1:44 - loss: 0.9213 - accuracy: 0.82 - ETA: 1:43 - loss: 0.9193 - accuracy: 0.82 - ETA: 1:42 - loss: 0.9103 - accuracy: 0.82 - ETA: 1:41 - loss: 0.9185 - accuracy: 0.82 - ETA: 1:40 - loss: 0.9144 - accuracy: 0.83 - ETA: 1:39 - loss: 0.9147 - accuracy: 0.82 - ETA: 1:38 - loss: 0.9096 - accuracy: 0.82 - ETA: 1:37 - loss: 0.9073 - accuracy: 0.82 - ETA: 1:36 - loss: 0.9048 - accuracy: 0.82 - ETA: 1:35 - loss: 0.9074 - accuracy: 0.82 - ETA: 1:34 - loss: 0.9160 - accuracy: 0.82 - ETA: 1:33 - loss: 0.9148 - accuracy: 0.82 - ETA: 1:32 - loss: 0.9241 - accuracy: 0.82 - ETA: 1:31 - loss: 0.9285 - accuracy: 0.82 - ETA: 1:30 - loss: 0.9287 - accuracy: 0.82 - ETA: 1:29 - loss: 0.9230 - accuracy: 0.82 - ETA: 1:28 - loss: 0.9226 - accuracy: 0.82 - ETA: 1:27 - loss: 0.9259 - accuracy: 0.82 - ETA: 1:26 - loss: 0.9264 - accuracy: 0.82 - ETA: 1:25 - loss: 0.9241 - accuracy: 0.82 - ETA: 1:24 - loss: 0.9322 - accuracy: 0.82 - ETA: 1:23 - loss: 0.9327 - accuracy: 0.82 - ETA: 1:22 - loss: 0.9273 - accuracy: 0.82 - ETA: 1:21 - loss: 0.9280 - accuracy: 0.82 - ETA: 1:21 - loss: 0.9285 - accuracy: 0.82 - ETA: 1:19 - loss: 0.9287 - accuracy: 0.82 - ETA: 1:19 - loss: 0.9301 - accuracy: 0.82 - ETA: 1:18 - loss: 0.9330 - accuracy: 0.82 - ETA: 1:17 - loss: 0.9374 - accuracy: 0.82 - ETA: 1:16 - loss: 0.9380 - accuracy: 0.82 - ETA: 1:15 - loss: 0.9361 - accuracy: 0.82 - ETA: 1:14 - loss: 0.9377 - accuracy: 0.82 - ETA: 1:13 - loss: 0.9370 - accuracy: 0.82 - ETA: 1:12 - loss: 0.9425 - accuracy: 0.82 - ETA: 1:11 - loss: 0.9395 - accuracy: 0.82 - ETA: 1:10 - loss: 0.9407 - accuracy: 0.82 - ETA: 1:09 - loss: 0.9387 - accuracy: 0.82 - ETA: 1:08 - loss: 0.9374 - accuracy: 0.82 - ETA: 1:07 - loss: 0.9378 - accuracy: 0.82 - ETA: 1:06 - loss: 0.9337 - accuracy: 0.82 - ETA: 1:05 - loss: 0.9395 - accuracy: 0.82 - ETA: 1:04 - loss: 0.9389 - accuracy: 0.82 - ETA: 1:03 - loss: 0.9399 - accuracy: 0.82 - ETA: 1:02 - loss: 0.9391 - accuracy: 0.82 - ETA: 1:01 - loss: 0.9362 - accuracy: 0.82 - ETA: 1:00 - loss: 0.9358 - accuracy: 0.82 - ETA: 59s - loss: 0.9384 - accuracy: 0.8270 - ETA: 58s - loss: 0.9377 - accuracy: 0.826 - ETA: 58s - loss: 0.9406 - accuracy: 0.826 - ETA: 57s - loss: 0.9428 - accuracy: 0.825 - ETA: 56s - loss: 0.9446 - accuracy: 0.826 - ETA: 55s - loss: 0.9484 - accuracy: 0.825 - ETA: 54s - loss: 0.9491 - accuracy: 0.825 - ETA: 53s - loss: 0.9476 - accuracy: 0.825 - ETA: 52s - loss: 0.9474 - accuracy: 0.826 - ETA: 51s - loss: 0.9483 - accuracy: 0.826 - ETA: 50s - loss: 0.9485 - accuracy: 0.825 - ETA: 49s - loss: 0.9500 - accuracy: 0.825 - ETA: 48s - loss: 0.9492 - accuracy: 0.825 - ETA: 47s - loss: 0.9519 - accuracy: 0.825 - ETA: 46s - loss: 0.9538 - accuracy: 0.824 - ETA: 45s - loss: 0.9555 - accuracy: 0.824 - ETA: 44s - loss: 0.9531 - accuracy: 0.824 - ETA: 43s - loss: 0.9508 - accuracy: 0.825 - ETA: 42s - loss: 0.9512 - accuracy: 0.825 - ETA: 41s - loss: 0.9484 - accuracy: 0.826 - ETA: 40s - loss: 0.9465 - accuracy: 0.826 - ETA: 39s - loss: 0.9479 - accuracy: 0.826 - ETA: 38s - loss: 0.9479 - accuracy: 0.826 - ETA: 37s - loss: 0.9454 - accuracy: 0.826 - ETA: 36s - loss: 0.9446 - accuracy: 0.826 - ETA: 35s - loss: 0.9484 - accuracy: 0.825 - ETA: 34s - loss: 0.9435 - accuracy: 0.826 - ETA: 33s - loss: 0.9404 - accuracy: 0.826 - ETA: 32s - loss: 0.9395 - accuracy: 0.827 - ETA: 31s - loss: 0.9419 - accuracy: 0.826 - ETA: 30s - loss: 0.9491 - accuracy: 0.826 - ETA: 29s - loss: 0.9465 - accuracy: 0.826 - ETA: 28s - loss: 0.9455 - accuracy: 0.826 - ETA: 27s - loss: 0.9463 - accuracy: 0.826 - ETA: 26s - loss: 0.9539 - accuracy: 0.826 - ETA: 26s - loss: 0.9552 - accuracy: 0.825 - ETA: 25s - loss: 0.9554 - accuracy: 0.825 - ETA: 24s - loss: 0.9554 - accuracy: 0.825 - ETA: 23s - loss: 0.9572 - accuracy: 0.825 - ETA: 22s - loss: 0.9619 - accuracy: 0.825 - ETA: 21s - loss: 0.9660 - accuracy: 0.825 - ETA: 20s - loss: 0.9682 - accuracy: 0.825 - ETA: 19s - loss: 0.9665 - accuracy: 0.825 - ETA: 18s - loss: 0.9676 - accuracy: 0.825 - ETA: 17s - loss: 0.9653 - accuracy: 0.826 - ETA: 16s - loss: 0.9666 - accuracy: 0.826 - ETA: 15s - loss: 0.9638 - accuracy: 0.826 - ETA: 14s - loss: 0.9634 - accuracy: 0.826 - ETA: 13s - loss: 0.9661 - accuracy: 0.825 - ETA: 12s - loss: 0.9657 - accuracy: 0.825 - ETA: 11s - loss: 0.9662 - accuracy: 0.825 - ETA: 10s - loss: 0.9660 - accuracy: 0.825 - ETA: 9s - loss: 0.9682 - accuracy: 0.825 - ETA: 8s - loss: 0.9675 - accuracy: 0.82 - ETA: 7s - loss: 0.9699 - accuracy: 0.82 - ETA: 6s - loss: 0.9680 - accuracy: 0.82 - ETA: 5s - loss: 0.9679 - accuracy: 0.82 - ETA: 4s - loss: 0.9671 - accuracy: 0.82 - ETA: 3s - loss: 0.9651 - accuracy: 0.82 - ETA: 2s - loss: 0.9658 - accuracy: 0.82 - ETA: 1s - loss: 0.9639 - accuracy: 0.82 - ETA: 0s - loss: 0.9622 - accuracy: 0.82 - 157s 8ms/step - loss: 0.9625 - accuracy: 0.8250 - val_loss: 2.8159 - val_accuracy: 0.7472\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:35 - loss: 0.9010 - accuracy: 0.82 - ETA: 2:25 - loss: 0.7646 - accuracy: 0.84 - ETA: 2:24 - loss: 0.7480 - accuracy: 0.84 - ETA: 2:23 - loss: 0.8486 - accuracy: 0.83 - ETA: 2:20 - loss: 0.7623 - accuracy: 0.85 - ETA: 2:18 - loss: 0.9286 - accuracy: 0.84 - ETA: 2:17 - loss: 0.9403 - accuracy: 0.84 - ETA: 2:16 - loss: 0.9221 - accuracy: 0.84 - ETA: 2:15 - loss: 0.9238 - accuracy: 0.84 - ETA: 2:15 - loss: 0.9227 - accuracy: 0.84 - ETA: 2:15 - loss: 0.8988 - accuracy: 0.84 - ETA: 2:14 - loss: 0.8792 - accuracy: 0.84 - ETA: 2:12 - loss: 0.8833 - accuracy: 0.84 - ETA: 2:11 - loss: 0.8634 - accuracy: 0.84 - ETA: 2:10 - loss: 0.8816 - accuracy: 0.84 - ETA: 2:09 - loss: 0.8627 - accuracy: 0.84 - ETA: 2:08 - loss: 0.8544 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8737 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8667 - accuracy: 0.84 - ETA: 2:06 - loss: 0.8692 - accuracy: 0.83 - ETA: 2:05 - loss: 0.8544 - accuracy: 0.84 - ETA: 2:03 - loss: 0.8620 - accuracy: 0.83 - ETA: 2:02 - loss: 0.8660 - accuracy: 0.84 - ETA: 2:01 - loss: 0.8639 - accuracy: 0.84 - ETA: 2:00 - loss: 0.8705 - accuracy: 0.84 - ETA: 1:59 - loss: 0.8916 - accuracy: 0.83 - ETA: 1:59 - loss: 0.9125 - accuracy: 0.83 - ETA: 1:58 - loss: 0.9048 - accuracy: 0.83 - ETA: 1:57 - loss: 0.8906 - accuracy: 0.83 - ETA: 1:56 - loss: 0.8830 - accuracy: 0.83 - ETA: 1:55 - loss: 0.8876 - accuracy: 0.83 - ETA: 1:54 - loss: 0.8894 - accuracy: 0.83 - ETA: 1:53 - loss: 0.8845 - accuracy: 0.83 - ETA: 1:52 - loss: 0.8805 - accuracy: 0.83 - ETA: 1:51 - loss: 0.8944 - accuracy: 0.83 - ETA: 1:50 - loss: 0.8925 - accuracy: 0.83 - ETA: 1:49 - loss: 0.8952 - accuracy: 0.83 - ETA: 1:48 - loss: 0.8900 - accuracy: 0.83 - ETA: 1:47 - loss: 0.8932 - accuracy: 0.83 - ETA: 1:46 - loss: 0.8867 - accuracy: 0.83 - ETA: 1:45 - loss: 0.8830 - accuracy: 0.83 - ETA: 1:44 - loss: 0.8831 - accuracy: 0.83 - ETA: 1:43 - loss: 0.8889 - accuracy: 0.83 - ETA: 1:42 - loss: 0.8818 - accuracy: 0.83 - ETA: 1:41 - loss: 0.8763 - accuracy: 0.83 - ETA: 1:40 - loss: 0.8738 - accuracy: 0.83 - ETA: 1:40 - loss: 0.8708 - accuracy: 0.83 - ETA: 1:39 - loss: 0.8709 - accuracy: 0.83 - ETA: 1:38 - loss: 0.8767 - accuracy: 0.83 - ETA: 1:37 - loss: 0.8802 - accuracy: 0.83 - ETA: 1:36 - loss: 0.8757 - accuracy: 0.83 - ETA: 1:35 - loss: 0.8690 - accuracy: 0.83 - ETA: 1:34 - loss: 0.8707 - accuracy: 0.83 - ETA: 1:33 - loss: 0.8683 - accuracy: 0.83 - ETA: 1:32 - loss: 0.8613 - accuracy: 0.83 - ETA: 1:31 - loss: 0.8546 - accuracy: 0.83 - ETA: 1:30 - loss: 0.8535 - accuracy: 0.83 - ETA: 1:29 - loss: 0.8502 - accuracy: 0.83 - ETA: 1:28 - loss: 0.8448 - accuracy: 0.83 - ETA: 1:27 - loss: 0.8464 - accuracy: 0.83 - ETA: 1:27 - loss: 0.8379 - accuracy: 0.83 - ETA: 1:25 - loss: 0.8376 - accuracy: 0.83 - ETA: 1:24 - loss: 0.8417 - accuracy: 0.83 - ETA: 1:23 - loss: 0.8436 - accuracy: 0.83 - ETA: 1:22 - loss: 0.8391 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8470 - accuracy: 0.83 - ETA: 1:20 - loss: 0.8450 - accuracy: 0.83 - ETA: 1:19 - loss: 0.8438 - accuracy: 0.83 - ETA: 1:18 - loss: 0.8497 - accuracy: 0.83 - ETA: 1:17 - loss: 0.8467 - accuracy: 0.83 - ETA: 1:17 - loss: 0.8469 - accuracy: 0.83 - ETA: 1:15 - loss: 0.8461 - accuracy: 0.83 - ETA: 1:15 - loss: 0.8471 - accuracy: 0.83 - ETA: 1:14 - loss: 0.8482 - accuracy: 0.83 - ETA: 1:13 - loss: 0.8550 - accuracy: 0.83 - ETA: 1:12 - loss: 0.8545 - accuracy: 0.83 - ETA: 1:11 - loss: 0.8550 - accuracy: 0.83 - ETA: 1:10 - loss: 0.8569 - accuracy: 0.83 - ETA: 1:09 - loss: 0.8533 - accuracy: 0.83 - ETA: 1:08 - loss: 0.8546 - accuracy: 0.83 - ETA: 1:07 - loss: 0.8625 - accuracy: 0.83 - ETA: 1:06 - loss: 0.8640 - accuracy: 0.83 - ETA: 1:05 - loss: 0.8635 - accuracy: 0.83 - ETA: 1:04 - loss: 0.8689 - accuracy: 0.83 - ETA: 1:03 - loss: 0.8712 - accuracy: 0.83 - ETA: 1:02 - loss: 0.8675 - accuracy: 0.83 - ETA: 1:01 - loss: 0.8677 - accuracy: 0.83 - ETA: 1:00 - loss: 0.8661 - accuracy: 0.83 - ETA: 59s - loss: 0.8642 - accuracy: 0.8358 - ETA: 58s - loss: 0.8605 - accuracy: 0.836 - ETA: 57s - loss: 0.8644 - accuracy: 0.835 - ETA: 56s - loss: 0.8609 - accuracy: 0.836 - ETA: 55s - loss: 0.8619 - accuracy: 0.835 - ETA: 54s - loss: 0.8679 - accuracy: 0.835 - ETA: 53s - loss: 0.8679 - accuracy: 0.835 - ETA: 52s - loss: 0.8652 - accuracy: 0.835 - ETA: 51s - loss: 0.8688 - accuracy: 0.835 - ETA: 50s - loss: 0.8669 - accuracy: 0.835 - ETA: 49s - loss: 0.8700 - accuracy: 0.834 - ETA: 49s - loss: 0.8726 - accuracy: 0.834 - ETA: 48s - loss: 0.8804 - accuracy: 0.834 - ETA: 47s - loss: 0.8810 - accuracy: 0.834 - ETA: 46s - loss: 0.8798 - accuracy: 0.834 - ETA: 45s - loss: 0.8778 - accuracy: 0.834 - ETA: 44s - loss: 0.8790 - accuracy: 0.834 - ETA: 43s - loss: 0.8823 - accuracy: 0.834 - ETA: 42s - loss: 0.8828 - accuracy: 0.833 - ETA: 41s - loss: 0.8827 - accuracy: 0.833 - ETA: 40s - loss: 0.8796 - accuracy: 0.834 - ETA: 39s - loss: 0.8820 - accuracy: 0.833 - ETA: 38s - loss: 0.8847 - accuracy: 0.833 - ETA: 37s - loss: 0.8857 - accuracy: 0.833 - ETA: 36s - loss: 0.8888 - accuracy: 0.833 - ETA: 35s - loss: 0.8883 - accuracy: 0.832 - ETA: 34s - loss: 0.8924 - accuracy: 0.832 - ETA: 33s - loss: 0.8907 - accuracy: 0.832 - ETA: 32s - loss: 0.8905 - accuracy: 0.832 - ETA: 31s - loss: 0.8915 - accuracy: 0.832 - ETA: 30s - loss: 0.8919 - accuracy: 0.832 - ETA: 29s - loss: 0.8935 - accuracy: 0.831 - ETA: 28s - loss: 0.8956 - accuracy: 0.831 - ETA: 27s - loss: 0.8982 - accuracy: 0.831 - ETA: 26s - loss: 0.8953 - accuracy: 0.831 - ETA: 25s - loss: 0.8957 - accuracy: 0.831 - ETA: 24s - loss: 0.8946 - accuracy: 0.831 - ETA: 23s - loss: 0.8923 - accuracy: 0.831 - ETA: 23s - loss: 0.8936 - accuracy: 0.831 - ETA: 22s - loss: 0.8993 - accuracy: 0.831 - ETA: 21s - loss: 0.9002 - accuracy: 0.830 - ETA: 20s - loss: 0.9019 - accuracy: 0.830 - ETA: 19s - loss: 0.9012 - accuracy: 0.830 - ETA: 18s - loss: 0.8991 - accuracy: 0.830 - ETA: 17s - loss: 0.8972 - accuracy: 0.830 - ETA: 16s - loss: 0.8950 - accuracy: 0.830 - ETA: 15s - loss: 0.8984 - accuracy: 0.830 - ETA: 14s - loss: 0.8978 - accuracy: 0.830 - ETA: 13s - loss: 0.8968 - accuracy: 0.830 - ETA: 12s - loss: 0.8988 - accuracy: 0.830 - ETA: 11s - loss: 0.9005 - accuracy: 0.830 - ETA: 10s - loss: 0.8965 - accuracy: 0.830 - ETA: 9s - loss: 0.8986 - accuracy: 0.830 - ETA: 8s - loss: 0.8978 - accuracy: 0.83 - ETA: 7s - loss: 0.8956 - accuracy: 0.83 - ETA: 6s - loss: 0.8950 - accuracy: 0.83 - ETA: 5s - loss: 0.8974 - accuracy: 0.83 - ETA: 4s - loss: 0.8973 - accuracy: 0.83 - ETA: 3s - loss: 0.8996 - accuracy: 0.83 - ETA: 2s - loss: 0.9025 - accuracy: 0.83 - ETA: 1s - loss: 0.9016 - accuracy: 0.83 - ETA: 0s - loss: 0.9019 - accuracy: 0.83 - 158s 8ms/step - loss: 0.9027 - accuracy: 0.8301 - val_loss: 2.8685 - val_accuracy: 0.7511\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:26 - loss: 0.6275 - accuracy: 0.88 - ETA: 2:22 - loss: 0.6677 - accuracy: 0.87 - ETA: 2:20 - loss: 0.8629 - accuracy: 0.84 - ETA: 2:19 - loss: 0.8867 - accuracy: 0.84 - ETA: 2:19 - loss: 0.9175 - accuracy: 0.84 - ETA: 2:17 - loss: 0.8651 - accuracy: 0.85 - ETA: 2:16 - loss: 0.8464 - accuracy: 0.84 - ETA: 2:16 - loss: 0.8696 - accuracy: 0.84 - ETA: 2:15 - loss: 0.8789 - accuracy: 0.84 - ETA: 2:13 - loss: 0.8483 - accuracy: 0.85 - ETA: 2:13 - loss: 0.8012 - accuracy: 0.85 - ETA: 2:12 - loss: 0.7967 - accuracy: 0.85 - ETA: 2:12 - loss: 0.7971 - accuracy: 0.85 - ETA: 2:12 - loss: 0.7780 - accuracy: 0.85 - ETA: 2:11 - loss: 0.7769 - accuracy: 0.85 - ETA: 2:10 - loss: 0.8129 - accuracy: 0.85 - ETA: 2:09 - loss: 0.8231 - accuracy: 0.85 - ETA: 2:08 - loss: 0.8303 - accuracy: 0.84 - ETA: 2:06 - loss: 0.8251 - accuracy: 0.84 - ETA: 2:05 - loss: 0.8131 - accuracy: 0.85 - ETA: 2:04 - loss: 0.8252 - accuracy: 0.84 - ETA: 2:04 - loss: 0.8246 - accuracy: 0.84 - ETA: 2:02 - loss: 0.8397 - accuracy: 0.84 - ETA: 2:01 - loss: 0.8319 - accuracy: 0.84 - ETA: 2:00 - loss: 0.8511 - accuracy: 0.84 - ETA: 1:59 - loss: 0.8539 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8428 - accuracy: 0.84 - ETA: 1:57 - loss: 0.8377 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8327 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8225 - accuracy: 0.84 - ETA: 1:55 - loss: 0.8200 - accuracy: 0.84 - ETA: 1:54 - loss: 0.8063 - accuracy: 0.84 - ETA: 1:53 - loss: 0.8158 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8211 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8236 - accuracy: 0.84 - ETA: 1:50 - loss: 0.8235 - accuracy: 0.84 - ETA: 1:49 - loss: 0.8281 - accuracy: 0.84 - ETA: 1:48 - loss: 0.8283 - accuracy: 0.84 - ETA: 1:47 - loss: 0.8336 - accuracy: 0.84 - ETA: 1:46 - loss: 0.8442 - accuracy: 0.84 - ETA: 1:45 - loss: 0.8495 - accuracy: 0.84 - ETA: 1:44 - loss: 0.8464 - accuracy: 0.84 - ETA: 1:43 - loss: 0.8471 - accuracy: 0.84 - ETA: 1:42 - loss: 0.8391 - accuracy: 0.84 - ETA: 1:42 - loss: 0.8442 - accuracy: 0.84 - ETA: 1:41 - loss: 0.8453 - accuracy: 0.84 - ETA: 1:40 - loss: 0.8480 - accuracy: 0.84 - ETA: 1:39 - loss: 0.8441 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8463 - accuracy: 0.84 - ETA: 1:37 - loss: 0.8397 - accuracy: 0.84 - ETA: 1:36 - loss: 0.8408 - accuracy: 0.84 - ETA: 1:35 - loss: 0.8346 - accuracy: 0.84 - ETA: 1:34 - loss: 0.8313 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8423 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8496 - accuracy: 0.84 - ETA: 1:31 - loss: 0.8446 - accuracy: 0.84 - ETA: 1:30 - loss: 0.8433 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8465 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8428 - accuracy: 0.84 - ETA: 1:28 - loss: 0.8536 - accuracy: 0.84 - ETA: 1:27 - loss: 0.8572 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8631 - accuracy: 0.84 - ETA: 1:25 - loss: 0.8626 - accuracy: 0.84 - ETA: 1:24 - loss: 0.8615 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8584 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8586 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8585 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8529 - accuracy: 0.84 - ETA: 1:19 - loss: 0.8554 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8565 - accuracy: 0.84 - ETA: 1:17 - loss: 0.8544 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8642 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8644 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8642 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8632 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8736 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8744 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8791 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8805 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8849 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8844 - accuracy: 0.84 - ETA: 1:06 - loss: 0.8805 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8822 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8805 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8843 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8830 - accuracy: 0.84 - ETA: 1:01 - loss: 0.8865 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8847 - accuracy: 0.84 - ETA: 59s - loss: 0.8895 - accuracy: 0.8400 - ETA: 58s - loss: 0.8915 - accuracy: 0.839 - ETA: 57s - loss: 0.8907 - accuracy: 0.839 - ETA: 56s - loss: 0.8903 - accuracy: 0.840 - ETA: 55s - loss: 0.8905 - accuracy: 0.839 - ETA: 55s - loss: 0.8932 - accuracy: 0.838 - ETA: 54s - loss: 0.8927 - accuracy: 0.838 - ETA: 53s - loss: 0.8930 - accuracy: 0.838 - ETA: 52s - loss: 0.8955 - accuracy: 0.838 - ETA: 51s - loss: 0.8928 - accuracy: 0.838 - ETA: 50s - loss: 0.8930 - accuracy: 0.838 - ETA: 49s - loss: 0.8914 - accuracy: 0.838 - ETA: 48s - loss: 0.8912 - accuracy: 0.838 - ETA: 47s - loss: 0.8879 - accuracy: 0.839 - ETA: 46s - loss: 0.8868 - accuracy: 0.839 - ETA: 45s - loss: 0.8931 - accuracy: 0.838 - ETA: 44s - loss: 0.8925 - accuracy: 0.838 - ETA: 43s - loss: 0.8923 - accuracy: 0.838 - ETA: 42s - loss: 0.8937 - accuracy: 0.838 - ETA: 41s - loss: 0.8919 - accuracy: 0.838 - ETA: 40s - loss: 0.8917 - accuracy: 0.838 - ETA: 39s - loss: 0.8901 - accuracy: 0.839 - ETA: 38s - loss: 0.8899 - accuracy: 0.838 - ETA: 37s - loss: 0.8907 - accuracy: 0.838 - ETA: 36s - loss: 0.8898 - accuracy: 0.838 - ETA: 35s - loss: 0.8928 - accuracy: 0.838 - ETA: 34s - loss: 0.8935 - accuracy: 0.838 - ETA: 33s - loss: 0.8967 - accuracy: 0.837 - ETA: 32s - loss: 0.8984 - accuracy: 0.837 - ETA: 31s - loss: 0.8960 - accuracy: 0.837 - ETA: 30s - loss: 0.9011 - accuracy: 0.837 - ETA: 29s - loss: 0.8996 - accuracy: 0.837 - ETA: 28s - loss: 0.8989 - accuracy: 0.837 - ETA: 27s - loss: 0.9018 - accuracy: 0.837 - ETA: 26s - loss: 0.9040 - accuracy: 0.837 - ETA: 26s - loss: 0.9039 - accuracy: 0.836 - ETA: 25s - loss: 0.9015 - accuracy: 0.837 - ETA: 24s - loss: 0.9028 - accuracy: 0.837 - ETA: 23s - loss: 0.8995 - accuracy: 0.837 - ETA: 22s - loss: 0.9024 - accuracy: 0.837 - ETA: 21s - loss: 0.9024 - accuracy: 0.836 - ETA: 20s - loss: 0.9033 - accuracy: 0.836 - ETA: 19s - loss: 0.9009 - accuracy: 0.836 - ETA: 18s - loss: 0.8990 - accuracy: 0.836 - ETA: 17s - loss: 0.8970 - accuracy: 0.836 - ETA: 16s - loss: 0.8982 - accuracy: 0.836 - ETA: 15s - loss: 0.8969 - accuracy: 0.836 - ETA: 14s - loss: 0.8965 - accuracy: 0.836 - ETA: 13s - loss: 0.8957 - accuracy: 0.836 - ETA: 12s - loss: 0.8925 - accuracy: 0.836 - ETA: 11s - loss: 0.8909 - accuracy: 0.836 - ETA: 10s - loss: 0.8899 - accuracy: 0.837 - ETA: 9s - loss: 0.8926 - accuracy: 0.836 - ETA: 8s - loss: 0.8918 - accuracy: 0.83 - ETA: 7s - loss: 0.8906 - accuracy: 0.83 - ETA: 6s - loss: 0.8915 - accuracy: 0.83 - ETA: 5s - loss: 0.8906 - accuracy: 0.83 - ETA: 4s - loss: 0.8904 - accuracy: 0.83 - ETA: 3s - loss: 0.8902 - accuracy: 0.83 - ETA: 2s - loss: 0.8908 - accuracy: 0.83 - ETA: 1s - loss: 0.8911 - accuracy: 0.83 - ETA: 0s - loss: 0.8925 - accuracy: 0.83 - 158s 8ms/step - loss: 0.8902 - accuracy: 0.8364 - val_loss: 2.9137 - val_accuracy: 0.7594\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:30 - loss: 0.7657 - accuracy: 0.80 - ETA: 2:30 - loss: 0.7507 - accuracy: 0.82 - ETA: 2:25 - loss: 0.8481 - accuracy: 0.80 - ETA: 2:22 - loss: 0.8425 - accuracy: 0.80 - ETA: 2:21 - loss: 0.8346 - accuracy: 0.81 - ETA: 2:19 - loss: 0.8379 - accuracy: 0.81 - ETA: 2:19 - loss: 0.8758 - accuracy: 0.81 - ETA: 2:17 - loss: 0.8384 - accuracy: 0.82 - ETA: 2:17 - loss: 0.8309 - accuracy: 0.82 - ETA: 2:15 - loss: 0.8004 - accuracy: 0.82 - ETA: 2:13 - loss: 0.8760 - accuracy: 0.83 - ETA: 2:12 - loss: 0.8840 - accuracy: 0.83 - ETA: 2:10 - loss: 0.9126 - accuracy: 0.82 - ETA: 2:09 - loss: 0.9247 - accuracy: 0.83 - ETA: 2:08 - loss: 0.9371 - accuracy: 0.82 - ETA: 2:08 - loss: 0.9378 - accuracy: 0.82 - ETA: 2:07 - loss: 0.9273 - accuracy: 0.83 - ETA: 2:06 - loss: 0.9072 - accuracy: 0.83 - ETA: 2:05 - loss: 0.8993 - accuracy: 0.83 - ETA: 2:04 - loss: 0.9018 - accuracy: 0.82 - ETA: 2:04 - loss: 0.9144 - accuracy: 0.83 - ETA: 2:03 - loss: 0.9233 - accuracy: 0.83 - ETA: 2:01 - loss: 0.9096 - accuracy: 0.83 - ETA: 2:00 - loss: 0.9179 - accuracy: 0.83 - ETA: 1:59 - loss: 0.9547 - accuracy: 0.83 - ETA: 1:58 - loss: 0.9471 - accuracy: 0.83 - ETA: 1:57 - loss: 0.9302 - accuracy: 0.83 - ETA: 1:56 - loss: 0.9459 - accuracy: 0.83 - ETA: 1:55 - loss: 0.9322 - accuracy: 0.83 - ETA: 1:54 - loss: 0.9256 - accuracy: 0.83 - ETA: 1:53 - loss: 0.9375 - accuracy: 0.83 - ETA: 1:53 - loss: 0.9316 - accuracy: 0.83 - ETA: 1:52 - loss: 0.9300 - accuracy: 0.83 - ETA: 1:51 - loss: 0.9227 - accuracy: 0.83 - ETA: 1:51 - loss: 0.9143 - accuracy: 0.83 - ETA: 1:50 - loss: 0.9062 - accuracy: 0.83 - ETA: 1:49 - loss: 0.9135 - accuracy: 0.83 - ETA: 1:48 - loss: 0.9165 - accuracy: 0.83 - ETA: 1:47 - loss: 0.9122 - accuracy: 0.83 - ETA: 1:46 - loss: 0.9043 - accuracy: 0.83 - ETA: 1:45 - loss: 0.9006 - accuracy: 0.83 - ETA: 1:44 - loss: 0.8980 - accuracy: 0.83 - ETA: 1:43 - loss: 0.9028 - accuracy: 0.83 - ETA: 1:42 - loss: 0.9044 - accuracy: 0.83 - ETA: 1:41 - loss: 0.9084 - accuracy: 0.83 - ETA: 1:40 - loss: 0.9040 - accuracy: 0.83 - ETA: 1:39 - loss: 0.8960 - accuracy: 0.83 - ETA: 1:38 - loss: 0.9022 - accuracy: 0.83 - ETA: 1:37 - loss: 0.9028 - accuracy: 0.83 - ETA: 1:36 - loss: 0.8987 - accuracy: 0.83 - ETA: 1:35 - loss: 0.9044 - accuracy: 0.83 - ETA: 1:34 - loss: 0.9198 - accuracy: 0.83 - ETA: 1:33 - loss: 0.9167 - accuracy: 0.83 - ETA: 1:32 - loss: 0.9201 - accuracy: 0.83 - ETA: 1:31 - loss: 0.9246 - accuracy: 0.83 - ETA: 1:30 - loss: 0.9251 - accuracy: 0.83 - ETA: 1:30 - loss: 0.9199 - accuracy: 0.83 - ETA: 1:28 - loss: 0.9222 - accuracy: 0.83 - ETA: 1:28 - loss: 0.9177 - accuracy: 0.83 - ETA: 1:27 - loss: 0.9216 - accuracy: 0.83 - ETA: 1:26 - loss: 0.9208 - accuracy: 0.83 - ETA: 1:25 - loss: 0.9282 - accuracy: 0.83 - ETA: 1:24 - loss: 0.9234 - accuracy: 0.83 - ETA: 1:23 - loss: 0.9197 - accuracy: 0.83 - ETA: 1:22 - loss: 0.9161 - accuracy: 0.83 - ETA: 1:21 - loss: 0.9207 - accuracy: 0.83 - ETA: 1:20 - loss: 0.9255 - accuracy: 0.83 - ETA: 1:19 - loss: 0.9267 - accuracy: 0.83 - ETA: 1:18 - loss: 0.9243 - accuracy: 0.83 - ETA: 1:17 - loss: 0.9287 - accuracy: 0.83 - ETA: 1:16 - loss: 0.9327 - accuracy: 0.83 - ETA: 1:15 - loss: 0.9340 - accuracy: 0.83 - ETA: 1:14 - loss: 0.9348 - accuracy: 0.83 - ETA: 1:13 - loss: 0.9337 - accuracy: 0.83 - ETA: 1:12 - loss: 0.9357 - accuracy: 0.83 - ETA: 1:11 - loss: 0.9345 - accuracy: 0.83 - ETA: 1:10 - loss: 0.9362 - accuracy: 0.83 - ETA: 1:09 - loss: 0.9372 - accuracy: 0.83 - ETA: 1:08 - loss: 0.9358 - accuracy: 0.83 - ETA: 1:07 - loss: 0.9376 - accuracy: 0.83 - ETA: 1:06 - loss: 0.9353 - accuracy: 0.83 - ETA: 1:05 - loss: 0.9307 - accuracy: 0.83 - ETA: 1:04 - loss: 0.9354 - accuracy: 0.83 - ETA: 1:04 - loss: 0.9339 - accuracy: 0.83 - ETA: 1:03 - loss: 0.9299 - accuracy: 0.83 - ETA: 1:02 - loss: 0.9321 - accuracy: 0.83 - ETA: 1:01 - loss: 0.9328 - accuracy: 0.83 - ETA: 1:00 - loss: 0.9393 - accuracy: 0.83 - ETA: 59s - loss: 0.9444 - accuracy: 0.8350 - ETA: 58s - loss: 0.9429 - accuracy: 0.835 - ETA: 57s - loss: 0.9411 - accuracy: 0.835 - ETA: 56s - loss: 0.9416 - accuracy: 0.834 - ETA: 55s - loss: 0.9407 - accuracy: 0.835 - ETA: 54s - loss: 0.9434 - accuracy: 0.834 - ETA: 53s - loss: 0.9416 - accuracy: 0.835 - ETA: 52s - loss: 0.9431 - accuracy: 0.835 - ETA: 51s - loss: 0.9411 - accuracy: 0.835 - ETA: 50s - loss: 0.9431 - accuracy: 0.835 - ETA: 49s - loss: 0.9475 - accuracy: 0.834 - ETA: 48s - loss: 0.9492 - accuracy: 0.832 - ETA: 47s - loss: 0.9490 - accuracy: 0.833 - ETA: 46s - loss: 0.9455 - accuracy: 0.833 - ETA: 46s - loss: 0.9451 - accuracy: 0.833 - ETA: 45s - loss: 0.9412 - accuracy: 0.834 - ETA: 44s - loss: 0.9389 - accuracy: 0.834 - ETA: 43s - loss: 0.9390 - accuracy: 0.834 - ETA: 42s - loss: 0.9388 - accuracy: 0.834 - ETA: 41s - loss: 0.9377 - accuracy: 0.834 - ETA: 40s - loss: 0.9380 - accuracy: 0.834 - ETA: 39s - loss: 0.9384 - accuracy: 0.834 - ETA: 38s - loss: 0.9382 - accuracy: 0.834 - ETA: 37s - loss: 0.9378 - accuracy: 0.834 - ETA: 36s - loss: 0.9399 - accuracy: 0.834 - ETA: 35s - loss: 0.9364 - accuracy: 0.834 - ETA: 34s - loss: 0.9331 - accuracy: 0.835 - ETA: 33s - loss: 0.9363 - accuracy: 0.835 - ETA: 32s - loss: 0.9378 - accuracy: 0.835 - ETA: 31s - loss: 0.9380 - accuracy: 0.835 - ETA: 30s - loss: 0.9378 - accuracy: 0.835 - ETA: 29s - loss: 0.9340 - accuracy: 0.835 - ETA: 28s - loss: 0.9363 - accuracy: 0.835 - ETA: 27s - loss: 0.9361 - accuracy: 0.835 - ETA: 26s - loss: 0.9365 - accuracy: 0.834 - ETA: 25s - loss: 0.9358 - accuracy: 0.834 - ETA: 24s - loss: 0.9339 - accuracy: 0.834 - ETA: 23s - loss: 0.9327 - accuracy: 0.834 - ETA: 22s - loss: 0.9309 - accuracy: 0.835 - ETA: 21s - loss: 0.9317 - accuracy: 0.835 - ETA: 20s - loss: 0.9309 - accuracy: 0.835 - ETA: 20s - loss: 0.9332 - accuracy: 0.835 - ETA: 19s - loss: 0.9335 - accuracy: 0.835 - ETA: 18s - loss: 0.9349 - accuracy: 0.835 - ETA: 17s - loss: 0.9445 - accuracy: 0.834 - ETA: 16s - loss: 0.9438 - accuracy: 0.834 - ETA: 15s - loss: 0.9440 - accuracy: 0.834 - ETA: 14s - loss: 0.9419 - accuracy: 0.834 - ETA: 13s - loss: 0.9384 - accuracy: 0.835 - ETA: 12s - loss: 0.9463 - accuracy: 0.834 - ETA: 11s - loss: 0.9445 - accuracy: 0.834 - ETA: 10s - loss: 0.9461 - accuracy: 0.834 - ETA: 9s - loss: 0.9474 - accuracy: 0.834 - ETA: 8s - loss: 0.9468 - accuracy: 0.83 - ETA: 7s - loss: 0.9501 - accuracy: 0.83 - ETA: 6s - loss: 0.9478 - accuracy: 0.83 - ETA: 5s - loss: 0.9473 - accuracy: 0.83 - ETA: 4s - loss: 0.9464 - accuracy: 0.83 - ETA: 3s - loss: 0.9447 - accuracy: 0.83 - ETA: 2s - loss: 0.9421 - accuracy: 0.83 - ETA: 1s - loss: 0.9452 - accuracy: 0.83 - ETA: 0s - loss: 0.9447 - accuracy: 0.83 - 156s 8ms/step - loss: 0.9438 - accuracy: 0.8346 - val_loss: 2.7466 - val_accuracy: 0.7614\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 0.9236 - accuracy: 0.85 - ETA: 2:23 - loss: 0.8331 - accuracy: 0.85 - ETA: 2:24 - loss: 0.8332 - accuracy: 0.85 - ETA: 2:24 - loss: 0.9012 - accuracy: 0.85 - ETA: 2:23 - loss: 0.8985 - accuracy: 0.85 - ETA: 2:22 - loss: 0.9313 - accuracy: 0.84 - ETA: 2:21 - loss: 0.9202 - accuracy: 0.84 - ETA: 2:19 - loss: 0.9193 - accuracy: 0.84 - ETA: 2:19 - loss: 0.9061 - accuracy: 0.84 - ETA: 2:17 - loss: 0.9184 - accuracy: 0.84 - ETA: 2:16 - loss: 0.9201 - accuracy: 0.83 - ETA: 2:16 - loss: 0.8957 - accuracy: 0.84 - ETA: 2:14 - loss: 0.9077 - accuracy: 0.83 - ETA: 2:12 - loss: 0.9014 - accuracy: 0.83 - ETA: 2:11 - loss: 0.9028 - accuracy: 0.83 - ETA: 2:10 - loss: 0.9342 - accuracy: 0.83 - ETA: 2:08 - loss: 0.9464 - accuracy: 0.83 - ETA: 2:08 - loss: 0.9512 - accuracy: 0.83 - ETA: 2:07 - loss: 0.9456 - accuracy: 0.83 - ETA: 2:06 - loss: 0.9402 - accuracy: 0.83 - ETA: 2:05 - loss: 0.9378 - accuracy: 0.83 - ETA: 2:04 - loss: 0.9330 - accuracy: 0.83 - ETA: 2:03 - loss: 0.9400 - accuracy: 0.83 - ETA: 2:02 - loss: 0.9223 - accuracy: 0.83 - ETA: 2:01 - loss: 0.9225 - accuracy: 0.83 - ETA: 2:00 - loss: 0.9257 - accuracy: 0.83 - ETA: 1:58 - loss: 0.9454 - accuracy: 0.83 - ETA: 1:57 - loss: 0.9483 - accuracy: 0.83 - ETA: 1:56 - loss: 0.9308 - accuracy: 0.83 - ETA: 1:56 - loss: 0.9267 - accuracy: 0.83 - ETA: 1:54 - loss: 0.9209 - accuracy: 0.83 - ETA: 1:53 - loss: 0.9188 - accuracy: 0.83 - ETA: 1:52 - loss: 0.9142 - accuracy: 0.83 - ETA: 1:51 - loss: 0.9172 - accuracy: 0.83 - ETA: 1:50 - loss: 0.9076 - accuracy: 0.83 - ETA: 1:49 - loss: 0.9125 - accuracy: 0.83 - ETA: 1:49 - loss: 0.9274 - accuracy: 0.83 - ETA: 1:48 - loss: 0.9227 - accuracy: 0.83 - ETA: 1:47 - loss: 0.9212 - accuracy: 0.83 - ETA: 1:46 - loss: 0.9246 - accuracy: 0.83 - ETA: 1:45 - loss: 0.9212 - accuracy: 0.83 - ETA: 1:44 - loss: 0.9349 - accuracy: 0.83 - ETA: 1:43 - loss: 0.9366 - accuracy: 0.83 - ETA: 1:42 - loss: 0.9266 - accuracy: 0.83 - ETA: 1:41 - loss: 0.9357 - accuracy: 0.83 - ETA: 1:40 - loss: 0.9395 - accuracy: 0.83 - ETA: 1:39 - loss: 0.9406 - accuracy: 0.83 - ETA: 1:38 - loss: 0.9333 - accuracy: 0.83 - ETA: 1:37 - loss: 0.9446 - accuracy: 0.83 - ETA: 1:36 - loss: 0.9453 - accuracy: 0.83 - ETA: 1:35 - loss: 0.9485 - accuracy: 0.83 - ETA: 1:34 - loss: 0.9561 - accuracy: 0.82 - ETA: 1:33 - loss: 0.9555 - accuracy: 0.82 - ETA: 1:32 - loss: 0.9470 - accuracy: 0.83 - ETA: 1:31 - loss: 0.9468 - accuracy: 0.83 - ETA: 1:30 - loss: 0.9526 - accuracy: 0.82 - ETA: 1:29 - loss: 0.9509 - accuracy: 0.82 - ETA: 1:28 - loss: 0.9480 - accuracy: 0.83 - ETA: 1:27 - loss: 0.9447 - accuracy: 0.82 - ETA: 1:26 - loss: 0.9554 - accuracy: 0.82 - ETA: 1:26 - loss: 0.9482 - accuracy: 0.83 - ETA: 1:25 - loss: 0.9454 - accuracy: 0.83 - ETA: 1:24 - loss: 0.9443 - accuracy: 0.83 - ETA: 1:23 - loss: 0.9391 - accuracy: 0.83 - ETA: 1:22 - loss: 0.9370 - accuracy: 0.83 - ETA: 1:21 - loss: 0.9324 - accuracy: 0.83 - ETA: 1:20 - loss: 0.9346 - accuracy: 0.83 - ETA: 1:19 - loss: 0.9368 - accuracy: 0.83 - ETA: 1:18 - loss: 0.9452 - accuracy: 0.83 - ETA: 1:17 - loss: 0.9458 - accuracy: 0.83 - ETA: 1:16 - loss: 0.9451 - accuracy: 0.83 - ETA: 1:15 - loss: 0.9423 - accuracy: 0.83 - ETA: 1:14 - loss: 0.9423 - accuracy: 0.83 - ETA: 1:13 - loss: 0.9503 - accuracy: 0.82 - ETA: 1:12 - loss: 0.9502 - accuracy: 0.82 - ETA: 1:11 - loss: 0.9486 - accuracy: 0.83 - ETA: 1:10 - loss: 0.9486 - accuracy: 0.83 - ETA: 1:09 - loss: 0.9491 - accuracy: 0.82 - ETA: 1:09 - loss: 0.9449 - accuracy: 0.83 - ETA: 1:08 - loss: 0.9427 - accuracy: 0.83 - ETA: 1:07 - loss: 0.9362 - accuracy: 0.83 - ETA: 1:06 - loss: 0.9341 - accuracy: 0.83 - ETA: 1:05 - loss: 0.9325 - accuracy: 0.83 - ETA: 1:04 - loss: 0.9348 - accuracy: 0.83 - ETA: 1:03 - loss: 0.9457 - accuracy: 0.82 - ETA: 1:02 - loss: 0.9456 - accuracy: 0.82 - ETA: 1:01 - loss: 0.9502 - accuracy: 0.82 - ETA: 1:00 - loss: 0.9493 - accuracy: 0.82 - ETA: 59s - loss: 0.9470 - accuracy: 0.8290 - ETA: 58s - loss: 0.9447 - accuracy: 0.828 - ETA: 57s - loss: 0.9413 - accuracy: 0.829 - ETA: 56s - loss: 0.9451 - accuracy: 0.828 - ETA: 55s - loss: 0.9453 - accuracy: 0.829 - ETA: 54s - loss: 0.9482 - accuracy: 0.829 - ETA: 53s - loss: 0.9475 - accuracy: 0.828 - ETA: 52s - loss: 0.9460 - accuracy: 0.828 - ETA: 51s - loss: 0.9439 - accuracy: 0.829 - ETA: 50s - loss: 0.9394 - accuracy: 0.829 - ETA: 49s - loss: 0.9434 - accuracy: 0.829 - ETA: 48s - loss: 0.9432 - accuracy: 0.830 - ETA: 47s - loss: 0.9411 - accuracy: 0.830 - ETA: 46s - loss: 0.9460 - accuracy: 0.830 - ETA: 45s - loss: 0.9486 - accuracy: 0.830 - ETA: 44s - loss: 0.9471 - accuracy: 0.830 - ETA: 44s - loss: 0.9430 - accuracy: 0.831 - ETA: 43s - loss: 0.9441 - accuracy: 0.831 - ETA: 42s - loss: 0.9448 - accuracy: 0.831 - ETA: 41s - loss: 0.9448 - accuracy: 0.831 - ETA: 40s - loss: 0.9457 - accuracy: 0.831 - ETA: 39s - loss: 0.9432 - accuracy: 0.832 - ETA: 38s - loss: 0.9395 - accuracy: 0.832 - ETA: 37s - loss: 0.9411 - accuracy: 0.832 - ETA: 36s - loss: 0.9377 - accuracy: 0.832 - ETA: 35s - loss: 0.9378 - accuracy: 0.833 - ETA: 34s - loss: 0.9384 - accuracy: 0.833 - ETA: 33s - loss: 0.9388 - accuracy: 0.833 - ETA: 32s - loss: 0.9380 - accuracy: 0.833 - ETA: 31s - loss: 0.9366 - accuracy: 0.833 - ETA: 30s - loss: 0.9368 - accuracy: 0.833 - ETA: 29s - loss: 0.9351 - accuracy: 0.833 - ETA: 28s - loss: 0.9361 - accuracy: 0.833 - ETA: 27s - loss: 0.9368 - accuracy: 0.833 - ETA: 26s - loss: 0.9356 - accuracy: 0.833 - ETA: 25s - loss: 0.9327 - accuracy: 0.833 - ETA: 24s - loss: 0.9334 - accuracy: 0.833 - ETA: 23s - loss: 0.9341 - accuracy: 0.833 - ETA: 22s - loss: 0.9319 - accuracy: 0.833 - ETA: 21s - loss: 0.9309 - accuracy: 0.833 - ETA: 20s - loss: 0.9283 - accuracy: 0.833 - ETA: 19s - loss: 0.9301 - accuracy: 0.833 - ETA: 19s - loss: 0.9288 - accuracy: 0.833 - ETA: 18s - loss: 0.9265 - accuracy: 0.833 - ETA: 17s - loss: 0.9264 - accuracy: 0.833 - ETA: 16s - loss: 0.9234 - accuracy: 0.834 - ETA: 15s - loss: 0.9247 - accuracy: 0.834 - ETA: 14s - loss: 0.9218 - accuracy: 0.834 - ETA: 13s - loss: 0.9215 - accuracy: 0.834 - ETA: 12s - loss: 0.9206 - accuracy: 0.834 - ETA: 11s - loss: 0.9208 - accuracy: 0.834 - ETA: 10s - loss: 0.9225 - accuracy: 0.834 - ETA: 9s - loss: 0.9208 - accuracy: 0.834 - ETA: 8s - loss: 0.9210 - accuracy: 0.83 - ETA: 7s - loss: 0.9196 - accuracy: 0.83 - ETA: 6s - loss: 0.9238 - accuracy: 0.83 - ETA: 5s - loss: 0.9270 - accuracy: 0.83 - ETA: 4s - loss: 0.9295 - accuracy: 0.83 - ETA: 3s - loss: 0.9319 - accuracy: 0.83 - ETA: 2s - loss: 0.9292 - accuracy: 0.83 - ETA: 1s - loss: 0.9268 - accuracy: 0.83 - ETA: 0s - loss: 0.9244 - accuracy: 0.83 - 156s 8ms/step - loss: 0.9245 - accuracy: 0.8336 - val_loss: 2.6672 - val_accuracy: 0.7610\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:31 - loss: 0.8798 - accuracy: 0.81 - ETA: 2:24 - loss: 0.9069 - accuracy: 0.80 - ETA: 2:22 - loss: 0.9880 - accuracy: 0.79 - ETA: 2:20 - loss: 1.0218 - accuracy: 0.79 - ETA: 2:20 - loss: 1.0356 - accuracy: 0.79 - ETA: 2:17 - loss: 1.0022 - accuracy: 0.80 - ETA: 2:16 - loss: 0.9917 - accuracy: 0.80 - ETA: 2:17 - loss: 0.9922 - accuracy: 0.81 - ETA: 2:16 - loss: 0.9626 - accuracy: 0.81 - ETA: 2:15 - loss: 0.9307 - accuracy: 0.82 - ETA: 2:13 - loss: 0.9165 - accuracy: 0.82 - ETA: 2:13 - loss: 0.9051 - accuracy: 0.82 - ETA: 2:12 - loss: 0.8961 - accuracy: 0.83 - ETA: 2:11 - loss: 0.9071 - accuracy: 0.82 - ETA: 2:10 - loss: 0.9194 - accuracy: 0.82 - ETA: 2:09 - loss: 0.9074 - accuracy: 0.82 - ETA: 2:08 - loss: 0.8963 - accuracy: 0.82 - ETA: 2:06 - loss: 0.8909 - accuracy: 0.82 - ETA: 2:05 - loss: 0.8836 - accuracy: 0.83 - ETA: 2:04 - loss: 0.9116 - accuracy: 0.82 - ETA: 2:03 - loss: 0.9111 - accuracy: 0.82 - ETA: 2:02 - loss: 0.9004 - accuracy: 0.82 - ETA: 2:01 - loss: 0.8921 - accuracy: 0.83 - ETA: 2:01 - loss: 0.8770 - accuracy: 0.83 - ETA: 2:00 - loss: 0.8751 - accuracy: 0.83 - ETA: 1:59 - loss: 0.8968 - accuracy: 0.82 - ETA: 1:58 - loss: 0.9010 - accuracy: 0.82 - ETA: 1:57 - loss: 0.9049 - accuracy: 0.82 - ETA: 1:56 - loss: 0.8952 - accuracy: 0.82 - ETA: 1:55 - loss: 0.9027 - accuracy: 0.82 - ETA: 1:54 - loss: 0.8903 - accuracy: 0.82 - ETA: 1:53 - loss: 0.8867 - accuracy: 0.82 - ETA: 1:52 - loss: 0.8787 - accuracy: 0.83 - ETA: 1:51 - loss: 0.8826 - accuracy: 0.82 - ETA: 1:50 - loss: 0.8724 - accuracy: 0.83 - ETA: 1:49 - loss: 0.8808 - accuracy: 0.82 - ETA: 1:48 - loss: 0.8800 - accuracy: 0.83 - ETA: 1:47 - loss: 0.8842 - accuracy: 0.82 - ETA: 1:46 - loss: 0.8921 - accuracy: 0.82 - ETA: 1:45 - loss: 0.8840 - accuracy: 0.82 - ETA: 1:45 - loss: 0.8821 - accuracy: 0.82 - ETA: 1:44 - loss: 0.8895 - accuracy: 0.82 - ETA: 1:43 - loss: 0.8944 - accuracy: 0.82 - ETA: 1:42 - loss: 0.8900 - accuracy: 0.82 - ETA: 1:41 - loss: 0.8874 - accuracy: 0.82 - ETA: 1:40 - loss: 0.8846 - accuracy: 0.83 - ETA: 1:39 - loss: 0.8947 - accuracy: 0.82 - ETA: 1:38 - loss: 0.8965 - accuracy: 0.82 - ETA: 1:37 - loss: 0.8954 - accuracy: 0.82 - ETA: 1:36 - loss: 0.8966 - accuracy: 0.82 - ETA: 1:35 - loss: 0.9012 - accuracy: 0.82 - ETA: 1:34 - loss: 0.9188 - accuracy: 0.82 - ETA: 1:34 - loss: 0.9114 - accuracy: 0.82 - ETA: 1:33 - loss: 0.9102 - accuracy: 0.82 - ETA: 1:32 - loss: 0.9103 - accuracy: 0.82 - ETA: 1:31 - loss: 0.9094 - accuracy: 0.82 - ETA: 1:30 - loss: 0.9056 - accuracy: 0.82 - ETA: 1:29 - loss: 0.9104 - accuracy: 0.82 - ETA: 1:28 - loss: 0.9145 - accuracy: 0.83 - ETA: 1:27 - loss: 0.9154 - accuracy: 0.83 - ETA: 1:26 - loss: 0.9143 - accuracy: 0.82 - ETA: 1:25 - loss: 0.9157 - accuracy: 0.82 - ETA: 1:24 - loss: 0.9263 - accuracy: 0.82 - ETA: 1:23 - loss: 0.9338 - accuracy: 0.82 - ETA: 1:22 - loss: 0.9307 - accuracy: 0.82 - ETA: 1:22 - loss: 0.9383 - accuracy: 0.82 - ETA: 1:21 - loss: 0.9351 - accuracy: 0.82 - ETA: 1:20 - loss: 0.9359 - accuracy: 0.83 - ETA: 1:19 - loss: 0.9326 - accuracy: 0.83 - ETA: 1:18 - loss: 0.9388 - accuracy: 0.82 - ETA: 1:18 - loss: 0.9346 - accuracy: 0.83 - ETA: 1:17 - loss: 0.9308 - accuracy: 0.83 - ETA: 1:16 - loss: 0.9329 - accuracy: 0.83 - ETA: 1:15 - loss: 0.9331 - accuracy: 0.83 - ETA: 1:14 - loss: 0.9329 - accuracy: 0.83 - ETA: 1:13 - loss: 0.9313 - accuracy: 0.83 - ETA: 1:12 - loss: 0.9289 - accuracy: 0.83 - ETA: 1:11 - loss: 0.9243 - accuracy: 0.83 - ETA: 1:10 - loss: 0.9242 - accuracy: 0.83 - ETA: 1:09 - loss: 0.9265 - accuracy: 0.83 - ETA: 1:08 - loss: 0.9247 - accuracy: 0.83 - ETA: 1:07 - loss: 0.9342 - accuracy: 0.83 - ETA: 1:06 - loss: 0.9393 - accuracy: 0.83 - ETA: 1:05 - loss: 0.9391 - accuracy: 0.83 - ETA: 1:04 - loss: 0.9389 - accuracy: 0.83 - ETA: 1:03 - loss: 0.9446 - accuracy: 0.83 - ETA: 1:02 - loss: 0.9451 - accuracy: 0.82 - ETA: 1:01 - loss: 0.9450 - accuracy: 0.83 - ETA: 1:00 - loss: 0.9394 - accuracy: 0.83 - ETA: 59s - loss: 0.9388 - accuracy: 0.8308 - ETA: 58s - loss: 0.9344 - accuracy: 0.831 - ETA: 57s - loss: 0.9370 - accuracy: 0.832 - ETA: 56s - loss: 0.9348 - accuracy: 0.832 - ETA: 55s - loss: 0.9344 - accuracy: 0.832 - ETA: 54s - loss: 0.9310 - accuracy: 0.832 - ETA: 53s - loss: 0.9320 - accuracy: 0.832 - ETA: 52s - loss: 0.9396 - accuracy: 0.832 - ETA: 51s - loss: 0.9452 - accuracy: 0.831 - ETA: 50s - loss: 0.9472 - accuracy: 0.831 - ETA: 49s - loss: 0.9466 - accuracy: 0.831 - ETA: 48s - loss: 0.9494 - accuracy: 0.830 - ETA: 47s - loss: 0.9497 - accuracy: 0.830 - ETA: 46s - loss: 0.9547 - accuracy: 0.830 - ETA: 45s - loss: 0.9529 - accuracy: 0.830 - ETA: 44s - loss: 0.9502 - accuracy: 0.831 - ETA: 43s - loss: 0.9483 - accuracy: 0.831 - ETA: 42s - loss: 0.9472 - accuracy: 0.831 - ETA: 41s - loss: 0.9499 - accuracy: 0.830 - ETA: 40s - loss: 0.9493 - accuracy: 0.831 - ETA: 39s - loss: 0.9503 - accuracy: 0.831 - ETA: 38s - loss: 0.9518 - accuracy: 0.830 - ETA: 37s - loss: 0.9514 - accuracy: 0.830 - ETA: 36s - loss: 0.9510 - accuracy: 0.830 - ETA: 35s - loss: 0.9514 - accuracy: 0.830 - ETA: 34s - loss: 0.9509 - accuracy: 0.830 - ETA: 33s - loss: 0.9475 - accuracy: 0.830 - ETA: 32s - loss: 0.9474 - accuracy: 0.830 - ETA: 31s - loss: 0.9477 - accuracy: 0.830 - ETA: 30s - loss: 0.9480 - accuracy: 0.831 - ETA: 30s - loss: 0.9503 - accuracy: 0.831 - ETA: 29s - loss: 0.9496 - accuracy: 0.831 - ETA: 28s - loss: 0.9485 - accuracy: 0.830 - ETA: 27s - loss: 0.9472 - accuracy: 0.830 - ETA: 26s - loss: 0.9471 - accuracy: 0.831 - ETA: 25s - loss: 0.9437 - accuracy: 0.831 - ETA: 24s - loss: 0.9433 - accuracy: 0.831 - ETA: 23s - loss: 0.9479 - accuracy: 0.831 - ETA: 22s - loss: 0.9455 - accuracy: 0.831 - ETA: 21s - loss: 0.9449 - accuracy: 0.831 - ETA: 20s - loss: 0.9421 - accuracy: 0.831 - ETA: 19s - loss: 0.9410 - accuracy: 0.831 - ETA: 18s - loss: 0.9461 - accuracy: 0.830 - ETA: 17s - loss: 0.9448 - accuracy: 0.830 - ETA: 16s - loss: 0.9406 - accuracy: 0.830 - ETA: 15s - loss: 0.9394 - accuracy: 0.831 - ETA: 14s - loss: 0.9383 - accuracy: 0.831 - ETA: 13s - loss: 0.9368 - accuracy: 0.831 - ETA: 12s - loss: 0.9356 - accuracy: 0.831 - ETA: 11s - loss: 0.9373 - accuracy: 0.831 - ETA: 10s - loss: 0.9378 - accuracy: 0.831 - ETA: 9s - loss: 0.9360 - accuracy: 0.831 - ETA: 8s - loss: 0.9335 - accuracy: 0.83 - ETA: 7s - loss: 0.9336 - accuracy: 0.83 - ETA: 6s - loss: 0.9338 - accuracy: 0.83 - ETA: 5s - loss: 0.9343 - accuracy: 0.83 - ETA: 4s - loss: 0.9344 - accuracy: 0.83 - ETA: 3s - loss: 0.9335 - accuracy: 0.83 - ETA: 2s - loss: 0.9324 - accuracy: 0.83 - ETA: 1s - loss: 0.9320 - accuracy: 0.83 - ETA: 0s - loss: 0.9313 - accuracy: 0.83 - 157s 8ms/step - loss: 0.9292 - accuracy: 0.8313 - val_loss: 2.6652 - val_accuracy: 0.7561\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:23 - loss: 0.7817 - accuracy: 0.85 - ETA: 2:22 - loss: 0.6968 - accuracy: 0.85 - ETA: 2:19 - loss: 0.7200 - accuracy: 0.83 - ETA: 2:18 - loss: 0.8531 - accuracy: 0.82 - ETA: 2:16 - loss: 0.8670 - accuracy: 0.82 - ETA: 2:15 - loss: 0.8004 - accuracy: 0.82 - ETA: 2:15 - loss: 0.8297 - accuracy: 0.83 - ETA: 2:16 - loss: 0.8289 - accuracy: 0.82 - ETA: 2:15 - loss: 0.8210 - accuracy: 0.82 - ETA: 2:14 - loss: 0.7957 - accuracy: 0.83 - ETA: 2:14 - loss: 0.8050 - accuracy: 0.83 - ETA: 2:14 - loss: 0.8234 - accuracy: 0.82 - ETA: 2:12 - loss: 0.8234 - accuracy: 0.83 - ETA: 2:11 - loss: 0.8049 - accuracy: 0.83 - ETA: 2:10 - loss: 0.8270 - accuracy: 0.83 - ETA: 2:09 - loss: 0.8446 - accuracy: 0.82 - ETA: 2:07 - loss: 0.8304 - accuracy: 0.83 - ETA: 2:06 - loss: 0.8292 - accuracy: 0.83 - ETA: 2:05 - loss: 0.8510 - accuracy: 0.83 - ETA: 2:04 - loss: 0.8296 - accuracy: 0.83 - ETA: 2:03 - loss: 0.8330 - accuracy: 0.83 - ETA: 2:03 - loss: 0.8332 - accuracy: 0.83 - ETA: 2:02 - loss: 0.8278 - accuracy: 0.83 - ETA: 2:01 - loss: 0.8312 - accuracy: 0.83 - ETA: 2:00 - loss: 0.8578 - accuracy: 0.83 - ETA: 2:00 - loss: 0.8507 - accuracy: 0.83 - ETA: 1:59 - loss: 0.8478 - accuracy: 0.83 - ETA: 1:58 - loss: 0.8379 - accuracy: 0.83 - ETA: 1:57 - loss: 0.8405 - accuracy: 0.83 - ETA: 1:56 - loss: 0.8538 - accuracy: 0.83 - ETA: 1:55 - loss: 0.8496 - accuracy: 0.83 - ETA: 1:54 - loss: 0.8601 - accuracy: 0.83 - ETA: 1:53 - loss: 0.8544 - accuracy: 0.83 - ETA: 1:52 - loss: 0.8522 - accuracy: 0.83 - ETA: 1:51 - loss: 0.8538 - accuracy: 0.83 - ETA: 1:50 - loss: 0.8505 - accuracy: 0.83 - ETA: 1:49 - loss: 0.8566 - accuracy: 0.83 - ETA: 1:48 - loss: 0.8553 - accuracy: 0.83 - ETA: 1:47 - loss: 0.8571 - accuracy: 0.83 - ETA: 1:46 - loss: 0.8634 - accuracy: 0.83 - ETA: 1:45 - loss: 0.8624 - accuracy: 0.83 - ETA: 1:44 - loss: 0.8638 - accuracy: 0.83 - ETA: 1:43 - loss: 0.8606 - accuracy: 0.83 - ETA: 1:43 - loss: 0.8690 - accuracy: 0.83 - ETA: 1:42 - loss: 0.8717 - accuracy: 0.83 - ETA: 1:41 - loss: 0.8713 - accuracy: 0.83 - ETA: 1:40 - loss: 0.8655 - accuracy: 0.83 - ETA: 1:39 - loss: 0.8609 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8515 - accuracy: 0.84 - ETA: 1:36 - loss: 0.8608 - accuracy: 0.83 - ETA: 1:36 - loss: 0.8572 - accuracy: 0.83 - ETA: 1:35 - loss: 0.8570 - accuracy: 0.83 - ETA: 1:34 - loss: 0.8494 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8568 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8682 - accuracy: 0.84 - ETA: 1:31 - loss: 0.8770 - accuracy: 0.84 - ETA: 1:30 - loss: 0.8717 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8674 - accuracy: 0.84 - ETA: 1:28 - loss: 0.8769 - accuracy: 0.84 - ETA: 1:27 - loss: 0.8728 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8679 - accuracy: 0.84 - ETA: 1:25 - loss: 0.8702 - accuracy: 0.84 - ETA: 1:24 - loss: 0.8693 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8678 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8675 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8658 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8637 - accuracy: 0.84 - ETA: 1:19 - loss: 0.8617 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8639 - accuracy: 0.84 - ETA: 1:17 - loss: 0.8688 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8789 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8745 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8718 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8716 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8689 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8680 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8641 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8644 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8622 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8618 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8630 - accuracy: 0.84 - ETA: 1:06 - loss: 0.8732 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8731 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8861 - accuracy: 0.83 - ETA: 1:03 - loss: 0.8805 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8782 - accuracy: 0.84 - ETA: 1:01 - loss: 0.8822 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8797 - accuracy: 0.84 - ETA: 59s - loss: 0.8766 - accuracy: 0.8404 - ETA: 58s - loss: 0.8748 - accuracy: 0.840 - ETA: 57s - loss: 0.8751 - accuracy: 0.840 - ETA: 56s - loss: 0.8785 - accuracy: 0.840 - ETA: 55s - loss: 0.8768 - accuracy: 0.839 - ETA: 54s - loss: 0.8756 - accuracy: 0.840 - ETA: 53s - loss: 0.8747 - accuracy: 0.840 - ETA: 52s - loss: 0.8705 - accuracy: 0.840 - ETA: 51s - loss: 0.8701 - accuracy: 0.840 - ETA: 50s - loss: 0.8718 - accuracy: 0.840 - ETA: 49s - loss: 0.8739 - accuracy: 0.839 - ETA: 49s - loss: 0.8725 - accuracy: 0.839 - ETA: 48s - loss: 0.8744 - accuracy: 0.839 - ETA: 47s - loss: 0.8729 - accuracy: 0.839 - ETA: 46s - loss: 0.8755 - accuracy: 0.839 - ETA: 45s - loss: 0.8727 - accuracy: 0.839 - ETA: 44s - loss: 0.8733 - accuracy: 0.839 - ETA: 43s - loss: 0.8784 - accuracy: 0.839 - ETA: 42s - loss: 0.8761 - accuracy: 0.839 - ETA: 41s - loss: 0.8776 - accuracy: 0.838 - ETA: 40s - loss: 0.8766 - accuracy: 0.838 - ETA: 39s - loss: 0.8762 - accuracy: 0.839 - ETA: 38s - loss: 0.8742 - accuracy: 0.839 - ETA: 37s - loss: 0.8738 - accuracy: 0.838 - ETA: 36s - loss: 0.8742 - accuracy: 0.838 - ETA: 35s - loss: 0.8755 - accuracy: 0.838 - ETA: 34s - loss: 0.8747 - accuracy: 0.838 - ETA: 33s - loss: 0.8750 - accuracy: 0.838 - ETA: 32s - loss: 0.8733 - accuracy: 0.839 - ETA: 31s - loss: 0.8721 - accuracy: 0.839 - ETA: 30s - loss: 0.8717 - accuracy: 0.839 - ETA: 29s - loss: 0.8751 - accuracy: 0.838 - ETA: 28s - loss: 0.8744 - accuracy: 0.838 - ETA: 27s - loss: 0.8759 - accuracy: 0.838 - ETA: 26s - loss: 0.8763 - accuracy: 0.838 - ETA: 25s - loss: 0.8742 - accuracy: 0.839 - ETA: 24s - loss: 0.8759 - accuracy: 0.838 - ETA: 23s - loss: 0.8749 - accuracy: 0.838 - ETA: 23s - loss: 0.8763 - accuracy: 0.838 - ETA: 22s - loss: 0.8775 - accuracy: 0.838 - ETA: 21s - loss: 0.8776 - accuracy: 0.838 - ETA: 20s - loss: 0.8773 - accuracy: 0.838 - ETA: 19s - loss: 0.8798 - accuracy: 0.837 - ETA: 18s - loss: 0.8803 - accuracy: 0.837 - ETA: 17s - loss: 0.8812 - accuracy: 0.837 - ETA: 16s - loss: 0.8818 - accuracy: 0.837 - ETA: 15s - loss: 0.8797 - accuracy: 0.837 - ETA: 14s - loss: 0.8793 - accuracy: 0.837 - ETA: 13s - loss: 0.8806 - accuracy: 0.837 - ETA: 12s - loss: 0.8808 - accuracy: 0.837 - ETA: 11s - loss: 0.8814 - accuracy: 0.837 - ETA: 10s - loss: 0.8793 - accuracy: 0.837 - ETA: 9s - loss: 0.8841 - accuracy: 0.837 - ETA: 8s - loss: 0.8840 - accuracy: 0.83 - ETA: 7s - loss: 0.8841 - accuracy: 0.83 - ETA: 6s - loss: 0.8855 - accuracy: 0.83 - ETA: 5s - loss: 0.8883 - accuracy: 0.83 - ETA: 4s - loss: 0.8870 - accuracy: 0.83 - ETA: 3s - loss: 0.8869 - accuracy: 0.83 - ETA: 2s - loss: 0.8853 - accuracy: 0.83 - ETA: 1s - loss: 0.8845 - accuracy: 0.83 - ETA: 0s - loss: 0.8819 - accuracy: 0.83 - 157s 8ms/step - loss: 0.8830 - accuracy: 0.8361 - val_loss: 2.6864 - val_accuracy: 0.7556\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:33 - loss: 0.6228 - accuracy: 0.83 - ETA: 2:25 - loss: 0.8352 - accuracy: 0.81 - ETA: 2:21 - loss: 0.8110 - accuracy: 0.82 - ETA: 2:20 - loss: 0.7831 - accuracy: 0.83 - ETA: 2:18 - loss: 0.7565 - accuracy: 0.84 - ETA: 2:17 - loss: 0.7735 - accuracy: 0.83 - ETA: 2:15 - loss: 0.7281 - accuracy: 0.84 - ETA: 2:14 - loss: 0.7540 - accuracy: 0.84 - ETA: 2:13 - loss: 0.7599 - accuracy: 0.84 - ETA: 2:12 - loss: 0.7266 - accuracy: 0.85 - ETA: 2:11 - loss: 0.7412 - accuracy: 0.84 - ETA: 2:09 - loss: 0.7241 - accuracy: 0.85 - ETA: 2:08 - loss: 0.7338 - accuracy: 0.85 - ETA: 2:09 - loss: 0.7121 - accuracy: 0.85 - ETA: 2:09 - loss: 0.7047 - accuracy: 0.85 - ETA: 2:08 - loss: 0.7347 - accuracy: 0.85 - ETA: 2:07 - loss: 0.7369 - accuracy: 0.85 - ETA: 2:06 - loss: 0.7480 - accuracy: 0.85 - ETA: 2:05 - loss: 0.7558 - accuracy: 0.85 - ETA: 2:04 - loss: 0.7613 - accuracy: 0.85 - ETA: 2:02 - loss: 0.7567 - accuracy: 0.85 - ETA: 2:01 - loss: 0.7674 - accuracy: 0.85 - ETA: 2:00 - loss: 0.7752 - accuracy: 0.85 - ETA: 2:00 - loss: 0.7988 - accuracy: 0.84 - ETA: 1:59 - loss: 0.8044 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8023 - accuracy: 0.84 - ETA: 1:57 - loss: 0.8092 - accuracy: 0.84 - ETA: 1:55 - loss: 0.8088 - accuracy: 0.84 - ETA: 1:55 - loss: 0.8185 - accuracy: 0.84 - ETA: 1:54 - loss: 0.8162 - accuracy: 0.84 - ETA: 1:53 - loss: 0.8337 - accuracy: 0.84 - ETA: 1:53 - loss: 0.8366 - accuracy: 0.84 - ETA: 1:52 - loss: 0.8318 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8265 - accuracy: 0.84 - ETA: 1:50 - loss: 0.8316 - accuracy: 0.84 - ETA: 1:49 - loss: 0.8250 - accuracy: 0.84 - ETA: 1:48 - loss: 0.8256 - accuracy: 0.84 - ETA: 1:47 - loss: 0.8303 - accuracy: 0.84 - ETA: 1:46 - loss: 0.8318 - accuracy: 0.84 - ETA: 1:45 - loss: 0.8440 - accuracy: 0.84 - ETA: 1:44 - loss: 0.8533 - accuracy: 0.84 - ETA: 1:43 - loss: 0.8484 - accuracy: 0.84 - ETA: 1:42 - loss: 0.8512 - accuracy: 0.84 - ETA: 1:41 - loss: 0.8443 - accuracy: 0.84 - ETA: 1:40 - loss: 0.8481 - accuracy: 0.84 - ETA: 1:39 - loss: 0.8499 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8446 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8423 - accuracy: 0.84 - ETA: 1:37 - loss: 0.8456 - accuracy: 0.84 - ETA: 1:36 - loss: 0.8440 - accuracy: 0.84 - ETA: 1:35 - loss: 0.8493 - accuracy: 0.84 - ETA: 1:34 - loss: 0.8538 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8564 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8571 - accuracy: 0.84 - ETA: 1:31 - loss: 0.8611 - accuracy: 0.84 - ETA: 1:30 - loss: 0.8572 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8534 - accuracy: 0.84 - ETA: 1:28 - loss: 0.8501 - accuracy: 0.84 - ETA: 1:27 - loss: 0.8543 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8535 - accuracy: 0.84 - ETA: 1:25 - loss: 0.8621 - accuracy: 0.84 - ETA: 1:24 - loss: 0.8706 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8755 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8749 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8721 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8719 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8740 - accuracy: 0.83 - ETA: 1:19 - loss: 0.8733 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8731 - accuracy: 0.83 - ETA: 1:17 - loss: 0.8676 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8654 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8731 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8705 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8726 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8769 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8770 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8810 - accuracy: 0.83 - ETA: 1:09 - loss: 0.8833 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8869 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8905 - accuracy: 0.83 - ETA: 1:06 - loss: 0.8912 - accuracy: 0.83 - ETA: 1:06 - loss: 0.8889 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8839 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8829 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8830 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8813 - accuracy: 0.84 - ETA: 1:01 - loss: 0.8777 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8760 - accuracy: 0.84 - ETA: 59s - loss: 0.8763 - accuracy: 0.8406 - ETA: 58s - loss: 0.8749 - accuracy: 0.841 - ETA: 57s - loss: 0.8769 - accuracy: 0.840 - ETA: 56s - loss: 0.8755 - accuracy: 0.841 - ETA: 55s - loss: 0.8730 - accuracy: 0.841 - ETA: 54s - loss: 0.8730 - accuracy: 0.840 - ETA: 53s - loss: 0.8723 - accuracy: 0.840 - ETA: 52s - loss: 0.8741 - accuracy: 0.840 - ETA: 51s - loss: 0.8760 - accuracy: 0.839 - ETA: 50s - loss: 0.8759 - accuracy: 0.839 - ETA: 49s - loss: 0.8739 - accuracy: 0.839 - ETA: 48s - loss: 0.8718 - accuracy: 0.839 - ETA: 47s - loss: 0.8688 - accuracy: 0.840 - ETA: 46s - loss: 0.8710 - accuracy: 0.840 - ETA: 45s - loss: 0.8682 - accuracy: 0.840 - ETA: 44s - loss: 0.8674 - accuracy: 0.841 - ETA: 43s - loss: 0.8678 - accuracy: 0.841 - ETA: 42s - loss: 0.8724 - accuracy: 0.841 - ETA: 41s - loss: 0.8718 - accuracy: 0.841 - ETA: 41s - loss: 0.8708 - accuracy: 0.840 - ETA: 40s - loss: 0.8718 - accuracy: 0.840 - ETA: 39s - loss: 0.8690 - accuracy: 0.840 - ETA: 38s - loss: 0.8741 - accuracy: 0.840 - ETA: 37s - loss: 0.8741 - accuracy: 0.839 - ETA: 36s - loss: 0.8743 - accuracy: 0.839 - ETA: 35s - loss: 0.8704 - accuracy: 0.840 - ETA: 34s - loss: 0.8666 - accuracy: 0.840 - ETA: 33s - loss: 0.8628 - accuracy: 0.841 - ETA: 32s - loss: 0.8608 - accuracy: 0.841 - ETA: 31s - loss: 0.8597 - accuracy: 0.841 - ETA: 30s - loss: 0.8595 - accuracy: 0.841 - ETA: 29s - loss: 0.8613 - accuracy: 0.841 - ETA: 28s - loss: 0.8608 - accuracy: 0.841 - ETA: 27s - loss: 0.8600 - accuracy: 0.841 - ETA: 26s - loss: 0.8609 - accuracy: 0.841 - ETA: 25s - loss: 0.8642 - accuracy: 0.841 - ETA: 24s - loss: 0.8627 - accuracy: 0.841 - ETA: 23s - loss: 0.8630 - accuracy: 0.841 - ETA: 22s - loss: 0.8650 - accuracy: 0.841 - ETA: 21s - loss: 0.8635 - accuracy: 0.841 - ETA: 20s - loss: 0.8619 - accuracy: 0.841 - ETA: 19s - loss: 0.8657 - accuracy: 0.840 - ETA: 19s - loss: 0.8651 - accuracy: 0.840 - ETA: 18s - loss: 0.8655 - accuracy: 0.840 - ETA: 17s - loss: 0.8663 - accuracy: 0.840 - ETA: 16s - loss: 0.8685 - accuracy: 0.840 - ETA: 15s - loss: 0.8696 - accuracy: 0.840 - ETA: 14s - loss: 0.8662 - accuracy: 0.840 - ETA: 13s - loss: 0.8658 - accuracy: 0.840 - ETA: 12s - loss: 0.8691 - accuracy: 0.840 - ETA: 11s - loss: 0.8664 - accuracy: 0.840 - ETA: 10s - loss: 0.8637 - accuracy: 0.840 - ETA: 9s - loss: 0.8619 - accuracy: 0.840 - ETA: 8s - loss: 0.8625 - accuracy: 0.84 - ETA: 7s - loss: 0.8630 - accuracy: 0.84 - ETA: 6s - loss: 0.8613 - accuracy: 0.84 - ETA: 5s - loss: 0.8652 - accuracy: 0.84 - ETA: 4s - loss: 0.8640 - accuracy: 0.84 - ETA: 3s - loss: 0.8635 - accuracy: 0.84 - ETA: 2s - loss: 0.8636 - accuracy: 0.84 - ETA: 1s - loss: 0.8633 - accuracy: 0.84 - ETA: 0s - loss: 0.8611 - accuracy: 0.84 - 156s 8ms/step - loss: 0.8626 - accuracy: 0.8402 - val_loss: 3.0705 - val_accuracy: 0.7556\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:42 - loss: 1.4097 - accuracy: 0.78 - ETA: 2:42 - loss: 1.1773 - accuracy: 0.80 - ETA: 2:44 - loss: 0.9977 - accuracy: 0.80 - ETA: 2:40 - loss: 1.0339 - accuracy: 0.81 - ETA: 2:35 - loss: 0.9960 - accuracy: 0.82 - ETA: 2:32 - loss: 0.9004 - accuracy: 0.83 - ETA: 2:29 - loss: 0.8699 - accuracy: 0.84 - ETA: 2:26 - loss: 0.9025 - accuracy: 0.83 - ETA: 2:23 - loss: 0.8552 - accuracy: 0.83 - ETA: 2:21 - loss: 0.8683 - accuracy: 0.83 - ETA: 2:19 - loss: 0.8512 - accuracy: 0.83 - ETA: 2:18 - loss: 0.8532 - accuracy: 0.83 - ETA: 2:16 - loss: 0.8814 - accuracy: 0.83 - ETA: 2:14 - loss: 0.8894 - accuracy: 0.83 - ETA: 2:13 - loss: 0.8860 - accuracy: 0.83 - ETA: 2:12 - loss: 0.8551 - accuracy: 0.83 - ETA: 2:11 - loss: 0.8799 - accuracy: 0.83 - ETA: 2:10 - loss: 0.8737 - accuracy: 0.83 - ETA: 2:09 - loss: 0.8633 - accuracy: 0.83 - ETA: 2:08 - loss: 0.8595 - accuracy: 0.83 - ETA: 2:07 - loss: 0.8718 - accuracy: 0.83 - ETA: 2:05 - loss: 0.8833 - accuracy: 0.83 - ETA: 2:04 - loss: 0.8785 - accuracy: 0.83 - ETA: 2:03 - loss: 0.8821 - accuracy: 0.83 - ETA: 2:02 - loss: 0.8759 - accuracy: 0.83 - ETA: 2:01 - loss: 0.8667 - accuracy: 0.83 - ETA: 2:00 - loss: 0.9021 - accuracy: 0.83 - ETA: 1:59 - loss: 0.9118 - accuracy: 0.83 - ETA: 1:58 - loss: 0.8933 - accuracy: 0.83 - ETA: 1:57 - loss: 0.8970 - accuracy: 0.83 - ETA: 1:55 - loss: 0.8979 - accuracy: 0.83 - ETA: 1:54 - loss: 0.9142 - accuracy: 0.83 - ETA: 1:53 - loss: 0.9233 - accuracy: 0.83 - ETA: 1:52 - loss: 0.9246 - accuracy: 0.83 - ETA: 1:52 - loss: 0.9126 - accuracy: 0.83 - ETA: 1:51 - loss: 0.9088 - accuracy: 0.83 - ETA: 1:50 - loss: 0.9089 - accuracy: 0.83 - ETA: 1:49 - loss: 0.8956 - accuracy: 0.83 - ETA: 1:48 - loss: 0.8913 - accuracy: 0.83 - ETA: 1:47 - loss: 0.8870 - accuracy: 0.83 - ETA: 1:46 - loss: 0.8841 - accuracy: 0.83 - ETA: 1:45 - loss: 0.8851 - accuracy: 0.83 - ETA: 1:44 - loss: 0.8986 - accuracy: 0.83 - ETA: 1:43 - loss: 0.9048 - accuracy: 0.83 - ETA: 1:42 - loss: 0.9030 - accuracy: 0.83 - ETA: 1:41 - loss: 0.9025 - accuracy: 0.83 - ETA: 1:40 - loss: 0.9057 - accuracy: 0.83 - ETA: 1:39 - loss: 0.9014 - accuracy: 0.83 - ETA: 1:38 - loss: 0.8996 - accuracy: 0.83 - ETA: 1:37 - loss: 0.8962 - accuracy: 0.83 - ETA: 1:36 - loss: 0.8906 - accuracy: 0.83 - ETA: 1:35 - loss: 0.8930 - accuracy: 0.83 - ETA: 1:34 - loss: 0.8945 - accuracy: 0.83 - ETA: 1:33 - loss: 0.8950 - accuracy: 0.83 - ETA: 1:32 - loss: 0.8910 - accuracy: 0.83 - ETA: 1:31 - loss: 0.8954 - accuracy: 0.83 - ETA: 1:30 - loss: 0.9000 - accuracy: 0.83 - ETA: 1:29 - loss: 0.9005 - accuracy: 0.83 - ETA: 1:28 - loss: 0.9008 - accuracy: 0.83 - ETA: 1:27 - loss: 0.9060 - accuracy: 0.83 - ETA: 1:26 - loss: 0.8984 - accuracy: 0.83 - ETA: 1:25 - loss: 0.8969 - accuracy: 0.83 - ETA: 1:24 - loss: 0.9008 - accuracy: 0.83 - ETA: 1:23 - loss: 0.9019 - accuracy: 0.83 - ETA: 1:22 - loss: 0.8989 - accuracy: 0.83 - ETA: 1:21 - loss: 0.8925 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8926 - accuracy: 0.83 - ETA: 1:19 - loss: 0.8854 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8804 - accuracy: 0.84 - ETA: 1:17 - loss: 0.8775 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8828 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8852 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8881 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8835 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8794 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8779 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8784 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8806 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8849 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8817 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8882 - accuracy: 0.84 - ETA: 1:06 - loss: 0.8915 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8902 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8962 - accuracy: 0.83 - ETA: 1:03 - loss: 0.8925 - accuracy: 0.83 - ETA: 1:02 - loss: 0.8986 - accuracy: 0.83 - ETA: 1:01 - loss: 0.8998 - accuracy: 0.83 - ETA: 1:00 - loss: 0.9039 - accuracy: 0.83 - ETA: 59s - loss: 0.9077 - accuracy: 0.8384 - ETA: 58s - loss: 0.9046 - accuracy: 0.838 - ETA: 57s - loss: 0.9004 - accuracy: 0.838 - ETA: 56s - loss: 0.9029 - accuracy: 0.838 - ETA: 55s - loss: 0.9082 - accuracy: 0.838 - ETA: 54s - loss: 0.9181 - accuracy: 0.838 - ETA: 53s - loss: 0.9158 - accuracy: 0.838 - ETA: 52s - loss: 0.9130 - accuracy: 0.838 - ETA: 51s - loss: 0.9147 - accuracy: 0.838 - ETA: 50s - loss: 0.9171 - accuracy: 0.838 - ETA: 49s - loss: 0.9142 - accuracy: 0.838 - ETA: 48s - loss: 0.9141 - accuracy: 0.838 - ETA: 48s - loss: 0.9153 - accuracy: 0.837 - ETA: 47s - loss: 0.9150 - accuracy: 0.838 - ETA: 46s - loss: 0.9182 - accuracy: 0.837 - ETA: 45s - loss: 0.9186 - accuracy: 0.837 - ETA: 44s - loss: 0.9174 - accuracy: 0.838 - ETA: 43s - loss: 0.9178 - accuracy: 0.838 - ETA: 42s - loss: 0.9228 - accuracy: 0.838 - ETA: 41s - loss: 0.9228 - accuracy: 0.838 - ETA: 40s - loss: 0.9196 - accuracy: 0.838 - ETA: 39s - loss: 0.9202 - accuracy: 0.839 - ETA: 38s - loss: 0.9212 - accuracy: 0.839 - ETA: 37s - loss: 0.9242 - accuracy: 0.838 - ETA: 36s - loss: 0.9202 - accuracy: 0.839 - ETA: 35s - loss: 0.9179 - accuracy: 0.839 - ETA: 34s - loss: 0.9154 - accuracy: 0.839 - ETA: 33s - loss: 0.9157 - accuracy: 0.839 - ETA: 32s - loss: 0.9155 - accuracy: 0.839 - ETA: 31s - loss: 0.9150 - accuracy: 0.839 - ETA: 30s - loss: 0.9150 - accuracy: 0.839 - ETA: 29s - loss: 0.9132 - accuracy: 0.839 - ETA: 28s - loss: 0.9100 - accuracy: 0.840 - ETA: 27s - loss: 0.9153 - accuracy: 0.840 - ETA: 26s - loss: 0.9143 - accuracy: 0.840 - ETA: 25s - loss: 0.9138 - accuracy: 0.840 - ETA: 24s - loss: 0.9123 - accuracy: 0.840 - ETA: 23s - loss: 0.9122 - accuracy: 0.839 - ETA: 23s - loss: 0.9095 - accuracy: 0.840 - ETA: 22s - loss: 0.9124 - accuracy: 0.840 - ETA: 21s - loss: 0.9119 - accuracy: 0.839 - ETA: 20s - loss: 0.9162 - accuracy: 0.839 - ETA: 19s - loss: 0.9136 - accuracy: 0.839 - ETA: 18s - loss: 0.9142 - accuracy: 0.839 - ETA: 17s - loss: 0.9119 - accuracy: 0.839 - ETA: 16s - loss: 0.9095 - accuracy: 0.839 - ETA: 15s - loss: 0.9074 - accuracy: 0.840 - ETA: 14s - loss: 0.9124 - accuracy: 0.840 - ETA: 13s - loss: 0.9116 - accuracy: 0.839 - ETA: 12s - loss: 0.9114 - accuracy: 0.839 - ETA: 11s - loss: 0.9127 - accuracy: 0.839 - ETA: 10s - loss: 0.9156 - accuracy: 0.839 - ETA: 9s - loss: 0.9140 - accuracy: 0.839 - ETA: 8s - loss: 0.9122 - accuracy: 0.83 - ETA: 7s - loss: 0.9145 - accuracy: 0.83 - ETA: 6s - loss: 0.9126 - accuracy: 0.83 - ETA: 5s - loss: 0.9152 - accuracy: 0.83 - ETA: 4s - loss: 0.9145 - accuracy: 0.83 - ETA: 3s - loss: 0.9117 - accuracy: 0.83 - ETA: 2s - loss: 0.9096 - accuracy: 0.83 - ETA: 1s - loss: 0.9134 - accuracy: 0.83 - ETA: 0s - loss: 0.9108 - accuracy: 0.83 - 157s 8ms/step - loss: 0.9113 - accuracy: 0.8385 - val_loss: 2.9476 - val_accuracy: 0.7608\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:20 - loss: 0.7584 - accuracy: 0.88 - ETA: 2:17 - loss: 0.8672 - accuracy: 0.86 - ETA: 2:19 - loss: 0.7682 - accuracy: 0.85 - ETA: 2:17 - loss: 0.6978 - accuracy: 0.86 - ETA: 2:20 - loss: 0.6772 - accuracy: 0.86 - ETA: 2:21 - loss: 0.7073 - accuracy: 0.86 - ETA: 2:19 - loss: 0.7408 - accuracy: 0.86 - ETA: 2:17 - loss: 0.7855 - accuracy: 0.86 - ETA: 2:18 - loss: 0.7593 - accuracy: 0.86 - ETA: 2:17 - loss: 0.7746 - accuracy: 0.86 - ETA: 2:15 - loss: 0.7831 - accuracy: 0.86 - ETA: 2:14 - loss: 0.8003 - accuracy: 0.86 - ETA: 2:13 - loss: 0.7898 - accuracy: 0.86 - ETA: 2:12 - loss: 0.7906 - accuracy: 0.86 - ETA: 2:11 - loss: 0.8027 - accuracy: 0.86 - ETA: 2:11 - loss: 0.8154 - accuracy: 0.86 - ETA: 2:10 - loss: 0.7970 - accuracy: 0.86 - ETA: 2:09 - loss: 0.8100 - accuracy: 0.86 - ETA: 2:08 - loss: 0.8261 - accuracy: 0.86 - ETA: 2:07 - loss: 0.8613 - accuracy: 0.85 - ETA: 2:06 - loss: 0.8578 - accuracy: 0.85 - ETA: 2:06 - loss: 0.8634 - accuracy: 0.85 - ETA: 2:05 - loss: 0.8704 - accuracy: 0.85 - ETA: 2:04 - loss: 0.8900 - accuracy: 0.84 - ETA: 2:03 - loss: 0.8787 - accuracy: 0.85 - ETA: 2:02 - loss: 0.8881 - accuracy: 0.84 - ETA: 2:01 - loss: 0.8950 - accuracy: 0.84 - ETA: 1:59 - loss: 0.8941 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8888 - accuracy: 0.84 - ETA: 1:57 - loss: 0.8905 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8866 - accuracy: 0.84 - ETA: 1:55 - loss: 0.8770 - accuracy: 0.84 - ETA: 1:54 - loss: 0.8773 - accuracy: 0.84 - ETA: 1:53 - loss: 0.8698 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8768 - accuracy: 0.84 - ETA: 1:50 - loss: 0.8837 - accuracy: 0.84 - ETA: 1:49 - loss: 0.8822 - accuracy: 0.84 - ETA: 1:49 - loss: 0.9019 - accuracy: 0.84 - ETA: 1:48 - loss: 0.9067 - accuracy: 0.84 - ETA: 1:47 - loss: 0.9173 - accuracy: 0.84 - ETA: 1:46 - loss: 0.9199 - accuracy: 0.84 - ETA: 1:45 - loss: 0.9134 - accuracy: 0.84 - ETA: 1:44 - loss: 0.9160 - accuracy: 0.84 - ETA: 1:43 - loss: 0.9148 - accuracy: 0.84 - ETA: 1:42 - loss: 0.9130 - accuracy: 0.84 - ETA: 1:41 - loss: 0.9146 - accuracy: 0.84 - ETA: 1:39 - loss: 0.9024 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8949 - accuracy: 0.84 - ETA: 1:37 - loss: 0.8861 - accuracy: 0.84 - ETA: 1:36 - loss: 0.8861 - accuracy: 0.84 - ETA: 1:35 - loss: 0.8921 - accuracy: 0.84 - ETA: 1:34 - loss: 0.8902 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8943 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8933 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8911 - accuracy: 0.84 - ETA: 1:31 - loss: 0.8920 - accuracy: 0.84 - ETA: 1:30 - loss: 0.8978 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8956 - accuracy: 0.84 - ETA: 1:28 - loss: 0.8927 - accuracy: 0.84 - ETA: 1:27 - loss: 0.8919 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8903 - accuracy: 0.84 - ETA: 1:25 - loss: 0.8912 - accuracy: 0.84 - ETA: 1:24 - loss: 0.8870 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8798 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8774 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8797 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8783 - accuracy: 0.84 - ETA: 1:19 - loss: 0.8712 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8667 - accuracy: 0.84 - ETA: 1:17 - loss: 0.8638 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8614 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8544 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8540 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8574 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8645 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8627 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8692 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8752 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8770 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8792 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8768 - accuracy: 0.84 - ETA: 1:06 - loss: 0.8793 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8797 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8813 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8886 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8869 - accuracy: 0.84 - ETA: 1:01 - loss: 0.8837 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8849 - accuracy: 0.84 - ETA: 59s - loss: 0.8863 - accuracy: 0.8445 - ETA: 58s - loss: 0.8865 - accuracy: 0.844 - ETA: 57s - loss: 0.8859 - accuracy: 0.844 - ETA: 56s - loss: 0.8855 - accuracy: 0.844 - ETA: 55s - loss: 0.8915 - accuracy: 0.843 - ETA: 54s - loss: 0.8915 - accuracy: 0.844 - ETA: 53s - loss: 0.8886 - accuracy: 0.844 - ETA: 52s - loss: 0.8874 - accuracy: 0.844 - ETA: 51s - loss: 0.8851 - accuracy: 0.844 - ETA: 50s - loss: 0.8844 - accuracy: 0.844 - ETA: 49s - loss: 0.8842 - accuracy: 0.844 - ETA: 48s - loss: 0.8833 - accuracy: 0.844 - ETA: 47s - loss: 0.8842 - accuracy: 0.844 - ETA: 46s - loss: 0.8828 - accuracy: 0.844 - ETA: 46s - loss: 0.8824 - accuracy: 0.844 - ETA: 45s - loss: 0.8826 - accuracy: 0.845 - ETA: 44s - loss: 0.8818 - accuracy: 0.845 - ETA: 43s - loss: 0.8799 - accuracy: 0.845 - ETA: 42s - loss: 0.8788 - accuracy: 0.845 - ETA: 41s - loss: 0.8771 - accuracy: 0.845 - ETA: 40s - loss: 0.8765 - accuracy: 0.845 - ETA: 39s - loss: 0.8768 - accuracy: 0.845 - ETA: 38s - loss: 0.8782 - accuracy: 0.844 - ETA: 37s - loss: 0.8775 - accuracy: 0.844 - ETA: 36s - loss: 0.8806 - accuracy: 0.844 - ETA: 35s - loss: 0.8814 - accuracy: 0.844 - ETA: 34s - loss: 0.8796 - accuracy: 0.844 - ETA: 33s - loss: 0.8768 - accuracy: 0.844 - ETA: 32s - loss: 0.8767 - accuracy: 0.844 - ETA: 31s - loss: 0.8751 - accuracy: 0.844 - ETA: 30s - loss: 0.8792 - accuracy: 0.844 - ETA: 29s - loss: 0.8789 - accuracy: 0.844 - ETA: 28s - loss: 0.8756 - accuracy: 0.844 - ETA: 27s - loss: 0.8741 - accuracy: 0.844 - ETA: 26s - loss: 0.8737 - accuracy: 0.844 - ETA: 25s - loss: 0.8755 - accuracy: 0.844 - ETA: 24s - loss: 0.8745 - accuracy: 0.844 - ETA: 23s - loss: 0.8720 - accuracy: 0.844 - ETA: 22s - loss: 0.8764 - accuracy: 0.843 - ETA: 21s - loss: 0.8768 - accuracy: 0.843 - ETA: 20s - loss: 0.8762 - accuracy: 0.843 - ETA: 20s - loss: 0.8739 - accuracy: 0.843 - ETA: 19s - loss: 0.8713 - accuracy: 0.843 - ETA: 18s - loss: 0.8715 - accuracy: 0.843 - ETA: 17s - loss: 0.8688 - accuracy: 0.843 - ETA: 16s - loss: 0.8726 - accuracy: 0.843 - ETA: 15s - loss: 0.8731 - accuracy: 0.843 - ETA: 14s - loss: 0.8745 - accuracy: 0.842 - ETA: 13s - loss: 0.8725 - accuracy: 0.842 - ETA: 12s - loss: 0.8722 - accuracy: 0.842 - ETA: 11s - loss: 0.8732 - accuracy: 0.842 - ETA: 10s - loss: 0.8771 - accuracy: 0.843 - ETA: 9s - loss: 0.8760 - accuracy: 0.843 - ETA: 8s - loss: 0.8748 - accuracy: 0.84 - ETA: 7s - loss: 0.8719 - accuracy: 0.84 - ETA: 6s - loss: 0.8693 - accuracy: 0.84 - ETA: 5s - loss: 0.8665 - accuracy: 0.84 - ETA: 4s - loss: 0.8663 - accuracy: 0.84 - ETA: 3s - loss: 0.8685 - accuracy: 0.84 - ETA: 2s - loss: 0.8669 - accuracy: 0.84 - ETA: 1s - loss: 0.8682 - accuracy: 0.84 - ETA: 0s - loss: 0.8675 - accuracy: 0.84 - 156s 8ms/step - loss: 0.8681 - accuracy: 0.8437 - val_loss: 3.0200 - val_accuracy: 0.7596\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:21 - loss: 1.0515 - accuracy: 0.82 - ETA: 2:27 - loss: 1.4062 - accuracy: 0.83 - ETA: 2:22 - loss: 1.1545 - accuracy: 0.83 - ETA: 2:21 - loss: 1.1989 - accuracy: 0.82 - ETA: 2:18 - loss: 1.1089 - accuracy: 0.83 - ETA: 2:16 - loss: 1.0592 - accuracy: 0.83 - ETA: 2:15 - loss: 1.1089 - accuracy: 0.83 - ETA: 2:13 - loss: 1.0348 - accuracy: 0.83 - ETA: 2:14 - loss: 1.0044 - accuracy: 0.84 - ETA: 2:14 - loss: 1.0087 - accuracy: 0.83 - ETA: 2:13 - loss: 0.9838 - accuracy: 0.83 - ETA: 2:11 - loss: 0.9790 - accuracy: 0.83 - ETA: 2:10 - loss: 0.9673 - accuracy: 0.83 - ETA: 2:09 - loss: 0.9348 - accuracy: 0.84 - ETA: 2:08 - loss: 0.9234 - accuracy: 0.84 - ETA: 2:07 - loss: 0.9630 - accuracy: 0.84 - ETA: 2:06 - loss: 0.9693 - accuracy: 0.84 - ETA: 2:05 - loss: 0.9727 - accuracy: 0.84 - ETA: 2:04 - loss: 0.9651 - accuracy: 0.84 - ETA: 2:03 - loss: 0.9447 - accuracy: 0.84 - ETA: 2:02 - loss: 0.9774 - accuracy: 0.84 - ETA: 2:01 - loss: 0.9868 - accuracy: 0.84 - ETA: 2:00 - loss: 0.9698 - accuracy: 0.84 - ETA: 2:00 - loss: 0.9484 - accuracy: 0.84 - ETA: 1:59 - loss: 0.9379 - accuracy: 0.84 - ETA: 1:58 - loss: 0.9420 - accuracy: 0.84 - ETA: 1:58 - loss: 0.9301 - accuracy: 0.84 - ETA: 1:57 - loss: 0.9444 - accuracy: 0.84 - ETA: 1:56 - loss: 0.9317 - accuracy: 0.84 - ETA: 1:55 - loss: 0.9356 - accuracy: 0.84 - ETA: 1:54 - loss: 0.9434 - accuracy: 0.84 - ETA: 1:53 - loss: 0.9314 - accuracy: 0.84 - ETA: 1:52 - loss: 0.9249 - accuracy: 0.84 - ETA: 1:51 - loss: 0.9184 - accuracy: 0.84 - ETA: 1:49 - loss: 0.9141 - accuracy: 0.84 - ETA: 1:49 - loss: 0.9207 - accuracy: 0.84 - ETA: 1:48 - loss: 0.9238 - accuracy: 0.84 - ETA: 1:47 - loss: 0.9272 - accuracy: 0.84 - ETA: 1:46 - loss: 0.9228 - accuracy: 0.84 - ETA: 1:45 - loss: 0.9360 - accuracy: 0.84 - ETA: 1:44 - loss: 0.9488 - accuracy: 0.84 - ETA: 1:43 - loss: 0.9635 - accuracy: 0.84 - ETA: 1:42 - loss: 0.9599 - accuracy: 0.84 - ETA: 1:41 - loss: 0.9523 - accuracy: 0.84 - ETA: 1:40 - loss: 0.9494 - accuracy: 0.84 - ETA: 1:39 - loss: 0.9392 - accuracy: 0.84 - ETA: 1:38 - loss: 0.9275 - accuracy: 0.84 - ETA: 1:37 - loss: 0.9264 - accuracy: 0.84 - ETA: 1:36 - loss: 0.9171 - accuracy: 0.84 - ETA: 1:36 - loss: 0.9118 - accuracy: 0.84 - ETA: 1:35 - loss: 0.9094 - accuracy: 0.84 - ETA: 1:34 - loss: 0.9063 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8997 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8970 - accuracy: 0.84 - ETA: 1:31 - loss: 0.9044 - accuracy: 0.84 - ETA: 1:30 - loss: 0.9064 - accuracy: 0.84 - ETA: 1:29 - loss: 0.9098 - accuracy: 0.84 - ETA: 1:28 - loss: 0.9074 - accuracy: 0.84 - ETA: 1:27 - loss: 0.9161 - accuracy: 0.84 - ETA: 1:26 - loss: 0.9143 - accuracy: 0.84 - ETA: 1:25 - loss: 0.9103 - accuracy: 0.84 - ETA: 1:24 - loss: 0.9015 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8957 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8927 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8943 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8951 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8911 - accuracy: 0.84 - ETA: 1:19 - loss: 0.8888 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8866 - accuracy: 0.84 - ETA: 1:17 - loss: 0.8836 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8850 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8821 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8804 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8799 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8893 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8895 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8825 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8806 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8801 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8827 - accuracy: 0.84 - ETA: 1:06 - loss: 0.8801 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8816 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8838 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8836 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8790 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8855 - accuracy: 0.84 - ETA: 1:01 - loss: 0.8852 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8847 - accuracy: 0.84 - ETA: 59s - loss: 0.8939 - accuracy: 0.8454 - ETA: 58s - loss: 0.8940 - accuracy: 0.845 - ETA: 57s - loss: 0.8967 - accuracy: 0.845 - ETA: 56s - loss: 0.8954 - accuracy: 0.845 - ETA: 55s - loss: 0.8921 - accuracy: 0.845 - ETA: 54s - loss: 0.8874 - accuracy: 0.845 - ETA: 53s - loss: 0.8920 - accuracy: 0.846 - ETA: 52s - loss: 0.8911 - accuracy: 0.846 - ETA: 51s - loss: 0.8900 - accuracy: 0.845 - ETA: 50s - loss: 0.8899 - accuracy: 0.845 - ETA: 49s - loss: 0.8885 - accuracy: 0.845 - ETA: 48s - loss: 0.8906 - accuracy: 0.845 - ETA: 47s - loss: 0.8894 - accuracy: 0.845 - ETA: 46s - loss: 0.8891 - accuracy: 0.845 - ETA: 45s - loss: 0.8913 - accuracy: 0.845 - ETA: 44s - loss: 0.8941 - accuracy: 0.845 - ETA: 43s - loss: 0.8895 - accuracy: 0.846 - ETA: 42s - loss: 0.8882 - accuracy: 0.846 - ETA: 41s - loss: 0.8883 - accuracy: 0.845 - ETA: 41s - loss: 0.8877 - accuracy: 0.845 - ETA: 40s - loss: 0.8880 - accuracy: 0.846 - ETA: 39s - loss: 0.8884 - accuracy: 0.845 - ETA: 38s - loss: 0.8893 - accuracy: 0.845 - ETA: 37s - loss: 0.8901 - accuracy: 0.845 - ETA: 36s - loss: 0.8893 - accuracy: 0.845 - ETA: 35s - loss: 0.8929 - accuracy: 0.845 - ETA: 34s - loss: 0.8978 - accuracy: 0.845 - ETA: 33s - loss: 0.8973 - accuracy: 0.845 - ETA: 32s - loss: 0.8975 - accuracy: 0.845 - ETA: 31s - loss: 0.8974 - accuracy: 0.844 - ETA: 30s - loss: 0.9013 - accuracy: 0.845 - ETA: 29s - loss: 0.9007 - accuracy: 0.844 - ETA: 28s - loss: 0.8978 - accuracy: 0.845 - ETA: 27s - loss: 0.8958 - accuracy: 0.845 - ETA: 26s - loss: 0.8967 - accuracy: 0.844 - ETA: 25s - loss: 0.8975 - accuracy: 0.844 - ETA: 24s - loss: 0.8973 - accuracy: 0.844 - ETA: 23s - loss: 0.8985 - accuracy: 0.844 - ETA: 22s - loss: 0.9007 - accuracy: 0.844 - ETA: 21s - loss: 0.9017 - accuracy: 0.844 - ETA: 20s - loss: 0.8991 - accuracy: 0.844 - ETA: 20s - loss: 0.8994 - accuracy: 0.844 - ETA: 19s - loss: 0.8974 - accuracy: 0.844 - ETA: 18s - loss: 0.8943 - accuracy: 0.844 - ETA: 17s - loss: 0.8915 - accuracy: 0.844 - ETA: 16s - loss: 0.8940 - accuracy: 0.844 - ETA: 15s - loss: 0.8949 - accuracy: 0.844 - ETA: 14s - loss: 0.8941 - accuracy: 0.844 - ETA: 13s - loss: 0.8928 - accuracy: 0.844 - ETA: 12s - loss: 0.8899 - accuracy: 0.844 - ETA: 11s - loss: 0.8895 - accuracy: 0.844 - ETA: 10s - loss: 0.8877 - accuracy: 0.844 - ETA: 9s - loss: 0.8870 - accuracy: 0.845 - ETA: 8s - loss: 0.8851 - accuracy: 0.84 - ETA: 7s - loss: 0.8832 - accuracy: 0.84 - ETA: 6s - loss: 0.8816 - accuracy: 0.84 - ETA: 5s - loss: 0.8820 - accuracy: 0.84 - ETA: 4s - loss: 0.8841 - accuracy: 0.84 - ETA: 3s - loss: 0.8813 - accuracy: 0.84 - ETA: 2s - loss: 0.8804 - accuracy: 0.84 - ETA: 1s - loss: 0.8802 - accuracy: 0.84 - ETA: 0s - loss: 0.8785 - accuracy: 0.84 - 156s 8ms/step - loss: 0.8786 - accuracy: 0.8451 - val_loss: 2.9736 - val_accuracy: 0.7587\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:38 - loss: 0.7259 - accuracy: 0.85 - ETA: 2:30 - loss: 1.0143 - accuracy: 0.84 - ETA: 2:24 - loss: 1.0242 - accuracy: 0.82 - ETA: 2:23 - loss: 1.0100 - accuracy: 0.82 - ETA: 2:22 - loss: 0.9610 - accuracy: 0.82 - ETA: 2:20 - loss: 0.8901 - accuracy: 0.83 - ETA: 2:20 - loss: 0.8727 - accuracy: 0.83 - ETA: 2:21 - loss: 0.8350 - accuracy: 0.84 - ETA: 2:20 - loss: 0.8483 - accuracy: 0.84 - ETA: 2:19 - loss: 0.8294 - accuracy: 0.85 - ETA: 2:19 - loss: 0.8198 - accuracy: 0.84 - ETA: 2:18 - loss: 0.8265 - accuracy: 0.84 - ETA: 2:17 - loss: 0.8169 - accuracy: 0.84 - ETA: 2:17 - loss: 0.8276 - accuracy: 0.84 - ETA: 2:16 - loss: 0.8059 - accuracy: 0.84 - ETA: 2:16 - loss: 0.7951 - accuracy: 0.85 - ETA: 2:15 - loss: 0.7988 - accuracy: 0.85 - ETA: 2:14 - loss: 0.7901 - accuracy: 0.85 - ETA: 2:13 - loss: 0.7903 - accuracy: 0.84 - ETA: 2:12 - loss: 0.7789 - accuracy: 0.84 - ETA: 2:12 - loss: 0.8020 - accuracy: 0.84 - ETA: 2:11 - loss: 0.8010 - accuracy: 0.84 - ETA: 2:10 - loss: 0.7891 - accuracy: 0.84 - ETA: 2:10 - loss: 0.7899 - accuracy: 0.84 - ETA: 2:09 - loss: 0.7695 - accuracy: 0.84 - ETA: 2:08 - loss: 0.7687 - accuracy: 0.84 - ETA: 2:07 - loss: 0.7860 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8142 - accuracy: 0.84 - ETA: 2:06 - loss: 0.8238 - accuracy: 0.84 - ETA: 2:05 - loss: 0.8403 - accuracy: 0.84 - ETA: 2:05 - loss: 0.8437 - accuracy: 0.84 - ETA: 2:04 - loss: 0.8371 - accuracy: 0.84 - ETA: 2:03 - loss: 0.8454 - accuracy: 0.84 - ETA: 2:02 - loss: 0.8347 - accuracy: 0.84 - ETA: 2:01 - loss: 0.8313 - accuracy: 0.84 - ETA: 2:00 - loss: 0.8340 - accuracy: 0.84 - ETA: 1:59 - loss: 0.8236 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8178 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8250 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8348 - accuracy: 0.84 - ETA: 1:55 - loss: 0.8303 - accuracy: 0.84 - ETA: 1:54 - loss: 0.8276 - accuracy: 0.84 - ETA: 1:53 - loss: 0.8623 - accuracy: 0.84 - ETA: 1:52 - loss: 0.8688 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8629 - accuracy: 0.84 - ETA: 1:50 - loss: 0.8577 - accuracy: 0.84 - ETA: 1:49 - loss: 0.8624 - accuracy: 0.84 - ETA: 1:48 - loss: 0.8822 - accuracy: 0.84 - ETA: 1:47 - loss: 0.8768 - accuracy: 0.84 - ETA: 1:46 - loss: 0.8769 - accuracy: 0.84 - ETA: 1:45 - loss: 0.8778 - accuracy: 0.84 - ETA: 1:44 - loss: 0.8880 - accuracy: 0.84 - ETA: 1:43 - loss: 0.8841 - accuracy: 0.84 - ETA: 1:42 - loss: 0.8929 - accuracy: 0.84 - ETA: 1:41 - loss: 0.8892 - accuracy: 0.84 - ETA: 1:40 - loss: 0.8833 - accuracy: 0.84 - ETA: 1:39 - loss: 0.8863 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8826 - accuracy: 0.84 - ETA: 1:37 - loss: 0.8770 - accuracy: 0.84 - ETA: 1:36 - loss: 0.8751 - accuracy: 0.84 - ETA: 1:34 - loss: 0.8741 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8770 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8777 - accuracy: 0.84 - ETA: 1:31 - loss: 0.8756 - accuracy: 0.84 - ETA: 1:30 - loss: 0.8745 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8686 - accuracy: 0.84 - ETA: 1:28 - loss: 0.8741 - accuracy: 0.84 - ETA: 1:27 - loss: 0.8678 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8756 - accuracy: 0.84 - ETA: 1:25 - loss: 0.8761 - accuracy: 0.84 - ETA: 1:24 - loss: 0.8753 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8724 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8784 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8757 - accuracy: 0.84 - ETA: 1:19 - loss: 0.8757 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8744 - accuracy: 0.84 - ETA: 1:17 - loss: 0.8747 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8711 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8718 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8693 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8669 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8634 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8615 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8577 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8556 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8564 - accuracy: 0.84 - ETA: 1:06 - loss: 0.8590 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8631 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8631 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8619 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8629 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8596 - accuracy: 0.84 - ETA: 59s - loss: 0.8656 - accuracy: 0.8479 - ETA: 58s - loss: 0.8661 - accuracy: 0.847 - ETA: 57s - loss: 0.8643 - accuracy: 0.847 - ETA: 56s - loss: 0.8669 - accuracy: 0.847 - ETA: 55s - loss: 0.8669 - accuracy: 0.847 - ETA: 54s - loss: 0.8718 - accuracy: 0.847 - ETA: 53s - loss: 0.8689 - accuracy: 0.847 - ETA: 52s - loss: 0.8643 - accuracy: 0.847 - ETA: 51s - loss: 0.8678 - accuracy: 0.847 - ETA: 50s - loss: 0.8693 - accuracy: 0.846 - ETA: 49s - loss: 0.8721 - accuracy: 0.846 - ETA: 48s - loss: 0.8697 - accuracy: 0.846 - ETA: 47s - loss: 0.8678 - accuracy: 0.846 - ETA: 46s - loss: 0.8694 - accuracy: 0.845 - ETA: 44s - loss: 0.8700 - accuracy: 0.845 - ETA: 43s - loss: 0.8655 - accuracy: 0.846 - ETA: 42s - loss: 0.8635 - accuracy: 0.846 - ETA: 41s - loss: 0.8652 - accuracy: 0.846 - ETA: 40s - loss: 0.8713 - accuracy: 0.846 - ETA: 39s - loss: 0.8752 - accuracy: 0.846 - ETA: 38s - loss: 0.8717 - accuracy: 0.846 - ETA: 37s - loss: 0.8723 - accuracy: 0.846 - ETA: 36s - loss: 0.8724 - accuracy: 0.846 - ETA: 35s - loss: 0.8756 - accuracy: 0.846 - ETA: 34s - loss: 0.8751 - accuracy: 0.846 - ETA: 33s - loss: 0.8767 - accuracy: 0.845 - ETA: 32s - loss: 0.8769 - accuracy: 0.845 - ETA: 31s - loss: 0.8751 - accuracy: 0.845 - ETA: 30s - loss: 0.8758 - accuracy: 0.845 - ETA: 29s - loss: 0.8739 - accuracy: 0.845 - ETA: 28s - loss: 0.8733 - accuracy: 0.845 - ETA: 27s - loss: 0.8741 - accuracy: 0.845 - ETA: 26s - loss: 0.8714 - accuracy: 0.845 - ETA: 25s - loss: 0.8700 - accuracy: 0.845 - ETA: 24s - loss: 0.8670 - accuracy: 0.845 - ETA: 23s - loss: 0.8661 - accuracy: 0.845 - ETA: 22s - loss: 0.8643 - accuracy: 0.845 - ETA: 21s - loss: 0.8639 - accuracy: 0.845 - ETA: 20s - loss: 0.8620 - accuracy: 0.845 - ETA: 19s - loss: 0.8634 - accuracy: 0.845 - ETA: 18s - loss: 0.8640 - accuracy: 0.845 - ETA: 17s - loss: 0.8634 - accuracy: 0.845 - ETA: 16s - loss: 0.8612 - accuracy: 0.845 - ETA: 15s - loss: 0.8628 - accuracy: 0.845 - ETA: 14s - loss: 0.8598 - accuracy: 0.846 - ETA: 12s - loss: 0.8577 - accuracy: 0.846 - ETA: 11s - loss: 0.8576 - accuracy: 0.846 - ETA: 10s - loss: 0.8598 - accuracy: 0.845 - ETA: 9s - loss: 0.8611 - accuracy: 0.845 - ETA: 8s - loss: 0.8616 - accuracy: 0.84 - ETA: 7s - loss: 0.8656 - accuracy: 0.84 - ETA: 6s - loss: 0.8695 - accuracy: 0.84 - ETA: 5s - loss: 0.8683 - accuracy: 0.84 - ETA: 4s - loss: 0.8690 - accuracy: 0.84 - ETA: 3s - loss: 0.8694 - accuracy: 0.84 - ETA: 2s - loss: 0.8703 - accuracy: 0.84 - ETA: 1s - loss: 0.8699 - accuracy: 0.84 - ETA: 0s - loss: 0.8670 - accuracy: 0.84 - 164s 8ms/step - loss: 0.8663 - accuracy: 0.8441 - val_loss: 2.9078 - val_accuracy: 0.7604\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:41 - loss: 0.9077 - accuracy: 0.87 - ETA: 2:29 - loss: 0.8262 - accuracy: 0.87 - ETA: 2:28 - loss: 0.9422 - accuracy: 0.84 - ETA: 2:28 - loss: 1.0021 - accuracy: 0.83 - ETA: 2:24 - loss: 0.9905 - accuracy: 0.83 - ETA: 2:23 - loss: 0.9417 - accuracy: 0.83 - ETA: 2:21 - loss: 0.9316 - accuracy: 0.83 - ETA: 2:18 - loss: 0.9244 - accuracy: 0.83 - ETA: 2:18 - loss: 0.8999 - accuracy: 0.83 - ETA: 2:18 - loss: 0.8956 - accuracy: 0.83 - ETA: 2:17 - loss: 0.9118 - accuracy: 0.83 - ETA: 2:16 - loss: 0.9508 - accuracy: 0.83 - ETA: 2:15 - loss: 0.9169 - accuracy: 0.83 - ETA: 2:14 - loss: 0.8867 - accuracy: 0.83 - ETA: 2:12 - loss: 0.8945 - accuracy: 0.84 - ETA: 2:11 - loss: 0.9439 - accuracy: 0.83 - ETA: 2:10 - loss: 0.9265 - accuracy: 0.84 - ETA: 2:09 - loss: 0.9214 - accuracy: 0.83 - ETA: 2:08 - loss: 0.9272 - accuracy: 0.84 - ETA: 2:07 - loss: 0.9182 - accuracy: 0.84 - ETA: 2:06 - loss: 0.9193 - accuracy: 0.84 - ETA: 2:05 - loss: 0.9163 - accuracy: 0.84 - ETA: 2:03 - loss: 0.9010 - accuracy: 0.84 - ETA: 2:02 - loss: 0.8858 - accuracy: 0.84 - ETA: 2:01 - loss: 0.8798 - accuracy: 0.84 - ETA: 2:00 - loss: 0.9000 - accuracy: 0.84 - ETA: 2:00 - loss: 0.8941 - accuracy: 0.84 - ETA: 1:59 - loss: 0.8990 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8984 - accuracy: 0.83 - ETA: 1:57 - loss: 0.8811 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8739 - accuracy: 0.84 - ETA: 1:55 - loss: 0.8828 - accuracy: 0.84 - ETA: 1:54 - loss: 0.8910 - accuracy: 0.84 - ETA: 1:53 - loss: 0.8886 - accuracy: 0.84 - ETA: 1:52 - loss: 0.8871 - accuracy: 0.84 - ETA: 1:50 - loss: 0.8770 - accuracy: 0.84 - ETA: 1:49 - loss: 0.8790 - accuracy: 0.84 - ETA: 1:48 - loss: 0.8747 - accuracy: 0.84 - ETA: 1:47 - loss: 0.8666 - accuracy: 0.84 - ETA: 1:46 - loss: 0.8595 - accuracy: 0.84 - ETA: 1:45 - loss: 0.8616 - accuracy: 0.84 - ETA: 1:44 - loss: 0.8671 - accuracy: 0.84 - ETA: 1:43 - loss: 0.8671 - accuracy: 0.84 - ETA: 1:43 - loss: 0.8631 - accuracy: 0.84 - ETA: 1:42 - loss: 0.8624 - accuracy: 0.84 - ETA: 1:41 - loss: 0.8652 - accuracy: 0.84 - ETA: 1:40 - loss: 0.8576 - accuracy: 0.84 - ETA: 1:39 - loss: 0.8531 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8626 - accuracy: 0.84 - ETA: 1:37 - loss: 0.8601 - accuracy: 0.84 - ETA: 1:36 - loss: 0.8555 - accuracy: 0.84 - ETA: 1:35 - loss: 0.8492 - accuracy: 0.84 - ETA: 1:34 - loss: 0.8520 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8568 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8617 - accuracy: 0.84 - ETA: 1:31 - loss: 0.8549 - accuracy: 0.84 - ETA: 1:30 - loss: 0.8527 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8532 - accuracy: 0.84 - ETA: 1:28 - loss: 0.8493 - accuracy: 0.84 - ETA: 1:27 - loss: 0.8501 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8516 - accuracy: 0.84 - ETA: 1:25 - loss: 0.8522 - accuracy: 0.84 - ETA: 1:24 - loss: 0.8483 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8609 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8590 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8589 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8624 - accuracy: 0.84 - ETA: 1:19 - loss: 0.8631 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8661 - accuracy: 0.84 - ETA: 1:17 - loss: 0.8647 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8619 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8678 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8640 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8660 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8638 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8612 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8623 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8614 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8601 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8629 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8627 - accuracy: 0.84 - ETA: 1:06 - loss: 0.8627 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8612 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8622 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8584 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8518 - accuracy: 0.84 - ETA: 1:01 - loss: 0.8508 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8548 - accuracy: 0.84 - ETA: 59s - loss: 0.8560 - accuracy: 0.8444 - ETA: 58s - loss: 0.8563 - accuracy: 0.843 - ETA: 57s - loss: 0.8508 - accuracy: 0.844 - ETA: 56s - loss: 0.8531 - accuracy: 0.843 - ETA: 55s - loss: 0.8523 - accuracy: 0.844 - ETA: 54s - loss: 0.8494 - accuracy: 0.844 - ETA: 53s - loss: 0.8538 - accuracy: 0.843 - ETA: 52s - loss: 0.8571 - accuracy: 0.843 - ETA: 51s - loss: 0.8557 - accuracy: 0.843 - ETA: 50s - loss: 0.8577 - accuracy: 0.843 - ETA: 49s - loss: 0.8597 - accuracy: 0.843 - ETA: 48s - loss: 0.8666 - accuracy: 0.842 - ETA: 48s - loss: 0.8665 - accuracy: 0.842 - ETA: 47s - loss: 0.8671 - accuracy: 0.842 - ETA: 46s - loss: 0.8656 - accuracy: 0.842 - ETA: 45s - loss: 0.8646 - accuracy: 0.842 - ETA: 44s - loss: 0.8687 - accuracy: 0.842 - ETA: 43s - loss: 0.8685 - accuracy: 0.842 - ETA: 42s - loss: 0.8812 - accuracy: 0.841 - ETA: 41s - loss: 0.8779 - accuracy: 0.842 - ETA: 40s - loss: 0.8748 - accuracy: 0.842 - ETA: 39s - loss: 0.8729 - accuracy: 0.842 - ETA: 38s - loss: 0.8747 - accuracy: 0.842 - ETA: 37s - loss: 0.8759 - accuracy: 0.842 - ETA: 36s - loss: 0.8751 - accuracy: 0.842 - ETA: 35s - loss: 0.8742 - accuracy: 0.842 - ETA: 34s - loss: 0.8783 - accuracy: 0.842 - ETA: 33s - loss: 0.8769 - accuracy: 0.842 - ETA: 32s - loss: 0.8744 - accuracy: 0.842 - ETA: 31s - loss: 0.8723 - accuracy: 0.842 - ETA: 30s - loss: 0.8714 - accuracy: 0.842 - ETA: 29s - loss: 0.8716 - accuracy: 0.842 - ETA: 28s - loss: 0.8692 - accuracy: 0.842 - ETA: 27s - loss: 0.8759 - accuracy: 0.842 - ETA: 26s - loss: 0.8760 - accuracy: 0.842 - ETA: 25s - loss: 0.8747 - accuracy: 0.842 - ETA: 24s - loss: 0.8737 - accuracy: 0.842 - ETA: 23s - loss: 0.8711 - accuracy: 0.843 - ETA: 22s - loss: 0.8706 - accuracy: 0.843 - ETA: 22s - loss: 0.8753 - accuracy: 0.842 - ETA: 21s - loss: 0.8738 - accuracy: 0.842 - ETA: 20s - loss: 0.8759 - accuracy: 0.842 - ETA: 19s - loss: 0.8762 - accuracy: 0.842 - ETA: 18s - loss: 0.8751 - accuracy: 0.841 - ETA: 17s - loss: 0.8722 - accuracy: 0.842 - ETA: 16s - loss: 0.8698 - accuracy: 0.842 - ETA: 15s - loss: 0.8679 - accuracy: 0.842 - ETA: 14s - loss: 0.8682 - accuracy: 0.842 - ETA: 13s - loss: 0.8662 - accuracy: 0.842 - ETA: 12s - loss: 0.8665 - accuracy: 0.842 - ETA: 11s - loss: 0.8656 - accuracy: 0.843 - ETA: 10s - loss: 0.8690 - accuracy: 0.843 - ETA: 9s - loss: 0.8684 - accuracy: 0.843 - ETA: 8s - loss: 0.8656 - accuracy: 0.84 - ETA: 7s - loss: 0.8650 - accuracy: 0.84 - ETA: 6s - loss: 0.8641 - accuracy: 0.84 - ETA: 5s - loss: 0.8625 - accuracy: 0.84 - ETA: 4s - loss: 0.8614 - accuracy: 0.84 - ETA: 3s - loss: 0.8620 - accuracy: 0.84 - ETA: 2s - loss: 0.8615 - accuracy: 0.84 - ETA: 1s - loss: 0.8597 - accuracy: 0.84 - ETA: 0s - loss: 0.8588 - accuracy: 0.84 - 157s 8ms/step - loss: 0.8575 - accuracy: 0.8436 - val_loss: 3.1813 - val_accuracy: 0.7616\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:19 - loss: 0.3914 - accuracy: 0.88 - ETA: 2:21 - loss: 0.6040 - accuracy: 0.85 - ETA: 2:19 - loss: 0.6810 - accuracy: 0.84 - ETA: 2:17 - loss: 0.7185 - accuracy: 0.84 - ETA: 2:14 - loss: 0.6778 - accuracy: 0.85 - ETA: 2:13 - loss: 0.7144 - accuracy: 0.85 - ETA: 2:12 - loss: 0.7384 - accuracy: 0.85 - ETA: 2:11 - loss: 0.7302 - accuracy: 0.85 - ETA: 2:10 - loss: 0.7149 - accuracy: 0.85 - ETA: 2:09 - loss: 0.7053 - accuracy: 0.85 - ETA: 2:09 - loss: 0.7667 - accuracy: 0.85 - ETA: 2:08 - loss: 0.7750 - accuracy: 0.85 - ETA: 2:07 - loss: 0.7654 - accuracy: 0.85 - ETA: 2:07 - loss: 0.8294 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8242 - accuracy: 0.85 - ETA: 2:06 - loss: 0.8266 - accuracy: 0.84 - ETA: 2:05 - loss: 0.8331 - accuracy: 0.84 - ETA: 2:04 - loss: 0.8166 - accuracy: 0.85 - ETA: 2:03 - loss: 0.8238 - accuracy: 0.84 - ETA: 2:02 - loss: 0.8248 - accuracy: 0.84 - ETA: 2:01 - loss: 0.8423 - accuracy: 0.84 - ETA: 2:01 - loss: 0.8737 - accuracy: 0.84 - ETA: 2:00 - loss: 0.8720 - accuracy: 0.84 - ETA: 1:59 - loss: 0.8788 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8794 - accuracy: 0.84 - ETA: 1:57 - loss: 0.8836 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8792 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8817 - accuracy: 0.84 - ETA: 1:54 - loss: 0.8837 - accuracy: 0.84 - ETA: 1:54 - loss: 0.8742 - accuracy: 0.84 - ETA: 1:53 - loss: 0.8780 - accuracy: 0.84 - ETA: 1:52 - loss: 0.8935 - accuracy: 0.83 - ETA: 1:51 - loss: 0.8834 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8779 - accuracy: 0.84 - ETA: 1:49 - loss: 0.8772 - accuracy: 0.84 - ETA: 1:49 - loss: 0.8864 - accuracy: 0.84 - ETA: 1:48 - loss: 0.8808 - accuracy: 0.84 - ETA: 1:46 - loss: 0.8880 - accuracy: 0.84 - ETA: 1:45 - loss: 0.8839 - accuracy: 0.84 - ETA: 1:44 - loss: 0.8805 - accuracy: 0.84 - ETA: 1:43 - loss: 0.8767 - accuracy: 0.84 - ETA: 1:42 - loss: 0.8813 - accuracy: 0.84 - ETA: 1:42 - loss: 0.8810 - accuracy: 0.84 - ETA: 1:41 - loss: 0.8856 - accuracy: 0.84 - ETA: 1:40 - loss: 0.8828 - accuracy: 0.84 - ETA: 1:39 - loss: 0.8806 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8874 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8830 - accuracy: 0.84 - ETA: 1:37 - loss: 0.8793 - accuracy: 0.84 - ETA: 1:36 - loss: 0.8754 - accuracy: 0.84 - ETA: 1:35 - loss: 0.8752 - accuracy: 0.84 - ETA: 1:34 - loss: 0.8761 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8768 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8720 - accuracy: 0.84 - ETA: 1:31 - loss: 0.8706 - accuracy: 0.84 - ETA: 1:30 - loss: 0.8783 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8780 - accuracy: 0.84 - ETA: 1:28 - loss: 0.8754 - accuracy: 0.84 - ETA: 1:27 - loss: 0.8709 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8766 - accuracy: 0.84 - ETA: 1:25 - loss: 0.8722 - accuracy: 0.84 - ETA: 1:24 - loss: 0.8703 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8774 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8709 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8686 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8638 - accuracy: 0.84 - ETA: 1:19 - loss: 0.8666 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8619 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8624 - accuracy: 0.84 - ETA: 1:17 - loss: 0.8572 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8528 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8507 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8521 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8528 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8464 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8428 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8492 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8543 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8535 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8521 - accuracy: 0.84 - ETA: 1:06 - loss: 0.8519 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8575 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8561 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8585 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8564 - accuracy: 0.84 - ETA: 1:01 - loss: 0.8547 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8589 - accuracy: 0.84 - ETA: 59s - loss: 0.8570 - accuracy: 0.8441 - ETA: 59s - loss: 0.8559 - accuracy: 0.844 - ETA: 58s - loss: 0.8571 - accuracy: 0.844 - ETA: 57s - loss: 0.8546 - accuracy: 0.844 - ETA: 56s - loss: 0.8524 - accuracy: 0.844 - ETA: 55s - loss: 0.8499 - accuracy: 0.844 - ETA: 54s - loss: 0.8480 - accuracy: 0.844 - ETA: 53s - loss: 0.8544 - accuracy: 0.844 - ETA: 52s - loss: 0.8592 - accuracy: 0.843 - ETA: 51s - loss: 0.8582 - accuracy: 0.843 - ETA: 50s - loss: 0.8598 - accuracy: 0.843 - ETA: 49s - loss: 0.8630 - accuracy: 0.842 - ETA: 48s - loss: 0.8611 - accuracy: 0.842 - ETA: 47s - loss: 0.8586 - accuracy: 0.842 - ETA: 46s - loss: 0.8585 - accuracy: 0.842 - ETA: 45s - loss: 0.8573 - accuracy: 0.843 - ETA: 44s - loss: 0.8575 - accuracy: 0.843 - ETA: 43s - loss: 0.8584 - accuracy: 0.843 - ETA: 42s - loss: 0.8568 - accuracy: 0.844 - ETA: 41s - loss: 0.8547 - accuracy: 0.844 - ETA: 40s - loss: 0.8525 - accuracy: 0.844 - ETA: 39s - loss: 0.8562 - accuracy: 0.844 - ETA: 38s - loss: 0.8567 - accuracy: 0.843 - ETA: 38s - loss: 0.8537 - accuracy: 0.844 - ETA: 37s - loss: 0.8547 - accuracy: 0.844 - ETA: 36s - loss: 0.8520 - accuracy: 0.844 - ETA: 35s - loss: 0.8510 - accuracy: 0.844 - ETA: 34s - loss: 0.8475 - accuracy: 0.845 - ETA: 33s - loss: 0.8517 - accuracy: 0.845 - ETA: 32s - loss: 0.8533 - accuracy: 0.845 - ETA: 31s - loss: 0.8519 - accuracy: 0.845 - ETA: 30s - loss: 0.8526 - accuracy: 0.845 - ETA: 29s - loss: 0.8522 - accuracy: 0.844 - ETA: 28s - loss: 0.8495 - accuracy: 0.845 - ETA: 27s - loss: 0.8501 - accuracy: 0.845 - ETA: 26s - loss: 0.8496 - accuracy: 0.845 - ETA: 25s - loss: 0.8466 - accuracy: 0.845 - ETA: 24s - loss: 0.8475 - accuracy: 0.845 - ETA: 23s - loss: 0.8470 - accuracy: 0.845 - ETA: 22s - loss: 0.8467 - accuracy: 0.845 - ETA: 21s - loss: 0.8473 - accuracy: 0.845 - ETA: 20s - loss: 0.8447 - accuracy: 0.845 - ETA: 19s - loss: 0.8459 - accuracy: 0.845 - ETA: 19s - loss: 0.8446 - accuracy: 0.845 - ETA: 18s - loss: 0.8461 - accuracy: 0.845 - ETA: 17s - loss: 0.8435 - accuracy: 0.845 - ETA: 16s - loss: 0.8417 - accuracy: 0.845 - ETA: 15s - loss: 0.8421 - accuracy: 0.845 - ETA: 14s - loss: 0.8407 - accuracy: 0.845 - ETA: 13s - loss: 0.8410 - accuracy: 0.845 - ETA: 12s - loss: 0.8405 - accuracy: 0.846 - ETA: 11s - loss: 0.8386 - accuracy: 0.846 - ETA: 10s - loss: 0.8380 - accuracy: 0.846 - ETA: 9s - loss: 0.8371 - accuracy: 0.846 - ETA: 8s - loss: 0.8385 - accuracy: 0.84 - ETA: 7s - loss: 0.8381 - accuracy: 0.84 - ETA: 6s - loss: 0.8386 - accuracy: 0.84 - ETA: 5s - loss: 0.8433 - accuracy: 0.84 - ETA: 4s - loss: 0.8431 - accuracy: 0.84 - ETA: 3s - loss: 0.8424 - accuracy: 0.84 - ETA: 2s - loss: 0.8425 - accuracy: 0.84 - ETA: 1s - loss: 0.8467 - accuracy: 0.84 - ETA: 0s - loss: 0.8470 - accuracy: 0.84 - 156s 8ms/step - loss: 0.8467 - accuracy: 0.8463 - val_loss: 3.2814 - val_accuracy: 0.7606\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:23 - loss: 0.7027 - accuracy: 0.84 - ETA: 2:24 - loss: 1.0102 - accuracy: 0.85 - ETA: 2:24 - loss: 0.8693 - accuracy: 0.85 - ETA: 2:22 - loss: 0.9538 - accuracy: 0.84 - ETA: 2:20 - loss: 0.9627 - accuracy: 0.85 - ETA: 2:19 - loss: 0.9631 - accuracy: 0.85 - ETA: 2:18 - loss: 0.9345 - accuracy: 0.84 - ETA: 2:17 - loss: 1.0076 - accuracy: 0.84 - ETA: 2:16 - loss: 0.9869 - accuracy: 0.83 - ETA: 2:15 - loss: 0.9433 - accuracy: 0.84 - ETA: 2:14 - loss: 0.9441 - accuracy: 0.83 - ETA: 2:13 - loss: 0.9135 - accuracy: 0.83 - ETA: 2:12 - loss: 0.9125 - accuracy: 0.83 - ETA: 2:10 - loss: 0.8772 - accuracy: 0.84 - ETA: 2:09 - loss: 0.8778 - accuracy: 0.84 - ETA: 2:08 - loss: 0.9002 - accuracy: 0.84 - ETA: 2:08 - loss: 0.9003 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8702 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8783 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8920 - accuracy: 0.84 - ETA: 2:06 - loss: 0.8914 - accuracy: 0.84 - ETA: 2:05 - loss: 0.8992 - accuracy: 0.84 - ETA: 2:04 - loss: 0.9036 - accuracy: 0.84 - ETA: 2:02 - loss: 0.9028 - accuracy: 0.84 - ETA: 2:02 - loss: 0.8939 - accuracy: 0.84 - ETA: 2:00 - loss: 0.8814 - accuracy: 0.84 - ETA: 1:59 - loss: 0.8672 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8739 - accuracy: 0.84 - ETA: 1:57 - loss: 0.8634 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8666 - accuracy: 0.84 - ETA: 1:55 - loss: 0.8607 - accuracy: 0.84 - ETA: 1:54 - loss: 0.8616 - accuracy: 0.84 - ETA: 1:53 - loss: 0.8642 - accuracy: 0.84 - ETA: 1:52 - loss: 0.8583 - accuracy: 0.84 - ETA: 1:52 - loss: 0.8576 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8583 - accuracy: 0.84 - ETA: 1:50 - loss: 0.8601 - accuracy: 0.84 - ETA: 1:49 - loss: 0.8711 - accuracy: 0.84 - ETA: 1:48 - loss: 0.8694 - accuracy: 0.84 - ETA: 1:47 - loss: 0.8607 - accuracy: 0.84 - ETA: 1:46 - loss: 0.8643 - accuracy: 0.84 - ETA: 1:45 - loss: 0.8584 - accuracy: 0.84 - ETA: 1:44 - loss: 0.8530 - accuracy: 0.84 - ETA: 1:43 - loss: 0.8533 - accuracy: 0.84 - ETA: 1:42 - loss: 0.8561 - accuracy: 0.84 - ETA: 1:41 - loss: 0.8485 - accuracy: 0.84 - ETA: 1:40 - loss: 0.8480 - accuracy: 0.84 - ETA: 1:39 - loss: 0.8536 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8621 - accuracy: 0.84 - ETA: 1:37 - loss: 0.8595 - accuracy: 0.84 - ETA: 1:36 - loss: 0.8541 - accuracy: 0.84 - ETA: 1:35 - loss: 0.8568 - accuracy: 0.84 - ETA: 1:34 - loss: 0.8818 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8756 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8725 - accuracy: 0.84 - ETA: 1:31 - loss: 0.8649 - accuracy: 0.84 - ETA: 1:30 - loss: 0.8656 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8665 - accuracy: 0.84 - ETA: 1:28 - loss: 0.8617 - accuracy: 0.84 - ETA: 1:27 - loss: 0.8641 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8631 - accuracy: 0.84 - ETA: 1:25 - loss: 0.8657 - accuracy: 0.84 - ETA: 1:24 - loss: 0.8678 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8650 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8653 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8681 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8683 - accuracy: 0.84 - ETA: 1:19 - loss: 0.8650 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8643 - accuracy: 0.84 - ETA: 1:17 - loss: 0.8689 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8690 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8751 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8818 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8842 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8869 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8800 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8765 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8713 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8686 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8728 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8695 - accuracy: 0.84 - ETA: 1:06 - loss: 0.8679 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8684 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8641 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8787 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8779 - accuracy: 0.84 - ETA: 1:01 - loss: 0.8822 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8820 - accuracy: 0.84 - ETA: 59s - loss: 0.8795 - accuracy: 0.8471 - ETA: 58s - loss: 0.8787 - accuracy: 0.846 - ETA: 57s - loss: 0.8834 - accuracy: 0.847 - ETA: 56s - loss: 0.8823 - accuracy: 0.846 - ETA: 55s - loss: 0.8853 - accuracy: 0.847 - ETA: 54s - loss: 0.8863 - accuracy: 0.847 - ETA: 53s - loss: 0.8827 - accuracy: 0.847 - ETA: 52s - loss: 0.8886 - accuracy: 0.846 - ETA: 51s - loss: 0.8916 - accuracy: 0.846 - ETA: 50s - loss: 0.8909 - accuracy: 0.846 - ETA: 49s - loss: 0.8851 - accuracy: 0.846 - ETA: 48s - loss: 0.8855 - accuracy: 0.846 - ETA: 48s - loss: 0.8872 - accuracy: 0.846 - ETA: 47s - loss: 0.8851 - accuracy: 0.846 - ETA: 46s - loss: 0.8820 - accuracy: 0.846 - ETA: 45s - loss: 0.8782 - accuracy: 0.847 - ETA: 44s - loss: 0.8807 - accuracy: 0.846 - ETA: 43s - loss: 0.8792 - accuracy: 0.847 - ETA: 42s - loss: 0.8803 - accuracy: 0.847 - ETA: 41s - loss: 0.8785 - accuracy: 0.847 - ETA: 40s - loss: 0.8752 - accuracy: 0.847 - ETA: 39s - loss: 0.8795 - accuracy: 0.846 - ETA: 38s - loss: 0.8780 - accuracy: 0.846 - ETA: 37s - loss: 0.8810 - accuracy: 0.846 - ETA: 36s - loss: 0.8807 - accuracy: 0.846 - ETA: 35s - loss: 0.8848 - accuracy: 0.846 - ETA: 34s - loss: 0.8842 - accuracy: 0.846 - ETA: 33s - loss: 0.8856 - accuracy: 0.845 - ETA: 32s - loss: 0.8822 - accuracy: 0.846 - ETA: 31s - loss: 0.8826 - accuracy: 0.845 - ETA: 30s - loss: 0.8814 - accuracy: 0.845 - ETA: 29s - loss: 0.8808 - accuracy: 0.845 - ETA: 28s - loss: 0.8827 - accuracy: 0.845 - ETA: 27s - loss: 0.8839 - accuracy: 0.845 - ETA: 26s - loss: 0.8813 - accuracy: 0.845 - ETA: 25s - loss: 0.8833 - accuracy: 0.845 - ETA: 24s - loss: 0.8834 - accuracy: 0.845 - ETA: 23s - loss: 0.8881 - accuracy: 0.844 - ETA: 22s - loss: 0.8876 - accuracy: 0.844 - ETA: 21s - loss: 0.8886 - accuracy: 0.844 - ETA: 21s - loss: 0.8889 - accuracy: 0.844 - ETA: 20s - loss: 0.8872 - accuracy: 0.844 - ETA: 19s - loss: 0.8892 - accuracy: 0.843 - ETA: 18s - loss: 0.8882 - accuracy: 0.843 - ETA: 17s - loss: 0.8884 - accuracy: 0.843 - ETA: 16s - loss: 0.8867 - accuracy: 0.843 - ETA: 15s - loss: 0.8858 - accuracy: 0.843 - ETA: 14s - loss: 0.8823 - accuracy: 0.844 - ETA: 13s - loss: 0.8815 - accuracy: 0.844 - ETA: 12s - loss: 0.8802 - accuracy: 0.844 - ETA: 11s - loss: 0.8816 - accuracy: 0.844 - ETA: 10s - loss: 0.8811 - accuracy: 0.844 - ETA: 9s - loss: 0.8791 - accuracy: 0.844 - ETA: 8s - loss: 0.8785 - accuracy: 0.84 - ETA: 7s - loss: 0.8763 - accuracy: 0.84 - ETA: 6s - loss: 0.8742 - accuracy: 0.84 - ETA: 5s - loss: 0.8723 - accuracy: 0.84 - ETA: 4s - loss: 0.8715 - accuracy: 0.84 - ETA: 3s - loss: 0.8685 - accuracy: 0.84 - ETA: 2s - loss: 0.8660 - accuracy: 0.84 - ETA: 1s - loss: 0.8659 - accuracy: 0.84 - ETA: 0s - loss: 0.8689 - accuracy: 0.84 - 156s 8ms/step - loss: 0.8658 - accuracy: 0.8458 - val_loss: 3.1617 - val_accuracy: 0.7616\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:27 - loss: 0.5708 - accuracy: 0.92 - ETA: 2:23 - loss: 0.5438 - accuracy: 0.90 - ETA: 2:22 - loss: 0.6191 - accuracy: 0.88 - ETA: 2:18 - loss: 0.5881 - accuracy: 0.88 - ETA: 2:20 - loss: 0.6244 - accuracy: 0.87 - ETA: 2:21 - loss: 0.6359 - accuracy: 0.88 - ETA: 2:19 - loss: 0.6599 - accuracy: 0.87 - ETA: 2:18 - loss: 0.6669 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6798 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7087 - accuracy: 0.86 - ETA: 2:14 - loss: 0.7173 - accuracy: 0.86 - ETA: 2:12 - loss: 0.7423 - accuracy: 0.86 - ETA: 2:11 - loss: 0.7656 - accuracy: 0.85 - ETA: 2:10 - loss: 0.7728 - accuracy: 0.85 - ETA: 2:09 - loss: 0.7780 - accuracy: 0.85 - ETA: 2:07 - loss: 0.7755 - accuracy: 0.85 - ETA: 2:06 - loss: 0.7856 - accuracy: 0.85 - ETA: 2:05 - loss: 0.7892 - accuracy: 0.84 - ETA: 2:04 - loss: 0.7820 - accuracy: 0.85 - ETA: 2:04 - loss: 0.7656 - accuracy: 0.85 - ETA: 2:02 - loss: 0.7696 - accuracy: 0.85 - ETA: 2:02 - loss: 0.7910 - accuracy: 0.85 - ETA: 2:01 - loss: 0.7917 - accuracy: 0.85 - ETA: 2:00 - loss: 0.8251 - accuracy: 0.85 - ETA: 2:00 - loss: 0.8279 - accuracy: 0.85 - ETA: 1:59 - loss: 0.8127 - accuracy: 0.85 - ETA: 1:59 - loss: 0.8111 - accuracy: 0.85 - ETA: 1:59 - loss: 0.8127 - accuracy: 0.85 - ETA: 1:58 - loss: 0.8202 - accuracy: 0.85 - ETA: 1:58 - loss: 0.8210 - accuracy: 0.85 - ETA: 1:56 - loss: 0.8252 - accuracy: 0.84 - ETA: 1:55 - loss: 0.8154 - accuracy: 0.85 - ETA: 1:54 - loss: 0.8257 - accuracy: 0.85 - ETA: 1:53 - loss: 0.8301 - accuracy: 0.84 - ETA: 1:52 - loss: 0.8221 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8216 - accuracy: 0.84 - ETA: 1:50 - loss: 0.8187 - accuracy: 0.84 - ETA: 1:49 - loss: 0.8114 - accuracy: 0.84 - ETA: 1:48 - loss: 0.8086 - accuracy: 0.84 - ETA: 1:47 - loss: 0.8151 - accuracy: 0.84 - ETA: 1:46 - loss: 0.8135 - accuracy: 0.84 - ETA: 1:45 - loss: 0.8131 - accuracy: 0.84 - ETA: 1:44 - loss: 0.8133 - accuracy: 0.84 - ETA: 1:43 - loss: 0.8107 - accuracy: 0.84 - ETA: 1:42 - loss: 0.8126 - accuracy: 0.84 - ETA: 1:41 - loss: 0.8132 - accuracy: 0.84 - ETA: 1:40 - loss: 0.8159 - accuracy: 0.84 - ETA: 1:39 - loss: 0.8147 - accuracy: 0.84 - ETA: 1:38 - loss: 0.8152 - accuracy: 0.84 - ETA: 1:37 - loss: 0.8141 - accuracy: 0.84 - ETA: 1:36 - loss: 0.8201 - accuracy: 0.84 - ETA: 1:35 - loss: 0.8250 - accuracy: 0.84 - ETA: 1:34 - loss: 0.8209 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8233 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8174 - accuracy: 0.84 - ETA: 1:31 - loss: 0.8121 - accuracy: 0.84 - ETA: 1:30 - loss: 0.8115 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8228 - accuracy: 0.84 - ETA: 1:28 - loss: 0.8253 - accuracy: 0.84 - ETA: 1:27 - loss: 0.8273 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8262 - accuracy: 0.84 - ETA: 1:25 - loss: 0.8305 - accuracy: 0.84 - ETA: 1:24 - loss: 0.8292 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8349 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8395 - accuracy: 0.84 - ETA: 1:21 - loss: 0.8385 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8369 - accuracy: 0.84 - ETA: 1:19 - loss: 0.8410 - accuracy: 0.84 - ETA: 1:18 - loss: 0.8353 - accuracy: 0.84 - ETA: 1:17 - loss: 0.8338 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8331 - accuracy: 0.84 - ETA: 1:16 - loss: 0.8353 - accuracy: 0.84 - ETA: 1:15 - loss: 0.8342 - accuracy: 0.84 - ETA: 1:14 - loss: 0.8360 - accuracy: 0.84 - ETA: 1:13 - loss: 0.8328 - accuracy: 0.84 - ETA: 1:12 - loss: 0.8276 - accuracy: 0.84 - ETA: 1:11 - loss: 0.8247 - accuracy: 0.84 - ETA: 1:10 - loss: 0.8207 - accuracy: 0.84 - ETA: 1:09 - loss: 0.8215 - accuracy: 0.84 - ETA: 1:08 - loss: 0.8218 - accuracy: 0.84 - ETA: 1:07 - loss: 0.8221 - accuracy: 0.84 - ETA: 1:06 - loss: 0.8314 - accuracy: 0.84 - ETA: 1:05 - loss: 0.8311 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8279 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8273 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8243 - accuracy: 0.84 - ETA: 1:01 - loss: 0.8251 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8301 - accuracy: 0.84 - ETA: 59s - loss: 0.8387 - accuracy: 0.8452 - ETA: 58s - loss: 0.8395 - accuracy: 0.845 - ETA: 57s - loss: 0.8358 - accuracy: 0.846 - ETA: 56s - loss: 0.8441 - accuracy: 0.845 - ETA: 55s - loss: 0.8402 - accuracy: 0.846 - ETA: 54s - loss: 0.8388 - accuracy: 0.846 - ETA: 53s - loss: 0.8381 - accuracy: 0.846 - ETA: 52s - loss: 0.8388 - accuracy: 0.845 - ETA: 51s - loss: 0.8344 - accuracy: 0.846 - ETA: 50s - loss: 0.8364 - accuracy: 0.846 - ETA: 49s - loss: 0.8318 - accuracy: 0.846 - ETA: 48s - loss: 0.8325 - accuracy: 0.846 - ETA: 47s - loss: 0.8299 - accuracy: 0.847 - ETA: 47s - loss: 0.8313 - accuracy: 0.847 - ETA: 46s - loss: 0.8306 - accuracy: 0.847 - ETA: 45s - loss: 0.8313 - accuracy: 0.847 - ETA: 44s - loss: 0.8297 - accuracy: 0.847 - ETA: 43s - loss: 0.8283 - accuracy: 0.847 - ETA: 42s - loss: 0.8283 - accuracy: 0.847 - ETA: 41s - loss: 0.8254 - accuracy: 0.847 - ETA: 40s - loss: 0.8254 - accuracy: 0.847 - ETA: 39s - loss: 0.8251 - accuracy: 0.847 - ETA: 38s - loss: 0.8213 - accuracy: 0.847 - ETA: 37s - loss: 0.8205 - accuracy: 0.847 - ETA: 36s - loss: 0.8206 - accuracy: 0.847 - ETA: 35s - loss: 0.8189 - accuracy: 0.847 - ETA: 34s - loss: 0.8182 - accuracy: 0.848 - ETA: 33s - loss: 0.8187 - accuracy: 0.847 - ETA: 32s - loss: 0.8163 - accuracy: 0.848 - ETA: 31s - loss: 0.8203 - accuracy: 0.847 - ETA: 30s - loss: 0.8208 - accuracy: 0.847 - ETA: 29s - loss: 0.8224 - accuracy: 0.847 - ETA: 28s - loss: 0.8196 - accuracy: 0.847 - ETA: 27s - loss: 0.8172 - accuracy: 0.848 - ETA: 26s - loss: 0.8154 - accuracy: 0.848 - ETA: 25s - loss: 0.8163 - accuracy: 0.848 - ETA: 24s - loss: 0.8137 - accuracy: 0.848 - ETA: 23s - loss: 0.8143 - accuracy: 0.848 - ETA: 22s - loss: 0.8132 - accuracy: 0.848 - ETA: 21s - loss: 0.8126 - accuracy: 0.848 - ETA: 21s - loss: 0.8125 - accuracy: 0.848 - ETA: 20s - loss: 0.8114 - accuracy: 0.848 - ETA: 19s - loss: 0.8094 - accuracy: 0.849 - ETA: 18s - loss: 0.8089 - accuracy: 0.849 - ETA: 17s - loss: 0.8063 - accuracy: 0.849 - ETA: 16s - loss: 0.8050 - accuracy: 0.849 - ETA: 15s - loss: 0.8028 - accuracy: 0.849 - ETA: 14s - loss: 0.8030 - accuracy: 0.849 - ETA: 13s - loss: 0.8048 - accuracy: 0.849 - ETA: 12s - loss: 0.8030 - accuracy: 0.849 - ETA: 11s - loss: 0.8029 - accuracy: 0.849 - ETA: 10s - loss: 0.8027 - accuracy: 0.849 - ETA: 9s - loss: 0.8051 - accuracy: 0.849 - ETA: 8s - loss: 0.8125 - accuracy: 0.84 - ETA: 7s - loss: 0.8129 - accuracy: 0.84 - ETA: 6s - loss: 0.8155 - accuracy: 0.84 - ETA: 5s - loss: 0.8149 - accuracy: 0.84 - ETA: 4s - loss: 0.8139 - accuracy: 0.84 - ETA: 3s - loss: 0.8114 - accuracy: 0.84 - ETA: 2s - loss: 0.8090 - accuracy: 0.84 - ETA: 1s - loss: 0.8089 - accuracy: 0.84 - ETA: 0s - loss: 0.8089 - accuracy: 0.84 - 157s 8ms/step - loss: 0.8096 - accuracy: 0.8487 - val_loss: 3.2150 - val_accuracy: 0.7583\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:34 - loss: 0.8998 - accuracy: 0.85 - ETA: 2:24 - loss: 0.7875 - accuracy: 0.86 - ETA: 2:20 - loss: 0.6955 - accuracy: 0.87 - ETA: 2:18 - loss: 0.7246 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7311 - accuracy: 0.85 - ETA: 2:15 - loss: 0.7205 - accuracy: 0.85 - ETA: 2:15 - loss: 0.6926 - accuracy: 0.85 - ETA: 2:14 - loss: 0.7114 - accuracy: 0.85 - ETA: 2:15 - loss: 0.7132 - accuracy: 0.85 - ETA: 2:14 - loss: 0.7266 - accuracy: 0.85 - ETA: 2:13 - loss: 0.7377 - accuracy: 0.85 - ETA: 2:11 - loss: 0.7309 - accuracy: 0.85 - ETA: 2:10 - loss: 0.7271 - accuracy: 0.85 - ETA: 2:10 - loss: 0.7080 - accuracy: 0.85 - ETA: 2:09 - loss: 0.6889 - accuracy: 0.85 - ETA: 2:08 - loss: 0.7070 - accuracy: 0.85 - ETA: 2:07 - loss: 0.7131 - accuracy: 0.85 - ETA: 2:06 - loss: 0.7238 - accuracy: 0.85 - ETA: 2:05 - loss: 0.7374 - accuracy: 0.85 - ETA: 2:04 - loss: 0.7285 - accuracy: 0.85 - ETA: 2:03 - loss: 0.7256 - accuracy: 0.85 - ETA: 2:02 - loss: 0.7232 - accuracy: 0.85 - ETA: 2:01 - loss: 0.7185 - accuracy: 0.85 - ETA: 2:00 - loss: 0.7223 - accuracy: 0.85 - ETA: 1:59 - loss: 0.7414 - accuracy: 0.85 - ETA: 1:58 - loss: 0.7378 - accuracy: 0.85 - ETA: 1:58 - loss: 0.7390 - accuracy: 0.85 - ETA: 1:57 - loss: 0.7494 - accuracy: 0.85 - ETA: 1:56 - loss: 0.7408 - accuracy: 0.85 - ETA: 1:55 - loss: 0.7476 - accuracy: 0.85 - ETA: 1:54 - loss: 0.7546 - accuracy: 0.85 - ETA: 1:53 - loss: 0.7529 - accuracy: 0.85 - ETA: 1:52 - loss: 0.7569 - accuracy: 0.85 - ETA: 1:51 - loss: 0.7544 - accuracy: 0.85 - ETA: 1:50 - loss: 0.7624 - accuracy: 0.85 - ETA: 1:49 - loss: 0.7602 - accuracy: 0.85 - ETA: 1:49 - loss: 0.7589 - accuracy: 0.85 - ETA: 1:48 - loss: 0.7557 - accuracy: 0.85 - ETA: 1:47 - loss: 0.7539 - accuracy: 0.85 - ETA: 1:46 - loss: 0.7481 - accuracy: 0.85 - ETA: 1:45 - loss: 0.7461 - accuracy: 0.85 - ETA: 1:44 - loss: 0.7397 - accuracy: 0.85 - ETA: 1:43 - loss: 0.7293 - accuracy: 0.85 - ETA: 1:42 - loss: 0.7450 - accuracy: 0.85 - ETA: 1:41 - loss: 0.7371 - accuracy: 0.85 - ETA: 1:40 - loss: 0.7485 - accuracy: 0.85 - ETA: 1:39 - loss: 0.7525 - accuracy: 0.85 - ETA: 1:38 - loss: 0.7533 - accuracy: 0.85 - ETA: 1:37 - loss: 0.7554 - accuracy: 0.85 - ETA: 1:36 - loss: 0.7624 - accuracy: 0.85 - ETA: 1:35 - loss: 0.7651 - accuracy: 0.85 - ETA: 1:34 - loss: 0.7692 - accuracy: 0.85 - ETA: 1:33 - loss: 0.7638 - accuracy: 0.85 - ETA: 1:32 - loss: 0.7707 - accuracy: 0.85 - ETA: 1:31 - loss: 0.7743 - accuracy: 0.85 - ETA: 1:30 - loss: 0.7721 - accuracy: 0.85 - ETA: 1:29 - loss: 0.7743 - accuracy: 0.85 - ETA: 1:28 - loss: 0.7732 - accuracy: 0.85 - ETA: 1:27 - loss: 0.7787 - accuracy: 0.85 - ETA: 1:27 - loss: 0.7760 - accuracy: 0.85 - ETA: 1:25 - loss: 0.7708 - accuracy: 0.85 - ETA: 1:25 - loss: 0.7662 - accuracy: 0.85 - ETA: 1:23 - loss: 0.7683 - accuracy: 0.85 - ETA: 1:22 - loss: 0.7670 - accuracy: 0.85 - ETA: 1:22 - loss: 0.7731 - accuracy: 0.85 - ETA: 1:21 - loss: 0.7773 - accuracy: 0.85 - ETA: 1:20 - loss: 0.7753 - accuracy: 0.85 - ETA: 1:19 - loss: 0.7796 - accuracy: 0.85 - ETA: 1:18 - loss: 0.7761 - accuracy: 0.85 - ETA: 1:17 - loss: 0.7693 - accuracy: 0.85 - ETA: 1:16 - loss: 0.7656 - accuracy: 0.85 - ETA: 1:15 - loss: 0.7737 - accuracy: 0.85 - ETA: 1:14 - loss: 0.7740 - accuracy: 0.85 - ETA: 1:13 - loss: 0.7731 - accuracy: 0.85 - ETA: 1:12 - loss: 0.7712 - accuracy: 0.85 - ETA: 1:11 - loss: 0.7694 - accuracy: 0.85 - ETA: 1:10 - loss: 0.7681 - accuracy: 0.85 - ETA: 1:09 - loss: 0.7679 - accuracy: 0.85 - ETA: 1:08 - loss: 0.7663 - accuracy: 0.85 - ETA: 1:07 - loss: 0.7725 - accuracy: 0.85 - ETA: 1:06 - loss: 0.7735 - accuracy: 0.85 - ETA: 1:05 - loss: 0.7716 - accuracy: 0.85 - ETA: 1:04 - loss: 0.7705 - accuracy: 0.85 - ETA: 1:04 - loss: 0.7709 - accuracy: 0.85 - ETA: 1:03 - loss: 0.7706 - accuracy: 0.85 - ETA: 1:02 - loss: 0.7691 - accuracy: 0.85 - ETA: 1:01 - loss: 0.7718 - accuracy: 0.85 - ETA: 1:00 - loss: 0.7795 - accuracy: 0.85 - ETA: 59s - loss: 0.7887 - accuracy: 0.8524 - ETA: 58s - loss: 0.7909 - accuracy: 0.852 - ETA: 57s - loss: 0.7881 - accuracy: 0.852 - ETA: 56s - loss: 0.7930 - accuracy: 0.852 - ETA: 55s - loss: 0.7968 - accuracy: 0.852 - ETA: 54s - loss: 0.7960 - accuracy: 0.851 - ETA: 53s - loss: 0.8040 - accuracy: 0.852 - ETA: 52s - loss: 0.8024 - accuracy: 0.852 - ETA: 51s - loss: 0.8036 - accuracy: 0.852 - ETA: 50s - loss: 0.8022 - accuracy: 0.852 - ETA: 49s - loss: 0.8004 - accuracy: 0.853 - ETA: 48s - loss: 0.7981 - accuracy: 0.853 - ETA: 47s - loss: 0.7953 - accuracy: 0.853 - ETA: 46s - loss: 0.7966 - accuracy: 0.853 - ETA: 45s - loss: 0.7947 - accuracy: 0.853 - ETA: 44s - loss: 0.7935 - accuracy: 0.853 - ETA: 44s - loss: 0.7957 - accuracy: 0.853 - ETA: 43s - loss: 0.8014 - accuracy: 0.852 - ETA: 42s - loss: 0.8019 - accuracy: 0.852 - ETA: 41s - loss: 0.8007 - accuracy: 0.852 - ETA: 40s - loss: 0.8028 - accuracy: 0.852 - ETA: 39s - loss: 0.8051 - accuracy: 0.852 - ETA: 38s - loss: 0.8046 - accuracy: 0.852 - ETA: 37s - loss: 0.8058 - accuracy: 0.852 - ETA: 36s - loss: 0.8056 - accuracy: 0.852 - ETA: 35s - loss: 0.8041 - accuracy: 0.852 - ETA: 34s - loss: 0.8041 - accuracy: 0.852 - ETA: 33s - loss: 0.8053 - accuracy: 0.852 - ETA: 32s - loss: 0.8071 - accuracy: 0.852 - ETA: 31s - loss: 0.8056 - accuracy: 0.852 - ETA: 30s - loss: 0.8053 - accuracy: 0.852 - ETA: 29s - loss: 0.8095 - accuracy: 0.851 - ETA: 28s - loss: 0.8107 - accuracy: 0.851 - ETA: 27s - loss: 0.8113 - accuracy: 0.851 - ETA: 26s - loss: 0.8100 - accuracy: 0.851 - ETA: 25s - loss: 0.8106 - accuracy: 0.851 - ETA: 24s - loss: 0.8110 - accuracy: 0.851 - ETA: 23s - loss: 0.8120 - accuracy: 0.852 - ETA: 22s - loss: 0.8108 - accuracy: 0.852 - ETA: 21s - loss: 0.8152 - accuracy: 0.852 - ETA: 21s - loss: 0.8168 - accuracy: 0.852 - ETA: 20s - loss: 0.8185 - accuracy: 0.852 - ETA: 19s - loss: 0.8220 - accuracy: 0.851 - ETA: 18s - loss: 0.8232 - accuracy: 0.851 - ETA: 17s - loss: 0.8226 - accuracy: 0.851 - ETA: 16s - loss: 0.8222 - accuracy: 0.851 - ETA: 15s - loss: 0.8223 - accuracy: 0.851 - ETA: 14s - loss: 0.8279 - accuracy: 0.851 - ETA: 13s - loss: 0.8288 - accuracy: 0.850 - ETA: 12s - loss: 0.8306 - accuracy: 0.850 - ETA: 11s - loss: 0.8308 - accuracy: 0.850 - ETA: 10s - loss: 0.8344 - accuracy: 0.850 - ETA: 9s - loss: 0.8319 - accuracy: 0.850 - ETA: 8s - loss: 0.8303 - accuracy: 0.85 - ETA: 7s - loss: 0.8296 - accuracy: 0.85 - ETA: 6s - loss: 0.8292 - accuracy: 0.85 - ETA: 5s - loss: 0.8256 - accuracy: 0.85 - ETA: 4s - loss: 0.8268 - accuracy: 0.85 - ETA: 3s - loss: 0.8266 - accuracy: 0.85 - ETA: 2s - loss: 0.8246 - accuracy: 0.85 - ETA: 1s - loss: 0.8241 - accuracy: 0.85 - ETA: 0s - loss: 0.8244 - accuracy: 0.85 - 157s 8ms/step - loss: 0.8260 - accuracy: 0.8512 - val_loss: 3.3441 - val_accuracy: 0.7583\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:24 - loss: 0.7911 - accuracy: 0.87 - ETA: 2:20 - loss: 0.7741 - accuracy: 0.87 - ETA: 2:21 - loss: 0.7716 - accuracy: 0.87 - ETA: 2:18 - loss: 0.7836 - accuracy: 0.86 - ETA: 2:17 - loss: 0.7402 - accuracy: 0.86 - ETA: 2:15 - loss: 0.7187 - accuracy: 0.86 - ETA: 2:14 - loss: 0.7582 - accuracy: 0.85 - ETA: 2:14 - loss: 0.8000 - accuracy: 0.85 - ETA: 2:14 - loss: 0.9156 - accuracy: 0.84 - ETA: 2:14 - loss: 0.8963 - accuracy: 0.84 - ETA: 2:14 - loss: 0.8926 - accuracy: 0.84 - ETA: 2:13 - loss: 0.8912 - accuracy: 0.84 - ETA: 2:13 - loss: 0.8811 - accuracy: 0.84 - ETA: 2:12 - loss: 0.8651 - accuracy: 0.84 - ETA: 2:11 - loss: 0.8375 - accuracy: 0.85 - ETA: 2:09 - loss: 0.8271 - accuracy: 0.85 - ETA: 2:08 - loss: 0.8080 - accuracy: 0.85 - ETA: 2:07 - loss: 0.7922 - accuracy: 0.85 - ETA: 2:05 - loss: 0.7891 - accuracy: 0.85 - ETA: 2:04 - loss: 0.7920 - accuracy: 0.85 - ETA: 2:03 - loss: 0.8012 - accuracy: 0.85 - ETA: 2:02 - loss: 0.7846 - accuracy: 0.85 - ETA: 2:01 - loss: 0.7685 - accuracy: 0.85 - ETA: 2:00 - loss: 0.7794 - accuracy: 0.85 - ETA: 1:59 - loss: 0.7665 - accuracy: 0.85 - ETA: 1:58 - loss: 0.7767 - accuracy: 0.85 - ETA: 1:57 - loss: 0.7731 - accuracy: 0.85 - ETA: 1:56 - loss: 0.7815 - accuracy: 0.85 - ETA: 1:55 - loss: 0.7829 - accuracy: 0.85 - ETA: 1:54 - loss: 0.7891 - accuracy: 0.85 - ETA: 1:54 - loss: 0.7895 - accuracy: 0.85 - ETA: 1:53 - loss: 0.7881 - accuracy: 0.85 - ETA: 1:52 - loss: 0.7876 - accuracy: 0.85 - ETA: 1:52 - loss: 0.7931 - accuracy: 0.85 - ETA: 1:51 - loss: 0.7849 - accuracy: 0.85 - ETA: 1:50 - loss: 0.7863 - accuracy: 0.85 - ETA: 1:49 - loss: 0.7779 - accuracy: 0.85 - ETA: 1:48 - loss: 0.7702 - accuracy: 0.85 - ETA: 1:48 - loss: 0.7793 - accuracy: 0.85 - ETA: 1:47 - loss: 0.7823 - accuracy: 0.85 - ETA: 1:46 - loss: 0.7826 - accuracy: 0.85 - ETA: 1:45 - loss: 0.7841 - accuracy: 0.85 - ETA: 1:44 - loss: 0.7832 - accuracy: 0.85 - ETA: 1:43 - loss: 0.7846 - accuracy: 0.85 - ETA: 1:42 - loss: 0.7804 - accuracy: 0.85 - ETA: 1:41 - loss: 0.7787 - accuracy: 0.85 - ETA: 1:40 - loss: 0.7836 - accuracy: 0.85 - ETA: 1:39 - loss: 0.7834 - accuracy: 0.85 - ETA: 1:38 - loss: 0.7904 - accuracy: 0.85 - ETA: 1:37 - loss: 0.7905 - accuracy: 0.85 - ETA: 1:36 - loss: 0.7849 - accuracy: 0.85 - ETA: 1:35 - loss: 0.7807 - accuracy: 0.85 - ETA: 1:34 - loss: 0.7811 - accuracy: 0.85 - ETA: 1:33 - loss: 0.7768 - accuracy: 0.85 - ETA: 1:32 - loss: 0.7770 - accuracy: 0.85 - ETA: 1:31 - loss: 0.7736 - accuracy: 0.85 - ETA: 1:30 - loss: 0.7690 - accuracy: 0.85 - ETA: 1:29 - loss: 0.7699 - accuracy: 0.85 - ETA: 1:28 - loss: 0.7704 - accuracy: 0.85 - ETA: 1:27 - loss: 0.7736 - accuracy: 0.85 - ETA: 1:26 - loss: 0.7720 - accuracy: 0.85 - ETA: 1:25 - loss: 0.7709 - accuracy: 0.85 - ETA: 1:24 - loss: 0.7737 - accuracy: 0.85 - ETA: 1:24 - loss: 0.7727 - accuracy: 0.85 - ETA: 1:23 - loss: 0.7751 - accuracy: 0.85 - ETA: 1:22 - loss: 0.7764 - accuracy: 0.85 - ETA: 1:21 - loss: 0.7747 - accuracy: 0.85 - ETA: 1:20 - loss: 0.7748 - accuracy: 0.85 - ETA: 1:19 - loss: 0.7860 - accuracy: 0.85 - ETA: 1:18 - loss: 0.7880 - accuracy: 0.85 - ETA: 1:17 - loss: 0.7905 - accuracy: 0.85 - ETA: 1:16 - loss: 0.7908 - accuracy: 0.85 - ETA: 1:15 - loss: 0.7866 - accuracy: 0.85 - ETA: 1:14 - loss: 0.7891 - accuracy: 0.85 - ETA: 1:13 - loss: 0.7938 - accuracy: 0.85 - ETA: 1:12 - loss: 0.7918 - accuracy: 0.85 - ETA: 1:11 - loss: 0.7888 - accuracy: 0.85 - ETA: 1:10 - loss: 0.7925 - accuracy: 0.85 - ETA: 1:09 - loss: 0.7920 - accuracy: 0.85 - ETA: 1:08 - loss: 0.7929 - accuracy: 0.85 - ETA: 1:07 - loss: 0.7963 - accuracy: 0.85 - ETA: 1:06 - loss: 0.7920 - accuracy: 0.85 - ETA: 1:05 - loss: 0.8014 - accuracy: 0.85 - ETA: 1:04 - loss: 0.8027 - accuracy: 0.85 - ETA: 1:03 - loss: 0.8037 - accuracy: 0.85 - ETA: 1:02 - loss: 0.8030 - accuracy: 0.85 - ETA: 1:01 - loss: 0.8059 - accuracy: 0.85 - ETA: 1:00 - loss: 0.8043 - accuracy: 0.85 - ETA: 59s - loss: 0.8022 - accuracy: 0.8542 - ETA: 58s - loss: 0.8041 - accuracy: 0.853 - ETA: 57s - loss: 0.8068 - accuracy: 0.853 - ETA: 56s - loss: 0.8069 - accuracy: 0.853 - ETA: 55s - loss: 0.8072 - accuracy: 0.853 - ETA: 54s - loss: 0.8089 - accuracy: 0.853 - ETA: 53s - loss: 0.8087 - accuracy: 0.853 - ETA: 52s - loss: 0.8106 - accuracy: 0.853 - ETA: 51s - loss: 0.8074 - accuracy: 0.854 - ETA: 50s - loss: 0.8064 - accuracy: 0.853 - ETA: 49s - loss: 0.8100 - accuracy: 0.853 - ETA: 49s - loss: 0.8080 - accuracy: 0.853 - ETA: 48s - loss: 0.8085 - accuracy: 0.853 - ETA: 47s - loss: 0.8084 - accuracy: 0.853 - ETA: 46s - loss: 0.8059 - accuracy: 0.854 - ETA: 45s - loss: 0.8039 - accuracy: 0.854 - ETA: 44s - loss: 0.7993 - accuracy: 0.854 - ETA: 43s - loss: 0.7956 - accuracy: 0.855 - ETA: 42s - loss: 0.7965 - accuracy: 0.855 - ETA: 41s - loss: 0.7998 - accuracy: 0.854 - ETA: 40s - loss: 0.7987 - accuracy: 0.854 - ETA: 39s - loss: 0.7973 - accuracy: 0.854 - ETA: 38s - loss: 0.7962 - accuracy: 0.854 - ETA: 37s - loss: 0.7952 - accuracy: 0.854 - ETA: 36s - loss: 0.8024 - accuracy: 0.854 - ETA: 35s - loss: 0.8004 - accuracy: 0.854 - ETA: 34s - loss: 0.7991 - accuracy: 0.854 - ETA: 33s - loss: 0.7991 - accuracy: 0.854 - ETA: 32s - loss: 0.8006 - accuracy: 0.854 - ETA: 31s - loss: 0.8049 - accuracy: 0.854 - ETA: 30s - loss: 0.8030 - accuracy: 0.854 - ETA: 29s - loss: 0.8030 - accuracy: 0.854 - ETA: 28s - loss: 0.8037 - accuracy: 0.854 - ETA: 27s - loss: 0.8024 - accuracy: 0.854 - ETA: 26s - loss: 0.8020 - accuracy: 0.853 - ETA: 25s - loss: 0.7994 - accuracy: 0.854 - ETA: 24s - loss: 0.8001 - accuracy: 0.854 - ETA: 23s - loss: 0.7988 - accuracy: 0.854 - ETA: 22s - loss: 0.8008 - accuracy: 0.854 - ETA: 21s - loss: 0.7989 - accuracy: 0.854 - ETA: 21s - loss: 0.7984 - accuracy: 0.854 - ETA: 20s - loss: 0.7957 - accuracy: 0.855 - ETA: 19s - loss: 0.7931 - accuracy: 0.855 - ETA: 18s - loss: 0.7906 - accuracy: 0.855 - ETA: 17s - loss: 0.7926 - accuracy: 0.855 - ETA: 16s - loss: 0.7932 - accuracy: 0.854 - ETA: 15s - loss: 0.7951 - accuracy: 0.854 - ETA: 14s - loss: 0.8003 - accuracy: 0.854 - ETA: 13s - loss: 0.8012 - accuracy: 0.854 - ETA: 12s - loss: 0.8011 - accuracy: 0.853 - ETA: 11s - loss: 0.8018 - accuracy: 0.853 - ETA: 10s - loss: 0.8007 - accuracy: 0.853 - ETA: 9s - loss: 0.7991 - accuracy: 0.853 - ETA: 8s - loss: 0.8018 - accuracy: 0.85 - ETA: 7s - loss: 0.8034 - accuracy: 0.85 - ETA: 6s - loss: 0.8018 - accuracy: 0.85 - ETA: 5s - loss: 0.7994 - accuracy: 0.85 - ETA: 4s - loss: 0.7963 - accuracy: 0.85 - ETA: 3s - loss: 0.7954 - accuracy: 0.85 - ETA: 2s - loss: 0.7957 - accuracy: 0.85 - ETA: 1s - loss: 0.7959 - accuracy: 0.85 - ETA: 0s - loss: 0.7951 - accuracy: 0.85 - 156s 8ms/step - loss: 0.7942 - accuracy: 0.8537 - val_loss: 3.1961 - val_accuracy: 0.7703\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 1.0082 - accuracy: 0.78 - ETA: 2:26 - loss: 1.0335 - accuracy: 0.83 - ETA: 2:22 - loss: 0.9330 - accuracy: 0.84 - ETA: 2:20 - loss: 0.9440 - accuracy: 0.83 - ETA: 2:18 - loss: 0.9781 - accuracy: 0.83 - ETA: 2:17 - loss: 1.0073 - accuracy: 0.83 - ETA: 2:16 - loss: 0.9724 - accuracy: 0.83 - ETA: 2:15 - loss: 0.9331 - accuracy: 0.83 - ETA: 2:14 - loss: 0.8982 - accuracy: 0.83 - ETA: 2:12 - loss: 0.8561 - accuracy: 0.84 - ETA: 2:11 - loss: 0.8360 - accuracy: 0.84 - ETA: 2:10 - loss: 0.8240 - accuracy: 0.84 - ETA: 2:09 - loss: 0.8284 - accuracy: 0.84 - ETA: 2:08 - loss: 0.8042 - accuracy: 0.84 - ETA: 2:08 - loss: 0.8046 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8243 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8284 - accuracy: 0.84 - ETA: 2:06 - loss: 0.8600 - accuracy: 0.84 - ETA: 2:05 - loss: 0.8737 - accuracy: 0.84 - ETA: 2:04 - loss: 0.8652 - accuracy: 0.84 - ETA: 2:03 - loss: 0.8560 - accuracy: 0.84 - ETA: 2:02 - loss: 0.8746 - accuracy: 0.84 - ETA: 2:01 - loss: 0.8790 - accuracy: 0.84 - ETA: 2:00 - loss: 0.8731 - accuracy: 0.84 - ETA: 1:59 - loss: 0.8615 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8633 - accuracy: 0.84 - ETA: 1:57 - loss: 0.8802 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8683 - accuracy: 0.84 - ETA: 1:55 - loss: 0.8665 - accuracy: 0.84 - ETA: 1:54 - loss: 0.8601 - accuracy: 0.84 - ETA: 1:53 - loss: 0.8784 - accuracy: 0.84 - ETA: 1:52 - loss: 0.8697 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8728 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8822 - accuracy: 0.84 - ETA: 1:50 - loss: 0.8723 - accuracy: 0.84 - ETA: 1:49 - loss: 0.8629 - accuracy: 0.84 - ETA: 1:48 - loss: 0.8536 - accuracy: 0.85 - ETA: 1:47 - loss: 0.8447 - accuracy: 0.85 - ETA: 1:46 - loss: 0.8409 - accuracy: 0.85 - ETA: 1:45 - loss: 0.8436 - accuracy: 0.85 - ETA: 1:44 - loss: 0.8561 - accuracy: 0.85 - ETA: 1:43 - loss: 0.8497 - accuracy: 0.85 - ETA: 1:42 - loss: 0.8446 - accuracy: 0.85 - ETA: 1:41 - loss: 0.8401 - accuracy: 0.85 - ETA: 1:40 - loss: 0.8304 - accuracy: 0.85 - ETA: 1:39 - loss: 0.8332 - accuracy: 0.85 - ETA: 1:38 - loss: 0.8286 - accuracy: 0.85 - ETA: 1:37 - loss: 0.8213 - accuracy: 0.85 - ETA: 1:36 - loss: 0.8316 - accuracy: 0.85 - ETA: 1:35 - loss: 0.8454 - accuracy: 0.84 - ETA: 1:35 - loss: 0.8500 - accuracy: 0.84 - ETA: 1:34 - loss: 0.8480 - accuracy: 0.84 - ETA: 1:33 - loss: 0.8486 - accuracy: 0.84 - ETA: 1:32 - loss: 0.8573 - accuracy: 0.84 - ETA: 1:31 - loss: 0.8576 - accuracy: 0.84 - ETA: 1:30 - loss: 0.8621 - accuracy: 0.84 - ETA: 1:29 - loss: 0.8592 - accuracy: 0.84 - ETA: 1:28 - loss: 0.8675 - accuracy: 0.84 - ETA: 1:27 - loss: 0.8687 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8709 - accuracy: 0.84 - ETA: 1:26 - loss: 0.8663 - accuracy: 0.84 - ETA: 1:25 - loss: 0.8633 - accuracy: 0.84 - ETA: 1:24 - loss: 0.8570 - accuracy: 0.84 - ETA: 1:23 - loss: 0.8578 - accuracy: 0.84 - ETA: 1:22 - loss: 0.8532 - accuracy: 0.85 - ETA: 1:21 - loss: 0.8562 - accuracy: 0.84 - ETA: 1:20 - loss: 0.8527 - accuracy: 0.85 - ETA: 1:19 - loss: 0.8489 - accuracy: 0.85 - ETA: 1:18 - loss: 0.8449 - accuracy: 0.85 - ETA: 1:17 - loss: 0.8427 - accuracy: 0.85 - ETA: 1:16 - loss: 0.8459 - accuracy: 0.85 - ETA: 1:15 - loss: 0.8395 - accuracy: 0.85 - ETA: 1:14 - loss: 0.8388 - accuracy: 0.85 - ETA: 1:13 - loss: 0.8553 - accuracy: 0.85 - ETA: 1:12 - loss: 0.8523 - accuracy: 0.85 - ETA: 1:11 - loss: 0.8505 - accuracy: 0.85 - ETA: 1:10 - loss: 0.8518 - accuracy: 0.85 - ETA: 1:09 - loss: 0.8592 - accuracy: 0.85 - ETA: 1:08 - loss: 0.8561 - accuracy: 0.85 - ETA: 1:07 - loss: 0.8535 - accuracy: 0.85 - ETA: 1:06 - loss: 0.8531 - accuracy: 0.85 - ETA: 1:05 - loss: 0.8578 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8552 - accuracy: 0.84 - ETA: 1:04 - loss: 0.8593 - accuracy: 0.84 - ETA: 1:03 - loss: 0.8554 - accuracy: 0.84 - ETA: 1:02 - loss: 0.8519 - accuracy: 0.84 - ETA: 1:01 - loss: 0.8483 - accuracy: 0.84 - ETA: 1:00 - loss: 0.8476 - accuracy: 0.84 - ETA: 59s - loss: 0.8493 - accuracy: 0.8495 - ETA: 58s - loss: 0.8475 - accuracy: 0.849 - ETA: 57s - loss: 0.8479 - accuracy: 0.849 - ETA: 56s - loss: 0.8481 - accuracy: 0.849 - ETA: 55s - loss: 0.8528 - accuracy: 0.849 - ETA: 54s - loss: 0.8508 - accuracy: 0.849 - ETA: 53s - loss: 0.8473 - accuracy: 0.849 - ETA: 52s - loss: 0.8480 - accuracy: 0.849 - ETA: 51s - loss: 0.8522 - accuracy: 0.849 - ETA: 50s - loss: 0.8538 - accuracy: 0.849 - ETA: 49s - loss: 0.8521 - accuracy: 0.849 - ETA: 48s - loss: 0.8492 - accuracy: 0.850 - ETA: 47s - loss: 0.8483 - accuracy: 0.850 - ETA: 46s - loss: 0.8487 - accuracy: 0.850 - ETA: 45s - loss: 0.8441 - accuracy: 0.850 - ETA: 44s - loss: 0.8424 - accuracy: 0.850 - ETA: 43s - loss: 0.8410 - accuracy: 0.850 - ETA: 42s - loss: 0.8411 - accuracy: 0.850 - ETA: 41s - loss: 0.8395 - accuracy: 0.850 - ETA: 41s - loss: 0.8373 - accuracy: 0.850 - ETA: 40s - loss: 0.8344 - accuracy: 0.851 - ETA: 39s - loss: 0.8354 - accuracy: 0.851 - ETA: 38s - loss: 0.8333 - accuracy: 0.851 - ETA: 37s - loss: 0.8319 - accuracy: 0.851 - ETA: 36s - loss: 0.8303 - accuracy: 0.851 - ETA: 35s - loss: 0.8312 - accuracy: 0.851 - ETA: 34s - loss: 0.8272 - accuracy: 0.851 - ETA: 33s - loss: 0.8274 - accuracy: 0.851 - ETA: 32s - loss: 0.8296 - accuracy: 0.851 - ETA: 31s - loss: 0.8311 - accuracy: 0.850 - ETA: 30s - loss: 0.8288 - accuracy: 0.851 - ETA: 29s - loss: 0.8302 - accuracy: 0.850 - ETA: 28s - loss: 0.8318 - accuracy: 0.850 - ETA: 27s - loss: 0.8326 - accuracy: 0.850 - ETA: 26s - loss: 0.8322 - accuracy: 0.850 - ETA: 25s - loss: 0.8329 - accuracy: 0.850 - ETA: 24s - loss: 0.8375 - accuracy: 0.850 - ETA: 23s - loss: 0.8344 - accuracy: 0.850 - ETA: 22s - loss: 0.8326 - accuracy: 0.850 - ETA: 21s - loss: 0.8318 - accuracy: 0.850 - ETA: 21s - loss: 0.8323 - accuracy: 0.850 - ETA: 20s - loss: 0.8311 - accuracy: 0.850 - ETA: 19s - loss: 0.8307 - accuracy: 0.850 - ETA: 18s - loss: 0.8335 - accuracy: 0.849 - ETA: 17s - loss: 0.8334 - accuracy: 0.850 - ETA: 16s - loss: 0.8332 - accuracy: 0.849 - ETA: 15s - loss: 0.8325 - accuracy: 0.849 - ETA: 14s - loss: 0.8328 - accuracy: 0.849 - ETA: 13s - loss: 0.8312 - accuracy: 0.849 - ETA: 12s - loss: 0.8324 - accuracy: 0.850 - ETA: 11s - loss: 0.8327 - accuracy: 0.850 - ETA: 10s - loss: 0.8387 - accuracy: 0.849 - ETA: 9s - loss: 0.8392 - accuracy: 0.849 - ETA: 8s - loss: 0.8372 - accuracy: 0.85 - ETA: 7s - loss: 0.8362 - accuracy: 0.85 - ETA: 6s - loss: 0.8357 - accuracy: 0.85 - ETA: 5s - loss: 0.8330 - accuracy: 0.85 - ETA: 4s - loss: 0.8344 - accuracy: 0.85 - ETA: 3s - loss: 0.8319 - accuracy: 0.85 - ETA: 2s - loss: 0.8297 - accuracy: 0.85 - ETA: 1s - loss: 0.8283 - accuracy: 0.85 - ETA: 0s - loss: 0.8301 - accuracy: 0.85 - 156s 8ms/step - loss: 0.8333 - accuracy: 0.8507 - val_loss: 3.1077 - val_accuracy: 0.7654\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:42 - loss: 0.6649 - accuracy: 0.86 - ETA: 2:34 - loss: 0.7874 - accuracy: 0.87 - ETA: 2:28 - loss: 0.8030 - accuracy: 0.86 - ETA: 2:27 - loss: 0.7246 - accuracy: 0.86 - ETA: 2:27 - loss: 0.7579 - accuracy: 0.86 - ETA: 2:24 - loss: 0.7335 - accuracy: 0.86 - ETA: 2:22 - loss: 0.7044 - accuracy: 0.86 - ETA: 2:21 - loss: 0.7748 - accuracy: 0.86 - ETA: 2:19 - loss: 0.7308 - accuracy: 0.86 - ETA: 2:17 - loss: 0.6983 - accuracy: 0.87 - ETA: 2:16 - loss: 0.7087 - accuracy: 0.86 - ETA: 2:15 - loss: 0.6918 - accuracy: 0.87 - ETA: 2:13 - loss: 0.7203 - accuracy: 0.86 - ETA: 2:12 - loss: 0.7259 - accuracy: 0.86 - ETA: 2:11 - loss: 0.7267 - accuracy: 0.86 - ETA: 2:10 - loss: 0.7300 - accuracy: 0.86 - ETA: 2:09 - loss: 0.7209 - accuracy: 0.86 - ETA: 2:07 - loss: 0.7237 - accuracy: 0.86 - ETA: 2:06 - loss: 0.7259 - accuracy: 0.86 - ETA: 2:05 - loss: 0.7299 - accuracy: 0.86 - ETA: 2:05 - loss: 0.7300 - accuracy: 0.86 - ETA: 2:04 - loss: 0.7451 - accuracy: 0.86 - ETA: 2:02 - loss: 0.7571 - accuracy: 0.86 - ETA: 2:01 - loss: 0.7544 - accuracy: 0.86 - ETA: 2:00 - loss: 0.7697 - accuracy: 0.86 - ETA: 2:00 - loss: 0.7974 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7926 - accuracy: 0.86 - ETA: 1:58 - loss: 0.8073 - accuracy: 0.86 - ETA: 1:57 - loss: 0.8128 - accuracy: 0.85 - ETA: 1:56 - loss: 0.8252 - accuracy: 0.85 - ETA: 1:55 - loss: 0.8268 - accuracy: 0.85 - ETA: 1:54 - loss: 0.8260 - accuracy: 0.85 - ETA: 1:53 - loss: 0.8338 - accuracy: 0.85 - ETA: 1:52 - loss: 0.8355 - accuracy: 0.85 - ETA: 1:51 - loss: 0.8313 - accuracy: 0.85 - ETA: 1:50 - loss: 0.8206 - accuracy: 0.85 - ETA: 1:49 - loss: 0.8290 - accuracy: 0.85 - ETA: 1:48 - loss: 0.8271 - accuracy: 0.85 - ETA: 1:47 - loss: 0.8252 - accuracy: 0.85 - ETA: 1:46 - loss: 0.8216 - accuracy: 0.85 - ETA: 1:45 - loss: 0.8206 - accuracy: 0.85 - ETA: 1:44 - loss: 0.8217 - accuracy: 0.85 - ETA: 1:44 - loss: 0.8157 - accuracy: 0.85 - ETA: 1:43 - loss: 0.8167 - accuracy: 0.85 - ETA: 1:41 - loss: 0.8137 - accuracy: 0.85 - ETA: 1:40 - loss: 0.8238 - accuracy: 0.85 - ETA: 1:39 - loss: 0.8199 - accuracy: 0.85 - ETA: 1:39 - loss: 0.8143 - accuracy: 0.85 - ETA: 1:38 - loss: 0.8166 - accuracy: 0.85 - ETA: 1:37 - loss: 0.8284 - accuracy: 0.85 - ETA: 1:36 - loss: 0.8327 - accuracy: 0.85 - ETA: 1:34 - loss: 0.8305 - accuracy: 0.85 - ETA: 1:33 - loss: 0.8344 - accuracy: 0.85 - ETA: 1:33 - loss: 0.8294 - accuracy: 0.85 - ETA: 1:32 - loss: 0.8222 - accuracy: 0.85 - ETA: 1:31 - loss: 0.8214 - accuracy: 0.85 - ETA: 1:30 - loss: 0.8207 - accuracy: 0.85 - ETA: 1:29 - loss: 0.8243 - accuracy: 0.85 - ETA: 1:28 - loss: 0.8227 - accuracy: 0.85 - ETA: 1:27 - loss: 0.8191 - accuracy: 0.85 - ETA: 1:26 - loss: 0.8244 - accuracy: 0.85 - ETA: 1:25 - loss: 0.8271 - accuracy: 0.85 - ETA: 1:24 - loss: 0.8213 - accuracy: 0.85 - ETA: 1:23 - loss: 0.8222 - accuracy: 0.85 - ETA: 1:22 - loss: 0.8167 - accuracy: 0.85 - ETA: 1:21 - loss: 0.8171 - accuracy: 0.85 - ETA: 1:20 - loss: 0.8199 - accuracy: 0.85 - ETA: 1:19 - loss: 0.8210 - accuracy: 0.85 - ETA: 1:18 - loss: 0.8149 - accuracy: 0.85 - ETA: 1:17 - loss: 0.8119 - accuracy: 0.85 - ETA: 1:16 - loss: 0.8148 - accuracy: 0.85 - ETA: 1:15 - loss: 0.8139 - accuracy: 0.85 - ETA: 1:14 - loss: 0.8127 - accuracy: 0.85 - ETA: 1:13 - loss: 0.8070 - accuracy: 0.85 - ETA: 1:12 - loss: 0.8014 - accuracy: 0.85 - ETA: 1:11 - loss: 0.8001 - accuracy: 0.85 - ETA: 1:10 - loss: 0.7997 - accuracy: 0.85 - ETA: 1:09 - loss: 0.7955 - accuracy: 0.85 - ETA: 1:09 - loss: 0.7924 - accuracy: 0.85 - ETA: 1:08 - loss: 0.7916 - accuracy: 0.85 - ETA: 1:07 - loss: 0.7903 - accuracy: 0.85 - ETA: 1:06 - loss: 0.7963 - accuracy: 0.85 - ETA: 1:05 - loss: 0.7959 - accuracy: 0.85 - ETA: 1:04 - loss: 0.7954 - accuracy: 0.85 - ETA: 1:03 - loss: 0.8002 - accuracy: 0.85 - ETA: 1:02 - loss: 0.7990 - accuracy: 0.85 - ETA: 1:01 - loss: 0.7986 - accuracy: 0.85 - ETA: 1:00 - loss: 0.7969 - accuracy: 0.85 - ETA: 59s - loss: 0.7993 - accuracy: 0.8564 - ETA: 58s - loss: 0.8033 - accuracy: 0.856 - ETA: 57s - loss: 0.8007 - accuracy: 0.856 - ETA: 56s - loss: 0.8082 - accuracy: 0.856 - ETA: 55s - loss: 0.8065 - accuracy: 0.856 - ETA: 54s - loss: 0.8099 - accuracy: 0.856 - ETA: 53s - loss: 0.8136 - accuracy: 0.855 - ETA: 52s - loss: 0.8119 - accuracy: 0.855 - ETA: 51s - loss: 0.8133 - accuracy: 0.855 - ETA: 50s - loss: 0.8160 - accuracy: 0.854 - ETA: 49s - loss: 0.8161 - accuracy: 0.854 - ETA: 49s - loss: 0.8141 - accuracy: 0.854 - ETA: 48s - loss: 0.8136 - accuracy: 0.854 - ETA: 47s - loss: 0.8137 - accuracy: 0.854 - ETA: 46s - loss: 0.8102 - accuracy: 0.855 - ETA: 45s - loss: 0.8070 - accuracy: 0.855 - ETA: 44s - loss: 0.8087 - accuracy: 0.855 - ETA: 43s - loss: 0.8081 - accuracy: 0.854 - ETA: 42s - loss: 0.8089 - accuracy: 0.854 - ETA: 41s - loss: 0.8116 - accuracy: 0.854 - ETA: 40s - loss: 0.8138 - accuracy: 0.854 - ETA: 39s - loss: 0.8148 - accuracy: 0.854 - ETA: 38s - loss: 0.8124 - accuracy: 0.855 - ETA: 37s - loss: 0.8103 - accuracy: 0.855 - ETA: 36s - loss: 0.8079 - accuracy: 0.855 - ETA: 35s - loss: 0.8068 - accuracy: 0.855 - ETA: 34s - loss: 0.8044 - accuracy: 0.855 - ETA: 33s - loss: 0.8053 - accuracy: 0.855 - ETA: 32s - loss: 0.8053 - accuracy: 0.855 - ETA: 31s - loss: 0.8048 - accuracy: 0.855 - ETA: 30s - loss: 0.8026 - accuracy: 0.855 - ETA: 29s - loss: 0.8018 - accuracy: 0.855 - ETA: 28s - loss: 0.8011 - accuracy: 0.855 - ETA: 27s - loss: 0.8009 - accuracy: 0.855 - ETA: 26s - loss: 0.8008 - accuracy: 0.855 - ETA: 25s - loss: 0.7981 - accuracy: 0.855 - ETA: 24s - loss: 0.7962 - accuracy: 0.856 - ETA: 23s - loss: 0.7943 - accuracy: 0.856 - ETA: 22s - loss: 0.7953 - accuracy: 0.856 - ETA: 21s - loss: 0.7978 - accuracy: 0.855 - ETA: 21s - loss: 0.7974 - accuracy: 0.855 - ETA: 20s - loss: 0.7954 - accuracy: 0.855 - ETA: 19s - loss: 0.7927 - accuracy: 0.856 - ETA: 18s - loss: 0.7922 - accuracy: 0.855 - ETA: 17s - loss: 0.7901 - accuracy: 0.856 - ETA: 16s - loss: 0.7914 - accuracy: 0.856 - ETA: 15s - loss: 0.7916 - accuracy: 0.855 - ETA: 14s - loss: 0.7901 - accuracy: 0.855 - ETA: 13s - loss: 0.7892 - accuracy: 0.855 - ETA: 12s - loss: 0.7885 - accuracy: 0.856 - ETA: 11s - loss: 0.7939 - accuracy: 0.855 - ETA: 10s - loss: 0.7951 - accuracy: 0.855 - ETA: 9s - loss: 0.7962 - accuracy: 0.855 - ETA: 8s - loss: 0.7979 - accuracy: 0.85 - ETA: 7s - loss: 0.7991 - accuracy: 0.85 - ETA: 6s - loss: 0.7988 - accuracy: 0.85 - ETA: 5s - loss: 0.7995 - accuracy: 0.85 - ETA: 4s - loss: 0.7976 - accuracy: 0.85 - ETA: 3s - loss: 0.8007 - accuracy: 0.85 - ETA: 2s - loss: 0.8001 - accuracy: 0.85 - ETA: 1s - loss: 0.8002 - accuracy: 0.85 - ETA: 0s - loss: 0.7984 - accuracy: 0.85 - 156s 8ms/step - loss: 0.7971 - accuracy: 0.8551 - val_loss: 3.3243 - val_accuracy: 0.7635\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:50 - loss: 0.5243 - accuracy: 0.89 - ETA: 2:38 - loss: 0.5715 - accuracy: 0.86 - ETA: 2:32 - loss: 0.6882 - accuracy: 0.85 - ETA: 2:27 - loss: 0.7266 - accuracy: 0.85 - ETA: 2:25 - loss: 0.6960 - accuracy: 0.86 - ETA: 2:22 - loss: 0.6607 - accuracy: 0.87 - ETA: 2:20 - loss: 0.6737 - accuracy: 0.86 - ETA: 2:20 - loss: 0.6511 - accuracy: 0.86 - ETA: 2:20 - loss: 0.6663 - accuracy: 0.86 - ETA: 2:19 - loss: 0.6949 - accuracy: 0.86 - ETA: 2:17 - loss: 0.7000 - accuracy: 0.86 - ETA: 2:15 - loss: 0.6921 - accuracy: 0.86 - ETA: 2:15 - loss: 0.7083 - accuracy: 0.86 - ETA: 2:13 - loss: 0.7869 - accuracy: 0.86 - ETA: 2:11 - loss: 0.7667 - accuracy: 0.86 - ETA: 2:10 - loss: 0.7625 - accuracy: 0.86 - ETA: 2:09 - loss: 0.7429 - accuracy: 0.86 - ETA: 2:08 - loss: 0.7436 - accuracy: 0.86 - ETA: 2:07 - loss: 0.7286 - accuracy: 0.86 - ETA: 2:06 - loss: 0.7312 - accuracy: 0.86 - ETA: 2:04 - loss: 0.7403 - accuracy: 0.86 - ETA: 2:03 - loss: 0.7494 - accuracy: 0.86 - ETA: 2:02 - loss: 0.7783 - accuracy: 0.85 - ETA: 2:01 - loss: 0.7962 - accuracy: 0.85 - ETA: 2:01 - loss: 0.8095 - accuracy: 0.85 - ETA: 2:00 - loss: 0.8142 - accuracy: 0.85 - ETA: 1:59 - loss: 0.8052 - accuracy: 0.85 - ETA: 1:58 - loss: 0.7947 - accuracy: 0.85 - ETA: 1:57 - loss: 0.7876 - accuracy: 0.85 - ETA: 1:56 - loss: 0.7909 - accuracy: 0.85 - ETA: 1:55 - loss: 0.7913 - accuracy: 0.85 - ETA: 1:54 - loss: 0.8047 - accuracy: 0.85 - ETA: 1:52 - loss: 0.7996 - accuracy: 0.85 - ETA: 1:51 - loss: 0.7947 - accuracy: 0.85 - ETA: 1:50 - loss: 0.7904 - accuracy: 0.85 - ETA: 1:49 - loss: 0.7905 - accuracy: 0.85 - ETA: 1:48 - loss: 0.7764 - accuracy: 0.85 - ETA: 1:47 - loss: 0.7656 - accuracy: 0.85 - ETA: 1:46 - loss: 0.7558 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7560 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7642 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7677 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7622 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7577 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7532 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7525 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7474 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7507 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7546 - accuracy: 0.85 - ETA: 1:36 - loss: 0.7450 - accuracy: 0.86 - ETA: 1:35 - loss: 0.7618 - accuracy: 0.86 - ETA: 1:34 - loss: 0.7786 - accuracy: 0.85 - ETA: 1:33 - loss: 0.7840 - accuracy: 0.85 - ETA: 1:32 - loss: 0.7849 - accuracy: 0.86 - ETA: 1:31 - loss: 0.7856 - accuracy: 0.86 - ETA: 1:30 - loss: 0.7882 - accuracy: 0.85 - ETA: 1:29 - loss: 0.7889 - accuracy: 0.85 - ETA: 1:28 - loss: 0.7898 - accuracy: 0.85 - ETA: 1:28 - loss: 0.7932 - accuracy: 0.85 - ETA: 1:27 - loss: 0.7929 - accuracy: 0.85 - ETA: 1:26 - loss: 0.7944 - accuracy: 0.85 - ETA: 1:25 - loss: 0.7921 - accuracy: 0.85 - ETA: 1:24 - loss: 0.7918 - accuracy: 0.85 - ETA: 1:23 - loss: 0.7932 - accuracy: 0.85 - ETA: 1:22 - loss: 0.7911 - accuracy: 0.85 - ETA: 1:21 - loss: 0.7907 - accuracy: 0.85 - ETA: 1:20 - loss: 0.7975 - accuracy: 0.85 - ETA: 1:19 - loss: 0.8038 - accuracy: 0.85 - ETA: 1:18 - loss: 0.8040 - accuracy: 0.85 - ETA: 1:17 - loss: 0.8017 - accuracy: 0.85 - ETA: 1:16 - loss: 0.8065 - accuracy: 0.85 - ETA: 1:15 - loss: 0.8037 - accuracy: 0.85 - ETA: 1:14 - loss: 0.8010 - accuracy: 0.85 - ETA: 1:13 - loss: 0.8016 - accuracy: 0.85 - ETA: 1:12 - loss: 0.7994 - accuracy: 0.85 - ETA: 1:11 - loss: 0.7994 - accuracy: 0.85 - ETA: 1:10 - loss: 0.8008 - accuracy: 0.85 - ETA: 1:09 - loss: 0.7988 - accuracy: 0.85 - ETA: 1:08 - loss: 0.7998 - accuracy: 0.85 - ETA: 1:07 - loss: 0.7973 - accuracy: 0.85 - ETA: 1:07 - loss: 0.7965 - accuracy: 0.85 - ETA: 1:06 - loss: 0.8037 - accuracy: 0.85 - ETA: 1:05 - loss: 0.8044 - accuracy: 0.85 - ETA: 1:04 - loss: 0.8017 - accuracy: 0.85 - ETA: 1:03 - loss: 0.8088 - accuracy: 0.85 - ETA: 1:02 - loss: 0.8070 - accuracy: 0.85 - ETA: 1:01 - loss: 0.8084 - accuracy: 0.85 - ETA: 1:00 - loss: 0.8054 - accuracy: 0.85 - ETA: 59s - loss: 0.8083 - accuracy: 0.8546 - ETA: 58s - loss: 0.8143 - accuracy: 0.854 - ETA: 57s - loss: 0.8180 - accuracy: 0.853 - ETA: 56s - loss: 0.8167 - accuracy: 0.853 - ETA: 55s - loss: 0.8194 - accuracy: 0.853 - ETA: 54s - loss: 0.8170 - accuracy: 0.853 - ETA: 53s - loss: 0.8197 - accuracy: 0.853 - ETA: 52s - loss: 0.8210 - accuracy: 0.852 - ETA: 51s - loss: 0.8226 - accuracy: 0.852 - ETA: 50s - loss: 0.8255 - accuracy: 0.852 - ETA: 49s - loss: 0.8239 - accuracy: 0.853 - ETA: 48s - loss: 0.8254 - accuracy: 0.852 - ETA: 47s - loss: 0.8253 - accuracy: 0.852 - ETA: 46s - loss: 0.8258 - accuracy: 0.852 - ETA: 45s - loss: 0.8284 - accuracy: 0.852 - ETA: 44s - loss: 0.8284 - accuracy: 0.852 - ETA: 43s - loss: 0.8317 - accuracy: 0.851 - ETA: 42s - loss: 0.8341 - accuracy: 0.851 - ETA: 41s - loss: 0.8351 - accuracy: 0.852 - ETA: 40s - loss: 0.8335 - accuracy: 0.852 - ETA: 40s - loss: 0.8329 - accuracy: 0.852 - ETA: 39s - loss: 0.8362 - accuracy: 0.852 - ETA: 38s - loss: 0.8315 - accuracy: 0.852 - ETA: 37s - loss: 0.8285 - accuracy: 0.853 - ETA: 36s - loss: 0.8247 - accuracy: 0.853 - ETA: 35s - loss: 0.8236 - accuracy: 0.853 - ETA: 34s - loss: 0.8237 - accuracy: 0.853 - ETA: 33s - loss: 0.8235 - accuracy: 0.853 - ETA: 32s - loss: 0.8204 - accuracy: 0.853 - ETA: 31s - loss: 0.8216 - accuracy: 0.853 - ETA: 30s - loss: 0.8229 - accuracy: 0.853 - ETA: 29s - loss: 0.8228 - accuracy: 0.853 - ETA: 28s - loss: 0.8276 - accuracy: 0.853 - ETA: 27s - loss: 0.8293 - accuracy: 0.853 - ETA: 26s - loss: 0.8306 - accuracy: 0.853 - ETA: 25s - loss: 0.8268 - accuracy: 0.853 - ETA: 24s - loss: 0.8300 - accuracy: 0.853 - ETA: 23s - loss: 0.8306 - accuracy: 0.853 - ETA: 22s - loss: 0.8277 - accuracy: 0.853 - ETA: 21s - loss: 0.8252 - accuracy: 0.853 - ETA: 20s - loss: 0.8223 - accuracy: 0.854 - ETA: 19s - loss: 0.8192 - accuracy: 0.854 - ETA: 19s - loss: 0.8212 - accuracy: 0.854 - ETA: 18s - loss: 0.8205 - accuracy: 0.854 - ETA: 17s - loss: 0.8224 - accuracy: 0.854 - ETA: 16s - loss: 0.8208 - accuracy: 0.854 - ETA: 15s - loss: 0.8198 - accuracy: 0.854 - ETA: 14s - loss: 0.8181 - accuracy: 0.854 - ETA: 13s - loss: 0.8193 - accuracy: 0.854 - ETA: 12s - loss: 0.8191 - accuracy: 0.854 - ETA: 11s - loss: 0.8178 - accuracy: 0.854 - ETA: 10s - loss: 0.8181 - accuracy: 0.854 - ETA: 9s - loss: 0.8197 - accuracy: 0.854 - ETA: 8s - loss: 0.8227 - accuracy: 0.85 - ETA: 7s - loss: 0.8234 - accuracy: 0.85 - ETA: 6s - loss: 0.8232 - accuracy: 0.85 - ETA: 5s - loss: 0.8207 - accuracy: 0.85 - ETA: 4s - loss: 0.8200 - accuracy: 0.85 - ETA: 3s - loss: 0.8256 - accuracy: 0.85 - ETA: 2s - loss: 0.8235 - accuracy: 0.85 - ETA: 1s - loss: 0.8244 - accuracy: 0.85 - ETA: 0s - loss: 0.8263 - accuracy: 0.85 - 156s 8ms/step - loss: 0.8249 - accuracy: 0.8548 - val_loss: 3.0677 - val_accuracy: 0.7662\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 1.3334 - accuracy: 0.75 - ETA: 2:28 - loss: 0.9786 - accuracy: 0.81 - ETA: 2:24 - loss: 0.9652 - accuracy: 0.82 - ETA: 2:23 - loss: 0.8904 - accuracy: 0.84 - ETA: 2:21 - loss: 0.9297 - accuracy: 0.84 - ETA: 2:20 - loss: 0.8787 - accuracy: 0.84 - ETA: 2:17 - loss: 0.8317 - accuracy: 0.84 - ETA: 2:17 - loss: 0.8185 - accuracy: 0.84 - ETA: 2:15 - loss: 0.7928 - accuracy: 0.85 - ETA: 2:13 - loss: 0.7712 - accuracy: 0.85 - ETA: 2:13 - loss: 0.7793 - accuracy: 0.84 - ETA: 2:12 - loss: 0.7967 - accuracy: 0.84 - ETA: 2:12 - loss: 0.7664 - accuracy: 0.84 - ETA: 2:10 - loss: 0.7677 - accuracy: 0.84 - ETA: 2:10 - loss: 0.7699 - accuracy: 0.85 - ETA: 2:08 - loss: 0.7801 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8051 - accuracy: 0.84 - ETA: 2:06 - loss: 0.8133 - accuracy: 0.84 - ETA: 2:05 - loss: 0.8043 - accuracy: 0.84 - ETA: 2:04 - loss: 0.8110 - accuracy: 0.84 - ETA: 2:02 - loss: 0.8869 - accuracy: 0.84 - ETA: 2:02 - loss: 0.8845 - accuracy: 0.84 - ETA: 2:00 - loss: 0.8793 - accuracy: 0.85 - ETA: 1:59 - loss: 0.8772 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8650 - accuracy: 0.85 - ETA: 1:57 - loss: 0.8564 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8453 - accuracy: 0.85 - ETA: 1:55 - loss: 0.8398 - accuracy: 0.85 - ETA: 1:55 - loss: 0.8443 - accuracy: 0.85 - ETA: 1:54 - loss: 0.8345 - accuracy: 0.85 - ETA: 1:53 - loss: 0.8297 - accuracy: 0.85 - ETA: 1:52 - loss: 0.8192 - accuracy: 0.85 - ETA: 1:51 - loss: 0.8236 - accuracy: 0.85 - ETA: 1:50 - loss: 0.8126 - accuracy: 0.85 - ETA: 1:49 - loss: 0.8218 - accuracy: 0.85 - ETA: 1:48 - loss: 0.8264 - accuracy: 0.85 - ETA: 1:47 - loss: 0.8275 - accuracy: 0.85 - ETA: 1:46 - loss: 0.8273 - accuracy: 0.85 - ETA: 1:46 - loss: 0.8249 - accuracy: 0.85 - ETA: 1:45 - loss: 0.8288 - accuracy: 0.85 - ETA: 1:44 - loss: 0.8233 - accuracy: 0.85 - ETA: 1:43 - loss: 0.8256 - accuracy: 0.85 - ETA: 1:42 - loss: 0.8370 - accuracy: 0.85 - ETA: 1:41 - loss: 0.8277 - accuracy: 0.85 - ETA: 1:40 - loss: 0.8236 - accuracy: 0.85 - ETA: 1:40 - loss: 0.8197 - accuracy: 0.85 - ETA: 1:39 - loss: 0.8214 - accuracy: 0.85 - ETA: 1:38 - loss: 0.8142 - accuracy: 0.85 - ETA: 1:37 - loss: 0.8186 - accuracy: 0.85 - ETA: 1:36 - loss: 0.8209 - accuracy: 0.85 - ETA: 1:35 - loss: 0.8171 - accuracy: 0.85 - ETA: 1:34 - loss: 0.8137 - accuracy: 0.85 - ETA: 1:33 - loss: 0.8158 - accuracy: 0.85 - ETA: 1:32 - loss: 0.8177 - accuracy: 0.85 - ETA: 1:31 - loss: 0.8239 - accuracy: 0.85 - ETA: 1:30 - loss: 0.8283 - accuracy: 0.85 - ETA: 1:29 - loss: 0.8305 - accuracy: 0.85 - ETA: 1:28 - loss: 0.8290 - accuracy: 0.85 - ETA: 1:27 - loss: 0.8309 - accuracy: 0.85 - ETA: 1:26 - loss: 0.8261 - accuracy: 0.85 - ETA: 1:26 - loss: 0.8194 - accuracy: 0.85 - ETA: 1:25 - loss: 0.8200 - accuracy: 0.85 - ETA: 1:24 - loss: 0.8229 - accuracy: 0.85 - ETA: 1:23 - loss: 0.8256 - accuracy: 0.85 - ETA: 1:22 - loss: 0.8221 - accuracy: 0.85 - ETA: 1:21 - loss: 0.8211 - accuracy: 0.85 - ETA: 1:20 - loss: 0.8245 - accuracy: 0.85 - ETA: 1:19 - loss: 0.8274 - accuracy: 0.85 - ETA: 1:18 - loss: 0.8233 - accuracy: 0.85 - ETA: 1:17 - loss: 0.8223 - accuracy: 0.85 - ETA: 1:16 - loss: 0.8209 - accuracy: 0.85 - ETA: 1:15 - loss: 0.8227 - accuracy: 0.85 - ETA: 1:14 - loss: 0.8272 - accuracy: 0.85 - ETA: 1:13 - loss: 0.8237 - accuracy: 0.85 - ETA: 1:12 - loss: 0.8227 - accuracy: 0.85 - ETA: 1:11 - loss: 0.8191 - accuracy: 0.85 - ETA: 1:10 - loss: 0.8165 - accuracy: 0.85 - ETA: 1:09 - loss: 0.8191 - accuracy: 0.85 - ETA: 1:08 - loss: 0.8184 - accuracy: 0.85 - ETA: 1:08 - loss: 0.8174 - accuracy: 0.85 - ETA: 1:07 - loss: 0.8134 - accuracy: 0.85 - ETA: 1:06 - loss: 0.8135 - accuracy: 0.85 - ETA: 1:05 - loss: 0.8119 - accuracy: 0.85 - ETA: 1:04 - loss: 0.8166 - accuracy: 0.85 - ETA: 1:03 - loss: 0.8138 - accuracy: 0.85 - ETA: 1:02 - loss: 0.8126 - accuracy: 0.85 - ETA: 1:01 - loss: 0.8109 - accuracy: 0.85 - ETA: 1:00 - loss: 0.8133 - accuracy: 0.85 - ETA: 59s - loss: 0.8153 - accuracy: 0.8537 - ETA: 58s - loss: 0.8159 - accuracy: 0.853 - ETA: 57s - loss: 0.8130 - accuracy: 0.853 - ETA: 56s - loss: 0.8107 - accuracy: 0.854 - ETA: 55s - loss: 0.8200 - accuracy: 0.854 - ETA: 54s - loss: 0.8212 - accuracy: 0.853 - ETA: 53s - loss: 0.8195 - accuracy: 0.854 - ETA: 52s - loss: 0.8181 - accuracy: 0.854 - ETA: 51s - loss: 0.8187 - accuracy: 0.854 - ETA: 50s - loss: 0.8179 - accuracy: 0.854 - ETA: 49s - loss: 0.8194 - accuracy: 0.854 - ETA: 48s - loss: 0.8215 - accuracy: 0.853 - ETA: 47s - loss: 0.8258 - accuracy: 0.853 - ETA: 46s - loss: 0.8219 - accuracy: 0.853 - ETA: 45s - loss: 0.8211 - accuracy: 0.854 - ETA: 44s - loss: 0.8229 - accuracy: 0.853 - ETA: 43s - loss: 0.8230 - accuracy: 0.853 - ETA: 43s - loss: 0.8228 - accuracy: 0.854 - ETA: 42s - loss: 0.8207 - accuracy: 0.854 - ETA: 41s - loss: 0.8216 - accuracy: 0.854 - ETA: 40s - loss: 0.8229 - accuracy: 0.853 - ETA: 39s - loss: 0.8239 - accuracy: 0.853 - ETA: 38s - loss: 0.8233 - accuracy: 0.853 - ETA: 37s - loss: 0.8243 - accuracy: 0.853 - ETA: 36s - loss: 0.8257 - accuracy: 0.853 - ETA: 35s - loss: 0.8241 - accuracy: 0.853 - ETA: 34s - loss: 0.8277 - accuracy: 0.853 - ETA: 33s - loss: 0.8291 - accuracy: 0.853 - ETA: 32s - loss: 0.8281 - accuracy: 0.852 - ETA: 31s - loss: 0.8294 - accuracy: 0.852 - ETA: 30s - loss: 0.8257 - accuracy: 0.853 - ETA: 29s - loss: 0.8237 - accuracy: 0.853 - ETA: 28s - loss: 0.8218 - accuracy: 0.854 - ETA: 27s - loss: 0.8261 - accuracy: 0.853 - ETA: 26s - loss: 0.8274 - accuracy: 0.853 - ETA: 25s - loss: 0.8263 - accuracy: 0.853 - ETA: 24s - loss: 0.8251 - accuracy: 0.854 - ETA: 23s - loss: 0.8229 - accuracy: 0.854 - ETA: 22s - loss: 0.8247 - accuracy: 0.854 - ETA: 21s - loss: 0.8246 - accuracy: 0.854 - ETA: 20s - loss: 0.8237 - accuracy: 0.854 - ETA: 20s - loss: 0.8233 - accuracy: 0.854 - ETA: 19s - loss: 0.8246 - accuracy: 0.854 - ETA: 18s - loss: 0.8268 - accuracy: 0.854 - ETA: 17s - loss: 0.8256 - accuracy: 0.854 - ETA: 16s - loss: 0.8238 - accuracy: 0.854 - ETA: 15s - loss: 0.8236 - accuracy: 0.854 - ETA: 14s - loss: 0.8274 - accuracy: 0.853 - ETA: 13s - loss: 0.8239 - accuracy: 0.854 - ETA: 12s - loss: 0.8206 - accuracy: 0.854 - ETA: 11s - loss: 0.8213 - accuracy: 0.855 - ETA: 10s - loss: 0.8214 - accuracy: 0.855 - ETA: 9s - loss: 0.8214 - accuracy: 0.855 - ETA: 8s - loss: 0.8190 - accuracy: 0.85 - ETA: 7s - loss: 0.8174 - accuracy: 0.85 - ETA: 6s - loss: 0.8192 - accuracy: 0.85 - ETA: 5s - loss: 0.8225 - accuracy: 0.85 - ETA: 4s - loss: 0.8266 - accuracy: 0.85 - ETA: 3s - loss: 0.8251 - accuracy: 0.85 - ETA: 2s - loss: 0.8251 - accuracy: 0.85 - ETA: 1s - loss: 0.8260 - accuracy: 0.85 - ETA: 0s - loss: 0.8248 - accuracy: 0.85 - 156s 8ms/step - loss: 0.8299 - accuracy: 0.8554 - val_loss: 3.8551 - val_accuracy: 0.7656\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:20 - loss: 1.5560 - accuracy: 0.85 - ETA: 2:19 - loss: 1.1533 - accuracy: 0.86 - ETA: 2:18 - loss: 1.1602 - accuracy: 0.85 - ETA: 2:18 - loss: 1.0019 - accuracy: 0.86 - ETA: 2:17 - loss: 0.9062 - accuracy: 0.85 - ETA: 2:17 - loss: 0.8487 - accuracy: 0.86 - ETA: 2:16 - loss: 0.8687 - accuracy: 0.86 - ETA: 2:17 - loss: 0.8613 - accuracy: 0.86 - ETA: 2:16 - loss: 0.8789 - accuracy: 0.85 - ETA: 2:15 - loss: 0.8111 - accuracy: 0.86 - ETA: 2:14 - loss: 0.8386 - accuracy: 0.86 - ETA: 2:13 - loss: 0.8185 - accuracy: 0.87 - ETA: 2:12 - loss: 0.8580 - accuracy: 0.86 - ETA: 2:10 - loss: 0.8860 - accuracy: 0.86 - ETA: 2:09 - loss: 0.8843 - accuracy: 0.86 - ETA: 2:09 - loss: 0.8802 - accuracy: 0.85 - ETA: 2:08 - loss: 0.8814 - accuracy: 0.85 - ETA: 2:08 - loss: 0.8627 - accuracy: 0.85 - ETA: 2:07 - loss: 0.8866 - accuracy: 0.85 - ETA: 2:06 - loss: 0.8891 - accuracy: 0.85 - ETA: 2:06 - loss: 0.9018 - accuracy: 0.85 - ETA: 2:05 - loss: 0.8850 - accuracy: 0.85 - ETA: 2:04 - loss: 0.8664 - accuracy: 0.85 - ETA: 2:03 - loss: 0.8774 - accuracy: 0.85 - ETA: 2:01 - loss: 0.8851 - accuracy: 0.85 - ETA: 2:01 - loss: 0.8770 - accuracy: 0.85 - ETA: 2:00 - loss: 0.8809 - accuracy: 0.85 - ETA: 1:58 - loss: 0.8907 - accuracy: 0.85 - ETA: 1:57 - loss: 0.8973 - accuracy: 0.85 - ETA: 1:56 - loss: 0.8861 - accuracy: 0.85 - ETA: 1:55 - loss: 0.8823 - accuracy: 0.85 - ETA: 1:54 - loss: 0.8804 - accuracy: 0.85 - ETA: 1:54 - loss: 0.8799 - accuracy: 0.85 - ETA: 1:53 - loss: 0.8719 - accuracy: 0.85 - ETA: 1:52 - loss: 0.8881 - accuracy: 0.85 - ETA: 1:50 - loss: 0.8761 - accuracy: 0.85 - ETA: 1:49 - loss: 0.8699 - accuracy: 0.85 - ETA: 1:48 - loss: 0.8590 - accuracy: 0.85 - ETA: 1:47 - loss: 0.8572 - accuracy: 0.85 - ETA: 1:46 - loss: 0.8586 - accuracy: 0.85 - ETA: 1:45 - loss: 0.8516 - accuracy: 0.85 - ETA: 1:44 - loss: 0.8573 - accuracy: 0.85 - ETA: 1:43 - loss: 0.8605 - accuracy: 0.85 - ETA: 1:42 - loss: 0.8624 - accuracy: 0.85 - ETA: 1:41 - loss: 0.8480 - accuracy: 0.85 - ETA: 1:40 - loss: 0.8409 - accuracy: 0.85 - ETA: 1:39 - loss: 0.8430 - accuracy: 0.85 - ETA: 1:38 - loss: 0.8366 - accuracy: 0.85 - ETA: 1:37 - loss: 0.8258 - accuracy: 0.85 - ETA: 1:37 - loss: 0.8217 - accuracy: 0.85 - ETA: 1:36 - loss: 0.8373 - accuracy: 0.85 - ETA: 1:35 - loss: 0.8384 - accuracy: 0.85 - ETA: 1:34 - loss: 0.8454 - accuracy: 0.85 - ETA: 1:33 - loss: 0.8404 - accuracy: 0.85 - ETA: 1:32 - loss: 0.8391 - accuracy: 0.85 - ETA: 1:31 - loss: 0.8363 - accuracy: 0.85 - ETA: 1:30 - loss: 0.8390 - accuracy: 0.85 - ETA: 1:29 - loss: 0.8318 - accuracy: 0.85 - ETA: 1:28 - loss: 0.8275 - accuracy: 0.85 - ETA: 1:27 - loss: 0.8264 - accuracy: 0.85 - ETA: 1:26 - loss: 0.8250 - accuracy: 0.85 - ETA: 1:25 - loss: 0.8185 - accuracy: 0.85 - ETA: 1:24 - loss: 0.8154 - accuracy: 0.85 - ETA: 1:23 - loss: 0.8158 - accuracy: 0.85 - ETA: 1:22 - loss: 0.8190 - accuracy: 0.85 - ETA: 1:21 - loss: 0.8192 - accuracy: 0.85 - ETA: 1:20 - loss: 0.8177 - accuracy: 0.85 - ETA: 1:19 - loss: 0.8205 - accuracy: 0.85 - ETA: 1:18 - loss: 0.8174 - accuracy: 0.85 - ETA: 1:17 - loss: 0.8209 - accuracy: 0.85 - ETA: 1:16 - loss: 0.8198 - accuracy: 0.85 - ETA: 1:15 - loss: 0.8172 - accuracy: 0.85 - ETA: 1:14 - loss: 0.8157 - accuracy: 0.85 - ETA: 1:13 - loss: 0.8131 - accuracy: 0.85 - ETA: 1:12 - loss: 0.8106 - accuracy: 0.85 - ETA: 1:11 - loss: 0.8106 - accuracy: 0.85 - ETA: 1:11 - loss: 0.8204 - accuracy: 0.85 - ETA: 1:09 - loss: 0.8263 - accuracy: 0.85 - ETA: 1:09 - loss: 0.8255 - accuracy: 0.85 - ETA: 1:08 - loss: 0.8208 - accuracy: 0.85 - ETA: 1:07 - loss: 0.8207 - accuracy: 0.85 - ETA: 1:06 - loss: 0.8234 - accuracy: 0.85 - ETA: 1:05 - loss: 0.8257 - accuracy: 0.85 - ETA: 1:04 - loss: 0.8192 - accuracy: 0.85 - ETA: 1:03 - loss: 0.8157 - accuracy: 0.85 - ETA: 1:02 - loss: 0.8141 - accuracy: 0.85 - ETA: 1:01 - loss: 0.8173 - accuracy: 0.85 - ETA: 1:00 - loss: 0.8156 - accuracy: 0.85 - ETA: 59s - loss: 0.8188 - accuracy: 0.8542 - ETA: 58s - loss: 0.8203 - accuracy: 0.854 - ETA: 57s - loss: 0.8254 - accuracy: 0.854 - ETA: 56s - loss: 0.8249 - accuracy: 0.855 - ETA: 55s - loss: 0.8257 - accuracy: 0.855 - ETA: 54s - loss: 0.8214 - accuracy: 0.855 - ETA: 53s - loss: 0.8208 - accuracy: 0.855 - ETA: 52s - loss: 0.8173 - accuracy: 0.855 - ETA: 51s - loss: 0.8151 - accuracy: 0.855 - ETA: 50s - loss: 0.8125 - accuracy: 0.855 - ETA: 49s - loss: 0.8122 - accuracy: 0.855 - ETA: 48s - loss: 0.8121 - accuracy: 0.854 - ETA: 47s - loss: 0.8102 - accuracy: 0.855 - ETA: 47s - loss: 0.8078 - accuracy: 0.855 - ETA: 46s - loss: 0.8075 - accuracy: 0.856 - ETA: 45s - loss: 0.8057 - accuracy: 0.855 - ETA: 44s - loss: 0.8066 - accuracy: 0.856 - ETA: 43s - loss: 0.8040 - accuracy: 0.856 - ETA: 42s - loss: 0.8019 - accuracy: 0.856 - ETA: 41s - loss: 0.8042 - accuracy: 0.856 - ETA: 40s - loss: 0.8036 - accuracy: 0.856 - ETA: 39s - loss: 0.8073 - accuracy: 0.856 - ETA: 38s - loss: 0.8090 - accuracy: 0.856 - ETA: 37s - loss: 0.8128 - accuracy: 0.856 - ETA: 36s - loss: 0.8112 - accuracy: 0.856 - ETA: 35s - loss: 0.8080 - accuracy: 0.857 - ETA: 34s - loss: 0.8086 - accuracy: 0.856 - ETA: 33s - loss: 0.8088 - accuracy: 0.856 - ETA: 32s - loss: 0.8048 - accuracy: 0.856 - ETA: 31s - loss: 0.8042 - accuracy: 0.856 - ETA: 30s - loss: 0.8048 - accuracy: 0.856 - ETA: 29s - loss: 0.8043 - accuracy: 0.856 - ETA: 28s - loss: 0.8028 - accuracy: 0.856 - ETA: 27s - loss: 0.8010 - accuracy: 0.856 - ETA: 26s - loss: 0.7987 - accuracy: 0.856 - ETA: 25s - loss: 0.8016 - accuracy: 0.856 - ETA: 24s - loss: 0.8015 - accuracy: 0.856 - ETA: 23s - loss: 0.8019 - accuracy: 0.856 - ETA: 22s - loss: 0.8026 - accuracy: 0.857 - ETA: 21s - loss: 0.8060 - accuracy: 0.856 - ETA: 20s - loss: 0.8076 - accuracy: 0.856 - ETA: 20s - loss: 0.8053 - accuracy: 0.856 - ETA: 19s - loss: 0.8065 - accuracy: 0.856 - ETA: 18s - loss: 0.8083 - accuracy: 0.857 - ETA: 17s - loss: 0.8058 - accuracy: 0.857 - ETA: 16s - loss: 0.8043 - accuracy: 0.857 - ETA: 15s - loss: 0.8109 - accuracy: 0.857 - ETA: 14s - loss: 0.8122 - accuracy: 0.857 - ETA: 13s - loss: 0.8117 - accuracy: 0.857 - ETA: 12s - loss: 0.8102 - accuracy: 0.857 - ETA: 11s - loss: 0.8132 - accuracy: 0.857 - ETA: 10s - loss: 0.8120 - accuracy: 0.857 - ETA: 9s - loss: 0.8094 - accuracy: 0.857 - ETA: 8s - loss: 0.8117 - accuracy: 0.85 - ETA: 7s - loss: 0.8123 - accuracy: 0.85 - ETA: 6s - loss: 0.8157 - accuracy: 0.85 - ETA: 5s - loss: 0.8171 - accuracy: 0.85 - ETA: 4s - loss: 0.8154 - accuracy: 0.85 - ETA: 3s - loss: 0.8160 - accuracy: 0.85 - ETA: 2s - loss: 0.8136 - accuracy: 0.85 - ETA: 1s - loss: 0.8141 - accuracy: 0.85 - ETA: 0s - loss: 0.8142 - accuracy: 0.85 - 156s 8ms/step - loss: 0.8132 - accuracy: 0.8570 - val_loss: 3.4578 - val_accuracy: 0.7710\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:34 - loss: 0.6522 - accuracy: 0.89 - ETA: 2:36 - loss: 0.7280 - accuracy: 0.87 - ETA: 2:38 - loss: 0.6996 - accuracy: 0.86 - ETA: 2:37 - loss: 0.6867 - accuracy: 0.85 - ETA: 2:35 - loss: 0.6424 - accuracy: 0.86 - ETA: 2:34 - loss: 0.6554 - accuracy: 0.86 - ETA: 2:32 - loss: 0.6802 - accuracy: 0.85 - ETA: 2:31 - loss: 0.7582 - accuracy: 0.85 - ETA: 2:29 - loss: 0.8084 - accuracy: 0.84 - ETA: 2:29 - loss: 0.8002 - accuracy: 0.84 - ETA: 2:26 - loss: 0.7957 - accuracy: 0.84 - ETA: 2:24 - loss: 0.8159 - accuracy: 0.85 - ETA: 2:23 - loss: 0.8281 - accuracy: 0.85 - ETA: 2:21 - loss: 0.8131 - accuracy: 0.85 - ETA: 2:18 - loss: 0.8176 - accuracy: 0.85 - ETA: 2:17 - loss: 0.8219 - accuracy: 0.85 - ETA: 2:15 - loss: 0.8144 - accuracy: 0.85 - ETA: 2:14 - loss: 0.8167 - accuracy: 0.85 - ETA: 2:14 - loss: 0.8124 - accuracy: 0.85 - ETA: 2:12 - loss: 0.8075 - accuracy: 0.85 - ETA: 2:11 - loss: 0.7984 - accuracy: 0.85 - ETA: 2:09 - loss: 0.7973 - accuracy: 0.85 - ETA: 2:08 - loss: 0.7884 - accuracy: 0.86 - ETA: 2:07 - loss: 0.7877 - accuracy: 0.86 - ETA: 2:05 - loss: 0.7920 - accuracy: 0.86 - ETA: 2:04 - loss: 0.7972 - accuracy: 0.86 - ETA: 2:03 - loss: 0.8023 - accuracy: 0.85 - ETA: 2:02 - loss: 0.8189 - accuracy: 0.85 - ETA: 2:00 - loss: 0.8062 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7940 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7885 - accuracy: 0.86 - ETA: 1:57 - loss: 0.8001 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7977 - accuracy: 0.86 - ETA: 1:54 - loss: 0.8092 - accuracy: 0.86 - ETA: 1:53 - loss: 0.8104 - accuracy: 0.86 - ETA: 1:53 - loss: 0.8005 - accuracy: 0.86 - ETA: 1:51 - loss: 0.8060 - accuracy: 0.86 - ETA: 1:50 - loss: 0.8102 - accuracy: 0.86 - ETA: 1:49 - loss: 0.8157 - accuracy: 0.86 - ETA: 1:48 - loss: 0.8200 - accuracy: 0.85 - ETA: 1:47 - loss: 0.8173 - accuracy: 0.86 - ETA: 1:46 - loss: 0.8167 - accuracy: 0.86 - ETA: 1:45 - loss: 0.8106 - accuracy: 0.86 - ETA: 1:43 - loss: 0.8153 - accuracy: 0.86 - ETA: 1:42 - loss: 0.8169 - accuracy: 0.86 - ETA: 1:41 - loss: 0.8104 - accuracy: 0.86 - ETA: 1:41 - loss: 0.8070 - accuracy: 0.86 - ETA: 1:39 - loss: 0.8040 - accuracy: 0.86 - ETA: 1:38 - loss: 0.8033 - accuracy: 0.86 - ETA: 1:37 - loss: 0.8024 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7995 - accuracy: 0.86 - ETA: 1:35 - loss: 0.8011 - accuracy: 0.86 - ETA: 1:34 - loss: 0.8007 - accuracy: 0.86 - ETA: 1:33 - loss: 0.7971 - accuracy: 0.86 - ETA: 1:32 - loss: 0.8029 - accuracy: 0.86 - ETA: 1:32 - loss: 0.7989 - accuracy: 0.86 - ETA: 1:31 - loss: 0.7958 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7979 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7972 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7985 - accuracy: 0.86 - ETA: 1:27 - loss: 0.8061 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7996 - accuracy: 0.86 - ETA: 1:25 - loss: 0.8015 - accuracy: 0.86 - ETA: 1:24 - loss: 0.8032 - accuracy: 0.86 - ETA: 1:23 - loss: 0.8033 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7992 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7993 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7963 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7977 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7959 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7982 - accuracy: 0.86 - ETA: 1:16 - loss: 0.8032 - accuracy: 0.86 - ETA: 1:15 - loss: 0.8029 - accuracy: 0.86 - ETA: 1:14 - loss: 0.8008 - accuracy: 0.86 - ETA: 1:13 - loss: 0.8021 - accuracy: 0.86 - ETA: 1:12 - loss: 0.8000 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7975 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7955 - accuracy: 0.86 - ETA: 1:09 - loss: 0.8080 - accuracy: 0.86 - ETA: 1:08 - loss: 0.8094 - accuracy: 0.86 - ETA: 1:07 - loss: 0.8081 - accuracy: 0.86 - ETA: 1:06 - loss: 0.8058 - accuracy: 0.86 - ETA: 1:05 - loss: 0.8058 - accuracy: 0.86 - ETA: 1:04 - loss: 0.8077 - accuracy: 0.86 - ETA: 1:03 - loss: 0.8040 - accuracy: 0.86 - ETA: 1:02 - loss: 0.8035 - accuracy: 0.86 - ETA: 1:01 - loss: 0.8022 - accuracy: 0.86 - ETA: 1:00 - loss: 0.8025 - accuracy: 0.86 - ETA: 59s - loss: 0.8025 - accuracy: 0.8603 - ETA: 58s - loss: 0.7988 - accuracy: 0.860 - ETA: 58s - loss: 0.8002 - accuracy: 0.860 - ETA: 57s - loss: 0.7949 - accuracy: 0.860 - ETA: 56s - loss: 0.7924 - accuracy: 0.860 - ETA: 55s - loss: 0.8009 - accuracy: 0.860 - ETA: 54s - loss: 0.7998 - accuracy: 0.860 - ETA: 53s - loss: 0.7983 - accuracy: 0.860 - ETA: 52s - loss: 0.7963 - accuracy: 0.860 - ETA: 51s - loss: 0.8061 - accuracy: 0.859 - ETA: 50s - loss: 0.8091 - accuracy: 0.859 - ETA: 49s - loss: 0.8124 - accuracy: 0.859 - ETA: 48s - loss: 0.8148 - accuracy: 0.859 - ETA: 47s - loss: 0.8140 - accuracy: 0.858 - ETA: 46s - loss: 0.8153 - accuracy: 0.858 - ETA: 45s - loss: 0.8137 - accuracy: 0.858 - ETA: 44s - loss: 0.8104 - accuracy: 0.858 - ETA: 43s - loss: 0.8136 - accuracy: 0.858 - ETA: 42s - loss: 0.8122 - accuracy: 0.857 - ETA: 41s - loss: 0.8107 - accuracy: 0.857 - ETA: 40s - loss: 0.8137 - accuracy: 0.857 - ETA: 39s - loss: 0.8109 - accuracy: 0.857 - ETA: 38s - loss: 0.8160 - accuracy: 0.857 - ETA: 37s - loss: 0.8202 - accuracy: 0.856 - ETA: 36s - loss: 0.8164 - accuracy: 0.856 - ETA: 35s - loss: 0.8148 - accuracy: 0.856 - ETA: 34s - loss: 0.8150 - accuracy: 0.857 - ETA: 33s - loss: 0.8152 - accuracy: 0.857 - ETA: 32s - loss: 0.8162 - accuracy: 0.857 - ETA: 31s - loss: 0.8155 - accuracy: 0.857 - ETA: 30s - loss: 0.8181 - accuracy: 0.857 - ETA: 29s - loss: 0.8155 - accuracy: 0.857 - ETA: 28s - loss: 0.8251 - accuracy: 0.857 - ETA: 27s - loss: 0.8243 - accuracy: 0.857 - ETA: 26s - loss: 0.8289 - accuracy: 0.856 - ETA: 25s - loss: 0.8287 - accuracy: 0.856 - ETA: 25s - loss: 0.8258 - accuracy: 0.856 - ETA: 24s - loss: 0.8260 - accuracy: 0.856 - ETA: 23s - loss: 0.8266 - accuracy: 0.856 - ETA: 22s - loss: 0.8266 - accuracy: 0.856 - ETA: 21s - loss: 0.8296 - accuracy: 0.856 - ETA: 20s - loss: 0.8322 - accuracy: 0.855 - ETA: 19s - loss: 0.8318 - accuracy: 0.855 - ETA: 18s - loss: 0.8378 - accuracy: 0.855 - ETA: 17s - loss: 0.8363 - accuracy: 0.855 - ETA: 16s - loss: 0.8368 - accuracy: 0.855 - ETA: 15s - loss: 0.8344 - accuracy: 0.855 - ETA: 14s - loss: 0.8355 - accuracy: 0.855 - ETA: 13s - loss: 0.8417 - accuracy: 0.855 - ETA: 12s - loss: 0.8404 - accuracy: 0.855 - ETA: 11s - loss: 0.8388 - accuracy: 0.855 - ETA: 10s - loss: 0.8370 - accuracy: 0.855 - ETA: 9s - loss: 0.8350 - accuracy: 0.855 - ETA: 8s - loss: 0.8368 - accuracy: 0.85 - ETA: 7s - loss: 0.8341 - accuracy: 0.85 - ETA: 6s - loss: 0.8343 - accuracy: 0.85 - ETA: 5s - loss: 0.8326 - accuracy: 0.85 - ETA: 4s - loss: 0.8308 - accuracy: 0.85 - ETA: 3s - loss: 0.8305 - accuracy: 0.85 - ETA: 2s - loss: 0.8282 - accuracy: 0.85 - ETA: 1s - loss: 0.8286 - accuracy: 0.85 - ETA: 0s - loss: 0.8251 - accuracy: 0.85 - 157s 8ms/step - loss: 0.8228 - accuracy: 0.8569 - val_loss: 3.6423 - val_accuracy: 0.7674\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:35 - loss: 1.2377 - accuracy: 0.82 - ETA: 2:32 - loss: 1.1706 - accuracy: 0.83 - ETA: 2:26 - loss: 0.9397 - accuracy: 0.84 - ETA: 2:24 - loss: 0.8786 - accuracy: 0.83 - ETA: 2:21 - loss: 0.9437 - accuracy: 0.83 - ETA: 2:21 - loss: 0.9128 - accuracy: 0.83 - ETA: 2:21 - loss: 0.9469 - accuracy: 0.83 - ETA: 2:20 - loss: 0.9323 - accuracy: 0.83 - ETA: 2:18 - loss: 0.9288 - accuracy: 0.83 - ETA: 2:17 - loss: 0.9042 - accuracy: 0.83 - ETA: 2:16 - loss: 0.9263 - accuracy: 0.83 - ETA: 2:14 - loss: 0.8805 - accuracy: 0.84 - ETA: 2:13 - loss: 0.8532 - accuracy: 0.84 - ETA: 2:12 - loss: 0.8314 - accuracy: 0.84 - ETA: 2:11 - loss: 0.8361 - accuracy: 0.85 - ETA: 2:10 - loss: 0.8293 - accuracy: 0.84 - ETA: 2:09 - loss: 0.8131 - accuracy: 0.84 - ETA: 2:08 - loss: 0.8022 - accuracy: 0.84 - ETA: 2:07 - loss: 0.7987 - accuracy: 0.84 - ETA: 2:05 - loss: 0.7865 - accuracy: 0.85 - ETA: 2:04 - loss: 0.7842 - accuracy: 0.85 - ETA: 2:03 - loss: 0.7691 - accuracy: 0.85 - ETA: 2:03 - loss: 0.7768 - accuracy: 0.85 - ETA: 2:02 - loss: 0.7722 - accuracy: 0.85 - ETA: 2:01 - loss: 0.7818 - accuracy: 0.84 - ETA: 2:01 - loss: 0.7970 - accuracy: 0.84 - ETA: 1:59 - loss: 0.7996 - accuracy: 0.84 - ETA: 1:59 - loss: 0.7892 - accuracy: 0.85 - ETA: 1:58 - loss: 0.7821 - accuracy: 0.85 - ETA: 1:57 - loss: 0.7802 - accuracy: 0.85 - ETA: 1:55 - loss: 0.7754 - accuracy: 0.85 - ETA: 1:54 - loss: 0.7725 - accuracy: 0.85 - ETA: 1:54 - loss: 0.7734 - accuracy: 0.85 - ETA: 1:52 - loss: 0.7899 - accuracy: 0.85 - ETA: 1:51 - loss: 0.8020 - accuracy: 0.85 - ETA: 1:51 - loss: 0.8125 - accuracy: 0.85 - ETA: 1:50 - loss: 0.8026 - accuracy: 0.85 - ETA: 1:49 - loss: 0.8044 - accuracy: 0.85 - ETA: 1:48 - loss: 0.7978 - accuracy: 0.85 - ETA: 1:47 - loss: 0.7950 - accuracy: 0.85 - ETA: 1:46 - loss: 0.7849 - accuracy: 0.85 - ETA: 1:45 - loss: 0.7793 - accuracy: 0.85 - ETA: 1:44 - loss: 0.7785 - accuracy: 0.85 - ETA: 1:43 - loss: 0.7749 - accuracy: 0.85 - ETA: 1:42 - loss: 0.7884 - accuracy: 0.85 - ETA: 1:41 - loss: 0.8024 - accuracy: 0.85 - ETA: 1:40 - loss: 0.8045 - accuracy: 0.85 - ETA: 1:39 - loss: 0.7994 - accuracy: 0.85 - ETA: 1:38 - loss: 0.7915 - accuracy: 0.85 - ETA: 1:37 - loss: 0.7863 - accuracy: 0.85 - ETA: 1:36 - loss: 0.7795 - accuracy: 0.85 - ETA: 1:35 - loss: 0.7760 - accuracy: 0.85 - ETA: 1:34 - loss: 0.7762 - accuracy: 0.85 - ETA: 1:33 - loss: 0.7746 - accuracy: 0.85 - ETA: 1:32 - loss: 0.7777 - accuracy: 0.85 - ETA: 1:31 - loss: 0.7811 - accuracy: 0.85 - ETA: 1:30 - loss: 0.7808 - accuracy: 0.85 - ETA: 1:29 - loss: 0.7877 - accuracy: 0.85 - ETA: 1:28 - loss: 0.7856 - accuracy: 0.85 - ETA: 1:27 - loss: 0.7870 - accuracy: 0.85 - ETA: 1:26 - loss: 0.7945 - accuracy: 0.85 - ETA: 1:25 - loss: 0.7949 - accuracy: 0.85 - ETA: 1:24 - loss: 0.7903 - accuracy: 0.85 - ETA: 1:23 - loss: 0.7881 - accuracy: 0.85 - ETA: 1:22 - loss: 0.7910 - accuracy: 0.85 - ETA: 1:21 - loss: 0.7863 - accuracy: 0.85 - ETA: 1:20 - loss: 0.7854 - accuracy: 0.85 - ETA: 1:19 - loss: 0.7829 - accuracy: 0.85 - ETA: 1:18 - loss: 0.7808 - accuracy: 0.85 - ETA: 1:17 - loss: 0.7797 - accuracy: 0.85 - ETA: 1:16 - loss: 0.7757 - accuracy: 0.85 - ETA: 1:15 - loss: 0.7789 - accuracy: 0.85 - ETA: 1:14 - loss: 0.7830 - accuracy: 0.85 - ETA: 1:13 - loss: 0.7884 - accuracy: 0.85 - ETA: 1:12 - loss: 0.7872 - accuracy: 0.85 - ETA: 1:11 - loss: 0.7826 - accuracy: 0.85 - ETA: 1:10 - loss: 0.7818 - accuracy: 0.85 - ETA: 1:09 - loss: 0.7816 - accuracy: 0.85 - ETA: 1:09 - loss: 0.7821 - accuracy: 0.85 - ETA: 1:08 - loss: 0.7815 - accuracy: 0.85 - ETA: 1:07 - loss: 0.7859 - accuracy: 0.85 - ETA: 1:06 - loss: 0.7873 - accuracy: 0.85 - ETA: 1:05 - loss: 0.7870 - accuracy: 0.85 - ETA: 1:04 - loss: 0.7824 - accuracy: 0.85 - ETA: 1:03 - loss: 0.7828 - accuracy: 0.85 - ETA: 1:02 - loss: 0.7926 - accuracy: 0.85 - ETA: 1:01 - loss: 0.7957 - accuracy: 0.85 - ETA: 1:00 - loss: 0.7941 - accuracy: 0.85 - ETA: 59s - loss: 0.7947 - accuracy: 0.8570 - ETA: 58s - loss: 0.7932 - accuracy: 0.856 - ETA: 57s - loss: 0.7979 - accuracy: 0.855 - ETA: 56s - loss: 0.7959 - accuracy: 0.856 - ETA: 55s - loss: 0.7944 - accuracy: 0.856 - ETA: 54s - loss: 0.8052 - accuracy: 0.856 - ETA: 53s - loss: 0.8084 - accuracy: 0.855 - ETA: 52s - loss: 0.8125 - accuracy: 0.855 - ETA: 51s - loss: 0.8114 - accuracy: 0.854 - ETA: 50s - loss: 0.8116 - accuracy: 0.854 - ETA: 49s - loss: 0.8113 - accuracy: 0.855 - ETA: 48s - loss: 0.8204 - accuracy: 0.854 - ETA: 47s - loss: 0.8222 - accuracy: 0.854 - ETA: 47s - loss: 0.8229 - accuracy: 0.854 - ETA: 46s - loss: 0.8198 - accuracy: 0.855 - ETA: 45s - loss: 0.8198 - accuracy: 0.855 - ETA: 44s - loss: 0.8179 - accuracy: 0.855 - ETA: 43s - loss: 0.8198 - accuracy: 0.855 - ETA: 42s - loss: 0.8203 - accuracy: 0.855 - ETA: 41s - loss: 0.8171 - accuracy: 0.855 - ETA: 40s - loss: 0.8171 - accuracy: 0.855 - ETA: 39s - loss: 0.8122 - accuracy: 0.856 - ETA: 38s - loss: 0.8121 - accuracy: 0.856 - ETA: 37s - loss: 0.8152 - accuracy: 0.856 - ETA: 36s - loss: 0.8118 - accuracy: 0.857 - ETA: 35s - loss: 0.8088 - accuracy: 0.857 - ETA: 34s - loss: 0.8098 - accuracy: 0.857 - ETA: 33s - loss: 0.8126 - accuracy: 0.856 - ETA: 32s - loss: 0.8109 - accuracy: 0.856 - ETA: 31s - loss: 0.8099 - accuracy: 0.856 - ETA: 30s - loss: 0.8094 - accuracy: 0.857 - ETA: 29s - loss: 0.8080 - accuracy: 0.856 - ETA: 28s - loss: 0.8084 - accuracy: 0.857 - ETA: 27s - loss: 0.8084 - accuracy: 0.857 - ETA: 26s - loss: 0.8065 - accuracy: 0.857 - ETA: 25s - loss: 0.8050 - accuracy: 0.858 - ETA: 24s - loss: 0.8048 - accuracy: 0.857 - ETA: 23s - loss: 0.8077 - accuracy: 0.857 - ETA: 22s - loss: 0.8057 - accuracy: 0.858 - ETA: 22s - loss: 0.8057 - accuracy: 0.858 - ETA: 21s - loss: 0.8042 - accuracy: 0.858 - ETA: 20s - loss: 0.8032 - accuracy: 0.858 - ETA: 19s - loss: 0.8029 - accuracy: 0.858 - ETA: 18s - loss: 0.8021 - accuracy: 0.859 - ETA: 17s - loss: 0.8035 - accuracy: 0.858 - ETA: 16s - loss: 0.8067 - accuracy: 0.858 - ETA: 15s - loss: 0.8050 - accuracy: 0.858 - ETA: 14s - loss: 0.8058 - accuracy: 0.858 - ETA: 13s - loss: 0.8073 - accuracy: 0.858 - ETA: 12s - loss: 0.8079 - accuracy: 0.858 - ETA: 11s - loss: 0.8084 - accuracy: 0.858 - ETA: 10s - loss: 0.8094 - accuracy: 0.858 - ETA: 9s - loss: 0.8073 - accuracy: 0.858 - ETA: 8s - loss: 0.8044 - accuracy: 0.85 - ETA: 7s - loss: 0.8074 - accuracy: 0.85 - ETA: 6s - loss: 0.8121 - accuracy: 0.85 - ETA: 5s - loss: 0.8113 - accuracy: 0.85 - ETA: 4s - loss: 0.8095 - accuracy: 0.85 - ETA: 3s - loss: 0.8117 - accuracy: 0.85 - ETA: 2s - loss: 0.8115 - accuracy: 0.85 - ETA: 1s - loss: 0.8109 - accuracy: 0.85 - ETA: 0s - loss: 0.8077 - accuracy: 0.85 - 156s 8ms/step - loss: 0.8094 - accuracy: 0.8583 - val_loss: 3.7130 - val_accuracy: 0.7660\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:42 - loss: 0.7696 - accuracy: 0.84 - ETA: 2:27 - loss: 0.8333 - accuracy: 0.82 - ETA: 2:25 - loss: 0.6961 - accuracy: 0.85 - ETA: 2:23 - loss: 0.6934 - accuracy: 0.84 - ETA: 2:22 - loss: 0.6174 - accuracy: 0.86 - ETA: 2:19 - loss: 0.6156 - accuracy: 0.86 - ETA: 2:18 - loss: 0.6511 - accuracy: 0.86 - ETA: 2:17 - loss: 0.6594 - accuracy: 0.87 - ETA: 2:16 - loss: 0.7375 - accuracy: 0.87 - ETA: 2:17 - loss: 0.7238 - accuracy: 0.87 - ETA: 2:16 - loss: 0.7496 - accuracy: 0.87 - ETA: 2:16 - loss: 0.7507 - accuracy: 0.87 - ETA: 2:15 - loss: 0.7539 - accuracy: 0.86 - ETA: 2:14 - loss: 0.7611 - accuracy: 0.86 - ETA: 2:12 - loss: 0.7423 - accuracy: 0.86 - ETA: 2:12 - loss: 0.7999 - accuracy: 0.86 - ETA: 2:10 - loss: 0.7900 - accuracy: 0.86 - ETA: 2:10 - loss: 0.8530 - accuracy: 0.86 - ETA: 2:09 - loss: 0.8622 - accuracy: 0.86 - ETA: 2:07 - loss: 0.8618 - accuracy: 0.86 - ETA: 2:06 - loss: 0.8446 - accuracy: 0.86 - ETA: 2:05 - loss: 0.8467 - accuracy: 0.86 - ETA: 2:04 - loss: 0.8432 - accuracy: 0.86 - ETA: 2:03 - loss: 0.8594 - accuracy: 0.86 - ETA: 2:01 - loss: 0.8650 - accuracy: 0.86 - ETA: 2:00 - loss: 0.8587 - accuracy: 0.86 - ETA: 2:00 - loss: 0.8486 - accuracy: 0.86 - ETA: 1:59 - loss: 0.8367 - accuracy: 0.86 - ETA: 1:58 - loss: 0.8397 - accuracy: 0.86 - ETA: 1:57 - loss: 0.8419 - accuracy: 0.85 - ETA: 1:56 - loss: 0.8365 - accuracy: 0.85 - ETA: 1:55 - loss: 0.8273 - accuracy: 0.85 - ETA: 1:53 - loss: 0.8266 - accuracy: 0.86 - ETA: 1:52 - loss: 0.8236 - accuracy: 0.86 - ETA: 1:51 - loss: 0.8167 - accuracy: 0.86 - ETA: 1:50 - loss: 0.8099 - accuracy: 0.86 - ETA: 1:49 - loss: 0.8041 - accuracy: 0.86 - ETA: 1:48 - loss: 0.8063 - accuracy: 0.86 - ETA: 1:47 - loss: 0.8092 - accuracy: 0.86 - ETA: 1:46 - loss: 0.8038 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7986 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7972 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7911 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7963 - accuracy: 0.86 - ETA: 1:42 - loss: 0.8036 - accuracy: 0.86 - ETA: 1:41 - loss: 0.8039 - accuracy: 0.86 - ETA: 1:40 - loss: 0.8071 - accuracy: 0.86 - ETA: 1:39 - loss: 0.8250 - accuracy: 0.86 - ETA: 1:38 - loss: 0.8289 - accuracy: 0.86 - ETA: 1:37 - loss: 0.8288 - accuracy: 0.86 - ETA: 1:36 - loss: 0.8303 - accuracy: 0.86 - ETA: 1:35 - loss: 0.8260 - accuracy: 0.86 - ETA: 1:34 - loss: 0.8319 - accuracy: 0.86 - ETA: 1:33 - loss: 0.8250 - accuracy: 0.86 - ETA: 1:32 - loss: 0.8265 - accuracy: 0.86 - ETA: 1:31 - loss: 0.8263 - accuracy: 0.86 - ETA: 1:30 - loss: 0.8178 - accuracy: 0.86 - ETA: 1:29 - loss: 0.8169 - accuracy: 0.86 - ETA: 1:28 - loss: 0.8135 - accuracy: 0.86 - ETA: 1:27 - loss: 0.8087 - accuracy: 0.86 - ETA: 1:26 - loss: 0.8058 - accuracy: 0.86 - ETA: 1:25 - loss: 0.8072 - accuracy: 0.86 - ETA: 1:24 - loss: 0.8053 - accuracy: 0.86 - ETA: 1:23 - loss: 0.8017 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7955 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7934 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7964 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7932 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7882 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7873 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7993 - accuracy: 0.85 - ETA: 1:15 - loss: 0.7929 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7965 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7923 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7871 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7901 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7977 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7945 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7936 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7944 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7969 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7918 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7904 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7874 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7900 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7889 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7859 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7851 - accuracy: 0.86 - ETA: 59s - loss: 0.7858 - accuracy: 0.8621 - ETA: 58s - loss: 0.7831 - accuracy: 0.862 - ETA: 57s - loss: 0.7853 - accuracy: 0.861 - ETA: 56s - loss: 0.7844 - accuracy: 0.861 - ETA: 55s - loss: 0.7824 - accuracy: 0.861 - ETA: 54s - loss: 0.7824 - accuracy: 0.862 - ETA: 53s - loss: 0.7809 - accuracy: 0.861 - ETA: 52s - loss: 0.7808 - accuracy: 0.861 - ETA: 51s - loss: 0.7884 - accuracy: 0.861 - ETA: 50s - loss: 0.7861 - accuracy: 0.861 - ETA: 49s - loss: 0.7890 - accuracy: 0.861 - ETA: 48s - loss: 0.7849 - accuracy: 0.861 - ETA: 48s - loss: 0.7857 - accuracy: 0.861 - ETA: 47s - loss: 0.7858 - accuracy: 0.861 - ETA: 46s - loss: 0.7832 - accuracy: 0.861 - ETA: 45s - loss: 0.7837 - accuracy: 0.861 - ETA: 44s - loss: 0.7883 - accuracy: 0.861 - ETA: 43s - loss: 0.7862 - accuracy: 0.861 - ETA: 42s - loss: 0.7884 - accuracy: 0.861 - ETA: 41s - loss: 0.7865 - accuracy: 0.861 - ETA: 40s - loss: 0.7894 - accuracy: 0.861 - ETA: 39s - loss: 0.7922 - accuracy: 0.861 - ETA: 38s - loss: 0.7918 - accuracy: 0.861 - ETA: 37s - loss: 0.7918 - accuracy: 0.861 - ETA: 36s - loss: 0.7902 - accuracy: 0.861 - ETA: 35s - loss: 0.7893 - accuracy: 0.861 - ETA: 34s - loss: 0.7871 - accuracy: 0.861 - ETA: 33s - loss: 0.7843 - accuracy: 0.861 - ETA: 32s - loss: 0.7852 - accuracy: 0.861 - ETA: 31s - loss: 0.7869 - accuracy: 0.862 - ETA: 30s - loss: 0.7851 - accuracy: 0.862 - ETA: 29s - loss: 0.7921 - accuracy: 0.861 - ETA: 28s - loss: 0.7903 - accuracy: 0.861 - ETA: 27s - loss: 0.7906 - accuracy: 0.861 - ETA: 26s - loss: 0.7906 - accuracy: 0.861 - ETA: 25s - loss: 0.7893 - accuracy: 0.861 - ETA: 24s - loss: 0.7891 - accuracy: 0.861 - ETA: 23s - loss: 0.7864 - accuracy: 0.861 - ETA: 22s - loss: 0.7867 - accuracy: 0.861 - ETA: 21s - loss: 0.7852 - accuracy: 0.861 - ETA: 20s - loss: 0.7833 - accuracy: 0.862 - ETA: 20s - loss: 0.7804 - accuracy: 0.862 - ETA: 19s - loss: 0.7873 - accuracy: 0.861 - ETA: 18s - loss: 0.7852 - accuracy: 0.861 - ETA: 17s - loss: 0.7821 - accuracy: 0.862 - ETA: 16s - loss: 0.7823 - accuracy: 0.861 - ETA: 15s - loss: 0.7858 - accuracy: 0.861 - ETA: 14s - loss: 0.7841 - accuracy: 0.862 - ETA: 13s - loss: 0.7834 - accuracy: 0.862 - ETA: 12s - loss: 0.7817 - accuracy: 0.862 - ETA: 11s - loss: 0.7868 - accuracy: 0.861 - ETA: 10s - loss: 0.7879 - accuracy: 0.861 - ETA: 9s - loss: 0.7900 - accuracy: 0.861 - ETA: 8s - loss: 0.7958 - accuracy: 0.86 - ETA: 7s - loss: 0.7985 - accuracy: 0.86 - ETA: 6s - loss: 0.8005 - accuracy: 0.86 - ETA: 5s - loss: 0.7989 - accuracy: 0.86 - ETA: 4s - loss: 0.8000 - accuracy: 0.86 - ETA: 3s - loss: 0.8008 - accuracy: 0.86 - ETA: 2s - loss: 0.7989 - accuracy: 0.86 - ETA: 1s - loss: 0.7959 - accuracy: 0.86 - ETA: 0s - loss: 0.7972 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7966 - accuracy: 0.8616 - val_loss: 3.4162 - val_accuracy: 0.7710\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:23 - loss: 0.8618 - accuracy: 0.85 - ETA: 2:23 - loss: 1.0297 - accuracy: 0.85 - ETA: 2:22 - loss: 0.8924 - accuracy: 0.85 - ETA: 2:22 - loss: 0.7802 - accuracy: 0.86 - ETA: 2:21 - loss: 0.7395 - accuracy: 0.87 - ETA: 2:19 - loss: 0.8081 - accuracy: 0.86 - ETA: 2:18 - loss: 0.7618 - accuracy: 0.86 - ETA: 2:16 - loss: 0.8060 - accuracy: 0.86 - ETA: 2:14 - loss: 0.7671 - accuracy: 0.86 - ETA: 2:13 - loss: 0.7578 - accuracy: 0.87 - ETA: 2:12 - loss: 0.7684 - accuracy: 0.86 - ETA: 2:12 - loss: 0.7863 - accuracy: 0.86 - ETA: 2:11 - loss: 0.8072 - accuracy: 0.86 - ETA: 2:11 - loss: 0.8560 - accuracy: 0.86 - ETA: 2:11 - loss: 0.8722 - accuracy: 0.86 - ETA: 2:09 - loss: 0.8680 - accuracy: 0.86 - ETA: 2:08 - loss: 0.8396 - accuracy: 0.86 - ETA: 2:07 - loss: 0.8598 - accuracy: 0.86 - ETA: 2:06 - loss: 0.8568 - accuracy: 0.86 - ETA: 2:04 - loss: 0.8533 - accuracy: 0.85 - ETA: 2:04 - loss: 0.8516 - accuracy: 0.85 - ETA: 2:03 - loss: 0.9143 - accuracy: 0.85 - ETA: 2:02 - loss: 0.9018 - accuracy: 0.85 - ETA: 2:01 - loss: 0.8839 - accuracy: 0.85 - ETA: 2:00 - loss: 0.8672 - accuracy: 0.85 - ETA: 1:59 - loss: 0.8790 - accuracy: 0.85 - ETA: 1:58 - loss: 0.8640 - accuracy: 0.85 - ETA: 1:57 - loss: 0.8764 - accuracy: 0.85 - ETA: 1:56 - loss: 0.8646 - accuracy: 0.85 - ETA: 1:55 - loss: 0.8778 - accuracy: 0.85 - ETA: 1:54 - loss: 0.8724 - accuracy: 0.85 - ETA: 1:53 - loss: 0.8764 - accuracy: 0.86 - ETA: 1:52 - loss: 0.8771 - accuracy: 0.85 - ETA: 1:52 - loss: 0.8756 - accuracy: 0.85 - ETA: 1:51 - loss: 0.8712 - accuracy: 0.85 - ETA: 1:50 - loss: 0.8731 - accuracy: 0.85 - ETA: 1:49 - loss: 0.8672 - accuracy: 0.85 - ETA: 1:48 - loss: 0.8643 - accuracy: 0.85 - ETA: 1:47 - loss: 0.8605 - accuracy: 0.85 - ETA: 1:46 - loss: 0.8578 - accuracy: 0.85 - ETA: 1:45 - loss: 0.8601 - accuracy: 0.85 - ETA: 1:44 - loss: 0.8636 - accuracy: 0.85 - ETA: 1:43 - loss: 0.8619 - accuracy: 0.85 - ETA: 1:42 - loss: 0.8645 - accuracy: 0.85 - ETA: 1:41 - loss: 0.8611 - accuracy: 0.85 - ETA: 1:40 - loss: 0.8555 - accuracy: 0.85 - ETA: 1:39 - loss: 0.8501 - accuracy: 0.85 - ETA: 1:38 - loss: 0.8494 - accuracy: 0.85 - ETA: 1:37 - loss: 0.8468 - accuracy: 0.85 - ETA: 1:36 - loss: 0.8403 - accuracy: 0.85 - ETA: 1:35 - loss: 0.8346 - accuracy: 0.85 - ETA: 1:34 - loss: 0.8250 - accuracy: 0.85 - ETA: 1:34 - loss: 0.8222 - accuracy: 0.85 - ETA: 1:33 - loss: 0.8213 - accuracy: 0.85 - ETA: 1:32 - loss: 0.8195 - accuracy: 0.85 - ETA: 1:31 - loss: 0.8173 - accuracy: 0.85 - ETA: 1:30 - loss: 0.8086 - accuracy: 0.85 - ETA: 1:29 - loss: 0.8139 - accuracy: 0.86 - ETA: 1:28 - loss: 0.8075 - accuracy: 0.86 - ETA: 1:27 - loss: 0.8053 - accuracy: 0.86 - ETA: 1:26 - loss: 0.8039 - accuracy: 0.86 - ETA: 1:25 - loss: 0.8025 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7962 - accuracy: 0.86 - ETA: 1:23 - loss: 0.7924 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7925 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7937 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7925 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7889 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7881 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7866 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7843 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7890 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7968 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7906 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7933 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7933 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7950 - accuracy: 0.86 - ETA: 1:09 - loss: 0.8011 - accuracy: 0.86 - ETA: 1:08 - loss: 0.8005 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7985 - accuracy: 0.86 - ETA: 1:06 - loss: 0.8017 - accuracy: 0.86 - ETA: 1:05 - loss: 0.8053 - accuracy: 0.86 - ETA: 1:05 - loss: 0.8021 - accuracy: 0.86 - ETA: 1:04 - loss: 0.8039 - accuracy: 0.86 - ETA: 1:03 - loss: 0.8047 - accuracy: 0.86 - ETA: 1:02 - loss: 0.8029 - accuracy: 0.86 - ETA: 1:01 - loss: 0.8138 - accuracy: 0.86 - ETA: 1:00 - loss: 0.8170 - accuracy: 0.86 - ETA: 59s - loss: 0.8157 - accuracy: 0.8617 - ETA: 58s - loss: 0.8160 - accuracy: 0.861 - ETA: 57s - loss: 0.8175 - accuracy: 0.861 - ETA: 56s - loss: 0.8144 - accuracy: 0.861 - ETA: 55s - loss: 0.8096 - accuracy: 0.861 - ETA: 54s - loss: 0.8137 - accuracy: 0.860 - ETA: 53s - loss: 0.8130 - accuracy: 0.860 - ETA: 52s - loss: 0.8142 - accuracy: 0.860 - ETA: 51s - loss: 0.8137 - accuracy: 0.860 - ETA: 50s - loss: 0.8122 - accuracy: 0.860 - ETA: 49s - loss: 0.8126 - accuracy: 0.860 - ETA: 48s - loss: 0.8124 - accuracy: 0.860 - ETA: 47s - loss: 0.8108 - accuracy: 0.860 - ETA: 46s - loss: 0.8138 - accuracy: 0.860 - ETA: 45s - loss: 0.8146 - accuracy: 0.860 - ETA: 44s - loss: 0.8164 - accuracy: 0.859 - ETA: 43s - loss: 0.8164 - accuracy: 0.859 - ETA: 42s - loss: 0.8155 - accuracy: 0.860 - ETA: 41s - loss: 0.8155 - accuracy: 0.860 - ETA: 40s - loss: 0.8149 - accuracy: 0.859 - ETA: 40s - loss: 0.8154 - accuracy: 0.859 - ETA: 39s - loss: 0.8182 - accuracy: 0.859 - ETA: 38s - loss: 0.8154 - accuracy: 0.859 - ETA: 37s - loss: 0.8144 - accuracy: 0.859 - ETA: 36s - loss: 0.8101 - accuracy: 0.860 - ETA: 35s - loss: 0.8105 - accuracy: 0.859 - ETA: 34s - loss: 0.8107 - accuracy: 0.859 - ETA: 33s - loss: 0.8086 - accuracy: 0.859 - ETA: 32s - loss: 0.8084 - accuracy: 0.859 - ETA: 31s - loss: 0.8064 - accuracy: 0.859 - ETA: 30s - loss: 0.8041 - accuracy: 0.860 - ETA: 29s - loss: 0.8024 - accuracy: 0.860 - ETA: 28s - loss: 0.8034 - accuracy: 0.859 - ETA: 27s - loss: 0.8036 - accuracy: 0.859 - ETA: 26s - loss: 0.8082 - accuracy: 0.859 - ETA: 25s - loss: 0.8074 - accuracy: 0.859 - ETA: 24s - loss: 0.8061 - accuracy: 0.859 - ETA: 23s - loss: 0.8032 - accuracy: 0.859 - ETA: 22s - loss: 0.8063 - accuracy: 0.859 - ETA: 21s - loss: 0.8091 - accuracy: 0.859 - ETA: 20s - loss: 0.8086 - accuracy: 0.859 - ETA: 19s - loss: 0.8074 - accuracy: 0.859 - ETA: 19s - loss: 0.8056 - accuracy: 0.859 - ETA: 18s - loss: 0.8038 - accuracy: 0.859 - ETA: 17s - loss: 0.8033 - accuracy: 0.859 - ETA: 16s - loss: 0.8010 - accuracy: 0.860 - ETA: 15s - loss: 0.7996 - accuracy: 0.860 - ETA: 14s - loss: 0.7970 - accuracy: 0.860 - ETA: 13s - loss: 0.7961 - accuracy: 0.860 - ETA: 12s - loss: 0.7989 - accuracy: 0.860 - ETA: 11s - loss: 0.8015 - accuracy: 0.860 - ETA: 10s - loss: 0.8006 - accuracy: 0.860 - ETA: 9s - loss: 0.8036 - accuracy: 0.859 - ETA: 8s - loss: 0.8029 - accuracy: 0.85 - ETA: 7s - loss: 0.8022 - accuracy: 0.86 - ETA: 6s - loss: 0.8002 - accuracy: 0.86 - ETA: 5s - loss: 0.7973 - accuracy: 0.86 - ETA: 4s - loss: 0.7963 - accuracy: 0.86 - ETA: 3s - loss: 0.7966 - accuracy: 0.86 - ETA: 2s - loss: 0.7970 - accuracy: 0.86 - ETA: 1s - loss: 0.7984 - accuracy: 0.86 - ETA: 0s - loss: 0.7969 - accuracy: 0.86 - 156s 8ms/step - loss: 0.8019 - accuracy: 0.8607 - val_loss: 3.5049 - val_accuracy: 0.7633\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:17 - loss: 0.5280 - accuracy: 0.91 - ETA: 2:26 - loss: 0.6119 - accuracy: 0.89 - ETA: 2:26 - loss: 0.7066 - accuracy: 0.87 - ETA: 2:22 - loss: 0.8360 - accuracy: 0.85 - ETA: 2:20 - loss: 0.8606 - accuracy: 0.86 - ETA: 2:18 - loss: 0.8323 - accuracy: 0.85 - ETA: 2:16 - loss: 0.8142 - accuracy: 0.85 - ETA: 2:15 - loss: 0.8219 - accuracy: 0.85 - ETA: 2:14 - loss: 0.7936 - accuracy: 0.85 - ETA: 2:13 - loss: 0.8174 - accuracy: 0.85 - ETA: 2:11 - loss: 0.8118 - accuracy: 0.85 - ETA: 2:10 - loss: 0.8509 - accuracy: 0.85 - ETA: 2:09 - loss: 0.8604 - accuracy: 0.84 - ETA: 2:08 - loss: 0.8492 - accuracy: 0.85 - ETA: 2:08 - loss: 0.8553 - accuracy: 0.85 - ETA: 2:07 - loss: 0.8587 - accuracy: 0.85 - ETA: 2:06 - loss: 0.8425 - accuracy: 0.85 - ETA: 2:05 - loss: 0.8527 - accuracy: 0.85 - ETA: 2:05 - loss: 0.8267 - accuracy: 0.85 - ETA: 2:04 - loss: 0.8157 - accuracy: 0.86 - ETA: 2:03 - loss: 0.8108 - accuracy: 0.86 - ETA: 2:02 - loss: 0.7979 - accuracy: 0.86 - ETA: 2:01 - loss: 0.8054 - accuracy: 0.85 - ETA: 2:00 - loss: 0.7964 - accuracy: 0.85 - ETA: 1:59 - loss: 0.7929 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7795 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7713 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7609 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7655 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7711 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7620 - accuracy: 0.86 - ETA: 1:53 - loss: 0.7651 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7575 - accuracy: 0.86 - ETA: 1:51 - loss: 0.7757 - accuracy: 0.86 - ETA: 1:50 - loss: 0.7784 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7729 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7899 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7868 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7980 - accuracy: 0.85 - ETA: 1:46 - loss: 0.7907 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7960 - accuracy: 0.85 - ETA: 1:44 - loss: 0.8059 - accuracy: 0.85 - ETA: 1:43 - loss: 0.7963 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7915 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7871 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7866 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7838 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7753 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7736 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7701 - accuracy: 0.86 - ETA: 1:35 - loss: 0.7667 - accuracy: 0.86 - ETA: 1:34 - loss: 0.7680 - accuracy: 0.86 - ETA: 1:33 - loss: 0.7668 - accuracy: 0.85 - ETA: 1:32 - loss: 0.7665 - accuracy: 0.85 - ETA: 1:31 - loss: 0.7596 - accuracy: 0.85 - ETA: 1:30 - loss: 0.7522 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7479 - accuracy: 0.86 - ETA: 1:28 - loss: 0.7516 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7507 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7504 - accuracy: 0.86 - ETA: 1:25 - loss: 0.7497 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7521 - accuracy: 0.86 - ETA: 1:23 - loss: 0.7629 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7592 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7558 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7573 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7615 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7628 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7750 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7807 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7779 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7800 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7822 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7870 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7934 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7929 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7883 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7839 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7912 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7883 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7863 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7878 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7906 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7895 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7864 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7835 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7805 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7792 - accuracy: 0.86 - ETA: 59s - loss: 0.7796 - accuracy: 0.8626 - ETA: 58s - loss: 0.7765 - accuracy: 0.862 - ETA: 57s - loss: 0.7752 - accuracy: 0.862 - ETA: 56s - loss: 0.7745 - accuracy: 0.862 - ETA: 55s - loss: 0.7734 - accuracy: 0.862 - ETA: 54s - loss: 0.7709 - accuracy: 0.862 - ETA: 53s - loss: 0.7701 - accuracy: 0.862 - ETA: 52s - loss: 0.7686 - accuracy: 0.862 - ETA: 51s - loss: 0.7687 - accuracy: 0.862 - ETA: 50s - loss: 0.7709 - accuracy: 0.861 - ETA: 49s - loss: 0.7683 - accuracy: 0.862 - ETA: 48s - loss: 0.7683 - accuracy: 0.862 - ETA: 47s - loss: 0.7712 - accuracy: 0.861 - ETA: 46s - loss: 0.7693 - accuracy: 0.861 - ETA: 45s - loss: 0.7672 - accuracy: 0.861 - ETA: 44s - loss: 0.7686 - accuracy: 0.861 - ETA: 43s - loss: 0.7679 - accuracy: 0.861 - ETA: 42s - loss: 0.7675 - accuracy: 0.861 - ETA: 41s - loss: 0.7659 - accuracy: 0.861 - ETA: 41s - loss: 0.7705 - accuracy: 0.861 - ETA: 40s - loss: 0.7670 - accuracy: 0.861 - ETA: 39s - loss: 0.7625 - accuracy: 0.862 - ETA: 38s - loss: 0.7640 - accuracy: 0.862 - ETA: 37s - loss: 0.7649 - accuracy: 0.862 - ETA: 36s - loss: 0.7691 - accuracy: 0.862 - ETA: 35s - loss: 0.7662 - accuracy: 0.862 - ETA: 34s - loss: 0.7685 - accuracy: 0.862 - ETA: 33s - loss: 0.7695 - accuracy: 0.862 - ETA: 32s - loss: 0.7691 - accuracy: 0.862 - ETA: 31s - loss: 0.7677 - accuracy: 0.862 - ETA: 30s - loss: 0.7673 - accuracy: 0.862 - ETA: 29s - loss: 0.7648 - accuracy: 0.862 - ETA: 28s - loss: 0.7633 - accuracy: 0.862 - ETA: 27s - loss: 0.7652 - accuracy: 0.862 - ETA: 26s - loss: 0.7647 - accuracy: 0.862 - ETA: 25s - loss: 0.7631 - accuracy: 0.862 - ETA: 24s - loss: 0.7631 - accuracy: 0.862 - ETA: 23s - loss: 0.7598 - accuracy: 0.862 - ETA: 22s - loss: 0.7583 - accuracy: 0.862 - ETA: 21s - loss: 0.7571 - accuracy: 0.862 - ETA: 20s - loss: 0.7575 - accuracy: 0.862 - ETA: 19s - loss: 0.7564 - accuracy: 0.862 - ETA: 19s - loss: 0.7546 - accuracy: 0.863 - ETA: 18s - loss: 0.7545 - accuracy: 0.862 - ETA: 17s - loss: 0.7551 - accuracy: 0.862 - ETA: 16s - loss: 0.7554 - accuracy: 0.862 - ETA: 15s - loss: 0.7565 - accuracy: 0.862 - ETA: 14s - loss: 0.7564 - accuracy: 0.862 - ETA: 13s - loss: 0.7576 - accuracy: 0.862 - ETA: 12s - loss: 0.7609 - accuracy: 0.862 - ETA: 11s - loss: 0.7590 - accuracy: 0.862 - ETA: 10s - loss: 0.7609 - accuracy: 0.862 - ETA: 9s - loss: 0.7608 - accuracy: 0.862 - ETA: 8s - loss: 0.7631 - accuracy: 0.86 - ETA: 7s - loss: 0.7617 - accuracy: 0.86 - ETA: 6s - loss: 0.7596 - accuracy: 0.86 - ETA: 5s - loss: 0.7604 - accuracy: 0.86 - ETA: 4s - loss: 0.7645 - accuracy: 0.86 - ETA: 3s - loss: 0.7678 - accuracy: 0.86 - ETA: 2s - loss: 0.7660 - accuracy: 0.86 - ETA: 1s - loss: 0.7657 - accuracy: 0.86 - ETA: 0s - loss: 0.7670 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7657 - accuracy: 0.8614 - val_loss: 3.5619 - val_accuracy: 0.7625\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:26 - loss: 1.3137 - accuracy: 0.82 - ETA: 2:25 - loss: 0.9865 - accuracy: 0.84 - ETA: 2:25 - loss: 0.8885 - accuracy: 0.85 - ETA: 2:24 - loss: 0.7634 - accuracy: 0.86 - ETA: 2:21 - loss: 0.7873 - accuracy: 0.86 - ETA: 2:22 - loss: 0.8094 - accuracy: 0.86 - ETA: 2:24 - loss: 0.7454 - accuracy: 0.87 - ETA: 2:22 - loss: 0.7220 - accuracy: 0.87 - ETA: 2:20 - loss: 0.7464 - accuracy: 0.86 - ETA: 2:19 - loss: 0.7783 - accuracy: 0.86 - ETA: 2:18 - loss: 0.7678 - accuracy: 0.86 - ETA: 2:15 - loss: 0.7907 - accuracy: 0.86 - ETA: 2:15 - loss: 0.7710 - accuracy: 0.86 - ETA: 2:14 - loss: 0.8027 - accuracy: 0.85 - ETA: 2:13 - loss: 0.7986 - accuracy: 0.85 - ETA: 2:12 - loss: 0.7975 - accuracy: 0.85 - ETA: 2:11 - loss: 0.8065 - accuracy: 0.85 - ETA: 2:10 - loss: 0.8390 - accuracy: 0.85 - ETA: 2:08 - loss: 0.8240 - accuracy: 0.85 - ETA: 2:07 - loss: 0.8106 - accuracy: 0.85 - ETA: 2:06 - loss: 0.7999 - accuracy: 0.85 - ETA: 2:05 - loss: 0.8383 - accuracy: 0.85 - ETA: 2:04 - loss: 0.8261 - accuracy: 0.85 - ETA: 2:03 - loss: 0.8289 - accuracy: 0.85 - ETA: 2:02 - loss: 0.8197 - accuracy: 0.85 - ETA: 2:01 - loss: 0.8295 - accuracy: 0.85 - ETA: 2:00 - loss: 0.8138 - accuracy: 0.86 - ETA: 1:59 - loss: 0.8063 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7992 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7838 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7934 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7974 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7923 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7835 - accuracy: 0.86 - ETA: 1:51 - loss: 0.7918 - accuracy: 0.86 - ETA: 1:50 - loss: 0.8041 - accuracy: 0.86 - ETA: 1:49 - loss: 0.8030 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7921 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7970 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7961 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7919 - accuracy: 0.86 - ETA: 1:44 - loss: 0.8032 - accuracy: 0.85 - ETA: 1:43 - loss: 0.8021 - accuracy: 0.85 - ETA: 1:42 - loss: 0.8013 - accuracy: 0.85 - ETA: 1:41 - loss: 0.8040 - accuracy: 0.85 - ETA: 1:40 - loss: 0.8102 - accuracy: 0.85 - ETA: 1:39 - loss: 0.8043 - accuracy: 0.85 - ETA: 1:38 - loss: 0.7985 - accuracy: 0.85 - ETA: 1:37 - loss: 0.7977 - accuracy: 0.85 - ETA: 1:36 - loss: 0.7978 - accuracy: 0.85 - ETA: 1:35 - loss: 0.8006 - accuracy: 0.85 - ETA: 1:34 - loss: 0.8011 - accuracy: 0.85 - ETA: 1:33 - loss: 0.8014 - accuracy: 0.85 - ETA: 1:32 - loss: 0.8023 - accuracy: 0.85 - ETA: 1:31 - loss: 0.7995 - accuracy: 0.85 - ETA: 1:30 - loss: 0.7994 - accuracy: 0.85 - ETA: 1:29 - loss: 0.7958 - accuracy: 0.85 - ETA: 1:29 - loss: 0.7975 - accuracy: 0.85 - ETA: 1:28 - loss: 0.7937 - accuracy: 0.85 - ETA: 1:27 - loss: 0.7920 - accuracy: 0.85 - ETA: 1:25 - loss: 0.7907 - accuracy: 0.85 - ETA: 1:25 - loss: 0.7890 - accuracy: 0.85 - ETA: 1:24 - loss: 0.7867 - accuracy: 0.85 - ETA: 1:23 - loss: 0.7867 - accuracy: 0.85 - ETA: 1:22 - loss: 0.7846 - accuracy: 0.85 - ETA: 1:21 - loss: 0.7833 - accuracy: 0.85 - ETA: 1:20 - loss: 0.7816 - accuracy: 0.85 - ETA: 1:19 - loss: 0.7921 - accuracy: 0.85 - ETA: 1:18 - loss: 0.7956 - accuracy: 0.85 - ETA: 1:17 - loss: 0.7963 - accuracy: 0.85 - ETA: 1:16 - loss: 0.7931 - accuracy: 0.85 - ETA: 1:15 - loss: 0.7945 - accuracy: 0.85 - ETA: 1:14 - loss: 0.7918 - accuracy: 0.85 - ETA: 1:13 - loss: 0.7952 - accuracy: 0.85 - ETA: 1:12 - loss: 0.7939 - accuracy: 0.85 - ETA: 1:11 - loss: 0.7928 - accuracy: 0.85 - ETA: 1:10 - loss: 0.7966 - accuracy: 0.85 - ETA: 1:09 - loss: 0.8118 - accuracy: 0.85 - ETA: 1:08 - loss: 0.8081 - accuracy: 0.85 - ETA: 1:07 - loss: 0.8064 - accuracy: 0.85 - ETA: 1:06 - loss: 0.8070 - accuracy: 0.85 - ETA: 1:05 - loss: 0.8052 - accuracy: 0.85 - ETA: 1:04 - loss: 0.8039 - accuracy: 0.85 - ETA: 1:03 - loss: 0.8038 - accuracy: 0.85 - ETA: 1:02 - loss: 0.8050 - accuracy: 0.85 - ETA: 1:01 - loss: 0.8001 - accuracy: 0.85 - ETA: 1:01 - loss: 0.8028 - accuracy: 0.85 - ETA: 1:00 - loss: 0.8013 - accuracy: 0.85 - ETA: 59s - loss: 0.8121 - accuracy: 0.8573 - ETA: 58s - loss: 0.8151 - accuracy: 0.857 - ETA: 57s - loss: 0.8228 - accuracy: 0.857 - ETA: 56s - loss: 0.8209 - accuracy: 0.857 - ETA: 55s - loss: 0.8259 - accuracy: 0.856 - ETA: 54s - loss: 0.8275 - accuracy: 0.857 - ETA: 53s - loss: 0.8267 - accuracy: 0.856 - ETA: 52s - loss: 0.8242 - accuracy: 0.857 - ETA: 51s - loss: 0.8224 - accuracy: 0.857 - ETA: 50s - loss: 0.8217 - accuracy: 0.857 - ETA: 49s - loss: 0.8179 - accuracy: 0.857 - ETA: 48s - loss: 0.8176 - accuracy: 0.857 - ETA: 47s - loss: 0.8154 - accuracy: 0.857 - ETA: 46s - loss: 0.8144 - accuracy: 0.857 - ETA: 45s - loss: 0.8139 - accuracy: 0.857 - ETA: 44s - loss: 0.8139 - accuracy: 0.857 - ETA: 43s - loss: 0.8177 - accuracy: 0.857 - ETA: 42s - loss: 0.8199 - accuracy: 0.857 - ETA: 41s - loss: 0.8192 - accuracy: 0.857 - ETA: 40s - loss: 0.8157 - accuracy: 0.858 - ETA: 40s - loss: 0.8167 - accuracy: 0.858 - ETA: 39s - loss: 0.8176 - accuracy: 0.857 - ETA: 38s - loss: 0.8143 - accuracy: 0.858 - ETA: 37s - loss: 0.8142 - accuracy: 0.858 - ETA: 36s - loss: 0.8140 - accuracy: 0.857 - ETA: 35s - loss: 0.8101 - accuracy: 0.858 - ETA: 34s - loss: 0.8078 - accuracy: 0.858 - ETA: 33s - loss: 0.8077 - accuracy: 0.858 - ETA: 32s - loss: 0.8104 - accuracy: 0.857 - ETA: 31s - loss: 0.8071 - accuracy: 0.858 - ETA: 30s - loss: 0.8079 - accuracy: 0.858 - ETA: 29s - loss: 0.8055 - accuracy: 0.858 - ETA: 28s - loss: 0.8089 - accuracy: 0.858 - ETA: 27s - loss: 0.8088 - accuracy: 0.857 - ETA: 26s - loss: 0.8090 - accuracy: 0.858 - ETA: 25s - loss: 0.8073 - accuracy: 0.858 - ETA: 24s - loss: 0.8085 - accuracy: 0.858 - ETA: 23s - loss: 0.8059 - accuracy: 0.858 - ETA: 22s - loss: 0.8057 - accuracy: 0.858 - ETA: 21s - loss: 0.8100 - accuracy: 0.858 - ETA: 20s - loss: 0.8109 - accuracy: 0.858 - ETA: 19s - loss: 0.8107 - accuracy: 0.858 - ETA: 18s - loss: 0.8105 - accuracy: 0.858 - ETA: 18s - loss: 0.8100 - accuracy: 0.858 - ETA: 17s - loss: 0.8080 - accuracy: 0.858 - ETA: 16s - loss: 0.8065 - accuracy: 0.858 - ETA: 15s - loss: 0.8047 - accuracy: 0.858 - ETA: 14s - loss: 0.8038 - accuracy: 0.858 - ETA: 13s - loss: 0.8020 - accuracy: 0.858 - ETA: 12s - loss: 0.8031 - accuracy: 0.858 - ETA: 11s - loss: 0.8054 - accuracy: 0.857 - ETA: 10s - loss: 0.8059 - accuracy: 0.858 - ETA: 9s - loss: 0.8051 - accuracy: 0.858 - ETA: 8s - loss: 0.8066 - accuracy: 0.85 - ETA: 7s - loss: 0.8052 - accuracy: 0.85 - ETA: 6s - loss: 0.8035 - accuracy: 0.85 - ETA: 5s - loss: 0.8038 - accuracy: 0.85 - ETA: 4s - loss: 0.8067 - accuracy: 0.85 - ETA: 3s - loss: 0.8052 - accuracy: 0.85 - ETA: 2s - loss: 0.8029 - accuracy: 0.85 - ETA: 1s - loss: 0.8011 - accuracy: 0.85 - ETA: 0s - loss: 0.8052 - accuracy: 0.85 - 156s 8ms/step - loss: 0.8040 - accuracy: 0.8587 - val_loss: 3.4869 - val_accuracy: 0.7635\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:33 - loss: 0.6282 - accuracy: 0.85 - ETA: 2:22 - loss: 0.4970 - accuracy: 0.87 - ETA: 2:21 - loss: 0.5216 - accuracy: 0.89 - ETA: 2:19 - loss: 0.5355 - accuracy: 0.88 - ETA: 2:17 - loss: 0.5688 - accuracy: 0.87 - ETA: 2:16 - loss: 0.6303 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6411 - accuracy: 0.87 - ETA: 2:14 - loss: 0.6116 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6459 - accuracy: 0.86 - ETA: 2:11 - loss: 0.6794 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6750 - accuracy: 0.86 - ETA: 2:12 - loss: 0.6499 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6377 - accuracy: 0.87 - ETA: 2:10 - loss: 0.6549 - accuracy: 0.86 - ETA: 2:09 - loss: 0.6544 - accuracy: 0.86 - ETA: 2:08 - loss: 0.6548 - accuracy: 0.86 - ETA: 2:06 - loss: 0.6575 - accuracy: 0.86 - ETA: 2:05 - loss: 0.6779 - accuracy: 0.86 - ETA: 2:04 - loss: 0.6715 - accuracy: 0.86 - ETA: 2:03 - loss: 0.6691 - accuracy: 0.86 - ETA: 2:02 - loss: 0.6717 - accuracy: 0.86 - ETA: 2:01 - loss: 0.6748 - accuracy: 0.86 - ETA: 2:00 - loss: 0.6664 - accuracy: 0.86 - ETA: 1:59 - loss: 0.6682 - accuracy: 0.86 - ETA: 1:58 - loss: 0.6748 - accuracy: 0.86 - ETA: 1:57 - loss: 0.6753 - accuracy: 0.86 - ETA: 1:57 - loss: 0.6806 - accuracy: 0.86 - ETA: 1:56 - loss: 0.6835 - accuracy: 0.86 - ETA: 1:55 - loss: 0.6824 - accuracy: 0.86 - ETA: 1:54 - loss: 0.6755 - accuracy: 0.86 - ETA: 1:53 - loss: 0.6760 - accuracy: 0.86 - ETA: 1:53 - loss: 0.6747 - accuracy: 0.86 - ETA: 1:52 - loss: 0.6873 - accuracy: 0.86 - ETA: 1:51 - loss: 0.6873 - accuracy: 0.86 - ETA: 1:50 - loss: 0.6965 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7067 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7095 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7099 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7043 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7194 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7168 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7128 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7054 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7033 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7166 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7183 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7138 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7145 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7141 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7155 - accuracy: 0.86 - ETA: 1:35 - loss: 0.7199 - accuracy: 0.86 - ETA: 1:34 - loss: 0.7195 - accuracy: 0.86 - ETA: 1:33 - loss: 0.7205 - accuracy: 0.86 - ETA: 1:32 - loss: 0.7194 - accuracy: 0.86 - ETA: 1:31 - loss: 0.7188 - accuracy: 0.86 - ETA: 1:30 - loss: 0.7249 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7250 - accuracy: 0.86 - ETA: 1:28 - loss: 0.7230 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7273 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7310 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7324 - accuracy: 0.86 - ETA: 1:25 - loss: 0.7298 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7270 - accuracy: 0.86 - ETA: 1:23 - loss: 0.7350 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7298 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7342 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7287 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7268 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7285 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7254 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7248 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7246 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7236 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7264 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7325 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7316 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7338 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7332 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7348 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7307 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7281 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7262 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7242 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7226 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7262 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7226 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7259 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7238 - accuracy: 0.86 - ETA: 59s - loss: 0.7191 - accuracy: 0.8640 - ETA: 58s - loss: 0.7166 - accuracy: 0.864 - ETA: 57s - loss: 0.7224 - accuracy: 0.864 - ETA: 56s - loss: 0.7210 - accuracy: 0.864 - ETA: 55s - loss: 0.7238 - accuracy: 0.864 - ETA: 54s - loss: 0.7252 - accuracy: 0.864 - ETA: 53s - loss: 0.7264 - accuracy: 0.864 - ETA: 52s - loss: 0.7260 - accuracy: 0.864 - ETA: 51s - loss: 0.7226 - accuracy: 0.865 - ETA: 50s - loss: 0.7199 - accuracy: 0.865 - ETA: 49s - loss: 0.7245 - accuracy: 0.865 - ETA: 48s - loss: 0.7241 - accuracy: 0.865 - ETA: 47s - loss: 0.7220 - accuracy: 0.866 - ETA: 46s - loss: 0.7208 - accuracy: 0.866 - ETA: 45s - loss: 0.7191 - accuracy: 0.866 - ETA: 44s - loss: 0.7188 - accuracy: 0.865 - ETA: 43s - loss: 0.7214 - accuracy: 0.866 - ETA: 42s - loss: 0.7211 - accuracy: 0.865 - ETA: 41s - loss: 0.7208 - accuracy: 0.866 - ETA: 40s - loss: 0.7218 - accuracy: 0.865 - ETA: 40s - loss: 0.7206 - accuracy: 0.866 - ETA: 39s - loss: 0.7179 - accuracy: 0.866 - ETA: 38s - loss: 0.7218 - accuracy: 0.866 - ETA: 37s - loss: 0.7223 - accuracy: 0.866 - ETA: 36s - loss: 0.7194 - accuracy: 0.867 - ETA: 35s - loss: 0.7227 - accuracy: 0.867 - ETA: 34s - loss: 0.7210 - accuracy: 0.867 - ETA: 33s - loss: 0.7220 - accuracy: 0.867 - ETA: 32s - loss: 0.7209 - accuracy: 0.867 - ETA: 31s - loss: 0.7219 - accuracy: 0.866 - ETA: 30s - loss: 0.7217 - accuracy: 0.866 - ETA: 29s - loss: 0.7261 - accuracy: 0.866 - ETA: 28s - loss: 0.7276 - accuracy: 0.866 - ETA: 27s - loss: 0.7291 - accuracy: 0.866 - ETA: 26s - loss: 0.7297 - accuracy: 0.865 - ETA: 25s - loss: 0.7280 - accuracy: 0.865 - ETA: 24s - loss: 0.7274 - accuracy: 0.865 - ETA: 23s - loss: 0.7274 - accuracy: 0.865 - ETA: 22s - loss: 0.7302 - accuracy: 0.865 - ETA: 21s - loss: 0.7304 - accuracy: 0.865 - ETA: 20s - loss: 0.7286 - accuracy: 0.865 - ETA: 20s - loss: 0.7312 - accuracy: 0.865 - ETA: 19s - loss: 0.7308 - accuracy: 0.865 - ETA: 18s - loss: 0.7303 - accuracy: 0.865 - ETA: 17s - loss: 0.7296 - accuracy: 0.865 - ETA: 16s - loss: 0.7298 - accuracy: 0.865 - ETA: 15s - loss: 0.7328 - accuracy: 0.864 - ETA: 14s - loss: 0.7327 - accuracy: 0.864 - ETA: 13s - loss: 0.7322 - accuracy: 0.864 - ETA: 12s - loss: 0.7319 - accuracy: 0.864 - ETA: 11s - loss: 0.7313 - accuracy: 0.864 - ETA: 10s - loss: 0.7282 - accuracy: 0.864 - ETA: 9s - loss: 0.7297 - accuracy: 0.864 - ETA: 8s - loss: 0.7332 - accuracy: 0.86 - ETA: 7s - loss: 0.7329 - accuracy: 0.86 - ETA: 6s - loss: 0.7328 - accuracy: 0.86 - ETA: 5s - loss: 0.7314 - accuracy: 0.86 - ETA: 4s - loss: 0.7306 - accuracy: 0.86 - ETA: 3s - loss: 0.7310 - accuracy: 0.86 - ETA: 2s - loss: 0.7311 - accuracy: 0.86 - ETA: 1s - loss: 0.7316 - accuracy: 0.86 - ETA: 0s - loss: 0.7310 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7316 - accuracy: 0.8643 - val_loss: 3.7611 - val_accuracy: 0.7650\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:41 - loss: 0.6608 - accuracy: 0.86 - ETA: 2:31 - loss: 0.8003 - accuracy: 0.85 - ETA: 2:27 - loss: 0.7602 - accuracy: 0.84 - ETA: 2:23 - loss: 0.8432 - accuracy: 0.83 - ETA: 2:19 - loss: 0.8278 - accuracy: 0.83 - ETA: 2:19 - loss: 0.8531 - accuracy: 0.82 - ETA: 2:18 - loss: 0.8821 - accuracy: 0.82 - ETA: 2:16 - loss: 0.8706 - accuracy: 0.82 - ETA: 2:16 - loss: 0.9036 - accuracy: 0.82 - ETA: 2:14 - loss: 0.8728 - accuracy: 0.83 - ETA: 2:13 - loss: 0.8388 - accuracy: 0.83 - ETA: 2:11 - loss: 0.8517 - accuracy: 0.83 - ETA: 2:11 - loss: 0.8286 - accuracy: 0.83 - ETA: 2:10 - loss: 0.8108 - accuracy: 0.84 - ETA: 2:09 - loss: 0.8193 - accuracy: 0.84 - ETA: 2:08 - loss: 0.8062 - accuracy: 0.84 - ETA: 2:07 - loss: 0.8135 - accuracy: 0.84 - ETA: 2:06 - loss: 0.8015 - accuracy: 0.84 - ETA: 2:05 - loss: 0.7905 - accuracy: 0.84 - ETA: 2:04 - loss: 0.7954 - accuracy: 0.84 - ETA: 2:04 - loss: 0.7982 - accuracy: 0.84 - ETA: 2:03 - loss: 0.7921 - accuracy: 0.84 - ETA: 2:02 - loss: 0.8014 - accuracy: 0.84 - ETA: 2:01 - loss: 0.8096 - accuracy: 0.84 - ETA: 2:00 - loss: 0.8130 - accuracy: 0.84 - ETA: 1:59 - loss: 0.8197 - accuracy: 0.84 - ETA: 1:58 - loss: 0.8210 - accuracy: 0.84 - ETA: 1:57 - loss: 0.8113 - accuracy: 0.84 - ETA: 1:56 - loss: 0.8004 - accuracy: 0.84 - ETA: 1:55 - loss: 0.7998 - accuracy: 0.84 - ETA: 1:54 - loss: 0.7914 - accuracy: 0.84 - ETA: 1:53 - loss: 0.7884 - accuracy: 0.84 - ETA: 1:52 - loss: 0.7907 - accuracy: 0.84 - ETA: 1:51 - loss: 0.8118 - accuracy: 0.85 - ETA: 1:50 - loss: 0.8187 - accuracy: 0.85 - ETA: 1:49 - loss: 0.8180 - accuracy: 0.85 - ETA: 1:48 - loss: 0.8170 - accuracy: 0.85 - ETA: 1:47 - loss: 0.8087 - accuracy: 0.85 - ETA: 1:47 - loss: 0.8106 - accuracy: 0.85 - ETA: 1:46 - loss: 0.8026 - accuracy: 0.85 - ETA: 1:45 - loss: 0.8075 - accuracy: 0.85 - ETA: 1:44 - loss: 0.8043 - accuracy: 0.85 - ETA: 1:43 - loss: 0.8006 - accuracy: 0.85 - ETA: 1:42 - loss: 0.7998 - accuracy: 0.85 - ETA: 1:41 - loss: 0.7997 - accuracy: 0.85 - ETA: 1:40 - loss: 0.7932 - accuracy: 0.85 - ETA: 1:39 - loss: 0.7959 - accuracy: 0.85 - ETA: 1:38 - loss: 0.7882 - accuracy: 0.85 - ETA: 1:37 - loss: 0.7906 - accuracy: 0.85 - ETA: 1:36 - loss: 0.7910 - accuracy: 0.85 - ETA: 1:35 - loss: 0.7903 - accuracy: 0.85 - ETA: 1:34 - loss: 0.7833 - accuracy: 0.85 - ETA: 1:33 - loss: 0.7807 - accuracy: 0.85 - ETA: 1:32 - loss: 0.7805 - accuracy: 0.85 - ETA: 1:31 - loss: 0.7803 - accuracy: 0.85 - ETA: 1:30 - loss: 0.7752 - accuracy: 0.85 - ETA: 1:29 - loss: 0.7731 - accuracy: 0.85 - ETA: 1:28 - loss: 0.7669 - accuracy: 0.85 - ETA: 1:27 - loss: 0.7677 - accuracy: 0.85 - ETA: 1:26 - loss: 0.7687 - accuracy: 0.85 - ETA: 1:25 - loss: 0.7636 - accuracy: 0.85 - ETA: 1:24 - loss: 0.7631 - accuracy: 0.85 - ETA: 1:23 - loss: 0.7642 - accuracy: 0.85 - ETA: 1:23 - loss: 0.7559 - accuracy: 0.85 - ETA: 1:22 - loss: 0.7527 - accuracy: 0.85 - ETA: 1:21 - loss: 0.7491 - accuracy: 0.85 - ETA: 1:20 - loss: 0.7468 - accuracy: 0.85 - ETA: 1:19 - loss: 0.7483 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7501 - accuracy: 0.85 - ETA: 1:17 - loss: 0.7478 - accuracy: 0.85 - ETA: 1:16 - loss: 0.7450 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7460 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7466 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7446 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7470 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7459 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7488 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7450 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7559 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7534 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7481 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7474 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7538 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7511 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7513 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7529 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7552 - accuracy: 0.86 - ETA: 59s - loss: 0.7516 - accuracy: 0.8616 - ETA: 58s - loss: 0.7502 - accuracy: 0.861 - ETA: 58s - loss: 0.7520 - accuracy: 0.861 - ETA: 57s - loss: 0.7486 - accuracy: 0.861 - ETA: 56s - loss: 0.7460 - accuracy: 0.861 - ETA: 55s - loss: 0.7461 - accuracy: 0.861 - ETA: 54s - loss: 0.7461 - accuracy: 0.861 - ETA: 53s - loss: 0.7430 - accuracy: 0.861 - ETA: 52s - loss: 0.7447 - accuracy: 0.861 - ETA: 51s - loss: 0.7447 - accuracy: 0.860 - ETA: 50s - loss: 0.7467 - accuracy: 0.860 - ETA: 49s - loss: 0.7507 - accuracy: 0.860 - ETA: 48s - loss: 0.7517 - accuracy: 0.860 - ETA: 47s - loss: 0.7558 - accuracy: 0.860 - ETA: 46s - loss: 0.7544 - accuracy: 0.860 - ETA: 45s - loss: 0.7543 - accuracy: 0.860 - ETA: 44s - loss: 0.7549 - accuracy: 0.860 - ETA: 43s - loss: 0.7524 - accuracy: 0.860 - ETA: 42s - loss: 0.7535 - accuracy: 0.860 - ETA: 41s - loss: 0.7509 - accuracy: 0.861 - ETA: 40s - loss: 0.7517 - accuracy: 0.861 - ETA: 39s - loss: 0.7549 - accuracy: 0.861 - ETA: 38s - loss: 0.7564 - accuracy: 0.861 - ETA: 38s - loss: 0.7549 - accuracy: 0.861 - ETA: 37s - loss: 0.7529 - accuracy: 0.861 - ETA: 36s - loss: 0.7509 - accuracy: 0.861 - ETA: 35s - loss: 0.7517 - accuracy: 0.861 - ETA: 34s - loss: 0.7514 - accuracy: 0.861 - ETA: 33s - loss: 0.7501 - accuracy: 0.861 - ETA: 32s - loss: 0.7474 - accuracy: 0.861 - ETA: 31s - loss: 0.7468 - accuracy: 0.861 - ETA: 30s - loss: 0.7523 - accuracy: 0.861 - ETA: 29s - loss: 0.7524 - accuracy: 0.861 - ETA: 28s - loss: 0.7494 - accuracy: 0.862 - ETA: 27s - loss: 0.7505 - accuracy: 0.862 - ETA: 26s - loss: 0.7522 - accuracy: 0.862 - ETA: 25s - loss: 0.7534 - accuracy: 0.862 - ETA: 24s - loss: 0.7515 - accuracy: 0.862 - ETA: 23s - loss: 0.7533 - accuracy: 0.862 - ETA: 22s - loss: 0.7541 - accuracy: 0.862 - ETA: 21s - loss: 0.7532 - accuracy: 0.862 - ETA: 20s - loss: 0.7522 - accuracy: 0.862 - ETA: 19s - loss: 0.7490 - accuracy: 0.863 - ETA: 18s - loss: 0.7503 - accuracy: 0.863 - ETA: 18s - loss: 0.7496 - accuracy: 0.863 - ETA: 17s - loss: 0.7513 - accuracy: 0.863 - ETA: 16s - loss: 0.7500 - accuracy: 0.863 - ETA: 15s - loss: 0.7519 - accuracy: 0.862 - ETA: 14s - loss: 0.7503 - accuracy: 0.862 - ETA: 13s - loss: 0.7488 - accuracy: 0.862 - ETA: 12s - loss: 0.7473 - accuracy: 0.863 - ETA: 11s - loss: 0.7489 - accuracy: 0.863 - ETA: 10s - loss: 0.7473 - accuracy: 0.863 - ETA: 9s - loss: 0.7461 - accuracy: 0.863 - ETA: 8s - loss: 0.7487 - accuracy: 0.86 - ETA: 7s - loss: 0.7456 - accuracy: 0.86 - ETA: 6s - loss: 0.7446 - accuracy: 0.86 - ETA: 5s - loss: 0.7439 - accuracy: 0.86 - ETA: 4s - loss: 0.7442 - accuracy: 0.86 - ETA: 3s - loss: 0.7457 - accuracy: 0.86 - ETA: 2s - loss: 0.7470 - accuracy: 0.86 - ETA: 1s - loss: 0.7465 - accuracy: 0.86 - ETA: 0s - loss: 0.7469 - accuracy: 0.86 - 155s 8ms/step - loss: 0.7468 - accuracy: 0.8633 - val_loss: 3.6745 - val_accuracy: 0.7683\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:27 - loss: 0.5572 - accuracy: 0.89 - ETA: 2:27 - loss: 0.5039 - accuracy: 0.88 - ETA: 2:30 - loss: 0.5664 - accuracy: 0.88 - ETA: 2:27 - loss: 0.7527 - accuracy: 0.86 - ETA: 2:26 - loss: 0.7164 - accuracy: 0.86 - ETA: 2:23 - loss: 0.6871 - accuracy: 0.86 - ETA: 2:21 - loss: 0.6475 - accuracy: 0.87 - ETA: 2:19 - loss: 0.7733 - accuracy: 0.87 - ETA: 2:18 - loss: 0.7872 - accuracy: 0.87 - ETA: 2:16 - loss: 0.7736 - accuracy: 0.87 - ETA: 2:15 - loss: 0.7471 - accuracy: 0.87 - ETA: 2:14 - loss: 0.7730 - accuracy: 0.87 - ETA: 2:13 - loss: 0.7687 - accuracy: 0.86 - ETA: 2:11 - loss: 0.7719 - accuracy: 0.87 - ETA: 2:10 - loss: 0.7740 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7629 - accuracy: 0.87 - ETA: 2:08 - loss: 0.7710 - accuracy: 0.87 - ETA: 2:07 - loss: 0.7532 - accuracy: 0.87 - ETA: 2:06 - loss: 0.7382 - accuracy: 0.87 - ETA: 2:06 - loss: 0.7213 - accuracy: 0.87 - ETA: 2:04 - loss: 0.7091 - accuracy: 0.87 - ETA: 2:03 - loss: 0.6934 - accuracy: 0.87 - ETA: 2:02 - loss: 0.6844 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6811 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6887 - accuracy: 0.87 - ETA: 1:59 - loss: 0.7088 - accuracy: 0.87 - ETA: 1:58 - loss: 0.7079 - accuracy: 0.87 - ETA: 1:58 - loss: 0.7110 - accuracy: 0.87 - ETA: 1:57 - loss: 0.7055 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6977 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6990 - accuracy: 0.87 - ETA: 1:54 - loss: 0.7032 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6955 - accuracy: 0.87 - ETA: 1:52 - loss: 0.7075 - accuracy: 0.87 - ETA: 1:51 - loss: 0.7252 - accuracy: 0.87 - ETA: 1:50 - loss: 0.7362 - accuracy: 0.87 - ETA: 1:50 - loss: 0.7293 - accuracy: 0.87 - ETA: 1:49 - loss: 0.7330 - accuracy: 0.87 - ETA: 1:47 - loss: 0.7309 - accuracy: 0.87 - ETA: 1:46 - loss: 0.7288 - accuracy: 0.87 - ETA: 1:45 - loss: 0.7342 - accuracy: 0.87 - ETA: 1:44 - loss: 0.7309 - accuracy: 0.87 - ETA: 1:43 - loss: 0.7315 - accuracy: 0.87 - ETA: 1:42 - loss: 0.7282 - accuracy: 0.87 - ETA: 1:41 - loss: 0.7275 - accuracy: 0.87 - ETA: 1:41 - loss: 0.7345 - accuracy: 0.87 - ETA: 1:40 - loss: 0.7339 - accuracy: 0.87 - ETA: 1:39 - loss: 0.7352 - accuracy: 0.87 - ETA: 1:38 - loss: 0.7360 - accuracy: 0.87 - ETA: 1:37 - loss: 0.7471 - accuracy: 0.87 - ETA: 1:36 - loss: 0.7417 - accuracy: 0.87 - ETA: 1:35 - loss: 0.7438 - accuracy: 0.87 - ETA: 1:34 - loss: 0.7417 - accuracy: 0.87 - ETA: 1:33 - loss: 0.7470 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7429 - accuracy: 0.87 - ETA: 1:31 - loss: 0.7454 - accuracy: 0.87 - ETA: 1:30 - loss: 0.7539 - accuracy: 0.87 - ETA: 1:29 - loss: 0.7660 - accuracy: 0.87 - ETA: 1:28 - loss: 0.7644 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7642 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7646 - accuracy: 0.87 - ETA: 1:25 - loss: 0.7617 - accuracy: 0.87 - ETA: 1:24 - loss: 0.7589 - accuracy: 0.87 - ETA: 1:23 - loss: 0.7563 - accuracy: 0.87 - ETA: 1:22 - loss: 0.7505 - accuracy: 0.87 - ETA: 1:21 - loss: 0.7465 - accuracy: 0.87 - ETA: 1:20 - loss: 0.7435 - accuracy: 0.87 - ETA: 1:19 - loss: 0.7444 - accuracy: 0.87 - ETA: 1:18 - loss: 0.7428 - accuracy: 0.87 - ETA: 1:18 - loss: 0.7451 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7463 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7497 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7573 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7551 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7651 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7684 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7660 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7648 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7670 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7628 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7620 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7578 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7639 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7647 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7685 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7759 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7730 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7700 - accuracy: 0.86 - ETA: 59s - loss: 0.7731 - accuracy: 0.8665 - ETA: 58s - loss: 0.7724 - accuracy: 0.866 - ETA: 57s - loss: 0.7716 - accuracy: 0.866 - ETA: 56s - loss: 0.7675 - accuracy: 0.866 - ETA: 55s - loss: 0.7666 - accuracy: 0.866 - ETA: 54s - loss: 0.7644 - accuracy: 0.866 - ETA: 53s - loss: 0.7631 - accuracy: 0.866 - ETA: 52s - loss: 0.7617 - accuracy: 0.866 - ETA: 51s - loss: 0.7610 - accuracy: 0.866 - ETA: 50s - loss: 0.7601 - accuracy: 0.866 - ETA: 49s - loss: 0.7647 - accuracy: 0.866 - ETA: 48s - loss: 0.7635 - accuracy: 0.866 - ETA: 47s - loss: 0.7638 - accuracy: 0.866 - ETA: 46s - loss: 0.7620 - accuracy: 0.867 - ETA: 46s - loss: 0.7613 - accuracy: 0.867 - ETA: 45s - loss: 0.7612 - accuracy: 0.867 - ETA: 44s - loss: 0.7610 - accuracy: 0.867 - ETA: 43s - loss: 0.7578 - accuracy: 0.867 - ETA: 42s - loss: 0.7569 - accuracy: 0.867 - ETA: 41s - loss: 0.7552 - accuracy: 0.867 - ETA: 40s - loss: 0.7570 - accuracy: 0.866 - ETA: 39s - loss: 0.7544 - accuracy: 0.866 - ETA: 38s - loss: 0.7527 - accuracy: 0.866 - ETA: 37s - loss: 0.7497 - accuracy: 0.867 - ETA: 36s - loss: 0.7491 - accuracy: 0.866 - ETA: 35s - loss: 0.7475 - accuracy: 0.867 - ETA: 34s - loss: 0.7491 - accuracy: 0.866 - ETA: 33s - loss: 0.7509 - accuracy: 0.865 - ETA: 32s - loss: 0.7493 - accuracy: 0.865 - ETA: 31s - loss: 0.7469 - accuracy: 0.865 - ETA: 30s - loss: 0.7506 - accuracy: 0.866 - ETA: 29s - loss: 0.7474 - accuracy: 0.866 - ETA: 28s - loss: 0.7576 - accuracy: 0.866 - ETA: 27s - loss: 0.7559 - accuracy: 0.866 - ETA: 26s - loss: 0.7560 - accuracy: 0.866 - ETA: 25s - loss: 0.7541 - accuracy: 0.866 - ETA: 24s - loss: 0.7568 - accuracy: 0.866 - ETA: 23s - loss: 0.7592 - accuracy: 0.866 - ETA: 22s - loss: 0.7572 - accuracy: 0.866 - ETA: 21s - loss: 0.7551 - accuracy: 0.866 - ETA: 20s - loss: 0.7548 - accuracy: 0.865 - ETA: 19s - loss: 0.7568 - accuracy: 0.865 - ETA: 19s - loss: 0.7577 - accuracy: 0.865 - ETA: 18s - loss: 0.7559 - accuracy: 0.865 - ETA: 17s - loss: 0.7602 - accuracy: 0.865 - ETA: 16s - loss: 0.7610 - accuracy: 0.865 - ETA: 15s - loss: 0.7592 - accuracy: 0.865 - ETA: 14s - loss: 0.7582 - accuracy: 0.865 - ETA: 13s - loss: 0.7558 - accuracy: 0.866 - ETA: 12s - loss: 0.7551 - accuracy: 0.866 - ETA: 11s - loss: 0.7565 - accuracy: 0.866 - ETA: 10s - loss: 0.7549 - accuracy: 0.866 - ETA: 9s - loss: 0.7587 - accuracy: 0.865 - ETA: 8s - loss: 0.7612 - accuracy: 0.86 - ETA: 7s - loss: 0.7629 - accuracy: 0.86 - ETA: 6s - loss: 0.7620 - accuracy: 0.86 - ETA: 5s - loss: 0.7603 - accuracy: 0.86 - ETA: 4s - loss: 0.7619 - accuracy: 0.86 - ETA: 3s - loss: 0.7646 - accuracy: 0.86 - ETA: 2s - loss: 0.7650 - accuracy: 0.86 - ETA: 1s - loss: 0.7642 - accuracy: 0.86 - ETA: 0s - loss: 0.7649 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7655 - accuracy: 0.8656 - val_loss: 3.8194 - val_accuracy: 0.7724\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:27 - loss: 0.5979 - accuracy: 0.85 - ETA: 2:21 - loss: 0.5710 - accuracy: 0.85 - ETA: 2:20 - loss: 0.7299 - accuracy: 0.84 - ETA: 2:19 - loss: 0.7233 - accuracy: 0.85 - ETA: 2:17 - loss: 0.7101 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7560 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7696 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7818 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7476 - accuracy: 0.87 - ETA: 2:15 - loss: 0.7165 - accuracy: 0.87 - ETA: 2:14 - loss: 0.7177 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6990 - accuracy: 0.87 - ETA: 2:11 - loss: 0.7202 - accuracy: 0.86 - ETA: 2:11 - loss: 0.7234 - accuracy: 0.86 - ETA: 2:09 - loss: 0.7739 - accuracy: 0.86 - ETA: 2:08 - loss: 0.7703 - accuracy: 0.86 - ETA: 2:07 - loss: 0.7616 - accuracy: 0.86 - ETA: 2:06 - loss: 0.8070 - accuracy: 0.86 - ETA: 2:05 - loss: 0.8030 - accuracy: 0.86 - ETA: 2:04 - loss: 0.8041 - accuracy: 0.86 - ETA: 2:03 - loss: 0.8347 - accuracy: 0.86 - ETA: 2:02 - loss: 0.8286 - accuracy: 0.86 - ETA: 2:01 - loss: 0.8075 - accuracy: 0.86 - ETA: 2:01 - loss: 0.7999 - accuracy: 0.86 - ETA: 2:00 - loss: 0.8089 - accuracy: 0.86 - ETA: 1:59 - loss: 0.8085 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7970 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7918 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7876 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7797 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7670 - accuracy: 0.86 - ETA: 1:53 - loss: 0.7556 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7482 - accuracy: 0.87 - ETA: 1:51 - loss: 0.7578 - accuracy: 0.87 - ETA: 1:50 - loss: 0.7490 - accuracy: 0.87 - ETA: 1:49 - loss: 0.7443 - accuracy: 0.87 - ETA: 1:48 - loss: 0.7390 - accuracy: 0.87 - ETA: 1:47 - loss: 0.7338 - accuracy: 0.87 - ETA: 1:46 - loss: 0.7267 - accuracy: 0.87 - ETA: 1:45 - loss: 0.7179 - accuracy: 0.87 - ETA: 1:45 - loss: 0.7192 - accuracy: 0.87 - ETA: 1:44 - loss: 0.7490 - accuracy: 0.87 - ETA: 1:43 - loss: 0.7527 - accuracy: 0.87 - ETA: 1:42 - loss: 0.7476 - accuracy: 0.87 - ETA: 1:41 - loss: 0.7427 - accuracy: 0.87 - ETA: 1:40 - loss: 0.7466 - accuracy: 0.87 - ETA: 1:39 - loss: 0.7479 - accuracy: 0.87 - ETA: 1:38 - loss: 0.7463 - accuracy: 0.87 - ETA: 1:37 - loss: 0.7494 - accuracy: 0.87 - ETA: 1:36 - loss: 0.7433 - accuracy: 0.87 - ETA: 1:35 - loss: 0.7437 - accuracy: 0.87 - ETA: 1:34 - loss: 0.7513 - accuracy: 0.87 - ETA: 1:33 - loss: 0.7520 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7526 - accuracy: 0.87 - ETA: 1:31 - loss: 0.7539 - accuracy: 0.87 - ETA: 1:30 - loss: 0.7549 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7502 - accuracy: 0.86 - ETA: 1:28 - loss: 0.7464 - accuracy: 0.87 - ETA: 1:27 - loss: 0.7411 - accuracy: 0.87 - ETA: 1:27 - loss: 0.7387 - accuracy: 0.87 - ETA: 1:26 - loss: 0.7399 - accuracy: 0.87 - ETA: 1:25 - loss: 0.7445 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7462 - accuracy: 0.86 - ETA: 1:23 - loss: 0.7450 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7431 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7471 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7422 - accuracy: 0.87 - ETA: 1:19 - loss: 0.7469 - accuracy: 0.87 - ETA: 1:18 - loss: 0.7460 - accuracy: 0.87 - ETA: 1:17 - loss: 0.7429 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7414 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7420 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7525 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7533 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7515 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7491 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7495 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7541 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7553 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7588 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7614 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7603 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7612 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7582 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7632 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7605 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7623 - accuracy: 0.86 - ETA: 59s - loss: 0.7570 - accuracy: 0.8683 - ETA: 58s - loss: 0.7586 - accuracy: 0.867 - ETA: 57s - loss: 0.7626 - accuracy: 0.867 - ETA: 57s - loss: 0.7611 - accuracy: 0.866 - ETA: 56s - loss: 0.7589 - accuracy: 0.866 - ETA: 55s - loss: 0.7596 - accuracy: 0.866 - ETA: 54s - loss: 0.7601 - accuracy: 0.866 - ETA: 53s - loss: 0.7576 - accuracy: 0.866 - ETA: 52s - loss: 0.7565 - accuracy: 0.866 - ETA: 51s - loss: 0.7549 - accuracy: 0.866 - ETA: 50s - loss: 0.7584 - accuracy: 0.867 - ETA: 49s - loss: 0.7554 - accuracy: 0.867 - ETA: 48s - loss: 0.7557 - accuracy: 0.867 - ETA: 47s - loss: 0.7552 - accuracy: 0.867 - ETA: 46s - loss: 0.7550 - accuracy: 0.866 - ETA: 45s - loss: 0.7536 - accuracy: 0.866 - ETA: 44s - loss: 0.7534 - accuracy: 0.866 - ETA: 43s - loss: 0.7575 - accuracy: 0.866 - ETA: 42s - loss: 0.7567 - accuracy: 0.866 - ETA: 41s - loss: 0.7571 - accuracy: 0.866 - ETA: 40s - loss: 0.7551 - accuracy: 0.867 - ETA: 40s - loss: 0.7551 - accuracy: 0.867 - ETA: 39s - loss: 0.7589 - accuracy: 0.866 - ETA: 38s - loss: 0.7568 - accuracy: 0.866 - ETA: 37s - loss: 0.7536 - accuracy: 0.866 - ETA: 36s - loss: 0.7539 - accuracy: 0.866 - ETA: 35s - loss: 0.7534 - accuracy: 0.866 - ETA: 34s - loss: 0.7572 - accuracy: 0.866 - ETA: 33s - loss: 0.7572 - accuracy: 0.866 - ETA: 32s - loss: 0.7616 - accuracy: 0.866 - ETA: 31s - loss: 0.7610 - accuracy: 0.866 - ETA: 30s - loss: 0.7606 - accuracy: 0.865 - ETA: 29s - loss: 0.7631 - accuracy: 0.865 - ETA: 28s - loss: 0.7666 - accuracy: 0.865 - ETA: 27s - loss: 0.7658 - accuracy: 0.865 - ETA: 26s - loss: 0.7648 - accuracy: 0.865 - ETA: 25s - loss: 0.7700 - accuracy: 0.865 - ETA: 24s - loss: 0.7695 - accuracy: 0.865 - ETA: 23s - loss: 0.7697 - accuracy: 0.865 - ETA: 22s - loss: 0.7667 - accuracy: 0.865 - ETA: 21s - loss: 0.7675 - accuracy: 0.865 - ETA: 20s - loss: 0.7666 - accuracy: 0.865 - ETA: 19s - loss: 0.7710 - accuracy: 0.864 - ETA: 19s - loss: 0.7722 - accuracy: 0.864 - ETA: 18s - loss: 0.7684 - accuracy: 0.865 - ETA: 17s - loss: 0.7671 - accuracy: 0.865 - ETA: 16s - loss: 0.7661 - accuracy: 0.865 - ETA: 15s - loss: 0.7676 - accuracy: 0.864 - ETA: 14s - loss: 0.7720 - accuracy: 0.864 - ETA: 13s - loss: 0.7724 - accuracy: 0.864 - ETA: 12s - loss: 0.7719 - accuracy: 0.864 - ETA: 11s - loss: 0.7711 - accuracy: 0.864 - ETA: 10s - loss: 0.7711 - accuracy: 0.864 - ETA: 9s - loss: 0.7710 - accuracy: 0.864 - ETA: 8s - loss: 0.7739 - accuracy: 0.86 - ETA: 7s - loss: 0.7741 - accuracy: 0.86 - ETA: 6s - loss: 0.7728 - accuracy: 0.86 - ETA: 5s - loss: 0.7721 - accuracy: 0.86 - ETA: 4s - loss: 0.7717 - accuracy: 0.86 - ETA: 3s - loss: 0.7704 - accuracy: 0.86 - ETA: 2s - loss: 0.7703 - accuracy: 0.86 - ETA: 1s - loss: 0.7714 - accuracy: 0.86 - ETA: 0s - loss: 0.7698 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7695 - accuracy: 0.8640 - val_loss: 3.9626 - val_accuracy: 0.7693\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:27 - loss: 0.9865 - accuracy: 0.84 - ETA: 2:25 - loss: 1.1537 - accuracy: 0.83 - ETA: 2:22 - loss: 1.1288 - accuracy: 0.84 - ETA: 2:22 - loss: 1.0194 - accuracy: 0.85 - ETA: 2:20 - loss: 1.0030 - accuracy: 0.85 - ETA: 2:18 - loss: 0.9553 - accuracy: 0.85 - ETA: 2:17 - loss: 0.9462 - accuracy: 0.85 - ETA: 2:16 - loss: 0.8784 - accuracy: 0.86 - ETA: 2:15 - loss: 0.8743 - accuracy: 0.85 - ETA: 2:13 - loss: 0.8877 - accuracy: 0.86 - ETA: 2:14 - loss: 0.8887 - accuracy: 0.85 - ETA: 2:13 - loss: 0.8681 - accuracy: 0.85 - ETA: 2:11 - loss: 0.8706 - accuracy: 0.86 - ETA: 2:11 - loss: 0.8619 - accuracy: 0.86 - ETA: 2:10 - loss: 0.8676 - accuracy: 0.86 - ETA: 2:10 - loss: 0.8462 - accuracy: 0.86 - ETA: 2:09 - loss: 0.8334 - accuracy: 0.86 - ETA: 2:08 - loss: 0.8229 - accuracy: 0.86 - ETA: 2:06 - loss: 0.8105 - accuracy: 0.86 - ETA: 2:05 - loss: 0.8121 - accuracy: 0.86 - ETA: 2:04 - loss: 0.7893 - accuracy: 0.86 - ETA: 2:03 - loss: 0.7904 - accuracy: 0.86 - ETA: 2:02 - loss: 0.7903 - accuracy: 0.86 - ETA: 2:01 - loss: 0.8004 - accuracy: 0.86 - ETA: 2:00 - loss: 0.7894 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7781 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7778 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7842 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7875 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7821 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7746 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7672 - accuracy: 0.86 - ETA: 1:53 - loss: 0.7619 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7578 - accuracy: 0.86 - ETA: 1:51 - loss: 0.7555 - accuracy: 0.86 - ETA: 1:50 - loss: 0.7555 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7578 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7587 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7490 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7486 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7497 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7563 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7497 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7491 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7496 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7519 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7477 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7515 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7606 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7671 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7714 - accuracy: 0.86 - ETA: 1:35 - loss: 0.7695 - accuracy: 0.86 - ETA: 1:34 - loss: 0.7623 - accuracy: 0.86 - ETA: 1:33 - loss: 0.7622 - accuracy: 0.86 - ETA: 1:32 - loss: 0.7671 - accuracy: 0.86 - ETA: 1:31 - loss: 0.7705 - accuracy: 0.86 - ETA: 1:30 - loss: 0.7662 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7646 - accuracy: 0.86 - ETA: 1:28 - loss: 0.7642 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7594 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7603 - accuracy: 0.86 - ETA: 1:25 - loss: 0.7570 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7595 - accuracy: 0.86 - ETA: 1:23 - loss: 0.7566 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7567 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7534 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7628 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7689 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7638 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7599 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7583 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7611 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7578 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7586 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7586 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7564 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7570 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7558 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7584 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7585 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7551 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7514 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7541 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7545 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7555 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7538 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7537 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7540 - accuracy: 0.86 - ETA: 59s - loss: 0.7536 - accuracy: 0.8628 - ETA: 58s - loss: 0.7555 - accuracy: 0.862 - ETA: 57s - loss: 0.7554 - accuracy: 0.862 - ETA: 56s - loss: 0.7552 - accuracy: 0.862 - ETA: 55s - loss: 0.7525 - accuracy: 0.862 - ETA: 54s - loss: 0.7526 - accuracy: 0.862 - ETA: 53s - loss: 0.7525 - accuracy: 0.862 - ETA: 52s - loss: 0.7511 - accuracy: 0.862 - ETA: 51s - loss: 0.7541 - accuracy: 0.862 - ETA: 50s - loss: 0.7592 - accuracy: 0.862 - ETA: 49s - loss: 0.7568 - accuracy: 0.862 - ETA: 49s - loss: 0.7559 - accuracy: 0.862 - ETA: 48s - loss: 0.7538 - accuracy: 0.863 - ETA: 47s - loss: 0.7533 - accuracy: 0.863 - ETA: 46s - loss: 0.7508 - accuracy: 0.863 - ETA: 45s - loss: 0.7497 - accuracy: 0.863 - ETA: 44s - loss: 0.7476 - accuracy: 0.863 - ETA: 43s - loss: 0.7470 - accuracy: 0.863 - ETA: 42s - loss: 0.7516 - accuracy: 0.863 - ETA: 41s - loss: 0.7605 - accuracy: 0.863 - ETA: 40s - loss: 0.7682 - accuracy: 0.863 - ETA: 39s - loss: 0.7663 - accuracy: 0.863 - ETA: 38s - loss: 0.7656 - accuracy: 0.863 - ETA: 37s - loss: 0.7629 - accuracy: 0.863 - ETA: 36s - loss: 0.7608 - accuracy: 0.863 - ETA: 35s - loss: 0.7623 - accuracy: 0.863 - ETA: 34s - loss: 0.7629 - accuracy: 0.863 - ETA: 33s - loss: 0.7626 - accuracy: 0.863 - ETA: 32s - loss: 0.7642 - accuracy: 0.862 - ETA: 31s - loss: 0.7729 - accuracy: 0.862 - ETA: 30s - loss: 0.7712 - accuracy: 0.862 - ETA: 29s - loss: 0.7703 - accuracy: 0.862 - ETA: 28s - loss: 0.7683 - accuracy: 0.862 - ETA: 27s - loss: 0.7699 - accuracy: 0.862 - ETA: 26s - loss: 0.7697 - accuracy: 0.862 - ETA: 25s - loss: 0.7670 - accuracy: 0.863 - ETA: 24s - loss: 0.7710 - accuracy: 0.862 - ETA: 23s - loss: 0.7706 - accuracy: 0.862 - ETA: 22s - loss: 0.7696 - accuracy: 0.862 - ETA: 22s - loss: 0.7698 - accuracy: 0.862 - ETA: 21s - loss: 0.7685 - accuracy: 0.862 - ETA: 20s - loss: 0.7700 - accuracy: 0.862 - ETA: 19s - loss: 0.7724 - accuracy: 0.862 - ETA: 18s - loss: 0.7787 - accuracy: 0.862 - ETA: 17s - loss: 0.7773 - accuracy: 0.862 - ETA: 16s - loss: 0.7776 - accuracy: 0.862 - ETA: 15s - loss: 0.7780 - accuracy: 0.862 - ETA: 14s - loss: 0.7779 - accuracy: 0.862 - ETA: 13s - loss: 0.7779 - accuracy: 0.862 - ETA: 12s - loss: 0.7769 - accuracy: 0.862 - ETA: 11s - loss: 0.7770 - accuracy: 0.862 - ETA: 10s - loss: 0.7907 - accuracy: 0.862 - ETA: 9s - loss: 0.7888 - accuracy: 0.862 - ETA: 8s - loss: 0.7916 - accuracy: 0.86 - ETA: 7s - loss: 0.7897 - accuracy: 0.86 - ETA: 6s - loss: 0.7890 - accuracy: 0.86 - ETA: 5s - loss: 0.7867 - accuracy: 0.86 - ETA: 4s - loss: 0.7850 - accuracy: 0.86 - ETA: 3s - loss: 0.7832 - accuracy: 0.86 - ETA: 2s - loss: 0.7803 - accuracy: 0.86 - ETA: 1s - loss: 0.7767 - accuracy: 0.86 - ETA: 0s - loss: 0.7752 - accuracy: 0.86 - 157s 8ms/step - loss: 0.7780 - accuracy: 0.8634 - val_loss: 4.1227 - val_accuracy: 0.7650\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:31 - loss: 0.6991 - accuracy: 0.87 - ETA: 2:23 - loss: 0.5862 - accuracy: 0.87 - ETA: 2:21 - loss: 0.6121 - accuracy: 0.87 - ETA: 2:19 - loss: 0.6030 - accuracy: 0.87 - ETA: 2:17 - loss: 0.5594 - accuracy: 0.87 - ETA: 2:16 - loss: 0.5324 - accuracy: 0.88 - ETA: 2:15 - loss: 0.5861 - accuracy: 0.87 - ETA: 2:14 - loss: 0.6381 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6425 - accuracy: 0.86 - ETA: 2:11 - loss: 0.6481 - accuracy: 0.86 - ETA: 2:11 - loss: 0.7081 - accuracy: 0.87 - ETA: 2:10 - loss: 0.7022 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7236 - accuracy: 0.87 - ETA: 2:08 - loss: 0.7427 - accuracy: 0.87 - ETA: 2:08 - loss: 0.7274 - accuracy: 0.87 - ETA: 2:08 - loss: 0.7182 - accuracy: 0.87 - ETA: 2:06 - loss: 0.7124 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7403 - accuracy: 0.87 - ETA: 2:04 - loss: 0.7224 - accuracy: 0.87 - ETA: 2:03 - loss: 0.7412 - accuracy: 0.87 - ETA: 2:02 - loss: 0.7484 - accuracy: 0.87 - ETA: 2:01 - loss: 0.7785 - accuracy: 0.86 - ETA: 2:00 - loss: 0.7823 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7828 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7764 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7815 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7897 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7839 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7691 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7594 - accuracy: 0.86 - ETA: 1:53 - loss: 0.7544 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7700 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7647 - accuracy: 0.86 - ETA: 1:51 - loss: 0.7581 - accuracy: 0.86 - ETA: 1:50 - loss: 0.7552 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7494 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7567 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7538 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7693 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7741 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7773 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7764 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7719 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7745 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7736 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7778 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7761 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7775 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7704 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7648 - accuracy: 0.86 - ETA: 1:35 - loss: 0.7664 - accuracy: 0.86 - ETA: 1:34 - loss: 0.7726 - accuracy: 0.86 - ETA: 1:33 - loss: 0.7784 - accuracy: 0.86 - ETA: 1:32 - loss: 0.7730 - accuracy: 0.86 - ETA: 1:31 - loss: 0.7709 - accuracy: 0.86 - ETA: 1:30 - loss: 0.7654 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7598 - accuracy: 0.86 - ETA: 1:28 - loss: 0.7546 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7513 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7603 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7585 - accuracy: 0.86 - ETA: 1:25 - loss: 0.7590 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7603 - accuracy: 0.86 - ETA: 1:23 - loss: 0.7619 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7653 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7622 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7637 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7614 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7653 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7747 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7848 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7817 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7840 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7841 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7843 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7819 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7822 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7828 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7773 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7745 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7709 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7691 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7655 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7633 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7677 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7656 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7631 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7619 - accuracy: 0.86 - ETA: 59s - loss: 0.7614 - accuracy: 0.8641 - ETA: 58s - loss: 0.7608 - accuracy: 0.863 - ETA: 57s - loss: 0.7583 - accuracy: 0.864 - ETA: 56s - loss: 0.7560 - accuracy: 0.864 - ETA: 55s - loss: 0.7529 - accuracy: 0.865 - ETA: 54s - loss: 0.7492 - accuracy: 0.865 - ETA: 53s - loss: 0.7498 - accuracy: 0.865 - ETA: 52s - loss: 0.7580 - accuracy: 0.864 - ETA: 51s - loss: 0.7572 - accuracy: 0.864 - ETA: 50s - loss: 0.7576 - accuracy: 0.864 - ETA: 49s - loss: 0.7555 - accuracy: 0.864 - ETA: 48s - loss: 0.7534 - accuracy: 0.864 - ETA: 47s - loss: 0.7535 - accuracy: 0.865 - ETA: 46s - loss: 0.7578 - accuracy: 0.864 - ETA: 45s - loss: 0.7582 - accuracy: 0.864 - ETA: 44s - loss: 0.7578 - accuracy: 0.864 - ETA: 43s - loss: 0.7562 - accuracy: 0.865 - ETA: 42s - loss: 0.7574 - accuracy: 0.864 - ETA: 41s - loss: 0.7572 - accuracy: 0.864 - ETA: 40s - loss: 0.7560 - accuracy: 0.864 - ETA: 40s - loss: 0.7559 - accuracy: 0.864 - ETA: 39s - loss: 0.7552 - accuracy: 0.865 - ETA: 38s - loss: 0.7529 - accuracy: 0.865 - ETA: 37s - loss: 0.7497 - accuracy: 0.865 - ETA: 36s - loss: 0.7491 - accuracy: 0.865 - ETA: 35s - loss: 0.7481 - accuracy: 0.866 - ETA: 34s - loss: 0.7479 - accuracy: 0.866 - ETA: 33s - loss: 0.7471 - accuracy: 0.866 - ETA: 32s - loss: 0.7465 - accuracy: 0.865 - ETA: 31s - loss: 0.7453 - accuracy: 0.865 - ETA: 30s - loss: 0.7434 - accuracy: 0.866 - ETA: 29s - loss: 0.7420 - accuracy: 0.866 - ETA: 28s - loss: 0.7402 - accuracy: 0.866 - ETA: 27s - loss: 0.7426 - accuracy: 0.866 - ETA: 26s - loss: 0.7463 - accuracy: 0.865 - ETA: 25s - loss: 0.7498 - accuracy: 0.865 - ETA: 24s - loss: 0.7461 - accuracy: 0.866 - ETA: 23s - loss: 0.7470 - accuracy: 0.866 - ETA: 22s - loss: 0.7455 - accuracy: 0.866 - ETA: 22s - loss: 0.7443 - accuracy: 0.866 - ETA: 21s - loss: 0.7444 - accuracy: 0.866 - ETA: 20s - loss: 0.7436 - accuracy: 0.866 - ETA: 19s - loss: 0.7416 - accuracy: 0.866 - ETA: 18s - loss: 0.7419 - accuracy: 0.866 - ETA: 17s - loss: 0.7402 - accuracy: 0.866 - ETA: 16s - loss: 0.7385 - accuracy: 0.866 - ETA: 15s - loss: 0.7403 - accuracy: 0.866 - ETA: 14s - loss: 0.7390 - accuracy: 0.866 - ETA: 13s - loss: 0.7384 - accuracy: 0.866 - ETA: 12s - loss: 0.7408 - accuracy: 0.866 - ETA: 11s - loss: 0.7393 - accuracy: 0.866 - ETA: 10s - loss: 0.7372 - accuracy: 0.866 - ETA: 9s - loss: 0.7356 - accuracy: 0.866 - ETA: 8s - loss: 0.7353 - accuracy: 0.86 - ETA: 7s - loss: 0.7370 - accuracy: 0.86 - ETA: 6s - loss: 0.7348 - accuracy: 0.86 - ETA: 5s - loss: 0.7341 - accuracy: 0.86 - ETA: 4s - loss: 0.7328 - accuracy: 0.86 - ETA: 3s - loss: 0.7330 - accuracy: 0.86 - ETA: 2s - loss: 0.7332 - accuracy: 0.86 - ETA: 1s - loss: 0.7328 - accuracy: 0.86 - ETA: 0s - loss: 0.7328 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7316 - accuracy: 0.8669 - val_loss: 4.0750 - val_accuracy: 0.7726\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:44 - loss: 0.5904 - accuracy: 0.89 - ETA: 2:34 - loss: 0.6419 - accuracy: 0.86 - ETA: 2:31 - loss: 0.6316 - accuracy: 0.86 - ETA: 2:28 - loss: 0.6416 - accuracy: 0.87 - ETA: 2:25 - loss: 0.6515 - accuracy: 0.87 - ETA: 2:22 - loss: 0.7107 - accuracy: 0.86 - ETA: 2:20 - loss: 0.7169 - accuracy: 0.86 - ETA: 2:19 - loss: 0.7452 - accuracy: 0.86 - ETA: 2:17 - loss: 0.7108 - accuracy: 0.86 - ETA: 2:16 - loss: 0.6894 - accuracy: 0.86 - ETA: 2:15 - loss: 0.6819 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6830 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6575 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6673 - accuracy: 0.87 - ETA: 2:10 - loss: 0.6997 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7198 - accuracy: 0.86 - ETA: 2:08 - loss: 0.7476 - accuracy: 0.86 - ETA: 2:08 - loss: 0.7543 - accuracy: 0.87 - ETA: 2:07 - loss: 0.7440 - accuracy: 0.87 - ETA: 2:06 - loss: 0.7595 - accuracy: 0.86 - ETA: 2:05 - loss: 0.7433 - accuracy: 0.86 - ETA: 2:04 - loss: 0.7414 - accuracy: 0.86 - ETA: 2:02 - loss: 0.7261 - accuracy: 0.87 - ETA: 2:01 - loss: 0.7263 - accuracy: 0.87 - ETA: 2:00 - loss: 0.7153 - accuracy: 0.87 - ETA: 1:59 - loss: 0.7184 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7213 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7109 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7126 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7233 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7285 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7256 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7186 - accuracy: 0.86 - ETA: 1:53 - loss: 0.7105 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7115 - accuracy: 0.86 - ETA: 1:51 - loss: 0.7189 - accuracy: 0.86 - ETA: 1:50 - loss: 0.7106 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7092 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7124 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7162 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7091 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7109 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7158 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7106 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7092 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7097 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7127 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7065 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7081 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7053 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7034 - accuracy: 0.86 - ETA: 1:35 - loss: 0.7004 - accuracy: 0.86 - ETA: 1:34 - loss: 0.7055 - accuracy: 0.86 - ETA: 1:33 - loss: 0.7100 - accuracy: 0.86 - ETA: 1:32 - loss: 0.7093 - accuracy: 0.86 - ETA: 1:31 - loss: 0.7111 - accuracy: 0.86 - ETA: 1:30 - loss: 0.7091 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7077 - accuracy: 0.86 - ETA: 1:28 - loss: 0.7086 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7093 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7078 - accuracy: 0.86 - ETA: 1:25 - loss: 0.7057 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7020 - accuracy: 0.86 - ETA: 1:23 - loss: 0.6973 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7048 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7104 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7140 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7269 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7222 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7190 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7173 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7183 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7209 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7293 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7310 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7302 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7251 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7305 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7305 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7316 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7292 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7278 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7233 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7203 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7198 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7147 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7176 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7141 - accuracy: 0.86 - ETA: 59s - loss: 0.7161 - accuracy: 0.8672 - ETA: 58s - loss: 0.7134 - accuracy: 0.867 - ETA: 57s - loss: 0.7146 - accuracy: 0.867 - ETA: 56s - loss: 0.7189 - accuracy: 0.867 - ETA: 55s - loss: 0.7228 - accuracy: 0.867 - ETA: 54s - loss: 0.7226 - accuracy: 0.866 - ETA: 53s - loss: 0.7227 - accuracy: 0.866 - ETA: 52s - loss: 0.7269 - accuracy: 0.866 - ETA: 51s - loss: 0.7376 - accuracy: 0.865 - ETA: 50s - loss: 0.7415 - accuracy: 0.865 - ETA: 49s - loss: 0.7402 - accuracy: 0.865 - ETA: 48s - loss: 0.7356 - accuracy: 0.865 - ETA: 47s - loss: 0.7410 - accuracy: 0.865 - ETA: 46s - loss: 0.7403 - accuracy: 0.865 - ETA: 46s - loss: 0.7384 - accuracy: 0.866 - ETA: 45s - loss: 0.7401 - accuracy: 0.865 - ETA: 44s - loss: 0.7384 - accuracy: 0.866 - ETA: 43s - loss: 0.7410 - accuracy: 0.865 - ETA: 42s - loss: 0.7384 - accuracy: 0.865 - ETA: 41s - loss: 0.7411 - accuracy: 0.865 - ETA: 40s - loss: 0.7432 - accuracy: 0.865 - ETA: 39s - loss: 0.7400 - accuracy: 0.865 - ETA: 38s - loss: 0.7380 - accuracy: 0.865 - ETA: 37s - loss: 0.7420 - accuracy: 0.866 - ETA: 36s - loss: 0.7478 - accuracy: 0.865 - ETA: 35s - loss: 0.7514 - accuracy: 0.865 - ETA: 34s - loss: 0.7530 - accuracy: 0.865 - ETA: 33s - loss: 0.7499 - accuracy: 0.865 - ETA: 32s - loss: 0.7507 - accuracy: 0.865 - ETA: 31s - loss: 0.7550 - accuracy: 0.865 - ETA: 30s - loss: 0.7516 - accuracy: 0.865 - ETA: 29s - loss: 0.7522 - accuracy: 0.865 - ETA: 28s - loss: 0.7533 - accuracy: 0.865 - ETA: 27s - loss: 0.7502 - accuracy: 0.865 - ETA: 26s - loss: 0.7513 - accuracy: 0.865 - ETA: 25s - loss: 0.7501 - accuracy: 0.865 - ETA: 24s - loss: 0.7490 - accuracy: 0.865 - ETA: 23s - loss: 0.7504 - accuracy: 0.865 - ETA: 22s - loss: 0.7485 - accuracy: 0.865 - ETA: 21s - loss: 0.7483 - accuracy: 0.865 - ETA: 21s - loss: 0.7471 - accuracy: 0.865 - ETA: 20s - loss: 0.7467 - accuracy: 0.865 - ETA: 19s - loss: 0.7456 - accuracy: 0.865 - ETA: 18s - loss: 0.7435 - accuracy: 0.865 - ETA: 17s - loss: 0.7458 - accuracy: 0.865 - ETA: 16s - loss: 0.7503 - accuracy: 0.865 - ETA: 15s - loss: 0.7516 - accuracy: 0.865 - ETA: 14s - loss: 0.7489 - accuracy: 0.865 - ETA: 13s - loss: 0.7460 - accuracy: 0.865 - ETA: 12s - loss: 0.7447 - accuracy: 0.865 - ETA: 11s - loss: 0.7438 - accuracy: 0.865 - ETA: 10s - loss: 0.7440 - accuracy: 0.865 - ETA: 9s - loss: 0.7424 - accuracy: 0.866 - ETA: 8s - loss: 0.7404 - accuracy: 0.86 - ETA: 7s - loss: 0.7376 - accuracy: 0.86 - ETA: 6s - loss: 0.7365 - accuracy: 0.86 - ETA: 5s - loss: 0.7370 - accuracy: 0.86 - ETA: 4s - loss: 0.7349 - accuracy: 0.86 - ETA: 3s - loss: 0.7362 - accuracy: 0.86 - ETA: 2s - loss: 0.7371 - accuracy: 0.86 - ETA: 1s - loss: 0.7366 - accuracy: 0.86 - ETA: 0s - loss: 0.7362 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7340 - accuracy: 0.8671 - val_loss: 3.9183 - val_accuracy: 0.7747\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:39 - loss: 0.5027 - accuracy: 0.89 - ETA: 2:28 - loss: 0.7907 - accuracy: 0.87 - ETA: 2:27 - loss: 0.6231 - accuracy: 0.88 - ETA: 2:30 - loss: 0.6504 - accuracy: 0.87 - ETA: 2:28 - loss: 0.6258 - accuracy: 0.88 - ETA: 2:30 - loss: 0.7354 - accuracy: 0.88 - ETA: 2:29 - loss: 0.7049 - accuracy: 0.88 - ETA: 2:27 - loss: 0.6941 - accuracy: 0.88 - ETA: 2:25 - loss: 0.6719 - accuracy: 0.88 - ETA: 2:24 - loss: 0.6666 - accuracy: 0.88 - ETA: 2:22 - loss: 0.6576 - accuracy: 0.88 - ETA: 2:21 - loss: 0.6526 - accuracy: 0.88 - ETA: 2:20 - loss: 0.6397 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6396 - accuracy: 0.87 - ETA: 2:15 - loss: 0.6833 - accuracy: 0.87 - ETA: 2:14 - loss: 0.6696 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6715 - accuracy: 0.87 - ETA: 2:11 - loss: 0.7264 - accuracy: 0.86 - ETA: 2:10 - loss: 0.7163 - accuracy: 0.86 - ETA: 2:09 - loss: 0.7067 - accuracy: 0.87 - ETA: 2:08 - loss: 0.6891 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6889 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6880 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7020 - accuracy: 0.87 - ETA: 2:04 - loss: 0.6914 - accuracy: 0.87 - ETA: 2:03 - loss: 0.6956 - accuracy: 0.87 - ETA: 2:02 - loss: 0.7077 - accuracy: 0.86 - ETA: 2:01 - loss: 0.6995 - accuracy: 0.87 - ETA: 1:59 - loss: 0.7267 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7180 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7213 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7151 - accuracy: 0.87 - ETA: 1:55 - loss: 0.7175 - accuracy: 0.87 - ETA: 1:54 - loss: 0.7285 - accuracy: 0.87 - ETA: 1:53 - loss: 0.7367 - accuracy: 0.87 - ETA: 1:52 - loss: 0.7309 - accuracy: 0.87 - ETA: 1:51 - loss: 0.7306 - accuracy: 0.87 - ETA: 1:50 - loss: 0.7350 - accuracy: 0.87 - ETA: 1:49 - loss: 0.7336 - accuracy: 0.87 - ETA: 1:48 - loss: 0.7554 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7502 - accuracy: 0.87 - ETA: 1:46 - loss: 0.7471 - accuracy: 0.87 - ETA: 1:45 - loss: 0.7432 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7482 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7406 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7390 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7370 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7319 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7323 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7427 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7409 - accuracy: 0.86 - ETA: 1:35 - loss: 0.7406 - accuracy: 0.86 - ETA: 1:34 - loss: 0.7367 - accuracy: 0.87 - ETA: 1:33 - loss: 0.7304 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7301 - accuracy: 0.87 - ETA: 1:31 - loss: 0.7347 - accuracy: 0.86 - ETA: 1:30 - loss: 0.7322 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7325 - accuracy: 0.86 - ETA: 1:28 - loss: 0.7292 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7358 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7356 - accuracy: 0.87 - ETA: 1:25 - loss: 0.7328 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7353 - accuracy: 0.86 - ETA: 1:23 - loss: 0.7276 - accuracy: 0.87 - ETA: 1:22 - loss: 0.7280 - accuracy: 0.87 - ETA: 1:21 - loss: 0.7287 - accuracy: 0.87 - ETA: 1:20 - loss: 0.7242 - accuracy: 0.87 - ETA: 1:19 - loss: 0.7193 - accuracy: 0.87 - ETA: 1:18 - loss: 0.7172 - accuracy: 0.87 - ETA: 1:17 - loss: 0.7127 - accuracy: 0.87 - ETA: 1:16 - loss: 0.7153 - accuracy: 0.87 - ETA: 1:15 - loss: 0.7146 - accuracy: 0.87 - ETA: 1:15 - loss: 0.7102 - accuracy: 0.87 - ETA: 1:14 - loss: 0.7102 - accuracy: 0.87 - ETA: 1:13 - loss: 0.7091 - accuracy: 0.87 - ETA: 1:12 - loss: 0.7182 - accuracy: 0.87 - ETA: 1:11 - loss: 0.7204 - accuracy: 0.87 - ETA: 1:10 - loss: 0.7245 - accuracy: 0.87 - ETA: 1:09 - loss: 0.7257 - accuracy: 0.87 - ETA: 1:08 - loss: 0.7245 - accuracy: 0.87 - ETA: 1:07 - loss: 0.7229 - accuracy: 0.87 - ETA: 1:06 - loss: 0.7217 - accuracy: 0.87 - ETA: 1:05 - loss: 0.7220 - accuracy: 0.87 - ETA: 1:04 - loss: 0.7221 - accuracy: 0.87 - ETA: 1:03 - loss: 0.7205 - accuracy: 0.87 - ETA: 1:02 - loss: 0.7176 - accuracy: 0.87 - ETA: 1:01 - loss: 0.7136 - accuracy: 0.87 - ETA: 1:00 - loss: 0.7180 - accuracy: 0.87 - ETA: 59s - loss: 0.7172 - accuracy: 0.8711 - ETA: 58s - loss: 0.7212 - accuracy: 0.870 - ETA: 57s - loss: 0.7274 - accuracy: 0.870 - ETA: 56s - loss: 0.7287 - accuracy: 0.869 - ETA: 55s - loss: 0.7315 - accuracy: 0.869 - ETA: 54s - loss: 0.7307 - accuracy: 0.869 - ETA: 53s - loss: 0.7278 - accuracy: 0.869 - ETA: 52s - loss: 0.7334 - accuracy: 0.869 - ETA: 51s - loss: 0.7303 - accuracy: 0.870 - ETA: 50s - loss: 0.7316 - accuracy: 0.869 - ETA: 49s - loss: 0.7299 - accuracy: 0.869 - ETA: 48s - loss: 0.7298 - accuracy: 0.869 - ETA: 47s - loss: 0.7311 - accuracy: 0.869 - ETA: 46s - loss: 0.7274 - accuracy: 0.869 - ETA: 45s - loss: 0.7305 - accuracy: 0.869 - ETA: 45s - loss: 0.7281 - accuracy: 0.869 - ETA: 44s - loss: 0.7287 - accuracy: 0.869 - ETA: 43s - loss: 0.7304 - accuracy: 0.869 - ETA: 42s - loss: 0.7319 - accuracy: 0.869 - ETA: 41s - loss: 0.7330 - accuracy: 0.868 - ETA: 40s - loss: 0.7331 - accuracy: 0.868 - ETA: 39s - loss: 0.7327 - accuracy: 0.868 - ETA: 38s - loss: 0.7377 - accuracy: 0.868 - ETA: 37s - loss: 0.7358 - accuracy: 0.868 - ETA: 36s - loss: 0.7383 - accuracy: 0.868 - ETA: 35s - loss: 0.7354 - accuracy: 0.868 - ETA: 34s - loss: 0.7346 - accuracy: 0.868 - ETA: 33s - loss: 0.7343 - accuracy: 0.868 - ETA: 32s - loss: 0.7330 - accuracy: 0.868 - ETA: 31s - loss: 0.7336 - accuracy: 0.868 - ETA: 30s - loss: 0.7357 - accuracy: 0.868 - ETA: 29s - loss: 0.7343 - accuracy: 0.868 - ETA: 28s - loss: 0.7317 - accuracy: 0.868 - ETA: 27s - loss: 0.7300 - accuracy: 0.868 - ETA: 26s - loss: 0.7298 - accuracy: 0.868 - ETA: 25s - loss: 0.7301 - accuracy: 0.868 - ETA: 24s - loss: 0.7310 - accuracy: 0.868 - ETA: 23s - loss: 0.7299 - accuracy: 0.868 - ETA: 22s - loss: 0.7297 - accuracy: 0.868 - ETA: 22s - loss: 0.7289 - accuracy: 0.867 - ETA: 21s - loss: 0.7290 - accuracy: 0.867 - ETA: 20s - loss: 0.7267 - accuracy: 0.867 - ETA: 19s - loss: 0.7265 - accuracy: 0.867 - ETA: 18s - loss: 0.7270 - accuracy: 0.867 - ETA: 17s - loss: 0.7256 - accuracy: 0.867 - ETA: 16s - loss: 0.7262 - accuracy: 0.867 - ETA: 15s - loss: 0.7258 - accuracy: 0.867 - ETA: 14s - loss: 0.7241 - accuracy: 0.867 - ETA: 13s - loss: 0.7229 - accuracy: 0.867 - ETA: 12s - loss: 0.7255 - accuracy: 0.867 - ETA: 11s - loss: 0.7292 - accuracy: 0.867 - ETA: 10s - loss: 0.7283 - accuracy: 0.867 - ETA: 9s - loss: 0.7281 - accuracy: 0.867 - ETA: 8s - loss: 0.7280 - accuracy: 0.86 - ETA: 7s - loss: 0.7264 - accuracy: 0.86 - ETA: 6s - loss: 0.7256 - accuracy: 0.86 - ETA: 5s - loss: 0.7302 - accuracy: 0.86 - ETA: 4s - loss: 0.7317 - accuracy: 0.86 - ETA: 3s - loss: 0.7293 - accuracy: 0.86 - ETA: 2s - loss: 0.7301 - accuracy: 0.86 - ETA: 1s - loss: 0.7349 - accuracy: 0.86 - ETA: 0s - loss: 0.7380 - accuracy: 0.86 - 157s 8ms/step - loss: 0.7385 - accuracy: 0.8660 - val_loss: 3.5703 - val_accuracy: 0.7730\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 0.9007 - accuracy: 0.83 - ETA: 2:25 - loss: 0.6540 - accuracy: 0.86 - ETA: 2:22 - loss: 0.7052 - accuracy: 0.85 - ETA: 2:19 - loss: 0.6870 - accuracy: 0.86 - ETA: 2:17 - loss: 0.6614 - accuracy: 0.87 - ETA: 2:16 - loss: 0.6236 - accuracy: 0.87 - ETA: 2:15 - loss: 0.7379 - accuracy: 0.86 - ETA: 2:14 - loss: 0.7268 - accuracy: 0.86 - ETA: 2:13 - loss: 0.7073 - accuracy: 0.86 - ETA: 2:13 - loss: 0.6804 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6931 - accuracy: 0.87 - ETA: 2:12 - loss: 0.7223 - accuracy: 0.86 - ETA: 2:11 - loss: 0.7150 - accuracy: 0.87 - ETA: 2:10 - loss: 0.7103 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7228 - accuracy: 0.86 - ETA: 2:08 - loss: 0.7353 - accuracy: 0.86 - ETA: 2:07 - loss: 0.7621 - accuracy: 0.86 - ETA: 2:06 - loss: 0.7520 - accuracy: 0.86 - ETA: 2:04 - loss: 0.7442 - accuracy: 0.87 - ETA: 2:04 - loss: 0.7493 - accuracy: 0.87 - ETA: 2:03 - loss: 0.7638 - accuracy: 0.86 - ETA: 2:02 - loss: 0.7593 - accuracy: 0.86 - ETA: 2:01 - loss: 0.7648 - accuracy: 0.86 - ETA: 2:00 - loss: 0.7681 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7759 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7658 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7612 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7533 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7547 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7515 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7431 - accuracy: 0.86 - ETA: 1:53 - loss: 0.7424 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7339 - accuracy: 0.86 - ETA: 1:51 - loss: 0.7388 - accuracy: 0.86 - ETA: 1:50 - loss: 0.7533 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7549 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7518 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7432 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7376 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7329 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7395 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7347 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7232 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7192 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7262 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7337 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7398 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7359 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7279 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7280 - accuracy: 0.86 - ETA: 1:35 - loss: 0.7321 - accuracy: 0.86 - ETA: 1:34 - loss: 0.7283 - accuracy: 0.86 - ETA: 1:33 - loss: 0.7288 - accuracy: 0.86 - ETA: 1:32 - loss: 0.7299 - accuracy: 0.86 - ETA: 1:31 - loss: 0.7223 - accuracy: 0.86 - ETA: 1:30 - loss: 0.7150 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7149 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7135 - accuracy: 0.86 - ETA: 1:28 - loss: 0.7090 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7124 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7196 - accuracy: 0.86 - ETA: 1:25 - loss: 0.7115 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7103 - accuracy: 0.86 - ETA: 1:23 - loss: 0.7120 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7122 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7124 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7302 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7278 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7259 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7287 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7325 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7263 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7331 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7348 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7376 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7404 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7397 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7355 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7365 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7339 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7340 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7409 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7443 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7479 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7464 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7484 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7517 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7495 - accuracy: 0.86 - ETA: 59s - loss: 0.7522 - accuracy: 0.8668 - ETA: 58s - loss: 0.7525 - accuracy: 0.867 - ETA: 57s - loss: 0.7526 - accuracy: 0.866 - ETA: 56s - loss: 0.7576 - accuracy: 0.866 - ETA: 55s - loss: 0.7580 - accuracy: 0.866 - ETA: 54s - loss: 0.7535 - accuracy: 0.867 - ETA: 53s - loss: 0.7521 - accuracy: 0.867 - ETA: 52s - loss: 0.7512 - accuracy: 0.867 - ETA: 51s - loss: 0.7529 - accuracy: 0.867 - ETA: 50s - loss: 0.7598 - accuracy: 0.866 - ETA: 49s - loss: 0.7567 - accuracy: 0.867 - ETA: 48s - loss: 0.7581 - accuracy: 0.866 - ETA: 47s - loss: 0.7578 - accuracy: 0.866 - ETA: 46s - loss: 0.7587 - accuracy: 0.866 - ETA: 45s - loss: 0.7594 - accuracy: 0.866 - ETA: 45s - loss: 0.7599 - accuracy: 0.866 - ETA: 44s - loss: 0.7592 - accuracy: 0.866 - ETA: 43s - loss: 0.7571 - accuracy: 0.867 - ETA: 42s - loss: 0.7593 - accuracy: 0.867 - ETA: 41s - loss: 0.7583 - accuracy: 0.867 - ETA: 40s - loss: 0.7591 - accuracy: 0.867 - ETA: 39s - loss: 0.7609 - accuracy: 0.867 - ETA: 38s - loss: 0.7610 - accuracy: 0.867 - ETA: 37s - loss: 0.7632 - accuracy: 0.866 - ETA: 36s - loss: 0.7604 - accuracy: 0.867 - ETA: 35s - loss: 0.7625 - accuracy: 0.866 - ETA: 34s - loss: 0.7646 - accuracy: 0.866 - ETA: 33s - loss: 0.7629 - accuracy: 0.866 - ETA: 32s - loss: 0.7625 - accuracy: 0.866 - ETA: 31s - loss: 0.7598 - accuracy: 0.866 - ETA: 30s - loss: 0.7571 - accuracy: 0.866 - ETA: 29s - loss: 0.7589 - accuracy: 0.866 - ETA: 28s - loss: 0.7623 - accuracy: 0.866 - ETA: 27s - loss: 0.7609 - accuracy: 0.866 - ETA: 26s - loss: 0.7597 - accuracy: 0.866 - ETA: 25s - loss: 0.7613 - accuracy: 0.866 - ETA: 24s - loss: 0.7608 - accuracy: 0.866 - ETA: 23s - loss: 0.7617 - accuracy: 0.866 - ETA: 23s - loss: 0.7628 - accuracy: 0.866 - ETA: 22s - loss: 0.7599 - accuracy: 0.867 - ETA: 21s - loss: 0.7591 - accuracy: 0.866 - ETA: 20s - loss: 0.7574 - accuracy: 0.866 - ETA: 19s - loss: 0.7594 - accuracy: 0.866 - ETA: 18s - loss: 0.7614 - accuracy: 0.866 - ETA: 17s - loss: 0.7583 - accuracy: 0.866 - ETA: 16s - loss: 0.7610 - accuracy: 0.866 - ETA: 15s - loss: 0.7611 - accuracy: 0.866 - ETA: 14s - loss: 0.7619 - accuracy: 0.865 - ETA: 13s - loss: 0.7622 - accuracy: 0.865 - ETA: 12s - loss: 0.7609 - accuracy: 0.865 - ETA: 11s - loss: 0.7591 - accuracy: 0.865 - ETA: 10s - loss: 0.7596 - accuracy: 0.865 - ETA: 9s - loss: 0.7568 - accuracy: 0.866 - ETA: 8s - loss: 0.7568 - accuracy: 0.86 - ETA: 7s - loss: 0.7585 - accuracy: 0.86 - ETA: 6s - loss: 0.7579 - accuracy: 0.86 - ETA: 5s - loss: 0.7565 - accuracy: 0.86 - ETA: 4s - loss: 0.7567 - accuracy: 0.86 - ETA: 3s - loss: 0.7568 - accuracy: 0.86 - ETA: 2s - loss: 0.7558 - accuracy: 0.86 - ETA: 1s - loss: 0.7548 - accuracy: 0.86 - ETA: 0s - loss: 0.7555 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7556 - accuracy: 0.8664 - val_loss: 3.7542 - val_accuracy: 0.7726\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:24 - loss: 1.3343 - accuracy: 0.81 - ETA: 2:22 - loss: 0.8169 - accuracy: 0.86 - ETA: 2:20 - loss: 0.8717 - accuracy: 0.86 - ETA: 2:21 - loss: 0.8620 - accuracy: 0.84 - ETA: 2:18 - loss: 0.7863 - accuracy: 0.85 - ETA: 2:16 - loss: 0.8084 - accuracy: 0.85 - ETA: 2:15 - loss: 0.8509 - accuracy: 0.85 - ETA: 2:15 - loss: 0.8802 - accuracy: 0.85 - ETA: 2:13 - loss: 0.8895 - accuracy: 0.85 - ETA: 2:12 - loss: 0.8983 - accuracy: 0.85 - ETA: 2:11 - loss: 0.8908 - accuracy: 0.85 - ETA: 2:10 - loss: 0.8746 - accuracy: 0.85 - ETA: 2:09 - loss: 0.8439 - accuracy: 0.85 - ETA: 2:09 - loss: 0.8582 - accuracy: 0.85 - ETA: 2:09 - loss: 0.8522 - accuracy: 0.85 - ETA: 2:08 - loss: 0.8282 - accuracy: 0.85 - ETA: 2:07 - loss: 0.8210 - accuracy: 0.85 - ETA: 2:06 - loss: 0.8374 - accuracy: 0.85 - ETA: 2:05 - loss: 0.8428 - accuracy: 0.85 - ETA: 2:04 - loss: 0.8452 - accuracy: 0.85 - ETA: 2:03 - loss: 0.8435 - accuracy: 0.85 - ETA: 2:02 - loss: 0.8275 - accuracy: 0.85 - ETA: 2:02 - loss: 0.8289 - accuracy: 0.85 - ETA: 2:01 - loss: 0.8298 - accuracy: 0.85 - ETA: 2:00 - loss: 0.8149 - accuracy: 0.85 - ETA: 1:59 - loss: 0.8166 - accuracy: 0.85 - ETA: 1:58 - loss: 0.8028 - accuracy: 0.85 - ETA: 1:57 - loss: 0.8180 - accuracy: 0.85 - ETA: 1:56 - loss: 0.8174 - accuracy: 0.85 - ETA: 1:56 - loss: 0.8303 - accuracy: 0.85 - ETA: 1:55 - loss: 0.8212 - accuracy: 0.85 - ETA: 1:55 - loss: 0.8122 - accuracy: 0.85 - ETA: 1:54 - loss: 0.8054 - accuracy: 0.85 - ETA: 1:54 - loss: 0.7990 - accuracy: 0.85 - ETA: 1:53 - loss: 0.7997 - accuracy: 0.85 - ETA: 1:52 - loss: 0.7913 - accuracy: 0.85 - ETA: 1:51 - loss: 0.7833 - accuracy: 0.86 - ETA: 1:50 - loss: 0.7764 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7682 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7831 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7735 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7724 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7785 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7718 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7704 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7660 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7640 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7614 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7652 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7589 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7638 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7689 - accuracy: 0.86 - ETA: 1:35 - loss: 0.7622 - accuracy: 0.86 - ETA: 1:34 - loss: 0.7529 - accuracy: 0.86 - ETA: 1:33 - loss: 0.7483 - accuracy: 0.86 - ETA: 1:32 - loss: 0.7472 - accuracy: 0.86 - ETA: 1:31 - loss: 0.7465 - accuracy: 0.86 - ETA: 1:30 - loss: 0.7476 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7575 - accuracy: 0.86 - ETA: 1:28 - loss: 0.7549 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7551 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7527 - accuracy: 0.86 - ETA: 1:25 - loss: 0.7485 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7474 - accuracy: 0.86 - ETA: 1:23 - loss: 0.7429 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7398 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7447 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7465 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7467 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7496 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7528 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7519 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7516 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7460 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7427 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7408 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7525 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7499 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7499 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7538 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7520 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7515 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7524 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7532 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7515 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7499 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7498 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7496 - accuracy: 0.86 - ETA: 59s - loss: 0.7531 - accuracy: 0.8640 - ETA: 58s - loss: 0.7507 - accuracy: 0.864 - ETA: 57s - loss: 0.7515 - accuracy: 0.863 - ETA: 56s - loss: 0.7480 - accuracy: 0.864 - ETA: 55s - loss: 0.7446 - accuracy: 0.864 - ETA: 55s - loss: 0.7423 - accuracy: 0.864 - ETA: 54s - loss: 0.7408 - accuracy: 0.864 - ETA: 53s - loss: 0.7413 - accuracy: 0.864 - ETA: 52s - loss: 0.7398 - accuracy: 0.864 - ETA: 51s - loss: 0.7419 - accuracy: 0.864 - ETA: 50s - loss: 0.7425 - accuracy: 0.864 - ETA: 49s - loss: 0.7389 - accuracy: 0.864 - ETA: 48s - loss: 0.7404 - accuracy: 0.864 - ETA: 47s - loss: 0.7444 - accuracy: 0.864 - ETA: 46s - loss: 0.7524 - accuracy: 0.864 - ETA: 45s - loss: 0.7533 - accuracy: 0.863 - ETA: 44s - loss: 0.7557 - accuracy: 0.863 - ETA: 43s - loss: 0.7541 - accuracy: 0.863 - ETA: 42s - loss: 0.7553 - accuracy: 0.863 - ETA: 41s - loss: 0.7530 - accuracy: 0.863 - ETA: 40s - loss: 0.7499 - accuracy: 0.864 - ETA: 39s - loss: 0.7523 - accuracy: 0.863 - ETA: 38s - loss: 0.7612 - accuracy: 0.863 - ETA: 37s - loss: 0.7665 - accuracy: 0.863 - ETA: 36s - loss: 0.7705 - accuracy: 0.862 - ETA: 35s - loss: 0.7685 - accuracy: 0.863 - ETA: 34s - loss: 0.7690 - accuracy: 0.863 - ETA: 33s - loss: 0.7692 - accuracy: 0.863 - ETA: 32s - loss: 0.7706 - accuracy: 0.863 - ETA: 31s - loss: 0.7786 - accuracy: 0.862 - ETA: 30s - loss: 0.7767 - accuracy: 0.862 - ETA: 29s - loss: 0.7756 - accuracy: 0.862 - ETA: 28s - loss: 0.7750 - accuracy: 0.862 - ETA: 27s - loss: 0.7751 - accuracy: 0.862 - ETA: 26s - loss: 0.7754 - accuracy: 0.862 - ETA: 25s - loss: 0.7735 - accuracy: 0.862 - ETA: 25s - loss: 0.7725 - accuracy: 0.862 - ETA: 24s - loss: 0.7705 - accuracy: 0.862 - ETA: 23s - loss: 0.7703 - accuracy: 0.862 - ETA: 22s - loss: 0.7678 - accuracy: 0.862 - ETA: 21s - loss: 0.7674 - accuracy: 0.862 - ETA: 20s - loss: 0.7712 - accuracy: 0.863 - ETA: 19s - loss: 0.7699 - accuracy: 0.863 - ETA: 18s - loss: 0.7690 - accuracy: 0.863 - ETA: 17s - loss: 0.7690 - accuracy: 0.863 - ETA: 16s - loss: 0.7682 - accuracy: 0.863 - ETA: 15s - loss: 0.7678 - accuracy: 0.863 - ETA: 14s - loss: 0.7687 - accuracy: 0.862 - ETA: 13s - loss: 0.7688 - accuracy: 0.862 - ETA: 12s - loss: 0.7687 - accuracy: 0.862 - ETA: 11s - loss: 0.7669 - accuracy: 0.862 - ETA: 10s - loss: 0.7657 - accuracy: 0.862 - ETA: 9s - loss: 0.7631 - accuracy: 0.863 - ETA: 8s - loss: 0.7647 - accuracy: 0.86 - ETA: 7s - loss: 0.7652 - accuracy: 0.86 - ETA: 6s - loss: 0.7638 - accuracy: 0.86 - ETA: 5s - loss: 0.7676 - accuracy: 0.86 - ETA: 4s - loss: 0.7675 - accuracy: 0.86 - ETA: 3s - loss: 0.7662 - accuracy: 0.86 - ETA: 2s - loss: 0.7657 - accuracy: 0.86 - ETA: 1s - loss: 0.7650 - accuracy: 0.86 - ETA: 0s - loss: 0.7635 - accuracy: 0.86 - 157s 8ms/step - loss: 0.7650 - accuracy: 0.8643 - val_loss: 4.0781 - val_accuracy: 0.7739\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:25 - loss: 0.6496 - accuracy: 0.90 - ETA: 2:20 - loss: 1.0260 - accuracy: 0.87 - ETA: 2:19 - loss: 0.8396 - accuracy: 0.87 - ETA: 2:17 - loss: 0.8773 - accuracy: 0.86 - ETA: 2:16 - loss: 0.8368 - accuracy: 0.86 - ETA: 2:15 - loss: 0.8147 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7584 - accuracy: 0.87 - ETA: 2:15 - loss: 0.7588 - accuracy: 0.87 - ETA: 2:14 - loss: 0.7389 - accuracy: 0.87 - ETA: 2:14 - loss: 0.7660 - accuracy: 0.87 - ETA: 2:12 - loss: 0.7351 - accuracy: 0.87 - ETA: 2:11 - loss: 0.7248 - accuracy: 0.87 - ETA: 2:10 - loss: 0.7802 - accuracy: 0.87 - ETA: 2:09 - loss: 0.8400 - accuracy: 0.87 - ETA: 2:08 - loss: 0.8244 - accuracy: 0.87 - ETA: 2:07 - loss: 0.8051 - accuracy: 0.87 - ETA: 2:07 - loss: 0.7912 - accuracy: 0.87 - ETA: 2:06 - loss: 0.7863 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7905 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7831 - accuracy: 0.87 - ETA: 2:04 - loss: 0.7832 - accuracy: 0.87 - ETA: 2:02 - loss: 0.7848 - accuracy: 0.87 - ETA: 2:01 - loss: 0.7857 - accuracy: 0.87 - ETA: 2:00 - loss: 0.7937 - accuracy: 0.87 - ETA: 2:00 - loss: 0.8023 - accuracy: 0.87 - ETA: 1:59 - loss: 0.8224 - accuracy: 0.87 - ETA: 1:58 - loss: 0.8173 - accuracy: 0.86 - ETA: 1:57 - loss: 0.8115 - accuracy: 0.87 - ETA: 1:56 - loss: 0.8155 - accuracy: 0.86 - ETA: 1:55 - loss: 0.8083 - accuracy: 0.87 - ETA: 1:54 - loss: 0.8038 - accuracy: 0.87 - ETA: 1:53 - loss: 0.8211 - accuracy: 0.87 - ETA: 1:52 - loss: 0.8343 - accuracy: 0.86 - ETA: 1:52 - loss: 0.8328 - accuracy: 0.86 - ETA: 1:51 - loss: 0.8345 - accuracy: 0.86 - ETA: 1:50 - loss: 0.8516 - accuracy: 0.86 - ETA: 1:49 - loss: 0.8400 - accuracy: 0.86 - ETA: 1:48 - loss: 0.8417 - accuracy: 0.86 - ETA: 1:47 - loss: 0.8348 - accuracy: 0.86 - ETA: 1:46 - loss: 0.8402 - accuracy: 0.86 - ETA: 1:45 - loss: 0.8499 - accuracy: 0.86 - ETA: 1:44 - loss: 0.8425 - accuracy: 0.86 - ETA: 1:43 - loss: 0.8359 - accuracy: 0.86 - ETA: 1:42 - loss: 0.8396 - accuracy: 0.86 - ETA: 1:41 - loss: 0.8313 - accuracy: 0.86 - ETA: 1:40 - loss: 0.8241 - accuracy: 0.86 - ETA: 1:39 - loss: 0.8243 - accuracy: 0.86 - ETA: 1:38 - loss: 0.8135 - accuracy: 0.86 - ETA: 1:37 - loss: 0.8124 - accuracy: 0.86 - ETA: 1:36 - loss: 0.8063 - accuracy: 0.86 - ETA: 1:35 - loss: 0.8106 - accuracy: 0.86 - ETA: 1:34 - loss: 0.8100 - accuracy: 0.86 - ETA: 1:33 - loss: 0.8048 - accuracy: 0.86 - ETA: 1:32 - loss: 0.8072 - accuracy: 0.86 - ETA: 1:31 - loss: 0.8057 - accuracy: 0.86 - ETA: 1:30 - loss: 0.8090 - accuracy: 0.86 - ETA: 1:29 - loss: 0.8067 - accuracy: 0.86 - ETA: 1:28 - loss: 0.8040 - accuracy: 0.86 - ETA: 1:27 - loss: 0.8022 - accuracy: 0.86 - ETA: 1:26 - loss: 0.7972 - accuracy: 0.86 - ETA: 1:25 - loss: 0.7942 - accuracy: 0.86 - ETA: 1:24 - loss: 0.7896 - accuracy: 0.86 - ETA: 1:23 - loss: 0.7949 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7997 - accuracy: 0.86 - ETA: 1:21 - loss: 0.8056 - accuracy: 0.86 - ETA: 1:21 - loss: 0.8047 - accuracy: 0.86 - ETA: 1:20 - loss: 0.8003 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7985 - accuracy: 0.86 - ETA: 1:18 - loss: 0.8029 - accuracy: 0.86 - ETA: 1:17 - loss: 0.8011 - accuracy: 0.86 - ETA: 1:16 - loss: 0.8018 - accuracy: 0.86 - ETA: 1:15 - loss: 0.8000 - accuracy: 0.86 - ETA: 1:14 - loss: 0.8033 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7999 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7953 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7964 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7944 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7913 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7890 - accuracy: 0.87 - ETA: 1:07 - loss: 0.7904 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7897 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7853 - accuracy: 0.87 - ETA: 1:05 - loss: 0.7833 - accuracy: 0.87 - ETA: 1:04 - loss: 0.7832 - accuracy: 0.87 - ETA: 1:03 - loss: 0.7797 - accuracy: 0.87 - ETA: 1:02 - loss: 0.7770 - accuracy: 0.87 - ETA: 1:01 - loss: 0.7804 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7809 - accuracy: 0.86 - ETA: 59s - loss: 0.7798 - accuracy: 0.8694 - ETA: 58s - loss: 0.7788 - accuracy: 0.870 - ETA: 57s - loss: 0.7782 - accuracy: 0.869 - ETA: 56s - loss: 0.7766 - accuracy: 0.869 - ETA: 55s - loss: 0.7747 - accuracy: 0.870 - ETA: 54s - loss: 0.7717 - accuracy: 0.870 - ETA: 53s - loss: 0.7734 - accuracy: 0.870 - ETA: 52s - loss: 0.7741 - accuracy: 0.870 - ETA: 51s - loss: 0.7721 - accuracy: 0.870 - ETA: 50s - loss: 0.7748 - accuracy: 0.870 - ETA: 49s - loss: 0.7809 - accuracy: 0.869 - ETA: 48s - loss: 0.7792 - accuracy: 0.869 - ETA: 47s - loss: 0.7787 - accuracy: 0.869 - ETA: 46s - loss: 0.7771 - accuracy: 0.869 - ETA: 45s - loss: 0.7745 - accuracy: 0.870 - ETA: 44s - loss: 0.7798 - accuracy: 0.869 - ETA: 43s - loss: 0.7778 - accuracy: 0.869 - ETA: 42s - loss: 0.7764 - accuracy: 0.869 - ETA: 42s - loss: 0.7743 - accuracy: 0.869 - ETA: 41s - loss: 0.7739 - accuracy: 0.869 - ETA: 40s - loss: 0.7734 - accuracy: 0.869 - ETA: 39s - loss: 0.7753 - accuracy: 0.869 - ETA: 38s - loss: 0.7788 - accuracy: 0.868 - ETA: 37s - loss: 0.7784 - accuracy: 0.869 - ETA: 36s - loss: 0.7759 - accuracy: 0.869 - ETA: 35s - loss: 0.7720 - accuracy: 0.869 - ETA: 34s - loss: 0.7688 - accuracy: 0.869 - ETA: 33s - loss: 0.7691 - accuracy: 0.869 - ETA: 32s - loss: 0.7677 - accuracy: 0.869 - ETA: 31s - loss: 0.7654 - accuracy: 0.869 - ETA: 30s - loss: 0.7630 - accuracy: 0.869 - ETA: 29s - loss: 0.7650 - accuracy: 0.869 - ETA: 28s - loss: 0.7658 - accuracy: 0.869 - ETA: 27s - loss: 0.7635 - accuracy: 0.869 - ETA: 26s - loss: 0.7640 - accuracy: 0.869 - ETA: 25s - loss: 0.7646 - accuracy: 0.868 - ETA: 24s - loss: 0.7656 - accuracy: 0.868 - ETA: 23s - loss: 0.7625 - accuracy: 0.868 - ETA: 22s - loss: 0.7631 - accuracy: 0.869 - ETA: 21s - loss: 0.7649 - accuracy: 0.869 - ETA: 20s - loss: 0.7655 - accuracy: 0.869 - ETA: 19s - loss: 0.7678 - accuracy: 0.869 - ETA: 19s - loss: 0.7690 - accuracy: 0.868 - ETA: 18s - loss: 0.7665 - accuracy: 0.869 - ETA: 17s - loss: 0.7683 - accuracy: 0.869 - ETA: 16s - loss: 0.7697 - accuracy: 0.868 - ETA: 15s - loss: 0.7684 - accuracy: 0.868 - ETA: 14s - loss: 0.7698 - accuracy: 0.868 - ETA: 13s - loss: 0.7694 - accuracy: 0.868 - ETA: 12s - loss: 0.7696 - accuracy: 0.868 - ETA: 11s - loss: 0.7678 - accuracy: 0.868 - ETA: 10s - loss: 0.7669 - accuracy: 0.868 - ETA: 9s - loss: 0.7660 - accuracy: 0.868 - ETA: 8s - loss: 0.7660 - accuracy: 0.86 - ETA: 7s - loss: 0.7649 - accuracy: 0.86 - ETA: 6s - loss: 0.7678 - accuracy: 0.86 - ETA: 5s - loss: 0.7687 - accuracy: 0.86 - ETA: 4s - loss: 0.7676 - accuracy: 0.86 - ETA: 3s - loss: 0.7689 - accuracy: 0.86 - ETA: 2s - loss: 0.7704 - accuracy: 0.86 - ETA: 1s - loss: 0.7681 - accuracy: 0.86 - ETA: 0s - loss: 0.7687 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7689 - accuracy: 0.8676 - val_loss: 3.8992 - val_accuracy: 0.7710\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:22 - loss: 0.3332 - accuracy: 0.91 - ETA: 2:22 - loss: 0.7179 - accuracy: 0.86 - ETA: 2:20 - loss: 0.5822 - accuracy: 0.87 - ETA: 2:22 - loss: 0.6375 - accuracy: 0.87 - ETA: 2:21 - loss: 0.6318 - accuracy: 0.87 - ETA: 2:19 - loss: 0.6591 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6890 - accuracy: 0.87 - ETA: 2:16 - loss: 0.7547 - accuracy: 0.87 - ETA: 2:15 - loss: 0.7238 - accuracy: 0.87 - ETA: 2:14 - loss: 0.6938 - accuracy: 0.87 - ETA: 2:13 - loss: 0.7135 - accuracy: 0.87 - ETA: 2:12 - loss: 0.7174 - accuracy: 0.87 - ETA: 2:11 - loss: 0.7262 - accuracy: 0.87 - ETA: 2:11 - loss: 0.7370 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7246 - accuracy: 0.87 - ETA: 2:08 - loss: 0.7342 - accuracy: 0.87 - ETA: 2:07 - loss: 0.7253 - accuracy: 0.87 - ETA: 2:06 - loss: 0.7264 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7200 - accuracy: 0.87 - ETA: 2:04 - loss: 0.7102 - accuracy: 0.87 - ETA: 2:03 - loss: 0.7247 - accuracy: 0.87 - ETA: 2:03 - loss: 0.7240 - accuracy: 0.86 - ETA: 2:02 - loss: 0.7141 - accuracy: 0.87 - ETA: 2:01 - loss: 0.7046 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6972 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6988 - accuracy: 0.87 - ETA: 1:58 - loss: 0.6893 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6897 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6904 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6810 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6891 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6891 - accuracy: 0.87 - ETA: 1:52 - loss: 0.7003 - accuracy: 0.87 - ETA: 1:51 - loss: 0.7054 - accuracy: 0.87 - ETA: 1:50 - loss: 0.7053 - accuracy: 0.87 - ETA: 1:49 - loss: 0.7048 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6994 - accuracy: 0.87 - ETA: 1:47 - loss: 0.7065 - accuracy: 0.87 - ETA: 1:46 - loss: 0.7068 - accuracy: 0.87 - ETA: 1:46 - loss: 0.7093 - accuracy: 0.87 - ETA: 1:45 - loss: 0.7070 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7103 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7154 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7233 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7330 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7338 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7331 - accuracy: 0.86 - ETA: 1:38 - loss: 0.7257 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7254 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7214 - accuracy: 0.87 - ETA: 1:35 - loss: 0.7172 - accuracy: 0.87 - ETA: 1:34 - loss: 0.7157 - accuracy: 0.87 - ETA: 1:33 - loss: 0.7203 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7167 - accuracy: 0.87 - ETA: 1:31 - loss: 0.7139 - accuracy: 0.87 - ETA: 1:30 - loss: 0.7194 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7200 - accuracy: 0.87 - ETA: 1:28 - loss: 0.7167 - accuracy: 0.87 - ETA: 1:27 - loss: 0.7118 - accuracy: 0.87 - ETA: 1:27 - loss: 0.7106 - accuracy: 0.87 - ETA: 1:25 - loss: 0.7139 - accuracy: 0.87 - ETA: 1:25 - loss: 0.7152 - accuracy: 0.87 - ETA: 1:24 - loss: 0.7172 - accuracy: 0.87 - ETA: 1:23 - loss: 0.7142 - accuracy: 0.87 - ETA: 1:22 - loss: 0.7177 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7127 - accuracy: 0.87 - ETA: 1:20 - loss: 0.7084 - accuracy: 0.87 - ETA: 1:19 - loss: 0.7074 - accuracy: 0.87 - ETA: 1:18 - loss: 0.7080 - accuracy: 0.87 - ETA: 1:17 - loss: 0.7077 - accuracy: 0.87 - ETA: 1:16 - loss: 0.7085 - accuracy: 0.87 - ETA: 1:15 - loss: 0.7172 - accuracy: 0.87 - ETA: 1:14 - loss: 0.7248 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7272 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7244 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7279 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7302 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7361 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7440 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7408 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7370 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7401 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7378 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7361 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7427 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7415 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7397 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7412 - accuracy: 0.86 - ETA: 59s - loss: 0.7419 - accuracy: 0.8679 - ETA: 58s - loss: 0.7441 - accuracy: 0.867 - ETA: 57s - loss: 0.7460 - accuracy: 0.867 - ETA: 56s - loss: 0.7506 - accuracy: 0.866 - ETA: 55s - loss: 0.7498 - accuracy: 0.866 - ETA: 54s - loss: 0.7519 - accuracy: 0.866 - ETA: 53s - loss: 0.7524 - accuracy: 0.866 - ETA: 52s - loss: 0.7488 - accuracy: 0.867 - ETA: 51s - loss: 0.7474 - accuracy: 0.867 - ETA: 50s - loss: 0.7450 - accuracy: 0.867 - ETA: 49s - loss: 0.7447 - accuracy: 0.867 - ETA: 48s - loss: 0.7401 - accuracy: 0.868 - ETA: 47s - loss: 0.7422 - accuracy: 0.868 - ETA: 46s - loss: 0.7406 - accuracy: 0.868 - ETA: 46s - loss: 0.7389 - accuracy: 0.869 - ETA: 45s - loss: 0.7403 - accuracy: 0.868 - ETA: 44s - loss: 0.7380 - accuracy: 0.868 - ETA: 43s - loss: 0.7377 - accuracy: 0.869 - ETA: 42s - loss: 0.7404 - accuracy: 0.869 - ETA: 41s - loss: 0.7402 - accuracy: 0.869 - ETA: 40s - loss: 0.7372 - accuracy: 0.869 - ETA: 39s - loss: 0.7360 - accuracy: 0.869 - ETA: 38s - loss: 0.7343 - accuracy: 0.869 - ETA: 37s - loss: 0.7351 - accuracy: 0.869 - ETA: 36s - loss: 0.7328 - accuracy: 0.869 - ETA: 35s - loss: 0.7331 - accuracy: 0.869 - ETA: 34s - loss: 0.7366 - accuracy: 0.869 - ETA: 33s - loss: 0.7363 - accuracy: 0.869 - ETA: 32s - loss: 0.7366 - accuracy: 0.868 - ETA: 31s - loss: 0.7388 - accuracy: 0.868 - ETA: 30s - loss: 0.7405 - accuracy: 0.868 - ETA: 29s - loss: 0.7375 - accuracy: 0.868 - ETA: 28s - loss: 0.7373 - accuracy: 0.868 - ETA: 27s - loss: 0.7369 - accuracy: 0.868 - ETA: 26s - loss: 0.7364 - accuracy: 0.868 - ETA: 25s - loss: 0.7350 - accuracy: 0.868 - ETA: 24s - loss: 0.7365 - accuracy: 0.868 - ETA: 23s - loss: 0.7382 - accuracy: 0.867 - ETA: 22s - loss: 0.7382 - accuracy: 0.867 - ETA: 21s - loss: 0.7364 - accuracy: 0.867 - ETA: 21s - loss: 0.7378 - accuracy: 0.867 - ETA: 20s - loss: 0.7369 - accuracy: 0.867 - ETA: 19s - loss: 0.7407 - accuracy: 0.867 - ETA: 18s - loss: 0.7417 - accuracy: 0.867 - ETA: 17s - loss: 0.7394 - accuracy: 0.867 - ETA: 16s - loss: 0.7426 - accuracy: 0.867 - ETA: 15s - loss: 0.7445 - accuracy: 0.867 - ETA: 14s - loss: 0.7445 - accuracy: 0.868 - ETA: 13s - loss: 0.7434 - accuracy: 0.867 - ETA: 12s - loss: 0.7438 - accuracy: 0.867 - ETA: 11s - loss: 0.7429 - accuracy: 0.867 - ETA: 10s - loss: 0.7421 - accuracy: 0.867 - ETA: 9s - loss: 0.7381 - accuracy: 0.868 - ETA: 8s - loss: 0.7372 - accuracy: 0.86 - ETA: 7s - loss: 0.7357 - accuracy: 0.86 - ETA: 6s - loss: 0.7353 - accuracy: 0.86 - ETA: 5s - loss: 0.7351 - accuracy: 0.86 - ETA: 4s - loss: 0.7352 - accuracy: 0.86 - ETA: 3s - loss: 0.7340 - accuracy: 0.86 - ETA: 2s - loss: 0.7335 - accuracy: 0.86 - ETA: 1s - loss: 0.7329 - accuracy: 0.86 - ETA: 0s - loss: 0.7353 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7344 - accuracy: 0.8683 - val_loss: 4.1545 - val_accuracy: 0.7683\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 1.6858 - accuracy: 0.85 - ETA: 2:25 - loss: 1.4176 - accuracy: 0.83 - ETA: 2:22 - loss: 1.1977 - accuracy: 0.84 - ETA: 2:21 - loss: 1.0840 - accuracy: 0.85 - ETA: 2:20 - loss: 1.0011 - accuracy: 0.85 - ETA: 2:17 - loss: 0.9666 - accuracy: 0.86 - ETA: 2:16 - loss: 0.8584 - accuracy: 0.87 - ETA: 2:16 - loss: 0.8326 - accuracy: 0.87 - ETA: 2:16 - loss: 0.7935 - accuracy: 0.87 - ETA: 2:15 - loss: 0.8270 - accuracy: 0.86 - ETA: 2:14 - loss: 0.7962 - accuracy: 0.86 - ETA: 2:13 - loss: 0.7902 - accuracy: 0.87 - ETA: 2:12 - loss: 0.7460 - accuracy: 0.87 - ETA: 2:11 - loss: 0.7418 - accuracy: 0.87 - ETA: 2:10 - loss: 0.7229 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7322 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7477 - accuracy: 0.87 - ETA: 2:08 - loss: 0.7409 - accuracy: 0.87 - ETA: 2:07 - loss: 0.7307 - accuracy: 0.87 - ETA: 2:06 - loss: 0.7269 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7177 - accuracy: 0.87 - ETA: 2:04 - loss: 0.7154 - accuracy: 0.87 - ETA: 2:03 - loss: 0.7067 - accuracy: 0.87 - ETA: 2:02 - loss: 0.7013 - accuracy: 0.87 - ETA: 2:01 - loss: 0.7056 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6982 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6858 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6965 - accuracy: 0.87 - ETA: 1:58 - loss: 0.6963 - accuracy: 0.88 - ETA: 1:56 - loss: 0.6918 - accuracy: 0.88 - ETA: 1:55 - loss: 0.6873 - accuracy: 0.88 - ETA: 1:54 - loss: 0.6812 - accuracy: 0.88 - ETA: 1:53 - loss: 0.6899 - accuracy: 0.88 - ETA: 1:52 - loss: 0.6928 - accuracy: 0.88 - ETA: 1:51 - loss: 0.6986 - accuracy: 0.88 - ETA: 1:50 - loss: 0.7006 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6938 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6916 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6893 - accuracy: 0.87 - ETA: 1:47 - loss: 0.6921 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6833 - accuracy: 0.87 - ETA: 1:45 - loss: 0.6984 - accuracy: 0.87 - ETA: 1:44 - loss: 0.7081 - accuracy: 0.87 - ETA: 1:43 - loss: 0.7188 - accuracy: 0.87 - ETA: 1:42 - loss: 0.7193 - accuracy: 0.87 - ETA: 1:41 - loss: 0.7195 - accuracy: 0.87 - ETA: 1:40 - loss: 0.7254 - accuracy: 0.87 - ETA: 1:39 - loss: 0.7431 - accuracy: 0.87 - ETA: 1:38 - loss: 0.7410 - accuracy: 0.87 - ETA: 1:37 - loss: 0.7517 - accuracy: 0.87 - ETA: 1:36 - loss: 0.7503 - accuracy: 0.87 - ETA: 1:35 - loss: 0.7590 - accuracy: 0.87 - ETA: 1:34 - loss: 0.7563 - accuracy: 0.87 - ETA: 1:33 - loss: 0.7634 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7631 - accuracy: 0.87 - ETA: 1:31 - loss: 0.7573 - accuracy: 0.87 - ETA: 1:30 - loss: 0.7581 - accuracy: 0.87 - ETA: 1:29 - loss: 0.7556 - accuracy: 0.87 - ETA: 1:28 - loss: 0.7542 - accuracy: 0.87 - ETA: 1:27 - loss: 0.7546 - accuracy: 0.87 - ETA: 1:26 - loss: 0.7524 - accuracy: 0.87 - ETA: 1:25 - loss: 0.7479 - accuracy: 0.87 - ETA: 1:24 - loss: 0.7421 - accuracy: 0.87 - ETA: 1:23 - loss: 0.7370 - accuracy: 0.87 - ETA: 1:22 - loss: 0.7421 - accuracy: 0.87 - ETA: 1:21 - loss: 0.7389 - accuracy: 0.87 - ETA: 1:20 - loss: 0.7458 - accuracy: 0.87 - ETA: 1:19 - loss: 0.7450 - accuracy: 0.87 - ETA: 1:18 - loss: 0.7480 - accuracy: 0.87 - ETA: 1:17 - loss: 0.7463 - accuracy: 0.87 - ETA: 1:16 - loss: 0.7432 - accuracy: 0.87 - ETA: 1:15 - loss: 0.7456 - accuracy: 0.87 - ETA: 1:14 - loss: 0.7431 - accuracy: 0.87 - ETA: 1:13 - loss: 0.7443 - accuracy: 0.87 - ETA: 1:12 - loss: 0.7424 - accuracy: 0.87 - ETA: 1:12 - loss: 0.7406 - accuracy: 0.87 - ETA: 1:11 - loss: 0.7407 - accuracy: 0.87 - ETA: 1:10 - loss: 0.7417 - accuracy: 0.87 - ETA: 1:09 - loss: 0.7383 - accuracy: 0.87 - ETA: 1:08 - loss: 0.7424 - accuracy: 0.87 - ETA: 1:07 - loss: 0.7464 - accuracy: 0.87 - ETA: 1:06 - loss: 0.7433 - accuracy: 0.87 - ETA: 1:05 - loss: 0.7442 - accuracy: 0.87 - ETA: 1:04 - loss: 0.7397 - accuracy: 0.87 - ETA: 1:03 - loss: 0.7486 - accuracy: 0.87 - ETA: 1:02 - loss: 0.7496 - accuracy: 0.87 - ETA: 1:01 - loss: 0.7546 - accuracy: 0.87 - ETA: 1:00 - loss: 0.7541 - accuracy: 0.87 - ETA: 59s - loss: 0.7540 - accuracy: 0.8709 - ETA: 58s - loss: 0.7514 - accuracy: 0.871 - ETA: 57s - loss: 0.7517 - accuracy: 0.870 - ETA: 56s - loss: 0.7488 - accuracy: 0.870 - ETA: 55s - loss: 0.7499 - accuracy: 0.870 - ETA: 54s - loss: 0.7459 - accuracy: 0.871 - ETA: 53s - loss: 0.7508 - accuracy: 0.871 - ETA: 52s - loss: 0.7530 - accuracy: 0.870 - ETA: 51s - loss: 0.7496 - accuracy: 0.870 - ETA: 50s - loss: 0.7504 - accuracy: 0.870 - ETA: 49s - loss: 0.7518 - accuracy: 0.870 - ETA: 49s - loss: 0.7476 - accuracy: 0.871 - ETA: 48s - loss: 0.7462 - accuracy: 0.871 - ETA: 47s - loss: 0.7481 - accuracy: 0.870 - ETA: 46s - loss: 0.7495 - accuracy: 0.870 - ETA: 45s - loss: 0.7499 - accuracy: 0.870 - ETA: 44s - loss: 0.7484 - accuracy: 0.870 - ETA: 43s - loss: 0.7514 - accuracy: 0.869 - ETA: 42s - loss: 0.7520 - accuracy: 0.869 - ETA: 41s - loss: 0.7514 - accuracy: 0.869 - ETA: 40s - loss: 0.7531 - accuracy: 0.869 - ETA: 39s - loss: 0.7534 - accuracy: 0.868 - ETA: 38s - loss: 0.7561 - accuracy: 0.868 - ETA: 37s - loss: 0.7593 - accuracy: 0.868 - ETA: 36s - loss: 0.7568 - accuracy: 0.868 - ETA: 35s - loss: 0.7557 - accuracy: 0.869 - ETA: 34s - loss: 0.7539 - accuracy: 0.869 - ETA: 33s - loss: 0.7570 - accuracy: 0.869 - ETA: 32s - loss: 0.7576 - accuracy: 0.869 - ETA: 31s - loss: 0.7576 - accuracy: 0.869 - ETA: 30s - loss: 0.7555 - accuracy: 0.869 - ETA: 29s - loss: 0.7537 - accuracy: 0.869 - ETA: 28s - loss: 0.7528 - accuracy: 0.869 - ETA: 27s - loss: 0.7562 - accuracy: 0.869 - ETA: 26s - loss: 0.7565 - accuracy: 0.869 - ETA: 25s - loss: 0.7558 - accuracy: 0.869 - ETA: 24s - loss: 0.7567 - accuracy: 0.869 - ETA: 23s - loss: 0.7588 - accuracy: 0.869 - ETA: 22s - loss: 0.7589 - accuracy: 0.869 - ETA: 21s - loss: 0.7659 - accuracy: 0.869 - ETA: 20s - loss: 0.7655 - accuracy: 0.869 - ETA: 20s - loss: 0.7633 - accuracy: 0.869 - ETA: 19s - loss: 0.7651 - accuracy: 0.868 - ETA: 18s - loss: 0.7656 - accuracy: 0.868 - ETA: 17s - loss: 0.7663 - accuracy: 0.868 - ETA: 16s - loss: 0.7656 - accuracy: 0.868 - ETA: 15s - loss: 0.7635 - accuracy: 0.868 - ETA: 14s - loss: 0.7610 - accuracy: 0.869 - ETA: 13s - loss: 0.7653 - accuracy: 0.868 - ETA: 12s - loss: 0.7644 - accuracy: 0.868 - ETA: 11s - loss: 0.7639 - accuracy: 0.869 - ETA: 10s - loss: 0.7619 - accuracy: 0.869 - ETA: 9s - loss: 0.7607 - accuracy: 0.869 - ETA: 8s - loss: 0.7576 - accuracy: 0.86 - ETA: 7s - loss: 0.7567 - accuracy: 0.86 - ETA: 6s - loss: 0.7582 - accuracy: 0.86 - ETA: 5s - loss: 0.7596 - accuracy: 0.86 - ETA: 4s - loss: 0.7625 - accuracy: 0.86 - ETA: 3s - loss: 0.7606 - accuracy: 0.86 - ETA: 2s - loss: 0.7581 - accuracy: 0.86 - ETA: 1s - loss: 0.7588 - accuracy: 0.86 - ETA: 0s - loss: 0.7564 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7555 - accuracy: 0.8690 - val_loss: 4.1397 - val_accuracy: 0.7732\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 0.7050 - accuracy: 0.85 - ETA: 2:22 - loss: 0.8593 - accuracy: 0.83 - ETA: 2:22 - loss: 0.7254 - accuracy: 0.86 - ETA: 2:20 - loss: 0.6408 - accuracy: 0.87 - ETA: 2:18 - loss: 0.6056 - accuracy: 0.87 - ETA: 2:16 - loss: 0.6784 - accuracy: 0.86 - ETA: 2:16 - loss: 0.6636 - accuracy: 0.86 - ETA: 2:15 - loss: 0.6967 - accuracy: 0.86 - ETA: 2:14 - loss: 0.6827 - accuracy: 0.86 - ETA: 2:14 - loss: 0.6856 - accuracy: 0.86 - ETA: 2:13 - loss: 0.6608 - accuracy: 0.86 - ETA: 2:13 - loss: 0.6713 - accuracy: 0.86 - ETA: 2:13 - loss: 0.6811 - accuracy: 0.86 - ETA: 2:11 - loss: 0.6708 - accuracy: 0.86 - ETA: 2:10 - loss: 0.6902 - accuracy: 0.86 - ETA: 2:10 - loss: 0.6944 - accuracy: 0.86 - ETA: 2:08 - loss: 0.6950 - accuracy: 0.86 - ETA: 2:07 - loss: 0.6970 - accuracy: 0.86 - ETA: 2:06 - loss: 0.6766 - accuracy: 0.86 - ETA: 2:05 - loss: 0.6843 - accuracy: 0.86 - ETA: 2:05 - loss: 0.6875 - accuracy: 0.86 - ETA: 2:04 - loss: 0.6871 - accuracy: 0.86 - ETA: 2:02 - loss: 0.6986 - accuracy: 0.86 - ETA: 2:01 - loss: 0.7082 - accuracy: 0.86 - ETA: 2:00 - loss: 0.7087 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7017 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7049 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7219 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7139 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7106 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7103 - accuracy: 0.86 - ETA: 1:53 - loss: 0.7162 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7153 - accuracy: 0.86 - ETA: 1:51 - loss: 0.7164 - accuracy: 0.86 - ETA: 1:50 - loss: 0.7148 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7131 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7079 - accuracy: 0.86 - ETA: 1:47 - loss: 0.6998 - accuracy: 0.86 - ETA: 1:46 - loss: 0.6934 - accuracy: 0.86 - ETA: 1:45 - loss: 0.6961 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7033 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7080 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7027 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7046 - accuracy: 0.86 - ETA: 1:40 - loss: 0.6962 - accuracy: 0.86 - ETA: 1:39 - loss: 0.6956 - accuracy: 0.86 - ETA: 1:39 - loss: 0.6904 - accuracy: 0.86 - ETA: 1:38 - loss: 0.6908 - accuracy: 0.86 - ETA: 1:37 - loss: 0.6881 - accuracy: 0.86 - ETA: 1:36 - loss: 0.6806 - accuracy: 0.86 - ETA: 1:35 - loss: 0.6843 - accuracy: 0.86 - ETA: 1:34 - loss: 0.6833 - accuracy: 0.86 - ETA: 1:33 - loss: 0.6849 - accuracy: 0.86 - ETA: 1:32 - loss: 0.6832 - accuracy: 0.86 - ETA: 1:31 - loss: 0.6871 - accuracy: 0.86 - ETA: 1:30 - loss: 0.6876 - accuracy: 0.86 - ETA: 1:29 - loss: 0.6921 - accuracy: 0.86 - ETA: 1:28 - loss: 0.6916 - accuracy: 0.86 - ETA: 1:27 - loss: 0.6921 - accuracy: 0.86 - ETA: 1:26 - loss: 0.6910 - accuracy: 0.86 - ETA: 1:25 - loss: 0.6907 - accuracy: 0.86 - ETA: 1:25 - loss: 0.6952 - accuracy: 0.86 - ETA: 1:24 - loss: 0.6940 - accuracy: 0.86 - ETA: 1:23 - loss: 0.6912 - accuracy: 0.86 - ETA: 1:22 - loss: 0.7012 - accuracy: 0.86 - ETA: 1:21 - loss: 0.7024 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7132 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7111 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7090 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7099 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7243 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7204 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7179 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7204 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7269 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7240 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7193 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7164 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7211 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7299 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7303 - accuracy: 0.86 - ETA: 1:05 - loss: 0.7319 - accuracy: 0.86 - ETA: 1:04 - loss: 0.7305 - accuracy: 0.86 - ETA: 1:03 - loss: 0.7275 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7250 - accuracy: 0.86 - ETA: 1:02 - loss: 0.7246 - accuracy: 0.86 - ETA: 1:01 - loss: 0.7201 - accuracy: 0.86 - ETA: 1:00 - loss: 0.7204 - accuracy: 0.86 - ETA: 59s - loss: 0.7169 - accuracy: 0.8670 - ETA: 58s - loss: 0.7167 - accuracy: 0.867 - ETA: 57s - loss: 0.7134 - accuracy: 0.867 - ETA: 56s - loss: 0.7100 - accuracy: 0.868 - ETA: 55s - loss: 0.7088 - accuracy: 0.868 - ETA: 54s - loss: 0.7121 - accuracy: 0.867 - ETA: 53s - loss: 0.7116 - accuracy: 0.868 - ETA: 52s - loss: 0.7131 - accuracy: 0.868 - ETA: 51s - loss: 0.7123 - accuracy: 0.868 - ETA: 50s - loss: 0.7104 - accuracy: 0.869 - ETA: 49s - loss: 0.7128 - accuracy: 0.868 - ETA: 48s - loss: 0.7143 - accuracy: 0.869 - ETA: 47s - loss: 0.7112 - accuracy: 0.869 - ETA: 46s - loss: 0.7108 - accuracy: 0.869 - ETA: 45s - loss: 0.7113 - accuracy: 0.869 - ETA: 44s - loss: 0.7103 - accuracy: 0.869 - ETA: 43s - loss: 0.7089 - accuracy: 0.869 - ETA: 42s - loss: 0.7098 - accuracy: 0.868 - ETA: 41s - loss: 0.7091 - accuracy: 0.868 - ETA: 41s - loss: 0.7057 - accuracy: 0.869 - ETA: 40s - loss: 0.7054 - accuracy: 0.869 - ETA: 39s - loss: 0.7043 - accuracy: 0.869 - ETA: 38s - loss: 0.7045 - accuracy: 0.868 - ETA: 37s - loss: 0.7052 - accuracy: 0.869 - ETA: 36s - loss: 0.7066 - accuracy: 0.868 - ETA: 35s - loss: 0.7069 - accuracy: 0.868 - ETA: 34s - loss: 0.7071 - accuracy: 0.867 - ETA: 33s - loss: 0.7072 - accuracy: 0.867 - ETA: 32s - loss: 0.7060 - accuracy: 0.867 - ETA: 31s - loss: 0.7052 - accuracy: 0.867 - ETA: 30s - loss: 0.7060 - accuracy: 0.867 - ETA: 29s - loss: 0.7034 - accuracy: 0.867 - ETA: 28s - loss: 0.7038 - accuracy: 0.867 - ETA: 27s - loss: 0.7043 - accuracy: 0.867 - ETA: 26s - loss: 0.7023 - accuracy: 0.867 - ETA: 25s - loss: 0.7077 - accuracy: 0.867 - ETA: 24s - loss: 0.7058 - accuracy: 0.867 - ETA: 23s - loss: 0.7055 - accuracy: 0.867 - ETA: 22s - loss: 0.7068 - accuracy: 0.867 - ETA: 21s - loss: 0.7064 - accuracy: 0.867 - ETA: 21s - loss: 0.7077 - accuracy: 0.867 - ETA: 20s - loss: 0.7073 - accuracy: 0.867 - ETA: 19s - loss: 0.7092 - accuracy: 0.867 - ETA: 18s - loss: 0.7080 - accuracy: 0.867 - ETA: 17s - loss: 0.7077 - accuracy: 0.867 - ETA: 16s - loss: 0.7064 - accuracy: 0.867 - ETA: 15s - loss: 0.7059 - accuracy: 0.867 - ETA: 14s - loss: 0.7063 - accuracy: 0.867 - ETA: 13s - loss: 0.7139 - accuracy: 0.867 - ETA: 12s - loss: 0.7123 - accuracy: 0.867 - ETA: 11s - loss: 0.7126 - accuracy: 0.867 - ETA: 10s - loss: 0.7134 - accuracy: 0.867 - ETA: 9s - loss: 0.7106 - accuracy: 0.867 - ETA: 8s - loss: 0.7087 - accuracy: 0.86 - ETA: 7s - loss: 0.7136 - accuracy: 0.86 - ETA: 6s - loss: 0.7135 - accuracy: 0.86 - ETA: 5s - loss: 0.7117 - accuracy: 0.86 - ETA: 4s - loss: 0.7117 - accuracy: 0.86 - ETA: 3s - loss: 0.7099 - accuracy: 0.86 - ETA: 2s - loss: 0.7097 - accuracy: 0.86 - ETA: 1s - loss: 0.7081 - accuracy: 0.86 - ETA: 0s - loss: 0.7076 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7090 - accuracy: 0.8680 - val_loss: 3.9429 - val_accuracy: 0.7724\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:23 - loss: 0.5315 - accuracy: 0.89 - ETA: 2:22 - loss: 0.5049 - accuracy: 0.89 - ETA: 2:21 - loss: 0.5521 - accuracy: 0.89 - ETA: 2:19 - loss: 0.5805 - accuracy: 0.88 - ETA: 2:18 - loss: 0.6816 - accuracy: 0.87 - ETA: 2:16 - loss: 0.7311 - accuracy: 0.86 - ETA: 2:16 - loss: 0.6956 - accuracy: 0.87 - ETA: 2:14 - loss: 0.7008 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6660 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6828 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6829 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6955 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6945 - accuracy: 0.87 - ETA: 2:09 - loss: 0.6749 - accuracy: 0.87 - ETA: 2:09 - loss: 0.6812 - accuracy: 0.87 - ETA: 2:09 - loss: 0.6636 - accuracy: 0.87 - ETA: 2:08 - loss: 0.6595 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6741 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6746 - accuracy: 0.87 - ETA: 2:05 - loss: 0.6714 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6975 - accuracy: 0.87 - ETA: 2:04 - loss: 0.6972 - accuracy: 0.87 - ETA: 2:03 - loss: 0.6898 - accuracy: 0.87 - ETA: 2:02 - loss: 0.6834 - accuracy: 0.88 - ETA: 2:00 - loss: 0.6782 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6995 - accuracy: 0.87 - ETA: 1:58 - loss: 0.6951 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6989 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6902 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6918 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6826 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6748 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6723 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6905 - accuracy: 0.87 - ETA: 1:52 - loss: 0.7096 - accuracy: 0.87 - ETA: 1:51 - loss: 0.7031 - accuracy: 0.87 - ETA: 1:50 - loss: 0.6974 - accuracy: 0.87 - ETA: 1:49 - loss: 0.7007 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6996 - accuracy: 0.87 - ETA: 1:47 - loss: 0.6991 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6956 - accuracy: 0.87 - ETA: 1:45 - loss: 0.7023 - accuracy: 0.87 - ETA: 1:44 - loss: 0.7069 - accuracy: 0.87 - ETA: 1:43 - loss: 0.7009 - accuracy: 0.87 - ETA: 1:42 - loss: 0.7036 - accuracy: 0.87 - ETA: 1:41 - loss: 0.7147 - accuracy: 0.87 - ETA: 1:40 - loss: 0.7103 - accuracy: 0.87 - ETA: 1:39 - loss: 0.7204 - accuracy: 0.87 - ETA: 1:38 - loss: 0.7200 - accuracy: 0.87 - ETA: 1:37 - loss: 0.7324 - accuracy: 0.87 - ETA: 1:36 - loss: 0.7332 - accuracy: 0.87 - ETA: 1:35 - loss: 0.7356 - accuracy: 0.87 - ETA: 1:34 - loss: 0.7351 - accuracy: 0.87 - ETA: 1:33 - loss: 0.7373 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7378 - accuracy: 0.86 - ETA: 1:31 - loss: 0.7353 - accuracy: 0.86 - ETA: 1:30 - loss: 0.7320 - accuracy: 0.86 - ETA: 1:29 - loss: 0.7273 - accuracy: 0.87 - ETA: 1:28 - loss: 0.7228 - accuracy: 0.87 - ETA: 1:27 - loss: 0.7176 - accuracy: 0.87 - ETA: 1:26 - loss: 0.7180 - accuracy: 0.87 - ETA: 1:25 - loss: 0.7178 - accuracy: 0.87 - ETA: 1:24 - loss: 0.7181 - accuracy: 0.87 - ETA: 1:23 - loss: 0.7157 - accuracy: 0.87 - ETA: 1:22 - loss: 0.7162 - accuracy: 0.87 - ETA: 1:21 - loss: 0.7164 - accuracy: 0.86 - ETA: 1:20 - loss: 0.7215 - accuracy: 0.86 - ETA: 1:19 - loss: 0.7255 - accuracy: 0.86 - ETA: 1:18 - loss: 0.7215 - accuracy: 0.86 - ETA: 1:17 - loss: 0.7212 - accuracy: 0.86 - ETA: 1:16 - loss: 0.7187 - accuracy: 0.86 - ETA: 1:15 - loss: 0.7139 - accuracy: 0.86 - ETA: 1:14 - loss: 0.7139 - accuracy: 0.86 - ETA: 1:13 - loss: 0.7107 - accuracy: 0.86 - ETA: 1:12 - loss: 0.7171 - accuracy: 0.86 - ETA: 1:11 - loss: 0.7179 - accuracy: 0.86 - ETA: 1:10 - loss: 0.7181 - accuracy: 0.86 - ETA: 1:09 - loss: 0.7148 - accuracy: 0.86 - ETA: 1:08 - loss: 0.7120 - accuracy: 0.86 - ETA: 1:07 - loss: 0.7138 - accuracy: 0.86 - ETA: 1:06 - loss: 0.7127 - accuracy: 0.87 - ETA: 1:05 - loss: 0.7158 - accuracy: 0.87 - ETA: 1:05 - loss: 0.7107 - accuracy: 0.87 - ETA: 1:04 - loss: 0.7085 - accuracy: 0.87 - ETA: 1:03 - loss: 0.7104 - accuracy: 0.87 - ETA: 1:02 - loss: 0.7129 - accuracy: 0.87 - ETA: 1:01 - loss: 0.7191 - accuracy: 0.87 - ETA: 1:00 - loss: 0.7213 - accuracy: 0.86 - ETA: 59s - loss: 0.7244 - accuracy: 0.8700 - ETA: 58s - loss: 0.7291 - accuracy: 0.870 - ETA: 57s - loss: 0.7298 - accuracy: 0.869 - ETA: 56s - loss: 0.7282 - accuracy: 0.869 - ETA: 55s - loss: 0.7246 - accuracy: 0.870 - ETA: 54s - loss: 0.7221 - accuracy: 0.870 - ETA: 53s - loss: 0.7250 - accuracy: 0.869 - ETA: 52s - loss: 0.7257 - accuracy: 0.869 - ETA: 51s - loss: 0.7244 - accuracy: 0.869 - ETA: 50s - loss: 0.7241 - accuracy: 0.869 - ETA: 49s - loss: 0.7221 - accuracy: 0.869 - ETA: 48s - loss: 0.7219 - accuracy: 0.869 - ETA: 47s - loss: 0.7191 - accuracy: 0.869 - ETA: 46s - loss: 0.7158 - accuracy: 0.869 - ETA: 45s - loss: 0.7134 - accuracy: 0.869 - ETA: 44s - loss: 0.7139 - accuracy: 0.869 - ETA: 44s - loss: 0.7114 - accuracy: 0.869 - ETA: 43s - loss: 0.7125 - accuracy: 0.869 - ETA: 42s - loss: 0.7158 - accuracy: 0.869 - ETA: 41s - loss: 0.7133 - accuracy: 0.869 - ETA: 40s - loss: 0.7157 - accuracy: 0.869 - ETA: 39s - loss: 0.7162 - accuracy: 0.869 - ETA: 38s - loss: 0.7180 - accuracy: 0.868 - ETA: 37s - loss: 0.7172 - accuracy: 0.868 - ETA: 36s - loss: 0.7186 - accuracy: 0.868 - ETA: 35s - loss: 0.7197 - accuracy: 0.868 - ETA: 34s - loss: 0.7174 - accuracy: 0.868 - ETA: 33s - loss: 0.7171 - accuracy: 0.868 - ETA: 32s - loss: 0.7180 - accuracy: 0.868 - ETA: 31s - loss: 0.7179 - accuracy: 0.868 - ETA: 30s - loss: 0.7150 - accuracy: 0.868 - ETA: 29s - loss: 0.7132 - accuracy: 0.869 - ETA: 28s - loss: 0.7099 - accuracy: 0.869 - ETA: 27s - loss: 0.7090 - accuracy: 0.869 - ETA: 26s - loss: 0.7090 - accuracy: 0.869 - ETA: 25s - loss: 0.7099 - accuracy: 0.869 - ETA: 24s - loss: 0.7120 - accuracy: 0.869 - ETA: 23s - loss: 0.7094 - accuracy: 0.869 - ETA: 22s - loss: 0.7082 - accuracy: 0.869 - ETA: 21s - loss: 0.7063 - accuracy: 0.869 - ETA: 20s - loss: 0.7060 - accuracy: 0.869 - ETA: 20s - loss: 0.7055 - accuracy: 0.869 - ETA: 19s - loss: 0.7035 - accuracy: 0.869 - ETA: 18s - loss: 0.7021 - accuracy: 0.869 - ETA: 17s - loss: 0.7031 - accuracy: 0.869 - ETA: 16s - loss: 0.7022 - accuracy: 0.869 - ETA: 15s - loss: 0.7012 - accuracy: 0.869 - ETA: 14s - loss: 0.7044 - accuracy: 0.869 - ETA: 13s - loss: 0.7023 - accuracy: 0.869 - ETA: 12s - loss: 0.7010 - accuracy: 0.869 - ETA: 11s - loss: 0.7011 - accuracy: 0.869 - ETA: 10s - loss: 0.7037 - accuracy: 0.869 - ETA: 9s - loss: 0.7068 - accuracy: 0.869 - ETA: 8s - loss: 0.7064 - accuracy: 0.86 - ETA: 7s - loss: 0.7103 - accuracy: 0.86 - ETA: 6s - loss: 0.7086 - accuracy: 0.87 - ETA: 5s - loss: 0.7080 - accuracy: 0.87 - ETA: 4s - loss: 0.7079 - accuracy: 0.87 - ETA: 3s - loss: 0.7075 - accuracy: 0.87 - ETA: 2s - loss: 0.7108 - accuracy: 0.87 - ETA: 1s - loss: 0.7090 - accuracy: 0.87 - ETA: 0s - loss: 0.7103 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7116 - accuracy: 0.8699 - val_loss: 3.8645 - val_accuracy: 0.7720\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:22 - loss: 0.6691 - accuracy: 0.85 - ETA: 2:18 - loss: 0.6599 - accuracy: 0.86 - ETA: 2:17 - loss: 0.7210 - accuracy: 0.86 - ETA: 2:19 - loss: 0.6841 - accuracy: 0.86 - ETA: 2:21 - loss: 0.6513 - accuracy: 0.86 - ETA: 2:19 - loss: 0.6174 - accuracy: 0.86 - ETA: 2:18 - loss: 0.6615 - accuracy: 0.86 - ETA: 2:18 - loss: 0.6698 - accuracy: 0.86 - ETA: 2:17 - loss: 0.6731 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7010 - accuracy: 0.86 - ETA: 2:15 - loss: 0.6718 - accuracy: 0.86 - ETA: 2:13 - loss: 0.7040 - accuracy: 0.86 - ETA: 2:12 - loss: 0.6878 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6832 - accuracy: 0.87 - ETA: 2:10 - loss: 0.6653 - accuracy: 0.87 - ETA: 2:08 - loss: 0.6614 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6610 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6758 - accuracy: 0.87 - ETA: 2:05 - loss: 0.6595 - accuracy: 0.87 - ETA: 2:04 - loss: 0.6673 - accuracy: 0.87 - ETA: 2:03 - loss: 0.6619 - accuracy: 0.87 - ETA: 2:03 - loss: 0.6645 - accuracy: 0.87 - ETA: 2:02 - loss: 0.6619 - accuracy: 0.86 - ETA: 2:01 - loss: 0.6556 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6639 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6637 - accuracy: 0.87 - ETA: 1:58 - loss: 0.6811 - accuracy: 0.86 - ETA: 1:57 - loss: 0.6868 - accuracy: 0.86 - ETA: 1:56 - loss: 0.6860 - accuracy: 0.86 - ETA: 1:55 - loss: 0.6913 - accuracy: 0.86 - ETA: 1:54 - loss: 0.6903 - accuracy: 0.86 - ETA: 1:53 - loss: 0.6824 - accuracy: 0.86 - ETA: 1:52 - loss: 0.6852 - accuracy: 0.86 - ETA: 1:51 - loss: 0.6946 - accuracy: 0.86 - ETA: 1:50 - loss: 0.6989 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7115 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7047 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7000 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7009 - accuracy: 0.86 - ETA: 1:46 - loss: 0.6963 - accuracy: 0.86 - ETA: 1:45 - loss: 0.6944 - accuracy: 0.86 - ETA: 1:44 - loss: 0.6904 - accuracy: 0.86 - ETA: 1:43 - loss: 0.6832 - accuracy: 0.86 - ETA: 1:42 - loss: 0.6746 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7131 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7163 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7076 - accuracy: 0.86 - ETA: 1:37 - loss: 0.7110 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7104 - accuracy: 0.86 - ETA: 1:36 - loss: 0.7085 - accuracy: 0.86 - ETA: 1:35 - loss: 0.7061 - accuracy: 0.86 - ETA: 1:33 - loss: 0.7026 - accuracy: 0.86 - ETA: 1:33 - loss: 0.7041 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7027 - accuracy: 0.87 - ETA: 1:31 - loss: 0.7036 - accuracy: 0.86 - ETA: 1:30 - loss: 0.7032 - accuracy: 0.87 - ETA: 1:29 - loss: 0.7051 - accuracy: 0.86 - ETA: 1:28 - loss: 0.7031 - accuracy: 0.86 - ETA: 1:27 - loss: 0.7000 - accuracy: 0.86 - ETA: 1:26 - loss: 0.6971 - accuracy: 0.86 - ETA: 1:25 - loss: 0.6941 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6915 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6904 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6859 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6864 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6851 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6899 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6857 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6872 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6896 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6860 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6838 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6848 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6879 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6876 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6845 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6835 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6848 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6878 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6895 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6917 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6931 - accuracy: 0.87 - ETA: 1:04 - loss: 0.7006 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6994 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6952 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6952 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6947 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6941 - accuracy: 0.87 - ETA: 59s - loss: 0.6942 - accuracy: 0.8710 - ETA: 58s - loss: 0.6956 - accuracy: 0.871 - ETA: 57s - loss: 0.7025 - accuracy: 0.870 - ETA: 56s - loss: 0.7053 - accuracy: 0.870 - ETA: 55s - loss: 0.7052 - accuracy: 0.870 - ETA: 54s - loss: 0.7034 - accuracy: 0.870 - ETA: 53s - loss: 0.7027 - accuracy: 0.870 - ETA: 52s - loss: 0.7005 - accuracy: 0.870 - ETA: 51s - loss: 0.6987 - accuracy: 0.871 - ETA: 50s - loss: 0.6991 - accuracy: 0.870 - ETA: 49s - loss: 0.6997 - accuracy: 0.870 - ETA: 48s - loss: 0.6998 - accuracy: 0.870 - ETA: 47s - loss: 0.7006 - accuracy: 0.870 - ETA: 46s - loss: 0.7003 - accuracy: 0.870 - ETA: 45s - loss: 0.7004 - accuracy: 0.870 - ETA: 44s - loss: 0.6992 - accuracy: 0.870 - ETA: 43s - loss: 0.6969 - accuracy: 0.870 - ETA: 42s - loss: 0.6971 - accuracy: 0.870 - ETA: 41s - loss: 0.6972 - accuracy: 0.870 - ETA: 41s - loss: 0.6951 - accuracy: 0.870 - ETA: 40s - loss: 0.7011 - accuracy: 0.870 - ETA: 39s - loss: 0.6987 - accuracy: 0.870 - ETA: 38s - loss: 0.7017 - accuracy: 0.870 - ETA: 37s - loss: 0.7007 - accuracy: 0.870 - ETA: 36s - loss: 0.6985 - accuracy: 0.870 - ETA: 35s - loss: 0.7017 - accuracy: 0.870 - ETA: 34s - loss: 0.7058 - accuracy: 0.870 - ETA: 33s - loss: 0.7049 - accuracy: 0.870 - ETA: 32s - loss: 0.7067 - accuracy: 0.870 - ETA: 31s - loss: 0.7082 - accuracy: 0.870 - ETA: 30s - loss: 0.7115 - accuracy: 0.870 - ETA: 29s - loss: 0.7132 - accuracy: 0.870 - ETA: 28s - loss: 0.7193 - accuracy: 0.870 - ETA: 27s - loss: 0.7160 - accuracy: 0.870 - ETA: 26s - loss: 0.7142 - accuracy: 0.870 - ETA: 25s - loss: 0.7140 - accuracy: 0.871 - ETA: 24s - loss: 0.7132 - accuracy: 0.871 - ETA: 23s - loss: 0.7157 - accuracy: 0.870 - ETA: 22s - loss: 0.7160 - accuracy: 0.870 - ETA: 21s - loss: 0.7153 - accuracy: 0.870 - ETA: 20s - loss: 0.7155 - accuracy: 0.870 - ETA: 19s - loss: 0.7132 - accuracy: 0.870 - ETA: 18s - loss: 0.7135 - accuracy: 0.870 - ETA: 18s - loss: 0.7125 - accuracy: 0.870 - ETA: 17s - loss: 0.7120 - accuracy: 0.870 - ETA: 16s - loss: 0.7146 - accuracy: 0.869 - ETA: 15s - loss: 0.7157 - accuracy: 0.869 - ETA: 14s - loss: 0.7169 - accuracy: 0.869 - ETA: 13s - loss: 0.7155 - accuracy: 0.869 - ETA: 12s - loss: 0.7163 - accuracy: 0.869 - ETA: 11s - loss: 0.7134 - accuracy: 0.869 - ETA: 10s - loss: 0.7116 - accuracy: 0.869 - ETA: 9s - loss: 0.7158 - accuracy: 0.869 - ETA: 8s - loss: 0.7170 - accuracy: 0.86 - ETA: 7s - loss: 0.7180 - accuracy: 0.86 - ETA: 6s - loss: 0.7200 - accuracy: 0.86 - ETA: 5s - loss: 0.7188 - accuracy: 0.86 - ETA: 4s - loss: 0.7178 - accuracy: 0.86 - ETA: 3s - loss: 0.7188 - accuracy: 0.86 - ETA: 2s - loss: 0.7171 - accuracy: 0.86 - ETA: 1s - loss: 0.7182 - accuracy: 0.86 - ETA: 0s - loss: 0.7180 - accuracy: 0.86 - 156s 8ms/step - loss: 0.7166 - accuracy: 0.8688 - val_loss: 3.7004 - val_accuracy: 0.7712\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:40 - loss: 0.7192 - accuracy: 0.83 - ETA: 2:33 - loss: 0.6399 - accuracy: 0.87 - ETA: 2:27 - loss: 0.6352 - accuracy: 0.87 - ETA: 2:25 - loss: 0.6150 - accuracy: 0.87 - ETA: 2:22 - loss: 0.6492 - accuracy: 0.85 - ETA: 2:20 - loss: 0.6238 - accuracy: 0.86 - ETA: 2:18 - loss: 0.6230 - accuracy: 0.86 - ETA: 2:18 - loss: 0.6383 - accuracy: 0.86 - ETA: 2:19 - loss: 0.6619 - accuracy: 0.86 - ETA: 2:18 - loss: 0.7141 - accuracy: 0.86 - ETA: 2:16 - loss: 0.6788 - accuracy: 0.87 - ETA: 2:14 - loss: 0.7010 - accuracy: 0.87 - ETA: 2:14 - loss: 0.6817 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6805 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6928 - accuracy: 0.87 - ETA: 2:10 - loss: 0.6815 - accuracy: 0.87 - ETA: 2:09 - loss: 0.6582 - accuracy: 0.87 - ETA: 2:08 - loss: 0.6467 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6492 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7132 - accuracy: 0.87 - ETA: 2:04 - loss: 0.7048 - accuracy: 0.87 - ETA: 2:03 - loss: 0.6963 - accuracy: 0.87 - ETA: 2:02 - loss: 0.6925 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6945 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6803 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6882 - accuracy: 0.87 - ETA: 1:58 - loss: 0.6867 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6738 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6846 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6803 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6704 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6692 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6799 - accuracy: 0.87 - ETA: 1:51 - loss: 0.6793 - accuracy: 0.87 - ETA: 1:50 - loss: 0.6820 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6761 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6845 - accuracy: 0.87 - ETA: 1:47 - loss: 0.6791 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6810 - accuracy: 0.87 - ETA: 1:45 - loss: 0.6734 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6765 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6792 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6823 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6814 - accuracy: 0.87 - ETA: 1:41 - loss: 0.6814 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6771 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6751 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6723 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6812 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6795 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6822 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6872 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6839 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6771 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6804 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6746 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6781 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6744 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6724 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6737 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6729 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6789 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6746 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6684 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6641 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6619 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6722 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6770 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6738 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6777 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6751 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6761 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6739 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6695 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6705 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6794 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6798 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6778 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6774 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6755 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6736 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6742 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6735 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6725 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6712 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6683 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6772 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6888 - accuracy: 0.87 - ETA: 59s - loss: 0.6876 - accuracy: 0.8767 - ETA: 58s - loss: 0.6908 - accuracy: 0.875 - ETA: 57s - loss: 0.6950 - accuracy: 0.875 - ETA: 56s - loss: 0.6958 - accuracy: 0.875 - ETA: 55s - loss: 0.6965 - accuracy: 0.875 - ETA: 54s - loss: 0.6961 - accuracy: 0.875 - ETA: 53s - loss: 0.6950 - accuracy: 0.874 - ETA: 52s - loss: 0.7028 - accuracy: 0.874 - ETA: 51s - loss: 0.7011 - accuracy: 0.874 - ETA: 50s - loss: 0.7074 - accuracy: 0.873 - ETA: 49s - loss: 0.7130 - accuracy: 0.873 - ETA: 48s - loss: 0.7115 - accuracy: 0.873 - ETA: 47s - loss: 0.7146 - accuracy: 0.872 - ETA: 46s - loss: 0.7143 - accuracy: 0.872 - ETA: 45s - loss: 0.7116 - accuracy: 0.873 - ETA: 44s - loss: 0.7107 - accuracy: 0.873 - ETA: 43s - loss: 0.7155 - accuracy: 0.872 - ETA: 43s - loss: 0.7142 - accuracy: 0.872 - ETA: 42s - loss: 0.7170 - accuracy: 0.872 - ETA: 41s - loss: 0.7166 - accuracy: 0.872 - ETA: 40s - loss: 0.7215 - accuracy: 0.872 - ETA: 39s - loss: 0.7229 - accuracy: 0.872 - ETA: 38s - loss: 0.7229 - accuracy: 0.872 - ETA: 37s - loss: 0.7209 - accuracy: 0.872 - ETA: 36s - loss: 0.7186 - accuracy: 0.872 - ETA: 35s - loss: 0.7154 - accuracy: 0.872 - ETA: 34s - loss: 0.7171 - accuracy: 0.872 - ETA: 33s - loss: 0.7167 - accuracy: 0.872 - ETA: 32s - loss: 0.7185 - accuracy: 0.872 - ETA: 31s - loss: 0.7182 - accuracy: 0.872 - ETA: 30s - loss: 0.7204 - accuracy: 0.872 - ETA: 29s - loss: 0.7185 - accuracy: 0.872 - ETA: 28s - loss: 0.7176 - accuracy: 0.872 - ETA: 27s - loss: 0.7172 - accuracy: 0.872 - ETA: 26s - loss: 0.7172 - accuracy: 0.872 - ETA: 25s - loss: 0.7163 - accuracy: 0.872 - ETA: 24s - loss: 0.7156 - accuracy: 0.872 - ETA: 23s - loss: 0.7186 - accuracy: 0.872 - ETA: 22s - loss: 0.7175 - accuracy: 0.872 - ETA: 21s - loss: 0.7151 - accuracy: 0.872 - ETA: 21s - loss: 0.7138 - accuracy: 0.872 - ETA: 20s - loss: 0.7151 - accuracy: 0.872 - ETA: 19s - loss: 0.7167 - accuracy: 0.872 - ETA: 18s - loss: 0.7148 - accuracy: 0.872 - ETA: 17s - loss: 0.7146 - accuracy: 0.871 - ETA: 16s - loss: 0.7146 - accuracy: 0.871 - ETA: 15s - loss: 0.7138 - accuracy: 0.872 - ETA: 14s - loss: 0.7181 - accuracy: 0.871 - ETA: 13s - loss: 0.7162 - accuracy: 0.872 - ETA: 12s - loss: 0.7148 - accuracy: 0.871 - ETA: 11s - loss: 0.7151 - accuracy: 0.871 - ETA: 10s - loss: 0.7124 - accuracy: 0.872 - ETA: 9s - loss: 0.7154 - accuracy: 0.871 - ETA: 8s - loss: 0.7146 - accuracy: 0.87 - ETA: 7s - loss: 0.7175 - accuracy: 0.87 - ETA: 6s - loss: 0.7159 - accuracy: 0.87 - ETA: 5s - loss: 0.7149 - accuracy: 0.87 - ETA: 4s - loss: 0.7144 - accuracy: 0.87 - ETA: 3s - loss: 0.7145 - accuracy: 0.87 - ETA: 2s - loss: 0.7139 - accuracy: 0.87 - ETA: 1s - loss: 0.7136 - accuracy: 0.87 - ETA: 0s - loss: 0.7148 - accuracy: 0.87 - 156s 8ms/step - loss: 0.7149 - accuracy: 0.8717 - val_loss: 4.2271 - val_accuracy: 0.7708\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:44 - loss: 0.3886 - accuracy: 0.89 - ETA: 2:32 - loss: 0.5083 - accuracy: 0.89 - ETA: 2:26 - loss: 0.6417 - accuracy: 0.88 - ETA: 2:22 - loss: 0.6449 - accuracy: 0.87 - ETA: 2:18 - loss: 0.6095 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6711 - accuracy: 0.87 - ETA: 2:18 - loss: 0.6502 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6671 - accuracy: 0.87 - ETA: 2:16 - loss: 0.6300 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6360 - accuracy: 0.87 - ETA: 2:14 - loss: 0.6558 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6429 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6373 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6448 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6370 - accuracy: 0.87 - ETA: 2:10 - loss: 0.6224 - accuracy: 0.87 - ETA: 2:09 - loss: 0.6642 - accuracy: 0.87 - ETA: 2:08 - loss: 0.6424 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6364 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6311 - accuracy: 0.88 - ETA: 2:04 - loss: 0.6392 - accuracy: 0.87 - ETA: 2:03 - loss: 0.6535 - accuracy: 0.87 - ETA: 2:02 - loss: 0.6812 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6832 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6967 - accuracy: 0.87 - ETA: 1:59 - loss: 0.7011 - accuracy: 0.87 - ETA: 1:58 - loss: 0.7181 - accuracy: 0.87 - ETA: 1:57 - loss: 0.7194 - accuracy: 0.87 - ETA: 1:57 - loss: 0.7096 - accuracy: 0.87 - ETA: 1:56 - loss: 0.7007 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6976 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6927 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6904 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6880 - accuracy: 0.87 - ETA: 1:51 - loss: 0.6909 - accuracy: 0.87 - ETA: 1:50 - loss: 0.6902 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6913 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6863 - accuracy: 0.87 - ETA: 1:47 - loss: 0.6954 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6932 - accuracy: 0.87 - ETA: 1:45 - loss: 0.6957 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6985 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6906 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6924 - accuracy: 0.87 - ETA: 1:41 - loss: 0.6857 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6873 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6843 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6898 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6923 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6882 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6911 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6962 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6903 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6916 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6907 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6894 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6847 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6824 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6843 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6802 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6854 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6829 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6872 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6898 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6948 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6934 - accuracy: 0.87 - ETA: 1:21 - loss: 0.7071 - accuracy: 0.87 - ETA: 1:20 - loss: 0.7063 - accuracy: 0.87 - ETA: 1:19 - loss: 0.7038 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6995 - accuracy: 0.87 - ETA: 1:17 - loss: 0.7031 - accuracy: 0.87 - ETA: 1:16 - loss: 0.7046 - accuracy: 0.87 - ETA: 1:15 - loss: 0.7009 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6981 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6940 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6907 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6888 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6860 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6858 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6872 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6960 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6953 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6942 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6963 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6987 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6992 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6964 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6986 - accuracy: 0.87 - ETA: 59s - loss: 0.6997 - accuracy: 0.8727 - ETA: 58s - loss: 0.6992 - accuracy: 0.872 - ETA: 57s - loss: 0.6990 - accuracy: 0.872 - ETA: 56s - loss: 0.6960 - accuracy: 0.873 - ETA: 55s - loss: 0.6927 - accuracy: 0.873 - ETA: 55s - loss: 0.6896 - accuracy: 0.873 - ETA: 54s - loss: 0.6873 - accuracy: 0.873 - ETA: 53s - loss: 0.6855 - accuracy: 0.874 - ETA: 52s - loss: 0.6851 - accuracy: 0.874 - ETA: 51s - loss: 0.6852 - accuracy: 0.873 - ETA: 50s - loss: 0.6881 - accuracy: 0.873 - ETA: 49s - loss: 0.6886 - accuracy: 0.873 - ETA: 48s - loss: 0.6911 - accuracy: 0.872 - ETA: 47s - loss: 0.6932 - accuracy: 0.872 - ETA: 46s - loss: 0.6938 - accuracy: 0.873 - ETA: 45s - loss: 0.6989 - accuracy: 0.873 - ETA: 44s - loss: 0.6980 - accuracy: 0.872 - ETA: 43s - loss: 0.6957 - accuracy: 0.873 - ETA: 42s - loss: 0.6940 - accuracy: 0.873 - ETA: 41s - loss: 0.6937 - accuracy: 0.873 - ETA: 40s - loss: 0.6911 - accuracy: 0.873 - ETA: 39s - loss: 0.6884 - accuracy: 0.873 - ETA: 38s - loss: 0.6862 - accuracy: 0.873 - ETA: 37s - loss: 0.6877 - accuracy: 0.873 - ETA: 36s - loss: 0.6845 - accuracy: 0.874 - ETA: 35s - loss: 0.6823 - accuracy: 0.874 - ETA: 34s - loss: 0.6803 - accuracy: 0.874 - ETA: 33s - loss: 0.6843 - accuracy: 0.874 - ETA: 32s - loss: 0.6837 - accuracy: 0.874 - ETA: 31s - loss: 0.6818 - accuracy: 0.874 - ETA: 30s - loss: 0.6841 - accuracy: 0.874 - ETA: 29s - loss: 0.6869 - accuracy: 0.874 - ETA: 28s - loss: 0.6872 - accuracy: 0.874 - ETA: 27s - loss: 0.6883 - accuracy: 0.873 - ETA: 26s - loss: 0.6897 - accuracy: 0.873 - ETA: 25s - loss: 0.6883 - accuracy: 0.873 - ETA: 24s - loss: 0.6911 - accuracy: 0.873 - ETA: 24s - loss: 0.6922 - accuracy: 0.873 - ETA: 23s - loss: 0.6903 - accuracy: 0.873 - ETA: 22s - loss: 0.6880 - accuracy: 0.873 - ETA: 21s - loss: 0.6896 - accuracy: 0.873 - ETA: 20s - loss: 0.6893 - accuracy: 0.873 - ETA: 19s - loss: 0.6878 - accuracy: 0.873 - ETA: 18s - loss: 0.6924 - accuracy: 0.873 - ETA: 17s - loss: 0.6946 - accuracy: 0.873 - ETA: 16s - loss: 0.6960 - accuracy: 0.873 - ETA: 15s - loss: 0.6983 - accuracy: 0.873 - ETA: 14s - loss: 0.6968 - accuracy: 0.873 - ETA: 13s - loss: 0.6985 - accuracy: 0.873 - ETA: 12s - loss: 0.6969 - accuracy: 0.873 - ETA: 11s - loss: 0.6971 - accuracy: 0.873 - ETA: 10s - loss: 0.6986 - accuracy: 0.873 - ETA: 9s - loss: 0.6970 - accuracy: 0.873 - ETA: 8s - loss: 0.6948 - accuracy: 0.87 - ETA: 7s - loss: 0.6946 - accuracy: 0.87 - ETA: 6s - loss: 0.6917 - accuracy: 0.87 - ETA: 5s - loss: 0.6889 - accuracy: 0.87 - ETA: 4s - loss: 0.6924 - accuracy: 0.87 - ETA: 3s - loss: 0.6925 - accuracy: 0.87 - ETA: 2s - loss: 0.6948 - accuracy: 0.87 - ETA: 1s - loss: 0.6962 - accuracy: 0.87 - ETA: 0s - loss: 0.6971 - accuracy: 0.87 - 157s 8ms/step - loss: 0.6964 - accuracy: 0.8745 - val_loss: 3.7720 - val_accuracy: 0.7741\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:38 - loss: 0.6087 - accuracy: 0.85 - ETA: 2:31 - loss: 0.7730 - accuracy: 0.82 - ETA: 2:28 - loss: 0.8000 - accuracy: 0.82 - ETA: 2:26 - loss: 0.8451 - accuracy: 0.84 - ETA: 2:23 - loss: 0.8704 - accuracy: 0.83 - ETA: 2:21 - loss: 0.7954 - accuracy: 0.84 - ETA: 2:20 - loss: 0.7898 - accuracy: 0.85 - ETA: 2:19 - loss: 0.7467 - accuracy: 0.85 - ETA: 2:17 - loss: 0.7573 - accuracy: 0.85 - ETA: 2:16 - loss: 0.7555 - accuracy: 0.85 - ETA: 2:14 - loss: 0.7511 - accuracy: 0.85 - ETA: 2:13 - loss: 0.7441 - accuracy: 0.85 - ETA: 2:12 - loss: 0.7272 - accuracy: 0.85 - ETA: 2:11 - loss: 0.7224 - accuracy: 0.85 - ETA: 2:10 - loss: 0.7291 - accuracy: 0.85 - ETA: 2:10 - loss: 0.7094 - accuracy: 0.86 - ETA: 2:09 - loss: 0.7031 - accuracy: 0.86 - ETA: 2:07 - loss: 0.7360 - accuracy: 0.86 - ETA: 2:06 - loss: 0.7228 - accuracy: 0.86 - ETA: 2:05 - loss: 0.7153 - accuracy: 0.86 - ETA: 2:04 - loss: 0.7189 - accuracy: 0.86 - ETA: 2:03 - loss: 0.7010 - accuracy: 0.86 - ETA: 2:02 - loss: 0.7020 - accuracy: 0.86 - ETA: 2:01 - loss: 0.7188 - accuracy: 0.86 - ETA: 2:00 - loss: 0.7142 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7175 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7210 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7123 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7058 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7072 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7054 - accuracy: 0.86 - ETA: 1:53 - loss: 0.7151 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7091 - accuracy: 0.86 - ETA: 1:51 - loss: 0.7116 - accuracy: 0.86 - ETA: 1:50 - loss: 0.7134 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7249 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7252 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7236 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7134 - accuracy: 0.87 - ETA: 1:45 - loss: 0.7018 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6957 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6927 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6979 - accuracy: 0.87 - ETA: 1:41 - loss: 0.7006 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6937 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6838 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6922 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6927 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6891 - accuracy: 0.87 - ETA: 1:36 - loss: 0.7088 - accuracy: 0.87 - ETA: 1:35 - loss: 0.7029 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6996 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6986 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6953 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6900 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6956 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6918 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6900 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6848 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6848 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6836 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6817 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6804 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6809 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6756 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6722 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6694 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6632 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6668 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6691 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6696 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6701 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6682 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6701 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6688 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6735 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6795 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6789 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6769 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6744 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6767 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6865 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6816 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6824 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6798 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6793 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6844 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6855 - accuracy: 0.87 - ETA: 59s - loss: 0.6860 - accuracy: 0.8747 - ETA: 58s - loss: 0.6912 - accuracy: 0.874 - ETA: 57s - loss: 0.6984 - accuracy: 0.873 - ETA: 56s - loss: 0.6960 - accuracy: 0.873 - ETA: 55s - loss: 0.6943 - accuracy: 0.873 - ETA: 54s - loss: 0.6957 - accuracy: 0.873 - ETA: 53s - loss: 0.6947 - accuracy: 0.873 - ETA: 52s - loss: 0.6931 - accuracy: 0.873 - ETA: 51s - loss: 0.6954 - accuracy: 0.873 - ETA: 50s - loss: 0.6930 - accuracy: 0.873 - ETA: 49s - loss: 0.6927 - accuracy: 0.873 - ETA: 48s - loss: 0.6927 - accuracy: 0.873 - ETA: 47s - loss: 0.6937 - accuracy: 0.873 - ETA: 46s - loss: 0.6921 - accuracy: 0.873 - ETA: 45s - loss: 0.6916 - accuracy: 0.873 - ETA: 44s - loss: 0.6913 - accuracy: 0.873 - ETA: 43s - loss: 0.6898 - accuracy: 0.873 - ETA: 42s - loss: 0.6869 - accuracy: 0.873 - ETA: 41s - loss: 0.6882 - accuracy: 0.873 - ETA: 40s - loss: 0.6921 - accuracy: 0.873 - ETA: 40s - loss: 0.6943 - accuracy: 0.873 - ETA: 39s - loss: 0.6905 - accuracy: 0.873 - ETA: 38s - loss: 0.6878 - accuracy: 0.874 - ETA: 37s - loss: 0.6898 - accuracy: 0.873 - ETA: 36s - loss: 0.6867 - accuracy: 0.873 - ETA: 35s - loss: 0.6876 - accuracy: 0.873 - ETA: 34s - loss: 0.6872 - accuracy: 0.873 - ETA: 33s - loss: 0.6891 - accuracy: 0.873 - ETA: 32s - loss: 0.6891 - accuracy: 0.873 - ETA: 31s - loss: 0.6883 - accuracy: 0.873 - ETA: 30s - loss: 0.6860 - accuracy: 0.873 - ETA: 29s - loss: 0.6880 - accuracy: 0.873 - ETA: 28s - loss: 0.6873 - accuracy: 0.873 - ETA: 27s - loss: 0.6859 - accuracy: 0.873 - ETA: 26s - loss: 0.6846 - accuracy: 0.873 - ETA: 25s - loss: 0.6829 - accuracy: 0.873 - ETA: 24s - loss: 0.6810 - accuracy: 0.873 - ETA: 23s - loss: 0.6811 - accuracy: 0.873 - ETA: 22s - loss: 0.6796 - accuracy: 0.874 - ETA: 21s - loss: 0.6799 - accuracy: 0.874 - ETA: 20s - loss: 0.6793 - accuracy: 0.874 - ETA: 19s - loss: 0.6791 - accuracy: 0.874 - ETA: 18s - loss: 0.6779 - accuracy: 0.874 - ETA: 18s - loss: 0.6810 - accuracy: 0.874 - ETA: 17s - loss: 0.6822 - accuracy: 0.873 - ETA: 16s - loss: 0.6853 - accuracy: 0.873 - ETA: 15s - loss: 0.6830 - accuracy: 0.873 - ETA: 14s - loss: 0.6856 - accuracy: 0.873 - ETA: 13s - loss: 0.6871 - accuracy: 0.873 - ETA: 12s - loss: 0.6861 - accuracy: 0.873 - ETA: 11s - loss: 0.6873 - accuracy: 0.873 - ETA: 10s - loss: 0.6884 - accuracy: 0.873 - ETA: 9s - loss: 0.6872 - accuracy: 0.873 - ETA: 8s - loss: 0.6883 - accuracy: 0.87 - ETA: 7s - loss: 0.6894 - accuracy: 0.87 - ETA: 6s - loss: 0.6872 - accuracy: 0.87 - ETA: 5s - loss: 0.6895 - accuracy: 0.87 - ETA: 4s - loss: 0.6905 - accuracy: 0.87 - ETA: 3s - loss: 0.6904 - accuracy: 0.87 - ETA: 2s - loss: 0.6892 - accuracy: 0.87 - ETA: 1s - loss: 0.6887 - accuracy: 0.87 - ETA: 0s - loss: 0.6878 - accuracy: 0.87 - 155s 8ms/step - loss: 0.6952 - accuracy: 0.8734 - val_loss: 3.8112 - val_accuracy: 0.7747\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:36 - loss: 1.4453 - accuracy: 0.81 - ETA: 2:27 - loss: 0.8076 - accuracy: 0.88 - ETA: 2:26 - loss: 0.6886 - accuracy: 0.88 - ETA: 2:26 - loss: 0.8047 - accuracy: 0.87 - ETA: 2:26 - loss: 0.8157 - accuracy: 0.87 - ETA: 2:23 - loss: 0.7959 - accuracy: 0.87 - ETA: 2:20 - loss: 0.8837 - accuracy: 0.86 - ETA: 2:18 - loss: 0.8793 - accuracy: 0.86 - ETA: 2:16 - loss: 0.8791 - accuracy: 0.86 - ETA: 2:15 - loss: 0.8750 - accuracy: 0.86 - ETA: 2:14 - loss: 0.8595 - accuracy: 0.86 - ETA: 2:14 - loss: 0.9468 - accuracy: 0.86 - ETA: 2:13 - loss: 0.9155 - accuracy: 0.86 - ETA: 2:11 - loss: 0.9048 - accuracy: 0.86 - ETA: 2:10 - loss: 0.8702 - accuracy: 0.86 - ETA: 2:09 - loss: 0.8522 - accuracy: 0.86 - ETA: 2:08 - loss: 0.8325 - accuracy: 0.86 - ETA: 2:07 - loss: 0.8417 - accuracy: 0.87 - ETA: 2:05 - loss: 0.8518 - accuracy: 0.86 - ETA: 2:04 - loss: 0.8505 - accuracy: 0.86 - ETA: 2:04 - loss: 0.8361 - accuracy: 0.86 - ETA: 2:03 - loss: 0.8161 - accuracy: 0.86 - ETA: 2:02 - loss: 0.8175 - accuracy: 0.86 - ETA: 2:01 - loss: 0.8037 - accuracy: 0.87 - ETA: 2:00 - loss: 0.8119 - accuracy: 0.87 - ETA: 1:59 - loss: 0.8073 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7954 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7904 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7909 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7833 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7745 - accuracy: 0.86 - ETA: 1:53 - loss: 0.7736 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7825 - accuracy: 0.86 - ETA: 1:51 - loss: 0.7965 - accuracy: 0.86 - ETA: 1:50 - loss: 0.8047 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7992 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7921 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7892 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7860 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7762 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7707 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7729 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7700 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7611 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7598 - accuracy: 0.87 - ETA: 1:40 - loss: 0.7512 - accuracy: 0.87 - ETA: 1:39 - loss: 0.7531 - accuracy: 0.87 - ETA: 1:38 - loss: 0.7651 - accuracy: 0.87 - ETA: 1:38 - loss: 0.7643 - accuracy: 0.87 - ETA: 1:37 - loss: 0.7656 - accuracy: 0.87 - ETA: 1:36 - loss: 0.7592 - accuracy: 0.87 - ETA: 1:35 - loss: 0.7588 - accuracy: 0.86 - ETA: 1:34 - loss: 0.7570 - accuracy: 0.87 - ETA: 1:33 - loss: 0.7534 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7559 - accuracy: 0.87 - ETA: 1:31 - loss: 0.7514 - accuracy: 0.87 - ETA: 1:30 - loss: 0.7533 - accuracy: 0.87 - ETA: 1:29 - loss: 0.7555 - accuracy: 0.87 - ETA: 1:28 - loss: 0.7501 - accuracy: 0.87 - ETA: 1:27 - loss: 0.7540 - accuracy: 0.87 - ETA: 1:26 - loss: 0.7530 - accuracy: 0.87 - ETA: 1:25 - loss: 0.7510 - accuracy: 0.87 - ETA: 1:24 - loss: 0.7485 - accuracy: 0.87 - ETA: 1:23 - loss: 0.7440 - accuracy: 0.87 - ETA: 1:22 - loss: 0.7419 - accuracy: 0.87 - ETA: 1:21 - loss: 0.7376 - accuracy: 0.87 - ETA: 1:20 - loss: 0.7350 - accuracy: 0.87 - ETA: 1:19 - loss: 0.7324 - accuracy: 0.87 - ETA: 1:18 - loss: 0.7362 - accuracy: 0.87 - ETA: 1:17 - loss: 0.7327 - accuracy: 0.87 - ETA: 1:16 - loss: 0.7309 - accuracy: 0.87 - ETA: 1:15 - loss: 0.7353 - accuracy: 0.87 - ETA: 1:14 - loss: 0.7339 - accuracy: 0.87 - ETA: 1:13 - loss: 0.7304 - accuracy: 0.87 - ETA: 1:12 - loss: 0.7286 - accuracy: 0.87 - ETA: 1:11 - loss: 0.7279 - accuracy: 0.87 - ETA: 1:11 - loss: 0.7271 - accuracy: 0.87 - ETA: 1:10 - loss: 0.7285 - accuracy: 0.87 - ETA: 1:09 - loss: 0.7236 - accuracy: 0.87 - ETA: 1:08 - loss: 0.7221 - accuracy: 0.87 - ETA: 1:07 - loss: 0.7189 - accuracy: 0.87 - ETA: 1:06 - loss: 0.7165 - accuracy: 0.87 - ETA: 1:05 - loss: 0.7162 - accuracy: 0.87 - ETA: 1:04 - loss: 0.7183 - accuracy: 0.87 - ETA: 1:03 - loss: 0.7186 - accuracy: 0.87 - ETA: 1:02 - loss: 0.7178 - accuracy: 0.87 - ETA: 1:01 - loss: 0.7204 - accuracy: 0.87 - ETA: 1:00 - loss: 0.7235 - accuracy: 0.87 - ETA: 59s - loss: 0.7192 - accuracy: 0.8737 - ETA: 58s - loss: 0.7151 - accuracy: 0.874 - ETA: 57s - loss: 0.7161 - accuracy: 0.873 - ETA: 56s - loss: 0.7158 - accuracy: 0.873 - ETA: 55s - loss: 0.7174 - accuracy: 0.873 - ETA: 54s - loss: 0.7206 - accuracy: 0.873 - ETA: 53s - loss: 0.7299 - accuracy: 0.872 - ETA: 52s - loss: 0.7274 - accuracy: 0.873 - ETA: 51s - loss: 0.7256 - accuracy: 0.873 - ETA: 50s - loss: 0.7236 - accuracy: 0.873 - ETA: 49s - loss: 0.7279 - accuracy: 0.872 - ETA: 48s - loss: 0.7236 - accuracy: 0.873 - ETA: 47s - loss: 0.7264 - accuracy: 0.872 - ETA: 46s - loss: 0.7261 - accuracy: 0.872 - ETA: 45s - loss: 0.7265 - accuracy: 0.872 - ETA: 44s - loss: 0.7270 - accuracy: 0.872 - ETA: 44s - loss: 0.7246 - accuracy: 0.872 - ETA: 43s - loss: 0.7225 - accuracy: 0.872 - ETA: 42s - loss: 0.7214 - accuracy: 0.872 - ETA: 41s - loss: 0.7199 - accuracy: 0.872 - ETA: 40s - loss: 0.7174 - accuracy: 0.872 - ETA: 39s - loss: 0.7160 - accuracy: 0.872 - ETA: 38s - loss: 0.7177 - accuracy: 0.872 - ETA: 37s - loss: 0.7175 - accuracy: 0.872 - ETA: 36s - loss: 0.7163 - accuracy: 0.872 - ETA: 35s - loss: 0.7152 - accuracy: 0.871 - ETA: 34s - loss: 0.7151 - accuracy: 0.872 - ETA: 33s - loss: 0.7201 - accuracy: 0.872 - ETA: 32s - loss: 0.7210 - accuracy: 0.871 - ETA: 31s - loss: 0.7220 - accuracy: 0.871 - ETA: 30s - loss: 0.7222 - accuracy: 0.871 - ETA: 29s - loss: 0.7209 - accuracy: 0.871 - ETA: 28s - loss: 0.7206 - accuracy: 0.871 - ETA: 27s - loss: 0.7237 - accuracy: 0.871 - ETA: 26s - loss: 0.7227 - accuracy: 0.871 - ETA: 25s - loss: 0.7235 - accuracy: 0.871 - ETA: 24s - loss: 0.7217 - accuracy: 0.871 - ETA: 23s - loss: 0.7219 - accuracy: 0.871 - ETA: 22s - loss: 0.7232 - accuracy: 0.871 - ETA: 21s - loss: 0.7222 - accuracy: 0.871 - ETA: 20s - loss: 0.7243 - accuracy: 0.871 - ETA: 20s - loss: 0.7241 - accuracy: 0.871 - ETA: 19s - loss: 0.7265 - accuracy: 0.871 - ETA: 18s - loss: 0.7248 - accuracy: 0.871 - ETA: 17s - loss: 0.7253 - accuracy: 0.871 - ETA: 16s - loss: 0.7233 - accuracy: 0.871 - ETA: 15s - loss: 0.7230 - accuracy: 0.871 - ETA: 14s - loss: 0.7221 - accuracy: 0.872 - ETA: 13s - loss: 0.7201 - accuracy: 0.872 - ETA: 12s - loss: 0.7200 - accuracy: 0.871 - ETA: 11s - loss: 0.7197 - accuracy: 0.871 - ETA: 10s - loss: 0.7193 - accuracy: 0.871 - ETA: 9s - loss: 0.7203 - accuracy: 0.871 - ETA: 8s - loss: 0.7180 - accuracy: 0.87 - ETA: 7s - loss: 0.7196 - accuracy: 0.87 - ETA: 6s - loss: 0.7188 - accuracy: 0.87 - ETA: 5s - loss: 0.7177 - accuracy: 0.87 - ETA: 4s - loss: 0.7176 - accuracy: 0.87 - ETA: 3s - loss: 0.7188 - accuracy: 0.87 - ETA: 2s - loss: 0.7191 - accuracy: 0.87 - ETA: 1s - loss: 0.7188 - accuracy: 0.87 - ETA: 0s - loss: 0.7198 - accuracy: 0.87 - 156s 8ms/step - loss: 0.7193 - accuracy: 0.8712 - val_loss: 4.1216 - val_accuracy: 0.7722\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 0.8969 - accuracy: 0.83 - ETA: 2:23 - loss: 0.7327 - accuracy: 0.84 - ETA: 2:26 - loss: 0.6890 - accuracy: 0.84 - ETA: 2:24 - loss: 0.6570 - accuracy: 0.85 - ETA: 2:22 - loss: 0.6509 - accuracy: 0.85 - ETA: 2:20 - loss: 0.6752 - accuracy: 0.85 - ETA: 2:19 - loss: 0.6291 - accuracy: 0.86 - ETA: 2:19 - loss: 0.6614 - accuracy: 0.86 - ETA: 2:19 - loss: 0.6473 - accuracy: 0.86 - ETA: 2:18 - loss: 0.6582 - accuracy: 0.86 - ETA: 2:16 - loss: 0.6465 - accuracy: 0.86 - ETA: 2:14 - loss: 0.6479 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6343 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6386 - accuracy: 0.87 - ETA: 2:10 - loss: 0.6393 - accuracy: 0.86 - ETA: 2:09 - loss: 0.6315 - accuracy: 0.86 - ETA: 2:08 - loss: 0.6572 - accuracy: 0.86 - ETA: 2:07 - loss: 0.6506 - accuracy: 0.86 - ETA: 2:06 - loss: 0.6821 - accuracy: 0.86 - ETA: 2:06 - loss: 0.6697 - accuracy: 0.87 - ETA: 2:05 - loss: 0.6730 - accuracy: 0.86 - ETA: 2:04 - loss: 0.6686 - accuracy: 0.86 - ETA: 2:03 - loss: 0.6553 - accuracy: 0.87 - ETA: 2:02 - loss: 0.6530 - accuracy: 0.86 - ETA: 2:02 - loss: 0.6409 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6485 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6577 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6567 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6507 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6541 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6630 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6654 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6921 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6951 - accuracy: 0.87 - ETA: 1:51 - loss: 0.7093 - accuracy: 0.87 - ETA: 1:50 - loss: 0.7075 - accuracy: 0.87 - ETA: 1:49 - loss: 0.7147 - accuracy: 0.87 - ETA: 1:48 - loss: 0.7153 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7135 - accuracy: 0.87 - ETA: 1:46 - loss: 0.7177 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7148 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7163 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7101 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7076 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7028 - accuracy: 0.87 - ETA: 1:40 - loss: 0.7021 - accuracy: 0.87 - ETA: 1:40 - loss: 0.7026 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6983 - accuracy: 0.87 - ETA: 1:37 - loss: 0.7018 - accuracy: 0.87 - ETA: 1:36 - loss: 0.7072 - accuracy: 0.87 - ETA: 1:35 - loss: 0.7028 - accuracy: 0.87 - ETA: 1:34 - loss: 0.7019 - accuracy: 0.87 - ETA: 1:33 - loss: 0.7006 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7015 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6976 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6975 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6923 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6906 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6838 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6821 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6816 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6872 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6846 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6844 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6853 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6826 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6844 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6889 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6868 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6866 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6852 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6876 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6851 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6851 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6866 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6873 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6887 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6904 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6927 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6903 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6871 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6911 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6904 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6885 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6874 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6936 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6906 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6946 - accuracy: 0.87 - ETA: 59s - loss: 0.6938 - accuracy: 0.8721 - ETA: 58s - loss: 0.6920 - accuracy: 0.872 - ETA: 57s - loss: 0.6916 - accuracy: 0.872 - ETA: 56s - loss: 0.6874 - accuracy: 0.873 - ETA: 55s - loss: 0.6834 - accuracy: 0.873 - ETA: 54s - loss: 0.6844 - accuracy: 0.873 - ETA: 53s - loss: 0.6835 - accuracy: 0.873 - ETA: 52s - loss: 0.6806 - accuracy: 0.873 - ETA: 51s - loss: 0.6773 - accuracy: 0.874 - ETA: 50s - loss: 0.6871 - accuracy: 0.874 - ETA: 49s - loss: 0.6903 - accuracy: 0.874 - ETA: 48s - loss: 0.6917 - accuracy: 0.873 - ETA: 47s - loss: 0.6892 - accuracy: 0.874 - ETA: 47s - loss: 0.6864 - accuracy: 0.874 - ETA: 46s - loss: 0.6849 - accuracy: 0.874 - ETA: 45s - loss: 0.6829 - accuracy: 0.874 - ETA: 44s - loss: 0.6815 - accuracy: 0.874 - ETA: 43s - loss: 0.6879 - accuracy: 0.874 - ETA: 42s - loss: 0.6869 - accuracy: 0.874 - ETA: 41s - loss: 0.6888 - accuracy: 0.874 - ETA: 40s - loss: 0.6865 - accuracy: 0.874 - ETA: 39s - loss: 0.6896 - accuracy: 0.874 - ETA: 38s - loss: 0.6904 - accuracy: 0.874 - ETA: 37s - loss: 0.6939 - accuracy: 0.873 - ETA: 36s - loss: 0.6930 - accuracy: 0.873 - ETA: 35s - loss: 0.6921 - accuracy: 0.872 - ETA: 34s - loss: 0.6893 - accuracy: 0.873 - ETA: 33s - loss: 0.6886 - accuracy: 0.873 - ETA: 32s - loss: 0.6906 - accuracy: 0.873 - ETA: 31s - loss: 0.6929 - accuracy: 0.873 - ETA: 30s - loss: 0.6965 - accuracy: 0.873 - ETA: 29s - loss: 0.6947 - accuracy: 0.873 - ETA: 28s - loss: 0.6947 - accuracy: 0.873 - ETA: 27s - loss: 0.6924 - accuracy: 0.874 - ETA: 26s - loss: 0.6927 - accuracy: 0.874 - ETA: 25s - loss: 0.6972 - accuracy: 0.873 - ETA: 24s - loss: 0.6950 - accuracy: 0.873 - ETA: 23s - loss: 0.6939 - accuracy: 0.873 - ETA: 22s - loss: 0.6974 - accuracy: 0.873 - ETA: 21s - loss: 0.6953 - accuracy: 0.873 - ETA: 21s - loss: 0.6959 - accuracy: 0.873 - ETA: 20s - loss: 0.6950 - accuracy: 0.873 - ETA: 19s - loss: 0.6952 - accuracy: 0.873 - ETA: 18s - loss: 0.6942 - accuracy: 0.873 - ETA: 17s - loss: 0.6984 - accuracy: 0.872 - ETA: 16s - loss: 0.6964 - accuracy: 0.873 - ETA: 15s - loss: 0.6936 - accuracy: 0.873 - ETA: 14s - loss: 0.6921 - accuracy: 0.873 - ETA: 13s - loss: 0.6902 - accuracy: 0.873 - ETA: 12s - loss: 0.6893 - accuracy: 0.873 - ETA: 11s - loss: 0.6874 - accuracy: 0.873 - ETA: 10s - loss: 0.6852 - accuracy: 0.874 - ETA: 9s - loss: 0.6855 - accuracy: 0.874 - ETA: 8s - loss: 0.6848 - accuracy: 0.87 - ETA: 7s - loss: 0.6856 - accuracy: 0.87 - ETA: 6s - loss: 0.6852 - accuracy: 0.87 - ETA: 5s - loss: 0.6839 - accuracy: 0.87 - ETA: 4s - loss: 0.6843 - accuracy: 0.87 - ETA: 3s - loss: 0.6842 - accuracy: 0.87 - ETA: 2s - loss: 0.6860 - accuracy: 0.87 - ETA: 1s - loss: 0.6871 - accuracy: 0.87 - ETA: 0s - loss: 0.6882 - accuracy: 0.87 - 156s 8ms/step - loss: 0.6873 - accuracy: 0.8742 - val_loss: 3.9366 - val_accuracy: 0.7726\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 1.0121 - accuracy: 0.84 - ETA: 2:32 - loss: 0.8259 - accuracy: 0.85 - ETA: 2:27 - loss: 0.9661 - accuracy: 0.84 - ETA: 2:23 - loss: 0.8491 - accuracy: 0.85 - ETA: 2:21 - loss: 0.7793 - accuracy: 0.86 - ETA: 2:20 - loss: 0.7318 - accuracy: 0.86 - ETA: 2:18 - loss: 0.7109 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7054 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7375 - accuracy: 0.86 - ETA: 2:15 - loss: 0.7107 - accuracy: 0.86 - ETA: 2:13 - loss: 0.7444 - accuracy: 0.86 - ETA: 2:13 - loss: 0.7247 - accuracy: 0.86 - ETA: 2:13 - loss: 0.7014 - accuracy: 0.86 - ETA: 2:12 - loss: 0.7103 - accuracy: 0.86 - ETA: 2:11 - loss: 0.6973 - accuracy: 0.86 - ETA: 2:10 - loss: 0.7033 - accuracy: 0.86 - ETA: 2:09 - loss: 0.6841 - accuracy: 0.86 - ETA: 2:08 - loss: 0.7036 - accuracy: 0.86 - ETA: 2:07 - loss: 0.7100 - accuracy: 0.86 - ETA: 2:05 - loss: 0.7083 - accuracy: 0.86 - ETA: 2:05 - loss: 0.6975 - accuracy: 0.86 - ETA: 2:03 - loss: 0.7054 - accuracy: 0.86 - ETA: 2:03 - loss: 0.6919 - accuracy: 0.86 - ETA: 2:01 - loss: 0.6863 - accuracy: 0.86 - ETA: 2:00 - loss: 0.6943 - accuracy: 0.86 - ETA: 1:59 - loss: 0.6843 - accuracy: 0.86 - ETA: 1:58 - loss: 0.6815 - accuracy: 0.86 - ETA: 1:58 - loss: 0.6725 - accuracy: 0.86 - ETA: 1:57 - loss: 0.6758 - accuracy: 0.86 - ETA: 1:56 - loss: 0.6844 - accuracy: 0.86 - ETA: 1:55 - loss: 0.6860 - accuracy: 0.86 - ETA: 1:54 - loss: 0.6849 - accuracy: 0.86 - ETA: 1:53 - loss: 0.6799 - accuracy: 0.86 - ETA: 1:52 - loss: 0.6905 - accuracy: 0.86 - ETA: 1:51 - loss: 0.6884 - accuracy: 0.86 - ETA: 1:50 - loss: 0.6828 - accuracy: 0.86 - ETA: 1:49 - loss: 0.6741 - accuracy: 0.86 - ETA: 1:48 - loss: 0.6795 - accuracy: 0.86 - ETA: 1:47 - loss: 0.6743 - accuracy: 0.86 - ETA: 1:45 - loss: 0.6712 - accuracy: 0.87 - ETA: 1:45 - loss: 0.6720 - accuracy: 0.86 - ETA: 1:43 - loss: 0.6737 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6787 - accuracy: 0.87 - ETA: 1:41 - loss: 0.6759 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6720 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6754 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6829 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6809 - accuracy: 0.86 - ETA: 1:37 - loss: 0.6735 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6680 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6675 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6647 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6586 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6600 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6539 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6588 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6613 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6585 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6568 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6563 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6538 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6636 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6601 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6599 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6619 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6621 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6594 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6549 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6569 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6558 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6508 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6477 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6516 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6596 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6575 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6573 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6585 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6584 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6571 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6585 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6603 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6584 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6610 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6603 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6620 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6623 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6645 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6611 - accuracy: 0.87 - ETA: 59s - loss: 0.6619 - accuracy: 0.8751 - ETA: 58s - loss: 0.6594 - accuracy: 0.875 - ETA: 57s - loss: 0.6577 - accuracy: 0.875 - ETA: 56s - loss: 0.6565 - accuracy: 0.875 - ETA: 55s - loss: 0.6528 - accuracy: 0.876 - ETA: 54s - loss: 0.6542 - accuracy: 0.876 - ETA: 53s - loss: 0.6559 - accuracy: 0.876 - ETA: 52s - loss: 0.6592 - accuracy: 0.876 - ETA: 51s - loss: 0.6588 - accuracy: 0.876 - ETA: 50s - loss: 0.6602 - accuracy: 0.876 - ETA: 49s - loss: 0.6643 - accuracy: 0.875 - ETA: 48s - loss: 0.6659 - accuracy: 0.875 - ETA: 47s - loss: 0.6670 - accuracy: 0.876 - ETA: 46s - loss: 0.6646 - accuracy: 0.876 - ETA: 45s - loss: 0.6689 - accuracy: 0.876 - ETA: 44s - loss: 0.6673 - accuracy: 0.876 - ETA: 43s - loss: 0.6700 - accuracy: 0.876 - ETA: 42s - loss: 0.6691 - accuracy: 0.876 - ETA: 41s - loss: 0.6705 - accuracy: 0.876 - ETA: 41s - loss: 0.6711 - accuracy: 0.876 - ETA: 40s - loss: 0.6708 - accuracy: 0.875 - ETA: 39s - loss: 0.6756 - accuracy: 0.875 - ETA: 38s - loss: 0.6753 - accuracy: 0.875 - ETA: 37s - loss: 0.6777 - accuracy: 0.874 - ETA: 36s - loss: 0.6798 - accuracy: 0.874 - ETA: 35s - loss: 0.6827 - accuracy: 0.874 - ETA: 34s - loss: 0.6839 - accuracy: 0.875 - ETA: 33s - loss: 0.6831 - accuracy: 0.875 - ETA: 32s - loss: 0.6827 - accuracy: 0.874 - ETA: 31s - loss: 0.6796 - accuracy: 0.875 - ETA: 30s - loss: 0.6807 - accuracy: 0.875 - ETA: 29s - loss: 0.6966 - accuracy: 0.874 - ETA: 28s - loss: 0.6955 - accuracy: 0.874 - ETA: 27s - loss: 0.6936 - accuracy: 0.874 - ETA: 26s - loss: 0.6932 - accuracy: 0.874 - ETA: 25s - loss: 0.6963 - accuracy: 0.874 - ETA: 24s - loss: 0.6957 - accuracy: 0.874 - ETA: 23s - loss: 0.6966 - accuracy: 0.874 - ETA: 22s - loss: 0.6984 - accuracy: 0.874 - ETA: 21s - loss: 0.6992 - accuracy: 0.874 - ETA: 20s - loss: 0.7006 - accuracy: 0.873 - ETA: 19s - loss: 0.7035 - accuracy: 0.873 - ETA: 19s - loss: 0.7055 - accuracy: 0.873 - ETA: 18s - loss: 0.7093 - accuracy: 0.872 - ETA: 17s - loss: 0.7079 - accuracy: 0.872 - ETA: 16s - loss: 0.7110 - accuracy: 0.873 - ETA: 15s - loss: 0.7084 - accuracy: 0.873 - ETA: 14s - loss: 0.7064 - accuracy: 0.873 - ETA: 13s - loss: 0.7065 - accuracy: 0.873 - ETA: 12s - loss: 0.7074 - accuracy: 0.873 - ETA: 11s - loss: 0.7075 - accuracy: 0.872 - ETA: 10s - loss: 0.7096 - accuracy: 0.872 - ETA: 9s - loss: 0.7086 - accuracy: 0.873 - ETA: 8s - loss: 0.7087 - accuracy: 0.87 - ETA: 7s - loss: 0.7105 - accuracy: 0.87 - ETA: 6s - loss: 0.7075 - accuracy: 0.87 - ETA: 5s - loss: 0.7083 - accuracy: 0.87 - ETA: 4s - loss: 0.7121 - accuracy: 0.87 - ETA: 3s - loss: 0.7119 - accuracy: 0.87 - ETA: 2s - loss: 0.7110 - accuracy: 0.87 - ETA: 1s - loss: 0.7093 - accuracy: 0.87 - ETA: 0s - loss: 0.7112 - accuracy: 0.87 - 156s 8ms/step - loss: 0.7125 - accuracy: 0.8730 - val_loss: 3.9805 - val_accuracy: 0.7716\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:47 - loss: 0.8182 - accuracy: 0.87 - ETA: 2:34 - loss: 0.8828 - accuracy: 0.89 - ETA: 2:27 - loss: 0.7375 - accuracy: 0.88 - ETA: 2:23 - loss: 0.6818 - accuracy: 0.88 - ETA: 2:20 - loss: 0.6334 - accuracy: 0.88 - ETA: 2:20 - loss: 0.5985 - accuracy: 0.88 - ETA: 2:18 - loss: 0.5409 - accuracy: 0.89 - ETA: 2:17 - loss: 0.5515 - accuracy: 0.89 - ETA: 2:15 - loss: 0.5781 - accuracy: 0.89 - ETA: 2:14 - loss: 0.6086 - accuracy: 0.89 - ETA: 2:13 - loss: 0.6051 - accuracy: 0.89 - ETA: 2:13 - loss: 0.6182 - accuracy: 0.89 - ETA: 2:12 - loss: 0.6218 - accuracy: 0.89 - ETA: 2:10 - loss: 0.6243 - accuracy: 0.89 - ETA: 2:09 - loss: 0.6610 - accuracy: 0.89 - ETA: 2:08 - loss: 0.6491 - accuracy: 0.89 - ETA: 2:08 - loss: 0.6704 - accuracy: 0.88 - ETA: 2:08 - loss: 0.6865 - accuracy: 0.88 - ETA: 2:07 - loss: 0.6975 - accuracy: 0.88 - ETA: 2:06 - loss: 0.6924 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6895 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6785 - accuracy: 0.88 - ETA: 2:02 - loss: 0.6710 - accuracy: 0.88 - ETA: 2:01 - loss: 0.6738 - accuracy: 0.88 - ETA: 2:00 - loss: 0.6753 - accuracy: 0.88 - ETA: 1:59 - loss: 0.6677 - accuracy: 0.88 - ETA: 1:58 - loss: 0.6594 - accuracy: 0.88 - ETA: 1:57 - loss: 0.6709 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6677 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6565 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6497 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6521 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6547 - accuracy: 0.87 - ETA: 1:51 - loss: 0.6784 - accuracy: 0.87 - ETA: 1:50 - loss: 0.6732 - accuracy: 0.87 - ETA: 1:50 - loss: 0.6765 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6773 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6785 - accuracy: 0.87 - ETA: 1:47 - loss: 0.6756 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6740 - accuracy: 0.87 - ETA: 1:45 - loss: 0.6716 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6725 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6691 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6831 - accuracy: 0.87 - ETA: 1:41 - loss: 0.6822 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6800 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6796 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6860 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6815 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6807 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6762 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6723 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6714 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6640 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6612 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6671 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6606 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6563 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6541 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6519 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6485 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6499 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6501 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6478 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6474 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6446 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6438 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6400 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6397 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6395 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6359 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6325 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6319 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6323 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6304 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6326 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6339 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6324 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6371 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6440 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6454 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6476 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6461 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6447 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6448 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6418 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6439 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6449 - accuracy: 0.87 - ETA: 59s - loss: 0.6435 - accuracy: 0.8786 - ETA: 58s - loss: 0.6406 - accuracy: 0.879 - ETA: 57s - loss: 0.6394 - accuracy: 0.879 - ETA: 56s - loss: 0.6372 - accuracy: 0.879 - ETA: 55s - loss: 0.6342 - accuracy: 0.880 - ETA: 54s - loss: 0.6350 - accuracy: 0.879 - ETA: 53s - loss: 0.6358 - accuracy: 0.879 - ETA: 52s - loss: 0.6355 - accuracy: 0.879 - ETA: 51s - loss: 0.6377 - accuracy: 0.879 - ETA: 50s - loss: 0.6375 - accuracy: 0.879 - ETA: 49s - loss: 0.6372 - accuracy: 0.879 - ETA: 48s - loss: 0.6420 - accuracy: 0.879 - ETA: 47s - loss: 0.6408 - accuracy: 0.879 - ETA: 46s - loss: 0.6430 - accuracy: 0.879 - ETA: 45s - loss: 0.6429 - accuracy: 0.879 - ETA: 44s - loss: 0.6419 - accuracy: 0.879 - ETA: 44s - loss: 0.6395 - accuracy: 0.879 - ETA: 43s - loss: 0.6389 - accuracy: 0.879 - ETA: 42s - loss: 0.6426 - accuracy: 0.878 - ETA: 41s - loss: 0.6438 - accuracy: 0.878 - ETA: 40s - loss: 0.6465 - accuracy: 0.877 - ETA: 39s - loss: 0.6464 - accuracy: 0.877 - ETA: 38s - loss: 0.6486 - accuracy: 0.877 - ETA: 37s - loss: 0.6491 - accuracy: 0.877 - ETA: 36s - loss: 0.6527 - accuracy: 0.876 - ETA: 35s - loss: 0.6503 - accuracy: 0.876 - ETA: 34s - loss: 0.6495 - accuracy: 0.876 - ETA: 33s - loss: 0.6502 - accuracy: 0.877 - ETA: 32s - loss: 0.6490 - accuracy: 0.877 - ETA: 31s - loss: 0.6491 - accuracy: 0.877 - ETA: 30s - loss: 0.6493 - accuracy: 0.877 - ETA: 29s - loss: 0.6498 - accuracy: 0.877 - ETA: 28s - loss: 0.6488 - accuracy: 0.877 - ETA: 27s - loss: 0.6484 - accuracy: 0.877 - ETA: 26s - loss: 0.6482 - accuracy: 0.877 - ETA: 25s - loss: 0.6471 - accuracy: 0.877 - ETA: 24s - loss: 0.6501 - accuracy: 0.877 - ETA: 23s - loss: 0.6515 - accuracy: 0.877 - ETA: 22s - loss: 0.6516 - accuracy: 0.877 - ETA: 22s - loss: 0.6489 - accuracy: 0.877 - ETA: 21s - loss: 0.6470 - accuracy: 0.877 - ETA: 20s - loss: 0.6461 - accuracy: 0.877 - ETA: 19s - loss: 0.6458 - accuracy: 0.877 - ETA: 18s - loss: 0.6472 - accuracy: 0.877 - ETA: 17s - loss: 0.6505 - accuracy: 0.876 - ETA: 16s - loss: 0.6497 - accuracy: 0.876 - ETA: 15s - loss: 0.6493 - accuracy: 0.876 - ETA: 14s - loss: 0.6501 - accuracy: 0.876 - ETA: 13s - loss: 0.6478 - accuracy: 0.877 - ETA: 12s - loss: 0.6496 - accuracy: 0.877 - ETA: 11s - loss: 0.6522 - accuracy: 0.876 - ETA: 10s - loss: 0.6509 - accuracy: 0.876 - ETA: 9s - loss: 0.6513 - accuracy: 0.876 - ETA: 8s - loss: 0.6495 - accuracy: 0.87 - ETA: 7s - loss: 0.6476 - accuracy: 0.87 - ETA: 6s - loss: 0.6511 - accuracy: 0.87 - ETA: 5s - loss: 0.6524 - accuracy: 0.87 - ETA: 4s - loss: 0.6510 - accuracy: 0.87 - ETA: 3s - loss: 0.6502 - accuracy: 0.87 - ETA: 2s - loss: 0.6496 - accuracy: 0.87 - ETA: 1s - loss: 0.6510 - accuracy: 0.87 - ETA: 0s - loss: 0.6498 - accuracy: 0.87 - 156s 8ms/step - loss: 0.6493 - accuracy: 0.8772 - val_loss: 4.1142 - val_accuracy: 0.7764\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:25 - loss: 0.7158 - accuracy: 0.88 - ETA: 2:21 - loss: 0.6380 - accuracy: 0.87 - ETA: 2:20 - loss: 0.7329 - accuracy: 0.87 - ETA: 2:21 - loss: 0.7673 - accuracy: 0.87 - ETA: 2:22 - loss: 0.7389 - accuracy: 0.87 - ETA: 2:19 - loss: 0.7195 - accuracy: 0.87 - ETA: 2:18 - loss: 0.7326 - accuracy: 0.86 - ETA: 2:17 - loss: 0.7237 - accuracy: 0.87 - ETA: 2:14 - loss: 0.7206 - accuracy: 0.87 - ETA: 2:13 - loss: 0.7373 - accuracy: 0.87 - ETA: 2:14 - loss: 0.7350 - accuracy: 0.86 - ETA: 2:13 - loss: 0.7336 - accuracy: 0.87 - ETA: 2:12 - loss: 0.7108 - accuracy: 0.87 - ETA: 2:11 - loss: 0.7366 - accuracy: 0.87 - ETA: 2:10 - loss: 0.7101 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7179 - accuracy: 0.87 - ETA: 2:08 - loss: 0.7397 - accuracy: 0.87 - ETA: 2:07 - loss: 0.7185 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7282 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7149 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7192 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7182 - accuracy: 0.87 - ETA: 2:04 - loss: 0.7237 - accuracy: 0.87 - ETA: 2:03 - loss: 0.7137 - accuracy: 0.87 - ETA: 2:03 - loss: 0.7064 - accuracy: 0.87 - ETA: 2:02 - loss: 0.7139 - accuracy: 0.87 - ETA: 2:01 - loss: 0.7073 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6941 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6859 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6827 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6794 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6718 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6654 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6788 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6729 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6893 - accuracy: 0.87 - ETA: 1:51 - loss: 0.6995 - accuracy: 0.87 - ETA: 1:50 - loss: 0.7075 - accuracy: 0.87 - ETA: 1:49 - loss: 0.7237 - accuracy: 0.87 - ETA: 1:48 - loss: 0.7333 - accuracy: 0.87 - ETA: 1:47 - loss: 0.7249 - accuracy: 0.87 - ETA: 1:46 - loss: 0.7287 - accuracy: 0.87 - ETA: 1:45 - loss: 0.7340 - accuracy: 0.87 - ETA: 1:44 - loss: 0.7319 - accuracy: 0.87 - ETA: 1:43 - loss: 0.7313 - accuracy: 0.87 - ETA: 1:42 - loss: 0.7289 - accuracy: 0.87 - ETA: 1:41 - loss: 0.7236 - accuracy: 0.87 - ETA: 1:40 - loss: 0.7286 - accuracy: 0.87 - ETA: 1:39 - loss: 0.7353 - accuracy: 0.87 - ETA: 1:38 - loss: 0.7301 - accuracy: 0.87 - ETA: 1:37 - loss: 0.7293 - accuracy: 0.87 - ETA: 1:36 - loss: 0.7284 - accuracy: 0.87 - ETA: 1:35 - loss: 0.7235 - accuracy: 0.87 - ETA: 1:34 - loss: 0.7184 - accuracy: 0.87 - ETA: 1:33 - loss: 0.7201 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7170 - accuracy: 0.87 - ETA: 1:31 - loss: 0.7139 - accuracy: 0.87 - ETA: 1:30 - loss: 0.7122 - accuracy: 0.87 - ETA: 1:29 - loss: 0.7088 - accuracy: 0.87 - ETA: 1:28 - loss: 0.7074 - accuracy: 0.87 - ETA: 1:27 - loss: 0.7063 - accuracy: 0.87 - ETA: 1:26 - loss: 0.7015 - accuracy: 0.87 - ETA: 1:25 - loss: 0.7013 - accuracy: 0.87 - ETA: 1:24 - loss: 0.7036 - accuracy: 0.87 - ETA: 1:23 - loss: 0.7047 - accuracy: 0.87 - ETA: 1:22 - loss: 0.7093 - accuracy: 0.87 - ETA: 1:21 - loss: 0.7044 - accuracy: 0.87 - ETA: 1:20 - loss: 0.7067 - accuracy: 0.87 - ETA: 1:19 - loss: 0.7051 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6988 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6982 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6951 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6964 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6936 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6920 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6898 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6872 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6897 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6864 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6819 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6785 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6767 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6768 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6719 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6714 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6739 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6770 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6818 - accuracy: 0.87 - ETA: 59s - loss: 0.6825 - accuracy: 0.8769 - ETA: 58s - loss: 0.6856 - accuracy: 0.876 - ETA: 57s - loss: 0.6840 - accuracy: 0.877 - ETA: 56s - loss: 0.6865 - accuracy: 0.876 - ETA: 55s - loss: 0.6880 - accuracy: 0.876 - ETA: 54s - loss: 0.6937 - accuracy: 0.876 - ETA: 53s - loss: 0.6933 - accuracy: 0.876 - ETA: 52s - loss: 0.6929 - accuracy: 0.876 - ETA: 51s - loss: 0.6915 - accuracy: 0.876 - ETA: 50s - loss: 0.6898 - accuracy: 0.876 - ETA: 50s - loss: 0.6907 - accuracy: 0.875 - ETA: 49s - loss: 0.6929 - accuracy: 0.875 - ETA: 48s - loss: 0.6931 - accuracy: 0.875 - ETA: 47s - loss: 0.6929 - accuracy: 0.875 - ETA: 46s - loss: 0.6922 - accuracy: 0.875 - ETA: 45s - loss: 0.6905 - accuracy: 0.875 - ETA: 44s - loss: 0.6918 - accuracy: 0.875 - ETA: 43s - loss: 0.6900 - accuracy: 0.875 - ETA: 42s - loss: 0.6902 - accuracy: 0.875 - ETA: 41s - loss: 0.6897 - accuracy: 0.875 - ETA: 40s - loss: 0.6889 - accuracy: 0.875 - ETA: 39s - loss: 0.6907 - accuracy: 0.875 - ETA: 38s - loss: 0.6934 - accuracy: 0.874 - ETA: 37s - loss: 0.6913 - accuracy: 0.874 - ETA: 36s - loss: 0.6899 - accuracy: 0.874 - ETA: 35s - loss: 0.6907 - accuracy: 0.874 - ETA: 34s - loss: 0.6908 - accuracy: 0.874 - ETA: 33s - loss: 0.6900 - accuracy: 0.874 - ETA: 32s - loss: 0.6878 - accuracy: 0.874 - ETA: 31s - loss: 0.6864 - accuracy: 0.874 - ETA: 30s - loss: 0.6877 - accuracy: 0.874 - ETA: 29s - loss: 0.6875 - accuracy: 0.874 - ETA: 28s - loss: 0.6864 - accuracy: 0.874 - ETA: 27s - loss: 0.6851 - accuracy: 0.874 - ETA: 26s - loss: 0.6849 - accuracy: 0.874 - ETA: 25s - loss: 0.6853 - accuracy: 0.874 - ETA: 24s - loss: 0.6831 - accuracy: 0.874 - ETA: 23s - loss: 0.6859 - accuracy: 0.874 - ETA: 22s - loss: 0.6849 - accuracy: 0.874 - ETA: 22s - loss: 0.6855 - accuracy: 0.874 - ETA: 21s - loss: 0.6825 - accuracy: 0.874 - ETA: 20s - loss: 0.6832 - accuracy: 0.874 - ETA: 19s - loss: 0.6847 - accuracy: 0.874 - ETA: 18s - loss: 0.6856 - accuracy: 0.874 - ETA: 17s - loss: 0.6845 - accuracy: 0.874 - ETA: 16s - loss: 0.6862 - accuracy: 0.873 - ETA: 15s - loss: 0.6880 - accuracy: 0.873 - ETA: 14s - loss: 0.6912 - accuracy: 0.873 - ETA: 13s - loss: 0.6978 - accuracy: 0.873 - ETA: 12s - loss: 0.6989 - accuracy: 0.873 - ETA: 11s - loss: 0.6969 - accuracy: 0.873 - ETA: 10s - loss: 0.6958 - accuracy: 0.873 - ETA: 9s - loss: 0.6950 - accuracy: 0.873 - ETA: 8s - loss: 0.6934 - accuracy: 0.87 - ETA: 7s - loss: 0.6964 - accuracy: 0.87 - ETA: 6s - loss: 0.6941 - accuracy: 0.87 - ETA: 5s - loss: 0.6950 - accuracy: 0.87 - ETA: 4s - loss: 0.6952 - accuracy: 0.87 - ETA: 3s - loss: 0.6952 - accuracy: 0.87 - ETA: 2s - loss: 0.6987 - accuracy: 0.87 - ETA: 1s - loss: 0.6968 - accuracy: 0.87 - ETA: 0s - loss: 0.6948 - accuracy: 0.87 - 157s 8ms/step - loss: 0.6946 - accuracy: 0.8732 - val_loss: 4.2511 - val_accuracy: 0.7768\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 0.5300 - accuracy: 0.89 - ETA: 2:22 - loss: 0.7357 - accuracy: 0.88 - ETA: 2:19 - loss: 0.7238 - accuracy: 0.87 - ETA: 2:20 - loss: 0.6860 - accuracy: 0.86 - ETA: 2:18 - loss: 0.6798 - accuracy: 0.87 - ETA: 2:17 - loss: 0.7429 - accuracy: 0.85 - ETA: 2:15 - loss: 0.7823 - accuracy: 0.85 - ETA: 2:17 - loss: 0.7751 - accuracy: 0.85 - ETA: 2:17 - loss: 0.7657 - accuracy: 0.85 - ETA: 2:16 - loss: 0.7284 - accuracy: 0.86 - ETA: 2:15 - loss: 0.7096 - accuracy: 0.86 - ETA: 2:14 - loss: 0.7081 - accuracy: 0.86 - ETA: 2:12 - loss: 0.7257 - accuracy: 0.86 - ETA: 2:11 - loss: 0.7043 - accuracy: 0.86 - ETA: 2:10 - loss: 0.6882 - accuracy: 0.86 - ETA: 2:08 - loss: 0.6779 - accuracy: 0.86 - ETA: 2:07 - loss: 0.6617 - accuracy: 0.86 - ETA: 2:06 - loss: 0.6490 - accuracy: 0.86 - ETA: 2:05 - loss: 0.6466 - accuracy: 0.86 - ETA: 2:04 - loss: 0.6394 - accuracy: 0.86 - ETA: 2:02 - loss: 0.6714 - accuracy: 0.86 - ETA: 2:01 - loss: 0.6685 - accuracy: 0.86 - ETA: 2:00 - loss: 0.6600 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7149 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7101 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7066 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7078 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7554 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7631 - accuracy: 0.86 - ETA: 1:54 - loss: 0.7569 - accuracy: 0.86 - ETA: 1:53 - loss: 0.7551 - accuracy: 0.86 - ETA: 1:52 - loss: 0.7555 - accuracy: 0.86 - ETA: 1:51 - loss: 0.7577 - accuracy: 0.86 - ETA: 1:50 - loss: 0.7616 - accuracy: 0.86 - ETA: 1:50 - loss: 0.7566 - accuracy: 0.86 - ETA: 1:49 - loss: 0.7570 - accuracy: 0.86 - ETA: 1:48 - loss: 0.7506 - accuracy: 0.86 - ETA: 1:47 - loss: 0.7455 - accuracy: 0.86 - ETA: 1:46 - loss: 0.7417 - accuracy: 0.86 - ETA: 1:45 - loss: 0.7306 - accuracy: 0.86 - ETA: 1:44 - loss: 0.7252 - accuracy: 0.86 - ETA: 1:43 - loss: 0.7272 - accuracy: 0.86 - ETA: 1:42 - loss: 0.7218 - accuracy: 0.86 - ETA: 1:41 - loss: 0.7132 - accuracy: 0.86 - ETA: 1:40 - loss: 0.7064 - accuracy: 0.86 - ETA: 1:39 - loss: 0.7033 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6942 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6962 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6991 - accuracy: 0.87 - ETA: 1:35 - loss: 0.7054 - accuracy: 0.87 - ETA: 1:34 - loss: 0.7100 - accuracy: 0.87 - ETA: 1:33 - loss: 0.7078 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7080 - accuracy: 0.87 - ETA: 1:32 - loss: 0.7046 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6998 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6962 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6966 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6969 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6944 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6937 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6924 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6908 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6937 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6919 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6865 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6814 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6778 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6773 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6769 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6711 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6763 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6766 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6769 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6790 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6819 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6821 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6823 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6924 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6948 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6921 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6892 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6863 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6889 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6862 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6858 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6826 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6823 - accuracy: 0.87 - ETA: 59s - loss: 0.6777 - accuracy: 0.8738 - ETA: 58s - loss: 0.6783 - accuracy: 0.873 - ETA: 58s - loss: 0.6780 - accuracy: 0.873 - ETA: 57s - loss: 0.6753 - accuracy: 0.873 - ETA: 56s - loss: 0.6796 - accuracy: 0.873 - ETA: 55s - loss: 0.6807 - accuracy: 0.874 - ETA: 54s - loss: 0.6822 - accuracy: 0.874 - ETA: 53s - loss: 0.6783 - accuracy: 0.874 - ETA: 52s - loss: 0.6763 - accuracy: 0.875 - ETA: 51s - loss: 0.6749 - accuracy: 0.875 - ETA: 50s - loss: 0.6747 - accuracy: 0.875 - ETA: 49s - loss: 0.6755 - accuracy: 0.875 - ETA: 48s - loss: 0.6766 - accuracy: 0.875 - ETA: 47s - loss: 0.6751 - accuracy: 0.874 - ETA: 46s - loss: 0.6726 - accuracy: 0.875 - ETA: 45s - loss: 0.6729 - accuracy: 0.875 - ETA: 44s - loss: 0.6721 - accuracy: 0.875 - ETA: 43s - loss: 0.6721 - accuracy: 0.875 - ETA: 42s - loss: 0.6697 - accuracy: 0.875 - ETA: 41s - loss: 0.6678 - accuracy: 0.875 - ETA: 40s - loss: 0.6712 - accuracy: 0.875 - ETA: 39s - loss: 0.6730 - accuracy: 0.875 - ETA: 38s - loss: 0.6740 - accuracy: 0.874 - ETA: 37s - loss: 0.6759 - accuracy: 0.874 - ETA: 37s - loss: 0.6755 - accuracy: 0.874 - ETA: 36s - loss: 0.6730 - accuracy: 0.874 - ETA: 35s - loss: 0.6767 - accuracy: 0.875 - ETA: 34s - loss: 0.6765 - accuracy: 0.875 - ETA: 33s - loss: 0.6745 - accuracy: 0.875 - ETA: 32s - loss: 0.6739 - accuracy: 0.875 - ETA: 31s - loss: 0.6764 - accuracy: 0.875 - ETA: 30s - loss: 0.6773 - accuracy: 0.874 - ETA: 29s - loss: 0.6771 - accuracy: 0.874 - ETA: 28s - loss: 0.6748 - accuracy: 0.874 - ETA: 27s - loss: 0.6748 - accuracy: 0.874 - ETA: 26s - loss: 0.6760 - accuracy: 0.874 - ETA: 25s - loss: 0.6803 - accuracy: 0.874 - ETA: 24s - loss: 0.6786 - accuracy: 0.874 - ETA: 23s - loss: 0.6794 - accuracy: 0.874 - ETA: 22s - loss: 0.6775 - accuracy: 0.874 - ETA: 21s - loss: 0.6754 - accuracy: 0.875 - ETA: 20s - loss: 0.6764 - accuracy: 0.874 - ETA: 19s - loss: 0.6754 - accuracy: 0.874 - ETA: 18s - loss: 0.6767 - accuracy: 0.875 - ETA: 18s - loss: 0.6761 - accuracy: 0.875 - ETA: 17s - loss: 0.6752 - accuracy: 0.874 - ETA: 16s - loss: 0.6744 - accuracy: 0.874 - ETA: 15s - loss: 0.6755 - accuracy: 0.874 - ETA: 14s - loss: 0.6744 - accuracy: 0.874 - ETA: 13s - loss: 0.6716 - accuracy: 0.875 - ETA: 12s - loss: 0.6694 - accuracy: 0.875 - ETA: 11s - loss: 0.6710 - accuracy: 0.875 - ETA: 10s - loss: 0.6753 - accuracy: 0.875 - ETA: 9s - loss: 0.6758 - accuracy: 0.875 - ETA: 8s - loss: 0.6735 - accuracy: 0.87 - ETA: 7s - loss: 0.6741 - accuracy: 0.87 - ETA: 6s - loss: 0.6754 - accuracy: 0.87 - ETA: 5s - loss: 0.6780 - accuracy: 0.87 - ETA: 4s - loss: 0.6789 - accuracy: 0.87 - ETA: 3s - loss: 0.6772 - accuracy: 0.87 - ETA: 2s - loss: 0.6778 - accuracy: 0.87 - ETA: 1s - loss: 0.6780 - accuracy: 0.87 - ETA: 0s - loss: 0.6767 - accuracy: 0.87 - 155s 8ms/step - loss: 0.6752 - accuracy: 0.8754 - val_loss: 4.1103 - val_accuracy: 0.7770\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:25 - loss: 0.4303 - accuracy: 0.91 - ETA: 2:20 - loss: 0.4230 - accuracy: 0.90 - ETA: 2:18 - loss: 0.4376 - accuracy: 0.90 - ETA: 2:17 - loss: 0.6088 - accuracy: 0.89 - ETA: 2:16 - loss: 0.6358 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6036 - accuracy: 0.88 - ETA: 2:14 - loss: 0.5491 - accuracy: 0.89 - ETA: 2:13 - loss: 0.5691 - accuracy: 0.88 - ETA: 2:13 - loss: 0.5708 - accuracy: 0.88 - ETA: 2:12 - loss: 0.5556 - accuracy: 0.88 - ETA: 2:13 - loss: 0.5345 - accuracy: 0.89 - ETA: 2:14 - loss: 0.5220 - accuracy: 0.89 - ETA: 2:13 - loss: 0.5339 - accuracy: 0.88 - ETA: 2:12 - loss: 0.5586 - accuracy: 0.88 - ETA: 2:11 - loss: 0.5684 - accuracy: 0.88 - ETA: 2:10 - loss: 0.5602 - accuracy: 0.88 - ETA: 2:09 - loss: 0.5709 - accuracy: 0.88 - ETA: 2:08 - loss: 0.5718 - accuracy: 0.88 - ETA: 2:07 - loss: 0.5603 - accuracy: 0.88 - ETA: 2:05 - loss: 0.5592 - accuracy: 0.88 - ETA: 2:04 - loss: 0.5710 - accuracy: 0.88 - ETA: 2:03 - loss: 0.5840 - accuracy: 0.88 - ETA: 2:02 - loss: 0.6031 - accuracy: 0.88 - ETA: 2:01 - loss: 0.6087 - accuracy: 0.88 - ETA: 2:00 - loss: 0.6150 - accuracy: 0.88 - ETA: 1:59 - loss: 0.6068 - accuracy: 0.88 - ETA: 1:58 - loss: 0.6167 - accuracy: 0.88 - ETA: 1:57 - loss: 0.6197 - accuracy: 0.88 - ETA: 1:56 - loss: 0.6136 - accuracy: 0.88 - ETA: 1:56 - loss: 0.6050 - accuracy: 0.88 - ETA: 1:55 - loss: 0.6017 - accuracy: 0.88 - ETA: 1:54 - loss: 0.6015 - accuracy: 0.88 - ETA: 1:53 - loss: 0.5962 - accuracy: 0.88 - ETA: 1:52 - loss: 0.6025 - accuracy: 0.88 - ETA: 1:51 - loss: 0.6027 - accuracy: 0.88 - ETA: 1:50 - loss: 0.6019 - accuracy: 0.88 - ETA: 1:49 - loss: 0.6084 - accuracy: 0.88 - ETA: 1:48 - loss: 0.6084 - accuracy: 0.88 - ETA: 1:47 - loss: 0.6148 - accuracy: 0.88 - ETA: 1:47 - loss: 0.6187 - accuracy: 0.88 - ETA: 1:46 - loss: 0.6123 - accuracy: 0.88 - ETA: 1:45 - loss: 0.6204 - accuracy: 0.88 - ETA: 1:44 - loss: 0.6188 - accuracy: 0.88 - ETA: 1:43 - loss: 0.6322 - accuracy: 0.88 - ETA: 1:42 - loss: 0.6332 - accuracy: 0.88 - ETA: 1:41 - loss: 0.6372 - accuracy: 0.88 - ETA: 1:40 - loss: 0.6358 - accuracy: 0.88 - ETA: 1:39 - loss: 0.6291 - accuracy: 0.88 - ETA: 1:38 - loss: 0.6304 - accuracy: 0.88 - ETA: 1:37 - loss: 0.6286 - accuracy: 0.88 - ETA: 1:36 - loss: 0.6243 - accuracy: 0.88 - ETA: 1:35 - loss: 0.6249 - accuracy: 0.88 - ETA: 1:34 - loss: 0.6282 - accuracy: 0.88 - ETA: 1:33 - loss: 0.6269 - accuracy: 0.88 - ETA: 1:31 - loss: 0.6246 - accuracy: 0.88 - ETA: 1:31 - loss: 0.6272 - accuracy: 0.88 - ETA: 1:29 - loss: 0.6373 - accuracy: 0.88 - ETA: 1:29 - loss: 0.6391 - accuracy: 0.88 - ETA: 1:27 - loss: 0.6435 - accuracy: 0.88 - ETA: 1:26 - loss: 0.6428 - accuracy: 0.88 - ETA: 1:25 - loss: 0.6450 - accuracy: 0.88 - ETA: 1:25 - loss: 0.6465 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6445 - accuracy: 0.88 - ETA: 1:23 - loss: 0.6446 - accuracy: 0.88 - ETA: 1:22 - loss: 0.6438 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6453 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6432 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6401 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6471 - accuracy: 0.88 - ETA: 1:17 - loss: 0.6437 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6470 - accuracy: 0.88 - ETA: 1:15 - loss: 0.6513 - accuracy: 0.88 - ETA: 1:14 - loss: 0.6487 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6561 - accuracy: 0.88 - ETA: 1:12 - loss: 0.6588 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6566 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6540 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6514 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6491 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6460 - accuracy: 0.88 - ETA: 1:07 - loss: 0.6438 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6431 - accuracy: 0.88 - ETA: 1:05 - loss: 0.6405 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6441 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6439 - accuracy: 0.88 - ETA: 1:02 - loss: 0.6444 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6424 - accuracy: 0.88 - ETA: 1:00 - loss: 0.6396 - accuracy: 0.88 - ETA: 59s - loss: 0.6355 - accuracy: 0.8825 - ETA: 58s - loss: 0.6384 - accuracy: 0.882 - ETA: 57s - loss: 0.6378 - accuracy: 0.882 - ETA: 56s - loss: 0.6367 - accuracy: 0.882 - ETA: 55s - loss: 0.6405 - accuracy: 0.881 - ETA: 54s - loss: 0.6437 - accuracy: 0.881 - ETA: 53s - loss: 0.6409 - accuracy: 0.881 - ETA: 52s - loss: 0.6461 - accuracy: 0.880 - ETA: 51s - loss: 0.6434 - accuracy: 0.881 - ETA: 50s - loss: 0.6482 - accuracy: 0.881 - ETA: 49s - loss: 0.6469 - accuracy: 0.881 - ETA: 48s - loss: 0.6456 - accuracy: 0.881 - ETA: 47s - loss: 0.6475 - accuracy: 0.881 - ETA: 46s - loss: 0.6475 - accuracy: 0.880 - ETA: 45s - loss: 0.6460 - accuracy: 0.880 - ETA: 44s - loss: 0.6451 - accuracy: 0.880 - ETA: 43s - loss: 0.6456 - accuracy: 0.880 - ETA: 43s - loss: 0.6440 - accuracy: 0.880 - ETA: 42s - loss: 0.6426 - accuracy: 0.880 - ETA: 41s - loss: 0.6447 - accuracy: 0.880 - ETA: 40s - loss: 0.6455 - accuracy: 0.879 - ETA: 39s - loss: 0.6439 - accuracy: 0.879 - ETA: 38s - loss: 0.6447 - accuracy: 0.879 - ETA: 37s - loss: 0.6434 - accuracy: 0.879 - ETA: 36s - loss: 0.6446 - accuracy: 0.878 - ETA: 35s - loss: 0.6426 - accuracy: 0.878 - ETA: 34s - loss: 0.6424 - accuracy: 0.878 - ETA: 33s - loss: 0.6409 - accuracy: 0.878 - ETA: 32s - loss: 0.6409 - accuracy: 0.878 - ETA: 31s - loss: 0.6398 - accuracy: 0.878 - ETA: 30s - loss: 0.6389 - accuracy: 0.879 - ETA: 29s - loss: 0.6388 - accuracy: 0.879 - ETA: 28s - loss: 0.6412 - accuracy: 0.878 - ETA: 27s - loss: 0.6397 - accuracy: 0.878 - ETA: 26s - loss: 0.6413 - accuracy: 0.878 - ETA: 25s - loss: 0.6432 - accuracy: 0.878 - ETA: 24s - loss: 0.6419 - accuracy: 0.878 - ETA: 23s - loss: 0.6407 - accuracy: 0.878 - ETA: 22s - loss: 0.6399 - accuracy: 0.878 - ETA: 21s - loss: 0.6390 - accuracy: 0.878 - ETA: 20s - loss: 0.6379 - accuracy: 0.878 - ETA: 19s - loss: 0.6346 - accuracy: 0.878 - ETA: 19s - loss: 0.6340 - accuracy: 0.878 - ETA: 18s - loss: 0.6337 - accuracy: 0.878 - ETA: 17s - loss: 0.6380 - accuracy: 0.878 - ETA: 16s - loss: 0.6372 - accuracy: 0.878 - ETA: 15s - loss: 0.6369 - accuracy: 0.878 - ETA: 14s - loss: 0.6372 - accuracy: 0.879 - ETA: 13s - loss: 0.6372 - accuracy: 0.879 - ETA: 12s - loss: 0.6395 - accuracy: 0.878 - ETA: 11s - loss: 0.6394 - accuracy: 0.879 - ETA: 10s - loss: 0.6386 - accuracy: 0.878 - ETA: 9s - loss: 0.6374 - accuracy: 0.879 - ETA: 8s - loss: 0.6398 - accuracy: 0.87 - ETA: 7s - loss: 0.6395 - accuracy: 0.87 - ETA: 6s - loss: 0.6430 - accuracy: 0.87 - ETA: 5s - loss: 0.6432 - accuracy: 0.87 - ETA: 4s - loss: 0.6419 - accuracy: 0.87 - ETA: 3s - loss: 0.6442 - accuracy: 0.87 - ETA: 2s - loss: 0.6479 - accuracy: 0.87 - ETA: 1s - loss: 0.6484 - accuracy: 0.87 - ETA: 0s - loss: 0.6459 - accuracy: 0.87 - 156s 8ms/step - loss: 0.6476 - accuracy: 0.8781 - val_loss: 4.4819 - val_accuracy: 0.7728\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:54 - loss: 1.0803 - accuracy: 0.82 - ETA: 2:36 - loss: 0.8180 - accuracy: 0.84 - ETA: 2:32 - loss: 0.9637 - accuracy: 0.85 - ETA: 2:27 - loss: 0.8896 - accuracy: 0.85 - ETA: 2:25 - loss: 0.7782 - accuracy: 0.86 - ETA: 2:24 - loss: 0.7497 - accuracy: 0.86 - ETA: 2:23 - loss: 0.7279 - accuracy: 0.86 - ETA: 2:21 - loss: 0.7335 - accuracy: 0.86 - ETA: 2:19 - loss: 0.8092 - accuracy: 0.86 - ETA: 2:17 - loss: 0.8044 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7541 - accuracy: 0.87 - ETA: 2:14 - loss: 0.7426 - accuracy: 0.87 - ETA: 2:13 - loss: 0.7256 - accuracy: 0.87 - ETA: 2:12 - loss: 0.7106 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6921 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7054 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7176 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7432 - accuracy: 0.86 - ETA: 2:08 - loss: 0.7604 - accuracy: 0.86 - ETA: 2:06 - loss: 0.7582 - accuracy: 0.86 - ETA: 2:05 - loss: 0.7447 - accuracy: 0.86 - ETA: 2:04 - loss: 0.7599 - accuracy: 0.86 - ETA: 2:03 - loss: 0.7607 - accuracy: 0.86 - ETA: 2:01 - loss: 0.7449 - accuracy: 0.86 - ETA: 2:00 - loss: 0.7362 - accuracy: 0.86 - ETA: 1:59 - loss: 0.7371 - accuracy: 0.86 - ETA: 1:58 - loss: 0.7255 - accuracy: 0.86 - ETA: 1:57 - loss: 0.7269 - accuracy: 0.86 - ETA: 1:56 - loss: 0.7175 - accuracy: 0.86 - ETA: 1:55 - loss: 0.7162 - accuracy: 0.87 - ETA: 1:54 - loss: 0.7157 - accuracy: 0.87 - ETA: 1:53 - loss: 0.7182 - accuracy: 0.87 - ETA: 1:52 - loss: 0.7106 - accuracy: 0.87 - ETA: 1:51 - loss: 0.7084 - accuracy: 0.87 - ETA: 1:51 - loss: 0.7104 - accuracy: 0.87 - ETA: 1:50 - loss: 0.7118 - accuracy: 0.87 - ETA: 1:49 - loss: 0.7079 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6999 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6972 - accuracy: 0.87 - ETA: 1:45 - loss: 0.6975 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6978 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6967 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6990 - accuracy: 0.87 - ETA: 1:41 - loss: 0.7045 - accuracy: 0.87 - ETA: 1:40 - loss: 0.7078 - accuracy: 0.87 - ETA: 1:39 - loss: 0.7009 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6956 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6968 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6959 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6914 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6909 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6868 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6961 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6963 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6905 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6872 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6873 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6925 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6989 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6952 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6917 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6904 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6939 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6910 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6898 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6874 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6860 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6812 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6790 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6758 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6740 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6764 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6736 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6788 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6795 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6786 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6762 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6758 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6729 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6747 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6714 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6681 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6691 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6686 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6652 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6655 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6637 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6650 - accuracy: 0.87 - ETA: 59s - loss: 0.6671 - accuracy: 0.8761 - ETA: 58s - loss: 0.6664 - accuracy: 0.876 - ETA: 57s - loss: 0.6679 - accuracy: 0.875 - ETA: 56s - loss: 0.6648 - accuracy: 0.875 - ETA: 55s - loss: 0.6633 - accuracy: 0.875 - ETA: 54s - loss: 0.6626 - accuracy: 0.875 - ETA: 53s - loss: 0.6608 - accuracy: 0.875 - ETA: 52s - loss: 0.6639 - accuracy: 0.875 - ETA: 51s - loss: 0.6650 - accuracy: 0.875 - ETA: 50s - loss: 0.6664 - accuracy: 0.875 - ETA: 49s - loss: 0.6647 - accuracy: 0.875 - ETA: 48s - loss: 0.6632 - accuracy: 0.875 - ETA: 47s - loss: 0.6619 - accuracy: 0.875 - ETA: 46s - loss: 0.6598 - accuracy: 0.875 - ETA: 45s - loss: 0.6602 - accuracy: 0.875 - ETA: 44s - loss: 0.6580 - accuracy: 0.875 - ETA: 43s - loss: 0.6562 - accuracy: 0.875 - ETA: 43s - loss: 0.6582 - accuracy: 0.875 - ETA: 42s - loss: 0.6559 - accuracy: 0.875 - ETA: 41s - loss: 0.6543 - accuracy: 0.875 - ETA: 40s - loss: 0.6539 - accuracy: 0.875 - ETA: 39s - loss: 0.6504 - accuracy: 0.876 - ETA: 38s - loss: 0.6591 - accuracy: 0.876 - ETA: 37s - loss: 0.6560 - accuracy: 0.876 - ETA: 36s - loss: 0.6562 - accuracy: 0.876 - ETA: 35s - loss: 0.6623 - accuracy: 0.876 - ETA: 34s - loss: 0.6598 - accuracy: 0.876 - ETA: 33s - loss: 0.6625 - accuracy: 0.876 - ETA: 32s - loss: 0.6656 - accuracy: 0.876 - ETA: 31s - loss: 0.6680 - accuracy: 0.876 - ETA: 30s - loss: 0.6660 - accuracy: 0.876 - ETA: 29s - loss: 0.6645 - accuracy: 0.876 - ETA: 28s - loss: 0.6639 - accuracy: 0.876 - ETA: 27s - loss: 0.6638 - accuracy: 0.876 - ETA: 26s - loss: 0.6653 - accuracy: 0.876 - ETA: 25s - loss: 0.6631 - accuracy: 0.877 - ETA: 24s - loss: 0.6624 - accuracy: 0.876 - ETA: 23s - loss: 0.6620 - accuracy: 0.876 - ETA: 22s - loss: 0.6608 - accuracy: 0.877 - ETA: 21s - loss: 0.6586 - accuracy: 0.877 - ETA: 20s - loss: 0.6559 - accuracy: 0.877 - ETA: 19s - loss: 0.6536 - accuracy: 0.878 - ETA: 19s - loss: 0.6523 - accuracy: 0.878 - ETA: 18s - loss: 0.6515 - accuracy: 0.878 - ETA: 17s - loss: 0.6539 - accuracy: 0.877 - ETA: 16s - loss: 0.6543 - accuracy: 0.877 - ETA: 15s - loss: 0.6537 - accuracy: 0.877 - ETA: 14s - loss: 0.6527 - accuracy: 0.877 - ETA: 13s - loss: 0.6536 - accuracy: 0.877 - ETA: 12s - loss: 0.6564 - accuracy: 0.877 - ETA: 11s - loss: 0.6550 - accuracy: 0.877 - ETA: 10s - loss: 0.6545 - accuracy: 0.877 - ETA: 9s - loss: 0.6512 - accuracy: 0.878 - ETA: 8s - loss: 0.6512 - accuracy: 0.87 - ETA: 7s - loss: 0.6498 - accuracy: 0.87 - ETA: 6s - loss: 0.6497 - accuracy: 0.87 - ETA: 5s - loss: 0.6529 - accuracy: 0.87 - ETA: 4s - loss: 0.6513 - accuracy: 0.87 - ETA: 3s - loss: 0.6509 - accuracy: 0.87 - ETA: 2s - loss: 0.6539 - accuracy: 0.87 - ETA: 1s - loss: 0.6538 - accuracy: 0.87 - ETA: 0s - loss: 0.6511 - accuracy: 0.87 - 156s 8ms/step - loss: 0.6513 - accuracy: 0.8786 - val_loss: 4.1966 - val_accuracy: 0.7784\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 0.4717 - accuracy: 0.87 - ETA: 2:21 - loss: 0.5075 - accuracy: 0.86 - ETA: 2:18 - loss: 0.5224 - accuracy: 0.87 - ETA: 2:18 - loss: 0.5324 - accuracy: 0.87 - ETA: 2:19 - loss: 0.6400 - accuracy: 0.87 - ETA: 2:19 - loss: 0.6780 - accuracy: 0.87 - ETA: 2:19 - loss: 0.6769 - accuracy: 0.87 - ETA: 2:18 - loss: 0.6478 - accuracy: 0.88 - ETA: 2:17 - loss: 0.6707 - accuracy: 0.87 - ETA: 2:15 - loss: 0.6613 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6430 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6191 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6353 - accuracy: 0.87 - ETA: 2:10 - loss: 0.6203 - accuracy: 0.87 - ETA: 2:08 - loss: 0.6070 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6024 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6054 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6217 - accuracy: 0.87 - ETA: 2:05 - loss: 0.6226 - accuracy: 0.87 - ETA: 2:04 - loss: 0.6023 - accuracy: 0.88 - ETA: 2:04 - loss: 0.5990 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6165 - accuracy: 0.87 - ETA: 2:03 - loss: 0.6195 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6155 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6115 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6003 - accuracy: 0.87 - ETA: 1:58 - loss: 0.5980 - accuracy: 0.87 - ETA: 1:57 - loss: 0.5890 - accuracy: 0.88 - ETA: 1:56 - loss: 0.5827 - accuracy: 0.88 - ETA: 1:55 - loss: 0.5725 - accuracy: 0.88 - ETA: 1:54 - loss: 0.5812 - accuracy: 0.88 - ETA: 1:53 - loss: 0.5886 - accuracy: 0.88 - ETA: 1:52 - loss: 0.5842 - accuracy: 0.88 - ETA: 1:51 - loss: 0.5818 - accuracy: 0.88 - ETA: 1:50 - loss: 0.5773 - accuracy: 0.88 - ETA: 1:49 - loss: 0.5846 - accuracy: 0.88 - ETA: 1:48 - loss: 0.5867 - accuracy: 0.88 - ETA: 1:47 - loss: 0.5840 - accuracy: 0.88 - ETA: 1:46 - loss: 0.5876 - accuracy: 0.88 - ETA: 1:45 - loss: 0.5905 - accuracy: 0.87 - ETA: 1:44 - loss: 0.5875 - accuracy: 0.87 - ETA: 1:43 - loss: 0.5814 - accuracy: 0.88 - ETA: 1:42 - loss: 0.5831 - accuracy: 0.87 - ETA: 1:41 - loss: 0.5800 - accuracy: 0.88 - ETA: 1:40 - loss: 0.5842 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6016 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6023 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6029 - accuracy: 0.87 - ETA: 1:37 - loss: 0.5995 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6032 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6008 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6092 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6136 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6217 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6265 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6217 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6223 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6275 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6290 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6243 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6229 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6272 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6284 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6300 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6343 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6353 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6361 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6331 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6308 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6291 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6316 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6342 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6348 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6359 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6387 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6352 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6402 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6361 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6418 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6384 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6463 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6447 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6419 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6408 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6411 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6435 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6460 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6454 - accuracy: 0.87 - ETA: 59s - loss: 0.6432 - accuracy: 0.8774 - ETA: 58s - loss: 0.6420 - accuracy: 0.877 - ETA: 57s - loss: 0.6394 - accuracy: 0.877 - ETA: 56s - loss: 0.6415 - accuracy: 0.877 - ETA: 55s - loss: 0.6411 - accuracy: 0.878 - ETA: 54s - loss: 0.6414 - accuracy: 0.877 - ETA: 53s - loss: 0.6413 - accuracy: 0.877 - ETA: 52s - loss: 0.6403 - accuracy: 0.877 - ETA: 51s - loss: 0.6404 - accuracy: 0.877 - ETA: 50s - loss: 0.6376 - accuracy: 0.878 - ETA: 49s - loss: 0.6422 - accuracy: 0.877 - ETA: 48s - loss: 0.6458 - accuracy: 0.877 - ETA: 47s - loss: 0.6458 - accuracy: 0.877 - ETA: 46s - loss: 0.6487 - accuracy: 0.876 - ETA: 45s - loss: 0.6487 - accuracy: 0.876 - ETA: 44s - loss: 0.6491 - accuracy: 0.876 - ETA: 43s - loss: 0.6478 - accuracy: 0.876 - ETA: 42s - loss: 0.6471 - accuracy: 0.876 - ETA: 41s - loss: 0.6467 - accuracy: 0.876 - ETA: 40s - loss: 0.6513 - accuracy: 0.876 - ETA: 39s - loss: 0.6512 - accuracy: 0.876 - ETA: 39s - loss: 0.6530 - accuracy: 0.876 - ETA: 38s - loss: 0.6563 - accuracy: 0.876 - ETA: 37s - loss: 0.6580 - accuracy: 0.875 - ETA: 36s - loss: 0.6606 - accuracy: 0.875 - ETA: 35s - loss: 0.6617 - accuracy: 0.875 - ETA: 34s - loss: 0.6606 - accuracy: 0.875 - ETA: 33s - loss: 0.6591 - accuracy: 0.875 - ETA: 32s - loss: 0.6612 - accuracy: 0.876 - ETA: 31s - loss: 0.6626 - accuracy: 0.875 - ETA: 30s - loss: 0.6631 - accuracy: 0.875 - ETA: 29s - loss: 0.6610 - accuracy: 0.875 - ETA: 28s - loss: 0.6614 - accuracy: 0.875 - ETA: 27s - loss: 0.6581 - accuracy: 0.876 - ETA: 26s - loss: 0.6561 - accuracy: 0.876 - ETA: 25s - loss: 0.6571 - accuracy: 0.875 - ETA: 24s - loss: 0.6601 - accuracy: 0.875 - ETA: 23s - loss: 0.6609 - accuracy: 0.875 - ETA: 22s - loss: 0.6589 - accuracy: 0.875 - ETA: 21s - loss: 0.6581 - accuracy: 0.875 - ETA: 20s - loss: 0.6568 - accuracy: 0.875 - ETA: 19s - loss: 0.6555 - accuracy: 0.875 - ETA: 18s - loss: 0.6580 - accuracy: 0.875 - ETA: 18s - loss: 0.6552 - accuracy: 0.875 - ETA: 17s - loss: 0.6582 - accuracy: 0.875 - ETA: 16s - loss: 0.6645 - accuracy: 0.875 - ETA: 15s - loss: 0.6639 - accuracy: 0.875 - ETA: 14s - loss: 0.6610 - accuracy: 0.876 - ETA: 13s - loss: 0.6600 - accuracy: 0.876 - ETA: 12s - loss: 0.6595 - accuracy: 0.876 - ETA: 11s - loss: 0.6619 - accuracy: 0.876 - ETA: 10s - loss: 0.6621 - accuracy: 0.876 - ETA: 9s - loss: 0.6618 - accuracy: 0.876 - ETA: 8s - loss: 0.6617 - accuracy: 0.87 - ETA: 7s - loss: 0.6611 - accuracy: 0.87 - ETA: 6s - loss: 0.6617 - accuracy: 0.87 - ETA: 5s - loss: 0.6664 - accuracy: 0.87 - ETA: 4s - loss: 0.6647 - accuracy: 0.87 - ETA: 3s - loss: 0.6632 - accuracy: 0.87 - ETA: 2s - loss: 0.6658 - accuracy: 0.87 - ETA: 1s - loss: 0.6646 - accuracy: 0.87 - ETA: 0s - loss: 0.6628 - accuracy: 0.87 - 156s 8ms/step - loss: 0.6625 - accuracy: 0.8761 - val_loss: 4.2317 - val_accuracy: 0.7788\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:39 - loss: 0.3084 - accuracy: 0.91 - ETA: 2:27 - loss: 0.5655 - accuracy: 0.87 - ETA: 2:24 - loss: 0.5898 - accuracy: 0.87 - ETA: 2:21 - loss: 0.5869 - accuracy: 0.87 - ETA: 2:19 - loss: 0.6317 - accuracy: 0.86 - ETA: 2:18 - loss: 0.6405 - accuracy: 0.86 - ETA: 2:17 - loss: 0.6318 - accuracy: 0.86 - ETA: 2:16 - loss: 0.6379 - accuracy: 0.86 - ETA: 2:16 - loss: 0.6306 - accuracy: 0.86 - ETA: 2:15 - loss: 0.6516 - accuracy: 0.86 - ETA: 2:15 - loss: 0.6449 - accuracy: 0.86 - ETA: 2:14 - loss: 0.6634 - accuracy: 0.86 - ETA: 2:13 - loss: 0.6403 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6220 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6202 - accuracy: 0.87 - ETA: 2:10 - loss: 0.6332 - accuracy: 0.87 - ETA: 2:08 - loss: 0.6188 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6528 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6923 - accuracy: 0.86 - ETA: 2:06 - loss: 0.6808 - accuracy: 0.87 - ETA: 2:04 - loss: 0.6975 - accuracy: 0.86 - ETA: 2:03 - loss: 0.6900 - accuracy: 0.86 - ETA: 2:02 - loss: 0.6959 - accuracy: 0.86 - ETA: 2:01 - loss: 0.6851 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6887 - accuracy: 0.86 - ETA: 2:00 - loss: 0.6801 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6811 - accuracy: 0.86 - ETA: 1:58 - loss: 0.6713 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6709 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6651 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6538 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6496 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6433 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6416 - accuracy: 0.87 - ETA: 1:51 - loss: 0.6484 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6473 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6454 - accuracy: 0.87 - ETA: 1:47 - loss: 0.6431 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6428 - accuracy: 0.87 - ETA: 1:45 - loss: 0.6546 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6499 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6544 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6501 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6551 - accuracy: 0.87 - ETA: 1:41 - loss: 0.6541 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6560 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6527 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6568 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6540 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6488 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6528 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6541 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6535 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6484 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6473 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6503 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6526 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6515 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6588 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6541 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6561 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6525 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6638 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6610 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6582 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6637 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6618 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6575 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6562 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6552 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6585 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6614 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6651 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6616 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6649 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6615 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6655 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6621 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6616 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6640 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6662 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6665 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6728 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6780 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6773 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6769 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6758 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6735 - accuracy: 0.87 - ETA: 59s - loss: 0.6787 - accuracy: 0.8723 - ETA: 58s - loss: 0.6757 - accuracy: 0.872 - ETA: 57s - loss: 0.6720 - accuracy: 0.872 - ETA: 56s - loss: 0.6729 - accuracy: 0.872 - ETA: 55s - loss: 0.6688 - accuracy: 0.873 - ETA: 54s - loss: 0.6665 - accuracy: 0.873 - ETA: 53s - loss: 0.6650 - accuracy: 0.873 - ETA: 52s - loss: 0.6646 - accuracy: 0.873 - ETA: 51s - loss: 0.6676 - accuracy: 0.873 - ETA: 50s - loss: 0.6692 - accuracy: 0.873 - ETA: 49s - loss: 0.6681 - accuracy: 0.873 - ETA: 48s - loss: 0.6668 - accuracy: 0.873 - ETA: 47s - loss: 0.6668 - accuracy: 0.873 - ETA: 46s - loss: 0.6683 - accuracy: 0.873 - ETA: 45s - loss: 0.6643 - accuracy: 0.874 - ETA: 44s - loss: 0.6607 - accuracy: 0.874 - ETA: 43s - loss: 0.6592 - accuracy: 0.874 - ETA: 42s - loss: 0.6562 - accuracy: 0.874 - ETA: 42s - loss: 0.6538 - accuracy: 0.875 - ETA: 41s - loss: 0.6512 - accuracy: 0.875 - ETA: 40s - loss: 0.6492 - accuracy: 0.875 - ETA: 39s - loss: 0.6499 - accuracy: 0.875 - ETA: 38s - loss: 0.6489 - accuracy: 0.875 - ETA: 37s - loss: 0.6486 - accuracy: 0.875 - ETA: 36s - loss: 0.6489 - accuracy: 0.875 - ETA: 35s - loss: 0.6488 - accuracy: 0.875 - ETA: 34s - loss: 0.6496 - accuracy: 0.875 - ETA: 33s - loss: 0.6530 - accuracy: 0.875 - ETA: 32s - loss: 0.6537 - accuracy: 0.875 - ETA: 31s - loss: 0.6541 - accuracy: 0.875 - ETA: 30s - loss: 0.6531 - accuracy: 0.875 - ETA: 29s - loss: 0.6506 - accuracy: 0.875 - ETA: 28s - loss: 0.6513 - accuracy: 0.875 - ETA: 27s - loss: 0.6504 - accuracy: 0.875 - ETA: 26s - loss: 0.6520 - accuracy: 0.875 - ETA: 25s - loss: 0.6537 - accuracy: 0.875 - ETA: 24s - loss: 0.6519 - accuracy: 0.875 - ETA: 23s - loss: 0.6498 - accuracy: 0.875 - ETA: 22s - loss: 0.6484 - accuracy: 0.875 - ETA: 21s - loss: 0.6492 - accuracy: 0.875 - ETA: 20s - loss: 0.6487 - accuracy: 0.875 - ETA: 20s - loss: 0.6489 - accuracy: 0.875 - ETA: 19s - loss: 0.6492 - accuracy: 0.875 - ETA: 18s - loss: 0.6490 - accuracy: 0.875 - ETA: 17s - loss: 0.6486 - accuracy: 0.875 - ETA: 16s - loss: 0.6518 - accuracy: 0.875 - ETA: 15s - loss: 0.6557 - accuracy: 0.875 - ETA: 14s - loss: 0.6537 - accuracy: 0.875 - ETA: 13s - loss: 0.6524 - accuracy: 0.875 - ETA: 12s - loss: 0.6562 - accuracy: 0.875 - ETA: 11s - loss: 0.6539 - accuracy: 0.875 - ETA: 10s - loss: 0.6512 - accuracy: 0.876 - ETA: 9s - loss: 0.6505 - accuracy: 0.876 - ETA: 8s - loss: 0.6550 - accuracy: 0.87 - ETA: 7s - loss: 0.6525 - accuracy: 0.87 - ETA: 6s - loss: 0.6528 - accuracy: 0.87 - ETA: 5s - loss: 0.6528 - accuracy: 0.87 - ETA: 4s - loss: 0.6554 - accuracy: 0.87 - ETA: 3s - loss: 0.6545 - accuracy: 0.87 - ETA: 2s - loss: 0.6535 - accuracy: 0.87 - ETA: 1s - loss: 0.6522 - accuracy: 0.87 - ETA: 0s - loss: 0.6531 - accuracy: 0.87 - 157s 8ms/step - loss: 0.6515 - accuracy: 0.8759 - val_loss: 4.3936 - val_accuracy: 0.7782\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:42 - loss: 0.4504 - accuracy: 0.89 - ETA: 2:40 - loss: 0.5341 - accuracy: 0.88 - ETA: 2:33 - loss: 0.4709 - accuracy: 0.89 - ETA: 2:31 - loss: 0.4665 - accuracy: 0.89 - ETA: 2:26 - loss: 0.5074 - accuracy: 0.88 - ETA: 2:22 - loss: 0.4676 - accuracy: 0.89 - ETA: 2:20 - loss: 0.5675 - accuracy: 0.88 - ETA: 2:18 - loss: 0.5749 - accuracy: 0.87 - ETA: 2:16 - loss: 0.6052 - accuracy: 0.87 - ETA: 2:16 - loss: 0.6242 - accuracy: 0.87 - ETA: 2:15 - loss: 0.6340 - accuracy: 0.87 - ETA: 2:15 - loss: 0.6376 - accuracy: 0.87 - ETA: 2:15 - loss: 0.6257 - accuracy: 0.87 - ETA: 2:14 - loss: 0.6351 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6424 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6601 - accuracy: 0.87 - ETA: 2:10 - loss: 0.6698 - accuracy: 0.87 - ETA: 2:08 - loss: 0.6650 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6625 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6527 - accuracy: 0.87 - ETA: 2:05 - loss: 0.6521 - accuracy: 0.87 - ETA: 2:04 - loss: 0.6488 - accuracy: 0.87 - ETA: 2:03 - loss: 0.6585 - accuracy: 0.87 - ETA: 2:02 - loss: 0.6610 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6535 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6417 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6351 - accuracy: 0.87 - ETA: 1:58 - loss: 0.6367 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6353 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6298 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6232 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6251 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6290 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6317 - accuracy: 0.87 - ETA: 1:51 - loss: 0.6382 - accuracy: 0.87 - ETA: 1:50 - loss: 0.6502 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6483 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6455 - accuracy: 0.87 - ETA: 1:47 - loss: 0.6514 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6471 - accuracy: 0.87 - ETA: 1:45 - loss: 0.6449 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6425 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6357 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6289 - accuracy: 0.87 - ETA: 1:41 - loss: 0.6323 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6370 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6349 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6454 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6435 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6437 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6385 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6344 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6387 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6372 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6387 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6372 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6412 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6406 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6416 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6392 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6364 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6415 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6446 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6437 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6441 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6406 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6398 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6431 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6451 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6427 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6508 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6467 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6512 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6485 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6478 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6459 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6426 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6411 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6424 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6447 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6465 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6494 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6479 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6517 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6522 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6509 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6526 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6560 - accuracy: 0.87 - ETA: 59s - loss: 0.6544 - accuracy: 0.8775 - ETA: 58s - loss: 0.6533 - accuracy: 0.878 - ETA: 57s - loss: 0.6511 - accuracy: 0.878 - ETA: 56s - loss: 0.6508 - accuracy: 0.878 - ETA: 55s - loss: 0.6522 - accuracy: 0.878 - ETA: 54s - loss: 0.6501 - accuracy: 0.878 - ETA: 53s - loss: 0.6521 - accuracy: 0.878 - ETA: 52s - loss: 0.6507 - accuracy: 0.878 - ETA: 51s - loss: 0.6520 - accuracy: 0.878 - ETA: 51s - loss: 0.6518 - accuracy: 0.878 - ETA: 50s - loss: 0.6544 - accuracy: 0.878 - ETA: 49s - loss: 0.6589 - accuracy: 0.878 - ETA: 48s - loss: 0.6580 - accuracy: 0.877 - ETA: 47s - loss: 0.6568 - accuracy: 0.878 - ETA: 46s - loss: 0.6547 - accuracy: 0.878 - ETA: 45s - loss: 0.6526 - accuracy: 0.878 - ETA: 44s - loss: 0.6589 - accuracy: 0.878 - ETA: 43s - loss: 0.6614 - accuracy: 0.878 - ETA: 42s - loss: 0.6609 - accuracy: 0.878 - ETA: 41s - loss: 0.6597 - accuracy: 0.877 - ETA: 40s - loss: 0.6617 - accuracy: 0.877 - ETA: 39s - loss: 0.6602 - accuracy: 0.877 - ETA: 38s - loss: 0.6599 - accuracy: 0.877 - ETA: 37s - loss: 0.6589 - accuracy: 0.877 - ETA: 36s - loss: 0.6573 - accuracy: 0.877 - ETA: 35s - loss: 0.6567 - accuracy: 0.877 - ETA: 34s - loss: 0.6567 - accuracy: 0.877 - ETA: 33s - loss: 0.6567 - accuracy: 0.877 - ETA: 32s - loss: 0.6560 - accuracy: 0.877 - ETA: 31s - loss: 0.6541 - accuracy: 0.877 - ETA: 30s - loss: 0.6549 - accuracy: 0.877 - ETA: 29s - loss: 0.6522 - accuracy: 0.878 - ETA: 28s - loss: 0.6527 - accuracy: 0.877 - ETA: 27s - loss: 0.6567 - accuracy: 0.877 - ETA: 26s - loss: 0.6552 - accuracy: 0.877 - ETA: 25s - loss: 0.6538 - accuracy: 0.877 - ETA: 24s - loss: 0.6623 - accuracy: 0.877 - ETA: 23s - loss: 0.6609 - accuracy: 0.878 - ETA: 22s - loss: 0.6605 - accuracy: 0.878 - ETA: 21s - loss: 0.6603 - accuracy: 0.878 - ETA: 21s - loss: 0.6597 - accuracy: 0.878 - ETA: 20s - loss: 0.6600 - accuracy: 0.878 - ETA: 19s - loss: 0.6600 - accuracy: 0.878 - ETA: 18s - loss: 0.6603 - accuracy: 0.878 - ETA: 17s - loss: 0.6620 - accuracy: 0.877 - ETA: 16s - loss: 0.6643 - accuracy: 0.877 - ETA: 15s - loss: 0.6616 - accuracy: 0.878 - ETA: 14s - loss: 0.6625 - accuracy: 0.877 - ETA: 13s - loss: 0.6621 - accuracy: 0.877 - ETA: 12s - loss: 0.6615 - accuracy: 0.877 - ETA: 11s - loss: 0.6599 - accuracy: 0.878 - ETA: 10s - loss: 0.6586 - accuracy: 0.878 - ETA: 9s - loss: 0.6580 - accuracy: 0.878 - ETA: 8s - loss: 0.6578 - accuracy: 0.87 - ETA: 7s - loss: 0.6560 - accuracy: 0.87 - ETA: 6s - loss: 0.6541 - accuracy: 0.87 - ETA: 5s - loss: 0.6568 - accuracy: 0.87 - ETA: 4s - loss: 0.6557 - accuracy: 0.87 - ETA: 3s - loss: 0.6549 - accuracy: 0.87 - ETA: 2s - loss: 0.6541 - accuracy: 0.87 - ETA: 1s - loss: 0.6524 - accuracy: 0.87 - ETA: 0s - loss: 0.6506 - accuracy: 0.87 - 157s 8ms/step - loss: 0.6513 - accuracy: 0.8786 - val_loss: 4.3206 - val_accuracy: 0.7751\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:36 - loss: 0.5847 - accuracy: 0.88 - ETA: 2:27 - loss: 0.7224 - accuracy: 0.85 - ETA: 2:24 - loss: 0.7216 - accuracy: 0.86 - ETA: 2:20 - loss: 0.6764 - accuracy: 0.87 - ETA: 2:19 - loss: 0.6264 - accuracy: 0.87 - ETA: 2:16 - loss: 0.6128 - accuracy: 0.87 - ETA: 2:15 - loss: 0.6002 - accuracy: 0.87 - ETA: 2:14 - loss: 0.6760 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6373 - accuracy: 0.88 - ETA: 2:13 - loss: 0.6364 - accuracy: 0.88 - ETA: 2:12 - loss: 0.7010 - accuracy: 0.87 - ETA: 2:10 - loss: 0.6790 - accuracy: 0.88 - ETA: 2:10 - loss: 0.6973 - accuracy: 0.88 - ETA: 2:09 - loss: 0.7293 - accuracy: 0.87 - ETA: 2:08 - loss: 0.7112 - accuracy: 0.87 - ETA: 2:08 - loss: 0.6919 - accuracy: 0.87 - ETA: 2:08 - loss: 0.6888 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6964 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6724 - accuracy: 0.87 - ETA: 2:04 - loss: 0.6619 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6759 - accuracy: 0.87 - ETA: 2:02 - loss: 0.6648 - accuracy: 0.88 - ETA: 2:01 - loss: 0.6792 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6742 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6739 - accuracy: 0.87 - ETA: 1:58 - loss: 0.6607 - accuracy: 0.88 - ETA: 1:58 - loss: 0.6575 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6603 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6553 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6440 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6353 - accuracy: 0.88 - ETA: 1:53 - loss: 0.6339 - accuracy: 0.88 - ETA: 1:52 - loss: 0.6428 - accuracy: 0.88 - ETA: 1:51 - loss: 0.6371 - accuracy: 0.88 - ETA: 1:50 - loss: 0.6377 - accuracy: 0.88 - ETA: 1:49 - loss: 0.6434 - accuracy: 0.88 - ETA: 1:48 - loss: 0.6387 - accuracy: 0.88 - ETA: 1:47 - loss: 0.6336 - accuracy: 0.88 - ETA: 1:46 - loss: 0.6367 - accuracy: 0.88 - ETA: 1:46 - loss: 0.6286 - accuracy: 0.88 - ETA: 1:45 - loss: 0.6334 - accuracy: 0.88 - ETA: 1:44 - loss: 0.6258 - accuracy: 0.88 - ETA: 1:43 - loss: 0.6213 - accuracy: 0.88 - ETA: 1:42 - loss: 0.6191 - accuracy: 0.88 - ETA: 1:41 - loss: 0.6141 - accuracy: 0.88 - ETA: 1:40 - loss: 0.6134 - accuracy: 0.88 - ETA: 1:39 - loss: 0.6112 - accuracy: 0.88 - ETA: 1:38 - loss: 0.6085 - accuracy: 0.88 - ETA: 1:37 - loss: 0.6198 - accuracy: 0.88 - ETA: 1:36 - loss: 0.6266 - accuracy: 0.88 - ETA: 1:35 - loss: 0.6256 - accuracy: 0.88 - ETA: 1:35 - loss: 0.6320 - accuracy: 0.88 - ETA: 1:34 - loss: 0.6295 - accuracy: 0.88 - ETA: 1:33 - loss: 0.6259 - accuracy: 0.88 - ETA: 1:31 - loss: 0.6333 - accuracy: 0.88 - ETA: 1:31 - loss: 0.6370 - accuracy: 0.88 - ETA: 1:30 - loss: 0.6385 - accuracy: 0.88 - ETA: 1:29 - loss: 0.6384 - accuracy: 0.88 - ETA: 1:28 - loss: 0.6392 - accuracy: 0.88 - ETA: 1:27 - loss: 0.6386 - accuracy: 0.88 - ETA: 1:26 - loss: 0.6415 - accuracy: 0.88 - ETA: 1:25 - loss: 0.6367 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6343 - accuracy: 0.88 - ETA: 1:23 - loss: 0.6376 - accuracy: 0.88 - ETA: 1:22 - loss: 0.6391 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6359 - accuracy: 0.88 - ETA: 1:20 - loss: 0.6383 - accuracy: 0.88 - ETA: 1:19 - loss: 0.6402 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6415 - accuracy: 0.88 - ETA: 1:17 - loss: 0.6383 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6378 - accuracy: 0.88 - ETA: 1:15 - loss: 0.6404 - accuracy: 0.88 - ETA: 1:14 - loss: 0.6383 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6364 - accuracy: 0.88 - ETA: 1:12 - loss: 0.6348 - accuracy: 0.88 - ETA: 1:11 - loss: 0.6344 - accuracy: 0.88 - ETA: 1:10 - loss: 0.6325 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6350 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6324 - accuracy: 0.88 - ETA: 1:07 - loss: 0.6291 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6255 - accuracy: 0.88 - ETA: 1:05 - loss: 0.6280 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6310 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6351 - accuracy: 0.88 - ETA: 1:02 - loss: 0.6313 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6345 - accuracy: 0.88 - ETA: 1:00 - loss: 0.6321 - accuracy: 0.88 - ETA: 1:00 - loss: 0.6512 - accuracy: 0.88 - ETA: 59s - loss: 0.6500 - accuracy: 0.8818 - ETA: 58s - loss: 0.6510 - accuracy: 0.881 - ETA: 57s - loss: 0.6482 - accuracy: 0.881 - ETA: 56s - loss: 0.6483 - accuracy: 0.881 - ETA: 55s - loss: 0.6521 - accuracy: 0.881 - ETA: 54s - loss: 0.6519 - accuracy: 0.881 - ETA: 53s - loss: 0.6530 - accuracy: 0.880 - ETA: 52s - loss: 0.6515 - accuracy: 0.880 - ETA: 51s - loss: 0.6466 - accuracy: 0.881 - ETA: 50s - loss: 0.6453 - accuracy: 0.881 - ETA: 49s - loss: 0.6429 - accuracy: 0.881 - ETA: 48s - loss: 0.6453 - accuracy: 0.881 - ETA: 47s - loss: 0.6449 - accuracy: 0.880 - ETA: 46s - loss: 0.6481 - accuracy: 0.880 - ETA: 45s - loss: 0.6502 - accuracy: 0.880 - ETA: 44s - loss: 0.6497 - accuracy: 0.880 - ETA: 43s - loss: 0.6514 - accuracy: 0.880 - ETA: 42s - loss: 0.6526 - accuracy: 0.880 - ETA: 41s - loss: 0.6503 - accuracy: 0.880 - ETA: 40s - loss: 0.6526 - accuracy: 0.880 - ETA: 39s - loss: 0.6544 - accuracy: 0.880 - ETA: 39s - loss: 0.6562 - accuracy: 0.880 - ETA: 38s - loss: 0.6533 - accuracy: 0.880 - ETA: 37s - loss: 0.6590 - accuracy: 0.880 - ETA: 36s - loss: 0.6556 - accuracy: 0.880 - ETA: 35s - loss: 0.6546 - accuracy: 0.880 - ETA: 34s - loss: 0.6539 - accuracy: 0.880 - ETA: 33s - loss: 0.6561 - accuracy: 0.879 - ETA: 32s - loss: 0.6568 - accuracy: 0.879 - ETA: 31s - loss: 0.6559 - accuracy: 0.879 - ETA: 30s - loss: 0.6556 - accuracy: 0.880 - ETA: 29s - loss: 0.6531 - accuracy: 0.880 - ETA: 28s - loss: 0.6575 - accuracy: 0.880 - ETA: 27s - loss: 0.6567 - accuracy: 0.880 - ETA: 26s - loss: 0.6584 - accuracy: 0.879 - ETA: 25s - loss: 0.6570 - accuracy: 0.880 - ETA: 24s - loss: 0.6577 - accuracy: 0.879 - ETA: 23s - loss: 0.6553 - accuracy: 0.880 - ETA: 22s - loss: 0.6558 - accuracy: 0.880 - ETA: 21s - loss: 0.6575 - accuracy: 0.879 - ETA: 20s - loss: 0.6560 - accuracy: 0.880 - ETA: 19s - loss: 0.6549 - accuracy: 0.879 - ETA: 18s - loss: 0.6568 - accuracy: 0.879 - ETA: 17s - loss: 0.6589 - accuracy: 0.879 - ETA: 17s - loss: 0.6577 - accuracy: 0.879 - ETA: 16s - loss: 0.6576 - accuracy: 0.879 - ETA: 15s - loss: 0.6572 - accuracy: 0.879 - ETA: 14s - loss: 0.6574 - accuracy: 0.878 - ETA: 13s - loss: 0.6572 - accuracy: 0.878 - ETA: 12s - loss: 0.6556 - accuracy: 0.878 - ETA: 11s - loss: 0.6548 - accuracy: 0.878 - ETA: 10s - loss: 0.6546 - accuracy: 0.878 - ETA: 9s - loss: 0.6535 - accuracy: 0.878 - ETA: 8s - loss: 0.6537 - accuracy: 0.87 - ETA: 7s - loss: 0.6533 - accuracy: 0.87 - ETA: 6s - loss: 0.6518 - accuracy: 0.87 - ETA: 5s - loss: 0.6490 - accuracy: 0.87 - ETA: 4s - loss: 0.6484 - accuracy: 0.87 - ETA: 3s - loss: 0.6490 - accuracy: 0.87 - ETA: 2s - loss: 0.6472 - accuracy: 0.87 - ETA: 1s - loss: 0.6461 - accuracy: 0.87 - ETA: 0s - loss: 0.6466 - accuracy: 0.87 - 155s 8ms/step - loss: 0.6454 - accuracy: 0.8793 - val_loss: 4.6462 - val_accuracy: 0.7766\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:36 - loss: 0.8466 - accuracy: 0.89 - ETA: 2:24 - loss: 0.7477 - accuracy: 0.88 - ETA: 2:22 - loss: 0.7549 - accuracy: 0.87 - ETA: 2:23 - loss: 0.6638 - accuracy: 0.88 - ETA: 2:24 - loss: 0.6266 - accuracy: 0.89 - ETA: 2:23 - loss: 0.6136 - accuracy: 0.89 - ETA: 2:21 - loss: 0.5978 - accuracy: 0.89 - ETA: 2:19 - loss: 0.5918 - accuracy: 0.89 - ETA: 2:17 - loss: 0.5858 - accuracy: 0.89 - ETA: 2:16 - loss: 0.6418 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6371 - accuracy: 0.88 - ETA: 2:13 - loss: 0.6169 - accuracy: 0.88 - ETA: 2:12 - loss: 0.5989 - accuracy: 0.88 - ETA: 2:11 - loss: 0.6026 - accuracy: 0.88 - ETA: 2:10 - loss: 0.5977 - accuracy: 0.88 - ETA: 2:09 - loss: 0.5862 - accuracy: 0.88 - ETA: 2:09 - loss: 0.5857 - accuracy: 0.88 - ETA: 2:08 - loss: 0.5855 - accuracy: 0.88 - ETA: 2:07 - loss: 0.5819 - accuracy: 0.88 - ETA: 2:06 - loss: 0.5830 - accuracy: 0.88 - ETA: 2:05 - loss: 0.5939 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6020 - accuracy: 0.88 - ETA: 2:03 - loss: 0.5995 - accuracy: 0.88 - ETA: 2:02 - loss: 0.5989 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6090 - accuracy: 0.87 - ETA: 2:00 - loss: 0.5956 - accuracy: 0.88 - ETA: 1:59 - loss: 0.5931 - accuracy: 0.88 - ETA: 1:58 - loss: 0.6171 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6229 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6190 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6205 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6219 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6345 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6356 - accuracy: 0.87 - ETA: 1:51 - loss: 0.6358 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6323 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6293 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6250 - accuracy: 0.87 - ETA: 1:47 - loss: 0.6266 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6211 - accuracy: 0.87 - ETA: 1:45 - loss: 0.6377 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6423 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6361 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6317 - accuracy: 0.87 - ETA: 1:41 - loss: 0.6247 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6229 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6211 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6170 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6192 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6161 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6274 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6239 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6213 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6270 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6225 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6207 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6206 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6161 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6112 - accuracy: 0.88 - ETA: 1:27 - loss: 0.6114 - accuracy: 0.88 - ETA: 1:26 - loss: 0.6109 - accuracy: 0.88 - ETA: 1:25 - loss: 0.6086 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6109 - accuracy: 0.88 - ETA: 1:23 - loss: 0.6150 - accuracy: 0.88 - ETA: 1:22 - loss: 0.6145 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6160 - accuracy: 0.88 - ETA: 1:20 - loss: 0.6135 - accuracy: 0.88 - ETA: 1:19 - loss: 0.6114 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6117 - accuracy: 0.88 - ETA: 1:17 - loss: 0.6126 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6093 - accuracy: 0.88 - ETA: 1:15 - loss: 0.6100 - accuracy: 0.88 - ETA: 1:14 - loss: 0.6137 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6133 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6123 - accuracy: 0.88 - ETA: 1:12 - loss: 0.6106 - accuracy: 0.88 - ETA: 1:11 - loss: 0.6093 - accuracy: 0.88 - ETA: 1:10 - loss: 0.6080 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6067 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6057 - accuracy: 0.88 - ETA: 1:07 - loss: 0.6088 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6072 - accuracy: 0.88 - ETA: 1:05 - loss: 0.6065 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6117 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6149 - accuracy: 0.88 - ETA: 1:02 - loss: 0.6184 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6197 - accuracy: 0.88 - ETA: 1:00 - loss: 0.6215 - accuracy: 0.88 - ETA: 59s - loss: 0.6267 - accuracy: 0.8794 - ETA: 58s - loss: 0.6306 - accuracy: 0.879 - ETA: 57s - loss: 0.6293 - accuracy: 0.879 - ETA: 56s - loss: 0.6285 - accuracy: 0.879 - ETA: 55s - loss: 0.6296 - accuracy: 0.879 - ETA: 54s - loss: 0.6301 - accuracy: 0.879 - ETA: 53s - loss: 0.6285 - accuracy: 0.879 - ETA: 52s - loss: 0.6265 - accuracy: 0.880 - ETA: 51s - loss: 0.6289 - accuracy: 0.880 - ETA: 50s - loss: 0.6276 - accuracy: 0.880 - ETA: 49s - loss: 0.6328 - accuracy: 0.879 - ETA: 48s - loss: 0.6360 - accuracy: 0.879 - ETA: 47s - loss: 0.6363 - accuracy: 0.879 - ETA: 46s - loss: 0.6354 - accuracy: 0.879 - ETA: 45s - loss: 0.6371 - accuracy: 0.879 - ETA: 44s - loss: 0.6346 - accuracy: 0.879 - ETA: 44s - loss: 0.6385 - accuracy: 0.879 - ETA: 43s - loss: 0.6377 - accuracy: 0.879 - ETA: 42s - loss: 0.6371 - accuracy: 0.879 - ETA: 41s - loss: 0.6359 - accuracy: 0.879 - ETA: 40s - loss: 0.6391 - accuracy: 0.878 - ETA: 39s - loss: 0.6368 - accuracy: 0.879 - ETA: 38s - loss: 0.6388 - accuracy: 0.879 - ETA: 37s - loss: 0.6392 - accuracy: 0.878 - ETA: 36s - loss: 0.6383 - accuracy: 0.879 - ETA: 35s - loss: 0.6397 - accuracy: 0.879 - ETA: 34s - loss: 0.6425 - accuracy: 0.879 - ETA: 33s - loss: 0.6432 - accuracy: 0.879 - ETA: 32s - loss: 0.6439 - accuracy: 0.879 - ETA: 31s - loss: 0.6444 - accuracy: 0.879 - ETA: 30s - loss: 0.6435 - accuracy: 0.879 - ETA: 29s - loss: 0.6429 - accuracy: 0.879 - ETA: 28s - loss: 0.6407 - accuracy: 0.879 - ETA: 27s - loss: 0.6387 - accuracy: 0.879 - ETA: 26s - loss: 0.6397 - accuracy: 0.879 - ETA: 25s - loss: 0.6450 - accuracy: 0.879 - ETA: 24s - loss: 0.6461 - accuracy: 0.879 - ETA: 23s - loss: 0.6467 - accuracy: 0.879 - ETA: 22s - loss: 0.6485 - accuracy: 0.879 - ETA: 21s - loss: 0.6495 - accuracy: 0.879 - ETA: 20s - loss: 0.6480 - accuracy: 0.879 - ETA: 19s - loss: 0.6569 - accuracy: 0.878 - ETA: 19s - loss: 0.6571 - accuracy: 0.879 - ETA: 18s - loss: 0.6590 - accuracy: 0.879 - ETA: 17s - loss: 0.6587 - accuracy: 0.879 - ETA: 16s - loss: 0.6628 - accuracy: 0.879 - ETA: 15s - loss: 0.6618 - accuracy: 0.879 - ETA: 14s - loss: 0.6635 - accuracy: 0.879 - ETA: 13s - loss: 0.6609 - accuracy: 0.879 - ETA: 12s - loss: 0.6631 - accuracy: 0.879 - ETA: 11s - loss: 0.6618 - accuracy: 0.879 - ETA: 10s - loss: 0.6601 - accuracy: 0.879 - ETA: 9s - loss: 0.6608 - accuracy: 0.879 - ETA: 8s - loss: 0.6626 - accuracy: 0.87 - ETA: 7s - loss: 0.6627 - accuracy: 0.87 - ETA: 6s - loss: 0.6643 - accuracy: 0.87 - ETA: 5s - loss: 0.6653 - accuracy: 0.87 - ETA: 4s - loss: 0.6664 - accuracy: 0.87 - ETA: 3s - loss: 0.6632 - accuracy: 0.87 - ETA: 2s - loss: 0.6633 - accuracy: 0.87 - ETA: 1s - loss: 0.6612 - accuracy: 0.87 - ETA: 0s - loss: 0.6620 - accuracy: 0.87 - 157s 8ms/step - loss: 0.6629 - accuracy: 0.8796 - val_loss: 4.3672 - val_accuracy: 0.7784\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:31 - loss: 0.8455 - accuracy: 0.84 - ETA: 2:27 - loss: 0.8637 - accuracy: 0.84 - ETA: 2:22 - loss: 0.7327 - accuracy: 0.85 - ETA: 2:22 - loss: 0.7160 - accuracy: 0.86 - ETA: 2:20 - loss: 0.7077 - accuracy: 0.86 - ETA: 2:17 - loss: 0.7588 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7159 - accuracy: 0.86 - ETA: 2:16 - loss: 0.6983 - accuracy: 0.87 - ETA: 2:16 - loss: 0.7155 - accuracy: 0.86 - ETA: 2:16 - loss: 0.7081 - accuracy: 0.86 - ETA: 2:15 - loss: 0.7214 - accuracy: 0.86 - ETA: 2:14 - loss: 0.7100 - accuracy: 0.86 - ETA: 2:12 - loss: 0.7035 - accuracy: 0.86 - ETA: 2:12 - loss: 0.6813 - accuracy: 0.86 - ETA: 2:10 - loss: 0.6720 - accuracy: 0.86 - ETA: 2:09 - loss: 0.6817 - accuracy: 0.86 - ETA: 2:08 - loss: 0.6745 - accuracy: 0.86 - ETA: 2:07 - loss: 0.6595 - accuracy: 0.86 - ETA: 2:05 - loss: 0.6622 - accuracy: 0.86 - ETA: 2:04 - loss: 0.6569 - accuracy: 0.86 - ETA: 2:04 - loss: 0.6497 - accuracy: 0.87 - ETA: 2:02 - loss: 0.6407 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6324 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6466 - accuracy: 0.87 - ETA: 2:00 - loss: 0.6458 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6533 - accuracy: 0.87 - ETA: 1:58 - loss: 0.6756 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6730 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6744 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6690 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6722 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6648 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6662 - accuracy: 0.87 - ETA: 1:51 - loss: 0.6574 - accuracy: 0.87 - ETA: 1:50 - loss: 0.6500 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6604 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6751 - accuracy: 0.87 - ETA: 1:47 - loss: 0.6712 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6695 - accuracy: 0.87 - ETA: 1:45 - loss: 0.6641 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6725 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6668 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6662 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6646 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6743 - accuracy: 0.87 - ETA: 1:41 - loss: 0.6800 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6724 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6651 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6708 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6732 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6648 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6620 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6586 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6640 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6606 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6580 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6584 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6564 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6534 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6589 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6536 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6559 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6512 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6548 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6564 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6559 - accuracy: 0.87 - ETA: 1:21 - loss: 0.6490 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6453 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6515 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6540 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6492 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6539 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6510 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6517 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6582 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6551 - accuracy: 0.87 - ETA: 1:11 - loss: 0.6567 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6567 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6527 - accuracy: 0.87 - ETA: 1:08 - loss: 0.6527 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6518 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6514 - accuracy: 0.87 - ETA: 1:05 - loss: 0.6488 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6614 - accuracy: 0.87 - ETA: 1:03 - loss: 0.6589 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6559 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6538 - accuracy: 0.87 - ETA: 1:00 - loss: 0.6519 - accuracy: 0.87 - ETA: 59s - loss: 0.6501 - accuracy: 0.8773 - ETA: 58s - loss: 0.6484 - accuracy: 0.877 - ETA: 57s - loss: 0.6477 - accuracy: 0.876 - ETA: 56s - loss: 0.6445 - accuracy: 0.877 - ETA: 55s - loss: 0.6448 - accuracy: 0.877 - ETA: 54s - loss: 0.6484 - accuracy: 0.876 - ETA: 53s - loss: 0.6496 - accuracy: 0.876 - ETA: 52s - loss: 0.6498 - accuracy: 0.877 - ETA: 51s - loss: 0.6501 - accuracy: 0.876 - ETA: 50s - loss: 0.6549 - accuracy: 0.876 - ETA: 50s - loss: 0.6558 - accuracy: 0.876 - ETA: 49s - loss: 0.6553 - accuracy: 0.876 - ETA: 48s - loss: 0.6528 - accuracy: 0.876 - ETA: 47s - loss: 0.6538 - accuracy: 0.876 - ETA: 46s - loss: 0.6550 - accuracy: 0.876 - ETA: 45s - loss: 0.6580 - accuracy: 0.876 - ETA: 44s - loss: 0.6551 - accuracy: 0.876 - ETA: 43s - loss: 0.6564 - accuracy: 0.876 - ETA: 42s - loss: 0.6556 - accuracy: 0.876 - ETA: 41s - loss: 0.6566 - accuracy: 0.876 - ETA: 40s - loss: 0.6601 - accuracy: 0.876 - ETA: 39s - loss: 0.6581 - accuracy: 0.876 - ETA: 38s - loss: 0.6578 - accuracy: 0.876 - ETA: 37s - loss: 0.6565 - accuracy: 0.876 - ETA: 36s - loss: 0.6595 - accuracy: 0.876 - ETA: 35s - loss: 0.6583 - accuracy: 0.876 - ETA: 34s - loss: 0.6575 - accuracy: 0.876 - ETA: 33s - loss: 0.6576 - accuracy: 0.875 - ETA: 32s - loss: 0.6556 - accuracy: 0.876 - ETA: 31s - loss: 0.6554 - accuracy: 0.876 - ETA: 30s - loss: 0.6558 - accuracy: 0.876 - ETA: 29s - loss: 0.6576 - accuracy: 0.876 - ETA: 28s - loss: 0.6566 - accuracy: 0.876 - ETA: 27s - loss: 0.6578 - accuracy: 0.876 - ETA: 26s - loss: 0.6598 - accuracy: 0.876 - ETA: 25s - loss: 0.6597 - accuracy: 0.876 - ETA: 24s - loss: 0.6590 - accuracy: 0.877 - ETA: 23s - loss: 0.6616 - accuracy: 0.877 - ETA: 23s - loss: 0.6642 - accuracy: 0.877 - ETA: 22s - loss: 0.6632 - accuracy: 0.877 - ETA: 21s - loss: 0.6633 - accuracy: 0.877 - ETA: 20s - loss: 0.6633 - accuracy: 0.877 - ETA: 19s - loss: 0.6636 - accuracy: 0.877 - ETA: 18s - loss: 0.6642 - accuracy: 0.877 - ETA: 17s - loss: 0.6630 - accuracy: 0.877 - ETA: 16s - loss: 0.6612 - accuracy: 0.877 - ETA: 15s - loss: 0.6605 - accuracy: 0.877 - ETA: 14s - loss: 0.6629 - accuracy: 0.877 - ETA: 13s - loss: 0.6641 - accuracy: 0.877 - ETA: 12s - loss: 0.6627 - accuracy: 0.877 - ETA: 11s - loss: 0.6605 - accuracy: 0.878 - ETA: 10s - loss: 0.6612 - accuracy: 0.877 - ETA: 9s - loss: 0.6604 - accuracy: 0.877 - ETA: 8s - loss: 0.6608 - accuracy: 0.87 - ETA: 7s - loss: 0.6596 - accuracy: 0.87 - ETA: 6s - loss: 0.6600 - accuracy: 0.87 - ETA: 5s - loss: 0.6575 - accuracy: 0.87 - ETA: 4s - loss: 0.6561 - accuracy: 0.87 - ETA: 3s - loss: 0.6551 - accuracy: 0.87 - ETA: 2s - loss: 0.6553 - accuracy: 0.87 - ETA: 1s - loss: 0.6548 - accuracy: 0.87 - ETA: 0s - loss: 0.6539 - accuracy: 0.87 - 157s 8ms/step - loss: 0.6558 - accuracy: 0.8781 - val_loss: 4.4303 - val_accuracy: 0.7826\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:26 - loss: 0.3769 - accuracy: 0.89 - ETA: 2:21 - loss: 0.3632 - accuracy: 0.89 - ETA: 2:18 - loss: 0.5048 - accuracy: 0.88 - ETA: 2:20 - loss: 0.6025 - accuracy: 0.88 - ETA: 2:18 - loss: 0.6430 - accuracy: 0.88 - ETA: 2:19 - loss: 0.6518 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6215 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6840 - accuracy: 0.87 - ETA: 2:15 - loss: 0.7565 - accuracy: 0.87 - ETA: 2:14 - loss: 0.7763 - accuracy: 0.87 - ETA: 2:13 - loss: 0.7675 - accuracy: 0.87 - ETA: 2:13 - loss: 0.7540 - accuracy: 0.87 - ETA: 2:12 - loss: 0.7386 - accuracy: 0.87 - ETA: 2:12 - loss: 0.7171 - accuracy: 0.87 - ETA: 2:10 - loss: 0.7188 - accuracy: 0.87 - ETA: 2:09 - loss: 0.7027 - accuracy: 0.87 - ETA: 2:08 - loss: 0.7466 - accuracy: 0.87 - ETA: 2:06 - loss: 0.7429 - accuracy: 0.87 - ETA: 2:05 - loss: 0.7276 - accuracy: 0.87 - ETA: 2:04 - loss: 0.7251 - accuracy: 0.87 - ETA: 2:03 - loss: 0.7185 - accuracy: 0.87 - ETA: 2:02 - loss: 0.7153 - accuracy: 0.87 - ETA: 2:01 - loss: 0.7224 - accuracy: 0.86 - ETA: 2:00 - loss: 0.7132 - accuracy: 0.87 - ETA: 1:59 - loss: 0.7083 - accuracy: 0.87 - ETA: 1:58 - loss: 0.6989 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6983 - accuracy: 0.87 - ETA: 1:56 - loss: 0.7003 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6862 - accuracy: 0.87 - ETA: 1:55 - loss: 0.6918 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6859 - accuracy: 0.87 - ETA: 1:53 - loss: 0.6795 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6665 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6559 - accuracy: 0.87 - ETA: 1:51 - loss: 0.6552 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6523 - accuracy: 0.88 - ETA: 1:48 - loss: 0.6447 - accuracy: 0.88 - ETA: 1:47 - loss: 0.6460 - accuracy: 0.88 - ETA: 1:46 - loss: 0.6496 - accuracy: 0.88 - ETA: 1:45 - loss: 0.6485 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6713 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6673 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6711 - accuracy: 0.87 - ETA: 1:42 - loss: 0.6736 - accuracy: 0.87 - ETA: 1:41 - loss: 0.6787 - accuracy: 0.87 - ETA: 1:40 - loss: 0.6735 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6720 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6828 - accuracy: 0.87 - ETA: 1:37 - loss: 0.6852 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6832 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6968 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6911 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6921 - accuracy: 0.87 - ETA: 1:32 - loss: 0.6865 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6850 - accuracy: 0.87 - ETA: 1:30 - loss: 0.6780 - accuracy: 0.87 - ETA: 1:29 - loss: 0.6782 - accuracy: 0.87 - ETA: 1:28 - loss: 0.6813 - accuracy: 0.87 - ETA: 1:27 - loss: 0.6824 - accuracy: 0.87 - ETA: 1:26 - loss: 0.6769 - accuracy: 0.87 - ETA: 1:25 - loss: 0.6728 - accuracy: 0.87 - ETA: 1:24 - loss: 0.6700 - accuracy: 0.87 - ETA: 1:23 - loss: 0.6713 - accuracy: 0.87 - ETA: 1:22 - loss: 0.6653 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6647 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6607 - accuracy: 0.88 - ETA: 1:19 - loss: 0.6657 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6693 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6695 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6704 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6681 - accuracy: 0.87 - ETA: 1:15 - loss: 0.6651 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6625 - accuracy: 0.87 - ETA: 1:13 - loss: 0.6587 - accuracy: 0.88 - ETA: 1:12 - loss: 0.6558 - accuracy: 0.88 - ETA: 1:11 - loss: 0.6544 - accuracy: 0.88 - ETA: 1:10 - loss: 0.6582 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6580 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6554 - accuracy: 0.88 - ETA: 1:07 - loss: 0.6530 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6538 - accuracy: 0.88 - ETA: 1:05 - loss: 0.6558 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6622 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6608 - accuracy: 0.88 - ETA: 1:02 - loss: 0.6596 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6580 - accuracy: 0.88 - ETA: 1:00 - loss: 0.6571 - accuracy: 0.87 - ETA: 59s - loss: 0.6551 - accuracy: 0.8801 - ETA: 58s - loss: 0.6539 - accuracy: 0.880 - ETA: 58s - loss: 0.6569 - accuracy: 0.879 - ETA: 57s - loss: 0.6566 - accuracy: 0.879 - ETA: 56s - loss: 0.6522 - accuracy: 0.880 - ETA: 55s - loss: 0.6490 - accuracy: 0.880 - ETA: 54s - loss: 0.6506 - accuracy: 0.880 - ETA: 53s - loss: 0.6462 - accuracy: 0.880 - ETA: 52s - loss: 0.6455 - accuracy: 0.881 - ETA: 51s - loss: 0.6473 - accuracy: 0.881 - ETA: 50s - loss: 0.6459 - accuracy: 0.881 - ETA: 49s - loss: 0.6469 - accuracy: 0.880 - ETA: 48s - loss: 0.6487 - accuracy: 0.880 - ETA: 47s - loss: 0.6516 - accuracy: 0.880 - ETA: 46s - loss: 0.6488 - accuracy: 0.880 - ETA: 45s - loss: 0.6478 - accuracy: 0.880 - ETA: 44s - loss: 0.6449 - accuracy: 0.881 - ETA: 43s - loss: 0.6431 - accuracy: 0.881 - ETA: 42s - loss: 0.6444 - accuracy: 0.880 - ETA: 41s - loss: 0.6421 - accuracy: 0.880 - ETA: 40s - loss: 0.6425 - accuracy: 0.880 - ETA: 39s - loss: 0.6412 - accuracy: 0.880 - ETA: 38s - loss: 0.6444 - accuracy: 0.880 - ETA: 37s - loss: 0.6456 - accuracy: 0.880 - ETA: 37s - loss: 0.6499 - accuracy: 0.880 - ETA: 36s - loss: 0.6478 - accuracy: 0.880 - ETA: 35s - loss: 0.6469 - accuracy: 0.880 - ETA: 34s - loss: 0.6487 - accuracy: 0.880 - ETA: 33s - loss: 0.6463 - accuracy: 0.880 - ETA: 32s - loss: 0.6508 - accuracy: 0.880 - ETA: 31s - loss: 0.6560 - accuracy: 0.881 - ETA: 30s - loss: 0.6612 - accuracy: 0.880 - ETA: 29s - loss: 0.6644 - accuracy: 0.880 - ETA: 28s - loss: 0.6635 - accuracy: 0.880 - ETA: 27s - loss: 0.6644 - accuracy: 0.880 - ETA: 26s - loss: 0.6638 - accuracy: 0.880 - ETA: 25s - loss: 0.6624 - accuracy: 0.880 - ETA: 24s - loss: 0.6612 - accuracy: 0.880 - ETA: 23s - loss: 0.6625 - accuracy: 0.880 - ETA: 22s - loss: 0.6646 - accuracy: 0.880 - ETA: 21s - loss: 0.6662 - accuracy: 0.879 - ETA: 20s - loss: 0.6690 - accuracy: 0.879 - ETA: 19s - loss: 0.6687 - accuracy: 0.879 - ETA: 18s - loss: 0.6678 - accuracy: 0.879 - ETA: 18s - loss: 0.6667 - accuracy: 0.880 - ETA: 17s - loss: 0.6672 - accuracy: 0.880 - ETA: 16s - loss: 0.6659 - accuracy: 0.880 - ETA: 15s - loss: 0.6646 - accuracy: 0.880 - ETA: 14s - loss: 0.6650 - accuracy: 0.880 - ETA: 13s - loss: 0.6666 - accuracy: 0.880 - ETA: 12s - loss: 0.6732 - accuracy: 0.880 - ETA: 11s - loss: 0.6748 - accuracy: 0.880 - ETA: 10s - loss: 0.6741 - accuracy: 0.880 - ETA: 9s - loss: 0.6726 - accuracy: 0.880 - ETA: 8s - loss: 0.6704 - accuracy: 0.88 - ETA: 7s - loss: 0.6688 - accuracy: 0.88 - ETA: 6s - loss: 0.6674 - accuracy: 0.88 - ETA: 5s - loss: 0.6668 - accuracy: 0.88 - ETA: 4s - loss: 0.6654 - accuracy: 0.88 - ETA: 3s - loss: 0.6631 - accuracy: 0.88 - ETA: 2s - loss: 0.6617 - accuracy: 0.88 - ETA: 1s - loss: 0.6596 - accuracy: 0.88 - ETA: 0s - loss: 0.6589 - accuracy: 0.88 - 155s 8ms/step - loss: 0.6574 - accuracy: 0.8817 - val_loss: 4.1032 - val_accuracy: 0.7793\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:25 - loss: 1.0233 - accuracy: 0.85 - ETA: 2:18 - loss: 0.7449 - accuracy: 0.87 - ETA: 2:20 - loss: 0.7368 - accuracy: 0.86 - ETA: 2:19 - loss: 0.7087 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6963 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6826 - accuracy: 0.87 - ETA: 2:18 - loss: 0.6480 - accuracy: 0.87 - ETA: 2:18 - loss: 0.6321 - accuracy: 0.87 - ETA: 2:18 - loss: 0.6177 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6285 - accuracy: 0.87 - ETA: 2:16 - loss: 0.6363 - accuracy: 0.87 - ETA: 2:15 - loss: 0.6160 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6214 - accuracy: 0.87 - ETA: 2:13 - loss: 0.6016 - accuracy: 0.88 - ETA: 2:11 - loss: 0.6064 - accuracy: 0.87 - ETA: 2:10 - loss: 0.5917 - accuracy: 0.87 - ETA: 2:10 - loss: 0.5983 - accuracy: 0.88 - ETA: 2:09 - loss: 0.5933 - accuracy: 0.88 - ETA: 2:07 - loss: 0.5822 - accuracy: 0.88 - ETA: 2:06 - loss: 0.5868 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6070 - accuracy: 0.88 - ETA: 2:04 - loss: 0.6420 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6586 - accuracy: 0.87 - ETA: 2:02 - loss: 0.6534 - accuracy: 0.88 - ETA: 2:00 - loss: 0.6535 - accuracy: 0.88 - ETA: 1:59 - loss: 0.6465 - accuracy: 0.88 - ETA: 1:59 - loss: 0.6412 - accuracy: 0.88 - ETA: 1:57 - loss: 0.6356 - accuracy: 0.88 - ETA: 1:56 - loss: 0.6219 - accuracy: 0.88 - ETA: 1:55 - loss: 0.6119 - accuracy: 0.88 - ETA: 1:54 - loss: 0.6151 - accuracy: 0.88 - ETA: 1:53 - loss: 0.6195 - accuracy: 0.88 - ETA: 1:52 - loss: 0.6306 - accuracy: 0.88 - ETA: 1:52 - loss: 0.6274 - accuracy: 0.88 - ETA: 1:51 - loss: 0.6204 - accuracy: 0.88 - ETA: 1:50 - loss: 0.6379 - accuracy: 0.88 - ETA: 1:49 - loss: 0.6437 - accuracy: 0.88 - ETA: 1:48 - loss: 0.6470 - accuracy: 0.88 - ETA: 1:47 - loss: 0.6406 - accuracy: 0.88 - ETA: 1:46 - loss: 0.6369 - accuracy: 0.88 - ETA: 1:45 - loss: 0.6303 - accuracy: 0.88 - ETA: 1:44 - loss: 0.6228 - accuracy: 0.88 - ETA: 1:43 - loss: 0.6217 - accuracy: 0.88 - ETA: 1:42 - loss: 0.6205 - accuracy: 0.88 - ETA: 1:41 - loss: 0.6258 - accuracy: 0.88 - ETA: 1:40 - loss: 0.6317 - accuracy: 0.88 - ETA: 1:39 - loss: 0.6284 - accuracy: 0.88 - ETA: 1:38 - loss: 0.6233 - accuracy: 0.88 - ETA: 1:37 - loss: 0.6243 - accuracy: 0.88 - ETA: 1:36 - loss: 0.6298 - accuracy: 0.88 - ETA: 1:35 - loss: 0.6296 - accuracy: 0.88 - ETA: 1:34 - loss: 0.6325 - accuracy: 0.88 - ETA: 1:33 - loss: 0.6335 - accuracy: 0.88 - ETA: 1:32 - loss: 0.6289 - accuracy: 0.88 - ETA: 1:31 - loss: 0.6314 - accuracy: 0.88 - ETA: 1:30 - loss: 0.6350 - accuracy: 0.88 - ETA: 1:29 - loss: 0.6320 - accuracy: 0.88 - ETA: 1:28 - loss: 0.6429 - accuracy: 0.88 - ETA: 1:27 - loss: 0.6387 - accuracy: 0.88 - ETA: 1:26 - loss: 0.6397 - accuracy: 0.88 - ETA: 1:25 - loss: 0.6483 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6424 - accuracy: 0.88 - ETA: 1:23 - loss: 0.6441 - accuracy: 0.88 - ETA: 1:22 - loss: 0.6408 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6403 - accuracy: 0.88 - ETA: 1:20 - loss: 0.6427 - accuracy: 0.88 - ETA: 1:19 - loss: 0.6381 - accuracy: 0.88 - ETA: 1:19 - loss: 0.6379 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6396 - accuracy: 0.88 - ETA: 1:17 - loss: 0.6341 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6348 - accuracy: 0.88 - ETA: 1:15 - loss: 0.6354 - accuracy: 0.88 - ETA: 1:14 - loss: 0.6348 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6307 - accuracy: 0.88 - ETA: 1:12 - loss: 0.6321 - accuracy: 0.88 - ETA: 1:11 - loss: 0.6278 - accuracy: 0.88 - ETA: 1:10 - loss: 0.6257 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6223 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6237 - accuracy: 0.88 - ETA: 1:07 - loss: 0.6211 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6274 - accuracy: 0.88 - ETA: 1:05 - loss: 0.6258 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6219 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6210 - accuracy: 0.88 - ETA: 1:02 - loss: 0.6202 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6182 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6175 - accuracy: 0.88 - ETA: 1:00 - loss: 0.6166 - accuracy: 0.88 - ETA: 59s - loss: 0.6218 - accuracy: 0.8825 - ETA: 58s - loss: 0.6229 - accuracy: 0.882 - ETA: 57s - loss: 0.6238 - accuracy: 0.882 - ETA: 56s - loss: 0.6219 - accuracy: 0.882 - ETA: 55s - loss: 0.6199 - accuracy: 0.883 - ETA: 54s - loss: 0.6203 - accuracy: 0.883 - ETA: 53s - loss: 0.6215 - accuracy: 0.882 - ETA: 52s - loss: 0.6291 - accuracy: 0.882 - ETA: 51s - loss: 0.6266 - accuracy: 0.882 - ETA: 50s - loss: 0.6278 - accuracy: 0.882 - ETA: 49s - loss: 0.6281 - accuracy: 0.882 - ETA: 48s - loss: 0.6277 - accuracy: 0.882 - ETA: 47s - loss: 0.6275 - accuracy: 0.882 - ETA: 46s - loss: 0.6274 - accuracy: 0.881 - ETA: 45s - loss: 0.6262 - accuracy: 0.881 - ETA: 44s - loss: 0.6297 - accuracy: 0.881 - ETA: 43s - loss: 0.6290 - accuracy: 0.881 - ETA: 42s - loss: 0.6263 - accuracy: 0.881 - ETA: 41s - loss: 0.6244 - accuracy: 0.882 - ETA: 40s - loss: 0.6233 - accuracy: 0.882 - ETA: 39s - loss: 0.6223 - accuracy: 0.882 - ETA: 38s - loss: 0.6218 - accuracy: 0.882 - ETA: 37s - loss: 0.6224 - accuracy: 0.882 - ETA: 37s - loss: 0.6233 - accuracy: 0.883 - ETA: 36s - loss: 0.6276 - accuracy: 0.882 - ETA: 35s - loss: 0.6296 - accuracy: 0.882 - ETA: 34s - loss: 0.6276 - accuracy: 0.882 - ETA: 33s - loss: 0.6299 - accuracy: 0.882 - ETA: 32s - loss: 0.6307 - accuracy: 0.882 - ETA: 31s - loss: 0.6317 - accuracy: 0.882 - ETA: 30s - loss: 0.6331 - accuracy: 0.882 - ETA: 29s - loss: 0.6335 - accuracy: 0.881 - ETA: 28s - loss: 0.6307 - accuracy: 0.882 - ETA: 27s - loss: 0.6299 - accuracy: 0.882 - ETA: 26s - loss: 0.6276 - accuracy: 0.882 - ETA: 25s - loss: 0.6331 - accuracy: 0.882 - ETA: 24s - loss: 0.6330 - accuracy: 0.881 - ETA: 23s - loss: 0.6314 - accuracy: 0.881 - ETA: 22s - loss: 0.6312 - accuracy: 0.881 - ETA: 21s - loss: 0.6307 - accuracy: 0.881 - ETA: 20s - loss: 0.6333 - accuracy: 0.881 - ETA: 19s - loss: 0.6319 - accuracy: 0.881 - ETA: 19s - loss: 0.6339 - accuracy: 0.881 - ETA: 18s - loss: 0.6359 - accuracy: 0.881 - ETA: 17s - loss: 0.6355 - accuracy: 0.881 - ETA: 16s - loss: 0.6370 - accuracy: 0.881 - ETA: 15s - loss: 0.6359 - accuracy: 0.881 - ETA: 14s - loss: 0.6343 - accuracy: 0.881 - ETA: 13s - loss: 0.6331 - accuracy: 0.881 - ETA: 12s - loss: 0.6325 - accuracy: 0.881 - ETA: 11s - loss: 0.6364 - accuracy: 0.881 - ETA: 10s - loss: 0.6384 - accuracy: 0.881 - ETA: 9s - loss: 0.6377 - accuracy: 0.881 - ETA: 8s - loss: 0.6383 - accuracy: 0.88 - ETA: 7s - loss: 0.6370 - accuracy: 0.88 - ETA: 6s - loss: 0.6356 - accuracy: 0.88 - ETA: 5s - loss: 0.6339 - accuracy: 0.88 - ETA: 4s - loss: 0.6317 - accuracy: 0.88 - ETA: 3s - loss: 0.6313 - accuracy: 0.88 - ETA: 2s - loss: 0.6290 - accuracy: 0.88 - ETA: 1s - loss: 0.6291 - accuracy: 0.88 - ETA: 0s - loss: 0.6275 - accuracy: 0.88 - 156s 8ms/step - loss: 0.6295 - accuracy: 0.8827 - val_loss: 4.3059 - val_accuracy: 0.7795\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:23 - loss: 0.9090 - accuracy: 0.89 - ETA: 2:23 - loss: 0.7354 - accuracy: 0.87 - ETA: 2:22 - loss: 0.6985 - accuracy: 0.88 - ETA: 2:22 - loss: 0.6641 - accuracy: 0.89 - ETA: 2:22 - loss: 0.6642 - accuracy: 0.88 - ETA: 2:21 - loss: 0.6341 - accuracy: 0.88 - ETA: 2:20 - loss: 0.6889 - accuracy: 0.87 - ETA: 2:20 - loss: 0.6402 - accuracy: 0.88 - ETA: 2:18 - loss: 0.6311 - accuracy: 0.88 - ETA: 2:16 - loss: 0.6487 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6173 - accuracy: 0.88 - ETA: 2:13 - loss: 0.7119 - accuracy: 0.88 - ETA: 2:12 - loss: 0.7304 - accuracy: 0.88 - ETA: 2:11 - loss: 0.7166 - accuracy: 0.88 - ETA: 2:10 - loss: 0.6948 - accuracy: 0.88 - ETA: 2:09 - loss: 0.6977 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6906 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6674 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6665 - accuracy: 0.88 - ETA: 2:04 - loss: 0.6609 - accuracy: 0.88 - ETA: 2:04 - loss: 0.6502 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6484 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6548 - accuracy: 0.88 - ETA: 2:01 - loss: 0.6753 - accuracy: 0.88 - ETA: 2:00 - loss: 0.6576 - accuracy: 0.88 - ETA: 1:59 - loss: 0.6620 - accuracy: 0.88 - ETA: 1:58 - loss: 0.6526 - accuracy: 0.88 - ETA: 1:58 - loss: 0.6474 - accuracy: 0.88 - ETA: 1:57 - loss: 0.6494 - accuracy: 0.88 - ETA: 1:56 - loss: 0.6464 - accuracy: 0.88 - ETA: 1:55 - loss: 0.6384 - accuracy: 0.88 - ETA: 1:54 - loss: 0.6339 - accuracy: 0.88 - ETA: 1:53 - loss: 0.6260 - accuracy: 0.88 - ETA: 1:51 - loss: 0.6268 - accuracy: 0.88 - ETA: 1:50 - loss: 0.6297 - accuracy: 0.88 - ETA: 1:49 - loss: 0.6269 - accuracy: 0.88 - ETA: 1:49 - loss: 0.6207 - accuracy: 0.88 - ETA: 1:48 - loss: 0.6172 - accuracy: 0.88 - ETA: 1:47 - loss: 0.6111 - accuracy: 0.88 - ETA: 1:46 - loss: 0.6070 - accuracy: 0.88 - ETA: 1:45 - loss: 0.6272 - accuracy: 0.88 - ETA: 1:44 - loss: 0.6248 - accuracy: 0.88 - ETA: 1:43 - loss: 0.6176 - accuracy: 0.88 - ETA: 1:42 - loss: 0.6167 - accuracy: 0.88 - ETA: 1:41 - loss: 0.6204 - accuracy: 0.88 - ETA: 1:40 - loss: 0.6308 - accuracy: 0.88 - ETA: 1:39 - loss: 0.6295 - accuracy: 0.88 - ETA: 1:38 - loss: 0.6366 - accuracy: 0.88 - ETA: 1:37 - loss: 0.6308 - accuracy: 0.88 - ETA: 1:36 - loss: 0.6423 - accuracy: 0.88 - ETA: 1:35 - loss: 0.6456 - accuracy: 0.88 - ETA: 1:34 - loss: 0.6460 - accuracy: 0.88 - ETA: 1:33 - loss: 0.6430 - accuracy: 0.88 - ETA: 1:33 - loss: 0.6483 - accuracy: 0.88 - ETA: 1:32 - loss: 0.6538 - accuracy: 0.88 - ETA: 1:31 - loss: 0.6564 - accuracy: 0.88 - ETA: 1:30 - loss: 0.6510 - accuracy: 0.88 - ETA: 1:29 - loss: 0.6527 - accuracy: 0.88 - ETA: 1:28 - loss: 0.6473 - accuracy: 0.88 - ETA: 1:27 - loss: 0.6415 - accuracy: 0.88 - ETA: 1:26 - loss: 0.6430 - accuracy: 0.88 - ETA: 1:25 - loss: 0.6391 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6350 - accuracy: 0.88 - ETA: 1:23 - loss: 0.6416 - accuracy: 0.88 - ETA: 1:22 - loss: 0.6403 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6488 - accuracy: 0.88 - ETA: 1:20 - loss: 0.6583 - accuracy: 0.88 - ETA: 1:19 - loss: 0.6651 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6643 - accuracy: 0.88 - ETA: 1:17 - loss: 0.6676 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6708 - accuracy: 0.88 - ETA: 1:15 - loss: 0.6697 - accuracy: 0.88 - ETA: 1:14 - loss: 0.6687 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6683 - accuracy: 0.88 - ETA: 1:12 - loss: 0.6641 - accuracy: 0.88 - ETA: 1:12 - loss: 0.6635 - accuracy: 0.88 - ETA: 1:11 - loss: 0.6615 - accuracy: 0.88 - ETA: 1:10 - loss: 0.6643 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6615 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6621 - accuracy: 0.88 - ETA: 1:07 - loss: 0.6614 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6597 - accuracy: 0.88 - ETA: 1:05 - loss: 0.6596 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6587 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6593 - accuracy: 0.88 - ETA: 1:02 - loss: 0.6587 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6612 - accuracy: 0.88 - ETA: 1:00 - loss: 0.6593 - accuracy: 0.88 - ETA: 59s - loss: 0.6636 - accuracy: 0.8824 - ETA: 58s - loss: 0.6629 - accuracy: 0.882 - ETA: 57s - loss: 0.6611 - accuracy: 0.882 - ETA: 56s - loss: 0.6628 - accuracy: 0.882 - ETA: 55s - loss: 0.6621 - accuracy: 0.882 - ETA: 54s - loss: 0.6598 - accuracy: 0.882 - ETA: 53s - loss: 0.6582 - accuracy: 0.882 - ETA: 52s - loss: 0.6557 - accuracy: 0.882 - ETA: 51s - loss: 0.6575 - accuracy: 0.882 - ETA: 50s - loss: 0.6596 - accuracy: 0.882 - ETA: 49s - loss: 0.6590 - accuracy: 0.882 - ETA: 48s - loss: 0.6606 - accuracy: 0.882 - ETA: 47s - loss: 0.6569 - accuracy: 0.882 - ETA: 46s - loss: 0.6577 - accuracy: 0.882 - ETA: 45s - loss: 0.6554 - accuracy: 0.882 - ETA: 44s - loss: 0.6570 - accuracy: 0.882 - ETA: 44s - loss: 0.6574 - accuracy: 0.881 - ETA: 43s - loss: 0.6563 - accuracy: 0.881 - ETA: 42s - loss: 0.6551 - accuracy: 0.881 - ETA: 41s - loss: 0.6562 - accuracy: 0.881 - ETA: 40s - loss: 0.6577 - accuracy: 0.881 - ETA: 39s - loss: 0.6559 - accuracy: 0.881 - ETA: 38s - loss: 0.6597 - accuracy: 0.881 - ETA: 37s - loss: 0.6582 - accuracy: 0.881 - ETA: 36s - loss: 0.6561 - accuracy: 0.881 - ETA: 35s - loss: 0.6538 - accuracy: 0.881 - ETA: 34s - loss: 0.6564 - accuracy: 0.881 - ETA: 33s - loss: 0.6532 - accuracy: 0.881 - ETA: 32s - loss: 0.6522 - accuracy: 0.882 - ETA: 31s - loss: 0.6543 - accuracy: 0.882 - ETA: 30s - loss: 0.6540 - accuracy: 0.881 - ETA: 29s - loss: 0.6529 - accuracy: 0.881 - ETA: 28s - loss: 0.6512 - accuracy: 0.881 - ETA: 27s - loss: 0.6522 - accuracy: 0.881 - ETA: 26s - loss: 0.6500 - accuracy: 0.881 - ETA: 25s - loss: 0.6550 - accuracy: 0.880 - ETA: 24s - loss: 0.6536 - accuracy: 0.881 - ETA: 23s - loss: 0.6534 - accuracy: 0.881 - ETA: 22s - loss: 0.6556 - accuracy: 0.881 - ETA: 21s - loss: 0.6537 - accuracy: 0.881 - ETA: 21s - loss: 0.6551 - accuracy: 0.881 - ETA: 20s - loss: 0.6547 - accuracy: 0.881 - ETA: 19s - loss: 0.6539 - accuracy: 0.881 - ETA: 18s - loss: 0.6597 - accuracy: 0.881 - ETA: 17s - loss: 0.6582 - accuracy: 0.881 - ETA: 16s - loss: 0.6577 - accuracy: 0.881 - ETA: 15s - loss: 0.6569 - accuracy: 0.881 - ETA: 14s - loss: 0.6565 - accuracy: 0.881 - ETA: 13s - loss: 0.6549 - accuracy: 0.881 - ETA: 12s - loss: 0.6546 - accuracy: 0.881 - ETA: 11s - loss: 0.6535 - accuracy: 0.882 - ETA: 10s - loss: 0.6537 - accuracy: 0.882 - ETA: 9s - loss: 0.6528 - accuracy: 0.882 - ETA: 8s - loss: 0.6539 - accuracy: 0.88 - ETA: 7s - loss: 0.6535 - accuracy: 0.88 - ETA: 6s - loss: 0.6533 - accuracy: 0.88 - ETA: 5s - loss: 0.6576 - accuracy: 0.88 - ETA: 4s - loss: 0.6588 - accuracy: 0.88 - ETA: 3s - loss: 0.6569 - accuracy: 0.88 - ETA: 2s - loss: 0.6558 - accuracy: 0.88 - ETA: 1s - loss: 0.6554 - accuracy: 0.88 - ETA: 0s - loss: 0.6569 - accuracy: 0.88 - 156s 8ms/step - loss: 0.6556 - accuracy: 0.8818 - val_loss: 4.3365 - val_accuracy: 0.7821\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:33 - loss: 0.6010 - accuracy: 0.86 - ETA: 2:25 - loss: 0.5927 - accuracy: 0.87 - ETA: 2:22 - loss: 0.5736 - accuracy: 0.88 - ETA: 2:20 - loss: 0.5369 - accuracy: 0.89 - ETA: 2:19 - loss: 0.6363 - accuracy: 0.88 - ETA: 2:17 - loss: 0.6315 - accuracy: 0.88 - ETA: 2:16 - loss: 0.6333 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6471 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6066 - accuracy: 0.89 - ETA: 2:15 - loss: 0.6414 - accuracy: 0.88 - ETA: 2:14 - loss: 0.6884 - accuracy: 0.88 - ETA: 2:13 - loss: 0.6601 - accuracy: 0.88 - ETA: 2:12 - loss: 0.6497 - accuracy: 0.88 - ETA: 2:10 - loss: 0.6420 - accuracy: 0.88 - ETA: 2:09 - loss: 0.6375 - accuracy: 0.88 - ETA: 2:08 - loss: 0.6314 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6179 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6211 - accuracy: 0.87 - ETA: 2:05 - loss: 0.6183 - accuracy: 0.87 - ETA: 2:04 - loss: 0.5993 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6057 - accuracy: 0.88 - ETA: 2:02 - loss: 0.6008 - accuracy: 0.88 - ETA: 2:01 - loss: 0.5941 - accuracy: 0.88 - ETA: 2:00 - loss: 0.5880 - accuracy: 0.88 - ETA: 2:00 - loss: 0.5971 - accuracy: 0.88 - ETA: 1:59 - loss: 0.5967 - accuracy: 0.88 - ETA: 1:59 - loss: 0.5881 - accuracy: 0.88 - ETA: 1:58 - loss: 0.5833 - accuracy: 0.88 - ETA: 1:57 - loss: 0.5781 - accuracy: 0.88 - ETA: 1:56 - loss: 0.5815 - accuracy: 0.88 - ETA: 1:55 - loss: 0.5842 - accuracy: 0.88 - ETA: 1:54 - loss: 0.5970 - accuracy: 0.88 - ETA: 1:53 - loss: 0.6011 - accuracy: 0.88 - ETA: 1:52 - loss: 0.5911 - accuracy: 0.88 - ETA: 1:50 - loss: 0.5881 - accuracy: 0.88 - ETA: 1:49 - loss: 0.6044 - accuracy: 0.88 - ETA: 1:49 - loss: 0.6010 - accuracy: 0.88 - ETA: 1:47 - loss: 0.6142 - accuracy: 0.88 - ETA: 1:46 - loss: 0.6149 - accuracy: 0.88 - ETA: 1:45 - loss: 0.6112 - accuracy: 0.88 - ETA: 1:44 - loss: 0.6100 - accuracy: 0.88 - ETA: 1:44 - loss: 0.6057 - accuracy: 0.88 - ETA: 1:43 - loss: 0.6042 - accuracy: 0.88 - ETA: 1:42 - loss: 0.6017 - accuracy: 0.88 - ETA: 1:41 - loss: 0.6058 - accuracy: 0.88 - ETA: 1:40 - loss: 0.6065 - accuracy: 0.88 - ETA: 1:39 - loss: 0.6042 - accuracy: 0.88 - ETA: 1:38 - loss: 0.6021 - accuracy: 0.88 - ETA: 1:37 - loss: 0.6114 - accuracy: 0.88 - ETA: 1:36 - loss: 0.6143 - accuracy: 0.88 - ETA: 1:35 - loss: 0.6108 - accuracy: 0.88 - ETA: 1:34 - loss: 0.6077 - accuracy: 0.88 - ETA: 1:33 - loss: 0.6059 - accuracy: 0.88 - ETA: 1:32 - loss: 0.6119 - accuracy: 0.88 - ETA: 1:31 - loss: 0.6099 - accuracy: 0.88 - ETA: 1:30 - loss: 0.6063 - accuracy: 0.88 - ETA: 1:29 - loss: 0.6058 - accuracy: 0.88 - ETA: 1:28 - loss: 0.5995 - accuracy: 0.88 - ETA: 1:27 - loss: 0.5984 - accuracy: 0.88 - ETA: 1:26 - loss: 0.5950 - accuracy: 0.88 - ETA: 1:25 - loss: 0.5954 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6024 - accuracy: 0.88 - ETA: 1:23 - loss: 0.6027 - accuracy: 0.88 - ETA: 1:22 - loss: 0.6054 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6017 - accuracy: 0.88 - ETA: 1:20 - loss: 0.6074 - accuracy: 0.88 - ETA: 1:19 - loss: 0.6146 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6135 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6134 - accuracy: 0.88 - ETA: 1:17 - loss: 0.6128 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6084 - accuracy: 0.88 - ETA: 1:15 - loss: 0.6070 - accuracy: 0.88 - ETA: 1:14 - loss: 0.6101 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6150 - accuracy: 0.88 - ETA: 1:12 - loss: 0.6161 - accuracy: 0.88 - ETA: 1:11 - loss: 0.6173 - accuracy: 0.88 - ETA: 1:10 - loss: 0.6143 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6192 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6227 - accuracy: 0.88 - ETA: 1:07 - loss: 0.6207 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6200 - accuracy: 0.88 - ETA: 1:05 - loss: 0.6224 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6224 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6207 - accuracy: 0.88 - ETA: 1:02 - loss: 0.6246 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6221 - accuracy: 0.88 - ETA: 1:00 - loss: 0.6244 - accuracy: 0.88 - ETA: 59s - loss: 0.6289 - accuracy: 0.8828 - ETA: 58s - loss: 0.6355 - accuracy: 0.882 - ETA: 57s - loss: 0.6321 - accuracy: 0.882 - ETA: 56s - loss: 0.6301 - accuracy: 0.883 - ETA: 55s - loss: 0.6309 - accuracy: 0.883 - ETA: 55s - loss: 0.6312 - accuracy: 0.882 - ETA: 54s - loss: 0.6270 - accuracy: 0.883 - ETA: 53s - loss: 0.6259 - accuracy: 0.883 - ETA: 52s - loss: 0.6275 - accuracy: 0.882 - ETA: 51s - loss: 0.6269 - accuracy: 0.882 - ETA: 50s - loss: 0.6333 - accuracy: 0.882 - ETA: 49s - loss: 0.6377 - accuracy: 0.882 - ETA: 48s - loss: 0.6401 - accuracy: 0.881 - ETA: 47s - loss: 0.6400 - accuracy: 0.881 - ETA: 46s - loss: 0.6393 - accuracy: 0.881 - ETA: 45s - loss: 0.6378 - accuracy: 0.881 - ETA: 44s - loss: 0.6375 - accuracy: 0.881 - ETA: 43s - loss: 0.6386 - accuracy: 0.881 - ETA: 42s - loss: 0.6381 - accuracy: 0.881 - ETA: 42s - loss: 0.6369 - accuracy: 0.881 - ETA: 41s - loss: 0.6362 - accuracy: 0.881 - ETA: 40s - loss: 0.6387 - accuracy: 0.881 - ETA: 39s - loss: 0.6375 - accuracy: 0.881 - ETA: 38s - loss: 0.6350 - accuracy: 0.882 - ETA: 38s - loss: 0.6359 - accuracy: 0.881 - ETA: 37s - loss: 0.6366 - accuracy: 0.881 - ETA: 36s - loss: 0.6372 - accuracy: 0.881 - ETA: 35s - loss: 0.6348 - accuracy: 0.881 - ETA: 35s - loss: 0.6327 - accuracy: 0.881 - ETA: 34s - loss: 0.6322 - accuracy: 0.881 - ETA: 33s - loss: 0.6347 - accuracy: 0.881 - ETA: 32s - loss: 0.6341 - accuracy: 0.881 - ETA: 31s - loss: 0.6305 - accuracy: 0.882 - ETA: 30s - loss: 0.6275 - accuracy: 0.882 - ETA: 29s - loss: 0.6303 - accuracy: 0.882 - ETA: 29s - loss: 0.6279 - accuracy: 0.882 - ETA: 28s - loss: 0.6321 - accuracy: 0.882 - ETA: 27s - loss: 0.6368 - accuracy: 0.881 - ETA: 26s - loss: 0.6376 - accuracy: 0.881 - ETA: 25s - loss: 0.6392 - accuracy: 0.881 - ETA: 24s - loss: 0.6413 - accuracy: 0.880 - ETA: 23s - loss: 0.6448 - accuracy: 0.880 - ETA: 22s - loss: 0.6444 - accuracy: 0.880 - ETA: 21s - loss: 0.6504 - accuracy: 0.880 - ETA: 20s - loss: 0.6504 - accuracy: 0.880 - ETA: 19s - loss: 0.6498 - accuracy: 0.880 - ETA: 18s - loss: 0.6490 - accuracy: 0.880 - ETA: 17s - loss: 0.6488 - accuracy: 0.879 - ETA: 16s - loss: 0.6481 - accuracy: 0.880 - ETA: 15s - loss: 0.6470 - accuracy: 0.880 - ETA: 14s - loss: 0.6523 - accuracy: 0.880 - ETA: 13s - loss: 0.6493 - accuracy: 0.880 - ETA: 12s - loss: 0.6506 - accuracy: 0.880 - ETA: 11s - loss: 0.6520 - accuracy: 0.880 - ETA: 9s - loss: 0.6519 - accuracy: 0.880 - ETA: 8s - loss: 0.6545 - accuracy: 0.87 - ETA: 7s - loss: 0.6564 - accuracy: 0.88 - ETA: 6s - loss: 0.6546 - accuracy: 0.88 - ETA: 5s - loss: 0.6589 - accuracy: 0.87 - ETA: 4s - loss: 0.6564 - accuracy: 0.88 - ETA: 3s - loss: 0.6543 - accuracy: 0.88 - ETA: 2s - loss: 0.6551 - accuracy: 0.88 - ETA: 1s - loss: 0.6546 - accuracy: 0.88 - 200s 10ms/step - loss: 0.6537 - accuracy: 0.8800 - val_loss: 4.2464 - val_accuracy: 0.7786\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:19 - loss: 0.7620 - accuracy: 0.85 - ETA: 4:17 - loss: 0.6415 - accuracy: 0.87 - ETA: 4:06 - loss: 0.6752 - accuracy: 0.86 - ETA: 4:08 - loss: 0.6036 - accuracy: 0.88 - ETA: 4:03 - loss: 0.6067 - accuracy: 0.87 - ETA: 3:58 - loss: 0.5580 - accuracy: 0.88 - ETA: 3:59 - loss: 0.5904 - accuracy: 0.88 - ETA: 3:56 - loss: 0.5915 - accuracy: 0.89 - ETA: 3:54 - loss: 0.5909 - accuracy: 0.89 - ETA: 3:51 - loss: 0.5775 - accuracy: 0.89 - ETA: 3:49 - loss: 0.5775 - accuracy: 0.89 - ETA: 3:46 - loss: 0.5805 - accuracy: 0.89 - ETA: 3:46 - loss: 0.6156 - accuracy: 0.88 - ETA: 3:45 - loss: 0.6174 - accuracy: 0.89 - ETA: 3:45 - loss: 0.6011 - accuracy: 0.89 - ETA: 3:44 - loss: 0.6178 - accuracy: 0.88 - ETA: 3:41 - loss: 0.6141 - accuracy: 0.88 - ETA: 3:39 - loss: 0.6014 - accuracy: 0.88 - ETA: 3:38 - loss: 0.5977 - accuracy: 0.88 - ETA: 3:36 - loss: 0.5953 - accuracy: 0.88 - ETA: 3:34 - loss: 0.5994 - accuracy: 0.88 - ETA: 3:33 - loss: 0.5879 - accuracy: 0.88 - ETA: 3:32 - loss: 0.6193 - accuracy: 0.88 - ETA: 3:30 - loss: 0.6097 - accuracy: 0.88 - ETA: 3:30 - loss: 0.6109 - accuracy: 0.88 - ETA: 3:28 - loss: 0.6053 - accuracy: 0.88 - ETA: 3:26 - loss: 0.6155 - accuracy: 0.88 - ETA: 3:25 - loss: 0.6208 - accuracy: 0.88 - ETA: 3:23 - loss: 0.6151 - accuracy: 0.88 - ETA: 3:21 - loss: 0.6103 - accuracy: 0.88 - ETA: 3:20 - loss: 0.6144 - accuracy: 0.88 - ETA: 3:17 - loss: 0.6158 - accuracy: 0.88 - ETA: 3:15 - loss: 0.6177 - accuracy: 0.88 - ETA: 3:14 - loss: 0.6173 - accuracy: 0.88 - ETA: 3:12 - loss: 0.6143 - accuracy: 0.88 - ETA: 3:11 - loss: 0.6157 - accuracy: 0.88 - ETA: 3:09 - loss: 0.6416 - accuracy: 0.88 - ETA: 3:07 - loss: 0.6440 - accuracy: 0.88 - ETA: 3:05 - loss: 0.6411 - accuracy: 0.88 - ETA: 3:04 - loss: 0.6401 - accuracy: 0.87 - ETA: 3:02 - loss: 0.6487 - accuracy: 0.87 - ETA: 3:00 - loss: 0.6445 - accuracy: 0.87 - ETA: 2:59 - loss: 0.6440 - accuracy: 0.87 - ETA: 2:57 - loss: 0.6444 - accuracy: 0.87 - ETA: 2:55 - loss: 0.6499 - accuracy: 0.87 - ETA: 2:54 - loss: 0.6506 - accuracy: 0.87 - ETA: 2:53 - loss: 0.6609 - accuracy: 0.87 - ETA: 2:51 - loss: 0.6586 - accuracy: 0.87 - ETA: 2:49 - loss: 0.6608 - accuracy: 0.87 - ETA: 2:47 - loss: 0.6574 - accuracy: 0.87 - ETA: 2:46 - loss: 0.6521 - accuracy: 0.87 - ETA: 2:44 - loss: 0.6475 - accuracy: 0.87 - ETA: 2:42 - loss: 0.6522 - accuracy: 0.87 - ETA: 2:41 - loss: 0.6599 - accuracy: 0.87 - ETA: 2:39 - loss: 0.6646 - accuracy: 0.87 - ETA: 2:37 - loss: 0.6581 - accuracy: 0.87 - ETA: 2:36 - loss: 0.6580 - accuracy: 0.87 - ETA: 2:34 - loss: 0.6572 - accuracy: 0.87 - ETA: 2:32 - loss: 0.6547 - accuracy: 0.87 - ETA: 2:30 - loss: 0.6533 - accuracy: 0.87 - ETA: 2:29 - loss: 0.6474 - accuracy: 0.87 - ETA: 2:27 - loss: 0.6466 - accuracy: 0.87 - ETA: 2:26 - loss: 0.6483 - accuracy: 0.87 - ETA: 2:24 - loss: 0.6474 - accuracy: 0.87 - ETA: 2:22 - loss: 0.6486 - accuracy: 0.87 - ETA: 2:21 - loss: 0.6482 - accuracy: 0.87 - ETA: 2:19 - loss: 0.6529 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6553 - accuracy: 0.87 - ETA: 2:16 - loss: 0.6538 - accuracy: 0.87 - ETA: 2:14 - loss: 0.6536 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6530 - accuracy: 0.87 - ETA: 2:11 - loss: 0.6518 - accuracy: 0.87 - ETA: 2:09 - loss: 0.6522 - accuracy: 0.87 - ETA: 2:07 - loss: 0.6503 - accuracy: 0.87 - ETA: 2:06 - loss: 0.6521 - accuracy: 0.87 - ETA: 2:04 - loss: 0.6552 - accuracy: 0.87 - ETA: 2:03 - loss: 0.6507 - accuracy: 0.87 - ETA: 2:01 - loss: 0.6497 - accuracy: 0.87 - ETA: 1:59 - loss: 0.6457 - accuracy: 0.87 - ETA: 1:57 - loss: 0.6463 - accuracy: 0.87 - ETA: 1:56 - loss: 0.6449 - accuracy: 0.87 - ETA: 1:54 - loss: 0.6501 - accuracy: 0.87 - ETA: 1:52 - loss: 0.6488 - accuracy: 0.87 - ETA: 1:51 - loss: 0.6541 - accuracy: 0.87 - ETA: 1:49 - loss: 0.6514 - accuracy: 0.87 - ETA: 1:48 - loss: 0.6538 - accuracy: 0.87 - ETA: 1:46 - loss: 0.6553 - accuracy: 0.87 - ETA: 1:44 - loss: 0.6514 - accuracy: 0.87 - ETA: 1:43 - loss: 0.6504 - accuracy: 0.87 - ETA: 1:41 - loss: 0.6586 - accuracy: 0.87 - ETA: 1:39 - loss: 0.6619 - accuracy: 0.87 - ETA: 1:38 - loss: 0.6607 - accuracy: 0.87 - ETA: 1:36 - loss: 0.6589 - accuracy: 0.87 - ETA: 1:34 - loss: 0.6582 - accuracy: 0.87 - ETA: 1:33 - loss: 0.6566 - accuracy: 0.87 - ETA: 1:31 - loss: 0.6556 - accuracy: 0.88 - ETA: 1:29 - loss: 0.6518 - accuracy: 0.88 - ETA: 1:28 - loss: 0.6529 - accuracy: 0.88 - ETA: 1:26 - loss: 0.6504 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6481 - accuracy: 0.88 - ETA: 1:23 - loss: 0.6468 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6494 - accuracy: 0.88 - ETA: 1:19 - loss: 0.6489 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6461 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6456 - accuracy: 0.88 - ETA: 1:14 - loss: 0.6443 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6418 - accuracy: 0.88 - ETA: 1:11 - loss: 0.6412 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6422 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6436 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6430 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6444 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6489 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6549 - accuracy: 0.88 - ETA: 59s - loss: 0.6518 - accuracy: 0.8806 - ETA: 58s - loss: 0.6570 - accuracy: 0.880 - ETA: 56s - loss: 0.6553 - accuracy: 0.880 - ETA: 54s - loss: 0.6552 - accuracy: 0.880 - ETA: 53s - loss: 0.6541 - accuracy: 0.880 - ETA: 51s - loss: 0.6531 - accuracy: 0.880 - ETA: 49s - loss: 0.6512 - accuracy: 0.880 - ETA: 48s - loss: 0.6532 - accuracy: 0.880 - ETA: 46s - loss: 0.6516 - accuracy: 0.880 - ETA: 44s - loss: 0.6539 - accuracy: 0.880 - ETA: 43s - loss: 0.6540 - accuracy: 0.879 - ETA: 41s - loss: 0.6527 - accuracy: 0.880 - ETA: 39s - loss: 0.6519 - accuracy: 0.879 - ETA: 38s - loss: 0.6520 - accuracy: 0.879 - ETA: 36s - loss: 0.6501 - accuracy: 0.879 - ETA: 34s - loss: 0.6508 - accuracy: 0.880 - ETA: 33s - loss: 0.6497 - accuracy: 0.880 - ETA: 31s - loss: 0.6494 - accuracy: 0.880 - ETA: 29s - loss: 0.6489 - accuracy: 0.880 - ETA: 28s - loss: 0.6475 - accuracy: 0.880 - ETA: 26s - loss: 0.6510 - accuracy: 0.880 - ETA: 24s - loss: 0.6480 - accuracy: 0.880 - ETA: 23s - loss: 0.6457 - accuracy: 0.880 - ETA: 21s - loss: 0.6444 - accuracy: 0.881 - ETA: 19s - loss: 0.6425 - accuracy: 0.881 - ETA: 18s - loss: 0.6425 - accuracy: 0.881 - ETA: 16s - loss: 0.6443 - accuracy: 0.881 - ETA: 14s - loss: 0.6433 - accuracy: 0.881 - ETA: 13s - loss: 0.6464 - accuracy: 0.881 - ETA: 11s - loss: 0.6445 - accuracy: 0.881 - ETA: 9s - loss: 0.6436 - accuracy: 0.881 - ETA: 8s - loss: 0.6440 - accuracy: 0.88 - ETA: 6s - loss: 0.6423 - accuracy: 0.88 - ETA: 4s - loss: 0.6406 - accuracy: 0.88 - ETA: 3s - loss: 0.6398 - accuracy: 0.88 - ETA: 1s - loss: 0.6377 - accuracy: 0.88 - 277s 14ms/step - loss: 0.6362 - accuracy: 0.8823 - val_loss: 4.2578 - val_accuracy: 0.7780\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:07 - loss: 0.8824 - accuracy: 0.88 - ETA: 4:04 - loss: 0.6604 - accuracy: 0.89 - ETA: 4:01 - loss: 0.6606 - accuracy: 0.87 - ETA: 3:56 - loss: 0.5374 - accuracy: 0.89 - ETA: 3:55 - loss: 0.5878 - accuracy: 0.89 - ETA: 4:00 - loss: 0.5632 - accuracy: 0.89 - ETA: 3:59 - loss: 0.5367 - accuracy: 0.89 - ETA: 3:56 - loss: 0.5452 - accuracy: 0.88 - ETA: 3:56 - loss: 0.5321 - accuracy: 0.88 - ETA: 3:54 - loss: 0.5270 - accuracy: 0.88 - ETA: 3:51 - loss: 0.5444 - accuracy: 0.88 - ETA: 3:47 - loss: 0.5668 - accuracy: 0.88 - ETA: 3:46 - loss: 0.5587 - accuracy: 0.88 - ETA: 3:42 - loss: 0.5697 - accuracy: 0.88 - ETA: 3:42 - loss: 0.5830 - accuracy: 0.88 - ETA: 3:39 - loss: 0.5735 - accuracy: 0.87 - ETA: 3:37 - loss: 0.5805 - accuracy: 0.88 - ETA: 3:35 - loss: 0.5927 - accuracy: 0.88 - ETA: 3:32 - loss: 0.5983 - accuracy: 0.87 - ETA: 3:30 - loss: 0.6217 - accuracy: 0.87 - ETA: 3:29 - loss: 0.6309 - accuracy: 0.87 - ETA: 3:27 - loss: 0.6211 - accuracy: 0.88 - ETA: 3:26 - loss: 0.6060 - accuracy: 0.88 - ETA: 3:24 - loss: 0.6007 - accuracy: 0.88 - ETA: 3:22 - loss: 0.5971 - accuracy: 0.88 - ETA: 3:21 - loss: 0.6031 - accuracy: 0.88 - ETA: 3:20 - loss: 0.6153 - accuracy: 0.88 - ETA: 3:18 - loss: 0.6054 - accuracy: 0.88 - ETA: 3:16 - loss: 0.5986 - accuracy: 0.88 - ETA: 3:15 - loss: 0.5990 - accuracy: 0.88 - ETA: 3:14 - loss: 0.6148 - accuracy: 0.88 - ETA: 3:13 - loss: 0.6120 - accuracy: 0.88 - ETA: 3:11 - loss: 0.6098 - accuracy: 0.88 - ETA: 3:08 - loss: 0.6188 - accuracy: 0.88 - ETA: 3:07 - loss: 0.6209 - accuracy: 0.88 - ETA: 3:05 - loss: 0.6259 - accuracy: 0.88 - ETA: 3:04 - loss: 0.6203 - accuracy: 0.88 - ETA: 3:02 - loss: 0.6170 - accuracy: 0.88 - ETA: 3:00 - loss: 0.6236 - accuracy: 0.87 - ETA: 3:00 - loss: 0.6272 - accuracy: 0.87 - ETA: 2:58 - loss: 0.6284 - accuracy: 0.87 - ETA: 2:57 - loss: 0.6520 - accuracy: 0.87 - ETA: 2:55 - loss: 0.6469 - accuracy: 0.87 - ETA: 2:53 - loss: 0.6458 - accuracy: 0.87 - ETA: 2:51 - loss: 0.6476 - accuracy: 0.87 - ETA: 2:50 - loss: 0.6495 - accuracy: 0.87 - ETA: 2:49 - loss: 0.6497 - accuracy: 0.87 - ETA: 2:47 - loss: 0.6456 - accuracy: 0.87 - ETA: 2:46 - loss: 0.6422 - accuracy: 0.87 - ETA: 2:44 - loss: 0.6383 - accuracy: 0.87 - ETA: 2:42 - loss: 0.6415 - accuracy: 0.87 - ETA: 2:40 - loss: 0.6386 - accuracy: 0.87 - ETA: 2:39 - loss: 0.6456 - accuracy: 0.87 - ETA: 2:37 - loss: 0.6421 - accuracy: 0.87 - ETA: 2:35 - loss: 0.6391 - accuracy: 0.87 - ETA: 2:34 - loss: 0.6409 - accuracy: 0.87 - ETA: 2:32 - loss: 0.6448 - accuracy: 0.87 - ETA: 2:30 - loss: 0.6402 - accuracy: 0.87 - ETA: 2:29 - loss: 0.6371 - accuracy: 0.87 - ETA: 2:27 - loss: 0.6444 - accuracy: 0.87 - ETA: 2:25 - loss: 0.6440 - accuracy: 0.87 - ETA: 2:24 - loss: 0.6454 - accuracy: 0.87 - ETA: 2:22 - loss: 0.6448 - accuracy: 0.87 - ETA: 2:20 - loss: 0.6445 - accuracy: 0.87 - ETA: 2:19 - loss: 0.6466 - accuracy: 0.87 - ETA: 2:17 - loss: 0.6476 - accuracy: 0.87 - ETA: 2:16 - loss: 0.6445 - accuracy: 0.87 - ETA: 2:14 - loss: 0.6398 - accuracy: 0.87 - ETA: 2:12 - loss: 0.6386 - accuracy: 0.88 - ETA: 2:11 - loss: 0.6412 - accuracy: 0.87 - ETA: 2:09 - loss: 0.6436 - accuracy: 0.88 - ETA: 2:08 - loss: 0.6462 - accuracy: 0.88 - ETA: 2:06 - loss: 0.6468 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6452 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6412 - accuracy: 0.88 - ETA: 2:01 - loss: 0.6391 - accuracy: 0.88 - ETA: 2:00 - loss: 0.6424 - accuracy: 0.88 - ETA: 1:58 - loss: 0.6414 - accuracy: 0.88 - ETA: 1:56 - loss: 0.6381 - accuracy: 0.88 - ETA: 1:55 - loss: 0.6392 - accuracy: 0.88 - ETA: 1:53 - loss: 0.6381 - accuracy: 0.88 - ETA: 1:52 - loss: 0.6350 - accuracy: 0.88 - ETA: 1:50 - loss: 0.6322 - accuracy: 0.88 - ETA: 1:49 - loss: 0.6336 - accuracy: 0.88 - ETA: 1:47 - loss: 0.6310 - accuracy: 0.88 - ETA: 1:45 - loss: 0.6288 - accuracy: 0.88 - ETA: 1:44 - loss: 0.6290 - accuracy: 0.88 - ETA: 1:42 - loss: 0.6333 - accuracy: 0.88 - ETA: 1:41 - loss: 0.6345 - accuracy: 0.88 - ETA: 1:39 - loss: 0.6350 - accuracy: 0.88 - ETA: 1:37 - loss: 0.6415 - accuracy: 0.88 - ETA: 1:36 - loss: 0.6383 - accuracy: 0.88 - ETA: 1:34 - loss: 0.6396 - accuracy: 0.88 - ETA: 1:33 - loss: 0.6355 - accuracy: 0.88 - ETA: 1:31 - loss: 0.6330 - accuracy: 0.88 - ETA: 1:29 - loss: 0.6326 - accuracy: 0.88 - ETA: 1:28 - loss: 0.6317 - accuracy: 0.88 - ETA: 1:26 - loss: 0.6333 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6323 - accuracy: 0.88 - ETA: 1:23 - loss: 0.6305 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6329 - accuracy: 0.88 - ETA: 1:20 - loss: 0.6383 - accuracy: 0.87 - ETA: 1:18 - loss: 0.6353 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6368 - accuracy: 0.88 - ETA: 1:15 - loss: 0.6430 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6391 - accuracy: 0.88 - ETA: 1:12 - loss: 0.6393 - accuracy: 0.88 - ETA: 1:10 - loss: 0.6379 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6357 - accuracy: 0.88 - ETA: 1:07 - loss: 0.6329 - accuracy: 0.88 - ETA: 1:05 - loss: 0.6311 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6327 - accuracy: 0.88 - ETA: 1:02 - loss: 0.6312 - accuracy: 0.88 - ETA: 1:00 - loss: 0.6305 - accuracy: 0.88 - ETA: 58s - loss: 0.6292 - accuracy: 0.8815 - ETA: 57s - loss: 0.6270 - accuracy: 0.881 - ETA: 55s - loss: 0.6288 - accuracy: 0.881 - ETA: 53s - loss: 0.6273 - accuracy: 0.881 - ETA: 52s - loss: 0.6263 - accuracy: 0.882 - ETA: 50s - loss: 0.6298 - accuracy: 0.881 - ETA: 49s - loss: 0.6302 - accuracy: 0.881 - ETA: 47s - loss: 0.6293 - accuracy: 0.882 - ETA: 45s - loss: 0.6312 - accuracy: 0.882 - ETA: 44s - loss: 0.6299 - accuracy: 0.882 - ETA: 42s - loss: 0.6325 - accuracy: 0.882 - ETA: 40s - loss: 0.6318 - accuracy: 0.882 - ETA: 39s - loss: 0.6295 - accuracy: 0.883 - ETA: 37s - loss: 0.6284 - accuracy: 0.883 - ETA: 36s - loss: 0.6289 - accuracy: 0.882 - ETA: 34s - loss: 0.6289 - accuracy: 0.882 - ETA: 32s - loss: 0.6274 - accuracy: 0.882 - ETA: 31s - loss: 0.6294 - accuracy: 0.882 - ETA: 29s - loss: 0.6278 - accuracy: 0.882 - ETA: 27s - loss: 0.6262 - accuracy: 0.883 - ETA: 26s - loss: 0.6266 - accuracy: 0.883 - ETA: 24s - loss: 0.6255 - accuracy: 0.883 - ETA: 22s - loss: 0.6228 - accuracy: 0.883 - ETA: 21s - loss: 0.6249 - accuracy: 0.883 - ETA: 19s - loss: 0.6237 - accuracy: 0.883 - ETA: 17s - loss: 0.6228 - accuracy: 0.883 - ETA: 16s - loss: 0.6222 - accuracy: 0.883 - ETA: 14s - loss: 0.6236 - accuracy: 0.883 - ETA: 13s - loss: 0.6243 - accuracy: 0.883 - ETA: 11s - loss: 0.6220 - accuracy: 0.883 - ETA: 9s - loss: 0.6210 - accuracy: 0.883 - ETA: 8s - loss: 0.6200 - accuracy: 0.88 - ETA: 6s - loss: 0.6182 - accuracy: 0.88 - ETA: 4s - loss: 0.6189 - accuracy: 0.88 - ETA: 3s - loss: 0.6222 - accuracy: 0.88 - ETA: 1s - loss: 0.6231 - accuracy: 0.88 - 275s 14ms/step - loss: 0.6213 - accuracy: 0.8836 - val_loss: 4.4897 - val_accuracy: 0.7782\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:32 - loss: 0.6594 - accuracy: 0.89 - ETA: 4:09 - loss: 0.9413 - accuracy: 0.87 - ETA: 4:08 - loss: 0.9403 - accuracy: 0.87 - ETA: 4:05 - loss: 0.8532 - accuracy: 0.87 - ETA: 4:05 - loss: 0.7808 - accuracy: 0.87 - ETA: 4:01 - loss: 0.7331 - accuracy: 0.86 - ETA: 3:59 - loss: 0.6812 - accuracy: 0.87 - ETA: 3:54 - loss: 0.6881 - accuracy: 0.87 - ETA: 3:55 - loss: 0.6704 - accuracy: 0.87 - ETA: 3:52 - loss: 0.6547 - accuracy: 0.87 - ETA: 3:51 - loss: 0.6540 - accuracy: 0.87 - ETA: 3:50 - loss: 0.6705 - accuracy: 0.87 - ETA: 3:47 - loss: 0.6570 - accuracy: 0.87 - ETA: 3:46 - loss: 0.6700 - accuracy: 0.87 - ETA: 3:44 - loss: 0.6468 - accuracy: 0.87 - ETA: 3:41 - loss: 0.6292 - accuracy: 0.87 - ETA: 3:39 - loss: 0.6207 - accuracy: 0.87 - ETA: 3:38 - loss: 0.6382 - accuracy: 0.87 - ETA: 3:37 - loss: 0.6288 - accuracy: 0.87 - ETA: 3:35 - loss: 0.6306 - accuracy: 0.87 - ETA: 3:34 - loss: 0.6320 - accuracy: 0.87 - ETA: 3:32 - loss: 0.6173 - accuracy: 0.87 - ETA: 3:31 - loss: 0.6118 - accuracy: 0.88 - ETA: 3:29 - loss: 0.5990 - accuracy: 0.88 - ETA: 3:27 - loss: 0.5995 - accuracy: 0.88 - ETA: 3:25 - loss: 0.6206 - accuracy: 0.88 - ETA: 3:24 - loss: 0.6154 - accuracy: 0.88 - ETA: 3:23 - loss: 0.6408 - accuracy: 0.88 - ETA: 3:21 - loss: 0.6358 - accuracy: 0.88 - ETA: 3:20 - loss: 0.6356 - accuracy: 0.88 - ETA: 3:19 - loss: 0.6335 - accuracy: 0.88 - ETA: 3:17 - loss: 0.6232 - accuracy: 0.88 - ETA: 3:16 - loss: 0.6357 - accuracy: 0.88 - ETA: 3:14 - loss: 0.6337 - accuracy: 0.88 - ETA: 3:12 - loss: 0.6256 - accuracy: 0.88 - ETA: 3:11 - loss: 0.6188 - accuracy: 0.88 - ETA: 3:10 - loss: 0.6174 - accuracy: 0.88 - ETA: 3:08 - loss: 0.6088 - accuracy: 0.88 - ETA: 3:06 - loss: 0.6007 - accuracy: 0.88 - ETA: 3:04 - loss: 0.6049 - accuracy: 0.88 - ETA: 3:02 - loss: 0.6025 - accuracy: 0.88 - ETA: 3:01 - loss: 0.6092 - accuracy: 0.88 - ETA: 2:59 - loss: 0.6062 - accuracy: 0.88 - ETA: 2:57 - loss: 0.6054 - accuracy: 0.89 - ETA: 2:56 - loss: 0.6036 - accuracy: 0.88 - ETA: 2:54 - loss: 0.6010 - accuracy: 0.88 - ETA: 2:52 - loss: 0.5931 - accuracy: 0.89 - ETA: 2:50 - loss: 0.5926 - accuracy: 0.89 - ETA: 2:48 - loss: 0.5903 - accuracy: 0.89 - ETA: 2:47 - loss: 0.5870 - accuracy: 0.89 - ETA: 2:45 - loss: 0.5991 - accuracy: 0.89 - ETA: 2:44 - loss: 0.6004 - accuracy: 0.89 - ETA: 2:42 - loss: 0.6108 - accuracy: 0.88 - ETA: 2:40 - loss: 0.6117 - accuracy: 0.88 - ETA: 2:39 - loss: 0.6108 - accuracy: 0.88 - ETA: 2:37 - loss: 0.6070 - accuracy: 0.88 - ETA: 2:35 - loss: 0.6046 - accuracy: 0.88 - ETA: 2:33 - loss: 0.6004 - accuracy: 0.88 - ETA: 2:32 - loss: 0.6057 - accuracy: 0.88 - ETA: 2:30 - loss: 0.6171 - accuracy: 0.88 - ETA: 2:28 - loss: 0.6186 - accuracy: 0.88 - ETA: 2:27 - loss: 0.6206 - accuracy: 0.88 - ETA: 2:25 - loss: 0.6278 - accuracy: 0.88 - ETA: 2:23 - loss: 0.6262 - accuracy: 0.88 - ETA: 2:22 - loss: 0.6309 - accuracy: 0.88 - ETA: 2:20 - loss: 0.6332 - accuracy: 0.88 - ETA: 2:18 - loss: 0.6329 - accuracy: 0.88 - ETA: 2:17 - loss: 0.6324 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6316 - accuracy: 0.88 - ETA: 2:13 - loss: 0.6346 - accuracy: 0.88 - ETA: 2:12 - loss: 0.6334 - accuracy: 0.88 - ETA: 2:10 - loss: 0.6298 - accuracy: 0.88 - ETA: 2:08 - loss: 0.6319 - accuracy: 0.88 - ETA: 2:07 - loss: 0.6372 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6360 - accuracy: 0.88 - ETA: 2:04 - loss: 0.6364 - accuracy: 0.88 - ETA: 2:02 - loss: 0.6393 - accuracy: 0.88 - ETA: 2:00 - loss: 0.6365 - accuracy: 0.88 - ETA: 1:59 - loss: 0.6350 - accuracy: 0.88 - ETA: 1:57 - loss: 0.6325 - accuracy: 0.88 - ETA: 1:55 - loss: 0.6296 - accuracy: 0.88 - ETA: 1:54 - loss: 0.6298 - accuracy: 0.88 - ETA: 1:52 - loss: 0.6304 - accuracy: 0.88 - ETA: 1:50 - loss: 0.6334 - accuracy: 0.88 - ETA: 1:49 - loss: 0.6440 - accuracy: 0.88 - ETA: 1:47 - loss: 0.6473 - accuracy: 0.88 - ETA: 1:46 - loss: 0.6464 - accuracy: 0.88 - ETA: 1:44 - loss: 0.6434 - accuracy: 0.88 - ETA: 1:42 - loss: 0.6486 - accuracy: 0.88 - ETA: 1:40 - loss: 0.6461 - accuracy: 0.88 - ETA: 1:39 - loss: 0.6476 - accuracy: 0.88 - ETA: 1:37 - loss: 0.6482 - accuracy: 0.87 - ETA: 1:35 - loss: 0.6495 - accuracy: 0.88 - ETA: 1:34 - loss: 0.6506 - accuracy: 0.88 - ETA: 1:32 - loss: 0.6586 - accuracy: 0.88 - ETA: 1:30 - loss: 0.6553 - accuracy: 0.88 - ETA: 1:29 - loss: 0.6546 - accuracy: 0.88 - ETA: 1:27 - loss: 0.6512 - accuracy: 0.88 - ETA: 1:25 - loss: 0.6512 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6482 - accuracy: 0.88 - ETA: 1:22 - loss: 0.6458 - accuracy: 0.88 - ETA: 1:20 - loss: 0.6456 - accuracy: 0.88 - ETA: 1:19 - loss: 0.6452 - accuracy: 0.88 - ETA: 1:17 - loss: 0.6441 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6437 - accuracy: 0.88 - ETA: 1:14 - loss: 0.6419 - accuracy: 0.88 - ETA: 1:12 - loss: 0.6424 - accuracy: 0.88 - ETA: 1:11 - loss: 0.6441 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6429 - accuracy: 0.88 - ETA: 1:07 - loss: 0.6434 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6458 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6438 - accuracy: 0.88 - ETA: 1:02 - loss: 0.6457 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6454 - accuracy: 0.88 - ETA: 59s - loss: 0.6452 - accuracy: 0.8813 - ETA: 57s - loss: 0.6468 - accuracy: 0.881 - ETA: 56s - loss: 0.6483 - accuracy: 0.881 - ETA: 54s - loss: 0.6467 - accuracy: 0.881 - ETA: 52s - loss: 0.6438 - accuracy: 0.881 - ETA: 51s - loss: 0.6436 - accuracy: 0.881 - ETA: 49s - loss: 0.6414 - accuracy: 0.881 - ETA: 47s - loss: 0.6394 - accuracy: 0.881 - ETA: 46s - loss: 0.6390 - accuracy: 0.881 - ETA: 44s - loss: 0.6406 - accuracy: 0.881 - ETA: 42s - loss: 0.6392 - accuracy: 0.881 - ETA: 41s - loss: 0.6414 - accuracy: 0.880 - ETA: 39s - loss: 0.6387 - accuracy: 0.881 - ETA: 37s - loss: 0.6404 - accuracy: 0.880 - ETA: 36s - loss: 0.6382 - accuracy: 0.881 - ETA: 34s - loss: 0.6401 - accuracy: 0.881 - ETA: 33s - loss: 0.6412 - accuracy: 0.881 - ETA: 31s - loss: 0.6408 - accuracy: 0.881 - ETA: 29s - loss: 0.6424 - accuracy: 0.881 - ETA: 28s - loss: 0.6409 - accuracy: 0.881 - ETA: 26s - loss: 0.6421 - accuracy: 0.881 - ETA: 24s - loss: 0.6403 - accuracy: 0.881 - ETA: 23s - loss: 0.6401 - accuracy: 0.881 - ETA: 21s - loss: 0.6396 - accuracy: 0.881 - ETA: 19s - loss: 0.6405 - accuracy: 0.881 - ETA: 18s - loss: 0.6381 - accuracy: 0.881 - ETA: 16s - loss: 0.6386 - accuracy: 0.881 - ETA: 14s - loss: 0.6384 - accuracy: 0.881 - ETA: 13s - loss: 0.6356 - accuracy: 0.882 - ETA: 11s - loss: 0.6367 - accuracy: 0.881 - ETA: 9s - loss: 0.6369 - accuracy: 0.882 - ETA: 8s - loss: 0.6384 - accuracy: 0.88 - ETA: 6s - loss: 0.6375 - accuracy: 0.88 - ETA: 4s - loss: 0.6363 - accuracy: 0.88 - ETA: 3s - loss: 0.6389 - accuracy: 0.88 - ETA: 1s - loss: 0.6406 - accuracy: 0.88 - 276s 14ms/step - loss: 0.6403 - accuracy: 0.8813 - val_loss: 4.3356 - val_accuracy: 0.7790\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:37 - loss: 0.8891 - accuracy: 0.89 - ETA: 3:54 - loss: 0.6450 - accuracy: 0.89 - ETA: 3:53 - loss: 0.6013 - accuracy: 0.88 - ETA: 3:52 - loss: 0.6554 - accuracy: 0.87 - ETA: 3:53 - loss: 0.7187 - accuracy: 0.87 - ETA: 3:52 - loss: 0.7193 - accuracy: 0.87 - ETA: 3:50 - loss: 0.7055 - accuracy: 0.87 - ETA: 3:48 - loss: 0.6666 - accuracy: 0.87 - ETA: 3:51 - loss: 0.6705 - accuracy: 0.87 - ETA: 3:49 - loss: 0.6551 - accuracy: 0.87 - ETA: 3:48 - loss: 0.6961 - accuracy: 0.87 - ETA: 3:47 - loss: 0.6872 - accuracy: 0.87 - ETA: 3:45 - loss: 0.6778 - accuracy: 0.87 - ETA: 3:45 - loss: 0.6612 - accuracy: 0.87 - ETA: 3:43 - loss: 0.6695 - accuracy: 0.87 - ETA: 3:41 - loss: 0.6633 - accuracy: 0.87 - ETA: 3:38 - loss: 0.6603 - accuracy: 0.87 - ETA: 3:38 - loss: 0.6434 - accuracy: 0.87 - ETA: 3:35 - loss: 0.6412 - accuracy: 0.87 - ETA: 3:35 - loss: 0.6292 - accuracy: 0.88 - ETA: 3:34 - loss: 0.6207 - accuracy: 0.88 - ETA: 3:32 - loss: 0.6217 - accuracy: 0.88 - ETA: 3:30 - loss: 0.6244 - accuracy: 0.88 - ETA: 3:29 - loss: 0.6322 - accuracy: 0.88 - ETA: 3:28 - loss: 0.6264 - accuracy: 0.88 - ETA: 3:26 - loss: 0.6286 - accuracy: 0.88 - ETA: 3:25 - loss: 0.6487 - accuracy: 0.87 - ETA: 3:23 - loss: 0.6619 - accuracy: 0.87 - ETA: 3:22 - loss: 0.6601 - accuracy: 0.87 - ETA: 3:20 - loss: 0.6538 - accuracy: 0.87 - ETA: 3:19 - loss: 0.6481 - accuracy: 0.87 - ETA: 3:17 - loss: 0.6463 - accuracy: 0.87 - ETA: 3:15 - loss: 0.6465 - accuracy: 0.87 - ETA: 3:13 - loss: 0.6458 - accuracy: 0.87 - ETA: 3:12 - loss: 0.6463 - accuracy: 0.87 - ETA: 3:10 - loss: 0.6727 - accuracy: 0.87 - ETA: 3:08 - loss: 0.6677 - accuracy: 0.87 - ETA: 3:07 - loss: 0.6622 - accuracy: 0.87 - ETA: 3:05 - loss: 0.6562 - accuracy: 0.87 - ETA: 3:03 - loss: 0.6532 - accuracy: 0.87 - ETA: 3:01 - loss: 0.6424 - accuracy: 0.87 - ETA: 2:59 - loss: 0.6413 - accuracy: 0.87 - ETA: 2:58 - loss: 0.6391 - accuracy: 0.88 - ETA: 2:56 - loss: 0.6320 - accuracy: 0.88 - ETA: 2:55 - loss: 0.6270 - accuracy: 0.88 - ETA: 2:53 - loss: 0.6282 - accuracy: 0.88 - ETA: 2:52 - loss: 0.6303 - accuracy: 0.88 - ETA: 2:50 - loss: 0.6256 - accuracy: 0.88 - ETA: 2:48 - loss: 0.6254 - accuracy: 0.88 - ETA: 2:46 - loss: 0.6223 - accuracy: 0.88 - ETA: 2:45 - loss: 0.6216 - accuracy: 0.88 - ETA: 2:43 - loss: 0.6262 - accuracy: 0.88 - ETA: 2:41 - loss: 0.6220 - accuracy: 0.88 - ETA: 2:40 - loss: 0.6280 - accuracy: 0.88 - ETA: 2:38 - loss: 0.6239 - accuracy: 0.88 - ETA: 2:36 - loss: 0.6273 - accuracy: 0.88 - ETA: 2:35 - loss: 0.6255 - accuracy: 0.88 - ETA: 2:33 - loss: 0.6235 - accuracy: 0.88 - ETA: 2:31 - loss: 0.6219 - accuracy: 0.88 - ETA: 2:30 - loss: 0.6183 - accuracy: 0.88 - ETA: 2:28 - loss: 0.6165 - accuracy: 0.88 - ETA: 2:26 - loss: 0.6239 - accuracy: 0.88 - ETA: 2:25 - loss: 0.6192 - accuracy: 0.88 - ETA: 2:23 - loss: 0.6164 - accuracy: 0.88 - ETA: 2:21 - loss: 0.6168 - accuracy: 0.88 - ETA: 2:20 - loss: 0.6140 - accuracy: 0.88 - ETA: 2:18 - loss: 0.6284 - accuracy: 0.88 - ETA: 2:16 - loss: 0.6246 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6190 - accuracy: 0.88 - ETA: 2:13 - loss: 0.6162 - accuracy: 0.88 - ETA: 2:12 - loss: 0.6202 - accuracy: 0.88 - ETA: 2:10 - loss: 0.6159 - accuracy: 0.88 - ETA: 2:08 - loss: 0.6155 - accuracy: 0.88 - ETA: 2:07 - loss: 0.6104 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6153 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6180 - accuracy: 0.88 - ETA: 2:02 - loss: 0.6214 - accuracy: 0.88 - ETA: 2:00 - loss: 0.6217 - accuracy: 0.88 - ETA: 1:58 - loss: 0.6233 - accuracy: 0.88 - ETA: 1:57 - loss: 0.6200 - accuracy: 0.88 - ETA: 1:55 - loss: 0.6200 - accuracy: 0.88 - ETA: 1:53 - loss: 0.6199 - accuracy: 0.88 - ETA: 1:52 - loss: 0.6192 - accuracy: 0.88 - ETA: 1:50 - loss: 0.6174 - accuracy: 0.88 - ETA: 1:48 - loss: 0.6166 - accuracy: 0.88 - ETA: 1:47 - loss: 0.6157 - accuracy: 0.88 - ETA: 1:45 - loss: 0.6156 - accuracy: 0.88 - ETA: 1:43 - loss: 0.6186 - accuracy: 0.88 - ETA: 1:42 - loss: 0.6186 - accuracy: 0.88 - ETA: 1:40 - loss: 0.6182 - accuracy: 0.88 - ETA: 1:38 - loss: 0.6199 - accuracy: 0.88 - ETA: 1:37 - loss: 0.6187 - accuracy: 0.88 - ETA: 1:35 - loss: 0.6189 - accuracy: 0.88 - ETA: 1:34 - loss: 0.6171 - accuracy: 0.88 - ETA: 1:32 - loss: 0.6192 - accuracy: 0.88 - ETA: 1:30 - loss: 0.6193 - accuracy: 0.88 - ETA: 1:29 - loss: 0.6172 - accuracy: 0.88 - ETA: 1:27 - loss: 0.6162 - accuracy: 0.88 - ETA: 1:25 - loss: 0.6149 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6175 - accuracy: 0.88 - ETA: 1:22 - loss: 0.6183 - accuracy: 0.87 - ETA: 1:20 - loss: 0.6233 - accuracy: 0.87 - ETA: 1:19 - loss: 0.6243 - accuracy: 0.87 - ETA: 1:17 - loss: 0.6220 - accuracy: 0.87 - ETA: 1:16 - loss: 0.6240 - accuracy: 0.87 - ETA: 1:14 - loss: 0.6239 - accuracy: 0.87 - ETA: 1:12 - loss: 0.6250 - accuracy: 0.87 - ETA: 1:10 - loss: 0.6257 - accuracy: 0.87 - ETA: 1:09 - loss: 0.6263 - accuracy: 0.87 - ETA: 1:07 - loss: 0.6251 - accuracy: 0.87 - ETA: 1:06 - loss: 0.6241 - accuracy: 0.87 - ETA: 1:04 - loss: 0.6227 - accuracy: 0.87 - ETA: 1:02 - loss: 0.6239 - accuracy: 0.87 - ETA: 1:01 - loss: 0.6214 - accuracy: 0.88 - ETA: 59s - loss: 0.6204 - accuracy: 0.8800 - ETA: 57s - loss: 0.6204 - accuracy: 0.879 - ETA: 56s - loss: 0.6264 - accuracy: 0.879 - ETA: 54s - loss: 0.6273 - accuracy: 0.879 - ETA: 52s - loss: 0.6237 - accuracy: 0.879 - ETA: 51s - loss: 0.6243 - accuracy: 0.879 - ETA: 49s - loss: 0.6237 - accuracy: 0.880 - ETA: 47s - loss: 0.6264 - accuracy: 0.879 - ETA: 46s - loss: 0.6257 - accuracy: 0.879 - ETA: 44s - loss: 0.6236 - accuracy: 0.879 - ETA: 42s - loss: 0.6228 - accuracy: 0.880 - ETA: 41s - loss: 0.6213 - accuracy: 0.880 - ETA: 39s - loss: 0.6189 - accuracy: 0.880 - ETA: 37s - loss: 0.6187 - accuracy: 0.880 - ETA: 36s - loss: 0.6173 - accuracy: 0.880 - ETA: 34s - loss: 0.6186 - accuracy: 0.881 - ETA: 32s - loss: 0.6192 - accuracy: 0.880 - ETA: 31s - loss: 0.6227 - accuracy: 0.880 - ETA: 29s - loss: 0.6198 - accuracy: 0.881 - ETA: 27s - loss: 0.6230 - accuracy: 0.880 - ETA: 26s - loss: 0.6209 - accuracy: 0.881 - ETA: 24s - loss: 0.6216 - accuracy: 0.881 - ETA: 22s - loss: 0.6200 - accuracy: 0.881 - ETA: 21s - loss: 0.6189 - accuracy: 0.881 - ETA: 19s - loss: 0.6222 - accuracy: 0.882 - ETA: 17s - loss: 0.6204 - accuracy: 0.882 - ETA: 16s - loss: 0.6205 - accuracy: 0.882 - ETA: 14s - loss: 0.6221 - accuracy: 0.881 - ETA: 13s - loss: 0.6221 - accuracy: 0.881 - ETA: 11s - loss: 0.6226 - accuracy: 0.881 - ETA: 9s - loss: 0.6233 - accuracy: 0.881 - ETA: 8s - loss: 0.6255 - accuracy: 0.88 - ETA: 6s - loss: 0.6297 - accuracy: 0.88 - ETA: 4s - loss: 0.6276 - accuracy: 0.88 - ETA: 3s - loss: 0.6263 - accuracy: 0.88 - ETA: 1s - loss: 0.6258 - accuracy: 0.88 - 275s 14ms/step - loss: 0.6267 - accuracy: 0.8816 - val_loss: 4.6494 - val_accuracy: 0.7826\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:18 - loss: 0.4696 - accuracy: 0.87 - ETA: 4:01 - loss: 0.5834 - accuracy: 0.88 - ETA: 4:07 - loss: 0.6167 - accuracy: 0.88 - ETA: 4:07 - loss: 0.5652 - accuracy: 0.89 - ETA: 4:06 - loss: 0.5326 - accuracy: 0.89 - ETA: 4:06 - loss: 0.6312 - accuracy: 0.88 - ETA: 4:02 - loss: 0.7298 - accuracy: 0.88 - ETA: 4:00 - loss: 0.6907 - accuracy: 0.88 - ETA: 3:58 - loss: 0.7087 - accuracy: 0.88 - ETA: 3:58 - loss: 0.6787 - accuracy: 0.88 - ETA: 3:55 - loss: 0.6499 - accuracy: 0.88 - ETA: 3:52 - loss: 0.6210 - accuracy: 0.88 - ETA: 3:50 - loss: 0.6238 - accuracy: 0.89 - ETA: 3:48 - loss: 0.6153 - accuracy: 0.89 - ETA: 3:47 - loss: 0.6286 - accuracy: 0.88 - ETA: 3:44 - loss: 0.6350 - accuracy: 0.88 - ETA: 3:43 - loss: 0.6299 - accuracy: 0.88 - ETA: 3:42 - loss: 0.6228 - accuracy: 0.88 - ETA: 3:39 - loss: 0.6229 - accuracy: 0.88 - ETA: 3:37 - loss: 0.6072 - accuracy: 0.88 - ETA: 3:35 - loss: 0.5959 - accuracy: 0.88 - ETA: 3:34 - loss: 0.5983 - accuracy: 0.88 - ETA: 3:33 - loss: 0.6069 - accuracy: 0.88 - ETA: 3:32 - loss: 0.6016 - accuracy: 0.88 - ETA: 3:30 - loss: 0.5888 - accuracy: 0.88 - ETA: 3:29 - loss: 0.5848 - accuracy: 0.88 - ETA: 3:27 - loss: 0.5876 - accuracy: 0.88 - ETA: 3:25 - loss: 0.5828 - accuracy: 0.88 - ETA: 3:23 - loss: 0.5760 - accuracy: 0.88 - ETA: 3:21 - loss: 0.5708 - accuracy: 0.88 - ETA: 3:20 - loss: 0.5752 - accuracy: 0.88 - ETA: 3:18 - loss: 0.5727 - accuracy: 0.88 - ETA: 3:16 - loss: 0.5726 - accuracy: 0.88 - ETA: 3:14 - loss: 0.5717 - accuracy: 0.88 - ETA: 3:12 - loss: 0.5704 - accuracy: 0.88 - ETA: 3:11 - loss: 0.5762 - accuracy: 0.88 - ETA: 3:09 - loss: 0.5727 - accuracy: 0.88 - ETA: 3:08 - loss: 0.5700 - accuracy: 0.88 - ETA: 3:06 - loss: 0.5665 - accuracy: 0.88 - ETA: 3:04 - loss: 0.5743 - accuracy: 0.88 - ETA: 3:02 - loss: 0.5741 - accuracy: 0.88 - ETA: 3:01 - loss: 0.5719 - accuracy: 0.88 - ETA: 2:59 - loss: 0.5672 - accuracy: 0.88 - ETA: 2:57 - loss: 0.5689 - accuracy: 0.88 - ETA: 2:56 - loss: 0.5735 - accuracy: 0.88 - ETA: 2:54 - loss: 0.5721 - accuracy: 0.88 - ETA: 2:52 - loss: 0.5807 - accuracy: 0.88 - ETA: 2:51 - loss: 0.5769 - accuracy: 0.88 - ETA: 2:49 - loss: 0.5770 - accuracy: 0.88 - ETA: 2:47 - loss: 0.5791 - accuracy: 0.88 - ETA: 2:46 - loss: 0.5743 - accuracy: 0.88 - ETA: 2:44 - loss: 0.5725 - accuracy: 0.88 - ETA: 2:43 - loss: 0.5807 - accuracy: 0.88 - ETA: 2:41 - loss: 0.5871 - accuracy: 0.88 - ETA: 2:39 - loss: 0.5859 - accuracy: 0.88 - ETA: 2:38 - loss: 0.5810 - accuracy: 0.88 - ETA: 2:36 - loss: 0.5855 - accuracy: 0.88 - ETA: 2:34 - loss: 0.5843 - accuracy: 0.88 - ETA: 2:33 - loss: 0.5839 - accuracy: 0.88 - ETA: 2:31 - loss: 0.5819 - accuracy: 0.88 - ETA: 2:29 - loss: 0.5975 - accuracy: 0.88 - ETA: 2:28 - loss: 0.5938 - accuracy: 0.88 - ETA: 2:26 - loss: 0.5927 - accuracy: 0.88 - ETA: 2:25 - loss: 0.5932 - accuracy: 0.88 - ETA: 2:23 - loss: 0.6044 - accuracy: 0.88 - ETA: 2:22 - loss: 0.6056 - accuracy: 0.88 - ETA: 2:20 - loss: 0.6043 - accuracy: 0.88 - ETA: 2:18 - loss: 0.6050 - accuracy: 0.88 - ETA: 2:17 - loss: 0.6104 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6137 - accuracy: 0.88 - ETA: 2:13 - loss: 0.6126 - accuracy: 0.88 - ETA: 2:12 - loss: 0.6136 - accuracy: 0.88 - ETA: 2:10 - loss: 0.6223 - accuracy: 0.88 - ETA: 2:08 - loss: 0.6184 - accuracy: 0.88 - ETA: 2:07 - loss: 0.6188 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6227 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6282 - accuracy: 0.88 - ETA: 2:02 - loss: 0.6275 - accuracy: 0.88 - ETA: 2:00 - loss: 0.6253 - accuracy: 0.88 - ETA: 1:58 - loss: 0.6216 - accuracy: 0.88 - ETA: 1:56 - loss: 0.6235 - accuracy: 0.88 - ETA: 1:55 - loss: 0.6255 - accuracy: 0.88 - ETA: 1:53 - loss: 0.6252 - accuracy: 0.88 - ETA: 1:52 - loss: 0.6222 - accuracy: 0.88 - ETA: 1:50 - loss: 0.6210 - accuracy: 0.88 - ETA: 1:48 - loss: 0.6221 - accuracy: 0.88 - ETA: 1:46 - loss: 0.6228 - accuracy: 0.88 - ETA: 1:45 - loss: 0.6251 - accuracy: 0.88 - ETA: 1:43 - loss: 0.6245 - accuracy: 0.88 - ETA: 1:41 - loss: 0.6214 - accuracy: 0.88 - ETA: 1:40 - loss: 0.6210 - accuracy: 0.88 - ETA: 1:38 - loss: 0.6199 - accuracy: 0.88 - ETA: 1:36 - loss: 0.6216 - accuracy: 0.88 - ETA: 1:35 - loss: 0.6223 - accuracy: 0.88 - ETA: 1:33 - loss: 0.6226 - accuracy: 0.88 - ETA: 1:31 - loss: 0.6238 - accuracy: 0.88 - ETA: 1:30 - loss: 0.6239 - accuracy: 0.88 - ETA: 1:28 - loss: 0.6240 - accuracy: 0.88 - ETA: 1:26 - loss: 0.6242 - accuracy: 0.88 - ETA: 1:24 - loss: 0.6233 - accuracy: 0.88 - ETA: 1:23 - loss: 0.6278 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6283 - accuracy: 0.88 - ETA: 1:20 - loss: 0.6251 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6254 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6248 - accuracy: 0.88 - ETA: 1:15 - loss: 0.6253 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6237 - accuracy: 0.88 - ETA: 1:11 - loss: 0.6238 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6226 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6212 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6188 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6166 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6164 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6173 - accuracy: 0.88 - ETA: 59s - loss: 0.6166 - accuracy: 0.8804 - ETA: 58s - loss: 0.6177 - accuracy: 0.880 - ETA: 56s - loss: 0.6187 - accuracy: 0.880 - ETA: 54s - loss: 0.6173 - accuracy: 0.880 - ETA: 53s - loss: 0.6174 - accuracy: 0.880 - ETA: 51s - loss: 0.6169 - accuracy: 0.880 - ETA: 49s - loss: 0.6151 - accuracy: 0.880 - ETA: 48s - loss: 0.6145 - accuracy: 0.880 - ETA: 46s - loss: 0.6128 - accuracy: 0.880 - ETA: 44s - loss: 0.6125 - accuracy: 0.881 - ETA: 43s - loss: 0.6109 - accuracy: 0.881 - ETA: 41s - loss: 0.6108 - accuracy: 0.881 - ETA: 39s - loss: 0.6127 - accuracy: 0.881 - ETA: 38s - loss: 0.6138 - accuracy: 0.881 - ETA: 36s - loss: 0.6171 - accuracy: 0.880 - ETA: 34s - loss: 0.6163 - accuracy: 0.881 - ETA: 33s - loss: 0.6160 - accuracy: 0.881 - ETA: 31s - loss: 0.6150 - accuracy: 0.881 - ETA: 29s - loss: 0.6141 - accuracy: 0.881 - ETA: 28s - loss: 0.6166 - accuracy: 0.881 - ETA: 26s - loss: 0.6170 - accuracy: 0.881 - ETA: 24s - loss: 0.6167 - accuracy: 0.881 - ETA: 23s - loss: 0.6168 - accuracy: 0.881 - ETA: 21s - loss: 0.6195 - accuracy: 0.880 - ETA: 19s - loss: 0.6199 - accuracy: 0.880 - ETA: 18s - loss: 0.6183 - accuracy: 0.880 - ETA: 16s - loss: 0.6184 - accuracy: 0.880 - ETA: 14s - loss: 0.6172 - accuracy: 0.881 - ETA: 13s - loss: 0.6150 - accuracy: 0.881 - ETA: 11s - loss: 0.6136 - accuracy: 0.881 - ETA: 9s - loss: 0.6114 - accuracy: 0.881 - ETA: 8s - loss: 0.6121 - accuracy: 0.88 - ETA: 6s - loss: 0.6122 - accuracy: 0.88 - ETA: 4s - loss: 0.6109 - accuracy: 0.88 - ETA: 3s - loss: 0.6128 - accuracy: 0.88 - ETA: 1s - loss: 0.6112 - accuracy: 0.88 - 277s 14ms/step - loss: 0.6091 - accuracy: 0.8825 - val_loss: 4.3910 - val_accuracy: 0.7799\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:07 - loss: 0.3989 - accuracy: 0.89 - ETA: 4:04 - loss: 0.3995 - accuracy: 0.90 - ETA: 4:06 - loss: 0.3944 - accuracy: 0.91 - ETA: 4:06 - loss: 0.5398 - accuracy: 0.89 - ETA: 4:03 - loss: 0.5206 - accuracy: 0.90 - ETA: 4:01 - loss: 0.4893 - accuracy: 0.90 - ETA: 4:01 - loss: 0.5203 - accuracy: 0.89 - ETA: 3:59 - loss: 0.5613 - accuracy: 0.89 - ETA: 3:56 - loss: 0.6050 - accuracy: 0.88 - ETA: 3:53 - loss: 0.6062 - accuracy: 0.88 - ETA: 3:52 - loss: 0.5847 - accuracy: 0.88 - ETA: 3:50 - loss: 0.5657 - accuracy: 0.88 - ETA: 3:49 - loss: 0.5619 - accuracy: 0.88 - ETA: 3:48 - loss: 0.5571 - accuracy: 0.89 - ETA: 3:47 - loss: 0.5646 - accuracy: 0.89 - ETA: 3:46 - loss: 0.5642 - accuracy: 0.89 - ETA: 3:45 - loss: 0.5564 - accuracy: 0.89 - ETA: 3:43 - loss: 0.5578 - accuracy: 0.89 - ETA: 3:42 - loss: 0.5451 - accuracy: 0.89 - ETA: 3:40 - loss: 0.5445 - accuracy: 0.89 - ETA: 3:38 - loss: 0.5468 - accuracy: 0.89 - ETA: 3:36 - loss: 0.5400 - accuracy: 0.89 - ETA: 3:34 - loss: 0.5290 - accuracy: 0.89 - ETA: 3:33 - loss: 0.5452 - accuracy: 0.89 - ETA: 3:30 - loss: 0.5307 - accuracy: 0.89 - ETA: 3:29 - loss: 0.5415 - accuracy: 0.89 - ETA: 3:27 - loss: 0.5322 - accuracy: 0.89 - ETA: 3:25 - loss: 0.5343 - accuracy: 0.89 - ETA: 3:23 - loss: 0.5366 - accuracy: 0.89 - ETA: 3:22 - loss: 0.5416 - accuracy: 0.89 - ETA: 3:20 - loss: 0.5345 - accuracy: 0.89 - ETA: 3:18 - loss: 0.5350 - accuracy: 0.89 - ETA: 3:16 - loss: 0.5411 - accuracy: 0.88 - ETA: 3:14 - loss: 0.5435 - accuracy: 0.88 - ETA: 3:12 - loss: 0.5505 - accuracy: 0.88 - ETA: 3:11 - loss: 0.5479 - accuracy: 0.88 - ETA: 3:09 - loss: 0.5504 - accuracy: 0.88 - ETA: 3:08 - loss: 0.5516 - accuracy: 0.88 - ETA: 3:07 - loss: 0.5515 - accuracy: 0.88 - ETA: 3:05 - loss: 0.5623 - accuracy: 0.88 - ETA: 3:04 - loss: 0.5600 - accuracy: 0.88 - ETA: 3:02 - loss: 0.5586 - accuracy: 0.88 - ETA: 3:00 - loss: 0.5574 - accuracy: 0.88 - ETA: 2:58 - loss: 0.5557 - accuracy: 0.88 - ETA: 2:56 - loss: 0.5584 - accuracy: 0.88 - ETA: 2:55 - loss: 0.5556 - accuracy: 0.88 - ETA: 2:53 - loss: 0.5565 - accuracy: 0.88 - ETA: 2:51 - loss: 0.5535 - accuracy: 0.88 - ETA: 2:50 - loss: 0.5523 - accuracy: 0.88 - ETA: 2:48 - loss: 0.5547 - accuracy: 0.88 - ETA: 2:47 - loss: 0.5562 - accuracy: 0.88 - ETA: 2:45 - loss: 0.5609 - accuracy: 0.88 - ETA: 2:43 - loss: 0.5618 - accuracy: 0.88 - ETA: 2:42 - loss: 0.5700 - accuracy: 0.88 - ETA: 2:40 - loss: 0.5739 - accuracy: 0.88 - ETA: 2:38 - loss: 0.5784 - accuracy: 0.88 - ETA: 2:37 - loss: 0.5841 - accuracy: 0.88 - ETA: 2:35 - loss: 0.5781 - accuracy: 0.88 - ETA: 2:33 - loss: 0.5779 - accuracy: 0.88 - ETA: 2:32 - loss: 0.5806 - accuracy: 0.88 - ETA: 2:30 - loss: 0.5803 - accuracy: 0.88 - ETA: 2:28 - loss: 0.5791 - accuracy: 0.88 - ETA: 2:27 - loss: 0.5757 - accuracy: 0.88 - ETA: 2:25 - loss: 0.5894 - accuracy: 0.88 - ETA: 2:23 - loss: 0.6052 - accuracy: 0.88 - ETA: 2:22 - loss: 0.6088 - accuracy: 0.88 - ETA: 2:20 - loss: 0.6120 - accuracy: 0.88 - ETA: 2:18 - loss: 0.6124 - accuracy: 0.88 - ETA: 2:17 - loss: 0.6079 - accuracy: 0.88 - ETA: 2:15 - loss: 0.6077 - accuracy: 0.88 - ETA: 2:13 - loss: 0.6076 - accuracy: 0.88 - ETA: 2:12 - loss: 0.6059 - accuracy: 0.88 - ETA: 2:10 - loss: 0.6095 - accuracy: 0.88 - ETA: 2:09 - loss: 0.6082 - accuracy: 0.88 - ETA: 2:07 - loss: 0.6077 - accuracy: 0.88 - ETA: 2:05 - loss: 0.6046 - accuracy: 0.88 - ETA: 2:03 - loss: 0.6002 - accuracy: 0.88 - ETA: 2:02 - loss: 0.6010 - accuracy: 0.88 - ETA: 2:00 - loss: 0.6028 - accuracy: 0.88 - ETA: 1:58 - loss: 0.6111 - accuracy: 0.88 - ETA: 1:56 - loss: 0.6381 - accuracy: 0.88 - ETA: 1:55 - loss: 0.6397 - accuracy: 0.88 - ETA: 1:53 - loss: 0.6393 - accuracy: 0.88 - ETA: 1:52 - loss: 0.6385 - accuracy: 0.88 - ETA: 1:50 - loss: 0.6351 - accuracy: 0.88 - ETA: 1:48 - loss: 0.6323 - accuracy: 0.88 - ETA: 1:46 - loss: 0.6328 - accuracy: 0.88 - ETA: 1:45 - loss: 0.6333 - accuracy: 0.88 - ETA: 1:43 - loss: 0.6310 - accuracy: 0.88 - ETA: 1:41 - loss: 0.6338 - accuracy: 0.88 - ETA: 1:40 - loss: 0.6334 - accuracy: 0.88 - ETA: 1:38 - loss: 0.6360 - accuracy: 0.88 - ETA: 1:36 - loss: 0.6357 - accuracy: 0.88 - ETA: 1:35 - loss: 0.6327 - accuracy: 0.88 - ETA: 1:33 - loss: 0.6379 - accuracy: 0.88 - ETA: 1:31 - loss: 0.6372 - accuracy: 0.88 - ETA: 1:30 - loss: 0.6334 - accuracy: 0.88 - ETA: 1:28 - loss: 0.6330 - accuracy: 0.88 - ETA: 1:26 - loss: 0.6299 - accuracy: 0.88 - ETA: 1:25 - loss: 0.6290 - accuracy: 0.88 - ETA: 1:23 - loss: 0.6331 - accuracy: 0.88 - ETA: 1:21 - loss: 0.6317 - accuracy: 0.88 - ETA: 1:20 - loss: 0.6325 - accuracy: 0.88 - ETA: 1:18 - loss: 0.6342 - accuracy: 0.88 - ETA: 1:16 - loss: 0.6366 - accuracy: 0.88 - ETA: 1:15 - loss: 0.6353 - accuracy: 0.88 - ETA: 1:13 - loss: 0.6369 - accuracy: 0.88 - ETA: 1:11 - loss: 0.6361 - accuracy: 0.88 - ETA: 1:09 - loss: 0.6368 - accuracy: 0.88 - ETA: 1:08 - loss: 0.6353 - accuracy: 0.88 - ETA: 1:06 - loss: 0.6326 - accuracy: 0.88 - ETA: 1:04 - loss: 0.6328 - accuracy: 0.88 - ETA: 1:03 - loss: 0.6296 - accuracy: 0.88 - ETA: 1:01 - loss: 0.6299 - accuracy: 0.88 - ETA: 59s - loss: 0.6282 - accuracy: 0.8838 - ETA: 58s - loss: 0.6276 - accuracy: 0.883 - ETA: 56s - loss: 0.6272 - accuracy: 0.883 - ETA: 54s - loss: 0.6282 - accuracy: 0.883 - ETA: 53s - loss: 0.6280 - accuracy: 0.883 - ETA: 51s - loss: 0.6249 - accuracy: 0.884 - ETA: 49s - loss: 0.6259 - accuracy: 0.883 - ETA: 48s - loss: 0.6255 - accuracy: 0.883 - ETA: 46s - loss: 0.6261 - accuracy: 0.883 - ETA: 44s - loss: 0.6255 - accuracy: 0.883 - ETA: 43s - loss: 0.6226 - accuracy: 0.883 - ETA: 41s - loss: 0.6220 - accuracy: 0.883 - ETA: 39s - loss: 0.6222 - accuracy: 0.884 - ETA: 38s - loss: 0.6204 - accuracy: 0.884 - ETA: 36s - loss: 0.6231 - accuracy: 0.884 - ETA: 34s - loss: 0.6237 - accuracy: 0.883 - ETA: 33s - loss: 0.6235 - accuracy: 0.883 - ETA: 31s - loss: 0.6234 - accuracy: 0.883 - ETA: 29s - loss: 0.6237 - accuracy: 0.883 - ETA: 28s - loss: 0.6218 - accuracy: 0.883 - ETA: 26s - loss: 0.6204 - accuracy: 0.883 - ETA: 24s - loss: 0.6181 - accuracy: 0.883 - ETA: 23s - loss: 0.6152 - accuracy: 0.884 - ETA: 21s - loss: 0.6142 - accuracy: 0.884 - ETA: 19s - loss: 0.6137 - accuracy: 0.884 - ETA: 18s - loss: 0.6128 - accuracy: 0.884 - ETA: 16s - loss: 0.6123 - accuracy: 0.884 - ETA: 14s - loss: 0.6105 - accuracy: 0.884 - ETA: 13s - loss: 0.6106 - accuracy: 0.884 - ETA: 11s - loss: 0.6095 - accuracy: 0.884 - ETA: 9s - loss: 0.6116 - accuracy: 0.883 - ETA: 8s - loss: 0.6120 - accuracy: 0.88 - ETA: 6s - loss: 0.6131 - accuracy: 0.88 - ETA: 4s - loss: 0.6119 - accuracy: 0.88 - ETA: 3s - loss: 0.6102 - accuracy: 0.88 - ETA: 1s - loss: 0.6093 - accuracy: 0.88 - 276s 14ms/step - loss: 0.6084 - accuracy: 0.8838 - val_loss: 4.3753 - val_accuracy: 0.7807\n",
      "2020-12-06 06:13:49.766103\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "t5=datetime.datetime.now()\n",
    "print(t5)\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n",
    "t6=datetime.datetime.now()\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [2.0085698335307507, 1.8057831944479263, 1.7717342000986187, 1.7079996349994726, 1.7383843395225649, 1.7006514608600811, 1.6793302886849928, 1.6164756959752036, 1.756025132270895, 1.831427244894202, 1.8451291263461433, 1.8951942512129474, 1.8776189736585287, 1.9522334080251953, 1.9775650973249899, 1.9365744326617758, 2.076784600552922, 2.152905437091686, 2.2742044400986146, 2.2922090047337447, 2.187795364059358, 2.5052908809566676, 2.31834697224729, 2.444376816115633, 2.367154809253066, 2.54075278355039, 2.5737913424836893, 2.663701928385199, 2.8158891714984375, 2.8684837046951257, 2.9136944882344893, 2.7465775000009756, 2.667226056451258, 2.66516068241418, 2.686368165956222, 3.0705409785140545, 2.947612610952433, 3.0199550929882184, 2.9735975620489383, 2.907805609268588, 3.181322022041294, 3.2814365323346752, 3.1616717718678937, 3.2149526813208475, 3.344104768672476, 3.1960983327467463, 3.107730971011693, 3.324304083806186, 3.0676526140292797, 3.855059348097695, 3.4577980359461176, 3.6422706763673753, 3.7130078838883187, 3.416216102933064, 3.5048817633891307, 3.561930788429807, 3.4868743446801953, 3.7611188608856025, 3.674522930456506, 3.8194145639877335, 3.962571109271884, 4.122667780991888, 4.075026628047345, 3.9182714294217145, 3.5703085812507247, 3.754230813670045, 4.078127204989221, 3.899199513056975, 4.1545428436200895, 4.1397389230779496, 3.942885596230302, 3.8644973564700917, 3.7004346755331508, 4.2270992183122456, 3.772043076058208, 3.8112287316837774, 4.121621875011, 3.9365588210709817, 3.9804734874151833, 4.114188702401722, 4.2511190255499445, 4.110308528687056, 4.481943192899684, 4.196642541384247, 4.231713240833899, 4.39361830450383, 4.320576217609499, 4.646166390601486, 4.367248414317676, 4.430262701719734, 4.103207341408626, 4.305852056561752, 4.336548006727128, 4.246395800184774, 4.2578399396505535, 4.489720179195803, 4.335621451166358, 4.649404291115234, 4.390973762193065, 4.375334501587399], 'val_accuracy': [0.5386208295822144, 0.6055083870887756, 0.6270449161529541, 0.6568647623062134, 0.6684613823890686, 0.6823359131813049, 0.6922758221626282, 0.6986953616142273, 0.6953820586204529, 0.7057361602783203, 0.7177469730377197, 0.7179540395736694, 0.7189894318580627, 0.7185752987861633, 0.7343135476112366, 0.7349347472190857, 0.7372126579284668, 0.7382481098175049, 0.7359701991081238, 0.7425968050956726, 0.7432180643081665, 0.7467384338378906, 0.7438393235206604, 0.7432180643081665, 0.7374197840690613, 0.7409401535987854, 0.75295090675354, 0.7539863586425781, 0.7471526265144348, 0.7510871887207031, 0.7593704462051392, 0.7614412903785706, 0.7610271573066711, 0.7560571432113647, 0.7556430101394653, 0.7556430101394653, 0.7608200311660767, 0.7595775723457336, 0.75874924659729, 0.7604058980941772, 0.7616483569145203, 0.760612964630127, 0.7616483569145203, 0.7583350539207458, 0.7583350539207458, 0.7703458070755005, 0.7653758525848389, 0.763512134552002, 0.7662041783332825, 0.7655829191207886, 0.7709670662879944, 0.7674466967582703, 0.7659971117973328, 0.7709670662879944, 0.7633050084114075, 0.7624766826629639, 0.763512134552002, 0.7649617195129395, 0.7682750225067139, 0.7724166512489319, 0.7693104147911072, 0.7649617195129395, 0.7726237177848816, 0.774694561958313, 0.7730379104614258, 0.7726237177848816, 0.7738662362098694, 0.7709670662879944, 0.7682750225067139, 0.7732449769973755, 0.7724166512489319, 0.7720024585723877, 0.7711741328239441, 0.7707599997520447, 0.7740733027458191, 0.774694561958313, 0.7722095847129822, 0.7726237177848816, 0.7715883255004883, 0.7763512134552002, 0.7767653465270996, 0.7769724726676941, 0.7728307843208313, 0.7784220576286316, 0.778836190700531, 0.7782149314880371, 0.7751086950302124, 0.7765582799911499, 0.7784220576286316, 0.7825636863708496, 0.7792503833770752, 0.7794574499130249, 0.7821494936943054, 0.7786291241645813, 0.7780078649520874, 0.7782149314880371, 0.7790432572364807, 0.7825636863708496, 0.7798715829849243, 0.7806999087333679], 'loss': [10.127644647718364, 2.464218683843289, 2.012468728924351, 1.8291969667709653, 1.7018251740053456, 1.5840580551310226, 1.4855360602088081, 1.4199297183194037, 1.390520936018589, 1.3416335053353046, 1.29626626936779, 1.2643582140401857, 1.193848674121531, 1.2090264321756243, 1.1942712644357374, 1.1553681822186574, 1.1219238420113513, 1.110341256970498, 1.1000342510313463, 1.0776562196910136, 1.028554548383648, 1.0272568627241336, 0.9972476347379676, 0.9764754973172944, 0.9738156133776572, 0.9750822573628619, 0.9762789908774944, 0.9723862604158618, 0.9624906244017215, 0.9026873268761118, 0.8902070692677881, 0.943848066964027, 0.9245360287735062, 0.9292171364395502, 0.8830386322198471, 0.8625975999342279, 0.911276226114812, 0.8680957276759902, 0.8786053327162995, 0.8662811948330618, 0.8575004010824695, 0.8467309759881937, 0.8657749764615085, 0.809647838538011, 0.8259775298828909, 0.7942073836539931, 0.8332951232827984, 0.7971291807730927, 0.8249008684683755, 0.8298741679796031, 0.8132188754231848, 0.8228408419700723, 0.8094260570127902, 0.7965825734893053, 0.8019378649467462, 0.7656859102185936, 0.8039917098952406, 0.7315869994566474, 0.7468066584896034, 0.7655237329924709, 0.7695458613354604, 0.7779730791480658, 0.731627294961934, 0.7339597916494447, 0.7385252080086152, 0.7556381190030557, 0.7650435174311501, 0.7688610297940246, 0.7344093609666074, 0.7554766573783477, 0.708961519161926, 0.7116219916912575, 0.7165729639544008, 0.7149386715079105, 0.6963856608885423, 0.6952134007348832, 0.7193129201417336, 0.6872911192507614, 0.7124538689777687, 0.6493259042674289, 0.6945790084512548, 0.675249813357561, 0.6476303233326025, 0.6513264015773751, 0.662526575069143, 0.6515187981855602, 0.6513495559818802, 0.6453602800659631, 0.6629387670641806, 0.6558014693690808, 0.6573614160088141, 0.6294594472266468, 0.6556193832780274, 0.6537257341333135, 0.6362324707648334, 0.6213233714125427, 0.6402876589450346, 0.6267379067511033, 0.6091088934090875, 0.6084252920838161], 'accuracy': [0.33062345, 0.5045568, 0.57756835, 0.6179578, 0.6497514, 0.6695319, 0.6928853, 0.7113194, 0.7224006, 0.7329122, 0.7478252, 0.75486743, 0.76118475, 0.76455057, 0.7761496, 0.77739227, 0.78717893, 0.7878003, 0.79282314, 0.7977423, 0.8061309, 0.80654514, 0.8138981, 0.8131214, 0.8193351, 0.8163318, 0.8196458, 0.8273094, 0.8249793, 0.83010566, 0.8364229, 0.8346106, 0.83357495, 0.8312966, 0.83611226, 0.840203, 0.8384942, 0.84372413, 0.8450704, 0.8441384, 0.84356874, 0.8462614, 0.84584713, 0.8487469, 0.8512324, 0.8537179, 0.8506628, 0.8550642, 0.8548053, 0.8553749, 0.8570319, 0.85687655, 0.85827464, 0.86158866, 0.86065656, 0.8614333, 0.8586889, 0.86433303, 0.8632974, 0.8656276, 0.8640224, 0.863401, 0.86687034, 0.86712927, 0.86599004, 0.8663525, 0.86433303, 0.86759526, 0.8683202, 0.86904514, 0.8680095, 0.86987364, 0.8687863, 0.8717378, 0.8744822, 0.8734466, 0.8711682, 0.8741715, 0.87303233, 0.8771748, 0.87323946, 0.87536246, 0.8780551, 0.8786247, 0.87613916, 0.8758803, 0.8786247, 0.87929785, 0.8795568, 0.8780551, 0.88173157, 0.8826636, 0.88178337, 0.88002276, 0.88230115, 0.8836475, 0.8813173, 0.88157624, 0.8824565, 0.88380283]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = np.arange(0, len(history.history['loss']))\n",
    "\n",
    "# You can chose the style of your preference\n",
    "# print(plt.style.available) to see the available options\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "plt.figure()\n",
    "plt.plot(N, history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(N, history.history['accuracy'], label = \"train_acc\")\n",
    "plt.plot(N, history.history['val_loss'], label = \"val_loss\")\n",
    "plt.plot(N, history.history['val_accuracy'], label = \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# Make sure there exists a folder called output in the current directory\n",
    "# or replace 'output' with whatever direcory you want to put in the plots\n",
    "plt.show()\n",
    "plt.savefig('../Output/EpochResNet101V2.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
