{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet_v2 import ResNet101V2\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24136</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24137</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24138</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24139</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24140</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image class\n",
       "24136  winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg  wave\n",
       "24137  winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg  wave\n",
       "24138  winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg  wave\n",
       "24139  winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg  wave\n",
       "24140  winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg  wave"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_2.csv')\n",
    "train.sort_values(by=['class', 'image'])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24141/24141 [02:50<00:00, 141.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/train_frame/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24141, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X = np.array(train_image,np.float16)\n",
    "train_image=[]\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 224, 224, 3)\n",
      "(4829, 224, 224, 3)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained ResNet101V2 model\n",
    "base_model = ResNet101V2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet101v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, None, None, 6 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, None, None, 6 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, None, None, 2 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, None, None, 2 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, None, None, 2 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, None, None, 2 0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, None, None, 2 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, None, None, 5 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, None, None, 5 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, None, None, 5 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, None, None, 5 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, None, None, 5 0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, None, None, 5 0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, None, None, 1 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, None, None, 1 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, None, None, 1 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, None, None, 1 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, None, None, 1 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, None, None, 1 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, None, None, 1 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block7_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, None, None, 2 0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, None, None, 2 0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, None, None, 1 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, None, None, 1 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, None, None, 2 0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, None, None, 2 0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, None, None, 1 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, None, None, 1 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, None, None, 2 0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, None, None, 2 0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, None, None, 1 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, None, None, 1 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, None, None, 1 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, None, None, 2 0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, None, None, 2 0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block10_2_relu[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, None, None, 1 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, None, None, 1 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, None, None, 1 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, None, None, 2 0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, None, None, 2 0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, None, None, 1 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, None, None, 1 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, None, None, 1 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, None, None, 2 0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, None, None, 2 0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, None, None, 1 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, None, None, 1 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, None, None, 1 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, None, None, 2 0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, None, None, 2 0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, None, None, 1 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, None, None, 1 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, None, None, 1 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, None, None, 2 0           conv4_block14_1_bn[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, None, None, 2 0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, None, None, 1 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, None, None, 1 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, None, None, 1 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, None, None, 2 0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, None, None, 2 0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, None, None, 1 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, None, None, 1 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, None, None, 1 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, None, None, 2 0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, None, None, 2 0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, None, None, 1 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, None, None, 1 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, None, None, 1 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, None, None, 2 0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, None, None, 2 0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, None, None, 1 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, None, None, 1 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, None, None, 1 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, None, None, 2 0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, None, None, 2 0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, None, None, 1 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, None, None, 1 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, None, None, 1 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, None, None, 2 0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, None, None, 2 0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, None, None, 1 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, None, None, 1 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, None, None, 1 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, None, None, 2 0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, None, None, 2 0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, None, None, 1 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, None, None, 1 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, None, None, 1 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, None, None, 2 0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block21_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, None, None, 2 0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, None, None, 1 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, None, None, 1 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, None, None, 1 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, None, None, 2 0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, None, None, 2 0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, None, None, 1 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, None, None, 1 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, None, None, 1 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, None, None, 2 0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, None, None, 2 0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, None, None, 1 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, None, None, 1 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, None, None, 2 0           conv5_block1_0_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, None, None, 2 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, None, None, 2 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, None, None, 2 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, None, None, 2 0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 42,626,560\n",
      "Trainable params: 42,528,896\n",
      "Non-trainable params: 97,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'resnet101v2',\n",
       " 'layers': [{'name': 'input_1',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_1'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'conv1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((3, 3), (3, 3)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (7, 7),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'pool1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pool',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'pool1_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool1_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_0_conv', 0, 0, {}],\n",
       "     ['conv2_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}],\n",
       "     ['conv2_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_1',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_1', 0, 0, {}],\n",
       "     ['conv2_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_0_conv', 0, 0, {}],\n",
       "     ['conv3_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}],\n",
       "     ['conv3_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}],\n",
       "     ['conv3_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_2',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}],\n",
       "     ['conv3_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_0_conv', 0, 0, {}],\n",
       "     ['conv4_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}],\n",
       "     ['conv4_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}],\n",
       "     ['conv4_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}],\n",
       "     ['conv4_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block5_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block5_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}],\n",
       "     ['conv4_block5_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block6_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block6_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}],\n",
       "     ['conv4_block6_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block7_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block7_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}],\n",
       "     ['conv4_block7_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block8_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block8_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}],\n",
       "     ['conv4_block8_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block9_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block9_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}],\n",
       "     ['conv4_block9_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block10_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block10_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}],\n",
       "     ['conv4_block10_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block11_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block11_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}],\n",
       "     ['conv4_block11_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block12_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block12_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}],\n",
       "     ['conv4_block12_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block13_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block13_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}],\n",
       "     ['conv4_block13_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block14_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block14_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}],\n",
       "     ['conv4_block14_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block15_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block15_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}],\n",
       "     ['conv4_block15_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block16_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block16_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}],\n",
       "     ['conv4_block16_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block17_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block17_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}],\n",
       "     ['conv4_block17_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block18_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block18_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}],\n",
       "     ['conv4_block18_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block19_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block19_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}],\n",
       "     ['conv4_block19_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block20_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block20_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}],\n",
       "     ['conv4_block20_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block21_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block21_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}],\n",
       "     ['conv4_block21_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block22_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block22_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}],\n",
       "     ['conv4_block22_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block23_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_3',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block23_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_3', 0, 0, {}],\n",
       "     ['conv4_block23_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_0_conv', 0, 0, {}],\n",
       "     ['conv5_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}],\n",
       "     ['conv5_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}],\n",
       "     ['conv5_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'post_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'post_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'post_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'post_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['post_bn', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['post_relu', 0, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1=datetime.datetime.now()\n",
    "print(t1)\n",
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "print(X_train.shape)\n",
    "t2=datetime.datetime.now()\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(19312, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(X_train, '../Pickle/ResNet101V2_X_train_2.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t3=datetime.datetime.now()\n",
    "print(t3)\n",
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "print(X_test.shape)\n",
    "t4=datetime.datetime.now()\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test = X_test.reshape(4829, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib.dump(X_test, '../Pickle/ResNet101V2_X_test_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "X_train = joblib.load('../Pickle/ResNet101V2_X_train_2.pkl') \n",
    "X_test = joblib.load('../Pickle/ResNet101V2_X_test_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 100352)\n",
      "(4829, 100352)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "# shape of images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 51)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 51)                52275     \n",
      "=================================================================\n",
      "Total params: 102,813,747\n",
      "Trainable params: 102,813,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('../Models/weightResNet101V2_5.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adadelta',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-06 18:46:22.688161\n",
      "Train on 19312 samples, validate on 4829 samples\n",
      "Epoch 1/100\n",
      "19312/19312 [==============================] - ETA: 21:40 - loss: 8.4011 - accuracy: 0.046 - ETA: 14:37 - loss: 32.6350 - accuracy: 0.09 - ETA: 11:24 - loss: 53.1415 - accuracy: 0.08 - ETA: 9:43 - loss: 54.9710 - accuracy: 0.0762 - ETA: 8:43 - loss: 55.2986 - accuracy: 0.065 - ETA: 7:58 - loss: 51.9287 - accuracy: 0.069 - ETA: 7:27 - loss: 47.3347 - accuracy: 0.071 - ETA: 7:06 - loss: 42.9827 - accuracy: 0.085 - ETA: 6:47 - loss: 39.0296 - accuracy: 0.093 - ETA: 6:33 - loss: 35.5929 - accuracy: 0.098 - ETA: 6:22 - loss: 32.7267 - accuracy: 0.112 - ETA: 6:09 - loss: 30.2857 - accuracy: 0.125 - ETA: 5:59 - loss: 28.2314 - accuracy: 0.128 - ETA: 5:50 - loss: 26.4721 - accuracy: 0.135 - ETA: 5:41 - loss: 24.9375 - accuracy: 0.146 - ETA: 5:34 - loss: 23.5980 - accuracy: 0.150 - ETA: 5:26 - loss: 22.4500 - accuracy: 0.149 - ETA: 5:19 - loss: 21.3977 - accuracy: 0.150 - ETA: 5:13 - loss: 20.4651 - accuracy: 0.153 - ETA: 5:08 - loss: 19.6179 - accuracy: 0.155 - ETA: 5:03 - loss: 18.8328 - accuracy: 0.159 - ETA: 4:59 - loss: 18.1302 - accuracy: 0.162 - ETA: 4:54 - loss: 17.4921 - accuracy: 0.166 - ETA: 4:50 - loss: 16.9061 - accuracy: 0.168 - ETA: 4:46 - loss: 16.3730 - accuracy: 0.170 - ETA: 4:42 - loss: 15.8642 - accuracy: 0.171 - ETA: 4:38 - loss: 15.4060 - accuracy: 0.174 - ETA: 4:35 - loss: 14.9671 - accuracy: 0.177 - ETA: 4:32 - loss: 14.5579 - accuracy: 0.182 - ETA: 4:29 - loss: 14.1736 - accuracy: 0.187 - ETA: 4:25 - loss: 13.8214 - accuracy: 0.189 - ETA: 4:22 - loss: 13.4885 - accuracy: 0.192 - ETA: 4:19 - loss: 13.1713 - accuracy: 0.197 - ETA: 4:16 - loss: 12.8759 - accuracy: 0.199 - ETA: 4:13 - loss: 12.5946 - accuracy: 0.202 - ETA: 4:11 - loss: 12.3328 - accuracy: 0.203 - ETA: 4:08 - loss: 12.0906 - accuracy: 0.204 - ETA: 4:05 - loss: 11.8530 - accuracy: 0.206 - ETA: 4:02 - loss: 11.6267 - accuracy: 0.208 - ETA: 4:00 - loss: 11.4094 - accuracy: 0.211 - ETA: 3:57 - loss: 11.2070 - accuracy: 0.214 - ETA: 3:55 - loss: 11.0169 - accuracy: 0.215 - ETA: 3:53 - loss: 10.8240 - accuracy: 0.218 - ETA: 3:51 - loss: 10.6480 - accuracy: 0.220 - ETA: 3:48 - loss: 10.4794 - accuracy: 0.220 - ETA: 3:45 - loss: 10.3199 - accuracy: 0.222 - ETA: 3:43 - loss: 10.1567 - accuracy: 0.225 - ETA: 3:41 - loss: 10.0125 - accuracy: 0.227 - ETA: 3:39 - loss: 9.8689 - accuracy: 0.230 - ETA: 3:36 - loss: 9.7337 - accuracy: 0.23 - ETA: 3:34 - loss: 9.5949 - accuracy: 0.23 - ETA: 3:31 - loss: 9.4693 - accuracy: 0.23 - ETA: 3:29 - loss: 9.3484 - accuracy: 0.23 - ETA: 3:26 - loss: 9.2245 - accuracy: 0.24 - ETA: 3:23 - loss: 9.1117 - accuracy: 0.24 - ETA: 3:21 - loss: 8.9999 - accuracy: 0.24 - ETA: 3:18 - loss: 8.8991 - accuracy: 0.24 - ETA: 3:16 - loss: 8.7912 - accuracy: 0.24 - ETA: 3:14 - loss: 8.6955 - accuracy: 0.24 - ETA: 3:11 - loss: 8.5994 - accuracy: 0.25 - ETA: 3:09 - loss: 8.5010 - accuracy: 0.25 - ETA: 3:06 - loss: 8.4099 - accuracy: 0.25 - ETA: 3:04 - loss: 8.3196 - accuracy: 0.25 - ETA: 3:01 - loss: 8.2385 - accuracy: 0.25 - ETA: 2:59 - loss: 8.1552 - accuracy: 0.25 - ETA: 2:57 - loss: 8.0754 - accuracy: 0.25 - ETA: 2:55 - loss: 7.9924 - accuracy: 0.26 - ETA: 2:52 - loss: 7.9141 - accuracy: 0.26 - ETA: 2:50 - loss: 7.8485 - accuracy: 0.26 - ETA: 2:48 - loss: 7.7729 - accuracy: 0.26 - ETA: 2:46 - loss: 7.7061 - accuracy: 0.26 - ETA: 2:43 - loss: 7.6370 - accuracy: 0.26 - ETA: 2:41 - loss: 7.5675 - accuracy: 0.26 - ETA: 2:39 - loss: 7.4995 - accuracy: 0.27 - ETA: 2:37 - loss: 7.4395 - accuracy: 0.27 - ETA: 2:35 - loss: 7.3807 - accuracy: 0.27 - ETA: 2:32 - loss: 7.3183 - accuracy: 0.27 - ETA: 2:30 - loss: 7.2534 - accuracy: 0.27 - ETA: 2:28 - loss: 7.1986 - accuracy: 0.27 - ETA: 2:26 - loss: 7.1399 - accuracy: 0.27 - ETA: 2:23 - loss: 7.0810 - accuracy: 0.28 - ETA: 2:21 - loss: 7.0250 - accuracy: 0.28 - ETA: 2:19 - loss: 6.9720 - accuracy: 0.28 - ETA: 2:17 - loss: 6.9207 - accuracy: 0.28 - ETA: 2:14 - loss: 6.8758 - accuracy: 0.28 - ETA: 2:12 - loss: 6.8227 - accuracy: 0.28 - ETA: 2:09 - loss: 6.7740 - accuracy: 0.28 - ETA: 2:07 - loss: 6.7301 - accuracy: 0.28 - ETA: 2:05 - loss: 6.6857 - accuracy: 0.28 - ETA: 2:03 - loss: 6.6419 - accuracy: 0.29 - ETA: 2:00 - loss: 6.5974 - accuracy: 0.29 - ETA: 1:58 - loss: 6.5536 - accuracy: 0.29 - ETA: 1:55 - loss: 6.5102 - accuracy: 0.29 - ETA: 1:53 - loss: 6.4696 - accuracy: 0.29 - ETA: 1:51 - loss: 6.4287 - accuracy: 0.29 - ETA: 1:48 - loss: 6.3878 - accuracy: 0.29 - ETA: 1:46 - loss: 6.3559 - accuracy: 0.29 - ETA: 1:44 - loss: 6.3264 - accuracy: 0.29 - ETA: 1:42 - loss: 6.2912 - accuracy: 0.29 - ETA: 1:40 - loss: 6.2548 - accuracy: 0.29 - ETA: 1:37 - loss: 6.2211 - accuracy: 0.29 - ETA: 1:35 - loss: 6.1884 - accuracy: 0.30 - ETA: 1:33 - loss: 6.1551 - accuracy: 0.30 - ETA: 1:31 - loss: 6.1214 - accuracy: 0.30 - ETA: 1:28 - loss: 6.0882 - accuracy: 0.30 - ETA: 1:26 - loss: 6.0546 - accuracy: 0.30 - ETA: 1:24 - loss: 6.0246 - accuracy: 0.30 - ETA: 1:22 - loss: 5.9932 - accuracy: 0.30 - ETA: 1:20 - loss: 5.9591 - accuracy: 0.30 - ETA: 1:18 - loss: 5.9310 - accuracy: 0.30 - ETA: 1:16 - loss: 5.8963 - accuracy: 0.30 - ETA: 1:14 - loss: 5.8680 - accuracy: 0.30 - ETA: 1:12 - loss: 5.8384 - accuracy: 0.31 - ETA: 1:10 - loss: 5.8087 - accuracy: 0.31 - ETA: 1:08 - loss: 5.7793 - accuracy: 0.31 - ETA: 1:06 - loss: 5.7505 - accuracy: 0.31 - ETA: 1:04 - loss: 5.7260 - accuracy: 0.31 - ETA: 1:01 - loss: 5.6995 - accuracy: 0.31 - ETA: 1:00 - loss: 5.6720 - accuracy: 0.31 - ETA: 58s - loss: 5.6458 - accuracy: 0.3156 - ETA: 56s - loss: 5.6218 - accuracy: 0.315 - ETA: 54s - loss: 5.5959 - accuracy: 0.316 - ETA: 52s - loss: 5.5688 - accuracy: 0.317 - ETA: 50s - loss: 5.5437 - accuracy: 0.318 - ETA: 48s - loss: 5.5218 - accuracy: 0.319 - ETA: 46s - loss: 5.4975 - accuracy: 0.320 - ETA: 44s - loss: 5.4722 - accuracy: 0.321 - ETA: 42s - loss: 5.4501 - accuracy: 0.322 - ETA: 40s - loss: 5.4273 - accuracy: 0.323 - ETA: 38s - loss: 5.4043 - accuracy: 0.324 - ETA: 36s - loss: 5.3827 - accuracy: 0.325 - ETA: 34s - loss: 5.3606 - accuracy: 0.326 - ETA: 33s - loss: 5.3362 - accuracy: 0.327 - ETA: 31s - loss: 5.3152 - accuracy: 0.328 - ETA: 29s - loss: 5.2946 - accuracy: 0.329 - ETA: 27s - loss: 5.2732 - accuracy: 0.329 - ETA: 25s - loss: 5.2512 - accuracy: 0.331 - ETA: 23s - loss: 5.2347 - accuracy: 0.331 - ETA: 21s - loss: 5.2185 - accuracy: 0.331 - ETA: 19s - loss: 5.2048 - accuracy: 0.331 - ETA: 18s - loss: 5.1843 - accuracy: 0.332 - ETA: 16s - loss: 5.1680 - accuracy: 0.333 - ETA: 14s - loss: 5.1496 - accuracy: 0.334 - ETA: 12s - loss: 5.1311 - accuracy: 0.335 - ETA: 10s - loss: 5.1129 - accuracy: 0.335 - ETA: 8s - loss: 5.0918 - accuracy: 0.336 - ETA: 7s - loss: 5.0722 - accuracy: 0.33 - ETA: 5s - loss: 5.0530 - accuracy: 0.33 - ETA: 3s - loss: 5.0334 - accuracy: 0.33 - ETA: 1s - loss: 5.0155 - accuracy: 0.34 - 291s 15ms/step - loss: 5.0000 - accuracy: 0.3408 - val_loss: 1.8866 - val_accuracy: 0.5492\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:27 - loss: 2.1504 - accuracy: 0.47 - ETA: 3:26 - loss: 2.2064 - accuracy: 0.48 - ETA: 3:22 - loss: 2.0987 - accuracy: 0.48 - ETA: 3:19 - loss: 2.0924 - accuracy: 0.49 - ETA: 3:20 - loss: 2.0277 - accuracy: 0.50 - ETA: 3:20 - loss: 1.9256 - accuracy: 0.52 - ETA: 3:25 - loss: 1.9215 - accuracy: 0.53 - ETA: 3:22 - loss: 1.9343 - accuracy: 0.52 - ETA: 3:20 - loss: 1.9259 - accuracy: 0.53 - ETA: 3:17 - loss: 1.8904 - accuracy: 0.54 - ETA: 3:15 - loss: 1.9223 - accuracy: 0.53 - ETA: 3:14 - loss: 1.9130 - accuracy: 0.53 - ETA: 3:11 - loss: 1.9417 - accuracy: 0.53 - ETA: 3:09 - loss: 1.9484 - accuracy: 0.53 - ETA: 3:08 - loss: 1.9637 - accuracy: 0.53 - ETA: 3:06 - loss: 1.9582 - accuracy: 0.53 - ETA: 3:04 - loss: 1.9662 - accuracy: 0.53 - ETA: 3:04 - loss: 1.9963 - accuracy: 0.53 - ETA: 3:02 - loss: 2.0019 - accuracy: 0.53 - ETA: 3:01 - loss: 1.9948 - accuracy: 0.53 - ETA: 2:59 - loss: 1.9853 - accuracy: 0.53 - ETA: 2:58 - loss: 1.9855 - accuracy: 0.53 - ETA: 2:56 - loss: 1.9897 - accuracy: 0.53 - ETA: 2:55 - loss: 1.9872 - accuracy: 0.53 - ETA: 2:53 - loss: 1.9720 - accuracy: 0.53 - ETA: 2:51 - loss: 1.9608 - accuracy: 0.53 - ETA: 2:50 - loss: 1.9492 - accuracy: 0.53 - ETA: 2:49 - loss: 1.9397 - accuracy: 0.54 - ETA: 2:48 - loss: 1.9365 - accuracy: 0.54 - ETA: 2:47 - loss: 1.9392 - accuracy: 0.54 - ETA: 2:46 - loss: 1.9400 - accuracy: 0.54 - ETA: 2:44 - loss: 1.9459 - accuracy: 0.53 - ETA: 2:43 - loss: 1.9607 - accuracy: 0.53 - ETA: 2:41 - loss: 1.9640 - accuracy: 0.53 - ETA: 2:40 - loss: 1.9783 - accuracy: 0.53 - ETA: 2:38 - loss: 1.9847 - accuracy: 0.53 - ETA: 2:37 - loss: 1.9808 - accuracy: 0.53 - ETA: 2:35 - loss: 1.9744 - accuracy: 0.53 - ETA: 2:34 - loss: 1.9751 - accuracy: 0.52 - ETA: 2:32 - loss: 1.9707 - accuracy: 0.53 - ETA: 2:31 - loss: 1.9797 - accuracy: 0.52 - ETA: 2:30 - loss: 1.9850 - accuracy: 0.52 - ETA: 2:28 - loss: 1.9882 - accuracy: 0.52 - ETA: 2:27 - loss: 1.9844 - accuracy: 0.53 - ETA: 2:26 - loss: 1.9871 - accuracy: 0.52 - ETA: 2:24 - loss: 1.9927 - accuracy: 0.52 - ETA: 2:23 - loss: 1.9878 - accuracy: 0.52 - ETA: 2:21 - loss: 1.9902 - accuracy: 0.52 - ETA: 2:20 - loss: 1.9871 - accuracy: 0.53 - ETA: 2:18 - loss: 1.9765 - accuracy: 0.53 - ETA: 2:17 - loss: 1.9766 - accuracy: 0.53 - ETA: 2:16 - loss: 1.9790 - accuracy: 0.53 - ETA: 2:14 - loss: 1.9781 - accuracy: 0.53 - ETA: 2:13 - loss: 1.9748 - accuracy: 0.53 - ETA: 2:12 - loss: 1.9753 - accuracy: 0.53 - ETA: 2:10 - loss: 1.9808 - accuracy: 0.53 - ETA: 2:09 - loss: 1.9754 - accuracy: 0.53 - ETA: 2:07 - loss: 1.9748 - accuracy: 0.53 - ETA: 2:06 - loss: 1.9717 - accuracy: 0.53 - ETA: 2:05 - loss: 1.9665 - accuracy: 0.53 - ETA: 2:03 - loss: 1.9634 - accuracy: 0.53 - ETA: 2:02 - loss: 1.9653 - accuracy: 0.53 - ETA: 2:01 - loss: 1.9592 - accuracy: 0.53 - ETA: 1:59 - loss: 1.9574 - accuracy: 0.53 - ETA: 1:58 - loss: 1.9529 - accuracy: 0.53 - ETA: 1:57 - loss: 1.9494 - accuracy: 0.53 - ETA: 1:55 - loss: 1.9521 - accuracy: 0.53 - ETA: 1:54 - loss: 1.9479 - accuracy: 0.53 - ETA: 1:53 - loss: 1.9447 - accuracy: 0.53 - ETA: 1:51 - loss: 1.9441 - accuracy: 0.53 - ETA: 1:50 - loss: 1.9462 - accuracy: 0.53 - ETA: 1:48 - loss: 1.9461 - accuracy: 0.53 - ETA: 1:47 - loss: 1.9479 - accuracy: 0.53 - ETA: 1:46 - loss: 1.9492 - accuracy: 0.53 - ETA: 1:44 - loss: 1.9470 - accuracy: 0.53 - ETA: 1:43 - loss: 1.9437 - accuracy: 0.54 - ETA: 1:42 - loss: 1.9473 - accuracy: 0.54 - ETA: 1:40 - loss: 1.9431 - accuracy: 0.54 - ETA: 1:39 - loss: 1.9436 - accuracy: 0.54 - ETA: 1:38 - loss: 1.9432 - accuracy: 0.54 - ETA: 1:36 - loss: 1.9425 - accuracy: 0.54 - ETA: 1:35 - loss: 1.9438 - accuracy: 0.54 - ETA: 1:33 - loss: 1.9460 - accuracy: 0.54 - ETA: 1:32 - loss: 1.9428 - accuracy: 0.54 - ETA: 1:31 - loss: 1.9466 - accuracy: 0.54 - ETA: 1:29 - loss: 1.9452 - accuracy: 0.54 - ETA: 1:28 - loss: 1.9453 - accuracy: 0.54 - ETA: 1:27 - loss: 1.9443 - accuracy: 0.54 - ETA: 1:25 - loss: 1.9404 - accuracy: 0.54 - ETA: 1:24 - loss: 1.9394 - accuracy: 0.54 - ETA: 1:23 - loss: 1.9406 - accuracy: 0.54 - ETA: 1:21 - loss: 1.9396 - accuracy: 0.54 - ETA: 1:20 - loss: 1.9369 - accuracy: 0.54 - ETA: 1:18 - loss: 1.9337 - accuracy: 0.54 - ETA: 1:17 - loss: 1.9334 - accuracy: 0.54 - ETA: 1:16 - loss: 1.9311 - accuracy: 0.54 - ETA: 1:14 - loss: 1.9286 - accuracy: 0.54 - ETA: 1:13 - loss: 1.9260 - accuracy: 0.54 - ETA: 1:12 - loss: 1.9252 - accuracy: 0.54 - ETA: 1:10 - loss: 1.9232 - accuracy: 0.54 - ETA: 1:09 - loss: 1.9201 - accuracy: 0.54 - ETA: 1:08 - loss: 1.9203 - accuracy: 0.54 - ETA: 1:06 - loss: 1.9180 - accuracy: 0.54 - ETA: 1:05 - loss: 1.9181 - accuracy: 0.54 - ETA: 1:03 - loss: 1.9167 - accuracy: 0.54 - ETA: 1:02 - loss: 1.9151 - accuracy: 0.54 - ETA: 1:01 - loss: 1.9143 - accuracy: 0.54 - ETA: 59s - loss: 1.9164 - accuracy: 0.5467 - ETA: 58s - loss: 1.9146 - accuracy: 0.546 - ETA: 57s - loss: 1.9127 - accuracy: 0.547 - ETA: 55s - loss: 1.9126 - accuracy: 0.547 - ETA: 54s - loss: 1.9153 - accuracy: 0.547 - ETA: 52s - loss: 1.9129 - accuracy: 0.547 - ETA: 51s - loss: 1.9138 - accuracy: 0.547 - ETA: 50s - loss: 1.9118 - accuracy: 0.547 - ETA: 48s - loss: 1.9099 - accuracy: 0.548 - ETA: 47s - loss: 1.9095 - accuracy: 0.548 - ETA: 46s - loss: 1.9070 - accuracy: 0.548 - ETA: 44s - loss: 1.9087 - accuracy: 0.548 - ETA: 43s - loss: 1.9081 - accuracy: 0.549 - ETA: 41s - loss: 1.9045 - accuracy: 0.549 - ETA: 40s - loss: 1.9061 - accuracy: 0.549 - ETA: 39s - loss: 1.9039 - accuracy: 0.549 - ETA: 37s - loss: 1.9030 - accuracy: 0.549 - ETA: 36s - loss: 1.9094 - accuracy: 0.549 - ETA: 34s - loss: 1.9076 - accuracy: 0.549 - ETA: 33s - loss: 1.9059 - accuracy: 0.549 - ETA: 32s - loss: 1.9049 - accuracy: 0.549 - ETA: 30s - loss: 1.9041 - accuracy: 0.549 - ETA: 29s - loss: 1.9039 - accuracy: 0.549 - ETA: 27s - loss: 1.9046 - accuracy: 0.550 - ETA: 26s - loss: 1.9031 - accuracy: 0.549 - ETA: 25s - loss: 1.9008 - accuracy: 0.550 - ETA: 23s - loss: 1.9020 - accuracy: 0.550 - ETA: 22s - loss: 1.9010 - accuracy: 0.550 - ETA: 20s - loss: 1.8993 - accuracy: 0.550 - ETA: 19s - loss: 1.8994 - accuracy: 0.550 - ETA: 18s - loss: 1.8999 - accuracy: 0.550 - ETA: 16s - loss: 1.8972 - accuracy: 0.550 - ETA: 15s - loss: 1.8972 - accuracy: 0.550 - ETA: 13s - loss: 1.8963 - accuracy: 0.550 - ETA: 12s - loss: 1.8966 - accuracy: 0.550 - ETA: 11s - loss: 1.8943 - accuracy: 0.551 - ETA: 9s - loss: 1.8942 - accuracy: 0.551 - ETA: 8s - loss: 1.8920 - accuracy: 0.55 - ETA: 6s - loss: 1.8893 - accuracy: 0.55 - ETA: 5s - loss: 1.8900 - accuracy: 0.55 - ETA: 4s - loss: 1.8888 - accuracy: 0.55 - ETA: 2s - loss: 1.8864 - accuracy: 0.55 - ETA: 1s - loss: 1.8883 - accuracy: 0.55 - 231s 12ms/step - loss: 1.8882 - accuracy: 0.5533 - val_loss: 1.5014 - val_accuracy: 0.6368\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:31 - loss: 1.2772 - accuracy: 0.66 - ETA: 3:27 - loss: 1.2235 - accuracy: 0.67 - ETA: 3:22 - loss: 1.3735 - accuracy: 0.64 - ETA: 3:19 - loss: 1.4076 - accuracy: 0.62 - ETA: 3:17 - loss: 1.4160 - accuracy: 0.62 - ETA: 3:16 - loss: 1.3891 - accuracy: 0.63 - ETA: 3:14 - loss: 1.4149 - accuracy: 0.62 - ETA: 3:14 - loss: 1.4367 - accuracy: 0.62 - ETA: 3:14 - loss: 1.4140 - accuracy: 0.62 - ETA: 3:13 - loss: 1.4068 - accuracy: 0.62 - ETA: 3:11 - loss: 1.4308 - accuracy: 0.62 - ETA: 3:10 - loss: 1.4482 - accuracy: 0.62 - ETA: 3:08 - loss: 1.4690 - accuracy: 0.62 - ETA: 3:07 - loss: 1.4816 - accuracy: 0.61 - ETA: 3:05 - loss: 1.4956 - accuracy: 0.61 - ETA: 3:04 - loss: 1.5110 - accuracy: 0.61 - ETA: 3:03 - loss: 1.5178 - accuracy: 0.61 - ETA: 3:01 - loss: 1.5178 - accuracy: 0.61 - ETA: 3:00 - loss: 1.4988 - accuracy: 0.61 - ETA: 2:59 - loss: 1.4978 - accuracy: 0.61 - ETA: 2:58 - loss: 1.4850 - accuracy: 0.62 - ETA: 2:56 - loss: 1.4911 - accuracy: 0.62 - ETA: 2:55 - loss: 1.4816 - accuracy: 0.62 - ETA: 2:54 - loss: 1.4844 - accuracy: 0.62 - ETA: 2:52 - loss: 1.4806 - accuracy: 0.62 - ETA: 2:51 - loss: 1.4820 - accuracy: 0.62 - ETA: 2:49 - loss: 1.4803 - accuracy: 0.62 - ETA: 2:47 - loss: 1.4796 - accuracy: 0.62 - ETA: 2:46 - loss: 1.4794 - accuracy: 0.62 - ETA: 2:45 - loss: 1.4719 - accuracy: 0.62 - ETA: 2:43 - loss: 1.4710 - accuracy: 0.62 - ETA: 2:42 - loss: 1.4728 - accuracy: 0.62 - ETA: 2:41 - loss: 1.4803 - accuracy: 0.62 - ETA: 2:39 - loss: 1.4722 - accuracy: 0.62 - ETA: 2:38 - loss: 1.4642 - accuracy: 0.62 - ETA: 2:36 - loss: 1.4527 - accuracy: 0.62 - ETA: 2:35 - loss: 1.4491 - accuracy: 0.62 - ETA: 2:33 - loss: 1.4489 - accuracy: 0.63 - ETA: 2:32 - loss: 1.4513 - accuracy: 0.62 - ETA: 2:31 - loss: 1.4579 - accuracy: 0.63 - ETA: 2:29 - loss: 1.4572 - accuracy: 0.63 - ETA: 2:28 - loss: 1.4527 - accuracy: 0.63 - ETA: 2:27 - loss: 1.4555 - accuracy: 0.63 - ETA: 2:25 - loss: 1.4582 - accuracy: 0.63 - ETA: 2:24 - loss: 1.4524 - accuracy: 0.63 - ETA: 2:23 - loss: 1.4522 - accuracy: 0.63 - ETA: 2:21 - loss: 1.4490 - accuracy: 0.63 - ETA: 2:20 - loss: 1.4537 - accuracy: 0.63 - ETA: 2:19 - loss: 1.4512 - accuracy: 0.63 - ETA: 2:17 - loss: 1.4514 - accuracy: 0.63 - ETA: 2:16 - loss: 1.4487 - accuracy: 0.63 - ETA: 2:14 - loss: 1.4498 - accuracy: 0.63 - ETA: 2:13 - loss: 1.4527 - accuracy: 0.63 - ETA: 2:12 - loss: 1.4534 - accuracy: 0.63 - ETA: 2:10 - loss: 1.4541 - accuracy: 0.63 - ETA: 2:09 - loss: 1.4559 - accuracy: 0.63 - ETA: 2:08 - loss: 1.4532 - accuracy: 0.63 - ETA: 2:06 - loss: 1.4529 - accuracy: 0.63 - ETA: 2:05 - loss: 1.4486 - accuracy: 0.63 - ETA: 2:04 - loss: 1.4506 - accuracy: 0.63 - ETA: 2:02 - loss: 1.4458 - accuracy: 0.63 - ETA: 2:01 - loss: 1.4444 - accuracy: 0.63 - ETA: 1:59 - loss: 1.4442 - accuracy: 0.63 - ETA: 1:58 - loss: 1.4455 - accuracy: 0.63 - ETA: 1:57 - loss: 1.4410 - accuracy: 0.63 - ETA: 1:55 - loss: 1.4369 - accuracy: 0.63 - ETA: 1:54 - loss: 1.4423 - accuracy: 0.63 - ETA: 1:53 - loss: 1.4427 - accuracy: 0.63 - ETA: 1:52 - loss: 1.4499 - accuracy: 0.63 - ETA: 1:50 - loss: 1.4448 - accuracy: 0.63 - ETA: 1:49 - loss: 1.4432 - accuracy: 0.63 - ETA: 1:47 - loss: 1.4451 - accuracy: 0.63 - ETA: 1:46 - loss: 1.4467 - accuracy: 0.63 - ETA: 1:45 - loss: 1.4477 - accuracy: 0.63 - ETA: 1:43 - loss: 1.4490 - accuracy: 0.63 - ETA: 1:42 - loss: 1.4517 - accuracy: 0.63 - ETA: 1:41 - loss: 1.4519 - accuracy: 0.63 - ETA: 1:39 - loss: 1.4505 - accuracy: 0.63 - ETA: 1:38 - loss: 1.4514 - accuracy: 0.63 - ETA: 1:37 - loss: 1.4505 - accuracy: 0.63 - ETA: 1:35 - loss: 1.4493 - accuracy: 0.63 - ETA: 1:34 - loss: 1.4565 - accuracy: 0.63 - ETA: 1:33 - loss: 1.4598 - accuracy: 0.63 - ETA: 1:31 - loss: 1.4646 - accuracy: 0.63 - ETA: 1:30 - loss: 1.4629 - accuracy: 0.63 - ETA: 1:28 - loss: 1.4637 - accuracy: 0.63 - ETA: 1:27 - loss: 1.4664 - accuracy: 0.63 - ETA: 1:26 - loss: 1.4676 - accuracy: 0.63 - ETA: 1:24 - loss: 1.4656 - accuracy: 0.63 - ETA: 1:23 - loss: 1.4653 - accuracy: 0.63 - ETA: 1:22 - loss: 1.4695 - accuracy: 0.63 - ETA: 1:20 - loss: 1.4671 - accuracy: 0.63 - ETA: 1:19 - loss: 1.4666 - accuracy: 0.63 - ETA: 1:18 - loss: 1.4688 - accuracy: 0.63 - ETA: 1:16 - loss: 1.4706 - accuracy: 0.63 - ETA: 1:15 - loss: 1.4720 - accuracy: 0.63 - ETA: 1:14 - loss: 1.4730 - accuracy: 0.63 - ETA: 1:12 - loss: 1.4750 - accuracy: 0.63 - ETA: 1:11 - loss: 1.4750 - accuracy: 0.63 - ETA: 1:09 - loss: 1.4754 - accuracy: 0.63 - ETA: 1:08 - loss: 1.4763 - accuracy: 0.63 - ETA: 1:07 - loss: 1.4729 - accuracy: 0.63 - ETA: 1:05 - loss: 1.4715 - accuracy: 0.63 - ETA: 1:04 - loss: 1.4682 - accuracy: 0.63 - ETA: 1:03 - loss: 1.4696 - accuracy: 0.63 - ETA: 1:01 - loss: 1.4676 - accuracy: 0.63 - ETA: 1:00 - loss: 1.4699 - accuracy: 0.63 - ETA: 59s - loss: 1.4719 - accuracy: 0.6351 - ETA: 57s - loss: 1.4702 - accuracy: 0.635 - ETA: 56s - loss: 1.4692 - accuracy: 0.635 - ETA: 54s - loss: 1.4668 - accuracy: 0.635 - ETA: 53s - loss: 1.4656 - accuracy: 0.636 - ETA: 52s - loss: 1.4635 - accuracy: 0.637 - ETA: 50s - loss: 1.4622 - accuracy: 0.636 - ETA: 49s - loss: 1.4616 - accuracy: 0.637 - ETA: 48s - loss: 1.4602 - accuracy: 0.637 - ETA: 46s - loss: 1.4600 - accuracy: 0.637 - ETA: 45s - loss: 1.4589 - accuracy: 0.637 - ETA: 43s - loss: 1.4607 - accuracy: 0.637 - ETA: 42s - loss: 1.4576 - accuracy: 0.637 - ETA: 41s - loss: 1.4570 - accuracy: 0.637 - ETA: 39s - loss: 1.4557 - accuracy: 0.638 - ETA: 38s - loss: 1.4575 - accuracy: 0.637 - ETA: 37s - loss: 1.4554 - accuracy: 0.638 - ETA: 35s - loss: 1.4528 - accuracy: 0.638 - ETA: 34s - loss: 1.4526 - accuracy: 0.638 - ETA: 33s - loss: 1.4551 - accuracy: 0.638 - ETA: 31s - loss: 1.4586 - accuracy: 0.638 - ETA: 30s - loss: 1.4604 - accuracy: 0.637 - ETA: 28s - loss: 1.4622 - accuracy: 0.637 - ETA: 27s - loss: 1.4612 - accuracy: 0.637 - ETA: 26s - loss: 1.4605 - accuracy: 0.637 - ETA: 24s - loss: 1.4578 - accuracy: 0.638 - ETA: 23s - loss: 1.4585 - accuracy: 0.638 - ETA: 22s - loss: 1.4577 - accuracy: 0.638 - ETA: 20s - loss: 1.4570 - accuracy: 0.638 - ETA: 19s - loss: 1.4546 - accuracy: 0.639 - ETA: 17s - loss: 1.4562 - accuracy: 0.638 - ETA: 16s - loss: 1.4538 - accuracy: 0.639 - ETA: 15s - loss: 1.4523 - accuracy: 0.639 - ETA: 13s - loss: 1.4531 - accuracy: 0.639 - ETA: 12s - loss: 1.4538 - accuracy: 0.639 - ETA: 10s - loss: 1.4535 - accuracy: 0.639 - ETA: 9s - loss: 1.4518 - accuracy: 0.639 - ETA: 8s - loss: 1.4496 - accuracy: 0.63 - ETA: 6s - loss: 1.4499 - accuracy: 0.63 - ETA: 5s - loss: 1.4494 - accuracy: 0.63 - ETA: 3s - loss: 1.4484 - accuracy: 0.63 - ETA: 2s - loss: 1.4478 - accuracy: 0.63 - ETA: 1s - loss: 1.4457 - accuracy: 0.63 - 230s 12ms/step - loss: 1.4474 - accuracy: 0.6397 - val_loss: 1.3637 - val_accuracy: 0.6892\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:47 - loss: 1.1067 - accuracy: 0.70 - ETA: 3:32 - loss: 1.0532 - accuracy: 0.69 - ETA: 3:26 - loss: 1.1921 - accuracy: 0.68 - ETA: 3:21 - loss: 1.2072 - accuracy: 0.68 - ETA: 3:19 - loss: 1.1404 - accuracy: 0.69 - ETA: 3:16 - loss: 1.1374 - accuracy: 0.69 - ETA: 3:15 - loss: 1.1624 - accuracy: 0.68 - ETA: 3:13 - loss: 1.1809 - accuracy: 0.68 - ETA: 3:11 - loss: 1.1757 - accuracy: 0.68 - ETA: 3:09 - loss: 1.1881 - accuracy: 0.68 - ETA: 3:08 - loss: 1.1787 - accuracy: 0.68 - ETA: 3:07 - loss: 1.1681 - accuracy: 0.69 - ETA: 3:05 - loss: 1.1390 - accuracy: 0.69 - ETA: 3:04 - loss: 1.1499 - accuracy: 0.69 - ETA: 3:02 - loss: 1.1428 - accuracy: 0.69 - ETA: 3:01 - loss: 1.1358 - accuracy: 0.69 - ETA: 3:00 - loss: 1.1298 - accuracy: 0.69 - ETA: 2:59 - loss: 1.1357 - accuracy: 0.70 - ETA: 2:58 - loss: 1.1407 - accuracy: 0.70 - ETA: 2:57 - loss: 1.1547 - accuracy: 0.70 - ETA: 2:55 - loss: 1.1451 - accuracy: 0.70 - ETA: 2:54 - loss: 1.1460 - accuracy: 0.70 - ETA: 2:52 - loss: 1.1357 - accuracy: 0.70 - ETA: 2:51 - loss: 1.1216 - accuracy: 0.70 - ETA: 2:49 - loss: 1.1288 - accuracy: 0.70 - ETA: 2:48 - loss: 1.1333 - accuracy: 0.70 - ETA: 2:46 - loss: 1.1265 - accuracy: 0.70 - ETA: 2:45 - loss: 1.1199 - accuracy: 0.70 - ETA: 2:44 - loss: 1.1217 - accuracy: 0.71 - ETA: 2:42 - loss: 1.1216 - accuracy: 0.71 - ETA: 2:41 - loss: 1.1204 - accuracy: 0.71 - ETA: 2:40 - loss: 1.1121 - accuracy: 0.71 - ETA: 2:39 - loss: 1.1088 - accuracy: 0.71 - ETA: 2:37 - loss: 1.1142 - accuracy: 0.71 - ETA: 2:36 - loss: 1.1126 - accuracy: 0.71 - ETA: 2:34 - loss: 1.1283 - accuracy: 0.71 - ETA: 2:33 - loss: 1.1269 - accuracy: 0.71 - ETA: 2:31 - loss: 1.1218 - accuracy: 0.71 - ETA: 2:30 - loss: 1.1280 - accuracy: 0.71 - ETA: 2:29 - loss: 1.1263 - accuracy: 0.71 - ETA: 2:27 - loss: 1.1268 - accuracy: 0.71 - ETA: 2:26 - loss: 1.1226 - accuracy: 0.71 - ETA: 2:25 - loss: 1.1229 - accuracy: 0.70 - ETA: 2:23 - loss: 1.1202 - accuracy: 0.70 - ETA: 2:22 - loss: 1.1175 - accuracy: 0.70 - ETA: 2:21 - loss: 1.1126 - accuracy: 0.71 - ETA: 2:20 - loss: 1.1123 - accuracy: 0.71 - ETA: 2:18 - loss: 1.1162 - accuracy: 0.71 - ETA: 2:17 - loss: 1.1180 - accuracy: 0.71 - ETA: 2:16 - loss: 1.1222 - accuracy: 0.70 - ETA: 2:14 - loss: 1.1172 - accuracy: 0.71 - ETA: 2:13 - loss: 1.1159 - accuracy: 0.71 - ETA: 2:12 - loss: 1.1184 - accuracy: 0.70 - ETA: 2:10 - loss: 1.1132 - accuracy: 0.71 - ETA: 2:09 - loss: 1.1170 - accuracy: 0.71 - ETA: 2:08 - loss: 1.1118 - accuracy: 0.71 - ETA: 2:07 - loss: 1.1112 - accuracy: 0.71 - ETA: 2:05 - loss: 1.1116 - accuracy: 0.71 - ETA: 2:04 - loss: 1.1117 - accuracy: 0.71 - ETA: 2:03 - loss: 1.1081 - accuracy: 0.71 - ETA: 2:01 - loss: 1.1093 - accuracy: 0.71 - ETA: 2:00 - loss: 1.1057 - accuracy: 0.71 - ETA: 1:58 - loss: 1.1096 - accuracy: 0.71 - ETA: 1:57 - loss: 1.1146 - accuracy: 0.71 - ETA: 1:56 - loss: 1.1125 - accuracy: 0.71 - ETA: 1:55 - loss: 1.1083 - accuracy: 0.71 - ETA: 1:53 - loss: 1.1102 - accuracy: 0.71 - ETA: 1:52 - loss: 1.1085 - accuracy: 0.71 - ETA: 1:51 - loss: 1.1133 - accuracy: 0.71 - ETA: 1:49 - loss: 1.1147 - accuracy: 0.71 - ETA: 1:48 - loss: 1.1253 - accuracy: 0.71 - ETA: 1:46 - loss: 1.1230 - accuracy: 0.71 - ETA: 1:45 - loss: 1.1223 - accuracy: 0.71 - ETA: 1:44 - loss: 1.1214 - accuracy: 0.71 - ETA: 1:43 - loss: 1.1219 - accuracy: 0.71 - ETA: 1:41 - loss: 1.1205 - accuracy: 0.71 - ETA: 1:40 - loss: 1.1191 - accuracy: 0.71 - ETA: 1:39 - loss: 1.1164 - accuracy: 0.71 - ETA: 1:37 - loss: 1.1198 - accuracy: 0.71 - ETA: 1:36 - loss: 1.1177 - accuracy: 0.71 - ETA: 1:34 - loss: 1.1173 - accuracy: 0.71 - ETA: 1:33 - loss: 1.1185 - accuracy: 0.71 - ETA: 1:32 - loss: 1.1171 - accuracy: 0.71 - ETA: 1:30 - loss: 1.1196 - accuracy: 0.71 - ETA: 1:29 - loss: 1.1234 - accuracy: 0.71 - ETA: 1:28 - loss: 1.1240 - accuracy: 0.71 - ETA: 1:26 - loss: 1.1240 - accuracy: 0.71 - ETA: 1:25 - loss: 1.1248 - accuracy: 0.71 - ETA: 1:24 - loss: 1.1250 - accuracy: 0.71 - ETA: 1:22 - loss: 1.1219 - accuracy: 0.71 - ETA: 1:21 - loss: 1.1204 - accuracy: 0.71 - ETA: 1:20 - loss: 1.1184 - accuracy: 0.71 - ETA: 1:18 - loss: 1.1181 - accuracy: 0.71 - ETA: 1:17 - loss: 1.1181 - accuracy: 0.71 - ETA: 1:15 - loss: 1.1160 - accuracy: 0.71 - ETA: 1:14 - loss: 1.1183 - accuracy: 0.71 - ETA: 1:13 - loss: 1.1217 - accuracy: 0.71 - ETA: 1:11 - loss: 1.1205 - accuracy: 0.71 - ETA: 1:10 - loss: 1.1196 - accuracy: 0.71 - ETA: 1:09 - loss: 1.1204 - accuracy: 0.71 - ETA: 1:07 - loss: 1.1196 - accuracy: 0.71 - ETA: 1:06 - loss: 1.1187 - accuracy: 0.71 - ETA: 1:05 - loss: 1.1189 - accuracy: 0.71 - ETA: 1:03 - loss: 1.1202 - accuracy: 0.71 - ETA: 1:02 - loss: 1.1195 - accuracy: 0.71 - ETA: 1:01 - loss: 1.1184 - accuracy: 0.71 - ETA: 59s - loss: 1.1194 - accuracy: 0.7136 - ETA: 58s - loss: 1.1206 - accuracy: 0.713 - ETA: 56s - loss: 1.1237 - accuracy: 0.712 - ETA: 55s - loss: 1.1237 - accuracy: 0.712 - ETA: 54s - loss: 1.1263 - accuracy: 0.712 - ETA: 52s - loss: 1.1255 - accuracy: 0.712 - ETA: 51s - loss: 1.1254 - accuracy: 0.712 - ETA: 50s - loss: 1.1236 - accuracy: 0.712 - ETA: 48s - loss: 1.1247 - accuracy: 0.712 - ETA: 47s - loss: 1.1278 - accuracy: 0.711 - ETA: 46s - loss: 1.1279 - accuracy: 0.711 - ETA: 44s - loss: 1.1293 - accuracy: 0.712 - ETA: 43s - loss: 1.1297 - accuracy: 0.712 - ETA: 42s - loss: 1.1310 - accuracy: 0.711 - ETA: 40s - loss: 1.1318 - accuracy: 0.711 - ETA: 39s - loss: 1.1328 - accuracy: 0.711 - ETA: 38s - loss: 1.1318 - accuracy: 0.711 - ETA: 36s - loss: 1.1340 - accuracy: 0.710 - ETA: 35s - loss: 1.1360 - accuracy: 0.710 - ETA: 34s - loss: 1.1372 - accuracy: 0.710 - ETA: 32s - loss: 1.1364 - accuracy: 0.710 - ETA: 31s - loss: 1.1368 - accuracy: 0.710 - ETA: 29s - loss: 1.1407 - accuracy: 0.710 - ETA: 28s - loss: 1.1415 - accuracy: 0.710 - ETA: 27s - loss: 1.1410 - accuracy: 0.710 - ETA: 25s - loss: 1.1409 - accuracy: 0.710 - ETA: 24s - loss: 1.1429 - accuracy: 0.710 - ETA: 23s - loss: 1.1424 - accuracy: 0.711 - ETA: 21s - loss: 1.1398 - accuracy: 0.711 - ETA: 20s - loss: 1.1400 - accuracy: 0.711 - ETA: 19s - loss: 1.1397 - accuracy: 0.711 - ETA: 17s - loss: 1.1385 - accuracy: 0.711 - ETA: 16s - loss: 1.1375 - accuracy: 0.711 - ETA: 14s - loss: 1.1367 - accuracy: 0.711 - ETA: 13s - loss: 1.1357 - accuracy: 0.711 - ETA: 12s - loss: 1.1362 - accuracy: 0.711 - ETA: 10s - loss: 1.1360 - accuracy: 0.711 - ETA: 9s - loss: 1.1370 - accuracy: 0.711 - ETA: 8s - loss: 1.1377 - accuracy: 0.71 - ETA: 6s - loss: 1.1375 - accuracy: 0.71 - ETA: 5s - loss: 1.1378 - accuracy: 0.71 - ETA: 3s - loss: 1.1368 - accuracy: 0.71 - ETA: 2s - loss: 1.1371 - accuracy: 0.71 - ETA: 1s - loss: 1.1392 - accuracy: 0.71 - 222s 12ms/step - loss: 1.1416 - accuracy: 0.7103 - val_loss: 1.3514 - val_accuracy: 0.6867\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:26 - loss: 1.0398 - accuracy: 0.73 - ETA: 3:22 - loss: 1.1230 - accuracy: 0.71 - ETA: 3:20 - loss: 0.9921 - accuracy: 0.74 - ETA: 3:18 - loss: 0.9178 - accuracy: 0.75 - ETA: 3:14 - loss: 0.8991 - accuracy: 0.75 - ETA: 3:13 - loss: 0.9551 - accuracy: 0.73 - ETA: 3:10 - loss: 0.9439 - accuracy: 0.73 - ETA: 3:09 - loss: 0.9746 - accuracy: 0.73 - ETA: 3:09 - loss: 1.0035 - accuracy: 0.72 - ETA: 3:08 - loss: 0.9810 - accuracy: 0.73 - ETA: 3:07 - loss: 0.9621 - accuracy: 0.73 - ETA: 3:06 - loss: 0.9499 - accuracy: 0.74 - ETA: 3:05 - loss: 0.9425 - accuracy: 0.74 - ETA: 3:04 - loss: 0.9253 - accuracy: 0.74 - ETA: 3:02 - loss: 0.9190 - accuracy: 0.74 - ETA: 3:00 - loss: 0.9193 - accuracy: 0.75 - ETA: 2:59 - loss: 0.9268 - accuracy: 0.74 - ETA: 2:58 - loss: 0.9430 - accuracy: 0.74 - ETA: 2:56 - loss: 0.9423 - accuracy: 0.74 - ETA: 2:55 - loss: 0.9476 - accuracy: 0.74 - ETA: 2:54 - loss: 0.9426 - accuracy: 0.74 - ETA: 2:53 - loss: 0.9316 - accuracy: 0.74 - ETA: 2:52 - loss: 0.9364 - accuracy: 0.74 - ETA: 2:51 - loss: 0.9300 - accuracy: 0.75 - ETA: 2:50 - loss: 0.9249 - accuracy: 0.75 - ETA: 2:48 - loss: 0.9209 - accuracy: 0.75 - ETA: 2:47 - loss: 0.9405 - accuracy: 0.75 - ETA: 2:46 - loss: 0.9535 - accuracy: 0.75 - ETA: 2:44 - loss: 0.9598 - accuracy: 0.75 - ETA: 2:43 - loss: 0.9628 - accuracy: 0.74 - ETA: 2:42 - loss: 0.9495 - accuracy: 0.75 - ETA: 2:41 - loss: 0.9508 - accuracy: 0.75 - ETA: 2:39 - loss: 0.9504 - accuracy: 0.75 - ETA: 2:38 - loss: 0.9537 - accuracy: 0.75 - ETA: 2:37 - loss: 0.9521 - accuracy: 0.75 - ETA: 2:36 - loss: 0.9482 - accuracy: 0.75 - ETA: 2:34 - loss: 0.9445 - accuracy: 0.75 - ETA: 2:33 - loss: 0.9424 - accuracy: 0.75 - ETA: 2:32 - loss: 0.9345 - accuracy: 0.75 - ETA: 2:30 - loss: 0.9366 - accuracy: 0.75 - ETA: 2:29 - loss: 0.9494 - accuracy: 0.75 - ETA: 2:27 - loss: 0.9490 - accuracy: 0.75 - ETA: 2:26 - loss: 0.9473 - accuracy: 0.75 - ETA: 2:25 - loss: 0.9495 - accuracy: 0.75 - ETA: 2:23 - loss: 0.9515 - accuracy: 0.75 - ETA: 2:22 - loss: 0.9546 - accuracy: 0.75 - ETA: 2:21 - loss: 0.9482 - accuracy: 0.75 - ETA: 2:20 - loss: 0.9491 - accuracy: 0.75 - ETA: 2:18 - loss: 0.9433 - accuracy: 0.75 - ETA: 2:17 - loss: 0.9397 - accuracy: 0.75 - ETA: 2:15 - loss: 0.9411 - accuracy: 0.75 - ETA: 2:14 - loss: 0.9412 - accuracy: 0.75 - ETA: 2:13 - loss: 0.9426 - accuracy: 0.75 - ETA: 2:11 - loss: 0.9439 - accuracy: 0.75 - ETA: 2:10 - loss: 0.9441 - accuracy: 0.75 - ETA: 2:08 - loss: 0.9403 - accuracy: 0.75 - ETA: 2:07 - loss: 0.9407 - accuracy: 0.75 - ETA: 2:06 - loss: 0.9413 - accuracy: 0.75 - ETA: 2:05 - loss: 0.9418 - accuracy: 0.75 - ETA: 2:03 - loss: 0.9398 - accuracy: 0.75 - ETA: 2:02 - loss: 0.9392 - accuracy: 0.75 - ETA: 2:01 - loss: 0.9405 - accuracy: 0.75 - ETA: 1:59 - loss: 0.9456 - accuracy: 0.75 - ETA: 1:58 - loss: 0.9483 - accuracy: 0.75 - ETA: 1:56 - loss: 0.9479 - accuracy: 0.75 - ETA: 1:55 - loss: 0.9463 - accuracy: 0.75 - ETA: 1:54 - loss: 0.9465 - accuracy: 0.75 - ETA: 1:53 - loss: 0.9438 - accuracy: 0.75 - ETA: 1:51 - loss: 0.9469 - accuracy: 0.75 - ETA: 1:50 - loss: 0.9477 - accuracy: 0.75 - ETA: 1:49 - loss: 0.9471 - accuracy: 0.75 - ETA: 1:47 - loss: 0.9479 - accuracy: 0.75 - ETA: 1:46 - loss: 0.9478 - accuracy: 0.75 - ETA: 1:44 - loss: 0.9483 - accuracy: 0.75 - ETA: 1:43 - loss: 0.9444 - accuracy: 0.75 - ETA: 1:42 - loss: 0.9416 - accuracy: 0.75 - ETA: 1:40 - loss: 0.9412 - accuracy: 0.75 - ETA: 1:39 - loss: 0.9364 - accuracy: 0.75 - ETA: 1:38 - loss: 0.9353 - accuracy: 0.75 - ETA: 1:36 - loss: 0.9373 - accuracy: 0.75 - ETA: 1:35 - loss: 0.9392 - accuracy: 0.75 - ETA: 1:34 - loss: 0.9379 - accuracy: 0.75 - ETA: 1:32 - loss: 0.9359 - accuracy: 0.75 - ETA: 1:31 - loss: 0.9364 - accuracy: 0.75 - ETA: 1:29 - loss: 0.9396 - accuracy: 0.75 - ETA: 1:28 - loss: 0.9384 - accuracy: 0.75 - ETA: 1:27 - loss: 0.9348 - accuracy: 0.75 - ETA: 1:25 - loss: 0.9345 - accuracy: 0.75 - ETA: 1:24 - loss: 0.9377 - accuracy: 0.75 - ETA: 1:23 - loss: 0.9366 - accuracy: 0.75 - ETA: 1:21 - loss: 0.9334 - accuracy: 0.75 - ETA: 1:20 - loss: 0.9312 - accuracy: 0.75 - ETA: 1:18 - loss: 0.9316 - accuracy: 0.75 - ETA: 1:17 - loss: 0.9315 - accuracy: 0.75 - ETA: 1:16 - loss: 0.9310 - accuracy: 0.75 - ETA: 1:14 - loss: 0.9318 - accuracy: 0.75 - ETA: 1:13 - loss: 0.9311 - accuracy: 0.75 - ETA: 1:12 - loss: 0.9291 - accuracy: 0.75 - ETA: 1:10 - loss: 0.9268 - accuracy: 0.75 - ETA: 1:09 - loss: 0.9275 - accuracy: 0.75 - ETA: 1:08 - loss: 0.9260 - accuracy: 0.75 - ETA: 1:06 - loss: 0.9250 - accuracy: 0.75 - ETA: 1:05 - loss: 0.9271 - accuracy: 0.75 - ETA: 1:03 - loss: 0.9254 - accuracy: 0.75 - ETA: 1:02 - loss: 0.9271 - accuracy: 0.75 - ETA: 1:01 - loss: 0.9277 - accuracy: 0.75 - ETA: 59s - loss: 0.9263 - accuracy: 0.7564 - ETA: 58s - loss: 0.9280 - accuracy: 0.755 - ETA: 57s - loss: 0.9287 - accuracy: 0.755 - ETA: 55s - loss: 0.9279 - accuracy: 0.755 - ETA: 54s - loss: 0.9304 - accuracy: 0.755 - ETA: 53s - loss: 0.9312 - accuracy: 0.755 - ETA: 51s - loss: 0.9318 - accuracy: 0.755 - ETA: 50s - loss: 0.9318 - accuracy: 0.754 - ETA: 49s - loss: 0.9325 - accuracy: 0.755 - ETA: 47s - loss: 0.9322 - accuracy: 0.754 - ETA: 46s - loss: 0.9298 - accuracy: 0.755 - ETA: 44s - loss: 0.9306 - accuracy: 0.755 - ETA: 43s - loss: 0.9308 - accuracy: 0.755 - ETA: 42s - loss: 0.9305 - accuracy: 0.755 - ETA: 40s - loss: 0.9297 - accuracy: 0.755 - ETA: 39s - loss: 0.9300 - accuracy: 0.755 - ETA: 38s - loss: 0.9321 - accuracy: 0.755 - ETA: 36s - loss: 0.9322 - accuracy: 0.755 - ETA: 35s - loss: 0.9316 - accuracy: 0.755 - ETA: 33s - loss: 0.9302 - accuracy: 0.755 - ETA: 32s - loss: 0.9323 - accuracy: 0.755 - ETA: 31s - loss: 0.9316 - accuracy: 0.756 - ETA: 29s - loss: 0.9339 - accuracy: 0.755 - ETA: 28s - loss: 0.9330 - accuracy: 0.755 - ETA: 27s - loss: 0.9319 - accuracy: 0.756 - ETA: 25s - loss: 0.9324 - accuracy: 0.755 - ETA: 24s - loss: 0.9329 - accuracy: 0.755 - ETA: 23s - loss: 0.9328 - accuracy: 0.755 - ETA: 21s - loss: 0.9310 - accuracy: 0.755 - ETA: 20s - loss: 0.9334 - accuracy: 0.755 - ETA: 18s - loss: 0.9331 - accuracy: 0.755 - ETA: 17s - loss: 0.9379 - accuracy: 0.755 - ETA: 16s - loss: 0.9391 - accuracy: 0.755 - ETA: 14s - loss: 0.9387 - accuracy: 0.755 - ETA: 13s - loss: 0.9396 - accuracy: 0.755 - ETA: 12s - loss: 0.9418 - accuracy: 0.754 - ETA: 10s - loss: 0.9411 - accuracy: 0.754 - ETA: 9s - loss: 0.9436 - accuracy: 0.754 - ETA: 8s - loss: 0.9446 - accuracy: 0.75 - ETA: 6s - loss: 0.9442 - accuracy: 0.75 - ETA: 5s - loss: 0.9417 - accuracy: 0.75 - ETA: 3s - loss: 0.9417 - accuracy: 0.75 - ETA: 2s - loss: 0.9390 - accuracy: 0.75 - ETA: 1s - loss: 0.9391 - accuracy: 0.75 - 218s 11ms/step - loss: 0.9364 - accuracy: 0.7561 - val_loss: 1.2247 - val_accuracy: 0.7242\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:28 - loss: 0.7654 - accuracy: 0.76 - ETA: 3:19 - loss: 0.8155 - accuracy: 0.74 - ETA: 3:15 - loss: 0.8440 - accuracy: 0.75 - ETA: 3:13 - loss: 0.8359 - accuracy: 0.75 - ETA: 3:12 - loss: 0.8656 - accuracy: 0.75 - ETA: 3:11 - loss: 0.8494 - accuracy: 0.75 - ETA: 3:11 - loss: 0.8605 - accuracy: 0.75 - ETA: 3:11 - loss: 0.8607 - accuracy: 0.76 - ETA: 3:11 - loss: 0.8521 - accuracy: 0.76 - ETA: 3:10 - loss: 0.8280 - accuracy: 0.77 - ETA: 3:10 - loss: 0.8211 - accuracy: 0.77 - ETA: 3:07 - loss: 0.8429 - accuracy: 0.76 - ETA: 3:06 - loss: 0.8297 - accuracy: 0.77 - ETA: 3:05 - loss: 0.8322 - accuracy: 0.77 - ETA: 3:04 - loss: 0.8359 - accuracy: 0.77 - ETA: 3:02 - loss: 0.8279 - accuracy: 0.77 - ETA: 3:01 - loss: 0.8256 - accuracy: 0.77 - ETA: 3:00 - loss: 0.8122 - accuracy: 0.77 - ETA: 2:58 - loss: 0.8256 - accuracy: 0.77 - ETA: 2:58 - loss: 0.8233 - accuracy: 0.77 - ETA: 2:57 - loss: 0.8125 - accuracy: 0.77 - ETA: 2:55 - loss: 0.8123 - accuracy: 0.77 - ETA: 2:54 - loss: 0.8063 - accuracy: 0.77 - ETA: 2:52 - loss: 0.8052 - accuracy: 0.77 - ETA: 2:51 - loss: 0.8029 - accuracy: 0.77 - ETA: 2:49 - loss: 0.8113 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8164 - accuracy: 0.77 - ETA: 2:46 - loss: 0.8169 - accuracy: 0.77 - ETA: 2:45 - loss: 0.8141 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8099 - accuracy: 0.77 - ETA: 2:42 - loss: 0.8013 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8038 - accuracy: 0.77 - ETA: 2:40 - loss: 0.7938 - accuracy: 0.78 - ETA: 2:38 - loss: 0.7940 - accuracy: 0.78 - ETA: 2:37 - loss: 0.7962 - accuracy: 0.78 - ETA: 2:35 - loss: 0.7973 - accuracy: 0.78 - ETA: 2:34 - loss: 0.7980 - accuracy: 0.78 - ETA: 2:33 - loss: 0.8009 - accuracy: 0.77 - ETA: 2:31 - loss: 0.7962 - accuracy: 0.78 - ETA: 2:30 - loss: 0.7963 - accuracy: 0.78 - ETA: 2:28 - loss: 0.7962 - accuracy: 0.78 - ETA: 2:27 - loss: 0.7913 - accuracy: 0.78 - ETA: 2:26 - loss: 0.7896 - accuracy: 0.78 - ETA: 2:25 - loss: 0.7839 - accuracy: 0.78 - ETA: 2:23 - loss: 0.7740 - accuracy: 0.78 - ETA: 2:22 - loss: 0.7732 - accuracy: 0.78 - ETA: 2:20 - loss: 0.7763 - accuracy: 0.78 - ETA: 2:19 - loss: 0.7732 - accuracy: 0.78 - ETA: 2:18 - loss: 0.7709 - accuracy: 0.78 - ETA: 2:16 - loss: 0.7672 - accuracy: 0.78 - ETA: 2:15 - loss: 0.7714 - accuracy: 0.78 - ETA: 2:14 - loss: 0.7715 - accuracy: 0.78 - ETA: 2:12 - loss: 0.7750 - accuracy: 0.78 - ETA: 2:11 - loss: 0.7794 - accuracy: 0.78 - ETA: 2:10 - loss: 0.7832 - accuracy: 0.78 - ETA: 2:08 - loss: 0.7804 - accuracy: 0.78 - ETA: 2:07 - loss: 0.7786 - accuracy: 0.78 - ETA: 2:06 - loss: 0.7757 - accuracy: 0.78 - ETA: 2:04 - loss: 0.7760 - accuracy: 0.78 - ETA: 2:03 - loss: 0.7806 - accuracy: 0.78 - ETA: 2:02 - loss: 0.7844 - accuracy: 0.78 - ETA: 2:00 - loss: 0.7855 - accuracy: 0.78 - ETA: 1:59 - loss: 0.7895 - accuracy: 0.78 - ETA: 1:57 - loss: 0.7894 - accuracy: 0.78 - ETA: 1:56 - loss: 0.7850 - accuracy: 0.78 - ETA: 1:55 - loss: 0.7869 - accuracy: 0.78 - ETA: 1:53 - loss: 0.7881 - accuracy: 0.78 - ETA: 1:52 - loss: 0.7898 - accuracy: 0.78 - ETA: 1:51 - loss: 0.7910 - accuracy: 0.78 - ETA: 1:49 - loss: 0.7932 - accuracy: 0.78 - ETA: 1:48 - loss: 0.7965 - accuracy: 0.78 - ETA: 1:47 - loss: 0.7959 - accuracy: 0.78 - ETA: 1:45 - loss: 0.7935 - accuracy: 0.78 - ETA: 1:44 - loss: 0.7919 - accuracy: 0.78 - ETA: 1:42 - loss: 0.7934 - accuracy: 0.78 - ETA: 1:41 - loss: 0.7906 - accuracy: 0.78 - ETA: 1:40 - loss: 0.7949 - accuracy: 0.78 - ETA: 1:38 - loss: 0.7957 - accuracy: 0.78 - ETA: 1:37 - loss: 0.7962 - accuracy: 0.78 - ETA: 1:36 - loss: 0.7950 - accuracy: 0.78 - ETA: 1:35 - loss: 0.7987 - accuracy: 0.78 - ETA: 1:33 - loss: 0.7965 - accuracy: 0.78 - ETA: 1:32 - loss: 0.7997 - accuracy: 0.78 - ETA: 1:30 - loss: 0.7982 - accuracy: 0.78 - ETA: 1:29 - loss: 0.7951 - accuracy: 0.78 - ETA: 1:28 - loss: 0.7957 - accuracy: 0.78 - ETA: 1:26 - loss: 0.7962 - accuracy: 0.78 - ETA: 1:25 - loss: 0.7943 - accuracy: 0.78 - ETA: 1:24 - loss: 0.7920 - accuracy: 0.78 - ETA: 1:22 - loss: 0.7941 - accuracy: 0.78 - ETA: 1:21 - loss: 0.7960 - accuracy: 0.78 - ETA: 1:20 - loss: 0.7973 - accuracy: 0.78 - ETA: 1:18 - loss: 0.7987 - accuracy: 0.78 - ETA: 1:17 - loss: 0.7994 - accuracy: 0.78 - ETA: 1:16 - loss: 0.8003 - accuracy: 0.78 - ETA: 1:14 - loss: 0.7980 - accuracy: 0.78 - ETA: 1:13 - loss: 0.8006 - accuracy: 0.78 - ETA: 1:11 - loss: 0.8010 - accuracy: 0.78 - ETA: 1:10 - loss: 0.8009 - accuracy: 0.78 - ETA: 1:09 - loss: 0.7991 - accuracy: 0.78 - ETA: 1:07 - loss: 0.7988 - accuracy: 0.78 - ETA: 1:06 - loss: 0.7999 - accuracy: 0.78 - ETA: 1:05 - loss: 0.7973 - accuracy: 0.78 - ETA: 1:03 - loss: 0.7989 - accuracy: 0.78 - ETA: 1:02 - loss: 0.7972 - accuracy: 0.78 - ETA: 1:01 - loss: 0.7978 - accuracy: 0.78 - ETA: 59s - loss: 0.7997 - accuracy: 0.7861 - ETA: 58s - loss: 0.7962 - accuracy: 0.787 - ETA: 56s - loss: 0.7962 - accuracy: 0.787 - ETA: 55s - loss: 0.7977 - accuracy: 0.787 - ETA: 54s - loss: 0.7958 - accuracy: 0.787 - ETA: 52s - loss: 0.7970 - accuracy: 0.786 - ETA: 51s - loss: 0.7978 - accuracy: 0.786 - ETA: 50s - loss: 0.7992 - accuracy: 0.786 - ETA: 48s - loss: 0.8000 - accuracy: 0.785 - ETA: 47s - loss: 0.8011 - accuracy: 0.785 - ETA: 46s - loss: 0.8008 - accuracy: 0.785 - ETA: 44s - loss: 0.8022 - accuracy: 0.785 - ETA: 43s - loss: 0.8003 - accuracy: 0.785 - ETA: 42s - loss: 0.7968 - accuracy: 0.786 - ETA: 40s - loss: 0.7961 - accuracy: 0.786 - ETA: 39s - loss: 0.7950 - accuracy: 0.786 - ETA: 37s - loss: 0.7958 - accuracy: 0.786 - ETA: 36s - loss: 0.7948 - accuracy: 0.787 - ETA: 35s - loss: 0.7919 - accuracy: 0.787 - ETA: 33s - loss: 0.7939 - accuracy: 0.787 - ETA: 32s - loss: 0.7938 - accuracy: 0.787 - ETA: 31s - loss: 0.7949 - accuracy: 0.787 - ETA: 29s - loss: 0.7962 - accuracy: 0.787 - ETA: 28s - loss: 0.7974 - accuracy: 0.787 - ETA: 27s - loss: 0.7974 - accuracy: 0.787 - ETA: 25s - loss: 0.7984 - accuracy: 0.787 - ETA: 24s - loss: 0.7962 - accuracy: 0.787 - ETA: 22s - loss: 0.7962 - accuracy: 0.787 - ETA: 21s - loss: 0.7952 - accuracy: 0.787 - ETA: 20s - loss: 0.7949 - accuracy: 0.787 - ETA: 18s - loss: 0.7943 - accuracy: 0.788 - ETA: 17s - loss: 0.7936 - accuracy: 0.788 - ETA: 16s - loss: 0.7930 - accuracy: 0.788 - ETA: 14s - loss: 0.7941 - accuracy: 0.788 - ETA: 13s - loss: 0.7944 - accuracy: 0.788 - ETA: 12s - loss: 0.7933 - accuracy: 0.788 - ETA: 10s - loss: 0.7937 - accuracy: 0.787 - ETA: 9s - loss: 0.7931 - accuracy: 0.787 - ETA: 7s - loss: 0.7915 - accuracy: 0.78 - ETA: 6s - loss: 0.7907 - accuracy: 0.78 - ETA: 5s - loss: 0.7912 - accuracy: 0.78 - ETA: 3s - loss: 0.7919 - accuracy: 0.78 - ETA: 2s - loss: 0.7904 - accuracy: 0.78 - ETA: 1s - loss: 0.7890 - accuracy: 0.78 - 217s 11ms/step - loss: 0.7889 - accuracy: 0.7882 - val_loss: 1.2775 - val_accuracy: 0.7345\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:20 - loss: 0.6342 - accuracy: 0.82 - ETA: 3:28 - loss: 0.5692 - accuracy: 0.83 - ETA: 3:26 - loss: 0.7259 - accuracy: 0.80 - ETA: 3:25 - loss: 0.7035 - accuracy: 0.81 - ETA: 3:21 - loss: 0.7012 - accuracy: 0.80 - ETA: 3:19 - loss: 0.7122 - accuracy: 0.79 - ETA: 3:17 - loss: 0.6895 - accuracy: 0.80 - ETA: 3:15 - loss: 0.6666 - accuracy: 0.81 - ETA: 3:14 - loss: 0.6770 - accuracy: 0.81 - ETA: 3:12 - loss: 0.6790 - accuracy: 0.81 - ETA: 3:10 - loss: 0.6585 - accuracy: 0.81 - ETA: 3:08 - loss: 0.6630 - accuracy: 0.81 - ETA: 3:08 - loss: 0.6571 - accuracy: 0.81 - ETA: 3:06 - loss: 0.6650 - accuracy: 0.81 - ETA: 3:05 - loss: 0.6484 - accuracy: 0.81 - ETA: 3:04 - loss: 0.6495 - accuracy: 0.81 - ETA: 3:03 - loss: 0.6382 - accuracy: 0.81 - ETA: 3:01 - loss: 0.6402 - accuracy: 0.81 - ETA: 3:00 - loss: 0.6408 - accuracy: 0.81 - ETA: 2:58 - loss: 0.6343 - accuracy: 0.81 - ETA: 2:58 - loss: 0.6330 - accuracy: 0.82 - ETA: 2:56 - loss: 0.6205 - accuracy: 0.82 - ETA: 2:55 - loss: 0.6331 - accuracy: 0.82 - ETA: 2:53 - loss: 0.6321 - accuracy: 0.82 - ETA: 2:52 - loss: 0.6293 - accuracy: 0.82 - ETA: 2:51 - loss: 0.6288 - accuracy: 0.82 - ETA: 2:49 - loss: 0.6265 - accuracy: 0.82 - ETA: 2:48 - loss: 0.6248 - accuracy: 0.82 - ETA: 2:46 - loss: 0.6297 - accuracy: 0.82 - ETA: 2:44 - loss: 0.6290 - accuracy: 0.82 - ETA: 2:43 - loss: 0.6261 - accuracy: 0.82 - ETA: 2:42 - loss: 0.6276 - accuracy: 0.82 - ETA: 2:40 - loss: 0.6270 - accuracy: 0.82 - ETA: 2:39 - loss: 0.6348 - accuracy: 0.82 - ETA: 2:37 - loss: 0.6359 - accuracy: 0.82 - ETA: 2:36 - loss: 0.6342 - accuracy: 0.82 - ETA: 2:35 - loss: 0.6344 - accuracy: 0.82 - ETA: 2:34 - loss: 0.6372 - accuracy: 0.82 - ETA: 2:32 - loss: 0.6349 - accuracy: 0.82 - ETA: 2:31 - loss: 0.6361 - accuracy: 0.82 - ETA: 2:30 - loss: 0.6444 - accuracy: 0.82 - ETA: 2:28 - loss: 0.6434 - accuracy: 0.82 - ETA: 2:27 - loss: 0.6372 - accuracy: 0.82 - ETA: 2:26 - loss: 0.6378 - accuracy: 0.82 - ETA: 2:24 - loss: 0.6384 - accuracy: 0.82 - ETA: 2:23 - loss: 0.6413 - accuracy: 0.82 - ETA: 2:22 - loss: 0.6421 - accuracy: 0.82 - ETA: 2:20 - loss: 0.6443 - accuracy: 0.82 - ETA: 2:19 - loss: 0.6459 - accuracy: 0.82 - ETA: 2:18 - loss: 0.6422 - accuracy: 0.82 - ETA: 2:16 - loss: 0.6425 - accuracy: 0.82 - ETA: 2:15 - loss: 0.6461 - accuracy: 0.82 - ETA: 2:14 - loss: 0.6464 - accuracy: 0.82 - ETA: 2:12 - loss: 0.6536 - accuracy: 0.82 - ETA: 2:11 - loss: 0.6557 - accuracy: 0.82 - ETA: 2:09 - loss: 0.6521 - accuracy: 0.82 - ETA: 2:08 - loss: 0.6549 - accuracy: 0.82 - ETA: 2:06 - loss: 0.6515 - accuracy: 0.82 - ETA: 2:05 - loss: 0.6577 - accuracy: 0.81 - ETA: 2:04 - loss: 0.6558 - accuracy: 0.82 - ETA: 2:02 - loss: 0.6590 - accuracy: 0.82 - ETA: 2:01 - loss: 0.6592 - accuracy: 0.82 - ETA: 2:00 - loss: 0.6619 - accuracy: 0.82 - ETA: 1:58 - loss: 0.6609 - accuracy: 0.82 - ETA: 1:57 - loss: 0.6586 - accuracy: 0.82 - ETA: 1:56 - loss: 0.6620 - accuracy: 0.82 - ETA: 1:54 - loss: 0.6610 - accuracy: 0.82 - ETA: 1:53 - loss: 0.6586 - accuracy: 0.82 - ETA: 1:51 - loss: 0.6585 - accuracy: 0.82 - ETA: 1:50 - loss: 0.6608 - accuracy: 0.82 - ETA: 1:49 - loss: 0.6639 - accuracy: 0.82 - ETA: 1:47 - loss: 0.6644 - accuracy: 0.81 - ETA: 1:46 - loss: 0.6662 - accuracy: 0.81 - ETA: 1:45 - loss: 0.6665 - accuracy: 0.81 - ETA: 1:43 - loss: 0.6651 - accuracy: 0.81 - ETA: 1:42 - loss: 0.6652 - accuracy: 0.81 - ETA: 1:41 - loss: 0.6659 - accuracy: 0.81 - ETA: 1:39 - loss: 0.6663 - accuracy: 0.81 - ETA: 1:38 - loss: 0.6657 - accuracy: 0.81 - ETA: 1:36 - loss: 0.6647 - accuracy: 0.82 - ETA: 1:35 - loss: 0.6653 - accuracy: 0.82 - ETA: 1:34 - loss: 0.6673 - accuracy: 0.81 - ETA: 1:32 - loss: 0.6651 - accuracy: 0.81 - ETA: 1:31 - loss: 0.6620 - accuracy: 0.82 - ETA: 1:30 - loss: 0.6595 - accuracy: 0.82 - ETA: 1:28 - loss: 0.6580 - accuracy: 0.82 - ETA: 1:27 - loss: 0.6581 - accuracy: 0.82 - ETA: 1:25 - loss: 0.6593 - accuracy: 0.82 - ETA: 1:24 - loss: 0.6618 - accuracy: 0.82 - ETA: 1:23 - loss: 0.6652 - accuracy: 0.81 - ETA: 1:21 - loss: 0.6668 - accuracy: 0.81 - ETA: 1:20 - loss: 0.6683 - accuracy: 0.81 - ETA: 1:19 - loss: 0.6686 - accuracy: 0.81 - ETA: 1:17 - loss: 0.6646 - accuracy: 0.82 - ETA: 1:16 - loss: 0.6623 - accuracy: 0.82 - ETA: 1:14 - loss: 0.6679 - accuracy: 0.82 - ETA: 1:13 - loss: 0.6672 - accuracy: 0.82 - ETA: 1:12 - loss: 0.6672 - accuracy: 0.82 - ETA: 1:10 - loss: 0.6660 - accuracy: 0.82 - ETA: 1:09 - loss: 0.6678 - accuracy: 0.81 - ETA: 1:08 - loss: 0.6696 - accuracy: 0.81 - ETA: 1:06 - loss: 0.6685 - accuracy: 0.82 - ETA: 1:05 - loss: 0.6671 - accuracy: 0.82 - ETA: 1:03 - loss: 0.6654 - accuracy: 0.82 - ETA: 1:02 - loss: 0.6646 - accuracy: 0.82 - ETA: 1:01 - loss: 0.6633 - accuracy: 0.82 - ETA: 59s - loss: 0.6637 - accuracy: 0.8211 - ETA: 58s - loss: 0.6646 - accuracy: 0.821 - ETA: 57s - loss: 0.6644 - accuracy: 0.821 - ETA: 56s - loss: 0.6633 - accuracy: 0.821 - ETA: 55s - loss: 0.6635 - accuracy: 0.821 - ETA: 53s - loss: 0.6646 - accuracy: 0.821 - ETA: 52s - loss: 0.6638 - accuracy: 0.821 - ETA: 51s - loss: 0.6656 - accuracy: 0.820 - ETA: 50s - loss: 0.6656 - accuracy: 0.820 - ETA: 49s - loss: 0.6672 - accuracy: 0.820 - ETA: 48s - loss: 0.6682 - accuracy: 0.820 - ETA: 47s - loss: 0.6705 - accuracy: 0.820 - ETA: 45s - loss: 0.6706 - accuracy: 0.820 - ETA: 44s - loss: 0.6718 - accuracy: 0.820 - ETA: 43s - loss: 0.6717 - accuracy: 0.820 - ETA: 42s - loss: 0.6717 - accuracy: 0.820 - ETA: 40s - loss: 0.6729 - accuracy: 0.820 - ETA: 39s - loss: 0.6730 - accuracy: 0.819 - ETA: 38s - loss: 0.6735 - accuracy: 0.819 - ETA: 36s - loss: 0.6734 - accuracy: 0.819 - ETA: 35s - loss: 0.6722 - accuracy: 0.819 - ETA: 34s - loss: 0.6721 - accuracy: 0.819 - ETA: 32s - loss: 0.6725 - accuracy: 0.819 - ETA: 31s - loss: 0.6727 - accuracy: 0.819 - ETA: 29s - loss: 0.6728 - accuracy: 0.819 - ETA: 28s - loss: 0.6727 - accuracy: 0.819 - ETA: 27s - loss: 0.6725 - accuracy: 0.819 - ETA: 25s - loss: 0.6724 - accuracy: 0.820 - ETA: 24s - loss: 0.6715 - accuracy: 0.820 - ETA: 22s - loss: 0.6722 - accuracy: 0.820 - ETA: 21s - loss: 0.6709 - accuracy: 0.820 - ETA: 19s - loss: 0.6703 - accuracy: 0.820 - ETA: 18s - loss: 0.6709 - accuracy: 0.820 - ETA: 16s - loss: 0.6719 - accuracy: 0.820 - ETA: 15s - loss: 0.6721 - accuracy: 0.819 - ETA: 13s - loss: 0.6708 - accuracy: 0.820 - ETA: 12s - loss: 0.6707 - accuracy: 0.820 - ETA: 10s - loss: 0.6719 - accuracy: 0.820 - ETA: 9s - loss: 0.6718 - accuracy: 0.819 - ETA: 7s - loss: 0.6736 - accuracy: 0.81 - ETA: 6s - loss: 0.6758 - accuracy: 0.81 - ETA: 4s - loss: 0.6765 - accuracy: 0.81 - ETA: 2s - loss: 0.6752 - accuracy: 0.81 - ETA: 1s - loss: 0.6738 - accuracy: 0.82 - 263s 14ms/step - loss: 0.6734 - accuracy: 0.8200 - val_loss: 1.3494 - val_accuracy: 0.7418\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:31 - loss: 0.7127 - accuracy: 0.82 - ETA: 5:18 - loss: 0.6382 - accuracy: 0.83 - ETA: 5:20 - loss: 0.6771 - accuracy: 0.82 - ETA: 5:14 - loss: 0.6251 - accuracy: 0.82 - ETA: 5:12 - loss: 0.5872 - accuracy: 0.84 - ETA: 5:10 - loss: 0.5952 - accuracy: 0.83 - ETA: 5:07 - loss: 0.6019 - accuracy: 0.83 - ETA: 5:02 - loss: 0.5994 - accuracy: 0.83 - ETA: 5:00 - loss: 0.5956 - accuracy: 0.83 - ETA: 4:58 - loss: 0.5793 - accuracy: 0.84 - ETA: 4:56 - loss: 0.5739 - accuracy: 0.84 - ETA: 4:54 - loss: 0.5885 - accuracy: 0.84 - ETA: 4:53 - loss: 0.5853 - accuracy: 0.84 - ETA: 4:50 - loss: 0.6035 - accuracy: 0.83 - ETA: 4:48 - loss: 0.6020 - accuracy: 0.84 - ETA: 4:46 - loss: 0.6158 - accuracy: 0.83 - ETA: 4:44 - loss: 0.6005 - accuracy: 0.83 - ETA: 4:42 - loss: 0.5967 - accuracy: 0.83 - ETA: 4:41 - loss: 0.5977 - accuracy: 0.84 - ETA: 4:39 - loss: 0.5879 - accuracy: 0.84 - ETA: 4:36 - loss: 0.5858 - accuracy: 0.84 - ETA: 4:34 - loss: 0.5795 - accuracy: 0.84 - ETA: 4:31 - loss: 0.5889 - accuracy: 0.84 - ETA: 4:29 - loss: 0.5965 - accuracy: 0.83 - ETA: 4:27 - loss: 0.5911 - accuracy: 0.84 - ETA: 4:25 - loss: 0.5943 - accuracy: 0.83 - ETA: 4:22 - loss: 0.5908 - accuracy: 0.83 - ETA: 4:20 - loss: 0.5984 - accuracy: 0.83 - ETA: 4:18 - loss: 0.6017 - accuracy: 0.83 - ETA: 4:15 - loss: 0.6033 - accuracy: 0.83 - ETA: 4:14 - loss: 0.5981 - accuracy: 0.83 - ETA: 4:11 - loss: 0.5899 - accuracy: 0.84 - ETA: 4:09 - loss: 0.5871 - accuracy: 0.84 - ETA: 4:06 - loss: 0.5868 - accuracy: 0.84 - ETA: 4:04 - loss: 0.5904 - accuracy: 0.84 - ETA: 4:02 - loss: 0.5954 - accuracy: 0.84 - ETA: 4:00 - loss: 0.5940 - accuracy: 0.84 - ETA: 3:59 - loss: 0.5968 - accuracy: 0.84 - ETA: 3:57 - loss: 0.5961 - accuracy: 0.84 - ETA: 3:55 - loss: 0.6024 - accuracy: 0.83 - ETA: 3:53 - loss: 0.6050 - accuracy: 0.83 - ETA: 3:50 - loss: 0.5996 - accuracy: 0.83 - ETA: 3:48 - loss: 0.5984 - accuracy: 0.84 - ETA: 3:46 - loss: 0.5989 - accuracy: 0.84 - ETA: 3:45 - loss: 0.6000 - accuracy: 0.83 - ETA: 3:42 - loss: 0.5984 - accuracy: 0.83 - ETA: 3:40 - loss: 0.6007 - accuracy: 0.83 - ETA: 3:38 - loss: 0.5956 - accuracy: 0.83 - ETA: 3:36 - loss: 0.6013 - accuracy: 0.83 - ETA: 3:34 - loss: 0.6013 - accuracy: 0.83 - ETA: 3:32 - loss: 0.6001 - accuracy: 0.83 - ETA: 3:30 - loss: 0.6005 - accuracy: 0.83 - ETA: 3:28 - loss: 0.5979 - accuracy: 0.83 - ETA: 3:26 - loss: 0.5972 - accuracy: 0.83 - ETA: 3:24 - loss: 0.5949 - accuracy: 0.83 - ETA: 3:22 - loss: 0.5935 - accuracy: 0.84 - ETA: 3:20 - loss: 0.5918 - accuracy: 0.84 - ETA: 3:18 - loss: 0.5975 - accuracy: 0.83 - ETA: 3:15 - loss: 0.5956 - accuracy: 0.83 - ETA: 3:13 - loss: 0.5928 - accuracy: 0.83 - ETA: 3:11 - loss: 0.5931 - accuracy: 0.83 - ETA: 3:09 - loss: 0.5922 - accuracy: 0.83 - ETA: 3:07 - loss: 0.5899 - accuracy: 0.84 - ETA: 3:05 - loss: 0.5911 - accuracy: 0.83 - ETA: 3:03 - loss: 0.5925 - accuracy: 0.83 - ETA: 3:00 - loss: 0.5923 - accuracy: 0.83 - ETA: 2:58 - loss: 0.5941 - accuracy: 0.83 - ETA: 2:56 - loss: 0.5941 - accuracy: 0.83 - ETA: 2:54 - loss: 0.5942 - accuracy: 0.83 - ETA: 2:52 - loss: 0.5953 - accuracy: 0.83 - ETA: 2:50 - loss: 0.5968 - accuracy: 0.83 - ETA: 2:47 - loss: 0.5956 - accuracy: 0.83 - ETA: 2:45 - loss: 0.5974 - accuracy: 0.83 - ETA: 2:43 - loss: 0.5992 - accuracy: 0.83 - ETA: 2:41 - loss: 0.5984 - accuracy: 0.83 - ETA: 2:39 - loss: 0.5992 - accuracy: 0.83 - ETA: 2:37 - loss: 0.6002 - accuracy: 0.83 - ETA: 2:35 - loss: 0.6019 - accuracy: 0.83 - ETA: 2:32 - loss: 0.6026 - accuracy: 0.83 - ETA: 2:30 - loss: 0.6052 - accuracy: 0.83 - ETA: 2:28 - loss: 0.6059 - accuracy: 0.83 - ETA: 2:26 - loss: 0.6077 - accuracy: 0.83 - ETA: 2:24 - loss: 0.6063 - accuracy: 0.83 - ETA: 2:22 - loss: 0.6053 - accuracy: 0.83 - ETA: 2:20 - loss: 0.6048 - accuracy: 0.83 - ETA: 2:18 - loss: 0.6031 - accuracy: 0.83 - ETA: 2:15 - loss: 0.6066 - accuracy: 0.83 - ETA: 2:13 - loss: 0.6064 - accuracy: 0.83 - ETA: 2:11 - loss: 0.6056 - accuracy: 0.83 - ETA: 2:09 - loss: 0.6067 - accuracy: 0.83 - ETA: 2:07 - loss: 0.6066 - accuracy: 0.83 - ETA: 2:05 - loss: 0.6058 - accuracy: 0.83 - ETA: 2:03 - loss: 0.6075 - accuracy: 0.83 - ETA: 2:01 - loss: 0.6067 - accuracy: 0.83 - ETA: 1:58 - loss: 0.6053 - accuracy: 0.83 - ETA: 1:56 - loss: 0.6056 - accuracy: 0.83 - ETA: 1:54 - loss: 0.6051 - accuracy: 0.83 - ETA: 1:52 - loss: 0.6045 - accuracy: 0.83 - ETA: 1:50 - loss: 0.6049 - accuracy: 0.83 - ETA: 1:48 - loss: 0.6041 - accuracy: 0.83 - ETA: 1:46 - loss: 0.6035 - accuracy: 0.83 - ETA: 1:44 - loss: 0.6051 - accuracy: 0.83 - ETA: 1:42 - loss: 0.6052 - accuracy: 0.83 - ETA: 1:39 - loss: 0.6048 - accuracy: 0.83 - ETA: 1:37 - loss: 0.6028 - accuracy: 0.83 - ETA: 1:35 - loss: 0.6011 - accuracy: 0.83 - ETA: 1:33 - loss: 0.6011 - accuracy: 0.83 - ETA: 1:31 - loss: 0.6033 - accuracy: 0.83 - ETA: 1:29 - loss: 0.6033 - accuracy: 0.83 - ETA: 1:27 - loss: 0.6017 - accuracy: 0.83 - ETA: 1:24 - loss: 0.6033 - accuracy: 0.83 - ETA: 1:22 - loss: 0.6034 - accuracy: 0.83 - ETA: 1:20 - loss: 0.6021 - accuracy: 0.83 - ETA: 1:18 - loss: 0.6022 - accuracy: 0.83 - ETA: 1:16 - loss: 0.6019 - accuracy: 0.83 - ETA: 1:14 - loss: 0.6030 - accuracy: 0.83 - ETA: 1:12 - loss: 0.6048 - accuracy: 0.83 - ETA: 1:10 - loss: 0.6043 - accuracy: 0.83 - ETA: 1:08 - loss: 0.6072 - accuracy: 0.83 - ETA: 1:05 - loss: 0.6092 - accuracy: 0.83 - ETA: 1:03 - loss: 0.6088 - accuracy: 0.83 - ETA: 1:01 - loss: 0.6091 - accuracy: 0.83 - ETA: 59s - loss: 0.6091 - accuracy: 0.8357 - ETA: 57s - loss: 0.6094 - accuracy: 0.835 - ETA: 55s - loss: 0.6104 - accuracy: 0.835 - ETA: 53s - loss: 0.6090 - accuracy: 0.835 - ETA: 50s - loss: 0.6095 - accuracy: 0.835 - ETA: 48s - loss: 0.6119 - accuracy: 0.835 - ETA: 46s - loss: 0.6117 - accuracy: 0.834 - ETA: 44s - loss: 0.6126 - accuracy: 0.834 - ETA: 42s - loss: 0.6123 - accuracy: 0.834 - ETA: 40s - loss: 0.6122 - accuracy: 0.834 - ETA: 38s - loss: 0.6110 - accuracy: 0.834 - ETA: 36s - loss: 0.6122 - accuracy: 0.834 - ETA: 33s - loss: 0.6126 - accuracy: 0.834 - ETA: 31s - loss: 0.6121 - accuracy: 0.834 - ETA: 29s - loss: 0.6118 - accuracy: 0.834 - ETA: 27s - loss: 0.6139 - accuracy: 0.834 - ETA: 25s - loss: 0.6148 - accuracy: 0.834 - ETA: 23s - loss: 0.6134 - accuracy: 0.834 - ETA: 21s - loss: 0.6121 - accuracy: 0.834 - ETA: 18s - loss: 0.6112 - accuracy: 0.834 - ETA: 16s - loss: 0.6135 - accuracy: 0.834 - ETA: 14s - loss: 0.6159 - accuracy: 0.834 - ETA: 12s - loss: 0.6158 - accuracy: 0.834 - ETA: 10s - loss: 0.6159 - accuracy: 0.833 - ETA: 8s - loss: 0.6162 - accuracy: 0.833 - ETA: 6s - loss: 0.6165 - accuracy: 0.83 - ETA: 4s - loss: 0.6150 - accuracy: 0.83 - ETA: 1s - loss: 0.6139 - accuracy: 0.83 - 347s 18ms/step - loss: 0.6139 - accuracy: 0.8339 - val_loss: 1.2651 - val_accuracy: 0.7530\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:21 - loss: 0.6103 - accuracy: 0.82 - ETA: 5:14 - loss: 0.7409 - accuracy: 0.81 - ETA: 5:14 - loss: 0.6956 - accuracy: 0.82 - ETA: 5:11 - loss: 0.6265 - accuracy: 0.83 - ETA: 5:08 - loss: 0.6268 - accuracy: 0.83 - ETA: 5:07 - loss: 0.5738 - accuracy: 0.83 - ETA: 5:04 - loss: 0.5608 - accuracy: 0.84 - ETA: 5:03 - loss: 0.5635 - accuracy: 0.83 - ETA: 5:01 - loss: 0.5513 - accuracy: 0.84 - ETA: 4:58 - loss: 0.5359 - accuracy: 0.84 - ETA: 4:57 - loss: 0.5278 - accuracy: 0.85 - ETA: 4:55 - loss: 0.5283 - accuracy: 0.85 - ETA: 4:54 - loss: 0.5369 - accuracy: 0.84 - ETA: 4:52 - loss: 0.5244 - accuracy: 0.84 - ETA: 4:50 - loss: 0.5245 - accuracy: 0.84 - ETA: 4:47 - loss: 0.5183 - accuracy: 0.85 - ETA: 4:45 - loss: 0.5288 - accuracy: 0.84 - ETA: 4:42 - loss: 0.5328 - accuracy: 0.85 - ETA: 4:39 - loss: 0.5292 - accuracy: 0.85 - ETA: 4:37 - loss: 0.5302 - accuracy: 0.84 - ETA: 4:36 - loss: 0.5362 - accuracy: 0.84 - ETA: 4:34 - loss: 0.5344 - accuracy: 0.84 - ETA: 4:32 - loss: 0.5394 - accuracy: 0.84 - ETA: 4:30 - loss: 0.5398 - accuracy: 0.84 - ETA: 4:28 - loss: 0.5402 - accuracy: 0.84 - ETA: 4:26 - loss: 0.5357 - accuracy: 0.84 - ETA: 4:24 - loss: 0.5372 - accuracy: 0.84 - ETA: 4:22 - loss: 0.5371 - accuracy: 0.84 - ETA: 4:19 - loss: 0.5348 - accuracy: 0.84 - ETA: 4:17 - loss: 0.5289 - accuracy: 0.84 - ETA: 4:15 - loss: 0.5338 - accuracy: 0.84 - ETA: 4:13 - loss: 0.5232 - accuracy: 0.84 - ETA: 4:11 - loss: 0.5241 - accuracy: 0.85 - ETA: 4:08 - loss: 0.5211 - accuracy: 0.85 - ETA: 4:07 - loss: 0.5190 - accuracy: 0.85 - ETA: 4:05 - loss: 0.5125 - accuracy: 0.85 - ETA: 4:03 - loss: 0.5158 - accuracy: 0.85 - ETA: 4:01 - loss: 0.5220 - accuracy: 0.85 - ETA: 3:59 - loss: 0.5237 - accuracy: 0.85 - ETA: 3:57 - loss: 0.5227 - accuracy: 0.85 - ETA: 3:55 - loss: 0.5247 - accuracy: 0.85 - ETA: 3:52 - loss: 0.5230 - accuracy: 0.85 - ETA: 3:50 - loss: 0.5219 - accuracy: 0.85 - ETA: 3:48 - loss: 0.5218 - accuracy: 0.85 - ETA: 3:46 - loss: 0.5225 - accuracy: 0.85 - ETA: 3:44 - loss: 0.5277 - accuracy: 0.85 - ETA: 3:42 - loss: 0.5292 - accuracy: 0.85 - ETA: 3:40 - loss: 0.5330 - accuracy: 0.84 - ETA: 3:38 - loss: 0.5289 - accuracy: 0.85 - ETA: 3:35 - loss: 0.5343 - accuracy: 0.85 - ETA: 3:33 - loss: 0.5320 - accuracy: 0.85 - ETA: 3:31 - loss: 0.5335 - accuracy: 0.85 - ETA: 3:29 - loss: 0.5330 - accuracy: 0.85 - ETA: 3:27 - loss: 0.5285 - accuracy: 0.85 - ETA: 3:25 - loss: 0.5273 - accuracy: 0.85 - ETA: 3:23 - loss: 0.5295 - accuracy: 0.85 - ETA: 3:20 - loss: 0.5298 - accuracy: 0.85 - ETA: 3:18 - loss: 0.5290 - accuracy: 0.85 - ETA: 3:16 - loss: 0.5277 - accuracy: 0.85 - ETA: 3:14 - loss: 0.5268 - accuracy: 0.85 - ETA: 3:12 - loss: 0.5304 - accuracy: 0.85 - ETA: 3:10 - loss: 0.5303 - accuracy: 0.85 - ETA: 3:08 - loss: 0.5317 - accuracy: 0.85 - ETA: 3:06 - loss: 0.5334 - accuracy: 0.85 - ETA: 3:04 - loss: 0.5327 - accuracy: 0.85 - ETA: 3:01 - loss: 0.5338 - accuracy: 0.85 - ETA: 2:59 - loss: 0.5356 - accuracy: 0.85 - ETA: 2:57 - loss: 0.5374 - accuracy: 0.85 - ETA: 2:55 - loss: 0.5401 - accuracy: 0.85 - ETA: 2:53 - loss: 0.5447 - accuracy: 0.85 - ETA: 2:50 - loss: 0.5437 - accuracy: 0.85 - ETA: 2:48 - loss: 0.5398 - accuracy: 0.85 - ETA: 2:46 - loss: 0.5391 - accuracy: 0.85 - ETA: 2:44 - loss: 0.5416 - accuracy: 0.85 - ETA: 2:42 - loss: 0.5403 - accuracy: 0.85 - ETA: 2:40 - loss: 0.5417 - accuracy: 0.85 - ETA: 2:37 - loss: 0.5420 - accuracy: 0.85 - ETA: 2:35 - loss: 0.5432 - accuracy: 0.85 - ETA: 2:33 - loss: 0.5451 - accuracy: 0.85 - ETA: 2:31 - loss: 0.5442 - accuracy: 0.85 - ETA: 2:29 - loss: 0.5445 - accuracy: 0.85 - ETA: 2:27 - loss: 0.5453 - accuracy: 0.85 - ETA: 2:25 - loss: 0.5433 - accuracy: 0.85 - ETA: 2:23 - loss: 0.5434 - accuracy: 0.85 - ETA: 2:21 - loss: 0.5427 - accuracy: 0.85 - ETA: 2:18 - loss: 0.5438 - accuracy: 0.85 - ETA: 2:16 - loss: 0.5448 - accuracy: 0.85 - ETA: 2:14 - loss: 0.5435 - accuracy: 0.85 - ETA: 2:12 - loss: 0.5397 - accuracy: 0.85 - ETA: 2:10 - loss: 0.5391 - accuracy: 0.85 - ETA: 2:08 - loss: 0.5376 - accuracy: 0.85 - ETA: 2:06 - loss: 0.5373 - accuracy: 0.85 - ETA: 2:03 - loss: 0.5351 - accuracy: 0.85 - ETA: 2:01 - loss: 0.5357 - accuracy: 0.85 - ETA: 1:59 - loss: 0.5352 - accuracy: 0.85 - ETA: 1:57 - loss: 0.5372 - accuracy: 0.85 - ETA: 1:55 - loss: 0.5374 - accuracy: 0.85 - ETA: 1:53 - loss: 0.5360 - accuracy: 0.85 - ETA: 1:51 - loss: 0.5359 - accuracy: 0.85 - ETA: 1:48 - loss: 0.5359 - accuracy: 0.85 - ETA: 1:46 - loss: 0.5359 - accuracy: 0.85 - ETA: 1:44 - loss: 0.5347 - accuracy: 0.85 - ETA: 1:42 - loss: 0.5343 - accuracy: 0.85 - ETA: 1:40 - loss: 0.5342 - accuracy: 0.85 - ETA: 1:38 - loss: 0.5358 - accuracy: 0.85 - ETA: 1:36 - loss: 0.5358 - accuracy: 0.85 - ETA: 1:34 - loss: 0.5345 - accuracy: 0.85 - ETA: 1:31 - loss: 0.5369 - accuracy: 0.85 - ETA: 1:29 - loss: 0.5418 - accuracy: 0.85 - ETA: 1:27 - loss: 0.5413 - accuracy: 0.85 - ETA: 1:25 - loss: 0.5428 - accuracy: 0.85 - ETA: 1:23 - loss: 0.5415 - accuracy: 0.85 - ETA: 1:21 - loss: 0.5422 - accuracy: 0.85 - ETA: 1:19 - loss: 0.5437 - accuracy: 0.85 - ETA: 1:16 - loss: 0.5448 - accuracy: 0.85 - ETA: 1:14 - loss: 0.5435 - accuracy: 0.85 - ETA: 1:12 - loss: 0.5429 - accuracy: 0.85 - ETA: 1:10 - loss: 0.5441 - accuracy: 0.85 - ETA: 1:08 - loss: 0.5444 - accuracy: 0.85 - ETA: 1:06 - loss: 0.5413 - accuracy: 0.85 - ETA: 1:03 - loss: 0.5393 - accuracy: 0.85 - ETA: 1:01 - loss: 0.5420 - accuracy: 0.85 - ETA: 59s - loss: 0.5425 - accuracy: 0.8518 - ETA: 57s - loss: 0.5412 - accuracy: 0.852 - ETA: 55s - loss: 0.5405 - accuracy: 0.852 - ETA: 53s - loss: 0.5407 - accuracy: 0.852 - ETA: 51s - loss: 0.5396 - accuracy: 0.852 - ETA: 48s - loss: 0.5398 - accuracy: 0.852 - ETA: 46s - loss: 0.5386 - accuracy: 0.852 - ETA: 44s - loss: 0.5379 - accuracy: 0.852 - ETA: 42s - loss: 0.5372 - accuracy: 0.852 - ETA: 40s - loss: 0.5381 - accuracy: 0.852 - ETA: 38s - loss: 0.5374 - accuracy: 0.852 - ETA: 36s - loss: 0.5352 - accuracy: 0.853 - ETA: 33s - loss: 0.5353 - accuracy: 0.852 - ETA: 31s - loss: 0.5363 - accuracy: 0.852 - ETA: 29s - loss: 0.5350 - accuracy: 0.852 - ETA: 27s - loss: 0.5341 - accuracy: 0.853 - ETA: 25s - loss: 0.5341 - accuracy: 0.853 - ETA: 23s - loss: 0.5333 - accuracy: 0.853 - ETA: 21s - loss: 0.5343 - accuracy: 0.853 - ETA: 19s - loss: 0.5337 - accuracy: 0.852 - ETA: 16s - loss: 0.5336 - accuracy: 0.852 - ETA: 14s - loss: 0.5335 - accuracy: 0.852 - ETA: 12s - loss: 0.5339 - accuracy: 0.852 - ETA: 10s - loss: 0.5357 - accuracy: 0.852 - ETA: 8s - loss: 0.5348 - accuracy: 0.852 - ETA: 6s - loss: 0.5327 - accuracy: 0.85 - ETA: 4s - loss: 0.5318 - accuracy: 0.85 - ETA: 1s - loss: 0.5302 - accuracy: 0.85 - 348s 18ms/step - loss: 0.5312 - accuracy: 0.8535 - val_loss: 1.2502 - val_accuracy: 0.7631\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:21 - loss: 0.6305 - accuracy: 0.84 - ETA: 5:23 - loss: 0.4865 - accuracy: 0.88 - ETA: 5:23 - loss: 0.4858 - accuracy: 0.86 - ETA: 5:20 - loss: 0.4692 - accuracy: 0.87 - ETA: 5:16 - loss: 0.4698 - accuracy: 0.87 - ETA: 5:13 - loss: 0.5157 - accuracy: 0.86 - ETA: 5:11 - loss: 0.4954 - accuracy: 0.87 - ETA: 5:09 - loss: 0.4760 - accuracy: 0.87 - ETA: 5:06 - loss: 0.4541 - accuracy: 0.87 - ETA: 5:03 - loss: 0.4474 - accuracy: 0.87 - ETA: 5:00 - loss: 0.4333 - accuracy: 0.88 - ETA: 4:58 - loss: 0.4301 - accuracy: 0.88 - ETA: 4:56 - loss: 0.4259 - accuracy: 0.88 - ETA: 4:54 - loss: 0.4436 - accuracy: 0.87 - ETA: 4:52 - loss: 0.4403 - accuracy: 0.87 - ETA: 4:52 - loss: 0.4400 - accuracy: 0.87 - ETA: 4:50 - loss: 0.4470 - accuracy: 0.87 - ETA: 4:47 - loss: 0.4384 - accuracy: 0.87 - ETA: 4:45 - loss: 0.4385 - accuracy: 0.87 - ETA: 4:42 - loss: 0.4476 - accuracy: 0.87 - ETA: 4:40 - loss: 0.4459 - accuracy: 0.87 - ETA: 4:37 - loss: 0.4470 - accuracy: 0.87 - ETA: 4:36 - loss: 0.4526 - accuracy: 0.87 - ETA: 4:33 - loss: 0.4552 - accuracy: 0.87 - ETA: 4:31 - loss: 0.4639 - accuracy: 0.87 - ETA: 4:28 - loss: 0.4635 - accuracy: 0.87 - ETA: 4:26 - loss: 0.4642 - accuracy: 0.87 - ETA: 4:24 - loss: 0.4611 - accuracy: 0.87 - ETA: 4:21 - loss: 0.4595 - accuracy: 0.87 - ETA: 4:19 - loss: 0.4584 - accuracy: 0.87 - ETA: 4:17 - loss: 0.4513 - accuracy: 0.87 - ETA: 4:16 - loss: 0.4503 - accuracy: 0.87 - ETA: 4:13 - loss: 0.4523 - accuracy: 0.87 - ETA: 4:11 - loss: 0.4486 - accuracy: 0.87 - ETA: 4:09 - loss: 0.4469 - accuracy: 0.87 - ETA: 4:06 - loss: 0.4524 - accuracy: 0.87 - ETA: 4:04 - loss: 0.4517 - accuracy: 0.87 - ETA: 4:02 - loss: 0.4509 - accuracy: 0.87 - ETA: 4:00 - loss: 0.4493 - accuracy: 0.87 - ETA: 3:58 - loss: 0.4473 - accuracy: 0.87 - ETA: 3:56 - loss: 0.4519 - accuracy: 0.87 - ETA: 3:54 - loss: 0.4528 - accuracy: 0.87 - ETA: 3:52 - loss: 0.4529 - accuracy: 0.87 - ETA: 3:50 - loss: 0.4500 - accuracy: 0.87 - ETA: 3:48 - loss: 0.4457 - accuracy: 0.87 - ETA: 3:45 - loss: 0.4414 - accuracy: 0.87 - ETA: 3:43 - loss: 0.4415 - accuracy: 0.88 - ETA: 3:41 - loss: 0.4403 - accuracy: 0.87 - ETA: 3:39 - loss: 0.4373 - accuracy: 0.88 - ETA: 3:37 - loss: 0.4403 - accuracy: 0.87 - ETA: 3:35 - loss: 0.4430 - accuracy: 0.87 - ETA: 3:33 - loss: 0.4460 - accuracy: 0.87 - ETA: 3:30 - loss: 0.4521 - accuracy: 0.87 - ETA: 3:28 - loss: 0.4527 - accuracy: 0.87 - ETA: 3:26 - loss: 0.4550 - accuracy: 0.87 - ETA: 3:24 - loss: 0.4536 - accuracy: 0.87 - ETA: 3:22 - loss: 0.4523 - accuracy: 0.87 - ETA: 3:20 - loss: 0.4495 - accuracy: 0.87 - ETA: 3:18 - loss: 0.4491 - accuracy: 0.87 - ETA: 3:16 - loss: 0.4509 - accuracy: 0.87 - ETA: 3:14 - loss: 0.4466 - accuracy: 0.87 - ETA: 3:12 - loss: 0.4449 - accuracy: 0.87 - ETA: 3:10 - loss: 0.4479 - accuracy: 0.87 - ETA: 3:08 - loss: 0.4468 - accuracy: 0.87 - ETA: 3:06 - loss: 0.4491 - accuracy: 0.87 - ETA: 3:04 - loss: 0.4475 - accuracy: 0.87 - ETA: 3:01 - loss: 0.4479 - accuracy: 0.87 - ETA: 2:59 - loss: 0.4481 - accuracy: 0.87 - ETA: 2:57 - loss: 0.4457 - accuracy: 0.87 - ETA: 2:55 - loss: 0.4437 - accuracy: 0.87 - ETA: 2:53 - loss: 0.4411 - accuracy: 0.87 - ETA: 2:50 - loss: 0.4403 - accuracy: 0.87 - ETA: 2:48 - loss: 0.4393 - accuracy: 0.87 - ETA: 2:46 - loss: 0.4394 - accuracy: 0.87 - ETA: 2:44 - loss: 0.4403 - accuracy: 0.87 - ETA: 2:41 - loss: 0.4411 - accuracy: 0.87 - ETA: 2:39 - loss: 0.4423 - accuracy: 0.87 - ETA: 2:37 - loss: 0.4435 - accuracy: 0.87 - ETA: 2:35 - loss: 0.4447 - accuracy: 0.87 - ETA: 2:33 - loss: 0.4452 - accuracy: 0.87 - ETA: 2:31 - loss: 0.4451 - accuracy: 0.87 - ETA: 2:28 - loss: 0.4448 - accuracy: 0.87 - ETA: 2:26 - loss: 0.4428 - accuracy: 0.87 - ETA: 2:24 - loss: 0.4424 - accuracy: 0.87 - ETA: 2:22 - loss: 0.4456 - accuracy: 0.87 - ETA: 2:20 - loss: 0.4457 - accuracy: 0.87 - ETA: 2:18 - loss: 0.4465 - accuracy: 0.87 - ETA: 2:16 - loss: 0.4498 - accuracy: 0.87 - ETA: 2:13 - loss: 0.4512 - accuracy: 0.87 - ETA: 2:11 - loss: 0.4511 - accuracy: 0.87 - ETA: 2:09 - loss: 0.4508 - accuracy: 0.87 - ETA: 2:07 - loss: 0.4522 - accuracy: 0.87 - ETA: 2:05 - loss: 0.4523 - accuracy: 0.87 - ETA: 2:03 - loss: 0.4545 - accuracy: 0.87 - ETA: 2:00 - loss: 0.4553 - accuracy: 0.87 - ETA: 1:58 - loss: 0.4558 - accuracy: 0.87 - ETA: 1:56 - loss: 0.4583 - accuracy: 0.87 - ETA: 1:54 - loss: 0.4586 - accuracy: 0.87 - ETA: 1:52 - loss: 0.4594 - accuracy: 0.87 - ETA: 1:49 - loss: 0.4584 - accuracy: 0.87 - ETA: 1:47 - loss: 0.4579 - accuracy: 0.87 - ETA: 1:45 - loss: 0.4587 - accuracy: 0.87 - ETA: 1:43 - loss: 0.4567 - accuracy: 0.87 - ETA: 1:41 - loss: 0.4550 - accuracy: 0.87 - ETA: 1:38 - loss: 0.4536 - accuracy: 0.87 - ETA: 1:36 - loss: 0.4529 - accuracy: 0.87 - ETA: 1:34 - loss: 0.4524 - accuracy: 0.87 - ETA: 1:32 - loss: 0.4531 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4539 - accuracy: 0.87 - ETA: 1:28 - loss: 0.4559 - accuracy: 0.87 - ETA: 1:25 - loss: 0.4555 - accuracy: 0.87 - ETA: 1:23 - loss: 0.4552 - accuracy: 0.87 - ETA: 1:21 - loss: 0.4566 - accuracy: 0.87 - ETA: 1:19 - loss: 0.4571 - accuracy: 0.87 - ETA: 1:17 - loss: 0.4568 - accuracy: 0.87 - ETA: 1:15 - loss: 0.4563 - accuracy: 0.87 - ETA: 1:13 - loss: 0.4552 - accuracy: 0.87 - ETA: 1:10 - loss: 0.4550 - accuracy: 0.87 - ETA: 1:08 - loss: 0.4556 - accuracy: 0.87 - ETA: 1:06 - loss: 0.4538 - accuracy: 0.87 - ETA: 1:04 - loss: 0.4555 - accuracy: 0.87 - ETA: 1:02 - loss: 0.4574 - accuracy: 0.87 - ETA: 1:00 - loss: 0.4575 - accuracy: 0.87 - ETA: 57s - loss: 0.4571 - accuracy: 0.8732 - ETA: 55s - loss: 0.4575 - accuracy: 0.873 - ETA: 53s - loss: 0.4571 - accuracy: 0.873 - ETA: 51s - loss: 0.4573 - accuracy: 0.873 - ETA: 49s - loss: 0.4558 - accuracy: 0.873 - ETA: 47s - loss: 0.4561 - accuracy: 0.873 - ETA: 45s - loss: 0.4599 - accuracy: 0.873 - ETA: 42s - loss: 0.4597 - accuracy: 0.873 - ETA: 40s - loss: 0.4592 - accuracy: 0.873 - ETA: 38s - loss: 0.4597 - accuracy: 0.873 - ETA: 36s - loss: 0.4609 - accuracy: 0.873 - ETA: 34s - loss: 0.4614 - accuracy: 0.873 - ETA: 32s - loss: 0.4607 - accuracy: 0.873 - ETA: 29s - loss: 0.4601 - accuracy: 0.873 - ETA: 27s - loss: 0.4609 - accuracy: 0.873 - ETA: 25s - loss: 0.4613 - accuracy: 0.873 - ETA: 23s - loss: 0.4604 - accuracy: 0.873 - ETA: 21s - loss: 0.4591 - accuracy: 0.873 - ETA: 19s - loss: 0.4607 - accuracy: 0.873 - ETA: 16s - loss: 0.4617 - accuracy: 0.872 - ETA: 14s - loss: 0.4618 - accuracy: 0.872 - ETA: 12s - loss: 0.4619 - accuracy: 0.872 - ETA: 10s - loss: 0.4616 - accuracy: 0.872 - ETA: 8s - loss: 0.4615 - accuracy: 0.872 - ETA: 6s - loss: 0.4618 - accuracy: 0.87 - ETA: 4s - loss: 0.4608 - accuracy: 0.87 - ETA: 1s - loss: 0.4620 - accuracy: 0.87 - 351s 18ms/step - loss: 0.4619 - accuracy: 0.8724 - val_loss: 1.3759 - val_accuracy: 0.7592\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:10 - loss: 0.4661 - accuracy: 0.89 - ETA: 5:20 - loss: 0.5132 - accuracy: 0.85 - ETA: 5:17 - loss: 0.4443 - accuracy: 0.87 - ETA: 5:13 - loss: 0.4515 - accuracy: 0.87 - ETA: 5:11 - loss: 0.4348 - accuracy: 0.87 - ETA: 5:08 - loss: 0.4549 - accuracy: 0.87 - ETA: 5:06 - loss: 0.4657 - accuracy: 0.87 - ETA: 5:06 - loss: 0.4520 - accuracy: 0.88 - ETA: 5:04 - loss: 0.4596 - accuracy: 0.88 - ETA: 5:02 - loss: 0.4414 - accuracy: 0.88 - ETA: 5:01 - loss: 0.4332 - accuracy: 0.88 - ETA: 5:01 - loss: 0.4477 - accuracy: 0.88 - ETA: 4:59 - loss: 0.4426 - accuracy: 0.88 - ETA: 4:58 - loss: 0.4449 - accuracy: 0.88 - ETA: 4:57 - loss: 0.4394 - accuracy: 0.88 - ETA: 4:57 - loss: 0.4308 - accuracy: 0.88 - ETA: 4:56 - loss: 0.4308 - accuracy: 0.88 - ETA: 4:55 - loss: 0.4250 - accuracy: 0.88 - ETA: 4:54 - loss: 0.4199 - accuracy: 0.88 - ETA: 4:51 - loss: 0.4238 - accuracy: 0.88 - ETA: 4:48 - loss: 0.4248 - accuracy: 0.88 - ETA: 4:45 - loss: 0.4231 - accuracy: 0.88 - ETA: 4:43 - loss: 0.4199 - accuracy: 0.88 - ETA: 4:40 - loss: 0.4185 - accuracy: 0.88 - ETA: 4:37 - loss: 0.4154 - accuracy: 0.88 - ETA: 4:34 - loss: 0.4149 - accuracy: 0.88 - ETA: 4:32 - loss: 0.4132 - accuracy: 0.88 - ETA: 4:30 - loss: 0.4136 - accuracy: 0.88 - ETA: 4:27 - loss: 0.4121 - accuracy: 0.88 - ETA: 4:25 - loss: 0.4179 - accuracy: 0.88 - ETA: 4:22 - loss: 0.4128 - accuracy: 0.88 - ETA: 4:20 - loss: 0.4129 - accuracy: 0.88 - ETA: 4:17 - loss: 0.4183 - accuracy: 0.88 - ETA: 4:15 - loss: 0.4196 - accuracy: 0.88 - ETA: 4:13 - loss: 0.4146 - accuracy: 0.88 - ETA: 4:11 - loss: 0.4150 - accuracy: 0.88 - ETA: 4:08 - loss: 0.4145 - accuracy: 0.88 - ETA: 4:06 - loss: 0.4115 - accuracy: 0.88 - ETA: 4:04 - loss: 0.4064 - accuracy: 0.88 - ETA: 4:02 - loss: 0.4093 - accuracy: 0.88 - ETA: 3:59 - loss: 0.4097 - accuracy: 0.88 - ETA: 3:57 - loss: 0.4041 - accuracy: 0.88 - ETA: 3:55 - loss: 0.4013 - accuracy: 0.88 - ETA: 3:53 - loss: 0.4012 - accuracy: 0.88 - ETA: 3:51 - loss: 0.4023 - accuracy: 0.88 - ETA: 3:49 - loss: 0.3986 - accuracy: 0.88 - ETA: 3:47 - loss: 0.4046 - accuracy: 0.88 - ETA: 3:44 - loss: 0.4029 - accuracy: 0.88 - ETA: 3:42 - loss: 0.4028 - accuracy: 0.88 - ETA: 3:40 - loss: 0.4001 - accuracy: 0.88 - ETA: 3:37 - loss: 0.4059 - accuracy: 0.88 - ETA: 3:35 - loss: 0.4028 - accuracy: 0.88 - ETA: 3:33 - loss: 0.4002 - accuracy: 0.89 - ETA: 3:30 - loss: 0.3997 - accuracy: 0.89 - ETA: 3:28 - loss: 0.4026 - accuracy: 0.89 - ETA: 3:26 - loss: 0.4020 - accuracy: 0.89 - ETA: 3:24 - loss: 0.4068 - accuracy: 0.88 - ETA: 3:22 - loss: 0.4050 - accuracy: 0.89 - ETA: 3:19 - loss: 0.4043 - accuracy: 0.89 - ETA: 3:17 - loss: 0.4060 - accuracy: 0.89 - ETA: 3:15 - loss: 0.4061 - accuracy: 0.89 - ETA: 3:12 - loss: 0.4073 - accuracy: 0.88 - ETA: 3:10 - loss: 0.4038 - accuracy: 0.89 - ETA: 3:08 - loss: 0.4068 - accuracy: 0.89 - ETA: 3:06 - loss: 0.4050 - accuracy: 0.89 - ETA: 3:04 - loss: 0.4063 - accuracy: 0.88 - ETA: 3:02 - loss: 0.4049 - accuracy: 0.89 - ETA: 3:00 - loss: 0.4053 - accuracy: 0.88 - ETA: 2:57 - loss: 0.4044 - accuracy: 0.88 - ETA: 2:55 - loss: 0.4031 - accuracy: 0.89 - ETA: 2:53 - loss: 0.4051 - accuracy: 0.89 - ETA: 2:51 - loss: 0.4056 - accuracy: 0.88 - ETA: 2:48 - loss: 0.4064 - accuracy: 0.88 - ETA: 2:46 - loss: 0.4079 - accuracy: 0.88 - ETA: 2:44 - loss: 0.4056 - accuracy: 0.89 - ETA: 2:42 - loss: 0.4056 - accuracy: 0.89 - ETA: 2:39 - loss: 0.4076 - accuracy: 0.88 - ETA: 2:37 - loss: 0.4082 - accuracy: 0.88 - ETA: 2:35 - loss: 0.4084 - accuracy: 0.88 - ETA: 2:33 - loss: 0.4065 - accuracy: 0.88 - ETA: 2:31 - loss: 0.4092 - accuracy: 0.88 - ETA: 2:29 - loss: 0.4072 - accuracy: 0.89 - ETA: 2:26 - loss: 0.4088 - accuracy: 0.89 - ETA: 2:24 - loss: 0.4086 - accuracy: 0.89 - ETA: 2:22 - loss: 0.4089 - accuracy: 0.89 - ETA: 2:20 - loss: 0.4096 - accuracy: 0.88 - ETA: 2:17 - loss: 0.4096 - accuracy: 0.88 - ETA: 2:15 - loss: 0.4074 - accuracy: 0.89 - ETA: 2:13 - loss: 0.4077 - accuracy: 0.89 - ETA: 2:11 - loss: 0.4093 - accuracy: 0.89 - ETA: 2:09 - loss: 0.4121 - accuracy: 0.88 - ETA: 2:07 - loss: 0.4119 - accuracy: 0.88 - ETA: 2:05 - loss: 0.4117 - accuracy: 0.88 - ETA: 2:02 - loss: 0.4124 - accuracy: 0.88 - ETA: 2:00 - loss: 0.4126 - accuracy: 0.88 - ETA: 1:58 - loss: 0.4118 - accuracy: 0.88 - ETA: 1:56 - loss: 0.4107 - accuracy: 0.88 - ETA: 1:54 - loss: 0.4096 - accuracy: 0.89 - ETA: 1:52 - loss: 0.4093 - accuracy: 0.88 - ETA: 1:50 - loss: 0.4087 - accuracy: 0.88 - ETA: 1:47 - loss: 0.4094 - accuracy: 0.88 - ETA: 1:45 - loss: 0.4101 - accuracy: 0.88 - ETA: 1:43 - loss: 0.4098 - accuracy: 0.88 - ETA: 1:41 - loss: 0.4106 - accuracy: 0.88 - ETA: 1:39 - loss: 0.4120 - accuracy: 0.88 - ETA: 1:36 - loss: 0.4101 - accuracy: 0.88 - ETA: 1:34 - loss: 0.4103 - accuracy: 0.88 - ETA: 1:32 - loss: 0.4109 - accuracy: 0.88 - ETA: 1:30 - loss: 0.4100 - accuracy: 0.88 - ETA: 1:28 - loss: 0.4100 - accuracy: 0.88 - ETA: 1:26 - loss: 0.4097 - accuracy: 0.88 - ETA: 1:23 - loss: 0.4087 - accuracy: 0.88 - ETA: 1:21 - loss: 0.4068 - accuracy: 0.88 - ETA: 1:19 - loss: 0.4066 - accuracy: 0.88 - ETA: 1:17 - loss: 0.4067 - accuracy: 0.88 - ETA: 1:15 - loss: 0.4071 - accuracy: 0.88 - ETA: 1:13 - loss: 0.4086 - accuracy: 0.88 - ETA: 1:10 - loss: 0.4089 - accuracy: 0.88 - ETA: 1:08 - loss: 0.4106 - accuracy: 0.88 - ETA: 1:06 - loss: 0.4113 - accuracy: 0.88 - ETA: 1:04 - loss: 0.4123 - accuracy: 0.88 - ETA: 1:02 - loss: 0.4124 - accuracy: 0.88 - ETA: 1:00 - loss: 0.4116 - accuracy: 0.88 - ETA: 57s - loss: 0.4135 - accuracy: 0.8879 - ETA: 55s - loss: 0.4131 - accuracy: 0.887 - ETA: 53s - loss: 0.4121 - accuracy: 0.888 - ETA: 51s - loss: 0.4112 - accuracy: 0.888 - ETA: 49s - loss: 0.4119 - accuracy: 0.888 - ETA: 47s - loss: 0.4126 - accuracy: 0.888 - ETA: 45s - loss: 0.4122 - accuracy: 0.888 - ETA: 42s - loss: 0.4116 - accuracy: 0.888 - ETA: 40s - loss: 0.4124 - accuracy: 0.888 - ETA: 38s - loss: 0.4112 - accuracy: 0.888 - ETA: 36s - loss: 0.4106 - accuracy: 0.888 - ETA: 34s - loss: 0.4125 - accuracy: 0.888 - ETA: 32s - loss: 0.4115 - accuracy: 0.888 - ETA: 29s - loss: 0.4120 - accuracy: 0.888 - ETA: 27s - loss: 0.4109 - accuracy: 0.888 - ETA: 25s - loss: 0.4103 - accuracy: 0.888 - ETA: 23s - loss: 0.4097 - accuracy: 0.888 - ETA: 21s - loss: 0.4098 - accuracy: 0.888 - ETA: 19s - loss: 0.4115 - accuracy: 0.888 - ETA: 16s - loss: 0.4133 - accuracy: 0.887 - ETA: 14s - loss: 0.4130 - accuracy: 0.887 - ETA: 12s - loss: 0.4132 - accuracy: 0.887 - ETA: 10s - loss: 0.4124 - accuracy: 0.887 - ETA: 8s - loss: 0.4116 - accuracy: 0.887 - ETA: 6s - loss: 0.4118 - accuracy: 0.88 - ETA: 4s - loss: 0.4114 - accuracy: 0.88 - ETA: 1s - loss: 0.4119 - accuracy: 0.88 - 349s 18ms/step - loss: 0.4126 - accuracy: 0.8874 - val_loss: 1.2515 - val_accuracy: 0.7726\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:24 - loss: 0.1927 - accuracy: 0.93 - ETA: 5:09 - loss: 0.3018 - accuracy: 0.92 - ETA: 5:05 - loss: 0.2623 - accuracy: 0.92 - ETA: 5:00 - loss: 0.3035 - accuracy: 0.91 - ETA: 4:58 - loss: 0.2797 - accuracy: 0.91 - ETA: 4:56 - loss: 0.2917 - accuracy: 0.91 - ETA: 4:57 - loss: 0.2785 - accuracy: 0.91 - ETA: 4:55 - loss: 0.2946 - accuracy: 0.91 - ETA: 4:54 - loss: 0.3190 - accuracy: 0.90 - ETA: 4:53 - loss: 0.3107 - accuracy: 0.90 - ETA: 4:52 - loss: 0.3226 - accuracy: 0.90 - ETA: 4:51 - loss: 0.3448 - accuracy: 0.90 - ETA: 4:49 - loss: 0.3450 - accuracy: 0.90 - ETA: 4:47 - loss: 0.3416 - accuracy: 0.90 - ETA: 4:45 - loss: 0.3559 - accuracy: 0.90 - ETA: 4:43 - loss: 0.3649 - accuracy: 0.89 - ETA: 4:42 - loss: 0.3718 - accuracy: 0.89 - ETA: 4:40 - loss: 0.3708 - accuracy: 0.89 - ETA: 4:38 - loss: 0.3713 - accuracy: 0.89 - ETA: 4:36 - loss: 0.3724 - accuracy: 0.89 - ETA: 4:34 - loss: 0.3742 - accuracy: 0.89 - ETA: 4:32 - loss: 0.3726 - accuracy: 0.89 - ETA: 4:31 - loss: 0.3710 - accuracy: 0.89 - ETA: 4:29 - loss: 0.3705 - accuracy: 0.89 - ETA: 4:27 - loss: 0.3667 - accuracy: 0.89 - ETA: 4:26 - loss: 0.3655 - accuracy: 0.89 - ETA: 4:24 - loss: 0.3665 - accuracy: 0.89 - ETA: 4:22 - loss: 0.3654 - accuracy: 0.89 - ETA: 4:20 - loss: 0.3670 - accuracy: 0.89 - ETA: 4:18 - loss: 0.3653 - accuracy: 0.89 - ETA: 4:16 - loss: 0.3644 - accuracy: 0.89 - ETA: 4:13 - loss: 0.3651 - accuracy: 0.89 - ETA: 4:11 - loss: 0.3637 - accuracy: 0.89 - ETA: 4:09 - loss: 0.3613 - accuracy: 0.89 - ETA: 4:07 - loss: 0.3620 - accuracy: 0.89 - ETA: 4:05 - loss: 0.3616 - accuracy: 0.89 - ETA: 4:02 - loss: 0.3597 - accuracy: 0.89 - ETA: 4:00 - loss: 0.3608 - accuracy: 0.89 - ETA: 3:57 - loss: 0.3614 - accuracy: 0.89 - ETA: 3:55 - loss: 0.3623 - accuracy: 0.89 - ETA: 3:54 - loss: 0.3601 - accuracy: 0.89 - ETA: 3:51 - loss: 0.3603 - accuracy: 0.89 - ETA: 3:49 - loss: 0.3636 - accuracy: 0.89 - ETA: 3:47 - loss: 0.3647 - accuracy: 0.89 - ETA: 3:45 - loss: 0.3619 - accuracy: 0.89 - ETA: 3:43 - loss: 0.3675 - accuracy: 0.89 - ETA: 3:41 - loss: 0.3680 - accuracy: 0.89 - ETA: 3:39 - loss: 0.3686 - accuracy: 0.89 - ETA: 3:36 - loss: 0.3682 - accuracy: 0.89 - ETA: 3:34 - loss: 0.3687 - accuracy: 0.89 - ETA: 3:32 - loss: 0.3681 - accuracy: 0.89 - ETA: 3:30 - loss: 0.3678 - accuracy: 0.89 - ETA: 3:27 - loss: 0.3693 - accuracy: 0.89 - ETA: 3:25 - loss: 0.3695 - accuracy: 0.89 - ETA: 3:23 - loss: 0.3670 - accuracy: 0.89 - ETA: 3:21 - loss: 0.3680 - accuracy: 0.89 - ETA: 3:19 - loss: 0.3678 - accuracy: 0.89 - ETA: 3:17 - loss: 0.3663 - accuracy: 0.89 - ETA: 3:15 - loss: 0.3671 - accuracy: 0.89 - ETA: 3:13 - loss: 0.3679 - accuracy: 0.89 - ETA: 3:11 - loss: 0.3669 - accuracy: 0.89 - ETA: 3:09 - loss: 0.3669 - accuracy: 0.89 - ETA: 3:07 - loss: 0.3704 - accuracy: 0.89 - ETA: 3:05 - loss: 0.3683 - accuracy: 0.89 - ETA: 3:02 - loss: 0.3690 - accuracy: 0.89 - ETA: 3:00 - loss: 0.3714 - accuracy: 0.89 - ETA: 2:58 - loss: 0.3748 - accuracy: 0.89 - ETA: 2:56 - loss: 0.3759 - accuracy: 0.89 - ETA: 2:54 - loss: 0.3730 - accuracy: 0.89 - ETA: 2:52 - loss: 0.3716 - accuracy: 0.89 - ETA: 2:50 - loss: 0.3702 - accuracy: 0.89 - ETA: 2:48 - loss: 0.3692 - accuracy: 0.89 - ETA: 2:46 - loss: 0.3689 - accuracy: 0.89 - ETA: 2:44 - loss: 0.3693 - accuracy: 0.89 - ETA: 2:42 - loss: 0.3709 - accuracy: 0.89 - ETA: 2:39 - loss: 0.3707 - accuracy: 0.89 - ETA: 2:37 - loss: 0.3723 - accuracy: 0.89 - ETA: 2:35 - loss: 0.3727 - accuracy: 0.89 - ETA: 2:33 - loss: 0.3718 - accuracy: 0.89 - ETA: 2:31 - loss: 0.3705 - accuracy: 0.89 - ETA: 2:29 - loss: 0.3725 - accuracy: 0.89 - ETA: 2:27 - loss: 0.3728 - accuracy: 0.89 - ETA: 2:24 - loss: 0.3722 - accuracy: 0.89 - ETA: 2:22 - loss: 0.3728 - accuracy: 0.89 - ETA: 2:20 - loss: 0.3746 - accuracy: 0.89 - ETA: 2:18 - loss: 0.3757 - accuracy: 0.89 - ETA: 2:16 - loss: 0.3766 - accuracy: 0.89 - ETA: 2:14 - loss: 0.3759 - accuracy: 0.89 - ETA: 2:12 - loss: 0.3771 - accuracy: 0.89 - ETA: 2:09 - loss: 0.3764 - accuracy: 0.89 - ETA: 2:07 - loss: 0.3769 - accuracy: 0.89 - ETA: 2:05 - loss: 0.3774 - accuracy: 0.89 - ETA: 2:03 - loss: 0.3774 - accuracy: 0.89 - ETA: 2:01 - loss: 0.3777 - accuracy: 0.89 - ETA: 1:59 - loss: 0.3758 - accuracy: 0.89 - ETA: 1:56 - loss: 0.3777 - accuracy: 0.89 - ETA: 1:54 - loss: 0.3784 - accuracy: 0.89 - ETA: 1:52 - loss: 0.3773 - accuracy: 0.89 - ETA: 1:50 - loss: 0.3770 - accuracy: 0.89 - ETA: 1:48 - loss: 0.3771 - accuracy: 0.89 - ETA: 1:46 - loss: 0.3770 - accuracy: 0.89 - ETA: 1:44 - loss: 0.3755 - accuracy: 0.89 - ETA: 1:42 - loss: 0.3756 - accuracy: 0.89 - ETA: 1:40 - loss: 0.3768 - accuracy: 0.89 - ETA: 1:38 - loss: 0.3761 - accuracy: 0.89 - ETA: 1:35 - loss: 0.3753 - accuracy: 0.89 - ETA: 1:33 - loss: 0.3753 - accuracy: 0.89 - ETA: 1:31 - loss: 0.3744 - accuracy: 0.89 - ETA: 1:29 - loss: 0.3732 - accuracy: 0.89 - ETA: 1:27 - loss: 0.3727 - accuracy: 0.89 - ETA: 1:25 - loss: 0.3736 - accuracy: 0.89 - ETA: 1:23 - loss: 0.3738 - accuracy: 0.89 - ETA: 1:21 - loss: 0.3738 - accuracy: 0.89 - ETA: 1:18 - loss: 0.3745 - accuracy: 0.89 - ETA: 1:16 - loss: 0.3741 - accuracy: 0.89 - ETA: 1:14 - loss: 0.3741 - accuracy: 0.89 - ETA: 1:12 - loss: 0.3735 - accuracy: 0.89 - ETA: 1:10 - loss: 0.3741 - accuracy: 0.89 - ETA: 1:08 - loss: 0.3737 - accuracy: 0.89 - ETA: 1:06 - loss: 0.3726 - accuracy: 0.89 - ETA: 1:04 - loss: 0.3725 - accuracy: 0.89 - ETA: 1:01 - loss: 0.3721 - accuracy: 0.89 - ETA: 59s - loss: 0.3745 - accuracy: 0.8930 - ETA: 57s - loss: 0.3742 - accuracy: 0.892 - ETA: 55s - loss: 0.3742 - accuracy: 0.892 - ETA: 53s - loss: 0.3740 - accuracy: 0.892 - ETA: 51s - loss: 0.3722 - accuracy: 0.893 - ETA: 48s - loss: 0.3731 - accuracy: 0.892 - ETA: 46s - loss: 0.3722 - accuracy: 0.892 - ETA: 44s - loss: 0.3722 - accuracy: 0.892 - ETA: 42s - loss: 0.3715 - accuracy: 0.892 - ETA: 40s - loss: 0.3726 - accuracy: 0.892 - ETA: 38s - loss: 0.3729 - accuracy: 0.892 - ETA: 36s - loss: 0.3721 - accuracy: 0.892 - ETA: 33s - loss: 0.3729 - accuracy: 0.892 - ETA: 31s - loss: 0.3730 - accuracy: 0.892 - ETA: 29s - loss: 0.3740 - accuracy: 0.892 - ETA: 27s - loss: 0.3754 - accuracy: 0.892 - ETA: 25s - loss: 0.3741 - accuracy: 0.893 - ETA: 23s - loss: 0.3733 - accuracy: 0.893 - ETA: 21s - loss: 0.3734 - accuracy: 0.893 - ETA: 19s - loss: 0.3729 - accuracy: 0.893 - ETA: 16s - loss: 0.3723 - accuracy: 0.893 - ETA: 14s - loss: 0.3725 - accuracy: 0.893 - ETA: 12s - loss: 0.3717 - accuracy: 0.893 - ETA: 10s - loss: 0.3719 - accuracy: 0.893 - ETA: 8s - loss: 0.3705 - accuracy: 0.893 - ETA: 6s - loss: 0.3708 - accuracy: 0.89 - ETA: 4s - loss: 0.3716 - accuracy: 0.89 - ETA: 1s - loss: 0.3712 - accuracy: 0.89 - 348s 18ms/step - loss: 0.3715 - accuracy: 0.8934 - val_loss: 1.3312 - val_accuracy: 0.7751\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:48 - loss: 0.2454 - accuracy: 0.91 - ETA: 5:32 - loss: 0.2478 - accuracy: 0.92 - ETA: 5:27 - loss: 0.2524 - accuracy: 0.92 - ETA: 5:27 - loss: 0.2528 - accuracy: 0.91 - ETA: 5:24 - loss: 0.2497 - accuracy: 0.92 - ETA: 5:21 - loss: 0.2523 - accuracy: 0.92 - ETA: 5:17 - loss: 0.2555 - accuracy: 0.92 - ETA: 5:15 - loss: 0.2569 - accuracy: 0.91 - ETA: 5:10 - loss: 0.2714 - accuracy: 0.91 - ETA: 5:06 - loss: 0.2711 - accuracy: 0.91 - ETA: 5:04 - loss: 0.2715 - accuracy: 0.91 - ETA: 5:01 - loss: 0.2940 - accuracy: 0.91 - ETA: 4:58 - loss: 0.2933 - accuracy: 0.91 - ETA: 4:56 - loss: 0.2904 - accuracy: 0.91 - ETA: 4:54 - loss: 0.3001 - accuracy: 0.91 - ETA: 4:51 - loss: 0.2971 - accuracy: 0.91 - ETA: 4:50 - loss: 0.3000 - accuracy: 0.91 - ETA: 4:48 - loss: 0.3132 - accuracy: 0.90 - ETA: 4:45 - loss: 0.3152 - accuracy: 0.90 - ETA: 4:43 - loss: 0.3345 - accuracy: 0.90 - ETA: 4:40 - loss: 0.3411 - accuracy: 0.90 - ETA: 4:37 - loss: 0.3456 - accuracy: 0.90 - ETA: 4:34 - loss: 0.3431 - accuracy: 0.90 - ETA: 4:32 - loss: 0.3395 - accuracy: 0.90 - ETA: 4:29 - loss: 0.3411 - accuracy: 0.90 - ETA: 4:27 - loss: 0.3428 - accuracy: 0.90 - ETA: 4:25 - loss: 0.3404 - accuracy: 0.90 - ETA: 4:23 - loss: 0.3412 - accuracy: 0.90 - ETA: 4:21 - loss: 0.3476 - accuracy: 0.90 - ETA: 4:19 - loss: 0.3496 - accuracy: 0.90 - ETA: 4:17 - loss: 0.3520 - accuracy: 0.90 - ETA: 4:15 - loss: 0.3518 - accuracy: 0.90 - ETA: 4:12 - loss: 0.3500 - accuracy: 0.90 - ETA: 4:10 - loss: 0.3571 - accuracy: 0.90 - ETA: 4:08 - loss: 0.3604 - accuracy: 0.90 - ETA: 4:06 - loss: 0.3649 - accuracy: 0.90 - ETA: 4:03 - loss: 0.3665 - accuracy: 0.90 - ETA: 4:02 - loss: 0.3694 - accuracy: 0.89 - ETA: 3:59 - loss: 0.3711 - accuracy: 0.89 - ETA: 3:57 - loss: 0.3712 - accuracy: 0.89 - ETA: 3:55 - loss: 0.3745 - accuracy: 0.89 - ETA: 3:53 - loss: 0.3721 - accuracy: 0.89 - ETA: 3:50 - loss: 0.3669 - accuracy: 0.89 - ETA: 3:48 - loss: 0.3648 - accuracy: 0.89 - ETA: 3:46 - loss: 0.3650 - accuracy: 0.89 - ETA: 3:44 - loss: 0.3633 - accuracy: 0.89 - ETA: 3:42 - loss: 0.3633 - accuracy: 0.89 - ETA: 3:40 - loss: 0.3603 - accuracy: 0.89 - ETA: 3:38 - loss: 0.3592 - accuracy: 0.90 - ETA: 3:36 - loss: 0.3563 - accuracy: 0.90 - ETA: 3:34 - loss: 0.3538 - accuracy: 0.90 - ETA: 3:32 - loss: 0.3516 - accuracy: 0.90 - ETA: 3:30 - loss: 0.3521 - accuracy: 0.90 - ETA: 3:28 - loss: 0.3495 - accuracy: 0.90 - ETA: 3:25 - loss: 0.3521 - accuracy: 0.90 - ETA: 3:23 - loss: 0.3514 - accuracy: 0.90 - ETA: 3:21 - loss: 0.3503 - accuracy: 0.90 - ETA: 3:19 - loss: 0.3481 - accuracy: 0.90 - ETA: 3:17 - loss: 0.3467 - accuracy: 0.90 - ETA: 3:15 - loss: 0.3488 - accuracy: 0.90 - ETA: 3:13 - loss: 0.3503 - accuracy: 0.90 - ETA: 3:11 - loss: 0.3520 - accuracy: 0.90 - ETA: 3:08 - loss: 0.3492 - accuracy: 0.90 - ETA: 3:06 - loss: 0.3473 - accuracy: 0.90 - ETA: 3:04 - loss: 0.3476 - accuracy: 0.90 - ETA: 3:02 - loss: 0.3451 - accuracy: 0.90 - ETA: 3:00 - loss: 0.3441 - accuracy: 0.90 - ETA: 2:58 - loss: 0.3460 - accuracy: 0.90 - ETA: 2:56 - loss: 0.3436 - accuracy: 0.90 - ETA: 2:53 - loss: 0.3418 - accuracy: 0.90 - ETA: 2:51 - loss: 0.3414 - accuracy: 0.90 - ETA: 2:49 - loss: 0.3447 - accuracy: 0.90 - ETA: 2:47 - loss: 0.3443 - accuracy: 0.90 - ETA: 2:45 - loss: 0.3429 - accuracy: 0.90 - ETA: 2:43 - loss: 0.3426 - accuracy: 0.90 - ETA: 2:41 - loss: 0.3442 - accuracy: 0.90 - ETA: 2:39 - loss: 0.3422 - accuracy: 0.90 - ETA: 2:36 - loss: 0.3443 - accuracy: 0.90 - ETA: 2:34 - loss: 0.3430 - accuracy: 0.90 - ETA: 2:32 - loss: 0.3429 - accuracy: 0.90 - ETA: 2:30 - loss: 0.3422 - accuracy: 0.90 - ETA: 2:28 - loss: 0.3425 - accuracy: 0.90 - ETA: 2:26 - loss: 0.3404 - accuracy: 0.90 - ETA: 2:23 - loss: 0.3394 - accuracy: 0.90 - ETA: 2:21 - loss: 0.3414 - accuracy: 0.90 - ETA: 2:19 - loss: 0.3402 - accuracy: 0.90 - ETA: 2:17 - loss: 0.3416 - accuracy: 0.90 - ETA: 2:15 - loss: 0.3420 - accuracy: 0.90 - ETA: 2:13 - loss: 0.3424 - accuracy: 0.90 - ETA: 2:11 - loss: 0.3447 - accuracy: 0.90 - ETA: 2:08 - loss: 0.3447 - accuracy: 0.90 - ETA: 2:06 - loss: 0.3443 - accuracy: 0.90 - ETA: 2:04 - loss: 0.3440 - accuracy: 0.90 - ETA: 2:02 - loss: 0.3455 - accuracy: 0.90 - ETA: 2:00 - loss: 0.3480 - accuracy: 0.90 - ETA: 1:58 - loss: 0.3481 - accuracy: 0.90 - ETA: 1:55 - loss: 0.3482 - accuracy: 0.90 - ETA: 1:53 - loss: 0.3496 - accuracy: 0.90 - ETA: 1:51 - loss: 0.3499 - accuracy: 0.90 - ETA: 1:49 - loss: 0.3489 - accuracy: 0.90 - ETA: 1:47 - loss: 0.3486 - accuracy: 0.90 - ETA: 1:45 - loss: 0.3473 - accuracy: 0.90 - ETA: 1:43 - loss: 0.3468 - accuracy: 0.90 - ETA: 1:40 - loss: 0.3466 - accuracy: 0.90 - ETA: 1:38 - loss: 0.3482 - accuracy: 0.90 - ETA: 1:36 - loss: 0.3494 - accuracy: 0.90 - ETA: 1:34 - loss: 0.3493 - accuracy: 0.90 - ETA: 1:32 - loss: 0.3480 - accuracy: 0.90 - ETA: 1:30 - loss: 0.3468 - accuracy: 0.90 - ETA: 1:27 - loss: 0.3469 - accuracy: 0.90 - ETA: 1:25 - loss: 0.3466 - accuracy: 0.90 - ETA: 1:23 - loss: 0.3461 - accuracy: 0.90 - ETA: 1:21 - loss: 0.3457 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3441 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3437 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3448 - accuracy: 0.90 - ETA: 1:12 - loss: 0.3443 - accuracy: 0.90 - ETA: 1:10 - loss: 0.3445 - accuracy: 0.90 - ETA: 1:08 - loss: 0.3463 - accuracy: 0.90 - ETA: 1:06 - loss: 0.3465 - accuracy: 0.90 - ETA: 1:04 - loss: 0.3460 - accuracy: 0.90 - ETA: 1:02 - loss: 0.3445 - accuracy: 0.90 - ETA: 59s - loss: 0.3454 - accuracy: 0.9048 - ETA: 57s - loss: 0.3452 - accuracy: 0.904 - ETA: 55s - loss: 0.3480 - accuracy: 0.904 - ETA: 53s - loss: 0.3475 - accuracy: 0.904 - ETA: 51s - loss: 0.3473 - accuracy: 0.904 - ETA: 49s - loss: 0.3468 - accuracy: 0.904 - ETA: 47s - loss: 0.3467 - accuracy: 0.904 - ETA: 44s - loss: 0.3460 - accuracy: 0.904 - ETA: 42s - loss: 0.3466 - accuracy: 0.904 - ETA: 40s - loss: 0.3453 - accuracy: 0.904 - ETA: 38s - loss: 0.3458 - accuracy: 0.904 - ETA: 36s - loss: 0.3456 - accuracy: 0.904 - ETA: 34s - loss: 0.3450 - accuracy: 0.904 - ETA: 31s - loss: 0.3470 - accuracy: 0.903 - ETA: 29s - loss: 0.3459 - accuracy: 0.904 - ETA: 27s - loss: 0.3461 - accuracy: 0.904 - ETA: 25s - loss: 0.3469 - accuracy: 0.903 - ETA: 23s - loss: 0.3479 - accuracy: 0.903 - ETA: 21s - loss: 0.3482 - accuracy: 0.903 - ETA: 19s - loss: 0.3492 - accuracy: 0.903 - ETA: 16s - loss: 0.3491 - accuracy: 0.903 - ETA: 14s - loss: 0.3494 - accuracy: 0.903 - ETA: 12s - loss: 0.3499 - accuracy: 0.903 - ETA: 10s - loss: 0.3494 - accuracy: 0.903 - ETA: 8s - loss: 0.3498 - accuracy: 0.903 - ETA: 6s - loss: 0.3504 - accuracy: 0.90 - ETA: 4s - loss: 0.3521 - accuracy: 0.90 - ETA: 1s - loss: 0.3513 - accuracy: 0.90 - 350s 18ms/step - loss: 0.3514 - accuracy: 0.9026 - val_loss: 1.4156 - val_accuracy: 0.7724\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:22 - loss: 0.4206 - accuracy: 0.88 - ETA: 5:13 - loss: 0.4735 - accuracy: 0.87 - ETA: 5:11 - loss: 0.4397 - accuracy: 0.88 - ETA: 5:07 - loss: 0.4252 - accuracy: 0.89 - ETA: 5:02 - loss: 0.3720 - accuracy: 0.90 - ETA: 5:01 - loss: 0.3423 - accuracy: 0.91 - ETA: 5:01 - loss: 0.3675 - accuracy: 0.91 - ETA: 4:58 - loss: 0.3532 - accuracy: 0.91 - ETA: 4:59 - loss: 0.3393 - accuracy: 0.91 - ETA: 4:57 - loss: 0.3473 - accuracy: 0.91 - ETA: 4:55 - loss: 0.3647 - accuracy: 0.90 - ETA: 4:54 - loss: 0.3476 - accuracy: 0.90 - ETA: 4:52 - loss: 0.3611 - accuracy: 0.90 - ETA: 4:50 - loss: 0.3572 - accuracy: 0.90 - ETA: 4:47 - loss: 0.3484 - accuracy: 0.90 - ETA: 4:45 - loss: 0.3457 - accuracy: 0.90 - ETA: 4:43 - loss: 0.3420 - accuracy: 0.90 - ETA: 4:42 - loss: 0.3421 - accuracy: 0.90 - ETA: 4:39 - loss: 0.3402 - accuracy: 0.91 - ETA: 4:37 - loss: 0.3345 - accuracy: 0.91 - ETA: 4:36 - loss: 0.3339 - accuracy: 0.91 - ETA: 4:33 - loss: 0.3301 - accuracy: 0.91 - ETA: 4:31 - loss: 0.3310 - accuracy: 0.91 - ETA: 4:29 - loss: 0.3290 - accuracy: 0.91 - ETA: 4:27 - loss: 0.3310 - accuracy: 0.91 - ETA: 4:25 - loss: 0.3295 - accuracy: 0.91 - ETA: 4:23 - loss: 0.3284 - accuracy: 0.91 - ETA: 4:20 - loss: 0.3269 - accuracy: 0.91 - ETA: 4:18 - loss: 0.3263 - accuracy: 0.91 - ETA: 4:17 - loss: 0.3266 - accuracy: 0.91 - ETA: 4:15 - loss: 0.3241 - accuracy: 0.91 - ETA: 4:12 - loss: 0.3243 - accuracy: 0.91 - ETA: 4:10 - loss: 0.3284 - accuracy: 0.91 - ETA: 4:08 - loss: 0.3307 - accuracy: 0.91 - ETA: 4:07 - loss: 0.3337 - accuracy: 0.91 - ETA: 4:04 - loss: 0.3376 - accuracy: 0.90 - ETA: 4:03 - loss: 0.3375 - accuracy: 0.90 - ETA: 4:01 - loss: 0.3342 - accuracy: 0.90 - ETA: 3:59 - loss: 0.3310 - accuracy: 0.90 - ETA: 3:56 - loss: 0.3318 - accuracy: 0.90 - ETA: 3:55 - loss: 0.3313 - accuracy: 0.90 - ETA: 3:52 - loss: 0.3331 - accuracy: 0.90 - ETA: 3:50 - loss: 0.3342 - accuracy: 0.90 - ETA: 3:48 - loss: 0.3380 - accuracy: 0.90 - ETA: 3:46 - loss: 0.3395 - accuracy: 0.90 - ETA: 3:44 - loss: 0.3390 - accuracy: 0.90 - ETA: 3:41 - loss: 0.3378 - accuracy: 0.90 - ETA: 3:39 - loss: 0.3389 - accuracy: 0.90 - ETA: 3:37 - loss: 0.3388 - accuracy: 0.90 - ETA: 3:35 - loss: 0.3376 - accuracy: 0.90 - ETA: 3:33 - loss: 0.3360 - accuracy: 0.90 - ETA: 3:31 - loss: 0.3376 - accuracy: 0.90 - ETA: 3:29 - loss: 0.3370 - accuracy: 0.90 - ETA: 3:27 - loss: 0.3363 - accuracy: 0.90 - ETA: 3:25 - loss: 0.3369 - accuracy: 0.90 - ETA: 3:23 - loss: 0.3372 - accuracy: 0.90 - ETA: 3:21 - loss: 0.3336 - accuracy: 0.91 - ETA: 3:19 - loss: 0.3361 - accuracy: 0.91 - ETA: 3:17 - loss: 0.3399 - accuracy: 0.90 - ETA: 3:14 - loss: 0.3396 - accuracy: 0.91 - ETA: 3:12 - loss: 0.3377 - accuracy: 0.91 - ETA: 3:10 - loss: 0.3349 - accuracy: 0.91 - ETA: 3:08 - loss: 0.3329 - accuracy: 0.91 - ETA: 3:06 - loss: 0.3343 - accuracy: 0.91 - ETA: 3:03 - loss: 0.3349 - accuracy: 0.91 - ETA: 3:01 - loss: 0.3341 - accuracy: 0.91 - ETA: 2:59 - loss: 0.3341 - accuracy: 0.91 - ETA: 2:57 - loss: 0.3323 - accuracy: 0.91 - ETA: 2:55 - loss: 0.3333 - accuracy: 0.91 - ETA: 2:53 - loss: 0.3331 - accuracy: 0.91 - ETA: 2:51 - loss: 0.3340 - accuracy: 0.91 - ETA: 2:49 - loss: 0.3326 - accuracy: 0.91 - ETA: 2:46 - loss: 0.3338 - accuracy: 0.91 - ETA: 2:44 - loss: 0.3340 - accuracy: 0.91 - ETA: 2:42 - loss: 0.3329 - accuracy: 0.91 - ETA: 2:40 - loss: 0.3333 - accuracy: 0.91 - ETA: 2:38 - loss: 0.3309 - accuracy: 0.91 - ETA: 2:36 - loss: 0.3305 - accuracy: 0.91 - ETA: 2:33 - loss: 0.3298 - accuracy: 0.91 - ETA: 2:31 - loss: 0.3298 - accuracy: 0.91 - ETA: 2:29 - loss: 0.3300 - accuracy: 0.91 - ETA: 2:27 - loss: 0.3289 - accuracy: 0.91 - ETA: 2:25 - loss: 0.3294 - accuracy: 0.91 - ETA: 2:23 - loss: 0.3282 - accuracy: 0.91 - ETA: 2:21 - loss: 0.3301 - accuracy: 0.91 - ETA: 2:18 - loss: 0.3293 - accuracy: 0.91 - ETA: 2:16 - loss: 0.3282 - accuracy: 0.91 - ETA: 2:14 - loss: 0.3280 - accuracy: 0.91 - ETA: 2:12 - loss: 0.3287 - accuracy: 0.91 - ETA: 2:10 - loss: 0.3282 - accuracy: 0.91 - ETA: 2:08 - loss: 0.3300 - accuracy: 0.91 - ETA: 2:06 - loss: 0.3315 - accuracy: 0.91 - ETA: 2:04 - loss: 0.3310 - accuracy: 0.91 - ETA: 2:02 - loss: 0.3316 - accuracy: 0.90 - ETA: 1:59 - loss: 0.3297 - accuracy: 0.91 - ETA: 1:57 - loss: 0.3297 - accuracy: 0.91 - ETA: 1:55 - loss: 0.3303 - accuracy: 0.91 - ETA: 1:53 - loss: 0.3291 - accuracy: 0.91 - ETA: 1:51 - loss: 0.3275 - accuracy: 0.91 - ETA: 1:49 - loss: 0.3275 - accuracy: 0.91 - ETA: 1:46 - loss: 0.3283 - accuracy: 0.91 - ETA: 1:44 - loss: 0.3287 - accuracy: 0.91 - ETA: 1:42 - loss: 0.3273 - accuracy: 0.91 - ETA: 1:40 - loss: 0.3262 - accuracy: 0.91 - ETA: 1:38 - loss: 0.3257 - accuracy: 0.91 - ETA: 1:36 - loss: 0.3260 - accuracy: 0.91 - ETA: 1:34 - loss: 0.3258 - accuracy: 0.91 - ETA: 1:31 - loss: 0.3242 - accuracy: 0.91 - ETA: 1:29 - loss: 0.3251 - accuracy: 0.91 - ETA: 1:27 - loss: 0.3245 - accuracy: 0.91 - ETA: 1:25 - loss: 0.3261 - accuracy: 0.91 - ETA: 1:23 - loss: 0.3258 - accuracy: 0.91 - ETA: 1:21 - loss: 0.3239 - accuracy: 0.91 - ETA: 1:19 - loss: 0.3247 - accuracy: 0.91 - ETA: 1:16 - loss: 0.3235 - accuracy: 0.91 - ETA: 1:14 - loss: 0.3232 - accuracy: 0.91 - ETA: 1:12 - loss: 0.3235 - accuracy: 0.91 - ETA: 1:10 - loss: 0.3234 - accuracy: 0.91 - ETA: 1:08 - loss: 0.3222 - accuracy: 0.91 - ETA: 1:06 - loss: 0.3217 - accuracy: 0.91 - ETA: 1:04 - loss: 0.3213 - accuracy: 0.91 - ETA: 1:01 - loss: 0.3219 - accuracy: 0.91 - ETA: 59s - loss: 0.3229 - accuracy: 0.9101 - ETA: 57s - loss: 0.3225 - accuracy: 0.910 - ETA: 55s - loss: 0.3230 - accuracy: 0.910 - ETA: 53s - loss: 0.3225 - accuracy: 0.910 - ETA: 51s - loss: 0.3246 - accuracy: 0.909 - ETA: 49s - loss: 0.3241 - accuracy: 0.909 - ETA: 46s - loss: 0.3242 - accuracy: 0.909 - ETA: 44s - loss: 0.3232 - accuracy: 0.910 - ETA: 42s - loss: 0.3227 - accuracy: 0.910 - ETA: 40s - loss: 0.3240 - accuracy: 0.910 - ETA: 38s - loss: 0.3247 - accuracy: 0.909 - ETA: 36s - loss: 0.3256 - accuracy: 0.909 - ETA: 34s - loss: 0.3263 - accuracy: 0.909 - ETA: 31s - loss: 0.3266 - accuracy: 0.909 - ETA: 29s - loss: 0.3252 - accuracy: 0.909 - ETA: 27s - loss: 0.3249 - accuracy: 0.909 - ETA: 25s - loss: 0.3253 - accuracy: 0.909 - ETA: 23s - loss: 0.3252 - accuracy: 0.909 - ETA: 21s - loss: 0.3245 - accuracy: 0.909 - ETA: 19s - loss: 0.3247 - accuracy: 0.909 - ETA: 16s - loss: 0.3266 - accuracy: 0.909 - ETA: 14s - loss: 0.3270 - accuracy: 0.909 - ETA: 12s - loss: 0.3261 - accuracy: 0.909 - ETA: 10s - loss: 0.3260 - accuracy: 0.909 - ETA: 8s - loss: 0.3253 - accuracy: 0.909 - ETA: 6s - loss: 0.3262 - accuracy: 0.90 - ETA: 4s - loss: 0.3256 - accuracy: 0.90 - ETA: 1s - loss: 0.3250 - accuracy: 0.90 - 347s 18ms/step - loss: 0.3249 - accuracy: 0.9098 - val_loss: 1.3883 - val_accuracy: 0.7821\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:24 - loss: 0.2563 - accuracy: 0.93 - ETA: 5:22 - loss: 0.1978 - accuracy: 0.94 - ETA: 5:21 - loss: 0.1628 - accuracy: 0.94 - ETA: 5:15 - loss: 0.2468 - accuracy: 0.93 - ETA: 5:16 - loss: 0.2498 - accuracy: 0.92 - ETA: 5:14 - loss: 0.2583 - accuracy: 0.92 - ETA: 5:11 - loss: 0.2606 - accuracy: 0.92 - ETA: 5:08 - loss: 0.2575 - accuracy: 0.92 - ETA: 5:06 - loss: 0.2657 - accuracy: 0.92 - ETA: 5:02 - loss: 0.2704 - accuracy: 0.92 - ETA: 5:01 - loss: 0.2693 - accuracy: 0.92 - ETA: 4:59 - loss: 0.2674 - accuracy: 0.92 - ETA: 4:55 - loss: 0.2687 - accuracy: 0.92 - ETA: 4:54 - loss: 0.2663 - accuracy: 0.92 - ETA: 4:52 - loss: 0.2763 - accuracy: 0.92 - ETA: 4:50 - loss: 0.2776 - accuracy: 0.92 - ETA: 4:48 - loss: 0.2834 - accuracy: 0.92 - ETA: 4:45 - loss: 0.2864 - accuracy: 0.92 - ETA: 4:43 - loss: 0.2833 - accuracy: 0.92 - ETA: 4:41 - loss: 0.2956 - accuracy: 0.92 - ETA: 4:39 - loss: 0.2958 - accuracy: 0.92 - ETA: 4:37 - loss: 0.2915 - accuracy: 0.92 - ETA: 4:35 - loss: 0.2914 - accuracy: 0.92 - ETA: 4:33 - loss: 0.2900 - accuracy: 0.92 - ETA: 4:30 - loss: 0.2874 - accuracy: 0.92 - ETA: 4:28 - loss: 0.2848 - accuracy: 0.92 - ETA: 4:25 - loss: 0.2825 - accuracy: 0.92 - ETA: 4:23 - loss: 0.2801 - accuracy: 0.92 - ETA: 4:21 - loss: 0.2804 - accuracy: 0.92 - ETA: 4:19 - loss: 0.2829 - accuracy: 0.92 - ETA: 4:17 - loss: 0.2840 - accuracy: 0.92 - ETA: 4:15 - loss: 0.2797 - accuracy: 0.92 - ETA: 4:13 - loss: 0.2820 - accuracy: 0.92 - ETA: 4:11 - loss: 0.2865 - accuracy: 0.92 - ETA: 4:09 - loss: 0.2833 - accuracy: 0.92 - ETA: 4:07 - loss: 0.2858 - accuracy: 0.92 - ETA: 4:05 - loss: 0.2931 - accuracy: 0.92 - ETA: 4:03 - loss: 0.2914 - accuracy: 0.92 - ETA: 4:01 - loss: 0.2923 - accuracy: 0.92 - ETA: 3:58 - loss: 0.2915 - accuracy: 0.92 - ETA: 3:56 - loss: 0.2890 - accuracy: 0.92 - ETA: 3:54 - loss: 0.2896 - accuracy: 0.92 - ETA: 3:52 - loss: 0.2906 - accuracy: 0.92 - ETA: 3:50 - loss: 0.2871 - accuracy: 0.92 - ETA: 3:48 - loss: 0.2876 - accuracy: 0.92 - ETA: 3:46 - loss: 0.2870 - accuracy: 0.92 - ETA: 3:43 - loss: 0.2857 - accuracy: 0.92 - ETA: 3:41 - loss: 0.2857 - accuracy: 0.92 - ETA: 3:39 - loss: 0.2918 - accuracy: 0.92 - ETA: 3:37 - loss: 0.2932 - accuracy: 0.92 - ETA: 3:35 - loss: 0.2898 - accuracy: 0.92 - ETA: 3:32 - loss: 0.2905 - accuracy: 0.92 - ETA: 3:31 - loss: 0.2904 - accuracy: 0.92 - ETA: 3:28 - loss: 0.2913 - accuracy: 0.92 - ETA: 3:26 - loss: 0.2927 - accuracy: 0.92 - ETA: 3:24 - loss: 0.2921 - accuracy: 0.92 - ETA: 3:22 - loss: 0.2925 - accuracy: 0.92 - ETA: 3:19 - loss: 0.2918 - accuracy: 0.92 - ETA: 3:17 - loss: 0.2959 - accuracy: 0.92 - ETA: 3:15 - loss: 0.2963 - accuracy: 0.92 - ETA: 3:13 - loss: 0.2996 - accuracy: 0.92 - ETA: 3:11 - loss: 0.3015 - accuracy: 0.92 - ETA: 3:09 - loss: 0.3020 - accuracy: 0.92 - ETA: 3:07 - loss: 0.3013 - accuracy: 0.91 - ETA: 3:05 - loss: 0.3008 - accuracy: 0.91 - ETA: 3:02 - loss: 0.3017 - accuracy: 0.91 - ETA: 3:00 - loss: 0.3039 - accuracy: 0.91 - ETA: 2:58 - loss: 0.3035 - accuracy: 0.91 - ETA: 2:56 - loss: 0.3025 - accuracy: 0.91 - ETA: 2:54 - loss: 0.3067 - accuracy: 0.91 - ETA: 2:52 - loss: 0.3070 - accuracy: 0.91 - ETA: 2:50 - loss: 0.3070 - accuracy: 0.91 - ETA: 2:47 - loss: 0.3076 - accuracy: 0.91 - ETA: 2:45 - loss: 0.3069 - accuracy: 0.91 - ETA: 2:43 - loss: 0.3066 - accuracy: 0.91 - ETA: 2:41 - loss: 0.3078 - accuracy: 0.91 - ETA: 2:39 - loss: 0.3064 - accuracy: 0.91 - ETA: 2:36 - loss: 0.3070 - accuracy: 0.91 - ETA: 2:34 - loss: 0.3082 - accuracy: 0.91 - ETA: 2:32 - loss: 0.3087 - accuracy: 0.91 - ETA: 2:30 - loss: 0.3090 - accuracy: 0.91 - ETA: 2:28 - loss: 0.3092 - accuracy: 0.91 - ETA: 2:25 - loss: 0.3092 - accuracy: 0.91 - ETA: 2:23 - loss: 0.3094 - accuracy: 0.91 - ETA: 2:21 - loss: 0.3090 - accuracy: 0.91 - ETA: 2:19 - loss: 0.3114 - accuracy: 0.91 - ETA: 2:17 - loss: 0.3117 - accuracy: 0.91 - ETA: 2:15 - loss: 0.3122 - accuracy: 0.91 - ETA: 2:13 - loss: 0.3126 - accuracy: 0.91 - ETA: 2:11 - loss: 0.3120 - accuracy: 0.91 - ETA: 2:08 - loss: 0.3116 - accuracy: 0.91 - ETA: 2:06 - loss: 0.3116 - accuracy: 0.91 - ETA: 2:04 - loss: 0.3125 - accuracy: 0.91 - ETA: 2:02 - loss: 0.3123 - accuracy: 0.91 - ETA: 2:00 - loss: 0.3151 - accuracy: 0.91 - ETA: 1:58 - loss: 0.3153 - accuracy: 0.91 - ETA: 1:56 - loss: 0.3146 - accuracy: 0.91 - ETA: 1:54 - loss: 0.3139 - accuracy: 0.91 - ETA: 1:51 - loss: 0.3134 - accuracy: 0.91 - ETA: 1:49 - loss: 0.3127 - accuracy: 0.91 - ETA: 1:47 - loss: 0.3125 - accuracy: 0.91 - ETA: 1:45 - loss: 0.3114 - accuracy: 0.91 - ETA: 1:43 - loss: 0.3103 - accuracy: 0.91 - ETA: 1:41 - loss: 0.3091 - accuracy: 0.91 - ETA: 1:39 - loss: 0.3096 - accuracy: 0.91 - ETA: 1:37 - loss: 0.3105 - accuracy: 0.91 - ETA: 1:36 - loss: 0.3106 - accuracy: 0.91 - ETA: 1:34 - loss: 0.3109 - accuracy: 0.91 - ETA: 1:32 - loss: 0.3100 - accuracy: 0.91 - ETA: 1:30 - loss: 0.3092 - accuracy: 0.91 - ETA: 1:27 - loss: 0.3091 - accuracy: 0.91 - ETA: 1:25 - loss: 0.3101 - accuracy: 0.91 - ETA: 1:23 - loss: 0.3104 - accuracy: 0.91 - ETA: 1:21 - loss: 0.3109 - accuracy: 0.91 - ETA: 1:19 - loss: 0.3108 - accuracy: 0.91 - ETA: 1:16 - loss: 0.3106 - accuracy: 0.91 - ETA: 1:14 - loss: 0.3093 - accuracy: 0.91 - ETA: 1:12 - loss: 0.3101 - accuracy: 0.91 - ETA: 1:10 - loss: 0.3099 - accuracy: 0.91 - ETA: 1:07 - loss: 0.3093 - accuracy: 0.91 - ETA: 1:05 - loss: 0.3081 - accuracy: 0.91 - ETA: 1:03 - loss: 0.3084 - accuracy: 0.91 - ETA: 1:01 - loss: 0.3082 - accuracy: 0.91 - ETA: 59s - loss: 0.3072 - accuracy: 0.9149 - ETA: 56s - loss: 0.3071 - accuracy: 0.914 - ETA: 54s - loss: 0.3089 - accuracy: 0.914 - ETA: 52s - loss: 0.3093 - accuracy: 0.914 - ETA: 50s - loss: 0.3088 - accuracy: 0.914 - ETA: 48s - loss: 0.3088 - accuracy: 0.914 - ETA: 45s - loss: 0.3081 - accuracy: 0.914 - ETA: 43s - loss: 0.3076 - accuracy: 0.914 - ETA: 41s - loss: 0.3101 - accuracy: 0.914 - ETA: 39s - loss: 0.3096 - accuracy: 0.914 - ETA: 37s - loss: 0.3090 - accuracy: 0.914 - ETA: 34s - loss: 0.3080 - accuracy: 0.914 - ETA: 32s - loss: 0.3078 - accuracy: 0.914 - ETA: 30s - loss: 0.3071 - accuracy: 0.914 - ETA: 28s - loss: 0.3073 - accuracy: 0.914 - ETA: 26s - loss: 0.3063 - accuracy: 0.914 - ETA: 23s - loss: 0.3072 - accuracy: 0.914 - ETA: 21s - loss: 0.3075 - accuracy: 0.914 - ETA: 19s - loss: 0.3075 - accuracy: 0.914 - ETA: 17s - loss: 0.3079 - accuracy: 0.914 - ETA: 15s - loss: 0.3084 - accuracy: 0.913 - ETA: 12s - loss: 0.3103 - accuracy: 0.913 - ETA: 10s - loss: 0.3104 - accuracy: 0.913 - ETA: 8s - loss: 0.3113 - accuracy: 0.913 - ETA: 6s - loss: 0.3110 - accuracy: 0.91 - ETA: 4s - loss: 0.3114 - accuracy: 0.91 - ETA: 1s - loss: 0.3117 - accuracy: 0.91 - 355s 18ms/step - loss: 0.3123 - accuracy: 0.9134 - val_loss: 1.3537 - val_accuracy: 0.7836\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:15 - loss: 0.2681 - accuracy: 0.96 - ETA: 5:23 - loss: 0.2874 - accuracy: 0.92 - ETA: 5:16 - loss: 0.3160 - accuracy: 0.92 - ETA: 5:15 - loss: 0.3069 - accuracy: 0.92 - ETA: 5:12 - loss: 0.2944 - accuracy: 0.92 - ETA: 5:09 - loss: 0.3037 - accuracy: 0.92 - ETA: 5:08 - loss: 0.3179 - accuracy: 0.92 - ETA: 5:08 - loss: 0.3028 - accuracy: 0.92 - ETA: 5:07 - loss: 0.3049 - accuracy: 0.92 - ETA: 5:05 - loss: 0.2948 - accuracy: 0.92 - ETA: 5:03 - loss: 0.3005 - accuracy: 0.92 - ETA: 5:00 - loss: 0.2967 - accuracy: 0.92 - ETA: 4:57 - loss: 0.2945 - accuracy: 0.92 - ETA: 4:57 - loss: 0.2879 - accuracy: 0.92 - ETA: 4:54 - loss: 0.2833 - accuracy: 0.92 - ETA: 4:51 - loss: 0.2755 - accuracy: 0.92 - ETA: 4:47 - loss: 0.2710 - accuracy: 0.92 - ETA: 4:46 - loss: 0.2699 - accuracy: 0.92 - ETA: 4:43 - loss: 0.2758 - accuracy: 0.92 - ETA: 4:41 - loss: 0.2783 - accuracy: 0.92 - ETA: 4:39 - loss: 0.2810 - accuracy: 0.92 - ETA: 4:37 - loss: 0.2773 - accuracy: 0.92 - ETA: 4:35 - loss: 0.2844 - accuracy: 0.92 - ETA: 4:33 - loss: 0.2863 - accuracy: 0.92 - ETA: 4:31 - loss: 0.2819 - accuracy: 0.92 - ETA: 4:29 - loss: 0.2882 - accuracy: 0.92 - ETA: 4:27 - loss: 0.2849 - accuracy: 0.92 - ETA: 4:25 - loss: 0.2820 - accuracy: 0.92 - ETA: 4:22 - loss: 0.2766 - accuracy: 0.92 - ETA: 4:20 - loss: 0.2741 - accuracy: 0.92 - ETA: 4:18 - loss: 0.2726 - accuracy: 0.92 - ETA: 4:17 - loss: 0.2703 - accuracy: 0.92 - ETA: 4:14 - loss: 0.2670 - accuracy: 0.92 - ETA: 4:12 - loss: 0.2693 - accuracy: 0.92 - ETA: 4:11 - loss: 0.2761 - accuracy: 0.92 - ETA: 4:08 - loss: 0.2752 - accuracy: 0.92 - ETA: 4:06 - loss: 0.2785 - accuracy: 0.92 - ETA: 4:04 - loss: 0.2809 - accuracy: 0.92 - ETA: 4:02 - loss: 0.2776 - accuracy: 0.92 - ETA: 4:00 - loss: 0.2821 - accuracy: 0.92 - ETA: 3:58 - loss: 0.2823 - accuracy: 0.92 - ETA: 3:56 - loss: 0.2854 - accuracy: 0.92 - ETA: 3:54 - loss: 0.2823 - accuracy: 0.92 - ETA: 3:52 - loss: 0.2799 - accuracy: 0.92 - ETA: 3:50 - loss: 0.2786 - accuracy: 0.92 - ETA: 3:48 - loss: 0.2789 - accuracy: 0.92 - ETA: 3:45 - loss: 0.2812 - accuracy: 0.92 - ETA: 3:43 - loss: 0.2824 - accuracy: 0.92 - ETA: 3:41 - loss: 0.2827 - accuracy: 0.92 - ETA: 3:38 - loss: 0.2862 - accuracy: 0.92 - ETA: 3:36 - loss: 0.2892 - accuracy: 0.92 - ETA: 3:34 - loss: 0.2864 - accuracy: 0.92 - ETA: 3:31 - loss: 0.2873 - accuracy: 0.92 - ETA: 3:29 - loss: 0.2854 - accuracy: 0.92 - ETA: 3:27 - loss: 0.2865 - accuracy: 0.92 - ETA: 3:25 - loss: 0.2869 - accuracy: 0.92 - ETA: 3:23 - loss: 0.2886 - accuracy: 0.92 - ETA: 3:20 - loss: 0.2870 - accuracy: 0.92 - ETA: 3:18 - loss: 0.2900 - accuracy: 0.92 - ETA: 3:16 - loss: 0.2905 - accuracy: 0.92 - ETA: 3:14 - loss: 0.2907 - accuracy: 0.92 - ETA: 3:12 - loss: 0.2892 - accuracy: 0.92 - ETA: 3:10 - loss: 0.2904 - accuracy: 0.92 - ETA: 3:07 - loss: 0.2907 - accuracy: 0.92 - ETA: 3:05 - loss: 0.2899 - accuracy: 0.92 - ETA: 3:03 - loss: 0.2903 - accuracy: 0.92 - ETA: 3:01 - loss: 0.2893 - accuracy: 0.92 - ETA: 2:58 - loss: 0.2886 - accuracy: 0.92 - ETA: 2:56 - loss: 0.2895 - accuracy: 0.92 - ETA: 2:54 - loss: 0.2912 - accuracy: 0.92 - ETA: 2:52 - loss: 0.2895 - accuracy: 0.92 - ETA: 2:50 - loss: 0.2877 - accuracy: 0.92 - ETA: 2:47 - loss: 0.2875 - accuracy: 0.92 - ETA: 2:46 - loss: 0.2862 - accuracy: 0.92 - ETA: 2:43 - loss: 0.2869 - accuracy: 0.92 - ETA: 2:41 - loss: 0.2863 - accuracy: 0.92 - ETA: 2:39 - loss: 0.2879 - accuracy: 0.92 - ETA: 2:37 - loss: 0.2880 - accuracy: 0.92 - ETA: 2:35 - loss: 0.2887 - accuracy: 0.92 - ETA: 2:32 - loss: 0.2887 - accuracy: 0.92 - ETA: 2:30 - loss: 0.2901 - accuracy: 0.92 - ETA: 2:28 - loss: 0.2920 - accuracy: 0.92 - ETA: 2:27 - loss: 0.2916 - accuracy: 0.92 - ETA: 2:25 - loss: 0.2907 - accuracy: 0.92 - ETA: 2:22 - loss: 0.2912 - accuracy: 0.92 - ETA: 2:19 - loss: 0.2895 - accuracy: 0.92 - ETA: 2:16 - loss: 0.2918 - accuracy: 0.92 - ETA: 2:14 - loss: 0.2914 - accuracy: 0.92 - ETA: 2:11 - loss: 0.2904 - accuracy: 0.92 - ETA: 2:08 - loss: 0.2896 - accuracy: 0.92 - ETA: 2:06 - loss: 0.2912 - accuracy: 0.92 - ETA: 2:03 - loss: 0.2897 - accuracy: 0.92 - ETA: 2:01 - loss: 0.2887 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2870 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2859 - accuracy: 0.92 - ETA: 1:54 - loss: 0.2871 - accuracy: 0.92 - ETA: 1:52 - loss: 0.2873 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2862 - accuracy: 0.92 - ETA: 1:47 - loss: 0.2866 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2881 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2897 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2915 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2931 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2929 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2924 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2941 - accuracy: 0.92 - ETA: 1:28 - loss: 0.2968 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2966 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2954 - accuracy: 0.92 - ETA: 1:21 - loss: 0.2949 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2954 - accuracy: 0.92 - ETA: 1:17 - loss: 0.2956 - accuracy: 0.92 - ETA: 1:15 - loss: 0.2962 - accuracy: 0.92 - ETA: 1:13 - loss: 0.2951 - accuracy: 0.92 - ETA: 1:10 - loss: 0.2954 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2962 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2956 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2951 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2961 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2958 - accuracy: 0.92 - ETA: 58s - loss: 0.2957 - accuracy: 0.9219 - ETA: 56s - loss: 0.2945 - accuracy: 0.922 - ETA: 53s - loss: 0.2946 - accuracy: 0.922 - ETA: 51s - loss: 0.2934 - accuracy: 0.922 - ETA: 49s - loss: 0.2926 - accuracy: 0.922 - ETA: 47s - loss: 0.2919 - accuracy: 0.923 - ETA: 45s - loss: 0.2918 - accuracy: 0.922 - ETA: 43s - loss: 0.2933 - accuracy: 0.922 - ETA: 41s - loss: 0.2932 - accuracy: 0.922 - ETA: 39s - loss: 0.2932 - accuracy: 0.923 - ETA: 37s - loss: 0.2940 - accuracy: 0.922 - ETA: 35s - loss: 0.2944 - accuracy: 0.922 - ETA: 33s - loss: 0.2938 - accuracy: 0.922 - ETA: 31s - loss: 0.2934 - accuracy: 0.922 - ETA: 29s - loss: 0.2938 - accuracy: 0.922 - ETA: 28s - loss: 0.2947 - accuracy: 0.922 - ETA: 26s - loss: 0.2950 - accuracy: 0.922 - ETA: 24s - loss: 0.2947 - accuracy: 0.922 - ETA: 22s - loss: 0.2940 - accuracy: 0.922 - ETA: 20s - loss: 0.2943 - accuracy: 0.922 - ETA: 18s - loss: 0.2940 - accuracy: 0.922 - ETA: 16s - loss: 0.2953 - accuracy: 0.922 - ETA: 14s - loss: 0.2940 - accuracy: 0.922 - ETA: 12s - loss: 0.2943 - accuracy: 0.922 - ETA: 10s - loss: 0.2945 - accuracy: 0.921 - ETA: 8s - loss: 0.2942 - accuracy: 0.922 - ETA: 7s - loss: 0.2941 - accuracy: 0.92 - ETA: 5s - loss: 0.2932 - accuracy: 0.92 - ETA: 3s - loss: 0.2927 - accuracy: 0.92 - ETA: 1s - loss: 0.2926 - accuracy: 0.92 - 288s 15ms/step - loss: 0.2930 - accuracy: 0.9223 - val_loss: 1.4312 - val_accuracy: 0.7850\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:35 - loss: 0.1550 - accuracy: 0.92 - ETA: 3:24 - loss: 0.3333 - accuracy: 0.91 - ETA: 3:19 - loss: 0.2905 - accuracy: 0.91 - ETA: 3:17 - loss: 0.3392 - accuracy: 0.90 - ETA: 3:15 - loss: 0.3533 - accuracy: 0.90 - ETA: 3:14 - loss: 0.3408 - accuracy: 0.90 - ETA: 3:12 - loss: 0.3132 - accuracy: 0.91 - ETA: 3:10 - loss: 0.2911 - accuracy: 0.92 - ETA: 3:08 - loss: 0.2863 - accuracy: 0.92 - ETA: 3:06 - loss: 0.2911 - accuracy: 0.92 - ETA: 3:05 - loss: 0.2955 - accuracy: 0.92 - ETA: 3:04 - loss: 0.2881 - accuracy: 0.92 - ETA: 3:04 - loss: 0.2951 - accuracy: 0.91 - ETA: 3:04 - loss: 0.2889 - accuracy: 0.92 - ETA: 3:02 - loss: 0.2834 - accuracy: 0.92 - ETA: 3:00 - loss: 0.2866 - accuracy: 0.92 - ETA: 2:59 - loss: 0.2875 - accuracy: 0.92 - ETA: 2:58 - loss: 0.2819 - accuracy: 0.92 - ETA: 2:56 - loss: 0.2766 - accuracy: 0.92 - ETA: 2:54 - loss: 0.2724 - accuracy: 0.92 - ETA: 2:54 - loss: 0.2703 - accuracy: 0.92 - ETA: 2:52 - loss: 0.2660 - accuracy: 0.92 - ETA: 2:51 - loss: 0.2608 - accuracy: 0.92 - ETA: 2:51 - loss: 0.2673 - accuracy: 0.92 - ETA: 2:50 - loss: 0.2643 - accuracy: 0.92 - ETA: 2:49 - loss: 0.2616 - accuracy: 0.92 - ETA: 2:47 - loss: 0.2678 - accuracy: 0.92 - ETA: 2:46 - loss: 0.2647 - accuracy: 0.92 - ETA: 2:45 - loss: 0.2664 - accuracy: 0.92 - ETA: 2:43 - loss: 0.2682 - accuracy: 0.92 - ETA: 2:42 - loss: 0.2662 - accuracy: 0.92 - ETA: 2:41 - loss: 0.2685 - accuracy: 0.92 - ETA: 2:39 - loss: 0.2693 - accuracy: 0.92 - ETA: 2:38 - loss: 0.2708 - accuracy: 0.92 - ETA: 2:37 - loss: 0.2655 - accuracy: 0.92 - ETA: 2:36 - loss: 0.2625 - accuracy: 0.92 - ETA: 2:35 - loss: 0.2604 - accuracy: 0.92 - ETA: 2:33 - loss: 0.2594 - accuracy: 0.92 - ETA: 2:32 - loss: 0.2594 - accuracy: 0.92 - ETA: 2:30 - loss: 0.2592 - accuracy: 0.92 - ETA: 2:29 - loss: 0.2603 - accuracy: 0.92 - ETA: 2:28 - loss: 0.2607 - accuracy: 0.92 - ETA: 2:26 - loss: 0.2603 - accuracy: 0.92 - ETA: 2:25 - loss: 0.2591 - accuracy: 0.92 - ETA: 2:23 - loss: 0.2580 - accuracy: 0.92 - ETA: 2:22 - loss: 0.2570 - accuracy: 0.92 - ETA: 2:20 - loss: 0.2583 - accuracy: 0.92 - ETA: 2:19 - loss: 0.2597 - accuracy: 0.92 - ETA: 2:18 - loss: 0.2615 - accuracy: 0.92 - ETA: 2:17 - loss: 0.2603 - accuracy: 0.92 - ETA: 2:16 - loss: 0.2589 - accuracy: 0.92 - ETA: 2:14 - loss: 0.2604 - accuracy: 0.92 - ETA: 2:13 - loss: 0.2587 - accuracy: 0.92 - ETA: 2:12 - loss: 0.2621 - accuracy: 0.92 - ETA: 2:10 - loss: 0.2606 - accuracy: 0.92 - ETA: 2:09 - loss: 0.2588 - accuracy: 0.92 - ETA: 2:08 - loss: 0.2579 - accuracy: 0.92 - ETA: 2:06 - loss: 0.2559 - accuracy: 0.92 - ETA: 2:05 - loss: 0.2584 - accuracy: 0.92 - ETA: 2:04 - loss: 0.2614 - accuracy: 0.92 - ETA: 2:03 - loss: 0.2606 - accuracy: 0.92 - ETA: 2:01 - loss: 0.2600 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2594 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2593 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2569 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2565 - accuracy: 0.92 - ETA: 1:54 - loss: 0.2595 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2587 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2575 - accuracy: 0.92 - ETA: 1:50 - loss: 0.2593 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2595 - accuracy: 0.92 - ETA: 1:47 - loss: 0.2600 - accuracy: 0.92 - ETA: 1:46 - loss: 0.2584 - accuracy: 0.92 - ETA: 1:45 - loss: 0.2589 - accuracy: 0.92 - ETA: 1:43 - loss: 0.2582 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2597 - accuracy: 0.92 - ETA: 1:41 - loss: 0.2619 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2623 - accuracy: 0.92 - ETA: 1:38 - loss: 0.2621 - accuracy: 0.92 - ETA: 1:36 - loss: 0.2616 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2601 - accuracy: 0.92 - ETA: 1:34 - loss: 0.2592 - accuracy: 0.92 - ETA: 1:32 - loss: 0.2585 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2603 - accuracy: 0.92 - ETA: 1:30 - loss: 0.2609 - accuracy: 0.92 - ETA: 1:28 - loss: 0.2609 - accuracy: 0.92 - ETA: 1:27 - loss: 0.2622 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2628 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2612 - accuracy: 0.92 - ETA: 1:23 - loss: 0.2629 - accuracy: 0.92 - ETA: 1:21 - loss: 0.2619 - accuracy: 0.92 - ETA: 1:20 - loss: 0.2617 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2615 - accuracy: 0.92 - ETA: 1:17 - loss: 0.2610 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2600 - accuracy: 0.92 - ETA: 1:15 - loss: 0.2590 - accuracy: 0.92 - ETA: 1:13 - loss: 0.2595 - accuracy: 0.92 - ETA: 1:12 - loss: 0.2598 - accuracy: 0.92 - ETA: 1:10 - loss: 0.2588 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2607 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2606 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2604 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2602 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2604 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2602 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2615 - accuracy: 0.92 - ETA: 59s - loss: 0.2624 - accuracy: 0.9268 - ETA: 58s - loss: 0.2629 - accuracy: 0.926 - ETA: 57s - loss: 0.2628 - accuracy: 0.926 - ETA: 55s - loss: 0.2621 - accuracy: 0.926 - ETA: 54s - loss: 0.2625 - accuracy: 0.926 - ETA: 53s - loss: 0.2631 - accuracy: 0.926 - ETA: 51s - loss: 0.2644 - accuracy: 0.925 - ETA: 50s - loss: 0.2635 - accuracy: 0.926 - ETA: 49s - loss: 0.2631 - accuracy: 0.926 - ETA: 47s - loss: 0.2616 - accuracy: 0.926 - ETA: 46s - loss: 0.2606 - accuracy: 0.926 - ETA: 44s - loss: 0.2617 - accuracy: 0.926 - ETA: 43s - loss: 0.2619 - accuracy: 0.926 - ETA: 42s - loss: 0.2617 - accuracy: 0.926 - ETA: 40s - loss: 0.2626 - accuracy: 0.926 - ETA: 39s - loss: 0.2627 - accuracy: 0.926 - ETA: 38s - loss: 0.2616 - accuracy: 0.926 - ETA: 36s - loss: 0.2612 - accuracy: 0.926 - ETA: 35s - loss: 0.2607 - accuracy: 0.926 - ETA: 34s - loss: 0.2616 - accuracy: 0.926 - ETA: 32s - loss: 0.2619 - accuracy: 0.926 - ETA: 31s - loss: 0.2623 - accuracy: 0.926 - ETA: 29s - loss: 0.2628 - accuracy: 0.925 - ETA: 28s - loss: 0.2634 - accuracy: 0.925 - ETA: 27s - loss: 0.2626 - accuracy: 0.925 - ETA: 25s - loss: 0.2650 - accuracy: 0.925 - ETA: 24s - loss: 0.2662 - accuracy: 0.925 - ETA: 23s - loss: 0.2653 - accuracy: 0.925 - ETA: 21s - loss: 0.2650 - accuracy: 0.925 - ETA: 20s - loss: 0.2654 - accuracy: 0.925 - ETA: 18s - loss: 0.2656 - accuracy: 0.925 - ETA: 17s - loss: 0.2651 - accuracy: 0.925 - ETA: 16s - loss: 0.2643 - accuracy: 0.925 - ETA: 14s - loss: 0.2634 - accuracy: 0.925 - ETA: 13s - loss: 0.2640 - accuracy: 0.925 - ETA: 12s - loss: 0.2645 - accuracy: 0.925 - ETA: 10s - loss: 0.2644 - accuracy: 0.925 - ETA: 9s - loss: 0.2642 - accuracy: 0.925 - ETA: 8s - loss: 0.2653 - accuracy: 0.92 - ETA: 6s - loss: 0.2659 - accuracy: 0.92 - ETA: 5s - loss: 0.2654 - accuracy: 0.92 - ETA: 3s - loss: 0.2650 - accuracy: 0.92 - ETA: 2s - loss: 0.2651 - accuracy: 0.92 - ETA: 1s - loss: 0.2659 - accuracy: 0.92 - 218s 11ms/step - loss: 0.2675 - accuracy: 0.9251 - val_loss: 1.4233 - val_accuracy: 0.7807\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:15 - loss: 0.3808 - accuracy: 0.89 - ETA: 3:15 - loss: 0.3524 - accuracy: 0.91 - ETA: 3:14 - loss: 0.3121 - accuracy: 0.91 - ETA: 3:17 - loss: 0.3042 - accuracy: 0.92 - ETA: 3:18 - loss: 0.2752 - accuracy: 0.92 - ETA: 3:18 - loss: 0.2548 - accuracy: 0.93 - ETA: 3:16 - loss: 0.2596 - accuracy: 0.93 - ETA: 3:13 - loss: 0.2401 - accuracy: 0.93 - ETA: 3:12 - loss: 0.2527 - accuracy: 0.93 - ETA: 3:10 - loss: 0.2481 - accuracy: 0.93 - ETA: 3:09 - loss: 0.2429 - accuracy: 0.93 - ETA: 3:08 - loss: 0.2312 - accuracy: 0.93 - ETA: 3:07 - loss: 0.2326 - accuracy: 0.93 - ETA: 3:06 - loss: 0.2247 - accuracy: 0.93 - ETA: 3:05 - loss: 0.2163 - accuracy: 0.93 - ETA: 3:03 - loss: 0.2077 - accuracy: 0.93 - ETA: 3:02 - loss: 0.2094 - accuracy: 0.93 - ETA: 3:01 - loss: 0.2121 - accuracy: 0.93 - ETA: 3:00 - loss: 0.2144 - accuracy: 0.93 - ETA: 2:58 - loss: 0.2146 - accuracy: 0.93 - ETA: 2:57 - loss: 0.2205 - accuracy: 0.93 - ETA: 2:55 - loss: 0.2334 - accuracy: 0.93 - ETA: 2:54 - loss: 0.2364 - accuracy: 0.93 - ETA: 2:52 - loss: 0.2320 - accuracy: 0.93 - ETA: 2:51 - loss: 0.2300 - accuracy: 0.93 - ETA: 2:49 - loss: 0.2258 - accuracy: 0.93 - ETA: 2:48 - loss: 0.2268 - accuracy: 0.93 - ETA: 2:47 - loss: 0.2261 - accuracy: 0.93 - ETA: 2:46 - loss: 0.2254 - accuracy: 0.93 - ETA: 2:44 - loss: 0.2245 - accuracy: 0.93 - ETA: 2:43 - loss: 0.2247 - accuracy: 0.93 - ETA: 2:41 - loss: 0.2241 - accuracy: 0.93 - ETA: 2:40 - loss: 0.2240 - accuracy: 0.93 - ETA: 2:39 - loss: 0.2242 - accuracy: 0.93 - ETA: 2:37 - loss: 0.2199 - accuracy: 0.93 - ETA: 2:36 - loss: 0.2231 - accuracy: 0.93 - ETA: 2:35 - loss: 0.2259 - accuracy: 0.93 - ETA: 2:33 - loss: 0.2274 - accuracy: 0.93 - ETA: 2:32 - loss: 0.2250 - accuracy: 0.93 - ETA: 2:31 - loss: 0.2239 - accuracy: 0.93 - ETA: 2:29 - loss: 0.2244 - accuracy: 0.93 - ETA: 2:28 - loss: 0.2230 - accuracy: 0.93 - ETA: 2:27 - loss: 0.2225 - accuracy: 0.93 - ETA: 2:26 - loss: 0.2225 - accuracy: 0.93 - ETA: 2:24 - loss: 0.2247 - accuracy: 0.93 - ETA: 2:23 - loss: 0.2243 - accuracy: 0.93 - ETA: 2:21 - loss: 0.2242 - accuracy: 0.93 - ETA: 2:20 - loss: 0.2266 - accuracy: 0.93 - ETA: 2:19 - loss: 0.2295 - accuracy: 0.93 - ETA: 2:17 - loss: 0.2265 - accuracy: 0.93 - ETA: 2:16 - loss: 0.2248 - accuracy: 0.93 - ETA: 2:15 - loss: 0.2244 - accuracy: 0.93 - ETA: 2:13 - loss: 0.2313 - accuracy: 0.93 - ETA: 2:12 - loss: 0.2314 - accuracy: 0.93 - ETA: 2:11 - loss: 0.2316 - accuracy: 0.93 - ETA: 2:09 - loss: 0.2337 - accuracy: 0.93 - ETA: 2:08 - loss: 0.2344 - accuracy: 0.93 - ETA: 2:06 - loss: 0.2351 - accuracy: 0.93 - ETA: 2:05 - loss: 0.2361 - accuracy: 0.93 - ETA: 2:03 - loss: 0.2381 - accuracy: 0.93 - ETA: 2:02 - loss: 0.2395 - accuracy: 0.93 - ETA: 2:01 - loss: 0.2378 - accuracy: 0.93 - ETA: 1:59 - loss: 0.2385 - accuracy: 0.93 - ETA: 1:58 - loss: 0.2390 - accuracy: 0.93 - ETA: 1:57 - loss: 0.2394 - accuracy: 0.93 - ETA: 1:55 - loss: 0.2406 - accuracy: 0.93 - ETA: 1:54 - loss: 0.2410 - accuracy: 0.93 - ETA: 1:53 - loss: 0.2417 - accuracy: 0.93 - ETA: 1:51 - loss: 0.2411 - accuracy: 0.93 - ETA: 1:50 - loss: 0.2402 - accuracy: 0.93 - ETA: 1:48 - loss: 0.2421 - accuracy: 0.93 - ETA: 1:47 - loss: 0.2412 - accuracy: 0.93 - ETA: 1:46 - loss: 0.2405 - accuracy: 0.93 - ETA: 1:44 - loss: 0.2408 - accuracy: 0.93 - ETA: 1:43 - loss: 0.2396 - accuracy: 0.93 - ETA: 1:42 - loss: 0.2396 - accuracy: 0.93 - ETA: 1:40 - loss: 0.2410 - accuracy: 0.93 - ETA: 1:39 - loss: 0.2413 - accuracy: 0.93 - ETA: 1:38 - loss: 0.2413 - accuracy: 0.93 - ETA: 1:36 - loss: 0.2426 - accuracy: 0.93 - ETA: 1:35 - loss: 0.2423 - accuracy: 0.93 - ETA: 1:33 - loss: 0.2403 - accuracy: 0.93 - ETA: 1:32 - loss: 0.2394 - accuracy: 0.93 - ETA: 1:31 - loss: 0.2383 - accuracy: 0.93 - ETA: 1:29 - loss: 0.2383 - accuracy: 0.93 - ETA: 1:28 - loss: 0.2380 - accuracy: 0.93 - ETA: 1:27 - loss: 0.2373 - accuracy: 0.93 - ETA: 1:25 - loss: 0.2388 - accuracy: 0.93 - ETA: 1:24 - loss: 0.2395 - accuracy: 0.93 - ETA: 1:23 - loss: 0.2379 - accuracy: 0.93 - ETA: 1:21 - loss: 0.2375 - accuracy: 0.93 - ETA: 1:20 - loss: 0.2387 - accuracy: 0.93 - ETA: 1:18 - loss: 0.2392 - accuracy: 0.93 - ETA: 1:17 - loss: 0.2432 - accuracy: 0.93 - ETA: 1:16 - loss: 0.2423 - accuracy: 0.93 - ETA: 1:14 - loss: 0.2409 - accuracy: 0.93 - ETA: 1:13 - loss: 0.2418 - accuracy: 0.93 - ETA: 1:12 - loss: 0.2426 - accuracy: 0.93 - ETA: 1:10 - loss: 0.2433 - accuracy: 0.93 - ETA: 1:09 - loss: 0.2445 - accuracy: 0.93 - ETA: 1:08 - loss: 0.2439 - accuracy: 0.93 - ETA: 1:06 - loss: 0.2433 - accuracy: 0.93 - ETA: 1:05 - loss: 0.2430 - accuracy: 0.93 - ETA: 1:03 - loss: 0.2417 - accuracy: 0.93 - ETA: 1:02 - loss: 0.2406 - accuracy: 0.93 - ETA: 1:01 - loss: 0.2404 - accuracy: 0.93 - ETA: 59s - loss: 0.2409 - accuracy: 0.9331 - ETA: 58s - loss: 0.2410 - accuracy: 0.933 - ETA: 57s - loss: 0.2412 - accuracy: 0.933 - ETA: 55s - loss: 0.2399 - accuracy: 0.933 - ETA: 54s - loss: 0.2394 - accuracy: 0.933 - ETA: 53s - loss: 0.2394 - accuracy: 0.933 - ETA: 51s - loss: 0.2381 - accuracy: 0.933 - ETA: 50s - loss: 0.2386 - accuracy: 0.933 - ETA: 49s - loss: 0.2383 - accuracy: 0.933 - ETA: 47s - loss: 0.2395 - accuracy: 0.933 - ETA: 46s - loss: 0.2384 - accuracy: 0.934 - ETA: 44s - loss: 0.2393 - accuracy: 0.933 - ETA: 43s - loss: 0.2394 - accuracy: 0.934 - ETA: 42s - loss: 0.2414 - accuracy: 0.933 - ETA: 40s - loss: 0.2415 - accuracy: 0.933 - ETA: 39s - loss: 0.2423 - accuracy: 0.933 - ETA: 38s - loss: 0.2422 - accuracy: 0.933 - ETA: 36s - loss: 0.2426 - accuracy: 0.933 - ETA: 35s - loss: 0.2430 - accuracy: 0.933 - ETA: 34s - loss: 0.2442 - accuracy: 0.933 - ETA: 32s - loss: 0.2443 - accuracy: 0.933 - ETA: 31s - loss: 0.2437 - accuracy: 0.933 - ETA: 29s - loss: 0.2436 - accuracy: 0.933 - ETA: 28s - loss: 0.2446 - accuracy: 0.933 - ETA: 27s - loss: 0.2474 - accuracy: 0.932 - ETA: 25s - loss: 0.2482 - accuracy: 0.932 - ETA: 24s - loss: 0.2472 - accuracy: 0.932 - ETA: 23s - loss: 0.2488 - accuracy: 0.932 - ETA: 21s - loss: 0.2481 - accuracy: 0.932 - ETA: 20s - loss: 0.2486 - accuracy: 0.932 - ETA: 18s - loss: 0.2489 - accuracy: 0.932 - ETA: 17s - loss: 0.2483 - accuracy: 0.932 - ETA: 16s - loss: 0.2488 - accuracy: 0.932 - ETA: 14s - loss: 0.2490 - accuracy: 0.932 - ETA: 13s - loss: 0.2501 - accuracy: 0.931 - ETA: 12s - loss: 0.2502 - accuracy: 0.931 - ETA: 10s - loss: 0.2508 - accuracy: 0.931 - ETA: 9s - loss: 0.2516 - accuracy: 0.931 - ETA: 8s - loss: 0.2507 - accuracy: 0.93 - ETA: 6s - loss: 0.2509 - accuracy: 0.93 - ETA: 5s - loss: 0.2509 - accuracy: 0.93 - ETA: 3s - loss: 0.2517 - accuracy: 0.93 - ETA: 2s - loss: 0.2515 - accuracy: 0.93 - ETA: 1s - loss: 0.2520 - accuracy: 0.93 - 218s 11ms/step - loss: 0.2522 - accuracy: 0.9315 - val_loss: 1.5142 - val_accuracy: 0.7780\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:35 - loss: 0.1901 - accuracy: 0.96 - ETA: 3:26 - loss: 0.2420 - accuracy: 0.94 - ETA: 3:21 - loss: 0.2215 - accuracy: 0.94 - ETA: 3:21 - loss: 0.2544 - accuracy: 0.93 - ETA: 3:19 - loss: 0.2158 - accuracy: 0.94 - ETA: 3:17 - loss: 0.2325 - accuracy: 0.94 - ETA: 3:16 - loss: 0.2355 - accuracy: 0.93 - ETA: 3:15 - loss: 0.2399 - accuracy: 0.93 - ETA: 3:14 - loss: 0.2516 - accuracy: 0.93 - ETA: 3:13 - loss: 0.2403 - accuracy: 0.93 - ETA: 3:12 - loss: 0.2336 - accuracy: 0.94 - ETA: 3:11 - loss: 0.2213 - accuracy: 0.94 - ETA: 3:09 - loss: 0.2156 - accuracy: 0.94 - ETA: 3:07 - loss: 0.2087 - accuracy: 0.94 - ETA: 3:06 - loss: 0.2153 - accuracy: 0.94 - ETA: 3:04 - loss: 0.2181 - accuracy: 0.94 - ETA: 3:03 - loss: 0.2206 - accuracy: 0.94 - ETA: 3:01 - loss: 0.2202 - accuracy: 0.94 - ETA: 3:00 - loss: 0.2110 - accuracy: 0.94 - ETA: 2:58 - loss: 0.2117 - accuracy: 0.94 - ETA: 2:57 - loss: 0.2148 - accuracy: 0.94 - ETA: 2:56 - loss: 0.2173 - accuracy: 0.94 - ETA: 2:55 - loss: 0.2202 - accuracy: 0.93 - ETA: 2:53 - loss: 0.2131 - accuracy: 0.94 - ETA: 2:51 - loss: 0.2142 - accuracy: 0.94 - ETA: 2:50 - loss: 0.2247 - accuracy: 0.93 - ETA: 2:48 - loss: 0.2212 - accuracy: 0.93 - ETA: 2:47 - loss: 0.2238 - accuracy: 0.93 - ETA: 2:45 - loss: 0.2334 - accuracy: 0.93 - ETA: 2:44 - loss: 0.2301 - accuracy: 0.93 - ETA: 2:43 - loss: 0.2337 - accuracy: 0.93 - ETA: 2:41 - loss: 0.2350 - accuracy: 0.93 - ETA: 2:40 - loss: 0.2376 - accuracy: 0.93 - ETA: 2:39 - loss: 0.2396 - accuracy: 0.93 - ETA: 2:37 - loss: 0.2406 - accuracy: 0.93 - ETA: 2:36 - loss: 0.2386 - accuracy: 0.93 - ETA: 2:34 - loss: 0.2385 - accuracy: 0.93 - ETA: 2:33 - loss: 0.2378 - accuracy: 0.93 - ETA: 2:32 - loss: 0.2383 - accuracy: 0.93 - ETA: 2:30 - loss: 0.2374 - accuracy: 0.93 - ETA: 2:29 - loss: 0.2354 - accuracy: 0.93 - ETA: 2:28 - loss: 0.2347 - accuracy: 0.93 - ETA: 2:26 - loss: 0.2332 - accuracy: 0.93 - ETA: 2:25 - loss: 0.2332 - accuracy: 0.93 - ETA: 2:23 - loss: 0.2333 - accuracy: 0.93 - ETA: 2:22 - loss: 0.2358 - accuracy: 0.93 - ETA: 2:21 - loss: 0.2322 - accuracy: 0.93 - ETA: 2:20 - loss: 0.2308 - accuracy: 0.93 - ETA: 2:19 - loss: 0.2305 - accuracy: 0.93 - ETA: 2:17 - loss: 0.2307 - accuracy: 0.93 - ETA: 2:16 - loss: 0.2290 - accuracy: 0.93 - ETA: 2:15 - loss: 0.2312 - accuracy: 0.93 - ETA: 2:14 - loss: 0.2312 - accuracy: 0.93 - ETA: 2:12 - loss: 0.2307 - accuracy: 0.93 - ETA: 2:11 - loss: 0.2306 - accuracy: 0.93 - ETA: 2:10 - loss: 0.2310 - accuracy: 0.93 - ETA: 2:09 - loss: 0.2327 - accuracy: 0.93 - ETA: 2:07 - loss: 0.2352 - accuracy: 0.93 - ETA: 2:06 - loss: 0.2333 - accuracy: 0.93 - ETA: 2:05 - loss: 0.2318 - accuracy: 0.93 - ETA: 2:03 - loss: 0.2307 - accuracy: 0.93 - ETA: 2:02 - loss: 0.2323 - accuracy: 0.93 - ETA: 2:00 - loss: 0.2331 - accuracy: 0.93 - ETA: 1:59 - loss: 0.2333 - accuracy: 0.93 - ETA: 1:58 - loss: 0.2323 - accuracy: 0.93 - ETA: 1:56 - loss: 0.2324 - accuracy: 0.93 - ETA: 1:55 - loss: 0.2318 - accuracy: 0.93 - ETA: 1:54 - loss: 0.2317 - accuracy: 0.93 - ETA: 1:52 - loss: 0.2315 - accuracy: 0.93 - ETA: 1:51 - loss: 0.2308 - accuracy: 0.93 - ETA: 1:50 - loss: 0.2305 - accuracy: 0.93 - ETA: 1:48 - loss: 0.2318 - accuracy: 0.93 - ETA: 1:47 - loss: 0.2359 - accuracy: 0.93 - ETA: 1:45 - loss: 0.2352 - accuracy: 0.93 - ETA: 1:44 - loss: 0.2351 - accuracy: 0.93 - ETA: 1:42 - loss: 0.2347 - accuracy: 0.93 - ETA: 1:41 - loss: 0.2341 - accuracy: 0.93 - ETA: 1:40 - loss: 0.2337 - accuracy: 0.93 - ETA: 1:38 - loss: 0.2332 - accuracy: 0.93 - ETA: 1:37 - loss: 0.2353 - accuracy: 0.93 - ETA: 1:36 - loss: 0.2347 - accuracy: 0.93 - ETA: 1:34 - loss: 0.2331 - accuracy: 0.93 - ETA: 1:33 - loss: 0.2339 - accuracy: 0.93 - ETA: 1:31 - loss: 0.2327 - accuracy: 0.93 - ETA: 1:30 - loss: 0.2350 - accuracy: 0.93 - ETA: 1:29 - loss: 0.2346 - accuracy: 0.93 - ETA: 1:27 - loss: 0.2353 - accuracy: 0.93 - ETA: 1:26 - loss: 0.2348 - accuracy: 0.93 - ETA: 1:24 - loss: 0.2340 - accuracy: 0.93 - ETA: 1:23 - loss: 0.2344 - accuracy: 0.93 - ETA: 1:22 - loss: 0.2338 - accuracy: 0.93 - ETA: 1:20 - loss: 0.2323 - accuracy: 0.93 - ETA: 1:19 - loss: 0.2319 - accuracy: 0.93 - ETA: 1:18 - loss: 0.2317 - accuracy: 0.93 - ETA: 1:16 - loss: 0.2316 - accuracy: 0.93 - ETA: 1:15 - loss: 0.2333 - accuracy: 0.93 - ETA: 1:13 - loss: 0.2332 - accuracy: 0.93 - ETA: 1:12 - loss: 0.2326 - accuracy: 0.93 - ETA: 1:11 - loss: 0.2321 - accuracy: 0.93 - ETA: 1:09 - loss: 0.2330 - accuracy: 0.93 - ETA: 1:08 - loss: 0.2324 - accuracy: 0.93 - ETA: 1:07 - loss: 0.2332 - accuracy: 0.93 - ETA: 1:05 - loss: 0.2319 - accuracy: 0.93 - ETA: 1:04 - loss: 0.2321 - accuracy: 0.93 - ETA: 1:02 - loss: 0.2306 - accuracy: 0.93 - ETA: 1:01 - loss: 0.2304 - accuracy: 0.93 - ETA: 1:00 - loss: 0.2306 - accuracy: 0.93 - ETA: 58s - loss: 0.2309 - accuracy: 0.9361 - ETA: 57s - loss: 0.2318 - accuracy: 0.935 - ETA: 56s - loss: 0.2313 - accuracy: 0.935 - ETA: 54s - loss: 0.2310 - accuracy: 0.935 - ETA: 53s - loss: 0.2312 - accuracy: 0.935 - ETA: 51s - loss: 0.2317 - accuracy: 0.935 - ETA: 50s - loss: 0.2327 - accuracy: 0.935 - ETA: 49s - loss: 0.2330 - accuracy: 0.934 - ETA: 47s - loss: 0.2318 - accuracy: 0.935 - ETA: 46s - loss: 0.2326 - accuracy: 0.934 - ETA: 45s - loss: 0.2326 - accuracy: 0.935 - ETA: 43s - loss: 0.2343 - accuracy: 0.934 - ETA: 42s - loss: 0.2348 - accuracy: 0.934 - ETA: 40s - loss: 0.2338 - accuracy: 0.935 - ETA: 39s - loss: 0.2334 - accuracy: 0.935 - ETA: 38s - loss: 0.2345 - accuracy: 0.935 - ETA: 36s - loss: 0.2333 - accuracy: 0.935 - ETA: 35s - loss: 0.2324 - accuracy: 0.935 - ETA: 34s - loss: 0.2323 - accuracy: 0.935 - ETA: 32s - loss: 0.2312 - accuracy: 0.936 - ETA: 31s - loss: 0.2319 - accuracy: 0.935 - ETA: 29s - loss: 0.2316 - accuracy: 0.935 - ETA: 28s - loss: 0.2313 - accuracy: 0.935 - ETA: 27s - loss: 0.2306 - accuracy: 0.936 - ETA: 25s - loss: 0.2305 - accuracy: 0.936 - ETA: 24s - loss: 0.2312 - accuracy: 0.936 - ETA: 23s - loss: 0.2308 - accuracy: 0.936 - ETA: 21s - loss: 0.2303 - accuracy: 0.936 - ETA: 20s - loss: 0.2292 - accuracy: 0.936 - ETA: 18s - loss: 0.2287 - accuracy: 0.936 - ETA: 17s - loss: 0.2288 - accuracy: 0.936 - ETA: 16s - loss: 0.2288 - accuracy: 0.936 - ETA: 14s - loss: 0.2291 - accuracy: 0.936 - ETA: 13s - loss: 0.2291 - accuracy: 0.936 - ETA: 12s - loss: 0.2285 - accuracy: 0.936 - ETA: 10s - loss: 0.2285 - accuracy: 0.936 - ETA: 9s - loss: 0.2306 - accuracy: 0.936 - ETA: 8s - loss: 0.2307 - accuracy: 0.93 - ETA: 6s - loss: 0.2308 - accuracy: 0.93 - ETA: 5s - loss: 0.2313 - accuracy: 0.93 - ETA: 3s - loss: 0.2319 - accuracy: 0.93 - ETA: 2s - loss: 0.2318 - accuracy: 0.93 - ETA: 1s - loss: 0.2315 - accuracy: 0.93 - 218s 11ms/step - loss: 0.2319 - accuracy: 0.9361 - val_loss: 1.4834 - val_accuracy: 0.7855\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:29 - loss: 0.2220 - accuracy: 0.93 - ETA: 3:29 - loss: 0.2524 - accuracy: 0.92 - ETA: 3:30 - loss: 0.2338 - accuracy: 0.93 - ETA: 3:26 - loss: 0.2519 - accuracy: 0.92 - ETA: 3:21 - loss: 0.2184 - accuracy: 0.93 - ETA: 3:20 - loss: 0.1980 - accuracy: 0.94 - ETA: 3:18 - loss: 0.1895 - accuracy: 0.94 - ETA: 3:16 - loss: 0.1826 - accuracy: 0.94 - ETA: 3:15 - loss: 0.1858 - accuracy: 0.94 - ETA: 3:13 - loss: 0.1817 - accuracy: 0.94 - ETA: 3:12 - loss: 0.1831 - accuracy: 0.94 - ETA: 3:09 - loss: 0.1793 - accuracy: 0.94 - ETA: 3:08 - loss: 0.1787 - accuracy: 0.94 - ETA: 3:08 - loss: 0.1877 - accuracy: 0.94 - ETA: 3:07 - loss: 0.1844 - accuracy: 0.94 - ETA: 3:05 - loss: 0.1818 - accuracy: 0.94 - ETA: 3:03 - loss: 0.1915 - accuracy: 0.94 - ETA: 3:02 - loss: 0.1922 - accuracy: 0.94 - ETA: 3:00 - loss: 0.1925 - accuracy: 0.94 - ETA: 2:59 - loss: 0.1865 - accuracy: 0.94 - ETA: 2:57 - loss: 0.1938 - accuracy: 0.94 - ETA: 2:56 - loss: 0.1959 - accuracy: 0.94 - ETA: 2:54 - loss: 0.2000 - accuracy: 0.94 - ETA: 2:53 - loss: 0.1996 - accuracy: 0.94 - ETA: 2:52 - loss: 0.2012 - accuracy: 0.94 - ETA: 2:51 - loss: 0.2018 - accuracy: 0.94 - ETA: 2:49 - loss: 0.2015 - accuracy: 0.94 - ETA: 2:48 - loss: 0.2036 - accuracy: 0.94 - ETA: 2:46 - loss: 0.2090 - accuracy: 0.94 - ETA: 2:45 - loss: 0.2084 - accuracy: 0.94 - ETA: 2:44 - loss: 0.2068 - accuracy: 0.94 - ETA: 2:42 - loss: 0.2095 - accuracy: 0.94 - ETA: 2:41 - loss: 0.2127 - accuracy: 0.93 - ETA: 2:39 - loss: 0.2145 - accuracy: 0.93 - ETA: 2:38 - loss: 0.2127 - accuracy: 0.93 - ETA: 2:37 - loss: 0.2144 - accuracy: 0.93 - ETA: 2:35 - loss: 0.2181 - accuracy: 0.93 - ETA: 2:34 - loss: 0.2181 - accuracy: 0.93 - ETA: 2:33 - loss: 0.2192 - accuracy: 0.93 - ETA: 2:31 - loss: 0.2173 - accuracy: 0.93 - ETA: 2:30 - loss: 0.2160 - accuracy: 0.93 - ETA: 2:29 - loss: 0.2175 - accuracy: 0.93 - ETA: 2:27 - loss: 0.2153 - accuracy: 0.93 - ETA: 2:26 - loss: 0.2137 - accuracy: 0.93 - ETA: 2:24 - loss: 0.2130 - accuracy: 0.93 - ETA: 2:23 - loss: 0.2131 - accuracy: 0.93 - ETA: 2:22 - loss: 0.2125 - accuracy: 0.93 - ETA: 2:20 - loss: 0.2121 - accuracy: 0.93 - ETA: 2:19 - loss: 0.2125 - accuracy: 0.93 - ETA: 2:18 - loss: 0.2127 - accuracy: 0.93 - ETA: 2:16 - loss: 0.2180 - accuracy: 0.93 - ETA: 2:15 - loss: 0.2178 - accuracy: 0.93 - ETA: 2:13 - loss: 0.2204 - accuracy: 0.93 - ETA: 2:12 - loss: 0.2197 - accuracy: 0.93 - ETA: 2:11 - loss: 0.2228 - accuracy: 0.93 - ETA: 2:09 - loss: 0.2222 - accuracy: 0.93 - ETA: 2:08 - loss: 0.2227 - accuracy: 0.93 - ETA: 2:07 - loss: 0.2236 - accuracy: 0.93 - ETA: 2:05 - loss: 0.2226 - accuracy: 0.93 - ETA: 2:04 - loss: 0.2206 - accuracy: 0.93 - ETA: 2:03 - loss: 0.2235 - accuracy: 0.93 - ETA: 2:01 - loss: 0.2219 - accuracy: 0.93 - ETA: 2:00 - loss: 0.2211 - accuracy: 0.93 - ETA: 1:58 - loss: 0.2198 - accuracy: 0.93 - ETA: 1:57 - loss: 0.2224 - accuracy: 0.93 - ETA: 1:56 - loss: 0.2234 - accuracy: 0.93 - ETA: 1:54 - loss: 0.2232 - accuracy: 0.93 - ETA: 1:53 - loss: 0.2221 - accuracy: 0.93 - ETA: 1:52 - loss: 0.2233 - accuracy: 0.93 - ETA: 1:50 - loss: 0.2225 - accuracy: 0.93 - ETA: 1:49 - loss: 0.2214 - accuracy: 0.93 - ETA: 1:47 - loss: 0.2209 - accuracy: 0.93 - ETA: 1:46 - loss: 0.2207 - accuracy: 0.93 - ETA: 1:45 - loss: 0.2240 - accuracy: 0.93 - ETA: 1:43 - loss: 0.2231 - accuracy: 0.93 - ETA: 1:42 - loss: 0.2235 - accuracy: 0.93 - ETA: 1:40 - loss: 0.2235 - accuracy: 0.93 - ETA: 1:39 - loss: 0.2221 - accuracy: 0.93 - ETA: 1:38 - loss: 0.2229 - accuracy: 0.93 - ETA: 1:36 - loss: 0.2226 - accuracy: 0.93 - ETA: 1:35 - loss: 0.2221 - accuracy: 0.93 - ETA: 1:34 - loss: 0.2209 - accuracy: 0.93 - ETA: 1:32 - loss: 0.2213 - accuracy: 0.93 - ETA: 1:31 - loss: 0.2218 - accuracy: 0.93 - ETA: 1:30 - loss: 0.2233 - accuracy: 0.93 - ETA: 1:28 - loss: 0.2233 - accuracy: 0.93 - ETA: 1:27 - loss: 0.2245 - accuracy: 0.93 - ETA: 1:25 - loss: 0.2236 - accuracy: 0.93 - ETA: 1:24 - loss: 0.2236 - accuracy: 0.93 - ETA: 1:23 - loss: 0.2227 - accuracy: 0.93 - ETA: 1:21 - loss: 0.2231 - accuracy: 0.93 - ETA: 1:20 - loss: 0.2235 - accuracy: 0.93 - ETA: 1:19 - loss: 0.2228 - accuracy: 0.93 - ETA: 1:17 - loss: 0.2225 - accuracy: 0.93 - ETA: 1:16 - loss: 0.2221 - accuracy: 0.93 - ETA: 1:15 - loss: 0.2220 - accuracy: 0.93 - ETA: 1:13 - loss: 0.2210 - accuracy: 0.93 - ETA: 1:12 - loss: 0.2205 - accuracy: 0.93 - ETA: 1:10 - loss: 0.2201 - accuracy: 0.93 - ETA: 1:09 - loss: 0.2211 - accuracy: 0.93 - ETA: 1:08 - loss: 0.2194 - accuracy: 0.93 - ETA: 1:06 - loss: 0.2180 - accuracy: 0.93 - ETA: 1:05 - loss: 0.2178 - accuracy: 0.93 - ETA: 1:04 - loss: 0.2175 - accuracy: 0.93 - ETA: 1:02 - loss: 0.2172 - accuracy: 0.93 - ETA: 1:01 - loss: 0.2161 - accuracy: 0.93 - ETA: 59s - loss: 0.2155 - accuracy: 0.9391 - ETA: 58s - loss: 0.2160 - accuracy: 0.939 - ETA: 57s - loss: 0.2144 - accuracy: 0.939 - ETA: 55s - loss: 0.2163 - accuracy: 0.939 - ETA: 54s - loss: 0.2153 - accuracy: 0.939 - ETA: 53s - loss: 0.2154 - accuracy: 0.939 - ETA: 51s - loss: 0.2162 - accuracy: 0.939 - ETA: 50s - loss: 0.2170 - accuracy: 0.939 - ETA: 49s - loss: 0.2171 - accuracy: 0.939 - ETA: 47s - loss: 0.2169 - accuracy: 0.939 - ETA: 46s - loss: 0.2177 - accuracy: 0.939 - ETA: 44s - loss: 0.2171 - accuracy: 0.939 - ETA: 43s - loss: 0.2175 - accuracy: 0.939 - ETA: 42s - loss: 0.2173 - accuracy: 0.939 - ETA: 40s - loss: 0.2171 - accuracy: 0.939 - ETA: 39s - loss: 0.2177 - accuracy: 0.939 - ETA: 38s - loss: 0.2184 - accuracy: 0.939 - ETA: 36s - loss: 0.2182 - accuracy: 0.939 - ETA: 35s - loss: 0.2174 - accuracy: 0.939 - ETA: 33s - loss: 0.2180 - accuracy: 0.939 - ETA: 32s - loss: 0.2188 - accuracy: 0.939 - ETA: 31s - loss: 0.2185 - accuracy: 0.939 - ETA: 29s - loss: 0.2176 - accuracy: 0.939 - ETA: 28s - loss: 0.2184 - accuracy: 0.939 - ETA: 27s - loss: 0.2176 - accuracy: 0.939 - ETA: 25s - loss: 0.2172 - accuracy: 0.939 - ETA: 24s - loss: 0.2166 - accuracy: 0.939 - ETA: 23s - loss: 0.2162 - accuracy: 0.939 - ETA: 21s - loss: 0.2166 - accuracy: 0.939 - ETA: 20s - loss: 0.2160 - accuracy: 0.939 - ETA: 18s - loss: 0.2161 - accuracy: 0.939 - ETA: 17s - loss: 0.2160 - accuracy: 0.939 - ETA: 16s - loss: 0.2162 - accuracy: 0.939 - ETA: 14s - loss: 0.2162 - accuracy: 0.939 - ETA: 13s - loss: 0.2164 - accuracy: 0.939 - ETA: 12s - loss: 0.2162 - accuracy: 0.939 - ETA: 10s - loss: 0.2176 - accuracy: 0.939 - ETA: 9s - loss: 0.2172 - accuracy: 0.939 - ETA: 8s - loss: 0.2185 - accuracy: 0.93 - ETA: 6s - loss: 0.2194 - accuracy: 0.93 - ETA: 5s - loss: 0.2195 - accuracy: 0.93 - ETA: 3s - loss: 0.2195 - accuracy: 0.93 - ETA: 2s - loss: 0.2194 - accuracy: 0.93 - ETA: 1s - loss: 0.2193 - accuracy: 0.93 - 218s 11ms/step - loss: 0.2199 - accuracy: 0.9383 - val_loss: 1.5265 - val_accuracy: 0.7915\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:24 - loss: 0.1408 - accuracy: 0.96 - ETA: 3:20 - loss: 0.1707 - accuracy: 0.95 - ETA: 3:20 - loss: 0.1535 - accuracy: 0.95 - ETA: 3:17 - loss: 0.1915 - accuracy: 0.94 - ETA: 3:16 - loss: 0.1696 - accuracy: 0.94 - ETA: 3:16 - loss: 0.1518 - accuracy: 0.95 - ETA: 3:15 - loss: 0.1436 - accuracy: 0.95 - ETA: 3:14 - loss: 0.1492 - accuracy: 0.95 - ETA: 3:13 - loss: 0.1435 - accuracy: 0.95 - ETA: 3:12 - loss: 0.1625 - accuracy: 0.95 - ETA: 3:10 - loss: 0.1700 - accuracy: 0.95 - ETA: 3:09 - loss: 0.1690 - accuracy: 0.95 - ETA: 3:07 - loss: 0.1758 - accuracy: 0.94 - ETA: 3:06 - loss: 0.1757 - accuracy: 0.94 - ETA: 3:05 - loss: 0.1744 - accuracy: 0.94 - ETA: 3:03 - loss: 0.1753 - accuracy: 0.94 - ETA: 3:01 - loss: 0.1723 - accuracy: 0.94 - ETA: 3:00 - loss: 0.1689 - accuracy: 0.94 - ETA: 3:00 - loss: 0.1750 - accuracy: 0.94 - ETA: 2:58 - loss: 0.1746 - accuracy: 0.94 - ETA: 2:57 - loss: 0.1780 - accuracy: 0.94 - ETA: 2:56 - loss: 0.1785 - accuracy: 0.94 - ETA: 2:55 - loss: 0.1868 - accuracy: 0.94 - ETA: 2:53 - loss: 0.1883 - accuracy: 0.94 - ETA: 2:51 - loss: 0.1875 - accuracy: 0.94 - ETA: 2:50 - loss: 0.1849 - accuracy: 0.94 - ETA: 2:48 - loss: 0.1884 - accuracy: 0.94 - ETA: 2:47 - loss: 0.1885 - accuracy: 0.94 - ETA: 2:46 - loss: 0.1894 - accuracy: 0.94 - ETA: 2:44 - loss: 0.1897 - accuracy: 0.94 - ETA: 2:43 - loss: 0.1883 - accuracy: 0.94 - ETA: 2:42 - loss: 0.1871 - accuracy: 0.94 - ETA: 2:40 - loss: 0.1848 - accuracy: 0.94 - ETA: 2:39 - loss: 0.1824 - accuracy: 0.94 - ETA: 2:37 - loss: 0.1850 - accuracy: 0.94 - ETA: 2:36 - loss: 0.1848 - accuracy: 0.94 - ETA: 2:35 - loss: 0.1854 - accuracy: 0.94 - ETA: 2:33 - loss: 0.1878 - accuracy: 0.94 - ETA: 2:32 - loss: 0.1879 - accuracy: 0.94 - ETA: 2:31 - loss: 0.1935 - accuracy: 0.94 - ETA: 2:29 - loss: 0.1978 - accuracy: 0.94 - ETA: 2:28 - loss: 0.1955 - accuracy: 0.94 - ETA: 2:27 - loss: 0.1960 - accuracy: 0.94 - ETA: 2:26 - loss: 0.1962 - accuracy: 0.94 - ETA: 2:24 - loss: 0.1978 - accuracy: 0.94 - ETA: 2:23 - loss: 0.1969 - accuracy: 0.94 - ETA: 2:22 - loss: 0.1987 - accuracy: 0.94 - ETA: 2:20 - loss: 0.1997 - accuracy: 0.94 - ETA: 2:19 - loss: 0.2005 - accuracy: 0.94 - ETA: 2:17 - loss: 0.2028 - accuracy: 0.94 - ETA: 2:16 - loss: 0.2033 - accuracy: 0.94 - ETA: 2:15 - loss: 0.2052 - accuracy: 0.94 - ETA: 2:13 - loss: 0.2042 - accuracy: 0.94 - ETA: 2:12 - loss: 0.2071 - accuracy: 0.94 - ETA: 2:11 - loss: 0.2077 - accuracy: 0.94 - ETA: 2:09 - loss: 0.2079 - accuracy: 0.94 - ETA: 2:08 - loss: 0.2080 - accuracy: 0.94 - ETA: 2:06 - loss: 0.2111 - accuracy: 0.94 - ETA: 2:05 - loss: 0.2106 - accuracy: 0.94 - ETA: 2:03 - loss: 0.2133 - accuracy: 0.94 - ETA: 2:02 - loss: 0.2147 - accuracy: 0.94 - ETA: 2:01 - loss: 0.2139 - accuracy: 0.94 - ETA: 1:59 - loss: 0.2129 - accuracy: 0.94 - ETA: 1:58 - loss: 0.2152 - accuracy: 0.94 - ETA: 1:57 - loss: 0.2157 - accuracy: 0.94 - ETA: 1:55 - loss: 0.2147 - accuracy: 0.94 - ETA: 1:54 - loss: 0.2150 - accuracy: 0.94 - ETA: 1:53 - loss: 0.2152 - accuracy: 0.94 - ETA: 1:51 - loss: 0.2128 - accuracy: 0.94 - ETA: 1:50 - loss: 0.2117 - accuracy: 0.94 - ETA: 1:48 - loss: 0.2114 - accuracy: 0.94 - ETA: 1:47 - loss: 0.2102 - accuracy: 0.94 - ETA: 1:46 - loss: 0.2117 - accuracy: 0.94 - ETA: 1:44 - loss: 0.2110 - accuracy: 0.94 - ETA: 1:43 - loss: 0.2106 - accuracy: 0.94 - ETA: 1:42 - loss: 0.2133 - accuracy: 0.94 - ETA: 1:40 - loss: 0.2113 - accuracy: 0.94 - ETA: 1:39 - loss: 0.2123 - accuracy: 0.94 - ETA: 1:38 - loss: 0.2124 - accuracy: 0.94 - ETA: 1:36 - loss: 0.2114 - accuracy: 0.94 - ETA: 1:35 - loss: 0.2123 - accuracy: 0.94 - ETA: 1:34 - loss: 0.2124 - accuracy: 0.94 - ETA: 1:32 - loss: 0.2119 - accuracy: 0.94 - ETA: 1:31 - loss: 0.2126 - accuracy: 0.94 - ETA: 1:30 - loss: 0.2122 - accuracy: 0.94 - ETA: 1:28 - loss: 0.2121 - accuracy: 0.94 - ETA: 1:27 - loss: 0.2126 - accuracy: 0.94 - ETA: 1:25 - loss: 0.2117 - accuracy: 0.94 - ETA: 1:24 - loss: 0.2105 - accuracy: 0.94 - ETA: 1:23 - loss: 0.2093 - accuracy: 0.94 - ETA: 1:21 - loss: 0.2095 - accuracy: 0.94 - ETA: 1:20 - loss: 0.2112 - accuracy: 0.94 - ETA: 1:19 - loss: 0.2109 - accuracy: 0.94 - ETA: 1:17 - loss: 0.2114 - accuracy: 0.94 - ETA: 1:16 - loss: 0.2126 - accuracy: 0.94 - ETA: 1:15 - loss: 0.2134 - accuracy: 0.94 - ETA: 1:13 - loss: 0.2143 - accuracy: 0.94 - ETA: 1:12 - loss: 0.2173 - accuracy: 0.94 - ETA: 1:10 - loss: 0.2167 - accuracy: 0.94 - ETA: 1:09 - loss: 0.2169 - accuracy: 0.94 - ETA: 1:08 - loss: 0.2163 - accuracy: 0.94 - ETA: 1:06 - loss: 0.2151 - accuracy: 0.94 - ETA: 1:05 - loss: 0.2170 - accuracy: 0.94 - ETA: 1:04 - loss: 0.2178 - accuracy: 0.94 - ETA: 1:02 - loss: 0.2189 - accuracy: 0.93 - ETA: 1:01 - loss: 0.2185 - accuracy: 0.94 - ETA: 1:00 - loss: 0.2182 - accuracy: 0.94 - ETA: 58s - loss: 0.2170 - accuracy: 0.9404 - ETA: 57s - loss: 0.2177 - accuracy: 0.940 - ETA: 55s - loss: 0.2191 - accuracy: 0.940 - ETA: 54s - loss: 0.2200 - accuracy: 0.940 - ETA: 53s - loss: 0.2195 - accuracy: 0.940 - ETA: 51s - loss: 0.2184 - accuracy: 0.940 - ETA: 50s - loss: 0.2182 - accuracy: 0.940 - ETA: 49s - loss: 0.2190 - accuracy: 0.940 - ETA: 47s - loss: 0.2184 - accuracy: 0.940 - ETA: 46s - loss: 0.2190 - accuracy: 0.940 - ETA: 44s - loss: 0.2195 - accuracy: 0.940 - ETA: 43s - loss: 0.2208 - accuracy: 0.940 - ETA: 42s - loss: 0.2202 - accuracy: 0.940 - ETA: 40s - loss: 0.2201 - accuracy: 0.940 - ETA: 39s - loss: 0.2196 - accuracy: 0.940 - ETA: 38s - loss: 0.2195 - accuracy: 0.940 - ETA: 36s - loss: 0.2187 - accuracy: 0.940 - ETA: 35s - loss: 0.2184 - accuracy: 0.940 - ETA: 34s - loss: 0.2180 - accuracy: 0.940 - ETA: 32s - loss: 0.2166 - accuracy: 0.940 - ETA: 31s - loss: 0.2180 - accuracy: 0.940 - ETA: 29s - loss: 0.2176 - accuracy: 0.940 - ETA: 28s - loss: 0.2186 - accuracy: 0.940 - ETA: 27s - loss: 0.2195 - accuracy: 0.940 - ETA: 25s - loss: 0.2190 - accuracy: 0.940 - ETA: 24s - loss: 0.2186 - accuracy: 0.940 - ETA: 23s - loss: 0.2181 - accuracy: 0.940 - ETA: 21s - loss: 0.2171 - accuracy: 0.940 - ETA: 20s - loss: 0.2180 - accuracy: 0.940 - ETA: 18s - loss: 0.2179 - accuracy: 0.940 - ETA: 17s - loss: 0.2178 - accuracy: 0.940 - ETA: 16s - loss: 0.2172 - accuracy: 0.940 - ETA: 14s - loss: 0.2179 - accuracy: 0.940 - ETA: 13s - loss: 0.2173 - accuracy: 0.940 - ETA: 12s - loss: 0.2166 - accuracy: 0.940 - ETA: 10s - loss: 0.2171 - accuracy: 0.940 - ETA: 9s - loss: 0.2163 - accuracy: 0.940 - ETA: 8s - loss: 0.2181 - accuracy: 0.94 - ETA: 6s - loss: 0.2170 - accuracy: 0.94 - ETA: 5s - loss: 0.2174 - accuracy: 0.94 - ETA: 3s - loss: 0.2167 - accuracy: 0.94 - ETA: 2s - loss: 0.2171 - accuracy: 0.94 - ETA: 1s - loss: 0.2161 - accuracy: 0.94 - 218s 11ms/step - loss: 0.2164 - accuracy: 0.9407 - val_loss: 1.4847 - val_accuracy: 0.7906\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:28 - loss: 0.3928 - accuracy: 0.92 - ETA: 3:22 - loss: 0.4049 - accuracy: 0.91 - ETA: 3:22 - loss: 0.3106 - accuracy: 0.93 - ETA: 3:19 - loss: 0.2676 - accuracy: 0.93 - ETA: 3:16 - loss: 0.2535 - accuracy: 0.94 - ETA: 3:16 - loss: 0.2583 - accuracy: 0.94 - ETA: 3:15 - loss: 0.2467 - accuracy: 0.94 - ETA: 3:13 - loss: 0.2429 - accuracy: 0.94 - ETA: 3:12 - loss: 0.2241 - accuracy: 0.94 - ETA: 3:11 - loss: 0.2085 - accuracy: 0.95 - ETA: 3:10 - loss: 0.1985 - accuracy: 0.95 - ETA: 3:10 - loss: 0.2022 - accuracy: 0.94 - ETA: 3:08 - loss: 0.2001 - accuracy: 0.94 - ETA: 3:07 - loss: 0.2066 - accuracy: 0.94 - ETA: 3:06 - loss: 0.2078 - accuracy: 0.94 - ETA: 3:04 - loss: 0.2184 - accuracy: 0.94 - ETA: 3:03 - loss: 0.2242 - accuracy: 0.94 - ETA: 3:01 - loss: 0.2206 - accuracy: 0.94 - ETA: 3:00 - loss: 0.2149 - accuracy: 0.94 - ETA: 2:58 - loss: 0.2156 - accuracy: 0.94 - ETA: 2:57 - loss: 0.2136 - accuracy: 0.94 - ETA: 2:56 - loss: 0.2160 - accuracy: 0.94 - ETA: 2:55 - loss: 0.2127 - accuracy: 0.94 - ETA: 2:53 - loss: 0.2084 - accuracy: 0.94 - ETA: 2:52 - loss: 0.2076 - accuracy: 0.94 - ETA: 2:51 - loss: 0.2042 - accuracy: 0.94 - ETA: 2:49 - loss: 0.2035 - accuracy: 0.94 - ETA: 2:48 - loss: 0.2062 - accuracy: 0.94 - ETA: 2:47 - loss: 0.2079 - accuracy: 0.94 - ETA: 2:45 - loss: 0.2063 - accuracy: 0.94 - ETA: 2:43 - loss: 0.2050 - accuracy: 0.94 - ETA: 2:42 - loss: 0.2021 - accuracy: 0.94 - ETA: 2:41 - loss: 0.2046 - accuracy: 0.94 - ETA: 2:40 - loss: 0.2047 - accuracy: 0.94 - ETA: 2:39 - loss: 0.2057 - accuracy: 0.94 - ETA: 2:37 - loss: 0.2054 - accuracy: 0.94 - ETA: 2:36 - loss: 0.2058 - accuracy: 0.94 - ETA: 2:34 - loss: 0.2037 - accuracy: 0.94 - ETA: 2:33 - loss: 0.2044 - accuracy: 0.94 - ETA: 2:31 - loss: 0.2055 - accuracy: 0.94 - ETA: 2:30 - loss: 0.2074 - accuracy: 0.94 - ETA: 2:29 - loss: 0.2094 - accuracy: 0.94 - ETA: 2:27 - loss: 0.2145 - accuracy: 0.94 - ETA: 2:26 - loss: 0.2129 - accuracy: 0.94 - ETA: 2:24 - loss: 0.2153 - accuracy: 0.94 - ETA: 2:23 - loss: 0.2195 - accuracy: 0.94 - ETA: 2:22 - loss: 0.2187 - accuracy: 0.94 - ETA: 2:20 - loss: 0.2177 - accuracy: 0.94 - ETA: 2:19 - loss: 0.2188 - accuracy: 0.94 - ETA: 2:17 - loss: 0.2162 - accuracy: 0.94 - ETA: 2:16 - loss: 0.2129 - accuracy: 0.94 - ETA: 2:15 - loss: 0.2124 - accuracy: 0.94 - ETA: 2:13 - loss: 0.2110 - accuracy: 0.94 - ETA: 2:12 - loss: 0.2102 - accuracy: 0.94 - ETA: 2:11 - loss: 0.2102 - accuracy: 0.94 - ETA: 2:09 - loss: 0.2078 - accuracy: 0.94 - ETA: 2:08 - loss: 0.2081 - accuracy: 0.94 - ETA: 2:06 - loss: 0.2078 - accuracy: 0.94 - ETA: 2:05 - loss: 0.2087 - accuracy: 0.94 - ETA: 2:04 - loss: 0.2082 - accuracy: 0.94 - ETA: 2:02 - loss: 0.2072 - accuracy: 0.94 - ETA: 2:01 - loss: 0.2061 - accuracy: 0.94 - ETA: 2:00 - loss: 0.2069 - accuracy: 0.94 - ETA: 1:58 - loss: 0.2072 - accuracy: 0.94 - ETA: 1:57 - loss: 0.2073 - accuracy: 0.94 - ETA: 1:56 - loss: 0.2048 - accuracy: 0.94 - ETA: 1:54 - loss: 0.2060 - accuracy: 0.94 - ETA: 1:53 - loss: 0.2063 - accuracy: 0.94 - ETA: 1:51 - loss: 0.2063 - accuracy: 0.94 - ETA: 1:50 - loss: 0.2063 - accuracy: 0.94 - ETA: 1:49 - loss: 0.2061 - accuracy: 0.94 - ETA: 1:47 - loss: 0.2052 - accuracy: 0.94 - ETA: 1:46 - loss: 0.2062 - accuracy: 0.94 - ETA: 1:45 - loss: 0.2072 - accuracy: 0.94 - ETA: 1:43 - loss: 0.2061 - accuracy: 0.94 - ETA: 1:42 - loss: 0.2050 - accuracy: 0.94 - ETA: 1:41 - loss: 0.2057 - accuracy: 0.94 - ETA: 1:39 - loss: 0.2040 - accuracy: 0.94 - ETA: 1:38 - loss: 0.2041 - accuracy: 0.94 - ETA: 1:36 - loss: 0.2046 - accuracy: 0.94 - ETA: 1:35 - loss: 0.2048 - accuracy: 0.94 - ETA: 1:34 - loss: 0.2049 - accuracy: 0.94 - ETA: 1:32 - loss: 0.2051 - accuracy: 0.94 - ETA: 1:31 - loss: 0.2044 - accuracy: 0.94 - ETA: 1:30 - loss: 0.2049 - accuracy: 0.94 - ETA: 1:28 - loss: 0.2039 - accuracy: 0.94 - ETA: 1:27 - loss: 0.2050 - accuracy: 0.94 - ETA: 1:26 - loss: 0.2065 - accuracy: 0.94 - ETA: 1:24 - loss: 0.2072 - accuracy: 0.94 - ETA: 1:23 - loss: 0.2064 - accuracy: 0.94 - ETA: 1:21 - loss: 0.2062 - accuracy: 0.94 - ETA: 1:20 - loss: 0.2053 - accuracy: 0.94 - ETA: 1:19 - loss: 0.2060 - accuracy: 0.94 - ETA: 1:17 - loss: 0.2059 - accuracy: 0.94 - ETA: 1:16 - loss: 0.2051 - accuracy: 0.94 - ETA: 1:15 - loss: 0.2060 - accuracy: 0.94 - ETA: 1:13 - loss: 0.2050 - accuracy: 0.94 - ETA: 1:12 - loss: 0.2053 - accuracy: 0.94 - ETA: 1:11 - loss: 0.2059 - accuracy: 0.94 - ETA: 1:09 - loss: 0.2061 - accuracy: 0.94 - ETA: 1:08 - loss: 0.2067 - accuracy: 0.94 - ETA: 1:06 - loss: 0.2059 - accuracy: 0.94 - ETA: 1:05 - loss: 0.2058 - accuracy: 0.94 - ETA: 1:04 - loss: 0.2048 - accuracy: 0.94 - ETA: 1:02 - loss: 0.2058 - accuracy: 0.94 - ETA: 1:01 - loss: 0.2044 - accuracy: 0.94 - ETA: 1:00 - loss: 0.2035 - accuracy: 0.94 - ETA: 58s - loss: 0.2017 - accuracy: 0.9453 - ETA: 57s - loss: 0.2024 - accuracy: 0.945 - ETA: 55s - loss: 0.2029 - accuracy: 0.944 - ETA: 54s - loss: 0.2024 - accuracy: 0.945 - ETA: 53s - loss: 0.2018 - accuracy: 0.945 - ETA: 51s - loss: 0.2015 - accuracy: 0.945 - ETA: 50s - loss: 0.2017 - accuracy: 0.945 - ETA: 49s - loss: 0.2010 - accuracy: 0.945 - ETA: 47s - loss: 0.2011 - accuracy: 0.945 - ETA: 46s - loss: 0.2010 - accuracy: 0.945 - ETA: 45s - loss: 0.2003 - accuracy: 0.945 - ETA: 43s - loss: 0.2000 - accuracy: 0.945 - ETA: 42s - loss: 0.2015 - accuracy: 0.945 - ETA: 40s - loss: 0.2014 - accuracy: 0.945 - ETA: 39s - loss: 0.2021 - accuracy: 0.945 - ETA: 38s - loss: 0.2019 - accuracy: 0.945 - ETA: 36s - loss: 0.2017 - accuracy: 0.945 - ETA: 35s - loss: 0.2018 - accuracy: 0.945 - ETA: 34s - loss: 0.2031 - accuracy: 0.944 - ETA: 32s - loss: 0.2046 - accuracy: 0.944 - ETA: 31s - loss: 0.2045 - accuracy: 0.945 - ETA: 29s - loss: 0.2058 - accuracy: 0.944 - ETA: 28s - loss: 0.2050 - accuracy: 0.944 - ETA: 27s - loss: 0.2059 - accuracy: 0.944 - ETA: 25s - loss: 0.2064 - accuracy: 0.944 - ETA: 24s - loss: 0.2074 - accuracy: 0.944 - ETA: 23s - loss: 0.2071 - accuracy: 0.944 - ETA: 21s - loss: 0.2069 - accuracy: 0.944 - ETA: 20s - loss: 0.2060 - accuracy: 0.944 - ETA: 19s - loss: 0.2055 - accuracy: 0.944 - ETA: 17s - loss: 0.2045 - accuracy: 0.944 - ETA: 16s - loss: 0.2047 - accuracy: 0.944 - ETA: 14s - loss: 0.2044 - accuracy: 0.944 - ETA: 13s - loss: 0.2043 - accuracy: 0.944 - ETA: 12s - loss: 0.2041 - accuracy: 0.944 - ETA: 10s - loss: 0.2041 - accuracy: 0.944 - ETA: 9s - loss: 0.2041 - accuracy: 0.944 - ETA: 8s - loss: 0.2038 - accuracy: 0.94 - ETA: 6s - loss: 0.2032 - accuracy: 0.94 - ETA: 5s - loss: 0.2033 - accuracy: 0.94 - ETA: 3s - loss: 0.2027 - accuracy: 0.94 - ETA: 2s - loss: 0.2023 - accuracy: 0.94 - ETA: 1s - loss: 0.2028 - accuracy: 0.94 - 218s 11ms/step - loss: 0.2017 - accuracy: 0.9453 - val_loss: 1.5253 - val_accuracy: 0.7888\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:25 - loss: 0.3726 - accuracy: 0.92 - ETA: 3:21 - loss: 0.3132 - accuracy: 0.92 - ETA: 3:23 - loss: 0.3185 - accuracy: 0.92 - ETA: 3:23 - loss: 0.2840 - accuracy: 0.93 - ETA: 3:19 - loss: 0.2637 - accuracy: 0.93 - ETA: 3:17 - loss: 0.2476 - accuracy: 0.93 - ETA: 3:16 - loss: 0.2727 - accuracy: 0.94 - ETA: 3:14 - loss: 0.2572 - accuracy: 0.94 - ETA: 3:14 - loss: 0.2409 - accuracy: 0.94 - ETA: 3:13 - loss: 0.2352 - accuracy: 0.94 - ETA: 3:11 - loss: 0.2325 - accuracy: 0.94 - ETA: 3:09 - loss: 0.2249 - accuracy: 0.94 - ETA: 3:08 - loss: 0.2242 - accuracy: 0.94 - ETA: 3:07 - loss: 0.2257 - accuracy: 0.94 - ETA: 3:06 - loss: 0.2187 - accuracy: 0.94 - ETA: 3:05 - loss: 0.2077 - accuracy: 0.94 - ETA: 3:03 - loss: 0.2043 - accuracy: 0.94 - ETA: 3:02 - loss: 0.2041 - accuracy: 0.94 - ETA: 3:00 - loss: 0.2013 - accuracy: 0.94 - ETA: 2:58 - loss: 0.2020 - accuracy: 0.95 - ETA: 2:57 - loss: 0.1988 - accuracy: 0.95 - ETA: 2:56 - loss: 0.1949 - accuracy: 0.95 - ETA: 2:54 - loss: 0.1999 - accuracy: 0.94 - ETA: 2:53 - loss: 0.2003 - accuracy: 0.94 - ETA: 2:52 - loss: 0.2020 - accuracy: 0.94 - ETA: 2:51 - loss: 0.2019 - accuracy: 0.94 - ETA: 2:50 - loss: 0.2014 - accuracy: 0.94 - ETA: 2:49 - loss: 0.2039 - accuracy: 0.94 - ETA: 2:47 - loss: 0.2007 - accuracy: 0.94 - ETA: 2:46 - loss: 0.2003 - accuracy: 0.94 - ETA: 2:44 - loss: 0.1986 - accuracy: 0.94 - ETA: 2:43 - loss: 0.1967 - accuracy: 0.95 - ETA: 2:42 - loss: 0.1942 - accuracy: 0.95 - ETA: 2:40 - loss: 0.1949 - accuracy: 0.94 - ETA: 2:39 - loss: 0.1948 - accuracy: 0.94 - ETA: 2:38 - loss: 0.1949 - accuracy: 0.94 - ETA: 2:36 - loss: 0.1931 - accuracy: 0.94 - ETA: 2:35 - loss: 0.1951 - accuracy: 0.94 - ETA: 2:34 - loss: 0.1938 - accuracy: 0.94 - ETA: 2:32 - loss: 0.1959 - accuracy: 0.94 - ETA: 2:31 - loss: 0.1950 - accuracy: 0.94 - ETA: 2:30 - loss: 0.1949 - accuracy: 0.94 - ETA: 2:29 - loss: 0.1935 - accuracy: 0.94 - ETA: 2:28 - loss: 0.1958 - accuracy: 0.94 - ETA: 2:26 - loss: 0.1921 - accuracy: 0.95 - ETA: 2:25 - loss: 0.1903 - accuracy: 0.95 - ETA: 2:23 - loss: 0.1899 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1941 - accuracy: 0.94 - ETA: 2:20 - loss: 0.1945 - accuracy: 0.94 - ETA: 2:19 - loss: 0.1942 - accuracy: 0.94 - ETA: 2:18 - loss: 0.1970 - accuracy: 0.94 - ETA: 2:16 - loss: 0.1957 - accuracy: 0.94 - ETA: 2:15 - loss: 0.1945 - accuracy: 0.94 - ETA: 2:13 - loss: 0.1942 - accuracy: 0.94 - ETA: 2:12 - loss: 0.1930 - accuracy: 0.94 - ETA: 2:10 - loss: 0.1940 - accuracy: 0.94 - ETA: 2:09 - loss: 0.1949 - accuracy: 0.94 - ETA: 2:08 - loss: 0.1947 - accuracy: 0.94 - ETA: 2:06 - loss: 0.1943 - accuracy: 0.94 - ETA: 2:05 - loss: 0.1976 - accuracy: 0.94 - ETA: 2:03 - loss: 0.2017 - accuracy: 0.94 - ETA: 2:02 - loss: 0.2015 - accuracy: 0.94 - ETA: 2:01 - loss: 0.2022 - accuracy: 0.94 - ETA: 1:59 - loss: 0.2034 - accuracy: 0.94 - ETA: 1:58 - loss: 0.2016 - accuracy: 0.94 - ETA: 1:56 - loss: 0.2001 - accuracy: 0.94 - ETA: 1:55 - loss: 0.1999 - accuracy: 0.94 - ETA: 1:53 - loss: 0.1990 - accuracy: 0.94 - ETA: 1:52 - loss: 0.1997 - accuracy: 0.94 - ETA: 1:51 - loss: 0.1988 - accuracy: 0.94 - ETA: 1:49 - loss: 0.1970 - accuracy: 0.94 - ETA: 1:48 - loss: 0.1959 - accuracy: 0.94 - ETA: 1:47 - loss: 0.1938 - accuracy: 0.94 - ETA: 1:45 - loss: 0.1936 - accuracy: 0.94 - ETA: 1:44 - loss: 0.1936 - accuracy: 0.94 - ETA: 1:42 - loss: 0.1964 - accuracy: 0.94 - ETA: 1:41 - loss: 0.1964 - accuracy: 0.94 - ETA: 1:40 - loss: 0.1977 - accuracy: 0.94 - ETA: 1:38 - loss: 0.1969 - accuracy: 0.94 - ETA: 1:37 - loss: 0.1983 - accuracy: 0.94 - ETA: 1:36 - loss: 0.1969 - accuracy: 0.94 - ETA: 1:34 - loss: 0.1952 - accuracy: 0.94 - ETA: 1:33 - loss: 0.1942 - accuracy: 0.94 - ETA: 1:32 - loss: 0.1938 - accuracy: 0.94 - ETA: 1:30 - loss: 0.1949 - accuracy: 0.94 - ETA: 1:29 - loss: 0.1947 - accuracy: 0.94 - ETA: 1:28 - loss: 0.1945 - accuracy: 0.94 - ETA: 1:26 - loss: 0.1950 - accuracy: 0.94 - ETA: 1:25 - loss: 0.1948 - accuracy: 0.94 - ETA: 1:24 - loss: 0.1950 - accuracy: 0.94 - ETA: 1:22 - loss: 0.1972 - accuracy: 0.94 - ETA: 1:21 - loss: 0.1958 - accuracy: 0.94 - ETA: 1:19 - loss: 0.1957 - accuracy: 0.94 - ETA: 1:18 - loss: 0.1948 - accuracy: 0.94 - ETA: 1:17 - loss: 0.1972 - accuracy: 0.94 - ETA: 1:15 - loss: 0.1979 - accuracy: 0.94 - ETA: 1:14 - loss: 0.1963 - accuracy: 0.94 - ETA: 1:13 - loss: 0.1958 - accuracy: 0.94 - ETA: 1:11 - loss: 0.1953 - accuracy: 0.94 - ETA: 1:10 - loss: 0.1953 - accuracy: 0.94 - ETA: 1:08 - loss: 0.1960 - accuracy: 0.94 - ETA: 1:07 - loss: 0.1960 - accuracy: 0.94 - ETA: 1:06 - loss: 0.1976 - accuracy: 0.94 - ETA: 1:04 - loss: 0.1965 - accuracy: 0.94 - ETA: 1:03 - loss: 0.1962 - accuracy: 0.94 - ETA: 1:01 - loss: 0.1961 - accuracy: 0.94 - ETA: 1:00 - loss: 0.1975 - accuracy: 0.94 - ETA: 59s - loss: 0.1970 - accuracy: 0.9471 - ETA: 57s - loss: 0.1975 - accuracy: 0.947 - ETA: 56s - loss: 0.1974 - accuracy: 0.947 - ETA: 55s - loss: 0.1972 - accuracy: 0.947 - ETA: 53s - loss: 0.1972 - accuracy: 0.947 - ETA: 52s - loss: 0.1964 - accuracy: 0.947 - ETA: 50s - loss: 0.1956 - accuracy: 0.947 - ETA: 49s - loss: 0.1952 - accuracy: 0.947 - ETA: 48s - loss: 0.1966 - accuracy: 0.946 - ETA: 46s - loss: 0.1960 - accuracy: 0.946 - ETA: 45s - loss: 0.1954 - accuracy: 0.947 - ETA: 43s - loss: 0.1955 - accuracy: 0.947 - ETA: 42s - loss: 0.1947 - accuracy: 0.947 - ETA: 41s - loss: 0.1956 - accuracy: 0.947 - ETA: 39s - loss: 0.1957 - accuracy: 0.947 - ETA: 38s - loss: 0.1965 - accuracy: 0.947 - ETA: 37s - loss: 0.1965 - accuracy: 0.947 - ETA: 35s - loss: 0.1955 - accuracy: 0.947 - ETA: 34s - loss: 0.1948 - accuracy: 0.947 - ETA: 32s - loss: 0.1947 - accuracy: 0.947 - ETA: 31s - loss: 0.1947 - accuracy: 0.947 - ETA: 30s - loss: 0.1945 - accuracy: 0.947 - ETA: 28s - loss: 0.1949 - accuracy: 0.947 - ETA: 27s - loss: 0.1943 - accuracy: 0.947 - ETA: 26s - loss: 0.1942 - accuracy: 0.947 - ETA: 24s - loss: 0.1951 - accuracy: 0.947 - ETA: 23s - loss: 0.1949 - accuracy: 0.947 - ETA: 21s - loss: 0.1945 - accuracy: 0.947 - ETA: 20s - loss: 0.1954 - accuracy: 0.947 - ETA: 19s - loss: 0.1947 - accuracy: 0.947 - ETA: 17s - loss: 0.1952 - accuracy: 0.947 - ETA: 16s - loss: 0.1948 - accuracy: 0.947 - ETA: 14s - loss: 0.1948 - accuracy: 0.947 - ETA: 13s - loss: 0.1941 - accuracy: 0.947 - ETA: 12s - loss: 0.1942 - accuracy: 0.947 - ETA: 10s - loss: 0.1937 - accuracy: 0.947 - ETA: 9s - loss: 0.1933 - accuracy: 0.947 - ETA: 8s - loss: 0.1929 - accuracy: 0.94 - ETA: 6s - loss: 0.1930 - accuracy: 0.94 - ETA: 5s - loss: 0.1922 - accuracy: 0.94 - ETA: 3s - loss: 0.1939 - accuracy: 0.94 - ETA: 2s - loss: 0.1939 - accuracy: 0.94 - ETA: 1s - loss: 0.1946 - accuracy: 0.94 - 220s 11ms/step - loss: 0.1943 - accuracy: 0.9469 - val_loss: 1.6903 - val_accuracy: 0.7879\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:19 - loss: 0.0375 - accuracy: 0.99 - ETA: 3:21 - loss: 0.0508 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0878 - accuracy: 0.98 - ETA: 3:20 - loss: 0.1125 - accuracy: 0.97 - ETA: 3:18 - loss: 0.1116 - accuracy: 0.97 - ETA: 3:18 - loss: 0.1063 - accuracy: 0.97 - ETA: 3:18 - loss: 0.1105 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1313 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1422 - accuracy: 0.96 - ETA: 3:14 - loss: 0.1385 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1412 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1470 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1400 - accuracy: 0.96 - ETA: 3:06 - loss: 0.1354 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1407 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1500 - accuracy: 0.95 - ETA: 3:02 - loss: 0.1470 - accuracy: 0.95 - ETA: 3:02 - loss: 0.1448 - accuracy: 0.96 - ETA: 3:01 - loss: 0.1410 - accuracy: 0.96 - ETA: 2:59 - loss: 0.1410 - accuracy: 0.96 - ETA: 2:58 - loss: 0.1438 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1485 - accuracy: 0.95 - ETA: 2:55 - loss: 0.1497 - accuracy: 0.95 - ETA: 2:53 - loss: 0.1493 - accuracy: 0.95 - ETA: 2:52 - loss: 0.1503 - accuracy: 0.95 - ETA: 2:51 - loss: 0.1503 - accuracy: 0.95 - ETA: 2:49 - loss: 0.1522 - accuracy: 0.95 - ETA: 2:48 - loss: 0.1540 - accuracy: 0.95 - ETA: 2:46 - loss: 0.1588 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1575 - accuracy: 0.95 - ETA: 2:44 - loss: 0.1594 - accuracy: 0.95 - ETA: 2:43 - loss: 0.1596 - accuracy: 0.95 - ETA: 2:42 - loss: 0.1574 - accuracy: 0.95 - ETA: 2:40 - loss: 0.1545 - accuracy: 0.95 - ETA: 2:39 - loss: 0.1683 - accuracy: 0.95 - ETA: 2:37 - loss: 0.1695 - accuracy: 0.95 - ETA: 2:36 - loss: 0.1725 - accuracy: 0.95 - ETA: 2:35 - loss: 0.1764 - accuracy: 0.95 - ETA: 2:33 - loss: 0.1734 - accuracy: 0.95 - ETA: 2:32 - loss: 0.1738 - accuracy: 0.95 - ETA: 2:31 - loss: 0.1744 - accuracy: 0.95 - ETA: 2:29 - loss: 0.1792 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1819 - accuracy: 0.95 - ETA: 2:27 - loss: 0.1845 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1867 - accuracy: 0.94 - ETA: 2:25 - loss: 0.1840 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1858 - accuracy: 0.95 - ETA: 2:23 - loss: 0.1843 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1866 - accuracy: 0.94 - ETA: 2:20 - loss: 0.1844 - accuracy: 0.95 - ETA: 2:18 - loss: 0.1835 - accuracy: 0.95 - ETA: 2:17 - loss: 0.1814 - accuracy: 0.95 - ETA: 2:16 - loss: 0.1824 - accuracy: 0.95 - ETA: 2:14 - loss: 0.1832 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1822 - accuracy: 0.95 - ETA: 2:12 - loss: 0.1813 - accuracy: 0.95 - ETA: 2:10 - loss: 0.1812 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1827 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1817 - accuracy: 0.95 - ETA: 2:06 - loss: 0.1807 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1790 - accuracy: 0.95 - ETA: 2:03 - loss: 0.1797 - accuracy: 0.95 - ETA: 2:01 - loss: 0.1828 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1840 - accuracy: 0.95 - ETA: 1:59 - loss: 0.1829 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1818 - accuracy: 0.95 - ETA: 1:56 - loss: 0.1809 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1828 - accuracy: 0.95 - ETA: 1:53 - loss: 0.1825 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1834 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1822 - accuracy: 0.95 - ETA: 1:49 - loss: 0.1811 - accuracy: 0.95 - ETA: 1:47 - loss: 0.1799 - accuracy: 0.95 - ETA: 1:46 - loss: 0.1799 - accuracy: 0.95 - ETA: 1:45 - loss: 0.1791 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1810 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1809 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1820 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1813 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1810 - accuracy: 0.95 - ETA: 1:36 - loss: 0.1818 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1814 - accuracy: 0.95 - ETA: 1:33 - loss: 0.1809 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1809 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1827 - accuracy: 0.95 - ETA: 1:29 - loss: 0.1831 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1830 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1822 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1820 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1837 - accuracy: 0.95 - ETA: 1:22 - loss: 0.1837 - accuracy: 0.95 - ETA: 1:21 - loss: 0.1832 - accuracy: 0.95 - ETA: 1:20 - loss: 0.1829 - accuracy: 0.95 - ETA: 1:18 - loss: 0.1824 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1815 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1807 - accuracy: 0.95 - ETA: 1:14 - loss: 0.1809 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1804 - accuracy: 0.95 - ETA: 1:11 - loss: 0.1801 - accuracy: 0.95 - ETA: 1:10 - loss: 0.1794 - accuracy: 0.95 - ETA: 1:08 - loss: 0.1796 - accuracy: 0.95 - ETA: 1:07 - loss: 0.1791 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1795 - accuracy: 0.95 - ETA: 1:04 - loss: 0.1794 - accuracy: 0.95 - ETA: 1:03 - loss: 0.1791 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1789 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1790 - accuracy: 0.95 - ETA: 59s - loss: 0.1814 - accuracy: 0.9504 - ETA: 57s - loss: 0.1808 - accuracy: 0.950 - ETA: 56s - loss: 0.1798 - accuracy: 0.950 - ETA: 55s - loss: 0.1806 - accuracy: 0.950 - ETA: 53s - loss: 0.1796 - accuracy: 0.950 - ETA: 52s - loss: 0.1804 - accuracy: 0.950 - ETA: 50s - loss: 0.1804 - accuracy: 0.950 - ETA: 49s - loss: 0.1822 - accuracy: 0.950 - ETA: 48s - loss: 0.1816 - accuracy: 0.950 - ETA: 46s - loss: 0.1829 - accuracy: 0.949 - ETA: 45s - loss: 0.1818 - accuracy: 0.950 - ETA: 44s - loss: 0.1814 - accuracy: 0.950 - ETA: 42s - loss: 0.1813 - accuracy: 0.950 - ETA: 41s - loss: 0.1806 - accuracy: 0.950 - ETA: 39s - loss: 0.1803 - accuracy: 0.950 - ETA: 38s - loss: 0.1795 - accuracy: 0.950 - ETA: 37s - loss: 0.1798 - accuracy: 0.950 - ETA: 35s - loss: 0.1798 - accuracy: 0.950 - ETA: 34s - loss: 0.1797 - accuracy: 0.950 - ETA: 32s - loss: 0.1799 - accuracy: 0.950 - ETA: 31s - loss: 0.1798 - accuracy: 0.950 - ETA: 30s - loss: 0.1793 - accuracy: 0.950 - ETA: 28s - loss: 0.1803 - accuracy: 0.950 - ETA: 27s - loss: 0.1802 - accuracy: 0.950 - ETA: 26s - loss: 0.1811 - accuracy: 0.949 - ETA: 24s - loss: 0.1820 - accuracy: 0.949 - ETA: 23s - loss: 0.1825 - accuracy: 0.949 - ETA: 21s - loss: 0.1823 - accuracy: 0.949 - ETA: 20s - loss: 0.1822 - accuracy: 0.949 - ETA: 19s - loss: 0.1826 - accuracy: 0.949 - ETA: 17s - loss: 0.1817 - accuracy: 0.950 - ETA: 16s - loss: 0.1819 - accuracy: 0.949 - ETA: 15s - loss: 0.1820 - accuracy: 0.949 - ETA: 13s - loss: 0.1819 - accuracy: 0.949 - ETA: 12s - loss: 0.1812 - accuracy: 0.949 - ETA: 10s - loss: 0.1814 - accuracy: 0.949 - ETA: 9s - loss: 0.1821 - accuracy: 0.949 - ETA: 8s - loss: 0.1839 - accuracy: 0.94 - ETA: 6s - loss: 0.1835 - accuracy: 0.94 - ETA: 5s - loss: 0.1836 - accuracy: 0.94 - ETA: 3s - loss: 0.1835 - accuracy: 0.94 - ETA: 2s - loss: 0.1835 - accuracy: 0.94 - ETA: 1s - loss: 0.1834 - accuracy: 0.94 - 220s 11ms/step - loss: 0.1833 - accuracy: 0.9494 - val_loss: 1.6005 - val_accuracy: 0.7917\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:23 - loss: 0.1248 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1325 - accuracy: 0.95 - ETA: 3:15 - loss: 0.1323 - accuracy: 0.95 - ETA: 3:14 - loss: 0.1189 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1403 - accuracy: 0.95 - ETA: 3:14 - loss: 0.1488 - accuracy: 0.95 - ETA: 3:14 - loss: 0.1365 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1486 - accuracy: 0.95 - ETA: 3:12 - loss: 0.1562 - accuracy: 0.95 - ETA: 3:12 - loss: 0.1693 - accuracy: 0.95 - ETA: 3:11 - loss: 0.1878 - accuracy: 0.95 - ETA: 3:10 - loss: 0.1924 - accuracy: 0.95 - ETA: 3:09 - loss: 0.1868 - accuracy: 0.95 - ETA: 3:07 - loss: 0.1856 - accuracy: 0.95 - ETA: 3:06 - loss: 0.1849 - accuracy: 0.95 - ETA: 3:04 - loss: 0.1815 - accuracy: 0.95 - ETA: 3:03 - loss: 0.1772 - accuracy: 0.95 - ETA: 3:01 - loss: 0.1891 - accuracy: 0.95 - ETA: 2:59 - loss: 0.1873 - accuracy: 0.95 - ETA: 2:58 - loss: 0.1867 - accuracy: 0.95 - ETA: 2:57 - loss: 0.1908 - accuracy: 0.94 - ETA: 2:56 - loss: 0.1925 - accuracy: 0.94 - ETA: 2:55 - loss: 0.1933 - accuracy: 0.94 - ETA: 2:53 - loss: 0.1933 - accuracy: 0.94 - ETA: 2:52 - loss: 0.1939 - accuracy: 0.94 - ETA: 2:51 - loss: 0.1940 - accuracy: 0.94 - ETA: 2:49 - loss: 0.1942 - accuracy: 0.94 - ETA: 2:48 - loss: 0.1894 - accuracy: 0.94 - ETA: 2:46 - loss: 0.1902 - accuracy: 0.94 - ETA: 2:45 - loss: 0.1879 - accuracy: 0.94 - ETA: 2:43 - loss: 0.1932 - accuracy: 0.94 - ETA: 2:42 - loss: 0.1918 - accuracy: 0.94 - ETA: 2:41 - loss: 0.1876 - accuracy: 0.94 - ETA: 2:40 - loss: 0.1865 - accuracy: 0.94 - ETA: 2:38 - loss: 0.1825 - accuracy: 0.95 - ETA: 2:37 - loss: 0.1870 - accuracy: 0.95 - ETA: 2:35 - loss: 0.1850 - accuracy: 0.95 - ETA: 2:34 - loss: 0.1857 - accuracy: 0.95 - ETA: 2:33 - loss: 0.1846 - accuracy: 0.95 - ETA: 2:31 - loss: 0.1832 - accuracy: 0.95 - ETA: 2:30 - loss: 0.1815 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1780 - accuracy: 0.95 - ETA: 2:27 - loss: 0.1793 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1793 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1779 - accuracy: 0.95 - ETA: 2:23 - loss: 0.1766 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1756 - accuracy: 0.95 - ETA: 2:20 - loss: 0.1759 - accuracy: 0.95 - ETA: 2:19 - loss: 0.1755 - accuracy: 0.95 - ETA: 2:17 - loss: 0.1746 - accuracy: 0.95 - ETA: 2:16 - loss: 0.1770 - accuracy: 0.95 - ETA: 2:15 - loss: 0.1746 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1752 - accuracy: 0.95 - ETA: 2:12 - loss: 0.1774 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1774 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1779 - accuracy: 0.95 - ETA: 2:08 - loss: 0.1766 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1764 - accuracy: 0.95 - ETA: 2:05 - loss: 0.1761 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1765 - accuracy: 0.95 - ETA: 2:03 - loss: 0.1764 - accuracy: 0.95 - ETA: 2:01 - loss: 0.1757 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1775 - accuracy: 0.95 - ETA: 1:59 - loss: 0.1763 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1767 - accuracy: 0.95 - ETA: 1:56 - loss: 0.1764 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1757 - accuracy: 0.95 - ETA: 1:53 - loss: 0.1756 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1741 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1747 - accuracy: 0.95 - ETA: 1:49 - loss: 0.1757 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1755 - accuracy: 0.95 - ETA: 1:46 - loss: 0.1750 - accuracy: 0.95 - ETA: 1:45 - loss: 0.1758 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1787 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1778 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1771 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1776 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1781 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1778 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1792 - accuracy: 0.94 - ETA: 1:34 - loss: 0.1795 - accuracy: 0.94 - ETA: 1:32 - loss: 0.1792 - accuracy: 0.94 - ETA: 1:31 - loss: 0.1800 - accuracy: 0.94 - ETA: 1:30 - loss: 0.1797 - accuracy: 0.94 - ETA: 1:28 - loss: 0.1798 - accuracy: 0.94 - ETA: 1:27 - loss: 0.1797 - accuracy: 0.94 - ETA: 1:26 - loss: 0.1811 - accuracy: 0.94 - ETA: 1:24 - loss: 0.1806 - accuracy: 0.94 - ETA: 1:23 - loss: 0.1809 - accuracy: 0.94 - ETA: 1:21 - loss: 0.1815 - accuracy: 0.94 - ETA: 1:20 - loss: 0.1817 - accuracy: 0.94 - ETA: 1:19 - loss: 0.1806 - accuracy: 0.94 - ETA: 1:17 - loss: 0.1821 - accuracy: 0.94 - ETA: 1:16 - loss: 0.1846 - accuracy: 0.94 - ETA: 1:15 - loss: 0.1844 - accuracy: 0.94 - ETA: 1:13 - loss: 0.1837 - accuracy: 0.94 - ETA: 1:12 - loss: 0.1832 - accuracy: 0.94 - ETA: 1:10 - loss: 0.1825 - accuracy: 0.94 - ETA: 1:09 - loss: 0.1824 - accuracy: 0.94 - ETA: 1:08 - loss: 0.1819 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1823 - accuracy: 0.94 - ETA: 1:05 - loss: 0.1844 - accuracy: 0.94 - ETA: 1:04 - loss: 0.1863 - accuracy: 0.94 - ETA: 1:02 - loss: 0.1862 - accuracy: 0.94 - ETA: 1:01 - loss: 0.1854 - accuracy: 0.94 - ETA: 1:00 - loss: 0.1861 - accuracy: 0.94 - ETA: 58s - loss: 0.1858 - accuracy: 0.9491 - ETA: 57s - loss: 0.1849 - accuracy: 0.949 - ETA: 55s - loss: 0.1841 - accuracy: 0.949 - ETA: 54s - loss: 0.1836 - accuracy: 0.950 - ETA: 53s - loss: 0.1833 - accuracy: 0.950 - ETA: 51s - loss: 0.1829 - accuracy: 0.950 - ETA: 50s - loss: 0.1835 - accuracy: 0.949 - ETA: 49s - loss: 0.1829 - accuracy: 0.949 - ETA: 47s - loss: 0.1837 - accuracy: 0.949 - ETA: 46s - loss: 0.1845 - accuracy: 0.949 - ETA: 44s - loss: 0.1851 - accuracy: 0.949 - ETA: 43s - loss: 0.1845 - accuracy: 0.949 - ETA: 42s - loss: 0.1841 - accuracy: 0.949 - ETA: 40s - loss: 0.1840 - accuracy: 0.949 - ETA: 39s - loss: 0.1838 - accuracy: 0.949 - ETA: 38s - loss: 0.1836 - accuracy: 0.949 - ETA: 36s - loss: 0.1834 - accuracy: 0.949 - ETA: 35s - loss: 0.1822 - accuracy: 0.950 - ETA: 34s - loss: 0.1824 - accuracy: 0.950 - ETA: 32s - loss: 0.1823 - accuracy: 0.949 - ETA: 31s - loss: 0.1831 - accuracy: 0.949 - ETA: 29s - loss: 0.1834 - accuracy: 0.949 - ETA: 28s - loss: 0.1839 - accuracy: 0.949 - ETA: 27s - loss: 0.1831 - accuracy: 0.949 - ETA: 25s - loss: 0.1825 - accuracy: 0.949 - ETA: 24s - loss: 0.1822 - accuracy: 0.949 - ETA: 23s - loss: 0.1826 - accuracy: 0.949 - ETA: 21s - loss: 0.1820 - accuracy: 0.949 - ETA: 20s - loss: 0.1813 - accuracy: 0.950 - ETA: 18s - loss: 0.1808 - accuracy: 0.950 - ETA: 17s - loss: 0.1810 - accuracy: 0.950 - ETA: 16s - loss: 0.1804 - accuracy: 0.950 - ETA: 14s - loss: 0.1808 - accuracy: 0.950 - ETA: 13s - loss: 0.1803 - accuracy: 0.950 - ETA: 12s - loss: 0.1818 - accuracy: 0.950 - ETA: 10s - loss: 0.1823 - accuracy: 0.950 - ETA: 9s - loss: 0.1826 - accuracy: 0.950 - ETA: 8s - loss: 0.1820 - accuracy: 0.95 - ETA: 6s - loss: 0.1822 - accuracy: 0.95 - ETA: 5s - loss: 0.1833 - accuracy: 0.95 - ETA: 3s - loss: 0.1838 - accuracy: 0.94 - ETA: 2s - loss: 0.1842 - accuracy: 0.94 - ETA: 1s - loss: 0.1842 - accuracy: 0.94 - 218s 11ms/step - loss: 0.1844 - accuracy: 0.9494 - val_loss: 1.6949 - val_accuracy: 0.7879\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:19 - loss: 0.1795 - accuracy: 0.95 - ETA: 3:28 - loss: 0.1901 - accuracy: 0.94 - ETA: 3:29 - loss: 0.1869 - accuracy: 0.94 - ETA: 3:24 - loss: 0.2014 - accuracy: 0.94 - ETA: 3:23 - loss: 0.1832 - accuracy: 0.94 - ETA: 3:20 - loss: 0.1764 - accuracy: 0.95 - ETA: 3:18 - loss: 0.1690 - accuracy: 0.95 - ETA: 3:16 - loss: 0.1647 - accuracy: 0.95 - ETA: 3:15 - loss: 0.1582 - accuracy: 0.95 - ETA: 3:13 - loss: 0.1579 - accuracy: 0.95 - ETA: 3:12 - loss: 0.1545 - accuracy: 0.95 - ETA: 3:11 - loss: 0.1576 - accuracy: 0.95 - ETA: 3:09 - loss: 0.1538 - accuracy: 0.95 - ETA: 3:09 - loss: 0.1571 - accuracy: 0.95 - ETA: 3:07 - loss: 0.1567 - accuracy: 0.95 - ETA: 3:06 - loss: 0.1505 - accuracy: 0.95 - ETA: 3:04 - loss: 0.1438 - accuracy: 0.95 - ETA: 3:03 - loss: 0.1525 - accuracy: 0.95 - ETA: 3:01 - loss: 0.1483 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1551 - accuracy: 0.95 - ETA: 2:58 - loss: 0.1538 - accuracy: 0.95 - ETA: 2:57 - loss: 0.1505 - accuracy: 0.95 - ETA: 2:55 - loss: 0.1577 - accuracy: 0.95 - ETA: 2:53 - loss: 0.1540 - accuracy: 0.95 - ETA: 2:52 - loss: 0.1607 - accuracy: 0.95 - ETA: 2:51 - loss: 0.1663 - accuracy: 0.95 - ETA: 2:50 - loss: 0.1657 - accuracy: 0.95 - ETA: 2:49 - loss: 0.1686 - accuracy: 0.95 - ETA: 2:47 - loss: 0.1697 - accuracy: 0.95 - ETA: 2:46 - loss: 0.1674 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1645 - accuracy: 0.95 - ETA: 2:43 - loss: 0.1671 - accuracy: 0.95 - ETA: 2:42 - loss: 0.1645 - accuracy: 0.95 - ETA: 2:40 - loss: 0.1643 - accuracy: 0.95 - ETA: 2:39 - loss: 0.1689 - accuracy: 0.95 - ETA: 2:37 - loss: 0.1698 - accuracy: 0.95 - ETA: 2:36 - loss: 0.1718 - accuracy: 0.95 - ETA: 2:35 - loss: 0.1763 - accuracy: 0.95 - ETA: 2:33 - loss: 0.1776 - accuracy: 0.95 - ETA: 2:32 - loss: 0.1829 - accuracy: 0.95 - ETA: 2:30 - loss: 0.1821 - accuracy: 0.95 - ETA: 2:29 - loss: 0.1821 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1836 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1838 - accuracy: 0.95 - ETA: 2:25 - loss: 0.1858 - accuracy: 0.95 - ETA: 2:23 - loss: 0.1837 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1811 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1790 - accuracy: 0.95 - ETA: 2:19 - loss: 0.1810 - accuracy: 0.95 - ETA: 2:18 - loss: 0.1834 - accuracy: 0.95 - ETA: 2:17 - loss: 0.1822 - accuracy: 0.95 - ETA: 2:15 - loss: 0.1815 - accuracy: 0.95 - ETA: 2:14 - loss: 0.1818 - accuracy: 0.95 - ETA: 2:12 - loss: 0.1803 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1780 - accuracy: 0.95 - ETA: 2:10 - loss: 0.1789 - accuracy: 0.95 - ETA: 2:08 - loss: 0.1759 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1767 - accuracy: 0.95 - ETA: 2:05 - loss: 0.1804 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1801 - accuracy: 0.95 - ETA: 2:03 - loss: 0.1787 - accuracy: 0.95 - ETA: 2:01 - loss: 0.1805 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1798 - accuracy: 0.95 - ETA: 1:59 - loss: 0.1778 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1778 - accuracy: 0.95 - ETA: 1:56 - loss: 0.1788 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1799 - accuracy: 0.95 - ETA: 1:53 - loss: 0.1811 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1822 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1806 - accuracy: 0.95 - ETA: 1:49 - loss: 0.1831 - accuracy: 0.95 - ETA: 1:47 - loss: 0.1825 - accuracy: 0.95 - ETA: 1:46 - loss: 0.1822 - accuracy: 0.95 - ETA: 1:45 - loss: 0.1821 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1810 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1813 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1809 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1804 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1818 - accuracy: 0.95 - ETA: 1:36 - loss: 0.1824 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1830 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1837 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1848 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1847 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1844 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1832 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1831 - accuracy: 0.95 - ETA: 1:26 - loss: 0.1834 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1825 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1825 - accuracy: 0.95 - ETA: 1:22 - loss: 0.1824 - accuracy: 0.95 - ETA: 1:20 - loss: 0.1813 - accuracy: 0.95 - ETA: 1:19 - loss: 0.1806 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1797 - accuracy: 0.95 - ETA: 1:16 - loss: 0.1801 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1812 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1827 - accuracy: 0.95 - ETA: 1:12 - loss: 0.1830 - accuracy: 0.95 - ETA: 1:11 - loss: 0.1824 - accuracy: 0.95 - ETA: 1:09 - loss: 0.1817 - accuracy: 0.95 - ETA: 1:08 - loss: 0.1815 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1807 - accuracy: 0.95 - ETA: 1:05 - loss: 0.1822 - accuracy: 0.95 - ETA: 1:04 - loss: 0.1824 - accuracy: 0.95 - ETA: 1:02 - loss: 0.1820 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1820 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1812 - accuracy: 0.95 - ETA: 58s - loss: 0.1817 - accuracy: 0.9517 - ETA: 57s - loss: 0.1820 - accuracy: 0.951 - ETA: 56s - loss: 0.1818 - accuracy: 0.951 - ETA: 54s - loss: 0.1825 - accuracy: 0.951 - ETA: 53s - loss: 0.1820 - accuracy: 0.951 - ETA: 51s - loss: 0.1815 - accuracy: 0.951 - ETA: 50s - loss: 0.1811 - accuracy: 0.951 - ETA: 49s - loss: 0.1805 - accuracy: 0.951 - ETA: 47s - loss: 0.1801 - accuracy: 0.951 - ETA: 46s - loss: 0.1809 - accuracy: 0.951 - ETA: 45s - loss: 0.1804 - accuracy: 0.951 - ETA: 43s - loss: 0.1801 - accuracy: 0.951 - ETA: 42s - loss: 0.1807 - accuracy: 0.951 - ETA: 40s - loss: 0.1811 - accuracy: 0.950 - ETA: 39s - loss: 0.1809 - accuracy: 0.950 - ETA: 38s - loss: 0.1804 - accuracy: 0.951 - ETA: 36s - loss: 0.1807 - accuracy: 0.951 - ETA: 35s - loss: 0.1803 - accuracy: 0.951 - ETA: 34s - loss: 0.1825 - accuracy: 0.950 - ETA: 32s - loss: 0.1833 - accuracy: 0.950 - ETA: 31s - loss: 0.1833 - accuracy: 0.950 - ETA: 29s - loss: 0.1841 - accuracy: 0.950 - ETA: 28s - loss: 0.1849 - accuracy: 0.950 - ETA: 27s - loss: 0.1845 - accuracy: 0.950 - ETA: 25s - loss: 0.1835 - accuracy: 0.951 - ETA: 24s - loss: 0.1841 - accuracy: 0.950 - ETA: 23s - loss: 0.1837 - accuracy: 0.950 - ETA: 21s - loss: 0.1852 - accuracy: 0.950 - ETA: 20s - loss: 0.1862 - accuracy: 0.950 - ETA: 19s - loss: 0.1862 - accuracy: 0.950 - ETA: 17s - loss: 0.1857 - accuracy: 0.950 - ETA: 16s - loss: 0.1872 - accuracy: 0.950 - ETA: 14s - loss: 0.1865 - accuracy: 0.950 - ETA: 13s - loss: 0.1869 - accuracy: 0.950 - ETA: 12s - loss: 0.1871 - accuracy: 0.950 - ETA: 10s - loss: 0.1877 - accuracy: 0.950 - ETA: 9s - loss: 0.1876 - accuracy: 0.950 - ETA: 8s - loss: 0.1874 - accuracy: 0.95 - ETA: 6s - loss: 0.1869 - accuracy: 0.95 - ETA: 5s - loss: 0.1869 - accuracy: 0.95 - ETA: 3s - loss: 0.1863 - accuracy: 0.95 - ETA: 2s - loss: 0.1859 - accuracy: 0.95 - ETA: 1s - loss: 0.1856 - accuracy: 0.95 - 219s 11ms/step - loss: 0.1855 - accuracy: 0.9502 - val_loss: 1.6881 - val_accuracy: 0.7884\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:30 - loss: 0.1830 - accuracy: 0.95 - ETA: 3:20 - loss: 0.1754 - accuracy: 0.95 - ETA: 3:20 - loss: 0.1874 - accuracy: 0.95 - ETA: 3:18 - loss: 0.1707 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1713 - accuracy: 0.95 - ETA: 3:17 - loss: 0.1694 - accuracy: 0.95 - ETA: 3:16 - loss: 0.1890 - accuracy: 0.95 - ETA: 3:15 - loss: 0.2055 - accuracy: 0.95 - ETA: 3:13 - loss: 0.1893 - accuracy: 0.95 - ETA: 3:12 - loss: 0.1785 - accuracy: 0.95 - ETA: 3:10 - loss: 0.1810 - accuracy: 0.95 - ETA: 3:09 - loss: 0.1782 - accuracy: 0.95 - ETA: 3:08 - loss: 0.1740 - accuracy: 0.95 - ETA: 3:07 - loss: 0.1804 - accuracy: 0.95 - ETA: 3:06 - loss: 0.1810 - accuracy: 0.95 - ETA: 3:04 - loss: 0.1762 - accuracy: 0.95 - ETA: 3:03 - loss: 0.1754 - accuracy: 0.95 - ETA: 3:02 - loss: 0.1722 - accuracy: 0.95 - ETA: 3:01 - loss: 0.1663 - accuracy: 0.95 - ETA: 2:59 - loss: 0.1774 - accuracy: 0.95 - ETA: 2:58 - loss: 0.1748 - accuracy: 0.95 - ETA: 2:57 - loss: 0.1764 - accuracy: 0.95 - ETA: 2:55 - loss: 0.1830 - accuracy: 0.95 - ETA: 2:54 - loss: 0.1805 - accuracy: 0.95 - ETA: 2:53 - loss: 0.1771 - accuracy: 0.95 - ETA: 2:51 - loss: 0.1781 - accuracy: 0.95 - ETA: 2:50 - loss: 0.1780 - accuracy: 0.95 - ETA: 2:48 - loss: 0.1743 - accuracy: 0.95 - ETA: 2:47 - loss: 0.1797 - accuracy: 0.95 - ETA: 2:46 - loss: 0.1798 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1781 - accuracy: 0.95 - ETA: 2:43 - loss: 0.1797 - accuracy: 0.95 - ETA: 2:42 - loss: 0.1802 - accuracy: 0.95 - ETA: 2:40 - loss: 0.1767 - accuracy: 0.95 - ETA: 2:39 - loss: 0.1784 - accuracy: 0.95 - ETA: 2:37 - loss: 0.1763 - accuracy: 0.95 - ETA: 2:36 - loss: 0.1774 - accuracy: 0.95 - ETA: 2:35 - loss: 0.1776 - accuracy: 0.95 - ETA: 2:33 - loss: 0.1771 - accuracy: 0.95 - ETA: 2:32 - loss: 0.1754 - accuracy: 0.95 - ETA: 2:31 - loss: 0.1747 - accuracy: 0.95 - ETA: 2:29 - loss: 0.1741 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1739 - accuracy: 0.95 - ETA: 2:27 - loss: 0.1738 - accuracy: 0.95 - ETA: 2:25 - loss: 0.1734 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1724 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1722 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1716 - accuracy: 0.95 - ETA: 2:19 - loss: 0.1694 - accuracy: 0.95 - ETA: 2:18 - loss: 0.1677 - accuracy: 0.95 - ETA: 2:17 - loss: 0.1654 - accuracy: 0.95 - ETA: 2:15 - loss: 0.1654 - accuracy: 0.95 - ETA: 2:14 - loss: 0.1650 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1650 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1652 - accuracy: 0.95 - ETA: 2:10 - loss: 0.1657 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1666 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1655 - accuracy: 0.95 - ETA: 2:06 - loss: 0.1656 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1657 - accuracy: 0.95 - ETA: 2:03 - loss: 0.1658 - accuracy: 0.95 - ETA: 2:02 - loss: 0.1653 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1639 - accuracy: 0.95 - ETA: 1:59 - loss: 0.1637 - accuracy: 0.95 - ETA: 1:58 - loss: 0.1633 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1646 - accuracy: 0.95 - ETA: 1:55 - loss: 0.1661 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1651 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1635 - accuracy: 0.95 - ETA: 1:51 - loss: 0.1629 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1630 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1624 - accuracy: 0.95 - ETA: 1:47 - loss: 0.1627 - accuracy: 0.95 - ETA: 1:45 - loss: 0.1626 - accuracy: 0.95 - ETA: 1:44 - loss: 0.1625 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1624 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1627 - accuracy: 0.95 - ETA: 1:40 - loss: 0.1640 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1651 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1656 - accuracy: 0.95 - ETA: 1:36 - loss: 0.1662 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1650 - accuracy: 0.95 - ETA: 1:33 - loss: 0.1677 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1685 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1679 - accuracy: 0.95 - ETA: 1:29 - loss: 0.1692 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1678 - accuracy: 0.95 - ETA: 1:26 - loss: 0.1683 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1709 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1699 - accuracy: 0.95 - ETA: 1:22 - loss: 0.1698 - accuracy: 0.95 - ETA: 1:21 - loss: 0.1699 - accuracy: 0.95 - ETA: 1:19 - loss: 0.1698 - accuracy: 0.95 - ETA: 1:18 - loss: 0.1697 - accuracy: 0.95 - ETA: 1:16 - loss: 0.1688 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1682 - accuracy: 0.95 - ETA: 1:14 - loss: 0.1680 - accuracy: 0.95 - ETA: 1:12 - loss: 0.1674 - accuracy: 0.95 - ETA: 1:11 - loss: 0.1677 - accuracy: 0.95 - ETA: 1:09 - loss: 0.1679 - accuracy: 0.95 - ETA: 1:08 - loss: 0.1680 - accuracy: 0.95 - ETA: 1:07 - loss: 0.1670 - accuracy: 0.95 - ETA: 1:05 - loss: 0.1668 - accuracy: 0.95 - ETA: 1:04 - loss: 0.1656 - accuracy: 0.95 - ETA: 1:03 - loss: 0.1650 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1641 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1641 - accuracy: 0.95 - ETA: 58s - loss: 0.1634 - accuracy: 0.9557 - ETA: 57s - loss: 0.1647 - accuracy: 0.955 - ETA: 56s - loss: 0.1641 - accuracy: 0.955 - ETA: 54s - loss: 0.1656 - accuracy: 0.955 - ETA: 53s - loss: 0.1670 - accuracy: 0.955 - ETA: 52s - loss: 0.1671 - accuracy: 0.955 - ETA: 50s - loss: 0.1665 - accuracy: 0.955 - ETA: 49s - loss: 0.1673 - accuracy: 0.955 - ETA: 48s - loss: 0.1663 - accuracy: 0.955 - ETA: 46s - loss: 0.1664 - accuracy: 0.955 - ETA: 45s - loss: 0.1672 - accuracy: 0.955 - ETA: 43s - loss: 0.1669 - accuracy: 0.955 - ETA: 42s - loss: 0.1670 - accuracy: 0.955 - ETA: 41s - loss: 0.1668 - accuracy: 0.955 - ETA: 39s - loss: 0.1667 - accuracy: 0.955 - ETA: 38s - loss: 0.1672 - accuracy: 0.955 - ETA: 37s - loss: 0.1666 - accuracy: 0.955 - ETA: 35s - loss: 0.1661 - accuracy: 0.955 - ETA: 34s - loss: 0.1662 - accuracy: 0.955 - ETA: 32s - loss: 0.1652 - accuracy: 0.955 - ETA: 31s - loss: 0.1657 - accuracy: 0.955 - ETA: 30s - loss: 0.1651 - accuracy: 0.955 - ETA: 28s - loss: 0.1650 - accuracy: 0.955 - ETA: 27s - loss: 0.1644 - accuracy: 0.956 - ETA: 26s - loss: 0.1655 - accuracy: 0.955 - ETA: 24s - loss: 0.1649 - accuracy: 0.955 - ETA: 23s - loss: 0.1643 - accuracy: 0.956 - ETA: 21s - loss: 0.1643 - accuracy: 0.956 - ETA: 20s - loss: 0.1650 - accuracy: 0.956 - ETA: 19s - loss: 0.1646 - accuracy: 0.956 - ETA: 17s - loss: 0.1668 - accuracy: 0.955 - ETA: 16s - loss: 0.1673 - accuracy: 0.955 - ETA: 15s - loss: 0.1674 - accuracy: 0.955 - ETA: 13s - loss: 0.1670 - accuracy: 0.955 - ETA: 12s - loss: 0.1667 - accuracy: 0.955 - ETA: 10s - loss: 0.1675 - accuracy: 0.955 - ETA: 9s - loss: 0.1675 - accuracy: 0.955 - ETA: 8s - loss: 0.1664 - accuracy: 0.95 - ETA: 6s - loss: 0.1664 - accuracy: 0.95 - ETA: 5s - loss: 0.1666 - accuracy: 0.95 - ETA: 3s - loss: 0.1664 - accuracy: 0.95 - ETA: 2s - loss: 0.1669 - accuracy: 0.95 - ETA: 1s - loss: 0.1675 - accuracy: 0.95 - 220s 11ms/step - loss: 0.1668 - accuracy: 0.9559 - val_loss: 1.7324 - val_accuracy: 0.7908\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:19 - loss: 0.1346 - accuracy: 0.97 - ETA: 3:18 - loss: 0.1650 - accuracy: 0.97 - ETA: 3:18 - loss: 0.1525 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1212 - accuracy: 0.97 - ETA: 3:16 - loss: 0.1061 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0998 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0948 - accuracy: 0.97 - ETA: 3:12 - loss: 0.1073 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0987 - accuracy: 0.97 - ETA: 3:12 - loss: 0.1169 - accuracy: 0.97 - ETA: 3:10 - loss: 0.1170 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1193 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1227 - accuracy: 0.96 - ETA: 3:06 - loss: 0.1294 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1286 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1277 - accuracy: 0.96 - ETA: 3:02 - loss: 0.1273 - accuracy: 0.96 - ETA: 3:01 - loss: 0.1291 - accuracy: 0.96 - ETA: 2:59 - loss: 0.1261 - accuracy: 0.96 - ETA: 2:58 - loss: 0.1232 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1287 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1281 - accuracy: 0.96 - ETA: 2:55 - loss: 0.1271 - accuracy: 0.96 - ETA: 2:53 - loss: 0.1366 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1417 - accuracy: 0.96 - ETA: 2:50 - loss: 0.1394 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1398 - accuracy: 0.96 - ETA: 2:47 - loss: 0.1449 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1454 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1458 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1472 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1503 - accuracy: 0.96 - ETA: 2:41 - loss: 0.1489 - accuracy: 0.96 - ETA: 2:40 - loss: 0.1479 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1488 - accuracy: 0.96 - ETA: 2:37 - loss: 0.1558 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1537 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1518 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1492 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1472 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1476 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1470 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1455 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1432 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1412 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1403 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1418 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1401 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1383 - accuracy: 0.96 - ETA: 2:17 - loss: 0.1367 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1347 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1356 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1385 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1393 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1387 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1383 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1374 - accuracy: 0.96 - ETA: 2:07 - loss: 0.1400 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1386 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1394 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1397 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1394 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1401 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1390 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1399 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1415 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1450 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1462 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1456 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1478 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1502 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1496 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1494 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1535 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1522 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1526 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1520 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1529 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1526 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1527 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1535 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1537 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1536 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1537 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1543 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1543 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1542 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1542 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1540 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1538 - accuracy: 0.95 - ETA: 1:21 - loss: 0.1528 - accuracy: 0.95 - ETA: 1:20 - loss: 0.1525 - accuracy: 0.95 - ETA: 1:19 - loss: 0.1520 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1527 - accuracy: 0.95 - ETA: 1:16 - loss: 0.1523 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1524 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1538 - accuracy: 0.95 - ETA: 1:12 - loss: 0.1541 - accuracy: 0.95 - ETA: 1:10 - loss: 0.1528 - accuracy: 0.95 - ETA: 1:09 - loss: 0.1540 - accuracy: 0.95 - ETA: 1:08 - loss: 0.1543 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1543 - accuracy: 0.95 - ETA: 1:05 - loss: 0.1544 - accuracy: 0.95 - ETA: 1:04 - loss: 0.1541 - accuracy: 0.95 - ETA: 1:02 - loss: 0.1552 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1550 - accuracy: 0.95 - ETA: 59s - loss: 0.1568 - accuracy: 0.9577 - ETA: 58s - loss: 0.1590 - accuracy: 0.957 - ETA: 57s - loss: 0.1590 - accuracy: 0.957 - ETA: 55s - loss: 0.1591 - accuracy: 0.957 - ETA: 54s - loss: 0.1602 - accuracy: 0.957 - ETA: 53s - loss: 0.1598 - accuracy: 0.957 - ETA: 51s - loss: 0.1600 - accuracy: 0.957 - ETA: 50s - loss: 0.1600 - accuracy: 0.957 - ETA: 49s - loss: 0.1594 - accuracy: 0.957 - ETA: 47s - loss: 0.1589 - accuracy: 0.957 - ETA: 46s - loss: 0.1584 - accuracy: 0.957 - ETA: 44s - loss: 0.1594 - accuracy: 0.957 - ETA: 43s - loss: 0.1587 - accuracy: 0.957 - ETA: 42s - loss: 0.1587 - accuracy: 0.957 - ETA: 40s - loss: 0.1604 - accuracy: 0.957 - ETA: 39s - loss: 0.1609 - accuracy: 0.957 - ETA: 38s - loss: 0.1605 - accuracy: 0.957 - ETA: 36s - loss: 0.1595 - accuracy: 0.958 - ETA: 35s - loss: 0.1591 - accuracy: 0.958 - ETA: 34s - loss: 0.1597 - accuracy: 0.958 - ETA: 32s - loss: 0.1608 - accuracy: 0.957 - ETA: 31s - loss: 0.1617 - accuracy: 0.957 - ETA: 29s - loss: 0.1623 - accuracy: 0.957 - ETA: 28s - loss: 0.1623 - accuracy: 0.957 - ETA: 27s - loss: 0.1617 - accuracy: 0.957 - ETA: 25s - loss: 0.1629 - accuracy: 0.957 - ETA: 24s - loss: 0.1621 - accuracy: 0.957 - ETA: 23s - loss: 0.1613 - accuracy: 0.957 - ETA: 21s - loss: 0.1615 - accuracy: 0.957 - ETA: 20s - loss: 0.1615 - accuracy: 0.957 - ETA: 18s - loss: 0.1608 - accuracy: 0.957 - ETA: 17s - loss: 0.1617 - accuracy: 0.957 - ETA: 16s - loss: 0.1620 - accuracy: 0.957 - ETA: 14s - loss: 0.1624 - accuracy: 0.957 - ETA: 13s - loss: 0.1627 - accuracy: 0.957 - ETA: 12s - loss: 0.1643 - accuracy: 0.956 - ETA: 10s - loss: 0.1638 - accuracy: 0.957 - ETA: 9s - loss: 0.1641 - accuracy: 0.956 - ETA: 8s - loss: 0.1655 - accuracy: 0.95 - ETA: 6s - loss: 0.1657 - accuracy: 0.95 - ETA: 5s - loss: 0.1660 - accuracy: 0.95 - ETA: 3s - loss: 0.1654 - accuracy: 0.95 - ETA: 2s - loss: 0.1662 - accuracy: 0.95 - ETA: 1s - loss: 0.1666 - accuracy: 0.95 - 219s 11ms/step - loss: 0.1669 - accuracy: 0.9563 - val_loss: 1.7373 - val_accuracy: 0.7908\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:38 - loss: 0.1497 - accuracy: 0.94 - ETA: 3:30 - loss: 0.2342 - accuracy: 0.92 - ETA: 3:27 - loss: 0.2074 - accuracy: 0.93 - ETA: 3:24 - loss: 0.1859 - accuracy: 0.94 - ETA: 3:21 - loss: 0.2024 - accuracy: 0.94 - ETA: 3:19 - loss: 0.1846 - accuracy: 0.94 - ETA: 3:18 - loss: 0.1844 - accuracy: 0.94 - ETA: 3:18 - loss: 0.1806 - accuracy: 0.94 - ETA: 3:16 - loss: 0.1749 - accuracy: 0.94 - ETA: 3:14 - loss: 0.1664 - accuracy: 0.95 - ETA: 3:12 - loss: 0.1566 - accuracy: 0.95 - ETA: 3:10 - loss: 0.1514 - accuracy: 0.95 - ETA: 3:10 - loss: 0.1457 - accuracy: 0.95 - ETA: 3:09 - loss: 0.1427 - accuracy: 0.95 - ETA: 3:08 - loss: 0.1424 - accuracy: 0.95 - ETA: 3:06 - loss: 0.1389 - accuracy: 0.96 - ETA: 3:04 - loss: 0.1434 - accuracy: 0.96 - ETA: 3:02 - loss: 0.1428 - accuracy: 0.96 - ETA: 3:01 - loss: 0.1436 - accuracy: 0.96 - ETA: 2:59 - loss: 0.1416 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1439 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1403 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1429 - accuracy: 0.96 - ETA: 2:53 - loss: 0.1403 - accuracy: 0.96 - ETA: 2:52 - loss: 0.1450 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1451 - accuracy: 0.95 - ETA: 2:49 - loss: 0.1447 - accuracy: 0.95 - ETA: 2:48 - loss: 0.1429 - accuracy: 0.95 - ETA: 2:46 - loss: 0.1417 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1450 - accuracy: 0.95 - ETA: 2:44 - loss: 0.1449 - accuracy: 0.95 - ETA: 2:42 - loss: 0.1441 - accuracy: 0.95 - ETA: 2:41 - loss: 0.1450 - accuracy: 0.95 - ETA: 2:39 - loss: 0.1429 - accuracy: 0.95 - ETA: 2:38 - loss: 0.1403 - accuracy: 0.95 - ETA: 2:36 - loss: 0.1412 - accuracy: 0.95 - ETA: 2:35 - loss: 0.1397 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1393 - accuracy: 0.95 - ETA: 2:33 - loss: 0.1387 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1362 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1365 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1365 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1390 - accuracy: 0.96 - ETA: 2:25 - loss: 0.1385 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1394 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1398 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1392 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1409 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1414 - accuracy: 0.95 - ETA: 2:18 - loss: 0.1418 - accuracy: 0.95 - ETA: 2:16 - loss: 0.1418 - accuracy: 0.95 - ETA: 2:15 - loss: 0.1408 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1430 - accuracy: 0.95 - ETA: 2:12 - loss: 0.1421 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1420 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1427 - accuracy: 0.95 - ETA: 2:08 - loss: 0.1414 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1463 - accuracy: 0.95 - ETA: 2:05 - loss: 0.1455 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1479 - accuracy: 0.95 - ETA: 2:03 - loss: 0.1490 - accuracy: 0.95 - ETA: 2:01 - loss: 0.1498 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1500 - accuracy: 0.95 - ETA: 1:58 - loss: 0.1508 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1497 - accuracy: 0.95 - ETA: 1:56 - loss: 0.1495 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1496 - accuracy: 0.95 - ETA: 1:53 - loss: 0.1484 - accuracy: 0.95 - ETA: 1:51 - loss: 0.1492 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1480 - accuracy: 0.95 - ETA: 1:49 - loss: 0.1473 - accuracy: 0.95 - ETA: 1:47 - loss: 0.1471 - accuracy: 0.95 - ETA: 1:46 - loss: 0.1455 - accuracy: 0.95 - ETA: 1:44 - loss: 0.1464 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1456 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1451 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1438 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1457 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1455 - accuracy: 0.95 - ETA: 1:36 - loss: 0.1453 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1459 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1453 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1450 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1447 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1444 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1442 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1442 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1450 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1442 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1440 - accuracy: 0.95 - ETA: 1:21 - loss: 0.1434 - accuracy: 0.95 - ETA: 1:20 - loss: 0.1450 - accuracy: 0.95 - ETA: 1:19 - loss: 0.1445 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1445 - accuracy: 0.95 - ETA: 1:16 - loss: 0.1438 - accuracy: 0.95 - ETA: 1:14 - loss: 0.1450 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1445 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1437 - accuracy: 0.96 - ETA: 1:10 - loss: 0.1435 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1430 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1428 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1425 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1429 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1423 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1443 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1449 - accuracy: 0.96 - ETA: 59s - loss: 0.1448 - accuracy: 0.9603 - ETA: 58s - loss: 0.1439 - accuracy: 0.960 - ETA: 57s - loss: 0.1446 - accuracy: 0.960 - ETA: 55s - loss: 0.1434 - accuracy: 0.960 - ETA: 54s - loss: 0.1429 - accuracy: 0.960 - ETA: 53s - loss: 0.1426 - accuracy: 0.960 - ETA: 51s - loss: 0.1427 - accuracy: 0.960 - ETA: 50s - loss: 0.1426 - accuracy: 0.960 - ETA: 48s - loss: 0.1425 - accuracy: 0.960 - ETA: 47s - loss: 0.1429 - accuracy: 0.960 - ETA: 46s - loss: 0.1425 - accuracy: 0.960 - ETA: 44s - loss: 0.1423 - accuracy: 0.960 - ETA: 43s - loss: 0.1427 - accuracy: 0.960 - ETA: 42s - loss: 0.1418 - accuracy: 0.961 - ETA: 40s - loss: 0.1419 - accuracy: 0.960 - ETA: 39s - loss: 0.1421 - accuracy: 0.960 - ETA: 38s - loss: 0.1422 - accuracy: 0.960 - ETA: 36s - loss: 0.1438 - accuracy: 0.960 - ETA: 35s - loss: 0.1452 - accuracy: 0.960 - ETA: 33s - loss: 0.1456 - accuracy: 0.960 - ETA: 32s - loss: 0.1467 - accuracy: 0.959 - ETA: 31s - loss: 0.1466 - accuracy: 0.959 - ETA: 29s - loss: 0.1483 - accuracy: 0.959 - ETA: 28s - loss: 0.1481 - accuracy: 0.959 - ETA: 27s - loss: 0.1481 - accuracy: 0.959 - ETA: 25s - loss: 0.1481 - accuracy: 0.959 - ETA: 24s - loss: 0.1485 - accuracy: 0.959 - ETA: 23s - loss: 0.1481 - accuracy: 0.959 - ETA: 21s - loss: 0.1478 - accuracy: 0.959 - ETA: 20s - loss: 0.1481 - accuracy: 0.959 - ETA: 18s - loss: 0.1476 - accuracy: 0.959 - ETA: 17s - loss: 0.1477 - accuracy: 0.959 - ETA: 16s - loss: 0.1474 - accuracy: 0.959 - ETA: 14s - loss: 0.1475 - accuracy: 0.959 - ETA: 13s - loss: 0.1470 - accuracy: 0.959 - ETA: 12s - loss: 0.1479 - accuracy: 0.959 - ETA: 10s - loss: 0.1482 - accuracy: 0.959 - ETA: 9s - loss: 0.1483 - accuracy: 0.959 - ETA: 8s - loss: 0.1480 - accuracy: 0.95 - ETA: 6s - loss: 0.1477 - accuracy: 0.95 - ETA: 5s - loss: 0.1474 - accuracy: 0.95 - ETA: 3s - loss: 0.1469 - accuracy: 0.95 - ETA: 2s - loss: 0.1473 - accuracy: 0.95 - ETA: 1s - loss: 0.1477 - accuracy: 0.95 - 218s 11ms/step - loss: 0.1480 - accuracy: 0.9597 - val_loss: 1.7399 - val_accuracy: 0.7923\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:31 - loss: 0.1647 - accuracy: 0.94 - ETA: 3:25 - loss: 0.1779 - accuracy: 0.96 - ETA: 3:21 - loss: 0.2107 - accuracy: 0.94 - ETA: 3:20 - loss: 0.1830 - accuracy: 0.95 - ETA: 3:19 - loss: 0.1904 - accuracy: 0.94 - ETA: 3:20 - loss: 0.1679 - accuracy: 0.95 - ETA: 3:19 - loss: 0.1831 - accuracy: 0.94 - ETA: 3:18 - loss: 0.1740 - accuracy: 0.95 - ETA: 3:16 - loss: 0.1681 - accuracy: 0.94 - ETA: 3:14 - loss: 0.1656 - accuracy: 0.95 - ETA: 3:12 - loss: 0.1597 - accuracy: 0.95 - ETA: 3:10 - loss: 0.1578 - accuracy: 0.95 - ETA: 3:09 - loss: 0.1686 - accuracy: 0.95 - ETA: 3:08 - loss: 0.1645 - accuracy: 0.95 - ETA: 3:06 - loss: 0.1578 - accuracy: 0.95 - ETA: 3:05 - loss: 0.1687 - accuracy: 0.95 - ETA: 3:04 - loss: 0.1683 - accuracy: 0.95 - ETA: 3:03 - loss: 0.1625 - accuracy: 0.95 - ETA: 3:02 - loss: 0.1578 - accuracy: 0.95 - ETA: 3:00 - loss: 0.1654 - accuracy: 0.95 - ETA: 2:58 - loss: 0.1631 - accuracy: 0.95 - ETA: 2:57 - loss: 0.1596 - accuracy: 0.95 - ETA: 2:55 - loss: 0.1607 - accuracy: 0.95 - ETA: 2:54 - loss: 0.1587 - accuracy: 0.95 - ETA: 2:52 - loss: 0.1571 - accuracy: 0.95 - ETA: 2:51 - loss: 0.1587 - accuracy: 0.95 - ETA: 2:49 - loss: 0.1699 - accuracy: 0.95 - ETA: 2:48 - loss: 0.1681 - accuracy: 0.95 - ETA: 2:47 - loss: 0.1683 - accuracy: 0.95 - ETA: 2:46 - loss: 0.1659 - accuracy: 0.95 - ETA: 2:44 - loss: 0.1665 - accuracy: 0.95 - ETA: 2:43 - loss: 0.1634 - accuracy: 0.95 - ETA: 2:42 - loss: 0.1621 - accuracy: 0.95 - ETA: 2:40 - loss: 0.1631 - accuracy: 0.95 - ETA: 2:39 - loss: 0.1623 - accuracy: 0.95 - ETA: 2:37 - loss: 0.1644 - accuracy: 0.95 - ETA: 2:36 - loss: 0.1632 - accuracy: 0.95 - ETA: 2:34 - loss: 0.1642 - accuracy: 0.95 - ETA: 2:33 - loss: 0.1628 - accuracy: 0.95 - ETA: 2:31 - loss: 0.1640 - accuracy: 0.95 - ETA: 2:30 - loss: 0.1645 - accuracy: 0.95 - ETA: 2:29 - loss: 0.1641 - accuracy: 0.95 - ETA: 2:27 - loss: 0.1636 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1660 - accuracy: 0.95 - ETA: 2:25 - loss: 0.1659 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1641 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1641 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1620 - accuracy: 0.95 - ETA: 2:20 - loss: 0.1596 - accuracy: 0.95 - ETA: 2:18 - loss: 0.1604 - accuracy: 0.95 - ETA: 2:17 - loss: 0.1603 - accuracy: 0.95 - ETA: 2:15 - loss: 0.1594 - accuracy: 0.95 - ETA: 2:14 - loss: 0.1571 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1573 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1566 - accuracy: 0.95 - ETA: 2:10 - loss: 0.1544 - accuracy: 0.95 - ETA: 2:08 - loss: 0.1553 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1549 - accuracy: 0.95 - ETA: 2:06 - loss: 0.1540 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1535 - accuracy: 0.95 - ETA: 2:03 - loss: 0.1529 - accuracy: 0.95 - ETA: 2:02 - loss: 0.1556 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1553 - accuracy: 0.95 - ETA: 1:59 - loss: 0.1554 - accuracy: 0.95 - ETA: 1:58 - loss: 0.1547 - accuracy: 0.95 - ETA: 1:56 - loss: 0.1535 - accuracy: 0.95 - ETA: 1:55 - loss: 0.1522 - accuracy: 0.95 - ETA: 1:53 - loss: 0.1537 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1535 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1515 - accuracy: 0.95 - ETA: 1:49 - loss: 0.1501 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1489 - accuracy: 0.95 - ETA: 1:46 - loss: 0.1488 - accuracy: 0.95 - ETA: 1:45 - loss: 0.1472 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1473 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1467 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1463 - accuracy: 0.96 - ETA: 1:39 - loss: 0.1451 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1466 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1463 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1452 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1464 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1458 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1453 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1464 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1480 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1472 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1466 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1455 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1455 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1451 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1459 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1466 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1463 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1455 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1465 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1464 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1453 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1463 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1457 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1458 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1458 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1457 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1447 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1447 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1449 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1450 - accuracy: 0.96 - ETA: 58s - loss: 0.1451 - accuracy: 0.9603 - ETA: 57s - loss: 0.1455 - accuracy: 0.960 - ETA: 55s - loss: 0.1461 - accuracy: 0.960 - ETA: 54s - loss: 0.1457 - accuracy: 0.960 - ETA: 53s - loss: 0.1451 - accuracy: 0.960 - ETA: 51s - loss: 0.1448 - accuracy: 0.960 - ETA: 50s - loss: 0.1449 - accuracy: 0.960 - ETA: 49s - loss: 0.1446 - accuracy: 0.960 - ETA: 47s - loss: 0.1443 - accuracy: 0.960 - ETA: 46s - loss: 0.1440 - accuracy: 0.960 - ETA: 45s - loss: 0.1448 - accuracy: 0.960 - ETA: 43s - loss: 0.1446 - accuracy: 0.960 - ETA: 42s - loss: 0.1452 - accuracy: 0.960 - ETA: 40s - loss: 0.1448 - accuracy: 0.960 - ETA: 39s - loss: 0.1444 - accuracy: 0.960 - ETA: 38s - loss: 0.1452 - accuracy: 0.960 - ETA: 36s - loss: 0.1448 - accuracy: 0.960 - ETA: 35s - loss: 0.1456 - accuracy: 0.960 - ETA: 34s - loss: 0.1448 - accuracy: 0.960 - ETA: 32s - loss: 0.1442 - accuracy: 0.960 - ETA: 31s - loss: 0.1445 - accuracy: 0.961 - ETA: 29s - loss: 0.1438 - accuracy: 0.961 - ETA: 28s - loss: 0.1436 - accuracy: 0.961 - ETA: 27s - loss: 0.1433 - accuracy: 0.961 - ETA: 25s - loss: 0.1429 - accuracy: 0.961 - ETA: 24s - loss: 0.1434 - accuracy: 0.961 - ETA: 23s - loss: 0.1431 - accuracy: 0.961 - ETA: 21s - loss: 0.1435 - accuracy: 0.961 - ETA: 20s - loss: 0.1444 - accuracy: 0.961 - ETA: 18s - loss: 0.1444 - accuracy: 0.961 - ETA: 17s - loss: 0.1446 - accuracy: 0.961 - ETA: 16s - loss: 0.1446 - accuracy: 0.961 - ETA: 14s - loss: 0.1449 - accuracy: 0.961 - ETA: 13s - loss: 0.1450 - accuracy: 0.961 - ETA: 12s - loss: 0.1447 - accuracy: 0.961 - ETA: 10s - loss: 0.1446 - accuracy: 0.961 - ETA: 9s - loss: 0.1445 - accuracy: 0.961 - ETA: 8s - loss: 0.1448 - accuracy: 0.96 - ETA: 6s - loss: 0.1443 - accuracy: 0.96 - ETA: 5s - loss: 0.1442 - accuracy: 0.96 - ETA: 3s - loss: 0.1438 - accuracy: 0.96 - ETA: 2s - loss: 0.1439 - accuracy: 0.96 - ETA: 1s - loss: 0.1439 - accuracy: 0.96 - 219s 11ms/step - loss: 0.1442 - accuracy: 0.9610 - val_loss: 1.7378 - val_accuracy: 0.7902\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:23 - loss: 0.2960 - accuracy: 0.95 - ETA: 3:21 - loss: 0.1727 - accuracy: 0.97 - ETA: 3:23 - loss: 0.1748 - accuracy: 0.96 - ETA: 3:20 - loss: 0.1565 - accuracy: 0.96 - ETA: 3:18 - loss: 0.1582 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1496 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1501 - accuracy: 0.96 - ETA: 3:14 - loss: 0.1457 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1390 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1438 - accuracy: 0.96 - ETA: 3:11 - loss: 0.1366 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1313 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1341 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1350 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1298 - accuracy: 0.96 - ETA: 3:04 - loss: 0.1315 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1354 - accuracy: 0.96 - ETA: 3:01 - loss: 0.1302 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1257 - accuracy: 0.96 - ETA: 2:58 - loss: 0.1280 - accuracy: 0.96 - ETA: 2:58 - loss: 0.1231 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1194 - accuracy: 0.96 - ETA: 2:55 - loss: 0.1223 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1196 - accuracy: 0.96 - ETA: 2:52 - loss: 0.1182 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1168 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1166 - accuracy: 0.96 - ETA: 2:48 - loss: 0.1180 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1167 - accuracy: 0.96 - ETA: 2:45 - loss: 0.1156 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1139 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1178 - accuracy: 0.96 - ETA: 2:41 - loss: 0.1170 - accuracy: 0.96 - ETA: 2:40 - loss: 0.1231 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1226 - accuracy: 0.96 - ETA: 2:37 - loss: 0.1226 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1219 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1210 - accuracy: 0.96 - ETA: 2:33 - loss: 0.1194 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1187 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1184 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1181 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1194 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1224 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1238 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1259 - accuracy: 0.96 - ETA: 2:22 - loss: 0.1256 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1261 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1266 - accuracy: 0.96 - ETA: 2:17 - loss: 0.1272 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1277 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1266 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1282 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1285 - accuracy: 0.96 - ETA: 2:11 - loss: 0.1311 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1314 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1317 - accuracy: 0.96 - ETA: 2:07 - loss: 0.1322 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1301 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1352 - accuracy: 0.96 - ETA: 2:03 - loss: 0.1335 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1348 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1352 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1348 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1351 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1338 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1334 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1349 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1333 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1327 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1317 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1301 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1297 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1297 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1287 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1295 - accuracy: 0.96 - ETA: 1:41 - loss: 0.1283 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1291 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1303 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1338 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1329 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1339 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1363 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1374 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1375 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1377 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1390 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1392 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1392 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1387 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1387 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1380 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1397 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1416 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1421 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1414 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1417 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1425 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1424 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1420 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1422 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1414 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1408 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1406 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1396 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1395 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1390 - accuracy: 0.96 - ETA: 58s - loss: 0.1402 - accuracy: 0.9625 - ETA: 57s - loss: 0.1401 - accuracy: 0.962 - ETA: 55s - loss: 0.1403 - accuracy: 0.962 - ETA: 54s - loss: 0.1399 - accuracy: 0.962 - ETA: 53s - loss: 0.1391 - accuracy: 0.962 - ETA: 51s - loss: 0.1386 - accuracy: 0.962 - ETA: 50s - loss: 0.1381 - accuracy: 0.962 - ETA: 49s - loss: 0.1374 - accuracy: 0.962 - ETA: 47s - loss: 0.1380 - accuracy: 0.962 - ETA: 46s - loss: 0.1384 - accuracy: 0.962 - ETA: 45s - loss: 0.1388 - accuracy: 0.962 - ETA: 43s - loss: 0.1400 - accuracy: 0.962 - ETA: 42s - loss: 0.1407 - accuracy: 0.962 - ETA: 40s - loss: 0.1405 - accuracy: 0.962 - ETA: 39s - loss: 0.1408 - accuracy: 0.962 - ETA: 38s - loss: 0.1406 - accuracy: 0.962 - ETA: 36s - loss: 0.1418 - accuracy: 0.962 - ETA: 35s - loss: 0.1420 - accuracy: 0.962 - ETA: 34s - loss: 0.1419 - accuracy: 0.962 - ETA: 32s - loss: 0.1424 - accuracy: 0.962 - ETA: 31s - loss: 0.1430 - accuracy: 0.961 - ETA: 29s - loss: 0.1424 - accuracy: 0.962 - ETA: 28s - loss: 0.1423 - accuracy: 0.961 - ETA: 27s - loss: 0.1423 - accuracy: 0.961 - ETA: 25s - loss: 0.1433 - accuracy: 0.961 - ETA: 24s - loss: 0.1432 - accuracy: 0.961 - ETA: 23s - loss: 0.1434 - accuracy: 0.961 - ETA: 21s - loss: 0.1433 - accuracy: 0.961 - ETA: 20s - loss: 0.1445 - accuracy: 0.961 - ETA: 18s - loss: 0.1441 - accuracy: 0.961 - ETA: 17s - loss: 0.1439 - accuracy: 0.961 - ETA: 16s - loss: 0.1436 - accuracy: 0.961 - ETA: 14s - loss: 0.1439 - accuracy: 0.961 - ETA: 13s - loss: 0.1442 - accuracy: 0.961 - ETA: 12s - loss: 0.1449 - accuracy: 0.961 - ETA: 10s - loss: 0.1444 - accuracy: 0.961 - ETA: 9s - loss: 0.1448 - accuracy: 0.961 - ETA: 8s - loss: 0.1448 - accuracy: 0.96 - ETA: 6s - loss: 0.1449 - accuracy: 0.96 - ETA: 5s - loss: 0.1453 - accuracy: 0.96 - ETA: 3s - loss: 0.1448 - accuracy: 0.96 - ETA: 2s - loss: 0.1450 - accuracy: 0.96 - ETA: 1s - loss: 0.1446 - accuracy: 0.96 - 220s 11ms/step - loss: 0.1450 - accuracy: 0.9613 - val_loss: 1.7161 - val_accuracy: 0.7962\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:26 - loss: 0.0204 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0806 - accuracy: 0.96 - ETA: 3:26 - loss: 0.1095 - accuracy: 0.97 - ETA: 3:24 - loss: 0.1026 - accuracy: 0.97 - ETA: 3:23 - loss: 0.1022 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0990 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0995 - accuracy: 0.97 - ETA: 3:16 - loss: 0.1033 - accuracy: 0.96 - ETA: 3:14 - loss: 0.1046 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1143 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1152 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1157 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1133 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1179 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1168 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1139 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1127 - accuracy: 0.96 - ETA: 3:02 - loss: 0.1128 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1122 - accuracy: 0.96 - ETA: 2:59 - loss: 0.1163 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1191 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1185 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1174 - accuracy: 0.96 - ETA: 2:53 - loss: 0.1151 - accuracy: 0.96 - ETA: 2:52 - loss: 0.1113 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1155 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1155 - accuracy: 0.96 - ETA: 2:47 - loss: 0.1151 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1129 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1129 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1101 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1118 - accuracy: 0.96 - ETA: 2:40 - loss: 0.1153 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1153 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1157 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1165 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1187 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1195 - accuracy: 0.96 - ETA: 2:33 - loss: 0.1196 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1207 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1212 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1211 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1246 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1275 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1269 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1246 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1252 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1259 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1249 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1238 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1237 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1275 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1271 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1291 - accuracy: 0.96 - ETA: 2:11 - loss: 0.1289 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1297 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1308 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1309 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1300 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1309 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1301 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1292 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1293 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1288 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1301 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1284 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1273 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1265 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1252 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1262 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1256 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1251 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1238 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1240 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1235 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1240 - accuracy: 0.96 - ETA: 1:41 - loss: 0.1232 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1217 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1210 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1221 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1229 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1225 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1233 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1239 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1240 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1249 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1251 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1251 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1250 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1248 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1257 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1258 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1250 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1248 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1245 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1233 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1227 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1222 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1216 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1215 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1217 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1220 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1222 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1230 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1246 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1242 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1239 - accuracy: 0.96 - ETA: 58s - loss: 0.1248 - accuracy: 0.9653 - ETA: 57s - loss: 0.1255 - accuracy: 0.965 - ETA: 56s - loss: 0.1250 - accuracy: 0.965 - ETA: 54s - loss: 0.1244 - accuracy: 0.965 - ETA: 53s - loss: 0.1245 - accuracy: 0.965 - ETA: 51s - loss: 0.1239 - accuracy: 0.965 - ETA: 50s - loss: 0.1240 - accuracy: 0.965 - ETA: 49s - loss: 0.1235 - accuracy: 0.965 - ETA: 47s - loss: 0.1258 - accuracy: 0.964 - ETA: 46s - loss: 0.1251 - accuracy: 0.965 - ETA: 45s - loss: 0.1264 - accuracy: 0.964 - ETA: 43s - loss: 0.1262 - accuracy: 0.964 - ETA: 42s - loss: 0.1262 - accuracy: 0.964 - ETA: 40s - loss: 0.1264 - accuracy: 0.964 - ETA: 39s - loss: 0.1267 - accuracy: 0.964 - ETA: 38s - loss: 0.1266 - accuracy: 0.964 - ETA: 36s - loss: 0.1264 - accuracy: 0.964 - ETA: 35s - loss: 0.1272 - accuracy: 0.964 - ETA: 34s - loss: 0.1275 - accuracy: 0.964 - ETA: 32s - loss: 0.1271 - accuracy: 0.964 - ETA: 31s - loss: 0.1279 - accuracy: 0.964 - ETA: 29s - loss: 0.1276 - accuracy: 0.964 - ETA: 28s - loss: 0.1270 - accuracy: 0.964 - ETA: 27s - loss: 0.1263 - accuracy: 0.964 - ETA: 25s - loss: 0.1261 - accuracy: 0.964 - ETA: 24s - loss: 0.1268 - accuracy: 0.964 - ETA: 23s - loss: 0.1264 - accuracy: 0.964 - ETA: 21s - loss: 0.1259 - accuracy: 0.964 - ETA: 20s - loss: 0.1262 - accuracy: 0.964 - ETA: 19s - loss: 0.1260 - accuracy: 0.964 - ETA: 17s - loss: 0.1261 - accuracy: 0.964 - ETA: 16s - loss: 0.1269 - accuracy: 0.964 - ETA: 14s - loss: 0.1269 - accuracy: 0.964 - ETA: 13s - loss: 0.1278 - accuracy: 0.964 - ETA: 12s - loss: 0.1287 - accuracy: 0.964 - ETA: 10s - loss: 0.1292 - accuracy: 0.964 - ETA: 9s - loss: 0.1289 - accuracy: 0.964 - ETA: 8s - loss: 0.1299 - accuracy: 0.96 - ETA: 6s - loss: 0.1291 - accuracy: 0.96 - ETA: 5s - loss: 0.1289 - accuracy: 0.96 - ETA: 3s - loss: 0.1296 - accuracy: 0.96 - ETA: 2s - loss: 0.1297 - accuracy: 0.96 - ETA: 1s - loss: 0.1299 - accuracy: 0.96 - 218s 11ms/step - loss: 0.1300 - accuracy: 0.9642 - val_loss: 1.7358 - val_accuracy: 0.7925\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:35 - loss: 0.1718 - accuracy: 0.96 - ETA: 3:28 - loss: 0.1372 - accuracy: 0.96 - ETA: 3:29 - loss: 0.1417 - accuracy: 0.96 - ETA: 3:26 - loss: 0.1280 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1198 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1056 - accuracy: 0.96 - ETA: 3:23 - loss: 0.1269 - accuracy: 0.96 - ETA: 3:22 - loss: 0.1175 - accuracy: 0.96 - ETA: 3:19 - loss: 0.1122 - accuracy: 0.96 - ETA: 3:18 - loss: 0.1195 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1176 - accuracy: 0.96 - ETA: 3:14 - loss: 0.1084 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1070 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1017 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1005 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1002 - accuracy: 0.96 - ETA: 3:06 - loss: 0.0982 - accuracy: 0.97 - ETA: 3:05 - loss: 0.1004 - accuracy: 0.96 - ETA: 3:03 - loss: 0.0994 - accuracy: 0.96 - ETA: 3:02 - loss: 0.1019 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1072 - accuracy: 0.96 - ETA: 2:59 - loss: 0.1086 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1189 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1172 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1154 - accuracy: 0.96 - ETA: 2:52 - loss: 0.1144 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1119 - accuracy: 0.96 - ETA: 2:50 - loss: 0.1099 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1125 - accuracy: 0.96 - ETA: 2:47 - loss: 0.1110 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1100 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1097 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1085 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1099 - accuracy: 0.96 - ETA: 2:40 - loss: 0.1115 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1122 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1161 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1203 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1225 - accuracy: 0.96 - ETA: 2:33 - loss: 0.1217 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1195 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1199 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1183 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1167 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1166 - accuracy: 0.96 - ETA: 2:25 - loss: 0.1166 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1173 - accuracy: 0.96 - ETA: 2:22 - loss: 0.1163 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1165 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1163 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1166 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1186 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1200 - accuracy: 0.96 - ETA: 2:14 - loss: 0.1201 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1203 - accuracy: 0.96 - ETA: 2:11 - loss: 0.1221 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1218 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1216 - accuracy: 0.96 - ETA: 2:07 - loss: 0.1211 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1210 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1212 - accuracy: 0.96 - ETA: 2:03 - loss: 0.1222 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1240 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1237 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1262 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1255 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1250 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1242 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1254 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1259 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1257 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1252 - accuracy: 0.96 - ETA: 1:47 - loss: 0.1238 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1231 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1251 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1240 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1228 - accuracy: 0.96 - ETA: 1:41 - loss: 0.1226 - accuracy: 0.96 - ETA: 1:39 - loss: 0.1232 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1219 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1231 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1216 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1222 - accuracy: 0.96 - ETA: 1:32 - loss: 0.1233 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1227 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1225 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1219 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1214 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1209 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1208 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1213 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1209 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1203 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1200 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1202 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1200 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1206 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1211 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1207 - accuracy: 0.96 - ETA: 1:10 - loss: 0.1202 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1196 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1205 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1204 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1196 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1189 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1193 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1196 - accuracy: 0.96 - ETA: 59s - loss: 0.1192 - accuracy: 0.9668 - ETA: 57s - loss: 0.1202 - accuracy: 0.966 - ETA: 56s - loss: 0.1197 - accuracy: 0.966 - ETA: 55s - loss: 0.1193 - accuracy: 0.966 - ETA: 53s - loss: 0.1187 - accuracy: 0.966 - ETA: 52s - loss: 0.1193 - accuracy: 0.966 - ETA: 50s - loss: 0.1196 - accuracy: 0.966 - ETA: 49s - loss: 0.1193 - accuracy: 0.966 - ETA: 48s - loss: 0.1200 - accuracy: 0.966 - ETA: 46s - loss: 0.1204 - accuracy: 0.966 - ETA: 45s - loss: 0.1211 - accuracy: 0.966 - ETA: 43s - loss: 0.1204 - accuracy: 0.966 - ETA: 42s - loss: 0.1204 - accuracy: 0.966 - ETA: 41s - loss: 0.1209 - accuracy: 0.966 - ETA: 39s - loss: 0.1211 - accuracy: 0.966 - ETA: 38s - loss: 0.1209 - accuracy: 0.966 - ETA: 37s - loss: 0.1210 - accuracy: 0.966 - ETA: 35s - loss: 0.1207 - accuracy: 0.966 - ETA: 34s - loss: 0.1202 - accuracy: 0.966 - ETA: 32s - loss: 0.1203 - accuracy: 0.966 - ETA: 31s - loss: 0.1199 - accuracy: 0.966 - ETA: 30s - loss: 0.1197 - accuracy: 0.966 - ETA: 28s - loss: 0.1198 - accuracy: 0.966 - ETA: 27s - loss: 0.1191 - accuracy: 0.966 - ETA: 25s - loss: 0.1200 - accuracy: 0.966 - ETA: 24s - loss: 0.1197 - accuracy: 0.966 - ETA: 23s - loss: 0.1195 - accuracy: 0.966 - ETA: 21s - loss: 0.1191 - accuracy: 0.966 - ETA: 20s - loss: 0.1190 - accuracy: 0.966 - ETA: 19s - loss: 0.1185 - accuracy: 0.966 - ETA: 17s - loss: 0.1181 - accuracy: 0.966 - ETA: 16s - loss: 0.1182 - accuracy: 0.966 - ETA: 14s - loss: 0.1182 - accuracy: 0.966 - ETA: 13s - loss: 0.1186 - accuracy: 0.966 - ETA: 12s - loss: 0.1179 - accuracy: 0.966 - ETA: 10s - loss: 0.1181 - accuracy: 0.966 - ETA: 9s - loss: 0.1185 - accuracy: 0.966 - ETA: 8s - loss: 0.1181 - accuracy: 0.96 - ETA: 6s - loss: 0.1179 - accuracy: 0.96 - ETA: 5s - loss: 0.1181 - accuracy: 0.96 - ETA: 3s - loss: 0.1182 - accuracy: 0.96 - ETA: 2s - loss: 0.1185 - accuracy: 0.96 - ETA: 1s - loss: 0.1184 - accuracy: 0.96 - 219s 11ms/step - loss: 0.1184 - accuracy: 0.9666 - val_loss: 1.9956 - val_accuracy: 0.7908\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:15 - loss: 0.0723 - accuracy: 0.97 - ETA: 3:24 - loss: 0.1461 - accuracy: 0.97 - ETA: 3:20 - loss: 0.1938 - accuracy: 0.97 - ETA: 3:18 - loss: 0.1622 - accuracy: 0.97 - ETA: 3:17 - loss: 0.1701 - accuracy: 0.97 - ETA: 3:17 - loss: 0.1617 - accuracy: 0.97 - ETA: 3:16 - loss: 0.1758 - accuracy: 0.96 - ETA: 3:14 - loss: 0.1652 - accuracy: 0.96 - ETA: 3:14 - loss: 0.1633 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1582 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1562 - accuracy: 0.96 - ETA: 3:11 - loss: 0.1573 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1589 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1592 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1686 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1699 - accuracy: 0.96 - ETA: 3:02 - loss: 0.1675 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1592 - accuracy: 0.96 - ETA: 2:59 - loss: 0.1626 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1587 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1572 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1587 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1619 - accuracy: 0.96 - ETA: 2:53 - loss: 0.1626 - accuracy: 0.96 - ETA: 2:52 - loss: 0.1623 - accuracy: 0.96 - ETA: 2:50 - loss: 0.1637 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1664 - accuracy: 0.96 - ETA: 2:47 - loss: 0.1610 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1619 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1610 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1589 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1553 - accuracy: 0.96 - ETA: 2:41 - loss: 0.1550 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1534 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1535 - accuracy: 0.96 - ETA: 2:37 - loss: 0.1564 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1553 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1522 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1534 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1535 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1527 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1547 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1574 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1563 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1580 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1604 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1578 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1554 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1552 - accuracy: 0.96 - ETA: 2:17 - loss: 0.1532 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1521 - accuracy: 0.96 - ETA: 2:14 - loss: 0.1510 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1513 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1523 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1518 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1496 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1485 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1466 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1456 - accuracy: 0.96 - ETA: 2:03 - loss: 0.1452 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1436 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1432 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1429 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1438 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1441 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1443 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1430 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1424 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1421 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1411 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1444 - accuracy: 0.96 - ETA: 1:47 - loss: 0.1457 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1470 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1479 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1473 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1478 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1460 - accuracy: 0.96 - ETA: 1:39 - loss: 0.1473 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1476 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1476 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1461 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1446 - accuracy: 0.96 - ETA: 1:32 - loss: 0.1442 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1446 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1445 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1453 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1466 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1466 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1466 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1460 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1459 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1456 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1446 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1436 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1438 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1429 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1444 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1433 - accuracy: 0.96 - ETA: 1:10 - loss: 0.1424 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1420 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1424 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1419 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1427 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1421 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1434 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1423 - accuracy: 0.96 - ETA: 59s - loss: 0.1416 - accuracy: 0.9649 - ETA: 58s - loss: 0.1417 - accuracy: 0.964 - ETA: 57s - loss: 0.1418 - accuracy: 0.964 - ETA: 55s - loss: 0.1410 - accuracy: 0.964 - ETA: 54s - loss: 0.1403 - accuracy: 0.964 - ETA: 52s - loss: 0.1401 - accuracy: 0.964 - ETA: 51s - loss: 0.1400 - accuracy: 0.964 - ETA: 50s - loss: 0.1390 - accuracy: 0.965 - ETA: 48s - loss: 0.1405 - accuracy: 0.964 - ETA: 47s - loss: 0.1403 - accuracy: 0.964 - ETA: 46s - loss: 0.1403 - accuracy: 0.964 - ETA: 44s - loss: 0.1411 - accuracy: 0.964 - ETA: 43s - loss: 0.1410 - accuracy: 0.964 - ETA: 42s - loss: 0.1407 - accuracy: 0.964 - ETA: 40s - loss: 0.1408 - accuracy: 0.964 - ETA: 39s - loss: 0.1407 - accuracy: 0.964 - ETA: 37s - loss: 0.1405 - accuracy: 0.964 - ETA: 36s - loss: 0.1400 - accuracy: 0.964 - ETA: 35s - loss: 0.1405 - accuracy: 0.964 - ETA: 33s - loss: 0.1414 - accuracy: 0.964 - ETA: 32s - loss: 0.1409 - accuracy: 0.964 - ETA: 31s - loss: 0.1422 - accuracy: 0.964 - ETA: 29s - loss: 0.1417 - accuracy: 0.964 - ETA: 28s - loss: 0.1411 - accuracy: 0.964 - ETA: 27s - loss: 0.1401 - accuracy: 0.964 - ETA: 25s - loss: 0.1399 - accuracy: 0.964 - ETA: 24s - loss: 0.1408 - accuracy: 0.964 - ETA: 23s - loss: 0.1414 - accuracy: 0.964 - ETA: 21s - loss: 0.1414 - accuracy: 0.964 - ETA: 20s - loss: 0.1407 - accuracy: 0.964 - ETA: 18s - loss: 0.1407 - accuracy: 0.964 - ETA: 17s - loss: 0.1408 - accuracy: 0.964 - ETA: 16s - loss: 0.1403 - accuracy: 0.964 - ETA: 14s - loss: 0.1400 - accuracy: 0.964 - ETA: 13s - loss: 0.1404 - accuracy: 0.964 - ETA: 12s - loss: 0.1400 - accuracy: 0.964 - ETA: 10s - loss: 0.1394 - accuracy: 0.964 - ETA: 9s - loss: 0.1390 - accuracy: 0.965 - ETA: 8s - loss: 0.1398 - accuracy: 0.96 - ETA: 6s - loss: 0.1399 - accuracy: 0.96 - ETA: 5s - loss: 0.1398 - accuracy: 0.96 - ETA: 3s - loss: 0.1409 - accuracy: 0.96 - ETA: 2s - loss: 0.1421 - accuracy: 0.96 - ETA: 1s - loss: 0.1423 - accuracy: 0.96 - 218s 11ms/step - loss: 0.1428 - accuracy: 0.9643 - val_loss: 1.7560 - val_accuracy: 0.7946\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:25 - loss: 0.1067 - accuracy: 0.96 - ETA: 3:25 - loss: 0.1243 - accuracy: 0.96 - ETA: 3:26 - loss: 0.0989 - accuracy: 0.97 - ETA: 3:23 - loss: 0.1248 - accuracy: 0.96 - ETA: 3:21 - loss: 0.1236 - accuracy: 0.96 - ETA: 3:18 - loss: 0.1336 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1299 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1331 - accuracy: 0.96 - ETA: 3:14 - loss: 0.1269 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1236 - accuracy: 0.96 - ETA: 3:11 - loss: 0.1231 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1235 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1250 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1185 - accuracy: 0.96 - ETA: 3:06 - loss: 0.1186 - accuracy: 0.96 - ETA: 3:04 - loss: 0.1178 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1193 - accuracy: 0.96 - ETA: 3:01 - loss: 0.1178 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1139 - accuracy: 0.97 - ETA: 2:58 - loss: 0.1177 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1244 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1230 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1227 - accuracy: 0.96 - ETA: 2:52 - loss: 0.1201 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1166 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1190 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1200 - accuracy: 0.96 - ETA: 2:48 - loss: 0.1182 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1155 - accuracy: 0.96 - ETA: 2:45 - loss: 0.1154 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1182 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1165 - accuracy: 0.96 - ETA: 2:40 - loss: 0.1171 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1141 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1160 - accuracy: 0.96 - ETA: 2:37 - loss: 0.1148 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1125 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1103 - accuracy: 0.96 - ETA: 2:33 - loss: 0.1126 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1156 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1151 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1143 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1143 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1147 - accuracy: 0.96 - ETA: 2:25 - loss: 0.1132 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1121 - accuracy: 0.96 - ETA: 2:22 - loss: 0.1156 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1141 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1141 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1133 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1127 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1118 - accuracy: 0.96 - ETA: 2:14 - loss: 0.1132 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1151 - accuracy: 0.96 - ETA: 2:11 - loss: 0.1156 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1165 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1162 - accuracy: 0.96 - ETA: 2:07 - loss: 0.1160 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1155 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1152 - accuracy: 0.96 - ETA: 2:03 - loss: 0.1161 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1146 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1147 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1137 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1149 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1138 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1128 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1137 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1138 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1136 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1140 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1156 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1155 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1172 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1202 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1194 - accuracy: 0.96 - ETA: 1:41 - loss: 0.1206 - accuracy: 0.96 - ETA: 1:39 - loss: 0.1209 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1202 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1203 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1204 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1209 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1218 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1228 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1230 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1222 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1223 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1224 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1219 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1212 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1224 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1216 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1214 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1214 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1216 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1212 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1214 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1222 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1215 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1213 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1215 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1225 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1238 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1251 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1242 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1246 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1240 - accuracy: 0.96 - ETA: 58s - loss: 0.1238 - accuracy: 0.9664 - ETA: 57s - loss: 0.1236 - accuracy: 0.966 - ETA: 56s - loss: 0.1247 - accuracy: 0.966 - ETA: 54s - loss: 0.1240 - accuracy: 0.966 - ETA: 53s - loss: 0.1244 - accuracy: 0.966 - ETA: 52s - loss: 0.1239 - accuracy: 0.966 - ETA: 50s - loss: 0.1247 - accuracy: 0.966 - ETA: 49s - loss: 0.1242 - accuracy: 0.966 - ETA: 47s - loss: 0.1241 - accuracy: 0.966 - ETA: 46s - loss: 0.1237 - accuracy: 0.966 - ETA: 45s - loss: 0.1234 - accuracy: 0.966 - ETA: 43s - loss: 0.1237 - accuracy: 0.966 - ETA: 42s - loss: 0.1236 - accuracy: 0.966 - ETA: 41s - loss: 0.1233 - accuracy: 0.966 - ETA: 39s - loss: 0.1234 - accuracy: 0.966 - ETA: 38s - loss: 0.1238 - accuracy: 0.966 - ETA: 36s - loss: 0.1231 - accuracy: 0.966 - ETA: 35s - loss: 0.1226 - accuracy: 0.966 - ETA: 34s - loss: 0.1229 - accuracy: 0.966 - ETA: 32s - loss: 0.1232 - accuracy: 0.966 - ETA: 31s - loss: 0.1226 - accuracy: 0.966 - ETA: 30s - loss: 0.1226 - accuracy: 0.966 - ETA: 28s - loss: 0.1230 - accuracy: 0.966 - ETA: 27s - loss: 0.1231 - accuracy: 0.966 - ETA: 25s - loss: 0.1231 - accuracy: 0.966 - ETA: 24s - loss: 0.1238 - accuracy: 0.966 - ETA: 23s - loss: 0.1240 - accuracy: 0.966 - ETA: 21s - loss: 0.1262 - accuracy: 0.966 - ETA: 20s - loss: 0.1258 - accuracy: 0.966 - ETA: 19s - loss: 0.1258 - accuracy: 0.966 - ETA: 17s - loss: 0.1256 - accuracy: 0.966 - ETA: 16s - loss: 0.1257 - accuracy: 0.966 - ETA: 14s - loss: 0.1254 - accuracy: 0.966 - ETA: 13s - loss: 0.1261 - accuracy: 0.966 - ETA: 12s - loss: 0.1256 - accuracy: 0.966 - ETA: 10s - loss: 0.1255 - accuracy: 0.966 - ETA: 9s - loss: 0.1255 - accuracy: 0.966 - ETA: 8s - loss: 0.1252 - accuracy: 0.96 - ETA: 6s - loss: 0.1254 - accuracy: 0.96 - ETA: 5s - loss: 0.1251 - accuracy: 0.96 - ETA: 3s - loss: 0.1251 - accuracy: 0.96 - ETA: 2s - loss: 0.1252 - accuracy: 0.96 - ETA: 1s - loss: 0.1256 - accuracy: 0.96 - 219s 11ms/step - loss: 0.1253 - accuracy: 0.9668 - val_loss: 1.7942 - val_accuracy: 0.7960\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:24 - loss: 0.1391 - accuracy: 0.96 - ETA: 3:21 - loss: 0.0900 - accuracy: 0.97 - ETA: 3:16 - loss: 0.1028 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0864 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0876 - accuracy: 0.98 - ETA: 3:17 - loss: 0.1013 - accuracy: 0.98 - ETA: 3:14 - loss: 0.1215 - accuracy: 0.97 - ETA: 3:13 - loss: 0.1121 - accuracy: 0.97 - ETA: 3:11 - loss: 0.1083 - accuracy: 0.97 - ETA: 3:10 - loss: 0.1125 - accuracy: 0.97 - ETA: 3:09 - loss: 0.1092 - accuracy: 0.97 - ETA: 3:08 - loss: 0.1121 - accuracy: 0.97 - ETA: 3:07 - loss: 0.1270 - accuracy: 0.97 - ETA: 3:07 - loss: 0.1297 - accuracy: 0.97 - ETA: 3:07 - loss: 0.1280 - accuracy: 0.97 - ETA: 3:06 - loss: 0.1326 - accuracy: 0.97 - ETA: 3:06 - loss: 0.1277 - accuracy: 0.97 - ETA: 3:05 - loss: 0.1320 - accuracy: 0.97 - ETA: 3:03 - loss: 0.1256 - accuracy: 0.97 - ETA: 3:02 - loss: 0.1215 - accuracy: 0.97 - ETA: 3:01 - loss: 0.1242 - accuracy: 0.97 - ETA: 2:59 - loss: 0.1261 - accuracy: 0.97 - ETA: 2:58 - loss: 0.1294 - accuracy: 0.97 - ETA: 2:57 - loss: 0.1274 - accuracy: 0.97 - ETA: 2:55 - loss: 0.1239 - accuracy: 0.97 - ETA: 2:54 - loss: 0.1260 - accuracy: 0.97 - ETA: 2:52 - loss: 0.1282 - accuracy: 0.97 - ETA: 2:51 - loss: 0.1245 - accuracy: 0.97 - ETA: 2:50 - loss: 0.1287 - accuracy: 0.97 - ETA: 2:48 - loss: 0.1249 - accuracy: 0.97 - ETA: 2:47 - loss: 0.1249 - accuracy: 0.97 - ETA: 2:45 - loss: 0.1236 - accuracy: 0.97 - ETA: 2:44 - loss: 0.1252 - accuracy: 0.97 - ETA: 2:42 - loss: 0.1252 - accuracy: 0.97 - ETA: 2:41 - loss: 0.1287 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1286 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1270 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1268 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1273 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1276 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1303 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1335 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1335 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1344 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1323 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1320 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1316 - accuracy: 0.96 - ETA: 2:22 - loss: 0.1332 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1320 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1317 - accuracy: 0.96 - ETA: 2:17 - loss: 0.1312 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1322 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1318 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1302 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1306 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1300 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1298 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1309 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1299 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1289 - accuracy: 0.96 - ETA: 2:03 - loss: 0.1274 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1276 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1269 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1275 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1270 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1254 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1249 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1259 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1247 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1244 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1235 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1231 - accuracy: 0.96 - ETA: 1:47 - loss: 0.1239 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1253 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1259 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1264 - accuracy: 0.96 - ETA: 1:41 - loss: 0.1254 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1250 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1252 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1245 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1243 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1243 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1237 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1243 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1251 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1255 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1242 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1257 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1263 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1266 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1268 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1260 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1263 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1269 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1289 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1294 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1292 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1288 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1285 - accuracy: 0.96 - ETA: 1:10 - loss: 0.1289 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1287 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1276 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1267 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1271 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1271 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1272 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1270 - accuracy: 0.96 - ETA: 58s - loss: 0.1284 - accuracy: 0.9680 - ETA: 57s - loss: 0.1283 - accuracy: 0.968 - ETA: 56s - loss: 0.1283 - accuracy: 0.967 - ETA: 54s - loss: 0.1281 - accuracy: 0.967 - ETA: 53s - loss: 0.1276 - accuracy: 0.968 - ETA: 52s - loss: 0.1272 - accuracy: 0.968 - ETA: 50s - loss: 0.1289 - accuracy: 0.967 - ETA: 49s - loss: 0.1280 - accuracy: 0.967 - ETA: 47s - loss: 0.1288 - accuracy: 0.967 - ETA: 46s - loss: 0.1289 - accuracy: 0.967 - ETA: 45s - loss: 0.1299 - accuracy: 0.967 - ETA: 43s - loss: 0.1297 - accuracy: 0.967 - ETA: 42s - loss: 0.1290 - accuracy: 0.967 - ETA: 40s - loss: 0.1298 - accuracy: 0.967 - ETA: 39s - loss: 0.1310 - accuracy: 0.967 - ETA: 38s - loss: 0.1316 - accuracy: 0.967 - ETA: 36s - loss: 0.1308 - accuracy: 0.967 - ETA: 35s - loss: 0.1305 - accuracy: 0.967 - ETA: 34s - loss: 0.1309 - accuracy: 0.967 - ETA: 32s - loss: 0.1302 - accuracy: 0.967 - ETA: 31s - loss: 0.1296 - accuracy: 0.967 - ETA: 29s - loss: 0.1294 - accuracy: 0.967 - ETA: 28s - loss: 0.1299 - accuracy: 0.967 - ETA: 27s - loss: 0.1294 - accuracy: 0.967 - ETA: 25s - loss: 0.1288 - accuracy: 0.967 - ETA: 24s - loss: 0.1292 - accuracy: 0.967 - ETA: 23s - loss: 0.1288 - accuracy: 0.967 - ETA: 21s - loss: 0.1282 - accuracy: 0.967 - ETA: 20s - loss: 0.1277 - accuracy: 0.967 - ETA: 19s - loss: 0.1274 - accuracy: 0.967 - ETA: 17s - loss: 0.1281 - accuracy: 0.967 - ETA: 16s - loss: 0.1279 - accuracy: 0.967 - ETA: 14s - loss: 0.1283 - accuracy: 0.967 - ETA: 13s - loss: 0.1291 - accuracy: 0.967 - ETA: 12s - loss: 0.1290 - accuracy: 0.967 - ETA: 10s - loss: 0.1289 - accuracy: 0.967 - ETA: 9s - loss: 0.1286 - accuracy: 0.967 - ETA: 8s - loss: 0.1287 - accuracy: 0.96 - ETA: 6s - loss: 0.1281 - accuracy: 0.96 - ETA: 5s - loss: 0.1277 - accuracy: 0.96 - ETA: 3s - loss: 0.1273 - accuracy: 0.96 - ETA: 2s - loss: 0.1276 - accuracy: 0.96 - ETA: 1s - loss: 0.1277 - accuracy: 0.96 - 219s 11ms/step - loss: 0.1277 - accuracy: 0.9676 - val_loss: 1.7580 - val_accuracy: 0.8031\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:19 - loss: 0.0720 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0812 - accuracy: 0.96 - ETA: 3:20 - loss: 0.0783 - accuracy: 0.96 - ETA: 3:18 - loss: 0.0888 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1029 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1153 - accuracy: 0.95 - ETA: 3:13 - loss: 0.1048 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1036 - accuracy: 0.96 - ETA: 3:11 - loss: 0.0978 - accuracy: 0.96 - ETA: 3:11 - loss: 0.0924 - accuracy: 0.96 - ETA: 3:10 - loss: 0.0949 - accuracy: 0.96 - ETA: 3:09 - loss: 0.0960 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1017 - accuracy: 0.96 - ETA: 3:06 - loss: 0.1015 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1001 - accuracy: 0.96 - ETA: 3:04 - loss: 0.0993 - accuracy: 0.96 - ETA: 3:02 - loss: 0.1048 - accuracy: 0.97 - ETA: 3:00 - loss: 0.1078 - accuracy: 0.97 - ETA: 2:59 - loss: 0.1065 - accuracy: 0.97 - ETA: 2:57 - loss: 0.1040 - accuracy: 0.97 - ETA: 2:56 - loss: 0.1003 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0997 - accuracy: 0.97 - ETA: 2:54 - loss: 0.1009 - accuracy: 0.97 - ETA: 2:52 - loss: 0.1022 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0999 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0973 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0997 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0981 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0995 - accuracy: 0.97 - ETA: 2:44 - loss: 0.1016 - accuracy: 0.97 - ETA: 2:42 - loss: 0.1043 - accuracy: 0.97 - ETA: 2:41 - loss: 0.1050 - accuracy: 0.97 - ETA: 2:40 - loss: 0.1054 - accuracy: 0.97 - ETA: 2:39 - loss: 0.1054 - accuracy: 0.97 - ETA: 2:37 - loss: 0.1049 - accuracy: 0.97 - ETA: 2:36 - loss: 0.1051 - accuracy: 0.97 - ETA: 2:34 - loss: 0.1073 - accuracy: 0.97 - ETA: 2:33 - loss: 0.1082 - accuracy: 0.97 - ETA: 2:32 - loss: 0.1105 - accuracy: 0.97 - ETA: 2:30 - loss: 0.1089 - accuracy: 0.97 - ETA: 2:29 - loss: 0.1118 - accuracy: 0.97 - ETA: 2:27 - loss: 0.1103 - accuracy: 0.97 - ETA: 2:26 - loss: 0.1110 - accuracy: 0.97 - ETA: 2:25 - loss: 0.1113 - accuracy: 0.97 - ETA: 2:24 - loss: 0.1114 - accuracy: 0.97 - ETA: 2:22 - loss: 0.1108 - accuracy: 0.97 - ETA: 2:21 - loss: 0.1097 - accuracy: 0.97 - ETA: 2:20 - loss: 0.1098 - accuracy: 0.97 - ETA: 2:18 - loss: 0.1119 - accuracy: 0.97 - ETA: 2:17 - loss: 0.1142 - accuracy: 0.97 - ETA: 2:15 - loss: 0.1132 - accuracy: 0.97 - ETA: 2:14 - loss: 0.1131 - accuracy: 0.97 - ETA: 2:13 - loss: 0.1122 - accuracy: 0.97 - ETA: 2:11 - loss: 0.1126 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1124 - accuracy: 0.97 - ETA: 2:09 - loss: 0.1139 - accuracy: 0.96 - ETA: 2:07 - loss: 0.1183 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1187 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1186 - accuracy: 0.96 - ETA: 2:03 - loss: 0.1187 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1179 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1164 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1167 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1173 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1171 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1178 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1181 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1180 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1184 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1179 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1188 - accuracy: 0.96 - ETA: 1:47 - loss: 0.1183 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1185 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1183 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1174 - accuracy: 0.96 - ETA: 1:41 - loss: 0.1170 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1181 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1194 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1188 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1198 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1199 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1190 - accuracy: 0.96 - ETA: 1:32 - loss: 0.1183 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1183 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1187 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1182 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1189 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1203 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1203 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1212 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1213 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1205 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1209 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1197 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1210 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1210 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1199 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1188 - accuracy: 0.96 - ETA: 1:10 - loss: 0.1184 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1187 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1197 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1202 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1192 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1189 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1187 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1198 - accuracy: 0.96 - ETA: 59s - loss: 0.1201 - accuracy: 0.9694 - ETA: 58s - loss: 0.1208 - accuracy: 0.969 - ETA: 57s - loss: 0.1201 - accuracy: 0.969 - ETA: 55s - loss: 0.1217 - accuracy: 0.969 - ETA: 54s - loss: 0.1210 - accuracy: 0.969 - ETA: 52s - loss: 0.1207 - accuracy: 0.969 - ETA: 51s - loss: 0.1217 - accuracy: 0.969 - ETA: 50s - loss: 0.1220 - accuracy: 0.969 - ETA: 48s - loss: 0.1212 - accuracy: 0.969 - ETA: 47s - loss: 0.1207 - accuracy: 0.970 - ETA: 46s - loss: 0.1201 - accuracy: 0.970 - ETA: 44s - loss: 0.1198 - accuracy: 0.970 - ETA: 43s - loss: 0.1197 - accuracy: 0.970 - ETA: 42s - loss: 0.1211 - accuracy: 0.969 - ETA: 40s - loss: 0.1209 - accuracy: 0.969 - ETA: 39s - loss: 0.1213 - accuracy: 0.969 - ETA: 37s - loss: 0.1211 - accuracy: 0.969 - ETA: 36s - loss: 0.1206 - accuracy: 0.969 - ETA: 35s - loss: 0.1210 - accuracy: 0.969 - ETA: 33s - loss: 0.1214 - accuracy: 0.969 - ETA: 32s - loss: 0.1217 - accuracy: 0.969 - ETA: 31s - loss: 0.1211 - accuracy: 0.969 - ETA: 29s - loss: 0.1212 - accuracy: 0.969 - ETA: 28s - loss: 0.1209 - accuracy: 0.969 - ETA: 27s - loss: 0.1202 - accuracy: 0.969 - ETA: 25s - loss: 0.1197 - accuracy: 0.970 - ETA: 24s - loss: 0.1195 - accuracy: 0.970 - ETA: 22s - loss: 0.1201 - accuracy: 0.969 - ETA: 21s - loss: 0.1200 - accuracy: 0.969 - ETA: 20s - loss: 0.1195 - accuracy: 0.969 - ETA: 18s - loss: 0.1199 - accuracy: 0.969 - ETA: 17s - loss: 0.1208 - accuracy: 0.969 - ETA: 16s - loss: 0.1214 - accuracy: 0.969 - ETA: 14s - loss: 0.1215 - accuracy: 0.969 - ETA: 13s - loss: 0.1217 - accuracy: 0.969 - ETA: 12s - loss: 0.1213 - accuracy: 0.969 - ETA: 10s - loss: 0.1225 - accuracy: 0.969 - ETA: 9s - loss: 0.1234 - accuracy: 0.969 - ETA: 8s - loss: 0.1231 - accuracy: 0.96 - ETA: 6s - loss: 0.1232 - accuracy: 0.96 - ETA: 5s - loss: 0.1234 - accuracy: 0.96 - ETA: 3s - loss: 0.1233 - accuracy: 0.96 - ETA: 2s - loss: 0.1232 - accuracy: 0.96 - ETA: 1s - loss: 0.1249 - accuracy: 0.96 - 218s 11ms/step - loss: 0.1249 - accuracy: 0.9691 - val_loss: 1.9029 - val_accuracy: 0.7952\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:17 - loss: 0.1044 - accuracy: 0.97 - ETA: 3:27 - loss: 0.1422 - accuracy: 0.97 - ETA: 3:25 - loss: 0.1657 - accuracy: 0.97 - ETA: 3:24 - loss: 0.1397 - accuracy: 0.97 - ETA: 3:22 - loss: 0.1250 - accuracy: 0.97 - ETA: 3:21 - loss: 0.1310 - accuracy: 0.97 - ETA: 3:19 - loss: 0.1432 - accuracy: 0.96 - ETA: 3:18 - loss: 0.1479 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1396 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1333 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1239 - accuracy: 0.97 - ETA: 3:11 - loss: 0.1213 - accuracy: 0.97 - ETA: 3:09 - loss: 0.1163 - accuracy: 0.97 - ETA: 3:09 - loss: 0.1159 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1145 - accuracy: 0.96 - ETA: 3:06 - loss: 0.1131 - accuracy: 0.96 - ETA: 3:04 - loss: 0.1113 - accuracy: 0.97 - ETA: 3:02 - loss: 0.1092 - accuracy: 0.97 - ETA: 3:01 - loss: 0.1072 - accuracy: 0.97 - ETA: 2:59 - loss: 0.1072 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1099 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1076 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1056 - accuracy: 0.97 - ETA: 2:53 - loss: 0.1062 - accuracy: 0.97 - ETA: 2:52 - loss: 0.1082 - accuracy: 0.97 - ETA: 2:51 - loss: 0.1088 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1095 - accuracy: 0.96 - ETA: 2:48 - loss: 0.1138 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1120 - accuracy: 0.96 - ETA: 2:45 - loss: 0.1092 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1119 - accuracy: 0.97 - ETA: 2:42 - loss: 0.1100 - accuracy: 0.97 - ETA: 2:41 - loss: 0.1122 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1094 - accuracy: 0.97 - ETA: 2:38 - loss: 0.1089 - accuracy: 0.97 - ETA: 2:36 - loss: 0.1076 - accuracy: 0.97 - ETA: 2:35 - loss: 0.1118 - accuracy: 0.97 - ETA: 2:34 - loss: 0.1145 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1152 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1159 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1152 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1132 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1145 - accuracy: 0.96 - ETA: 2:25 - loss: 0.1149 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1126 - accuracy: 0.96 - ETA: 2:22 - loss: 0.1125 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1118 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1139 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1120 - accuracy: 0.96 - ETA: 2:17 - loss: 0.1130 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1132 - accuracy: 0.96 - ETA: 2:14 - loss: 0.1131 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1139 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1158 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1152 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1166 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1153 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1152 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1139 - accuracy: 0.96 - ETA: 2:03 - loss: 0.1145 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1152 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1150 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1149 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1170 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1176 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1205 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1200 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1193 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1200 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1187 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1197 - accuracy: 0.96 - ETA: 1:47 - loss: 0.1195 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1187 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1177 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1164 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1152 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1153 - accuracy: 0.96 - ETA: 1:39 - loss: 0.1144 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1135 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1131 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1143 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1153 - accuracy: 0.96 - ETA: 1:32 - loss: 0.1156 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1147 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1141 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1142 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1152 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1149 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1147 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1142 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1152 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1146 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1148 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1138 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1127 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1130 - accuracy: 0.97 - ETA: 1:13 - loss: 0.1126 - accuracy: 0.97 - ETA: 1:12 - loss: 0.1128 - accuracy: 0.97 - ETA: 1:10 - loss: 0.1125 - accuracy: 0.97 - ETA: 1:09 - loss: 0.1131 - accuracy: 0.97 - ETA: 1:08 - loss: 0.1124 - accuracy: 0.97 - ETA: 1:06 - loss: 0.1118 - accuracy: 0.97 - ETA: 1:05 - loss: 0.1120 - accuracy: 0.97 - ETA: 1:04 - loss: 0.1113 - accuracy: 0.97 - ETA: 1:02 - loss: 0.1108 - accuracy: 0.97 - ETA: 1:01 - loss: 0.1103 - accuracy: 0.97 - ETA: 59s - loss: 0.1097 - accuracy: 0.9706 - ETA: 58s - loss: 0.1105 - accuracy: 0.970 - ETA: 57s - loss: 0.1103 - accuracy: 0.970 - ETA: 55s - loss: 0.1110 - accuracy: 0.970 - ETA: 54s - loss: 0.1111 - accuracy: 0.969 - ETA: 53s - loss: 0.1112 - accuracy: 0.969 - ETA: 51s - loss: 0.1102 - accuracy: 0.970 - ETA: 50s - loss: 0.1102 - accuracy: 0.970 - ETA: 48s - loss: 0.1109 - accuracy: 0.970 - ETA: 47s - loss: 0.1112 - accuracy: 0.970 - ETA: 46s - loss: 0.1111 - accuracy: 0.970 - ETA: 44s - loss: 0.1113 - accuracy: 0.969 - ETA: 43s - loss: 0.1118 - accuracy: 0.969 - ETA: 42s - loss: 0.1117 - accuracy: 0.969 - ETA: 40s - loss: 0.1113 - accuracy: 0.969 - ETA: 39s - loss: 0.1107 - accuracy: 0.969 - ETA: 38s - loss: 0.1111 - accuracy: 0.969 - ETA: 36s - loss: 0.1112 - accuracy: 0.969 - ETA: 35s - loss: 0.1119 - accuracy: 0.969 - ETA: 33s - loss: 0.1119 - accuracy: 0.969 - ETA: 32s - loss: 0.1117 - accuracy: 0.969 - ETA: 31s - loss: 0.1112 - accuracy: 0.970 - ETA: 29s - loss: 0.1111 - accuracy: 0.970 - ETA: 28s - loss: 0.1114 - accuracy: 0.970 - ETA: 27s - loss: 0.1123 - accuracy: 0.969 - ETA: 25s - loss: 0.1119 - accuracy: 0.970 - ETA: 24s - loss: 0.1117 - accuracy: 0.970 - ETA: 23s - loss: 0.1113 - accuracy: 0.970 - ETA: 21s - loss: 0.1109 - accuracy: 0.970 - ETA: 20s - loss: 0.1106 - accuracy: 0.970 - ETA: 18s - loss: 0.1099 - accuracy: 0.970 - ETA: 17s - loss: 0.1096 - accuracy: 0.970 - ETA: 16s - loss: 0.1096 - accuracy: 0.970 - ETA: 14s - loss: 0.1093 - accuracy: 0.970 - ETA: 13s - loss: 0.1098 - accuracy: 0.970 - ETA: 12s - loss: 0.1108 - accuracy: 0.970 - ETA: 10s - loss: 0.1109 - accuracy: 0.970 - ETA: 9s - loss: 0.1108 - accuracy: 0.970 - ETA: 8s - loss: 0.1106 - accuracy: 0.97 - ETA: 6s - loss: 0.1104 - accuracy: 0.97 - ETA: 5s - loss: 0.1104 - accuracy: 0.97 - ETA: 3s - loss: 0.1099 - accuracy: 0.97 - ETA: 2s - loss: 0.1094 - accuracy: 0.97 - ETA: 1s - loss: 0.1088 - accuracy: 0.97 - 218s 11ms/step - loss: 0.1084 - accuracy: 0.9709 - val_loss: 1.7706 - val_accuracy: 0.8022\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:34 - loss: 0.0890 - accuracy: 0.96 - ETA: 3:27 - loss: 0.1129 - accuracy: 0.96 - ETA: 3:28 - loss: 0.0838 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0979 - accuracy: 0.96 - ETA: 3:22 - loss: 0.0965 - accuracy: 0.96 - ETA: 3:21 - loss: 0.0922 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0803 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0817 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0754 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0716 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0672 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0656 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0707 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0773 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0798 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0903 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0938 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0992 - accuracy: 0.97 - ETA: 3:00 - loss: 0.1037 - accuracy: 0.97 - ETA: 2:59 - loss: 0.1040 - accuracy: 0.97 - ETA: 2:58 - loss: 0.1058 - accuracy: 0.97 - ETA: 2:56 - loss: 0.1148 - accuracy: 0.97 - ETA: 2:55 - loss: 0.1139 - accuracy: 0.97 - ETA: 2:54 - loss: 0.1114 - accuracy: 0.97 - ETA: 2:52 - loss: 0.1109 - accuracy: 0.97 - ETA: 2:50 - loss: 0.1137 - accuracy: 0.97 - ETA: 2:49 - loss: 0.1158 - accuracy: 0.97 - ETA: 2:47 - loss: 0.1157 - accuracy: 0.97 - ETA: 2:46 - loss: 0.1190 - accuracy: 0.97 - ETA: 2:45 - loss: 0.1204 - accuracy: 0.97 - ETA: 2:44 - loss: 0.1215 - accuracy: 0.97 - ETA: 2:43 - loss: 0.1234 - accuracy: 0.97 - ETA: 2:41 - loss: 0.1211 - accuracy: 0.97 - ETA: 2:40 - loss: 0.1192 - accuracy: 0.97 - ETA: 2:38 - loss: 0.1195 - accuracy: 0.97 - ETA: 2:37 - loss: 0.1209 - accuracy: 0.97 - ETA: 2:36 - loss: 0.1183 - accuracy: 0.97 - ETA: 2:34 - loss: 0.1169 - accuracy: 0.97 - ETA: 2:33 - loss: 0.1164 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1152 - accuracy: 0.97 - ETA: 2:30 - loss: 0.1149 - accuracy: 0.97 - ETA: 2:29 - loss: 0.1151 - accuracy: 0.97 - ETA: 2:28 - loss: 0.1128 - accuracy: 0.97 - ETA: 2:26 - loss: 0.1110 - accuracy: 0.97 - ETA: 2:25 - loss: 0.1096 - accuracy: 0.97 - ETA: 2:23 - loss: 0.1075 - accuracy: 0.97 - ETA: 2:22 - loss: 0.1065 - accuracy: 0.97 - ETA: 2:21 - loss: 0.1076 - accuracy: 0.97 - ETA: 2:19 - loss: 0.1059 - accuracy: 0.97 - ETA: 2:18 - loss: 0.1055 - accuracy: 0.97 - ETA: 2:16 - loss: 0.1043 - accuracy: 0.97 - ETA: 2:15 - loss: 0.1047 - accuracy: 0.97 - ETA: 2:14 - loss: 0.1073 - accuracy: 0.97 - ETA: 2:13 - loss: 0.1066 - accuracy: 0.97 - ETA: 2:11 - loss: 0.1070 - accuracy: 0.97 - ETA: 2:10 - loss: 0.1056 - accuracy: 0.97 - ETA: 2:09 - loss: 0.1049 - accuracy: 0.97 - ETA: 2:07 - loss: 0.1046 - accuracy: 0.97 - ETA: 2:06 - loss: 0.1048 - accuracy: 0.97 - ETA: 2:04 - loss: 0.1040 - accuracy: 0.97 - ETA: 2:03 - loss: 0.1048 - accuracy: 0.97 - ETA: 2:02 - loss: 0.1042 - accuracy: 0.97 - ETA: 2:00 - loss: 0.1033 - accuracy: 0.97 - ETA: 1:59 - loss: 0.1037 - accuracy: 0.97 - ETA: 1:58 - loss: 0.1051 - accuracy: 0.97 - ETA: 1:56 - loss: 0.1036 - accuracy: 0.97 - ETA: 1:55 - loss: 0.1038 - accuracy: 0.97 - ETA: 1:53 - loss: 0.1032 - accuracy: 0.97 - ETA: 1:52 - loss: 0.1038 - accuracy: 0.97 - ETA: 1:51 - loss: 0.1027 - accuracy: 0.97 - ETA: 1:49 - loss: 0.1026 - accuracy: 0.97 - ETA: 1:48 - loss: 0.1030 - accuracy: 0.97 - ETA: 1:46 - loss: 0.1025 - accuracy: 0.97 - ETA: 1:45 - loss: 0.1031 - accuracy: 0.97 - ETA: 1:44 - loss: 0.1043 - accuracy: 0.97 - ETA: 1:42 - loss: 0.1062 - accuracy: 0.97 - ETA: 1:41 - loss: 0.1056 - accuracy: 0.97 - ETA: 1:40 - loss: 0.1060 - accuracy: 0.97 - ETA: 1:38 - loss: 0.1057 - accuracy: 0.97 - ETA: 1:37 - loss: 0.1049 - accuracy: 0.97 - ETA: 1:35 - loss: 0.1039 - accuracy: 0.97 - ETA: 1:34 - loss: 0.1046 - accuracy: 0.97 - ETA: 1:33 - loss: 0.1051 - accuracy: 0.97 - ETA: 1:31 - loss: 0.1044 - accuracy: 0.97 - ETA: 1:30 - loss: 0.1044 - accuracy: 0.97 - ETA: 1:28 - loss: 0.1055 - accuracy: 0.97 - ETA: 1:27 - loss: 0.1050 - accuracy: 0.97 - ETA: 1:26 - loss: 0.1067 - accuracy: 0.97 - ETA: 1:24 - loss: 0.1060 - accuracy: 0.97 - ETA: 1:23 - loss: 0.1086 - accuracy: 0.97 - ETA: 1:22 - loss: 0.1105 - accuracy: 0.97 - ETA: 1:20 - loss: 0.1101 - accuracy: 0.97 - ETA: 1:19 - loss: 0.1106 - accuracy: 0.97 - ETA: 1:18 - loss: 0.1108 - accuracy: 0.97 - ETA: 1:16 - loss: 0.1101 - accuracy: 0.97 - ETA: 1:15 - loss: 0.1097 - accuracy: 0.97 - ETA: 1:13 - loss: 0.1094 - accuracy: 0.97 - ETA: 1:12 - loss: 0.1087 - accuracy: 0.97 - ETA: 1:11 - loss: 0.1087 - accuracy: 0.97 - ETA: 1:09 - loss: 0.1090 - accuracy: 0.97 - ETA: 1:08 - loss: 0.1085 - accuracy: 0.97 - ETA: 1:06 - loss: 0.1081 - accuracy: 0.97 - ETA: 1:05 - loss: 0.1077 - accuracy: 0.97 - ETA: 1:04 - loss: 0.1080 - accuracy: 0.97 - ETA: 1:02 - loss: 0.1085 - accuracy: 0.97 - ETA: 1:01 - loss: 0.1081 - accuracy: 0.97 - ETA: 1:00 - loss: 0.1080 - accuracy: 0.97 - ETA: 58s - loss: 0.1086 - accuracy: 0.9735 - ETA: 57s - loss: 0.1084 - accuracy: 0.973 - ETA: 55s - loss: 0.1086 - accuracy: 0.973 - ETA: 54s - loss: 0.1086 - accuracy: 0.973 - ETA: 53s - loss: 0.1092 - accuracy: 0.972 - ETA: 51s - loss: 0.1094 - accuracy: 0.972 - ETA: 50s - loss: 0.1092 - accuracy: 0.972 - ETA: 49s - loss: 0.1086 - accuracy: 0.972 - ETA: 47s - loss: 0.1082 - accuracy: 0.973 - ETA: 46s - loss: 0.1078 - accuracy: 0.973 - ETA: 45s - loss: 0.1074 - accuracy: 0.973 - ETA: 43s - loss: 0.1079 - accuracy: 0.973 - ETA: 42s - loss: 0.1077 - accuracy: 0.973 - ETA: 41s - loss: 0.1093 - accuracy: 0.972 - ETA: 39s - loss: 0.1096 - accuracy: 0.972 - ETA: 38s - loss: 0.1091 - accuracy: 0.972 - ETA: 36s - loss: 0.1085 - accuracy: 0.972 - ETA: 35s - loss: 0.1091 - accuracy: 0.972 - ETA: 34s - loss: 0.1088 - accuracy: 0.972 - ETA: 32s - loss: 0.1088 - accuracy: 0.972 - ETA: 31s - loss: 0.1091 - accuracy: 0.972 - ETA: 30s - loss: 0.1091 - accuracy: 0.972 - ETA: 28s - loss: 0.1087 - accuracy: 0.973 - ETA: 27s - loss: 0.1086 - accuracy: 0.972 - ETA: 25s - loss: 0.1082 - accuracy: 0.973 - ETA: 24s - loss: 0.1079 - accuracy: 0.973 - ETA: 23s - loss: 0.1080 - accuracy: 0.972 - ETA: 21s - loss: 0.1075 - accuracy: 0.973 - ETA: 20s - loss: 0.1075 - accuracy: 0.973 - ETA: 19s - loss: 0.1082 - accuracy: 0.972 - ETA: 17s - loss: 0.1078 - accuracy: 0.972 - ETA: 16s - loss: 0.1083 - accuracy: 0.972 - ETA: 14s - loss: 0.1093 - accuracy: 0.972 - ETA: 13s - loss: 0.1088 - accuracy: 0.972 - ETA: 12s - loss: 0.1082 - accuracy: 0.972 - ETA: 10s - loss: 0.1083 - accuracy: 0.972 - ETA: 9s - loss: 0.1081 - accuracy: 0.972 - ETA: 8s - loss: 0.1082 - accuracy: 0.97 - ETA: 6s - loss: 0.1093 - accuracy: 0.97 - ETA: 5s - loss: 0.1096 - accuracy: 0.97 - ETA: 3s - loss: 0.1094 - accuracy: 0.97 - ETA: 2s - loss: 0.1092 - accuracy: 0.97 - ETA: 1s - loss: 0.1088 - accuracy: 0.97 - 219s 11ms/step - loss: 0.1083 - accuracy: 0.9727 - val_loss: 1.8400 - val_accuracy: 0.7977\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:22 - loss: 0.0847 - accuracy: 0.95 - ETA: 3:29 - loss: 0.1477 - accuracy: 0.95 - ETA: 3:23 - loss: 0.1339 - accuracy: 0.95 - ETA: 3:21 - loss: 0.1301 - accuracy: 0.95 - ETA: 3:18 - loss: 0.1393 - accuracy: 0.95 - ETA: 3:17 - loss: 0.1302 - accuracy: 0.95 - ETA: 3:15 - loss: 0.1232 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1111 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1063 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1107 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1085 - accuracy: 0.97 - ETA: 3:08 - loss: 0.1345 - accuracy: 0.97 - ETA: 3:07 - loss: 0.1394 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1357 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1326 - accuracy: 0.97 - ETA: 3:02 - loss: 0.1299 - accuracy: 0.97 - ETA: 3:00 - loss: 0.1280 - accuracy: 0.97 - ETA: 2:59 - loss: 0.1282 - accuracy: 0.96 - ETA: 2:58 - loss: 0.1304 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1261 - accuracy: 0.96 - ETA: 2:55 - loss: 0.1257 - accuracy: 0.96 - ETA: 2:55 - loss: 0.1227 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1222 - accuracy: 0.97 - ETA: 2:53 - loss: 0.1201 - accuracy: 0.97 - ETA: 2:52 - loss: 0.1176 - accuracy: 0.97 - ETA: 2:52 - loss: 0.1162 - accuracy: 0.97 - ETA: 2:51 - loss: 0.1132 - accuracy: 0.97 - ETA: 2:51 - loss: 0.1113 - accuracy: 0.97 - ETA: 2:50 - loss: 0.1081 - accuracy: 0.97 - ETA: 2:50 - loss: 0.1062 - accuracy: 0.97 - ETA: 2:51 - loss: 0.1096 - accuracy: 0.97 - ETA: 2:51 - loss: 0.1070 - accuracy: 0.97 - ETA: 2:51 - loss: 0.1082 - accuracy: 0.97 - ETA: 2:52 - loss: 0.1062 - accuracy: 0.97 - ETA: 2:54 - loss: 0.1039 - accuracy: 0.97 - ETA: 2:53 - loss: 0.1051 - accuracy: 0.97 - ETA: 2:53 - loss: 0.1029 - accuracy: 0.97 - ETA: 2:51 - loss: 0.1004 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0989 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0976 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0956 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0959 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0969 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0952 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0958 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0972 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0965 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0960 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0949 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0963 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0949 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0950 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0954 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0946 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0945 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0952 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0955 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0950 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0965 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0959 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0952 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0962 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0958 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0948 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0947 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0966 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0960 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0957 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0950 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0952 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0951 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0943 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0947 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0935 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0951 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0952 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0949 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0949 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0952 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0949 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0953 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0945 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0938 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0956 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0958 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0960 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0957 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0964 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0963 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0976 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0977 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0975 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0978 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0976 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0972 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0992 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0993 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0996 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0997 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0995 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0987 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0987 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0980 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0982 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0983 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0983 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0989 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0987 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0981 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0973 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0971 - accuracy: 0.97 - ETA: 58s - loss: 0.0964 - accuracy: 0.9745 - ETA: 57s - loss: 0.0964 - accuracy: 0.974 - ETA: 55s - loss: 0.0971 - accuracy: 0.974 - ETA: 54s - loss: 0.0975 - accuracy: 0.974 - ETA: 52s - loss: 0.0967 - accuracy: 0.974 - ETA: 51s - loss: 0.0969 - accuracy: 0.974 - ETA: 49s - loss: 0.0968 - accuracy: 0.974 - ETA: 47s - loss: 0.0963 - accuracy: 0.974 - ETA: 46s - loss: 0.0963 - accuracy: 0.974 - ETA: 44s - loss: 0.0961 - accuracy: 0.974 - ETA: 43s - loss: 0.0954 - accuracy: 0.974 - ETA: 41s - loss: 0.0956 - accuracy: 0.974 - ETA: 40s - loss: 0.0950 - accuracy: 0.974 - ETA: 38s - loss: 0.0952 - accuracy: 0.974 - ETA: 37s - loss: 0.0947 - accuracy: 0.974 - ETA: 35s - loss: 0.0947 - accuracy: 0.974 - ETA: 34s - loss: 0.0949 - accuracy: 0.974 - ETA: 32s - loss: 0.0942 - accuracy: 0.974 - ETA: 31s - loss: 0.0946 - accuracy: 0.974 - ETA: 29s - loss: 0.0943 - accuracy: 0.974 - ETA: 28s - loss: 0.0940 - accuracy: 0.974 - ETA: 26s - loss: 0.0947 - accuracy: 0.974 - ETA: 25s - loss: 0.0945 - accuracy: 0.974 - ETA: 23s - loss: 0.0944 - accuracy: 0.974 - ETA: 22s - loss: 0.0943 - accuracy: 0.974 - ETA: 20s - loss: 0.0937 - accuracy: 0.974 - ETA: 19s - loss: 0.0948 - accuracy: 0.974 - ETA: 17s - loss: 0.0950 - accuracy: 0.974 - ETA: 16s - loss: 0.0947 - accuracy: 0.974 - ETA: 14s - loss: 0.0959 - accuracy: 0.974 - ETA: 13s - loss: 0.0955 - accuracy: 0.974 - ETA: 11s - loss: 0.0951 - accuracy: 0.974 - ETA: 10s - loss: 0.0956 - accuracy: 0.974 - ETA: 8s - loss: 0.0960 - accuracy: 0.974 - ETA: 7s - loss: 0.0959 - accuracy: 0.97 - ETA: 5s - loss: 0.0961 - accuracy: 0.97 - ETA: 4s - loss: 0.0960 - accuracy: 0.97 - ETA: 2s - loss: 0.0954 - accuracy: 0.97 - ETA: 1s - loss: 0.0954 - accuracy: 0.97 - 246s 13ms/step - loss: 0.0955 - accuracy: 0.9744 - val_loss: 1.7972 - val_accuracy: 0.8041\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:25 - loss: 0.1218 - accuracy: 0.96 - ETA: 3:27 - loss: 0.0623 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0971 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0903 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0876 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0969 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0905 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0865 - accuracy: 0.97 - ETA: 3:18 - loss: 0.1125 - accuracy: 0.97 - ETA: 3:16 - loss: 0.1035 - accuracy: 0.97 - ETA: 3:14 - loss: 0.1019 - accuracy: 0.97 - ETA: 3:14 - loss: 0.1066 - accuracy: 0.97 - ETA: 3:12 - loss: 0.1053 - accuracy: 0.97 - ETA: 3:10 - loss: 0.1016 - accuracy: 0.97 - ETA: 3:08 - loss: 0.1064 - accuracy: 0.97 - ETA: 3:06 - loss: 0.1035 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1033 - accuracy: 0.96 - ETA: 3:04 - loss: 0.1023 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0999 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0968 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0955 - accuracy: 0.97 - ETA: 2:58 - loss: 0.1019 - accuracy: 0.97 - ETA: 2:57 - loss: 0.1002 - accuracy: 0.97 - ETA: 2:55 - loss: 0.1072 - accuracy: 0.97 - ETA: 2:54 - loss: 0.1055 - accuracy: 0.97 - ETA: 2:52 - loss: 0.1037 - accuracy: 0.97 - ETA: 2:51 - loss: 0.1030 - accuracy: 0.97 - ETA: 2:49 - loss: 0.1057 - accuracy: 0.97 - ETA: 2:48 - loss: 0.1056 - accuracy: 0.97 - ETA: 2:47 - loss: 0.1061 - accuracy: 0.97 - ETA: 2:46 - loss: 0.1056 - accuracy: 0.97 - ETA: 2:44 - loss: 0.1060 - accuracy: 0.97 - ETA: 2:42 - loss: 0.1036 - accuracy: 0.97 - ETA: 2:41 - loss: 0.1075 - accuracy: 0.97 - ETA: 2:40 - loss: 0.1056 - accuracy: 0.97 - ETA: 2:38 - loss: 0.1054 - accuracy: 0.97 - ETA: 2:37 - loss: 0.1046 - accuracy: 0.97 - ETA: 2:36 - loss: 0.1027 - accuracy: 0.97 - ETA: 2:34 - loss: 0.1049 - accuracy: 0.97 - ETA: 2:33 - loss: 0.1058 - accuracy: 0.97 - ETA: 2:32 - loss: 0.1064 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1072 - accuracy: 0.97 - ETA: 2:30 - loss: 0.1068 - accuracy: 0.97 - ETA: 2:29 - loss: 0.1074 - accuracy: 0.97 - ETA: 2:30 - loss: 0.1058 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1055 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1072 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1058 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1043 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1033 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1030 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1038 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1045 - accuracy: 0.97 - ETA: 2:30 - loss: 0.1040 - accuracy: 0.97 - ETA: 2:30 - loss: 0.1044 - accuracy: 0.97 - ETA: 2:30 - loss: 0.1033 - accuracy: 0.97 - ETA: 2:29 - loss: 0.1026 - accuracy: 0.97 - ETA: 2:28 - loss: 0.1035 - accuracy: 0.97 - ETA: 2:28 - loss: 0.1030 - accuracy: 0.97 - ETA: 2:27 - loss: 0.1069 - accuracy: 0.97 - ETA: 2:26 - loss: 0.1062 - accuracy: 0.97 - ETA: 2:26 - loss: 0.1060 - accuracy: 0.97 - ETA: 2:25 - loss: 0.1057 - accuracy: 0.97 - ETA: 2:24 - loss: 0.1056 - accuracy: 0.97 - ETA: 2:23 - loss: 0.1054 - accuracy: 0.97 - ETA: 2:22 - loss: 0.1065 - accuracy: 0.97 - ETA: 2:21 - loss: 0.1059 - accuracy: 0.97 - ETA: 2:20 - loss: 0.1056 - accuracy: 0.97 - ETA: 2:19 - loss: 0.1058 - accuracy: 0.97 - ETA: 2:18 - loss: 0.1046 - accuracy: 0.97 - ETA: 2:17 - loss: 0.1032 - accuracy: 0.97 - ETA: 2:16 - loss: 0.1028 - accuracy: 0.97 - ETA: 2:15 - loss: 0.1032 - accuracy: 0.97 - ETA: 2:14 - loss: 0.1034 - accuracy: 0.97 - ETA: 2:12 - loss: 0.1045 - accuracy: 0.97 - ETA: 2:11 - loss: 0.1041 - accuracy: 0.97 - ETA: 2:10 - loss: 0.1037 - accuracy: 0.97 - ETA: 2:08 - loss: 0.1043 - accuracy: 0.97 - ETA: 2:07 - loss: 0.1041 - accuracy: 0.97 - ETA: 2:06 - loss: 0.1042 - accuracy: 0.97 - ETA: 2:04 - loss: 0.1049 - accuracy: 0.97 - ETA: 2:03 - loss: 0.1050 - accuracy: 0.97 - ETA: 2:02 - loss: 0.1046 - accuracy: 0.97 - ETA: 2:00 - loss: 0.1048 - accuracy: 0.97 - ETA: 1:59 - loss: 0.1052 - accuracy: 0.97 - ETA: 1:58 - loss: 0.1047 - accuracy: 0.97 - ETA: 1:56 - loss: 0.1061 - accuracy: 0.97 - ETA: 1:54 - loss: 0.1058 - accuracy: 0.97 - ETA: 1:53 - loss: 0.1053 - accuracy: 0.97 - ETA: 1:51 - loss: 0.1060 - accuracy: 0.97 - ETA: 1:50 - loss: 0.1057 - accuracy: 0.97 - ETA: 1:48 - loss: 0.1048 - accuracy: 0.97 - ETA: 1:46 - loss: 0.1056 - accuracy: 0.97 - ETA: 1:45 - loss: 0.1064 - accuracy: 0.97 - ETA: 1:43 - loss: 0.1069 - accuracy: 0.97 - ETA: 1:41 - loss: 0.1064 - accuracy: 0.97 - ETA: 1:40 - loss: 0.1061 - accuracy: 0.97 - ETA: 1:38 - loss: 0.1071 - accuracy: 0.97 - ETA: 1:36 - loss: 0.1067 - accuracy: 0.97 - ETA: 1:34 - loss: 0.1066 - accuracy: 0.97 - ETA: 1:33 - loss: 0.1069 - accuracy: 0.97 - ETA: 1:31 - loss: 0.1088 - accuracy: 0.97 - ETA: 1:29 - loss: 0.1102 - accuracy: 0.97 - ETA: 1:27 - loss: 0.1098 - accuracy: 0.97 - ETA: 1:26 - loss: 0.1092 - accuracy: 0.97 - ETA: 1:24 - loss: 0.1093 - accuracy: 0.97 - ETA: 1:22 - loss: 0.1092 - accuracy: 0.97 - ETA: 1:20 - loss: 0.1095 - accuracy: 0.97 - ETA: 1:19 - loss: 0.1097 - accuracy: 0.97 - ETA: 1:17 - loss: 0.1093 - accuracy: 0.97 - ETA: 1:15 - loss: 0.1090 - accuracy: 0.97 - ETA: 1:13 - loss: 0.1087 - accuracy: 0.97 - ETA: 1:11 - loss: 0.1082 - accuracy: 0.97 - ETA: 1:10 - loss: 0.1086 - accuracy: 0.97 - ETA: 1:08 - loss: 0.1081 - accuracy: 0.97 - ETA: 1:06 - loss: 0.1075 - accuracy: 0.97 - ETA: 1:04 - loss: 0.1069 - accuracy: 0.97 - ETA: 1:02 - loss: 0.1069 - accuracy: 0.97 - ETA: 1:01 - loss: 0.1070 - accuracy: 0.97 - ETA: 59s - loss: 0.1076 - accuracy: 0.9718 - ETA: 57s - loss: 0.1082 - accuracy: 0.971 - ETA: 55s - loss: 0.1077 - accuracy: 0.971 - ETA: 53s - loss: 0.1071 - accuracy: 0.971 - ETA: 51s - loss: 0.1070 - accuracy: 0.971 - ETA: 49s - loss: 0.1064 - accuracy: 0.972 - ETA: 48s - loss: 0.1069 - accuracy: 0.971 - ETA: 46s - loss: 0.1066 - accuracy: 0.971 - ETA: 44s - loss: 0.1068 - accuracy: 0.971 - ETA: 42s - loss: 0.1069 - accuracy: 0.971 - ETA: 40s - loss: 0.1068 - accuracy: 0.971 - ETA: 38s - loss: 0.1061 - accuracy: 0.971 - ETA: 36s - loss: 0.1057 - accuracy: 0.972 - ETA: 34s - loss: 0.1052 - accuracy: 0.972 - ETA: 32s - loss: 0.1049 - accuracy: 0.972 - ETA: 30s - loss: 0.1053 - accuracy: 0.972 - ETA: 29s - loss: 0.1053 - accuracy: 0.972 - ETA: 27s - loss: 0.1051 - accuracy: 0.972 - ETA: 25s - loss: 0.1048 - accuracy: 0.972 - ETA: 23s - loss: 0.1049 - accuracy: 0.972 - ETA: 21s - loss: 0.1045 - accuracy: 0.972 - ETA: 19s - loss: 0.1047 - accuracy: 0.972 - ETA: 17s - loss: 0.1045 - accuracy: 0.972 - ETA: 15s - loss: 0.1043 - accuracy: 0.972 - ETA: 13s - loss: 0.1041 - accuracy: 0.972 - ETA: 11s - loss: 0.1042 - accuracy: 0.972 - ETA: 9s - loss: 0.1035 - accuracy: 0.972 - ETA: 7s - loss: 0.1030 - accuracy: 0.97 - ETA: 5s - loss: 0.1029 - accuracy: 0.97 - ETA: 3s - loss: 0.1024 - accuracy: 0.97 - ETA: 1s - loss: 0.1025 - accuracy: 0.97 - 326s 17ms/step - loss: 0.1022 - accuracy: 0.9726 - val_loss: 1.8718 - val_accuracy: 0.8037\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:33 - loss: 0.1027 - accuracy: 0.96 - ETA: 5:22 - loss: 0.1076 - accuracy: 0.96 - ETA: 5:22 - loss: 0.1473 - accuracy: 0.96 - ETA: 5:18 - loss: 0.1304 - accuracy: 0.96 - ETA: 5:19 - loss: 0.1299 - accuracy: 0.96 - ETA: 5:17 - loss: 0.1143 - accuracy: 0.97 - ETA: 5:15 - loss: 0.1019 - accuracy: 0.97 - ETA: 5:14 - loss: 0.1027 - accuracy: 0.97 - ETA: 5:11 - loss: 0.1021 - accuracy: 0.97 - ETA: 5:08 - loss: 0.1005 - accuracy: 0.97 - ETA: 5:06 - loss: 0.0923 - accuracy: 0.97 - ETA: 5:05 - loss: 0.0860 - accuracy: 0.97 - ETA: 5:03 - loss: 0.0846 - accuracy: 0.97 - ETA: 5:00 - loss: 0.0836 - accuracy: 0.97 - ETA: 4:58 - loss: 0.0837 - accuracy: 0.97 - ETA: 4:56 - loss: 0.0870 - accuracy: 0.97 - ETA: 4:54 - loss: 0.0840 - accuracy: 0.97 - ETA: 4:52 - loss: 0.0840 - accuracy: 0.97 - ETA: 4:51 - loss: 0.0818 - accuracy: 0.97 - ETA: 4:48 - loss: 0.0896 - accuracy: 0.97 - ETA: 4:46 - loss: 0.0933 - accuracy: 0.97 - ETA: 4:44 - loss: 0.0922 - accuracy: 0.97 - ETA: 4:42 - loss: 0.0919 - accuracy: 0.97 - ETA: 4:39 - loss: 0.0929 - accuracy: 0.97 - ETA: 4:37 - loss: 0.0944 - accuracy: 0.97 - ETA: 4:35 - loss: 0.0928 - accuracy: 0.97 - ETA: 4:33 - loss: 0.0931 - accuracy: 0.97 - ETA: 4:31 - loss: 0.0946 - accuracy: 0.97 - ETA: 4:29 - loss: 0.0958 - accuracy: 0.97 - ETA: 4:27 - loss: 0.0945 - accuracy: 0.97 - ETA: 4:24 - loss: 0.0972 - accuracy: 0.97 - ETA: 4:22 - loss: 0.0948 - accuracy: 0.97 - ETA: 4:20 - loss: 0.0936 - accuracy: 0.97 - ETA: 4:18 - loss: 0.0912 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0917 - accuracy: 0.97 - ETA: 4:14 - loss: 0.0921 - accuracy: 0.97 - ETA: 4:12 - loss: 0.0926 - accuracy: 0.97 - ETA: 4:10 - loss: 0.0940 - accuracy: 0.97 - ETA: 4:08 - loss: 0.0960 - accuracy: 0.97 - ETA: 4:05 - loss: 0.0975 - accuracy: 0.97 - ETA: 4:03 - loss: 0.0963 - accuracy: 0.97 - ETA: 4:01 - loss: 0.0948 - accuracy: 0.97 - ETA: 3:59 - loss: 0.0943 - accuracy: 0.97 - ETA: 3:56 - loss: 0.0938 - accuracy: 0.97 - ETA: 3:54 - loss: 0.0933 - accuracy: 0.97 - ETA: 3:52 - loss: 0.0942 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0938 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0963 - accuracy: 0.97 - ETA: 3:46 - loss: 0.0949 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0949 - accuracy: 0.97 - ETA: 3:41 - loss: 0.0947 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0946 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0946 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0955 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0955 - accuracy: 0.97 - ETA: 3:30 - loss: 0.0947 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0969 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0969 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0962 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0970 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0974 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0980 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0982 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0989 - accuracy: 0.97 - ETA: 3:13 - loss: 0.1000 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0990 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0994 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0989 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0976 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0975 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0963 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0952 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0950 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0944 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0944 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0936 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0941 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0934 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0936 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0947 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0956 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0954 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0964 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0969 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0962 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0956 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0948 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0937 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0941 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0939 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0936 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0949 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0942 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0934 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0929 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0925 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0924 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0916 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0912 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0910 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0919 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0919 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0923 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0922 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0921 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0919 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0929 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0925 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0923 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0925 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0941 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0942 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0941 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0942 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0934 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0931 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0931 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0935 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0939 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0935 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0935 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0931 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0932 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0926 - accuracy: 0.97 - ETA: 57s - loss: 0.0923 - accuracy: 0.9736 - ETA: 55s - loss: 0.0923 - accuracy: 0.973 - ETA: 53s - loss: 0.0922 - accuracy: 0.973 - ETA: 51s - loss: 0.0924 - accuracy: 0.973 - ETA: 48s - loss: 0.0923 - accuracy: 0.973 - ETA: 46s - loss: 0.0918 - accuracy: 0.973 - ETA: 44s - loss: 0.0912 - accuracy: 0.973 - ETA: 42s - loss: 0.0913 - accuracy: 0.973 - ETA: 39s - loss: 0.0913 - accuracy: 0.973 - ETA: 37s - loss: 0.0915 - accuracy: 0.973 - ETA: 35s - loss: 0.0914 - accuracy: 0.973 - ETA: 33s - loss: 0.0910 - accuracy: 0.973 - ETA: 31s - loss: 0.0907 - accuracy: 0.973 - ETA: 28s - loss: 0.0914 - accuracy: 0.973 - ETA: 26s - loss: 0.0917 - accuracy: 0.973 - ETA: 24s - loss: 0.0917 - accuracy: 0.973 - ETA: 22s - loss: 0.0916 - accuracy: 0.973 - ETA: 19s - loss: 0.0919 - accuracy: 0.973 - ETA: 17s - loss: 0.0928 - accuracy: 0.973 - ETA: 15s - loss: 0.0933 - accuracy: 0.973 - ETA: 13s - loss: 0.0936 - accuracy: 0.973 - ETA: 10s - loss: 0.0942 - accuracy: 0.973 - ETA: 8s - loss: 0.0940 - accuracy: 0.973 - ETA: 6s - loss: 0.0937 - accuracy: 0.97 - ETA: 4s - loss: 0.0932 - accuracy: 0.97 - ETA: 1s - loss: 0.0932 - accuracy: 0.97 - 369s 19ms/step - loss: 0.0931 - accuracy: 0.9733 - val_loss: 1.8943 - val_accuracy: 0.8024\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:25 - loss: 0.0740 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0882 - accuracy: 0.98 - ETA: 5:36 - loss: 0.0769 - accuracy: 0.97 - ETA: 5:34 - loss: 0.0784 - accuracy: 0.98 - ETA: 5:32 - loss: 0.0740 - accuracy: 0.98 - ETA: 5:30 - loss: 0.0686 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0631 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0783 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0729 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0666 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0641 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0766 - accuracy: 0.97 - ETA: 5:07 - loss: 0.0771 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0760 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0760 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0774 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0785 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0760 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0754 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0772 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0806 - accuracy: 0.97 - ETA: 4:46 - loss: 0.0795 - accuracy: 0.97 - ETA: 4:42 - loss: 0.0771 - accuracy: 0.97 - ETA: 4:40 - loss: 0.0780 - accuracy: 0.97 - ETA: 4:38 - loss: 0.0808 - accuracy: 0.97 - ETA: 4:36 - loss: 0.0828 - accuracy: 0.97 - ETA: 4:34 - loss: 0.0848 - accuracy: 0.97 - ETA: 4:32 - loss: 0.0874 - accuracy: 0.97 - ETA: 4:30 - loss: 0.0873 - accuracy: 0.97 - ETA: 4:27 - loss: 0.0851 - accuracy: 0.97 - ETA: 4:24 - loss: 0.0855 - accuracy: 0.97 - ETA: 4:22 - loss: 0.0845 - accuracy: 0.97 - ETA: 4:20 - loss: 0.0854 - accuracy: 0.97 - ETA: 4:18 - loss: 0.0849 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0845 - accuracy: 0.97 - ETA: 4:14 - loss: 0.0824 - accuracy: 0.97 - ETA: 4:12 - loss: 0.0811 - accuracy: 0.97 - ETA: 4:09 - loss: 0.0799 - accuracy: 0.97 - ETA: 4:07 - loss: 0.0784 - accuracy: 0.97 - ETA: 4:05 - loss: 0.0847 - accuracy: 0.97 - ETA: 4:03 - loss: 0.0861 - accuracy: 0.97 - ETA: 4:00 - loss: 0.0846 - accuracy: 0.97 - ETA: 3:58 - loss: 0.0849 - accuracy: 0.97 - ETA: 3:55 - loss: 0.0847 - accuracy: 0.97 - ETA: 3:53 - loss: 0.0876 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0867 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0874 - accuracy: 0.97 - ETA: 3:46 - loss: 0.0857 - accuracy: 0.97 - ETA: 3:44 - loss: 0.0841 - accuracy: 0.97 - ETA: 3:41 - loss: 0.0837 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0832 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0818 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0819 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0844 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0853 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0853 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0842 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0834 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0829 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0827 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0816 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0828 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0839 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0853 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0846 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0841 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0832 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0844 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0833 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0829 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0834 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0835 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0833 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0841 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0839 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0833 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0835 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0832 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0825 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0838 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0837 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0835 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0834 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0839 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0841 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0845 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0844 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0843 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0851 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0853 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0869 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0865 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0882 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0884 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0891 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0884 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0883 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0876 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0869 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0871 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0872 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0877 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0877 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0873 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0871 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0868 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0864 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0859 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0869 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0863 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0859 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0853 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0850 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0850 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0846 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0841 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0843 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0863 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0868 - accuracy: 0.97 - ETA: 59s - loss: 0.0868 - accuracy: 0.9764 - ETA: 57s - loss: 0.0878 - accuracy: 0.976 - ETA: 55s - loss: 0.0875 - accuracy: 0.976 - ETA: 53s - loss: 0.0872 - accuracy: 0.976 - ETA: 51s - loss: 0.0867 - accuracy: 0.976 - ETA: 48s - loss: 0.0872 - accuracy: 0.976 - ETA: 46s - loss: 0.0868 - accuracy: 0.976 - ETA: 44s - loss: 0.0865 - accuracy: 0.976 - ETA: 42s - loss: 0.0876 - accuracy: 0.976 - ETA: 40s - loss: 0.0872 - accuracy: 0.976 - ETA: 38s - loss: 0.0868 - accuracy: 0.976 - ETA: 36s - loss: 0.0869 - accuracy: 0.976 - ETA: 33s - loss: 0.0877 - accuracy: 0.976 - ETA: 31s - loss: 0.0874 - accuracy: 0.976 - ETA: 29s - loss: 0.0875 - accuracy: 0.976 - ETA: 27s - loss: 0.0871 - accuracy: 0.976 - ETA: 25s - loss: 0.0867 - accuracy: 0.976 - ETA: 23s - loss: 0.0871 - accuracy: 0.976 - ETA: 21s - loss: 0.0868 - accuracy: 0.976 - ETA: 18s - loss: 0.0863 - accuracy: 0.976 - ETA: 16s - loss: 0.0867 - accuracy: 0.976 - ETA: 14s - loss: 0.0869 - accuracy: 0.976 - ETA: 12s - loss: 0.0871 - accuracy: 0.976 - ETA: 10s - loss: 0.0869 - accuracy: 0.976 - ETA: 8s - loss: 0.0871 - accuracy: 0.976 - ETA: 6s - loss: 0.0872 - accuracy: 0.97 - ETA: 4s - loss: 0.0872 - accuracy: 0.97 - ETA: 1s - loss: 0.0869 - accuracy: 0.97 - 345s 18ms/step - loss: 0.0872 - accuracy: 0.9763 - val_loss: 1.9150 - val_accuracy: 0.8027\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:15 - loss: 0.0692 - accuracy: 0.96 - ETA: 5:10 - loss: 0.0570 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0551 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0630 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0829 - accuracy: 0.97 - ETA: 4:58 - loss: 0.0916 - accuracy: 0.97 - ETA: 4:57 - loss: 0.0905 - accuracy: 0.97 - ETA: 4:55 - loss: 0.1081 - accuracy: 0.97 - ETA: 4:53 - loss: 0.1038 - accuracy: 0.97 - ETA: 4:51 - loss: 0.0975 - accuracy: 0.97 - ETA: 4:49 - loss: 0.0916 - accuracy: 0.97 - ETA: 4:47 - loss: 0.0902 - accuracy: 0.97 - ETA: 4:45 - loss: 0.0842 - accuracy: 0.97 - ETA: 4:42 - loss: 0.0799 - accuracy: 0.97 - ETA: 4:40 - loss: 0.0753 - accuracy: 0.97 - ETA: 4:38 - loss: 0.0778 - accuracy: 0.97 - ETA: 4:36 - loss: 0.0766 - accuracy: 0.97 - ETA: 4:34 - loss: 0.0791 - accuracy: 0.97 - ETA: 4:32 - loss: 0.0792 - accuracy: 0.97 - ETA: 4:30 - loss: 0.0760 - accuracy: 0.97 - ETA: 4:28 - loss: 0.0785 - accuracy: 0.97 - ETA: 4:26 - loss: 0.0777 - accuracy: 0.97 - ETA: 4:24 - loss: 0.0836 - accuracy: 0.97 - ETA: 4:22 - loss: 0.0838 - accuracy: 0.97 - ETA: 4:20 - loss: 0.0831 - accuracy: 0.97 - ETA: 4:18 - loss: 0.0815 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0800 - accuracy: 0.97 - ETA: 4:14 - loss: 0.0802 - accuracy: 0.97 - ETA: 4:12 - loss: 0.0807 - accuracy: 0.97 - ETA: 4:10 - loss: 0.0819 - accuracy: 0.97 - ETA: 4:08 - loss: 0.0814 - accuracy: 0.97 - ETA: 4:06 - loss: 0.0823 - accuracy: 0.97 - ETA: 4:03 - loss: 0.0837 - accuracy: 0.97 - ETA: 4:01 - loss: 0.0864 - accuracy: 0.97 - ETA: 3:59 - loss: 0.0854 - accuracy: 0.97 - ETA: 3:57 - loss: 0.0836 - accuracy: 0.97 - ETA: 3:55 - loss: 0.0858 - accuracy: 0.97 - ETA: 3:53 - loss: 0.0869 - accuracy: 0.97 - ETA: 3:51 - loss: 0.0852 - accuracy: 0.97 - ETA: 3:49 - loss: 0.0852 - accuracy: 0.97 - ETA: 3:47 - loss: 0.0871 - accuracy: 0.97 - ETA: 3:45 - loss: 0.0908 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0956 - accuracy: 0.97 - ETA: 3:41 - loss: 0.0949 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0959 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0959 - accuracy: 0.97 - ETA: 3:35 - loss: 0.0952 - accuracy: 0.97 - ETA: 3:33 - loss: 0.0947 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0944 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0949 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0933 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0942 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0936 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0931 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0928 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0923 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0930 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0920 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0916 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0913 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0905 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0893 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0917 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0926 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0917 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0909 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0901 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0903 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0908 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0897 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0907 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0930 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0922 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0928 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0922 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0938 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0947 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0958 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0969 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0965 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0960 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0951 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0953 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0950 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0955 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0952 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0962 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0955 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0956 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0958 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0952 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0947 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0955 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0955 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0964 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0960 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0953 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0962 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0962 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0965 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0962 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0957 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0958 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0956 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0950 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0945 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0941 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0945 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0939 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0959 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0960 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0960 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0959 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0960 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0958 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0960 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0960 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0957 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0953 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0953 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0958 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0959 - accuracy: 0.97 - ETA: 59s - loss: 0.0953 - accuracy: 0.9743 - ETA: 57s - loss: 0.0947 - accuracy: 0.974 - ETA: 55s - loss: 0.0948 - accuracy: 0.974 - ETA: 52s - loss: 0.0945 - accuracy: 0.974 - ETA: 50s - loss: 0.0943 - accuracy: 0.974 - ETA: 48s - loss: 0.0945 - accuracy: 0.974 - ETA: 46s - loss: 0.0943 - accuracy: 0.974 - ETA: 44s - loss: 0.0938 - accuracy: 0.974 - ETA: 42s - loss: 0.0937 - accuracy: 0.974 - ETA: 40s - loss: 0.0952 - accuracy: 0.974 - ETA: 38s - loss: 0.0948 - accuracy: 0.974 - ETA: 35s - loss: 0.0945 - accuracy: 0.974 - ETA: 33s - loss: 0.0943 - accuracy: 0.974 - ETA: 31s - loss: 0.0951 - accuracy: 0.974 - ETA: 29s - loss: 0.0948 - accuracy: 0.974 - ETA: 27s - loss: 0.0951 - accuracy: 0.974 - ETA: 25s - loss: 0.0952 - accuracy: 0.974 - ETA: 23s - loss: 0.0960 - accuracy: 0.974 - ETA: 21s - loss: 0.0955 - accuracy: 0.974 - ETA: 18s - loss: 0.0957 - accuracy: 0.974 - ETA: 16s - loss: 0.0961 - accuracy: 0.974 - ETA: 14s - loss: 0.0956 - accuracy: 0.974 - ETA: 12s - loss: 0.0960 - accuracy: 0.974 - ETA: 10s - loss: 0.0955 - accuracy: 0.974 - ETA: 8s - loss: 0.0956 - accuracy: 0.974 - ETA: 6s - loss: 0.0968 - accuracy: 0.97 - ETA: 4s - loss: 0.0965 - accuracy: 0.97 - ETA: 1s - loss: 0.0966 - accuracy: 0.97 - 346s 18ms/step - loss: 0.0963 - accuracy: 0.9743 - val_loss: 1.8981 - val_accuracy: 0.8039\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:30 - loss: 0.0643 - accuracy: 0.97 - ETA: 5:20 - loss: 0.0573 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0977 - accuracy: 0.96 - ETA: 5:14 - loss: 0.0927 - accuracy: 0.96 - ETA: 5:11 - loss: 0.1084 - accuracy: 0.96 - ETA: 5:08 - loss: 0.0934 - accuracy: 0.96 - ETA: 5:06 - loss: 0.0924 - accuracy: 0.96 - ETA: 5:05 - loss: 0.0959 - accuracy: 0.97 - ETA: 5:04 - loss: 0.1011 - accuracy: 0.97 - ETA: 5:01 - loss: 0.1017 - accuracy: 0.96 - ETA: 4:58 - loss: 0.1093 - accuracy: 0.96 - ETA: 4:56 - loss: 0.1053 - accuracy: 0.96 - ETA: 4:53 - loss: 0.1012 - accuracy: 0.97 - ETA: 4:51 - loss: 0.0950 - accuracy: 0.97 - ETA: 4:49 - loss: 0.0964 - accuracy: 0.97 - ETA: 4:48 - loss: 0.0948 - accuracy: 0.97 - ETA: 4:48 - loss: 0.0944 - accuracy: 0.97 - ETA: 4:46 - loss: 0.0920 - accuracy: 0.97 - ETA: 4:44 - loss: 0.0948 - accuracy: 0.97 - ETA: 4:42 - loss: 0.0956 - accuracy: 0.97 - ETA: 4:40 - loss: 0.0987 - accuracy: 0.97 - ETA: 4:40 - loss: 0.0978 - accuracy: 0.97 - ETA: 4:38 - loss: 0.0954 - accuracy: 0.97 - ETA: 4:36 - loss: 0.0947 - accuracy: 0.97 - ETA: 4:33 - loss: 0.0945 - accuracy: 0.97 - ETA: 4:32 - loss: 0.0942 - accuracy: 0.97 - ETA: 4:29 - loss: 0.0910 - accuracy: 0.97 - ETA: 4:27 - loss: 0.0892 - accuracy: 0.97 - ETA: 4:25 - loss: 0.0892 - accuracy: 0.97 - ETA: 4:22 - loss: 0.0880 - accuracy: 0.97 - ETA: 4:20 - loss: 0.0870 - accuracy: 0.97 - ETA: 4:18 - loss: 0.0859 - accuracy: 0.97 - ETA: 4:15 - loss: 0.0885 - accuracy: 0.97 - ETA: 4:13 - loss: 0.0874 - accuracy: 0.97 - ETA: 4:10 - loss: 0.0876 - accuracy: 0.97 - ETA: 4:08 - loss: 0.0907 - accuracy: 0.97 - ETA: 4:06 - loss: 0.0904 - accuracy: 0.97 - ETA: 4:04 - loss: 0.0883 - accuracy: 0.97 - ETA: 4:02 - loss: 0.0868 - accuracy: 0.97 - ETA: 4:00 - loss: 0.0871 - accuracy: 0.97 - ETA: 3:57 - loss: 0.0850 - accuracy: 0.97 - ETA: 3:55 - loss: 0.0847 - accuracy: 0.97 - ETA: 3:52 - loss: 0.0840 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0874 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0861 - accuracy: 0.97 - ETA: 3:45 - loss: 0.0854 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0843 - accuracy: 0.97 - ETA: 3:41 - loss: 0.0833 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0834 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0831 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0836 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0838 - accuracy: 0.97 - ETA: 3:30 - loss: 0.0844 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0841 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0840 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0826 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0813 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0804 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0794 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0786 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0783 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0778 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0767 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0770 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0771 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0770 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0770 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0781 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0779 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0793 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0789 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0796 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0788 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0799 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0794 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0794 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0797 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0806 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0810 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0809 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0830 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0833 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0836 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0835 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0829 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0823 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0834 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0831 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0822 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0820 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0811 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0805 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0802 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0805 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0810 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0817 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0821 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0819 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0821 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0817 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0824 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0833 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0835 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0834 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0837 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0829 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0830 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0831 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0826 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0831 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0826 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0834 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0827 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0836 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0837 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0842 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0838 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0840 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0835 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0840 - accuracy: 0.97 - ETA: 58s - loss: 0.0841 - accuracy: 0.9773 - ETA: 56s - loss: 0.0843 - accuracy: 0.977 - ETA: 54s - loss: 0.0839 - accuracy: 0.977 - ETA: 51s - loss: 0.0833 - accuracy: 0.977 - ETA: 49s - loss: 0.0846 - accuracy: 0.977 - ETA: 47s - loss: 0.0846 - accuracy: 0.977 - ETA: 45s - loss: 0.0853 - accuracy: 0.977 - ETA: 43s - loss: 0.0851 - accuracy: 0.977 - ETA: 41s - loss: 0.0856 - accuracy: 0.977 - ETA: 38s - loss: 0.0858 - accuracy: 0.977 - ETA: 36s - loss: 0.0857 - accuracy: 0.977 - ETA: 34s - loss: 0.0858 - accuracy: 0.977 - ETA: 32s - loss: 0.0854 - accuracy: 0.977 - ETA: 30s - loss: 0.0854 - accuracy: 0.977 - ETA: 28s - loss: 0.0852 - accuracy: 0.977 - ETA: 25s - loss: 0.0862 - accuracy: 0.977 - ETA: 23s - loss: 0.0858 - accuracy: 0.977 - ETA: 21s - loss: 0.0859 - accuracy: 0.977 - ETA: 19s - loss: 0.0854 - accuracy: 0.977 - ETA: 17s - loss: 0.0852 - accuracy: 0.977 - ETA: 14s - loss: 0.0860 - accuracy: 0.977 - ETA: 12s - loss: 0.0862 - accuracy: 0.977 - ETA: 10s - loss: 0.0859 - accuracy: 0.977 - ETA: 8s - loss: 0.0872 - accuracy: 0.977 - ETA: 6s - loss: 0.0880 - accuracy: 0.97 - ETA: 4s - loss: 0.0878 - accuracy: 0.97 - ETA: 1s - loss: 0.0873 - accuracy: 0.97 - 355s 18ms/step - loss: 0.0869 - accuracy: 0.9775 - val_loss: 1.8509 - val_accuracy: 0.8043\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:22 - loss: 0.1054 - accuracy: 0.96 - ETA: 5:22 - loss: 0.0959 - accuracy: 0.97 - ETA: 5:16 - loss: 0.0744 - accuracy: 0.97 - ETA: 5:17 - loss: 0.0712 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0696 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0743 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0815 - accuracy: 0.97 - ETA: 5:10 - loss: 0.0854 - accuracy: 0.97 - ETA: 5:09 - loss: 0.1045 - accuracy: 0.97 - ETA: 5:04 - loss: 0.0954 - accuracy: 0.97 - ETA: 5:04 - loss: 0.0899 - accuracy: 0.97 - ETA: 5:05 - loss: 0.0885 - accuracy: 0.97 - ETA: 5:05 - loss: 0.0860 - accuracy: 0.97 - ETA: 5:03 - loss: 0.0898 - accuracy: 0.97 - ETA: 5:01 - loss: 0.0906 - accuracy: 0.97 - ETA: 4:59 - loss: 0.0866 - accuracy: 0.97 - ETA: 4:56 - loss: 0.0817 - accuracy: 0.97 - ETA: 4:52 - loss: 0.0785 - accuracy: 0.97 - ETA: 4:50 - loss: 0.0839 - accuracy: 0.97 - ETA: 4:49 - loss: 0.0915 - accuracy: 0.97 - ETA: 4:46 - loss: 0.0928 - accuracy: 0.97 - ETA: 4:44 - loss: 0.0914 - accuracy: 0.97 - ETA: 4:41 - loss: 0.0878 - accuracy: 0.97 - ETA: 4:38 - loss: 0.0844 - accuracy: 0.97 - ETA: 4:35 - loss: 0.0822 - accuracy: 0.97 - ETA: 4:33 - loss: 0.0827 - accuracy: 0.97 - ETA: 4:32 - loss: 0.0811 - accuracy: 0.97 - ETA: 4:30 - loss: 0.0810 - accuracy: 0.97 - ETA: 4:27 - loss: 0.0805 - accuracy: 0.97 - ETA: 4:26 - loss: 0.0795 - accuracy: 0.97 - ETA: 4:23 - loss: 0.0807 - accuracy: 0.97 - ETA: 4:20 - loss: 0.0815 - accuracy: 0.97 - ETA: 4:18 - loss: 0.0805 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0812 - accuracy: 0.97 - ETA: 4:15 - loss: 0.0839 - accuracy: 0.97 - ETA: 4:12 - loss: 0.0827 - accuracy: 0.97 - ETA: 4:10 - loss: 0.0837 - accuracy: 0.97 - ETA: 4:07 - loss: 0.0834 - accuracy: 0.97 - ETA: 4:05 - loss: 0.0828 - accuracy: 0.97 - ETA: 4:02 - loss: 0.0813 - accuracy: 0.97 - ETA: 4:00 - loss: 0.0812 - accuracy: 0.97 - ETA: 3:57 - loss: 0.0812 - accuracy: 0.97 - ETA: 3:55 - loss: 0.0829 - accuracy: 0.97 - ETA: 3:52 - loss: 0.0818 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0819 - accuracy: 0.97 - ETA: 3:47 - loss: 0.0820 - accuracy: 0.97 - ETA: 3:45 - loss: 0.0829 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0825 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0822 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0836 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0869 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0858 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0864 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0872 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0863 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0856 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0867 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0871 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0878 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0887 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0884 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0886 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0910 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0919 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0913 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0909 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0907 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0900 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0902 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0916 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0918 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0920 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0918 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0912 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0921 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0930 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0925 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0921 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0916 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0927 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0924 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0923 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0914 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0910 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0916 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0911 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0906 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0903 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0898 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0908 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0907 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0907 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0898 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0904 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0896 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0899 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0909 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0921 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0916 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0919 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0917 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0923 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0921 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0932 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0938 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0932 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0931 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0929 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0934 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0933 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0930 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0931 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0924 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0921 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0922 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0920 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0918 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0921 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0927 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0931 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0930 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0930 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0931 - accuracy: 0.97 - ETA: 58s - loss: 0.0934 - accuracy: 0.9749 - ETA: 56s - loss: 0.0932 - accuracy: 0.974 - ETA: 54s - loss: 0.0929 - accuracy: 0.975 - ETA: 51s - loss: 0.0924 - accuracy: 0.975 - ETA: 49s - loss: 0.0927 - accuracy: 0.975 - ETA: 47s - loss: 0.0923 - accuracy: 0.975 - ETA: 45s - loss: 0.0917 - accuracy: 0.975 - ETA: 43s - loss: 0.0912 - accuracy: 0.975 - ETA: 41s - loss: 0.0924 - accuracy: 0.975 - ETA: 39s - loss: 0.0930 - accuracy: 0.975 - ETA: 36s - loss: 0.0930 - accuracy: 0.974 - ETA: 34s - loss: 0.0928 - accuracy: 0.975 - ETA: 32s - loss: 0.0934 - accuracy: 0.974 - ETA: 30s - loss: 0.0937 - accuracy: 0.974 - ETA: 28s - loss: 0.0944 - accuracy: 0.974 - ETA: 26s - loss: 0.0939 - accuracy: 0.974 - ETA: 23s - loss: 0.0940 - accuracy: 0.974 - ETA: 21s - loss: 0.0934 - accuracy: 0.975 - ETA: 19s - loss: 0.0927 - accuracy: 0.975 - ETA: 17s - loss: 0.0926 - accuracy: 0.975 - ETA: 15s - loss: 0.0925 - accuracy: 0.975 - ETA: 12s - loss: 0.0921 - accuracy: 0.975 - ETA: 10s - loss: 0.0926 - accuracy: 0.975 - ETA: 8s - loss: 0.0923 - accuracy: 0.975 - ETA: 6s - loss: 0.0921 - accuracy: 0.97 - ETA: 4s - loss: 0.0919 - accuracy: 0.97 - ETA: 1s - loss: 0.0915 - accuracy: 0.97 - 361s 19ms/step - loss: 0.0916 - accuracy: 0.9755 - val_loss: 2.0281 - val_accuracy: 0.8047\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:58 - loss: 0.0725 - accuracy: 0.97 - ETA: 6:05 - loss: 0.0568 - accuracy: 0.98 - ETA: 6:00 - loss: 0.0440 - accuracy: 0.98 - ETA: 5:52 - loss: 0.0363 - accuracy: 0.98 - ETA: 5:44 - loss: 0.0455 - accuracy: 0.98 - ETA: 5:39 - loss: 0.0457 - accuracy: 0.98 - ETA: 5:37 - loss: 0.0455 - accuracy: 0.98 - ETA: 5:36 - loss: 0.0615 - accuracy: 0.98 - ETA: 5:34 - loss: 0.0591 - accuracy: 0.98 - ETA: 5:32 - loss: 0.0625 - accuracy: 0.98 - ETA: 5:30 - loss: 0.0755 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0725 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0763 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0840 - accuracy: 0.98 - ETA: 5:18 - loss: 0.0816 - accuracy: 0.97 - ETA: 5:14 - loss: 0.0790 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0786 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0759 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0797 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0792 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0800 - accuracy: 0.97 - ETA: 5:00 - loss: 0.0817 - accuracy: 0.97 - ETA: 4:58 - loss: 0.0839 - accuracy: 0.97 - ETA: 4:56 - loss: 0.0849 - accuracy: 0.97 - ETA: 4:54 - loss: 0.0857 - accuracy: 0.97 - ETA: 4:51 - loss: 0.0854 - accuracy: 0.97 - ETA: 4:49 - loss: 0.0845 - accuracy: 0.97 - ETA: 4:46 - loss: 0.0856 - accuracy: 0.97 - ETA: 4:44 - loss: 0.0848 - accuracy: 0.97 - ETA: 4:43 - loss: 0.0855 - accuracy: 0.97 - ETA: 4:40 - loss: 0.0846 - accuracy: 0.97 - ETA: 4:38 - loss: 0.0883 - accuracy: 0.97 - ETA: 4:35 - loss: 0.0864 - accuracy: 0.97 - ETA: 4:32 - loss: 0.0876 - accuracy: 0.97 - ETA: 4:29 - loss: 0.0868 - accuracy: 0.97 - ETA: 4:27 - loss: 0.0861 - accuracy: 0.97 - ETA: 4:25 - loss: 0.0874 - accuracy: 0.97 - ETA: 4:23 - loss: 0.0866 - accuracy: 0.97 - ETA: 4:20 - loss: 0.0869 - accuracy: 0.97 - ETA: 4:17 - loss: 0.0862 - accuracy: 0.97 - ETA: 4:14 - loss: 0.0864 - accuracy: 0.97 - ETA: 4:12 - loss: 0.0878 - accuracy: 0.97 - ETA: 4:10 - loss: 0.0866 - accuracy: 0.97 - ETA: 4:08 - loss: 0.0862 - accuracy: 0.97 - ETA: 4:06 - loss: 0.0853 - accuracy: 0.97 - ETA: 4:03 - loss: 0.0881 - accuracy: 0.97 - ETA: 4:01 - loss: 0.0871 - accuracy: 0.97 - ETA: 3:59 - loss: 0.0891 - accuracy: 0.97 - ETA: 3:56 - loss: 0.0880 - accuracy: 0.97 - ETA: 3:54 - loss: 0.0887 - accuracy: 0.97 - ETA: 3:52 - loss: 0.0879 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0872 - accuracy: 0.97 - ETA: 3:47 - loss: 0.0901 - accuracy: 0.97 - ETA: 3:45 - loss: 0.0902 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0900 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0889 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0885 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0893 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0881 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0879 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0882 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0882 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0876 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0867 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0867 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0880 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0875 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0871 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0863 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0870 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0883 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0880 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0882 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0878 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0884 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0878 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0872 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0883 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0878 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0874 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0883 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0886 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0879 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0869 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0872 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0874 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0878 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0879 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0871 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0865 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0857 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0851 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0846 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0851 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0851 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0857 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0851 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0848 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0846 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0849 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0843 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0838 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0844 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0843 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0842 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0850 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0849 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0840 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0835 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0838 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0835 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0834 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0836 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0842 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0843 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0849 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0851 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0854 - accuracy: 0.97 - ETA: 59s - loss: 0.0856 - accuracy: 0.9768 - ETA: 57s - loss: 0.0858 - accuracy: 0.976 - ETA: 55s - loss: 0.0877 - accuracy: 0.976 - ETA: 53s - loss: 0.0882 - accuracy: 0.976 - ETA: 50s - loss: 0.0880 - accuracy: 0.976 - ETA: 48s - loss: 0.0876 - accuracy: 0.976 - ETA: 46s - loss: 0.0878 - accuracy: 0.976 - ETA: 43s - loss: 0.0877 - accuracy: 0.976 - ETA: 41s - loss: 0.0872 - accuracy: 0.976 - ETA: 39s - loss: 0.0874 - accuracy: 0.976 - ETA: 36s - loss: 0.0870 - accuracy: 0.976 - ETA: 34s - loss: 0.0869 - accuracy: 0.976 - ETA: 32s - loss: 0.0877 - accuracy: 0.976 - ETA: 29s - loss: 0.0882 - accuracy: 0.976 - ETA: 27s - loss: 0.0892 - accuracy: 0.976 - ETA: 25s - loss: 0.0892 - accuracy: 0.976 - ETA: 22s - loss: 0.0894 - accuracy: 0.976 - ETA: 20s - loss: 0.0899 - accuracy: 0.976 - ETA: 18s - loss: 0.0903 - accuracy: 0.976 - ETA: 15s - loss: 0.0904 - accuracy: 0.976 - ETA: 13s - loss: 0.0907 - accuracy: 0.976 - ETA: 11s - loss: 0.0906 - accuracy: 0.976 - ETA: 8s - loss: 0.0902 - accuracy: 0.976 - ETA: 6s - loss: 0.0896 - accuracy: 0.97 - ETA: 4s - loss: 0.0906 - accuracy: 0.97 - ETA: 2s - loss: 0.0905 - accuracy: 0.97 - 379s 20ms/step - loss: 0.0923 - accuracy: 0.9758 - val_loss: 1.9691 - val_accuracy: 0.8029\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:33 - loss: 0.0702 - accuracy: 0.96 - ETA: 5:31 - loss: 0.0687 - accuracy: 0.97 - ETA: 5:27 - loss: 0.0648 - accuracy: 0.97 - ETA: 5:31 - loss: 0.0597 - accuracy: 0.97 - ETA: 5:29 - loss: 0.0744 - accuracy: 0.97 - ETA: 5:28 - loss: 0.0690 - accuracy: 0.97 - ETA: 5:23 - loss: 0.0619 - accuracy: 0.97 - ETA: 5:21 - loss: 0.0699 - accuracy: 0.97 - ETA: 5:18 - loss: 0.0704 - accuracy: 0.97 - ETA: 5:16 - loss: 0.0714 - accuracy: 0.97 - ETA: 5:16 - loss: 0.0692 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0662 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0731 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0736 - accuracy: 0.97 - ETA: 5:06 - loss: 0.0797 - accuracy: 0.97 - ETA: 5:03 - loss: 0.0774 - accuracy: 0.97 - ETA: 5:01 - loss: 0.0757 - accuracy: 0.97 - ETA: 5:00 - loss: 0.0784 - accuracy: 0.97 - ETA: 4:57 - loss: 0.0783 - accuracy: 0.97 - ETA: 4:56 - loss: 0.0837 - accuracy: 0.97 - ETA: 4:53 - loss: 0.0851 - accuracy: 0.97 - ETA: 4:50 - loss: 0.0871 - accuracy: 0.97 - ETA: 4:47 - loss: 0.0898 - accuracy: 0.97 - ETA: 4:45 - loss: 0.0888 - accuracy: 0.97 - ETA: 4:43 - loss: 0.0920 - accuracy: 0.97 - ETA: 4:41 - loss: 0.0954 - accuracy: 0.97 - ETA: 4:39 - loss: 0.0973 - accuracy: 0.97 - ETA: 4:37 - loss: 0.0965 - accuracy: 0.97 - ETA: 4:34 - loss: 0.0937 - accuracy: 0.97 - ETA: 4:32 - loss: 0.0937 - accuracy: 0.97 - ETA: 4:30 - loss: 0.0962 - accuracy: 0.97 - ETA: 4:28 - loss: 0.0945 - accuracy: 0.97 - ETA: 4:25 - loss: 0.0949 - accuracy: 0.97 - ETA: 4:23 - loss: 0.0964 - accuracy: 0.97 - ETA: 4:21 - loss: 0.0959 - accuracy: 0.97 - ETA: 4:19 - loss: 0.0962 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0947 - accuracy: 0.97 - ETA: 4:14 - loss: 0.0944 - accuracy: 0.97 - ETA: 4:12 - loss: 0.0928 - accuracy: 0.97 - ETA: 4:10 - loss: 0.0916 - accuracy: 0.97 - ETA: 4:08 - loss: 0.0917 - accuracy: 0.97 - ETA: 4:06 - loss: 0.0901 - accuracy: 0.97 - ETA: 4:03 - loss: 0.0891 - accuracy: 0.97 - ETA: 4:01 - loss: 0.0892 - accuracy: 0.97 - ETA: 3:59 - loss: 0.0890 - accuracy: 0.97 - ETA: 3:57 - loss: 0.0884 - accuracy: 0.97 - ETA: 3:55 - loss: 0.0880 - accuracy: 0.97 - ETA: 3:53 - loss: 0.0875 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0867 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0872 - accuracy: 0.97 - ETA: 3:45 - loss: 0.0874 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0870 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0864 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0854 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0864 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0859 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0869 - accuracy: 0.97 - ETA: 3:30 - loss: 0.0864 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0857 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0864 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0857 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0848 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0846 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0842 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0848 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0842 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0835 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0848 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0839 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0845 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0850 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0848 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0840 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0832 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0838 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0840 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0836 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0840 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0830 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0831 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0821 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0830 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0832 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0832 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0828 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0833 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0848 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0855 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0858 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0858 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0850 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0849 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0854 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0859 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0868 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0873 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0873 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0875 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0869 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0875 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0873 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0873 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0873 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0865 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0865 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0862 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0856 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0860 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0859 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0852 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0854 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0853 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0849 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0852 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0850 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0867 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0867 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0865 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0860 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0858 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0872 - accuracy: 0.97 - ETA: 58s - loss: 0.0879 - accuracy: 0.9763 - ETA: 56s - loss: 0.0875 - accuracy: 0.976 - ETA: 54s - loss: 0.0878 - accuracy: 0.976 - ETA: 51s - loss: 0.0877 - accuracy: 0.976 - ETA: 49s - loss: 0.0874 - accuracy: 0.976 - ETA: 47s - loss: 0.0878 - accuracy: 0.976 - ETA: 45s - loss: 0.0883 - accuracy: 0.976 - ETA: 42s - loss: 0.0881 - accuracy: 0.976 - ETA: 40s - loss: 0.0878 - accuracy: 0.976 - ETA: 38s - loss: 0.0882 - accuracy: 0.976 - ETA: 36s - loss: 0.0876 - accuracy: 0.976 - ETA: 33s - loss: 0.0873 - accuracy: 0.976 - ETA: 31s - loss: 0.0873 - accuracy: 0.976 - ETA: 29s - loss: 0.0868 - accuracy: 0.976 - ETA: 26s - loss: 0.0866 - accuracy: 0.976 - ETA: 24s - loss: 0.0860 - accuracy: 0.976 - ETA: 22s - loss: 0.0864 - accuracy: 0.976 - ETA: 20s - loss: 0.0859 - accuracy: 0.976 - ETA: 17s - loss: 0.0862 - accuracy: 0.976 - ETA: 15s - loss: 0.0859 - accuracy: 0.976 - ETA: 13s - loss: 0.0863 - accuracy: 0.976 - ETA: 11s - loss: 0.0862 - accuracy: 0.976 - ETA: 8s - loss: 0.0861 - accuracy: 0.976 - ETA: 6s - loss: 0.0862 - accuracy: 0.97 - ETA: 4s - loss: 0.0860 - accuracy: 0.97 - ETA: 1s - loss: 0.0857 - accuracy: 0.97 - 367s 19ms/step - loss: 0.0854 - accuracy: 0.9767 - val_loss: 1.8829 - val_accuracy: 0.8016\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:34 - loss: 0.0784 - accuracy: 0.96 - ETA: 5:33 - loss: 0.0974 - accuracy: 0.97 - ETA: 5:29 - loss: 0.0825 - accuracy: 0.97 - ETA: 5:33 - loss: 0.0661 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0664 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0586 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0611 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0634 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0719 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0679 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0741 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0716 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0848 - accuracy: 0.97 - ETA: 5:08 - loss: 0.0888 - accuracy: 0.97 - ETA: 5:06 - loss: 0.0843 - accuracy: 0.97 - ETA: 5:03 - loss: 0.0831 - accuracy: 0.97 - ETA: 5:01 - loss: 0.0843 - accuracy: 0.97 - ETA: 4:59 - loss: 0.0858 - accuracy: 0.97 - ETA: 4:58 - loss: 0.0822 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0822 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0835 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0837 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0829 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0800 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0778 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0757 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0784 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0768 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0765 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0748 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0764 - accuracy: 0.97 - ETA: 4:30 - loss: 0.0752 - accuracy: 0.97 - ETA: 4:28 - loss: 0.0757 - accuracy: 0.97 - ETA: 4:26 - loss: 0.0746 - accuracy: 0.97 - ETA: 4:24 - loss: 0.0739 - accuracy: 0.97 - ETA: 4:21 - loss: 0.0753 - accuracy: 0.97 - ETA: 4:19 - loss: 0.0744 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0756 - accuracy: 0.97 - ETA: 4:14 - loss: 0.0746 - accuracy: 0.97 - ETA: 4:12 - loss: 0.0735 - accuracy: 0.97 - ETA: 4:10 - loss: 0.0734 - accuracy: 0.97 - ETA: 4:08 - loss: 0.0742 - accuracy: 0.97 - ETA: 4:05 - loss: 0.0738 - accuracy: 0.97 - ETA: 4:03 - loss: 0.0745 - accuracy: 0.97 - ETA: 4:01 - loss: 0.0750 - accuracy: 0.97 - ETA: 3:59 - loss: 0.0757 - accuracy: 0.97 - ETA: 3:57 - loss: 0.0758 - accuracy: 0.97 - ETA: 3:55 - loss: 0.0748 - accuracy: 0.97 - ETA: 3:53 - loss: 0.0757 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0772 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0769 - accuracy: 0.97 - ETA: 3:46 - loss: 0.0777 - accuracy: 0.97 - ETA: 3:44 - loss: 0.0769 - accuracy: 0.97 - ETA: 3:42 - loss: 0.0768 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0759 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0757 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0765 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0786 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0792 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0779 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0770 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0782 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0784 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0793 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0783 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0773 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0771 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0764 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0767 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0768 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0769 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0762 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0776 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0779 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0778 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0778 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0783 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0788 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0797 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0823 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0823 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0813 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0805 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0799 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0795 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0799 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0792 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0816 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0808 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0813 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0817 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0827 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0827 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0835 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0843 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0837 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0830 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0831 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0823 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0826 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0834 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0836 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0848 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0846 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0840 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0836 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0843 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0838 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0837 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0838 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0838 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0838 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0837 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0836 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0836 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0834 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0838 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0841 - accuracy: 0.97 - ETA: 59s - loss: 0.0844 - accuracy: 0.9779 - ETA: 57s - loss: 0.0839 - accuracy: 0.978 - ETA: 54s - loss: 0.0838 - accuracy: 0.978 - ETA: 52s - loss: 0.0835 - accuracy: 0.978 - ETA: 50s - loss: 0.0835 - accuracy: 0.978 - ETA: 47s - loss: 0.0831 - accuracy: 0.978 - ETA: 45s - loss: 0.0827 - accuracy: 0.978 - ETA: 43s - loss: 0.0828 - accuracy: 0.978 - ETA: 41s - loss: 0.0836 - accuracy: 0.978 - ETA: 38s - loss: 0.0834 - accuracy: 0.978 - ETA: 36s - loss: 0.0833 - accuracy: 0.978 - ETA: 34s - loss: 0.0833 - accuracy: 0.977 - ETA: 31s - loss: 0.0835 - accuracy: 0.977 - ETA: 29s - loss: 0.0833 - accuracy: 0.977 - ETA: 27s - loss: 0.0834 - accuracy: 0.977 - ETA: 24s - loss: 0.0832 - accuracy: 0.978 - ETA: 22s - loss: 0.0828 - accuracy: 0.978 - ETA: 20s - loss: 0.0823 - accuracy: 0.978 - ETA: 18s - loss: 0.0824 - accuracy: 0.978 - ETA: 15s - loss: 0.0830 - accuracy: 0.978 - ETA: 13s - loss: 0.0827 - accuracy: 0.978 - ETA: 11s - loss: 0.0827 - accuracy: 0.978 - ETA: 8s - loss: 0.0822 - accuracy: 0.978 - ETA: 6s - loss: 0.0836 - accuracy: 0.97 - ETA: 4s - loss: 0.0833 - accuracy: 0.97 - ETA: 2s - loss: 0.0832 - accuracy: 0.97 - 372s 19ms/step - loss: 0.0831 - accuracy: 0.9782 - val_loss: 1.9085 - val_accuracy: 0.8016\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:27 - loss: 0.1398 - accuracy: 0.96 - ETA: 5:27 - loss: 0.1184 - accuracy: 0.96 - ETA: 5:31 - loss: 0.0989 - accuracy: 0.97 - ETA: 5:33 - loss: 0.0760 - accuracy: 0.98 - ETA: 5:36 - loss: 0.0753 - accuracy: 0.98 - ETA: 5:31 - loss: 0.0792 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0740 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0781 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0748 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0761 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0695 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0783 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0802 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0750 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0750 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0769 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0729 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0715 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0740 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0854 - accuracy: 0.97 - ETA: 4:54 - loss: 0.0833 - accuracy: 0.97 - ETA: 4:51 - loss: 0.0837 - accuracy: 0.97 - ETA: 4:49 - loss: 0.0804 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0793 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0769 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0747 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0738 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0732 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0755 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0755 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0810 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0811 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0841 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0842 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0830 - accuracy: 0.97 - ETA: 4:22 - loss: 0.0817 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0818 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0809 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0808 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0806 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0818 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0810 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0807 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0807 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0793 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0777 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0768 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0785 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0776 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0778 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0790 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0789 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0784 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0772 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0782 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0769 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0756 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0745 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0769 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0760 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0756 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0750 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0749 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0779 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0781 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0779 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0770 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0783 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0782 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0775 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0773 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0773 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0777 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0776 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0769 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0776 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0773 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0765 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0761 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0761 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0754 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0753 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0757 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0756 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0751 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0771 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0767 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0778 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0775 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0774 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0768 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0766 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0761 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0778 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0776 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0775 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0781 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0780 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0781 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0776 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0774 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0770 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0773 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0772 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0772 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0769 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0770 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0786 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0781 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0779 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0781 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0783 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0780 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0777 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0773 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0769 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0769 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0774 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0770 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0769 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0772 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0771 - accuracy: 0.97 - ETA: 58s - loss: 0.0772 - accuracy: 0.9793 - ETA: 56s - loss: 0.0773 - accuracy: 0.979 - ETA: 54s - loss: 0.0780 - accuracy: 0.979 - ETA: 51s - loss: 0.0786 - accuracy: 0.979 - ETA: 49s - loss: 0.0791 - accuracy: 0.978 - ETA: 47s - loss: 0.0788 - accuracy: 0.978 - ETA: 45s - loss: 0.0787 - accuracy: 0.978 - ETA: 43s - loss: 0.0796 - accuracy: 0.978 - ETA: 40s - loss: 0.0791 - accuracy: 0.978 - ETA: 38s - loss: 0.0796 - accuracy: 0.978 - ETA: 36s - loss: 0.0802 - accuracy: 0.978 - ETA: 34s - loss: 0.0806 - accuracy: 0.978 - ETA: 31s - loss: 0.0801 - accuracy: 0.978 - ETA: 29s - loss: 0.0799 - accuracy: 0.978 - ETA: 27s - loss: 0.0801 - accuracy: 0.978 - ETA: 24s - loss: 0.0798 - accuracy: 0.978 - ETA: 22s - loss: 0.0794 - accuracy: 0.978 - ETA: 20s - loss: 0.0792 - accuracy: 0.978 - ETA: 18s - loss: 0.0791 - accuracy: 0.978 - ETA: 15s - loss: 0.0790 - accuracy: 0.978 - ETA: 13s - loss: 0.0804 - accuracy: 0.978 - ETA: 11s - loss: 0.0805 - accuracy: 0.978 - ETA: 8s - loss: 0.0812 - accuracy: 0.978 - ETA: 6s - loss: 0.0809 - accuracy: 0.97 - ETA: 4s - loss: 0.0809 - accuracy: 0.97 - ETA: 2s - loss: 0.0817 - accuracy: 0.97 - 374s 19ms/step - loss: 0.0814 - accuracy: 0.9782 - val_loss: 1.9311 - val_accuracy: 0.8018\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:13 - loss: 0.0318 - accuracy: 0.99 - ETA: 6:01 - loss: 0.0446 - accuracy: 0.99 - ETA: 5:56 - loss: 0.0467 - accuracy: 0.98 - ETA: 5:47 - loss: 0.1040 - accuracy: 0.97 - ETA: 5:41 - loss: 0.0884 - accuracy: 0.98 - ETA: 5:36 - loss: 0.0815 - accuracy: 0.98 - ETA: 5:30 - loss: 0.0985 - accuracy: 0.97 - ETA: 5:28 - loss: 0.0951 - accuracy: 0.97 - ETA: 5:26 - loss: 0.1032 - accuracy: 0.97 - ETA: 5:25 - loss: 0.0941 - accuracy: 0.97 - ETA: 5:20 - loss: 0.0884 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0841 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0829 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0825 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0856 - accuracy: 0.97 - ETA: 5:07 - loss: 0.0846 - accuracy: 0.97 - ETA: 5:04 - loss: 0.0866 - accuracy: 0.97 - ETA: 5:01 - loss: 0.0856 - accuracy: 0.97 - ETA: 4:59 - loss: 0.0858 - accuracy: 0.97 - ETA: 4:57 - loss: 0.0846 - accuracy: 0.97 - ETA: 4:56 - loss: 0.0821 - accuracy: 0.97 - ETA: 4:53 - loss: 0.0825 - accuracy: 0.97 - ETA: 4:51 - loss: 0.0808 - accuracy: 0.97 - ETA: 4:48 - loss: 0.0783 - accuracy: 0.97 - ETA: 4:46 - loss: 0.0801 - accuracy: 0.97 - ETA: 4:43 - loss: 0.0801 - accuracy: 0.97 - ETA: 4:40 - loss: 0.0832 - accuracy: 0.97 - ETA: 4:39 - loss: 0.0804 - accuracy: 0.97 - ETA: 4:37 - loss: 0.0814 - accuracy: 0.97 - ETA: 4:35 - loss: 0.0823 - accuracy: 0.97 - ETA: 4:32 - loss: 0.0815 - accuracy: 0.97 - ETA: 4:30 - loss: 0.0814 - accuracy: 0.97 - ETA: 4:27 - loss: 0.0805 - accuracy: 0.97 - ETA: 4:25 - loss: 0.0782 - accuracy: 0.97 - ETA: 4:23 - loss: 0.0829 - accuracy: 0.97 - ETA: 4:21 - loss: 0.0832 - accuracy: 0.97 - ETA: 4:19 - loss: 0.0815 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0795 - accuracy: 0.97 - ETA: 4:13 - loss: 0.0807 - accuracy: 0.97 - ETA: 4:11 - loss: 0.0799 - accuracy: 0.97 - ETA: 4:09 - loss: 0.0789 - accuracy: 0.97 - ETA: 4:07 - loss: 0.0788 - accuracy: 0.97 - ETA: 4:05 - loss: 0.0775 - accuracy: 0.97 - ETA: 4:03 - loss: 0.0798 - accuracy: 0.97 - ETA: 4:01 - loss: 0.0801 - accuracy: 0.97 - ETA: 3:58 - loss: 0.0810 - accuracy: 0.97 - ETA: 3:56 - loss: 0.0799 - accuracy: 0.97 - ETA: 3:53 - loss: 0.0808 - accuracy: 0.97 - ETA: 3:51 - loss: 0.0812 - accuracy: 0.97 - ETA: 3:49 - loss: 0.0822 - accuracy: 0.97 - ETA: 3:47 - loss: 0.0831 - accuracy: 0.97 - ETA: 3:45 - loss: 0.0827 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0824 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0812 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0820 - accuracy: 0.97 - ETA: 3:35 - loss: 0.0819 - accuracy: 0.97 - ETA: 3:33 - loss: 0.0833 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0826 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0817 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0806 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0842 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0831 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0837 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0832 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0821 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0829 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0824 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0825 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0823 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0836 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0824 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0826 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0816 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0814 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0811 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0811 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0806 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0801 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0804 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0802 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0810 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0820 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0824 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0829 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0833 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0830 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0826 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0834 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0840 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0843 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0839 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0834 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0844 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0852 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0845 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0841 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0835 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0841 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0825 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0817 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0825 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0833 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0825 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0835 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0831 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0833 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0826 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0819 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0817 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0822 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0827 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0822 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0830 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0827 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0823 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0834 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0834 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0833 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0833 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0831 - accuracy: 0.97 - ETA: 59s - loss: 0.0829 - accuracy: 0.9783 - ETA: 57s - loss: 0.0829 - accuracy: 0.978 - ETA: 55s - loss: 0.0825 - accuracy: 0.978 - ETA: 52s - loss: 0.0827 - accuracy: 0.978 - ETA: 50s - loss: 0.0825 - accuracy: 0.978 - ETA: 48s - loss: 0.0820 - accuracy: 0.978 - ETA: 45s - loss: 0.0832 - accuracy: 0.978 - ETA: 43s - loss: 0.0831 - accuracy: 0.978 - ETA: 41s - loss: 0.0828 - accuracy: 0.978 - ETA: 38s - loss: 0.0830 - accuracy: 0.978 - ETA: 36s - loss: 0.0827 - accuracy: 0.978 - ETA: 34s - loss: 0.0826 - accuracy: 0.978 - ETA: 32s - loss: 0.0825 - accuracy: 0.978 - ETA: 29s - loss: 0.0837 - accuracy: 0.978 - ETA: 27s - loss: 0.0834 - accuracy: 0.978 - ETA: 25s - loss: 0.0832 - accuracy: 0.978 - ETA: 22s - loss: 0.0832 - accuracy: 0.978 - ETA: 20s - loss: 0.0837 - accuracy: 0.978 - ETA: 18s - loss: 0.0832 - accuracy: 0.978 - ETA: 15s - loss: 0.0835 - accuracy: 0.978 - ETA: 13s - loss: 0.0830 - accuracy: 0.978 - ETA: 11s - loss: 0.0826 - accuracy: 0.978 - ETA: 8s - loss: 0.0827 - accuracy: 0.978 - ETA: 6s - loss: 0.0839 - accuracy: 0.97 - ETA: 4s - loss: 0.0836 - accuracy: 0.97 - ETA: 2s - loss: 0.0840 - accuracy: 0.97 - 378s 20ms/step - loss: 0.0836 - accuracy: 0.9786 - val_loss: 1.9593 - val_accuracy: 0.8047\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:00 - loss: 0.0353 - accuracy: 0.98 - ETA: 6:02 - loss: 0.0294 - accuracy: 0.98 - ETA: 5:37 - loss: 0.0738 - accuracy: 0.97 - ETA: 5:41 - loss: 0.0643 - accuracy: 0.97 - ETA: 5:35 - loss: 0.0621 - accuracy: 0.97 - ETA: 5:31 - loss: 0.0702 - accuracy: 0.97 - ETA: 5:29 - loss: 0.0713 - accuracy: 0.97 - ETA: 5:27 - loss: 0.0668 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0598 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0651 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0636 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0606 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0562 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0561 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0565 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0576 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0587 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0648 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0624 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0679 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0669 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0688 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0673 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0691 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0679 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0663 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0673 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0650 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0657 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0660 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0657 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0727 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0736 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0716 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0700 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0682 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0685 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0668 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0684 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0678 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0666 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0673 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0677 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0695 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0681 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0696 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0724 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0716 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0713 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0711 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0734 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0749 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0760 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0761 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0754 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0747 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0735 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0740 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0733 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0736 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0757 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0763 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0756 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0745 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0743 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0747 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0760 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0762 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0759 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0766 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0758 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0769 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0763 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0766 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0758 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0766 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0764 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0767 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0762 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0763 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0756 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0757 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0757 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0753 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0770 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0766 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0762 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0765 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0773 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0776 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0776 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0777 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0790 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0796 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0789 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0787 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0782 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0778 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0779 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0773 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0770 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0779 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0776 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0772 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0775 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0775 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0770 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0771 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0773 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0781 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0776 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0774 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0770 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0766 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0760 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0760 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0758 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0761 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0760 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0758 - accuracy: 0.98 - ETA: 59s - loss: 0.0756 - accuracy: 0.9803 - ETA: 57s - loss: 0.0760 - accuracy: 0.980 - ETA: 54s - loss: 0.0760 - accuracy: 0.980 - ETA: 52s - loss: 0.0761 - accuracy: 0.980 - ETA: 50s - loss: 0.0756 - accuracy: 0.980 - ETA: 48s - loss: 0.0754 - accuracy: 0.980 - ETA: 45s - loss: 0.0751 - accuracy: 0.980 - ETA: 43s - loss: 0.0754 - accuracy: 0.980 - ETA: 41s - loss: 0.0756 - accuracy: 0.980 - ETA: 38s - loss: 0.0751 - accuracy: 0.980 - ETA: 36s - loss: 0.0747 - accuracy: 0.980 - ETA: 34s - loss: 0.0743 - accuracy: 0.980 - ETA: 31s - loss: 0.0741 - accuracy: 0.980 - ETA: 29s - loss: 0.0739 - accuracy: 0.980 - ETA: 27s - loss: 0.0738 - accuracy: 0.980 - ETA: 24s - loss: 0.0735 - accuracy: 0.980 - ETA: 22s - loss: 0.0735 - accuracy: 0.980 - ETA: 20s - loss: 0.0740 - accuracy: 0.980 - ETA: 18s - loss: 0.0739 - accuracy: 0.980 - ETA: 15s - loss: 0.0743 - accuracy: 0.980 - ETA: 13s - loss: 0.0740 - accuracy: 0.980 - ETA: 11s - loss: 0.0737 - accuracy: 0.980 - ETA: 8s - loss: 0.0736 - accuracy: 0.980 - ETA: 6s - loss: 0.0740 - accuracy: 0.98 - ETA: 4s - loss: 0.0739 - accuracy: 0.98 - ETA: 2s - loss: 0.0740 - accuracy: 0.98 - 370s 19ms/step - loss: 0.0741 - accuracy: 0.9804 - val_loss: 1.9665 - val_accuracy: 0.8041\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:03 - loss: 0.1137 - accuracy: 0.97 - ETA: 5:55 - loss: 0.1830 - accuracy: 0.96 - ETA: 5:51 - loss: 0.1600 - accuracy: 0.96 - ETA: 5:42 - loss: 0.1416 - accuracy: 0.97 - ETA: 5:33 - loss: 0.1474 - accuracy: 0.97 - ETA: 5:29 - loss: 0.1390 - accuracy: 0.97 - ETA: 5:23 - loss: 0.1239 - accuracy: 0.97 - ETA: 5:24 - loss: 0.1147 - accuracy: 0.97 - ETA: 5:22 - loss: 0.1144 - accuracy: 0.97 - ETA: 5:22 - loss: 0.1073 - accuracy: 0.97 - ETA: 5:20 - loss: 0.1139 - accuracy: 0.97 - ETA: 5:17 - loss: 0.1143 - accuracy: 0.97 - ETA: 5:13 - loss: 0.1138 - accuracy: 0.97 - ETA: 5:11 - loss: 0.1064 - accuracy: 0.97 - ETA: 5:10 - loss: 0.1030 - accuracy: 0.97 - ETA: 5:08 - loss: 0.1061 - accuracy: 0.97 - ETA: 5:06 - loss: 0.1014 - accuracy: 0.97 - ETA: 5:03 - loss: 0.0968 - accuracy: 0.97 - ETA: 4:59 - loss: 0.0946 - accuracy: 0.97 - ETA: 5:01 - loss: 0.0971 - accuracy: 0.97 - ETA: 5:06 - loss: 0.1026 - accuracy: 0.97 - ETA: 5:06 - loss: 0.1025 - accuracy: 0.97 - ETA: 5:03 - loss: 0.1037 - accuracy: 0.97 - ETA: 5:00 - loss: 0.1020 - accuracy: 0.97 - ETA: 4:58 - loss: 0.1010 - accuracy: 0.97 - ETA: 4:55 - loss: 0.1050 - accuracy: 0.97 - ETA: 4:52 - loss: 0.1032 - accuracy: 0.97 - ETA: 4:49 - loss: 0.1005 - accuracy: 0.97 - ETA: 4:47 - loss: 0.1017 - accuracy: 0.97 - ETA: 4:44 - loss: 0.1019 - accuracy: 0.97 - ETA: 4:41 - loss: 0.1020 - accuracy: 0.97 - ETA: 4:39 - loss: 0.0998 - accuracy: 0.97 - ETA: 4:36 - loss: 0.1008 - accuracy: 0.97 - ETA: 4:33 - loss: 0.1016 - accuracy: 0.97 - ETA: 4:30 - loss: 0.0988 - accuracy: 0.97 - ETA: 4:28 - loss: 0.1010 - accuracy: 0.97 - ETA: 4:26 - loss: 0.0998 - accuracy: 0.97 - ETA: 4:23 - loss: 0.1004 - accuracy: 0.97 - ETA: 4:20 - loss: 0.0994 - accuracy: 0.97 - ETA: 4:18 - loss: 0.1015 - accuracy: 0.97 - ETA: 4:15 - loss: 0.1036 - accuracy: 0.97 - ETA: 4:13 - loss: 0.1017 - accuracy: 0.97 - ETA: 4:11 - loss: 0.1003 - accuracy: 0.97 - ETA: 4:08 - loss: 0.0994 - accuracy: 0.97 - ETA: 4:06 - loss: 0.0976 - accuracy: 0.97 - ETA: 4:03 - loss: 0.0959 - accuracy: 0.97 - ETA: 4:00 - loss: 0.0966 - accuracy: 0.97 - ETA: 3:58 - loss: 0.0974 - accuracy: 0.97 - ETA: 3:55 - loss: 0.0961 - accuracy: 0.97 - ETA: 3:53 - loss: 0.0975 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0961 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0965 - accuracy: 0.97 - ETA: 3:46 - loss: 0.0964 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0956 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0955 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0961 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0964 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0961 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0964 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0950 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0947 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0938 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0932 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0920 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0918 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0911 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0915 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0912 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0917 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0917 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0906 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0904 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0904 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0898 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0899 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0896 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0900 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0891 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0895 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0895 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0906 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0901 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0894 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0888 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0882 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0888 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0879 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0881 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0879 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0880 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0895 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0887 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0883 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0877 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0878 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0870 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0866 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0860 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0853 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0839 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0832 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0826 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0827 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0824 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0817 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0824 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0834 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0830 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0826 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0832 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0835 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0830 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0836 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0836 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0834 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0830 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0824 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0826 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0822 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0819 - accuracy: 0.97 - ETA: 58s - loss: 0.0816 - accuracy: 0.9799 - ETA: 56s - loss: 0.0815 - accuracy: 0.979 - ETA: 54s - loss: 0.0813 - accuracy: 0.979 - ETA: 52s - loss: 0.0809 - accuracy: 0.979 - ETA: 49s - loss: 0.0814 - accuracy: 0.979 - ETA: 47s - loss: 0.0816 - accuracy: 0.979 - ETA: 45s - loss: 0.0812 - accuracy: 0.979 - ETA: 42s - loss: 0.0819 - accuracy: 0.979 - ETA: 40s - loss: 0.0815 - accuracy: 0.979 - ETA: 38s - loss: 0.0815 - accuracy: 0.979 - ETA: 36s - loss: 0.0814 - accuracy: 0.979 - ETA: 33s - loss: 0.0817 - accuracy: 0.979 - ETA: 31s - loss: 0.0820 - accuracy: 0.979 - ETA: 29s - loss: 0.0815 - accuracy: 0.979 - ETA: 27s - loss: 0.0817 - accuracy: 0.979 - ETA: 24s - loss: 0.0823 - accuracy: 0.979 - ETA: 22s - loss: 0.0818 - accuracy: 0.979 - ETA: 20s - loss: 0.0824 - accuracy: 0.979 - ETA: 18s - loss: 0.0823 - accuracy: 0.979 - ETA: 15s - loss: 0.0822 - accuracy: 0.979 - ETA: 13s - loss: 0.0819 - accuracy: 0.979 - ETA: 11s - loss: 0.0817 - accuracy: 0.979 - ETA: 8s - loss: 0.0818 - accuracy: 0.979 - ETA: 6s - loss: 0.0816 - accuracy: 0.97 - ETA: 4s - loss: 0.0816 - accuracy: 0.97 - ETA: 2s - loss: 0.0815 - accuracy: 0.97 - 378s 20ms/step - loss: 0.0824 - accuracy: 0.9794 - val_loss: 1.9611 - val_accuracy: 0.8041\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:00 - loss: 0.0079 - accuracy: 1.00 - ETA: 5:37 - loss: 0.0090 - accuracy: 1.00 - ETA: 5:38 - loss: 0.0093 - accuracy: 0.99 - ETA: 5:40 - loss: 0.0191 - accuracy: 0.99 - ETA: 5:35 - loss: 0.0169 - accuracy: 0.99 - ETA: 5:33 - loss: 0.0342 - accuracy: 0.99 - ETA: 5:32 - loss: 0.0360 - accuracy: 0.99 - ETA: 5:27 - loss: 0.0425 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0441 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0484 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0478 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0503 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0468 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0461 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0558 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0591 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0565 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0640 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0665 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0680 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0652 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0687 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0665 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0640 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0655 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0639 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0623 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0667 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0674 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0669 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0689 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0677 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0719 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0700 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0687 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0724 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0705 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0698 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0710 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0704 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0704 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0708 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0696 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0684 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0685 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0680 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0681 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0742 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0747 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0759 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0754 - accuracy: 0.97 - ETA: 3:44 - loss: 0.0751 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0748 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0754 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0776 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0771 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0787 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0775 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0780 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0775 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0768 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0774 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0766 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0757 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0772 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0778 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0782 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0779 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0770 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0761 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0758 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0747 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0746 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0768 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0777 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0775 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0783 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0774 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0780 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0782 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0789 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0785 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0792 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0784 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0793 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0789 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0788 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0787 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0789 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0787 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0779 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0773 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0767 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0764 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0759 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0755 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0751 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0757 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0765 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0774 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0778 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0781 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0775 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0772 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0769 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0771 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0769 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0774 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0771 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0774 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0772 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0785 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0793 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0794 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0790 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0790 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0784 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0782 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0784 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0786 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0791 - accuracy: 0.97 - ETA: 57s - loss: 0.0787 - accuracy: 0.9791 - ETA: 55s - loss: 0.0783 - accuracy: 0.979 - ETA: 53s - loss: 0.0783 - accuracy: 0.979 - ETA: 51s - loss: 0.0785 - accuracy: 0.979 - ETA: 48s - loss: 0.0783 - accuracy: 0.979 - ETA: 46s - loss: 0.0782 - accuracy: 0.979 - ETA: 44s - loss: 0.0787 - accuracy: 0.979 - ETA: 42s - loss: 0.0793 - accuracy: 0.979 - ETA: 39s - loss: 0.0788 - accuracy: 0.979 - ETA: 37s - loss: 0.0787 - accuracy: 0.979 - ETA: 35s - loss: 0.0788 - accuracy: 0.979 - ETA: 33s - loss: 0.0784 - accuracy: 0.979 - ETA: 31s - loss: 0.0782 - accuracy: 0.979 - ETA: 28s - loss: 0.0781 - accuracy: 0.979 - ETA: 26s - loss: 0.0777 - accuracy: 0.979 - ETA: 24s - loss: 0.0773 - accuracy: 0.979 - ETA: 22s - loss: 0.0769 - accuracy: 0.979 - ETA: 19s - loss: 0.0769 - accuracy: 0.979 - ETA: 17s - loss: 0.0765 - accuracy: 0.979 - ETA: 15s - loss: 0.0779 - accuracy: 0.979 - ETA: 13s - loss: 0.0784 - accuracy: 0.979 - ETA: 10s - loss: 0.0783 - accuracy: 0.979 - ETA: 8s - loss: 0.0796 - accuracy: 0.979 - ETA: 6s - loss: 0.0792 - accuracy: 0.97 - ETA: 4s - loss: 0.0790 - accuracy: 0.97 - ETA: 1s - loss: 0.0786 - accuracy: 0.97 - 364s 19ms/step - loss: 0.0785 - accuracy: 0.9795 - val_loss: 1.9995 - val_accuracy: 0.8020\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:29 - loss: 0.0276 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0476 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0454 - accuracy: 0.98 - ETA: 5:18 - loss: 0.0566 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0478 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0476 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0505 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0650 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0632 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0649 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0657 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0626 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0599 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0644 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0679 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0721 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0725 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0711 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0721 - accuracy: 0.97 - ETA: 4:56 - loss: 0.0715 - accuracy: 0.97 - ETA: 4:54 - loss: 0.0696 - accuracy: 0.97 - ETA: 4:52 - loss: 0.0705 - accuracy: 0.97 - ETA: 4:50 - loss: 0.0718 - accuracy: 0.97 - ETA: 4:47 - loss: 0.0730 - accuracy: 0.97 - ETA: 4:44 - loss: 0.0741 - accuracy: 0.97 - ETA: 4:42 - loss: 0.0752 - accuracy: 0.97 - ETA: 4:40 - loss: 0.0730 - accuracy: 0.97 - ETA: 4:38 - loss: 0.0765 - accuracy: 0.97 - ETA: 4:37 - loss: 0.0758 - accuracy: 0.97 - ETA: 4:35 - loss: 0.0746 - accuracy: 0.97 - ETA: 4:33 - loss: 0.0789 - accuracy: 0.97 - ETA: 4:31 - loss: 0.0784 - accuracy: 0.97 - ETA: 4:28 - loss: 0.0782 - accuracy: 0.97 - ETA: 4:26 - loss: 0.0765 - accuracy: 0.97 - ETA: 4:24 - loss: 0.0748 - accuracy: 0.97 - ETA: 4:21 - loss: 0.0763 - accuracy: 0.97 - ETA: 4:19 - loss: 0.0753 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0741 - accuracy: 0.97 - ETA: 4:14 - loss: 0.0731 - accuracy: 0.97 - ETA: 4:12 - loss: 0.0735 - accuracy: 0.97 - ETA: 4:09 - loss: 0.0790 - accuracy: 0.97 - ETA: 4:07 - loss: 0.0794 - accuracy: 0.97 - ETA: 4:05 - loss: 0.0793 - accuracy: 0.97 - ETA: 4:03 - loss: 0.0789 - accuracy: 0.97 - ETA: 4:01 - loss: 0.0781 - accuracy: 0.97 - ETA: 3:58 - loss: 0.0774 - accuracy: 0.97 - ETA: 3:56 - loss: 0.0777 - accuracy: 0.97 - ETA: 3:54 - loss: 0.0791 - accuracy: 0.97 - ETA: 3:51 - loss: 0.0795 - accuracy: 0.97 - ETA: 3:49 - loss: 0.0785 - accuracy: 0.97 - ETA: 3:46 - loss: 0.0790 - accuracy: 0.97 - ETA: 3:44 - loss: 0.0805 - accuracy: 0.97 - ETA: 3:41 - loss: 0.0804 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0825 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0824 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0815 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0805 - accuracy: 0.97 - ETA: 3:30 - loss: 0.0795 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0802 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0801 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0797 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0806 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0797 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0788 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0782 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0782 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0771 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0798 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0792 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0784 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0783 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0777 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0783 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0782 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0778 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0770 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0764 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0763 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0777 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0776 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0774 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0765 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0767 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0776 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0770 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0762 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0763 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0764 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0759 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0757 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0752 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0748 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0741 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0737 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0729 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0731 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0725 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0719 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0717 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0714 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0711 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0705 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0702 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0697 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0693 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0688 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0682 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0681 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0682 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0671 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0671 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0666 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0669 - accuracy: 0.98 - ETA: 58s - loss: 0.0667 - accuracy: 0.9812 - ETA: 56s - loss: 0.0663 - accuracy: 0.981 - ETA: 54s - loss: 0.0666 - accuracy: 0.981 - ETA: 51s - loss: 0.0669 - accuracy: 0.981 - ETA: 49s - loss: 0.0666 - accuracy: 0.981 - ETA: 47s - loss: 0.0676 - accuracy: 0.981 - ETA: 45s - loss: 0.0682 - accuracy: 0.981 - ETA: 42s - loss: 0.0685 - accuracy: 0.981 - ETA: 40s - loss: 0.0685 - accuracy: 0.981 - ETA: 38s - loss: 0.0685 - accuracy: 0.981 - ETA: 36s - loss: 0.0687 - accuracy: 0.981 - ETA: 33s - loss: 0.0690 - accuracy: 0.980 - ETA: 31s - loss: 0.0700 - accuracy: 0.980 - ETA: 29s - loss: 0.0699 - accuracy: 0.980 - ETA: 26s - loss: 0.0701 - accuracy: 0.980 - ETA: 24s - loss: 0.0711 - accuracy: 0.980 - ETA: 22s - loss: 0.0715 - accuracy: 0.980 - ETA: 20s - loss: 0.0713 - accuracy: 0.980 - ETA: 17s - loss: 0.0709 - accuracy: 0.980 - ETA: 15s - loss: 0.0706 - accuracy: 0.980 - ETA: 13s - loss: 0.0709 - accuracy: 0.980 - ETA: 11s - loss: 0.0713 - accuracy: 0.980 - ETA: 8s - loss: 0.0716 - accuracy: 0.980 - ETA: 6s - loss: 0.0718 - accuracy: 0.98 - ETA: 4s - loss: 0.0715 - accuracy: 0.98 - ETA: 1s - loss: 0.0720 - accuracy: 0.98 - 367s 19ms/step - loss: 0.0718 - accuracy: 0.9805 - val_loss: 1.9235 - val_accuracy: 0.8078\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:36 - loss: 0.0516 - accuracy: 0.96 - ETA: 5:33 - loss: 0.0377 - accuracy: 0.97 - ETA: 5:38 - loss: 0.0738 - accuracy: 0.97 - ETA: 5:36 - loss: 0.0593 - accuracy: 0.97 - ETA: 5:37 - loss: 0.0553 - accuracy: 0.97 - ETA: 5:37 - loss: 0.0480 - accuracy: 0.98 - ETA: 5:37 - loss: 0.0452 - accuracy: 0.98 - ETA: 5:37 - loss: 0.0422 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0487 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0546 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0567 - accuracy: 0.97 - ETA: 5:23 - loss: 0.0583 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0545 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0524 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0543 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0631 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0608 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0660 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0634 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0619 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0623 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0651 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0631 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0629 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0650 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0669 - accuracy: 0.97 - ETA: 4:44 - loss: 0.0668 - accuracy: 0.97 - ETA: 4:42 - loss: 0.0651 - accuracy: 0.97 - ETA: 4:39 - loss: 0.0653 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0640 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0638 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0624 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0638 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0626 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0645 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0675 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0676 - accuracy: 0.97 - ETA: 4:18 - loss: 0.0664 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0678 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0668 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0667 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0687 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0683 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0673 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0679 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0694 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0682 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0691 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0687 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0675 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0673 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0672 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0667 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0674 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0668 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0676 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0697 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0687 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0680 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0678 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0671 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0675 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0687 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0680 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0675 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0672 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0678 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0673 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0677 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0669 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0667 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0659 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0652 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0665 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0666 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0675 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0674 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0676 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0685 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0684 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0700 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0708 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0707 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0706 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0709 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0716 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0716 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0709 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0712 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0711 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0728 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0727 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0721 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0717 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0717 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0716 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0716 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0715 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0715 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0713 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0706 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0705 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0723 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0732 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0753 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0757 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0756 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0762 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0760 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0754 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0761 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0763 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0758 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0756 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0750 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0748 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0746 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0748 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0752 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0749 - accuracy: 0.97 - ETA: 58s - loss: 0.0748 - accuracy: 0.9797 - ETA: 56s - loss: 0.0742 - accuracy: 0.979 - ETA: 54s - loss: 0.0742 - accuracy: 0.979 - ETA: 51s - loss: 0.0745 - accuracy: 0.980 - ETA: 49s - loss: 0.0743 - accuracy: 0.980 - ETA: 47s - loss: 0.0739 - accuracy: 0.980 - ETA: 44s - loss: 0.0738 - accuracy: 0.980 - ETA: 42s - loss: 0.0734 - accuracy: 0.980 - ETA: 40s - loss: 0.0736 - accuracy: 0.980 - ETA: 38s - loss: 0.0738 - accuracy: 0.980 - ETA: 35s - loss: 0.0734 - accuracy: 0.980 - ETA: 33s - loss: 0.0735 - accuracy: 0.980 - ETA: 31s - loss: 0.0733 - accuracy: 0.980 - ETA: 29s - loss: 0.0737 - accuracy: 0.980 - ETA: 26s - loss: 0.0741 - accuracy: 0.979 - ETA: 24s - loss: 0.0740 - accuracy: 0.980 - ETA: 22s - loss: 0.0746 - accuracy: 0.979 - ETA: 20s - loss: 0.0744 - accuracy: 0.980 - ETA: 17s - loss: 0.0742 - accuracy: 0.979 - ETA: 15s - loss: 0.0738 - accuracy: 0.980 - ETA: 13s - loss: 0.0735 - accuracy: 0.980 - ETA: 11s - loss: 0.0735 - accuracy: 0.980 - ETA: 8s - loss: 0.0734 - accuracy: 0.980 - ETA: 6s - loss: 0.0732 - accuracy: 0.98 - ETA: 4s - loss: 0.0733 - accuracy: 0.98 - ETA: 1s - loss: 0.0729 - accuracy: 0.98 - 367s 19ms/step - loss: 0.0725 - accuracy: 0.9802 - val_loss: 1.9614 - val_accuracy: 0.8087\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:35 - loss: 0.1401 - accuracy: 0.99 - ETA: 5:35 - loss: 0.0798 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0780 - accuracy: 0.98 - ETA: 5:30 - loss: 0.0611 - accuracy: 0.99 - ETA: 5:30 - loss: 0.0647 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0659 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0655 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0621 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0628 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0659 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0617 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0643 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0616 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0703 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0732 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0773 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0746 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0783 - accuracy: 0.97 - ETA: 4:59 - loss: 0.0801 - accuracy: 0.97 - ETA: 4:57 - loss: 0.0777 - accuracy: 0.97 - ETA: 4:55 - loss: 0.0785 - accuracy: 0.97 - ETA: 4:54 - loss: 0.0809 - accuracy: 0.97 - ETA: 4:56 - loss: 0.0787 - accuracy: 0.97 - ETA: 4:55 - loss: 0.0770 - accuracy: 0.97 - ETA: 4:54 - loss: 0.0799 - accuracy: 0.97 - ETA: 4:54 - loss: 0.0773 - accuracy: 0.97 - ETA: 4:53 - loss: 0.0786 - accuracy: 0.97 - ETA: 4:51 - loss: 0.0774 - accuracy: 0.97 - ETA: 4:49 - loss: 0.0814 - accuracy: 0.97 - ETA: 4:46 - loss: 0.0816 - accuracy: 0.97 - ETA: 4:44 - loss: 0.0805 - accuracy: 0.97 - ETA: 4:41 - loss: 0.0837 - accuracy: 0.97 - ETA: 4:39 - loss: 0.0830 - accuracy: 0.97 - ETA: 4:37 - loss: 0.0822 - accuracy: 0.97 - ETA: 4:35 - loss: 0.0814 - accuracy: 0.97 - ETA: 4:34 - loss: 0.0820 - accuracy: 0.97 - ETA: 4:31 - loss: 0.0808 - accuracy: 0.97 - ETA: 4:28 - loss: 0.0803 - accuracy: 0.97 - ETA: 4:24 - loss: 0.0795 - accuracy: 0.97 - ETA: 4:21 - loss: 0.0819 - accuracy: 0.97 - ETA: 4:18 - loss: 0.0800 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0796 - accuracy: 0.97 - ETA: 4:14 - loss: 0.0800 - accuracy: 0.97 - ETA: 4:10 - loss: 0.0784 - accuracy: 0.97 - ETA: 4:08 - loss: 0.0770 - accuracy: 0.97 - ETA: 4:06 - loss: 0.0766 - accuracy: 0.97 - ETA: 4:04 - loss: 0.0758 - accuracy: 0.97 - ETA: 4:01 - loss: 0.0747 - accuracy: 0.97 - ETA: 3:58 - loss: 0.0749 - accuracy: 0.97 - ETA: 3:55 - loss: 0.0763 - accuracy: 0.97 - ETA: 3:51 - loss: 0.0776 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0768 - accuracy: 0.97 - ETA: 3:45 - loss: 0.0778 - accuracy: 0.97 - ETA: 3:42 - loss: 0.0768 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0772 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0784 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0772 - accuracy: 0.97 - ETA: 3:30 - loss: 0.0768 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0760 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0759 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0761 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0753 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0750 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0751 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0758 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0753 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0762 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0755 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0763 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0756 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0756 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0762 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0763 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0753 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0762 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0766 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0764 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0772 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0774 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0772 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0772 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0768 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0776 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0785 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0785 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0779 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0790 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0787 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0794 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0794 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0789 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0787 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0784 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0790 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0787 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0778 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0771 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0766 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0772 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0775 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0771 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0780 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0773 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0769 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0769 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0775 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0784 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0786 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0779 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0780 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0780 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0784 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0791 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0788 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0781 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0777 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0778 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0775 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0771 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0774 - accuracy: 0.97 - ETA: 58s - loss: 0.0773 - accuracy: 0.9793 - ETA: 56s - loss: 0.0772 - accuracy: 0.979 - ETA: 54s - loss: 0.0773 - accuracy: 0.979 - ETA: 52s - loss: 0.0773 - accuracy: 0.979 - ETA: 50s - loss: 0.0770 - accuracy: 0.979 - ETA: 48s - loss: 0.0770 - accuracy: 0.979 - ETA: 46s - loss: 0.0767 - accuracy: 0.979 - ETA: 44s - loss: 0.0778 - accuracy: 0.979 - ETA: 42s - loss: 0.0772 - accuracy: 0.979 - ETA: 41s - loss: 0.0770 - accuracy: 0.979 - ETA: 39s - loss: 0.0782 - accuracy: 0.979 - ETA: 37s - loss: 0.0778 - accuracy: 0.979 - ETA: 35s - loss: 0.0777 - accuracy: 0.979 - ETA: 33s - loss: 0.0773 - accuracy: 0.979 - ETA: 31s - loss: 0.0770 - accuracy: 0.979 - ETA: 29s - loss: 0.0779 - accuracy: 0.979 - ETA: 27s - loss: 0.0776 - accuracy: 0.979 - ETA: 25s - loss: 0.0776 - accuracy: 0.979 - ETA: 23s - loss: 0.0775 - accuracy: 0.979 - ETA: 21s - loss: 0.0771 - accuracy: 0.979 - ETA: 19s - loss: 0.0766 - accuracy: 0.979 - ETA: 17s - loss: 0.0764 - accuracy: 0.979 - ETA: 15s - loss: 0.0760 - accuracy: 0.979 - ETA: 13s - loss: 0.0764 - accuracy: 0.979 - ETA: 11s - loss: 0.0761 - accuracy: 0.979 - ETA: 9s - loss: 0.0756 - accuracy: 0.979 - ETA: 7s - loss: 0.0754 - accuracy: 0.98 - ETA: 5s - loss: 0.0756 - accuracy: 0.97 - ETA: 3s - loss: 0.0759 - accuracy: 0.97 - ETA: 1s - loss: 0.0760 - accuracy: 0.98 - 336s 17ms/step - loss: 0.0755 - accuracy: 0.9801 - val_loss: 2.0598 - val_accuracy: 0.8093\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:06 - loss: 0.0036 - accuracy: 1.00 - ETA: 3:59 - loss: 0.0236 - accuracy: 0.99 - ETA: 3:58 - loss: 0.0175 - accuracy: 0.99 - ETA: 3:56 - loss: 0.0155 - accuracy: 0.99 - ETA: 3:53 - loss: 0.0142 - accuracy: 0.99 - ETA: 3:51 - loss: 0.0251 - accuracy: 0.99 - ETA: 3:47 - loss: 0.0249 - accuracy: 0.99 - ETA: 3:45 - loss: 0.0230 - accuracy: 0.99 - ETA: 3:43 - loss: 0.0208 - accuracy: 0.99 - ETA: 3:41 - loss: 0.0204 - accuracy: 0.99 - ETA: 3:41 - loss: 0.0206 - accuracy: 0.99 - ETA: 3:40 - loss: 0.0218 - accuracy: 0.99 - ETA: 3:38 - loss: 0.0309 - accuracy: 0.99 - ETA: 3:36 - loss: 0.0334 - accuracy: 0.99 - ETA: 3:35 - loss: 0.0354 - accuracy: 0.99 - ETA: 3:33 - loss: 0.0338 - accuracy: 0.99 - ETA: 3:30 - loss: 0.0318 - accuracy: 0.99 - ETA: 3:29 - loss: 0.0303 - accuracy: 0.99 - ETA: 3:27 - loss: 0.0349 - accuracy: 0.99 - ETA: 3:25 - loss: 0.0402 - accuracy: 0.99 - ETA: 3:24 - loss: 0.0435 - accuracy: 0.99 - ETA: 3:22 - loss: 0.0454 - accuracy: 0.99 - ETA: 3:21 - loss: 0.0446 - accuracy: 0.99 - ETA: 3:19 - loss: 0.0489 - accuracy: 0.99 - ETA: 3:17 - loss: 0.0475 - accuracy: 0.99 - ETA: 3:15 - loss: 0.0492 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0506 - accuracy: 0.99 - ETA: 3:12 - loss: 0.0562 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0566 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0548 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0553 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0537 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0581 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0564 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0598 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0621 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0631 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0626 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0637 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0647 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0619 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0627 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0639 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0638 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0631 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0624 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0653 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0652 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0654 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0644 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0651 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0642 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0647 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0652 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0650 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0660 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0660 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0661 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0669 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0675 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0683 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0701 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0692 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0686 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0696 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0708 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0701 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0686 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0678 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0671 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0658 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0644 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0653 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0641 - accuracy: 0.98 - ETA: 59s - loss: 0.0643 - accuracy: 0.9833 - ETA: 58s - loss: 0.0640 - accuracy: 0.983 - ETA: 56s - loss: 0.0644 - accuracy: 0.983 - ETA: 54s - loss: 0.0654 - accuracy: 0.983 - ETA: 53s - loss: 0.0650 - accuracy: 0.983 - ETA: 51s - loss: 0.0645 - accuracy: 0.983 - ETA: 50s - loss: 0.0646 - accuracy: 0.983 - ETA: 48s - loss: 0.0646 - accuracy: 0.983 - ETA: 46s - loss: 0.0663 - accuracy: 0.983 - ETA: 45s - loss: 0.0658 - accuracy: 0.983 - ETA: 43s - loss: 0.0658 - accuracy: 0.983 - ETA: 42s - loss: 0.0656 - accuracy: 0.983 - ETA: 40s - loss: 0.0656 - accuracy: 0.983 - ETA: 39s - loss: 0.0656 - accuracy: 0.983 - ETA: 37s - loss: 0.0659 - accuracy: 0.983 - ETA: 35s - loss: 0.0658 - accuracy: 0.983 - ETA: 34s - loss: 0.0655 - accuracy: 0.983 - ETA: 32s - loss: 0.0651 - accuracy: 0.983 - ETA: 31s - loss: 0.0649 - accuracy: 0.983 - ETA: 29s - loss: 0.0650 - accuracy: 0.983 - ETA: 28s - loss: 0.0650 - accuracy: 0.983 - ETA: 26s - loss: 0.0656 - accuracy: 0.983 - ETA: 25s - loss: 0.0651 - accuracy: 0.983 - ETA: 23s - loss: 0.0653 - accuracy: 0.983 - ETA: 21s - loss: 0.0649 - accuracy: 0.983 - ETA: 20s - loss: 0.0645 - accuracy: 0.983 - ETA: 18s - loss: 0.0647 - accuracy: 0.983 - ETA: 17s - loss: 0.0644 - accuracy: 0.983 - ETA: 15s - loss: 0.0640 - accuracy: 0.983 - ETA: 13s - loss: 0.0640 - accuracy: 0.983 - ETA: 12s - loss: 0.0639 - accuracy: 0.983 - ETA: 10s - loss: 0.0640 - accuracy: 0.983 - ETA: 9s - loss: 0.0640 - accuracy: 0.983 - ETA: 7s - loss: 0.0653 - accuracy: 0.98 - ETA: 6s - loss: 0.0649 - accuracy: 0.98 - ETA: 4s - loss: 0.0647 - accuracy: 0.98 - ETA: 2s - loss: 0.0651 - accuracy: 0.98 - ETA: 1s - loss: 0.0649 - accuracy: 0.98 - 261s 14ms/step - loss: 0.0649 - accuracy: 0.9832 - val_loss: 2.0136 - val_accuracy: 0.8078\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:05 - loss: 0.0124 - accuracy: 0.99 - ETA: 3:54 - loss: 0.0826 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0756 - accuracy: 0.97 - ETA: 3:45 - loss: 0.0585 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0597 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0517 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0516 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0539 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0573 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0630 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0697 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0694 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0684 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0695 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0701 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0685 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0712 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0703 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0704 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0737 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0706 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0700 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0692 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0697 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0674 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0666 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0670 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0648 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0633 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0636 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0622 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0644 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0651 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0672 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0663 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0655 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0663 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0647 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0640 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0655 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0649 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0641 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0642 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0633 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0636 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0622 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0628 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0620 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0619 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0620 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0658 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0650 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0659 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0667 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0659 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0655 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0649 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0650 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0664 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0654 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0651 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0651 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0646 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0630 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0643 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0641 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0644 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0619 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0653 - accuracy: 0.98 - ETA: 59s - loss: 0.0657 - accuracy: 0.9813 - ETA: 57s - loss: 0.0659 - accuracy: 0.981 - ETA: 56s - loss: 0.0657 - accuracy: 0.981 - ETA: 54s - loss: 0.0655 - accuracy: 0.981 - ETA: 53s - loss: 0.0663 - accuracy: 0.981 - ETA: 51s - loss: 0.0663 - accuracy: 0.981 - ETA: 50s - loss: 0.0664 - accuracy: 0.981 - ETA: 48s - loss: 0.0661 - accuracy: 0.981 - ETA: 46s - loss: 0.0657 - accuracy: 0.981 - ETA: 45s - loss: 0.0663 - accuracy: 0.980 - ETA: 43s - loss: 0.0666 - accuracy: 0.980 - ETA: 42s - loss: 0.0664 - accuracy: 0.981 - ETA: 40s - loss: 0.0663 - accuracy: 0.981 - ETA: 39s - loss: 0.0662 - accuracy: 0.981 - ETA: 37s - loss: 0.0666 - accuracy: 0.980 - ETA: 35s - loss: 0.0668 - accuracy: 0.980 - ETA: 34s - loss: 0.0672 - accuracy: 0.980 - ETA: 32s - loss: 0.0671 - accuracy: 0.980 - ETA: 31s - loss: 0.0679 - accuracy: 0.980 - ETA: 29s - loss: 0.0684 - accuracy: 0.980 - ETA: 28s - loss: 0.0686 - accuracy: 0.980 - ETA: 26s - loss: 0.0683 - accuracy: 0.980 - ETA: 24s - loss: 0.0684 - accuracy: 0.980 - ETA: 23s - loss: 0.0681 - accuracy: 0.980 - ETA: 21s - loss: 0.0679 - accuracy: 0.980 - ETA: 20s - loss: 0.0685 - accuracy: 0.980 - ETA: 18s - loss: 0.0681 - accuracy: 0.980 - ETA: 17s - loss: 0.0683 - accuracy: 0.980 - ETA: 15s - loss: 0.0692 - accuracy: 0.980 - ETA: 13s - loss: 0.0697 - accuracy: 0.980 - ETA: 12s - loss: 0.0698 - accuracy: 0.980 - ETA: 10s - loss: 0.0700 - accuracy: 0.980 - ETA: 9s - loss: 0.0705 - accuracy: 0.980 - ETA: 7s - loss: 0.0707 - accuracy: 0.98 - ETA: 6s - loss: 0.0710 - accuracy: 0.98 - ETA: 4s - loss: 0.0713 - accuracy: 0.98 - ETA: 2s - loss: 0.0711 - accuracy: 0.98 - ETA: 1s - loss: 0.0708 - accuracy: 0.98 - 253s 13ms/step - loss: 0.0705 - accuracy: 0.9803 - val_loss: 2.0459 - val_accuracy: 0.8012\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:47 - loss: 0.0419 - accuracy: 0.99 - ETA: 3:46 - loss: 0.1159 - accuracy: 0.97 - ETA: 3:48 - loss: 0.1243 - accuracy: 0.97 - ETA: 3:44 - loss: 0.1110 - accuracy: 0.97 - ETA: 3:44 - loss: 0.0957 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0863 - accuracy: 0.97 - ETA: 3:42 - loss: 0.0833 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0852 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0781 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0744 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0724 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0741 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0736 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0777 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0774 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0763 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0744 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0722 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0721 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0692 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0672 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0665 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0696 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0669 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0735 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0751 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0727 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0705 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0685 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0707 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0701 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0712 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0770 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0754 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0746 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0728 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0718 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0712 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0708 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0695 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0687 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0680 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0678 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0670 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0684 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0674 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0678 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0683 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0685 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0690 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0687 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0676 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0665 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0656 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0650 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0653 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0655 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0652 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0651 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0661 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0651 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0648 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0648 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0665 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0667 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0687 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0689 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0692 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0693 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0695 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0702 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0707 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0700 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0705 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0708 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0721 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0720 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0716 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0717 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0711 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0715 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0714 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0712 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0734 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0728 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0728 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0722 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0723 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0720 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0722 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0722 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0726 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0731 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0734 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0737 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0747 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0746 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0744 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0752 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0752 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0766 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0764 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0756 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0754 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0751 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0749 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0748 - accuracy: 0.98 - ETA: 59s - loss: 0.0749 - accuracy: 0.9812 - ETA: 57s - loss: 0.0746 - accuracy: 0.981 - ETA: 56s - loss: 0.0747 - accuracy: 0.981 - ETA: 54s - loss: 0.0748 - accuracy: 0.981 - ETA: 52s - loss: 0.0744 - accuracy: 0.981 - ETA: 51s - loss: 0.0740 - accuracy: 0.981 - ETA: 49s - loss: 0.0738 - accuracy: 0.981 - ETA: 47s - loss: 0.0737 - accuracy: 0.981 - ETA: 46s - loss: 0.0741 - accuracy: 0.981 - ETA: 44s - loss: 0.0738 - accuracy: 0.981 - ETA: 42s - loss: 0.0739 - accuracy: 0.981 - ETA: 41s - loss: 0.0736 - accuracy: 0.981 - ETA: 39s - loss: 0.0732 - accuracy: 0.981 - ETA: 37s - loss: 0.0735 - accuracy: 0.981 - ETA: 36s - loss: 0.0745 - accuracy: 0.981 - ETA: 34s - loss: 0.0740 - accuracy: 0.981 - ETA: 32s - loss: 0.0744 - accuracy: 0.981 - ETA: 31s - loss: 0.0739 - accuracy: 0.981 - ETA: 29s - loss: 0.0739 - accuracy: 0.981 - ETA: 27s - loss: 0.0740 - accuracy: 0.981 - ETA: 26s - loss: 0.0746 - accuracy: 0.981 - ETA: 24s - loss: 0.0746 - accuracy: 0.981 - ETA: 22s - loss: 0.0741 - accuracy: 0.981 - ETA: 21s - loss: 0.0743 - accuracy: 0.981 - ETA: 19s - loss: 0.0738 - accuracy: 0.981 - ETA: 17s - loss: 0.0747 - accuracy: 0.981 - ETA: 16s - loss: 0.0747 - accuracy: 0.981 - ETA: 14s - loss: 0.0744 - accuracy: 0.981 - ETA: 12s - loss: 0.0740 - accuracy: 0.981 - ETA: 11s - loss: 0.0737 - accuracy: 0.981 - ETA: 9s - loss: 0.0732 - accuracy: 0.981 - ETA: 8s - loss: 0.0735 - accuracy: 0.98 - ETA: 6s - loss: 0.0731 - accuracy: 0.98 - ETA: 4s - loss: 0.0729 - accuracy: 0.98 - ETA: 3s - loss: 0.0727 - accuracy: 0.98 - ETA: 1s - loss: 0.0729 - accuracy: 0.98 - 266s 14ms/step - loss: 0.0729 - accuracy: 0.9814 - val_loss: 2.1440 - val_accuracy: 0.8024\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:12 - loss: 0.0117 - accuracy: 1.00 - ETA: 4:18 - loss: 0.0674 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0784 - accuracy: 0.97 - ETA: 4:22 - loss: 0.0699 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0873 - accuracy: 0.97 - ETA: 4:09 - loss: 0.0783 - accuracy: 0.97 - ETA: 4:05 - loss: 0.0828 - accuracy: 0.97 - ETA: 4:01 - loss: 0.0764 - accuracy: 0.97 - ETA: 3:56 - loss: 0.0690 - accuracy: 0.97 - ETA: 3:52 - loss: 0.0733 - accuracy: 0.97 - ETA: 3:49 - loss: 0.0697 - accuracy: 0.97 - ETA: 3:45 - loss: 0.0727 - accuracy: 0.97 - ETA: 3:44 - loss: 0.0714 - accuracy: 0.97 - ETA: 3:41 - loss: 0.0669 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0648 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0624 - accuracy: 0.97 - ETA: 3:35 - loss: 0.0620 - accuracy: 0.97 - ETA: 3:33 - loss: 0.0619 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0590 - accuracy: 0.97 - ETA: 3:30 - loss: 0.0564 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0575 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0562 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0562 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0541 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0553 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0534 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0538 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0591 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0596 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0583 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0595 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0607 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0637 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0663 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0645 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0660 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0675 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0675 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0710 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0698 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0729 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0728 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0768 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0762 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0753 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0746 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0731 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0725 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0714 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0713 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0715 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0707 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0706 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0711 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0712 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0704 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0713 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0705 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0706 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0696 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0703 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0724 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0729 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0731 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0721 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0712 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0713 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0709 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0700 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0700 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0697 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0693 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0687 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0692 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0695 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0691 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0685 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0691 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0687 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0698 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0698 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0698 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0697 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0697 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0693 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0688 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0688 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0689 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0682 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0671 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0666 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0674 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0673 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0681 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0674 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0682 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0681 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0693 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0693 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0697 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0712 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0709 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0704 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0704 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0703 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0703 - accuracy: 0.98 - ETA: 59s - loss: 0.0700 - accuracy: 0.9804 - ETA: 57s - loss: 0.0696 - accuracy: 0.980 - ETA: 56s - loss: 0.0696 - accuracy: 0.980 - ETA: 54s - loss: 0.0703 - accuracy: 0.980 - ETA: 53s - loss: 0.0704 - accuracy: 0.980 - ETA: 51s - loss: 0.0707 - accuracy: 0.980 - ETA: 49s - loss: 0.0710 - accuracy: 0.980 - ETA: 48s - loss: 0.0707 - accuracy: 0.980 - ETA: 46s - loss: 0.0706 - accuracy: 0.980 - ETA: 44s - loss: 0.0705 - accuracy: 0.980 - ETA: 43s - loss: 0.0717 - accuracy: 0.980 - ETA: 41s - loss: 0.0711 - accuracy: 0.980 - ETA: 40s - loss: 0.0709 - accuracy: 0.980 - ETA: 38s - loss: 0.0715 - accuracy: 0.980 - ETA: 36s - loss: 0.0709 - accuracy: 0.980 - ETA: 35s - loss: 0.0707 - accuracy: 0.980 - ETA: 33s - loss: 0.0708 - accuracy: 0.980 - ETA: 31s - loss: 0.0707 - accuracy: 0.980 - ETA: 30s - loss: 0.0706 - accuracy: 0.980 - ETA: 28s - loss: 0.0705 - accuracy: 0.980 - ETA: 27s - loss: 0.0712 - accuracy: 0.980 - ETA: 25s - loss: 0.0718 - accuracy: 0.980 - ETA: 23s - loss: 0.0714 - accuracy: 0.980 - ETA: 22s - loss: 0.0711 - accuracy: 0.980 - ETA: 20s - loss: 0.0712 - accuracy: 0.980 - ETA: 19s - loss: 0.0708 - accuracy: 0.980 - ETA: 17s - loss: 0.0705 - accuracy: 0.980 - ETA: 15s - loss: 0.0705 - accuracy: 0.980 - ETA: 14s - loss: 0.0710 - accuracy: 0.980 - ETA: 12s - loss: 0.0708 - accuracy: 0.980 - ETA: 11s - loss: 0.0709 - accuracy: 0.980 - ETA: 9s - loss: 0.0707 - accuracy: 0.980 - ETA: 7s - loss: 0.0709 - accuracy: 0.98 - ETA: 6s - loss: 0.0709 - accuracy: 0.98 - ETA: 4s - loss: 0.0711 - accuracy: 0.98 - ETA: 3s - loss: 0.0709 - accuracy: 0.98 - ETA: 1s - loss: 0.0706 - accuracy: 0.98 - 262s 14ms/step - loss: 0.0704 - accuracy: 0.9804 - val_loss: 2.0515 - val_accuracy: 0.8045\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:23 - loss: 0.0499 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0463 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0387 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0369 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0564 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0564 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0609 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0662 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0642 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0713 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0755 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0737 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0727 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0756 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0735 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0742 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0712 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0717 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0706 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0681 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0689 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0691 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0689 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0694 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0672 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0686 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0685 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0682 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0672 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0677 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0658 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0642 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0647 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0648 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0683 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0685 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0677 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0694 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0691 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0700 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0699 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0704 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0700 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0687 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0679 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0669 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0671 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0661 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0664 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0667 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0667 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0666 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0656 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0648 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0655 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0662 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0665 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0685 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0689 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0679 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0679 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0675 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0676 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0671 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0665 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0655 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0654 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0661 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0661 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0658 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0654 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0653 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0662 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0661 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0662 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0658 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0686 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0683 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0679 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0673 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0662 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0661 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0658 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0654 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0653 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0668 - accuracy: 0.98 - ETA: 58s - loss: 0.0671 - accuracy: 0.9819 - ETA: 56s - loss: 0.0673 - accuracy: 0.981 - ETA: 55s - loss: 0.0669 - accuracy: 0.981 - ETA: 53s - loss: 0.0668 - accuracy: 0.981 - ETA: 51s - loss: 0.0668 - accuracy: 0.981 - ETA: 50s - loss: 0.0671 - accuracy: 0.981 - ETA: 48s - loss: 0.0666 - accuracy: 0.982 - ETA: 47s - loss: 0.0665 - accuracy: 0.982 - ETA: 45s - loss: 0.0670 - accuracy: 0.982 - ETA: 43s - loss: 0.0672 - accuracy: 0.981 - ETA: 42s - loss: 0.0672 - accuracy: 0.981 - ETA: 40s - loss: 0.0671 - accuracy: 0.981 - ETA: 38s - loss: 0.0672 - accuracy: 0.981 - ETA: 37s - loss: 0.0673 - accuracy: 0.981 - ETA: 35s - loss: 0.0670 - accuracy: 0.981 - ETA: 33s - loss: 0.0666 - accuracy: 0.982 - ETA: 32s - loss: 0.0664 - accuracy: 0.982 - ETA: 30s - loss: 0.0663 - accuracy: 0.981 - ETA: 29s - loss: 0.0663 - accuracy: 0.982 - ETA: 27s - loss: 0.0668 - accuracy: 0.981 - ETA: 25s - loss: 0.0666 - accuracy: 0.981 - ETA: 24s - loss: 0.0666 - accuracy: 0.982 - ETA: 22s - loss: 0.0662 - accuracy: 0.982 - ETA: 20s - loss: 0.0662 - accuracy: 0.982 - ETA: 19s - loss: 0.0658 - accuracy: 0.982 - ETA: 17s - loss: 0.0657 - accuracy: 0.982 - ETA: 16s - loss: 0.0664 - accuracy: 0.982 - ETA: 14s - loss: 0.0669 - accuracy: 0.982 - ETA: 12s - loss: 0.0676 - accuracy: 0.981 - ETA: 11s - loss: 0.0676 - accuracy: 0.982 - ETA: 9s - loss: 0.0678 - accuracy: 0.981 - ETA: 7s - loss: 0.0676 - accuracy: 0.98 - ETA: 6s - loss: 0.0677 - accuracy: 0.98 - ETA: 4s - loss: 0.0678 - accuracy: 0.98 - ETA: 3s - loss: 0.0676 - accuracy: 0.98 - ETA: 1s - loss: 0.0672 - accuracy: 0.98 - 268s 14ms/step - loss: 0.0670 - accuracy: 0.9818 - val_loss: 2.0381 - val_accuracy: 0.8093\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:01 - loss: 0.1454 - accuracy: 0.96 - ETA: 3:58 - loss: 0.0735 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0780 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0803 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0728 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0841 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0873 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0773 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0818 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0762 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0710 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0681 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0647 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0618 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0659 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0620 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0599 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0573 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0583 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0601 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0581 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0564 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0544 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0573 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0561 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0562 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0547 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0537 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0557 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0572 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0577 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0583 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0568 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0561 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0547 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0542 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0557 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0550 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0536 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0572 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0569 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0564 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0557 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0550 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0542 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0541 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0540 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0550 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0555 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0576 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0566 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0585 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0616 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0607 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0621 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0621 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0626 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0627 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0623 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0622 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0626 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0650 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0642 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0625 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0623 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0623 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0621 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0621 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0669 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0666 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0660 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0653 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0646 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0647 - accuracy: 0.98 - ETA: 59s - loss: 0.0642 - accuracy: 0.9833 - ETA: 57s - loss: 0.0638 - accuracy: 0.983 - ETA: 56s - loss: 0.0647 - accuracy: 0.983 - ETA: 54s - loss: 0.0643 - accuracy: 0.983 - ETA: 52s - loss: 0.0644 - accuracy: 0.983 - ETA: 51s - loss: 0.0641 - accuracy: 0.983 - ETA: 49s - loss: 0.0636 - accuracy: 0.983 - ETA: 48s - loss: 0.0632 - accuracy: 0.983 - ETA: 46s - loss: 0.0627 - accuracy: 0.983 - ETA: 44s - loss: 0.0623 - accuracy: 0.983 - ETA: 43s - loss: 0.0619 - accuracy: 0.983 - ETA: 41s - loss: 0.0619 - accuracy: 0.983 - ETA: 40s - loss: 0.0618 - accuracy: 0.983 - ETA: 38s - loss: 0.0615 - accuracy: 0.983 - ETA: 37s - loss: 0.0612 - accuracy: 0.983 - ETA: 35s - loss: 0.0612 - accuracy: 0.983 - ETA: 33s - loss: 0.0607 - accuracy: 0.984 - ETA: 32s - loss: 0.0604 - accuracy: 0.984 - ETA: 30s - loss: 0.0611 - accuracy: 0.983 - ETA: 28s - loss: 0.0607 - accuracy: 0.983 - ETA: 27s - loss: 0.0603 - accuracy: 0.984 - ETA: 25s - loss: 0.0607 - accuracy: 0.984 - ETA: 24s - loss: 0.0605 - accuracy: 0.984 - ETA: 22s - loss: 0.0617 - accuracy: 0.983 - ETA: 20s - loss: 0.0617 - accuracy: 0.983 - ETA: 19s - loss: 0.0619 - accuracy: 0.983 - ETA: 17s - loss: 0.0618 - accuracy: 0.983 - ETA: 15s - loss: 0.0618 - accuracy: 0.983 - ETA: 14s - loss: 0.0621 - accuracy: 0.983 - ETA: 12s - loss: 0.0618 - accuracy: 0.983 - ETA: 11s - loss: 0.0621 - accuracy: 0.983 - ETA: 9s - loss: 0.0625 - accuracy: 0.983 - ETA: 7s - loss: 0.0628 - accuracy: 0.98 - ETA: 6s - loss: 0.0627 - accuracy: 0.98 - ETA: 4s - loss: 0.0625 - accuracy: 0.98 - ETA: 3s - loss: 0.0621 - accuracy: 0.98 - ETA: 1s - loss: 0.0617 - accuracy: 0.98 - 259s 13ms/step - loss: 0.0616 - accuracy: 0.9839 - val_loss: 2.1914 - val_accuracy: 0.8031\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:09 - loss: 0.0283 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0307 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0239 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0352 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0382 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0348 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0400 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0417 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0521 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0552 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0525 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0601 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0647 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0670 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0689 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0678 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0699 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0729 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0729 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0743 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0759 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0740 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0708 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0688 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0668 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0662 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0673 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0665 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0671 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0650 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0631 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0627 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0608 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0613 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0620 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0671 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0663 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0646 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0631 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0644 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0626 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0622 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0608 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0604 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0599 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0595 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0584 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0585 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0581 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0583 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0577 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0586 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0590 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0589 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0584 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0577 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0567 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0573 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0565 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0560 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0573 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0573 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0575 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0570 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0564 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0561 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0557 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0554 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0561 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0564 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0568 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0576 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0566 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0569 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0576 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0571 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0571 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0543 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0555 - accuracy: 0.98 - ETA: 58s - loss: 0.0550 - accuracy: 0.9841 - ETA: 56s - loss: 0.0559 - accuracy: 0.983 - ETA: 55s - loss: 0.0564 - accuracy: 0.983 - ETA: 53s - loss: 0.0570 - accuracy: 0.983 - ETA: 52s - loss: 0.0572 - accuracy: 0.983 - ETA: 50s - loss: 0.0580 - accuracy: 0.983 - ETA: 49s - loss: 0.0578 - accuracy: 0.983 - ETA: 47s - loss: 0.0577 - accuracy: 0.983 - ETA: 45s - loss: 0.0574 - accuracy: 0.983 - ETA: 44s - loss: 0.0578 - accuracy: 0.982 - ETA: 42s - loss: 0.0579 - accuracy: 0.982 - ETA: 41s - loss: 0.0576 - accuracy: 0.982 - ETA: 39s - loss: 0.0572 - accuracy: 0.983 - ETA: 37s - loss: 0.0571 - accuracy: 0.983 - ETA: 36s - loss: 0.0569 - accuracy: 0.983 - ETA: 34s - loss: 0.0577 - accuracy: 0.983 - ETA: 33s - loss: 0.0574 - accuracy: 0.983 - ETA: 31s - loss: 0.0572 - accuracy: 0.983 - ETA: 30s - loss: 0.0568 - accuracy: 0.983 - ETA: 28s - loss: 0.0565 - accuracy: 0.983 - ETA: 26s - loss: 0.0567 - accuracy: 0.983 - ETA: 25s - loss: 0.0567 - accuracy: 0.983 - ETA: 23s - loss: 0.0568 - accuracy: 0.983 - ETA: 22s - loss: 0.0578 - accuracy: 0.983 - ETA: 20s - loss: 0.0590 - accuracy: 0.982 - ETA: 18s - loss: 0.0588 - accuracy: 0.982 - ETA: 17s - loss: 0.0590 - accuracy: 0.983 - ETA: 15s - loss: 0.0592 - accuracy: 0.982 - ETA: 14s - loss: 0.0589 - accuracy: 0.982 - ETA: 12s - loss: 0.0590 - accuracy: 0.983 - ETA: 10s - loss: 0.0591 - accuracy: 0.982 - ETA: 9s - loss: 0.0589 - accuracy: 0.982 - ETA: 7s - loss: 0.0588 - accuracy: 0.98 - ETA: 6s - loss: 0.0588 - accuracy: 0.98 - ETA: 4s - loss: 0.0585 - accuracy: 0.98 - ETA: 2s - loss: 0.0585 - accuracy: 0.98 - ETA: 1s - loss: 0.0583 - accuracy: 0.98 - 259s 13ms/step - loss: 0.0586 - accuracy: 0.9829 - val_loss: 2.1644 - val_accuracy: 0.8016\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:59 - loss: 0.0580 - accuracy: 0.98 - ETA: 3:58 - loss: 0.1017 - accuracy: 0.97 - ETA: 3:52 - loss: 0.1049 - accuracy: 0.97 - ETA: 3:52 - loss: 0.0857 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0848 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0780 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0729 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0653 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0651 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0623 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0588 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0595 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0557 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0525 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0509 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0524 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0522 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0583 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0589 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0577 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0608 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0592 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0647 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0644 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0644 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0673 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0672 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0673 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0666 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0662 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0698 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0713 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0729 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0711 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0695 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0682 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0724 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0716 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0702 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0689 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0688 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0695 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0685 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0677 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0668 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0687 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0693 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0691 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0689 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0686 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0678 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0670 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0659 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0658 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0652 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0648 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0639 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0631 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0629 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0625 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0629 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0632 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0632 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0652 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0662 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0661 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0653 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0656 - accuracy: 0.98 - ETA: 59s - loss: 0.0655 - accuracy: 0.9840 - ETA: 58s - loss: 0.0651 - accuracy: 0.984 - ETA: 56s - loss: 0.0652 - accuracy: 0.984 - ETA: 55s - loss: 0.0653 - accuracy: 0.984 - ETA: 53s - loss: 0.0650 - accuracy: 0.984 - ETA: 52s - loss: 0.0648 - accuracy: 0.984 - ETA: 50s - loss: 0.0647 - accuracy: 0.983 - ETA: 48s - loss: 0.0653 - accuracy: 0.983 - ETA: 47s - loss: 0.0651 - accuracy: 0.983 - ETA: 45s - loss: 0.0648 - accuracy: 0.983 - ETA: 43s - loss: 0.0644 - accuracy: 0.984 - ETA: 42s - loss: 0.0646 - accuracy: 0.984 - ETA: 40s - loss: 0.0646 - accuracy: 0.984 - ETA: 38s - loss: 0.0644 - accuracy: 0.984 - ETA: 37s - loss: 0.0643 - accuracy: 0.984 - ETA: 35s - loss: 0.0641 - accuracy: 0.984 - ETA: 33s - loss: 0.0651 - accuracy: 0.984 - ETA: 31s - loss: 0.0646 - accuracy: 0.984 - ETA: 30s - loss: 0.0649 - accuracy: 0.984 - ETA: 28s - loss: 0.0650 - accuracy: 0.983 - ETA: 26s - loss: 0.0651 - accuracy: 0.983 - ETA: 25s - loss: 0.0650 - accuracy: 0.983 - ETA: 23s - loss: 0.0648 - accuracy: 0.983 - ETA: 21s - loss: 0.0645 - accuracy: 0.983 - ETA: 19s - loss: 0.0653 - accuracy: 0.983 - ETA: 17s - loss: 0.0651 - accuracy: 0.983 - ETA: 16s - loss: 0.0653 - accuracy: 0.983 - ETA: 14s - loss: 0.0653 - accuracy: 0.983 - ETA: 12s - loss: 0.0650 - accuracy: 0.983 - ETA: 10s - loss: 0.0658 - accuracy: 0.983 - ETA: 8s - loss: 0.0656 - accuracy: 0.983 - ETA: 7s - loss: 0.0655 - accuracy: 0.98 - ETA: 5s - loss: 0.0661 - accuracy: 0.98 - ETA: 3s - loss: 0.0661 - accuracy: 0.98 - ETA: 1s - loss: 0.0662 - accuracy: 0.98 - 309s 16ms/step - loss: 0.0666 - accuracy: 0.9832 - val_loss: 2.1192 - val_accuracy: 0.8113\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:43 - loss: 0.0273 - accuracy: 0.99 - ETA: 5:44 - loss: 0.0388 - accuracy: 0.98 - ETA: 5:38 - loss: 0.0582 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0455 - accuracy: 0.99 - ETA: 5:29 - loss: 0.0508 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0519 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0510 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0556 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0521 - accuracy: 0.98 - ETA: 5:18 - loss: 0.0588 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0596 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0658 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0628 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0591 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0699 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0665 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0660 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0675 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0644 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0615 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0643 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0661 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0642 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0673 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0694 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0668 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0670 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0674 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0691 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0677 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0678 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0682 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0666 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0650 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0648 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0641 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0632 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0636 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0635 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0632 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0616 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0605 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0604 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0601 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0596 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0633 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0643 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0634 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0633 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0634 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0645 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0634 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0627 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0622 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0621 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0613 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0618 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0608 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0610 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0602 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0602 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0602 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0595 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0605 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0598 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0592 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0604 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0602 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0595 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0589 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0586 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0576 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0576 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0572 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0576 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0573 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0568 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0564 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0561 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0557 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0555 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0552 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0553 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0558 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0572 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0566 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0580 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0575 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0579 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0576 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0577 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0580 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0585 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0585 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0584 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0593 - accuracy: 0.98 - ETA: 59s - loss: 0.0593 - accuracy: 0.9837 - ETA: 57s - loss: 0.0596 - accuracy: 0.983 - ETA: 54s - loss: 0.0601 - accuracy: 0.983 - ETA: 52s - loss: 0.0600 - accuracy: 0.983 - ETA: 50s - loss: 0.0599 - accuracy: 0.983 - ETA: 47s - loss: 0.0603 - accuracy: 0.983 - ETA: 45s - loss: 0.0605 - accuracy: 0.983 - ETA: 43s - loss: 0.0605 - accuracy: 0.983 - ETA: 41s - loss: 0.0608 - accuracy: 0.983 - ETA: 38s - loss: 0.0609 - accuracy: 0.983 - ETA: 36s - loss: 0.0605 - accuracy: 0.983 - ETA: 34s - loss: 0.0604 - accuracy: 0.983 - ETA: 31s - loss: 0.0605 - accuracy: 0.983 - ETA: 29s - loss: 0.0604 - accuracy: 0.983 - ETA: 27s - loss: 0.0606 - accuracy: 0.983 - ETA: 25s - loss: 0.0603 - accuracy: 0.983 - ETA: 22s - loss: 0.0599 - accuracy: 0.983 - ETA: 20s - loss: 0.0600 - accuracy: 0.983 - ETA: 18s - loss: 0.0596 - accuracy: 0.983 - ETA: 15s - loss: 0.0599 - accuracy: 0.983 - ETA: 13s - loss: 0.0596 - accuracy: 0.983 - ETA: 11s - loss: 0.0593 - accuracy: 0.983 - ETA: 8s - loss: 0.0596 - accuracy: 0.983 - ETA: 6s - loss: 0.0600 - accuracy: 0.98 - ETA: 4s - loss: 0.0600 - accuracy: 0.98 - ETA: 2s - loss: 0.0603 - accuracy: 0.98 - 375s 19ms/step - loss: 0.0601 - accuracy: 0.9835 - val_loss: 2.0837 - val_accuracy: 0.8084\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:03 - loss: 0.0087 - accuracy: 1.00 - ETA: 5:53 - loss: 0.0111 - accuracy: 0.99 - ETA: 5:49 - loss: 0.0282 - accuracy: 0.99 - ETA: 5:41 - loss: 0.0522 - accuracy: 0.99 - ETA: 5:31 - loss: 0.0633 - accuracy: 0.98 - ETA: 5:30 - loss: 0.0674 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0733 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0766 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0699 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0736 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0673 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0630 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0611 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0585 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0666 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0664 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0631 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0603 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0628 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0604 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0596 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0580 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0574 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0598 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0605 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0675 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0661 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0639 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0620 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0614 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0614 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0619 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0643 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0663 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0678 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0671 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0674 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0665 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0655 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0665 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0665 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0651 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0646 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0647 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0640 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0648 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0639 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0645 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0652 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0655 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0646 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0647 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0661 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0654 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0658 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0648 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0640 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0641 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0632 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0633 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0633 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0634 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0636 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0639 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0639 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0630 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0628 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0625 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0618 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0616 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0613 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0607 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0609 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0620 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0627 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0626 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0619 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0611 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0607 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0611 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0623 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0617 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0610 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0607 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0609 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0615 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0623 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0638 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0632 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0629 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0637 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0646 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0646 - accuracy: 0.98 - ETA: 58s - loss: 0.0642 - accuracy: 0.9837 - ETA: 55s - loss: 0.0643 - accuracy: 0.983 - ETA: 53s - loss: 0.0643 - accuracy: 0.983 - ETA: 50s - loss: 0.0641 - accuracy: 0.983 - ETA: 48s - loss: 0.0639 - accuracy: 0.983 - ETA: 46s - loss: 0.0640 - accuracy: 0.983 - ETA: 43s - loss: 0.0638 - accuracy: 0.983 - ETA: 41s - loss: 0.0639 - accuracy: 0.983 - ETA: 39s - loss: 0.0639 - accuracy: 0.983 - ETA: 36s - loss: 0.0634 - accuracy: 0.983 - ETA: 34s - loss: 0.0633 - accuracy: 0.983 - ETA: 32s - loss: 0.0636 - accuracy: 0.983 - ETA: 29s - loss: 0.0632 - accuracy: 0.983 - ETA: 27s - loss: 0.0632 - accuracy: 0.983 - ETA: 25s - loss: 0.0627 - accuracy: 0.983 - ETA: 22s - loss: 0.0627 - accuracy: 0.983 - ETA: 20s - loss: 0.0628 - accuracy: 0.983 - ETA: 18s - loss: 0.0631 - accuracy: 0.983 - ETA: 15s - loss: 0.0631 - accuracy: 0.983 - ETA: 13s - loss: 0.0628 - accuracy: 0.983 - ETA: 11s - loss: 0.0633 - accuracy: 0.983 - ETA: 9s - loss: 0.0632 - accuracy: 0.983 - ETA: 6s - loss: 0.0628 - accuracy: 0.98 - ETA: 4s - loss: 0.0632 - accuracy: 0.98 - ETA: 2s - loss: 0.0632 - accuracy: 0.98 - 376s 19ms/step - loss: 0.0629 - accuracy: 0.9836 - val_loss: 2.2656 - val_accuracy: 0.8062\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:30 - loss: 0.0813 - accuracy: 0.98 - ETA: 5:38 - loss: 0.0453 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0502 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0461 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0674 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0623 - accuracy: 0.98 - ETA: 5:31 - loss: 0.0628 - accuracy: 0.98 - ETA: 5:27 - loss: 0.0668 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0682 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0649 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0610 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0581 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0584 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0641 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0684 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0698 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0780 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0753 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0714 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0709 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0708 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0682 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0706 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0694 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0699 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0677 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0661 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0650 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0650 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0630 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0616 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0628 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0655 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0654 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0671 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0681 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0668 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0671 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0671 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0665 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0685 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0680 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0667 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0674 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0650 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0651 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0650 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0652 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0649 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0675 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0677 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0702 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0691 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0683 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0675 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0666 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0655 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0654 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0661 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0658 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0653 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0656 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0653 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0644 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0639 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0649 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0648 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0660 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0658 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0660 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0666 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0670 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0663 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0662 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0656 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0654 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0652 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0648 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0657 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0660 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0671 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0675 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0668 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0672 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0669 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0662 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0660 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0656 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0651 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0641 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0635 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0635 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0640 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0620 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0605 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0610 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0610 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0608 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0590 - accuracy: 0.98 - ETA: 59s - loss: 0.0590 - accuracy: 0.9847 - ETA: 57s - loss: 0.0588 - accuracy: 0.984 - ETA: 55s - loss: 0.0584 - accuracy: 0.984 - ETA: 52s - loss: 0.0581 - accuracy: 0.984 - ETA: 50s - loss: 0.0585 - accuracy: 0.984 - ETA: 48s - loss: 0.0586 - accuracy: 0.984 - ETA: 46s - loss: 0.0588 - accuracy: 0.984 - ETA: 43s - loss: 0.0590 - accuracy: 0.984 - ETA: 41s - loss: 0.0593 - accuracy: 0.984 - ETA: 39s - loss: 0.0590 - accuracy: 0.984 - ETA: 36s - loss: 0.0589 - accuracy: 0.984 - ETA: 34s - loss: 0.0588 - accuracy: 0.984 - ETA: 32s - loss: 0.0585 - accuracy: 0.984 - ETA: 29s - loss: 0.0590 - accuracy: 0.984 - ETA: 27s - loss: 0.0600 - accuracy: 0.984 - ETA: 25s - loss: 0.0601 - accuracy: 0.984 - ETA: 22s - loss: 0.0603 - accuracy: 0.984 - ETA: 20s - loss: 0.0601 - accuracy: 0.984 - ETA: 18s - loss: 0.0597 - accuracy: 0.984 - ETA: 15s - loss: 0.0595 - accuracy: 0.984 - ETA: 13s - loss: 0.0603 - accuracy: 0.984 - ETA: 11s - loss: 0.0606 - accuracy: 0.984 - ETA: 8s - loss: 0.0610 - accuracy: 0.984 - ETA: 6s - loss: 0.0610 - accuracy: 0.98 - ETA: 4s - loss: 0.0613 - accuracy: 0.98 - ETA: 2s - loss: 0.0612 - accuracy: 0.98 - 376s 19ms/step - loss: 0.0612 - accuracy: 0.9843 - val_loss: 2.1756 - val_accuracy: 0.8064\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:35 - loss: 0.0052 - accuracy: 1.00 - ETA: 5:40 - loss: 0.0107 - accuracy: 1.00 - ETA: 5:45 - loss: 0.0377 - accuracy: 0.98 - ETA: 5:43 - loss: 0.0464 - accuracy: 0.98 - ETA: 5:40 - loss: 0.0479 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0568 - accuracy: 0.98 - ETA: 5:34 - loss: 0.0501 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0461 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0529 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0583 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0567 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0613 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0581 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0540 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0555 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0559 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0570 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0578 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0559 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0577 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0571 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0645 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0670 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0677 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0656 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0690 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0723 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0721 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0733 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0768 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0758 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0740 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0748 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0732 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0731 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0766 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0789 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0773 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0759 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0751 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0737 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0725 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0715 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0706 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0698 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0685 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0711 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0720 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0709 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0721 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0715 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0705 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0698 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0697 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0694 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0696 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0693 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0697 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0704 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0693 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0691 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0680 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0674 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0674 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0665 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0657 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0649 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0646 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0648 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0661 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0664 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0661 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0659 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0659 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0659 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0654 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0657 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0654 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0653 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0656 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0667 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0662 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0674 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0677 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0682 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0675 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0671 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0672 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0673 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0676 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0677 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0678 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0675 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0674 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0676 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0673 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0669 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0662 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0626 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0620 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0623 - accuracy: 0.98 - ETA: 58s - loss: 0.0622 - accuracy: 0.9845 - ETA: 55s - loss: 0.0621 - accuracy: 0.984 - ETA: 53s - loss: 0.0618 - accuracy: 0.984 - ETA: 51s - loss: 0.0618 - accuracy: 0.984 - ETA: 48s - loss: 0.0615 - accuracy: 0.984 - ETA: 46s - loss: 0.0616 - accuracy: 0.984 - ETA: 44s - loss: 0.0613 - accuracy: 0.984 - ETA: 41s - loss: 0.0610 - accuracy: 0.984 - ETA: 39s - loss: 0.0608 - accuracy: 0.984 - ETA: 37s - loss: 0.0605 - accuracy: 0.984 - ETA: 34s - loss: 0.0603 - accuracy: 0.984 - ETA: 32s - loss: 0.0602 - accuracy: 0.984 - ETA: 30s - loss: 0.0601 - accuracy: 0.984 - ETA: 27s - loss: 0.0602 - accuracy: 0.984 - ETA: 25s - loss: 0.0605 - accuracy: 0.984 - ETA: 23s - loss: 0.0601 - accuracy: 0.984 - ETA: 20s - loss: 0.0598 - accuracy: 0.984 - ETA: 18s - loss: 0.0595 - accuracy: 0.984 - ETA: 16s - loss: 0.0602 - accuracy: 0.984 - ETA: 13s - loss: 0.0601 - accuracy: 0.984 - ETA: 11s - loss: 0.0599 - accuracy: 0.984 - ETA: 9s - loss: 0.0605 - accuracy: 0.984 - ETA: 6s - loss: 0.0607 - accuracy: 0.98 - ETA: 4s - loss: 0.0606 - accuracy: 0.98 - ETA: 2s - loss: 0.0605 - accuracy: 0.98 - 380s 20ms/step - loss: 0.0603 - accuracy: 0.9846 - val_loss: 2.2157 - val_accuracy: 0.8049\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:39 - loss: 0.0233 - accuracy: 0.99 - ETA: 5:39 - loss: 0.0460 - accuracy: 0.98 - ETA: 5:40 - loss: 0.0512 - accuracy: 0.97 - ETA: 5:42 - loss: 0.0458 - accuracy: 0.98 - ETA: 5:46 - loss: 0.0691 - accuracy: 0.97 - ETA: 5:45 - loss: 0.0612 - accuracy: 0.97 - ETA: 5:43 - loss: 0.0548 - accuracy: 0.97 - ETA: 5:41 - loss: 0.0713 - accuracy: 0.97 - ETA: 5:40 - loss: 0.0712 - accuracy: 0.97 - ETA: 5:40 - loss: 0.0666 - accuracy: 0.97 - ETA: 5:37 - loss: 0.0673 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0708 - accuracy: 0.97 - ETA: 5:32 - loss: 0.0678 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0644 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0660 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0692 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0717 - accuracy: 0.98 - ETA: 5:18 - loss: 0.0758 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0848 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0813 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0804 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0786 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0791 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0817 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0810 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0870 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0855 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0844 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0845 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0833 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0828 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0856 - accuracy: 0.97 - ETA: 4:39 - loss: 0.0841 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0862 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0839 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0823 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0820 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0808 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0817 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0798 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0787 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0809 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0812 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0807 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0809 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0797 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0800 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0791 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0787 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0783 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0782 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0775 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0766 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0763 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0750 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0758 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0764 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0753 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0743 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0743 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0742 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0732 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0725 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0713 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0709 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0708 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0722 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0721 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0717 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0718 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0711 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0710 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0703 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0710 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0702 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0718 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0723 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0716 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0722 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0714 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0709 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0729 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0724 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0719 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0717 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0710 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0702 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0697 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0689 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0681 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0685 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0692 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0685 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0680 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0673 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0670 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0667 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0670 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0673 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0671 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0675 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0671 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0678 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0683 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0683 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0678 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0678 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0683 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0685 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0681 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0669 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0673 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0681 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0676 - accuracy: 0.98 - ETA: 58s - loss: 0.0680 - accuracy: 0.9834 - ETA: 55s - loss: 0.0675 - accuracy: 0.983 - ETA: 53s - loss: 0.0671 - accuracy: 0.983 - ETA: 51s - loss: 0.0666 - accuracy: 0.983 - ETA: 48s - loss: 0.0665 - accuracy: 0.983 - ETA: 46s - loss: 0.0662 - accuracy: 0.983 - ETA: 44s - loss: 0.0658 - accuracy: 0.984 - ETA: 41s - loss: 0.0655 - accuracy: 0.984 - ETA: 39s - loss: 0.0654 - accuracy: 0.984 - ETA: 37s - loss: 0.0651 - accuracy: 0.984 - ETA: 34s - loss: 0.0651 - accuracy: 0.984 - ETA: 32s - loss: 0.0653 - accuracy: 0.983 - ETA: 30s - loss: 0.0654 - accuracy: 0.983 - ETA: 27s - loss: 0.0651 - accuracy: 0.984 - ETA: 25s - loss: 0.0662 - accuracy: 0.983 - ETA: 23s - loss: 0.0658 - accuracy: 0.983 - ETA: 20s - loss: 0.0656 - accuracy: 0.983 - ETA: 18s - loss: 0.0660 - accuracy: 0.983 - ETA: 16s - loss: 0.0661 - accuracy: 0.983 - ETA: 13s - loss: 0.0661 - accuracy: 0.983 - ETA: 11s - loss: 0.0660 - accuracy: 0.983 - ETA: 9s - loss: 0.0661 - accuracy: 0.983 - ETA: 6s - loss: 0.0665 - accuracy: 0.98 - ETA: 4s - loss: 0.0664 - accuracy: 0.98 - ETA: 2s - loss: 0.0662 - accuracy: 0.98 - 378s 20ms/step - loss: 0.0662 - accuracy: 0.9837 - val_loss: 2.2132 - val_accuracy: 0.8020\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:30 - loss: 0.0178 - accuracy: 0.99 - ETA: 5:22 - loss: 0.0358 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0270 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0346 - accuracy: 0.99 - ETA: 5:19 - loss: 0.0391 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0546 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0490 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0430 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0661 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0649 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0615 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0665 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0753 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0727 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0682 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0665 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0629 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0616 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0585 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0575 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0578 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0562 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0552 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0548 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0553 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0542 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0524 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0516 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0602 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0598 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0581 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0569 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0585 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0587 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0586 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0599 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0596 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0599 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0596 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0590 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0584 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0571 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0583 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0573 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0578 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0568 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0588 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0581 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0591 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0588 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0577 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0575 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0567 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0576 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0568 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0568 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0558 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0552 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0557 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0558 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0559 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0560 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0577 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0590 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0581 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0573 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0572 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0567 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0567 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0565 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0584 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0590 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0589 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0590 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0598 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0600 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0595 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0597 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0594 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0599 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0601 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0595 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0598 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0592 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0587 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0584 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0596 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0598 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0595 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0592 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0600 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0604 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0599 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0585 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0577 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0573 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0573 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0584 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0569 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0574 - accuracy: 0.98 - ETA: 57s - loss: 0.0575 - accuracy: 0.9863 - ETA: 55s - loss: 0.0571 - accuracy: 0.986 - ETA: 53s - loss: 0.0568 - accuracy: 0.986 - ETA: 50s - loss: 0.0563 - accuracy: 0.986 - ETA: 48s - loss: 0.0562 - accuracy: 0.986 - ETA: 46s - loss: 0.0564 - accuracy: 0.986 - ETA: 43s - loss: 0.0568 - accuracy: 0.986 - ETA: 41s - loss: 0.0570 - accuracy: 0.986 - ETA: 39s - loss: 0.0566 - accuracy: 0.986 - ETA: 36s - loss: 0.0569 - accuracy: 0.986 - ETA: 34s - loss: 0.0569 - accuracy: 0.986 - ETA: 32s - loss: 0.0568 - accuracy: 0.986 - ETA: 29s - loss: 0.0568 - accuracy: 0.986 - ETA: 27s - loss: 0.0566 - accuracy: 0.986 - ETA: 25s - loss: 0.0565 - accuracy: 0.986 - ETA: 22s - loss: 0.0570 - accuracy: 0.986 - ETA: 20s - loss: 0.0568 - accuracy: 0.986 - ETA: 18s - loss: 0.0568 - accuracy: 0.986 - ETA: 15s - loss: 0.0565 - accuracy: 0.986 - ETA: 13s - loss: 0.0562 - accuracy: 0.986 - ETA: 11s - loss: 0.0570 - accuracy: 0.986 - ETA: 9s - loss: 0.0573 - accuracy: 0.986 - ETA: 6s - loss: 0.0572 - accuracy: 0.98 - ETA: 4s - loss: 0.0571 - accuracy: 0.98 - ETA: 2s - loss: 0.0573 - accuracy: 0.98 - 377s 19ms/step - loss: 0.0571 - accuracy: 0.9863 - val_loss: 2.0750 - val_accuracy: 0.8091\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:48 - loss: 6.3606e-04 - accuracy: 1.00 - ETA: 5:59 - loss: 0.0136 - accuracy: 0.9922   - ETA: 5:56 - loss: 0.0103 - accuracy: 0.99 - ETA: 5:55 - loss: 0.0105 - accuracy: 0.99 - ETA: 5:50 - loss: 0.0259 - accuracy: 0.99 - ETA: 5:46 - loss: 0.0277 - accuracy: 0.98 - ETA: 5:41 - loss: 0.0240 - accuracy: 0.99 - ETA: 5:38 - loss: 0.0257 - accuracy: 0.99 - ETA: 5:37 - loss: 0.0288 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0281 - accuracy: 0.98 - ETA: 5:31 - loss: 0.0309 - accuracy: 0.99 - ETA: 5:26 - loss: 0.0355 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0356 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0359 - accuracy: 0.98 - ETA: 5:18 - loss: 0.0346 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0326 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0337 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0355 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0381 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0397 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0379 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0395 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0420 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0413 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0446 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0461 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0446 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0434 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0444 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0441 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0439 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0429 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0461 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0488 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0505 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0534 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0529 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0525 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0517 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0510 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0498 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0504 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0494 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0505 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0507 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0510 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0511 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0507 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0517 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0528 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0535 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0532 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0534 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0531 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0523 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0516 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0515 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0507 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0506 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0505 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0509 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0509 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0489 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0505 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0511 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0507 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0510 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0505 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0500 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0499 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0497 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0494 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0492 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0497 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0500 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0495 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0493 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0505 - accuracy: 0.98 - ETA: 58s - loss: 0.0503 - accuracy: 0.9864 - ETA: 56s - loss: 0.0508 - accuracy: 0.986 - ETA: 53s - loss: 0.0506 - accuracy: 0.986 - ETA: 51s - loss: 0.0508 - accuracy: 0.986 - ETA: 49s - loss: 0.0508 - accuracy: 0.986 - ETA: 46s - loss: 0.0507 - accuracy: 0.986 - ETA: 44s - loss: 0.0516 - accuracy: 0.986 - ETA: 42s - loss: 0.0512 - accuracy: 0.986 - ETA: 39s - loss: 0.0510 - accuracy: 0.986 - ETA: 37s - loss: 0.0516 - accuracy: 0.986 - ETA: 34s - loss: 0.0513 - accuracy: 0.986 - ETA: 32s - loss: 0.0518 - accuracy: 0.986 - ETA: 30s - loss: 0.0517 - accuracy: 0.986 - ETA: 27s - loss: 0.0515 - accuracy: 0.986 - ETA: 25s - loss: 0.0515 - accuracy: 0.986 - ETA: 23s - loss: 0.0515 - accuracy: 0.986 - ETA: 20s - loss: 0.0514 - accuracy: 0.986 - ETA: 18s - loss: 0.0516 - accuracy: 0.986 - ETA: 16s - loss: 0.0513 - accuracy: 0.986 - ETA: 13s - loss: 0.0515 - accuracy: 0.986 - ETA: 11s - loss: 0.0527 - accuracy: 0.986 - ETA: 9s - loss: 0.0539 - accuracy: 0.985 - ETA: 6s - loss: 0.0548 - accuracy: 0.98 - ETA: 4s - loss: 0.0545 - accuracy: 0.98 - ETA: 2s - loss: 0.0552 - accuracy: 0.98 - 382s 20ms/step - loss: 0.0559 - accuracy: 0.9857 - val_loss: 2.1550 - val_accuracy: 0.8058\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:24 - loss: 0.0036 - accuracy: 1.00 - ETA: 5:34 - loss: 0.0277 - accuracy: 0.98 - ETA: 5:40 - loss: 0.0335 - accuracy: 0.98 - ETA: 5:39 - loss: 0.0523 - accuracy: 0.98 - ETA: 5:40 - loss: 0.0571 - accuracy: 0.98 - ETA: 5:37 - loss: 0.0529 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0575 - accuracy: 0.98 - ETA: 5:32 - loss: 0.0566 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0550 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0596 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0603 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0646 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0604 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0580 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0550 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0534 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0567 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0542 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0534 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0517 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0495 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0481 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0467 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0456 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0454 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0440 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0431 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0424 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0440 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0531 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0522 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0512 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0500 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0539 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0525 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0531 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0524 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0549 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0540 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0531 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0523 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0517 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0519 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0508 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0513 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0529 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0540 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0536 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0530 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0520 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0511 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0519 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0511 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0500 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0499 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0506 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0508 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0506 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0501 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0507 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0516 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0510 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0515 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0519 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0515 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0520 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0534 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0528 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0533 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0542 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0545 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0545 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0543 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0543 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0539 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0553 - accuracy: 0.98 - ETA: 58s - loss: 0.0550 - accuracy: 0.9858 - ETA: 55s - loss: 0.0550 - accuracy: 0.985 - ETA: 53s - loss: 0.0552 - accuracy: 0.985 - ETA: 51s - loss: 0.0550 - accuracy: 0.985 - ETA: 48s - loss: 0.0550 - accuracy: 0.985 - ETA: 46s - loss: 0.0547 - accuracy: 0.985 - ETA: 44s - loss: 0.0553 - accuracy: 0.985 - ETA: 41s - loss: 0.0560 - accuracy: 0.985 - ETA: 39s - loss: 0.0559 - accuracy: 0.985 - ETA: 37s - loss: 0.0556 - accuracy: 0.985 - ETA: 34s - loss: 0.0554 - accuracy: 0.985 - ETA: 32s - loss: 0.0553 - accuracy: 0.985 - ETA: 30s - loss: 0.0549 - accuracy: 0.985 - ETA: 27s - loss: 0.0545 - accuracy: 0.985 - ETA: 25s - loss: 0.0547 - accuracy: 0.985 - ETA: 23s - loss: 0.0547 - accuracy: 0.985 - ETA: 20s - loss: 0.0554 - accuracy: 0.985 - ETA: 18s - loss: 0.0555 - accuracy: 0.985 - ETA: 16s - loss: 0.0554 - accuracy: 0.985 - ETA: 13s - loss: 0.0556 - accuracy: 0.985 - ETA: 11s - loss: 0.0557 - accuracy: 0.985 - ETA: 9s - loss: 0.0556 - accuracy: 0.985 - ETA: 6s - loss: 0.0555 - accuracy: 0.98 - ETA: 4s - loss: 0.0555 - accuracy: 0.98 - ETA: 2s - loss: 0.0561 - accuracy: 0.98 - 380s 20ms/step - loss: 0.0562 - accuracy: 0.9853 - val_loss: 2.1226 - val_accuracy: 0.8047\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:34 - loss: 0.0134 - accuracy: 1.00 - ETA: 5:34 - loss: 0.0071 - accuracy: 1.00 - ETA: 5:32 - loss: 0.0048 - accuracy: 1.00 - ETA: 5:27 - loss: 0.0169 - accuracy: 0.99 - ETA: 5:27 - loss: 0.0141 - accuracy: 0.99 - ETA: 5:26 - loss: 0.0199 - accuracy: 0.99 - ETA: 5:22 - loss: 0.0227 - accuracy: 0.99 - ETA: 5:19 - loss: 0.0291 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0366 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0362 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0414 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0435 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0427 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0422 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0442 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0425 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0411 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0443 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0446 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0467 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0489 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0469 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0455 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0452 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0463 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0466 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0462 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0460 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0450 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0456 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0466 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0471 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0469 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0459 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0461 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0451 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0465 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0508 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0496 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0488 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0483 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0473 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0467 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0460 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0468 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0485 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0477 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0500 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0484 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0489 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0499 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0499 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0495 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0489 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0501 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0496 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0490 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0498 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0486 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0486 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0505 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0507 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0510 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0520 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0527 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0539 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0540 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0541 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0542 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0540 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0538 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0520 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0498 - accuracy: 0.98 - ETA: 57s - loss: 0.0498 - accuracy: 0.9866 - ETA: 55s - loss: 0.0498 - accuracy: 0.986 - ETA: 53s - loss: 0.0494 - accuracy: 0.986 - ETA: 50s - loss: 0.0493 - accuracy: 0.986 - ETA: 48s - loss: 0.0490 - accuracy: 0.986 - ETA: 45s - loss: 0.0487 - accuracy: 0.986 - ETA: 43s - loss: 0.0489 - accuracy: 0.986 - ETA: 40s - loss: 0.0490 - accuracy: 0.986 - ETA: 38s - loss: 0.0487 - accuracy: 0.986 - ETA: 35s - loss: 0.0487 - accuracy: 0.986 - ETA: 33s - loss: 0.0488 - accuracy: 0.986 - ETA: 31s - loss: 0.0495 - accuracy: 0.986 - ETA: 28s - loss: 0.0494 - accuracy: 0.986 - ETA: 26s - loss: 0.0495 - accuracy: 0.986 - ETA: 23s - loss: 0.0497 - accuracy: 0.986 - ETA: 21s - loss: 0.0496 - accuracy: 0.986 - ETA: 19s - loss: 0.0493 - accuracy: 0.986 - ETA: 16s - loss: 0.0495 - accuracy: 0.986 - ETA: 14s - loss: 0.0503 - accuracy: 0.986 - ETA: 11s - loss: 0.0511 - accuracy: 0.986 - ETA: 9s - loss: 0.0508 - accuracy: 0.986 - ETA: 6s - loss: 0.0509 - accuracy: 0.98 - ETA: 4s - loss: 0.0529 - accuracy: 0.98 - ETA: 2s - loss: 0.0528 - accuracy: 0.98 - 390s 20ms/step - loss: 0.0531 - accuracy: 0.9861 - val_loss: 2.2225 - val_accuracy: 0.8045\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:42 - loss: 0.0535 - accuracy: 0.98 - ETA: 6:00 - loss: 0.0360 - accuracy: 0.98 - ETA: 5:58 - loss: 0.0308 - accuracy: 0.98 - ETA: 5:55 - loss: 0.0241 - accuracy: 0.99 - ETA: 5:50 - loss: 0.0342 - accuracy: 0.98 - ETA: 5:44 - loss: 0.0541 - accuracy: 0.98 - ETA: 5:41 - loss: 0.0477 - accuracy: 0.98 - ETA: 5:39 - loss: 0.0476 - accuracy: 0.98 - ETA: 5:38 - loss: 0.0442 - accuracy: 0.98 - ETA: 5:34 - loss: 0.0455 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0487 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0450 - accuracy: 0.98 - ETA: 5:27 - loss: 0.0419 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0398 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0432 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0408 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0416 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0444 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0511 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0497 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0499 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0482 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0517 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0512 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0498 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0501 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0493 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0507 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0500 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0493 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0493 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0506 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0496 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0482 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0468 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0469 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0464 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0456 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0457 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0479 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0488 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0492 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0485 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0476 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0473 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0474 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0469 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0480 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0482 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0470 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0473 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0483 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0481 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0480 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0474 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0480 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0479 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0479 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0476 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0509 - accuracy: 0.98 - ETA: 58s - loss: 0.0509 - accuracy: 0.9862 - ETA: 55s - loss: 0.0513 - accuracy: 0.986 - ETA: 53s - loss: 0.0516 - accuracy: 0.986 - ETA: 51s - loss: 0.0522 - accuracy: 0.986 - ETA: 48s - loss: 0.0523 - accuracy: 0.986 - ETA: 46s - loss: 0.0522 - accuracy: 0.986 - ETA: 43s - loss: 0.0536 - accuracy: 0.985 - ETA: 41s - loss: 0.0532 - accuracy: 0.985 - ETA: 39s - loss: 0.0531 - accuracy: 0.985 - ETA: 37s - loss: 0.0533 - accuracy: 0.985 - ETA: 34s - loss: 0.0532 - accuracy: 0.985 - ETA: 32s - loss: 0.0535 - accuracy: 0.985 - ETA: 30s - loss: 0.0534 - accuracy: 0.985 - ETA: 27s - loss: 0.0531 - accuracy: 0.985 - ETA: 25s - loss: 0.0538 - accuracy: 0.985 - ETA: 23s - loss: 0.0537 - accuracy: 0.985 - ETA: 20s - loss: 0.0536 - accuracy: 0.985 - ETA: 18s - loss: 0.0539 - accuracy: 0.985 - ETA: 16s - loss: 0.0538 - accuracy: 0.985 - ETA: 13s - loss: 0.0536 - accuracy: 0.985 - ETA: 11s - loss: 0.0535 - accuracy: 0.985 - ETA: 9s - loss: 0.0539 - accuracy: 0.985 - ETA: 6s - loss: 0.0536 - accuracy: 0.98 - ETA: 4s - loss: 0.0534 - accuracy: 0.98 - ETA: 2s - loss: 0.0535 - accuracy: 0.98 - 379s 20ms/step - loss: 0.0532 - accuracy: 0.9856 - val_loss: 2.2339 - val_accuracy: 0.8066\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:00 - loss: 0.0102 - accuracy: 1.00 - ETA: 5:39 - loss: 0.0102 - accuracy: 0.99 - ETA: 5:36 - loss: 0.0114 - accuracy: 0.99 - ETA: 5:44 - loss: 0.0160 - accuracy: 0.99 - ETA: 5:42 - loss: 0.0464 - accuracy: 0.98 - ETA: 5:43 - loss: 0.0405 - accuracy: 0.98 - ETA: 5:39 - loss: 0.0419 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0473 - accuracy: 0.98 - ETA: 5:27 - loss: 0.0422 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0469 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0510 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0467 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0616 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0607 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0610 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0612 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0690 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0652 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0630 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0632 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0603 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0599 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0637 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0634 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0622 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0610 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0637 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0618 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0656 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0640 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0622 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0613 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0595 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0579 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0578 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0574 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0587 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0593 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0596 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0588 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0602 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0596 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0598 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0602 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0611 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0630 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0641 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0634 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0634 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0664 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0662 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0657 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0654 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0643 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0634 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0636 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0633 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0624 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0629 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0631 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0632 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0626 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0625 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0629 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0626 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0629 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0644 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0651 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0642 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0646 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0638 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0643 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0638 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0632 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0632 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0630 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0620 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0614 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0607 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0602 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0595 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0595 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0596 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0585 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0584 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0579 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0579 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0576 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0583 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0594 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0589 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0608 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0608 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0610 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0618 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0619 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0618 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0612 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0610 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0599 - accuracy: 0.98 - ETA: 57s - loss: 0.0597 - accuracy: 0.9851 - ETA: 55s - loss: 0.0593 - accuracy: 0.985 - ETA: 53s - loss: 0.0590 - accuracy: 0.985 - ETA: 50s - loss: 0.0586 - accuracy: 0.985 - ETA: 48s - loss: 0.0583 - accuracy: 0.985 - ETA: 46s - loss: 0.0579 - accuracy: 0.985 - ETA: 43s - loss: 0.0577 - accuracy: 0.985 - ETA: 41s - loss: 0.0589 - accuracy: 0.985 - ETA: 39s - loss: 0.0592 - accuracy: 0.985 - ETA: 36s - loss: 0.0588 - accuracy: 0.985 - ETA: 34s - loss: 0.0595 - accuracy: 0.985 - ETA: 32s - loss: 0.0595 - accuracy: 0.985 - ETA: 29s - loss: 0.0602 - accuracy: 0.985 - ETA: 27s - loss: 0.0598 - accuracy: 0.985 - ETA: 25s - loss: 0.0597 - accuracy: 0.985 - ETA: 22s - loss: 0.0598 - accuracy: 0.985 - ETA: 20s - loss: 0.0596 - accuracy: 0.985 - ETA: 18s - loss: 0.0592 - accuracy: 0.985 - ETA: 15s - loss: 0.0590 - accuracy: 0.985 - ETA: 13s - loss: 0.0588 - accuracy: 0.985 - ETA: 11s - loss: 0.0587 - accuracy: 0.985 - ETA: 9s - loss: 0.0583 - accuracy: 0.985 - ETA: 6s - loss: 0.0588 - accuracy: 0.98 - ETA: 4s - loss: 0.0585 - accuracy: 0.98 - ETA: 2s - loss: 0.0586 - accuracy: 0.98 - 377s 20ms/step - loss: 0.0583 - accuracy: 0.9853 - val_loss: 2.3088 - val_accuracy: 0.8091\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:44 - loss: 0.0579 - accuracy: 0.99 - ETA: 5:43 - loss: 0.0334 - accuracy: 0.99 - ETA: 5:44 - loss: 0.0345 - accuracy: 0.98 - ETA: 5:43 - loss: 0.0276 - accuracy: 0.99 - ETA: 5:38 - loss: 0.0410 - accuracy: 0.98 - ETA: 5:34 - loss: 0.0369 - accuracy: 0.98 - ETA: 5:31 - loss: 0.0363 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0340 - accuracy: 0.98 - ETA: 5:27 - loss: 0.0545 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0574 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0550 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0589 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0575 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0562 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0588 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0555 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0538 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0512 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0501 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0521 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0504 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0487 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0484 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0501 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0515 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0505 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0504 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0488 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0493 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0486 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0475 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0478 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0476 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0498 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0488 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0470 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0462 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0465 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0463 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0461 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0451 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0443 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0445 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0444 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0439 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0435 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0429 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0433 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0471 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0484 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0486 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0509 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0505 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0501 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0506 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0513 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0519 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0534 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0542 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0527 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0533 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0538 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0541 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0539 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0544 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0542 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0539 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0539 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0540 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0543 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0546 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0542 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0521 - accuracy: 0.98 - ETA: 58s - loss: 0.0519 - accuracy: 0.9872 - ETA: 55s - loss: 0.0519 - accuracy: 0.987 - ETA: 53s - loss: 0.0527 - accuracy: 0.986 - ETA: 51s - loss: 0.0526 - accuracy: 0.986 - ETA: 48s - loss: 0.0523 - accuracy: 0.987 - ETA: 46s - loss: 0.0521 - accuracy: 0.987 - ETA: 44s - loss: 0.0526 - accuracy: 0.987 - ETA: 41s - loss: 0.0533 - accuracy: 0.986 - ETA: 39s - loss: 0.0533 - accuracy: 0.986 - ETA: 37s - loss: 0.0529 - accuracy: 0.987 - ETA: 34s - loss: 0.0528 - accuracy: 0.987 - ETA: 32s - loss: 0.0525 - accuracy: 0.987 - ETA: 30s - loss: 0.0527 - accuracy: 0.987 - ETA: 27s - loss: 0.0524 - accuracy: 0.987 - ETA: 25s - loss: 0.0521 - accuracy: 0.987 - ETA: 23s - loss: 0.0517 - accuracy: 0.987 - ETA: 20s - loss: 0.0520 - accuracy: 0.987 - ETA: 18s - loss: 0.0518 - accuracy: 0.987 - ETA: 16s - loss: 0.0520 - accuracy: 0.987 - ETA: 13s - loss: 0.0524 - accuracy: 0.987 - ETA: 11s - loss: 0.0525 - accuracy: 0.987 - ETA: 9s - loss: 0.0523 - accuracy: 0.987 - ETA: 6s - loss: 0.0520 - accuracy: 0.98 - ETA: 4s - loss: 0.0519 - accuracy: 0.98 - ETA: 2s - loss: 0.0517 - accuracy: 0.98 - 379s 20ms/step - loss: 0.0517 - accuracy: 0.9871 - val_loss: 2.2825 - val_accuracy: 0.8068\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:29 - loss: 0.0469 - accuracy: 0.98 - ETA: 5:49 - loss: 0.0285 - accuracy: 0.98 - ETA: 5:51 - loss: 0.0270 - accuracy: 0.98 - ETA: 5:50 - loss: 0.0203 - accuracy: 0.99 - ETA: 5:43 - loss: 0.0178 - accuracy: 0.99 - ETA: 5:40 - loss: 0.0242 - accuracy: 0.99 - ETA: 5:36 - loss: 0.0259 - accuracy: 0.99 - ETA: 5:34 - loss: 0.0233 - accuracy: 0.99 - ETA: 5:33 - loss: 0.0215 - accuracy: 0.99 - ETA: 5:32 - loss: 0.0341 - accuracy: 0.99 - ETA: 5:29 - loss: 0.0339 - accuracy: 0.99 - ETA: 5:27 - loss: 0.0414 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0410 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0397 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0438 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0429 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0460 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0441 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0429 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0410 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0402 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0395 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0378 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0391 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0378 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0453 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0436 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0429 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0428 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0430 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0416 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0409 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0401 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0454 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0451 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0457 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0457 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0446 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0437 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0431 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0427 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0421 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0430 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0431 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0443 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0441 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0437 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0452 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0444 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0441 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0435 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0428 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0439 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0482 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0477 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0474 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0494 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0493 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0500 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0505 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0520 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0533 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0527 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0519 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0531 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0539 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0531 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0529 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0529 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0500 - accuracy: 0.98 - ETA: 59s - loss: 0.0505 - accuracy: 0.9862 - ETA: 57s - loss: 0.0511 - accuracy: 0.986 - ETA: 55s - loss: 0.0510 - accuracy: 0.986 - ETA: 52s - loss: 0.0511 - accuracy: 0.986 - ETA: 50s - loss: 0.0507 - accuracy: 0.986 - ETA: 48s - loss: 0.0504 - accuracy: 0.986 - ETA: 46s - loss: 0.0504 - accuracy: 0.986 - ETA: 43s - loss: 0.0512 - accuracy: 0.986 - ETA: 41s - loss: 0.0520 - accuracy: 0.986 - ETA: 39s - loss: 0.0520 - accuracy: 0.985 - ETA: 36s - loss: 0.0527 - accuracy: 0.985 - ETA: 34s - loss: 0.0532 - accuracy: 0.985 - ETA: 32s - loss: 0.0532 - accuracy: 0.985 - ETA: 29s - loss: 0.0530 - accuracy: 0.985 - ETA: 27s - loss: 0.0536 - accuracy: 0.985 - ETA: 25s - loss: 0.0533 - accuracy: 0.985 - ETA: 22s - loss: 0.0532 - accuracy: 0.985 - ETA: 20s - loss: 0.0530 - accuracy: 0.985 - ETA: 18s - loss: 0.0528 - accuracy: 0.985 - ETA: 15s - loss: 0.0530 - accuracy: 0.985 - ETA: 13s - loss: 0.0527 - accuracy: 0.985 - ETA: 11s - loss: 0.0525 - accuracy: 0.985 - ETA: 8s - loss: 0.0533 - accuracy: 0.985 - ETA: 6s - loss: 0.0531 - accuracy: 0.98 - ETA: 4s - loss: 0.0528 - accuracy: 0.98 - ETA: 2s - loss: 0.0528 - accuracy: 0.98 - 376s 19ms/step - loss: 0.0528 - accuracy: 0.9857 - val_loss: 2.1652 - val_accuracy: 0.8070\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:20 - loss: 0.0847 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0461 - accuracy: 0.99 - ETA: 5:28 - loss: 0.0323 - accuracy: 0.99 - ETA: 5:29 - loss: 0.0327 - accuracy: 0.99 - ETA: 5:25 - loss: 0.0465 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0411 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0430 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0385 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0375 - accuracy: 0.98 - ETA: 5:27 - loss: 0.0355 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0451 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0502 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0506 - accuracy: 0.98 - ETA: 5:24 - loss: 0.0523 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0490 - accuracy: 0.98 - ETA: 5:18 - loss: 0.0490 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0523 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0513 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0512 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0579 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0552 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0541 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0539 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0541 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0530 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0523 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0514 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0497 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0471 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0470 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0463 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0456 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0444 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0479 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0467 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0479 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0468 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0473 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0465 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0476 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0511 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0502 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0497 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0507 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0520 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0520 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0521 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0516 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0530 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0521 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0519 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0517 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0513 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0505 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0506 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0508 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0537 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0547 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0543 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0554 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0547 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0541 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0546 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0558 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0554 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0555 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0558 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0557 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0551 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0561 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0556 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0550 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0558 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0558 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0553 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0558 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0569 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0579 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0580 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0595 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0589 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0583 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0577 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0584 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0586 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0583 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0577 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0576 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0592 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0584 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0584 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0605 - accuracy: 0.98 - ETA: 57s - loss: 0.0608 - accuracy: 0.9857 - ETA: 55s - loss: 0.0607 - accuracy: 0.985 - ETA: 53s - loss: 0.0611 - accuracy: 0.985 - ETA: 50s - loss: 0.0607 - accuracy: 0.985 - ETA: 48s - loss: 0.0606 - accuracy: 0.985 - ETA: 46s - loss: 0.0601 - accuracy: 0.985 - ETA: 43s - loss: 0.0597 - accuracy: 0.985 - ETA: 41s - loss: 0.0598 - accuracy: 0.985 - ETA: 39s - loss: 0.0596 - accuracy: 0.985 - ETA: 36s - loss: 0.0601 - accuracy: 0.985 - ETA: 34s - loss: 0.0598 - accuracy: 0.986 - ETA: 32s - loss: 0.0599 - accuracy: 0.985 - ETA: 29s - loss: 0.0598 - accuracy: 0.986 - ETA: 27s - loss: 0.0597 - accuracy: 0.986 - ETA: 25s - loss: 0.0594 - accuracy: 0.986 - ETA: 22s - loss: 0.0591 - accuracy: 0.986 - ETA: 20s - loss: 0.0592 - accuracy: 0.986 - ETA: 18s - loss: 0.0597 - accuracy: 0.986 - ETA: 16s - loss: 0.0594 - accuracy: 0.986 - ETA: 13s - loss: 0.0594 - accuracy: 0.986 - ETA: 11s - loss: 0.0593 - accuracy: 0.986 - ETA: 9s - loss: 0.0594 - accuracy: 0.986 - ETA: 6s - loss: 0.0601 - accuracy: 0.98 - ETA: 4s - loss: 0.0598 - accuracy: 0.98 - ETA: 2s - loss: 0.0595 - accuracy: 0.98 - 376s 19ms/step - loss: 0.0593 - accuracy: 0.9861 - val_loss: 2.1079 - val_accuracy: 0.8103\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:19 - loss: 0.1369 - accuracy: 0.98 - ETA: 5:28 - loss: 0.1063 - accuracy: 0.98 - ETA: 5:40 - loss: 0.0835 - accuracy: 0.98 - ETA: 5:37 - loss: 0.0800 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0843 - accuracy: 0.97 - ETA: 5:33 - loss: 0.0727 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0696 - accuracy: 0.97 - ETA: 5:23 - loss: 0.0619 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0595 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0568 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0535 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0631 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0586 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0548 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0512 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0485 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0489 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0510 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0535 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0530 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0520 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0526 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0540 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0540 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0551 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0538 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0534 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0517 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0543 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0534 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0532 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0540 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0534 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0528 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0517 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0525 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0517 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0522 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0517 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0510 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0506 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0506 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0503 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0496 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0511 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0517 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0511 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0510 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0510 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0494 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0501 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0495 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0479 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0474 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0457 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0470 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0443 - accuracy: 0.98 - ETA: 59s - loss: 0.0440 - accuracy: 0.9870 - ETA: 57s - loss: 0.0438 - accuracy: 0.987 - ETA: 55s - loss: 0.0437 - accuracy: 0.987 - ETA: 52s - loss: 0.0436 - accuracy: 0.987 - ETA: 50s - loss: 0.0439 - accuracy: 0.987 - ETA: 48s - loss: 0.0440 - accuracy: 0.987 - ETA: 45s - loss: 0.0437 - accuracy: 0.987 - ETA: 43s - loss: 0.0434 - accuracy: 0.987 - ETA: 41s - loss: 0.0442 - accuracy: 0.987 - ETA: 39s - loss: 0.0441 - accuracy: 0.987 - ETA: 36s - loss: 0.0438 - accuracy: 0.987 - ETA: 34s - loss: 0.0441 - accuracy: 0.987 - ETA: 32s - loss: 0.0445 - accuracy: 0.987 - ETA: 29s - loss: 0.0442 - accuracy: 0.987 - ETA: 27s - loss: 0.0441 - accuracy: 0.987 - ETA: 25s - loss: 0.0441 - accuracy: 0.987 - ETA: 22s - loss: 0.0440 - accuracy: 0.987 - ETA: 20s - loss: 0.0442 - accuracy: 0.987 - ETA: 18s - loss: 0.0442 - accuracy: 0.987 - ETA: 15s - loss: 0.0441 - accuracy: 0.987 - ETA: 13s - loss: 0.0439 - accuracy: 0.987 - ETA: 11s - loss: 0.0436 - accuracy: 0.987 - ETA: 8s - loss: 0.0436 - accuracy: 0.987 - ETA: 6s - loss: 0.0440 - accuracy: 0.98 - ETA: 4s - loss: 0.0444 - accuracy: 0.98 - ETA: 2s - loss: 0.0444 - accuracy: 0.98 - 375s 19ms/step - loss: 0.0445 - accuracy: 0.9872 - val_loss: 2.2373 - val_accuracy: 0.8101\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:39 - loss: 0.0375 - accuracy: 0.98 - ETA: 5:39 - loss: 0.0329 - accuracy: 0.98 - ETA: 5:38 - loss: 0.0241 - accuracy: 0.99 - ETA: 5:32 - loss: 0.0268 - accuracy: 0.98 - ETA: 5:30 - loss: 0.0328 - accuracy: 0.98 - ETA: 5:27 - loss: 0.0276 - accuracy: 0.99 - ETA: 5:32 - loss: 0.0361 - accuracy: 0.99 - ETA: 5:30 - loss: 0.0428 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0408 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0455 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0464 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0537 - accuracy: 0.98 - ETA: 5:18 - loss: 0.0552 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0524 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0540 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0528 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0522 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0555 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0527 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0505 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0488 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0462 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0443 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0474 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0468 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0492 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0515 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0498 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0488 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0479 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0483 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0536 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0524 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0526 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0526 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0537 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0538 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0546 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0544 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0532 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0537 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0536 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0529 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0518 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0523 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0519 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0521 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0505 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0496 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0498 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0509 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0516 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0509 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0501 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0495 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0490 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0498 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0494 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0489 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0505 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0497 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0490 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0499 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0501 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0534 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0547 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0554 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0553 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0562 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0557 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0551 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0539 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0539 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0543 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0542 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0539 - accuracy: 0.98 - ETA: 58s - loss: 0.0537 - accuracy: 0.9863 - ETA: 55s - loss: 0.0537 - accuracy: 0.986 - ETA: 53s - loss: 0.0533 - accuracy: 0.986 - ETA: 51s - loss: 0.0529 - accuracy: 0.986 - ETA: 48s - loss: 0.0529 - accuracy: 0.986 - ETA: 46s - loss: 0.0525 - accuracy: 0.986 - ETA: 44s - loss: 0.0525 - accuracy: 0.986 - ETA: 41s - loss: 0.0522 - accuracy: 0.986 - ETA: 39s - loss: 0.0518 - accuracy: 0.986 - ETA: 37s - loss: 0.0517 - accuracy: 0.986 - ETA: 34s - loss: 0.0524 - accuracy: 0.986 - ETA: 32s - loss: 0.0526 - accuracy: 0.986 - ETA: 30s - loss: 0.0525 - accuracy: 0.986 - ETA: 27s - loss: 0.0522 - accuracy: 0.986 - ETA: 25s - loss: 0.0525 - accuracy: 0.986 - ETA: 23s - loss: 0.0536 - accuracy: 0.986 - ETA: 20s - loss: 0.0534 - accuracy: 0.986 - ETA: 18s - loss: 0.0531 - accuracy: 0.986 - ETA: 16s - loss: 0.0531 - accuracy: 0.986 - ETA: 13s - loss: 0.0531 - accuracy: 0.986 - ETA: 11s - loss: 0.0533 - accuracy: 0.986 - ETA: 9s - loss: 0.0542 - accuracy: 0.986 - ETA: 6s - loss: 0.0547 - accuracy: 0.98 - ETA: 4s - loss: 0.0547 - accuracy: 0.98 - ETA: 2s - loss: 0.0552 - accuracy: 0.98 - 382s 20ms/step - loss: 0.0549 - accuracy: 0.9865 - val_loss: 2.3232 - val_accuracy: 0.8076\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:38 - loss: 2.6594e-04 - accuracy: 1.00 - ETA: 6:13 - loss: 0.0110 - accuracy: 0.9961   - ETA: 6:07 - loss: 0.0133 - accuracy: 0.99 - ETA: 6:03 - loss: 0.0231 - accuracy: 0.98 - ETA: 5:58 - loss: 0.0284 - accuracy: 0.98 - ETA: 5:50 - loss: 0.0239 - accuracy: 0.98 - ETA: 5:44 - loss: 0.0205 - accuracy: 0.99 - ETA: 5:42 - loss: 0.0257 - accuracy: 0.99 - ETA: 5:40 - loss: 0.0258 - accuracy: 0.99 - ETA: 5:35 - loss: 0.0294 - accuracy: 0.99 - ETA: 5:33 - loss: 0.0271 - accuracy: 0.99 - ETA: 5:28 - loss: 0.0269 - accuracy: 0.99 - ETA: 5:25 - loss: 0.0285 - accuracy: 0.99 - ETA: 5:21 - loss: 0.0320 - accuracy: 0.99 - ETA: 5:18 - loss: 0.0412 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0387 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0368 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0374 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0396 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0384 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0383 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0370 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0354 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0363 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0357 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0359 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0385 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0372 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0373 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0365 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0385 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0394 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0390 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0381 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0370 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0368 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0373 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0368 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0372 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0366 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0361 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0354 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0362 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0377 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0370 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0362 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0357 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0361 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0361 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0357 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0355 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0353 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0348 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0351 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0348 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0360 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0363 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0370 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0365 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0373 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0371 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0369 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0373 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0370 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0365 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0369 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0366 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0370 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0375 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0372 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0370 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0365 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0366 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0364 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0361 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0366 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0372 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0370 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0370 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0368 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0368 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0365 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0374 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0385 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0399 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0400 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0400 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0400 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0401 - accuracy: 0.98 - ETA: 58s - loss: 0.0401 - accuracy: 0.9883 - ETA: 55s - loss: 0.0398 - accuracy: 0.988 - ETA: 53s - loss: 0.0395 - accuracy: 0.988 - ETA: 51s - loss: 0.0392 - accuracy: 0.988 - ETA: 48s - loss: 0.0390 - accuracy: 0.988 - ETA: 46s - loss: 0.0388 - accuracy: 0.988 - ETA: 44s - loss: 0.0391 - accuracy: 0.988 - ETA: 41s - loss: 0.0390 - accuracy: 0.988 - ETA: 39s - loss: 0.0393 - accuracy: 0.988 - ETA: 37s - loss: 0.0390 - accuracy: 0.988 - ETA: 34s - loss: 0.0389 - accuracy: 0.988 - ETA: 32s - loss: 0.0387 - accuracy: 0.988 - ETA: 30s - loss: 0.0386 - accuracy: 0.988 - ETA: 27s - loss: 0.0391 - accuracy: 0.988 - ETA: 25s - loss: 0.0392 - accuracy: 0.988 - ETA: 23s - loss: 0.0392 - accuracy: 0.988 - ETA: 20s - loss: 0.0393 - accuracy: 0.988 - ETA: 18s - loss: 0.0406 - accuracy: 0.988 - ETA: 16s - loss: 0.0413 - accuracy: 0.988 - ETA: 13s - loss: 0.0418 - accuracy: 0.988 - ETA: 11s - loss: 0.0416 - accuracy: 0.988 - ETA: 9s - loss: 0.0421 - accuracy: 0.987 - ETA: 6s - loss: 0.0421 - accuracy: 0.98 - ETA: 4s - loss: 0.0427 - accuracy: 0.98 - ETA: 2s - loss: 0.0428 - accuracy: 0.98 - 382s 20ms/step - loss: 0.0428 - accuracy: 0.9878 - val_loss: 2.2501 - val_accuracy: 0.8130\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:17 - loss: 0.0281 - accuracy: 0.99 - ETA: 6:16 - loss: 0.0410 - accuracy: 0.98 - ETA: 6:02 - loss: 0.0298 - accuracy: 0.99 - ETA: 5:50 - loss: 0.0520 - accuracy: 0.98 - ETA: 5:38 - loss: 0.0518 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0466 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0422 - accuracy: 0.99 - ETA: 5:28 - loss: 0.0396 - accuracy: 0.99 - ETA: 5:26 - loss: 0.0363 - accuracy: 0.99 - ETA: 5:26 - loss: 0.0388 - accuracy: 0.99 - ETA: 5:24 - loss: 0.0365 - accuracy: 0.99 - ETA: 5:22 - loss: 0.0335 - accuracy: 0.99 - ETA: 5:21 - loss: 0.0411 - accuracy: 0.99 - ETA: 5:21 - loss: 0.0397 - accuracy: 0.99 - ETA: 5:22 - loss: 0.0412 - accuracy: 0.99 - ETA: 5:23 - loss: 0.0443 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0420 - accuracy: 0.99 - ETA: 5:20 - loss: 0.0419 - accuracy: 0.99 - ETA: 5:18 - loss: 0.0402 - accuracy: 0.99 - ETA: 5:16 - loss: 0.0388 - accuracy: 0.99 - ETA: 5:14 - loss: 0.0382 - accuracy: 0.99 - ETA: 5:12 - loss: 0.0384 - accuracy: 0.99 - ETA: 5:11 - loss: 0.0371 - accuracy: 0.99 - ETA: 5:10 - loss: 0.0363 - accuracy: 0.99 - ETA: 5:07 - loss: 0.0386 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0380 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0401 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0461 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0460 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0459 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0445 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0447 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0450 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0476 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0481 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0482 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0495 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0492 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0481 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0473 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0490 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0486 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0485 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0500 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0493 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0495 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0486 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0473 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0482 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0482 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0483 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0481 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0469 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0477 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0480 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0477 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0472 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0470 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0482 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0479 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0495 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0492 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0483 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0476 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0478 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0499 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0499 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0500 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0505 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0505 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0500 - accuracy: 0.98 - ETA: 58s - loss: 0.0501 - accuracy: 0.9876 - ETA: 55s - loss: 0.0502 - accuracy: 0.987 - ETA: 53s - loss: 0.0503 - accuracy: 0.987 - ETA: 50s - loss: 0.0499 - accuracy: 0.987 - ETA: 48s - loss: 0.0502 - accuracy: 0.987 - ETA: 46s - loss: 0.0498 - accuracy: 0.987 - ETA: 43s - loss: 0.0496 - accuracy: 0.987 - ETA: 41s - loss: 0.0495 - accuracy: 0.987 - ETA: 38s - loss: 0.0501 - accuracy: 0.987 - ETA: 36s - loss: 0.0502 - accuracy: 0.987 - ETA: 33s - loss: 0.0507 - accuracy: 0.987 - ETA: 31s - loss: 0.0506 - accuracy: 0.987 - ETA: 28s - loss: 0.0506 - accuracy: 0.987 - ETA: 26s - loss: 0.0505 - accuracy: 0.987 - ETA: 24s - loss: 0.0509 - accuracy: 0.987 - ETA: 21s - loss: 0.0505 - accuracy: 0.987 - ETA: 19s - loss: 0.0507 - accuracy: 0.987 - ETA: 16s - loss: 0.0520 - accuracy: 0.987 - ETA: 14s - loss: 0.0527 - accuracy: 0.987 - ETA: 11s - loss: 0.0531 - accuracy: 0.987 - ETA: 9s - loss: 0.0528 - accuracy: 0.987 - ETA: 6s - loss: 0.0527 - accuracy: 0.98 - ETA: 4s - loss: 0.0532 - accuracy: 0.98 - ETA: 2s - loss: 0.0528 - accuracy: 0.98 - 394s 20ms/step - loss: 0.0526 - accuracy: 0.9872 - val_loss: 2.1690 - val_accuracy: 0.8192\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:51 - loss: 0.0060 - accuracy: 1.00 - ETA: 5:44 - loss: 0.0226 - accuracy: 0.99 - ETA: 5:36 - loss: 0.0192 - accuracy: 0.99 - ETA: 5:39 - loss: 0.0360 - accuracy: 0.99 - ETA: 5:35 - loss: 0.0488 - accuracy: 0.99 - ETA: 5:33 - loss: 0.0440 - accuracy: 0.99 - ETA: 5:30 - loss: 0.0384 - accuracy: 0.99 - ETA: 5:25 - loss: 0.0345 - accuracy: 0.99 - ETA: 5:21 - loss: 0.0321 - accuracy: 0.99 - ETA: 5:19 - loss: 0.0295 - accuracy: 0.99 - ETA: 5:19 - loss: 0.0343 - accuracy: 0.99 - ETA: 5:18 - loss: 0.0396 - accuracy: 0.99 - ETA: 5:16 - loss: 0.0379 - accuracy: 0.99 - ETA: 5:14 - loss: 0.0424 - accuracy: 0.99 - ETA: 5:12 - loss: 0.0416 - accuracy: 0.99 - ETA: 5:09 - loss: 0.0445 - accuracy: 0.99 - ETA: 5:06 - loss: 0.0491 - accuracy: 0.99 - ETA: 5:05 - loss: 0.0482 - accuracy: 0.99 - ETA: 5:03 - loss: 0.0494 - accuracy: 0.99 - ETA: 5:01 - loss: 0.0500 - accuracy: 0.99 - ETA: 4:59 - loss: 0.0480 - accuracy: 0.99 - ETA: 4:57 - loss: 0.0465 - accuracy: 0.99 - ETA: 4:55 - loss: 0.0450 - accuracy: 0.99 - ETA: 4:53 - loss: 0.0487 - accuracy: 0.99 - ETA: 4:51 - loss: 0.0489 - accuracy: 0.99 - ETA: 4:49 - loss: 0.0525 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0506 - accuracy: 0.99 - ETA: 4:45 - loss: 0.0496 - accuracy: 0.99 - ETA: 4:42 - loss: 0.0500 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0560 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0564 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0562 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0545 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0541 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0548 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0580 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0567 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0557 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0551 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0552 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0551 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0559 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0548 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0536 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0526 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0515 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0511 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0509 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0506 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0496 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0498 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0513 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0517 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0527 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0531 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0526 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0524 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0519 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0519 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0539 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0532 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0533 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0547 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0540 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0540 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0532 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0542 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0542 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0537 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0530 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0515 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0511 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0505 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0515 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0515 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0516 - accuracy: 0.98 - ETA: 59s - loss: 0.0516 - accuracy: 0.9872 - ETA: 57s - loss: 0.0524 - accuracy: 0.987 - ETA: 54s - loss: 0.0521 - accuracy: 0.987 - ETA: 52s - loss: 0.0518 - accuracy: 0.987 - ETA: 49s - loss: 0.0516 - accuracy: 0.987 - ETA: 47s - loss: 0.0513 - accuracy: 0.987 - ETA: 44s - loss: 0.0518 - accuracy: 0.987 - ETA: 42s - loss: 0.0516 - accuracy: 0.987 - ETA: 39s - loss: 0.0521 - accuracy: 0.987 - ETA: 37s - loss: 0.0523 - accuracy: 0.987 - ETA: 34s - loss: 0.0534 - accuracy: 0.986 - ETA: 32s - loss: 0.0533 - accuracy: 0.986 - ETA: 29s - loss: 0.0531 - accuracy: 0.986 - ETA: 27s - loss: 0.0532 - accuracy: 0.986 - ETA: 25s - loss: 0.0528 - accuracy: 0.986 - ETA: 22s - loss: 0.0528 - accuracy: 0.987 - ETA: 35:03 - loss: 0.0527 - accuracy: 0.987 - ETA: 30:54 - loss: 0.0530 - accuracy: 0.986 - ETA: 26:47 - loss: 0.0530 - accuracy: 0.986 - ETA: 22:44 - loss: 0.0527 - accuracy: 0.986 - ETA: 18:44 - loss: 0.0524 - accuracy: 0.986 - ETA: 14:47 - loss: 0.0522 - accuracy: 0.986 - ETA: 10:54 - loss: 0.0524 - accuracy: 0.986 - ETA: 7:03 - loss: 0.0522 - accuracy: 0.986 - ETA: 3:16 - loss: 0.0523 - accuracy: 0.98 - 33713s 2s/step - loss: 0.0526 - accuracy: 0.9867 - val_loss: 2.4188 - val_accuracy: 0.8087\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:38 - loss: 0.1054 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0788 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0647 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0815 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0661 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0618 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0553 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0555 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0512 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0463 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0427 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0430 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0417 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0434 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0418 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0394 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0376 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0362 - accuracy: 0.99 - ETA: 3:46 - loss: 0.0383 - accuracy: 0.99 - ETA: 3:44 - loss: 0.0366 - accuracy: 0.99 - ETA: 3:42 - loss: 0.0353 - accuracy: 0.99 - ETA: 3:41 - loss: 0.0338 - accuracy: 0.99 - ETA: 3:40 - loss: 0.0342 - accuracy: 0.99 - ETA: 3:38 - loss: 0.0334 - accuracy: 0.99 - ETA: 3:36 - loss: 0.0322 - accuracy: 0.99 - ETA: 3:33 - loss: 0.0348 - accuracy: 0.99 - ETA: 3:31 - loss: 0.0348 - accuracy: 0.99 - ETA: 3:29 - loss: 0.0356 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0351 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0366 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0370 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0385 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0438 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0440 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0431 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0490 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0462 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0436 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0434 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0431 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0422 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0422 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0417 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0417 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0411 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0408 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0403 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0402 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0401 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0400 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0403 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0398 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0399 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0399 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0405 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0406 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0408 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0408 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0431 - accuracy: 0.98 - ETA: 58s - loss: 0.0431 - accuracy: 0.9882 - ETA: 56s - loss: 0.0432 - accuracy: 0.988 - ETA: 55s - loss: 0.0432 - accuracy: 0.988 - ETA: 53s - loss: 0.0436 - accuracy: 0.988 - ETA: 51s - loss: 0.0436 - accuracy: 0.988 - ETA: 50s - loss: 0.0440 - accuracy: 0.988 - ETA: 48s - loss: 0.0437 - accuracy: 0.988 - ETA: 46s - loss: 0.0442 - accuracy: 0.987 - ETA: 44s - loss: 0.0441 - accuracy: 0.987 - ETA: 43s - loss: 0.0438 - accuracy: 0.987 - ETA: 41s - loss: 0.0435 - accuracy: 0.988 - ETA: 39s - loss: 0.0432 - accuracy: 0.988 - ETA: 38s - loss: 0.0431 - accuracy: 0.988 - ETA: 36s - loss: 0.0440 - accuracy: 0.988 - ETA: 34s - loss: 0.0445 - accuracy: 0.988 - ETA: 32s - loss: 0.0444 - accuracy: 0.988 - ETA: 31s - loss: 0.0447 - accuracy: 0.987 - ETA: 29s - loss: 0.0445 - accuracy: 0.987 - ETA: 27s - loss: 0.0443 - accuracy: 0.988 - ETA: 25s - loss: 0.0440 - accuracy: 0.988 - ETA: 24s - loss: 0.0440 - accuracy: 0.988 - ETA: 22s - loss: 0.0440 - accuracy: 0.988 - ETA: 20s - loss: 0.0437 - accuracy: 0.988 - ETA: 19s - loss: 0.0440 - accuracy: 0.988 - ETA: 17s - loss: 0.0441 - accuracy: 0.988 - ETA: 15s - loss: 0.0439 - accuracy: 0.988 - ETA: 13s - loss: 0.0436 - accuracy: 0.988 - ETA: 12s - loss: 0.0438 - accuracy: 0.988 - ETA: 10s - loss: 0.0436 - accuracy: 0.988 - ETA: 8s - loss: 0.0436 - accuracy: 0.988 - ETA: 6s - loss: 0.0434 - accuracy: 0.98 - ETA: 5s - loss: 0.0433 - accuracy: 0.98 - ETA: 3s - loss: 0.0431 - accuracy: 0.98 - ETA: 1s - loss: 0.0432 - accuracy: 0.98 - 289s 15ms/step - loss: 0.0435 - accuracy: 0.9882 - val_loss: 2.3073 - val_accuracy: 0.8159\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:11 - loss: 0.0404 - accuracy: 0.99 - ETA: 4:01 - loss: 0.0679 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0794 - accuracy: 0.97 - ETA: 3:55 - loss: 0.0719 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0585 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0560 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0701 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0682 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0618 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0650 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0712 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0693 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0724 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0817 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0806 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0784 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0762 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0758 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0802 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0770 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0759 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0738 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0717 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0711 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0703 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0689 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0667 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0668 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0646 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0629 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0636 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0636 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0653 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0645 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0644 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0631 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0618 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0626 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0621 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0607 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0615 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0610 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0624 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0605 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0613 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0606 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0606 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0606 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0623 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0629 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0626 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0618 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0608 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0602 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0593 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0583 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0601 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0592 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0607 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0604 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0610 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0601 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0604 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0597 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0610 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0617 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0616 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0620 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0607 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0603 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0585 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0576 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0568 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0545 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0545 - accuracy: 0.98 - ETA: 58s - loss: 0.0542 - accuracy: 0.9864 - ETA: 56s - loss: 0.0545 - accuracy: 0.986 - ETA: 55s - loss: 0.0544 - accuracy: 0.986 - ETA: 53s - loss: 0.0542 - accuracy: 0.986 - ETA: 51s - loss: 0.0541 - accuracy: 0.986 - ETA: 50s - loss: 0.0537 - accuracy: 0.986 - ETA: 48s - loss: 0.0533 - accuracy: 0.986 - ETA: 47s - loss: 0.0531 - accuracy: 0.986 - ETA: 45s - loss: 0.0535 - accuracy: 0.986 - ETA: 43s - loss: 0.0535 - accuracy: 0.986 - ETA: 42s - loss: 0.0531 - accuracy: 0.986 - ETA: 40s - loss: 0.0529 - accuracy: 0.986 - ETA: 38s - loss: 0.0540 - accuracy: 0.986 - ETA: 37s - loss: 0.0537 - accuracy: 0.986 - ETA: 35s - loss: 0.0533 - accuracy: 0.986 - ETA: 33s - loss: 0.0536 - accuracy: 0.986 - ETA: 32s - loss: 0.0534 - accuracy: 0.986 - ETA: 30s - loss: 0.0531 - accuracy: 0.986 - ETA: 28s - loss: 0.0528 - accuracy: 0.986 - ETA: 27s - loss: 0.0527 - accuracy: 0.986 - ETA: 25s - loss: 0.0528 - accuracy: 0.986 - ETA: 23s - loss: 0.0531 - accuracy: 0.986 - ETA: 21s - loss: 0.0530 - accuracy: 0.986 - ETA: 20s - loss: 0.0527 - accuracy: 0.986 - ETA: 18s - loss: 0.0529 - accuracy: 0.986 - ETA: 16s - loss: 0.0534 - accuracy: 0.986 - ETA: 15s - loss: 0.0531 - accuracy: 0.986 - ETA: 13s - loss: 0.0535 - accuracy: 0.986 - ETA: 11s - loss: 0.0532 - accuracy: 0.986 - ETA: 10s - loss: 0.0531 - accuracy: 0.986 - ETA: 8s - loss: 0.0534 - accuracy: 0.986 - ETA: 6s - loss: 0.0532 - accuracy: 0.98 - ETA: 4s - loss: 0.0529 - accuracy: 0.98 - ETA: 3s - loss: 0.0539 - accuracy: 0.98 - ETA: 1s - loss: 0.0538 - accuracy: 0.98 - 286s 15ms/step - loss: 0.0535 - accuracy: 0.9866 - val_loss: 2.3299 - val_accuracy: 0.8140\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:57 - loss: 0.0124 - accuracy: 1.00 - ETA: 4:43 - loss: 0.0503 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0897 - accuracy: 0.97 - ETA: 4:32 - loss: 0.1121 - accuracy: 0.97 - ETA: 4:31 - loss: 0.0900 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0766 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0664 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0584 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0526 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0483 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0502 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0464 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0444 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0455 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0439 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0422 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0400 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0416 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0409 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0392 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0392 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0428 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0413 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0397 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0394 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0397 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0398 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0391 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0381 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0395 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0405 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0425 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0479 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0438 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0429 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0423 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0423 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0418 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0426 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0427 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0426 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0424 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0423 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0424 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0423 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0436 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0476 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0495 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0499 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0489 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0500 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0531 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0545 - accuracy: 0.98 - ETA: 59s - loss: 0.0540 - accuracy: 0.9866 - ETA: 57s - loss: 0.0537 - accuracy: 0.986 - ETA: 55s - loss: 0.0537 - accuracy: 0.986 - ETA: 53s - loss: 0.0535 - accuracy: 0.986 - ETA: 51s - loss: 0.0532 - accuracy: 0.986 - ETA: 49s - loss: 0.0530 - accuracy: 0.986 - ETA: 48s - loss: 0.0529 - accuracy: 0.986 - ETA: 46s - loss: 0.0531 - accuracy: 0.986 - ETA: 44s - loss: 0.0528 - accuracy: 0.986 - ETA: 42s - loss: 0.0527 - accuracy: 0.986 - ETA: 40s - loss: 0.0523 - accuracy: 0.986 - ETA: 38s - loss: 0.0524 - accuracy: 0.986 - ETA: 36s - loss: 0.0520 - accuracy: 0.986 - ETA: 34s - loss: 0.0517 - accuracy: 0.987 - ETA: 32s - loss: 0.0514 - accuracy: 0.987 - ETA: 30s - loss: 0.0524 - accuracy: 0.986 - ETA: 28s - loss: 0.0524 - accuracy: 0.986 - ETA: 26s - loss: 0.0522 - accuracy: 0.986 - ETA: 24s - loss: 0.0519 - accuracy: 0.987 - ETA: 22s - loss: 0.0516 - accuracy: 0.987 - ETA: 20s - loss: 0.0520 - accuracy: 0.987 - ETA: 19s - loss: 0.0520 - accuracy: 0.987 - ETA: 17s - loss: 0.0520 - accuracy: 0.987 - ETA: 15s - loss: 0.0518 - accuracy: 0.987 - ETA: 13s - loss: 0.0518 - accuracy: 0.987 - ETA: 11s - loss: 0.0515 - accuracy: 0.987 - ETA: 9s - loss: 0.0517 - accuracy: 0.987 - ETA: 7s - loss: 0.0515 - accuracy: 0.98 - ETA: 5s - loss: 0.0515 - accuracy: 0.98 - ETA: 3s - loss: 0.0512 - accuracy: 0.98 - ETA: 1s - loss: 0.0511 - accuracy: 0.98 - 323s 17ms/step - loss: 0.0508 - accuracy: 0.9874 - val_loss: 2.2768 - val_accuracy: 0.8105\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:19 - loss: 0.0128 - accuracy: 1.00 - ETA: 4:11 - loss: 0.0331 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0248 - accuracy: 0.99 - ETA: 4:10 - loss: 0.0241 - accuracy: 0.99 - ETA: 4:10 - loss: 0.0287 - accuracy: 0.99 - ETA: 4:11 - loss: 0.0325 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0295 - accuracy: 0.99 - ETA: 4:23 - loss: 0.0296 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0284 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0257 - accuracy: 0.99 - ETA: 4:35 - loss: 0.0242 - accuracy: 0.99 - ETA: 4:33 - loss: 0.0251 - accuracy: 0.99 - ETA: 4:29 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0609 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0570 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0540 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0585 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0572 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0597 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0587 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0562 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0577 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0572 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0593 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0571 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0577 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0594 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0599 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0589 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0583 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0567 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0558 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0562 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0549 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0535 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0530 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0522 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0522 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0541 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0528 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0550 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0537 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0530 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0525 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0528 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0539 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0539 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0534 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0581 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0575 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0579 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0572 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0563 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0570 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0563 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0554 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0547 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0543 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0543 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0540 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0534 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0528 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0539 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0525 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0534 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0534 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0538 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0536 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0541 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0536 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0541 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0524 - accuracy: 0.98 - ETA: 59s - loss: 0.0522 - accuracy: 0.9874 - ETA: 57s - loss: 0.0520 - accuracy: 0.987 - ETA: 56s - loss: 0.0525 - accuracy: 0.987 - ETA: 54s - loss: 0.0529 - accuracy: 0.987 - ETA: 52s - loss: 0.0527 - accuracy: 0.987 - ETA: 50s - loss: 0.0524 - accuracy: 0.987 - ETA: 48s - loss: 0.0530 - accuracy: 0.987 - ETA: 46s - loss: 0.0537 - accuracy: 0.987 - ETA: 44s - loss: 0.0539 - accuracy: 0.987 - ETA: 42s - loss: 0.0537 - accuracy: 0.987 - ETA: 41s - loss: 0.0540 - accuracy: 0.987 - ETA: 39s - loss: 0.0540 - accuracy: 0.987 - ETA: 37s - loss: 0.0537 - accuracy: 0.987 - ETA: 35s - loss: 0.0537 - accuracy: 0.987 - ETA: 33s - loss: 0.0539 - accuracy: 0.987 - ETA: 31s - loss: 0.0538 - accuracy: 0.987 - ETA: 29s - loss: 0.0538 - accuracy: 0.987 - ETA: 27s - loss: 0.0543 - accuracy: 0.987 - ETA: 26s - loss: 0.0550 - accuracy: 0.987 - ETA: 24s - loss: 0.0548 - accuracy: 0.987 - ETA: 22s - loss: 0.0547 - accuracy: 0.987 - ETA: 20s - loss: 0.0558 - accuracy: 0.987 - ETA: 18s - loss: 0.0561 - accuracy: 0.987 - ETA: 17s - loss: 0.0558 - accuracy: 0.987 - ETA: 15s - loss: 0.0554 - accuracy: 0.987 - ETA: 13s - loss: 0.0557 - accuracy: 0.987 - ETA: 11s - loss: 0.0555 - accuracy: 0.987 - ETA: 9s - loss: 0.0552 - accuracy: 0.987 - ETA: 7s - loss: 0.0563 - accuracy: 0.98 - ETA: 5s - loss: 0.0560 - accuracy: 0.98 - ETA: 3s - loss: 0.0559 - accuracy: 0.98 - ETA: 1s - loss: 0.0559 - accuracy: 0.98 - 333s 17ms/step - loss: 0.0568 - accuracy: 0.9870 - val_loss: 2.2078 - val_accuracy: 0.8132\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:26 - loss: 0.0052 - accuracy: 1.00 - ETA: 5:12 - loss: 0.0043 - accuracy: 1.00 - ETA: 5:02 - loss: 0.0276 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0228 - accuracy: 0.99 - ETA: 4:56 - loss: 0.0306 - accuracy: 0.99 - ETA: 4:54 - loss: 0.0439 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0417 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0402 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0409 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0370 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0364 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0353 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0336 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0339 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0366 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0346 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0348 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0352 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0336 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0335 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0349 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0359 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0367 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0398 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0406 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0411 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0416 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0402 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0389 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0387 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0403 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0391 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0381 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0382 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0406 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0414 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0434 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0423 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0414 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0410 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0404 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0423 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0428 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0420 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0428 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0428 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0425 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0419 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0417 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0412 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0427 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0425 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0424 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0424 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0423 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0418 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0413 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0417 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0411 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0408 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0401 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0400 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0393 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0393 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0394 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0394 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0399 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0402 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0401 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0397 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0409 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0406 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0402 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0402 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0408 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0403 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0401 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0392 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0388 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0390 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0406 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0408 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0411 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0406 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0407 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0410 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0410 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0410 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0414 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0413 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0411 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0416 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0418 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0442 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0428 - accuracy: 0.98 - ETA: 58s - loss: 0.0426 - accuracy: 0.9875 - ETA: 55s - loss: 0.0432 - accuracy: 0.987 - ETA: 53s - loss: 0.0429 - accuracy: 0.987 - ETA: 51s - loss: 0.0432 - accuracy: 0.987 - ETA: 49s - loss: 0.0430 - accuracy: 0.987 - ETA: 46s - loss: 0.0431 - accuracy: 0.987 - ETA: 44s - loss: 0.0428 - accuracy: 0.987 - ETA: 42s - loss: 0.0427 - accuracy: 0.987 - ETA: 40s - loss: 0.0427 - accuracy: 0.987 - ETA: 37s - loss: 0.0428 - accuracy: 0.987 - ETA: 35s - loss: 0.0431 - accuracy: 0.987 - ETA: 33s - loss: 0.0430 - accuracy: 0.987 - ETA: 31s - loss: 0.0434 - accuracy: 0.987 - ETA: 28s - loss: 0.0432 - accuracy: 0.987 - ETA: 26s - loss: 0.0433 - accuracy: 0.987 - ETA: 24s - loss: 0.0432 - accuracy: 0.987 - ETA: 22s - loss: 0.0429 - accuracy: 0.987 - ETA: 19s - loss: 0.0429 - accuracy: 0.987 - ETA: 17s - loss: 0.0427 - accuracy: 0.987 - ETA: 15s - loss: 0.0426 - accuracy: 0.987 - ETA: 13s - loss: 0.0428 - accuracy: 0.987 - ETA: 10s - loss: 0.0426 - accuracy: 0.987 - ETA: 8s - loss: 0.0427 - accuracy: 0.987 - ETA: 6s - loss: 0.0429 - accuracy: 0.98 - ETA: 4s - loss: 0.0427 - accuracy: 0.98 - ETA: 1s - loss: 0.0428 - accuracy: 0.98 - 363s 19ms/step - loss: 0.0427 - accuracy: 0.9875 - val_loss: 2.1687 - val_accuracy: 0.8126\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:10 - loss: 0.0212 - accuracy: 0.99 - ETA: 4:20 - loss: 0.0108 - accuracy: 0.99 - ETA: 4:37 - loss: 0.0278 - accuracy: 0.99 - ETA: 4:44 - loss: 0.0308 - accuracy: 0.99 - ETA: 4:45 - loss: 0.0253 - accuracy: 0.99 - ETA: 4:46 - loss: 0.0269 - accuracy: 0.99 - ETA: 4:43 - loss: 0.0231 - accuracy: 0.99 - ETA: 4:39 - loss: 0.0274 - accuracy: 0.99 - ETA: 4:36 - loss: 0.0259 - accuracy: 0.99 - ETA: 4:33 - loss: 0.0247 - accuracy: 0.99 - ETA: 4:31 - loss: 0.0293 - accuracy: 0.99 - ETA: 4:29 - loss: 0.0280 - accuracy: 0.99 - ETA: 4:25 - loss: 0.0280 - accuracy: 0.99 - ETA: 4:22 - loss: 0.0285 - accuracy: 0.99 - ETA: 4:19 - loss: 0.0304 - accuracy: 0.99 - ETA: 4:15 - loss: 0.0303 - accuracy: 0.99 - ETA: 4:11 - loss: 0.0303 - accuracy: 0.99 - ETA: 4:12 - loss: 0.0291 - accuracy: 0.99 - ETA: 4:12 - loss: 0.0289 - accuracy: 0.99 - ETA: 4:10 - loss: 0.0305 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0295 - accuracy: 0.99 - ETA: 4:09 - loss: 0.0293 - accuracy: 0.99 - ETA: 4:06 - loss: 0.0299 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0303 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0315 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0314 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0303 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0301 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0354 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0360 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0349 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0350 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0364 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0355 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0356 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0395 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0391 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0396 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0397 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0401 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0406 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0407 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0405 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0411 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0407 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0403 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0401 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0393 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0398 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0393 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0402 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0399 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0394 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0388 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0382 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0399 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0394 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0388 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0382 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0376 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0374 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0378 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0374 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0371 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0371 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0375 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0373 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0373 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0383 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0393 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0394 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0394 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0393 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0400 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0405 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0406 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0407 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0424 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0450 - accuracy: 0.98 - ETA: 58s - loss: 0.0448 - accuracy: 0.9878 - ETA: 56s - loss: 0.0445 - accuracy: 0.987 - ETA: 54s - loss: 0.0441 - accuracy: 0.988 - ETA: 52s - loss: 0.0438 - accuracy: 0.988 - ETA: 50s - loss: 0.0435 - accuracy: 0.988 - ETA: 48s - loss: 0.0443 - accuracy: 0.988 - ETA: 46s - loss: 0.0444 - accuracy: 0.988 - ETA: 44s - loss: 0.0446 - accuracy: 0.988 - ETA: 42s - loss: 0.0443 - accuracy: 0.988 - ETA: 40s - loss: 0.0440 - accuracy: 0.988 - ETA: 38s - loss: 0.0441 - accuracy: 0.988 - ETA: 36s - loss: 0.0444 - accuracy: 0.988 - ETA: 34s - loss: 0.0446 - accuracy: 0.988 - ETA: 32s - loss: 0.0449 - accuracy: 0.988 - ETA: 30s - loss: 0.0447 - accuracy: 0.988 - ETA: 28s - loss: 0.0444 - accuracy: 0.988 - ETA: 26s - loss: 0.0442 - accuracy: 0.988 - ETA: 24s - loss: 0.0439 - accuracy: 0.988 - ETA: 22s - loss: 0.0436 - accuracy: 0.988 - ETA: 20s - loss: 0.0433 - accuracy: 0.988 - ETA: 19s - loss: 0.0430 - accuracy: 0.988 - ETA: 17s - loss: 0.0427 - accuracy: 0.988 - ETA: 15s - loss: 0.0430 - accuracy: 0.988 - ETA: 13s - loss: 0.0428 - accuracy: 0.988 - ETA: 11s - loss: 0.0434 - accuracy: 0.988 - ETA: 9s - loss: 0.0433 - accuracy: 0.988 - ETA: 7s - loss: 0.0430 - accuracy: 0.98 - ETA: 5s - loss: 0.0431 - accuracy: 0.98 - ETA: 3s - loss: 0.0429 - accuracy: 0.98 - ETA: 1s - loss: 0.0431 - accuracy: 0.98 - 316s 16ms/step - loss: 0.0429 - accuracy: 0.9886 - val_loss: 2.1964 - val_accuracy: 0.8107\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:21 - loss: 0.0490 - accuracy: 0.99 - ETA: 4:17 - loss: 0.0363 - accuracy: 0.99 - ETA: 4:15 - loss: 0.0386 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0476 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0504 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0595 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0563 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0605 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0545 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0494 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0477 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0508 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0572 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0541 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0515 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0520 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0474 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0431 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0432 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0418 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0406 - accuracy: 0.99 - ETA: 3:30 - loss: 0.0416 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0406 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0398 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0389 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0391 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0397 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0398 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0388 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0384 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0390 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0390 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0400 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0399 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0390 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0386 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0378 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0370 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0382 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0375 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0386 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0386 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0407 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0400 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0393 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0386 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0391 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0375 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0372 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0366 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0369 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0375 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0372 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0370 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0375 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0374 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0372 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0374 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0372 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0374 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0370 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0370 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0368 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0372 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0380 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0374 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0372 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0369 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0367 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0363 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0362 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0358 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0359 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0362 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0361 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0358 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0359 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0358 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0362 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0360 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0366 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0374 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0386 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0382 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0379 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0371 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0372 - accuracy: 0.98 - ETA: 58s - loss: 0.0372 - accuracy: 0.9891 - ETA: 56s - loss: 0.0374 - accuracy: 0.989 - ETA: 54s - loss: 0.0377 - accuracy: 0.989 - ETA: 53s - loss: 0.0376 - accuracy: 0.989 - ETA: 51s - loss: 0.0377 - accuracy: 0.989 - ETA: 49s - loss: 0.0376 - accuracy: 0.989 - ETA: 48s - loss: 0.0379 - accuracy: 0.988 - ETA: 46s - loss: 0.0384 - accuracy: 0.988 - ETA: 44s - loss: 0.0381 - accuracy: 0.988 - ETA: 42s - loss: 0.0380 - accuracy: 0.988 - ETA: 40s - loss: 0.0378 - accuracy: 0.988 - ETA: 39s - loss: 0.0379 - accuracy: 0.988 - ETA: 37s - loss: 0.0384 - accuracy: 0.988 - ETA: 35s - loss: 0.0384 - accuracy: 0.988 - ETA: 33s - loss: 0.0387 - accuracy: 0.988 - ETA: 32s - loss: 0.0387 - accuracy: 0.988 - ETA: 30s - loss: 0.0386 - accuracy: 0.988 - ETA: 28s - loss: 0.0384 - accuracy: 0.988 - ETA: 26s - loss: 0.0383 - accuracy: 0.988 - ETA: 24s - loss: 0.0387 - accuracy: 0.988 - ETA: 23s - loss: 0.0384 - accuracy: 0.988 - ETA: 21s - loss: 0.0381 - accuracy: 0.988 - ETA: 19s - loss: 0.0384 - accuracy: 0.988 - ETA: 17s - loss: 0.0384 - accuracy: 0.988 - ETA: 15s - loss: 0.0382 - accuracy: 0.988 - ETA: 14s - loss: 0.0384 - accuracy: 0.988 - ETA: 12s - loss: 0.0381 - accuracy: 0.988 - ETA: 10s - loss: 0.0385 - accuracy: 0.988 - ETA: 8s - loss: 0.0382 - accuracy: 0.988 - ETA: 6s - loss: 0.0389 - accuracy: 0.98 - ETA: 5s - loss: 0.0388 - accuracy: 0.98 - ETA: 3s - loss: 0.0392 - accuracy: 0.98 - ETA: 1s - loss: 0.0397 - accuracy: 0.98 - 299s 15ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 2.2824 - val_accuracy: 0.8070\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:59 - loss: 0.0872 - accuracy: 0.96 - ETA: 4:38 - loss: 0.0920 - accuracy: 0.97 - ETA: 4:28 - loss: 0.0958 - accuracy: 0.97 - ETA: 4:24 - loss: 0.0808 - accuracy: 0.97 - ETA: 4:19 - loss: 0.0729 - accuracy: 0.97 - ETA: 4:16 - loss: 0.0701 - accuracy: 0.97 - ETA: 4:13 - loss: 0.0638 - accuracy: 0.97 - ETA: 4:12 - loss: 0.0582 - accuracy: 0.97 - ETA: 4:13 - loss: 0.0525 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0555 - accuracy: 0.97 - ETA: 4:08 - loss: 0.0510 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0543 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0535 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0585 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0547 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0519 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0560 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0604 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0598 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0576 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0560 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0564 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0540 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0533 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0505 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0541 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0526 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0509 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0527 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0496 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0484 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0479 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0471 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0460 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0468 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0483 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0478 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0483 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0476 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0489 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0486 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0514 - accuracy: 0.98 - ETA: 58s - loss: 0.0515 - accuracy: 0.9869 - ETA: 56s - loss: 0.0515 - accuracy: 0.986 - ETA: 54s - loss: 0.0511 - accuracy: 0.987 - ETA: 53s - loss: 0.0509 - accuracy: 0.987 - ETA: 51s - loss: 0.0511 - accuracy: 0.987 - ETA: 49s - loss: 0.0516 - accuracy: 0.987 - ETA: 47s - loss: 0.0514 - accuracy: 0.986 - ETA: 45s - loss: 0.0513 - accuracy: 0.986 - ETA: 44s - loss: 0.0511 - accuracy: 0.986 - ETA: 42s - loss: 0.0509 - accuracy: 0.986 - ETA: 40s - loss: 0.0509 - accuracy: 0.986 - ETA: 38s - loss: 0.0512 - accuracy: 0.986 - ETA: 36s - loss: 0.0508 - accuracy: 0.986 - ETA: 34s - loss: 0.0509 - accuracy: 0.986 - ETA: 33s - loss: 0.0511 - accuracy: 0.986 - ETA: 31s - loss: 0.0508 - accuracy: 0.986 - ETA: 29s - loss: 0.0507 - accuracy: 0.986 - ETA: 27s - loss: 0.0512 - accuracy: 0.986 - ETA: 25s - loss: 0.0510 - accuracy: 0.986 - ETA: 23s - loss: 0.0509 - accuracy: 0.986 - ETA: 22s - loss: 0.0508 - accuracy: 0.986 - ETA: 20s - loss: 0.0509 - accuracy: 0.986 - ETA: 18s - loss: 0.0506 - accuracy: 0.986 - ETA: 16s - loss: 0.0505 - accuracy: 0.987 - ETA: 14s - loss: 0.0501 - accuracy: 0.987 - ETA: 12s - loss: 0.0498 - accuracy: 0.987 - ETA: 10s - loss: 0.0500 - accuracy: 0.987 - ETA: 9s - loss: 0.0498 - accuracy: 0.987 - ETA: 7s - loss: 0.0495 - accuracy: 0.98 - ETA: 5s - loss: 0.0493 - accuracy: 0.98 - ETA: 3s - loss: 0.0496 - accuracy: 0.98 - ETA: 1s - loss: 0.0493 - accuracy: 0.98 - 302s 16ms/step - loss: 0.0492 - accuracy: 0.9872 - val_loss: 2.2278 - val_accuracy: 0.8097\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:55 - loss: 0.0056 - accuracy: 1.00 - ETA: 4:36 - loss: 0.0198 - accuracy: 0.99 - ETA: 4:33 - loss: 0.0408 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0357 - accuracy: 0.99 - ETA: 4:37 - loss: 0.0337 - accuracy: 0.99 - ETA: 4:38 - loss: 0.0292 - accuracy: 0.99 - ETA: 4:33 - loss: 0.0302 - accuracy: 0.99 - ETA: 4:32 - loss: 0.0268 - accuracy: 0.99 - ETA: 4:35 - loss: 0.0244 - accuracy: 0.99 - ETA: 4:34 - loss: 0.0229 - accuracy: 0.99 - ETA: 4:33 - loss: 0.0211 - accuracy: 0.99 - ETA: 4:30 - loss: 0.0233 - accuracy: 0.99 - ETA: 4:27 - loss: 0.0220 - accuracy: 0.99 - ETA: 4:26 - loss: 0.0221 - accuracy: 0.99 - ETA: 4:22 - loss: 0.0208 - accuracy: 0.99 - ETA: 4:21 - loss: 0.0237 - accuracy: 0.99 - ETA: 4:20 - loss: 0.0240 - accuracy: 0.99 - ETA: 4:18 - loss: 0.0285 - accuracy: 0.99 - ETA: 4:15 - loss: 0.0276 - accuracy: 0.99 - ETA: 4:12 - loss: 0.0305 - accuracy: 0.99 - ETA: 4:11 - loss: 0.0291 - accuracy: 0.99 - ETA: 4:08 - loss: 0.0281 - accuracy: 0.99 - ETA: 4:06 - loss: 0.0278 - accuracy: 0.99 - ETA: 4:05 - loss: 0.0306 - accuracy: 0.99 - ETA: 4:04 - loss: 0.0305 - accuracy: 0.99 - ETA: 4:02 - loss: 0.0301 - accuracy: 0.99 - ETA: 4:01 - loss: 0.0296 - accuracy: 0.99 - ETA: 3:58 - loss: 0.0312 - accuracy: 0.99 - ETA: 3:57 - loss: 0.0303 - accuracy: 0.99 - ETA: 3:54 - loss: 0.0310 - accuracy: 0.99 - ETA: 3:52 - loss: 0.0310 - accuracy: 0.99 - ETA: 3:50 - loss: 0.0304 - accuracy: 0.99 - ETA: 3:48 - loss: 0.0306 - accuracy: 0.99 - ETA: 3:47 - loss: 0.0297 - accuracy: 0.99 - ETA: 3:46 - loss: 0.0301 - accuracy: 0.99 - ETA: 3:44 - loss: 0.0294 - accuracy: 0.99 - ETA: 3:42 - loss: 0.0291 - accuracy: 0.99 - ETA: 3:39 - loss: 0.0307 - accuracy: 0.99 - ETA: 3:37 - loss: 0.0315 - accuracy: 0.99 - ETA: 3:35 - loss: 0.0314 - accuracy: 0.99 - ETA: 3:33 - loss: 0.0312 - accuracy: 0.99 - ETA: 3:31 - loss: 0.0314 - accuracy: 0.99 - ETA: 3:29 - loss: 0.0308 - accuracy: 0.99 - ETA: 3:26 - loss: 0.0312 - accuracy: 0.99 - ETA: 3:24 - loss: 0.0317 - accuracy: 0.99 - ETA: 3:22 - loss: 0.0320 - accuracy: 0.99 - ETA: 3:19 - loss: 0.0317 - accuracy: 0.99 - ETA: 3:17 - loss: 0.0325 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0337 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0334 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0340 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0355 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0360 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0374 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0374 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0388 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0390 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0386 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0387 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0403 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0412 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0408 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0416 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0424 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0426 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0435 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0433 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0427 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0432 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0426 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0427 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0426 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0425 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0420 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0420 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0431 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0425 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0425 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0463 - accuracy: 0.98 - ETA: 58s - loss: 0.0462 - accuracy: 0.9874 - ETA: 56s - loss: 0.0459 - accuracy: 0.987 - ETA: 55s - loss: 0.0456 - accuracy: 0.987 - ETA: 53s - loss: 0.0455 - accuracy: 0.987 - ETA: 51s - loss: 0.0451 - accuracy: 0.987 - ETA: 49s - loss: 0.0451 - accuracy: 0.987 - ETA: 47s - loss: 0.0448 - accuracy: 0.987 - ETA: 45s - loss: 0.0446 - accuracy: 0.987 - ETA: 43s - loss: 0.0447 - accuracy: 0.987 - ETA: 41s - loss: 0.0448 - accuracy: 0.987 - ETA: 39s - loss: 0.0457 - accuracy: 0.987 - ETA: 37s - loss: 0.0454 - accuracy: 0.987 - ETA: 35s - loss: 0.0451 - accuracy: 0.987 - ETA: 34s - loss: 0.0452 - accuracy: 0.987 - ETA: 32s - loss: 0.0455 - accuracy: 0.987 - ETA: 30s - loss: 0.0473 - accuracy: 0.987 - ETA: 28s - loss: 0.0479 - accuracy: 0.987 - ETA: 26s - loss: 0.0485 - accuracy: 0.987 - ETA: 24s - loss: 0.0487 - accuracy: 0.987 - ETA: 22s - loss: 0.0485 - accuracy: 0.987 - ETA: 20s - loss: 0.0483 - accuracy: 0.987 - ETA: 18s - loss: 0.0480 - accuracy: 0.987 - ETA: 16s - loss: 0.0481 - accuracy: 0.987 - ETA: 15s - loss: 0.0480 - accuracy: 0.987 - ETA: 13s - loss: 0.0477 - accuracy: 0.987 - ETA: 11s - loss: 0.0477 - accuracy: 0.987 - ETA: 9s - loss: 0.0476 - accuracy: 0.987 - ETA: 7s - loss: 0.0473 - accuracy: 0.98 - ETA: 5s - loss: 0.0470 - accuracy: 0.98 - ETA: 3s - loss: 0.0467 - accuracy: 0.98 - ETA: 1s - loss: 0.0466 - accuracy: 0.98 - 314s 16ms/step - loss: 0.0466 - accuracy: 0.9874 - val_loss: 2.4812 - val_accuracy: 0.8064\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:07 - loss: 0.0251 - accuracy: 0.99 - ETA: 4:04 - loss: 0.0126 - accuracy: 0.99 - ETA: 4:03 - loss: 0.0185 - accuracy: 0.99 - ETA: 4:02 - loss: 0.0432 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0505 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0435 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0386 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0338 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0309 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0279 - accuracy: 0.99 - ETA: 4:02 - loss: 0.0292 - accuracy: 0.99 - ETA: 4:03 - loss: 0.0293 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0278 - accuracy: 0.99 - ETA: 4:01 - loss: 0.0300 - accuracy: 0.99 - ETA: 4:01 - loss: 0.0322 - accuracy: 0.99 - ETA: 3:59 - loss: 0.0316 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0303 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0306 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0292 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0351 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0337 - accuracy: 0.99 - ETA: 3:47 - loss: 0.0337 - accuracy: 0.99 - ETA: 3:46 - loss: 0.0337 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0325 - accuracy: 0.99 - ETA: 3:42 - loss: 0.0322 - accuracy: 0.99 - ETA: 3:40 - loss: 0.0325 - accuracy: 0.99 - ETA: 3:38 - loss: 0.0313 - accuracy: 0.99 - ETA: 3:35 - loss: 0.0304 - accuracy: 0.99 - ETA: 3:33 - loss: 0.0315 - accuracy: 0.99 - ETA: 3:32 - loss: 0.0307 - accuracy: 0.99 - ETA: 3:31 - loss: 0.0303 - accuracy: 0.99 - ETA: 3:29 - loss: 0.0295 - accuracy: 0.99 - ETA: 3:28 - loss: 0.0308 - accuracy: 0.99 - ETA: 3:26 - loss: 0.0314 - accuracy: 0.99 - ETA: 3:24 - loss: 0.0322 - accuracy: 0.99 - ETA: 3:22 - loss: 0.0314 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0305 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0317 - accuracy: 0.99 - ETA: 3:16 - loss: 0.0331 - accuracy: 0.99 - ETA: 3:15 - loss: 0.0344 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0337 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0348 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0359 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0358 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0367 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0384 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0396 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0400 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0398 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0393 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0386 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0386 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0396 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0426 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0419 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0416 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0409 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0403 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0400 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0394 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0388 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0390 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0388 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0387 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0390 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0388 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0393 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0394 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0396 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0398 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0412 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0417 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0414 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0408 - accuracy: 0.98 - ETA: 59s - loss: 0.0408 - accuracy: 0.9881 - ETA: 58s - loss: 0.0405 - accuracy: 0.988 - ETA: 56s - loss: 0.0405 - accuracy: 0.988 - ETA: 54s - loss: 0.0402 - accuracy: 0.988 - ETA: 52s - loss: 0.0399 - accuracy: 0.988 - ETA: 51s - loss: 0.0396 - accuracy: 0.988 - ETA: 49s - loss: 0.0395 - accuracy: 0.988 - ETA: 47s - loss: 0.0394 - accuracy: 0.988 - ETA: 45s - loss: 0.0392 - accuracy: 0.988 - ETA: 44s - loss: 0.0392 - accuracy: 0.988 - ETA: 42s - loss: 0.0390 - accuracy: 0.988 - ETA: 40s - loss: 0.0387 - accuracy: 0.988 - ETA: 39s - loss: 0.0388 - accuracy: 0.988 - ETA: 37s - loss: 0.0388 - accuracy: 0.988 - ETA: 35s - loss: 0.0386 - accuracy: 0.988 - ETA: 34s - loss: 0.0383 - accuracy: 0.988 - ETA: 32s - loss: 0.0382 - accuracy: 0.988 - ETA: 30s - loss: 0.0390 - accuracy: 0.988 - ETA: 28s - loss: 0.0390 - accuracy: 0.988 - ETA: 27s - loss: 0.0389 - accuracy: 0.988 - ETA: 25s - loss: 0.0387 - accuracy: 0.988 - ETA: 23s - loss: 0.0386 - accuracy: 0.988 - ETA: 22s - loss: 0.0391 - accuracy: 0.988 - ETA: 20s - loss: 0.0390 - accuracy: 0.988 - ETA: 18s - loss: 0.0389 - accuracy: 0.988 - ETA: 16s - loss: 0.0394 - accuracy: 0.988 - ETA: 15s - loss: 0.0395 - accuracy: 0.988 - ETA: 13s - loss: 0.0396 - accuracy: 0.988 - ETA: 11s - loss: 0.0397 - accuracy: 0.988 - ETA: 10s - loss: 0.0395 - accuracy: 0.988 - ETA: 8s - loss: 0.0393 - accuracy: 0.988 - ETA: 6s - loss: 0.0395 - accuracy: 0.98 - ETA: 4s - loss: 0.0397 - accuracy: 0.98 - ETA: 3s - loss: 0.0395 - accuracy: 0.98 - ETA: 1s - loss: 0.0399 - accuracy: 0.98 - 284s 15ms/step - loss: 0.0397 - accuracy: 0.9888 - val_loss: 2.2863 - val_accuracy: 0.8103\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:37 - loss: 0.0734 - accuracy: 0.99 - ETA: 4:15 - loss: 0.0599 - accuracy: 0.99 - ETA: 4:09 - loss: 0.0473 - accuracy: 0.99 - ETA: 4:03 - loss: 0.0356 - accuracy: 0.99 - ETA: 4:00 - loss: 0.0393 - accuracy: 0.99 - ETA: 3:59 - loss: 0.0471 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0413 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0436 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0433 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0547 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0552 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0536 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0510 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0532 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0507 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0495 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0546 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0539 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0532 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0519 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0513 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0499 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0486 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0477 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0472 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0469 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0450 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0438 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0436 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0434 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0431 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0427 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0431 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0424 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0420 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0414 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0424 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0421 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0431 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0426 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0423 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0426 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0442 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0439 - accuracy: 0.98 - ETA: 59s - loss: 0.0435 - accuracy: 0.9888 - ETA: 58s - loss: 0.0432 - accuracy: 0.988 - ETA: 56s - loss: 0.0434 - accuracy: 0.988 - ETA: 55s - loss: 0.0435 - accuracy: 0.988 - ETA: 53s - loss: 0.0432 - accuracy: 0.988 - ETA: 51s - loss: 0.0429 - accuracy: 0.989 - ETA: 50s - loss: 0.0428 - accuracy: 0.989 - ETA: 48s - loss: 0.0426 - accuracy: 0.989 - ETA: 46s - loss: 0.0426 - accuracy: 0.989 - ETA: 45s - loss: 0.0422 - accuracy: 0.989 - ETA: 43s - loss: 0.0422 - accuracy: 0.989 - ETA: 42s - loss: 0.0424 - accuracy: 0.989 - ETA: 40s - loss: 0.0423 - accuracy: 0.989 - ETA: 38s - loss: 0.0422 - accuracy: 0.989 - ETA: 37s - loss: 0.0423 - accuracy: 0.989 - ETA: 35s - loss: 0.0422 - accuracy: 0.989 - ETA: 33s - loss: 0.0426 - accuracy: 0.989 - ETA: 32s - loss: 0.0423 - accuracy: 0.989 - ETA: 30s - loss: 0.0420 - accuracy: 0.989 - ETA: 29s - loss: 0.0426 - accuracy: 0.989 - ETA: 27s - loss: 0.0429 - accuracy: 0.989 - ETA: 25s - loss: 0.0427 - accuracy: 0.989 - ETA: 24s - loss: 0.0429 - accuracy: 0.989 - ETA: 22s - loss: 0.0429 - accuracy: 0.989 - ETA: 21s - loss: 0.0428 - accuracy: 0.989 - ETA: 19s - loss: 0.0425 - accuracy: 0.989 - ETA: 17s - loss: 0.0426 - accuracy: 0.989 - ETA: 16s - loss: 0.0423 - accuracy: 0.989 - ETA: 14s - loss: 0.0424 - accuracy: 0.989 - ETA: 12s - loss: 0.0423 - accuracy: 0.989 - ETA: 11s - loss: 0.0423 - accuracy: 0.989 - ETA: 9s - loss: 0.0420 - accuracy: 0.989 - ETA: 7s - loss: 0.0420 - accuracy: 0.98 - ETA: 6s - loss: 0.0418 - accuracy: 0.98 - ETA: 4s - loss: 0.0419 - accuracy: 0.98 - ETA: 3s - loss: 0.0419 - accuracy: 0.98 - ETA: 1s - loss: 0.0416 - accuracy: 0.98 - 279s 14ms/step - loss: 0.0419 - accuracy: 0.9891 - val_loss: 2.2043 - val_accuracy: 0.8124\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:35 - loss: 0.0221 - accuracy: 0.99 - ETA: 4:24 - loss: 0.0112 - accuracy: 0.99 - ETA: 4:31 - loss: 0.0491 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0599 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0609 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0530 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0458 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0402 - accuracy: 0.99 - ETA: 4:17 - loss: 0.0360 - accuracy: 0.99 - ETA: 4:13 - loss: 0.0367 - accuracy: 0.99 - ETA: 4:13 - loss: 0.0386 - accuracy: 0.99 - ETA: 4:11 - loss: 0.0498 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0512 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0483 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0452 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0460 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0433 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0442 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0435 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0440 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0439 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0453 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0430 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0432 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0422 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0408 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0400 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0424 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0411 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0399 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0387 - accuracy: 0.99 - ETA: 3:27 - loss: 0.0392 - accuracy: 0.99 - ETA: 3:25 - loss: 0.0387 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0377 - accuracy: 0.99 - ETA: 3:21 - loss: 0.0383 - accuracy: 0.99 - ETA: 3:19 - loss: 0.0392 - accuracy: 0.99 - ETA: 3:17 - loss: 0.0387 - accuracy: 0.99 - ETA: 3:15 - loss: 0.0388 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0381 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0373 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0368 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0375 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0367 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0377 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0393 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0385 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0377 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0394 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0433 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0486 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0487 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0495 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0489 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0490 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0515 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0505 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0495 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0507 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0510 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0510 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0530 - accuracy: 0.98 - ETA: 59s - loss: 0.0527 - accuracy: 0.9885 - ETA: 58s - loss: 0.0525 - accuracy: 0.988 - ETA: 56s - loss: 0.0526 - accuracy: 0.988 - ETA: 54s - loss: 0.0526 - accuracy: 0.988 - ETA: 52s - loss: 0.0522 - accuracy: 0.988 - ETA: 50s - loss: 0.0519 - accuracy: 0.988 - ETA: 48s - loss: 0.0517 - accuracy: 0.988 - ETA: 47s - loss: 0.0517 - accuracy: 0.988 - ETA: 45s - loss: 0.0523 - accuracy: 0.988 - ETA: 43s - loss: 0.0526 - accuracy: 0.988 - ETA: 41s - loss: 0.0529 - accuracy: 0.988 - ETA: 39s - loss: 0.0526 - accuracy: 0.988 - ETA: 38s - loss: 0.0522 - accuracy: 0.988 - ETA: 36s - loss: 0.0521 - accuracy: 0.988 - ETA: 34s - loss: 0.0518 - accuracy: 0.988 - ETA: 32s - loss: 0.0522 - accuracy: 0.988 - ETA: 30s - loss: 0.0527 - accuracy: 0.988 - ETA: 29s - loss: 0.0523 - accuracy: 0.988 - ETA: 27s - loss: 0.0525 - accuracy: 0.988 - ETA: 25s - loss: 0.0523 - accuracy: 0.988 - ETA: 23s - loss: 0.0520 - accuracy: 0.988 - ETA: 21s - loss: 0.0522 - accuracy: 0.988 - ETA: 20s - loss: 0.0519 - accuracy: 0.988 - ETA: 18s - loss: 0.0518 - accuracy: 0.988 - ETA: 16s - loss: 0.0516 - accuracy: 0.988 - ETA: 14s - loss: 0.0515 - accuracy: 0.988 - ETA: 12s - loss: 0.0515 - accuracy: 0.988 - ETA: 10s - loss: 0.0516 - accuracy: 0.988 - ETA: 9s - loss: 0.0513 - accuracy: 0.988 - ETA: 7s - loss: 0.0511 - accuracy: 0.98 - ETA: 5s - loss: 0.0510 - accuracy: 0.98 - ETA: 3s - loss: 0.0507 - accuracy: 0.98 - ETA: 1s - loss: 0.0504 - accuracy: 0.98 - 301s 16ms/step - loss: 0.0507 - accuracy: 0.9887 - val_loss: 2.3810 - val_accuracy: 0.8103\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:15 - loss: 0.0069 - accuracy: 1.00 - ETA: 4:13 - loss: 0.0061 - accuracy: 1.00 - ETA: 4:18 - loss: 0.0086 - accuracy: 0.99 - ETA: 4:18 - loss: 0.0443 - accuracy: 0.99 - ETA: 4:19 - loss: 0.0376 - accuracy: 0.99 - ETA: 4:19 - loss: 0.0363 - accuracy: 0.99 - ETA: 4:15 - loss: 0.0356 - accuracy: 0.99 - ETA: 4:12 - loss: 0.0352 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0323 - accuracy: 0.99 - ETA: 4:06 - loss: 0.0361 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0488 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0452 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0422 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0398 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0402 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0431 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0454 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0489 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0513 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0499 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0452 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0474 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0481 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0454 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0453 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0438 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0450 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0440 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0490 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0489 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0462 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0438 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0437 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0436 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0432 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0425 - accuracy: 0.98 - ETA: 59s - loss: 0.0422 - accuracy: 0.9879 - ETA: 57s - loss: 0.0425 - accuracy: 0.988 - ETA: 55s - loss: 0.0424 - accuracy: 0.988 - ETA: 53s - loss: 0.0423 - accuracy: 0.988 - ETA: 51s - loss: 0.0420 - accuracy: 0.988 - ETA: 49s - loss: 0.0418 - accuracy: 0.988 - ETA: 48s - loss: 0.0416 - accuracy: 0.988 - ETA: 46s - loss: 0.0416 - accuracy: 0.988 - ETA: 44s - loss: 0.0416 - accuracy: 0.988 - ETA: 42s - loss: 0.0415 - accuracy: 0.988 - ETA: 40s - loss: 0.0412 - accuracy: 0.988 - ETA: 38s - loss: 0.0409 - accuracy: 0.988 - ETA: 36s - loss: 0.0419 - accuracy: 0.988 - ETA: 35s - loss: 0.0417 - accuracy: 0.988 - ETA: 33s - loss: 0.0417 - accuracy: 0.988 - ETA: 31s - loss: 0.0415 - accuracy: 0.988 - ETA: 29s - loss: 0.0419 - accuracy: 0.988 - ETA: 27s - loss: 0.0416 - accuracy: 0.988 - ETA: 25s - loss: 0.0420 - accuracy: 0.988 - ETA: 23s - loss: 0.0421 - accuracy: 0.988 - ETA: 22s - loss: 0.0421 - accuracy: 0.988 - ETA: 20s - loss: 0.0423 - accuracy: 0.988 - ETA: 18s - loss: 0.0421 - accuracy: 0.988 - ETA: 16s - loss: 0.0426 - accuracy: 0.988 - ETA: 14s - loss: 0.0427 - accuracy: 0.988 - ETA: 12s - loss: 0.0424 - accuracy: 0.988 - ETA: 10s - loss: 0.0422 - accuracy: 0.988 - ETA: 9s - loss: 0.0419 - accuracy: 0.988 - ETA: 7s - loss: 0.0420 - accuracy: 0.98 - ETA: 5s - loss: 0.0417 - accuracy: 0.98 - ETA: 3s - loss: 0.0416 - accuracy: 0.98 - ETA: 1s - loss: 0.0420 - accuracy: 0.98 - 307s 16ms/step - loss: 0.0420 - accuracy: 0.9885 - val_loss: 2.2951 - val_accuracy: 0.8124\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:49 - loss: 0.0435 - accuracy: 0.99 - ETA: 4:43 - loss: 0.0227 - accuracy: 0.99 - ETA: 4:37 - loss: 0.0307 - accuracy: 0.99 - ETA: 4:28 - loss: 0.0234 - accuracy: 0.99 - ETA: 4:20 - loss: 0.0209 - accuracy: 0.99 - ETA: 4:13 - loss: 0.0397 - accuracy: 0.99 - ETA: 4:08 - loss: 0.0344 - accuracy: 0.99 - ETA: 4:05 - loss: 0.0304 - accuracy: 0.99 - ETA: 4:06 - loss: 0.0281 - accuracy: 0.99 - ETA: 4:03 - loss: 0.0312 - accuracy: 0.99 - ETA: 4:03 - loss: 0.0439 - accuracy: 0.99 - ETA: 4:04 - loss: 0.0451 - accuracy: 0.99 - ETA: 4:03 - loss: 0.0446 - accuracy: 0.99 - ETA: 4:02 - loss: 0.0424 - accuracy: 0.99 - ETA: 3:59 - loss: 0.0429 - accuracy: 0.99 - ETA: 3:57 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0434 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0410 - accuracy: 0.99 - ETA: 3:52 - loss: 0.0389 - accuracy: 0.99 - ETA: 3:51 - loss: 0.0385 - accuracy: 0.99 - ETA: 3:50 - loss: 0.0392 - accuracy: 0.99 - ETA: 3:48 - loss: 0.0388 - accuracy: 0.99 - ETA: 3:45 - loss: 0.0393 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0389 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0389 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0406 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0397 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0392 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0390 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0380 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0368 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0363 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0353 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0343 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0334 - accuracy: 0.99 - ETA: 3:16 - loss: 0.0325 - accuracy: 0.99 - ETA: 3:15 - loss: 0.0335 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0344 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0355 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0390 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0403 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0394 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0393 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0385 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0378 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0376 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0376 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0375 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0383 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0401 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0399 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0401 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0435 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0431 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0426 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0437 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0438 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0433 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0427 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0421 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0425 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0419 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0417 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0411 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0438 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0448 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0448 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0448 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0435 - accuracy: 0.98 - ETA: 59s - loss: 0.0431 - accuracy: 0.9888 - ETA: 57s - loss: 0.0430 - accuracy: 0.988 - ETA: 55s - loss: 0.0438 - accuracy: 0.988 - ETA: 53s - loss: 0.0434 - accuracy: 0.988 - ETA: 52s - loss: 0.0431 - accuracy: 0.988 - ETA: 50s - loss: 0.0438 - accuracy: 0.988 - ETA: 48s - loss: 0.0438 - accuracy: 0.988 - ETA: 47s - loss: 0.0435 - accuracy: 0.988 - ETA: 45s - loss: 0.0431 - accuracy: 0.988 - ETA: 43s - loss: 0.0429 - accuracy: 0.988 - ETA: 41s - loss: 0.0426 - accuracy: 0.988 - ETA: 40s - loss: 0.0424 - accuracy: 0.988 - ETA: 38s - loss: 0.0435 - accuracy: 0.988 - ETA: 36s - loss: 0.0432 - accuracy: 0.988 - ETA: 35s - loss: 0.0431 - accuracy: 0.988 - ETA: 33s - loss: 0.0429 - accuracy: 0.988 - ETA: 31s - loss: 0.0430 - accuracy: 0.988 - ETA: 29s - loss: 0.0427 - accuracy: 0.989 - ETA: 27s - loss: 0.0428 - accuracy: 0.988 - ETA: 26s - loss: 0.0434 - accuracy: 0.988 - ETA: 24s - loss: 0.0432 - accuracy: 0.988 - ETA: 22s - loss: 0.0430 - accuracy: 0.988 - ETA: 20s - loss: 0.0427 - accuracy: 0.988 - ETA: 19s - loss: 0.0431 - accuracy: 0.988 - ETA: 17s - loss: 0.0428 - accuracy: 0.988 - ETA: 15s - loss: 0.0426 - accuracy: 0.988 - ETA: 13s - loss: 0.0424 - accuracy: 0.988 - ETA: 12s - loss: 0.0422 - accuracy: 0.989 - ETA: 10s - loss: 0.0419 - accuracy: 0.989 - ETA: 8s - loss: 0.0417 - accuracy: 0.989 - ETA: 6s - loss: 0.0414 - accuracy: 0.98 - ETA: 5s - loss: 0.0414 - accuracy: 0.98 - ETA: 3s - loss: 0.0413 - accuracy: 0.98 - ETA: 1s - loss: 0.0414 - accuracy: 0.98 - 294s 15ms/step - loss: 0.0414 - accuracy: 0.9891 - val_loss: 2.3167 - val_accuracy: 0.8174\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:19 - loss: 0.0094 - accuracy: 0.99 - ETA: 4:49 - loss: 0.0265 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0464 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0420 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0350 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0330 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0304 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0269 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0255 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0242 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0235 - accuracy: 0.99 - ETA: 4:26 - loss: 0.0291 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0302 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0295 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0298 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0283 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0275 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0291 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0330 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0344 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0335 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0320 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0307 - accuracy: 0.99 - ETA: 3:54 - loss: 0.0314 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0344 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0340 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0332 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0330 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0320 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0309 - accuracy: 0.99 - ETA: 3:37 - loss: 0.0362 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0351 - accuracy: 0.99 - ETA: 3:33 - loss: 0.0349 - accuracy: 0.99 - ETA: 3:32 - loss: 0.0341 - accuracy: 0.99 - ETA: 3:30 - loss: 0.0344 - accuracy: 0.99 - ETA: 3:28 - loss: 0.0352 - accuracy: 0.99 - ETA: 3:27 - loss: 0.0352 - accuracy: 0.99 - ETA: 3:25 - loss: 0.0352 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0353 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0344 - accuracy: 0.99 - ETA: 3:19 - loss: 0.0354 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0346 - accuracy: 0.99 - ETA: 3:16 - loss: 0.0346 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0354 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0349 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0353 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0381 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0379 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0383 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0383 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0391 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0434 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0437 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0432 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0438 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0433 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0425 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0420 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0424 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0419 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0421 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0417 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0412 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0410 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0406 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0406 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0404 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0412 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0410 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0409 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0416 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0414 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0410 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0413 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0411 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0406 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0408 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0414 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0412 - accuracy: 0.98 - ETA: 59s - loss: 0.0410 - accuracy: 0.9890 - ETA: 57s - loss: 0.0413 - accuracy: 0.988 - ETA: 55s - loss: 0.0409 - accuracy: 0.989 - ETA: 53s - loss: 0.0407 - accuracy: 0.989 - ETA: 51s - loss: 0.0406 - accuracy: 0.989 - ETA: 49s - loss: 0.0404 - accuracy: 0.989 - ETA: 48s - loss: 0.0404 - accuracy: 0.989 - ETA: 46s - loss: 0.0412 - accuracy: 0.989 - ETA: 44s - loss: 0.0410 - accuracy: 0.989 - ETA: 42s - loss: 0.0417 - accuracy: 0.988 - ETA: 40s - loss: 0.0414 - accuracy: 0.989 - ETA: 38s - loss: 0.0411 - accuracy: 0.989 - ETA: 36s - loss: 0.0410 - accuracy: 0.989 - ETA: 35s - loss: 0.0408 - accuracy: 0.989 - ETA: 33s - loss: 0.0411 - accuracy: 0.989 - ETA: 31s - loss: 0.0413 - accuracy: 0.988 - ETA: 29s - loss: 0.0413 - accuracy: 0.988 - ETA: 27s - loss: 0.0411 - accuracy: 0.988 - ETA: 25s - loss: 0.0409 - accuracy: 0.988 - ETA: 24s - loss: 0.0413 - accuracy: 0.988 - ETA: 22s - loss: 0.0410 - accuracy: 0.989 - ETA: 20s - loss: 0.0414 - accuracy: 0.989 - ETA: 18s - loss: 0.0414 - accuracy: 0.989 - ETA: 16s - loss: 0.0412 - accuracy: 0.989 - ETA: 14s - loss: 0.0416 - accuracy: 0.989 - ETA: 12s - loss: 0.0418 - accuracy: 0.988 - ETA: 10s - loss: 0.0417 - accuracy: 0.988 - ETA: 9s - loss: 0.0416 - accuracy: 0.988 - ETA: 7s - loss: 0.0417 - accuracy: 0.98 - ETA: 5s - loss: 0.0415 - accuracy: 0.98 - ETA: 3s - loss: 0.0413 - accuracy: 0.98 - ETA: 1s - loss: 0.0419 - accuracy: 0.98 - 303s 16ms/step - loss: 0.0417 - accuracy: 0.9889 - val_loss: 2.2618 - val_accuracy: 0.8128\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:42 - loss: 0.0163 - accuracy: 0.99 - ETA: 4:30 - loss: 0.0084 - accuracy: 0.99 - ETA: 4:27 - loss: 0.0098 - accuracy: 0.99 - ETA: 4:19 - loss: 0.0075 - accuracy: 0.99 - ETA: 4:15 - loss: 0.0148 - accuracy: 0.99 - ETA: 4:15 - loss: 0.0159 - accuracy: 0.99 - ETA: 4:12 - loss: 0.0140 - accuracy: 0.99 - ETA: 4:12 - loss: 0.0124 - accuracy: 0.99 - ETA: 4:09 - loss: 0.0154 - accuracy: 0.99 - ETA: 4:05 - loss: 0.0208 - accuracy: 0.99 - ETA: 4:02 - loss: 0.0196 - accuracy: 0.99 - ETA: 3:59 - loss: 0.0217 - accuracy: 0.99 - ETA: 3:57 - loss: 0.0229 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0321 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0337 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0327 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0342 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0332 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0315 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0304 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0306 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0311 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0299 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0290 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0280 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0307 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0303 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0324 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0336 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0351 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0349 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0350 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0419 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0413 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0438 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0433 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0450 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0472 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0481 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0483 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0490 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0495 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0500 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0490 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0493 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0490 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0497 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0483 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0462 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0435 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0408 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0406 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0397 - accuracy: 0.98 - ETA: 59s - loss: 0.0397 - accuracy: 0.9890 - ETA: 58s - loss: 0.0397 - accuracy: 0.989 - ETA: 56s - loss: 0.0394 - accuracy: 0.989 - ETA: 54s - loss: 0.0395 - accuracy: 0.989 - ETA: 53s - loss: 0.0398 - accuracy: 0.988 - ETA: 51s - loss: 0.0397 - accuracy: 0.988 - ETA: 49s - loss: 0.0401 - accuracy: 0.988 - ETA: 47s - loss: 0.0406 - accuracy: 0.988 - ETA: 46s - loss: 0.0410 - accuracy: 0.988 - ETA: 44s - loss: 0.0407 - accuracy: 0.988 - ETA: 42s - loss: 0.0407 - accuracy: 0.988 - ETA: 41s - loss: 0.0407 - accuracy: 0.988 - ETA: 39s - loss: 0.0404 - accuracy: 0.989 - ETA: 37s - loss: 0.0404 - accuracy: 0.989 - ETA: 36s - loss: 0.0403 - accuracy: 0.989 - ETA: 34s - loss: 0.0400 - accuracy: 0.989 - ETA: 32s - loss: 0.0401 - accuracy: 0.989 - ETA: 30s - loss: 0.0404 - accuracy: 0.989 - ETA: 29s - loss: 0.0413 - accuracy: 0.988 - ETA: 27s - loss: 0.0411 - accuracy: 0.988 - ETA: 25s - loss: 0.0408 - accuracy: 0.989 - ETA: 24s - loss: 0.0408 - accuracy: 0.989 - ETA: 22s - loss: 0.0406 - accuracy: 0.989 - ETA: 20s - loss: 0.0404 - accuracy: 0.989 - ETA: 18s - loss: 0.0403 - accuracy: 0.989 - ETA: 17s - loss: 0.0401 - accuracy: 0.989 - ETA: 15s - loss: 0.0398 - accuracy: 0.989 - ETA: 13s - loss: 0.0404 - accuracy: 0.989 - ETA: 11s - loss: 0.0401 - accuracy: 0.989 - ETA: 10s - loss: 0.0400 - accuracy: 0.989 - ETA: 8s - loss: 0.0404 - accuracy: 0.989 - ETA: 6s - loss: 0.0409 - accuracy: 0.98 - ETA: 5s - loss: 0.0408 - accuracy: 0.98 - ETA: 3s - loss: 0.0408 - accuracy: 0.98 - ETA: 1s - loss: 0.0406 - accuracy: 0.98 - 288s 15ms/step - loss: 0.0408 - accuracy: 0.9890 - val_loss: 2.2527 - val_accuracy: 0.8147\n",
      "2020-12-07 12:30:00.094532\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "t5=datetime.datetime.now()\n",
    "print(t5)\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n",
    "t6=datetime.datetime.now()\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [1.8865799474577944, 1.5013823757558709, 1.363680910535865, 1.3513735630023946, 1.2247246923370623, 1.277503716634603, 1.3494190836229243, 1.2650882611982717, 1.2501503723974579, 1.3758558039093491, 1.251477462259428, 1.3311846995728929, 1.4155743147404107, 1.388266004682155, 1.3537378324734595, 1.4312141650728765, 1.4232919595581721, 1.5141867680143781, 1.4833775146157135, 1.526510642426037, 1.4846714014319757, 1.5253187433783129, 1.6902873578291795, 1.600481255648422, 1.6948971987313726, 1.6880633356063157, 1.7324148596727866, 1.73731900182267, 1.7398590902335205, 1.7377906740760922, 1.7161241424431783, 1.7358035064429866, 1.9955893243956353, 1.756044768798324, 1.7942248143920694, 1.7580306330781763, 1.9029036045913792, 1.7706120077387149, 1.8399505754710972, 1.7972463177064606, 1.871839330023084, 1.894331981884468, 1.9149948784124533, 1.8981015345008014, 1.8509160006458554, 2.0280868148774087, 1.9690532524606954, 1.8828550979794367, 1.9085148111538108, 1.931081161979909, 1.9592917856159948, 1.9665481235749431, 1.961124126623323, 1.9995498071918578, 1.9234632464713206, 1.961371959058067, 2.059767874853782, 2.01360225870042, 2.045923419881494, 2.144042013792005, 2.051468908675686, 2.0380839284939114, 2.1914314902527385, 2.164431914208863, 2.119234503216565, 2.0837258409086186, 2.2655707340996862, 2.175627049611799, 2.2156784859076866, 2.2131704504530876, 2.075033728714487, 2.155048982478442, 2.122583131978763, 2.2225275826666464, 2.2339167181663964, 2.308755781739907, 2.2824955246023424, 2.1652280555844774, 2.1078518445903063, 2.2373062036229503, 2.323216070815825, 2.250102022069906, 2.1690175544897157, 2.4187544630684203, 2.307267072754238, 2.3298578787156083, 2.2768230215563587, 2.2078092656883057, 2.168676787613588, 2.196434894983604, 2.282373324539578, 2.227792123208803, 2.481171100646671, 2.286294851423569, 2.2043421146266824, 2.380987513013497, 2.2950538160342266, 2.3166930826338805, 2.261791120382243, 2.2526718846115914], 'val_accuracy': [0.5491819977760315, 0.6367778182029724, 0.6891695857048035, 0.6866846084594727, 0.7241665124893188, 0.7345206141471863, 0.741768479347229, 0.75295090675354, 0.7630979418754578, 0.7591633796691895, 0.7726237177848816, 0.7751086950302124, 0.7724166512489319, 0.7821494936943054, 0.7835990786552429, 0.7850486636161804, 0.7806999087333679, 0.7780078649520874, 0.7854628562927246, 0.7914682030677795, 0.7906398773193359, 0.788776159286499, 0.7879478335380554, 0.7916752696037292, 0.7879478335380554, 0.7883619666099548, 0.7908469438552856, 0.7908469438552856, 0.7922965288162231, 0.7902257442474365, 0.7962310910224915, 0.7925035953521729, 0.7908469438552856, 0.7945744395256042, 0.7960240244865417, 0.8030648231506348, 0.7951956987380981, 0.8022364974021912, 0.797680675983429, 0.8041002154350281, 0.8036860823631287, 0.8024435639381409, 0.8026506304740906, 0.8038931488990784, 0.8043072819709778, 0.804721474647522, 0.8028577566146851, 0.8016152381896973, 0.8016152381896973, 0.801822304725647, 0.804721474647522, 0.8041002154350281, 0.8041002154350281, 0.8020294308662415, 0.8078277111053467, 0.8086560368537903, 0.8092772960662842, 0.8078277111053467, 0.8012011051177979, 0.8024435639381409, 0.8045144081115723, 0.8092772960662842, 0.8030648231506348, 0.8016152381896973, 0.8113480806350708, 0.8084489703178406, 0.8061710596084595, 0.8063781261444092, 0.8049285411834717, 0.8020294308662415, 0.8090702295303345, 0.8057568669319153, 0.804721474647522, 0.8045144081115723, 0.8065851926803589, 0.8090702295303345, 0.8067923188209534, 0.8069993853569031, 0.8103126883506775, 0.8101056218147278, 0.807620644569397, 0.8130047917366028, 0.8192172050476074, 0.8086560368537903, 0.815903902053833, 0.8140401840209961, 0.8105197548866272, 0.8132118582725525, 0.8125905990600586, 0.8107268810272217, 0.8069993853569031, 0.8096914291381836, 0.8063781261444092, 0.8103126883506775, 0.8123835325241089, 0.8103126883506775, 0.8123835325241089, 0.8173534870147705, 0.8127976655960083, 0.81466144323349], 'loss': [5.000002256186422, 1.8882161509230202, 1.4473612371711762, 1.141594150980939, 0.9363971888870865, 0.7889177835274058, 0.6734343510377279, 0.613869726410955, 0.5311839868435706, 0.4618842691899136, 0.41261765106512477, 0.37152184236118785, 0.3513518465187496, 0.32486242848481633, 0.31231307662412366, 0.2929792926641368, 0.26745417015356965, 0.252245665682972, 0.23188974757083902, 0.21992051208819252, 0.216403733256837, 0.20172194951671454, 0.19431056663727306, 0.18334997155840177, 0.1843800009926588, 0.18552375191015552, 0.16681229316049997, 0.16688760874334602, 0.14797249682673563, 0.14416439374468992, 0.14497598767428727, 0.12996888890331604, 0.11838436334115371, 0.1428139069933188, 0.12528295929805247, 0.12767429369892971, 0.12486409511364682, 0.10841310038458936, 0.1083427491538418, 0.0955068998551112, 0.10221708371121106, 0.0930783916650573, 0.08718104348784157, 0.09633504166927531, 0.08688868701680488, 0.09158989786947426, 0.09232811451069363, 0.0853873050598815, 0.08308099249459637, 0.08142847354834792, 0.08361994068492466, 0.07408740325478255, 0.08236437060198165, 0.07852081742366064, 0.07179485979646617, 0.07254326816064914, 0.07552104339690481, 0.06492789766663268, 0.0704936920502686, 0.07288859680745606, 0.07044228678993578, 0.06700417522399654, 0.061615287858005935, 0.058627435100143704, 0.06662208435002964, 0.060091276834244346, 0.06285169654253442, 0.06119216664064623, 0.06027316737552764, 0.06616765133266483, 0.05711022495078394, 0.05591060440600005, 0.05615428528982248, 0.05305729564854161, 0.05324816465506665, 0.058295374427163586, 0.051742169001026274, 0.05279959888408129, 0.0592613729020691, 0.04450961847750234, 0.054890324270862746, 0.042818756151192856, 0.052632113471446876, 0.05263468322873443, 0.04352128321988556, 0.05347495606128981, 0.05079774034063958, 0.056790688538471704, 0.04269998554162899, 0.04288948231648504, 0.039481615061015614, 0.049190139817753914, 0.04662812700279654, 0.03972975713330207, 0.04194275118852232, 0.0506971715554844, 0.04199323190303632, 0.041352017580963345, 0.04168936983040243, 0.040818767991324376], 'accuracy': [0.34077257, 0.5532829, 0.6396541, 0.71028376, 0.7561102, 0.7881628, 0.8199565, 0.83393747, 0.8535108, 0.87241095, 0.8873757, 0.8934341, 0.9025994, 0.9098488, 0.91336995, 0.9223281, 0.9250725, 0.93154514, 0.9360501, 0.9383285, 0.9406586, 0.9452672, 0.9469242, 0.94940966, 0.9493579, 0.95018643, 0.9558824, 0.9562966, 0.9597142, 0.96095693, 0.9613194, 0.96416736, 0.9666011, 0.9643227, 0.9668082, 0.9675849, 0.9691384, 0.9708989, 0.97265947, 0.9744201, 0.97260773, 0.97333264, 0.97633594, 0.9742647, 0.9775269, 0.9754557, 0.97576636, 0.9766984, 0.9782001, 0.9782001, 0.97861433, 0.98042667, 0.97939104, 0.97949463, 0.98047847, 0.98021954, 0.980116, 0.9831711, 0.98032314, 0.98135877, 0.9803749, 0.98182476, 0.9839478, 0.9828604, 0.98322284, 0.98348176, 0.98358536, 0.98431027, 0.984621, 0.9836889, 0.98632973, 0.98565656, 0.9852941, 0.9861226, 0.985553, 0.9852941, 0.9870547, 0.98565656, 0.9860708, 0.98715824, 0.98648506, 0.9878314, 0.98721004, 0.9866922, 0.98819387, 0.98664045, 0.98741716, 0.9870029, 0.98746896, 0.9885563, 0.98871166, 0.98715824, 0.98741716, 0.98876345, 0.9890742, 0.98871166, 0.9885045, 0.9890742, 0.98886704, 0.9889706]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = np.arange(0, len(history.history['loss']))\n",
    "\n",
    "# You can chose the style of your preference\n",
    "# print(plt.style.available) to see the available options\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "plt.figure()\n",
    "plt.plot(N, history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(N, history.history['accuracy'], label = \"train_acc\")\n",
    "plt.plot(N, history.history['val_loss'], label = \"val_loss\")\n",
    "plt.plot(N, history.history['val_accuracy'], label = \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# Make sure there exists a folder called output in the current directory\n",
    "# or replace 'output' with whatever direcory you want to put in the plots\n",
    "plt.show()\n",
    "plt.savefig('../Output/EpochResNet101V2.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
