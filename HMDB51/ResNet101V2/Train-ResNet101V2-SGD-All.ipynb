{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet_v2 import ResNet101V2\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24136</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24137</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24138</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24139</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24140</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image class\n",
       "24136  winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg  wave\n",
       "24137  winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg  wave\n",
       "24138  winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg  wave\n",
       "24139  winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg  wave\n",
       "24140  winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg  wave"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_2.csv')\n",
    "train.sort_values(by=['class', 'image'])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24141/24141 [01:24<00:00, 285.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/train_frame/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24141, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X = np.array(train_image,np.float16)\n",
    "train_image=[]\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 224, 224, 3)\n",
      "(4829, 224, 224, 3)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained ResNet101V2 model\n",
    "base_model = ResNet101V2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet101v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, None, None, 6 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, None, None, 6 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, None, None, 2 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, None, None, 2 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, None, None, 2 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, None, None, 2 0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, None, None, 2 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, None, None, 5 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, None, None, 5 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, None, None, 5 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, None, None, 5 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, None, None, 5 0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, None, None, 5 0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, None, None, 1 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, None, None, 1 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, None, None, 1 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, None, None, 1 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, None, None, 1 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, None, None, 1 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, None, None, 1 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block7_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, None, None, 2 0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, None, None, 2 0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, None, None, 1 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, None, None, 1 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, None, None, 2 0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, None, None, 2 0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, None, None, 1 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, None, None, 1 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, None, None, 2 0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, None, None, 2 0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, None, None, 1 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, None, None, 1 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, None, None, 1 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, None, None, 2 0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, None, None, 2 0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block10_2_relu[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, None, None, 1 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, None, None, 1 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, None, None, 1 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, None, None, 2 0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, None, None, 2 0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, None, None, 1 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, None, None, 1 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, None, None, 1 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, None, None, 2 0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, None, None, 2 0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, None, None, 1 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, None, None, 1 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, None, None, 1 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, None, None, 2 0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, None, None, 2 0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, None, None, 1 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, None, None, 1 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, None, None, 1 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, None, None, 2 0           conv4_block14_1_bn[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, None, None, 2 0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, None, None, 1 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, None, None, 1 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, None, None, 1 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, None, None, 2 0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, None, None, 2 0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, None, None, 1 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, None, None, 1 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, None, None, 1 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, None, None, 2 0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, None, None, 2 0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, None, None, 1 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, None, None, 1 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, None, None, 1 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, None, None, 2 0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, None, None, 2 0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, None, None, 1 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, None, None, 1 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, None, None, 1 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, None, None, 2 0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, None, None, 2 0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, None, None, 1 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, None, None, 1 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, None, None, 1 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, None, None, 2 0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, None, None, 2 0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, None, None, 1 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, None, None, 1 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, None, None, 1 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, None, None, 2 0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, None, None, 2 0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, None, None, 1 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, None, None, 1 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, None, None, 1 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, None, None, 2 0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block21_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, None, None, 2 0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, None, None, 1 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, None, None, 1 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, None, None, 1 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, None, None, 2 0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, None, None, 2 0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, None, None, 1 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, None, None, 1 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, None, None, 1 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, None, None, 2 0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, None, None, 2 0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, None, None, 1 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, None, None, 1 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, None, None, 2 0           conv5_block1_0_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, None, None, 2 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, None, None, 2 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, None, None, 2 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, None, None, 2 0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 42,626,560\n",
      "Trainable params: 42,528,896\n",
      "Non-trainable params: 97,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'resnet101v2',\n",
       " 'layers': [{'name': 'input_1',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_1'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'conv1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((3, 3), (3, 3)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (7, 7),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'pool1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pool',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'pool1_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool1_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_0_conv', 0, 0, {}],\n",
       "     ['conv2_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}],\n",
       "     ['conv2_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_1',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_1', 0, 0, {}],\n",
       "     ['conv2_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_0_conv', 0, 0, {}],\n",
       "     ['conv3_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}],\n",
       "     ['conv3_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}],\n",
       "     ['conv3_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_2',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}],\n",
       "     ['conv3_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_0_conv', 0, 0, {}],\n",
       "     ['conv4_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}],\n",
       "     ['conv4_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}],\n",
       "     ['conv4_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}],\n",
       "     ['conv4_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block5_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block5_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}],\n",
       "     ['conv4_block5_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block6_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block6_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}],\n",
       "     ['conv4_block6_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block7_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block7_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}],\n",
       "     ['conv4_block7_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block8_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block8_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}],\n",
       "     ['conv4_block8_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block9_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block9_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}],\n",
       "     ['conv4_block9_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block10_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block10_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}],\n",
       "     ['conv4_block10_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block11_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block11_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}],\n",
       "     ['conv4_block11_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block12_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block12_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}],\n",
       "     ['conv4_block12_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block13_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block13_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}],\n",
       "     ['conv4_block13_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block14_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block14_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}],\n",
       "     ['conv4_block14_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block15_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block15_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}],\n",
       "     ['conv4_block15_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block16_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block16_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}],\n",
       "     ['conv4_block16_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block17_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block17_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}],\n",
       "     ['conv4_block17_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block18_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block18_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}],\n",
       "     ['conv4_block18_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block19_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block19_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}],\n",
       "     ['conv4_block19_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block20_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block20_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}],\n",
       "     ['conv4_block20_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block21_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block21_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}],\n",
       "     ['conv4_block21_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block22_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block22_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}],\n",
       "     ['conv4_block22_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block23_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_3',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block23_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_3', 0, 0, {}],\n",
       "     ['conv4_block23_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_0_conv', 0, 0, {}],\n",
       "     ['conv5_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}],\n",
       "     ['conv5_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}],\n",
       "     ['conv5_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'post_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'post_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'post_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'post_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['post_bn', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['post_relu', 0, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1=datetime.datetime.now()\n",
    "print(t1)\n",
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "print(X_train.shape)\n",
    "t2=datetime.datetime.now()\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(19312, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(X_train, '../Pickle/ResNet101V2_X_train_2.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t3=datetime.datetime.now()\n",
    "print(t3)\n",
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "print(X_test.shape)\n",
    "t4=datetime.datetime.now()\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test = X_test.reshape(4829, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib.dump(X_test, '../Pickle/ResNet101V2_X_test_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "X_train = joblib.load('../Pickle/ResNet101V2_X_train_2.pkl') \n",
    "X_test = joblib.load('../Pickle/ResNet101V2_X_test_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 100352)\n",
      "(4829, 100352)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "# shape of images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 51)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 51)                52275     \n",
      "=================================================================\n",
      "Total params: 102,813,747\n",
      "Trainable params: 102,813,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('../Models/weightResNet101V2_4.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='SGD',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-06 12:30:09.507703\n",
      "Train on 19312 samples, validate on 4829 samples\n",
      "Epoch 1/100\n",
      "19312/19312 [==============================] - ETA: 3:42 - loss: 8.8601 - accuracy: 0.04 - ETA: 2:51 - loss: 9.5920 - accuracy: 0.07 - ETA: 2:38 - loss: 11.0004 - accuracy: 0.085 - ETA: 2:29 - loss: 11.8383 - accuracy: 0.093 - ETA: 2:23 - loss: 11.2209 - accuracy: 0.100 - ETA: 2:20 - loss: 10.2421 - accuracy: 0.112 - ETA: 2:15 - loss: 9.3599 - accuracy: 0.125 - ETA: 2:12 - loss: 8.7283 - accuracy: 0.12 - ETA: 2:09 - loss: 8.1406 - accuracy: 0.13 - ETA: 2:07 - loss: 7.6365 - accuracy: 0.15 - ETA: 2:05 - loss: 7.2451 - accuracy: 0.16 - ETA: 2:03 - loss: 6.9222 - accuracy: 0.16 - ETA: 2:01 - loss: 6.6137 - accuracy: 0.17 - ETA: 2:00 - loss: 6.3461 - accuracy: 0.18 - ETA: 1:59 - loss: 6.1022 - accuracy: 0.20 - ETA: 1:58 - loss: 5.9141 - accuracy: 0.20 - ETA: 1:57 - loss: 5.7429 - accuracy: 0.21 - ETA: 1:56 - loss: 5.5855 - accuracy: 0.21 - ETA: 1:55 - loss: 5.4345 - accuracy: 0.22 - ETA: 1:54 - loss: 5.3052 - accuracy: 0.23 - ETA: 1:53 - loss: 5.1961 - accuracy: 0.23 - ETA: 1:52 - loss: 5.0691 - accuracy: 0.23 - ETA: 1:50 - loss: 5.0033 - accuracy: 0.23 - ETA: 1:49 - loss: 4.9015 - accuracy: 0.24 - ETA: 1:48 - loss: 4.8147 - accuracy: 0.24 - ETA: 1:48 - loss: 4.7414 - accuracy: 0.24 - ETA: 1:47 - loss: 4.6696 - accuracy: 0.25 - ETA: 1:46 - loss: 4.5980 - accuracy: 0.25 - ETA: 1:45 - loss: 4.5460 - accuracy: 0.25 - ETA: 1:44 - loss: 4.4879 - accuracy: 0.26 - ETA: 1:43 - loss: 4.4293 - accuracy: 0.26 - ETA: 1:42 - loss: 4.3713 - accuracy: 0.26 - ETA: 1:41 - loss: 4.3196 - accuracy: 0.27 - ETA: 1:40 - loss: 4.2649 - accuracy: 0.27 - ETA: 1:40 - loss: 4.2104 - accuracy: 0.27 - ETA: 1:39 - loss: 4.1758 - accuracy: 0.27 - ETA: 1:38 - loss: 4.1321 - accuracy: 0.28 - ETA: 1:37 - loss: 4.0939 - accuracy: 0.28 - ETA: 1:36 - loss: 4.0592 - accuracy: 0.28 - ETA: 1:35 - loss: 4.0236 - accuracy: 0.28 - ETA: 1:34 - loss: 3.9834 - accuracy: 0.29 - ETA: 1:33 - loss: 3.9425 - accuracy: 0.29 - ETA: 1:32 - loss: 3.9062 - accuracy: 0.29 - ETA: 1:31 - loss: 3.8745 - accuracy: 0.29 - ETA: 1:31 - loss: 3.8400 - accuracy: 0.30 - ETA: 1:30 - loss: 3.8034 - accuracy: 0.30 - ETA: 1:29 - loss: 3.7766 - accuracy: 0.30 - ETA: 1:28 - loss: 3.7437 - accuracy: 0.31 - ETA: 1:27 - loss: 3.7218 - accuracy: 0.31 - ETA: 1:26 - loss: 3.6945 - accuracy: 0.31 - ETA: 1:25 - loss: 3.6669 - accuracy: 0.31 - ETA: 1:24 - loss: 3.6404 - accuracy: 0.31 - ETA: 1:23 - loss: 3.6131 - accuracy: 0.32 - ETA: 1:22 - loss: 3.5915 - accuracy: 0.32 - ETA: 1:21 - loss: 3.5738 - accuracy: 0.32 - ETA: 1:20 - loss: 3.5529 - accuracy: 0.32 - ETA: 1:19 - loss: 3.5292 - accuracy: 0.32 - ETA: 1:18 - loss: 3.5071 - accuracy: 0.33 - ETA: 1:17 - loss: 3.4839 - accuracy: 0.33 - ETA: 1:16 - loss: 3.4633 - accuracy: 0.33 - ETA: 1:15 - loss: 3.4433 - accuracy: 0.33 - ETA: 1:14 - loss: 3.4205 - accuracy: 0.34 - ETA: 1:13 - loss: 3.4043 - accuracy: 0.34 - ETA: 1:13 - loss: 3.3916 - accuracy: 0.34 - ETA: 1:12 - loss: 3.3711 - accuracy: 0.34 - ETA: 1:11 - loss: 3.3556 - accuracy: 0.34 - ETA: 1:10 - loss: 3.3376 - accuracy: 0.34 - ETA: 1:09 - loss: 3.3182 - accuracy: 0.35 - ETA: 1:08 - loss: 3.3023 - accuracy: 0.35 - ETA: 1:08 - loss: 3.2838 - accuracy: 0.35 - ETA: 1:07 - loss: 3.2707 - accuracy: 0.35 - ETA: 1:06 - loss: 3.2567 - accuracy: 0.35 - ETA: 1:05 - loss: 3.2421 - accuracy: 0.35 - ETA: 1:04 - loss: 3.2292 - accuracy: 0.35 - ETA: 1:03 - loss: 3.2170 - accuracy: 0.35 - ETA: 1:02 - loss: 3.2036 - accuracy: 0.36 - ETA: 1:01 - loss: 3.1940 - accuracy: 0.36 - ETA: 1:00 - loss: 3.1774 - accuracy: 0.36 - ETA: 1:00 - loss: 3.1617 - accuracy: 0.36 - ETA: 59s - loss: 3.1438 - accuracy: 0.3688 - ETA: 58s - loss: 3.1312 - accuracy: 0.370 - ETA: 57s - loss: 3.1181 - accuracy: 0.371 - ETA: 56s - loss: 3.1061 - accuracy: 0.372 - ETA: 55s - loss: 3.0949 - accuracy: 0.374 - ETA: 54s - loss: 3.0817 - accuracy: 0.375 - ETA: 53s - loss: 3.0676 - accuracy: 0.377 - ETA: 52s - loss: 3.0564 - accuracy: 0.378 - ETA: 52s - loss: 3.0452 - accuracy: 0.379 - ETA: 51s - loss: 3.0345 - accuracy: 0.381 - ETA: 50s - loss: 3.0211 - accuracy: 0.382 - ETA: 49s - loss: 3.0099 - accuracy: 0.384 - ETA: 48s - loss: 2.9984 - accuracy: 0.385 - ETA: 47s - loss: 2.9859 - accuracy: 0.387 - ETA: 47s - loss: 2.9752 - accuracy: 0.388 - ETA: 46s - loss: 2.9620 - accuracy: 0.390 - ETA: 45s - loss: 2.9502 - accuracy: 0.391 - ETA: 44s - loss: 2.9380 - accuracy: 0.393 - ETA: 43s - loss: 2.9258 - accuracy: 0.395 - ETA: 42s - loss: 2.9137 - accuracy: 0.396 - ETA: 41s - loss: 2.9041 - accuracy: 0.398 - ETA: 41s - loss: 2.8948 - accuracy: 0.399 - ETA: 40s - loss: 2.8858 - accuracy: 0.400 - ETA: 39s - loss: 2.8754 - accuracy: 0.401 - ETA: 38s - loss: 2.8682 - accuracy: 0.402 - ETA: 37s - loss: 2.8606 - accuracy: 0.403 - ETA: 37s - loss: 2.8536 - accuracy: 0.404 - ETA: 36s - loss: 2.8472 - accuracy: 0.405 - ETA: 35s - loss: 2.8389 - accuracy: 0.406 - ETA: 34s - loss: 2.8296 - accuracy: 0.407 - ETA: 33s - loss: 2.8213 - accuracy: 0.409 - ETA: 32s - loss: 2.8110 - accuracy: 0.410 - ETA: 32s - loss: 2.8038 - accuracy: 0.411 - ETA: 31s - loss: 2.7961 - accuracy: 0.412 - ETA: 30s - loss: 2.7899 - accuracy: 0.412 - ETA: 29s - loss: 2.7817 - accuracy: 0.414 - ETA: 28s - loss: 2.7743 - accuracy: 0.414 - ETA: 27s - loss: 2.7648 - accuracy: 0.416 - ETA: 27s - loss: 2.7564 - accuracy: 0.417 - ETA: 26s - loss: 2.7467 - accuracy: 0.419 - ETA: 25s - loss: 2.7373 - accuracy: 0.421 - ETA: 24s - loss: 2.7291 - accuracy: 0.422 - ETA: 23s - loss: 2.7219 - accuracy: 0.423 - ETA: 22s - loss: 2.7133 - accuracy: 0.425 - ETA: 22s - loss: 2.7043 - accuracy: 0.426 - ETA: 21s - loss: 2.6970 - accuracy: 0.427 - ETA: 20s - loss: 2.6920 - accuracy: 0.428 - ETA: 19s - loss: 2.6878 - accuracy: 0.428 - ETA: 18s - loss: 2.6807 - accuracy: 0.429 - ETA: 17s - loss: 2.6723 - accuracy: 0.431 - ETA: 17s - loss: 2.6675 - accuracy: 0.431 - ETA: 16s - loss: 2.6610 - accuracy: 0.433 - ETA: 15s - loss: 2.6551 - accuracy: 0.433 - ETA: 14s - loss: 2.6491 - accuracy: 0.434 - ETA: 13s - loss: 2.6409 - accuracy: 0.436 - ETA: 13s - loss: 2.6331 - accuracy: 0.437 - ETA: 12s - loss: 2.6262 - accuracy: 0.438 - ETA: 11s - loss: 2.6193 - accuracy: 0.439 - ETA: 10s - loss: 2.6140 - accuracy: 0.440 - ETA: 9s - loss: 2.6077 - accuracy: 0.441 - ETA: 8s - loss: 2.5997 - accuracy: 0.44 - ETA: 8s - loss: 2.5954 - accuracy: 0.44 - ETA: 7s - loss: 2.5890 - accuracy: 0.44 - ETA: 6s - loss: 2.5826 - accuracy: 0.44 - ETA: 5s - loss: 2.5770 - accuracy: 0.44 - ETA: 4s - loss: 2.5711 - accuracy: 0.44 - ETA: 3s - loss: 2.5663 - accuracy: 0.44 - ETA: 3s - loss: 2.5590 - accuracy: 0.44 - ETA: 2s - loss: 2.5527 - accuracy: 0.44 - ETA: 1s - loss: 2.5449 - accuracy: 0.44 - ETA: 0s - loss: 2.5420 - accuracy: 0.44 - 135s 7ms/step - loss: 2.5374 - accuracy: 0.4504 - val_loss: 1.3617 - val_accuracy: 0.6575\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:52 - loss: 1.2528 - accuracy: 0.64 - ETA: 1:48 - loss: 1.0407 - accuracy: 0.69 - ETA: 1:45 - loss: 1.0225 - accuracy: 0.70 - ETA: 1:45 - loss: 1.0682 - accuracy: 0.68 - ETA: 1:45 - loss: 1.0387 - accuracy: 0.70 - ETA: 1:45 - loss: 1.0136 - accuracy: 0.70 - ETA: 1:46 - loss: 0.9983 - accuracy: 0.71 - ETA: 1:46 - loss: 1.0093 - accuracy: 0.71 - ETA: 1:44 - loss: 1.0143 - accuracy: 0.71 - ETA: 1:43 - loss: 1.0255 - accuracy: 0.71 - ETA: 1:43 - loss: 1.0138 - accuracy: 0.71 - ETA: 1:42 - loss: 1.0149 - accuracy: 0.72 - ETA: 1:41 - loss: 1.0224 - accuracy: 0.72 - ETA: 1:40 - loss: 1.0174 - accuracy: 0.72 - ETA: 1:39 - loss: 1.0143 - accuracy: 0.72 - ETA: 1:38 - loss: 1.0237 - accuracy: 0.71 - ETA: 1:37 - loss: 1.0169 - accuracy: 0.72 - ETA: 1:36 - loss: 1.0181 - accuracy: 0.71 - ETA: 1:36 - loss: 1.0212 - accuracy: 0.71 - ETA: 1:35 - loss: 1.0180 - accuracy: 0.71 - ETA: 1:34 - loss: 1.0216 - accuracy: 0.71 - ETA: 1:33 - loss: 1.0287 - accuracy: 0.71 - ETA: 1:33 - loss: 1.0217 - accuracy: 0.71 - ETA: 1:32 - loss: 1.0182 - accuracy: 0.71 - ETA: 1:31 - loss: 1.0157 - accuracy: 0.71 - ETA: 1:30 - loss: 1.0132 - accuracy: 0.72 - ETA: 1:30 - loss: 1.0115 - accuracy: 0.72 - ETA: 1:29 - loss: 1.0083 - accuracy: 0.72 - ETA: 1:28 - loss: 1.0073 - accuracy: 0.72 - ETA: 1:28 - loss: 1.0076 - accuracy: 0.72 - ETA: 1:27 - loss: 1.0038 - accuracy: 0.72 - ETA: 1:26 - loss: 1.0030 - accuracy: 0.72 - ETA: 1:25 - loss: 1.0106 - accuracy: 0.72 - ETA: 1:25 - loss: 1.0088 - accuracy: 0.72 - ETA: 1:24 - loss: 1.0051 - accuracy: 0.72 - ETA: 1:23 - loss: 1.0078 - accuracy: 0.72 - ETA: 1:22 - loss: 1.0091 - accuracy: 0.72 - ETA: 1:21 - loss: 1.0129 - accuracy: 0.72 - ETA: 1:21 - loss: 1.0104 - accuracy: 0.72 - ETA: 1:20 - loss: 1.0141 - accuracy: 0.72 - ETA: 1:19 - loss: 1.0135 - accuracy: 0.72 - ETA: 1:18 - loss: 1.0149 - accuracy: 0.72 - ETA: 1:18 - loss: 1.0216 - accuracy: 0.71 - ETA: 1:17 - loss: 1.0233 - accuracy: 0.71 - ETA: 1:16 - loss: 1.0270 - accuracy: 0.71 - ETA: 1:15 - loss: 1.0319 - accuracy: 0.71 - ETA: 1:14 - loss: 1.0360 - accuracy: 0.71 - ETA: 1:14 - loss: 1.0330 - accuracy: 0.71 - ETA: 1:13 - loss: 1.0353 - accuracy: 0.71 - ETA: 1:12 - loss: 1.0329 - accuracy: 0.71 - ETA: 1:12 - loss: 1.0374 - accuracy: 0.71 - ETA: 1:11 - loss: 1.0387 - accuracy: 0.71 - ETA: 1:10 - loss: 1.0349 - accuracy: 0.71 - ETA: 1:10 - loss: 1.0337 - accuracy: 0.71 - ETA: 1:09 - loss: 1.0336 - accuracy: 0.71 - ETA: 1:08 - loss: 1.0352 - accuracy: 0.71 - ETA: 1:08 - loss: 1.0372 - accuracy: 0.71 - ETA: 1:07 - loss: 1.0352 - accuracy: 0.71 - ETA: 1:07 - loss: 1.0330 - accuracy: 0.71 - ETA: 1:06 - loss: 1.0319 - accuracy: 0.71 - ETA: 1:05 - loss: 1.0322 - accuracy: 0.71 - ETA: 1:05 - loss: 1.0338 - accuracy: 0.71 - ETA: 1:04 - loss: 1.0363 - accuracy: 0.71 - ETA: 1:04 - loss: 1.0369 - accuracy: 0.71 - ETA: 1:03 - loss: 1.0377 - accuracy: 0.71 - ETA: 1:02 - loss: 1.0380 - accuracy: 0.71 - ETA: 1:01 - loss: 1.0395 - accuracy: 0.71 - ETA: 1:01 - loss: 1.0380 - accuracy: 0.71 - ETA: 1:00 - loss: 1.0357 - accuracy: 0.71 - ETA: 59s - loss: 1.0332 - accuracy: 0.7179 - ETA: 59s - loss: 1.0300 - accuracy: 0.718 - ETA: 58s - loss: 1.0298 - accuracy: 0.718 - ETA: 57s - loss: 1.0307 - accuracy: 0.718 - ETA: 57s - loss: 1.0280 - accuracy: 0.718 - ETA: 56s - loss: 1.0257 - accuracy: 0.719 - ETA: 55s - loss: 1.0251 - accuracy: 0.719 - ETA: 54s - loss: 1.0263 - accuracy: 0.719 - ETA: 53s - loss: 1.0270 - accuracy: 0.718 - ETA: 53s - loss: 1.0272 - accuracy: 0.718 - ETA: 52s - loss: 1.0275 - accuracy: 0.718 - ETA: 51s - loss: 1.0256 - accuracy: 0.719 - ETA: 50s - loss: 1.0250 - accuracy: 0.719 - ETA: 50s - loss: 1.0248 - accuracy: 0.719 - ETA: 49s - loss: 1.0243 - accuracy: 0.719 - ETA: 48s - loss: 1.0249 - accuracy: 0.719 - ETA: 47s - loss: 1.0262 - accuracy: 0.718 - ETA: 47s - loss: 1.0242 - accuracy: 0.719 - ETA: 46s - loss: 1.0246 - accuracy: 0.719 - ETA: 45s - loss: 1.0235 - accuracy: 0.719 - ETA: 44s - loss: 1.0227 - accuracy: 0.720 - ETA: 44s - loss: 1.0233 - accuracy: 0.719 - ETA: 43s - loss: 1.0238 - accuracy: 0.719 - ETA: 42s - loss: 1.0228 - accuracy: 0.719 - ETA: 41s - loss: 1.0207 - accuracy: 0.720 - ETA: 41s - loss: 1.0196 - accuracy: 0.721 - ETA: 40s - loss: 1.0202 - accuracy: 0.721 - ETA: 39s - loss: 1.0200 - accuracy: 0.721 - ETA: 38s - loss: 1.0181 - accuracy: 0.722 - ETA: 38s - loss: 1.0194 - accuracy: 0.722 - ETA: 37s - loss: 1.0200 - accuracy: 0.721 - ETA: 36s - loss: 1.0198 - accuracy: 0.722 - ETA: 35s - loss: 1.0192 - accuracy: 0.722 - ETA: 35s - loss: 1.0200 - accuracy: 0.722 - ETA: 34s - loss: 1.0206 - accuracy: 0.722 - ETA: 33s - loss: 1.0206 - accuracy: 0.722 - ETA: 32s - loss: 1.0229 - accuracy: 0.721 - ETA: 32s - loss: 1.0229 - accuracy: 0.722 - ETA: 31s - loss: 1.0216 - accuracy: 0.722 - ETA: 30s - loss: 1.0217 - accuracy: 0.721 - ETA: 30s - loss: 1.0223 - accuracy: 0.721 - ETA: 29s - loss: 1.0237 - accuracy: 0.721 - ETA: 28s - loss: 1.0212 - accuracy: 0.722 - ETA: 27s - loss: 1.0215 - accuracy: 0.722 - ETA: 27s - loss: 1.0220 - accuracy: 0.722 - ETA: 26s - loss: 1.0211 - accuracy: 0.722 - ETA: 25s - loss: 1.0190 - accuracy: 0.723 - ETA: 24s - loss: 1.0187 - accuracy: 0.723 - ETA: 24s - loss: 1.0180 - accuracy: 0.723 - ETA: 23s - loss: 1.0179 - accuracy: 0.723 - ETA: 22s - loss: 1.0168 - accuracy: 0.723 - ETA: 21s - loss: 1.0162 - accuracy: 0.723 - ETA: 21s - loss: 1.0144 - accuracy: 0.724 - ETA: 20s - loss: 1.0138 - accuracy: 0.724 - ETA: 19s - loss: 1.0121 - accuracy: 0.724 - ETA: 18s - loss: 1.0111 - accuracy: 0.725 - ETA: 18s - loss: 1.0105 - accuracy: 0.725 - ETA: 17s - loss: 1.0103 - accuracy: 0.725 - ETA: 16s - loss: 1.0095 - accuracy: 0.725 - ETA: 16s - loss: 1.0087 - accuracy: 0.725 - ETA: 15s - loss: 1.0069 - accuracy: 0.726 - ETA: 14s - loss: 1.0077 - accuracy: 0.725 - ETA: 13s - loss: 1.0073 - accuracy: 0.725 - ETA: 13s - loss: 1.0082 - accuracy: 0.726 - ETA: 12s - loss: 1.0079 - accuracy: 0.725 - ETA: 11s - loss: 1.0070 - accuracy: 0.726 - ETA: 10s - loss: 1.0066 - accuracy: 0.726 - ETA: 10s - loss: 1.0065 - accuracy: 0.726 - ETA: 9s - loss: 1.0048 - accuracy: 0.726 - ETA: 8s - loss: 1.0019 - accuracy: 0.72 - ETA: 7s - loss: 1.0012 - accuracy: 0.72 - ETA: 7s - loss: 1.0002 - accuracy: 0.72 - ETA: 6s - loss: 1.0003 - accuracy: 0.72 - ETA: 5s - loss: 0.9991 - accuracy: 0.72 - ETA: 5s - loss: 0.9978 - accuracy: 0.72 - ETA: 4s - loss: 0.9975 - accuracy: 0.72 - ETA: 3s - loss: 0.9994 - accuracy: 0.72 - ETA: 2s - loss: 1.0038 - accuracy: 0.72 - ETA: 2s - loss: 1.0033 - accuracy: 0.72 - ETA: 1s - loss: 1.0019 - accuracy: 0.72 - ETA: 0s - loss: 1.0009 - accuracy: 0.72 - 121s 6ms/step - loss: 1.0008 - accuracy: 0.7283 - val_loss: 1.1041 - val_accuracy: 0.7223\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:37 - loss: 0.6258 - accuracy: 0.84 - ETA: 1:39 - loss: 0.5793 - accuracy: 0.86 - ETA: 1:42 - loss: 0.5561 - accuracy: 0.85 - ETA: 1:39 - loss: 0.5542 - accuracy: 0.84 - ETA: 1:38 - loss: 0.5252 - accuracy: 0.86 - ETA: 1:38 - loss: 0.5267 - accuracy: 0.86 - ETA: 1:38 - loss: 0.5522 - accuracy: 0.85 - ETA: 1:38 - loss: 0.5397 - accuracy: 0.85 - ETA: 1:38 - loss: 0.5458 - accuracy: 0.85 - ETA: 1:37 - loss: 0.5484 - accuracy: 0.84 - ETA: 1:36 - loss: 0.5591 - accuracy: 0.84 - ETA: 1:36 - loss: 0.5510 - accuracy: 0.84 - ETA: 1:35 - loss: 0.5544 - accuracy: 0.84 - ETA: 1:36 - loss: 0.5529 - accuracy: 0.84 - ETA: 1:36 - loss: 0.5540 - accuracy: 0.84 - ETA: 1:35 - loss: 0.5416 - accuracy: 0.85 - ETA: 1:35 - loss: 0.5395 - accuracy: 0.85 - ETA: 1:34 - loss: 0.5475 - accuracy: 0.84 - ETA: 1:33 - loss: 0.5477 - accuracy: 0.85 - ETA: 1:33 - loss: 0.5474 - accuracy: 0.85 - ETA: 1:32 - loss: 0.5434 - accuracy: 0.85 - ETA: 1:31 - loss: 0.5511 - accuracy: 0.85 - ETA: 1:31 - loss: 0.5486 - accuracy: 0.85 - ETA: 1:30 - loss: 0.5466 - accuracy: 0.85 - ETA: 1:30 - loss: 0.5499 - accuracy: 0.85 - ETA: 1:29 - loss: 0.5507 - accuracy: 0.84 - ETA: 1:28 - loss: 0.5501 - accuracy: 0.84 - ETA: 1:28 - loss: 0.5457 - accuracy: 0.84 - ETA: 1:27 - loss: 0.5438 - accuracy: 0.85 - ETA: 1:26 - loss: 0.5422 - accuracy: 0.85 - ETA: 1:25 - loss: 0.5523 - accuracy: 0.84 - ETA: 1:25 - loss: 0.5497 - accuracy: 0.84 - ETA: 1:24 - loss: 0.5482 - accuracy: 0.84 - ETA: 1:23 - loss: 0.5483 - accuracy: 0.84 - ETA: 1:22 - loss: 0.5507 - accuracy: 0.84 - ETA: 1:22 - loss: 0.5488 - accuracy: 0.84 - ETA: 1:21 - loss: 0.5486 - accuracy: 0.84 - ETA: 1:20 - loss: 0.5479 - accuracy: 0.84 - ETA: 1:20 - loss: 0.5454 - accuracy: 0.85 - ETA: 1:19 - loss: 0.5410 - accuracy: 0.85 - ETA: 1:18 - loss: 0.5385 - accuracy: 0.85 - ETA: 1:18 - loss: 0.5416 - accuracy: 0.85 - ETA: 1:17 - loss: 0.5410 - accuracy: 0.85 - ETA: 1:16 - loss: 0.5383 - accuracy: 0.85 - ETA: 1:15 - loss: 0.5388 - accuracy: 0.85 - ETA: 1:15 - loss: 0.5367 - accuracy: 0.85 - ETA: 1:14 - loss: 0.5375 - accuracy: 0.84 - ETA: 1:13 - loss: 0.5331 - accuracy: 0.85 - ETA: 1:12 - loss: 0.5328 - accuracy: 0.85 - ETA: 1:12 - loss: 0.5351 - accuracy: 0.85 - ETA: 1:11 - loss: 0.5354 - accuracy: 0.85 - ETA: 1:10 - loss: 0.5357 - accuracy: 0.85 - ETA: 1:10 - loss: 0.5358 - accuracy: 0.85 - ETA: 1:09 - loss: 0.5375 - accuracy: 0.85 - ETA: 1:08 - loss: 0.5361 - accuracy: 0.85 - ETA: 1:07 - loss: 0.5351 - accuracy: 0.85 - ETA: 1:07 - loss: 0.5354 - accuracy: 0.85 - ETA: 1:06 - loss: 0.5348 - accuracy: 0.85 - ETA: 1:05 - loss: 0.5342 - accuracy: 0.85 - ETA: 1:05 - loss: 0.5337 - accuracy: 0.85 - ETA: 1:04 - loss: 0.5330 - accuracy: 0.85 - ETA: 1:03 - loss: 0.5333 - accuracy: 0.85 - ETA: 1:03 - loss: 0.5351 - accuracy: 0.85 - ETA: 1:02 - loss: 0.5353 - accuracy: 0.85 - ETA: 1:01 - loss: 0.5358 - accuracy: 0.85 - ETA: 1:00 - loss: 0.5355 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5367 - accuracy: 0.84 - ETA: 59s - loss: 0.5381 - accuracy: 0.8495 - ETA: 58s - loss: 0.5383 - accuracy: 0.849 - ETA: 58s - loss: 0.5390 - accuracy: 0.848 - ETA: 57s - loss: 0.5391 - accuracy: 0.848 - ETA: 56s - loss: 0.5403 - accuracy: 0.848 - ETA: 55s - loss: 0.5406 - accuracy: 0.848 - ETA: 55s - loss: 0.5399 - accuracy: 0.848 - ETA: 54s - loss: 0.5402 - accuracy: 0.848 - ETA: 53s - loss: 0.5388 - accuracy: 0.849 - ETA: 52s - loss: 0.5393 - accuracy: 0.849 - ETA: 52s - loss: 0.5391 - accuracy: 0.849 - ETA: 51s - loss: 0.5384 - accuracy: 0.849 - ETA: 50s - loss: 0.5411 - accuracy: 0.848 - ETA: 50s - loss: 0.5401 - accuracy: 0.848 - ETA: 49s - loss: 0.5402 - accuracy: 0.848 - ETA: 48s - loss: 0.5396 - accuracy: 0.848 - ETA: 48s - loss: 0.5397 - accuracy: 0.848 - ETA: 47s - loss: 0.5390 - accuracy: 0.848 - ETA: 46s - loss: 0.5380 - accuracy: 0.848 - ETA: 45s - loss: 0.5383 - accuracy: 0.848 - ETA: 45s - loss: 0.5370 - accuracy: 0.849 - ETA: 44s - loss: 0.5360 - accuracy: 0.849 - ETA: 43s - loss: 0.5376 - accuracy: 0.848 - ETA: 43s - loss: 0.5371 - accuracy: 0.849 - ETA: 42s - loss: 0.5360 - accuracy: 0.849 - ETA: 41s - loss: 0.5362 - accuracy: 0.849 - ETA: 40s - loss: 0.5365 - accuracy: 0.849 - ETA: 40s - loss: 0.5382 - accuracy: 0.848 - ETA: 39s - loss: 0.5379 - accuracy: 0.848 - ETA: 38s - loss: 0.5402 - accuracy: 0.848 - ETA: 38s - loss: 0.5404 - accuracy: 0.848 - ETA: 37s - loss: 0.5397 - accuracy: 0.848 - ETA: 36s - loss: 0.5401 - accuracy: 0.847 - ETA: 35s - loss: 0.5409 - accuracy: 0.847 - ETA: 35s - loss: 0.5411 - accuracy: 0.847 - ETA: 34s - loss: 0.5427 - accuracy: 0.847 - ETA: 33s - loss: 0.5448 - accuracy: 0.846 - ETA: 33s - loss: 0.5462 - accuracy: 0.846 - ETA: 32s - loss: 0.5456 - accuracy: 0.846 - ETA: 31s - loss: 0.5462 - accuracy: 0.846 - ETA: 30s - loss: 0.5469 - accuracy: 0.846 - ETA: 30s - loss: 0.5481 - accuracy: 0.845 - ETA: 29s - loss: 0.5480 - accuracy: 0.845 - ETA: 28s - loss: 0.5477 - accuracy: 0.845 - ETA: 27s - loss: 0.5489 - accuracy: 0.845 - ETA: 27s - loss: 0.5488 - accuracy: 0.845 - ETA: 26s - loss: 0.5482 - accuracy: 0.845 - ETA: 25s - loss: 0.5492 - accuracy: 0.845 - ETA: 25s - loss: 0.5491 - accuracy: 0.845 - ETA: 24s - loss: 0.5500 - accuracy: 0.845 - ETA: 23s - loss: 0.5495 - accuracy: 0.845 - ETA: 22s - loss: 0.5483 - accuracy: 0.845 - ETA: 22s - loss: 0.5483 - accuracy: 0.845 - ETA: 21s - loss: 0.5489 - accuracy: 0.845 - ETA: 20s - loss: 0.5486 - accuracy: 0.845 - ETA: 20s - loss: 0.5487 - accuracy: 0.845 - ETA: 19s - loss: 0.5484 - accuracy: 0.845 - ETA: 18s - loss: 0.5490 - accuracy: 0.845 - ETA: 17s - loss: 0.5509 - accuracy: 0.844 - ETA: 17s - loss: 0.5501 - accuracy: 0.845 - ETA: 16s - loss: 0.5495 - accuracy: 0.845 - ETA: 15s - loss: 0.5504 - accuracy: 0.845 - ETA: 15s - loss: 0.5498 - accuracy: 0.845 - ETA: 14s - loss: 0.5506 - accuracy: 0.845 - ETA: 13s - loss: 0.5502 - accuracy: 0.845 - ETA: 12s - loss: 0.5491 - accuracy: 0.845 - ETA: 12s - loss: 0.5474 - accuracy: 0.846 - ETA: 11s - loss: 0.5469 - accuracy: 0.846 - ETA: 10s - loss: 0.5466 - accuracy: 0.846 - ETA: 9s - loss: 0.5464 - accuracy: 0.846 - ETA: 9s - loss: 0.5468 - accuracy: 0.84 - ETA: 8s - loss: 0.5468 - accuracy: 0.84 - ETA: 7s - loss: 0.5469 - accuracy: 0.84 - ETA: 7s - loss: 0.5469 - accuracy: 0.84 - ETA: 6s - loss: 0.5474 - accuracy: 0.84 - ETA: 5s - loss: 0.5474 - accuracy: 0.84 - ETA: 4s - loss: 0.5487 - accuracy: 0.84 - ETA: 4s - loss: 0.5483 - accuracy: 0.84 - ETA: 3s - loss: 0.5488 - accuracy: 0.84 - ETA: 2s - loss: 0.5486 - accuracy: 0.84 - ETA: 2s - loss: 0.5485 - accuracy: 0.84 - ETA: 1s - loss: 0.5481 - accuracy: 0.84 - ETA: 0s - loss: 0.5470 - accuracy: 0.84 - 119s 6ms/step - loss: 0.5472 - accuracy: 0.8458 - val_loss: 0.9835 - val_accuracy: 0.7563\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:51 - loss: 0.3182 - accuracy: 0.89 - ETA: 1:46 - loss: 0.2656 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2709 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2771 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2799 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2879 - accuracy: 0.90 - ETA: 1:41 - loss: 0.2814 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2868 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2906 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2921 - accuracy: 0.91 - ETA: 1:38 - loss: 0.3008 - accuracy: 0.90 - ETA: 1:38 - loss: 0.3072 - accuracy: 0.90 - ETA: 1:37 - loss: 0.3156 - accuracy: 0.90 - ETA: 1:36 - loss: 0.3168 - accuracy: 0.90 - ETA: 1:36 - loss: 0.3159 - accuracy: 0.90 - ETA: 1:35 - loss: 0.3113 - accuracy: 0.90 - ETA: 1:34 - loss: 0.3050 - accuracy: 0.90 - ETA: 1:33 - loss: 0.3080 - accuracy: 0.90 - ETA: 1:32 - loss: 0.3112 - accuracy: 0.91 - ETA: 1:32 - loss: 0.3097 - accuracy: 0.91 - ETA: 1:31 - loss: 0.3062 - accuracy: 0.91 - ETA: 1:31 - loss: 0.3046 - accuracy: 0.91 - ETA: 1:31 - loss: 0.3040 - accuracy: 0.91 - ETA: 1:30 - loss: 0.3052 - accuracy: 0.91 - ETA: 1:29 - loss: 0.3077 - accuracy: 0.91 - ETA: 1:28 - loss: 0.3106 - accuracy: 0.90 - ETA: 1:28 - loss: 0.3195 - accuracy: 0.90 - ETA: 1:27 - loss: 0.3223 - accuracy: 0.90 - ETA: 1:26 - loss: 0.3274 - accuracy: 0.90 - ETA: 1:25 - loss: 0.3282 - accuracy: 0.90 - ETA: 1:25 - loss: 0.3293 - accuracy: 0.90 - ETA: 1:24 - loss: 0.3263 - accuracy: 0.90 - ETA: 1:23 - loss: 0.3264 - accuracy: 0.90 - ETA: 1:22 - loss: 0.3293 - accuracy: 0.90 - ETA: 1:22 - loss: 0.3246 - accuracy: 0.90 - ETA: 1:21 - loss: 0.3240 - accuracy: 0.90 - ETA: 1:20 - loss: 0.3216 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3191 - accuracy: 0.90 - ETA: 1:19 - loss: 0.3197 - accuracy: 0.90 - ETA: 1:18 - loss: 0.3203 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3193 - accuracy: 0.90 - ETA: 1:17 - loss: 0.3205 - accuracy: 0.90 - ETA: 1:16 - loss: 0.3197 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3210 - accuracy: 0.90 - ETA: 1:15 - loss: 0.3207 - accuracy: 0.90 - ETA: 1:14 - loss: 0.3184 - accuracy: 0.91 - ETA: 1:13 - loss: 0.3168 - accuracy: 0.91 - ETA: 1:13 - loss: 0.3187 - accuracy: 0.90 - ETA: 1:12 - loss: 0.3167 - accuracy: 0.91 - ETA: 1:12 - loss: 0.3156 - accuracy: 0.91 - ETA: 1:11 - loss: 0.3146 - accuracy: 0.91 - ETA: 1:11 - loss: 0.3130 - accuracy: 0.91 - ETA: 1:10 - loss: 0.3129 - accuracy: 0.91 - ETA: 1:09 - loss: 0.3135 - accuracy: 0.91 - ETA: 1:08 - loss: 0.3128 - accuracy: 0.91 - ETA: 1:08 - loss: 0.3125 - accuracy: 0.91 - ETA: 1:07 - loss: 0.3128 - accuracy: 0.90 - ETA: 1:06 - loss: 0.3134 - accuracy: 0.90 - ETA: 1:05 - loss: 0.3134 - accuracy: 0.90 - ETA: 1:05 - loss: 0.3133 - accuracy: 0.90 - ETA: 1:04 - loss: 0.3135 - accuracy: 0.90 - ETA: 1:03 - loss: 0.3129 - accuracy: 0.90 - ETA: 1:02 - loss: 0.3118 - accuracy: 0.91 - ETA: 1:02 - loss: 0.3101 - accuracy: 0.91 - ETA: 1:01 - loss: 0.3104 - accuracy: 0.91 - ETA: 1:00 - loss: 0.3130 - accuracy: 0.90 - ETA: 1:00 - loss: 0.3113 - accuracy: 0.91 - ETA: 59s - loss: 0.3101 - accuracy: 0.9100 - ETA: 58s - loss: 0.3121 - accuracy: 0.909 - ETA: 58s - loss: 0.3125 - accuracy: 0.908 - ETA: 57s - loss: 0.3131 - accuracy: 0.908 - ETA: 56s - loss: 0.3121 - accuracy: 0.909 - ETA: 55s - loss: 0.3136 - accuracy: 0.908 - ETA: 55s - loss: 0.3118 - accuracy: 0.909 - ETA: 54s - loss: 0.3123 - accuracy: 0.909 - ETA: 53s - loss: 0.3108 - accuracy: 0.909 - ETA: 52s - loss: 0.3102 - accuracy: 0.910 - ETA: 52s - loss: 0.3102 - accuracy: 0.910 - ETA: 51s - loss: 0.3108 - accuracy: 0.910 - ETA: 50s - loss: 0.3100 - accuracy: 0.910 - ETA: 50s - loss: 0.3103 - accuracy: 0.910 - ETA: 49s - loss: 0.3100 - accuracy: 0.910 - ETA: 48s - loss: 0.3109 - accuracy: 0.910 - ETA: 47s - loss: 0.3104 - accuracy: 0.910 - ETA: 47s - loss: 0.3088 - accuracy: 0.911 - ETA: 46s - loss: 0.3093 - accuracy: 0.911 - ETA: 45s - loss: 0.3106 - accuracy: 0.910 - ETA: 45s - loss: 0.3104 - accuracy: 0.910 - ETA: 44s - loss: 0.3110 - accuracy: 0.910 - ETA: 43s - loss: 0.3113 - accuracy: 0.910 - ETA: 42s - loss: 0.3120 - accuracy: 0.910 - ETA: 42s - loss: 0.3120 - accuracy: 0.910 - ETA: 41s - loss: 0.3114 - accuracy: 0.910 - ETA: 40s - loss: 0.3122 - accuracy: 0.910 - ETA: 40s - loss: 0.3119 - accuracy: 0.910 - ETA: 39s - loss: 0.3112 - accuracy: 0.910 - ETA: 38s - loss: 0.3106 - accuracy: 0.910 - ETA: 38s - loss: 0.3096 - accuracy: 0.911 - ETA: 37s - loss: 0.3104 - accuracy: 0.911 - ETA: 36s - loss: 0.3106 - accuracy: 0.911 - ETA: 35s - loss: 0.3111 - accuracy: 0.911 - ETA: 35s - loss: 0.3106 - accuracy: 0.911 - ETA: 34s - loss: 0.3115 - accuracy: 0.910 - ETA: 33s - loss: 0.3129 - accuracy: 0.910 - ETA: 33s - loss: 0.3122 - accuracy: 0.910 - ETA: 32s - loss: 0.3115 - accuracy: 0.910 - ETA: 31s - loss: 0.3115 - accuracy: 0.910 - ETA: 30s - loss: 0.3118 - accuracy: 0.910 - ETA: 30s - loss: 0.3121 - accuracy: 0.910 - ETA: 29s - loss: 0.3125 - accuracy: 0.910 - ETA: 28s - loss: 0.3131 - accuracy: 0.910 - ETA: 28s - loss: 0.3127 - accuracy: 0.910 - ETA: 27s - loss: 0.3123 - accuracy: 0.911 - ETA: 26s - loss: 0.3119 - accuracy: 0.911 - ETA: 25s - loss: 0.3117 - accuracy: 0.911 - ETA: 25s - loss: 0.3122 - accuracy: 0.911 - ETA: 24s - loss: 0.3127 - accuracy: 0.910 - ETA: 23s - loss: 0.3144 - accuracy: 0.910 - ETA: 22s - loss: 0.3140 - accuracy: 0.910 - ETA: 22s - loss: 0.3143 - accuracy: 0.910 - ETA: 21s - loss: 0.3142 - accuracy: 0.910 - ETA: 20s - loss: 0.3157 - accuracy: 0.910 - ETA: 20s - loss: 0.3154 - accuracy: 0.910 - ETA: 19s - loss: 0.3162 - accuracy: 0.909 - ETA: 18s - loss: 0.3162 - accuracy: 0.909 - ETA: 17s - loss: 0.3159 - accuracy: 0.909 - ETA: 17s - loss: 0.3173 - accuracy: 0.909 - ETA: 16s - loss: 0.3183 - accuracy: 0.909 - ETA: 15s - loss: 0.3182 - accuracy: 0.909 - ETA: 15s - loss: 0.3181 - accuracy: 0.909 - ETA: 14s - loss: 0.3178 - accuracy: 0.909 - ETA: 13s - loss: 0.3187 - accuracy: 0.909 - ETA: 12s - loss: 0.3190 - accuracy: 0.908 - ETA: 12s - loss: 0.3193 - accuracy: 0.908 - ETA: 11s - loss: 0.3201 - accuracy: 0.908 - ETA: 10s - loss: 0.3203 - accuracy: 0.908 - ETA: 10s - loss: 0.3208 - accuracy: 0.908 - ETA: 9s - loss: 0.3207 - accuracy: 0.908 - ETA: 8s - loss: 0.3208 - accuracy: 0.90 - ETA: 7s - loss: 0.3203 - accuracy: 0.90 - ETA: 7s - loss: 0.3201 - accuracy: 0.90 - ETA: 6s - loss: 0.3208 - accuracy: 0.90 - ETA: 5s - loss: 0.3203 - accuracy: 0.90 - ETA: 4s - loss: 0.3207 - accuracy: 0.90 - ETA: 4s - loss: 0.3203 - accuracy: 0.90 - ETA: 3s - loss: 0.3202 - accuracy: 0.90 - ETA: 2s - loss: 0.3203 - accuracy: 0.90 - ETA: 2s - loss: 0.3200 - accuracy: 0.90 - ETA: 1s - loss: 0.3203 - accuracy: 0.90 - ETA: 0s - loss: 0.3203 - accuracy: 0.90 - 120s 6ms/step - loss: 0.3210 - accuracy: 0.9071 - val_loss: 0.9327 - val_accuracy: 0.7755\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:38 - loss: 0.2382 - accuracy: 0.92 - ETA: 1:38 - loss: 0.2104 - accuracy: 0.94 - ETA: 1:40 - loss: 0.1754 - accuracy: 0.95 - ETA: 1:40 - loss: 0.1640 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1761 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1904 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1947 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1935 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1959 - accuracy: 0.94 - ETA: 1:38 - loss: 0.1927 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1926 - accuracy: 0.94 - ETA: 1:37 - loss: 0.1966 - accuracy: 0.94 - ETA: 1:36 - loss: 0.1942 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1959 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1959 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1913 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1919 - accuracy: 0.95 - ETA: 1:33 - loss: 0.1919 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1900 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1907 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1926 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1928 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1916 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1895 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1918 - accuracy: 0.95 - ETA: 1:29 - loss: 0.1936 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1955 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1925 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1903 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1923 - accuracy: 0.95 - ETA: 1:26 - loss: 0.1930 - accuracy: 0.95 - ETA: 1:26 - loss: 0.1937 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1966 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1982 - accuracy: 0.95 - ETA: 1:23 - loss: 0.2002 - accuracy: 0.94 - ETA: 1:23 - loss: 0.2018 - accuracy: 0.94 - ETA: 1:22 - loss: 0.2024 - accuracy: 0.94 - ETA: 1:21 - loss: 0.2041 - accuracy: 0.94 - ETA: 1:21 - loss: 0.2036 - accuracy: 0.94 - ETA: 1:20 - loss: 0.2028 - accuracy: 0.94 - ETA: 1:19 - loss: 0.2023 - accuracy: 0.94 - ETA: 1:18 - loss: 0.2010 - accuracy: 0.94 - ETA: 1:17 - loss: 0.2033 - accuracy: 0.94 - ETA: 1:17 - loss: 0.2016 - accuracy: 0.94 - ETA: 1:16 - loss: 0.2006 - accuracy: 0.94 - ETA: 1:15 - loss: 0.2009 - accuracy: 0.94 - ETA: 1:14 - loss: 0.2020 - accuracy: 0.94 - ETA: 1:14 - loss: 0.2008 - accuracy: 0.94 - ETA: 1:13 - loss: 0.2012 - accuracy: 0.94 - ETA: 1:12 - loss: 0.2003 - accuracy: 0.94 - ETA: 1:12 - loss: 0.1991 - accuracy: 0.94 - ETA: 1:11 - loss: 0.1978 - accuracy: 0.94 - ETA: 1:10 - loss: 0.1983 - accuracy: 0.94 - ETA: 1:10 - loss: 0.1977 - accuracy: 0.94 - ETA: 1:09 - loss: 0.1980 - accuracy: 0.94 - ETA: 1:08 - loss: 0.1972 - accuracy: 0.94 - ETA: 1:07 - loss: 0.1984 - accuracy: 0.94 - ETA: 1:07 - loss: 0.1982 - accuracy: 0.94 - ETA: 1:06 - loss: 0.1974 - accuracy: 0.94 - ETA: 1:05 - loss: 0.1972 - accuracy: 0.94 - ETA: 1:04 - loss: 0.1989 - accuracy: 0.94 - ETA: 1:04 - loss: 0.1984 - accuracy: 0.94 - ETA: 1:03 - loss: 0.1978 - accuracy: 0.94 - ETA: 1:02 - loss: 0.1982 - accuracy: 0.94 - ETA: 1:01 - loss: 0.1973 - accuracy: 0.94 - ETA: 1:01 - loss: 0.1974 - accuracy: 0.94 - ETA: 1:00 - loss: 0.1976 - accuracy: 0.94 - ETA: 59s - loss: 0.1975 - accuracy: 0.9496 - ETA: 58s - loss: 0.1969 - accuracy: 0.949 - ETA: 58s - loss: 0.1956 - accuracy: 0.949 - ETA: 57s - loss: 0.1968 - accuracy: 0.950 - ETA: 56s - loss: 0.1965 - accuracy: 0.949 - ETA: 56s - loss: 0.1975 - accuracy: 0.949 - ETA: 55s - loss: 0.1972 - accuracy: 0.949 - ETA: 54s - loss: 0.1965 - accuracy: 0.949 - ETA: 53s - loss: 0.1966 - accuracy: 0.949 - ETA: 53s - loss: 0.1966 - accuracy: 0.949 - ETA: 52s - loss: 0.1964 - accuracy: 0.949 - ETA: 51s - loss: 0.1974 - accuracy: 0.949 - ETA: 51s - loss: 0.1965 - accuracy: 0.949 - ETA: 50s - loss: 0.1972 - accuracy: 0.949 - ETA: 49s - loss: 0.1973 - accuracy: 0.949 - ETA: 48s - loss: 0.1985 - accuracy: 0.948 - ETA: 48s - loss: 0.1972 - accuracy: 0.949 - ETA: 47s - loss: 0.1966 - accuracy: 0.949 - ETA: 46s - loss: 0.1969 - accuracy: 0.948 - ETA: 45s - loss: 0.1962 - accuracy: 0.949 - ETA: 45s - loss: 0.1950 - accuracy: 0.949 - ETA: 44s - loss: 0.1953 - accuracy: 0.949 - ETA: 43s - loss: 0.1946 - accuracy: 0.949 - ETA: 42s - loss: 0.1949 - accuracy: 0.949 - ETA: 42s - loss: 0.1954 - accuracy: 0.949 - ETA: 41s - loss: 0.1952 - accuracy: 0.949 - ETA: 40s - loss: 0.1946 - accuracy: 0.949 - ETA: 40s - loss: 0.1945 - accuracy: 0.949 - ETA: 39s - loss: 0.1950 - accuracy: 0.948 - ETA: 38s - loss: 0.1954 - accuracy: 0.948 - ETA: 38s - loss: 0.1956 - accuracy: 0.948 - ETA: 37s - loss: 0.1958 - accuracy: 0.948 - ETA: 36s - loss: 0.1958 - accuracy: 0.948 - ETA: 35s - loss: 0.1972 - accuracy: 0.947 - ETA: 35s - loss: 0.1973 - accuracy: 0.947 - ETA: 34s - loss: 0.1969 - accuracy: 0.947 - ETA: 33s - loss: 0.1960 - accuracy: 0.948 - ETA: 33s - loss: 0.1970 - accuracy: 0.947 - ETA: 32s - loss: 0.1971 - accuracy: 0.947 - ETA: 31s - loss: 0.1968 - accuracy: 0.948 - ETA: 30s - loss: 0.1962 - accuracy: 0.948 - ETA: 30s - loss: 0.1964 - accuracy: 0.948 - ETA: 29s - loss: 0.1956 - accuracy: 0.948 - ETA: 28s - loss: 0.1961 - accuracy: 0.948 - ETA: 28s - loss: 0.1955 - accuracy: 0.948 - ETA: 27s - loss: 0.1951 - accuracy: 0.948 - ETA: 26s - loss: 0.1950 - accuracy: 0.948 - ETA: 25s - loss: 0.1954 - accuracy: 0.948 - ETA: 25s - loss: 0.1948 - accuracy: 0.948 - ETA: 24s - loss: 0.1948 - accuracy: 0.948 - ETA: 23s - loss: 0.1945 - accuracy: 0.949 - ETA: 23s - loss: 0.1941 - accuracy: 0.949 - ETA: 22s - loss: 0.1941 - accuracy: 0.949 - ETA: 21s - loss: 0.1935 - accuracy: 0.949 - ETA: 20s - loss: 0.1932 - accuracy: 0.949 - ETA: 20s - loss: 0.1940 - accuracy: 0.949 - ETA: 19s - loss: 0.1941 - accuracy: 0.949 - ETA: 18s - loss: 0.1949 - accuracy: 0.949 - ETA: 17s - loss: 0.1944 - accuracy: 0.949 - ETA: 17s - loss: 0.1956 - accuracy: 0.948 - ETA: 16s - loss: 0.1955 - accuracy: 0.948 - ETA: 15s - loss: 0.1961 - accuracy: 0.948 - ETA: 15s - loss: 0.1957 - accuracy: 0.948 - ETA: 14s - loss: 0.1957 - accuracy: 0.948 - ETA: 13s - loss: 0.1957 - accuracy: 0.948 - ETA: 12s - loss: 0.1953 - accuracy: 0.948 - ETA: 12s - loss: 0.1955 - accuracy: 0.948 - ETA: 11s - loss: 0.1947 - accuracy: 0.948 - ETA: 10s - loss: 0.1947 - accuracy: 0.948 - ETA: 10s - loss: 0.1954 - accuracy: 0.948 - ETA: 9s - loss: 0.1954 - accuracy: 0.948 - ETA: 8s - loss: 0.1949 - accuracy: 0.94 - ETA: 7s - loss: 0.1952 - accuracy: 0.94 - ETA: 7s - loss: 0.1956 - accuracy: 0.94 - ETA: 6s - loss: 0.1957 - accuracy: 0.94 - ETA: 5s - loss: 0.1955 - accuracy: 0.94 - ETA: 4s - loss: 0.1947 - accuracy: 0.94 - ETA: 4s - loss: 0.1946 - accuracy: 0.94 - ETA: 3s - loss: 0.1945 - accuracy: 0.94 - ETA: 2s - loss: 0.1941 - accuracy: 0.94 - ETA: 2s - loss: 0.1947 - accuracy: 0.94 - ETA: 1s - loss: 0.1946 - accuracy: 0.94 - ETA: 0s - loss: 0.1941 - accuracy: 0.94 - 120s 6ms/step - loss: 0.1944 - accuracy: 0.9488 - val_loss: 0.9285 - val_accuracy: 0.7757\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:47 - loss: 0.1117 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1116 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1450 - accuracy: 0.95 - ETA: 1:40 - loss: 0.1526 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1425 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1361 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1317 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1327 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1318 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1329 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1299 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1264 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1284 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1271 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1307 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1286 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1311 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1316 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1334 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1348 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1356 - accuracy: 0.96 - ETA: 1:32 - loss: 0.1354 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1367 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1347 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1331 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1329 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1320 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1307 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1292 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1310 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1294 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1301 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1308 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1306 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1300 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1284 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1268 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1269 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1267 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1268 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1257 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1262 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1250 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1256 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1248 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1245 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1244 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1255 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1250 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1249 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1232 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1238 - accuracy: 0.96 - ETA: 1:10 - loss: 0.1247 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1249 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1254 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1252 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1251 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1249 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1240 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1241 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1236 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1234 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1247 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1266 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1266 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1268 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1267 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1259 - accuracy: 0.96 - ETA: 59s - loss: 0.1269 - accuracy: 0.9680 - ETA: 58s - loss: 0.1269 - accuracy: 0.968 - ETA: 58s - loss: 0.1264 - accuracy: 0.967 - ETA: 57s - loss: 0.1261 - accuracy: 0.968 - ETA: 56s - loss: 0.1263 - accuracy: 0.968 - ETA: 55s - loss: 0.1259 - accuracy: 0.968 - ETA: 55s - loss: 0.1254 - accuracy: 0.968 - ETA: 54s - loss: 0.1248 - accuracy: 0.968 - ETA: 53s - loss: 0.1254 - accuracy: 0.968 - ETA: 53s - loss: 0.1255 - accuracy: 0.968 - ETA: 52s - loss: 0.1259 - accuracy: 0.968 - ETA: 51s - loss: 0.1254 - accuracy: 0.968 - ETA: 50s - loss: 0.1253 - accuracy: 0.968 - ETA: 50s - loss: 0.1250 - accuracy: 0.968 - ETA: 49s - loss: 0.1254 - accuracy: 0.968 - ETA: 48s - loss: 0.1252 - accuracy: 0.968 - ETA: 47s - loss: 0.1245 - accuracy: 0.968 - ETA: 47s - loss: 0.1243 - accuracy: 0.969 - ETA: 46s - loss: 0.1244 - accuracy: 0.968 - ETA: 45s - loss: 0.1243 - accuracy: 0.969 - ETA: 45s - loss: 0.1239 - accuracy: 0.969 - ETA: 44s - loss: 0.1243 - accuracy: 0.969 - ETA: 43s - loss: 0.1239 - accuracy: 0.969 - ETA: 42s - loss: 0.1242 - accuracy: 0.969 - ETA: 42s - loss: 0.1244 - accuracy: 0.968 - ETA: 41s - loss: 0.1244 - accuracy: 0.969 - ETA: 40s - loss: 0.1240 - accuracy: 0.969 - ETA: 39s - loss: 0.1244 - accuracy: 0.968 - ETA: 39s - loss: 0.1242 - accuracy: 0.969 - ETA: 38s - loss: 0.1243 - accuracy: 0.968 - ETA: 37s - loss: 0.1245 - accuracy: 0.969 - ETA: 36s - loss: 0.1245 - accuracy: 0.968 - ETA: 36s - loss: 0.1250 - accuracy: 0.968 - ETA: 35s - loss: 0.1260 - accuracy: 0.968 - ETA: 34s - loss: 0.1273 - accuracy: 0.968 - ETA: 34s - loss: 0.1273 - accuracy: 0.967 - ETA: 33s - loss: 0.1276 - accuracy: 0.967 - ETA: 32s - loss: 0.1273 - accuracy: 0.967 - ETA: 31s - loss: 0.1271 - accuracy: 0.968 - ETA: 31s - loss: 0.1278 - accuracy: 0.967 - ETA: 30s - loss: 0.1285 - accuracy: 0.967 - ETA: 29s - loss: 0.1285 - accuracy: 0.967 - ETA: 29s - loss: 0.1280 - accuracy: 0.968 - ETA: 28s - loss: 0.1281 - accuracy: 0.967 - ETA: 27s - loss: 0.1285 - accuracy: 0.967 - ETA: 26s - loss: 0.1287 - accuracy: 0.967 - ETA: 26s - loss: 0.1288 - accuracy: 0.967 - ETA: 25s - loss: 0.1289 - accuracy: 0.967 - ETA: 24s - loss: 0.1286 - accuracy: 0.967 - ETA: 23s - loss: 0.1288 - accuracy: 0.967 - ETA: 23s - loss: 0.1286 - accuracy: 0.967 - ETA: 22s - loss: 0.1283 - accuracy: 0.967 - ETA: 21s - loss: 0.1284 - accuracy: 0.967 - ETA: 21s - loss: 0.1286 - accuracy: 0.967 - ETA: 20s - loss: 0.1288 - accuracy: 0.967 - ETA: 19s - loss: 0.1287 - accuracy: 0.967 - ETA: 18s - loss: 0.1286 - accuracy: 0.967 - ETA: 18s - loss: 0.1290 - accuracy: 0.967 - ETA: 17s - loss: 0.1300 - accuracy: 0.967 - ETA: 16s - loss: 0.1302 - accuracy: 0.966 - ETA: 15s - loss: 0.1303 - accuracy: 0.966 - ETA: 15s - loss: 0.1305 - accuracy: 0.966 - ETA: 14s - loss: 0.1303 - accuracy: 0.966 - ETA: 13s - loss: 0.1306 - accuracy: 0.966 - ETA: 13s - loss: 0.1301 - accuracy: 0.966 - ETA: 12s - loss: 0.1300 - accuracy: 0.966 - ETA: 11s - loss: 0.1300 - accuracy: 0.966 - ETA: 10s - loss: 0.1303 - accuracy: 0.966 - ETA: 10s - loss: 0.1304 - accuracy: 0.966 - ETA: 9s - loss: 0.1300 - accuracy: 0.966 - ETA: 8s - loss: 0.1300 - accuracy: 0.96 - ETA: 7s - loss: 0.1298 - accuracy: 0.96 - ETA: 7s - loss: 0.1298 - accuracy: 0.96 - ETA: 6s - loss: 0.1297 - accuracy: 0.96 - ETA: 5s - loss: 0.1298 - accuracy: 0.96 - ETA: 5s - loss: 0.1296 - accuracy: 0.96 - ETA: 4s - loss: 0.1292 - accuracy: 0.96 - ETA: 3s - loss: 0.1294 - accuracy: 0.96 - ETA: 2s - loss: 0.1294 - accuracy: 0.96 - ETA: 2s - loss: 0.1294 - accuracy: 0.96 - ETA: 1s - loss: 0.1293 - accuracy: 0.96 - ETA: 0s - loss: 0.1299 - accuracy: 0.96 - 121s 6ms/step - loss: 0.1300 - accuracy: 0.9665 - val_loss: 0.9283 - val_accuracy: 0.7844\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:45 - loss: 0.0538 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0601 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0564 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0638 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0677 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0671 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0717 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0750 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0721 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0815 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0876 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0855 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0853 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0871 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0860 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0851 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0837 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0862 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0851 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0870 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0875 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0882 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0881 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0872 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0877 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0871 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0887 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0870 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0864 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0868 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0859 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0883 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0880 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0889 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0888 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0899 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0896 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0887 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0877 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0888 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0893 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0896 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0892 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0895 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0899 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0901 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0897 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0897 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0894 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0906 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0902 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0901 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0906 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0899 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0897 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0899 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0895 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0892 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0888 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0888 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0884 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0890 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0883 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0879 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0887 - accuracy: 0.97 - ETA: 59s - loss: 0.0892 - accuracy: 0.9787 - ETA: 58s - loss: 0.0891 - accuracy: 0.978 - ETA: 58s - loss: 0.0901 - accuracy: 0.978 - ETA: 57s - loss: 0.0899 - accuracy: 0.978 - ETA: 56s - loss: 0.0901 - accuracy: 0.978 - ETA: 55s - loss: 0.0900 - accuracy: 0.978 - ETA: 55s - loss: 0.0904 - accuracy: 0.978 - ETA: 54s - loss: 0.0903 - accuracy: 0.978 - ETA: 53s - loss: 0.0898 - accuracy: 0.978 - ETA: 52s - loss: 0.0905 - accuracy: 0.978 - ETA: 52s - loss: 0.0906 - accuracy: 0.978 - ETA: 51s - loss: 0.0905 - accuracy: 0.978 - ETA: 50s - loss: 0.0908 - accuracy: 0.978 - ETA: 50s - loss: 0.0906 - accuracy: 0.978 - ETA: 49s - loss: 0.0904 - accuracy: 0.978 - ETA: 48s - loss: 0.0902 - accuracy: 0.978 - ETA: 47s - loss: 0.0902 - accuracy: 0.978 - ETA: 47s - loss: 0.0903 - accuracy: 0.978 - ETA: 46s - loss: 0.0911 - accuracy: 0.978 - ETA: 45s - loss: 0.0909 - accuracy: 0.978 - ETA: 44s - loss: 0.0906 - accuracy: 0.978 - ETA: 44s - loss: 0.0908 - accuracy: 0.978 - ETA: 43s - loss: 0.0906 - accuracy: 0.978 - ETA: 42s - loss: 0.0907 - accuracy: 0.978 - ETA: 42s - loss: 0.0910 - accuracy: 0.977 - ETA: 41s - loss: 0.0907 - accuracy: 0.977 - ETA: 40s - loss: 0.0904 - accuracy: 0.978 - ETA: 39s - loss: 0.0904 - accuracy: 0.977 - ETA: 39s - loss: 0.0906 - accuracy: 0.977 - ETA: 38s - loss: 0.0905 - accuracy: 0.977 - ETA: 37s - loss: 0.0909 - accuracy: 0.977 - ETA: 36s - loss: 0.0909 - accuracy: 0.977 - ETA: 36s - loss: 0.0915 - accuracy: 0.977 - ETA: 35s - loss: 0.0914 - accuracy: 0.977 - ETA: 34s - loss: 0.0916 - accuracy: 0.977 - ETA: 34s - loss: 0.0920 - accuracy: 0.977 - ETA: 33s - loss: 0.0920 - accuracy: 0.977 - ETA: 32s - loss: 0.0923 - accuracy: 0.977 - ETA: 31s - loss: 0.0930 - accuracy: 0.976 - ETA: 31s - loss: 0.0935 - accuracy: 0.976 - ETA: 30s - loss: 0.0933 - accuracy: 0.976 - ETA: 29s - loss: 0.0936 - accuracy: 0.976 - ETA: 28s - loss: 0.0932 - accuracy: 0.976 - ETA: 28s - loss: 0.0930 - accuracy: 0.976 - ETA: 27s - loss: 0.0927 - accuracy: 0.977 - ETA: 26s - loss: 0.0928 - accuracy: 0.977 - ETA: 26s - loss: 0.0930 - accuracy: 0.976 - ETA: 25s - loss: 0.0931 - accuracy: 0.976 - ETA: 24s - loss: 0.0930 - accuracy: 0.977 - ETA: 23s - loss: 0.0930 - accuracy: 0.977 - ETA: 23s - loss: 0.0935 - accuracy: 0.976 - ETA: 22s - loss: 0.0941 - accuracy: 0.976 - ETA: 21s - loss: 0.0943 - accuracy: 0.976 - ETA: 20s - loss: 0.0940 - accuracy: 0.976 - ETA: 20s - loss: 0.0942 - accuracy: 0.976 - ETA: 19s - loss: 0.0945 - accuracy: 0.976 - ETA: 18s - loss: 0.0947 - accuracy: 0.976 - ETA: 18s - loss: 0.0946 - accuracy: 0.976 - ETA: 17s - loss: 0.0945 - accuracy: 0.976 - ETA: 16s - loss: 0.0954 - accuracy: 0.976 - ETA: 15s - loss: 0.0952 - accuracy: 0.976 - ETA: 15s - loss: 0.0950 - accuracy: 0.976 - ETA: 14s - loss: 0.0948 - accuracy: 0.976 - ETA: 13s - loss: 0.0947 - accuracy: 0.976 - ETA: 12s - loss: 0.0948 - accuracy: 0.976 - ETA: 12s - loss: 0.0949 - accuracy: 0.976 - ETA: 11s - loss: 0.0949 - accuracy: 0.976 - ETA: 10s - loss: 0.0948 - accuracy: 0.976 - ETA: 10s - loss: 0.0952 - accuracy: 0.976 - ETA: 9s - loss: 0.0953 - accuracy: 0.976 - ETA: 8s - loss: 0.0959 - accuracy: 0.97 - ETA: 7s - loss: 0.0959 - accuracy: 0.97 - ETA: 7s - loss: 0.0962 - accuracy: 0.97 - ETA: 6s - loss: 0.0961 - accuracy: 0.97 - ETA: 5s - loss: 0.0961 - accuracy: 0.97 - ETA: 5s - loss: 0.0959 - accuracy: 0.97 - ETA: 4s - loss: 0.0960 - accuracy: 0.97 - ETA: 3s - loss: 0.0960 - accuracy: 0.97 - ETA: 2s - loss: 0.0956 - accuracy: 0.97 - ETA: 2s - loss: 0.0956 - accuracy: 0.97 - ETA: 1s - loss: 0.0960 - accuracy: 0.97 - ETA: 0s - loss: 0.0962 - accuracy: 0.97 - 121s 6ms/step - loss: 0.0964 - accuracy: 0.9762 - val_loss: 0.9149 - val_accuracy: 0.7882\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:47 - loss: 0.1015 - accuracy: 0.96 - ETA: 1:46 - loss: 0.0910 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0749 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0729 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0682 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0729 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0725 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0719 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0693 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0717 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0736 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0719 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0717 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0713 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0736 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0715 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0711 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0711 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0698 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0695 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0683 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0671 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0658 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0658 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0659 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0686 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0678 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0671 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0675 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0675 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0671 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0666 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0660 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0666 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0669 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0675 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0682 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0689 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0695 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0699 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0704 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0705 - accuracy: 0.98 - ETA: 59s - loss: 0.0705 - accuracy: 0.9836 - ETA: 59s - loss: 0.0707 - accuracy: 0.983 - ETA: 58s - loss: 0.0709 - accuracy: 0.983 - ETA: 57s - loss: 0.0708 - accuracy: 0.983 - ETA: 56s - loss: 0.0705 - accuracy: 0.983 - ETA: 56s - loss: 0.0702 - accuracy: 0.983 - ETA: 55s - loss: 0.0698 - accuracy: 0.983 - ETA: 54s - loss: 0.0698 - accuracy: 0.983 - ETA: 53s - loss: 0.0695 - accuracy: 0.983 - ETA: 53s - loss: 0.0693 - accuracy: 0.983 - ETA: 52s - loss: 0.0696 - accuracy: 0.983 - ETA: 51s - loss: 0.0697 - accuracy: 0.983 - ETA: 51s - loss: 0.0705 - accuracy: 0.983 - ETA: 50s - loss: 0.0706 - accuracy: 0.983 - ETA: 49s - loss: 0.0708 - accuracy: 0.983 - ETA: 48s - loss: 0.0708 - accuracy: 0.983 - ETA: 48s - loss: 0.0714 - accuracy: 0.983 - ETA: 47s - loss: 0.0710 - accuracy: 0.983 - ETA: 46s - loss: 0.0706 - accuracy: 0.983 - ETA: 45s - loss: 0.0702 - accuracy: 0.983 - ETA: 45s - loss: 0.0699 - accuracy: 0.983 - ETA: 44s - loss: 0.0695 - accuracy: 0.984 - ETA: 43s - loss: 0.0697 - accuracy: 0.984 - ETA: 43s - loss: 0.0698 - accuracy: 0.984 - ETA: 42s - loss: 0.0696 - accuracy: 0.984 - ETA: 41s - loss: 0.0691 - accuracy: 0.984 - ETA: 40s - loss: 0.0693 - accuracy: 0.984 - ETA: 40s - loss: 0.0696 - accuracy: 0.984 - ETA: 39s - loss: 0.0693 - accuracy: 0.984 - ETA: 38s - loss: 0.0691 - accuracy: 0.984 - ETA: 38s - loss: 0.0690 - accuracy: 0.984 - ETA: 37s - loss: 0.0691 - accuracy: 0.984 - ETA: 36s - loss: 0.0691 - accuracy: 0.984 - ETA: 35s - loss: 0.0697 - accuracy: 0.983 - ETA: 35s - loss: 0.0694 - accuracy: 0.983 - ETA: 34s - loss: 0.0699 - accuracy: 0.983 - ETA: 33s - loss: 0.0696 - accuracy: 0.983 - ETA: 33s - loss: 0.0698 - accuracy: 0.983 - ETA: 32s - loss: 0.0697 - accuracy: 0.983 - ETA: 31s - loss: 0.0696 - accuracy: 0.983 - ETA: 30s - loss: 0.0700 - accuracy: 0.983 - ETA: 30s - loss: 0.0699 - accuracy: 0.983 - ETA: 29s - loss: 0.0699 - accuracy: 0.983 - ETA: 28s - loss: 0.0699 - accuracy: 0.983 - ETA: 27s - loss: 0.0703 - accuracy: 0.983 - ETA: 27s - loss: 0.0704 - accuracy: 0.983 - ETA: 26s - loss: 0.0702 - accuracy: 0.983 - ETA: 25s - loss: 0.0704 - accuracy: 0.983 - ETA: 25s - loss: 0.0702 - accuracy: 0.983 - ETA: 24s - loss: 0.0703 - accuracy: 0.983 - ETA: 23s - loss: 0.0703 - accuracy: 0.983 - ETA: 22s - loss: 0.0707 - accuracy: 0.983 - ETA: 22s - loss: 0.0706 - accuracy: 0.983 - ETA: 21s - loss: 0.0708 - accuracy: 0.983 - ETA: 20s - loss: 0.0705 - accuracy: 0.983 - ETA: 20s - loss: 0.0703 - accuracy: 0.983 - ETA: 19s - loss: 0.0700 - accuracy: 0.983 - ETA: 18s - loss: 0.0702 - accuracy: 0.983 - ETA: 17s - loss: 0.0706 - accuracy: 0.983 - ETA: 17s - loss: 0.0706 - accuracy: 0.983 - ETA: 16s - loss: 0.0707 - accuracy: 0.983 - ETA: 15s - loss: 0.0705 - accuracy: 0.983 - ETA: 15s - loss: 0.0704 - accuracy: 0.983 - ETA: 14s - loss: 0.0702 - accuracy: 0.983 - ETA: 13s - loss: 0.0702 - accuracy: 0.983 - ETA: 12s - loss: 0.0703 - accuracy: 0.983 - ETA: 12s - loss: 0.0706 - accuracy: 0.983 - ETA: 11s - loss: 0.0710 - accuracy: 0.983 - ETA: 10s - loss: 0.0712 - accuracy: 0.983 - ETA: 10s - loss: 0.0710 - accuracy: 0.983 - ETA: 9s - loss: 0.0711 - accuracy: 0.983 - ETA: 8s - loss: 0.0709 - accuracy: 0.98 - ETA: 7s - loss: 0.0709 - accuracy: 0.98 - ETA: 7s - loss: 0.0711 - accuracy: 0.98 - ETA: 6s - loss: 0.0711 - accuracy: 0.98 - ETA: 5s - loss: 0.0711 - accuracy: 0.98 - ETA: 4s - loss: 0.0715 - accuracy: 0.98 - ETA: 4s - loss: 0.0716 - accuracy: 0.98 - ETA: 3s - loss: 0.0718 - accuracy: 0.98 - ETA: 2s - loss: 0.0719 - accuracy: 0.98 - ETA: 2s - loss: 0.0718 - accuracy: 0.98 - ETA: 1s - loss: 0.0719 - accuracy: 0.98 - ETA: 0s - loss: 0.0720 - accuracy: 0.98 - 120s 6ms/step - loss: 0.0720 - accuracy: 0.9826 - val_loss: 0.9184 - val_accuracy: 0.7913\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:10 - loss: 0.0422 - accuracy: 1.00 - ETA: 2:02 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0532 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0526 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0516 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0577 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0618 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0626 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0653 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0644 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0646 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0653 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0647 - accuracy: 0.98 - ETA: 59s - loss: 0.0648 - accuracy: 0.9848 - ETA: 58s - loss: 0.0647 - accuracy: 0.984 - ETA: 57s - loss: 0.0645 - accuracy: 0.985 - ETA: 57s - loss: 0.0649 - accuracy: 0.984 - ETA: 56s - loss: 0.0646 - accuracy: 0.985 - ETA: 55s - loss: 0.0643 - accuracy: 0.985 - ETA: 55s - loss: 0.0641 - accuracy: 0.985 - ETA: 54s - loss: 0.0646 - accuracy: 0.985 - ETA: 53s - loss: 0.0645 - accuracy: 0.985 - ETA: 52s - loss: 0.0642 - accuracy: 0.985 - ETA: 52s - loss: 0.0639 - accuracy: 0.985 - ETA: 51s - loss: 0.0649 - accuracy: 0.985 - ETA: 50s - loss: 0.0646 - accuracy: 0.985 - ETA: 49s - loss: 0.0656 - accuracy: 0.985 - ETA: 49s - loss: 0.0658 - accuracy: 0.985 - ETA: 48s - loss: 0.0655 - accuracy: 0.985 - ETA: 47s - loss: 0.0655 - accuracy: 0.985 - ETA: 47s - loss: 0.0651 - accuracy: 0.985 - ETA: 46s - loss: 0.0651 - accuracy: 0.985 - ETA: 45s - loss: 0.0651 - accuracy: 0.985 - ETA: 44s - loss: 0.0651 - accuracy: 0.985 - ETA: 44s - loss: 0.0650 - accuracy: 0.985 - ETA: 43s - loss: 0.0649 - accuracy: 0.985 - ETA: 42s - loss: 0.0655 - accuracy: 0.984 - ETA: 41s - loss: 0.0654 - accuracy: 0.984 - ETA: 41s - loss: 0.0651 - accuracy: 0.984 - ETA: 40s - loss: 0.0649 - accuracy: 0.985 - ETA: 39s - loss: 0.0650 - accuracy: 0.984 - ETA: 39s - loss: 0.0649 - accuracy: 0.984 - ETA: 38s - loss: 0.0649 - accuracy: 0.984 - ETA: 37s - loss: 0.0648 - accuracy: 0.984 - ETA: 36s - loss: 0.0645 - accuracy: 0.984 - ETA: 36s - loss: 0.0643 - accuracy: 0.985 - ETA: 35s - loss: 0.0641 - accuracy: 0.985 - ETA: 34s - loss: 0.0638 - accuracy: 0.985 - ETA: 33s - loss: 0.0636 - accuracy: 0.985 - ETA: 33s - loss: 0.0633 - accuracy: 0.985 - ETA: 32s - loss: 0.0633 - accuracy: 0.985 - ETA: 31s - loss: 0.0635 - accuracy: 0.984 - ETA: 31s - loss: 0.0632 - accuracy: 0.984 - ETA: 30s - loss: 0.0632 - accuracy: 0.984 - ETA: 29s - loss: 0.0629 - accuracy: 0.984 - ETA: 28s - loss: 0.0627 - accuracy: 0.985 - ETA: 28s - loss: 0.0626 - accuracy: 0.984 - ETA: 27s - loss: 0.0629 - accuracy: 0.984 - ETA: 26s - loss: 0.0629 - accuracy: 0.984 - ETA: 25s - loss: 0.0631 - accuracy: 0.984 - ETA: 25s - loss: 0.0632 - accuracy: 0.984 - ETA: 24s - loss: 0.0634 - accuracy: 0.984 - ETA: 23s - loss: 0.0635 - accuracy: 0.984 - ETA: 23s - loss: 0.0634 - accuracy: 0.984 - ETA: 22s - loss: 0.0634 - accuracy: 0.984 - ETA: 21s - loss: 0.0633 - accuracy: 0.984 - ETA: 20s - loss: 0.0632 - accuracy: 0.984 - ETA: 20s - loss: 0.0633 - accuracy: 0.984 - ETA: 19s - loss: 0.0634 - accuracy: 0.984 - ETA: 18s - loss: 0.0634 - accuracy: 0.984 - ETA: 17s - loss: 0.0633 - accuracy: 0.984 - ETA: 17s - loss: 0.0632 - accuracy: 0.984 - ETA: 16s - loss: 0.0631 - accuracy: 0.984 - ETA: 15s - loss: 0.0632 - accuracy: 0.984 - ETA: 15s - loss: 0.0630 - accuracy: 0.984 - ETA: 14s - loss: 0.0629 - accuracy: 0.984 - ETA: 13s - loss: 0.0628 - accuracy: 0.984 - ETA: 12s - loss: 0.0627 - accuracy: 0.984 - ETA: 12s - loss: 0.0628 - accuracy: 0.985 - ETA: 11s - loss: 0.0629 - accuracy: 0.985 - ETA: 10s - loss: 0.0626 - accuracy: 0.985 - ETA: 10s - loss: 0.0624 - accuracy: 0.985 - ETA: 9s - loss: 0.0626 - accuracy: 0.985 - ETA: 8s - loss: 0.0626 - accuracy: 0.98 - ETA: 7s - loss: 0.0631 - accuracy: 0.98 - ETA: 7s - loss: 0.0630 - accuracy: 0.98 - ETA: 6s - loss: 0.0628 - accuracy: 0.98 - ETA: 5s - loss: 0.0628 - accuracy: 0.98 - ETA: 4s - loss: 0.0627 - accuracy: 0.98 - ETA: 4s - loss: 0.0627 - accuracy: 0.98 - ETA: 3s - loss: 0.0628 - accuracy: 0.98 - ETA: 2s - loss: 0.0628 - accuracy: 0.98 - ETA: 2s - loss: 0.0632 - accuracy: 0.98 - ETA: 1s - loss: 0.0630 - accuracy: 0.98 - ETA: 0s - loss: 0.0627 - accuracy: 0.98 - 120s 6ms/step - loss: 0.0626 - accuracy: 0.9854 - val_loss: 0.9185 - val_accuracy: 0.7919\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:01 - loss: 0.0961 - accuracy: 0.96 - ETA: 1:54 - loss: 0.0708 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0606 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0582 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0674 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0605 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0608 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0564 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0542 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0492 - accuracy: 0.98 - ETA: 59s - loss: 0.0498 - accuracy: 0.9886 - ETA: 59s - loss: 0.0495 - accuracy: 0.988 - ETA: 58s - loss: 0.0494 - accuracy: 0.988 - ETA: 57s - loss: 0.0494 - accuracy: 0.989 - ETA: 57s - loss: 0.0495 - accuracy: 0.988 - ETA: 56s - loss: 0.0493 - accuracy: 0.989 - ETA: 55s - loss: 0.0492 - accuracy: 0.989 - ETA: 54s - loss: 0.0489 - accuracy: 0.989 - ETA: 54s - loss: 0.0485 - accuracy: 0.989 - ETA: 53s - loss: 0.0484 - accuracy: 0.989 - ETA: 52s - loss: 0.0482 - accuracy: 0.989 - ETA: 52s - loss: 0.0482 - accuracy: 0.989 - ETA: 51s - loss: 0.0480 - accuracy: 0.989 - ETA: 50s - loss: 0.0483 - accuracy: 0.989 - ETA: 49s - loss: 0.0485 - accuracy: 0.988 - ETA: 49s - loss: 0.0484 - accuracy: 0.989 - ETA: 48s - loss: 0.0484 - accuracy: 0.988 - ETA: 47s - loss: 0.0487 - accuracy: 0.988 - ETA: 46s - loss: 0.0488 - accuracy: 0.988 - ETA: 46s - loss: 0.0486 - accuracy: 0.988 - ETA: 45s - loss: 0.0484 - accuracy: 0.989 - ETA: 44s - loss: 0.0483 - accuracy: 0.989 - ETA: 44s - loss: 0.0484 - accuracy: 0.988 - ETA: 43s - loss: 0.0484 - accuracy: 0.988 - ETA: 42s - loss: 0.0483 - accuracy: 0.989 - ETA: 41s - loss: 0.0481 - accuracy: 0.989 - ETA: 41s - loss: 0.0484 - accuracy: 0.989 - ETA: 40s - loss: 0.0482 - accuracy: 0.989 - ETA: 39s - loss: 0.0486 - accuracy: 0.988 - ETA: 39s - loss: 0.0484 - accuracy: 0.989 - ETA: 38s - loss: 0.0484 - accuracy: 0.988 - ETA: 37s - loss: 0.0485 - accuracy: 0.988 - ETA: 36s - loss: 0.0486 - accuracy: 0.988 - ETA: 36s - loss: 0.0487 - accuracy: 0.988 - ETA: 35s - loss: 0.0486 - accuracy: 0.988 - ETA: 34s - loss: 0.0486 - accuracy: 0.988 - ETA: 33s - loss: 0.0489 - accuracy: 0.988 - ETA: 33s - loss: 0.0489 - accuracy: 0.988 - ETA: 32s - loss: 0.0489 - accuracy: 0.988 - ETA: 31s - loss: 0.0488 - accuracy: 0.988 - ETA: 31s - loss: 0.0485 - accuracy: 0.988 - ETA: 30s - loss: 0.0489 - accuracy: 0.988 - ETA: 29s - loss: 0.0488 - accuracy: 0.988 - ETA: 28s - loss: 0.0486 - accuracy: 0.988 - ETA: 28s - loss: 0.0486 - accuracy: 0.988 - ETA: 27s - loss: 0.0487 - accuracy: 0.988 - ETA: 26s - loss: 0.0486 - accuracy: 0.988 - ETA: 25s - loss: 0.0486 - accuracy: 0.988 - ETA: 25s - loss: 0.0484 - accuracy: 0.988 - ETA: 24s - loss: 0.0487 - accuracy: 0.988 - ETA: 23s - loss: 0.0488 - accuracy: 0.988 - ETA: 23s - loss: 0.0486 - accuracy: 0.988 - ETA: 22s - loss: 0.0485 - accuracy: 0.988 - ETA: 21s - loss: 0.0483 - accuracy: 0.988 - ETA: 20s - loss: 0.0481 - accuracy: 0.988 - ETA: 20s - loss: 0.0479 - accuracy: 0.988 - ETA: 19s - loss: 0.0477 - accuracy: 0.988 - ETA: 18s - loss: 0.0477 - accuracy: 0.988 - ETA: 18s - loss: 0.0476 - accuracy: 0.988 - ETA: 17s - loss: 0.0475 - accuracy: 0.988 - ETA: 16s - loss: 0.0473 - accuracy: 0.989 - ETA: 15s - loss: 0.0473 - accuracy: 0.988 - ETA: 15s - loss: 0.0474 - accuracy: 0.988 - ETA: 14s - loss: 0.0476 - accuracy: 0.988 - ETA: 13s - loss: 0.0474 - accuracy: 0.988 - ETA: 12s - loss: 0.0474 - accuracy: 0.988 - ETA: 12s - loss: 0.0473 - accuracy: 0.988 - ETA: 11s - loss: 0.0476 - accuracy: 0.988 - ETA: 10s - loss: 0.0475 - accuracy: 0.988 - ETA: 10s - loss: 0.0474 - accuracy: 0.988 - ETA: 9s - loss: 0.0476 - accuracy: 0.988 - ETA: 8s - loss: 0.0478 - accuracy: 0.98 - ETA: 7s - loss: 0.0479 - accuracy: 0.98 - ETA: 7s - loss: 0.0480 - accuracy: 0.98 - ETA: 6s - loss: 0.0479 - accuracy: 0.98 - ETA: 5s - loss: 0.0479 - accuracy: 0.98 - ETA: 4s - loss: 0.0478 - accuracy: 0.98 - ETA: 4s - loss: 0.0478 - accuracy: 0.98 - ETA: 3s - loss: 0.0479 - accuracy: 0.98 - ETA: 2s - loss: 0.0478 - accuracy: 0.98 - ETA: 2s - loss: 0.0478 - accuracy: 0.98 - ETA: 1s - loss: 0.0476 - accuracy: 0.98 - ETA: 0s - loss: 0.0478 - accuracy: 0.98 - 120s 6ms/step - loss: 0.0477 - accuracy: 0.9888 - val_loss: 0.9270 - val_accuracy: 0.7906\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:49 - loss: 0.0303 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0357 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0391 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0373 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0381 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0391 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0406 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0393 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0386 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0396 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0388 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0377 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0376 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0381 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0374 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0366 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0359 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0359 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0357 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0365 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0367 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0360 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0352 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0354 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0350 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0348 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0347 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0344 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0352 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0351 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0356 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0362 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0359 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0364 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0373 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0373 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0372 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0377 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0373 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0369 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0375 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0373 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0370 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0383 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0386 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0385 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0383 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0380 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0383 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0381 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0385 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0391 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0389 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0399 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0396 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0408 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0407 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0405 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0410 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0413 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0416 - accuracy: 0.99 - ETA: 59s - loss: 0.0413 - accuracy: 0.9910 - ETA: 59s - loss: 0.0412 - accuracy: 0.991 - ETA: 58s - loss: 0.0410 - accuracy: 0.991 - ETA: 57s - loss: 0.0407 - accuracy: 0.991 - ETA: 56s - loss: 0.0405 - accuracy: 0.991 - ETA: 56s - loss: 0.0403 - accuracy: 0.991 - ETA: 55s - loss: 0.0404 - accuracy: 0.991 - ETA: 54s - loss: 0.0402 - accuracy: 0.991 - ETA: 54s - loss: 0.0403 - accuracy: 0.991 - ETA: 53s - loss: 0.0402 - accuracy: 0.991 - ETA: 52s - loss: 0.0402 - accuracy: 0.991 - ETA: 51s - loss: 0.0401 - accuracy: 0.991 - ETA: 51s - loss: 0.0402 - accuracy: 0.991 - ETA: 50s - loss: 0.0400 - accuracy: 0.991 - ETA: 49s - loss: 0.0399 - accuracy: 0.991 - ETA: 48s - loss: 0.0402 - accuracy: 0.991 - ETA: 48s - loss: 0.0398 - accuracy: 0.991 - ETA: 47s - loss: 0.0394 - accuracy: 0.991 - ETA: 46s - loss: 0.0393 - accuracy: 0.991 - ETA: 46s - loss: 0.0390 - accuracy: 0.992 - ETA: 45s - loss: 0.0388 - accuracy: 0.992 - ETA: 44s - loss: 0.0387 - accuracy: 0.992 - ETA: 43s - loss: 0.0392 - accuracy: 0.992 - ETA: 43s - loss: 0.0393 - accuracy: 0.992 - ETA: 42s - loss: 0.0397 - accuracy: 0.992 - ETA: 41s - loss: 0.0394 - accuracy: 0.992 - ETA: 40s - loss: 0.0395 - accuracy: 0.992 - ETA: 40s - loss: 0.0394 - accuracy: 0.992 - ETA: 39s - loss: 0.0395 - accuracy: 0.992 - ETA: 38s - loss: 0.0401 - accuracy: 0.991 - ETA: 38s - loss: 0.0401 - accuracy: 0.992 - ETA: 37s - loss: 0.0400 - accuracy: 0.992 - ETA: 36s - loss: 0.0397 - accuracy: 0.992 - ETA: 35s - loss: 0.0395 - accuracy: 0.992 - ETA: 35s - loss: 0.0400 - accuracy: 0.992 - ETA: 34s - loss: 0.0398 - accuracy: 0.992 - ETA: 33s - loss: 0.0398 - accuracy: 0.992 - ETA: 33s - loss: 0.0396 - accuracy: 0.992 - ETA: 32s - loss: 0.0394 - accuracy: 0.992 - ETA: 31s - loss: 0.0396 - accuracy: 0.992 - ETA: 30s - loss: 0.0397 - accuracy: 0.992 - ETA: 30s - loss: 0.0396 - accuracy: 0.992 - ETA: 29s - loss: 0.0398 - accuracy: 0.992 - ETA: 28s - loss: 0.0398 - accuracy: 0.992 - ETA: 28s - loss: 0.0396 - accuracy: 0.992 - ETA: 27s - loss: 0.0395 - accuracy: 0.992 - ETA: 26s - loss: 0.0394 - accuracy: 0.992 - ETA: 25s - loss: 0.0396 - accuracy: 0.992 - ETA: 25s - loss: 0.0395 - accuracy: 0.992 - ETA: 24s - loss: 0.0395 - accuracy: 0.992 - ETA: 23s - loss: 0.0397 - accuracy: 0.992 - ETA: 23s - loss: 0.0396 - accuracy: 0.992 - ETA: 22s - loss: 0.0404 - accuracy: 0.991 - ETA: 21s - loss: 0.0403 - accuracy: 0.992 - ETA: 20s - loss: 0.0403 - accuracy: 0.991 - ETA: 20s - loss: 0.0404 - accuracy: 0.991 - ETA: 19s - loss: 0.0404 - accuracy: 0.991 - ETA: 18s - loss: 0.0403 - accuracy: 0.991 - ETA: 17s - loss: 0.0402 - accuracy: 0.992 - ETA: 17s - loss: 0.0401 - accuracy: 0.992 - ETA: 16s - loss: 0.0400 - accuracy: 0.992 - ETA: 15s - loss: 0.0397 - accuracy: 0.992 - ETA: 15s - loss: 0.0397 - accuracy: 0.992 - ETA: 14s - loss: 0.0397 - accuracy: 0.992 - ETA: 13s - loss: 0.0396 - accuracy: 0.992 - ETA: 12s - loss: 0.0398 - accuracy: 0.992 - ETA: 12s - loss: 0.0397 - accuracy: 0.992 - ETA: 11s - loss: 0.0397 - accuracy: 0.992 - ETA: 10s - loss: 0.0397 - accuracy: 0.992 - ETA: 10s - loss: 0.0397 - accuracy: 0.992 - ETA: 9s - loss: 0.0398 - accuracy: 0.992 - ETA: 8s - loss: 0.0400 - accuracy: 0.99 - ETA: 7s - loss: 0.0400 - accuracy: 0.99 - ETA: 7s - loss: 0.0398 - accuracy: 0.99 - ETA: 6s - loss: 0.0398 - accuracy: 0.99 - ETA: 5s - loss: 0.0398 - accuracy: 0.99 - ETA: 4s - loss: 0.0398 - accuracy: 0.99 - ETA: 4s - loss: 0.0397 - accuracy: 0.99 - ETA: 3s - loss: 0.0398 - accuracy: 0.99 - ETA: 2s - loss: 0.0401 - accuracy: 0.99 - ETA: 2s - loss: 0.0400 - accuracy: 0.99 - ETA: 1s - loss: 0.0402 - accuracy: 0.99 - ETA: 0s - loss: 0.0401 - accuracy: 0.99 - 119s 6ms/step - loss: 0.0400 - accuracy: 0.9918 - val_loss: 0.9247 - val_accuracy: 0.7931\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:54 - loss: 0.0433 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0368 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0284 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0385 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0352 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0359 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0343 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0331 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0313 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0293 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0301 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0317 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0310 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0302 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0302 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0310 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0298 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0287 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0287 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0283 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0284 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0289 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0291 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0290 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0291 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0290 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0294 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0289 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0296 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0295 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0297 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0292 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0303 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0306 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0301 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0304 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0303 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0301 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0306 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0307 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0316 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0321 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0320 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0319 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0324 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0321 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0319 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0319 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0319 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0322 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0329 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0325 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0323 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0321 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0323 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0323 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0329 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0330 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0331 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0333 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0332 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0331 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0335 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0334 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0338 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0336 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0336 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0335 - accuracy: 0.99 - ETA: 59s - loss: 0.0335 - accuracy: 0.9937 - ETA: 58s - loss: 0.0333 - accuracy: 0.993 - ETA: 58s - loss: 0.0330 - accuracy: 0.993 - ETA: 57s - loss: 0.0330 - accuracy: 0.993 - ETA: 56s - loss: 0.0328 - accuracy: 0.993 - ETA: 55s - loss: 0.0325 - accuracy: 0.994 - ETA: 55s - loss: 0.0325 - accuracy: 0.994 - ETA: 54s - loss: 0.0324 - accuracy: 0.994 - ETA: 53s - loss: 0.0327 - accuracy: 0.993 - ETA: 52s - loss: 0.0330 - accuracy: 0.993 - ETA: 52s - loss: 0.0330 - accuracy: 0.993 - ETA: 51s - loss: 0.0329 - accuracy: 0.993 - ETA: 50s - loss: 0.0335 - accuracy: 0.993 - ETA: 50s - loss: 0.0336 - accuracy: 0.993 - ETA: 49s - loss: 0.0336 - accuracy: 0.993 - ETA: 48s - loss: 0.0335 - accuracy: 0.993 - ETA: 47s - loss: 0.0334 - accuracy: 0.993 - ETA: 47s - loss: 0.0334 - accuracy: 0.993 - ETA: 46s - loss: 0.0332 - accuracy: 0.993 - ETA: 45s - loss: 0.0331 - accuracy: 0.993 - ETA: 44s - loss: 0.0332 - accuracy: 0.993 - ETA: 44s - loss: 0.0334 - accuracy: 0.993 - ETA: 43s - loss: 0.0332 - accuracy: 0.993 - ETA: 42s - loss: 0.0333 - accuracy: 0.993 - ETA: 41s - loss: 0.0332 - accuracy: 0.993 - ETA: 41s - loss: 0.0331 - accuracy: 0.993 - ETA: 40s - loss: 0.0330 - accuracy: 0.993 - ETA: 39s - loss: 0.0329 - accuracy: 0.993 - ETA: 39s - loss: 0.0327 - accuracy: 0.993 - ETA: 38s - loss: 0.0326 - accuracy: 0.993 - ETA: 37s - loss: 0.0328 - accuracy: 0.993 - ETA: 36s - loss: 0.0328 - accuracy: 0.993 - ETA: 36s - loss: 0.0326 - accuracy: 0.993 - ETA: 35s - loss: 0.0325 - accuracy: 0.993 - ETA: 34s - loss: 0.0326 - accuracy: 0.993 - ETA: 34s - loss: 0.0327 - accuracy: 0.993 - ETA: 33s - loss: 0.0327 - accuracy: 0.993 - ETA: 32s - loss: 0.0328 - accuracy: 0.993 - ETA: 31s - loss: 0.0327 - accuracy: 0.993 - ETA: 31s - loss: 0.0327 - accuracy: 0.993 - ETA: 30s - loss: 0.0326 - accuracy: 0.993 - ETA: 29s - loss: 0.0327 - accuracy: 0.993 - ETA: 28s - loss: 0.0325 - accuracy: 0.993 - ETA: 28s - loss: 0.0325 - accuracy: 0.993 - ETA: 27s - loss: 0.0325 - accuracy: 0.993 - ETA: 26s - loss: 0.0325 - accuracy: 0.993 - ETA: 26s - loss: 0.0326 - accuracy: 0.993 - ETA: 25s - loss: 0.0325 - accuracy: 0.993 - ETA: 24s - loss: 0.0324 - accuracy: 0.993 - ETA: 23s - loss: 0.0323 - accuracy: 0.993 - ETA: 23s - loss: 0.0324 - accuracy: 0.993 - ETA: 22s - loss: 0.0322 - accuracy: 0.993 - ETA: 21s - loss: 0.0324 - accuracy: 0.993 - ETA: 21s - loss: 0.0322 - accuracy: 0.993 - ETA: 20s - loss: 0.0321 - accuracy: 0.993 - ETA: 19s - loss: 0.0322 - accuracy: 0.993 - ETA: 18s - loss: 0.0321 - accuracy: 0.993 - ETA: 18s - loss: 0.0320 - accuracy: 0.993 - ETA: 17s - loss: 0.0321 - accuracy: 0.993 - ETA: 16s - loss: 0.0322 - accuracy: 0.993 - ETA: 15s - loss: 0.0322 - accuracy: 0.993 - ETA: 15s - loss: 0.0321 - accuracy: 0.993 - ETA: 14s - loss: 0.0320 - accuracy: 0.993 - ETA: 13s - loss: 0.0323 - accuracy: 0.993 - ETA: 13s - loss: 0.0322 - accuracy: 0.993 - ETA: 12s - loss: 0.0325 - accuracy: 0.993 - ETA: 11s - loss: 0.0328 - accuracy: 0.993 - ETA: 10s - loss: 0.0328 - accuracy: 0.993 - ETA: 10s - loss: 0.0328 - accuracy: 0.993 - ETA: 9s - loss: 0.0329 - accuracy: 0.993 - ETA: 8s - loss: 0.0330 - accuracy: 0.99 - ETA: 7s - loss: 0.0330 - accuracy: 0.99 - ETA: 7s - loss: 0.0330 - accuracy: 0.99 - ETA: 6s - loss: 0.0329 - accuracy: 0.99 - ETA: 5s - loss: 0.0331 - accuracy: 0.99 - ETA: 4s - loss: 0.0330 - accuracy: 0.99 - ETA: 4s - loss: 0.0330 - accuracy: 0.99 - ETA: 3s - loss: 0.0330 - accuracy: 0.99 - ETA: 2s - loss: 0.0329 - accuracy: 0.99 - ETA: 2s - loss: 0.0329 - accuracy: 0.99 - ETA: 1s - loss: 0.0330 - accuracy: 0.99 - ETA: 0s - loss: 0.0331 - accuracy: 0.99 - 120s 6ms/step - loss: 0.0331 - accuracy: 0.9930 - val_loss: 0.9170 - val_accuracy: 0.7983\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:55 - loss: 0.0099 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0155 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0191 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0229 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0216 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0229 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0227 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0231 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0284 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0267 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0264 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0264 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0256 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0249 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0244 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0248 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0251 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0245 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0253 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0257 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0268 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0263 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0265 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0264 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0261 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0269 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0265 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0268 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0269 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0266 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0263 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0267 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0264 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0261 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0262 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0263 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0262 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0262 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0260 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0266 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0266 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0268 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0265 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0264 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0264 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0263 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0262 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0260 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0258 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0258 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0259 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0261 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0259 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0258 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0256 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0254 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0255 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0252 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0254 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0255 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0253 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0254 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0254 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0255 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0253 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0252 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0252 - accuracy: 0.99 - ETA: 59s - loss: 0.0251 - accuracy: 0.9954 - ETA: 59s - loss: 0.0251 - accuracy: 0.995 - ETA: 58s - loss: 0.0250 - accuracy: 0.995 - ETA: 57s - loss: 0.0259 - accuracy: 0.995 - ETA: 56s - loss: 0.0270 - accuracy: 0.995 - ETA: 56s - loss: 0.0269 - accuracy: 0.995 - ETA: 55s - loss: 0.0267 - accuracy: 0.995 - ETA: 54s - loss: 0.0268 - accuracy: 0.995 - ETA: 53s - loss: 0.0267 - accuracy: 0.995 - ETA: 53s - loss: 0.0266 - accuracy: 0.995 - ETA: 52s - loss: 0.0269 - accuracy: 0.994 - ETA: 51s - loss: 0.0278 - accuracy: 0.994 - ETA: 51s - loss: 0.0280 - accuracy: 0.994 - ETA: 50s - loss: 0.0282 - accuracy: 0.994 - ETA: 49s - loss: 0.0279 - accuracy: 0.994 - ETA: 48s - loss: 0.0279 - accuracy: 0.994 - ETA: 48s - loss: 0.0278 - accuracy: 0.994 - ETA: 47s - loss: 0.0278 - accuracy: 0.994 - ETA: 46s - loss: 0.0278 - accuracy: 0.994 - ETA: 46s - loss: 0.0277 - accuracy: 0.994 - ETA: 45s - loss: 0.0280 - accuracy: 0.994 - ETA: 44s - loss: 0.0278 - accuracy: 0.994 - ETA: 44s - loss: 0.0283 - accuracy: 0.994 - ETA: 43s - loss: 0.0282 - accuracy: 0.994 - ETA: 42s - loss: 0.0284 - accuracy: 0.994 - ETA: 41s - loss: 0.0284 - accuracy: 0.994 - ETA: 41s - loss: 0.0285 - accuracy: 0.994 - ETA: 40s - loss: 0.0284 - accuracy: 0.994 - ETA: 39s - loss: 0.0285 - accuracy: 0.994 - ETA: 39s - loss: 0.0288 - accuracy: 0.994 - ETA: 38s - loss: 0.0286 - accuracy: 0.994 - ETA: 37s - loss: 0.0287 - accuracy: 0.994 - ETA: 36s - loss: 0.0286 - accuracy: 0.994 - ETA: 36s - loss: 0.0290 - accuracy: 0.994 - ETA: 35s - loss: 0.0289 - accuracy: 0.994 - ETA: 34s - loss: 0.0291 - accuracy: 0.994 - ETA: 33s - loss: 0.0290 - accuracy: 0.994 - ETA: 33s - loss: 0.0288 - accuracy: 0.994 - ETA: 32s - loss: 0.0291 - accuracy: 0.994 - ETA: 31s - loss: 0.0290 - accuracy: 0.994 - ETA: 30s - loss: 0.0291 - accuracy: 0.994 - ETA: 30s - loss: 0.0290 - accuracy: 0.994 - ETA: 29s - loss: 0.0291 - accuracy: 0.994 - ETA: 28s - loss: 0.0292 - accuracy: 0.994 - ETA: 28s - loss: 0.0293 - accuracy: 0.994 - ETA: 27s - loss: 0.0294 - accuracy: 0.994 - ETA: 26s - loss: 0.0295 - accuracy: 0.994 - ETA: 26s - loss: 0.0296 - accuracy: 0.994 - ETA: 25s - loss: 0.0296 - accuracy: 0.994 - ETA: 24s - loss: 0.0297 - accuracy: 0.994 - ETA: 23s - loss: 0.0296 - accuracy: 0.994 - ETA: 23s - loss: 0.0296 - accuracy: 0.994 - ETA: 22s - loss: 0.0297 - accuracy: 0.994 - ETA: 21s - loss: 0.0296 - accuracy: 0.994 - ETA: 20s - loss: 0.0296 - accuracy: 0.994 - ETA: 20s - loss: 0.0296 - accuracy: 0.994 - ETA: 19s - loss: 0.0296 - accuracy: 0.994 - ETA: 18s - loss: 0.0296 - accuracy: 0.994 - ETA: 18s - loss: 0.0296 - accuracy: 0.994 - ETA: 17s - loss: 0.0295 - accuracy: 0.994 - ETA: 16s - loss: 0.0295 - accuracy: 0.994 - ETA: 15s - loss: 0.0297 - accuracy: 0.994 - ETA: 15s - loss: 0.0296 - accuracy: 0.994 - ETA: 14s - loss: 0.0295 - accuracy: 0.994 - ETA: 13s - loss: 0.0296 - accuracy: 0.994 - ETA: 12s - loss: 0.0295 - accuracy: 0.994 - ETA: 12s - loss: 0.0294 - accuracy: 0.994 - ETA: 11s - loss: 0.0296 - accuracy: 0.994 - ETA: 10s - loss: 0.0296 - accuracy: 0.994 - ETA: 10s - loss: 0.0297 - accuracy: 0.994 - ETA: 9s - loss: 0.0296 - accuracy: 0.994 - ETA: 8s - loss: 0.0296 - accuracy: 0.99 - ETA: 7s - loss: 0.0297 - accuracy: 0.99 - ETA: 7s - loss: 0.0296 - accuracy: 0.99 - ETA: 6s - loss: 0.0296 - accuracy: 0.99 - ETA: 5s - loss: 0.0295 - accuracy: 0.99 - ETA: 4s - loss: 0.0297 - accuracy: 0.99 - ETA: 4s - loss: 0.0297 - accuracy: 0.99 - ETA: 3s - loss: 0.0296 - accuracy: 0.99 - ETA: 2s - loss: 0.0295 - accuracy: 0.99 - ETA: 2s - loss: 0.0294 - accuracy: 0.99 - ETA: 1s - loss: 0.0294 - accuracy: 0.99 - ETA: 0s - loss: 0.0295 - accuracy: 0.99 - 120s 6ms/step - loss: 0.0294 - accuracy: 0.9944 - val_loss: 0.9186 - val_accuracy: 0.7966\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:49 - loss: 0.0137 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0135 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0190 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0208 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0340 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0315 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0313 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0301 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0305 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0305 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0297 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0287 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0277 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0270 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0258 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0263 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0252 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0248 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0243 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0238 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0235 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0244 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0241 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0261 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0257 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0252 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0248 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0246 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0245 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0242 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0242 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0240 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0236 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0235 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0244 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0250 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0251 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0251 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0252 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0253 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0259 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0257 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0254 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0254 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0255 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0254 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0253 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0254 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0253 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0251 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0250 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0248 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0246 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0244 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0244 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0243 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0246 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0246 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0247 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0250 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0249 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0249 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0253 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0254 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0254 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0253 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0251 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0253 - accuracy: 0.99 - ETA: 59s - loss: 0.0253 - accuracy: 0.9946 - ETA: 58s - loss: 0.0253 - accuracy: 0.994 - ETA: 58s - loss: 0.0250 - accuracy: 0.994 - ETA: 57s - loss: 0.0253 - accuracy: 0.994 - ETA: 56s - loss: 0.0251 - accuracy: 0.994 - ETA: 55s - loss: 0.0252 - accuracy: 0.994 - ETA: 55s - loss: 0.0250 - accuracy: 0.994 - ETA: 54s - loss: 0.0250 - accuracy: 0.994 - ETA: 53s - loss: 0.0248 - accuracy: 0.994 - ETA: 53s - loss: 0.0247 - accuracy: 0.995 - ETA: 52s - loss: 0.0246 - accuracy: 0.995 - ETA: 51s - loss: 0.0245 - accuracy: 0.995 - ETA: 50s - loss: 0.0246 - accuracy: 0.995 - ETA: 50s - loss: 0.0246 - accuracy: 0.995 - ETA: 49s - loss: 0.0245 - accuracy: 0.995 - ETA: 48s - loss: 0.0246 - accuracy: 0.995 - ETA: 47s - loss: 0.0244 - accuracy: 0.995 - ETA: 47s - loss: 0.0247 - accuracy: 0.995 - ETA: 46s - loss: 0.0249 - accuracy: 0.995 - ETA: 45s - loss: 0.0247 - accuracy: 0.995 - ETA: 44s - loss: 0.0248 - accuracy: 0.995 - ETA: 44s - loss: 0.0248 - accuracy: 0.995 - ETA: 43s - loss: 0.0247 - accuracy: 0.995 - ETA: 42s - loss: 0.0248 - accuracy: 0.995 - ETA: 41s - loss: 0.0248 - accuracy: 0.995 - ETA: 41s - loss: 0.0247 - accuracy: 0.995 - ETA: 40s - loss: 0.0246 - accuracy: 0.995 - ETA: 39s - loss: 0.0246 - accuracy: 0.995 - ETA: 39s - loss: 0.0246 - accuracy: 0.995 - ETA: 38s - loss: 0.0248 - accuracy: 0.995 - ETA: 37s - loss: 0.0249 - accuracy: 0.995 - ETA: 36s - loss: 0.0248 - accuracy: 0.995 - ETA: 36s - loss: 0.0248 - accuracy: 0.995 - ETA: 35s - loss: 0.0247 - accuracy: 0.995 - ETA: 34s - loss: 0.0246 - accuracy: 0.995 - ETA: 33s - loss: 0.0246 - accuracy: 0.995 - ETA: 33s - loss: 0.0247 - accuracy: 0.995 - ETA: 32s - loss: 0.0247 - accuracy: 0.995 - ETA: 31s - loss: 0.0246 - accuracy: 0.995 - ETA: 31s - loss: 0.0247 - accuracy: 0.995 - ETA: 30s - loss: 0.0247 - accuracy: 0.995 - ETA: 29s - loss: 0.0248 - accuracy: 0.995 - ETA: 28s - loss: 0.0248 - accuracy: 0.995 - ETA: 28s - loss: 0.0247 - accuracy: 0.995 - ETA: 27s - loss: 0.0248 - accuracy: 0.995 - ETA: 26s - loss: 0.0248 - accuracy: 0.994 - ETA: 25s - loss: 0.0248 - accuracy: 0.994 - ETA: 25s - loss: 0.0249 - accuracy: 0.994 - ETA: 24s - loss: 0.0250 - accuracy: 0.994 - ETA: 23s - loss: 0.0251 - accuracy: 0.994 - ETA: 23s - loss: 0.0252 - accuracy: 0.994 - ETA: 22s - loss: 0.0251 - accuracy: 0.994 - ETA: 21s - loss: 0.0251 - accuracy: 0.994 - ETA: 20s - loss: 0.0250 - accuracy: 0.994 - ETA: 20s - loss: 0.0249 - accuracy: 0.995 - ETA: 19s - loss: 0.0252 - accuracy: 0.994 - ETA: 18s - loss: 0.0253 - accuracy: 0.994 - ETA: 18s - loss: 0.0252 - accuracy: 0.994 - ETA: 17s - loss: 0.0254 - accuracy: 0.994 - ETA: 16s - loss: 0.0253 - accuracy: 0.994 - ETA: 15s - loss: 0.0259 - accuracy: 0.994 - ETA: 15s - loss: 0.0258 - accuracy: 0.994 - ETA: 14s - loss: 0.0260 - accuracy: 0.994 - ETA: 13s - loss: 0.0262 - accuracy: 0.994 - ETA: 12s - loss: 0.0263 - accuracy: 0.994 - ETA: 12s - loss: 0.0262 - accuracy: 0.994 - ETA: 11s - loss: 0.0263 - accuracy: 0.994 - ETA: 10s - loss: 0.0268 - accuracy: 0.994 - ETA: 10s - loss: 0.0267 - accuracy: 0.994 - ETA: 9s - loss: 0.0268 - accuracy: 0.994 - ETA: 8s - loss: 0.0268 - accuracy: 0.99 - ETA: 7s - loss: 0.0266 - accuracy: 0.99 - ETA: 7s - loss: 0.0266 - accuracy: 0.99 - ETA: 6s - loss: 0.0265 - accuracy: 0.99 - ETA: 5s - loss: 0.0265 - accuracy: 0.99 - ETA: 4s - loss: 0.0266 - accuracy: 0.99 - ETA: 4s - loss: 0.0265 - accuracy: 0.99 - ETA: 3s - loss: 0.0264 - accuracy: 0.99 - ETA: 2s - loss: 0.0263 - accuracy: 0.99 - ETA: 2s - loss: 0.0264 - accuracy: 0.99 - ETA: 1s - loss: 0.0264 - accuracy: 0.99 - ETA: 0s - loss: 0.0264 - accuracy: 0.99 - 120s 6ms/step - loss: 0.0263 - accuracy: 0.9947 - val_loss: 0.9397 - val_accuracy: 0.7964\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:59 - loss: 0.0154 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0158 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0137 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0131 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0131 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0152 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0141 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0137 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0141 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0140 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0158 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0165 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0162 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0159 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0160 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0158 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0166 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0172 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0171 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0166 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0170 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0169 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0166 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0165 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0164 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0165 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0171 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0171 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0170 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0171 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0172 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0176 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0172 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0184 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0186 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0187 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0188 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0187 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0189 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0187 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0188 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0186 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0187 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0187 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0188 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0188 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0187 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0198 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0196 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0194 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0192 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0195 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0194 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0193 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0193 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0195 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0194 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0191 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0191 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0189 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0188 - accuracy: 0.99 - ETA: 59s - loss: 0.0187 - accuracy: 0.9970 - ETA: 58s - loss: 0.0187 - accuracy: 0.997 - ETA: 58s - loss: 0.0192 - accuracy: 0.997 - ETA: 57s - loss: 0.0191 - accuracy: 0.997 - ETA: 56s - loss: 0.0190 - accuracy: 0.997 - ETA: 55s - loss: 0.0189 - accuracy: 0.997 - ETA: 55s - loss: 0.0191 - accuracy: 0.997 - ETA: 54s - loss: 0.0191 - accuracy: 0.997 - ETA: 53s - loss: 0.0192 - accuracy: 0.997 - ETA: 52s - loss: 0.0194 - accuracy: 0.997 - ETA: 52s - loss: 0.0197 - accuracy: 0.996 - ETA: 51s - loss: 0.0198 - accuracy: 0.996 - ETA: 50s - loss: 0.0200 - accuracy: 0.996 - ETA: 50s - loss: 0.0201 - accuracy: 0.996 - ETA: 49s - loss: 0.0201 - accuracy: 0.996 - ETA: 48s - loss: 0.0200 - accuracy: 0.996 - ETA: 48s - loss: 0.0200 - accuracy: 0.996 - ETA: 47s - loss: 0.0200 - accuracy: 0.996 - ETA: 46s - loss: 0.0199 - accuracy: 0.996 - ETA: 46s - loss: 0.0198 - accuracy: 0.996 - ETA: 45s - loss: 0.0200 - accuracy: 0.996 - ETA: 44s - loss: 0.0201 - accuracy: 0.996 - ETA: 43s - loss: 0.0207 - accuracy: 0.996 - ETA: 43s - loss: 0.0207 - accuracy: 0.996 - ETA: 42s - loss: 0.0205 - accuracy: 0.996 - ETA: 41s - loss: 0.0206 - accuracy: 0.996 - ETA: 41s - loss: 0.0206 - accuracy: 0.996 - ETA: 40s - loss: 0.0205 - accuracy: 0.996 - ETA: 39s - loss: 0.0204 - accuracy: 0.996 - ETA: 38s - loss: 0.0207 - accuracy: 0.996 - ETA: 38s - loss: 0.0208 - accuracy: 0.996 - ETA: 37s - loss: 0.0207 - accuracy: 0.996 - ETA: 36s - loss: 0.0207 - accuracy: 0.996 - ETA: 35s - loss: 0.0206 - accuracy: 0.996 - ETA: 35s - loss: 0.0206 - accuracy: 0.996 - ETA: 34s - loss: 0.0206 - accuracy: 0.996 - ETA: 33s - loss: 0.0205 - accuracy: 0.996 - ETA: 32s - loss: 0.0206 - accuracy: 0.996 - ETA: 32s - loss: 0.0207 - accuracy: 0.996 - ETA: 31s - loss: 0.0206 - accuracy: 0.996 - ETA: 30s - loss: 0.0207 - accuracy: 0.996 - ETA: 30s - loss: 0.0205 - accuracy: 0.996 - ETA: 29s - loss: 0.0211 - accuracy: 0.996 - ETA: 28s - loss: 0.0212 - accuracy: 0.996 - ETA: 27s - loss: 0.0212 - accuracy: 0.996 - ETA: 27s - loss: 0.0211 - accuracy: 0.996 - ETA: 26s - loss: 0.0211 - accuracy: 0.996 - ETA: 25s - loss: 0.0210 - accuracy: 0.996 - ETA: 25s - loss: 0.0210 - accuracy: 0.996 - ETA: 24s - loss: 0.0209 - accuracy: 0.996 - ETA: 23s - loss: 0.0211 - accuracy: 0.996 - ETA: 22s - loss: 0.0210 - accuracy: 0.996 - ETA: 22s - loss: 0.0213 - accuracy: 0.996 - ETA: 21s - loss: 0.0213 - accuracy: 0.996 - ETA: 20s - loss: 0.0212 - accuracy: 0.996 - ETA: 20s - loss: 0.0213 - accuracy: 0.995 - ETA: 19s - loss: 0.0213 - accuracy: 0.996 - ETA: 18s - loss: 0.0213 - accuracy: 0.996 - ETA: 17s - loss: 0.0213 - accuracy: 0.996 - ETA: 17s - loss: 0.0214 - accuracy: 0.995 - ETA: 16s - loss: 0.0215 - accuracy: 0.995 - ETA: 15s - loss: 0.0215 - accuracy: 0.995 - ETA: 14s - loss: 0.0215 - accuracy: 0.995 - ETA: 14s - loss: 0.0215 - accuracy: 0.995 - ETA: 13s - loss: 0.0218 - accuracy: 0.995 - ETA: 12s - loss: 0.0218 - accuracy: 0.995 - ETA: 12s - loss: 0.0218 - accuracy: 0.995 - ETA: 11s - loss: 0.0218 - accuracy: 0.995 - ETA: 10s - loss: 0.0217 - accuracy: 0.995 - ETA: 9s - loss: 0.0216 - accuracy: 0.995 - ETA: 9s - loss: 0.0215 - accuracy: 0.99 - ETA: 8s - loss: 0.0217 - accuracy: 0.99 - ETA: 7s - loss: 0.0216 - accuracy: 0.99 - ETA: 7s - loss: 0.0216 - accuracy: 0.99 - ETA: 6s - loss: 0.0215 - accuracy: 0.99 - ETA: 5s - loss: 0.0216 - accuracy: 0.99 - ETA: 4s - loss: 0.0217 - accuracy: 0.99 - ETA: 4s - loss: 0.0217 - accuracy: 0.99 - ETA: 3s - loss: 0.0216 - accuracy: 0.99 - ETA: 2s - loss: 0.0215 - accuracy: 0.99 - ETA: 2s - loss: 0.0214 - accuracy: 0.99 - ETA: 1s - loss: 0.0215 - accuracy: 0.99 - ETA: 0s - loss: 0.0215 - accuracy: 0.99 - 137s 7ms/step - loss: 0.0215 - accuracy: 0.9960 - val_loss: 0.9314 - val_accuracy: 0.7991\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:30 - loss: 0.0178 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0226 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0251 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0213 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0191 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0179 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0169 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0173 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0187 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0191 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0194 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0187 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0185 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0191 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0201 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0211 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0208 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0202 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0196 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0199 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0205 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0201 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0199 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0196 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0194 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0197 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0194 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0193 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0209 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0214 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0213 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0213 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0211 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0212 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0208 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0212 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0215 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0215 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0212 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0209 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0210 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0208 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0209 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0208 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0209 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0207 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0212 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0213 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0213 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0218 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0216 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0215 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0215 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0217 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0217 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0217 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0216 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0215 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0215 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0218 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0217 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0216 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0215 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0214 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0217 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0216 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0216 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0216 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0216 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0218 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0217 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0221 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0221 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0221 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0220 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0221 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0220 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0218 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0218 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0218 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0218 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0216 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0219 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0220 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0228 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0227 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0229 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0232 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0230 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0232 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0232 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0230 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0230 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0229 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0231 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0230 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0234 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0232 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0232 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0231 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0231 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0233 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0231 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0232 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0231 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0230 - accuracy: 0.99 - ETA: 58s - loss: 0.0228 - accuracy: 0.9951 - ETA: 57s - loss: 0.0227 - accuracy: 0.995 - ETA: 56s - loss: 0.0226 - accuracy: 0.995 - ETA: 54s - loss: 0.0226 - accuracy: 0.995 - ETA: 53s - loss: 0.0224 - accuracy: 0.995 - ETA: 52s - loss: 0.0224 - accuracy: 0.995 - ETA: 50s - loss: 0.0224 - accuracy: 0.995 - ETA: 49s - loss: 0.0223 - accuracy: 0.995 - ETA: 48s - loss: 0.0227 - accuracy: 0.995 - ETA: 46s - loss: 0.0230 - accuracy: 0.995 - ETA: 45s - loss: 0.0232 - accuracy: 0.995 - ETA: 44s - loss: 0.0233 - accuracy: 0.995 - ETA: 42s - loss: 0.0232 - accuracy: 0.995 - ETA: 41s - loss: 0.0236 - accuracy: 0.995 - ETA: 40s - loss: 0.0236 - accuracy: 0.995 - ETA: 38s - loss: 0.0235 - accuracy: 0.995 - ETA: 37s - loss: 0.0234 - accuracy: 0.995 - ETA: 36s - loss: 0.0233 - accuracy: 0.995 - ETA: 34s - loss: 0.0236 - accuracy: 0.995 - ETA: 33s - loss: 0.0239 - accuracy: 0.995 - ETA: 31s - loss: 0.0238 - accuracy: 0.995 - ETA: 30s - loss: 0.0238 - accuracy: 0.995 - ETA: 29s - loss: 0.0237 - accuracy: 0.995 - ETA: 27s - loss: 0.0236 - accuracy: 0.995 - ETA: 26s - loss: 0.0239 - accuracy: 0.994 - ETA: 25s - loss: 0.0239 - accuracy: 0.994 - ETA: 23s - loss: 0.0240 - accuracy: 0.994 - ETA: 22s - loss: 0.0239 - accuracy: 0.994 - ETA: 21s - loss: 0.0239 - accuracy: 0.994 - ETA: 19s - loss: 0.0239 - accuracy: 0.994 - ETA: 18s - loss: 0.0238 - accuracy: 0.994 - ETA: 17s - loss: 0.0237 - accuracy: 0.994 - ETA: 15s - loss: 0.0241 - accuracy: 0.994 - ETA: 14s - loss: 0.0240 - accuracy: 0.994 - ETA: 13s - loss: 0.0240 - accuracy: 0.995 - ETA: 11s - loss: 0.0239 - accuracy: 0.995 - ETA: 10s - loss: 0.0243 - accuracy: 0.994 - ETA: 9s - loss: 0.0244 - accuracy: 0.994 - ETA: 7s - loss: 0.0243 - accuracy: 0.99 - ETA: 6s - loss: 0.0244 - accuracy: 0.99 - ETA: 5s - loss: 0.0246 - accuracy: 0.99 - ETA: 3s - loss: 0.0246 - accuracy: 0.99 - ETA: 2s - loss: 0.0247 - accuracy: 0.99 - ETA: 1s - loss: 0.0247 - accuracy: 0.99 - 227s 12ms/step - loss: 0.0246 - accuracy: 0.9948 - val_loss: 0.9237 - val_accuracy: 0.7993\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:22 - loss: 0.0325 - accuracy: 0.99 - ETA: 3:17 - loss: 0.0224 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0268 - accuracy: 0.99 - ETA: 3:15 - loss: 0.0249 - accuracy: 0.99 - ETA: 3:16 - loss: 0.0244 - accuracy: 0.99 - ETA: 3:12 - loss: 0.0227 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0246 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0256 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0241 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0231 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0226 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0238 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0224 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0215 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0209 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0207 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0206 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0204 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0206 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0207 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0204 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0204 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0200 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0201 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0202 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0199 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0199 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0216 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0215 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0210 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0208 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0205 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0203 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0204 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0202 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0200 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0198 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0195 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0193 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0193 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0195 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0194 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0191 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0191 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0188 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0186 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0186 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0186 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0184 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0186 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0187 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0187 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0188 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0190 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0189 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0188 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0190 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0189 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0191 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0192 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0192 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0191 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0190 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0189 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0189 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0192 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0196 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0195 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0196 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0196 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0195 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0198 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0201 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0202 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0200 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0201 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0200 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0198 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0196 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0195 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0195 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0194 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0193 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0192 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0192 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0193 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0193 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0191 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0190 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0189 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0189 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0190 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0190 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0189 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0190 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0189 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0188 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0187 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0187 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0186 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0184 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0184 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0184 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0183 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0183 - accuracy: 0.99 - ETA: 58s - loss: 0.0183 - accuracy: 0.9974 - ETA: 57s - loss: 0.0182 - accuracy: 0.997 - ETA: 56s - loss: 0.0182 - accuracy: 0.997 - ETA: 54s - loss: 0.0182 - accuracy: 0.997 - ETA: 53s - loss: 0.0183 - accuracy: 0.997 - ETA: 52s - loss: 0.0183 - accuracy: 0.997 - ETA: 50s - loss: 0.0183 - accuracy: 0.997 - ETA: 49s - loss: 0.0183 - accuracy: 0.997 - ETA: 48s - loss: 0.0183 - accuracy: 0.997 - ETA: 46s - loss: 0.0188 - accuracy: 0.997 - ETA: 45s - loss: 0.0188 - accuracy: 0.997 - ETA: 44s - loss: 0.0187 - accuracy: 0.997 - ETA: 42s - loss: 0.0187 - accuracy: 0.997 - ETA: 41s - loss: 0.0188 - accuracy: 0.997 - ETA: 40s - loss: 0.0188 - accuracy: 0.997 - ETA: 38s - loss: 0.0187 - accuracy: 0.997 - ETA: 37s - loss: 0.0187 - accuracy: 0.997 - ETA: 36s - loss: 0.0189 - accuracy: 0.997 - ETA: 34s - loss: 0.0188 - accuracy: 0.997 - ETA: 33s - loss: 0.0187 - accuracy: 0.997 - ETA: 32s - loss: 0.0188 - accuracy: 0.997 - ETA: 30s - loss: 0.0188 - accuracy: 0.997 - ETA: 29s - loss: 0.0188 - accuracy: 0.997 - ETA: 28s - loss: 0.0189 - accuracy: 0.997 - ETA: 26s - loss: 0.0188 - accuracy: 0.997 - ETA: 25s - loss: 0.0190 - accuracy: 0.997 - ETA: 24s - loss: 0.0189 - accuracy: 0.997 - ETA: 22s - loss: 0.0189 - accuracy: 0.997 - ETA: 21s - loss: 0.0189 - accuracy: 0.997 - ETA: 20s - loss: 0.0188 - accuracy: 0.997 - ETA: 18s - loss: 0.0188 - accuracy: 0.997 - ETA: 17s - loss: 0.0188 - accuracy: 0.997 - ETA: 15s - loss: 0.0187 - accuracy: 0.997 - ETA: 14s - loss: 0.0189 - accuracy: 0.997 - ETA: 13s - loss: 0.0189 - accuracy: 0.997 - ETA: 11s - loss: 0.0189 - accuracy: 0.997 - ETA: 10s - loss: 0.0189 - accuracy: 0.997 - ETA: 9s - loss: 0.0188 - accuracy: 0.997 - ETA: 7s - loss: 0.0193 - accuracy: 0.99 - ETA: 6s - loss: 0.0192 - accuracy: 0.99 - ETA: 5s - loss: 0.0192 - accuracy: 0.99 - ETA: 3s - loss: 0.0193 - accuracy: 0.99 - ETA: 2s - loss: 0.0193 - accuracy: 0.99 - ETA: 1s - loss: 0.0193 - accuracy: 0.99 - 227s 12ms/step - loss: 0.0193 - accuracy: 0.9968 - val_loss: 0.9364 - val_accuracy: 0.8016\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:26 - loss: 0.0062 - accuracy: 1.00 - ETA: 3:33 - loss: 0.0061 - accuracy: 1.00 - ETA: 3:30 - loss: 0.0085 - accuracy: 1.00 - ETA: 3:28 - loss: 0.0127 - accuracy: 0.99 - ETA: 3:27 - loss: 0.0138 - accuracy: 0.99 - ETA: 3:25 - loss: 0.0137 - accuracy: 0.99 - ETA: 3:24 - loss: 0.0134 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0149 - accuracy: 0.99 - ETA: 3:19 - loss: 0.0169 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0163 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0159 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0156 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0157 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0153 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0146 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0151 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0149 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0147 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0146 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0144 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0150 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0158 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0158 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0156 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0154 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0153 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0149 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0154 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0152 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0149 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0155 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0153 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0153 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0152 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0153 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0152 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0150 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0153 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0152 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0152 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0150 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0152 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0157 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0157 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0159 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0162 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0161 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0161 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0161 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0162 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0165 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0165 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0164 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0163 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0162 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0163 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0164 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0164 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0170 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0168 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0168 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0168 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0167 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0167 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0168 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0168 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0170 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0170 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0172 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0171 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0172 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0174 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0174 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0172 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0174 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0174 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0175 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0177 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0176 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0175 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0177 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0180 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0180 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0179 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0179 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0181 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0180 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0181 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0181 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0184 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0184 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0184 - accuracy: 0.99 - ETA: 59s - loss: 0.0186 - accuracy: 0.9966 - ETA: 57s - loss: 0.0185 - accuracy: 0.996 - ETA: 56s - loss: 0.0184 - accuracy: 0.996 - ETA: 55s - loss: 0.0185 - accuracy: 0.996 - ETA: 53s - loss: 0.0184 - accuracy: 0.996 - ETA: 52s - loss: 0.0184 - accuracy: 0.996 - ETA: 51s - loss: 0.0183 - accuracy: 0.996 - ETA: 49s - loss: 0.0184 - accuracy: 0.996 - ETA: 48s - loss: 0.0183 - accuracy: 0.996 - ETA: 47s - loss: 0.0183 - accuracy: 0.996 - ETA: 45s - loss: 0.0182 - accuracy: 0.996 - ETA: 44s - loss: 0.0186 - accuracy: 0.996 - ETA: 42s - loss: 0.0185 - accuracy: 0.996 - ETA: 41s - loss: 0.0186 - accuracy: 0.996 - ETA: 40s - loss: 0.0186 - accuracy: 0.996 - ETA: 38s - loss: 0.0190 - accuracy: 0.996 - ETA: 37s - loss: 0.0190 - accuracy: 0.996 - ETA: 36s - loss: 0.0189 - accuracy: 0.996 - ETA: 34s - loss: 0.0188 - accuracy: 0.996 - ETA: 33s - loss: 0.0192 - accuracy: 0.996 - ETA: 32s - loss: 0.0191 - accuracy: 0.996 - ETA: 30s - loss: 0.0193 - accuracy: 0.996 - ETA: 29s - loss: 0.0193 - accuracy: 0.996 - ETA: 28s - loss: 0.0192 - accuracy: 0.996 - ETA: 26s - loss: 0.0193 - accuracy: 0.996 - ETA: 25s - loss: 0.0192 - accuracy: 0.996 - ETA: 24s - loss: 0.0192 - accuracy: 0.996 - ETA: 22s - loss: 0.0191 - accuracy: 0.996 - ETA: 21s - loss: 0.0191 - accuracy: 0.996 - ETA: 20s - loss: 0.0194 - accuracy: 0.996 - ETA: 18s - loss: 0.0197 - accuracy: 0.996 - ETA: 17s - loss: 0.0197 - accuracy: 0.996 - ETA: 15s - loss: 0.0197 - accuracy: 0.996 - ETA: 14s - loss: 0.0198 - accuracy: 0.996 - ETA: 13s - loss: 0.0198 - accuracy: 0.996 - ETA: 11s - loss: 0.0198 - accuracy: 0.996 - ETA: 10s - loss: 0.0198 - accuracy: 0.996 - ETA: 9s - loss: 0.0197 - accuracy: 0.996 - ETA: 7s - loss: 0.0197 - accuracy: 0.99 - ETA: 6s - loss: 0.0198 - accuracy: 0.99 - ETA: 5s - loss: 0.0197 - accuracy: 0.99 - ETA: 3s - loss: 0.0197 - accuracy: 0.99 - ETA: 2s - loss: 0.0196 - accuracy: 0.99 - ETA: 1s - loss: 0.0196 - accuracy: 0.99 - 226s 12ms/step - loss: 0.0196 - accuracy: 0.9963 - val_loss: 0.9246 - val_accuracy: 0.8012\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:25 - loss: 0.0123 - accuracy: 0.99 - ETA: 3:22 - loss: 0.0133 - accuracy: 0.99 - ETA: 3:21 - loss: 0.0149 - accuracy: 0.99 - ETA: 3:22 - loss: 0.0174 - accuracy: 0.99 - ETA: 3:19 - loss: 0.0158 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0154 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0168 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0168 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0174 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0167 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0169 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0171 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0168 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0168 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0168 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0173 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0169 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0178 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0180 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0182 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0177 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0186 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0197 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0192 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0190 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0188 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0189 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0184 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0182 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0178 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0178 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0180 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0177 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0180 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0182 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0179 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0182 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0179 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0182 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0179 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0179 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0176 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0182 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0183 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0182 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0186 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0188 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0186 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0186 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0184 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0185 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0184 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0182 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0183 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0182 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0181 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0181 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0180 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0178 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0177 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0175 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0175 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0178 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0177 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0176 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0176 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0175 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0174 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0172 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0172 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0172 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0171 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0171 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0171 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0171 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0174 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0173 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0175 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0175 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0175 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0174 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0178 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0178 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0178 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0177 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0176 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0176 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0177 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0175 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0176 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0181 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0186 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0184 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0184 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0183 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0181 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0184 - accuracy: 0.99 - ETA: 58s - loss: 0.0184 - accuracy: 0.9961 - ETA: 57s - loss: 0.0184 - accuracy: 0.996 - ETA: 56s - loss: 0.0183 - accuracy: 0.996 - ETA: 54s - loss: 0.0183 - accuracy: 0.996 - ETA: 53s - loss: 0.0183 - accuracy: 0.996 - ETA: 51s - loss: 0.0183 - accuracy: 0.996 - ETA: 50s - loss: 0.0183 - accuracy: 0.996 - ETA: 49s - loss: 0.0182 - accuracy: 0.996 - ETA: 47s - loss: 0.0181 - accuracy: 0.996 - ETA: 46s - loss: 0.0181 - accuracy: 0.996 - ETA: 45s - loss: 0.0180 - accuracy: 0.996 - ETA: 43s - loss: 0.0179 - accuracy: 0.996 - ETA: 42s - loss: 0.0181 - accuracy: 0.996 - ETA: 41s - loss: 0.0182 - accuracy: 0.996 - ETA: 39s - loss: 0.0182 - accuracy: 0.996 - ETA: 38s - loss: 0.0181 - accuracy: 0.996 - ETA: 37s - loss: 0.0181 - accuracy: 0.996 - ETA: 35s - loss: 0.0183 - accuracy: 0.996 - ETA: 34s - loss: 0.0183 - accuracy: 0.996 - ETA: 33s - loss: 0.0182 - accuracy: 0.996 - ETA: 31s - loss: 0.0183 - accuracy: 0.996 - ETA: 30s - loss: 0.0182 - accuracy: 0.996 - ETA: 29s - loss: 0.0181 - accuracy: 0.996 - ETA: 27s - loss: 0.0182 - accuracy: 0.996 - ETA: 26s - loss: 0.0181 - accuracy: 0.996 - ETA: 25s - loss: 0.0182 - accuracy: 0.996 - ETA: 23s - loss: 0.0182 - accuracy: 0.996 - ETA: 22s - loss: 0.0182 - accuracy: 0.996 - ETA: 21s - loss: 0.0181 - accuracy: 0.996 - ETA: 19s - loss: 0.0180 - accuracy: 0.996 - ETA: 18s - loss: 0.0181 - accuracy: 0.996 - ETA: 17s - loss: 0.0181 - accuracy: 0.996 - ETA: 15s - loss: 0.0181 - accuracy: 0.996 - ETA: 14s - loss: 0.0180 - accuracy: 0.996 - ETA: 13s - loss: 0.0179 - accuracy: 0.996 - ETA: 11s - loss: 0.0179 - accuracy: 0.996 - ETA: 10s - loss: 0.0179 - accuracy: 0.996 - ETA: 9s - loss: 0.0178 - accuracy: 0.996 - ETA: 7s - loss: 0.0178 - accuracy: 0.99 - ETA: 6s - loss: 0.0178 - accuracy: 0.99 - ETA: 5s - loss: 0.0178 - accuracy: 0.99 - ETA: 3s - loss: 0.0178 - accuracy: 0.99 - ETA: 2s - loss: 0.0177 - accuracy: 0.99 - ETA: 1s - loss: 0.0176 - accuracy: 0.99 - 225s 12ms/step - loss: 0.0176 - accuracy: 0.9963 - val_loss: 0.9448 - val_accuracy: 0.7995\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:02 - loss: 0.0157 - accuracy: 1.00 - ETA: 3:20 - loss: 0.0117 - accuracy: 1.00 - ETA: 3:19 - loss: 0.0130 - accuracy: 1.00 - ETA: 3:19 - loss: 0.0314 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0272 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0248 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0245 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0230 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0242 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0226 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0222 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0207 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0201 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0197 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0200 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0196 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0198 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0192 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0185 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0183 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0180 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0175 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0176 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0171 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0172 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0169 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0166 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0164 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0159 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0157 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0153 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0157 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0160 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0163 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0163 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0162 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0161 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0157 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0155 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0156 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0155 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0152 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0150 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0148 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0147 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0146 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0145 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0144 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0145 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0144 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0143 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0143 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0142 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0144 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0143 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0142 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0142 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0140 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0143 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0143 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0143 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0142 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0144 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0142 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0143 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0142 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0143 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0143 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0142 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0135 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0135 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0134 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0135 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0135 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0135 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0134 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0134 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0141 - accuracy: 0.99 - ETA: 58s - loss: 0.0141 - accuracy: 0.9979 - ETA: 57s - loss: 0.0142 - accuracy: 0.997 - ETA: 56s - loss: 0.0141 - accuracy: 0.997 - ETA: 54s - loss: 0.0141 - accuracy: 0.997 - ETA: 53s - loss: 0.0141 - accuracy: 0.997 - ETA: 52s - loss: 0.0140 - accuracy: 0.997 - ETA: 50s - loss: 0.0140 - accuracy: 0.997 - ETA: 49s - loss: 0.0140 - accuracy: 0.997 - ETA: 48s - loss: 0.0139 - accuracy: 0.998 - ETA: 46s - loss: 0.0139 - accuracy: 0.998 - ETA: 45s - loss: 0.0139 - accuracy: 0.998 - ETA: 44s - loss: 0.0138 - accuracy: 0.998 - ETA: 42s - loss: 0.0139 - accuracy: 0.998 - ETA: 41s - loss: 0.0138 - accuracy: 0.998 - ETA: 40s - loss: 0.0138 - accuracy: 0.998 - ETA: 38s - loss: 0.0138 - accuracy: 0.998 - ETA: 37s - loss: 0.0138 - accuracy: 0.998 - ETA: 36s - loss: 0.0139 - accuracy: 0.998 - ETA: 34s - loss: 0.0139 - accuracy: 0.998 - ETA: 33s - loss: 0.0138 - accuracy: 0.998 - ETA: 32s - loss: 0.0137 - accuracy: 0.998 - ETA: 30s - loss: 0.0137 - accuracy: 0.998 - ETA: 29s - loss: 0.0137 - accuracy: 0.998 - ETA: 28s - loss: 0.0137 - accuracy: 0.998 - ETA: 26s - loss: 0.0136 - accuracy: 0.998 - ETA: 25s - loss: 0.0141 - accuracy: 0.998 - ETA: 24s - loss: 0.0143 - accuracy: 0.997 - ETA: 22s - loss: 0.0142 - accuracy: 0.998 - ETA: 21s - loss: 0.0142 - accuracy: 0.998 - ETA: 20s - loss: 0.0142 - accuracy: 0.998 - ETA: 18s - loss: 0.0142 - accuracy: 0.998 - ETA: 17s - loss: 0.0142 - accuracy: 0.998 - ETA: 15s - loss: 0.0142 - accuracy: 0.998 - ETA: 14s - loss: 0.0141 - accuracy: 0.998 - ETA: 13s - loss: 0.0141 - accuracy: 0.998 - ETA: 11s - loss: 0.0140 - accuracy: 0.998 - ETA: 10s - loss: 0.0140 - accuracy: 0.998 - ETA: 9s - loss: 0.0141 - accuracy: 0.998 - ETA: 7s - loss: 0.0140 - accuracy: 0.99 - ETA: 6s - loss: 0.0140 - accuracy: 0.99 - ETA: 5s - loss: 0.0140 - accuracy: 0.99 - ETA: 3s - loss: 0.0140 - accuracy: 0.99 - ETA: 2s - loss: 0.0139 - accuracy: 0.99 - ETA: 1s - loss: 0.0139 - accuracy: 0.99 - 227s 12ms/step - loss: 0.0140 - accuracy: 0.9980 - val_loss: 0.9454 - val_accuracy: 0.7993\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:23 - loss: 0.0111 - accuracy: 1.00 - ETA: 3:13 - loss: 0.0179 - accuracy: 0.99 - ETA: 3:17 - loss: 0.0133 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0138 - accuracy: 0.99 - ETA: 3:15 - loss: 0.0182 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0164 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0183 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0172 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0161 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0154 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0150 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0142 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0149 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0154 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0158 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0153 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0156 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0146 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0144 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0144 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0143 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0144 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0146 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0144 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0140 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0149 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0146 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0151 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0150 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0147 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0146 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0148 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0147 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0145 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0143 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0140 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0141 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0143 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0142 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0140 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0140 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0139 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0137 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0136 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0136 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0135 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0135 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0134 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0137 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0135 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0135 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0135 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0134 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0132 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0133 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0141 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0140 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0140 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0141 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0140 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0144 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0143 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0144 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0145 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0145 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0144 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0144 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0144 - accuracy: 0.99 - ETA: 59s - loss: 0.0144 - accuracy: 0.9974 - ETA: 57s - loss: 0.0143 - accuracy: 0.997 - ETA: 56s - loss: 0.0144 - accuracy: 0.997 - ETA: 54s - loss: 0.0144 - accuracy: 0.997 - ETA: 53s - loss: 0.0144 - accuracy: 0.997 - ETA: 52s - loss: 0.0142 - accuracy: 0.997 - ETA: 50s - loss: 0.0143 - accuracy: 0.997 - ETA: 49s - loss: 0.0142 - accuracy: 0.997 - ETA: 48s - loss: 0.0142 - accuracy: 0.997 - ETA: 46s - loss: 0.0141 - accuracy: 0.997 - ETA: 45s - loss: 0.0142 - accuracy: 0.997 - ETA: 44s - loss: 0.0142 - accuracy: 0.997 - ETA: 42s - loss: 0.0141 - accuracy: 0.997 - ETA: 41s - loss: 0.0141 - accuracy: 0.997 - ETA: 40s - loss: 0.0141 - accuracy: 0.997 - ETA: 38s - loss: 0.0142 - accuracy: 0.997 - ETA: 37s - loss: 0.0142 - accuracy: 0.997 - ETA: 36s - loss: 0.0141 - accuracy: 0.997 - ETA: 34s - loss: 0.0141 - accuracy: 0.997 - ETA: 33s - loss: 0.0141 - accuracy: 0.997 - ETA: 32s - loss: 0.0141 - accuracy: 0.997 - ETA: 30s - loss: 0.0140 - accuracy: 0.997 - ETA: 29s - loss: 0.0140 - accuracy: 0.997 - ETA: 28s - loss: 0.0139 - accuracy: 0.997 - ETA: 26s - loss: 0.0139 - accuracy: 0.997 - ETA: 25s - loss: 0.0138 - accuracy: 0.997 - ETA: 24s - loss: 0.0139 - accuracy: 0.997 - ETA: 22s - loss: 0.0139 - accuracy: 0.997 - ETA: 21s - loss: 0.0138 - accuracy: 0.997 - ETA: 20s - loss: 0.0138 - accuracy: 0.997 - ETA: 18s - loss: 0.0138 - accuracy: 0.997 - ETA: 17s - loss: 0.0138 - accuracy: 0.997 - ETA: 15s - loss: 0.0138 - accuracy: 0.997 - ETA: 14s - loss: 0.0137 - accuracy: 0.997 - ETA: 13s - loss: 0.0139 - accuracy: 0.997 - ETA: 11s - loss: 0.0139 - accuracy: 0.997 - ETA: 10s - loss: 0.0138 - accuracy: 0.997 - ETA: 9s - loss: 0.0138 - accuracy: 0.997 - ETA: 7s - loss: 0.0138 - accuracy: 0.99 - ETA: 6s - loss: 0.0138 - accuracy: 0.99 - ETA: 5s - loss: 0.0138 - accuracy: 0.99 - ETA: 3s - loss: 0.0138 - accuracy: 0.99 - ETA: 2s - loss: 0.0139 - accuracy: 0.99 - ETA: 1s - loss: 0.0138 - accuracy: 0.99 - 226s 12ms/step - loss: 0.0138 - accuracy: 0.9976 - val_loss: 0.9423 - val_accuracy: 0.7991\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:23 - loss: 0.0049 - accuracy: 1.00 - ETA: 3:23 - loss: 0.0062 - accuracy: 1.00 - ETA: 3:19 - loss: 0.0182 - accuracy: 0.99 - ETA: 3:12 - loss: 0.0150 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0216 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0194 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0212 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0191 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0183 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0174 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0162 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0167 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0164 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0157 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0159 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0151 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0147 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0143 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0147 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0145 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0144 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0140 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0138 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0138 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0141 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0140 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0140 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0139 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0136 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0134 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0135 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0134 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0133 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0132 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0131 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0132 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0132 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0130 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0128 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0130 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0130 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0130 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0128 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0128 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0129 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0127 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0127 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0126 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0127 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0127 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0127 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0126 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0126 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0126 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0128 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0127 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0126 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0125 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0126 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0129 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0129 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0128 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0132 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0131 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0130 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0129 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0129 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0130 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0132 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0131 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0130 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0130 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0129 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0129 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0128 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0128 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0139 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0138 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0135 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0136 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0135 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0135 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0135 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0134 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0134 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0134 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0133 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0133 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0133 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0132 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0133 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0133 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0132 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0132 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0133 - accuracy: 0.99 - ETA: 59s - loss: 0.0132 - accuracy: 0.9979 - ETA: 58s - loss: 0.0131 - accuracy: 0.998 - ETA: 57s - loss: 0.0132 - accuracy: 0.998 - ETA: 55s - loss: 0.0131 - accuracy: 0.998 - ETA: 54s - loss: 0.0132 - accuracy: 0.998 - ETA: 53s - loss: 0.0133 - accuracy: 0.998 - ETA: 52s - loss: 0.0132 - accuracy: 0.998 - ETA: 50s - loss: 0.0133 - accuracy: 0.998 - ETA: 49s - loss: 0.0132 - accuracy: 0.998 - ETA: 47s - loss: 0.0133 - accuracy: 0.998 - ETA: 46s - loss: 0.0134 - accuracy: 0.998 - ETA: 45s - loss: 0.0133 - accuracy: 0.998 - ETA: 43s - loss: 0.0133 - accuracy: 0.998 - ETA: 42s - loss: 0.0132 - accuracy: 0.998 - ETA: 41s - loss: 0.0131 - accuracy: 0.998 - ETA: 39s - loss: 0.0131 - accuracy: 0.998 - ETA: 38s - loss: 0.0131 - accuracy: 0.998 - ETA: 37s - loss: 0.0130 - accuracy: 0.998 - ETA: 35s - loss: 0.0131 - accuracy: 0.998 - ETA: 34s - loss: 0.0132 - accuracy: 0.998 - ETA: 33s - loss: 0.0131 - accuracy: 0.998 - ETA: 31s - loss: 0.0132 - accuracy: 0.998 - ETA: 30s - loss: 0.0131 - accuracy: 0.998 - ETA: 29s - loss: 0.0131 - accuracy: 0.998 - ETA: 27s - loss: 0.0130 - accuracy: 0.998 - ETA: 26s - loss: 0.0130 - accuracy: 0.998 - ETA: 25s - loss: 0.0129 - accuracy: 0.998 - ETA: 23s - loss: 0.0130 - accuracy: 0.998 - ETA: 22s - loss: 0.0130 - accuracy: 0.998 - ETA: 21s - loss: 0.0129 - accuracy: 0.998 - ETA: 19s - loss: 0.0132 - accuracy: 0.998 - ETA: 18s - loss: 0.0131 - accuracy: 0.998 - ETA: 17s - loss: 0.0131 - accuracy: 0.998 - ETA: 15s - loss: 0.0131 - accuracy: 0.998 - ETA: 14s - loss: 0.0130 - accuracy: 0.998 - ETA: 13s - loss: 0.0131 - accuracy: 0.998 - ETA: 11s - loss: 0.0131 - accuracy: 0.998 - ETA: 10s - loss: 0.0131 - accuracy: 0.998 - ETA: 9s - loss: 0.0132 - accuracy: 0.998 - ETA: 7s - loss: 0.0132 - accuracy: 0.99 - ETA: 6s - loss: 0.0131 - accuracy: 0.99 - ETA: 5s - loss: 0.0131 - accuracy: 0.99 - ETA: 3s - loss: 0.0131 - accuracy: 0.99 - ETA: 2s - loss: 0.0131 - accuracy: 0.99 - ETA: 1s - loss: 0.0131 - accuracy: 0.99 - 225s 12ms/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 0.9421 - val_accuracy: 0.8020\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:08 - loss: 0.0237 - accuracy: 1.00 - ETA: 3:13 - loss: 0.0213 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0153 - accuracy: 0.99 - ETA: 3:16 - loss: 0.0127 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0117 - accuracy: 0.99 - ETA: 3:12 - loss: 0.0131 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0123 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0125 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0120 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0114 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0110 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0116 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0113 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0120 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0116 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0113 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0110 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0112 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0110 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0112 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0109 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0108 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0109 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0108 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0106 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0107 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0110 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0109 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0115 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0115 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0113 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0117 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0116 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0115 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0112 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0110 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0109 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0110 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0110 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0110 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0110 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0109 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0108 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0107 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0106 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0106 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0106 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0106 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0106 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0107 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0106 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0106 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0110 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0110 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0110 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0110 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0107 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0107 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0107 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0110 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0110 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0108 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0109 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0109 - accuracy: 0.99 - ETA: 59s - loss: 0.0109 - accuracy: 0.9981 - ETA: 58s - loss: 0.0109 - accuracy: 0.998 - ETA: 57s - loss: 0.0110 - accuracy: 0.998 - ETA: 55s - loss: 0.0111 - accuracy: 0.998 - ETA: 54s - loss: 0.0112 - accuracy: 0.998 - ETA: 53s - loss: 0.0111 - accuracy: 0.998 - ETA: 52s - loss: 0.0111 - accuracy: 0.998 - ETA: 50s - loss: 0.0111 - accuracy: 0.998 - ETA: 49s - loss: 0.0111 - accuracy: 0.998 - ETA: 48s - loss: 0.0111 - accuracy: 0.998 - ETA: 46s - loss: 0.0112 - accuracy: 0.998 - ETA: 45s - loss: 0.0112 - accuracy: 0.998 - ETA: 44s - loss: 0.0114 - accuracy: 0.998 - ETA: 42s - loss: 0.0114 - accuracy: 0.998 - ETA: 41s - loss: 0.0114 - accuracy: 0.998 - ETA: 40s - loss: 0.0114 - accuracy: 0.998 - ETA: 39s - loss: 0.0113 - accuracy: 0.998 - ETA: 37s - loss: 0.0113 - accuracy: 0.998 - ETA: 36s - loss: 0.0113 - accuracy: 0.998 - ETA: 35s - loss: 0.0114 - accuracy: 0.998 - ETA: 33s - loss: 0.0114 - accuracy: 0.998 - ETA: 32s - loss: 0.0114 - accuracy: 0.998 - ETA: 31s - loss: 0.0115 - accuracy: 0.998 - ETA: 29s - loss: 0.0115 - accuracy: 0.998 - ETA: 28s - loss: 0.0114 - accuracy: 0.998 - ETA: 27s - loss: 0.0115 - accuracy: 0.998 - ETA: 25s - loss: 0.0115 - accuracy: 0.998 - ETA: 24s - loss: 0.0115 - accuracy: 0.998 - ETA: 23s - loss: 0.0115 - accuracy: 0.998 - ETA: 22s - loss: 0.0119 - accuracy: 0.998 - ETA: 20s - loss: 0.0118 - accuracy: 0.998 - ETA: 19s - loss: 0.0118 - accuracy: 0.998 - ETA: 18s - loss: 0.0118 - accuracy: 0.998 - ETA: 16s - loss: 0.0118 - accuracy: 0.998 - ETA: 15s - loss: 0.0118 - accuracy: 0.998 - ETA: 14s - loss: 0.0117 - accuracy: 0.998 - ETA: 12s - loss: 0.0118 - accuracy: 0.998 - ETA: 11s - loss: 0.0118 - accuracy: 0.998 - ETA: 10s - loss: 0.0117 - accuracy: 0.998 - ETA: 8s - loss: 0.0117 - accuracy: 0.998 - ETA: 7s - loss: 0.0117 - accuracy: 0.99 - ETA: 6s - loss: 0.0117 - accuracy: 0.99 - ETA: 5s - loss: 0.0117 - accuracy: 0.99 - ETA: 3s - loss: 0.0118 - accuracy: 0.99 - ETA: 2s - loss: 0.0119 - accuracy: 0.99 - ETA: 1s - loss: 0.0119 - accuracy: 0.99 - 220s 11ms/step - loss: 0.0119 - accuracy: 0.9980 - val_loss: 0.9419 - val_accuracy: 0.8053\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:30 - loss: 0.0029 - accuracy: 1.00 - ETA: 3:24 - loss: 0.0042 - accuracy: 1.00 - ETA: 3:15 - loss: 0.0075 - accuracy: 1.00 - ETA: 3:13 - loss: 0.0092 - accuracy: 1.00 - ETA: 3:15 - loss: 0.0092 - accuracy: 1.00 - ETA: 3:13 - loss: 0.0092 - accuracy: 1.00 - ETA: 3:09 - loss: 0.0086 - accuracy: 1.00 - ETA: 3:09 - loss: 0.0093 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0103 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0106 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0103 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0107 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0113 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0114 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0111 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0108 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0106 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0105 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0103 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0103 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0109 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0107 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0112 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0109 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0117 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0122 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0119 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0117 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0116 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0117 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0116 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0113 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0113 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0115 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0113 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0114 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0112 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0112 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0113 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0113 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0112 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0110 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0113 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0112 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0111 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0110 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0111 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0112 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0112 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0111 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0111 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0115 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0115 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0115 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0114 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0115 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0114 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0117 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0117 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0117 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0117 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0117 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0117 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0119 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0117 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0117 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0120 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0120 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0120 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0119 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0120 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0120 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0119 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0119 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0119 - accuracy: 0.99 - ETA: 59s - loss: 0.0118 - accuracy: 0.9979 - ETA: 58s - loss: 0.0117 - accuracy: 0.997 - ETA: 57s - loss: 0.0119 - accuracy: 0.997 - ETA: 55s - loss: 0.0118 - accuracy: 0.997 - ETA: 54s - loss: 0.0118 - accuracy: 0.997 - ETA: 53s - loss: 0.0118 - accuracy: 0.997 - ETA: 51s - loss: 0.0119 - accuracy: 0.997 - ETA: 50s - loss: 0.0121 - accuracy: 0.997 - ETA: 49s - loss: 0.0120 - accuracy: 0.997 - ETA: 47s - loss: 0.0122 - accuracy: 0.997 - ETA: 46s - loss: 0.0122 - accuracy: 0.997 - ETA: 45s - loss: 0.0122 - accuracy: 0.997 - ETA: 43s - loss: 0.0123 - accuracy: 0.997 - ETA: 42s - loss: 0.0123 - accuracy: 0.997 - ETA: 41s - loss: 0.0123 - accuracy: 0.997 - ETA: 39s - loss: 0.0122 - accuracy: 0.997 - ETA: 38s - loss: 0.0122 - accuracy: 0.997 - ETA: 37s - loss: 0.0122 - accuracy: 0.997 - ETA: 35s - loss: 0.0121 - accuracy: 0.997 - ETA: 34s - loss: 0.0120 - accuracy: 0.997 - ETA: 33s - loss: 0.0120 - accuracy: 0.997 - ETA: 31s - loss: 0.0120 - accuracy: 0.997 - ETA: 30s - loss: 0.0120 - accuracy: 0.997 - ETA: 29s - loss: 0.0120 - accuracy: 0.997 - ETA: 27s - loss: 0.0120 - accuracy: 0.997 - ETA: 26s - loss: 0.0121 - accuracy: 0.997 - ETA: 25s - loss: 0.0120 - accuracy: 0.997 - ETA: 23s - loss: 0.0123 - accuracy: 0.997 - ETA: 22s - loss: 0.0123 - accuracy: 0.997 - ETA: 21s - loss: 0.0122 - accuracy: 0.997 - ETA: 19s - loss: 0.0122 - accuracy: 0.997 - ETA: 18s - loss: 0.0122 - accuracy: 0.997 - ETA: 17s - loss: 0.0121 - accuracy: 0.997 - ETA: 15s - loss: 0.0121 - accuracy: 0.997 - ETA: 14s - loss: 0.0120 - accuracy: 0.997 - ETA: 13s - loss: 0.0120 - accuracy: 0.997 - ETA: 11s - loss: 0.0120 - accuracy: 0.997 - ETA: 10s - loss: 0.0120 - accuracy: 0.997 - ETA: 9s - loss: 0.0119 - accuracy: 0.997 - ETA: 7s - loss: 0.0119 - accuracy: 0.99 - ETA: 6s - loss: 0.0119 - accuracy: 0.99 - ETA: 5s - loss: 0.0119 - accuracy: 0.99 - ETA: 3s - loss: 0.0119 - accuracy: 0.99 - ETA: 2s - loss: 0.0118 - accuracy: 0.99 - ETA: 1s - loss: 0.0118 - accuracy: 0.99 - 223s 12ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.9198 - val_accuracy: 0.8053\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:29 - loss: 0.0039 - accuracy: 1.00 - ETA: 3:30 - loss: 0.0044 - accuracy: 1.00 - ETA: 3:26 - loss: 0.0044 - accuracy: 1.00 - ETA: 3:25 - loss: 0.0049 - accuracy: 1.00 - ETA: 3:22 - loss: 0.0051 - accuracy: 1.00 - ETA: 3:21 - loss: 0.0057 - accuracy: 1.00 - ETA: 3:19 - loss: 0.0061 - accuracy: 1.00 - ETA: 3:15 - loss: 0.0063 - accuracy: 1.00 - ETA: 3:13 - loss: 0.0061 - accuracy: 1.00 - ETA: 3:10 - loss: 0.0061 - accuracy: 1.00 - ETA: 3:10 - loss: 0.0067 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0069 - accuracy: 1.00 - ETA: 3:06 - loss: 0.0072 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0070 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0072 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0070 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0071 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0071 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0070 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0068 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0073 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0072 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0075 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0075 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0075 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0078 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0082 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0084 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0083 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0084 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0084 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0083 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0081 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0081 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0081 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0082 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0081 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0080 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0080 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0080 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0078 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0078 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0077 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0082 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0083 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0082 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0084 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0084 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0085 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0085 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0087 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0087 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0087 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0086 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0086 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0094 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0098 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0098 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0098 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0098 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0104 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0101 - accuracy: 0.99 - ETA: 59s - loss: 0.0101 - accuracy: 0.9985 - ETA: 58s - loss: 0.0102 - accuracy: 0.998 - ETA: 56s - loss: 0.0102 - accuracy: 0.998 - ETA: 55s - loss: 0.0102 - accuracy: 0.998 - ETA: 54s - loss: 0.0102 - accuracy: 0.998 - ETA: 52s - loss: 0.0102 - accuracy: 0.998 - ETA: 51s - loss: 0.0102 - accuracy: 0.998 - ETA: 50s - loss: 0.0102 - accuracy: 0.998 - ETA: 48s - loss: 0.0102 - accuracy: 0.998 - ETA: 47s - loss: 0.0102 - accuracy: 0.998 - ETA: 46s - loss: 0.0102 - accuracy: 0.998 - ETA: 44s - loss: 0.0102 - accuracy: 0.998 - ETA: 43s - loss: 0.0101 - accuracy: 0.998 - ETA: 42s - loss: 0.0102 - accuracy: 0.998 - ETA: 40s - loss: 0.0103 - accuracy: 0.998 - ETA: 39s - loss: 0.0103 - accuracy: 0.998 - ETA: 38s - loss: 0.0104 - accuracy: 0.998 - ETA: 36s - loss: 0.0104 - accuracy: 0.998 - ETA: 35s - loss: 0.0105 - accuracy: 0.998 - ETA: 34s - loss: 0.0104 - accuracy: 0.998 - ETA: 32s - loss: 0.0105 - accuracy: 0.998 - ETA: 31s - loss: 0.0104 - accuracy: 0.998 - ETA: 30s - loss: 0.0104 - accuracy: 0.998 - ETA: 28s - loss: 0.0103 - accuracy: 0.998 - ETA: 27s - loss: 0.0104 - accuracy: 0.998 - ETA: 26s - loss: 0.0103 - accuracy: 0.998 - ETA: 24s - loss: 0.0103 - accuracy: 0.998 - ETA: 23s - loss: 0.0103 - accuracy: 0.998 - ETA: 22s - loss: 0.0103 - accuracy: 0.998 - ETA: 20s - loss: 0.0102 - accuracy: 0.998 - ETA: 19s - loss: 0.0103 - accuracy: 0.998 - ETA: 18s - loss: 0.0102 - accuracy: 0.998 - ETA: 17s - loss: 0.0103 - accuracy: 0.998 - ETA: 15s - loss: 0.0104 - accuracy: 0.998 - ETA: 14s - loss: 0.0104 - accuracy: 0.998 - ETA: 13s - loss: 0.0103 - accuracy: 0.998 - ETA: 11s - loss: 0.0105 - accuracy: 0.998 - ETA: 10s - loss: 0.0105 - accuracy: 0.998 - ETA: 9s - loss: 0.0105 - accuracy: 0.998 - ETA: 7s - loss: 0.0107 - accuracy: 0.99 - ETA: 6s - loss: 0.0106 - accuracy: 0.99 - ETA: 5s - loss: 0.0106 - accuracy: 0.99 - ETA: 3s - loss: 0.0106 - accuracy: 0.99 - ETA: 2s - loss: 0.0106 - accuracy: 0.99 - ETA: 1s - loss: 0.0106 - accuracy: 0.99 - 222s 12ms/step - loss: 0.0106 - accuracy: 0.9981 - val_loss: 0.9444 - val_accuracy: 0.8058\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:42 - loss: 0.0054 - accuracy: 1.00 - ETA: 3:30 - loss: 0.0052 - accuracy: 1.00 - ETA: 3:22 - loss: 0.0054 - accuracy: 1.00 - ETA: 3:20 - loss: 0.0049 - accuracy: 1.00 - ETA: 3:18 - loss: 0.0050 - accuracy: 1.00 - ETA: 3:16 - loss: 0.0059 - accuracy: 1.00 - ETA: 3:16 - loss: 0.0068 - accuracy: 1.00 - ETA: 3:13 - loss: 0.0068 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0076 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0074 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0101 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0101 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0114 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0112 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0107 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0104 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0099 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0105 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0103 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0100 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0099 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0097 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0100 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0099 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0098 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0096 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0090 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0091 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0087 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0087 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0087 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0087 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0086 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0086 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0098 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0097 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0104 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0104 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0104 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0104 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0103 - accuracy: 0.99 - ETA: 59s - loss: 0.0103 - accuracy: 0.9981 - ETA: 57s - loss: 0.0103 - accuracy: 0.998 - ETA: 56s - loss: 0.0103 - accuracy: 0.998 - ETA: 55s - loss: 0.0102 - accuracy: 0.998 - ETA: 53s - loss: 0.0101 - accuracy: 0.998 - ETA: 52s - loss: 0.0101 - accuracy: 0.998 - ETA: 51s - loss: 0.0102 - accuracy: 0.998 - ETA: 49s - loss: 0.0102 - accuracy: 0.998 - ETA: 48s - loss: 0.0102 - accuracy: 0.998 - ETA: 47s - loss: 0.0102 - accuracy: 0.998 - ETA: 45s - loss: 0.0102 - accuracy: 0.998 - ETA: 44s - loss: 0.0102 - accuracy: 0.998 - ETA: 42s - loss: 0.0102 - accuracy: 0.998 - ETA: 41s - loss: 0.0101 - accuracy: 0.998 - ETA: 40s - loss: 0.0102 - accuracy: 0.998 - ETA: 38s - loss: 0.0101 - accuracy: 0.998 - ETA: 37s - loss: 0.0102 - accuracy: 0.998 - ETA: 36s - loss: 0.0102 - accuracy: 0.998 - ETA: 34s - loss: 0.0101 - accuracy: 0.998 - ETA: 33s - loss: 0.0100 - accuracy: 0.998 - ETA: 32s - loss: 0.0100 - accuracy: 0.998 - ETA: 30s - loss: 0.0100 - accuracy: 0.998 - ETA: 29s - loss: 0.0100 - accuracy: 0.998 - ETA: 28s - loss: 0.0100 - accuracy: 0.998 - ETA: 26s - loss: 0.0102 - accuracy: 0.998 - ETA: 25s - loss: 0.0102 - accuracy: 0.998 - ETA: 24s - loss: 0.0102 - accuracy: 0.998 - ETA: 22s - loss: 0.0102 - accuracy: 0.998 - ETA: 21s - loss: 0.0102 - accuracy: 0.998 - ETA: 20s - loss: 0.0102 - accuracy: 0.998 - ETA: 18s - loss: 0.0102 - accuracy: 0.998 - ETA: 17s - loss: 0.0102 - accuracy: 0.998 - ETA: 16s - loss: 0.0101 - accuracy: 0.998 - ETA: 14s - loss: 0.0101 - accuracy: 0.998 - ETA: 13s - loss: 0.0101 - accuracy: 0.998 - ETA: 11s - loss: 0.0100 - accuracy: 0.998 - ETA: 10s - loss: 0.0101 - accuracy: 0.998 - ETA: 9s - loss: 0.0101 - accuracy: 0.998 - ETA: 7s - loss: 0.0102 - accuracy: 0.99 - ETA: 6s - loss: 0.0103 - accuracy: 0.99 - ETA: 5s - loss: 0.0103 - accuracy: 0.99 - ETA: 3s - loss: 0.0102 - accuracy: 0.99 - ETA: 2s - loss: 0.0102 - accuracy: 0.99 - ETA: 1s - loss: 0.0102 - accuracy: 0.99 - 227s 12ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 0.9510 - val_accuracy: 0.8031\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:18 - loss: 0.0044 - accuracy: 1.00 - ETA: 3:18 - loss: 0.0048 - accuracy: 1.00 - ETA: 3:16 - loss: 0.0064 - accuracy: 1.00 - ETA: 3:16 - loss: 0.0066 - accuracy: 1.00 - ETA: 3:12 - loss: 0.0061 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0063 - accuracy: 1.00 - ETA: 3:09 - loss: 0.0061 - accuracy: 1.00 - ETA: 3:07 - loss: 0.0064 - accuracy: 1.00 - ETA: 3:06 - loss: 0.0072 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0078 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0078 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0081 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0086 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0093 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0101 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0098 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0097 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0090 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0091 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0096 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0091 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0091 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0090 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0090 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0091 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0090 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0091 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0090 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0096 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0094 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0094 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0094 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0094 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0094 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0094 - accuracy: 0.99 - ETA: 59s - loss: 0.0094 - accuracy: 0.9985 - ETA: 57s - loss: 0.0094 - accuracy: 0.998 - ETA: 56s - loss: 0.0095 - accuracy: 0.998 - ETA: 55s - loss: 0.0094 - accuracy: 0.998 - ETA: 53s - loss: 0.0094 - accuracy: 0.998 - ETA: 52s - loss: 0.0094 - accuracy: 0.998 - ETA: 51s - loss: 0.0093 - accuracy: 0.998 - ETA: 49s - loss: 0.0093 - accuracy: 0.998 - ETA: 48s - loss: 0.0093 - accuracy: 0.998 - ETA: 47s - loss: 0.0093 - accuracy: 0.998 - ETA: 45s - loss: 0.0093 - accuracy: 0.998 - ETA: 44s - loss: 0.0093 - accuracy: 0.998 - ETA: 43s - loss: 0.0092 - accuracy: 0.998 - ETA: 41s - loss: 0.0092 - accuracy: 0.998 - ETA: 40s - loss: 0.0093 - accuracy: 0.998 - ETA: 39s - loss: 0.0092 - accuracy: 0.998 - ETA: 37s - loss: 0.0092 - accuracy: 0.998 - ETA: 36s - loss: 0.0091 - accuracy: 0.998 - ETA: 35s - loss: 0.0091 - accuracy: 0.998 - ETA: 33s - loss: 0.0093 - accuracy: 0.998 - ETA: 32s - loss: 0.0092 - accuracy: 0.998 - ETA: 30s - loss: 0.0095 - accuracy: 0.998 - ETA: 29s - loss: 0.0095 - accuracy: 0.998 - ETA: 28s - loss: 0.0095 - accuracy: 0.998 - ETA: 26s - loss: 0.0094 - accuracy: 0.998 - ETA: 25s - loss: 0.0095 - accuracy: 0.998 - ETA: 24s - loss: 0.0095 - accuracy: 0.998 - ETA: 22s - loss: 0.0094 - accuracy: 0.998 - ETA: 21s - loss: 0.0094 - accuracy: 0.998 - ETA: 20s - loss: 0.0094 - accuracy: 0.998 - ETA: 18s - loss: 0.0094 - accuracy: 0.998 - ETA: 17s - loss: 0.0094 - accuracy: 0.998 - ETA: 15s - loss: 0.0094 - accuracy: 0.998 - ETA: 14s - loss: 0.0094 - accuracy: 0.998 - ETA: 13s - loss: 0.0094 - accuracy: 0.998 - ETA: 11s - loss: 0.0095 - accuracy: 0.998 - ETA: 10s - loss: 0.0095 - accuracy: 0.998 - ETA: 9s - loss: 0.0101 - accuracy: 0.998 - ETA: 7s - loss: 0.0101 - accuracy: 0.99 - ETA: 6s - loss: 0.0101 - accuracy: 0.99 - ETA: 5s - loss: 0.0101 - accuracy: 0.99 - ETA: 3s - loss: 0.0101 - accuracy: 0.99 - ETA: 2s - loss: 0.0101 - accuracy: 0.99 - ETA: 1s - loss: 0.0102 - accuracy: 0.99 - 225s 12ms/step - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.9602 - val_accuracy: 0.8041\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:01 - loss: 0.0044 - accuracy: 1.00 - ETA: 3:03 - loss: 0.0054 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0075 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0069 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0068 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0091 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0097 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0090 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0108 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0099 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0099 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0105 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0101 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0100 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0099 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0106 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0108 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0109 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0108 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0106 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0106 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0109 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0107 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0108 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0105 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0104 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0104 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0104 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0101 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0100 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0099 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0103 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0103 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0100 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0108 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0106 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0106 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0107 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0106 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0106 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0105 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0104 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0104 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0104 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0103 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0101 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0103 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0101 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0098 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0097 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0097 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0095 - accuracy: 0.99 - ETA: 59s - loss: 0.0095 - accuracy: 0.9982 - ETA: 57s - loss: 0.0094 - accuracy: 0.998 - ETA: 56s - loss: 0.0094 - accuracy: 0.998 - ETA: 55s - loss: 0.0094 - accuracy: 0.998 - ETA: 53s - loss: 0.0093 - accuracy: 0.998 - ETA: 52s - loss: 0.0094 - accuracy: 0.998 - ETA: 51s - loss: 0.0094 - accuracy: 0.998 - ETA: 49s - loss: 0.0095 - accuracy: 0.998 - ETA: 48s - loss: 0.0096 - accuracy: 0.997 - ETA: 47s - loss: 0.0097 - accuracy: 0.997 - ETA: 45s - loss: 0.0097 - accuracy: 0.997 - ETA: 44s - loss: 0.0097 - accuracy: 0.997 - ETA: 43s - loss: 0.0097 - accuracy: 0.997 - ETA: 41s - loss: 0.0097 - accuracy: 0.997 - ETA: 40s - loss: 0.0097 - accuracy: 0.997 - ETA: 39s - loss: 0.0097 - accuracy: 0.997 - ETA: 37s - loss: 0.0098 - accuracy: 0.997 - ETA: 36s - loss: 0.0098 - accuracy: 0.997 - ETA: 35s - loss: 0.0097 - accuracy: 0.997 - ETA: 33s - loss: 0.0097 - accuracy: 0.997 - ETA: 32s - loss: 0.0097 - accuracy: 0.998 - ETA: 31s - loss: 0.0097 - accuracy: 0.998 - ETA: 30s - loss: 0.0096 - accuracy: 0.998 - ETA: 28s - loss: 0.0096 - accuracy: 0.998 - ETA: 27s - loss: 0.0096 - accuracy: 0.998 - ETA: 26s - loss: 0.0095 - accuracy: 0.998 - ETA: 24s - loss: 0.0095 - accuracy: 0.998 - ETA: 23s - loss: 0.0095 - accuracy: 0.998 - ETA: 22s - loss: 0.0095 - accuracy: 0.998 - ETA: 20s - loss: 0.0095 - accuracy: 0.998 - ETA: 19s - loss: 0.0095 - accuracy: 0.998 - ETA: 18s - loss: 0.0096 - accuracy: 0.998 - ETA: 16s - loss: 0.0096 - accuracy: 0.998 - ETA: 15s - loss: 0.0096 - accuracy: 0.998 - ETA: 14s - loss: 0.0095 - accuracy: 0.998 - ETA: 12s - loss: 0.0095 - accuracy: 0.998 - ETA: 11s - loss: 0.0095 - accuracy: 0.998 - ETA: 10s - loss: 0.0095 - accuracy: 0.998 - ETA: 9s - loss: 0.0094 - accuracy: 0.998 - ETA: 7s - loss: 0.0094 - accuracy: 0.99 - ETA: 6s - loss: 0.0094 - accuracy: 0.99 - ETA: 5s - loss: 0.0095 - accuracy: 0.99 - ETA: 3s - loss: 0.0094 - accuracy: 0.99 - ETA: 2s - loss: 0.0097 - accuracy: 0.99 - ETA: 1s - loss: 0.0098 - accuracy: 0.99 - 221s 11ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.9590 - val_accuracy: 0.8033\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:12 - loss: 0.0037 - accuracy: 1.00 - ETA: 3:17 - loss: 0.0026 - accuracy: 1.00 - ETA: 3:17 - loss: 0.0064 - accuracy: 0.99 - ETA: 3:12 - loss: 0.0054 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0067 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0075 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0083 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0078 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0075 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0072 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0070 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0069 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0072 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0072 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0069 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0071 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0068 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0076 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0074 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0072 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0070 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0068 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0067 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0065 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0068 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0066 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0065 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0065 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0064 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0063 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0062 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0062 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0064 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0064 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0063 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0062 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0061 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0061 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0060 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0060 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0059 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0061 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0061 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0061 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0061 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0061 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0061 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0062 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0062 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0062 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0063 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0062 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0063 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0066 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0065 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0065 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0064 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0063 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0072 - accuracy: 0.99 - ETA: 59s - loss: 0.0072 - accuracy: 0.9990 - ETA: 58s - loss: 0.0072 - accuracy: 0.999 - ETA: 57s - loss: 0.0072 - accuracy: 0.999 - ETA: 55s - loss: 0.0071 - accuracy: 0.999 - ETA: 54s - loss: 0.0072 - accuracy: 0.999 - ETA: 53s - loss: 0.0073 - accuracy: 0.998 - ETA: 51s - loss: 0.0073 - accuracy: 0.998 - ETA: 50s - loss: 0.0073 - accuracy: 0.999 - ETA: 49s - loss: 0.0073 - accuracy: 0.999 - ETA: 48s - loss: 0.0073 - accuracy: 0.999 - ETA: 46s - loss: 0.0073 - accuracy: 0.999 - ETA: 45s - loss: 0.0073 - accuracy: 0.999 - ETA: 44s - loss: 0.0073 - accuracy: 0.999 - ETA: 42s - loss: 0.0072 - accuracy: 0.999 - ETA: 41s - loss: 0.0072 - accuracy: 0.999 - ETA: 40s - loss: 0.0072 - accuracy: 0.999 - ETA: 38s - loss: 0.0072 - accuracy: 0.999 - ETA: 37s - loss: 0.0072 - accuracy: 0.999 - ETA: 36s - loss: 0.0071 - accuracy: 0.999 - ETA: 35s - loss: 0.0071 - accuracy: 0.999 - ETA: 33s - loss: 0.0072 - accuracy: 0.999 - ETA: 32s - loss: 0.0072 - accuracy: 0.999 - ETA: 31s - loss: 0.0072 - accuracy: 0.999 - ETA: 29s - loss: 0.0072 - accuracy: 0.999 - ETA: 28s - loss: 0.0072 - accuracy: 0.999 - ETA: 27s - loss: 0.0072 - accuracy: 0.999 - ETA: 25s - loss: 0.0072 - accuracy: 0.999 - ETA: 24s - loss: 0.0072 - accuracy: 0.999 - ETA: 23s - loss: 0.0073 - accuracy: 0.999 - ETA: 21s - loss: 0.0073 - accuracy: 0.999 - ETA: 20s - loss: 0.0073 - accuracy: 0.999 - ETA: 19s - loss: 0.0075 - accuracy: 0.999 - ETA: 18s - loss: 0.0075 - accuracy: 0.999 - ETA: 16s - loss: 0.0075 - accuracy: 0.999 - ETA: 15s - loss: 0.0075 - accuracy: 0.999 - ETA: 14s - loss: 0.0077 - accuracy: 0.998 - ETA: 12s - loss: 0.0077 - accuracy: 0.998 - ETA: 11s - loss: 0.0079 - accuracy: 0.998 - ETA: 10s - loss: 0.0079 - accuracy: 0.998 - ETA: 8s - loss: 0.0079 - accuracy: 0.998 - ETA: 7s - loss: 0.0079 - accuracy: 0.99 - ETA: 6s - loss: 0.0078 - accuracy: 0.99 - ETA: 5s - loss: 0.0078 - accuracy: 0.99 - ETA: 3s - loss: 0.0078 - accuracy: 0.99 - ETA: 2s - loss: 0.0078 - accuracy: 0.99 - ETA: 1s - loss: 0.0078 - accuracy: 0.99 - 219s 11ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.9733 - val_accuracy: 0.8043\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:01 - loss: 0.0044 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0070 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0064 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0067 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0057 - accuracy: 1.00 - ETA: 3:13 - loss: 0.0072 - accuracy: 0.99 - ETA: 3:15 - loss: 0.0092 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0090 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0083 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0096 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0102 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0096 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0094 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0092 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0087 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0099 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0098 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0086 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0084 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0082 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0080 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0077 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0078 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0076 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0076 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0077 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0076 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0075 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0073 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0075 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0077 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0076 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0075 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0075 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0074 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0081 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0080 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0078 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0078 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0081 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0081 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0080 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0081 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0081 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0080 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0078 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0078 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0077 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0083 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0082 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0082 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0082 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0077 - accuracy: 0.99 - ETA: 59s - loss: 0.0076 - accuracy: 0.9986 - ETA: 58s - loss: 0.0076 - accuracy: 0.998 - ETA: 57s - loss: 0.0076 - accuracy: 0.998 - ETA: 56s - loss: 0.0076 - accuracy: 0.998 - ETA: 54s - loss: 0.0076 - accuracy: 0.998 - ETA: 53s - loss: 0.0076 - accuracy: 0.998 - ETA: 52s - loss: 0.0076 - accuracy: 0.998 - ETA: 50s - loss: 0.0076 - accuracy: 0.998 - ETA: 49s - loss: 0.0076 - accuracy: 0.998 - ETA: 48s - loss: 0.0079 - accuracy: 0.998 - ETA: 46s - loss: 0.0080 - accuracy: 0.998 - ETA: 45s - loss: 0.0080 - accuracy: 0.998 - ETA: 44s - loss: 0.0079 - accuracy: 0.998 - ETA: 42s - loss: 0.0080 - accuracy: 0.998 - ETA: 41s - loss: 0.0080 - accuracy: 0.998 - ETA: 40s - loss: 0.0080 - accuracy: 0.998 - ETA: 38s - loss: 0.0079 - accuracy: 0.998 - ETA: 37s - loss: 0.0079 - accuracy: 0.998 - ETA: 36s - loss: 0.0082 - accuracy: 0.998 - ETA: 35s - loss: 0.0085 - accuracy: 0.998 - ETA: 33s - loss: 0.0085 - accuracy: 0.998 - ETA: 32s - loss: 0.0086 - accuracy: 0.998 - ETA: 31s - loss: 0.0085 - accuracy: 0.998 - ETA: 29s - loss: 0.0086 - accuracy: 0.998 - ETA: 28s - loss: 0.0086 - accuracy: 0.998 - ETA: 27s - loss: 0.0085 - accuracy: 0.998 - ETA: 25s - loss: 0.0085 - accuracy: 0.998 - ETA: 24s - loss: 0.0085 - accuracy: 0.998 - ETA: 23s - loss: 0.0084 - accuracy: 0.998 - ETA: 22s - loss: 0.0084 - accuracy: 0.998 - ETA: 20s - loss: 0.0084 - accuracy: 0.998 - ETA: 19s - loss: 0.0084 - accuracy: 0.998 - ETA: 18s - loss: 0.0084 - accuracy: 0.998 - ETA: 16s - loss: 0.0084 - accuracy: 0.998 - ETA: 15s - loss: 0.0084 - accuracy: 0.998 - ETA: 14s - loss: 0.0084 - accuracy: 0.998 - ETA: 12s - loss: 0.0084 - accuracy: 0.998 - ETA: 11s - loss: 0.0085 - accuracy: 0.998 - ETA: 10s - loss: 0.0084 - accuracy: 0.998 - ETA: 8s - loss: 0.0085 - accuracy: 0.998 - ETA: 7s - loss: 0.0085 - accuracy: 0.99 - ETA: 6s - loss: 0.0085 - accuracy: 0.99 - ETA: 5s - loss: 0.0086 - accuracy: 0.99 - ETA: 3s - loss: 0.0088 - accuracy: 0.99 - ETA: 2s - loss: 0.0088 - accuracy: 0.99 - ETA: 1s - loss: 0.0088 - accuracy: 0.99 - 220s 11ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.9451 - val_accuracy: 0.8072\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:06 - loss: 0.0140 - accuracy: 0.99 - ETA: 3:26 - loss: 0.0077 - accuracy: 0.99 - ETA: 3:26 - loss: 0.0064 - accuracy: 0.99 - ETA: 3:25 - loss: 0.0064 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0084 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0080 - accuracy: 0.99 - ETA: 3:16 - loss: 0.0075 - accuracy: 0.99 - ETA: 3:15 - loss: 0.0084 - accuracy: 0.99 - ETA: 3:12 - loss: 0.0126 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0120 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0114 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0108 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0102 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0098 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0097 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0102 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0098 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0100 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0100 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0098 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0098 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0097 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0097 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0091 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0095 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0092 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0094 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0093 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0091 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0090 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0089 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0088 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0087 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0086 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0086 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0085 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0084 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0083 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0082 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0082 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0081 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0080 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0080 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0079 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0076 - accuracy: 0.99 - ETA: 59s - loss: 0.0076 - accuracy: 0.9988 - ETA: 58s - loss: 0.0076 - accuracy: 0.998 - ETA: 57s - loss: 0.0077 - accuracy: 0.998 - ETA: 55s - loss: 0.0077 - accuracy: 0.998 - ETA: 54s - loss: 0.0076 - accuracy: 0.998 - ETA: 53s - loss: 0.0076 - accuracy: 0.998 - ETA: 51s - loss: 0.0075 - accuracy: 0.998 - ETA: 50s - loss: 0.0075 - accuracy: 0.998 - ETA: 49s - loss: 0.0075 - accuracy: 0.998 - ETA: 48s - loss: 0.0075 - accuracy: 0.998 - ETA: 46s - loss: 0.0075 - accuracy: 0.998 - ETA: 45s - loss: 0.0074 - accuracy: 0.998 - ETA: 44s - loss: 0.0074 - accuracy: 0.998 - ETA: 43s - loss: 0.0074 - accuracy: 0.998 - ETA: 41s - loss: 0.0073 - accuracy: 0.998 - ETA: 40s - loss: 0.0076 - accuracy: 0.998 - ETA: 39s - loss: 0.0075 - accuracy: 0.998 - ETA: 38s - loss: 0.0080 - accuracy: 0.998 - ETA: 37s - loss: 0.0080 - accuracy: 0.998 - ETA: 36s - loss: 0.0079 - accuracy: 0.998 - ETA: 34s - loss: 0.0080 - accuracy: 0.998 - ETA: 33s - loss: 0.0080 - accuracy: 0.998 - ETA: 32s - loss: 0.0080 - accuracy: 0.998 - ETA: 31s - loss: 0.0079 - accuracy: 0.998 - ETA: 30s - loss: 0.0079 - accuracy: 0.998 - ETA: 29s - loss: 0.0079 - accuracy: 0.998 - ETA: 27s - loss: 0.0080 - accuracy: 0.998 - ETA: 26s - loss: 0.0080 - accuracy: 0.998 - ETA: 25s - loss: 0.0080 - accuracy: 0.998 - ETA: 24s - loss: 0.0079 - accuracy: 0.998 - ETA: 23s - loss: 0.0079 - accuracy: 0.998 - ETA: 22s - loss: 0.0079 - accuracy: 0.998 - ETA: 21s - loss: 0.0080 - accuracy: 0.998 - ETA: 20s - loss: 0.0080 - accuracy: 0.998 - ETA: 19s - loss: 0.0080 - accuracy: 0.998 - ETA: 18s - loss: 0.0081 - accuracy: 0.998 - ETA: 17s - loss: 0.0081 - accuracy: 0.998 - ETA: 16s - loss: 0.0081 - accuracy: 0.998 - ETA: 15s - loss: 0.0080 - accuracy: 0.998 - ETA: 14s - loss: 0.0080 - accuracy: 0.998 - ETA: 12s - loss: 0.0080 - accuracy: 0.998 - ETA: 11s - loss: 0.0080 - accuracy: 0.998 - ETA: 10s - loss: 0.0080 - accuracy: 0.998 - ETA: 9s - loss: 0.0080 - accuracy: 0.998 - ETA: 8s - loss: 0.0081 - accuracy: 0.99 - ETA: 7s - loss: 0.0081 - accuracy: 0.99 - ETA: 6s - loss: 0.0080 - accuracy: 0.99 - ETA: 5s - loss: 0.0080 - accuracy: 0.99 - ETA: 4s - loss: 0.0080 - accuracy: 0.99 - ETA: 3s - loss: 0.0080 - accuracy: 0.99 - ETA: 2s - loss: 0.0079 - accuracy: 0.99 - ETA: 1s - loss: 0.0080 - accuracy: 0.99 - ETA: 0s - loss: 0.0081 - accuracy: 0.99 - 159s 8ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.9652 - val_accuracy: 0.8037\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:58 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0044 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0076 - accuracy: 0.99 - ETA: 59s - loss: 0.0076 - accuracy: 0.9990 - ETA: 58s - loss: 0.0075 - accuracy: 0.999 - ETA: 57s - loss: 0.0075 - accuracy: 0.999 - ETA: 56s - loss: 0.0077 - accuracy: 0.999 - ETA: 56s - loss: 0.0077 - accuracy: 0.999 - ETA: 55s - loss: 0.0077 - accuracy: 0.999 - ETA: 54s - loss: 0.0076 - accuracy: 0.999 - ETA: 53s - loss: 0.0076 - accuracy: 0.999 - ETA: 52s - loss: 0.0076 - accuracy: 0.999 - ETA: 52s - loss: 0.0075 - accuracy: 0.999 - ETA: 51s - loss: 0.0076 - accuracy: 0.999 - ETA: 50s - loss: 0.0075 - accuracy: 0.999 - ETA: 49s - loss: 0.0076 - accuracy: 0.999 - ETA: 48s - loss: 0.0076 - accuracy: 0.998 - ETA: 47s - loss: 0.0076 - accuracy: 0.998 - ETA: 47s - loss: 0.0076 - accuracy: 0.998 - ETA: 46s - loss: 0.0077 - accuracy: 0.998 - ETA: 45s - loss: 0.0076 - accuracy: 0.998 - ETA: 44s - loss: 0.0076 - accuracy: 0.998 - ETA: 44s - loss: 0.0075 - accuracy: 0.998 - ETA: 43s - loss: 0.0076 - accuracy: 0.998 - ETA: 42s - loss: 0.0076 - accuracy: 0.998 - ETA: 41s - loss: 0.0082 - accuracy: 0.998 - ETA: 41s - loss: 0.0081 - accuracy: 0.998 - ETA: 40s - loss: 0.0081 - accuracy: 0.998 - ETA: 39s - loss: 0.0081 - accuracy: 0.998 - ETA: 38s - loss: 0.0080 - accuracy: 0.998 - ETA: 37s - loss: 0.0080 - accuracy: 0.998 - ETA: 37s - loss: 0.0080 - accuracy: 0.998 - ETA: 36s - loss: 0.0083 - accuracy: 0.998 - ETA: 35s - loss: 0.0083 - accuracy: 0.998 - ETA: 34s - loss: 0.0083 - accuracy: 0.998 - ETA: 34s - loss: 0.0083 - accuracy: 0.998 - ETA: 33s - loss: 0.0082 - accuracy: 0.998 - ETA: 32s - loss: 0.0082 - accuracy: 0.998 - ETA: 31s - loss: 0.0082 - accuracy: 0.998 - ETA: 30s - loss: 0.0081 - accuracy: 0.998 - ETA: 30s - loss: 0.0081 - accuracy: 0.998 - ETA: 29s - loss: 0.0082 - accuracy: 0.998 - ETA: 28s - loss: 0.0082 - accuracy: 0.998 - ETA: 27s - loss: 0.0081 - accuracy: 0.998 - ETA: 27s - loss: 0.0081 - accuracy: 0.998 - ETA: 26s - loss: 0.0082 - accuracy: 0.998 - ETA: 25s - loss: 0.0081 - accuracy: 0.998 - ETA: 24s - loss: 0.0081 - accuracy: 0.998 - ETA: 24s - loss: 0.0081 - accuracy: 0.998 - ETA: 23s - loss: 0.0080 - accuracy: 0.998 - ETA: 22s - loss: 0.0080 - accuracy: 0.998 - ETA: 21s - loss: 0.0080 - accuracy: 0.998 - ETA: 21s - loss: 0.0080 - accuracy: 0.998 - ETA: 20s - loss: 0.0082 - accuracy: 0.998 - ETA: 19s - loss: 0.0083 - accuracy: 0.998 - ETA: 18s - loss: 0.0083 - accuracy: 0.998 - ETA: 18s - loss: 0.0083 - accuracy: 0.998 - ETA: 17s - loss: 0.0082 - accuracy: 0.998 - ETA: 16s - loss: 0.0082 - accuracy: 0.998 - ETA: 15s - loss: 0.0082 - accuracy: 0.998 - ETA: 14s - loss: 0.0081 - accuracy: 0.998 - ETA: 14s - loss: 0.0081 - accuracy: 0.998 - ETA: 13s - loss: 0.0081 - accuracy: 0.998 - ETA: 12s - loss: 0.0081 - accuracy: 0.998 - ETA: 11s - loss: 0.0080 - accuracy: 0.998 - ETA: 11s - loss: 0.0082 - accuracy: 0.998 - ETA: 10s - loss: 0.0082 - accuracy: 0.998 - ETA: 9s - loss: 0.0083 - accuracy: 0.998 - ETA: 8s - loss: 0.0083 - accuracy: 0.99 - ETA: 8s - loss: 0.0083 - accuracy: 0.99 - ETA: 7s - loss: 0.0083 - accuracy: 0.99 - ETA: 6s - loss: 0.0083 - accuracy: 0.99 - ETA: 5s - loss: 0.0083 - accuracy: 0.99 - ETA: 5s - loss: 0.0083 - accuracy: 0.99 - ETA: 4s - loss: 0.0083 - accuracy: 0.99 - ETA: 3s - loss: 0.0083 - accuracy: 0.99 - ETA: 2s - loss: 0.0083 - accuracy: 0.99 - ETA: 2s - loss: 0.0083 - accuracy: 0.99 - ETA: 1s - loss: 0.0083 - accuracy: 0.99 - ETA: 0s - loss: 0.0082 - accuracy: 0.99 - 124s 6ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.9534 - val_accuracy: 0.8043\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:48 - loss: 0.0082 - accuracy: 1.00 - ETA: 1:53 - loss: 0.0065 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0112 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0105 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0099 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0084 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0087 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0083 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0070 - accuracy: 0.99 - ETA: 59s - loss: 0.0070 - accuracy: 0.9990 - ETA: 59s - loss: 0.0069 - accuracy: 0.999 - ETA: 58s - loss: 0.0069 - accuracy: 0.999 - ETA: 57s - loss: 0.0069 - accuracy: 0.999 - ETA: 56s - loss: 0.0068 - accuracy: 0.999 - ETA: 56s - loss: 0.0068 - accuracy: 0.999 - ETA: 55s - loss: 0.0071 - accuracy: 0.999 - ETA: 54s - loss: 0.0071 - accuracy: 0.999 - ETA: 54s - loss: 0.0071 - accuracy: 0.999 - ETA: 53s - loss: 0.0070 - accuracy: 0.999 - ETA: 52s - loss: 0.0070 - accuracy: 0.998 - ETA: 52s - loss: 0.0070 - accuracy: 0.998 - ETA: 51s - loss: 0.0070 - accuracy: 0.998 - ETA: 50s - loss: 0.0070 - accuracy: 0.999 - ETA: 50s - loss: 0.0070 - accuracy: 0.999 - ETA: 49s - loss: 0.0070 - accuracy: 0.999 - ETA: 48s - loss: 0.0073 - accuracy: 0.998 - ETA: 47s - loss: 0.0073 - accuracy: 0.998 - ETA: 47s - loss: 0.0073 - accuracy: 0.998 - ETA: 46s - loss: 0.0072 - accuracy: 0.998 - ETA: 45s - loss: 0.0072 - accuracy: 0.998 - ETA: 44s - loss: 0.0072 - accuracy: 0.999 - ETA: 44s - loss: 0.0071 - accuracy: 0.999 - ETA: 43s - loss: 0.0071 - accuracy: 0.999 - ETA: 42s - loss: 0.0071 - accuracy: 0.999 - ETA: 41s - loss: 0.0072 - accuracy: 0.998 - ETA: 41s - loss: 0.0071 - accuracy: 0.998 - ETA: 40s - loss: 0.0071 - accuracy: 0.998 - ETA: 39s - loss: 0.0072 - accuracy: 0.998 - ETA: 38s - loss: 0.0072 - accuracy: 0.998 - ETA: 38s - loss: 0.0071 - accuracy: 0.998 - ETA: 37s - loss: 0.0072 - accuracy: 0.998 - ETA: 36s - loss: 0.0072 - accuracy: 0.998 - ETA: 35s - loss: 0.0071 - accuracy: 0.998 - ETA: 35s - loss: 0.0071 - accuracy: 0.998 - ETA: 34s - loss: 0.0071 - accuracy: 0.998 - ETA: 33s - loss: 0.0071 - accuracy: 0.999 - ETA: 32s - loss: 0.0072 - accuracy: 0.998 - ETA: 32s - loss: 0.0073 - accuracy: 0.998 - ETA: 31s - loss: 0.0073 - accuracy: 0.998 - ETA: 30s - loss: 0.0072 - accuracy: 0.998 - ETA: 29s - loss: 0.0072 - accuracy: 0.998 - ETA: 29s - loss: 0.0072 - accuracy: 0.998 - ETA: 28s - loss: 0.0072 - accuracy: 0.998 - ETA: 27s - loss: 0.0072 - accuracy: 0.998 - ETA: 27s - loss: 0.0072 - accuracy: 0.998 - ETA: 26s - loss: 0.0072 - accuracy: 0.998 - ETA: 25s - loss: 0.0071 - accuracy: 0.998 - ETA: 24s - loss: 0.0071 - accuracy: 0.998 - ETA: 24s - loss: 0.0071 - accuracy: 0.998 - ETA: 23s - loss: 0.0070 - accuracy: 0.998 - ETA: 22s - loss: 0.0070 - accuracy: 0.999 - ETA: 21s - loss: 0.0072 - accuracy: 0.998 - ETA: 21s - loss: 0.0072 - accuracy: 0.998 - ETA: 20s - loss: 0.0072 - accuracy: 0.998 - ETA: 19s - loss: 0.0072 - accuracy: 0.998 - ETA: 19s - loss: 0.0073 - accuracy: 0.998 - ETA: 18s - loss: 0.0073 - accuracy: 0.998 - ETA: 17s - loss: 0.0072 - accuracy: 0.998 - ETA: 16s - loss: 0.0072 - accuracy: 0.998 - ETA: 16s - loss: 0.0072 - accuracy: 0.998 - ETA: 15s - loss: 0.0071 - accuracy: 0.998 - ETA: 14s - loss: 0.0071 - accuracy: 0.998 - ETA: 13s - loss: 0.0071 - accuracy: 0.998 - ETA: 13s - loss: 0.0071 - accuracy: 0.998 - ETA: 12s - loss: 0.0071 - accuracy: 0.999 - ETA: 11s - loss: 0.0071 - accuracy: 0.999 - ETA: 10s - loss: 0.0071 - accuracy: 0.999 - ETA: 10s - loss: 0.0071 - accuracy: 0.999 - ETA: 9s - loss: 0.0073 - accuracy: 0.998 - ETA: 8s - loss: 0.0072 - accuracy: 0.99 - ETA: 7s - loss: 0.0072 - accuracy: 0.99 - ETA: 7s - loss: 0.0072 - accuracy: 0.99 - ETA: 6s - loss: 0.0072 - accuracy: 0.99 - ETA: 5s - loss: 0.0072 - accuracy: 0.99 - ETA: 5s - loss: 0.0072 - accuracy: 0.99 - ETA: 4s - loss: 0.0072 - accuracy: 0.99 - ETA: 3s - loss: 0.0072 - accuracy: 0.99 - ETA: 2s - loss: 0.0072 - accuracy: 0.99 - ETA: 2s - loss: 0.0072 - accuracy: 0.99 - ETA: 1s - loss: 0.0072 - accuracy: 0.99 - ETA: 0s - loss: 0.0071 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.9597 - val_accuracy: 0.8064\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:56 - loss: 0.0087 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0082 - accuracy: 1.00 - ETA: 1:53 - loss: 0.0064 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0054 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0053 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0054 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0056 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0053 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0050 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0049 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0061 - accuracy: 0.99 - ETA: 59s - loss: 0.0061 - accuracy: 0.9990 - ETA: 58s - loss: 0.0061 - accuracy: 0.999 - ETA: 57s - loss: 0.0060 - accuracy: 0.999 - ETA: 57s - loss: 0.0061 - accuracy: 0.999 - ETA: 56s - loss: 0.0061 - accuracy: 0.999 - ETA: 55s - loss: 0.0060 - accuracy: 0.999 - ETA: 54s - loss: 0.0060 - accuracy: 0.999 - ETA: 53s - loss: 0.0062 - accuracy: 0.999 - ETA: 53s - loss: 0.0061 - accuracy: 0.999 - ETA: 52s - loss: 0.0063 - accuracy: 0.998 - ETA: 51s - loss: 0.0062 - accuracy: 0.998 - ETA: 50s - loss: 0.0062 - accuracy: 0.998 - ETA: 50s - loss: 0.0062 - accuracy: 0.999 - ETA: 49s - loss: 0.0061 - accuracy: 0.999 - ETA: 48s - loss: 0.0061 - accuracy: 0.999 - ETA: 48s - loss: 0.0061 - accuracy: 0.999 - ETA: 47s - loss: 0.0061 - accuracy: 0.999 - ETA: 46s - loss: 0.0061 - accuracy: 0.999 - ETA: 45s - loss: 0.0060 - accuracy: 0.999 - ETA: 45s - loss: 0.0060 - accuracy: 0.999 - ETA: 44s - loss: 0.0060 - accuracy: 0.999 - ETA: 43s - loss: 0.0060 - accuracy: 0.999 - ETA: 42s - loss: 0.0060 - accuracy: 0.999 - ETA: 42s - loss: 0.0060 - accuracy: 0.999 - ETA: 41s - loss: 0.0059 - accuracy: 0.999 - ETA: 40s - loss: 0.0059 - accuracy: 0.999 - ETA: 40s - loss: 0.0059 - accuracy: 0.999 - ETA: 39s - loss: 0.0059 - accuracy: 0.999 - ETA: 38s - loss: 0.0059 - accuracy: 0.999 - ETA: 37s - loss: 0.0060 - accuracy: 0.999 - ETA: 37s - loss: 0.0060 - accuracy: 0.999 - ETA: 36s - loss: 0.0060 - accuracy: 0.999 - ETA: 35s - loss: 0.0060 - accuracy: 0.999 - ETA: 34s - loss: 0.0060 - accuracy: 0.999 - ETA: 34s - loss: 0.0060 - accuracy: 0.999 - ETA: 33s - loss: 0.0060 - accuracy: 0.999 - ETA: 32s - loss: 0.0059 - accuracy: 0.999 - ETA: 31s - loss: 0.0060 - accuracy: 0.999 - ETA: 31s - loss: 0.0061 - accuracy: 0.999 - ETA: 30s - loss: 0.0060 - accuracy: 0.999 - ETA: 29s - loss: 0.0061 - accuracy: 0.999 - ETA: 29s - loss: 0.0061 - accuracy: 0.999 - ETA: 28s - loss: 0.0061 - accuracy: 0.999 - ETA: 27s - loss: 0.0061 - accuracy: 0.999 - ETA: 26s - loss: 0.0061 - accuracy: 0.999 - ETA: 26s - loss: 0.0060 - accuracy: 0.999 - ETA: 25s - loss: 0.0060 - accuracy: 0.999 - ETA: 24s - loss: 0.0060 - accuracy: 0.999 - ETA: 23s - loss: 0.0060 - accuracy: 0.999 - ETA: 23s - loss: 0.0060 - accuracy: 0.999 - ETA: 22s - loss: 0.0059 - accuracy: 0.999 - ETA: 21s - loss: 0.0059 - accuracy: 0.999 - ETA: 21s - loss: 0.0059 - accuracy: 0.999 - ETA: 20s - loss: 0.0059 - accuracy: 0.999 - ETA: 19s - loss: 0.0059 - accuracy: 0.999 - ETA: 18s - loss: 0.0059 - accuracy: 0.999 - ETA: 18s - loss: 0.0058 - accuracy: 0.999 - ETA: 17s - loss: 0.0058 - accuracy: 0.999 - ETA: 16s - loss: 0.0058 - accuracy: 0.999 - ETA: 15s - loss: 0.0058 - accuracy: 0.999 - ETA: 15s - loss: 0.0058 - accuracy: 0.999 - ETA: 14s - loss: 0.0057 - accuracy: 0.999 - ETA: 13s - loss: 0.0057 - accuracy: 0.999 - ETA: 13s - loss: 0.0057 - accuracy: 0.999 - ETA: 12s - loss: 0.0058 - accuracy: 0.999 - ETA: 11s - loss: 0.0057 - accuracy: 0.999 - ETA: 10s - loss: 0.0057 - accuracy: 0.999 - ETA: 10s - loss: 0.0057 - accuracy: 0.999 - ETA: 9s - loss: 0.0058 - accuracy: 0.999 - ETA: 8s - loss: 0.0059 - accuracy: 0.99 - ETA: 7s - loss: 0.0059 - accuracy: 0.99 - ETA: 7s - loss: 0.0059 - accuracy: 0.99 - ETA: 6s - loss: 0.0059 - accuracy: 0.99 - ETA: 5s - loss: 0.0059 - accuracy: 0.99 - ETA: 5s - loss: 0.0059 - accuracy: 0.99 - ETA: 4s - loss: 0.0059 - accuracy: 0.99 - ETA: 3s - loss: 0.0059 - accuracy: 0.99 - ETA: 2s - loss: 0.0060 - accuracy: 0.99 - ETA: 2s - loss: 0.0060 - accuracy: 0.99 - ETA: 1s - loss: 0.0060 - accuracy: 0.99 - ETA: 0s - loss: 0.0060 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.9700 - val_accuracy: 0.8045\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:54 - loss: 0.0063 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0083 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0118 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0086 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0062 - accuracy: 0.99 - ETA: 59s - loss: 0.0061 - accuracy: 0.9985 - ETA: 59s - loss: 0.0061 - accuracy: 0.998 - ETA: 58s - loss: 0.0061 - accuracy: 0.998 - ETA: 57s - loss: 0.0062 - accuracy: 0.998 - ETA: 57s - loss: 0.0063 - accuracy: 0.998 - ETA: 56s - loss: 0.0062 - accuracy: 0.998 - ETA: 55s - loss: 0.0062 - accuracy: 0.998 - ETA: 54s - loss: 0.0061 - accuracy: 0.998 - ETA: 54s - loss: 0.0061 - accuracy: 0.998 - ETA: 53s - loss: 0.0061 - accuracy: 0.998 - ETA: 52s - loss: 0.0063 - accuracy: 0.998 - ETA: 52s - loss: 0.0063 - accuracy: 0.998 - ETA: 51s - loss: 0.0063 - accuracy: 0.998 - ETA: 50s - loss: 0.0063 - accuracy: 0.998 - ETA: 49s - loss: 0.0062 - accuracy: 0.998 - ETA: 49s - loss: 0.0062 - accuracy: 0.998 - ETA: 48s - loss: 0.0062 - accuracy: 0.998 - ETA: 47s - loss: 0.0062 - accuracy: 0.998 - ETA: 46s - loss: 0.0062 - accuracy: 0.998 - ETA: 46s - loss: 0.0062 - accuracy: 0.998 - ETA: 45s - loss: 0.0061 - accuracy: 0.998 - ETA: 44s - loss: 0.0062 - accuracy: 0.998 - ETA: 43s - loss: 0.0062 - accuracy: 0.998 - ETA: 43s - loss: 0.0062 - accuracy: 0.998 - ETA: 42s - loss: 0.0061 - accuracy: 0.998 - ETA: 41s - loss: 0.0062 - accuracy: 0.998 - ETA: 40s - loss: 0.0062 - accuracy: 0.998 - ETA: 40s - loss: 0.0062 - accuracy: 0.998 - ETA: 39s - loss: 0.0063 - accuracy: 0.998 - ETA: 38s - loss: 0.0068 - accuracy: 0.998 - ETA: 37s - loss: 0.0070 - accuracy: 0.998 - ETA: 37s - loss: 0.0069 - accuracy: 0.998 - ETA: 36s - loss: 0.0069 - accuracy: 0.998 - ETA: 35s - loss: 0.0069 - accuracy: 0.998 - ETA: 35s - loss: 0.0069 - accuracy: 0.998 - ETA: 34s - loss: 0.0068 - accuracy: 0.998 - ETA: 33s - loss: 0.0068 - accuracy: 0.998 - ETA: 32s - loss: 0.0067 - accuracy: 0.998 - ETA: 32s - loss: 0.0067 - accuracy: 0.998 - ETA: 31s - loss: 0.0067 - accuracy: 0.998 - ETA: 30s - loss: 0.0066 - accuracy: 0.998 - ETA: 29s - loss: 0.0066 - accuracy: 0.998 - ETA: 29s - loss: 0.0066 - accuracy: 0.998 - ETA: 28s - loss: 0.0066 - accuracy: 0.998 - ETA: 27s - loss: 0.0066 - accuracy: 0.998 - ETA: 26s - loss: 0.0066 - accuracy: 0.998 - ETA: 26s - loss: 0.0066 - accuracy: 0.998 - ETA: 25s - loss: 0.0066 - accuracy: 0.998 - ETA: 24s - loss: 0.0069 - accuracy: 0.998 - ETA: 24s - loss: 0.0069 - accuracy: 0.998 - ETA: 23s - loss: 0.0069 - accuracy: 0.998 - ETA: 22s - loss: 0.0069 - accuracy: 0.998 - ETA: 21s - loss: 0.0069 - accuracy: 0.998 - ETA: 21s - loss: 0.0068 - accuracy: 0.998 - ETA: 20s - loss: 0.0068 - accuracy: 0.998 - ETA: 19s - loss: 0.0068 - accuracy: 0.998 - ETA: 18s - loss: 0.0068 - accuracy: 0.998 - ETA: 18s - loss: 0.0069 - accuracy: 0.998 - ETA: 17s - loss: 0.0069 - accuracy: 0.998 - ETA: 16s - loss: 0.0068 - accuracy: 0.998 - ETA: 16s - loss: 0.0069 - accuracy: 0.998 - ETA: 15s - loss: 0.0068 - accuracy: 0.998 - ETA: 14s - loss: 0.0068 - accuracy: 0.998 - ETA: 13s - loss: 0.0068 - accuracy: 0.998 - ETA: 13s - loss: 0.0070 - accuracy: 0.998 - ETA: 12s - loss: 0.0071 - accuracy: 0.998 - ETA: 11s - loss: 0.0071 - accuracy: 0.998 - ETA: 10s - loss: 0.0071 - accuracy: 0.998 - ETA: 10s - loss: 0.0072 - accuracy: 0.998 - ETA: 9s - loss: 0.0072 - accuracy: 0.998 - ETA: 8s - loss: 0.0072 - accuracy: 0.99 - ETA: 7s - loss: 0.0072 - accuracy: 0.99 - ETA: 7s - loss: 0.0072 - accuracy: 0.99 - ETA: 6s - loss: 0.0072 - accuracy: 0.99 - ETA: 5s - loss: 0.0071 - accuracy: 0.99 - ETA: 5s - loss: 0.0071 - accuracy: 0.99 - ETA: 4s - loss: 0.0071 - accuracy: 0.99 - ETA: 3s - loss: 0.0071 - accuracy: 0.99 - ETA: 2s - loss: 0.0070 - accuracy: 0.99 - ETA: 2s - loss: 0.0070 - accuracy: 0.99 - ETA: 1s - loss: 0.0070 - accuracy: 0.99 - ETA: 0s - loss: 0.0070 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.9693 - val_accuracy: 0.8037\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:15 - loss: 0.0067 - accuracy: 1.00 - ETA: 1:58 - loss: 0.0057 - accuracy: 1.00 - ETA: 1:55 - loss: 0.0050 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0047 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0042 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0040 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0039 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0114 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0113 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0105 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0135 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0133 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0126 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0128 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0123 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0120 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0117 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0112 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0110 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0106 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0102 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0098 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0098 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0092 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0086 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0085 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0083 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0082 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0100 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0098 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0097 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0098 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0088 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0086 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0085 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0085 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0084 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0083 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0082 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0083 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0083 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0082 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0085 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0085 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0084 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0083 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0083 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0082 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0081 - accuracy: 0.99 - ETA: 59s - loss: 0.0080 - accuracy: 0.9990 - ETA: 59s - loss: 0.0079 - accuracy: 0.999 - ETA: 58s - loss: 0.0079 - accuracy: 0.999 - ETA: 57s - loss: 0.0078 - accuracy: 0.999 - ETA: 57s - loss: 0.0077 - accuracy: 0.999 - ETA: 56s - loss: 0.0078 - accuracy: 0.998 - ETA: 55s - loss: 0.0077 - accuracy: 0.998 - ETA: 54s - loss: 0.0076 - accuracy: 0.999 - ETA: 54s - loss: 0.0076 - accuracy: 0.999 - ETA: 53s - loss: 0.0075 - accuracy: 0.999 - ETA: 52s - loss: 0.0075 - accuracy: 0.999 - ETA: 51s - loss: 0.0075 - accuracy: 0.999 - ETA: 51s - loss: 0.0075 - accuracy: 0.999 - ETA: 50s - loss: 0.0074 - accuracy: 0.999 - ETA: 49s - loss: 0.0074 - accuracy: 0.999 - ETA: 49s - loss: 0.0074 - accuracy: 0.999 - ETA: 48s - loss: 0.0074 - accuracy: 0.999 - ETA: 47s - loss: 0.0076 - accuracy: 0.999 - ETA: 46s - loss: 0.0075 - accuracy: 0.999 - ETA: 46s - loss: 0.0076 - accuracy: 0.998 - ETA: 45s - loss: 0.0077 - accuracy: 0.998 - ETA: 44s - loss: 0.0077 - accuracy: 0.998 - ETA: 44s - loss: 0.0076 - accuracy: 0.998 - ETA: 43s - loss: 0.0076 - accuracy: 0.998 - ETA: 42s - loss: 0.0076 - accuracy: 0.998 - ETA: 42s - loss: 0.0075 - accuracy: 0.998 - ETA: 41s - loss: 0.0075 - accuracy: 0.998 - ETA: 40s - loss: 0.0075 - accuracy: 0.998 - ETA: 39s - loss: 0.0074 - accuracy: 0.998 - ETA: 39s - loss: 0.0074 - accuracy: 0.998 - ETA: 38s - loss: 0.0074 - accuracy: 0.998 - ETA: 37s - loss: 0.0074 - accuracy: 0.998 - ETA: 36s - loss: 0.0074 - accuracy: 0.998 - ETA: 36s - loss: 0.0073 - accuracy: 0.998 - ETA: 35s - loss: 0.0073 - accuracy: 0.998 - ETA: 34s - loss: 0.0073 - accuracy: 0.998 - ETA: 34s - loss: 0.0073 - accuracy: 0.998 - ETA: 33s - loss: 0.0073 - accuracy: 0.998 - ETA: 32s - loss: 0.0073 - accuracy: 0.998 - ETA: 31s - loss: 0.0073 - accuracy: 0.998 - ETA: 31s - loss: 0.0073 - accuracy: 0.998 - ETA: 30s - loss: 0.0072 - accuracy: 0.998 - ETA: 29s - loss: 0.0073 - accuracy: 0.998 - ETA: 29s - loss: 0.0073 - accuracy: 0.998 - ETA: 28s - loss: 0.0072 - accuracy: 0.998 - ETA: 27s - loss: 0.0072 - accuracy: 0.998 - ETA: 26s - loss: 0.0073 - accuracy: 0.998 - ETA: 26s - loss: 0.0072 - accuracy: 0.998 - ETA: 25s - loss: 0.0072 - accuracy: 0.998 - ETA: 24s - loss: 0.0074 - accuracy: 0.998 - ETA: 23s - loss: 0.0073 - accuracy: 0.998 - ETA: 23s - loss: 0.0073 - accuracy: 0.998 - ETA: 22s - loss: 0.0074 - accuracy: 0.998 - ETA: 21s - loss: 0.0073 - accuracy: 0.998 - ETA: 21s - loss: 0.0075 - accuracy: 0.998 - ETA: 20s - loss: 0.0075 - accuracy: 0.998 - ETA: 19s - loss: 0.0075 - accuracy: 0.998 - ETA: 18s - loss: 0.0076 - accuracy: 0.998 - ETA: 18s - loss: 0.0075 - accuracy: 0.998 - ETA: 17s - loss: 0.0075 - accuracy: 0.998 - ETA: 16s - loss: 0.0075 - accuracy: 0.998 - ETA: 15s - loss: 0.0075 - accuracy: 0.998 - ETA: 15s - loss: 0.0075 - accuracy: 0.998 - ETA: 14s - loss: 0.0075 - accuracy: 0.998 - ETA: 13s - loss: 0.0074 - accuracy: 0.998 - ETA: 13s - loss: 0.0074 - accuracy: 0.998 - ETA: 12s - loss: 0.0074 - accuracy: 0.998 - ETA: 11s - loss: 0.0074 - accuracy: 0.998 - ETA: 10s - loss: 0.0073 - accuracy: 0.998 - ETA: 10s - loss: 0.0073 - accuracy: 0.998 - ETA: 9s - loss: 0.0073 - accuracy: 0.998 - ETA: 8s - loss: 0.0074 - accuracy: 0.99 - ETA: 7s - loss: 0.0074 - accuracy: 0.99 - ETA: 7s - loss: 0.0074 - accuracy: 0.99 - ETA: 6s - loss: 0.0073 - accuracy: 0.99 - ETA: 5s - loss: 0.0073 - accuracy: 0.99 - ETA: 4s - loss: 0.0073 - accuracy: 0.99 - ETA: 4s - loss: 0.0073 - accuracy: 0.99 - ETA: 3s - loss: 0.0073 - accuracy: 0.99 - ETA: 2s - loss: 0.0072 - accuracy: 0.99 - ETA: 2s - loss: 0.0072 - accuracy: 0.99 - ETA: 1s - loss: 0.0072 - accuracy: 0.99 - ETA: 0s - loss: 0.0072 - accuracy: 0.99 - 120s 6ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.9778 - val_accuracy: 0.8041\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:05 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:55 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0049 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0040 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0040 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0046 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0046 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0045 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0053 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0051 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0048 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0050 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0048 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0049 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0049 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0049 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0049 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0048 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0046 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0045 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0045 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0044 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0069 - accuracy: 0.99 - ETA: 59s - loss: 0.0068 - accuracy: 0.9990 - ETA: 59s - loss: 0.0068 - accuracy: 0.999 - ETA: 58s - loss: 0.0068 - accuracy: 0.999 - ETA: 57s - loss: 0.0068 - accuracy: 0.999 - ETA: 56s - loss: 0.0068 - accuracy: 0.999 - ETA: 56s - loss: 0.0067 - accuracy: 0.999 - ETA: 55s - loss: 0.0067 - accuracy: 0.999 - ETA: 54s - loss: 0.0066 - accuracy: 0.999 - ETA: 54s - loss: 0.0066 - accuracy: 0.999 - ETA: 53s - loss: 0.0066 - accuracy: 0.999 - ETA: 52s - loss: 0.0065 - accuracy: 0.999 - ETA: 51s - loss: 0.0065 - accuracy: 0.999 - ETA: 51s - loss: 0.0065 - accuracy: 0.999 - ETA: 50s - loss: 0.0064 - accuracy: 0.999 - ETA: 49s - loss: 0.0064 - accuracy: 0.999 - ETA: 48s - loss: 0.0064 - accuracy: 0.999 - ETA: 48s - loss: 0.0063 - accuracy: 0.999 - ETA: 47s - loss: 0.0066 - accuracy: 0.999 - ETA: 46s - loss: 0.0065 - accuracy: 0.999 - ETA: 45s - loss: 0.0065 - accuracy: 0.999 - ETA: 45s - loss: 0.0064 - accuracy: 0.999 - ETA: 44s - loss: 0.0064 - accuracy: 0.999 - ETA: 43s - loss: 0.0065 - accuracy: 0.999 - ETA: 42s - loss: 0.0065 - accuracy: 0.999 - ETA: 42s - loss: 0.0067 - accuracy: 0.999 - ETA: 41s - loss: 0.0067 - accuracy: 0.999 - ETA: 40s - loss: 0.0067 - accuracy: 0.999 - ETA: 39s - loss: 0.0066 - accuracy: 0.999 - ETA: 39s - loss: 0.0066 - accuracy: 0.999 - ETA: 38s - loss: 0.0066 - accuracy: 0.999 - ETA: 37s - loss: 0.0066 - accuracy: 0.999 - ETA: 37s - loss: 0.0066 - accuracy: 0.999 - ETA: 36s - loss: 0.0066 - accuracy: 0.999 - ETA: 35s - loss: 0.0066 - accuracy: 0.999 - ETA: 34s - loss: 0.0065 - accuracy: 0.999 - ETA: 34s - loss: 0.0065 - accuracy: 0.999 - ETA: 33s - loss: 0.0065 - accuracy: 0.999 - ETA: 32s - loss: 0.0065 - accuracy: 0.999 - ETA: 32s - loss: 0.0067 - accuracy: 0.998 - ETA: 31s - loss: 0.0067 - accuracy: 0.998 - ETA: 30s - loss: 0.0066 - accuracy: 0.998 - ETA: 29s - loss: 0.0066 - accuracy: 0.998 - ETA: 29s - loss: 0.0066 - accuracy: 0.998 - ETA: 28s - loss: 0.0067 - accuracy: 0.998 - ETA: 27s - loss: 0.0067 - accuracy: 0.998 - ETA: 26s - loss: 0.0068 - accuracy: 0.998 - ETA: 26s - loss: 0.0067 - accuracy: 0.998 - ETA: 25s - loss: 0.0067 - accuracy: 0.998 - ETA: 24s - loss: 0.0067 - accuracy: 0.998 - ETA: 23s - loss: 0.0067 - accuracy: 0.998 - ETA: 23s - loss: 0.0067 - accuracy: 0.998 - ETA: 22s - loss: 0.0067 - accuracy: 0.998 - ETA: 21s - loss: 0.0067 - accuracy: 0.998 - ETA: 21s - loss: 0.0067 - accuracy: 0.998 - ETA: 20s - loss: 0.0067 - accuracy: 0.998 - ETA: 19s - loss: 0.0066 - accuracy: 0.998 - ETA: 18s - loss: 0.0066 - accuracy: 0.998 - ETA: 18s - loss: 0.0066 - accuracy: 0.998 - ETA: 17s - loss: 0.0066 - accuracy: 0.998 - ETA: 16s - loss: 0.0066 - accuracy: 0.998 - ETA: 15s - loss: 0.0066 - accuracy: 0.998 - ETA: 15s - loss: 0.0066 - accuracy: 0.998 - ETA: 14s - loss: 0.0065 - accuracy: 0.998 - ETA: 13s - loss: 0.0066 - accuracy: 0.998 - ETA: 13s - loss: 0.0067 - accuracy: 0.998 - ETA: 12s - loss: 0.0068 - accuracy: 0.998 - ETA: 11s - loss: 0.0068 - accuracy: 0.998 - ETA: 10s - loss: 0.0068 - accuracy: 0.998 - ETA: 10s - loss: 0.0067 - accuracy: 0.998 - ETA: 9s - loss: 0.0067 - accuracy: 0.998 - ETA: 8s - loss: 0.0067 - accuracy: 0.99 - ETA: 7s - loss: 0.0067 - accuracy: 0.99 - ETA: 7s - loss: 0.0067 - accuracy: 0.99 - ETA: 6s - loss: 0.0067 - accuracy: 0.99 - ETA: 5s - loss: 0.0067 - accuracy: 0.99 - ETA: 5s - loss: 0.0066 - accuracy: 0.99 - ETA: 4s - loss: 0.0067 - accuracy: 0.99 - ETA: 3s - loss: 0.0067 - accuracy: 0.99 - ETA: 2s - loss: 0.0067 - accuracy: 0.99 - ETA: 2s - loss: 0.0066 - accuracy: 0.99 - ETA: 1s - loss: 0.0066 - accuracy: 0.99 - ETA: 0s - loss: 0.0067 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.9720 - val_accuracy: 0.8002\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:00 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0040 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0084 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0086 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0084 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0080 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0055 - accuracy: 0.99 - ETA: 59s - loss: 0.0054 - accuracy: 0.9994 - ETA: 58s - loss: 0.0055 - accuracy: 0.999 - ETA: 58s - loss: 0.0055 - accuracy: 0.999 - ETA: 57s - loss: 0.0054 - accuracy: 0.999 - ETA: 56s - loss: 0.0054 - accuracy: 0.999 - ETA: 55s - loss: 0.0054 - accuracy: 0.999 - ETA: 55s - loss: 0.0055 - accuracy: 0.999 - ETA: 54s - loss: 0.0056 - accuracy: 0.999 - ETA: 53s - loss: 0.0056 - accuracy: 0.999 - ETA: 52s - loss: 0.0056 - accuracy: 0.999 - ETA: 52s - loss: 0.0055 - accuracy: 0.999 - ETA: 51s - loss: 0.0055 - accuracy: 0.999 - ETA: 50s - loss: 0.0055 - accuracy: 0.999 - ETA: 49s - loss: 0.0054 - accuracy: 0.999 - ETA: 49s - loss: 0.0054 - accuracy: 0.999 - ETA: 48s - loss: 0.0055 - accuracy: 0.999 - ETA: 47s - loss: 0.0055 - accuracy: 0.999 - ETA: 47s - loss: 0.0055 - accuracy: 0.999 - ETA: 46s - loss: 0.0055 - accuracy: 0.999 - ETA: 45s - loss: 0.0055 - accuracy: 0.999 - ETA: 45s - loss: 0.0055 - accuracy: 0.999 - ETA: 44s - loss: 0.0054 - accuracy: 0.999 - ETA: 43s - loss: 0.0056 - accuracy: 0.999 - ETA: 42s - loss: 0.0057 - accuracy: 0.999 - ETA: 42s - loss: 0.0057 - accuracy: 0.999 - ETA: 41s - loss: 0.0057 - accuracy: 0.999 - ETA: 40s - loss: 0.0057 - accuracy: 0.999 - ETA: 39s - loss: 0.0056 - accuracy: 0.999 - ETA: 39s - loss: 0.0056 - accuracy: 0.999 - ETA: 38s - loss: 0.0056 - accuracy: 0.999 - ETA: 37s - loss: 0.0056 - accuracy: 0.999 - ETA: 37s - loss: 0.0055 - accuracy: 0.999 - ETA: 36s - loss: 0.0055 - accuracy: 0.999 - ETA: 35s - loss: 0.0055 - accuracy: 0.999 - ETA: 34s - loss: 0.0055 - accuracy: 0.999 - ETA: 34s - loss: 0.0056 - accuracy: 0.999 - ETA: 33s - loss: 0.0056 - accuracy: 0.999 - ETA: 32s - loss: 0.0056 - accuracy: 0.999 - ETA: 31s - loss: 0.0057 - accuracy: 0.999 - ETA: 31s - loss: 0.0057 - accuracy: 0.999 - ETA: 30s - loss: 0.0057 - accuracy: 0.999 - ETA: 29s - loss: 0.0057 - accuracy: 0.999 - ETA: 29s - loss: 0.0056 - accuracy: 0.999 - ETA: 28s - loss: 0.0056 - accuracy: 0.999 - ETA: 27s - loss: 0.0056 - accuracy: 0.999 - ETA: 26s - loss: 0.0056 - accuracy: 0.999 - ETA: 26s - loss: 0.0056 - accuracy: 0.999 - ETA: 25s - loss: 0.0056 - accuracy: 0.999 - ETA: 24s - loss: 0.0055 - accuracy: 0.999 - ETA: 23s - loss: 0.0055 - accuracy: 0.999 - ETA: 23s - loss: 0.0055 - accuracy: 0.999 - ETA: 22s - loss: 0.0055 - accuracy: 0.999 - ETA: 21s - loss: 0.0055 - accuracy: 0.999 - ETA: 21s - loss: 0.0055 - accuracy: 0.999 - ETA: 20s - loss: 0.0055 - accuracy: 0.999 - ETA: 19s - loss: 0.0055 - accuracy: 0.999 - ETA: 18s - loss: 0.0055 - accuracy: 0.999 - ETA: 18s - loss: 0.0055 - accuracy: 0.999 - ETA: 17s - loss: 0.0056 - accuracy: 0.999 - ETA: 16s - loss: 0.0055 - accuracy: 0.999 - ETA: 15s - loss: 0.0056 - accuracy: 0.999 - ETA: 15s - loss: 0.0056 - accuracy: 0.999 - ETA: 14s - loss: 0.0056 - accuracy: 0.999 - ETA: 13s - loss: 0.0055 - accuracy: 0.999 - ETA: 13s - loss: 0.0056 - accuracy: 0.999 - ETA: 12s - loss: 0.0056 - accuracy: 0.999 - ETA: 11s - loss: 0.0056 - accuracy: 0.999 - ETA: 10s - loss: 0.0055 - accuracy: 0.999 - ETA: 10s - loss: 0.0055 - accuracy: 0.999 - ETA: 9s - loss: 0.0055 - accuracy: 0.999 - ETA: 8s - loss: 0.0055 - accuracy: 0.99 - ETA: 7s - loss: 0.0055 - accuracy: 0.99 - ETA: 7s - loss: 0.0055 - accuracy: 0.99 - ETA: 6s - loss: 0.0054 - accuracy: 0.99 - ETA: 5s - loss: 0.0055 - accuracy: 0.99 - ETA: 5s - loss: 0.0055 - accuracy: 0.99 - ETA: 4s - loss: 0.0055 - accuracy: 0.99 - ETA: 3s - loss: 0.0056 - accuracy: 0.99 - ETA: 2s - loss: 0.0056 - accuracy: 0.99 - ETA: 2s - loss: 0.0056 - accuracy: 0.99 - ETA: 1s - loss: 0.0058 - accuracy: 0.99 - ETA: 0s - loss: 0.0058 - accuracy: 0.99 - 120s 6ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.9649 - val_accuracy: 0.8058\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:43 - loss: 0.0047 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0046 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0045 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0082 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0096 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0091 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0087 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0082 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0075 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0068 - accuracy: 0.99 - ETA: 59s - loss: 0.0068 - accuracy: 0.9986 - ETA: 59s - loss: 0.0067 - accuracy: 0.998 - ETA: 58s - loss: 0.0066 - accuracy: 0.998 - ETA: 57s - loss: 0.0066 - accuracy: 0.998 - ETA: 56s - loss: 0.0066 - accuracy: 0.998 - ETA: 56s - loss: 0.0065 - accuracy: 0.998 - ETA: 55s - loss: 0.0065 - accuracy: 0.998 - ETA: 54s - loss: 0.0067 - accuracy: 0.998 - ETA: 54s - loss: 0.0067 - accuracy: 0.998 - ETA: 53s - loss: 0.0067 - accuracy: 0.998 - ETA: 52s - loss: 0.0066 - accuracy: 0.998 - ETA: 51s - loss: 0.0066 - accuracy: 0.998 - ETA: 51s - loss: 0.0066 - accuracy: 0.998 - ETA: 50s - loss: 0.0066 - accuracy: 0.998 - ETA: 49s - loss: 0.0066 - accuracy: 0.998 - ETA: 49s - loss: 0.0065 - accuracy: 0.998 - ETA: 48s - loss: 0.0065 - accuracy: 0.998 - ETA: 47s - loss: 0.0065 - accuracy: 0.998 - ETA: 46s - loss: 0.0065 - accuracy: 0.998 - ETA: 46s - loss: 0.0064 - accuracy: 0.998 - ETA: 45s - loss: 0.0064 - accuracy: 0.998 - ETA: 44s - loss: 0.0063 - accuracy: 0.998 - ETA: 43s - loss: 0.0063 - accuracy: 0.998 - ETA: 43s - loss: 0.0063 - accuracy: 0.998 - ETA: 42s - loss: 0.0063 - accuracy: 0.998 - ETA: 41s - loss: 0.0063 - accuracy: 0.998 - ETA: 40s - loss: 0.0062 - accuracy: 0.998 - ETA: 40s - loss: 0.0062 - accuracy: 0.998 - ETA: 39s - loss: 0.0062 - accuracy: 0.998 - ETA: 38s - loss: 0.0062 - accuracy: 0.998 - ETA: 38s - loss: 0.0062 - accuracy: 0.998 - ETA: 37s - loss: 0.0062 - accuracy: 0.998 - ETA: 36s - loss: 0.0062 - accuracy: 0.998 - ETA: 35s - loss: 0.0062 - accuracy: 0.998 - ETA: 35s - loss: 0.0061 - accuracy: 0.998 - ETA: 34s - loss: 0.0062 - accuracy: 0.998 - ETA: 33s - loss: 0.0062 - accuracy: 0.998 - ETA: 32s - loss: 0.0062 - accuracy: 0.998 - ETA: 32s - loss: 0.0063 - accuracy: 0.998 - ETA: 31s - loss: 0.0063 - accuracy: 0.998 - ETA: 30s - loss: 0.0062 - accuracy: 0.998 - ETA: 29s - loss: 0.0062 - accuracy: 0.998 - ETA: 29s - loss: 0.0062 - accuracy: 0.998 - ETA: 28s - loss: 0.0062 - accuracy: 0.998 - ETA: 27s - loss: 0.0062 - accuracy: 0.998 - ETA: 26s - loss: 0.0062 - accuracy: 0.998 - ETA: 26s - loss: 0.0061 - accuracy: 0.998 - ETA: 25s - loss: 0.0061 - accuracy: 0.998 - ETA: 24s - loss: 0.0061 - accuracy: 0.998 - ETA: 24s - loss: 0.0061 - accuracy: 0.998 - ETA: 23s - loss: 0.0061 - accuracy: 0.998 - ETA: 22s - loss: 0.0061 - accuracy: 0.998 - ETA: 21s - loss: 0.0061 - accuracy: 0.998 - ETA: 21s - loss: 0.0061 - accuracy: 0.998 - ETA: 20s - loss: 0.0061 - accuracy: 0.998 - ETA: 19s - loss: 0.0061 - accuracy: 0.998 - ETA: 18s - loss: 0.0060 - accuracy: 0.998 - ETA: 18s - loss: 0.0060 - accuracy: 0.998 - ETA: 17s - loss: 0.0060 - accuracy: 0.999 - ETA: 16s - loss: 0.0060 - accuracy: 0.999 - ETA: 15s - loss: 0.0061 - accuracy: 0.998 - ETA: 15s - loss: 0.0061 - accuracy: 0.998 - ETA: 14s - loss: 0.0061 - accuracy: 0.998 - ETA: 13s - loss: 0.0061 - accuracy: 0.998 - ETA: 13s - loss: 0.0062 - accuracy: 0.998 - ETA: 12s - loss: 0.0062 - accuracy: 0.998 - ETA: 11s - loss: 0.0062 - accuracy: 0.998 - ETA: 10s - loss: 0.0062 - accuracy: 0.998 - ETA: 10s - loss: 0.0062 - accuracy: 0.998 - ETA: 9s - loss: 0.0062 - accuracy: 0.998 - ETA: 8s - loss: 0.0062 - accuracy: 0.99 - ETA: 7s - loss: 0.0062 - accuracy: 0.99 - ETA: 7s - loss: 0.0063 - accuracy: 0.99 - ETA: 6s - loss: 0.0063 - accuracy: 0.99 - ETA: 5s - loss: 0.0063 - accuracy: 0.99 - ETA: 5s - loss: 0.0062 - accuracy: 0.99 - ETA: 4s - loss: 0.0062 - accuracy: 0.99 - ETA: 3s - loss: 0.0062 - accuracy: 0.99 - ETA: 2s - loss: 0.0062 - accuracy: 0.99 - ETA: 2s - loss: 0.0062 - accuracy: 0.99 - ETA: 1s - loss: 0.0063 - accuracy: 0.99 - ETA: 0s - loss: 0.0064 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.9741 - val_accuracy: 0.8043\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:03 - loss: 0.0043 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0052 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0042 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0041 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0039 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0063 - accuracy: 0.99 - ETA: 59s - loss: 0.0062 - accuracy: 0.9991 - ETA: 58s - loss: 0.0062 - accuracy: 0.999 - ETA: 58s - loss: 0.0062 - accuracy: 0.999 - ETA: 57s - loss: 0.0062 - accuracy: 0.999 - ETA: 56s - loss: 0.0062 - accuracy: 0.999 - ETA: 55s - loss: 0.0061 - accuracy: 0.999 - ETA: 55s - loss: 0.0061 - accuracy: 0.999 - ETA: 54s - loss: 0.0061 - accuracy: 0.999 - ETA: 53s - loss: 0.0060 - accuracy: 0.999 - ETA: 53s - loss: 0.0061 - accuracy: 0.999 - ETA: 52s - loss: 0.0060 - accuracy: 0.999 - ETA: 51s - loss: 0.0060 - accuracy: 0.999 - ETA: 50s - loss: 0.0060 - accuracy: 0.999 - ETA: 50s - loss: 0.0060 - accuracy: 0.999 - ETA: 49s - loss: 0.0059 - accuracy: 0.999 - ETA: 48s - loss: 0.0059 - accuracy: 0.999 - ETA: 48s - loss: 0.0061 - accuracy: 0.999 - ETA: 47s - loss: 0.0060 - accuracy: 0.999 - ETA: 46s - loss: 0.0060 - accuracy: 0.999 - ETA: 45s - loss: 0.0060 - accuracy: 0.999 - ETA: 45s - loss: 0.0060 - accuracy: 0.999 - ETA: 44s - loss: 0.0061 - accuracy: 0.999 - ETA: 43s - loss: 0.0060 - accuracy: 0.999 - ETA: 42s - loss: 0.0060 - accuracy: 0.999 - ETA: 42s - loss: 0.0060 - accuracy: 0.999 - ETA: 41s - loss: 0.0059 - accuracy: 0.999 - ETA: 40s - loss: 0.0059 - accuracy: 0.999 - ETA: 40s - loss: 0.0059 - accuracy: 0.999 - ETA: 39s - loss: 0.0059 - accuracy: 0.999 - ETA: 38s - loss: 0.0059 - accuracy: 0.999 - ETA: 37s - loss: 0.0059 - accuracy: 0.999 - ETA: 37s - loss: 0.0059 - accuracy: 0.999 - ETA: 36s - loss: 0.0059 - accuracy: 0.999 - ETA: 35s - loss: 0.0059 - accuracy: 0.999 - ETA: 34s - loss: 0.0059 - accuracy: 0.999 - ETA: 34s - loss: 0.0059 - accuracy: 0.999 - ETA: 33s - loss: 0.0059 - accuracy: 0.999 - ETA: 32s - loss: 0.0059 - accuracy: 0.999 - ETA: 31s - loss: 0.0058 - accuracy: 0.999 - ETA: 31s - loss: 0.0058 - accuracy: 0.999 - ETA: 30s - loss: 0.0059 - accuracy: 0.999 - ETA: 29s - loss: 0.0058 - accuracy: 0.999 - ETA: 29s - loss: 0.0058 - accuracy: 0.999 - ETA: 28s - loss: 0.0058 - accuracy: 0.999 - ETA: 27s - loss: 0.0058 - accuracy: 0.999 - ETA: 26s - loss: 0.0058 - accuracy: 0.999 - ETA: 26s - loss: 0.0057 - accuracy: 0.999 - ETA: 25s - loss: 0.0057 - accuracy: 0.999 - ETA: 24s - loss: 0.0057 - accuracy: 0.999 - ETA: 23s - loss: 0.0057 - accuracy: 0.999 - ETA: 23s - loss: 0.0057 - accuracy: 0.999 - ETA: 22s - loss: 0.0056 - accuracy: 0.999 - ETA: 21s - loss: 0.0058 - accuracy: 0.999 - ETA: 21s - loss: 0.0058 - accuracy: 0.999 - ETA: 20s - loss: 0.0058 - accuracy: 0.999 - ETA: 19s - loss: 0.0058 - accuracy: 0.999 - ETA: 18s - loss: 0.0057 - accuracy: 0.999 - ETA: 18s - loss: 0.0057 - accuracy: 0.999 - ETA: 17s - loss: 0.0057 - accuracy: 0.999 - ETA: 16s - loss: 0.0057 - accuracy: 0.999 - ETA: 15s - loss: 0.0057 - accuracy: 0.999 - ETA: 15s - loss: 0.0056 - accuracy: 0.999 - ETA: 14s - loss: 0.0057 - accuracy: 0.999 - ETA: 13s - loss: 0.0057 - accuracy: 0.999 - ETA: 13s - loss: 0.0057 - accuracy: 0.999 - ETA: 12s - loss: 0.0056 - accuracy: 0.999 - ETA: 11s - loss: 0.0056 - accuracy: 0.999 - ETA: 10s - loss: 0.0056 - accuracy: 0.999 - ETA: 10s - loss: 0.0056 - accuracy: 0.999 - ETA: 9s - loss: 0.0056 - accuracy: 0.999 - ETA: 8s - loss: 0.0056 - accuracy: 0.99 - ETA: 7s - loss: 0.0056 - accuracy: 0.99 - ETA: 7s - loss: 0.0055 - accuracy: 0.99 - ETA: 6s - loss: 0.0055 - accuracy: 0.99 - ETA: 5s - loss: 0.0055 - accuracy: 0.99 - ETA: 5s - loss: 0.0055 - accuracy: 0.99 - ETA: 4s - loss: 0.0055 - accuracy: 0.99 - ETA: 3s - loss: 0.0055 - accuracy: 0.99 - ETA: 2s - loss: 0.0055 - accuracy: 0.99 - ETA: 2s - loss: 0.0055 - accuracy: 0.99 - ETA: 1s - loss: 0.0055 - accuracy: 0.99 - ETA: 0s - loss: 0.0055 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.9679 - val_accuracy: 0.8053\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:59 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:54 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0044 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0051 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0047 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0054 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0050 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0052 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0054 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0051 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0051 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0052 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0052 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0051 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0050 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0054 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0052 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0051 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0049 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0051 - accuracy: 0.99 - ETA: 59s - loss: 0.0052 - accuracy: 0.9995 - ETA: 59s - loss: 0.0053 - accuracy: 0.999 - ETA: 58s - loss: 0.0053 - accuracy: 0.999 - ETA: 57s - loss: 0.0052 - accuracy: 0.999 - ETA: 57s - loss: 0.0052 - accuracy: 0.999 - ETA: 56s - loss: 0.0052 - accuracy: 0.999 - ETA: 55s - loss: 0.0051 - accuracy: 0.999 - ETA: 54s - loss: 0.0051 - accuracy: 0.999 - ETA: 54s - loss: 0.0051 - accuracy: 0.999 - ETA: 53s - loss: 0.0050 - accuracy: 0.999 - ETA: 52s - loss: 0.0051 - accuracy: 0.999 - ETA: 51s - loss: 0.0054 - accuracy: 0.999 - ETA: 51s - loss: 0.0054 - accuracy: 0.999 - ETA: 50s - loss: 0.0054 - accuracy: 0.999 - ETA: 49s - loss: 0.0054 - accuracy: 0.999 - ETA: 48s - loss: 0.0054 - accuracy: 0.999 - ETA: 48s - loss: 0.0054 - accuracy: 0.999 - ETA: 47s - loss: 0.0054 - accuracy: 0.999 - ETA: 46s - loss: 0.0053 - accuracy: 0.999 - ETA: 45s - loss: 0.0053 - accuracy: 0.999 - ETA: 45s - loss: 0.0052 - accuracy: 0.999 - ETA: 44s - loss: 0.0052 - accuracy: 0.999 - ETA: 43s - loss: 0.0051 - accuracy: 0.999 - ETA: 43s - loss: 0.0051 - accuracy: 0.999 - ETA: 42s - loss: 0.0051 - accuracy: 0.999 - ETA: 41s - loss: 0.0051 - accuracy: 0.999 - ETA: 40s - loss: 0.0051 - accuracy: 0.999 - ETA: 40s - loss: 0.0051 - accuracy: 0.999 - ETA: 39s - loss: 0.0051 - accuracy: 0.999 - ETA: 38s - loss: 0.0050 - accuracy: 0.999 - ETA: 37s - loss: 0.0050 - accuracy: 0.999 - ETA: 37s - loss: 0.0050 - accuracy: 0.999 - ETA: 36s - loss: 0.0049 - accuracy: 0.999 - ETA: 35s - loss: 0.0049 - accuracy: 0.999 - ETA: 35s - loss: 0.0049 - accuracy: 0.999 - ETA: 34s - loss: 0.0049 - accuracy: 0.999 - ETA: 33s - loss: 0.0049 - accuracy: 0.999 - ETA: 32s - loss: 0.0049 - accuracy: 0.999 - ETA: 32s - loss: 0.0048 - accuracy: 0.999 - ETA: 31s - loss: 0.0048 - accuracy: 0.999 - ETA: 30s - loss: 0.0048 - accuracy: 0.999 - ETA: 29s - loss: 0.0050 - accuracy: 0.999 - ETA: 29s - loss: 0.0050 - accuracy: 0.999 - ETA: 28s - loss: 0.0050 - accuracy: 0.999 - ETA: 27s - loss: 0.0050 - accuracy: 0.999 - ETA: 26s - loss: 0.0050 - accuracy: 0.999 - ETA: 26s - loss: 0.0050 - accuracy: 0.999 - ETA: 25s - loss: 0.0050 - accuracy: 0.999 - ETA: 24s - loss: 0.0050 - accuracy: 0.999 - ETA: 24s - loss: 0.0050 - accuracy: 0.999 - ETA: 23s - loss: 0.0049 - accuracy: 0.999 - ETA: 22s - loss: 0.0049 - accuracy: 0.999 - ETA: 21s - loss: 0.0049 - accuracy: 0.999 - ETA: 21s - loss: 0.0049 - accuracy: 0.999 - ETA: 20s - loss: 0.0049 - accuracy: 0.999 - ETA: 19s - loss: 0.0049 - accuracy: 0.999 - ETA: 18s - loss: 0.0049 - accuracy: 0.999 - ETA: 18s - loss: 0.0049 - accuracy: 0.999 - ETA: 17s - loss: 0.0049 - accuracy: 0.999 - ETA: 16s - loss: 0.0049 - accuracy: 0.999 - ETA: 15s - loss: 0.0049 - accuracy: 0.999 - ETA: 15s - loss: 0.0049 - accuracy: 0.999 - ETA: 14s - loss: 0.0049 - accuracy: 0.999 - ETA: 13s - loss: 0.0048 - accuracy: 0.999 - ETA: 13s - loss: 0.0049 - accuracy: 0.999 - ETA: 12s - loss: 0.0049 - accuracy: 0.999 - ETA: 11s - loss: 0.0048 - accuracy: 0.999 - ETA: 10s - loss: 0.0048 - accuracy: 0.999 - ETA: 10s - loss: 0.0048 - accuracy: 0.999 - ETA: 9s - loss: 0.0048 - accuracy: 0.999 - ETA: 8s - loss: 0.0048 - accuracy: 0.99 - ETA: 7s - loss: 0.0048 - accuracy: 0.99 - ETA: 7s - loss: 0.0048 - accuracy: 0.99 - ETA: 6s - loss: 0.0048 - accuracy: 0.99 - ETA: 5s - loss: 0.0048 - accuracy: 0.99 - ETA: 5s - loss: 0.0048 - accuracy: 0.99 - ETA: 4s - loss: 0.0048 - accuracy: 0.99 - ETA: 3s - loss: 0.0048 - accuracy: 0.99 - ETA: 2s - loss: 0.0048 - accuracy: 0.99 - ETA: 2s - loss: 0.0048 - accuracy: 0.99 - ETA: 1s - loss: 0.0048 - accuracy: 0.99 - ETA: 0s - loss: 0.0048 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.9707 - val_accuracy: 0.8055\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:47 - loss: 0.0045 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0065 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0090 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0095 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0085 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0053 - accuracy: 0.99 - ETA: 59s - loss: 0.0055 - accuracy: 0.9990 - ETA: 59s - loss: 0.0055 - accuracy: 0.999 - ETA: 58s - loss: 0.0055 - accuracy: 0.999 - ETA: 57s - loss: 0.0058 - accuracy: 0.998 - ETA: 57s - loss: 0.0057 - accuracy: 0.998 - ETA: 56s - loss: 0.0057 - accuracy: 0.998 - ETA: 55s - loss: 0.0058 - accuracy: 0.998 - ETA: 54s - loss: 0.0061 - accuracy: 0.998 - ETA: 54s - loss: 0.0061 - accuracy: 0.998 - ETA: 53s - loss: 0.0061 - accuracy: 0.998 - ETA: 52s - loss: 0.0061 - accuracy: 0.998 - ETA: 52s - loss: 0.0061 - accuracy: 0.998 - ETA: 51s - loss: 0.0061 - accuracy: 0.998 - ETA: 50s - loss: 0.0061 - accuracy: 0.998 - ETA: 50s - loss: 0.0060 - accuracy: 0.998 - ETA: 49s - loss: 0.0060 - accuracy: 0.998 - ETA: 48s - loss: 0.0060 - accuracy: 0.998 - ETA: 47s - loss: 0.0061 - accuracy: 0.998 - ETA: 47s - loss: 0.0060 - accuracy: 0.998 - ETA: 46s - loss: 0.0062 - accuracy: 0.998 - ETA: 45s - loss: 0.0061 - accuracy: 0.998 - ETA: 45s - loss: 0.0061 - accuracy: 0.998 - ETA: 44s - loss: 0.0061 - accuracy: 0.998 - ETA: 43s - loss: 0.0061 - accuracy: 0.998 - ETA: 42s - loss: 0.0061 - accuracy: 0.998 - ETA: 42s - loss: 0.0061 - accuracy: 0.998 - ETA: 41s - loss: 0.0060 - accuracy: 0.998 - ETA: 40s - loss: 0.0063 - accuracy: 0.998 - ETA: 39s - loss: 0.0063 - accuracy: 0.998 - ETA: 39s - loss: 0.0062 - accuracy: 0.998 - ETA: 38s - loss: 0.0062 - accuracy: 0.998 - ETA: 37s - loss: 0.0062 - accuracy: 0.998 - ETA: 37s - loss: 0.0061 - accuracy: 0.998 - ETA: 36s - loss: 0.0061 - accuracy: 0.998 - ETA: 35s - loss: 0.0061 - accuracy: 0.998 - ETA: 34s - loss: 0.0061 - accuracy: 0.998 - ETA: 34s - loss: 0.0060 - accuracy: 0.998 - ETA: 33s - loss: 0.0061 - accuracy: 0.998 - ETA: 32s - loss: 0.0061 - accuracy: 0.998 - ETA: 31s - loss: 0.0061 - accuracy: 0.998 - ETA: 31s - loss: 0.0061 - accuracy: 0.998 - ETA: 30s - loss: 0.0062 - accuracy: 0.998 - ETA: 29s - loss: 0.0063 - accuracy: 0.998 - ETA: 29s - loss: 0.0062 - accuracy: 0.998 - ETA: 28s - loss: 0.0062 - accuracy: 0.998 - ETA: 27s - loss: 0.0062 - accuracy: 0.998 - ETA: 26s - loss: 0.0062 - accuracy: 0.998 - ETA: 26s - loss: 0.0061 - accuracy: 0.998 - ETA: 25s - loss: 0.0061 - accuracy: 0.998 - ETA: 24s - loss: 0.0061 - accuracy: 0.998 - ETA: 23s - loss: 0.0061 - accuracy: 0.998 - ETA: 23s - loss: 0.0061 - accuracy: 0.998 - ETA: 22s - loss: 0.0061 - accuracy: 0.998 - ETA: 21s - loss: 0.0061 - accuracy: 0.998 - ETA: 21s - loss: 0.0061 - accuracy: 0.998 - ETA: 20s - loss: 0.0061 - accuracy: 0.998 - ETA: 19s - loss: 0.0061 - accuracy: 0.998 - ETA: 18s - loss: 0.0061 - accuracy: 0.998 - ETA: 18s - loss: 0.0061 - accuracy: 0.998 - ETA: 17s - loss: 0.0060 - accuracy: 0.998 - ETA: 16s - loss: 0.0060 - accuracy: 0.998 - ETA: 15s - loss: 0.0060 - accuracy: 0.998 - ETA: 15s - loss: 0.0060 - accuracy: 0.998 - ETA: 14s - loss: 0.0059 - accuracy: 0.998 - ETA: 13s - loss: 0.0059 - accuracy: 0.998 - ETA: 13s - loss: 0.0059 - accuracy: 0.998 - ETA: 12s - loss: 0.0059 - accuracy: 0.999 - ETA: 11s - loss: 0.0059 - accuracy: 0.999 - ETA: 10s - loss: 0.0058 - accuracy: 0.999 - ETA: 10s - loss: 0.0058 - accuracy: 0.999 - ETA: 9s - loss: 0.0058 - accuracy: 0.999 - ETA: 8s - loss: 0.0058 - accuracy: 0.99 - ETA: 7s - loss: 0.0058 - accuracy: 0.99 - ETA: 7s - loss: 0.0058 - accuracy: 0.99 - ETA: 6s - loss: 0.0058 - accuracy: 0.99 - ETA: 5s - loss: 0.0058 - accuracy: 0.99 - ETA: 4s - loss: 0.0057 - accuracy: 0.99 - ETA: 4s - loss: 0.0057 - accuracy: 0.99 - ETA: 3s - loss: 0.0057 - accuracy: 0.99 - ETA: 2s - loss: 0.0057 - accuracy: 0.99 - ETA: 2s - loss: 0.0057 - accuracy: 0.99 - ETA: 1s - loss: 0.0057 - accuracy: 0.99 - ETA: 0s - loss: 0.0057 - accuracy: 0.99 - 120s 6ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.9744 - val_accuracy: 0.8051\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:53 - loss: 0.0046 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0043 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0050 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0046 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0044 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0056 - accuracy: 0.99 - ETA: 59s - loss: 0.0056 - accuracy: 0.9990 - ETA: 58s - loss: 0.0056 - accuracy: 0.999 - ETA: 58s - loss: 0.0056 - accuracy: 0.999 - ETA: 57s - loss: 0.0057 - accuracy: 0.998 - ETA: 56s - loss: 0.0056 - accuracy: 0.998 - ETA: 55s - loss: 0.0056 - accuracy: 0.998 - ETA: 55s - loss: 0.0056 - accuracy: 0.999 - ETA: 54s - loss: 0.0055 - accuracy: 0.999 - ETA: 53s - loss: 0.0055 - accuracy: 0.999 - ETA: 52s - loss: 0.0055 - accuracy: 0.999 - ETA: 52s - loss: 0.0055 - accuracy: 0.999 - ETA: 51s - loss: 0.0056 - accuracy: 0.998 - ETA: 50s - loss: 0.0056 - accuracy: 0.998 - ETA: 49s - loss: 0.0056 - accuracy: 0.999 - ETA: 49s - loss: 0.0055 - accuracy: 0.999 - ETA: 48s - loss: 0.0056 - accuracy: 0.999 - ETA: 47s - loss: 0.0055 - accuracy: 0.999 - ETA: 47s - loss: 0.0055 - accuracy: 0.999 - ETA: 46s - loss: 0.0055 - accuracy: 0.999 - ETA: 45s - loss: 0.0054 - accuracy: 0.999 - ETA: 44s - loss: 0.0054 - accuracy: 0.999 - ETA: 44s - loss: 0.0054 - accuracy: 0.999 - ETA: 43s - loss: 0.0054 - accuracy: 0.999 - ETA: 42s - loss: 0.0054 - accuracy: 0.999 - ETA: 42s - loss: 0.0055 - accuracy: 0.999 - ETA: 41s - loss: 0.0055 - accuracy: 0.999 - ETA: 40s - loss: 0.0055 - accuracy: 0.999 - ETA: 39s - loss: 0.0054 - accuracy: 0.999 - ETA: 39s - loss: 0.0054 - accuracy: 0.999 - ETA: 38s - loss: 0.0054 - accuracy: 0.999 - ETA: 37s - loss: 0.0054 - accuracy: 0.999 - ETA: 36s - loss: 0.0054 - accuracy: 0.999 - ETA: 36s - loss: 0.0054 - accuracy: 0.999 - ETA: 35s - loss: 0.0054 - accuracy: 0.999 - ETA: 34s - loss: 0.0053 - accuracy: 0.999 - ETA: 34s - loss: 0.0053 - accuracy: 0.999 - ETA: 33s - loss: 0.0053 - accuracy: 0.999 - ETA: 32s - loss: 0.0053 - accuracy: 0.999 - ETA: 31s - loss: 0.0052 - accuracy: 0.999 - ETA: 31s - loss: 0.0052 - accuracy: 0.999 - ETA: 30s - loss: 0.0053 - accuracy: 0.999 - ETA: 29s - loss: 0.0052 - accuracy: 0.999 - ETA: 29s - loss: 0.0052 - accuracy: 0.999 - ETA: 28s - loss: 0.0052 - accuracy: 0.999 - ETA: 27s - loss: 0.0052 - accuracy: 0.999 - ETA: 26s - loss: 0.0052 - accuracy: 0.999 - ETA: 26s - loss: 0.0052 - accuracy: 0.999 - ETA: 25s - loss: 0.0052 - accuracy: 0.999 - ETA: 24s - loss: 0.0052 - accuracy: 0.999 - ETA: 23s - loss: 0.0052 - accuracy: 0.999 - ETA: 23s - loss: 0.0052 - accuracy: 0.999 - ETA: 22s - loss: 0.0051 - accuracy: 0.999 - ETA: 21s - loss: 0.0051 - accuracy: 0.999 - ETA: 21s - loss: 0.0051 - accuracy: 0.999 - ETA: 20s - loss: 0.0051 - accuracy: 0.999 - ETA: 19s - loss: 0.0051 - accuracy: 0.999 - ETA: 18s - loss: 0.0051 - accuracy: 0.999 - ETA: 18s - loss: 0.0051 - accuracy: 0.999 - ETA: 17s - loss: 0.0051 - accuracy: 0.999 - ETA: 16s - loss: 0.0050 - accuracy: 0.999 - ETA: 15s - loss: 0.0050 - accuracy: 0.999 - ETA: 15s - loss: 0.0050 - accuracy: 0.999 - ETA: 14s - loss: 0.0050 - accuracy: 0.999 - ETA: 13s - loss: 0.0050 - accuracy: 0.999 - ETA: 12s - loss: 0.0050 - accuracy: 0.999 - ETA: 12s - loss: 0.0050 - accuracy: 0.999 - ETA: 11s - loss: 0.0050 - accuracy: 0.999 - ETA: 10s - loss: 0.0050 - accuracy: 0.999 - ETA: 10s - loss: 0.0050 - accuracy: 0.999 - ETA: 9s - loss: 0.0050 - accuracy: 0.999 - ETA: 8s - loss: 0.0050 - accuracy: 0.99 - ETA: 7s - loss: 0.0050 - accuracy: 0.99 - ETA: 7s - loss: 0.0050 - accuracy: 0.99 - ETA: 6s - loss: 0.0050 - accuracy: 0.99 - ETA: 5s - loss: 0.0050 - accuracy: 0.99 - ETA: 4s - loss: 0.0050 - accuracy: 0.99 - ETA: 4s - loss: 0.0050 - accuracy: 0.99 - ETA: 3s - loss: 0.0050 - accuracy: 0.99 - ETA: 2s - loss: 0.0051 - accuracy: 0.99 - ETA: 2s - loss: 0.0052 - accuracy: 0.99 - ETA: 1s - loss: 0.0051 - accuracy: 0.99 - ETA: 0s - loss: 0.0051 - accuracy: 0.99 - 120s 6ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.9739 - val_accuracy: 0.8058\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:51 - loss: 7.2781e-04 - accuracy: 1.00 - ETA: 1:47 - loss: 7.4180e-04 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0024 - accuracy: 1.0000   - ETA: 1:47 - loss: 0.0052 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0054 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0050 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0044 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0041 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0063 - accuracy: 0.99 - ETA: 59s - loss: 0.0062 - accuracy: 0.9989 - ETA: 58s - loss: 0.0062 - accuracy: 0.998 - ETA: 57s - loss: 0.0062 - accuracy: 0.998 - ETA: 57s - loss: 0.0061 - accuracy: 0.998 - ETA: 56s - loss: 0.0062 - accuracy: 0.998 - ETA: 55s - loss: 0.0067 - accuracy: 0.998 - ETA: 54s - loss: 0.0067 - accuracy: 0.998 - ETA: 54s - loss: 0.0066 - accuracy: 0.998 - ETA: 53s - loss: 0.0065 - accuracy: 0.998 - ETA: 52s - loss: 0.0066 - accuracy: 0.998 - ETA: 52s - loss: 0.0065 - accuracy: 0.998 - ETA: 51s - loss: 0.0065 - accuracy: 0.998 - ETA: 50s - loss: 0.0065 - accuracy: 0.998 - ETA: 50s - loss: 0.0064 - accuracy: 0.998 - ETA: 49s - loss: 0.0064 - accuracy: 0.998 - ETA: 48s - loss: 0.0063 - accuracy: 0.998 - ETA: 47s - loss: 0.0063 - accuracy: 0.998 - ETA: 47s - loss: 0.0062 - accuracy: 0.998 - ETA: 46s - loss: 0.0062 - accuracy: 0.998 - ETA: 45s - loss: 0.0061 - accuracy: 0.998 - ETA: 45s - loss: 0.0061 - accuracy: 0.998 - ETA: 44s - loss: 0.0061 - accuracy: 0.999 - ETA: 43s - loss: 0.0061 - accuracy: 0.999 - ETA: 42s - loss: 0.0062 - accuracy: 0.999 - ETA: 42s - loss: 0.0061 - accuracy: 0.999 - ETA: 41s - loss: 0.0061 - accuracy: 0.999 - ETA: 40s - loss: 0.0061 - accuracy: 0.999 - ETA: 39s - loss: 0.0061 - accuracy: 0.998 - ETA: 39s - loss: 0.0061 - accuracy: 0.999 - ETA: 38s - loss: 0.0060 - accuracy: 0.999 - ETA: 37s - loss: 0.0060 - accuracy: 0.999 - ETA: 37s - loss: 0.0060 - accuracy: 0.999 - ETA: 36s - loss: 0.0061 - accuracy: 0.999 - ETA: 35s - loss: 0.0061 - accuracy: 0.998 - ETA: 34s - loss: 0.0061 - accuracy: 0.998 - ETA: 34s - loss: 0.0061 - accuracy: 0.998 - ETA: 33s - loss: 0.0061 - accuracy: 0.999 - ETA: 32s - loss: 0.0061 - accuracy: 0.999 - ETA: 31s - loss: 0.0061 - accuracy: 0.999 - ETA: 31s - loss: 0.0060 - accuracy: 0.999 - ETA: 30s - loss: 0.0061 - accuracy: 0.999 - ETA: 29s - loss: 0.0061 - accuracy: 0.999 - ETA: 29s - loss: 0.0060 - accuracy: 0.999 - ETA: 28s - loss: 0.0060 - accuracy: 0.999 - ETA: 27s - loss: 0.0060 - accuracy: 0.999 - ETA: 26s - loss: 0.0059 - accuracy: 0.999 - ETA: 26s - loss: 0.0059 - accuracy: 0.999 - ETA: 25s - loss: 0.0059 - accuracy: 0.999 - ETA: 24s - loss: 0.0059 - accuracy: 0.999 - ETA: 23s - loss: 0.0059 - accuracy: 0.999 - ETA: 23s - loss: 0.0059 - accuracy: 0.999 - ETA: 22s - loss: 0.0059 - accuracy: 0.999 - ETA: 21s - loss: 0.0059 - accuracy: 0.999 - ETA: 21s - loss: 0.0058 - accuracy: 0.999 - ETA: 20s - loss: 0.0058 - accuracy: 0.999 - ETA: 19s - loss: 0.0058 - accuracy: 0.999 - ETA: 18s - loss: 0.0059 - accuracy: 0.999 - ETA: 18s - loss: 0.0058 - accuracy: 0.999 - ETA: 17s - loss: 0.0058 - accuracy: 0.999 - ETA: 16s - loss: 0.0058 - accuracy: 0.999 - ETA: 15s - loss: 0.0058 - accuracy: 0.999 - ETA: 15s - loss: 0.0058 - accuracy: 0.999 - ETA: 14s - loss: 0.0058 - accuracy: 0.999 - ETA: 13s - loss: 0.0058 - accuracy: 0.999 - ETA: 13s - loss: 0.0057 - accuracy: 0.999 - ETA: 12s - loss: 0.0057 - accuracy: 0.999 - ETA: 11s - loss: 0.0057 - accuracy: 0.999 - ETA: 10s - loss: 0.0058 - accuracy: 0.999 - ETA: 10s - loss: 0.0058 - accuracy: 0.999 - ETA: 9s - loss: 0.0057 - accuracy: 0.999 - ETA: 8s - loss: 0.0057 - accuracy: 0.99 - ETA: 7s - loss: 0.0057 - accuracy: 0.99 - ETA: 7s - loss: 0.0057 - accuracy: 0.99 - ETA: 6s - loss: 0.0056 - accuracy: 0.99 - ETA: 5s - loss: 0.0056 - accuracy: 0.99 - ETA: 5s - loss: 0.0056 - accuracy: 0.99 - ETA: 4s - loss: 0.0056 - accuracy: 0.99 - ETA: 3s - loss: 0.0056 - accuracy: 0.99 - ETA: 2s - loss: 0.0055 - accuracy: 0.99 - ETA: 2s - loss: 0.0055 - accuracy: 0.99 - ETA: 1s - loss: 0.0055 - accuracy: 0.99 - ETA: 0s - loss: 0.0055 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.9606 - val_accuracy: 0.8076\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:00 - loss: 0.0015 - accuracy: 1.00 - ETA: 1:59 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:55 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0063 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0057 - accuracy: 0.99 - ETA: 59s - loss: 0.0058 - accuracy: 0.9990 - ETA: 58s - loss: 0.0057 - accuracy: 0.999 - ETA: 57s - loss: 0.0058 - accuracy: 0.998 - ETA: 57s - loss: 0.0057 - accuracy: 0.998 - ETA: 56s - loss: 0.0057 - accuracy: 0.998 - ETA: 55s - loss: 0.0056 - accuracy: 0.999 - ETA: 54s - loss: 0.0056 - accuracy: 0.999 - ETA: 54s - loss: 0.0056 - accuracy: 0.999 - ETA: 53s - loss: 0.0056 - accuracy: 0.999 - ETA: 52s - loss: 0.0056 - accuracy: 0.999 - ETA: 51s - loss: 0.0056 - accuracy: 0.999 - ETA: 51s - loss: 0.0056 - accuracy: 0.999 - ETA: 50s - loss: 0.0055 - accuracy: 0.999 - ETA: 49s - loss: 0.0055 - accuracy: 0.999 - ETA: 48s - loss: 0.0054 - accuracy: 0.999 - ETA: 48s - loss: 0.0055 - accuracy: 0.999 - ETA: 47s - loss: 0.0054 - accuracy: 0.999 - ETA: 46s - loss: 0.0054 - accuracy: 0.999 - ETA: 45s - loss: 0.0054 - accuracy: 0.999 - ETA: 45s - loss: 0.0054 - accuracy: 0.999 - ETA: 44s - loss: 0.0054 - accuracy: 0.999 - ETA: 43s - loss: 0.0053 - accuracy: 0.999 - ETA: 43s - loss: 0.0053 - accuracy: 0.999 - ETA: 42s - loss: 0.0052 - accuracy: 0.999 - ETA: 41s - loss: 0.0052 - accuracy: 0.999 - ETA: 40s - loss: 0.0053 - accuracy: 0.999 - ETA: 40s - loss: 0.0052 - accuracy: 0.999 - ETA: 39s - loss: 0.0052 - accuracy: 0.999 - ETA: 38s - loss: 0.0052 - accuracy: 0.999 - ETA: 37s - loss: 0.0052 - accuracy: 0.999 - ETA: 37s - loss: 0.0051 - accuracy: 0.999 - ETA: 36s - loss: 0.0051 - accuracy: 0.999 - ETA: 35s - loss: 0.0051 - accuracy: 0.999 - ETA: 34s - loss: 0.0051 - accuracy: 0.999 - ETA: 34s - loss: 0.0051 - accuracy: 0.999 - ETA: 33s - loss: 0.0050 - accuracy: 0.999 - ETA: 32s - loss: 0.0050 - accuracy: 0.999 - ETA: 32s - loss: 0.0050 - accuracy: 0.999 - ETA: 31s - loss: 0.0050 - accuracy: 0.999 - ETA: 30s - loss: 0.0050 - accuracy: 0.999 - ETA: 29s - loss: 0.0049 - accuracy: 0.999 - ETA: 29s - loss: 0.0049 - accuracy: 0.999 - ETA: 28s - loss: 0.0049 - accuracy: 0.999 - ETA: 27s - loss: 0.0049 - accuracy: 0.999 - ETA: 26s - loss: 0.0049 - accuracy: 0.999 - ETA: 26s - loss: 0.0049 - accuracy: 0.999 - ETA: 25s - loss: 0.0049 - accuracy: 0.999 - ETA: 24s - loss: 0.0049 - accuracy: 0.999 - ETA: 24s - loss: 0.0048 - accuracy: 0.999 - ETA: 23s - loss: 0.0050 - accuracy: 0.999 - ETA: 22s - loss: 0.0050 - accuracy: 0.999 - ETA: 21s - loss: 0.0050 - accuracy: 0.999 - ETA: 21s - loss: 0.0049 - accuracy: 0.999 - ETA: 20s - loss: 0.0050 - accuracy: 0.999 - ETA: 19s - loss: 0.0049 - accuracy: 0.999 - ETA: 18s - loss: 0.0049 - accuracy: 0.999 - ETA: 18s - loss: 0.0049 - accuracy: 0.999 - ETA: 17s - loss: 0.0049 - accuracy: 0.999 - ETA: 16s - loss: 0.0049 - accuracy: 0.999 - ETA: 15s - loss: 0.0049 - accuracy: 0.999 - ETA: 15s - loss: 0.0052 - accuracy: 0.999 - ETA: 14s - loss: 0.0051 - accuracy: 0.999 - ETA: 13s - loss: 0.0051 - accuracy: 0.999 - ETA: 13s - loss: 0.0051 - accuracy: 0.999 - ETA: 12s - loss: 0.0052 - accuracy: 0.999 - ETA: 11s - loss: 0.0052 - accuracy: 0.999 - ETA: 10s - loss: 0.0052 - accuracy: 0.999 - ETA: 10s - loss: 0.0052 - accuracy: 0.999 - ETA: 9s - loss: 0.0052 - accuracy: 0.999 - ETA: 8s - loss: 0.0051 - accuracy: 0.99 - ETA: 7s - loss: 0.0051 - accuracy: 0.99 - ETA: 7s - loss: 0.0051 - accuracy: 0.99 - ETA: 6s - loss: 0.0051 - accuracy: 0.99 - ETA: 5s - loss: 0.0051 - accuracy: 0.99 - ETA: 5s - loss: 0.0051 - accuracy: 0.99 - ETA: 4s - loss: 0.0051 - accuracy: 0.99 - ETA: 3s - loss: 0.0051 - accuracy: 0.99 - ETA: 2s - loss: 0.0051 - accuracy: 0.99 - ETA: 2s - loss: 0.0051 - accuracy: 0.99 - ETA: 1s - loss: 0.0051 - accuracy: 0.99 - ETA: 0s - loss: 0.0051 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.9747 - val_accuracy: 0.8060\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:01 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:31 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:31 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:30 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:29 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:29 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:28 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:27 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:26 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:26 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:26 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:25 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:24 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:24 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:23 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:22 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:21 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:20 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:19 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:19 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:18 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:17 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:16 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:16 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:15 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:14 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:13 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:13 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:12 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:12 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:11 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:11 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0036 - accuracy: 0.99 - ETA: 59s - loss: 0.0036 - accuracy: 0.9999 - ETA: 58s - loss: 0.0036 - accuracy: 0.999 - ETA: 57s - loss: 0.0036 - accuracy: 0.999 - ETA: 57s - loss: 0.0036 - accuracy: 0.999 - ETA: 56s - loss: 0.0035 - accuracy: 0.999 - ETA: 55s - loss: 0.0035 - accuracy: 0.999 - ETA: 54s - loss: 0.0035 - accuracy: 0.999 - ETA: 54s - loss: 0.0035 - accuracy: 0.999 - ETA: 53s - loss: 0.0035 - accuracy: 0.999 - ETA: 52s - loss: 0.0035 - accuracy: 0.999 - ETA: 51s - loss: 0.0035 - accuracy: 0.999 - ETA: 51s - loss: 0.0035 - accuracy: 0.999 - ETA: 50s - loss: 0.0034 - accuracy: 0.999 - ETA: 49s - loss: 0.0034 - accuracy: 0.999 - ETA: 48s - loss: 0.0034 - accuracy: 0.999 - ETA: 47s - loss: 0.0034 - accuracy: 0.999 - ETA: 47s - loss: 0.0034 - accuracy: 0.999 - ETA: 46s - loss: 0.0034 - accuracy: 0.999 - ETA: 45s - loss: 0.0033 - accuracy: 0.999 - ETA: 44s - loss: 0.0033 - accuracy: 0.999 - ETA: 44s - loss: 0.0033 - accuracy: 0.999 - ETA: 43s - loss: 0.0033 - accuracy: 0.999 - ETA: 42s - loss: 0.0033 - accuracy: 0.999 - ETA: 41s - loss: 0.0033 - accuracy: 0.999 - ETA: 41s - loss: 0.0033 - accuracy: 0.999 - ETA: 40s - loss: 0.0035 - accuracy: 0.999 - ETA: 39s - loss: 0.0036 - accuracy: 0.999 - ETA: 38s - loss: 0.0036 - accuracy: 0.999 - ETA: 38s - loss: 0.0037 - accuracy: 0.999 - ETA: 37s - loss: 0.0037 - accuracy: 0.999 - ETA: 36s - loss: 0.0037 - accuracy: 0.999 - ETA: 35s - loss: 0.0037 - accuracy: 0.999 - ETA: 35s - loss: 0.0037 - accuracy: 0.999 - ETA: 34s - loss: 0.0037 - accuracy: 0.999 - ETA: 33s - loss: 0.0037 - accuracy: 0.999 - ETA: 32s - loss: 0.0037 - accuracy: 0.999 - ETA: 32s - loss: 0.0037 - accuracy: 0.999 - ETA: 31s - loss: 0.0036 - accuracy: 0.999 - ETA: 30s - loss: 0.0036 - accuracy: 0.999 - ETA: 29s - loss: 0.0036 - accuracy: 0.999 - ETA: 29s - loss: 0.0036 - accuracy: 0.999 - ETA: 28s - loss: 0.0038 - accuracy: 0.999 - ETA: 27s - loss: 0.0038 - accuracy: 0.999 - ETA: 26s - loss: 0.0038 - accuracy: 0.999 - ETA: 25s - loss: 0.0037 - accuracy: 0.999 - ETA: 25s - loss: 0.0037 - accuracy: 0.999 - ETA: 24s - loss: 0.0037 - accuracy: 0.999 - ETA: 23s - loss: 0.0037 - accuracy: 0.999 - ETA: 23s - loss: 0.0037 - accuracy: 0.999 - ETA: 22s - loss: 0.0037 - accuracy: 0.999 - ETA: 21s - loss: 0.0037 - accuracy: 0.999 - ETA: 20s - loss: 0.0037 - accuracy: 0.999 - ETA: 20s - loss: 0.0037 - accuracy: 0.999 - ETA: 19s - loss: 0.0037 - accuracy: 0.999 - ETA: 18s - loss: 0.0037 - accuracy: 0.999 - ETA: 17s - loss: 0.0037 - accuracy: 0.999 - ETA: 17s - loss: 0.0038 - accuracy: 0.999 - ETA: 16s - loss: 0.0037 - accuracy: 0.999 - ETA: 15s - loss: 0.0037 - accuracy: 0.999 - ETA: 14s - loss: 0.0038 - accuracy: 0.999 - ETA: 14s - loss: 0.0038 - accuracy: 0.999 - ETA: 13s - loss: 0.0038 - accuracy: 0.999 - ETA: 12s - loss: 0.0038 - accuracy: 0.999 - ETA: 11s - loss: 0.0038 - accuracy: 0.999 - ETA: 11s - loss: 0.0038 - accuracy: 0.999 - ETA: 10s - loss: 0.0037 - accuracy: 0.999 - ETA: 9s - loss: 0.0039 - accuracy: 0.999 - ETA: 8s - loss: 0.0040 - accuracy: 0.99 - ETA: 8s - loss: 0.0040 - accuracy: 0.99 - ETA: 7s - loss: 0.0040 - accuracy: 0.99 - ETA: 6s - loss: 0.0041 - accuracy: 0.99 - ETA: 5s - loss: 0.0041 - accuracy: 0.99 - ETA: 5s - loss: 0.0041 - accuracy: 0.99 - ETA: 4s - loss: 0.0041 - accuracy: 0.99 - ETA: 3s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 1s - loss: 0.0040 - accuracy: 0.99 - ETA: 0s - loss: 0.0041 - accuracy: 0.99 - 123s 6ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.9655 - val_accuracy: 0.8089\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:52 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0039 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:31 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:30 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:29 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:29 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:28 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:27 - loss: 0.0039 - accuracy: 1.00 - ETA: 1:26 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:26 - loss: 0.0041 - accuracy: 1.00 - ETA: 1:25 - loss: 0.0042 - accuracy: 1.00 - ETA: 1:24 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0052 - accuracy: 0.99 - ETA: 59s - loss: 0.0051 - accuracy: 0.9993 - ETA: 59s - loss: 0.0051 - accuracy: 0.999 - ETA: 58s - loss: 0.0050 - accuracy: 0.999 - ETA: 57s - loss: 0.0050 - accuracy: 0.999 - ETA: 56s - loss: 0.0050 - accuracy: 0.999 - ETA: 56s - loss: 0.0049 - accuracy: 0.999 - ETA: 55s - loss: 0.0049 - accuracy: 0.999 - ETA: 54s - loss: 0.0049 - accuracy: 0.999 - ETA: 53s - loss: 0.0049 - accuracy: 0.999 - ETA: 53s - loss: 0.0048 - accuracy: 0.999 - ETA: 52s - loss: 0.0048 - accuracy: 0.999 - ETA: 51s - loss: 0.0048 - accuracy: 0.999 - ETA: 50s - loss: 0.0051 - accuracy: 0.999 - ETA: 50s - loss: 0.0051 - accuracy: 0.999 - ETA: 49s - loss: 0.0051 - accuracy: 0.999 - ETA: 48s - loss: 0.0051 - accuracy: 0.999 - ETA: 48s - loss: 0.0051 - accuracy: 0.999 - ETA: 47s - loss: 0.0051 - accuracy: 0.999 - ETA: 46s - loss: 0.0050 - accuracy: 0.999 - ETA: 45s - loss: 0.0050 - accuracy: 0.999 - ETA: 45s - loss: 0.0050 - accuracy: 0.999 - ETA: 44s - loss: 0.0050 - accuracy: 0.999 - ETA: 43s - loss: 0.0049 - accuracy: 0.999 - ETA: 42s - loss: 0.0049 - accuracy: 0.999 - ETA: 42s - loss: 0.0049 - accuracy: 0.999 - ETA: 41s - loss: 0.0049 - accuracy: 0.999 - ETA: 40s - loss: 0.0049 - accuracy: 0.999 - ETA: 39s - loss: 0.0049 - accuracy: 0.999 - ETA: 39s - loss: 0.0048 - accuracy: 0.999 - ETA: 38s - loss: 0.0051 - accuracy: 0.999 - ETA: 37s - loss: 0.0051 - accuracy: 0.999 - ETA: 37s - loss: 0.0051 - accuracy: 0.999 - ETA: 36s - loss: 0.0051 - accuracy: 0.999 - ETA: 35s - loss: 0.0051 - accuracy: 0.999 - ETA: 34s - loss: 0.0050 - accuracy: 0.999 - ETA: 34s - loss: 0.0050 - accuracy: 0.999 - ETA: 33s - loss: 0.0050 - accuracy: 0.999 - ETA: 32s - loss: 0.0050 - accuracy: 0.999 - ETA: 31s - loss: 0.0049 - accuracy: 0.999 - ETA: 31s - loss: 0.0050 - accuracy: 0.999 - ETA: 30s - loss: 0.0049 - accuracy: 0.999 - ETA: 29s - loss: 0.0049 - accuracy: 0.999 - ETA: 29s - loss: 0.0049 - accuracy: 0.999 - ETA: 28s - loss: 0.0049 - accuracy: 0.999 - ETA: 27s - loss: 0.0049 - accuracy: 0.999 - ETA: 26s - loss: 0.0049 - accuracy: 0.999 - ETA: 26s - loss: 0.0049 - accuracy: 0.999 - ETA: 25s - loss: 0.0049 - accuracy: 0.999 - ETA: 24s - loss: 0.0049 - accuracy: 0.999 - ETA: 23s - loss: 0.0049 - accuracy: 0.999 - ETA: 23s - loss: 0.0049 - accuracy: 0.999 - ETA: 22s - loss: 0.0049 - accuracy: 0.999 - ETA: 21s - loss: 0.0049 - accuracy: 0.999 - ETA: 20s - loss: 0.0049 - accuracy: 0.999 - ETA: 20s - loss: 0.0049 - accuracy: 0.999 - ETA: 19s - loss: 0.0049 - accuracy: 0.999 - ETA: 18s - loss: 0.0049 - accuracy: 0.999 - ETA: 18s - loss: 0.0049 - accuracy: 0.999 - ETA: 17s - loss: 0.0048 - accuracy: 0.999 - ETA: 16s - loss: 0.0048 - accuracy: 0.999 - ETA: 15s - loss: 0.0048 - accuracy: 0.999 - ETA: 15s - loss: 0.0048 - accuracy: 0.999 - ETA: 14s - loss: 0.0048 - accuracy: 0.999 - ETA: 13s - loss: 0.0048 - accuracy: 0.999 - ETA: 12s - loss: 0.0048 - accuracy: 0.999 - ETA: 12s - loss: 0.0047 - accuracy: 0.999 - ETA: 11s - loss: 0.0047 - accuracy: 0.999 - ETA: 10s - loss: 0.0047 - accuracy: 0.999 - ETA: 10s - loss: 0.0048 - accuracy: 0.999 - ETA: 9s - loss: 0.0048 - accuracy: 0.999 - ETA: 8s - loss: 0.0048 - accuracy: 0.99 - ETA: 7s - loss: 0.0048 - accuracy: 0.99 - ETA: 7s - loss: 0.0047 - accuracy: 0.99 - ETA: 6s - loss: 0.0047 - accuracy: 0.99 - ETA: 5s - loss: 0.0047 - accuracy: 0.99 - ETA: 4s - loss: 0.0047 - accuracy: 0.99 - ETA: 4s - loss: 0.0047 - accuracy: 0.99 - ETA: 3s - loss: 0.0047 - accuracy: 0.99 - ETA: 2s - loss: 0.0047 - accuracy: 0.99 - ETA: 2s - loss: 0.0047 - accuracy: 0.99 - ETA: 1s - loss: 0.0046 - accuracy: 0.99 - ETA: 0s - loss: 0.0046 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.9745 - val_accuracy: 0.8035\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:49 - loss: 0.0045 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:31 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:30 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:29 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:29 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:28 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:28 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:27 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:26 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:25 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0034 - accuracy: 0.99 - ETA: 59s - loss: 0.0034 - accuracy: 0.9997 - ETA: 58s - loss: 0.0034 - accuracy: 0.999 - ETA: 58s - loss: 0.0034 - accuracy: 0.999 - ETA: 57s - loss: 0.0034 - accuracy: 0.999 - ETA: 56s - loss: 0.0036 - accuracy: 0.999 - ETA: 56s - loss: 0.0036 - accuracy: 0.999 - ETA: 55s - loss: 0.0036 - accuracy: 0.999 - ETA: 54s - loss: 0.0036 - accuracy: 0.999 - ETA: 54s - loss: 0.0036 - accuracy: 0.999 - ETA: 53s - loss: 0.0036 - accuracy: 0.999 - ETA: 52s - loss: 0.0037 - accuracy: 0.999 - ETA: 52s - loss: 0.0037 - accuracy: 0.999 - ETA: 51s - loss: 0.0037 - accuracy: 0.999 - ETA: 50s - loss: 0.0037 - accuracy: 0.999 - ETA: 49s - loss: 0.0037 - accuracy: 0.999 - ETA: 49s - loss: 0.0037 - accuracy: 0.999 - ETA: 48s - loss: 0.0037 - accuracy: 0.999 - ETA: 47s - loss: 0.0037 - accuracy: 0.999 - ETA: 47s - loss: 0.0037 - accuracy: 0.999 - ETA: 46s - loss: 0.0038 - accuracy: 0.999 - ETA: 45s - loss: 0.0038 - accuracy: 0.999 - ETA: 44s - loss: 0.0038 - accuracy: 0.999 - ETA: 44s - loss: 0.0038 - accuracy: 0.999 - ETA: 43s - loss: 0.0038 - accuracy: 0.999 - ETA: 42s - loss: 0.0038 - accuracy: 0.999 - ETA: 41s - loss: 0.0038 - accuracy: 0.999 - ETA: 41s - loss: 0.0039 - accuracy: 0.999 - ETA: 40s - loss: 0.0039 - accuracy: 0.999 - ETA: 39s - loss: 0.0039 - accuracy: 0.999 - ETA: 38s - loss: 0.0039 - accuracy: 0.999 - ETA: 38s - loss: 0.0039 - accuracy: 0.999 - ETA: 37s - loss: 0.0039 - accuracy: 0.999 - ETA: 36s - loss: 0.0039 - accuracy: 0.999 - ETA: 36s - loss: 0.0039 - accuracy: 0.999 - ETA: 35s - loss: 0.0038 - accuracy: 0.999 - ETA: 34s - loss: 0.0038 - accuracy: 0.999 - ETA: 34s - loss: 0.0038 - accuracy: 0.999 - ETA: 33s - loss: 0.0038 - accuracy: 0.999 - ETA: 32s - loss: 0.0038 - accuracy: 0.999 - ETA: 31s - loss: 0.0038 - accuracy: 0.999 - ETA: 31s - loss: 0.0037 - accuracy: 0.999 - ETA: 30s - loss: 0.0037 - accuracy: 0.999 - ETA: 29s - loss: 0.0037 - accuracy: 0.999 - ETA: 28s - loss: 0.0037 - accuracy: 0.999 - ETA: 28s - loss: 0.0037 - accuracy: 0.999 - ETA: 27s - loss: 0.0037 - accuracy: 0.999 - ETA: 26s - loss: 0.0037 - accuracy: 0.999 - ETA: 25s - loss: 0.0037 - accuracy: 0.999 - ETA: 25s - loss: 0.0037 - accuracy: 0.999 - ETA: 24s - loss: 0.0037 - accuracy: 0.999 - ETA: 23s - loss: 0.0037 - accuracy: 0.999 - ETA: 22s - loss: 0.0037 - accuracy: 0.999 - ETA: 22s - loss: 0.0037 - accuracy: 0.999 - ETA: 21s - loss: 0.0037 - accuracy: 0.999 - ETA: 20s - loss: 0.0037 - accuracy: 0.999 - ETA: 19s - loss: 0.0037 - accuracy: 0.999 - ETA: 19s - loss: 0.0037 - accuracy: 0.999 - ETA: 18s - loss: 0.0037 - accuracy: 0.999 - ETA: 17s - loss: 0.0037 - accuracy: 0.999 - ETA: 16s - loss: 0.0036 - accuracy: 0.999 - ETA: 16s - loss: 0.0036 - accuracy: 0.999 - ETA: 15s - loss: 0.0037 - accuracy: 0.999 - ETA: 14s - loss: 0.0037 - accuracy: 0.999 - ETA: 13s - loss: 0.0037 - accuracy: 0.999 - ETA: 13s - loss: 0.0037 - accuracy: 0.999 - ETA: 12s - loss: 0.0037 - accuracy: 0.999 - ETA: 11s - loss: 0.0037 - accuracy: 0.999 - ETA: 11s - loss: 0.0037 - accuracy: 0.999 - ETA: 10s - loss: 0.0037 - accuracy: 0.999 - ETA: 9s - loss: 0.0037 - accuracy: 0.999 - ETA: 8s - loss: 0.0036 - accuracy: 0.99 - ETA: 8s - loss: 0.0036 - accuracy: 0.99 - ETA: 7s - loss: 0.0037 - accuracy: 0.99 - ETA: 6s - loss: 0.0038 - accuracy: 0.99 - ETA: 5s - loss: 0.0038 - accuracy: 0.99 - ETA: 5s - loss: 0.0037 - accuracy: 0.99 - ETA: 4s - loss: 0.0038 - accuracy: 0.99 - ETA: 3s - loss: 0.0038 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 1s - loss: 0.0038 - accuracy: 0.99 - ETA: 0s - loss: 0.0039 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.9770 - val_accuracy: 0.8041\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:53 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0082 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0086 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0077 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0057 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0044 - accuracy: 0.99 - ETA: 59s - loss: 0.0045 - accuracy: 0.9991 - ETA: 58s - loss: 0.0045 - accuracy: 0.999 - ETA: 57s - loss: 0.0045 - accuracy: 0.999 - ETA: 57s - loss: 0.0045 - accuracy: 0.999 - ETA: 56s - loss: 0.0045 - accuracy: 0.999 - ETA: 55s - loss: 0.0045 - accuracy: 0.999 - ETA: 54s - loss: 0.0045 - accuracy: 0.999 - ETA: 54s - loss: 0.0044 - accuracy: 0.999 - ETA: 53s - loss: 0.0044 - accuracy: 0.999 - ETA: 52s - loss: 0.0044 - accuracy: 0.999 - ETA: 52s - loss: 0.0044 - accuracy: 0.999 - ETA: 51s - loss: 0.0044 - accuracy: 0.999 - ETA: 50s - loss: 0.0044 - accuracy: 0.999 - ETA: 49s - loss: 0.0044 - accuracy: 0.999 - ETA: 49s - loss: 0.0043 - accuracy: 0.999 - ETA: 48s - loss: 0.0043 - accuracy: 0.999 - ETA: 47s - loss: 0.0043 - accuracy: 0.999 - ETA: 46s - loss: 0.0043 - accuracy: 0.999 - ETA: 46s - loss: 0.0043 - accuracy: 0.999 - ETA: 45s - loss: 0.0042 - accuracy: 0.999 - ETA: 44s - loss: 0.0042 - accuracy: 0.999 - ETA: 43s - loss: 0.0042 - accuracy: 0.999 - ETA: 43s - loss: 0.0042 - accuracy: 0.999 - ETA: 42s - loss: 0.0042 - accuracy: 0.999 - ETA: 41s - loss: 0.0042 - accuracy: 0.999 - ETA: 41s - loss: 0.0043 - accuracy: 0.999 - ETA: 40s - loss: 0.0042 - accuracy: 0.999 - ETA: 39s - loss: 0.0043 - accuracy: 0.999 - ETA: 38s - loss: 0.0042 - accuracy: 0.999 - ETA: 38s - loss: 0.0042 - accuracy: 0.999 - ETA: 37s - loss: 0.0042 - accuracy: 0.999 - ETA: 36s - loss: 0.0042 - accuracy: 0.999 - ETA: 35s - loss: 0.0043 - accuracy: 0.999 - ETA: 35s - loss: 0.0042 - accuracy: 0.999 - ETA: 34s - loss: 0.0042 - accuracy: 0.999 - ETA: 33s - loss: 0.0042 - accuracy: 0.999 - ETA: 32s - loss: 0.0042 - accuracy: 0.999 - ETA: 32s - loss: 0.0042 - accuracy: 0.999 - ETA: 31s - loss: 0.0042 - accuracy: 0.999 - ETA: 30s - loss: 0.0042 - accuracy: 0.999 - ETA: 30s - loss: 0.0042 - accuracy: 0.999 - ETA: 29s - loss: 0.0042 - accuracy: 0.999 - ETA: 28s - loss: 0.0042 - accuracy: 0.999 - ETA: 27s - loss: 0.0042 - accuracy: 0.999 - ETA: 27s - loss: 0.0042 - accuracy: 0.999 - ETA: 26s - loss: 0.0042 - accuracy: 0.999 - ETA: 25s - loss: 0.0042 - accuracy: 0.999 - ETA: 24s - loss: 0.0042 - accuracy: 0.999 - ETA: 24s - loss: 0.0042 - accuracy: 0.999 - ETA: 23s - loss: 0.0041 - accuracy: 0.999 - ETA: 22s - loss: 0.0041 - accuracy: 0.999 - ETA: 21s - loss: 0.0041 - accuracy: 0.999 - ETA: 21s - loss: 0.0041 - accuracy: 0.999 - ETA: 20s - loss: 0.0041 - accuracy: 0.999 - ETA: 19s - loss: 0.0041 - accuracy: 0.999 - ETA: 19s - loss: 0.0041 - accuracy: 0.999 - ETA: 18s - loss: 0.0041 - accuracy: 0.999 - ETA: 17s - loss: 0.0041 - accuracy: 0.999 - ETA: 16s - loss: 0.0041 - accuracy: 0.999 - ETA: 16s - loss: 0.0041 - accuracy: 0.999 - ETA: 15s - loss: 0.0041 - accuracy: 0.999 - ETA: 14s - loss: 0.0041 - accuracy: 0.999 - ETA: 13s - loss: 0.0040 - accuracy: 0.999 - ETA: 13s - loss: 0.0040 - accuracy: 0.999 - ETA: 12s - loss: 0.0040 - accuracy: 0.999 - ETA: 11s - loss: 0.0040 - accuracy: 0.999 - ETA: 10s - loss: 0.0040 - accuracy: 0.999 - ETA: 10s - loss: 0.0041 - accuracy: 0.999 - ETA: 9s - loss: 0.0041 - accuracy: 0.999 - ETA: 8s - loss: 0.0040 - accuracy: 0.99 - ETA: 7s - loss: 0.0041 - accuracy: 0.99 - ETA: 7s - loss: 0.0041 - accuracy: 0.99 - ETA: 6s - loss: 0.0044 - accuracy: 0.99 - ETA: 5s - loss: 0.0044 - accuracy: 0.99 - ETA: 5s - loss: 0.0044 - accuracy: 0.99 - ETA: 4s - loss: 0.0044 - accuracy: 0.99 - ETA: 3s - loss: 0.0045 - accuracy: 0.99 - ETA: 2s - loss: 0.0045 - accuracy: 0.99 - ETA: 2s - loss: 0.0045 - accuracy: 0.99 - ETA: 1s - loss: 0.0044 - accuracy: 0.99 - ETA: 0s - loss: 0.0044 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.9596 - val_accuracy: 0.8074\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:06 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:56 - loss: 0.0045 - accuracy: 1.00 - ETA: 1:53 - loss: 0.0049 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0041 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0039 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0035 - accuracy: 0.99 - ETA: 59s - loss: 0.0035 - accuracy: 0.9997 - ETA: 58s - loss: 0.0035 - accuracy: 0.999 - ETA: 57s - loss: 0.0035 - accuracy: 0.999 - ETA: 57s - loss: 0.0035 - accuracy: 0.999 - ETA: 56s - loss: 0.0036 - accuracy: 0.999 - ETA: 55s - loss: 0.0036 - accuracy: 0.999 - ETA: 54s - loss: 0.0036 - accuracy: 0.999 - ETA: 54s - loss: 0.0036 - accuracy: 0.999 - ETA: 53s - loss: 0.0035 - accuracy: 0.999 - ETA: 52s - loss: 0.0035 - accuracy: 0.999 - ETA: 51s - loss: 0.0035 - accuracy: 0.999 - ETA: 51s - loss: 0.0035 - accuracy: 0.999 - ETA: 50s - loss: 0.0034 - accuracy: 0.999 - ETA: 49s - loss: 0.0035 - accuracy: 0.999 - ETA: 48s - loss: 0.0037 - accuracy: 0.999 - ETA: 48s - loss: 0.0037 - accuracy: 0.999 - ETA: 47s - loss: 0.0037 - accuracy: 0.999 - ETA: 46s - loss: 0.0037 - accuracy: 0.999 - ETA: 46s - loss: 0.0037 - accuracy: 0.999 - ETA: 45s - loss: 0.0037 - accuracy: 0.999 - ETA: 44s - loss: 0.0037 - accuracy: 0.999 - ETA: 43s - loss: 0.0036 - accuracy: 0.999 - ETA: 43s - loss: 0.0036 - accuracy: 0.999 - ETA: 42s - loss: 0.0036 - accuracy: 0.999 - ETA: 41s - loss: 0.0036 - accuracy: 0.999 - ETA: 40s - loss: 0.0036 - accuracy: 0.999 - ETA: 40s - loss: 0.0036 - accuracy: 0.999 - ETA: 39s - loss: 0.0035 - accuracy: 0.999 - ETA: 38s - loss: 0.0035 - accuracy: 0.999 - ETA: 37s - loss: 0.0035 - accuracy: 0.999 - ETA: 37s - loss: 0.0035 - accuracy: 0.999 - ETA: 36s - loss: 0.0035 - accuracy: 0.999 - ETA: 35s - loss: 0.0035 - accuracy: 0.999 - ETA: 35s - loss: 0.0036 - accuracy: 0.999 - ETA: 34s - loss: 0.0036 - accuracy: 0.999 - ETA: 33s - loss: 0.0040 - accuracy: 0.999 - ETA: 32s - loss: 0.0039 - accuracy: 0.999 - ETA: 32s - loss: 0.0039 - accuracy: 0.999 - ETA: 31s - loss: 0.0039 - accuracy: 0.999 - ETA: 30s - loss: 0.0039 - accuracy: 0.999 - ETA: 30s - loss: 0.0039 - accuracy: 0.999 - ETA: 29s - loss: 0.0039 - accuracy: 0.999 - ETA: 28s - loss: 0.0039 - accuracy: 0.999 - ETA: 27s - loss: 0.0039 - accuracy: 0.999 - ETA: 27s - loss: 0.0039 - accuracy: 0.999 - ETA: 26s - loss: 0.0039 - accuracy: 0.999 - ETA: 25s - loss: 0.0039 - accuracy: 0.999 - ETA: 24s - loss: 0.0039 - accuracy: 0.999 - ETA: 24s - loss: 0.0039 - accuracy: 0.999 - ETA: 23s - loss: 0.0039 - accuracy: 0.999 - ETA: 22s - loss: 0.0039 - accuracy: 0.999 - ETA: 21s - loss: 0.0038 - accuracy: 0.999 - ETA: 21s - loss: 0.0038 - accuracy: 0.999 - ETA: 20s - loss: 0.0038 - accuracy: 0.999 - ETA: 19s - loss: 0.0038 - accuracy: 0.999 - ETA: 18s - loss: 0.0038 - accuracy: 0.999 - ETA: 18s - loss: 0.0038 - accuracy: 0.999 - ETA: 17s - loss: 0.0038 - accuracy: 0.999 - ETA: 16s - loss: 0.0038 - accuracy: 0.999 - ETA: 16s - loss: 0.0038 - accuracy: 0.999 - ETA: 15s - loss: 0.0038 - accuracy: 0.999 - ETA: 14s - loss: 0.0038 - accuracy: 0.999 - ETA: 13s - loss: 0.0039 - accuracy: 0.999 - ETA: 13s - loss: 0.0039 - accuracy: 0.999 - ETA: 12s - loss: 0.0039 - accuracy: 0.999 - ETA: 11s - loss: 0.0039 - accuracy: 0.999 - ETA: 10s - loss: 0.0039 - accuracy: 0.999 - ETA: 10s - loss: 0.0039 - accuracy: 0.999 - ETA: 9s - loss: 0.0039 - accuracy: 0.999 - ETA: 8s - loss: 0.0039 - accuracy: 0.99 - ETA: 7s - loss: 0.0039 - accuracy: 0.99 - ETA: 7s - loss: 0.0039 - accuracy: 0.99 - ETA: 6s - loss: 0.0039 - accuracy: 0.99 - ETA: 5s - loss: 0.0039 - accuracy: 0.99 - ETA: 5s - loss: 0.0039 - accuracy: 0.99 - ETA: 4s - loss: 0.0039 - accuracy: 0.99 - ETA: 3s - loss: 0.0039 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 1s - loss: 0.0038 - accuracy: 0.99 - ETA: 0s - loss: 0.0039 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.9757 - val_accuracy: 0.8053\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:46 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:31 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:30 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:30 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:29 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:28 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:28 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:27 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:26 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:26 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:25 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:25 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:24 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:23 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:22 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:22 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:21 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:20 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:19 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:19 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:18 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:17 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:16 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:16 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:15 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:14 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:13 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:13 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:12 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:11 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:11 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:10 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0039 - accuracy: 0.99 - ETA: 59s - loss: 0.0039 - accuracy: 0.9998 - ETA: 59s - loss: 0.0039 - accuracy: 0.999 - ETA: 58s - loss: 0.0039 - accuracy: 0.999 - ETA: 57s - loss: 0.0038 - accuracy: 0.999 - ETA: 56s - loss: 0.0038 - accuracy: 0.999 - ETA: 56s - loss: 0.0038 - accuracy: 0.999 - ETA: 55s - loss: 0.0037 - accuracy: 0.999 - ETA: 54s - loss: 0.0038 - accuracy: 0.999 - ETA: 54s - loss: 0.0038 - accuracy: 0.999 - ETA: 53s - loss: 0.0038 - accuracy: 0.999 - ETA: 52s - loss: 0.0038 - accuracy: 0.999 - ETA: 51s - loss: 0.0038 - accuracy: 0.999 - ETA: 51s - loss: 0.0038 - accuracy: 0.999 - ETA: 50s - loss: 0.0038 - accuracy: 0.999 - ETA: 49s - loss: 0.0037 - accuracy: 0.999 - ETA: 48s - loss: 0.0037 - accuracy: 0.999 - ETA: 48s - loss: 0.0038 - accuracy: 0.999 - ETA: 47s - loss: 0.0038 - accuracy: 0.999 - ETA: 46s - loss: 0.0038 - accuracy: 0.999 - ETA: 45s - loss: 0.0037 - accuracy: 0.999 - ETA: 45s - loss: 0.0037 - accuracy: 0.999 - ETA: 44s - loss: 0.0037 - accuracy: 0.999 - ETA: 43s - loss: 0.0037 - accuracy: 0.999 - ETA: 43s - loss: 0.0037 - accuracy: 0.999 - ETA: 42s - loss: 0.0037 - accuracy: 0.999 - ETA: 41s - loss: 0.0038 - accuracy: 0.999 - ETA: 40s - loss: 0.0038 - accuracy: 0.999 - ETA: 40s - loss: 0.0038 - accuracy: 0.999 - ETA: 39s - loss: 0.0038 - accuracy: 0.999 - ETA: 38s - loss: 0.0038 - accuracy: 0.999 - ETA: 37s - loss: 0.0038 - accuracy: 0.999 - ETA: 37s - loss: 0.0038 - accuracy: 0.999 - ETA: 36s - loss: 0.0038 - accuracy: 0.999 - ETA: 35s - loss: 0.0040 - accuracy: 0.999 - ETA: 34s - loss: 0.0040 - accuracy: 0.999 - ETA: 34s - loss: 0.0040 - accuracy: 0.999 - ETA: 33s - loss: 0.0040 - accuracy: 0.999 - ETA: 32s - loss: 0.0040 - accuracy: 0.999 - ETA: 31s - loss: 0.0039 - accuracy: 0.999 - ETA: 31s - loss: 0.0039 - accuracy: 0.999 - ETA: 30s - loss: 0.0039 - accuracy: 0.999 - ETA: 29s - loss: 0.0039 - accuracy: 0.999 - ETA: 29s - loss: 0.0039 - accuracy: 0.999 - ETA: 28s - loss: 0.0038 - accuracy: 0.999 - ETA: 27s - loss: 0.0038 - accuracy: 0.999 - ETA: 26s - loss: 0.0038 - accuracy: 0.999 - ETA: 26s - loss: 0.0038 - accuracy: 0.999 - ETA: 25s - loss: 0.0039 - accuracy: 0.999 - ETA: 24s - loss: 0.0039 - accuracy: 0.999 - ETA: 23s - loss: 0.0039 - accuracy: 0.999 - ETA: 23s - loss: 0.0040 - accuracy: 0.999 - ETA: 22s - loss: 0.0040 - accuracy: 0.999 - ETA: 21s - loss: 0.0040 - accuracy: 0.999 - ETA: 21s - loss: 0.0040 - accuracy: 0.999 - ETA: 20s - loss: 0.0040 - accuracy: 0.999 - ETA: 19s - loss: 0.0040 - accuracy: 0.999 - ETA: 18s - loss: 0.0042 - accuracy: 0.999 - ETA: 18s - loss: 0.0041 - accuracy: 0.999 - ETA: 17s - loss: 0.0041 - accuracy: 0.999 - ETA: 16s - loss: 0.0043 - accuracy: 0.999 - ETA: 15s - loss: 0.0043 - accuracy: 0.999 - ETA: 15s - loss: 0.0043 - accuracy: 0.999 - ETA: 14s - loss: 0.0043 - accuracy: 0.999 - ETA: 13s - loss: 0.0043 - accuracy: 0.999 - ETA: 13s - loss: 0.0042 - accuracy: 0.999 - ETA: 12s - loss: 0.0042 - accuracy: 0.999 - ETA: 11s - loss: 0.0042 - accuracy: 0.999 - ETA: 10s - loss: 0.0043 - accuracy: 0.999 - ETA: 10s - loss: 0.0043 - accuracy: 0.999 - ETA: 9s - loss: 0.0043 - accuracy: 0.999 - ETA: 8s - loss: 0.0043 - accuracy: 0.99 - ETA: 7s - loss: 0.0043 - accuracy: 0.99 - ETA: 7s - loss: 0.0043 - accuracy: 0.99 - ETA: 6s - loss: 0.0043 - accuracy: 0.99 - ETA: 5s - loss: 0.0044 - accuracy: 0.99 - ETA: 5s - loss: 0.0043 - accuracy: 0.99 - ETA: 4s - loss: 0.0043 - accuracy: 0.99 - ETA: 3s - loss: 0.0043 - accuracy: 0.99 - ETA: 2s - loss: 0.0043 - accuracy: 0.99 - ETA: 2s - loss: 0.0043 - accuracy: 0.99 - ETA: 1s - loss: 0.0043 - accuracy: 0.99 - ETA: 0s - loss: 0.0043 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.9711 - val_accuracy: 0.8076\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:48 - loss: 0.0092 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0051 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0044 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0039 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0040 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0045 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0043 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0042 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0043 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0041 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0041 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0049 - accuracy: 0.99 - ETA: 59s - loss: 0.0049 - accuracy: 0.9991 - ETA: 58s - loss: 0.0048 - accuracy: 0.999 - ETA: 57s - loss: 0.0048 - accuracy: 0.999 - ETA: 57s - loss: 0.0048 - accuracy: 0.999 - ETA: 56s - loss: 0.0048 - accuracy: 0.999 - ETA: 55s - loss: 0.0047 - accuracy: 0.999 - ETA: 54s - loss: 0.0047 - accuracy: 0.999 - ETA: 54s - loss: 0.0047 - accuracy: 0.999 - ETA: 53s - loss: 0.0046 - accuracy: 0.999 - ETA: 52s - loss: 0.0052 - accuracy: 0.999 - ETA: 51s - loss: 0.0052 - accuracy: 0.999 - ETA: 51s - loss: 0.0051 - accuracy: 0.999 - ETA: 50s - loss: 0.0051 - accuracy: 0.999 - ETA: 49s - loss: 0.0050 - accuracy: 0.999 - ETA: 48s - loss: 0.0050 - accuracy: 0.999 - ETA: 48s - loss: 0.0049 - accuracy: 0.999 - ETA: 47s - loss: 0.0050 - accuracy: 0.999 - ETA: 46s - loss: 0.0050 - accuracy: 0.999 - ETA: 45s - loss: 0.0049 - accuracy: 0.999 - ETA: 45s - loss: 0.0049 - accuracy: 0.999 - ETA: 44s - loss: 0.0049 - accuracy: 0.999 - ETA: 43s - loss: 0.0049 - accuracy: 0.999 - ETA: 42s - loss: 0.0048 - accuracy: 0.999 - ETA: 42s - loss: 0.0048 - accuracy: 0.999 - ETA: 41s - loss: 0.0048 - accuracy: 0.999 - ETA: 40s - loss: 0.0048 - accuracy: 0.999 - ETA: 40s - loss: 0.0048 - accuracy: 0.999 - ETA: 39s - loss: 0.0047 - accuracy: 0.999 - ETA: 38s - loss: 0.0047 - accuracy: 0.999 - ETA: 37s - loss: 0.0047 - accuracy: 0.999 - ETA: 37s - loss: 0.0047 - accuracy: 0.999 - ETA: 36s - loss: 0.0047 - accuracy: 0.999 - ETA: 35s - loss: 0.0047 - accuracy: 0.999 - ETA: 34s - loss: 0.0047 - accuracy: 0.999 - ETA: 34s - loss: 0.0046 - accuracy: 0.999 - ETA: 33s - loss: 0.0046 - accuracy: 0.999 - ETA: 32s - loss: 0.0046 - accuracy: 0.999 - ETA: 32s - loss: 0.0046 - accuracy: 0.999 - ETA: 31s - loss: 0.0045 - accuracy: 0.999 - ETA: 30s - loss: 0.0045 - accuracy: 0.999 - ETA: 29s - loss: 0.0045 - accuracy: 0.999 - ETA: 29s - loss: 0.0045 - accuracy: 0.999 - ETA: 28s - loss: 0.0045 - accuracy: 0.999 - ETA: 27s - loss: 0.0048 - accuracy: 0.999 - ETA: 26s - loss: 0.0047 - accuracy: 0.999 - ETA: 26s - loss: 0.0047 - accuracy: 0.999 - ETA: 25s - loss: 0.0047 - accuracy: 0.999 - ETA: 24s - loss: 0.0047 - accuracy: 0.999 - ETA: 24s - loss: 0.0047 - accuracy: 0.999 - ETA: 23s - loss: 0.0046 - accuracy: 0.999 - ETA: 22s - loss: 0.0046 - accuracy: 0.999 - ETA: 21s - loss: 0.0046 - accuracy: 0.999 - ETA: 21s - loss: 0.0046 - accuracy: 0.999 - ETA: 20s - loss: 0.0046 - accuracy: 0.999 - ETA: 19s - loss: 0.0046 - accuracy: 0.999 - ETA: 18s - loss: 0.0046 - accuracy: 0.999 - ETA: 18s - loss: 0.0045 - accuracy: 0.999 - ETA: 17s - loss: 0.0045 - accuracy: 0.999 - ETA: 16s - loss: 0.0045 - accuracy: 0.999 - ETA: 15s - loss: 0.0045 - accuracy: 0.999 - ETA: 15s - loss: 0.0045 - accuracy: 0.999 - ETA: 14s - loss: 0.0045 - accuracy: 0.999 - ETA: 13s - loss: 0.0045 - accuracy: 0.999 - ETA: 13s - loss: 0.0044 - accuracy: 0.999 - ETA: 12s - loss: 0.0044 - accuracy: 0.999 - ETA: 11s - loss: 0.0044 - accuracy: 0.999 - ETA: 10s - loss: 0.0044 - accuracy: 0.999 - ETA: 10s - loss: 0.0044 - accuracy: 0.999 - ETA: 9s - loss: 0.0044 - accuracy: 0.999 - ETA: 8s - loss: 0.0043 - accuracy: 0.99 - ETA: 7s - loss: 0.0044 - accuracy: 0.99 - ETA: 7s - loss: 0.0044 - accuracy: 0.99 - ETA: 6s - loss: 0.0043 - accuracy: 0.99 - ETA: 5s - loss: 0.0044 - accuracy: 0.99 - ETA: 5s - loss: 0.0045 - accuracy: 0.99 - ETA: 4s - loss: 0.0045 - accuracy: 0.99 - ETA: 3s - loss: 0.0044 - accuracy: 0.99 - ETA: 2s - loss: 0.0044 - accuracy: 0.99 - ETA: 2s - loss: 0.0044 - accuracy: 0.99 - ETA: 1s - loss: 0.0044 - accuracy: 0.99 - ETA: 0s - loss: 0.0044 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.9789 - val_accuracy: 0.8093\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:55 - loss: 0.0083 - accuracy: 1.00 - ETA: 1:54 - loss: 0.0049 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0043 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0039 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0046 - accuracy: 0.99 - ETA: 59s - loss: 0.0046 - accuracy: 0.9995 - ETA: 58s - loss: 0.0045 - accuracy: 0.999 - ETA: 58s - loss: 0.0045 - accuracy: 0.999 - ETA: 57s - loss: 0.0047 - accuracy: 0.999 - ETA: 56s - loss: 0.0047 - accuracy: 0.999 - ETA: 56s - loss: 0.0047 - accuracy: 0.999 - ETA: 55s - loss: 0.0046 - accuracy: 0.999 - ETA: 54s - loss: 0.0046 - accuracy: 0.999 - ETA: 53s - loss: 0.0046 - accuracy: 0.999 - ETA: 53s - loss: 0.0046 - accuracy: 0.999 - ETA: 52s - loss: 0.0045 - accuracy: 0.999 - ETA: 51s - loss: 0.0045 - accuracy: 0.999 - ETA: 50s - loss: 0.0045 - accuracy: 0.999 - ETA: 50s - loss: 0.0045 - accuracy: 0.999 - ETA: 49s - loss: 0.0046 - accuracy: 0.999 - ETA: 48s - loss: 0.0045 - accuracy: 0.999 - ETA: 47s - loss: 0.0045 - accuracy: 0.999 - ETA: 47s - loss: 0.0045 - accuracy: 0.999 - ETA: 46s - loss: 0.0044 - accuracy: 0.999 - ETA: 45s - loss: 0.0044 - accuracy: 0.999 - ETA: 45s - loss: 0.0043 - accuracy: 0.999 - ETA: 44s - loss: 0.0043 - accuracy: 0.999 - ETA: 43s - loss: 0.0043 - accuracy: 0.999 - ETA: 42s - loss: 0.0043 - accuracy: 0.999 - ETA: 42s - loss: 0.0042 - accuracy: 0.999 - ETA: 41s - loss: 0.0042 - accuracy: 0.999 - ETA: 40s - loss: 0.0042 - accuracy: 0.999 - ETA: 40s - loss: 0.0042 - accuracy: 0.999 - ETA: 39s - loss: 0.0042 - accuracy: 0.999 - ETA: 38s - loss: 0.0042 - accuracy: 0.999 - ETA: 37s - loss: 0.0041 - accuracy: 0.999 - ETA: 37s - loss: 0.0042 - accuracy: 0.999 - ETA: 36s - loss: 0.0042 - accuracy: 0.999 - ETA: 35s - loss: 0.0043 - accuracy: 0.999 - ETA: 34s - loss: 0.0043 - accuracy: 0.999 - ETA: 34s - loss: 0.0042 - accuracy: 0.999 - ETA: 33s - loss: 0.0042 - accuracy: 0.999 - ETA: 32s - loss: 0.0042 - accuracy: 0.999 - ETA: 31s - loss: 0.0042 - accuracy: 0.999 - ETA: 31s - loss: 0.0043 - accuracy: 0.999 - ETA: 30s - loss: 0.0043 - accuracy: 0.999 - ETA: 29s - loss: 0.0042 - accuracy: 0.999 - ETA: 29s - loss: 0.0042 - accuracy: 0.999 - ETA: 28s - loss: 0.0042 - accuracy: 0.999 - ETA: 27s - loss: 0.0042 - accuracy: 0.999 - ETA: 26s - loss: 0.0042 - accuracy: 0.999 - ETA: 26s - loss: 0.0042 - accuracy: 0.999 - ETA: 25s - loss: 0.0042 - accuracy: 0.999 - ETA: 24s - loss: 0.0042 - accuracy: 0.999 - ETA: 23s - loss: 0.0042 - accuracy: 0.999 - ETA: 23s - loss: 0.0041 - accuracy: 0.999 - ETA: 22s - loss: 0.0041 - accuracy: 0.999 - ETA: 21s - loss: 0.0041 - accuracy: 0.999 - ETA: 21s - loss: 0.0041 - accuracy: 0.999 - ETA: 20s - loss: 0.0041 - accuracy: 0.999 - ETA: 19s - loss: 0.0041 - accuracy: 0.999 - ETA: 18s - loss: 0.0041 - accuracy: 0.999 - ETA: 18s - loss: 0.0041 - accuracy: 0.999 - ETA: 17s - loss: 0.0041 - accuracy: 0.999 - ETA: 16s - loss: 0.0040 - accuracy: 0.999 - ETA: 15s - loss: 0.0040 - accuracy: 0.999 - ETA: 15s - loss: 0.0040 - accuracy: 0.999 - ETA: 14s - loss: 0.0040 - accuracy: 0.999 - ETA: 13s - loss: 0.0040 - accuracy: 0.999 - ETA: 13s - loss: 0.0039 - accuracy: 0.999 - ETA: 12s - loss: 0.0039 - accuracy: 0.999 - ETA: 11s - loss: 0.0039 - accuracy: 0.999 - ETA: 10s - loss: 0.0039 - accuracy: 0.999 - ETA: 10s - loss: 0.0039 - accuracy: 0.999 - ETA: 9s - loss: 0.0039 - accuracy: 0.999 - ETA: 8s - loss: 0.0039 - accuracy: 0.99 - ETA: 7s - loss: 0.0039 - accuracy: 0.99 - ETA: 7s - loss: 0.0039 - accuracy: 0.99 - ETA: 6s - loss: 0.0038 - accuracy: 0.99 - ETA: 5s - loss: 0.0038 - accuracy: 0.99 - ETA: 5s - loss: 0.0038 - accuracy: 0.99 - ETA: 4s - loss: 0.0038 - accuracy: 0.99 - ETA: 3s - loss: 0.0038 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 1s - loss: 0.0038 - accuracy: 0.99 - ETA: 0s - loss: 0.0038 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.9618 - val_accuracy: 0.8128\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:58 - loss: 8.9484e-04 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0019 - accuracy: 1.0000   - ETA: 1:47 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0015 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0015 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0015 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0032 - accuracy: 0.99 - ETA: 59s - loss: 0.0032 - accuracy: 0.9997 - ETA: 58s - loss: 0.0031 - accuracy: 0.999 - ETA: 58s - loss: 0.0031 - accuracy: 0.999 - ETA: 57s - loss: 0.0031 - accuracy: 0.999 - ETA: 56s - loss: 0.0031 - accuracy: 0.999 - ETA: 56s - loss: 0.0031 - accuracy: 0.999 - ETA: 55s - loss: 0.0031 - accuracy: 0.999 - ETA: 54s - loss: 0.0031 - accuracy: 0.999 - ETA: 53s - loss: 0.0030 - accuracy: 0.999 - ETA: 53s - loss: 0.0030 - accuracy: 0.999 - ETA: 52s - loss: 0.0030 - accuracy: 0.999 - ETA: 51s - loss: 0.0030 - accuracy: 0.999 - ETA: 51s - loss: 0.0031 - accuracy: 0.999 - ETA: 50s - loss: 0.0031 - accuracy: 0.999 - ETA: 49s - loss: 0.0032 - accuracy: 0.999 - ETA: 48s - loss: 0.0034 - accuracy: 0.999 - ETA: 48s - loss: 0.0034 - accuracy: 0.999 - ETA: 47s - loss: 0.0034 - accuracy: 0.999 - ETA: 46s - loss: 0.0033 - accuracy: 0.999 - ETA: 46s - loss: 0.0036 - accuracy: 0.999 - ETA: 45s - loss: 0.0036 - accuracy: 0.999 - ETA: 44s - loss: 0.0036 - accuracy: 0.999 - ETA: 43s - loss: 0.0035 - accuracy: 0.999 - ETA: 43s - loss: 0.0035 - accuracy: 0.999 - ETA: 42s - loss: 0.0035 - accuracy: 0.999 - ETA: 41s - loss: 0.0037 - accuracy: 0.999 - ETA: 40s - loss: 0.0038 - accuracy: 0.999 - ETA: 40s - loss: 0.0038 - accuracy: 0.999 - ETA: 39s - loss: 0.0038 - accuracy: 0.999 - ETA: 38s - loss: 0.0038 - accuracy: 0.999 - ETA: 37s - loss: 0.0038 - accuracy: 0.999 - ETA: 37s - loss: 0.0038 - accuracy: 0.999 - ETA: 36s - loss: 0.0038 - accuracy: 0.999 - ETA: 35s - loss: 0.0038 - accuracy: 0.999 - ETA: 34s - loss: 0.0038 - accuracy: 0.999 - ETA: 34s - loss: 0.0038 - accuracy: 0.999 - ETA: 33s - loss: 0.0038 - accuracy: 0.999 - ETA: 32s - loss: 0.0037 - accuracy: 0.999 - ETA: 32s - loss: 0.0037 - accuracy: 0.999 - ETA: 31s - loss: 0.0037 - accuracy: 0.999 - ETA: 30s - loss: 0.0037 - accuracy: 0.999 - ETA: 29s - loss: 0.0037 - accuracy: 0.999 - ETA: 29s - loss: 0.0037 - accuracy: 0.999 - ETA: 28s - loss: 0.0037 - accuracy: 0.999 - ETA: 27s - loss: 0.0037 - accuracy: 0.999 - ETA: 26s - loss: 0.0039 - accuracy: 0.999 - ETA: 26s - loss: 0.0039 - accuracy: 0.999 - ETA: 25s - loss: 0.0039 - accuracy: 0.999 - ETA: 24s - loss: 0.0039 - accuracy: 0.999 - ETA: 24s - loss: 0.0039 - accuracy: 0.999 - ETA: 23s - loss: 0.0038 - accuracy: 0.999 - ETA: 22s - loss: 0.0039 - accuracy: 0.999 - ETA: 21s - loss: 0.0042 - accuracy: 0.999 - ETA: 21s - loss: 0.0042 - accuracy: 0.999 - ETA: 20s - loss: 0.0041 - accuracy: 0.999 - ETA: 19s - loss: 0.0047 - accuracy: 0.999 - ETA: 18s - loss: 0.0047 - accuracy: 0.999 - ETA: 18s - loss: 0.0047 - accuracy: 0.999 - ETA: 17s - loss: 0.0047 - accuracy: 0.999 - ETA: 16s - loss: 0.0047 - accuracy: 0.999 - ETA: 16s - loss: 0.0046 - accuracy: 0.999 - ETA: 15s - loss: 0.0047 - accuracy: 0.999 - ETA: 14s - loss: 0.0047 - accuracy: 0.999 - ETA: 13s - loss: 0.0046 - accuracy: 0.999 - ETA: 13s - loss: 0.0046 - accuracy: 0.999 - ETA: 12s - loss: 0.0046 - accuracy: 0.999 - ETA: 11s - loss: 0.0046 - accuracy: 0.999 - ETA: 10s - loss: 0.0046 - accuracy: 0.999 - ETA: 10s - loss: 0.0046 - accuracy: 0.999 - ETA: 9s - loss: 0.0046 - accuracy: 0.999 - ETA: 8s - loss: 0.0046 - accuracy: 0.99 - ETA: 7s - loss: 0.0046 - accuracy: 0.99 - ETA: 7s - loss: 0.0046 - accuracy: 0.99 - ETA: 6s - loss: 0.0046 - accuracy: 0.99 - ETA: 5s - loss: 0.0046 - accuracy: 0.99 - ETA: 5s - loss: 0.0045 - accuracy: 0.99 - ETA: 4s - loss: 0.0046 - accuracy: 0.99 - ETA: 3s - loss: 0.0045 - accuracy: 0.99 - ETA: 2s - loss: 0.0045 - accuracy: 0.99 - ETA: 2s - loss: 0.0045 - accuracy: 0.99 - ETA: 1s - loss: 0.0045 - accuracy: 0.99 - ETA: 0s - loss: 0.0045 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.9725 - val_accuracy: 0.8087\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:56 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:56 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:55 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:57 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:56 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:53 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0038 - accuracy: 0.99 - ETA: 59s - loss: 0.0038 - accuracy: 0.9994 - ETA: 58s - loss: 0.0038 - accuracy: 0.999 - ETA: 58s - loss: 0.0038 - accuracy: 0.999 - ETA: 57s - loss: 0.0038 - accuracy: 0.999 - ETA: 56s - loss: 0.0038 - accuracy: 0.999 - ETA: 55s - loss: 0.0037 - accuracy: 0.999 - ETA: 55s - loss: 0.0037 - accuracy: 0.999 - ETA: 54s - loss: 0.0037 - accuracy: 0.999 - ETA: 53s - loss: 0.0037 - accuracy: 0.999 - ETA: 53s - loss: 0.0037 - accuracy: 0.999 - ETA: 52s - loss: 0.0037 - accuracy: 0.999 - ETA: 51s - loss: 0.0037 - accuracy: 0.999 - ETA: 50s - loss: 0.0036 - accuracy: 0.999 - ETA: 50s - loss: 0.0036 - accuracy: 0.999 - ETA: 49s - loss: 0.0036 - accuracy: 0.999 - ETA: 48s - loss: 0.0037 - accuracy: 0.999 - ETA: 47s - loss: 0.0037 - accuracy: 0.999 - ETA: 47s - loss: 0.0036 - accuracy: 0.999 - ETA: 46s - loss: 0.0037 - accuracy: 0.999 - ETA: 45s - loss: 0.0037 - accuracy: 0.999 - ETA: 45s - loss: 0.0038 - accuracy: 0.999 - ETA: 44s - loss: 0.0037 - accuracy: 0.999 - ETA: 43s - loss: 0.0038 - accuracy: 0.999 - ETA: 42s - loss: 0.0038 - accuracy: 0.999 - ETA: 42s - loss: 0.0038 - accuracy: 0.999 - ETA: 41s - loss: 0.0038 - accuracy: 0.999 - ETA: 40s - loss: 0.0038 - accuracy: 0.999 - ETA: 40s - loss: 0.0038 - accuracy: 0.999 - ETA: 39s - loss: 0.0037 - accuracy: 0.999 - ETA: 38s - loss: 0.0037 - accuracy: 0.999 - ETA: 37s - loss: 0.0037 - accuracy: 0.999 - ETA: 37s - loss: 0.0037 - accuracy: 0.999 - ETA: 36s - loss: 0.0037 - accuracy: 0.999 - ETA: 35s - loss: 0.0037 - accuracy: 0.999 - ETA: 34s - loss: 0.0037 - accuracy: 0.999 - ETA: 34s - loss: 0.0037 - accuracy: 0.999 - ETA: 33s - loss: 0.0037 - accuracy: 0.999 - ETA: 32s - loss: 0.0037 - accuracy: 0.999 - ETA: 32s - loss: 0.0037 - accuracy: 0.999 - ETA: 31s - loss: 0.0037 - accuracy: 0.999 - ETA: 30s - loss: 0.0037 - accuracy: 0.999 - ETA: 29s - loss: 0.0036 - accuracy: 0.999 - ETA: 29s - loss: 0.0036 - accuracy: 0.999 - ETA: 28s - loss: 0.0036 - accuracy: 0.999 - ETA: 27s - loss: 0.0036 - accuracy: 0.999 - ETA: 26s - loss: 0.0036 - accuracy: 0.999 - ETA: 26s - loss: 0.0036 - accuracy: 0.999 - ETA: 25s - loss: 0.0035 - accuracy: 0.999 - ETA: 24s - loss: 0.0035 - accuracy: 0.999 - ETA: 24s - loss: 0.0035 - accuracy: 0.999 - ETA: 23s - loss: 0.0035 - accuracy: 0.999 - ETA: 22s - loss: 0.0035 - accuracy: 0.999 - ETA: 21s - loss: 0.0035 - accuracy: 0.999 - ETA: 21s - loss: 0.0035 - accuracy: 0.999 - ETA: 20s - loss: 0.0036 - accuracy: 0.999 - ETA: 19s - loss: 0.0036 - accuracy: 0.999 - ETA: 18s - loss: 0.0035 - accuracy: 0.999 - ETA: 18s - loss: 0.0035 - accuracy: 0.999 - ETA: 17s - loss: 0.0035 - accuracy: 0.999 - ETA: 16s - loss: 0.0035 - accuracy: 0.999 - ETA: 15s - loss: 0.0035 - accuracy: 0.999 - ETA: 15s - loss: 0.0035 - accuracy: 0.999 - ETA: 14s - loss: 0.0035 - accuracy: 0.999 - ETA: 13s - loss: 0.0035 - accuracy: 0.999 - ETA: 13s - loss: 0.0035 - accuracy: 0.999 - ETA: 12s - loss: 0.0035 - accuracy: 0.999 - ETA: 11s - loss: 0.0035 - accuracy: 0.999 - ETA: 10s - loss: 0.0035 - accuracy: 0.999 - ETA: 10s - loss: 0.0035 - accuracy: 0.999 - ETA: 9s - loss: 0.0035 - accuracy: 0.999 - ETA: 8s - loss: 0.0035 - accuracy: 0.99 - ETA: 7s - loss: 0.0035 - accuracy: 0.99 - ETA: 7s - loss: 0.0035 - accuracy: 0.99 - ETA: 6s - loss: 0.0034 - accuracy: 0.99 - ETA: 5s - loss: 0.0034 - accuracy: 0.99 - ETA: 5s - loss: 0.0034 - accuracy: 0.99 - ETA: 4s - loss: 0.0034 - accuracy: 0.99 - ETA: 3s - loss: 0.0034 - accuracy: 0.99 - ETA: 2s - loss: 0.0034 - accuracy: 0.99 - ETA: 2s - loss: 0.0034 - accuracy: 0.99 - ETA: 1s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.9727 - val_accuracy: 0.8095\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:51 - loss: 0.0053 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0033 - accuracy: 0.99 - ETA: 59s - loss: 0.0033 - accuracy: 0.9992 - ETA: 58s - loss: 0.0032 - accuracy: 0.999 - ETA: 57s - loss: 0.0032 - accuracy: 0.999 - ETA: 57s - loss: 0.0032 - accuracy: 0.999 - ETA: 56s - loss: 0.0032 - accuracy: 0.999 - ETA: 55s - loss: 0.0031 - accuracy: 0.999 - ETA: 54s - loss: 0.0031 - accuracy: 0.999 - ETA: 54s - loss: 0.0031 - accuracy: 0.999 - ETA: 53s - loss: 0.0031 - accuracy: 0.999 - ETA: 52s - loss: 0.0030 - accuracy: 0.999 - ETA: 51s - loss: 0.0030 - accuracy: 0.999 - ETA: 50s - loss: 0.0030 - accuracy: 0.999 - ETA: 50s - loss: 0.0030 - accuracy: 0.999 - ETA: 49s - loss: 0.0030 - accuracy: 0.999 - ETA: 48s - loss: 0.0030 - accuracy: 0.999 - ETA: 47s - loss: 0.0031 - accuracy: 0.999 - ETA: 47s - loss: 0.0031 - accuracy: 0.999 - ETA: 46s - loss: 0.0031 - accuracy: 0.999 - ETA: 45s - loss: 0.0030 - accuracy: 0.999 - ETA: 44s - loss: 0.0030 - accuracy: 0.999 - ETA: 43s - loss: 0.0030 - accuracy: 0.999 - ETA: 43s - loss: 0.0030 - accuracy: 0.999 - ETA: 42s - loss: 0.0030 - accuracy: 0.999 - ETA: 41s - loss: 0.0030 - accuracy: 0.999 - ETA: 40s - loss: 0.0030 - accuracy: 0.999 - ETA: 40s - loss: 0.0030 - accuracy: 0.999 - ETA: 39s - loss: 0.0030 - accuracy: 0.999 - ETA: 38s - loss: 0.0030 - accuracy: 0.999 - ETA: 37s - loss: 0.0030 - accuracy: 0.999 - ETA: 37s - loss: 0.0030 - accuracy: 0.999 - ETA: 36s - loss: 0.0030 - accuracy: 0.999 - ETA: 35s - loss: 0.0030 - accuracy: 0.999 - ETA: 35s - loss: 0.0030 - accuracy: 0.999 - ETA: 34s - loss: 0.0030 - accuracy: 0.999 - ETA: 33s - loss: 0.0030 - accuracy: 0.999 - ETA: 32s - loss: 0.0030 - accuracy: 0.999 - ETA: 32s - loss: 0.0030 - accuracy: 0.999 - ETA: 31s - loss: 0.0031 - accuracy: 0.999 - ETA: 30s - loss: 0.0031 - accuracy: 0.999 - ETA: 29s - loss: 0.0031 - accuracy: 0.999 - ETA: 29s - loss: 0.0031 - accuracy: 0.999 - ETA: 28s - loss: 0.0031 - accuracy: 0.999 - ETA: 27s - loss: 0.0031 - accuracy: 0.999 - ETA: 26s - loss: 0.0031 - accuracy: 0.999 - ETA: 26s - loss: 0.0031 - accuracy: 0.999 - ETA: 25s - loss: 0.0031 - accuracy: 0.999 - ETA: 24s - loss: 0.0031 - accuracy: 0.999 - ETA: 23s - loss: 0.0031 - accuracy: 0.999 - ETA: 23s - loss: 0.0030 - accuracy: 0.999 - ETA: 22s - loss: 0.0030 - accuracy: 0.999 - ETA: 21s - loss: 0.0030 - accuracy: 0.999 - ETA: 20s - loss: 0.0030 - accuracy: 0.999 - ETA: 20s - loss: 0.0031 - accuracy: 0.999 - ETA: 19s - loss: 0.0031 - accuracy: 0.999 - ETA: 18s - loss: 0.0031 - accuracy: 0.999 - ETA: 17s - loss: 0.0031 - accuracy: 0.999 - ETA: 17s - loss: 0.0031 - accuracy: 0.999 - ETA: 16s - loss: 0.0032 - accuracy: 0.999 - ETA: 15s - loss: 0.0032 - accuracy: 0.999 - ETA: 14s - loss: 0.0032 - accuracy: 0.999 - ETA: 14s - loss: 0.0032 - accuracy: 0.999 - ETA: 13s - loss: 0.0032 - accuracy: 0.999 - ETA: 12s - loss: 0.0032 - accuracy: 0.999 - ETA: 11s - loss: 0.0032 - accuracy: 0.999 - ETA: 11s - loss: 0.0032 - accuracy: 0.999 - ETA: 10s - loss: 0.0032 - accuracy: 0.999 - ETA: 9s - loss: 0.0032 - accuracy: 0.999 - ETA: 8s - loss: 0.0032 - accuracy: 0.99 - ETA: 8s - loss: 0.0033 - accuracy: 0.99 - ETA: 7s - loss: 0.0033 - accuracy: 0.99 - ETA: 6s - loss: 0.0033 - accuracy: 0.99 - ETA: 5s - loss: 0.0033 - accuracy: 0.99 - ETA: 5s - loss: 0.0032 - accuracy: 0.99 - ETA: 4s - loss: 0.0033 - accuracy: 0.99 - ETA: 3s - loss: 0.0033 - accuracy: 0.99 - ETA: 2s - loss: 0.0032 - accuracy: 0.99 - ETA: 2s - loss: 0.0032 - accuracy: 0.99 - ETA: 1s - loss: 0.0032 - accuracy: 0.99 - ETA: 0s - loss: 0.0032 - accuracy: 0.99 - 124s 6ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.9808 - val_accuracy: 0.8087\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:53 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0079 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0069 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0038 - accuracy: 0.99 - ETA: 59s - loss: 0.0038 - accuracy: 0.9993 - ETA: 58s - loss: 0.0037 - accuracy: 0.999 - ETA: 58s - loss: 0.0037 - accuracy: 0.999 - ETA: 57s - loss: 0.0037 - accuracy: 0.999 - ETA: 56s - loss: 0.0037 - accuracy: 0.999 - ETA: 55s - loss: 0.0036 - accuracy: 0.999 - ETA: 54s - loss: 0.0036 - accuracy: 0.999 - ETA: 54s - loss: 0.0036 - accuracy: 0.999 - ETA: 53s - loss: 0.0036 - accuracy: 0.999 - ETA: 52s - loss: 0.0035 - accuracy: 0.999 - ETA: 51s - loss: 0.0035 - accuracy: 0.999 - ETA: 51s - loss: 0.0035 - accuracy: 0.999 - ETA: 50s - loss: 0.0035 - accuracy: 0.999 - ETA: 49s - loss: 0.0037 - accuracy: 0.999 - ETA: 49s - loss: 0.0037 - accuracy: 0.999 - ETA: 48s - loss: 0.0036 - accuracy: 0.999 - ETA: 47s - loss: 0.0037 - accuracy: 0.999 - ETA: 46s - loss: 0.0037 - accuracy: 0.999 - ETA: 46s - loss: 0.0037 - accuracy: 0.999 - ETA: 45s - loss: 0.0038 - accuracy: 0.999 - ETA: 44s - loss: 0.0037 - accuracy: 0.999 - ETA: 43s - loss: 0.0037 - accuracy: 0.999 - ETA: 43s - loss: 0.0037 - accuracy: 0.999 - ETA: 42s - loss: 0.0037 - accuracy: 0.999 - ETA: 41s - loss: 0.0037 - accuracy: 0.999 - ETA: 40s - loss: 0.0037 - accuracy: 0.999 - ETA: 40s - loss: 0.0037 - accuracy: 0.999 - ETA: 39s - loss: 0.0037 - accuracy: 0.999 - ETA: 38s - loss: 0.0037 - accuracy: 0.999 - ETA: 37s - loss: 0.0037 - accuracy: 0.999 - ETA: 37s - loss: 0.0037 - accuracy: 0.999 - ETA: 36s - loss: 0.0037 - accuracy: 0.999 - ETA: 35s - loss: 0.0037 - accuracy: 0.999 - ETA: 35s - loss: 0.0036 - accuracy: 0.999 - ETA: 34s - loss: 0.0036 - accuracy: 0.999 - ETA: 33s - loss: 0.0036 - accuracy: 0.999 - ETA: 32s - loss: 0.0036 - accuracy: 0.999 - ETA: 32s - loss: 0.0036 - accuracy: 0.999 - ETA: 31s - loss: 0.0038 - accuracy: 0.999 - ETA: 30s - loss: 0.0037 - accuracy: 0.999 - ETA: 29s - loss: 0.0037 - accuracy: 0.999 - ETA: 29s - loss: 0.0038 - accuracy: 0.999 - ETA: 28s - loss: 0.0037 - accuracy: 0.999 - ETA: 27s - loss: 0.0037 - accuracy: 0.999 - ETA: 27s - loss: 0.0037 - accuracy: 0.999 - ETA: 26s - loss: 0.0037 - accuracy: 0.999 - ETA: 25s - loss: 0.0037 - accuracy: 0.999 - ETA: 24s - loss: 0.0037 - accuracy: 0.999 - ETA: 24s - loss: 0.0036 - accuracy: 0.999 - ETA: 23s - loss: 0.0037 - accuracy: 0.999 - ETA: 22s - loss: 0.0037 - accuracy: 0.999 - ETA: 21s - loss: 0.0037 - accuracy: 0.999 - ETA: 21s - loss: 0.0037 - accuracy: 0.999 - ETA: 20s - loss: 0.0037 - accuracy: 0.999 - ETA: 19s - loss: 0.0037 - accuracy: 0.999 - ETA: 18s - loss: 0.0037 - accuracy: 0.999 - ETA: 18s - loss: 0.0037 - accuracy: 0.999 - ETA: 17s - loss: 0.0038 - accuracy: 0.999 - ETA: 16s - loss: 0.0038 - accuracy: 0.999 - ETA: 16s - loss: 0.0039 - accuracy: 0.999 - ETA: 15s - loss: 0.0039 - accuracy: 0.999 - ETA: 14s - loss: 0.0039 - accuracy: 0.999 - ETA: 13s - loss: 0.0039 - accuracy: 0.999 - ETA: 13s - loss: 0.0040 - accuracy: 0.999 - ETA: 12s - loss: 0.0040 - accuracy: 0.999 - ETA: 11s - loss: 0.0040 - accuracy: 0.999 - ETA: 10s - loss: 0.0040 - accuracy: 0.999 - ETA: 10s - loss: 0.0039 - accuracy: 0.999 - ETA: 9s - loss: 0.0040 - accuracy: 0.999 - ETA: 8s - loss: 0.0039 - accuracy: 0.99 - ETA: 7s - loss: 0.0040 - accuracy: 0.99 - ETA: 7s - loss: 0.0039 - accuracy: 0.99 - ETA: 6s - loss: 0.0039 - accuracy: 0.99 - ETA: 5s - loss: 0.0039 - accuracy: 0.99 - ETA: 5s - loss: 0.0040 - accuracy: 0.99 - ETA: 4s - loss: 0.0040 - accuracy: 0.99 - ETA: 3s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 1s - loss: 0.0040 - accuracy: 0.99 - ETA: 0s - loss: 0.0041 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.9894 - val_accuracy: 0.8068\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:46 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0049 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0050 - accuracy: 0.99 - ETA: 59s - loss: 0.0049 - accuracy: 0.9990 - ETA: 58s - loss: 0.0049 - accuracy: 0.999 - ETA: 58s - loss: 0.0049 - accuracy: 0.999 - ETA: 57s - loss: 0.0049 - accuracy: 0.999 - ETA: 56s - loss: 0.0049 - accuracy: 0.999 - ETA: 56s - loss: 0.0049 - accuracy: 0.999 - ETA: 55s - loss: 0.0048 - accuracy: 0.999 - ETA: 54s - loss: 0.0048 - accuracy: 0.999 - ETA: 53s - loss: 0.0048 - accuracy: 0.999 - ETA: 53s - loss: 0.0047 - accuracy: 0.999 - ETA: 52s - loss: 0.0047 - accuracy: 0.999 - ETA: 51s - loss: 0.0046 - accuracy: 0.999 - ETA: 51s - loss: 0.0046 - accuracy: 0.999 - ETA: 50s - loss: 0.0046 - accuracy: 0.999 - ETA: 49s - loss: 0.0045 - accuracy: 0.999 - ETA: 48s - loss: 0.0045 - accuracy: 0.999 - ETA: 47s - loss: 0.0045 - accuracy: 0.999 - ETA: 47s - loss: 0.0045 - accuracy: 0.999 - ETA: 46s - loss: 0.0044 - accuracy: 0.999 - ETA: 45s - loss: 0.0044 - accuracy: 0.999 - ETA: 45s - loss: 0.0044 - accuracy: 0.999 - ETA: 44s - loss: 0.0043 - accuracy: 0.999 - ETA: 43s - loss: 0.0043 - accuracy: 0.999 - ETA: 42s - loss: 0.0043 - accuracy: 0.999 - ETA: 42s - loss: 0.0044 - accuracy: 0.999 - ETA: 41s - loss: 0.0043 - accuracy: 0.999 - ETA: 40s - loss: 0.0043 - accuracy: 0.999 - ETA: 39s - loss: 0.0043 - accuracy: 0.999 - ETA: 39s - loss: 0.0043 - accuracy: 0.999 - ETA: 38s - loss: 0.0042 - accuracy: 0.999 - ETA: 37s - loss: 0.0042 - accuracy: 0.999 - ETA: 37s - loss: 0.0042 - accuracy: 0.999 - ETA: 36s - loss: 0.0042 - accuracy: 0.999 - ETA: 35s - loss: 0.0043 - accuracy: 0.999 - ETA: 34s - loss: 0.0043 - accuracy: 0.999 - ETA: 34s - loss: 0.0043 - accuracy: 0.999 - ETA: 33s - loss: 0.0043 - accuracy: 0.999 - ETA: 32s - loss: 0.0042 - accuracy: 0.999 - ETA: 31s - loss: 0.0042 - accuracy: 0.999 - ETA: 31s - loss: 0.0042 - accuracy: 0.999 - ETA: 30s - loss: 0.0042 - accuracy: 0.999 - ETA: 29s - loss: 0.0042 - accuracy: 0.999 - ETA: 28s - loss: 0.0041 - accuracy: 0.999 - ETA: 28s - loss: 0.0041 - accuracy: 0.999 - ETA: 27s - loss: 0.0041 - accuracy: 0.999 - ETA: 26s - loss: 0.0041 - accuracy: 0.999 - ETA: 26s - loss: 0.0040 - accuracy: 0.999 - ETA: 25s - loss: 0.0040 - accuracy: 0.999 - ETA: 24s - loss: 0.0040 - accuracy: 0.999 - ETA: 23s - loss: 0.0040 - accuracy: 0.999 - ETA: 23s - loss: 0.0040 - accuracy: 0.999 - ETA: 22s - loss: 0.0040 - accuracy: 0.999 - ETA: 21s - loss: 0.0040 - accuracy: 0.999 - ETA: 20s - loss: 0.0040 - accuracy: 0.999 - ETA: 20s - loss: 0.0039 - accuracy: 0.999 - ETA: 19s - loss: 0.0039 - accuracy: 0.999 - ETA: 18s - loss: 0.0039 - accuracy: 0.999 - ETA: 18s - loss: 0.0040 - accuracy: 0.999 - ETA: 17s - loss: 0.0040 - accuracy: 0.999 - ETA: 16s - loss: 0.0041 - accuracy: 0.999 - ETA: 15s - loss: 0.0041 - accuracy: 0.999 - ETA: 15s - loss: 0.0041 - accuracy: 0.999 - ETA: 14s - loss: 0.0040 - accuracy: 0.999 - ETA: 13s - loss: 0.0040 - accuracy: 0.999 - ETA: 12s - loss: 0.0040 - accuracy: 0.999 - ETA: 12s - loss: 0.0040 - accuracy: 0.999 - ETA: 11s - loss: 0.0040 - accuracy: 0.999 - ETA: 10s - loss: 0.0040 - accuracy: 0.999 - ETA: 10s - loss: 0.0040 - accuracy: 0.999 - ETA: 9s - loss: 0.0040 - accuracy: 0.999 - ETA: 8s - loss: 0.0041 - accuracy: 0.99 - ETA: 7s - loss: 0.0041 - accuracy: 0.99 - ETA: 7s - loss: 0.0041 - accuracy: 0.99 - ETA: 6s - loss: 0.0041 - accuracy: 0.99 - ETA: 5s - loss: 0.0041 - accuracy: 0.99 - ETA: 5s - loss: 0.0041 - accuracy: 0.99 - ETA: 4s - loss: 0.0041 - accuracy: 0.99 - ETA: 3s - loss: 0.0041 - accuracy: 0.99 - ETA: 2s - loss: 0.0041 - accuracy: 0.99 - ETA: 2s - loss: 0.0040 - accuracy: 0.99 - ETA: 1s - loss: 0.0040 - accuracy: 0.99 - ETA: 0s - loss: 0.0040 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.9803 - val_accuracy: 0.8091\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:51 - loss: 0.0014 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0071 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0042 - accuracy: 0.99 - ETA: 59s - loss: 0.0041 - accuracy: 0.9989 - ETA: 58s - loss: 0.0041 - accuracy: 0.998 - ETA: 58s - loss: 0.0041 - accuracy: 0.998 - ETA: 57s - loss: 0.0041 - accuracy: 0.998 - ETA: 56s - loss: 0.0042 - accuracy: 0.998 - ETA: 55s - loss: 0.0042 - accuracy: 0.998 - ETA: 55s - loss: 0.0041 - accuracy: 0.998 - ETA: 54s - loss: 0.0041 - accuracy: 0.998 - ETA: 53s - loss: 0.0041 - accuracy: 0.998 - ETA: 52s - loss: 0.0041 - accuracy: 0.998 - ETA: 52s - loss: 0.0040 - accuracy: 0.998 - ETA: 51s - loss: 0.0040 - accuracy: 0.998 - ETA: 50s - loss: 0.0040 - accuracy: 0.998 - ETA: 50s - loss: 0.0040 - accuracy: 0.999 - ETA: 49s - loss: 0.0040 - accuracy: 0.999 - ETA: 48s - loss: 0.0039 - accuracy: 0.999 - ETA: 47s - loss: 0.0039 - accuracy: 0.999 - ETA: 47s - loss: 0.0041 - accuracy: 0.998 - ETA: 46s - loss: 0.0042 - accuracy: 0.998 - ETA: 45s - loss: 0.0041 - accuracy: 0.998 - ETA: 44s - loss: 0.0041 - accuracy: 0.998 - ETA: 44s - loss: 0.0041 - accuracy: 0.999 - ETA: 43s - loss: 0.0040 - accuracy: 0.999 - ETA: 42s - loss: 0.0040 - accuracy: 0.999 - ETA: 42s - loss: 0.0040 - accuracy: 0.999 - ETA: 41s - loss: 0.0040 - accuracy: 0.999 - ETA: 40s - loss: 0.0040 - accuracy: 0.999 - ETA: 39s - loss: 0.0040 - accuracy: 0.999 - ETA: 39s - loss: 0.0039 - accuracy: 0.999 - ETA: 38s - loss: 0.0039 - accuracy: 0.999 - ETA: 37s - loss: 0.0039 - accuracy: 0.999 - ETA: 36s - loss: 0.0039 - accuracy: 0.999 - ETA: 36s - loss: 0.0039 - accuracy: 0.999 - ETA: 35s - loss: 0.0039 - accuracy: 0.999 - ETA: 34s - loss: 0.0040 - accuracy: 0.999 - ETA: 34s - loss: 0.0041 - accuracy: 0.998 - ETA: 33s - loss: 0.0041 - accuracy: 0.999 - ETA: 32s - loss: 0.0041 - accuracy: 0.999 - ETA: 31s - loss: 0.0041 - accuracy: 0.999 - ETA: 31s - loss: 0.0040 - accuracy: 0.999 - ETA: 30s - loss: 0.0040 - accuracy: 0.999 - ETA: 29s - loss: 0.0040 - accuracy: 0.999 - ETA: 28s - loss: 0.0040 - accuracy: 0.999 - ETA: 28s - loss: 0.0039 - accuracy: 0.999 - ETA: 27s - loss: 0.0039 - accuracy: 0.999 - ETA: 26s - loss: 0.0039 - accuracy: 0.999 - ETA: 26s - loss: 0.0039 - accuracy: 0.999 - ETA: 25s - loss: 0.0039 - accuracy: 0.999 - ETA: 24s - loss: 0.0038 - accuracy: 0.999 - ETA: 23s - loss: 0.0038 - accuracy: 0.999 - ETA: 23s - loss: 0.0038 - accuracy: 0.999 - ETA: 22s - loss: 0.0039 - accuracy: 0.999 - ETA: 21s - loss: 0.0039 - accuracy: 0.999 - ETA: 20s - loss: 0.0039 - accuracy: 0.999 - ETA: 20s - loss: 0.0038 - accuracy: 0.999 - ETA: 19s - loss: 0.0038 - accuracy: 0.999 - ETA: 18s - loss: 0.0038 - accuracy: 0.999 - ETA: 18s - loss: 0.0038 - accuracy: 0.999 - ETA: 17s - loss: 0.0038 - accuracy: 0.999 - ETA: 16s - loss: 0.0038 - accuracy: 0.999 - ETA: 15s - loss: 0.0038 - accuracy: 0.999 - ETA: 15s - loss: 0.0038 - accuracy: 0.999 - ETA: 14s - loss: 0.0038 - accuracy: 0.999 - ETA: 13s - loss: 0.0038 - accuracy: 0.999 - ETA: 12s - loss: 0.0038 - accuracy: 0.999 - ETA: 12s - loss: 0.0038 - accuracy: 0.999 - ETA: 11s - loss: 0.0037 - accuracy: 0.999 - ETA: 10s - loss: 0.0037 - accuracy: 0.999 - ETA: 10s - loss: 0.0037 - accuracy: 0.999 - ETA: 9s - loss: 0.0037 - accuracy: 0.999 - ETA: 8s - loss: 0.0037 - accuracy: 0.99 - ETA: 7s - loss: 0.0037 - accuracy: 0.99 - ETA: 7s - loss: 0.0037 - accuracy: 0.99 - ETA: 6s - loss: 0.0037 - accuracy: 0.99 - ETA: 5s - loss: 0.0038 - accuracy: 0.99 - ETA: 4s - loss: 0.0037 - accuracy: 0.99 - ETA: 4s - loss: 0.0037 - accuracy: 0.99 - ETA: 3s - loss: 0.0037 - accuracy: 0.99 - ETA: 2s - loss: 0.0037 - accuracy: 0.99 - ETA: 2s - loss: 0.0037 - accuracy: 0.99 - ETA: 1s - loss: 0.0037 - accuracy: 0.99 - ETA: 0s - loss: 0.0037 - accuracy: 0.99 - 120s 6ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.9788 - val_accuracy: 0.8099\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:50 - loss: 0.0071 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0042 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0044 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0040 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0034 - accuracy: 0.99 - ETA: 59s - loss: 0.0033 - accuracy: 0.9995 - ETA: 59s - loss: 0.0033 - accuracy: 0.999 - ETA: 58s - loss: 0.0033 - accuracy: 0.999 - ETA: 57s - loss: 0.0033 - accuracy: 0.999 - ETA: 57s - loss: 0.0033 - accuracy: 0.999 - ETA: 56s - loss: 0.0032 - accuracy: 0.999 - ETA: 55s - loss: 0.0032 - accuracy: 0.999 - ETA: 55s - loss: 0.0032 - accuracy: 0.999 - ETA: 54s - loss: 0.0033 - accuracy: 0.999 - ETA: 53s - loss: 0.0032 - accuracy: 0.999 - ETA: 53s - loss: 0.0032 - accuracy: 0.999 - ETA: 52s - loss: 0.0032 - accuracy: 0.999 - ETA: 51s - loss: 0.0032 - accuracy: 0.999 - ETA: 51s - loss: 0.0031 - accuracy: 0.999 - ETA: 50s - loss: 0.0032 - accuracy: 0.999 - ETA: 49s - loss: 0.0032 - accuracy: 0.999 - ETA: 48s - loss: 0.0032 - accuracy: 0.999 - ETA: 48s - loss: 0.0031 - accuracy: 0.999 - ETA: 47s - loss: 0.0032 - accuracy: 0.999 - ETA: 46s - loss: 0.0032 - accuracy: 0.999 - ETA: 45s - loss: 0.0031 - accuracy: 0.999 - ETA: 45s - loss: 0.0033 - accuracy: 0.999 - ETA: 44s - loss: 0.0033 - accuracy: 0.999 - ETA: 43s - loss: 0.0033 - accuracy: 0.999 - ETA: 43s - loss: 0.0033 - accuracy: 0.999 - ETA: 42s - loss: 0.0033 - accuracy: 0.999 - ETA: 41s - loss: 0.0033 - accuracy: 0.999 - ETA: 40s - loss: 0.0033 - accuracy: 0.999 - ETA: 40s - loss: 0.0033 - accuracy: 0.999 - ETA: 39s - loss: 0.0033 - accuracy: 0.999 - ETA: 38s - loss: 0.0032 - accuracy: 0.999 - ETA: 37s - loss: 0.0032 - accuracy: 0.999 - ETA: 37s - loss: 0.0032 - accuracy: 0.999 - ETA: 36s - loss: 0.0033 - accuracy: 0.999 - ETA: 35s - loss: 0.0033 - accuracy: 0.999 - ETA: 34s - loss: 0.0033 - accuracy: 0.999 - ETA: 34s - loss: 0.0033 - accuracy: 0.999 - ETA: 33s - loss: 0.0033 - accuracy: 0.999 - ETA: 32s - loss: 0.0032 - accuracy: 0.999 - ETA: 31s - loss: 0.0032 - accuracy: 0.999 - ETA: 31s - loss: 0.0032 - accuracy: 0.999 - ETA: 30s - loss: 0.0034 - accuracy: 0.999 - ETA: 29s - loss: 0.0034 - accuracy: 0.999 - ETA: 29s - loss: 0.0033 - accuracy: 0.999 - ETA: 28s - loss: 0.0033 - accuracy: 0.999 - ETA: 27s - loss: 0.0033 - accuracy: 0.999 - ETA: 26s - loss: 0.0033 - accuracy: 0.999 - ETA: 26s - loss: 0.0033 - accuracy: 0.999 - ETA: 25s - loss: 0.0033 - accuracy: 0.999 - ETA: 24s - loss: 0.0033 - accuracy: 0.999 - ETA: 23s - loss: 0.0033 - accuracy: 0.999 - ETA: 23s - loss: 0.0033 - accuracy: 0.999 - ETA: 22s - loss: 0.0033 - accuracy: 0.999 - ETA: 21s - loss: 0.0033 - accuracy: 0.999 - ETA: 21s - loss: 0.0033 - accuracy: 0.999 - ETA: 20s - loss: 0.0032 - accuracy: 0.999 - ETA: 19s - loss: 0.0034 - accuracy: 0.999 - ETA: 18s - loss: 0.0034 - accuracy: 0.999 - ETA: 18s - loss: 0.0034 - accuracy: 0.999 - ETA: 17s - loss: 0.0034 - accuracy: 0.999 - ETA: 16s - loss: 0.0034 - accuracy: 0.999 - ETA: 15s - loss: 0.0034 - accuracy: 0.999 - ETA: 15s - loss: 0.0034 - accuracy: 0.999 - ETA: 14s - loss: 0.0034 - accuracy: 0.999 - ETA: 13s - loss: 0.0033 - accuracy: 0.999 - ETA: 13s - loss: 0.0033 - accuracy: 0.999 - ETA: 12s - loss: 0.0033 - accuracy: 0.999 - ETA: 11s - loss: 0.0033 - accuracy: 0.999 - ETA: 10s - loss: 0.0033 - accuracy: 0.999 - ETA: 10s - loss: 0.0033 - accuracy: 0.999 - ETA: 9s - loss: 0.0033 - accuracy: 0.999 - ETA: 8s - loss: 0.0034 - accuracy: 0.99 - ETA: 7s - loss: 0.0033 - accuracy: 0.99 - ETA: 7s - loss: 0.0033 - accuracy: 0.99 - ETA: 6s - loss: 0.0033 - accuracy: 0.99 - ETA: 5s - loss: 0.0034 - accuracy: 0.99 - ETA: 5s - loss: 0.0034 - accuracy: 0.99 - ETA: 4s - loss: 0.0034 - accuracy: 0.99 - ETA: 3s - loss: 0.0034 - accuracy: 0.99 - ETA: 2s - loss: 0.0034 - accuracy: 0.99 - ETA: 2s - loss: 0.0034 - accuracy: 0.99 - ETA: 1s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.9870 - val_accuracy: 0.8066\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:02 - loss: 0.0011 - accuracy: 1.00 - ETA: 1:58 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:55 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:53 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0037 - accuracy: 0.99 - ETA: 59s - loss: 0.0036 - accuracy: 0.9991 - ETA: 58s - loss: 0.0036 - accuracy: 0.999 - ETA: 57s - loss: 0.0036 - accuracy: 0.999 - ETA: 57s - loss: 0.0035 - accuracy: 0.999 - ETA: 56s - loss: 0.0035 - accuracy: 0.999 - ETA: 55s - loss: 0.0035 - accuracy: 0.999 - ETA: 54s - loss: 0.0035 - accuracy: 0.999 - ETA: 54s - loss: 0.0034 - accuracy: 0.999 - ETA: 53s - loss: 0.0035 - accuracy: 0.999 - ETA: 52s - loss: 0.0035 - accuracy: 0.999 - ETA: 52s - loss: 0.0035 - accuracy: 0.999 - ETA: 51s - loss: 0.0035 - accuracy: 0.999 - ETA: 50s - loss: 0.0035 - accuracy: 0.999 - ETA: 50s - loss: 0.0035 - accuracy: 0.999 - ETA: 49s - loss: 0.0040 - accuracy: 0.999 - ETA: 48s - loss: 0.0040 - accuracy: 0.999 - ETA: 47s - loss: 0.0039 - accuracy: 0.999 - ETA: 47s - loss: 0.0039 - accuracy: 0.999 - ETA: 46s - loss: 0.0039 - accuracy: 0.999 - ETA: 45s - loss: 0.0039 - accuracy: 0.999 - ETA: 45s - loss: 0.0039 - accuracy: 0.999 - ETA: 44s - loss: 0.0038 - accuracy: 0.999 - ETA: 43s - loss: 0.0038 - accuracy: 0.999 - ETA: 42s - loss: 0.0038 - accuracy: 0.999 - ETA: 42s - loss: 0.0038 - accuracy: 0.999 - ETA: 41s - loss: 0.0038 - accuracy: 0.999 - ETA: 40s - loss: 0.0037 - accuracy: 0.999 - ETA: 40s - loss: 0.0037 - accuracy: 0.999 - ETA: 39s - loss: 0.0037 - accuracy: 0.999 - ETA: 38s - loss: 0.0037 - accuracy: 0.999 - ETA: 38s - loss: 0.0037 - accuracy: 0.999 - ETA: 37s - loss: 0.0037 - accuracy: 0.999 - ETA: 36s - loss: 0.0036 - accuracy: 0.999 - ETA: 35s - loss: 0.0036 - accuracy: 0.999 - ETA: 35s - loss: 0.0036 - accuracy: 0.999 - ETA: 34s - loss: 0.0036 - accuracy: 0.999 - ETA: 33s - loss: 0.0036 - accuracy: 0.999 - ETA: 32s - loss: 0.0036 - accuracy: 0.999 - ETA: 32s - loss: 0.0036 - accuracy: 0.999 - ETA: 31s - loss: 0.0036 - accuracy: 0.999 - ETA: 30s - loss: 0.0035 - accuracy: 0.999 - ETA: 29s - loss: 0.0038 - accuracy: 0.999 - ETA: 29s - loss: 0.0038 - accuracy: 0.999 - ETA: 28s - loss: 0.0038 - accuracy: 0.999 - ETA: 27s - loss: 0.0038 - accuracy: 0.999 - ETA: 27s - loss: 0.0038 - accuracy: 0.999 - ETA: 26s - loss: 0.0038 - accuracy: 0.999 - ETA: 25s - loss: 0.0039 - accuracy: 0.999 - ETA: 24s - loss: 0.0039 - accuracy: 0.999 - ETA: 24s - loss: 0.0039 - accuracy: 0.999 - ETA: 23s - loss: 0.0039 - accuracy: 0.999 - ETA: 22s - loss: 0.0039 - accuracy: 0.999 - ETA: 21s - loss: 0.0038 - accuracy: 0.999 - ETA: 21s - loss: 0.0039 - accuracy: 0.999 - ETA: 20s - loss: 0.0038 - accuracy: 0.999 - ETA: 19s - loss: 0.0038 - accuracy: 0.999 - ETA: 18s - loss: 0.0038 - accuracy: 0.999 - ETA: 18s - loss: 0.0038 - accuracy: 0.999 - ETA: 17s - loss: 0.0038 - accuracy: 0.999 - ETA: 16s - loss: 0.0040 - accuracy: 0.999 - ETA: 16s - loss: 0.0040 - accuracy: 0.999 - ETA: 15s - loss: 0.0040 - accuracy: 0.999 - ETA: 14s - loss: 0.0040 - accuracy: 0.999 - ETA: 13s - loss: 0.0039 - accuracy: 0.999 - ETA: 13s - loss: 0.0039 - accuracy: 0.999 - ETA: 12s - loss: 0.0039 - accuracy: 0.999 - ETA: 11s - loss: 0.0039 - accuracy: 0.999 - ETA: 10s - loss: 0.0039 - accuracy: 0.999 - ETA: 10s - loss: 0.0039 - accuracy: 0.999 - ETA: 9s - loss: 0.0039 - accuracy: 0.999 - ETA: 8s - loss: 0.0039 - accuracy: 0.99 - ETA: 7s - loss: 0.0039 - accuracy: 0.99 - ETA: 7s - loss: 0.0039 - accuracy: 0.99 - ETA: 6s - loss: 0.0039 - accuracy: 0.99 - ETA: 5s - loss: 0.0039 - accuracy: 0.99 - ETA: 5s - loss: 0.0039 - accuracy: 0.99 - ETA: 4s - loss: 0.0039 - accuracy: 0.99 - ETA: 3s - loss: 0.0039 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 2s - loss: 0.0038 - accuracy: 0.99 - ETA: 1s - loss: 0.0038 - accuracy: 0.99 - ETA: 0s - loss: 0.0038 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.9893 - val_accuracy: 0.8091\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:48 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0016 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0038 - accuracy: 0.99 - ETA: 59s - loss: 0.0038 - accuracy: 0.9991 - ETA: 58s - loss: 0.0037 - accuracy: 0.999 - ETA: 57s - loss: 0.0037 - accuracy: 0.999 - ETA: 57s - loss: 0.0037 - accuracy: 0.999 - ETA: 56s - loss: 0.0037 - accuracy: 0.999 - ETA: 55s - loss: 0.0037 - accuracy: 0.999 - ETA: 54s - loss: 0.0037 - accuracy: 0.999 - ETA: 54s - loss: 0.0037 - accuracy: 0.999 - ETA: 53s - loss: 0.0037 - accuracy: 0.999 - ETA: 52s - loss: 0.0036 - accuracy: 0.999 - ETA: 51s - loss: 0.0036 - accuracy: 0.999 - ETA: 51s - loss: 0.0036 - accuracy: 0.999 - ETA: 50s - loss: 0.0036 - accuracy: 0.999 - ETA: 49s - loss: 0.0036 - accuracy: 0.999 - ETA: 48s - loss: 0.0036 - accuracy: 0.999 - ETA: 48s - loss: 0.0036 - accuracy: 0.999 - ETA: 47s - loss: 0.0036 - accuracy: 0.999 - ETA: 46s - loss: 0.0035 - accuracy: 0.999 - ETA: 46s - loss: 0.0035 - accuracy: 0.999 - ETA: 45s - loss: 0.0035 - accuracy: 0.999 - ETA: 44s - loss: 0.0035 - accuracy: 0.999 - ETA: 43s - loss: 0.0035 - accuracy: 0.999 - ETA: 43s - loss: 0.0035 - accuracy: 0.999 - ETA: 42s - loss: 0.0034 - accuracy: 0.999 - ETA: 41s - loss: 0.0034 - accuracy: 0.999 - ETA: 40s - loss: 0.0034 - accuracy: 0.999 - ETA: 40s - loss: 0.0034 - accuracy: 0.999 - ETA: 39s - loss: 0.0034 - accuracy: 0.999 - ETA: 38s - loss: 0.0034 - accuracy: 0.999 - ETA: 37s - loss: 0.0034 - accuracy: 0.999 - ETA: 37s - loss: 0.0034 - accuracy: 0.999 - ETA: 36s - loss: 0.0034 - accuracy: 0.999 - ETA: 35s - loss: 0.0034 - accuracy: 0.999 - ETA: 35s - loss: 0.0034 - accuracy: 0.999 - ETA: 34s - loss: 0.0034 - accuracy: 0.999 - ETA: 33s - loss: 0.0034 - accuracy: 0.999 - ETA: 32s - loss: 0.0034 - accuracy: 0.999 - ETA: 32s - loss: 0.0034 - accuracy: 0.999 - ETA: 31s - loss: 0.0034 - accuracy: 0.999 - ETA: 30s - loss: 0.0034 - accuracy: 0.999 - ETA: 30s - loss: 0.0034 - accuracy: 0.999 - ETA: 29s - loss: 0.0034 - accuracy: 0.999 - ETA: 28s - loss: 0.0034 - accuracy: 0.999 - ETA: 27s - loss: 0.0033 - accuracy: 0.999 - ETA: 27s - loss: 0.0033 - accuracy: 0.999 - ETA: 26s - loss: 0.0033 - accuracy: 0.999 - ETA: 25s - loss: 0.0033 - accuracy: 0.999 - ETA: 24s - loss: 0.0033 - accuracy: 0.999 - ETA: 24s - loss: 0.0033 - accuracy: 0.999 - ETA: 23s - loss: 0.0033 - accuracy: 0.999 - ETA: 22s - loss: 0.0033 - accuracy: 0.999 - ETA: 21s - loss: 0.0033 - accuracy: 0.999 - ETA: 21s - loss: 0.0033 - accuracy: 0.999 - ETA: 20s - loss: 0.0034 - accuracy: 0.999 - ETA: 19s - loss: 0.0033 - accuracy: 0.999 - ETA: 18s - loss: 0.0034 - accuracy: 0.999 - ETA: 18s - loss: 0.0034 - accuracy: 0.999 - ETA: 17s - loss: 0.0034 - accuracy: 0.999 - ETA: 16s - loss: 0.0034 - accuracy: 0.999 - ETA: 16s - loss: 0.0034 - accuracy: 0.999 - ETA: 15s - loss: 0.0034 - accuracy: 0.999 - ETA: 14s - loss: 0.0034 - accuracy: 0.999 - ETA: 13s - loss: 0.0034 - accuracy: 0.999 - ETA: 13s - loss: 0.0034 - accuracy: 0.999 - ETA: 12s - loss: 0.0033 - accuracy: 0.999 - ETA: 11s - loss: 0.0033 - accuracy: 0.999 - ETA: 10s - loss: 0.0034 - accuracy: 0.999 - ETA: 10s - loss: 0.0034 - accuracy: 0.999 - ETA: 9s - loss: 0.0033 - accuracy: 0.999 - ETA: 8s - loss: 0.0033 - accuracy: 0.99 - ETA: 7s - loss: 0.0033 - accuracy: 0.99 - ETA: 7s - loss: 0.0033 - accuracy: 0.99 - ETA: 6s - loss: 0.0033 - accuracy: 0.99 - ETA: 5s - loss: 0.0033 - accuracy: 0.99 - ETA: 5s - loss: 0.0033 - accuracy: 0.99 - ETA: 4s - loss: 0.0033 - accuracy: 0.99 - ETA: 3s - loss: 0.0033 - accuracy: 0.99 - ETA: 2s - loss: 0.0033 - accuracy: 0.99 - ETA: 2s - loss: 0.0033 - accuracy: 0.99 - ETA: 1s - loss: 0.0033 - accuracy: 0.99 - ETA: 0s - loss: 0.0033 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.9790 - val_accuracy: 0.8101\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:51 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0042 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0066 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0064 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0059 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0054 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0038 - accuracy: 0.99 - ETA: 59s - loss: 0.0038 - accuracy: 0.9992 - ETA: 59s - loss: 0.0037 - accuracy: 0.999 - ETA: 58s - loss: 0.0037 - accuracy: 0.999 - ETA: 57s - loss: 0.0036 - accuracy: 0.999 - ETA: 56s - loss: 0.0036 - accuracy: 0.999 - ETA: 56s - loss: 0.0036 - accuracy: 0.999 - ETA: 55s - loss: 0.0036 - accuracy: 0.999 - ETA: 54s - loss: 0.0036 - accuracy: 0.999 - ETA: 53s - loss: 0.0036 - accuracy: 0.999 - ETA: 53s - loss: 0.0036 - accuracy: 0.999 - ETA: 52s - loss: 0.0035 - accuracy: 0.999 - ETA: 51s - loss: 0.0035 - accuracy: 0.999 - ETA: 50s - loss: 0.0035 - accuracy: 0.999 - ETA: 50s - loss: 0.0034 - accuracy: 0.999 - ETA: 49s - loss: 0.0034 - accuracy: 0.999 - ETA: 48s - loss: 0.0034 - accuracy: 0.999 - ETA: 47s - loss: 0.0034 - accuracy: 0.999 - ETA: 47s - loss: 0.0034 - accuracy: 0.999 - ETA: 46s - loss: 0.0034 - accuracy: 0.999 - ETA: 45s - loss: 0.0034 - accuracy: 0.999 - ETA: 44s - loss: 0.0034 - accuracy: 0.999 - ETA: 44s - loss: 0.0034 - accuracy: 0.999 - ETA: 43s - loss: 0.0034 - accuracy: 0.999 - ETA: 42s - loss: 0.0034 - accuracy: 0.999 - ETA: 41s - loss: 0.0034 - accuracy: 0.999 - ETA: 41s - loss: 0.0034 - accuracy: 0.999 - ETA: 40s - loss: 0.0034 - accuracy: 0.999 - ETA: 39s - loss: 0.0034 - accuracy: 0.999 - ETA: 38s - loss: 0.0034 - accuracy: 0.999 - ETA: 38s - loss: 0.0034 - accuracy: 0.999 - ETA: 37s - loss: 0.0034 - accuracy: 0.999 - ETA: 36s - loss: 0.0034 - accuracy: 0.999 - ETA: 36s - loss: 0.0034 - accuracy: 0.999 - ETA: 35s - loss: 0.0034 - accuracy: 0.999 - ETA: 34s - loss: 0.0034 - accuracy: 0.999 - ETA: 33s - loss: 0.0033 - accuracy: 0.999 - ETA: 33s - loss: 0.0033 - accuracy: 0.999 - ETA: 32s - loss: 0.0033 - accuracy: 0.999 - ETA: 31s - loss: 0.0033 - accuracy: 0.999 - ETA: 30s - loss: 0.0033 - accuracy: 0.999 - ETA: 30s - loss: 0.0033 - accuracy: 0.999 - ETA: 29s - loss: 0.0033 - accuracy: 0.999 - ETA: 28s - loss: 0.0033 - accuracy: 0.999 - ETA: 27s - loss: 0.0033 - accuracy: 0.999 - ETA: 27s - loss: 0.0032 - accuracy: 0.999 - ETA: 26s - loss: 0.0032 - accuracy: 0.999 - ETA: 25s - loss: 0.0032 - accuracy: 0.999 - ETA: 24s - loss: 0.0032 - accuracy: 0.999 - ETA: 24s - loss: 0.0032 - accuracy: 0.999 - ETA: 23s - loss: 0.0032 - accuracy: 0.999 - ETA: 22s - loss: 0.0032 - accuracy: 0.999 - ETA: 22s - loss: 0.0032 - accuracy: 0.999 - ETA: 21s - loss: 0.0032 - accuracy: 0.999 - ETA: 20s - loss: 0.0032 - accuracy: 0.999 - ETA: 19s - loss: 0.0032 - accuracy: 0.999 - ETA: 19s - loss: 0.0032 - accuracy: 0.999 - ETA: 18s - loss: 0.0032 - accuracy: 0.999 - ETA: 17s - loss: 0.0032 - accuracy: 0.999 - ETA: 16s - loss: 0.0036 - accuracy: 0.999 - ETA: 16s - loss: 0.0036 - accuracy: 0.999 - ETA: 15s - loss: 0.0036 - accuracy: 0.999 - ETA: 14s - loss: 0.0035 - accuracy: 0.999 - ETA: 13s - loss: 0.0035 - accuracy: 0.999 - ETA: 13s - loss: 0.0035 - accuracy: 0.999 - ETA: 12s - loss: 0.0035 - accuracy: 0.999 - ETA: 11s - loss: 0.0036 - accuracy: 0.999 - ETA: 10s - loss: 0.0036 - accuracy: 0.999 - ETA: 10s - loss: 0.0036 - accuracy: 0.999 - ETA: 9s - loss: 0.0036 - accuracy: 0.999 - ETA: 8s - loss: 0.0036 - accuracy: 0.99 - ETA: 8s - loss: 0.0035 - accuracy: 0.99 - ETA: 7s - loss: 0.0035 - accuracy: 0.99 - ETA: 6s - loss: 0.0035 - accuracy: 0.99 - ETA: 5s - loss: 0.0035 - accuracy: 0.99 - ETA: 5s - loss: 0.0035 - accuracy: 0.99 - ETA: 4s - loss: 0.0035 - accuracy: 0.99 - ETA: 3s - loss: 0.0035 - accuracy: 0.99 - ETA: 2s - loss: 0.0035 - accuracy: 0.99 - ETA: 2s - loss: 0.0035 - accuracy: 0.99 - ETA: 1s - loss: 0.0035 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.9936 - val_accuracy: 0.8058\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:56 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:54 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0026 - accuracy: 0.99 - ETA: 59s - loss: 0.0026 - accuracy: 0.9998 - ETA: 59s - loss: 0.0026 - accuracy: 0.999 - ETA: 58s - loss: 0.0026 - accuracy: 0.999 - ETA: 57s - loss: 0.0026 - accuracy: 0.999 - ETA: 56s - loss: 0.0026 - accuracy: 0.999 - ETA: 56s - loss: 0.0026 - accuracy: 0.999 - ETA: 55s - loss: 0.0026 - accuracy: 0.999 - ETA: 54s - loss: 0.0026 - accuracy: 0.999 - ETA: 53s - loss: 0.0026 - accuracy: 0.999 - ETA: 53s - loss: 0.0027 - accuracy: 0.999 - ETA: 52s - loss: 0.0027 - accuracy: 0.999 - ETA: 51s - loss: 0.0027 - accuracy: 0.999 - ETA: 50s - loss: 0.0027 - accuracy: 0.999 - ETA: 50s - loss: 0.0027 - accuracy: 0.999 - ETA: 49s - loss: 0.0027 - accuracy: 0.999 - ETA: 48s - loss: 0.0026 - accuracy: 0.999 - ETA: 48s - loss: 0.0026 - accuracy: 0.999 - ETA: 47s - loss: 0.0026 - accuracy: 0.999 - ETA: 46s - loss: 0.0027 - accuracy: 0.999 - ETA: 45s - loss: 0.0027 - accuracy: 0.999 - ETA: 45s - loss: 0.0027 - accuracy: 0.999 - ETA: 44s - loss: 0.0028 - accuracy: 0.999 - ETA: 43s - loss: 0.0028 - accuracy: 0.999 - ETA: 42s - loss: 0.0028 - accuracy: 0.999 - ETA: 42s - loss: 0.0028 - accuracy: 0.999 - ETA: 41s - loss: 0.0028 - accuracy: 0.999 - ETA: 40s - loss: 0.0028 - accuracy: 0.999 - ETA: 39s - loss: 0.0028 - accuracy: 0.999 - ETA: 39s - loss: 0.0028 - accuracy: 0.999 - ETA: 38s - loss: 0.0028 - accuracy: 0.999 - ETA: 37s - loss: 0.0029 - accuracy: 0.999 - ETA: 37s - loss: 0.0030 - accuracy: 0.999 - ETA: 36s - loss: 0.0030 - accuracy: 0.999 - ETA: 35s - loss: 0.0030 - accuracy: 0.999 - ETA: 34s - loss: 0.0030 - accuracy: 0.999 - ETA: 34s - loss: 0.0029 - accuracy: 0.999 - ETA: 33s - loss: 0.0029 - accuracy: 0.999 - ETA: 32s - loss: 0.0029 - accuracy: 0.999 - ETA: 31s - loss: 0.0029 - accuracy: 0.999 - ETA: 31s - loss: 0.0029 - accuracy: 0.999 - ETA: 30s - loss: 0.0029 - accuracy: 0.999 - ETA: 29s - loss: 0.0029 - accuracy: 0.999 - ETA: 28s - loss: 0.0030 - accuracy: 0.999 - ETA: 28s - loss: 0.0030 - accuracy: 0.999 - ETA: 27s - loss: 0.0030 - accuracy: 0.999 - ETA: 26s - loss: 0.0031 - accuracy: 0.999 - ETA: 26s - loss: 0.0030 - accuracy: 0.999 - ETA: 25s - loss: 0.0032 - accuracy: 0.999 - ETA: 24s - loss: 0.0032 - accuracy: 0.999 - ETA: 23s - loss: 0.0033 - accuracy: 0.999 - ETA: 23s - loss: 0.0032 - accuracy: 0.999 - ETA: 22s - loss: 0.0032 - accuracy: 0.999 - ETA: 21s - loss: 0.0032 - accuracy: 0.999 - ETA: 20s - loss: 0.0032 - accuracy: 0.999 - ETA: 20s - loss: 0.0032 - accuracy: 0.999 - ETA: 19s - loss: 0.0032 - accuracy: 0.999 - ETA: 18s - loss: 0.0032 - accuracy: 0.999 - ETA: 18s - loss: 0.0032 - accuracy: 0.999 - ETA: 17s - loss: 0.0032 - accuracy: 0.999 - ETA: 16s - loss: 0.0032 - accuracy: 0.999 - ETA: 15s - loss: 0.0032 - accuracy: 0.999 - ETA: 15s - loss: 0.0033 - accuracy: 0.999 - ETA: 14s - loss: 0.0034 - accuracy: 0.999 - ETA: 13s - loss: 0.0034 - accuracy: 0.999 - ETA: 12s - loss: 0.0034 - accuracy: 0.999 - ETA: 12s - loss: 0.0034 - accuracy: 0.999 - ETA: 11s - loss: 0.0034 - accuracy: 0.999 - ETA: 10s - loss: 0.0034 - accuracy: 0.999 - ETA: 10s - loss: 0.0035 - accuracy: 0.999 - ETA: 9s - loss: 0.0034 - accuracy: 0.999 - ETA: 8s - loss: 0.0034 - accuracy: 0.99 - ETA: 7s - loss: 0.0034 - accuracy: 0.99 - ETA: 7s - loss: 0.0034 - accuracy: 0.99 - ETA: 6s - loss: 0.0034 - accuracy: 0.99 - ETA: 5s - loss: 0.0034 - accuracy: 0.99 - ETA: 5s - loss: 0.0034 - accuracy: 0.99 - ETA: 4s - loss: 0.0034 - accuracy: 0.99 - ETA: 3s - loss: 0.0034 - accuracy: 0.99 - ETA: 2s - loss: 0.0034 - accuracy: 0.99 - ETA: 2s - loss: 0.0034 - accuracy: 0.99 - ETA: 1s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.9936 - val_accuracy: 0.8074\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:01 - loss: 0.0056 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0040 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:31 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:30 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0052 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0043 - accuracy: 0.99 - ETA: 59s - loss: 0.0043 - accuracy: 0.9993 - ETA: 58s - loss: 0.0042 - accuracy: 0.999 - ETA: 58s - loss: 0.0043 - accuracy: 0.999 - ETA: 57s - loss: 0.0043 - accuracy: 0.999 - ETA: 56s - loss: 0.0046 - accuracy: 0.999 - ETA: 56s - loss: 0.0045 - accuracy: 0.999 - ETA: 55s - loss: 0.0045 - accuracy: 0.999 - ETA: 54s - loss: 0.0045 - accuracy: 0.999 - ETA: 53s - loss: 0.0044 - accuracy: 0.999 - ETA: 53s - loss: 0.0044 - accuracy: 0.999 - ETA: 52s - loss: 0.0044 - accuracy: 0.999 - ETA: 51s - loss: 0.0044 - accuracy: 0.999 - ETA: 50s - loss: 0.0043 - accuracy: 0.999 - ETA: 50s - loss: 0.0043 - accuracy: 0.999 - ETA: 49s - loss: 0.0043 - accuracy: 0.999 - ETA: 48s - loss: 0.0043 - accuracy: 0.999 - ETA: 47s - loss: 0.0042 - accuracy: 0.999 - ETA: 47s - loss: 0.0042 - accuracy: 0.999 - ETA: 46s - loss: 0.0042 - accuracy: 0.999 - ETA: 45s - loss: 0.0041 - accuracy: 0.999 - ETA: 45s - loss: 0.0041 - accuracy: 0.999 - ETA: 44s - loss: 0.0043 - accuracy: 0.999 - ETA: 43s - loss: 0.0043 - accuracy: 0.999 - ETA: 42s - loss: 0.0042 - accuracy: 0.999 - ETA: 42s - loss: 0.0042 - accuracy: 0.999 - ETA: 41s - loss: 0.0042 - accuracy: 0.999 - ETA: 40s - loss: 0.0042 - accuracy: 0.999 - ETA: 40s - loss: 0.0042 - accuracy: 0.999 - ETA: 39s - loss: 0.0041 - accuracy: 0.999 - ETA: 38s - loss: 0.0041 - accuracy: 0.999 - ETA: 37s - loss: 0.0041 - accuracy: 0.999 - ETA: 37s - loss: 0.0041 - accuracy: 0.999 - ETA: 36s - loss: 0.0041 - accuracy: 0.999 - ETA: 35s - loss: 0.0041 - accuracy: 0.999 - ETA: 34s - loss: 0.0040 - accuracy: 0.999 - ETA: 34s - loss: 0.0040 - accuracy: 0.999 - ETA: 33s - loss: 0.0041 - accuracy: 0.999 - ETA: 32s - loss: 0.0041 - accuracy: 0.999 - ETA: 31s - loss: 0.0041 - accuracy: 0.999 - ETA: 31s - loss: 0.0040 - accuracy: 0.999 - ETA: 30s - loss: 0.0040 - accuracy: 0.999 - ETA: 29s - loss: 0.0040 - accuracy: 0.999 - ETA: 29s - loss: 0.0040 - accuracy: 0.999 - ETA: 28s - loss: 0.0039 - accuracy: 0.999 - ETA: 27s - loss: 0.0039 - accuracy: 0.999 - ETA: 26s - loss: 0.0039 - accuracy: 0.999 - ETA: 26s - loss: 0.0039 - accuracy: 0.999 - ETA: 25s - loss: 0.0039 - accuracy: 0.999 - ETA: 24s - loss: 0.0038 - accuracy: 0.999 - ETA: 23s - loss: 0.0038 - accuracy: 0.999 - ETA: 23s - loss: 0.0038 - accuracy: 0.999 - ETA: 22s - loss: 0.0038 - accuracy: 0.999 - ETA: 21s - loss: 0.0039 - accuracy: 0.999 - ETA: 21s - loss: 0.0039 - accuracy: 0.999 - ETA: 20s - loss: 0.0042 - accuracy: 0.999 - ETA: 19s - loss: 0.0042 - accuracy: 0.999 - ETA: 18s - loss: 0.0042 - accuracy: 0.999 - ETA: 18s - loss: 0.0042 - accuracy: 0.999 - ETA: 17s - loss: 0.0041 - accuracy: 0.999 - ETA: 16s - loss: 0.0042 - accuracy: 0.999 - ETA: 15s - loss: 0.0041 - accuracy: 0.999 - ETA: 15s - loss: 0.0041 - accuracy: 0.999 - ETA: 14s - loss: 0.0043 - accuracy: 0.999 - ETA: 13s - loss: 0.0042 - accuracy: 0.999 - ETA: 13s - loss: 0.0043 - accuracy: 0.999 - ETA: 12s - loss: 0.0043 - accuracy: 0.999 - ETA: 11s - loss: 0.0043 - accuracy: 0.999 - ETA: 10s - loss: 0.0043 - accuracy: 0.999 - ETA: 10s - loss: 0.0043 - accuracy: 0.999 - ETA: 9s - loss: 0.0042 - accuracy: 0.999 - ETA: 8s - loss: 0.0043 - accuracy: 0.99 - ETA: 7s - loss: 0.0043 - accuracy: 0.99 - ETA: 7s - loss: 0.0042 - accuracy: 0.99 - ETA: 6s - loss: 0.0042 - accuracy: 0.99 - ETA: 5s - loss: 0.0042 - accuracy: 0.99 - ETA: 5s - loss: 0.0042 - accuracy: 0.99 - ETA: 4s - loss: 0.0042 - accuracy: 0.99 - ETA: 3s - loss: 0.0042 - accuracy: 0.99 - ETA: 2s - loss: 0.0042 - accuracy: 0.99 - ETA: 2s - loss: 0.0042 - accuracy: 0.99 - ETA: 1s - loss: 0.0041 - accuracy: 0.99 - ETA: 0s - loss: 0.0041 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.9861 - val_accuracy: 0.8087\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:49 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0031 - accuracy: 0.99 - ETA: 59s - loss: 0.0032 - accuracy: 0.9995 - ETA: 58s - loss: 0.0032 - accuracy: 0.999 - ETA: 58s - loss: 0.0032 - accuracy: 0.999 - ETA: 57s - loss: 0.0031 - accuracy: 0.999 - ETA: 56s - loss: 0.0031 - accuracy: 0.999 - ETA: 55s - loss: 0.0031 - accuracy: 0.999 - ETA: 55s - loss: 0.0031 - accuracy: 0.999 - ETA: 54s - loss: 0.0030 - accuracy: 0.999 - ETA: 53s - loss: 0.0031 - accuracy: 0.999 - ETA: 53s - loss: 0.0031 - accuracy: 0.999 - ETA: 52s - loss: 0.0031 - accuracy: 0.999 - ETA: 51s - loss: 0.0031 - accuracy: 0.999 - ETA: 50s - loss: 0.0031 - accuracy: 0.999 - ETA: 50s - loss: 0.0030 - accuracy: 0.999 - ETA: 49s - loss: 0.0031 - accuracy: 0.999 - ETA: 48s - loss: 0.0030 - accuracy: 0.999 - ETA: 48s - loss: 0.0030 - accuracy: 0.999 - ETA: 47s - loss: 0.0030 - accuracy: 0.999 - ETA: 46s - loss: 0.0030 - accuracy: 0.999 - ETA: 45s - loss: 0.0030 - accuracy: 0.999 - ETA: 45s - loss: 0.0030 - accuracy: 0.999 - ETA: 44s - loss: 0.0030 - accuracy: 0.999 - ETA: 43s - loss: 0.0030 - accuracy: 0.999 - ETA: 42s - loss: 0.0030 - accuracy: 0.999 - ETA: 42s - loss: 0.0031 - accuracy: 0.999 - ETA: 41s - loss: 0.0030 - accuracy: 0.999 - ETA: 40s - loss: 0.0030 - accuracy: 0.999 - ETA: 39s - loss: 0.0030 - accuracy: 0.999 - ETA: 39s - loss: 0.0031 - accuracy: 0.999 - ETA: 38s - loss: 0.0031 - accuracy: 0.999 - ETA: 37s - loss: 0.0031 - accuracy: 0.999 - ETA: 36s - loss: 0.0032 - accuracy: 0.999 - ETA: 36s - loss: 0.0032 - accuracy: 0.999 - ETA: 35s - loss: 0.0032 - accuracy: 0.999 - ETA: 34s - loss: 0.0032 - accuracy: 0.999 - ETA: 34s - loss: 0.0031 - accuracy: 0.999 - ETA: 33s - loss: 0.0031 - accuracy: 0.999 - ETA: 32s - loss: 0.0032 - accuracy: 0.999 - ETA: 31s - loss: 0.0032 - accuracy: 0.999 - ETA: 31s - loss: 0.0031 - accuracy: 0.999 - ETA: 30s - loss: 0.0031 - accuracy: 0.999 - ETA: 29s - loss: 0.0031 - accuracy: 0.999 - ETA: 28s - loss: 0.0031 - accuracy: 0.999 - ETA: 28s - loss: 0.0031 - accuracy: 0.999 - ETA: 27s - loss: 0.0031 - accuracy: 0.999 - ETA: 26s - loss: 0.0031 - accuracy: 0.999 - ETA: 26s - loss: 0.0031 - accuracy: 0.999 - ETA: 25s - loss: 0.0031 - accuracy: 0.999 - ETA: 24s - loss: 0.0033 - accuracy: 0.999 - ETA: 23s - loss: 0.0033 - accuracy: 0.999 - ETA: 23s - loss: 0.0033 - accuracy: 0.999 - ETA: 22s - loss: 0.0033 - accuracy: 0.999 - ETA: 21s - loss: 0.0033 - accuracy: 0.999 - ETA: 20s - loss: 0.0033 - accuracy: 0.999 - ETA: 20s - loss: 0.0033 - accuracy: 0.999 - ETA: 19s - loss: 0.0033 - accuracy: 0.999 - ETA: 18s - loss: 0.0033 - accuracy: 0.999 - ETA: 18s - loss: 0.0034 - accuracy: 0.999 - ETA: 17s - loss: 0.0034 - accuracy: 0.999 - ETA: 16s - loss: 0.0034 - accuracy: 0.999 - ETA: 15s - loss: 0.0034 - accuracy: 0.999 - ETA: 15s - loss: 0.0034 - accuracy: 0.999 - ETA: 14s - loss: 0.0034 - accuracy: 0.999 - ETA: 13s - loss: 0.0034 - accuracy: 0.999 - ETA: 12s - loss: 0.0033 - accuracy: 0.999 - ETA: 12s - loss: 0.0033 - accuracy: 0.999 - ETA: 11s - loss: 0.0034 - accuracy: 0.999 - ETA: 10s - loss: 0.0034 - accuracy: 0.999 - ETA: 10s - loss: 0.0034 - accuracy: 0.999 - ETA: 9s - loss: 0.0034 - accuracy: 0.999 - ETA: 8s - loss: 0.0034 - accuracy: 0.99 - ETA: 7s - loss: 0.0034 - accuracy: 0.99 - ETA: 7s - loss: 0.0034 - accuracy: 0.99 - ETA: 6s - loss: 0.0034 - accuracy: 0.99 - ETA: 5s - loss: 0.0034 - accuracy: 0.99 - ETA: 4s - loss: 0.0034 - accuracy: 0.99 - ETA: 4s - loss: 0.0033 - accuracy: 0.99 - ETA: 3s - loss: 0.0033 - accuracy: 0.99 - ETA: 2s - loss: 0.0033 - accuracy: 0.99 - ETA: 2s - loss: 0.0033 - accuracy: 0.99 - ETA: 1s - loss: 0.0033 - accuracy: 0.99 - ETA: 0s - loss: 0.0033 - accuracy: 0.99 - 120s 6ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.9867 - val_accuracy: 0.8089\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:55 - loss: 0.0040 - accuracy: 1.00 - ETA: 1:56 - loss: 0.0068 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0054 - accuracy: 1.00 - ETA: 1:53 - loss: 0.0043 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0067 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0060 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0032 - accuracy: 0.99 - ETA: 59s - loss: 0.0033 - accuracy: 0.9994 - ETA: 58s - loss: 0.0033 - accuracy: 0.999 - ETA: 57s - loss: 0.0033 - accuracy: 0.999 - ETA: 57s - loss: 0.0032 - accuracy: 0.999 - ETA: 56s - loss: 0.0032 - accuracy: 0.999 - ETA: 55s - loss: 0.0032 - accuracy: 0.999 - ETA: 54s - loss: 0.0032 - accuracy: 0.999 - ETA: 54s - loss: 0.0032 - accuracy: 0.999 - ETA: 53s - loss: 0.0031 - accuracy: 0.999 - ETA: 52s - loss: 0.0031 - accuracy: 0.999 - ETA: 51s - loss: 0.0031 - accuracy: 0.999 - ETA: 51s - loss: 0.0032 - accuracy: 0.999 - ETA: 50s - loss: 0.0031 - accuracy: 0.999 - ETA: 49s - loss: 0.0031 - accuracy: 0.999 - ETA: 48s - loss: 0.0036 - accuracy: 0.999 - ETA: 48s - loss: 0.0036 - accuracy: 0.999 - ETA: 47s - loss: 0.0035 - accuracy: 0.999 - ETA: 46s - loss: 0.0035 - accuracy: 0.999 - ETA: 46s - loss: 0.0035 - accuracy: 0.999 - ETA: 45s - loss: 0.0035 - accuracy: 0.999 - ETA: 44s - loss: 0.0035 - accuracy: 0.999 - ETA: 44s - loss: 0.0034 - accuracy: 0.999 - ETA: 43s - loss: 0.0034 - accuracy: 0.999 - ETA: 42s - loss: 0.0034 - accuracy: 0.999 - ETA: 41s - loss: 0.0034 - accuracy: 0.999 - ETA: 41s - loss: 0.0034 - accuracy: 0.999 - ETA: 40s - loss: 0.0034 - accuracy: 0.999 - ETA: 39s - loss: 0.0033 - accuracy: 0.999 - ETA: 38s - loss: 0.0033 - accuracy: 0.999 - ETA: 38s - loss: 0.0033 - accuracy: 0.999 - ETA: 37s - loss: 0.0033 - accuracy: 0.999 - ETA: 36s - loss: 0.0033 - accuracy: 0.999 - ETA: 35s - loss: 0.0033 - accuracy: 0.999 - ETA: 35s - loss: 0.0033 - accuracy: 0.999 - ETA: 34s - loss: 0.0033 - accuracy: 0.999 - ETA: 33s - loss: 0.0033 - accuracy: 0.999 - ETA: 32s - loss: 0.0033 - accuracy: 0.999 - ETA: 32s - loss: 0.0033 - accuracy: 0.999 - ETA: 31s - loss: 0.0032 - accuracy: 0.999 - ETA: 30s - loss: 0.0032 - accuracy: 0.999 - ETA: 30s - loss: 0.0032 - accuracy: 0.999 - ETA: 29s - loss: 0.0032 - accuracy: 0.999 - ETA: 28s - loss: 0.0032 - accuracy: 0.999 - ETA: 27s - loss: 0.0032 - accuracy: 0.999 - ETA: 27s - loss: 0.0032 - accuracy: 0.999 - ETA: 26s - loss: 0.0032 - accuracy: 0.999 - ETA: 25s - loss: 0.0032 - accuracy: 0.999 - ETA: 24s - loss: 0.0032 - accuracy: 0.999 - ETA: 24s - loss: 0.0032 - accuracy: 0.999 - ETA: 23s - loss: 0.0032 - accuracy: 0.999 - ETA: 22s - loss: 0.0032 - accuracy: 0.999 - ETA: 21s - loss: 0.0032 - accuracy: 0.999 - ETA: 21s - loss: 0.0031 - accuracy: 0.999 - ETA: 20s - loss: 0.0031 - accuracy: 0.999 - ETA: 19s - loss: 0.0031 - accuracy: 0.999 - ETA: 18s - loss: 0.0031 - accuracy: 0.999 - ETA: 18s - loss: 0.0031 - accuracy: 0.999 - ETA: 17s - loss: 0.0031 - accuracy: 0.999 - ETA: 16s - loss: 0.0031 - accuracy: 0.999 - ETA: 16s - loss: 0.0031 - accuracy: 0.999 - ETA: 15s - loss: 0.0031 - accuracy: 0.999 - ETA: 14s - loss: 0.0031 - accuracy: 0.999 - ETA: 13s - loss: 0.0031 - accuracy: 0.999 - ETA: 13s - loss: 0.0031 - accuracy: 0.999 - ETA: 12s - loss: 0.0031 - accuracy: 0.999 - ETA: 11s - loss: 0.0032 - accuracy: 0.999 - ETA: 10s - loss: 0.0032 - accuracy: 0.999 - ETA: 10s - loss: 0.0031 - accuracy: 0.999 - ETA: 9s - loss: 0.0031 - accuracy: 0.999 - ETA: 8s - loss: 0.0031 - accuracy: 0.99 - ETA: 7s - loss: 0.0031 - accuracy: 0.99 - ETA: 7s - loss: 0.0031 - accuracy: 0.99 - ETA: 6s - loss: 0.0031 - accuracy: 0.99 - ETA: 5s - loss: 0.0031 - accuracy: 0.99 - ETA: 5s - loss: 0.0031 - accuracy: 0.99 - ETA: 4s - loss: 0.0031 - accuracy: 0.99 - ETA: 3s - loss: 0.0030 - accuracy: 0.99 - ETA: 2s - loss: 0.0030 - accuracy: 0.99 - ETA: 2s - loss: 0.0030 - accuracy: 0.99 - ETA: 1s - loss: 0.0030 - accuracy: 0.99 - ETA: 0s - loss: 0.0030 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.9924 - val_accuracy: 0.8091\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:45 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0027 - accuracy: 0.99 - ETA: 59s - loss: 0.0027 - accuracy: 0.9998 - ETA: 59s - loss: 0.0026 - accuracy: 0.999 - ETA: 58s - loss: 0.0027 - accuracy: 0.999 - ETA: 57s - loss: 0.0026 - accuracy: 0.999 - ETA: 56s - loss: 0.0027 - accuracy: 0.999 - ETA: 56s - loss: 0.0027 - accuracy: 0.999 - ETA: 55s - loss: 0.0027 - accuracy: 0.999 - ETA: 54s - loss: 0.0027 - accuracy: 0.999 - ETA: 53s - loss: 0.0026 - accuracy: 0.999 - ETA: 53s - loss: 0.0028 - accuracy: 0.999 - ETA: 52s - loss: 0.0028 - accuracy: 0.999 - ETA: 51s - loss: 0.0028 - accuracy: 0.999 - ETA: 51s - loss: 0.0028 - accuracy: 0.999 - ETA: 50s - loss: 0.0028 - accuracy: 0.999 - ETA: 49s - loss: 0.0028 - accuracy: 0.999 - ETA: 48s - loss: 0.0028 - accuracy: 0.999 - ETA: 48s - loss: 0.0027 - accuracy: 0.999 - ETA: 47s - loss: 0.0028 - accuracy: 0.999 - ETA: 46s - loss: 0.0028 - accuracy: 0.999 - ETA: 45s - loss: 0.0027 - accuracy: 0.999 - ETA: 45s - loss: 0.0027 - accuracy: 0.999 - ETA: 44s - loss: 0.0027 - accuracy: 0.999 - ETA: 43s - loss: 0.0027 - accuracy: 0.999 - ETA: 43s - loss: 0.0027 - accuracy: 0.999 - ETA: 42s - loss: 0.0027 - accuracy: 0.999 - ETA: 41s - loss: 0.0027 - accuracy: 0.999 - ETA: 40s - loss: 0.0027 - accuracy: 0.999 - ETA: 40s - loss: 0.0027 - accuracy: 0.999 - ETA: 39s - loss: 0.0028 - accuracy: 0.999 - ETA: 38s - loss: 0.0028 - accuracy: 0.999 - ETA: 37s - loss: 0.0027 - accuracy: 0.999 - ETA: 37s - loss: 0.0028 - accuracy: 0.999 - ETA: 36s - loss: 0.0028 - accuracy: 0.999 - ETA: 35s - loss: 0.0027 - accuracy: 0.999 - ETA: 34s - loss: 0.0027 - accuracy: 0.999 - ETA: 34s - loss: 0.0027 - accuracy: 0.999 - ETA: 33s - loss: 0.0027 - accuracy: 0.999 - ETA: 32s - loss: 0.0027 - accuracy: 0.999 - ETA: 32s - loss: 0.0027 - accuracy: 0.999 - ETA: 31s - loss: 0.0027 - accuracy: 0.999 - ETA: 30s - loss: 0.0027 - accuracy: 0.999 - ETA: 29s - loss: 0.0027 - accuracy: 0.999 - ETA: 29s - loss: 0.0027 - accuracy: 0.999 - ETA: 28s - loss: 0.0027 - accuracy: 0.999 - ETA: 27s - loss: 0.0027 - accuracy: 0.999 - ETA: 26s - loss: 0.0026 - accuracy: 0.999 - ETA: 26s - loss: 0.0026 - accuracy: 0.999 - ETA: 25s - loss: 0.0026 - accuracy: 0.999 - ETA: 24s - loss: 0.0026 - accuracy: 0.999 - ETA: 23s - loss: 0.0026 - accuracy: 0.999 - ETA: 23s - loss: 0.0026 - accuracy: 0.999 - ETA: 22s - loss: 0.0026 - accuracy: 0.999 - ETA: 21s - loss: 0.0026 - accuracy: 0.999 - ETA: 21s - loss: 0.0026 - accuracy: 0.999 - ETA: 20s - loss: 0.0026 - accuracy: 0.999 - ETA: 19s - loss: 0.0026 - accuracy: 0.999 - ETA: 18s - loss: 0.0026 - accuracy: 0.999 - ETA: 18s - loss: 0.0026 - accuracy: 0.999 - ETA: 17s - loss: 0.0026 - accuracy: 0.999 - ETA: 16s - loss: 0.0027 - accuracy: 0.999 - ETA: 15s - loss: 0.0028 - accuracy: 0.999 - ETA: 15s - loss: 0.0028 - accuracy: 0.999 - ETA: 14s - loss: 0.0028 - accuracy: 0.999 - ETA: 13s - loss: 0.0028 - accuracy: 0.999 - ETA: 13s - loss: 0.0028 - accuracy: 0.999 - ETA: 12s - loss: 0.0028 - accuracy: 0.999 - ETA: 11s - loss: 0.0028 - accuracy: 0.999 - ETA: 10s - loss: 0.0028 - accuracy: 0.999 - ETA: 10s - loss: 0.0028 - accuracy: 0.999 - ETA: 9s - loss: 0.0028 - accuracy: 0.999 - ETA: 8s - loss: 0.0028 - accuracy: 0.99 - ETA: 7s - loss: 0.0027 - accuracy: 0.99 - ETA: 7s - loss: 0.0027 - accuracy: 0.99 - ETA: 6s - loss: 0.0027 - accuracy: 0.99 - ETA: 5s - loss: 0.0027 - accuracy: 0.99 - ETA: 5s - loss: 0.0027 - accuracy: 0.99 - ETA: 4s - loss: 0.0027 - accuracy: 0.99 - ETA: 3s - loss: 0.0028 - accuracy: 0.99 - ETA: 2s - loss: 0.0030 - accuracy: 0.99 - ETA: 2s - loss: 0.0030 - accuracy: 0.99 - ETA: 1s - loss: 0.0029 - accuracy: 0.99 - ETA: 0s - loss: 0.0029 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 1.0037 - val_accuracy: 0.8097\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:11 - loss: 0.0034 - accuracy: 1.00 - ETA: 2:00 - loss: 0.0025 - accuracy: 1.00 - ETA: 2:02 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:02 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:59 - loss: 0.0015 - accuracy: 1.00 - ETA: 1:55 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0022 - accuracy: 0.99 - ETA: 59s - loss: 0.0022 - accuracy: 0.9997 - ETA: 58s - loss: 0.0022 - accuracy: 0.999 - ETA: 58s - loss: 0.0022 - accuracy: 0.999 - ETA: 57s - loss: 0.0022 - accuracy: 0.999 - ETA: 56s - loss: 0.0022 - accuracy: 0.999 - ETA: 55s - loss: 0.0022 - accuracy: 0.999 - ETA: 55s - loss: 0.0021 - accuracy: 0.999 - ETA: 54s - loss: 0.0021 - accuracy: 0.999 - ETA: 53s - loss: 0.0022 - accuracy: 0.999 - ETA: 52s - loss: 0.0023 - accuracy: 0.999 - ETA: 52s - loss: 0.0022 - accuracy: 0.999 - ETA: 51s - loss: 0.0022 - accuracy: 0.999 - ETA: 50s - loss: 0.0022 - accuracy: 0.999 - ETA: 49s - loss: 0.0022 - accuracy: 0.999 - ETA: 49s - loss: 0.0022 - accuracy: 0.999 - ETA: 48s - loss: 0.0022 - accuracy: 0.999 - ETA: 47s - loss: 0.0022 - accuracy: 0.999 - ETA: 46s - loss: 0.0022 - accuracy: 0.999 - ETA: 46s - loss: 0.0022 - accuracy: 0.999 - ETA: 45s - loss: 0.0022 - accuracy: 0.999 - ETA: 44s - loss: 0.0022 - accuracy: 0.999 - ETA: 43s - loss: 0.0022 - accuracy: 0.999 - ETA: 43s - loss: 0.0024 - accuracy: 0.999 - ETA: 42s - loss: 0.0024 - accuracy: 0.999 - ETA: 41s - loss: 0.0024 - accuracy: 0.999 - ETA: 41s - loss: 0.0024 - accuracy: 0.999 - ETA: 40s - loss: 0.0024 - accuracy: 0.999 - ETA: 39s - loss: 0.0024 - accuracy: 0.999 - ETA: 38s - loss: 0.0023 - accuracy: 0.999 - ETA: 38s - loss: 0.0024 - accuracy: 0.999 - ETA: 37s - loss: 0.0024 - accuracy: 0.999 - ETA: 36s - loss: 0.0024 - accuracy: 0.999 - ETA: 35s - loss: 0.0024 - accuracy: 0.999 - ETA: 35s - loss: 0.0023 - accuracy: 0.999 - ETA: 34s - loss: 0.0023 - accuracy: 0.999 - ETA: 33s - loss: 0.0026 - accuracy: 0.999 - ETA: 32s - loss: 0.0026 - accuracy: 0.999 - ETA: 32s - loss: 0.0026 - accuracy: 0.999 - ETA: 31s - loss: 0.0026 - accuracy: 0.999 - ETA: 30s - loss: 0.0026 - accuracy: 0.999 - ETA: 29s - loss: 0.0026 - accuracy: 0.999 - ETA: 29s - loss: 0.0026 - accuracy: 0.999 - ETA: 28s - loss: 0.0026 - accuracy: 0.999 - ETA: 27s - loss: 0.0026 - accuracy: 0.999 - ETA: 27s - loss: 0.0026 - accuracy: 0.999 - ETA: 26s - loss: 0.0026 - accuracy: 0.999 - ETA: 25s - loss: 0.0026 - accuracy: 0.999 - ETA: 24s - loss: 0.0026 - accuracy: 0.999 - ETA: 24s - loss: 0.0026 - accuracy: 0.999 - ETA: 23s - loss: 0.0026 - accuracy: 0.999 - ETA: 22s - loss: 0.0026 - accuracy: 0.999 - ETA: 21s - loss: 0.0025 - accuracy: 0.999 - ETA: 21s - loss: 0.0025 - accuracy: 0.999 - ETA: 20s - loss: 0.0025 - accuracy: 0.999 - ETA: 19s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 17s - loss: 0.0027 - accuracy: 0.999 - ETA: 16s - loss: 0.0028 - accuracy: 0.999 - ETA: 16s - loss: 0.0028 - accuracy: 0.999 - ETA: 15s - loss: 0.0028 - accuracy: 0.999 - ETA: 14s - loss: 0.0028 - accuracy: 0.999 - ETA: 13s - loss: 0.0028 - accuracy: 0.999 - ETA: 13s - loss: 0.0028 - accuracy: 0.999 - ETA: 12s - loss: 0.0027 - accuracy: 0.999 - ETA: 11s - loss: 0.0027 - accuracy: 0.999 - ETA: 10s - loss: 0.0027 - accuracy: 0.999 - ETA: 10s - loss: 0.0027 - accuracy: 0.999 - ETA: 9s - loss: 0.0027 - accuracy: 0.999 - ETA: 8s - loss: 0.0027 - accuracy: 0.99 - ETA: 7s - loss: 0.0027 - accuracy: 0.99 - ETA: 7s - loss: 0.0027 - accuracy: 0.99 - ETA: 6s - loss: 0.0027 - accuracy: 0.99 - ETA: 5s - loss: 0.0027 - accuracy: 0.99 - ETA: 5s - loss: 0.0027 - accuracy: 0.99 - ETA: 4s - loss: 0.0028 - accuracy: 0.99 - ETA: 3s - loss: 0.0028 - accuracy: 0.99 - ETA: 2s - loss: 0.0028 - accuracy: 0.99 - ETA: 2s - loss: 0.0028 - accuracy: 0.99 - ETA: 1s - loss: 0.0028 - accuracy: 0.99 - ETA: 0s - loss: 0.0028 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.9932 - val_accuracy: 0.8101\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:51 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0016 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0026 - accuracy: 0.99 - ETA: 59s - loss: 0.0026 - accuracy: 0.9997 - ETA: 59s - loss: 0.0026 - accuracy: 0.999 - ETA: 58s - loss: 0.0026 - accuracy: 0.999 - ETA: 57s - loss: 0.0026 - accuracy: 0.999 - ETA: 56s - loss: 0.0026 - accuracy: 0.999 - ETA: 56s - loss: 0.0026 - accuracy: 0.999 - ETA: 55s - loss: 0.0026 - accuracy: 0.999 - ETA: 54s - loss: 0.0026 - accuracy: 0.999 - ETA: 54s - loss: 0.0025 - accuracy: 0.999 - ETA: 53s - loss: 0.0025 - accuracy: 0.999 - ETA: 52s - loss: 0.0025 - accuracy: 0.999 - ETA: 51s - loss: 0.0025 - accuracy: 0.999 - ETA: 51s - loss: 0.0026 - accuracy: 0.999 - ETA: 50s - loss: 0.0026 - accuracy: 0.999 - ETA: 49s - loss: 0.0026 - accuracy: 0.999 - ETA: 48s - loss: 0.0026 - accuracy: 0.999 - ETA: 48s - loss: 0.0026 - accuracy: 0.999 - ETA: 47s - loss: 0.0025 - accuracy: 0.999 - ETA: 46s - loss: 0.0025 - accuracy: 0.999 - ETA: 45s - loss: 0.0025 - accuracy: 0.999 - ETA: 45s - loss: 0.0028 - accuracy: 0.999 - ETA: 44s - loss: 0.0028 - accuracy: 0.999 - ETA: 43s - loss: 0.0028 - accuracy: 0.999 - ETA: 42s - loss: 0.0028 - accuracy: 0.999 - ETA: 42s - loss: 0.0028 - accuracy: 0.999 - ETA: 41s - loss: 0.0027 - accuracy: 0.999 - ETA: 40s - loss: 0.0028 - accuracy: 0.999 - ETA: 40s - loss: 0.0028 - accuracy: 0.999 - ETA: 39s - loss: 0.0028 - accuracy: 0.999 - ETA: 38s - loss: 0.0028 - accuracy: 0.999 - ETA: 37s - loss: 0.0028 - accuracy: 0.999 - ETA: 37s - loss: 0.0028 - accuracy: 0.999 - ETA: 36s - loss: 0.0028 - accuracy: 0.999 - ETA: 35s - loss: 0.0028 - accuracy: 0.999 - ETA: 34s - loss: 0.0028 - accuracy: 0.999 - ETA: 34s - loss: 0.0028 - accuracy: 0.999 - ETA: 33s - loss: 0.0027 - accuracy: 0.999 - ETA: 32s - loss: 0.0027 - accuracy: 0.999 - ETA: 32s - loss: 0.0027 - accuracy: 0.999 - ETA: 31s - loss: 0.0027 - accuracy: 0.999 - ETA: 30s - loss: 0.0027 - accuracy: 0.999 - ETA: 29s - loss: 0.0027 - accuracy: 0.999 - ETA: 29s - loss: 0.0027 - accuracy: 0.999 - ETA: 28s - loss: 0.0027 - accuracy: 0.999 - ETA: 27s - loss: 0.0027 - accuracy: 0.999 - ETA: 26s - loss: 0.0027 - accuracy: 0.999 - ETA: 26s - loss: 0.0028 - accuracy: 0.999 - ETA: 25s - loss: 0.0028 - accuracy: 0.999 - ETA: 24s - loss: 0.0028 - accuracy: 0.999 - ETA: 23s - loss: 0.0028 - accuracy: 0.999 - ETA: 23s - loss: 0.0028 - accuracy: 0.999 - ETA: 22s - loss: 0.0028 - accuracy: 0.999 - ETA: 21s - loss: 0.0028 - accuracy: 0.999 - ETA: 21s - loss: 0.0028 - accuracy: 0.999 - ETA: 20s - loss: 0.0029 - accuracy: 0.999 - ETA: 19s - loss: 0.0030 - accuracy: 0.999 - ETA: 18s - loss: 0.0029 - accuracy: 0.999 - ETA: 18s - loss: 0.0029 - accuracy: 0.999 - ETA: 17s - loss: 0.0029 - accuracy: 0.999 - ETA: 16s - loss: 0.0029 - accuracy: 0.999 - ETA: 15s - loss: 0.0029 - accuracy: 0.999 - ETA: 15s - loss: 0.0029 - accuracy: 0.999 - ETA: 14s - loss: 0.0029 - accuracy: 0.999 - ETA: 13s - loss: 0.0029 - accuracy: 0.999 - ETA: 13s - loss: 0.0030 - accuracy: 0.999 - ETA: 12s - loss: 0.0030 - accuracy: 0.999 - ETA: 11s - loss: 0.0030 - accuracy: 0.999 - ETA: 10s - loss: 0.0030 - accuracy: 0.999 - ETA: 10s - loss: 0.0030 - accuracy: 0.999 - ETA: 9s - loss: 0.0030 - accuracy: 0.999 - ETA: 8s - loss: 0.0030 - accuracy: 0.99 - ETA: 8s - loss: 0.0030 - accuracy: 0.99 - ETA: 7s - loss: 0.0030 - accuracy: 0.99 - ETA: 6s - loss: 0.0030 - accuracy: 0.99 - ETA: 5s - loss: 0.0029 - accuracy: 0.99 - ETA: 5s - loss: 0.0029 - accuracy: 0.99 - ETA: 4s - loss: 0.0029 - accuracy: 0.99 - ETA: 3s - loss: 0.0029 - accuracy: 0.99 - ETA: 2s - loss: 0.0029 - accuracy: 0.99 - ETA: 2s - loss: 0.0029 - accuracy: 0.99 - ETA: 1s - loss: 0.0029 - accuracy: 0.99 - ETA: 0s - loss: 0.0029 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 1.0019 - val_accuracy: 0.8095\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:49 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0027 - accuracy: 0.99 - ETA: 59s - loss: 0.0026 - accuracy: 0.9998 - ETA: 58s - loss: 0.0026 - accuracy: 0.999 - ETA: 58s - loss: 0.0026 - accuracy: 0.999 - ETA: 57s - loss: 0.0026 - accuracy: 0.999 - ETA: 56s - loss: 0.0026 - accuracy: 0.999 - ETA: 55s - loss: 0.0026 - accuracy: 0.999 - ETA: 55s - loss: 0.0025 - accuracy: 0.999 - ETA: 54s - loss: 0.0025 - accuracy: 0.999 - ETA: 53s - loss: 0.0026 - accuracy: 0.999 - ETA: 52s - loss: 0.0025 - accuracy: 0.999 - ETA: 51s - loss: 0.0025 - accuracy: 0.999 - ETA: 51s - loss: 0.0025 - accuracy: 0.999 - ETA: 50s - loss: 0.0026 - accuracy: 0.999 - ETA: 49s - loss: 0.0025 - accuracy: 0.999 - ETA: 49s - loss: 0.0026 - accuracy: 0.999 - ETA: 48s - loss: 0.0026 - accuracy: 0.999 - ETA: 47s - loss: 0.0026 - accuracy: 0.999 - ETA: 46s - loss: 0.0027 - accuracy: 0.999 - ETA: 46s - loss: 0.0027 - accuracy: 0.999 - ETA: 45s - loss: 0.0026 - accuracy: 0.999 - ETA: 44s - loss: 0.0027 - accuracy: 0.999 - ETA: 44s - loss: 0.0027 - accuracy: 0.999 - ETA: 43s - loss: 0.0027 - accuracy: 0.999 - ETA: 42s - loss: 0.0026 - accuracy: 0.999 - ETA: 41s - loss: 0.0026 - accuracy: 0.999 - ETA: 41s - loss: 0.0026 - accuracy: 0.999 - ETA: 40s - loss: 0.0026 - accuracy: 0.999 - ETA: 39s - loss: 0.0026 - accuracy: 0.999 - ETA: 38s - loss: 0.0026 - accuracy: 0.999 - ETA: 38s - loss: 0.0025 - accuracy: 0.999 - ETA: 37s - loss: 0.0026 - accuracy: 0.999 - ETA: 36s - loss: 0.0026 - accuracy: 0.999 - ETA: 35s - loss: 0.0027 - accuracy: 0.999 - ETA: 35s - loss: 0.0028 - accuracy: 0.999 - ETA: 34s - loss: 0.0029 - accuracy: 0.999 - ETA: 33s - loss: 0.0028 - accuracy: 0.999 - ETA: 32s - loss: 0.0028 - accuracy: 0.999 - ETA: 32s - loss: 0.0028 - accuracy: 0.999 - ETA: 31s - loss: 0.0028 - accuracy: 0.999 - ETA: 30s - loss: 0.0028 - accuracy: 0.999 - ETA: 30s - loss: 0.0028 - accuracy: 0.999 - ETA: 29s - loss: 0.0028 - accuracy: 0.999 - ETA: 28s - loss: 0.0028 - accuracy: 0.999 - ETA: 27s - loss: 0.0028 - accuracy: 0.999 - ETA: 27s - loss: 0.0028 - accuracy: 0.999 - ETA: 26s - loss: 0.0028 - accuracy: 0.999 - ETA: 25s - loss: 0.0028 - accuracy: 0.999 - ETA: 24s - loss: 0.0028 - accuracy: 0.999 - ETA: 24s - loss: 0.0027 - accuracy: 0.999 - ETA: 23s - loss: 0.0027 - accuracy: 0.999 - ETA: 22s - loss: 0.0027 - accuracy: 0.999 - ETA: 21s - loss: 0.0027 - accuracy: 0.999 - ETA: 21s - loss: 0.0027 - accuracy: 0.999 - ETA: 20s - loss: 0.0027 - accuracy: 0.999 - ETA: 19s - loss: 0.0027 - accuracy: 0.999 - ETA: 18s - loss: 0.0027 - accuracy: 0.999 - ETA: 18s - loss: 0.0026 - accuracy: 0.999 - ETA: 17s - loss: 0.0026 - accuracy: 0.999 - ETA: 16s - loss: 0.0026 - accuracy: 0.999 - ETA: 16s - loss: 0.0027 - accuracy: 0.999 - ETA: 15s - loss: 0.0026 - accuracy: 0.999 - ETA: 14s - loss: 0.0028 - accuracy: 0.999 - ETA: 13s - loss: 0.0028 - accuracy: 0.999 - ETA: 13s - loss: 0.0028 - accuracy: 0.999 - ETA: 12s - loss: 0.0028 - accuracy: 0.999 - ETA: 11s - loss: 0.0028 - accuracy: 0.999 - ETA: 10s - loss: 0.0028 - accuracy: 0.999 - ETA: 10s - loss: 0.0028 - accuracy: 0.999 - ETA: 9s - loss: 0.0028 - accuracy: 0.999 - ETA: 8s - loss: 0.0028 - accuracy: 0.99 - ETA: 7s - loss: 0.0027 - accuracy: 0.99 - ETA: 7s - loss: 0.0027 - accuracy: 0.99 - ETA: 6s - loss: 0.0027 - accuracy: 0.99 - ETA: 5s - loss: 0.0027 - accuracy: 0.99 - ETA: 5s - loss: 0.0027 - accuracy: 0.99 - ETA: 4s - loss: 0.0027 - accuracy: 0.99 - ETA: 3s - loss: 0.0027 - accuracy: 0.99 - ETA: 2s - loss: 0.0027 - accuracy: 0.99 - ETA: 2s - loss: 0.0027 - accuracy: 0.99 - ETA: 1s - loss: 0.0028 - accuracy: 0.99 - ETA: 0s - loss: 0.0028 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 1.0123 - val_accuracy: 0.8080\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:53 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:53 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:53 - loss: 0.0016 - accuracy: 1.00 - ETA: 1:54 - loss: 0.0016 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0029 - accuracy: 0.99 - ETA: 59s - loss: 0.0029 - accuracy: 0.9993 - ETA: 59s - loss: 0.0029 - accuracy: 0.999 - ETA: 58s - loss: 0.0029 - accuracy: 0.999 - ETA: 57s - loss: 0.0029 - accuracy: 0.999 - ETA: 57s - loss: 0.0029 - accuracy: 0.999 - ETA: 56s - loss: 0.0029 - accuracy: 0.999 - ETA: 55s - loss: 0.0029 - accuracy: 0.999 - ETA: 54s - loss: 0.0029 - accuracy: 0.999 - ETA: 54s - loss: 0.0028 - accuracy: 0.999 - ETA: 53s - loss: 0.0029 - accuracy: 0.999 - ETA: 52s - loss: 0.0029 - accuracy: 0.999 - ETA: 51s - loss: 0.0029 - accuracy: 0.999 - ETA: 51s - loss: 0.0030 - accuracy: 0.999 - ETA: 50s - loss: 0.0029 - accuracy: 0.999 - ETA: 49s - loss: 0.0029 - accuracy: 0.999 - ETA: 48s - loss: 0.0029 - accuracy: 0.999 - ETA: 48s - loss: 0.0029 - accuracy: 0.999 - ETA: 47s - loss: 0.0029 - accuracy: 0.999 - ETA: 46s - loss: 0.0029 - accuracy: 0.999 - ETA: 45s - loss: 0.0029 - accuracy: 0.999 - ETA: 45s - loss: 0.0029 - accuracy: 0.999 - ETA: 44s - loss: 0.0029 - accuracy: 0.999 - ETA: 43s - loss: 0.0029 - accuracy: 0.999 - ETA: 42s - loss: 0.0029 - accuracy: 0.999 - ETA: 42s - loss: 0.0029 - accuracy: 0.999 - ETA: 41s - loss: 0.0029 - accuracy: 0.999 - ETA: 40s - loss: 0.0028 - accuracy: 0.999 - ETA: 39s - loss: 0.0029 - accuracy: 0.999 - ETA: 39s - loss: 0.0031 - accuracy: 0.999 - ETA: 38s - loss: 0.0032 - accuracy: 0.999 - ETA: 37s - loss: 0.0032 - accuracy: 0.999 - ETA: 37s - loss: 0.0034 - accuracy: 0.999 - ETA: 36s - loss: 0.0034 - accuracy: 0.999 - ETA: 35s - loss: 0.0034 - accuracy: 0.999 - ETA: 34s - loss: 0.0034 - accuracy: 0.999 - ETA: 34s - loss: 0.0033 - accuracy: 0.999 - ETA: 33s - loss: 0.0033 - accuracy: 0.999 - ETA: 32s - loss: 0.0033 - accuracy: 0.999 - ETA: 31s - loss: 0.0033 - accuracy: 0.999 - ETA: 31s - loss: 0.0033 - accuracy: 0.999 - ETA: 30s - loss: 0.0033 - accuracy: 0.999 - ETA: 29s - loss: 0.0033 - accuracy: 0.999 - ETA: 28s - loss: 0.0033 - accuracy: 0.999 - ETA: 28s - loss: 0.0033 - accuracy: 0.999 - ETA: 27s - loss: 0.0033 - accuracy: 0.999 - ETA: 26s - loss: 0.0033 - accuracy: 0.999 - ETA: 26s - loss: 0.0032 - accuracy: 0.999 - ETA: 25s - loss: 0.0032 - accuracy: 0.999 - ETA: 24s - loss: 0.0032 - accuracy: 0.999 - ETA: 23s - loss: 0.0032 - accuracy: 0.999 - ETA: 23s - loss: 0.0032 - accuracy: 0.999 - ETA: 22s - loss: 0.0033 - accuracy: 0.999 - ETA: 21s - loss: 0.0033 - accuracy: 0.999 - ETA: 21s - loss: 0.0032 - accuracy: 0.999 - ETA: 20s - loss: 0.0032 - accuracy: 0.999 - ETA: 19s - loss: 0.0032 - accuracy: 0.999 - ETA: 18s - loss: 0.0032 - accuracy: 0.999 - ETA: 18s - loss: 0.0032 - accuracy: 0.999 - ETA: 17s - loss: 0.0032 - accuracy: 0.999 - ETA: 16s - loss: 0.0032 - accuracy: 0.999 - ETA: 15s - loss: 0.0032 - accuracy: 0.999 - ETA: 15s - loss: 0.0032 - accuracy: 0.999 - ETA: 14s - loss: 0.0032 - accuracy: 0.999 - ETA: 13s - loss: 0.0032 - accuracy: 0.999 - ETA: 13s - loss: 0.0032 - accuracy: 0.999 - ETA: 12s - loss: 0.0032 - accuracy: 0.999 - ETA: 11s - loss: 0.0032 - accuracy: 0.999 - ETA: 10s - loss: 0.0032 - accuracy: 0.999 - ETA: 10s - loss: 0.0032 - accuracy: 0.999 - ETA: 9s - loss: 0.0032 - accuracy: 0.999 - ETA: 8s - loss: 0.0032 - accuracy: 0.99 - ETA: 7s - loss: 0.0032 - accuracy: 0.99 - ETA: 7s - loss: 0.0032 - accuracy: 0.99 - ETA: 6s - loss: 0.0032 - accuracy: 0.99 - ETA: 5s - loss: 0.0032 - accuracy: 0.99 - ETA: 5s - loss: 0.0032 - accuracy: 0.99 - ETA: 4s - loss: 0.0031 - accuracy: 0.99 - ETA: 3s - loss: 0.0032 - accuracy: 0.99 - ETA: 2s - loss: 0.0032 - accuracy: 0.99 - ETA: 2s - loss: 0.0032 - accuracy: 0.99 - ETA: 1s - loss: 0.0032 - accuracy: 0.99 - ETA: 0s - loss: 0.0032 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.9893 - val_accuracy: 0.8101\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:59 - loss: 8.2517e-04 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0106 - accuracy: 0.9961   - ETA: 1:50 - loss: 0.0073 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0093 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0089 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0081 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0074 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0068 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0070 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0065 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0062 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0058 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0053 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0051 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0050 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0048 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0035 - accuracy: 0.99 - ETA: 59s - loss: 0.0035 - accuracy: 0.9993 - ETA: 59s - loss: 0.0039 - accuracy: 0.999 - ETA: 58s - loss: 0.0039 - accuracy: 0.999 - ETA: 57s - loss: 0.0039 - accuracy: 0.999 - ETA: 56s - loss: 0.0039 - accuracy: 0.999 - ETA: 56s - loss: 0.0038 - accuracy: 0.999 - ETA: 55s - loss: 0.0038 - accuracy: 0.999 - ETA: 54s - loss: 0.0038 - accuracy: 0.999 - ETA: 53s - loss: 0.0037 - accuracy: 0.999 - ETA: 53s - loss: 0.0037 - accuracy: 0.999 - ETA: 52s - loss: 0.0038 - accuracy: 0.999 - ETA: 51s - loss: 0.0038 - accuracy: 0.999 - ETA: 50s - loss: 0.0037 - accuracy: 0.999 - ETA: 50s - loss: 0.0037 - accuracy: 0.999 - ETA: 49s - loss: 0.0037 - accuracy: 0.999 - ETA: 48s - loss: 0.0037 - accuracy: 0.999 - ETA: 48s - loss: 0.0037 - accuracy: 0.999 - ETA: 47s - loss: 0.0036 - accuracy: 0.999 - ETA: 46s - loss: 0.0036 - accuracy: 0.999 - ETA: 45s - loss: 0.0036 - accuracy: 0.999 - ETA: 45s - loss: 0.0036 - accuracy: 0.999 - ETA: 44s - loss: 0.0036 - accuracy: 0.999 - ETA: 43s - loss: 0.0036 - accuracy: 0.999 - ETA: 42s - loss: 0.0036 - accuracy: 0.999 - ETA: 42s - loss: 0.0037 - accuracy: 0.999 - ETA: 41s - loss: 0.0036 - accuracy: 0.999 - ETA: 40s - loss: 0.0036 - accuracy: 0.999 - ETA: 39s - loss: 0.0036 - accuracy: 0.999 - ETA: 39s - loss: 0.0036 - accuracy: 0.999 - ETA: 38s - loss: 0.0035 - accuracy: 0.999 - ETA: 37s - loss: 0.0035 - accuracy: 0.999 - ETA: 36s - loss: 0.0035 - accuracy: 0.999 - ETA: 36s - loss: 0.0035 - accuracy: 0.999 - ETA: 35s - loss: 0.0035 - accuracy: 0.999 - ETA: 34s - loss: 0.0035 - accuracy: 0.999 - ETA: 33s - loss: 0.0035 - accuracy: 0.999 - ETA: 33s - loss: 0.0035 - accuracy: 0.999 - ETA: 32s - loss: 0.0034 - accuracy: 0.999 - ETA: 31s - loss: 0.0034 - accuracy: 0.999 - ETA: 30s - loss: 0.0034 - accuracy: 0.999 - ETA: 30s - loss: 0.0034 - accuracy: 0.999 - ETA: 29s - loss: 0.0034 - accuracy: 0.999 - ETA: 28s - loss: 0.0034 - accuracy: 0.999 - ETA: 28s - loss: 0.0034 - accuracy: 0.999 - ETA: 27s - loss: 0.0034 - accuracy: 0.999 - ETA: 26s - loss: 0.0034 - accuracy: 0.999 - ETA: 25s - loss: 0.0034 - accuracy: 0.999 - ETA: 25s - loss: 0.0033 - accuracy: 0.999 - ETA: 24s - loss: 0.0033 - accuracy: 0.999 - ETA: 23s - loss: 0.0033 - accuracy: 0.999 - ETA: 22s - loss: 0.0033 - accuracy: 0.999 - ETA: 22s - loss: 0.0033 - accuracy: 0.999 - ETA: 21s - loss: 0.0033 - accuracy: 0.999 - ETA: 20s - loss: 0.0033 - accuracy: 0.999 - ETA: 19s - loss: 0.0033 - accuracy: 0.999 - ETA: 19s - loss: 0.0033 - accuracy: 0.999 - ETA: 18s - loss: 0.0032 - accuracy: 0.999 - ETA: 17s - loss: 0.0032 - accuracy: 0.999 - ETA: 16s - loss: 0.0032 - accuracy: 0.999 - ETA: 16s - loss: 0.0032 - accuracy: 0.999 - ETA: 15s - loss: 0.0032 - accuracy: 0.999 - ETA: 14s - loss: 0.0032 - accuracy: 0.999 - ETA: 13s - loss: 0.0032 - accuracy: 0.999 - ETA: 13s - loss: 0.0032 - accuracy: 0.999 - ETA: 12s - loss: 0.0033 - accuracy: 0.999 - ETA: 11s - loss: 0.0033 - accuracy: 0.999 - ETA: 10s - loss: 0.0033 - accuracy: 0.999 - ETA: 10s - loss: 0.0033 - accuracy: 0.999 - ETA: 9s - loss: 0.0034 - accuracy: 0.999 - ETA: 8s - loss: 0.0034 - accuracy: 0.99 - ETA: 8s - loss: 0.0034 - accuracy: 0.99 - ETA: 7s - loss: 0.0033 - accuracy: 0.99 - ETA: 6s - loss: 0.0033 - accuracy: 0.99 - ETA: 5s - loss: 0.0033 - accuracy: 0.99 - ETA: 5s - loss: 0.0033 - accuracy: 0.99 - ETA: 4s - loss: 0.0033 - accuracy: 0.99 - ETA: 3s - loss: 0.0033 - accuracy: 0.99 - ETA: 2s - loss: 0.0034 - accuracy: 0.99 - ETA: 2s - loss: 0.0034 - accuracy: 0.99 - ETA: 1s - loss: 0.0034 - accuracy: 0.99 - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.9839 - val_accuracy: 0.8080\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:58 - loss: 0.0014 - accuracy: 1.00 - ETA: 1:58 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:53 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:53 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0047 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0046 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0044 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0043 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0042 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0036 - accuracy: 0.99 - ETA: 59s - loss: 0.0037 - accuracy: 0.9993 - ETA: 59s - loss: 0.0036 - accuracy: 0.999 - ETA: 58s - loss: 0.0036 - accuracy: 0.999 - ETA: 57s - loss: 0.0035 - accuracy: 0.999 - ETA: 56s - loss: 0.0035 - accuracy: 0.999 - ETA: 56s - loss: 0.0035 - accuracy: 0.999 - ETA: 55s - loss: 0.0035 - accuracy: 0.999 - ETA: 54s - loss: 0.0035 - accuracy: 0.999 - ETA: 53s - loss: 0.0035 - accuracy: 0.999 - ETA: 53s - loss: 0.0035 - accuracy: 0.999 - ETA: 52s - loss: 0.0034 - accuracy: 0.999 - ETA: 51s - loss: 0.0034 - accuracy: 0.999 - ETA: 51s - loss: 0.0034 - accuracy: 0.999 - ETA: 50s - loss: 0.0034 - accuracy: 0.999 - ETA: 49s - loss: 0.0035 - accuracy: 0.999 - ETA: 48s - loss: 0.0035 - accuracy: 0.999 - ETA: 48s - loss: 0.0035 - accuracy: 0.999 - ETA: 47s - loss: 0.0034 - accuracy: 0.999 - ETA: 46s - loss: 0.0034 - accuracy: 0.999 - ETA: 45s - loss: 0.0034 - accuracy: 0.999 - ETA: 45s - loss: 0.0034 - accuracy: 0.999 - ETA: 44s - loss: 0.0033 - accuracy: 0.999 - ETA: 43s - loss: 0.0033 - accuracy: 0.999 - ETA: 43s - loss: 0.0033 - accuracy: 0.999 - ETA: 42s - loss: 0.0033 - accuracy: 0.999 - ETA: 41s - loss: 0.0033 - accuracy: 0.999 - ETA: 40s - loss: 0.0033 - accuracy: 0.999 - ETA: 40s - loss: 0.0033 - accuracy: 0.999 - ETA: 39s - loss: 0.0032 - accuracy: 0.999 - ETA: 38s - loss: 0.0032 - accuracy: 0.999 - ETA: 38s - loss: 0.0032 - accuracy: 0.999 - ETA: 37s - loss: 0.0032 - accuracy: 0.999 - ETA: 36s - loss: 0.0032 - accuracy: 0.999 - ETA: 35s - loss: 0.0032 - accuracy: 0.999 - ETA: 35s - loss: 0.0031 - accuracy: 0.999 - ETA: 34s - loss: 0.0032 - accuracy: 0.999 - ETA: 33s - loss: 0.0032 - accuracy: 0.999 - ETA: 32s - loss: 0.0033 - accuracy: 0.999 - ETA: 32s - loss: 0.0033 - accuracy: 0.999 - ETA: 31s - loss: 0.0033 - accuracy: 0.999 - ETA: 30s - loss: 0.0032 - accuracy: 0.999 - ETA: 30s - loss: 0.0032 - accuracy: 0.999 - ETA: 29s - loss: 0.0033 - accuracy: 0.999 - ETA: 28s - loss: 0.0033 - accuracy: 0.999 - ETA: 27s - loss: 0.0033 - accuracy: 0.999 - ETA: 27s - loss: 0.0032 - accuracy: 0.999 - ETA: 26s - loss: 0.0032 - accuracy: 0.999 - ETA: 25s - loss: 0.0032 - accuracy: 0.999 - ETA: 24s - loss: 0.0032 - accuracy: 0.999 - ETA: 24s - loss: 0.0032 - accuracy: 0.999 - ETA: 23s - loss: 0.0032 - accuracy: 0.999 - ETA: 22s - loss: 0.0032 - accuracy: 0.999 - ETA: 21s - loss: 0.0032 - accuracy: 0.999 - ETA: 21s - loss: 0.0032 - accuracy: 0.999 - ETA: 20s - loss: 0.0032 - accuracy: 0.999 - ETA: 19s - loss: 0.0032 - accuracy: 0.999 - ETA: 18s - loss: 0.0031 - accuracy: 0.999 - ETA: 18s - loss: 0.0031 - accuracy: 0.999 - ETA: 17s - loss: 0.0031 - accuracy: 0.999 - ETA: 16s - loss: 0.0031 - accuracy: 0.999 - ETA: 16s - loss: 0.0031 - accuracy: 0.999 - ETA: 15s - loss: 0.0031 - accuracy: 0.999 - ETA: 14s - loss: 0.0031 - accuracy: 0.999 - ETA: 13s - loss: 0.0032 - accuracy: 0.999 - ETA: 13s - loss: 0.0032 - accuracy: 0.999 - ETA: 12s - loss: 0.0031 - accuracy: 0.999 - ETA: 11s - loss: 0.0031 - accuracy: 0.999 - ETA: 10s - loss: 0.0031 - accuracy: 0.999 - ETA: 10s - loss: 0.0031 - accuracy: 0.999 - ETA: 9s - loss: 0.0031 - accuracy: 0.999 - ETA: 8s - loss: 0.0031 - accuracy: 0.99 - ETA: 7s - loss: 0.0031 - accuracy: 0.99 - ETA: 7s - loss: 0.0030 - accuracy: 0.99 - ETA: 6s - loss: 0.0030 - accuracy: 0.99 - ETA: 5s - loss: 0.0030 - accuracy: 0.99 - ETA: 5s - loss: 0.0030 - accuracy: 0.99 - ETA: 4s - loss: 0.0030 - accuracy: 0.99 - ETA: 3s - loss: 0.0030 - accuracy: 0.99 - ETA: 2s - loss: 0.0030 - accuracy: 0.99 - ETA: 2s - loss: 0.0029 - accuracy: 0.99 - ETA: 1s - loss: 0.0029 - accuracy: 0.99 - ETA: 0s - loss: 0.0029 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.9851 - val_accuracy: 0.8116\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:49 - loss: 0.0012 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0012 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0011 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0036 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0035 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0032 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0028 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:31 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:30 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:30 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:29 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:28 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:28 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:27 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:26 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:25 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:25 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:24 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:23 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:22 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0026 - accuracy: 0.99 - ETA: 59s - loss: 0.0027 - accuracy: 0.9996 - ETA: 58s - loss: 0.0027 - accuracy: 0.999 - ETA: 58s - loss: 0.0027 - accuracy: 0.999 - ETA: 57s - loss: 0.0027 - accuracy: 0.999 - ETA: 56s - loss: 0.0027 - accuracy: 0.999 - ETA: 55s - loss: 0.0026 - accuracy: 0.999 - ETA: 55s - loss: 0.0026 - accuracy: 0.999 - ETA: 54s - loss: 0.0026 - accuracy: 0.999 - ETA: 53s - loss: 0.0026 - accuracy: 0.999 - ETA: 52s - loss: 0.0026 - accuracy: 0.999 - ETA: 52s - loss: 0.0026 - accuracy: 0.999 - ETA: 51s - loss: 0.0026 - accuracy: 0.999 - ETA: 50s - loss: 0.0026 - accuracy: 0.999 - ETA: 49s - loss: 0.0025 - accuracy: 0.999 - ETA: 49s - loss: 0.0025 - accuracy: 0.999 - ETA: 48s - loss: 0.0025 - accuracy: 0.999 - ETA: 47s - loss: 0.0025 - accuracy: 0.999 - ETA: 46s - loss: 0.0025 - accuracy: 0.999 - ETA: 46s - loss: 0.0025 - accuracy: 0.999 - ETA: 45s - loss: 0.0025 - accuracy: 0.999 - ETA: 44s - loss: 0.0025 - accuracy: 0.999 - ETA: 43s - loss: 0.0025 - accuracy: 0.999 - ETA: 43s - loss: 0.0025 - accuracy: 0.999 - ETA: 42s - loss: 0.0025 - accuracy: 0.999 - ETA: 41s - loss: 0.0025 - accuracy: 0.999 - ETA: 40s - loss: 0.0025 - accuracy: 0.999 - ETA: 40s - loss: 0.0025 - accuracy: 0.999 - ETA: 39s - loss: 0.0024 - accuracy: 0.999 - ETA: 38s - loss: 0.0024 - accuracy: 0.999 - ETA: 38s - loss: 0.0024 - accuracy: 0.999 - ETA: 37s - loss: 0.0024 - accuracy: 0.999 - ETA: 36s - loss: 0.0024 - accuracy: 0.999 - ETA: 35s - loss: 0.0024 - accuracy: 0.999 - ETA: 35s - loss: 0.0024 - accuracy: 0.999 - ETA: 34s - loss: 0.0024 - accuracy: 0.999 - ETA: 33s - loss: 0.0024 - accuracy: 0.999 - ETA: 32s - loss: 0.0024 - accuracy: 0.999 - ETA: 32s - loss: 0.0024 - accuracy: 0.999 - ETA: 31s - loss: 0.0024 - accuracy: 0.999 - ETA: 30s - loss: 0.0024 - accuracy: 0.999 - ETA: 29s - loss: 0.0024 - accuracy: 0.999 - ETA: 29s - loss: 0.0024 - accuracy: 0.999 - ETA: 28s - loss: 0.0024 - accuracy: 0.999 - ETA: 27s - loss: 0.0024 - accuracy: 0.999 - ETA: 27s - loss: 0.0024 - accuracy: 0.999 - ETA: 26s - loss: 0.0024 - accuracy: 0.999 - ETA: 25s - loss: 0.0024 - accuracy: 0.999 - ETA: 24s - loss: 0.0026 - accuracy: 0.999 - ETA: 24s - loss: 0.0026 - accuracy: 0.999 - ETA: 23s - loss: 0.0026 - accuracy: 0.999 - ETA: 22s - loss: 0.0026 - accuracy: 0.999 - ETA: 21s - loss: 0.0026 - accuracy: 0.999 - ETA: 21s - loss: 0.0026 - accuracy: 0.999 - ETA: 20s - loss: 0.0026 - accuracy: 0.999 - ETA: 19s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 17s - loss: 0.0025 - accuracy: 0.999 - ETA: 16s - loss: 0.0025 - accuracy: 0.999 - ETA: 16s - loss: 0.0026 - accuracy: 0.999 - ETA: 15s - loss: 0.0026 - accuracy: 0.999 - ETA: 14s - loss: 0.0026 - accuracy: 0.999 - ETA: 13s - loss: 0.0025 - accuracy: 0.999 - ETA: 13s - loss: 0.0025 - accuracy: 0.999 - ETA: 12s - loss: 0.0026 - accuracy: 0.999 - ETA: 11s - loss: 0.0025 - accuracy: 0.999 - ETA: 10s - loss: 0.0025 - accuracy: 0.999 - ETA: 10s - loss: 0.0025 - accuracy: 0.999 - ETA: 9s - loss: 0.0026 - accuracy: 0.999 - ETA: 8s - loss: 0.0026 - accuracy: 0.99 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 6s - loss: 0.0026 - accuracy: 0.99 - ETA: 5s - loss: 0.0026 - accuracy: 0.99 - ETA: 5s - loss: 0.0026 - accuracy: 0.99 - ETA: 4s - loss: 0.0026 - accuracy: 0.99 - ETA: 3s - loss: 0.0026 - accuracy: 0.99 - ETA: 2s - loss: 0.0026 - accuracy: 0.99 - ETA: 2s - loss: 0.0026 - accuracy: 0.99 - ETA: 1s - loss: 0.0026 - accuracy: 0.99 - ETA: 0s - loss: 0.0026 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.9892 - val_accuracy: 0.8109\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:50 - loss: 0.0052 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0033 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0029 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:36 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:35 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:34 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:33 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:32 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:31 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:30 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:30 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:29 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:28 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:27 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:27 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:26 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:25 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:24 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:24 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:23 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:23 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:22 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:22 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:21 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:20 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:20 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:19 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:18 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:18 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:17 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:16 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:15 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:15 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:14 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:13 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:12 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:11 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:11 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:10 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:09 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0027 - accuracy: 0.99 - ETA: 59s - loss: 0.0027 - accuracy: 0.9997 - ETA: 58s - loss: 0.0026 - accuracy: 0.999 - ETA: 57s - loss: 0.0026 - accuracy: 0.999 - ETA: 57s - loss: 0.0026 - accuracy: 0.999 - ETA: 56s - loss: 0.0026 - accuracy: 0.999 - ETA: 55s - loss: 0.0026 - accuracy: 0.999 - ETA: 55s - loss: 0.0026 - accuracy: 0.999 - ETA: 54s - loss: 0.0026 - accuracy: 0.999 - ETA: 53s - loss: 0.0026 - accuracy: 0.999 - ETA: 52s - loss: 0.0025 - accuracy: 0.999 - ETA: 52s - loss: 0.0025 - accuracy: 0.999 - ETA: 51s - loss: 0.0025 - accuracy: 0.999 - ETA: 50s - loss: 0.0026 - accuracy: 0.999 - ETA: 49s - loss: 0.0026 - accuracy: 0.999 - ETA: 49s - loss: 0.0026 - accuracy: 0.999 - ETA: 48s - loss: 0.0026 - accuracy: 0.999 - ETA: 47s - loss: 0.0025 - accuracy: 0.999 - ETA: 47s - loss: 0.0025 - accuracy: 0.999 - ETA: 46s - loss: 0.0025 - accuracy: 0.999 - ETA: 45s - loss: 0.0025 - accuracy: 0.999 - ETA: 44s - loss: 0.0025 - accuracy: 0.999 - ETA: 43s - loss: 0.0026 - accuracy: 0.999 - ETA: 43s - loss: 0.0026 - accuracy: 0.999 - ETA: 42s - loss: 0.0026 - accuracy: 0.999 - ETA: 41s - loss: 0.0026 - accuracy: 0.999 - ETA: 41s - loss: 0.0025 - accuracy: 0.999 - ETA: 40s - loss: 0.0025 - accuracy: 0.999 - ETA: 39s - loss: 0.0025 - accuracy: 0.999 - ETA: 38s - loss: 0.0025 - accuracy: 0.999 - ETA: 38s - loss: 0.0025 - accuracy: 0.999 - ETA: 37s - loss: 0.0025 - accuracy: 0.999 - ETA: 36s - loss: 0.0025 - accuracy: 0.999 - ETA: 35s - loss: 0.0025 - accuracy: 0.999 - ETA: 35s - loss: 0.0025 - accuracy: 0.999 - ETA: 34s - loss: 0.0025 - accuracy: 0.999 - ETA: 33s - loss: 0.0025 - accuracy: 0.999 - ETA: 32s - loss: 0.0025 - accuracy: 0.999 - ETA: 32s - loss: 0.0025 - accuracy: 0.999 - ETA: 31s - loss: 0.0024 - accuracy: 0.999 - ETA: 30s - loss: 0.0024 - accuracy: 0.999 - ETA: 29s - loss: 0.0024 - accuracy: 0.999 - ETA: 29s - loss: 0.0024 - accuracy: 0.999 - ETA: 28s - loss: 0.0025 - accuracy: 0.999 - ETA: 27s - loss: 0.0025 - accuracy: 0.999 - ETA: 27s - loss: 0.0025 - accuracy: 0.999 - ETA: 26s - loss: 0.0025 - accuracy: 0.999 - ETA: 25s - loss: 0.0025 - accuracy: 0.999 - ETA: 24s - loss: 0.0025 - accuracy: 0.999 - ETA: 24s - loss: 0.0025 - accuracy: 0.999 - ETA: 23s - loss: 0.0024 - accuracy: 0.999 - ETA: 22s - loss: 0.0026 - accuracy: 0.999 - ETA: 21s - loss: 0.0026 - accuracy: 0.999 - ETA: 21s - loss: 0.0026 - accuracy: 0.999 - ETA: 20s - loss: 0.0026 - accuracy: 0.999 - ETA: 19s - loss: 0.0026 - accuracy: 0.999 - ETA: 18s - loss: 0.0026 - accuracy: 0.999 - ETA: 18s - loss: 0.0026 - accuracy: 0.999 - ETA: 17s - loss: 0.0026 - accuracy: 0.999 - ETA: 16s - loss: 0.0026 - accuracy: 0.999 - ETA: 16s - loss: 0.0026 - accuracy: 0.999 - ETA: 15s - loss: 0.0026 - accuracy: 0.999 - ETA: 14s - loss: 0.0025 - accuracy: 0.999 - ETA: 13s - loss: 0.0025 - accuracy: 0.999 - ETA: 13s - loss: 0.0026 - accuracy: 0.999 - ETA: 12s - loss: 0.0026 - accuracy: 0.999 - ETA: 11s - loss: 0.0025 - accuracy: 0.999 - ETA: 10s - loss: 0.0026 - accuracy: 0.999 - ETA: 10s - loss: 0.0026 - accuracy: 0.999 - ETA: 9s - loss: 0.0026 - accuracy: 0.999 - ETA: 8s - loss: 0.0026 - accuracy: 0.99 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 6s - loss: 0.0025 - accuracy: 0.99 - ETA: 5s - loss: 0.0025 - accuracy: 0.99 - ETA: 5s - loss: 0.0025 - accuracy: 0.99 - ETA: 4s - loss: 0.0025 - accuracy: 0.99 - ETA: 3s - loss: 0.0027 - accuracy: 0.99 - ETA: 2s - loss: 0.0027 - accuracy: 0.99 - ETA: 2s - loss: 0.0026 - accuracy: 0.99 - ETA: 1s - loss: 0.0026 - accuracy: 0.99 - ETA: 0s - loss: 0.0026 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.9995 - val_accuracy: 0.8091\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:56 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0058 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0047 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0038 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0024 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0028 - accuracy: 0.99 - ETA: 59s - loss: 0.0028 - accuracy: 0.9996 - ETA: 58s - loss: 0.0028 - accuracy: 0.999 - ETA: 57s - loss: 0.0028 - accuracy: 0.999 - ETA: 57s - loss: 0.0028 - accuracy: 0.999 - ETA: 56s - loss: 0.0028 - accuracy: 0.999 - ETA: 55s - loss: 0.0028 - accuracy: 0.999 - ETA: 55s - loss: 0.0027 - accuracy: 0.999 - ETA: 54s - loss: 0.0027 - accuracy: 0.999 - ETA: 53s - loss: 0.0027 - accuracy: 0.999 - ETA: 52s - loss: 0.0027 - accuracy: 0.999 - ETA: 52s - loss: 0.0027 - accuracy: 0.999 - ETA: 51s - loss: 0.0027 - accuracy: 0.999 - ETA: 50s - loss: 0.0027 - accuracy: 0.999 - ETA: 49s - loss: 0.0027 - accuracy: 0.999 - ETA: 49s - loss: 0.0027 - accuracy: 0.999 - ETA: 48s - loss: 0.0027 - accuracy: 0.999 - ETA: 47s - loss: 0.0027 - accuracy: 0.999 - ETA: 46s - loss: 0.0027 - accuracy: 0.999 - ETA: 45s - loss: 0.0026 - accuracy: 0.999 - ETA: 45s - loss: 0.0026 - accuracy: 0.999 - ETA: 44s - loss: 0.0027 - accuracy: 0.999 - ETA: 43s - loss: 0.0026 - accuracy: 0.999 - ETA: 43s - loss: 0.0026 - accuracy: 0.999 - ETA: 42s - loss: 0.0026 - accuracy: 0.999 - ETA: 41s - loss: 0.0026 - accuracy: 0.999 - ETA: 40s - loss: 0.0026 - accuracy: 0.999 - ETA: 40s - loss: 0.0026 - accuracy: 0.999 - ETA: 39s - loss: 0.0026 - accuracy: 0.999 - ETA: 38s - loss: 0.0026 - accuracy: 0.999 - ETA: 37s - loss: 0.0025 - accuracy: 0.999 - ETA: 37s - loss: 0.0025 - accuracy: 0.999 - ETA: 36s - loss: 0.0026 - accuracy: 0.999 - ETA: 35s - loss: 0.0026 - accuracy: 0.999 - ETA: 34s - loss: 0.0026 - accuracy: 0.999 - ETA: 34s - loss: 0.0026 - accuracy: 0.999 - ETA: 33s - loss: 0.0026 - accuracy: 0.999 - ETA: 32s - loss: 0.0026 - accuracy: 0.999 - ETA: 32s - loss: 0.0025 - accuracy: 0.999 - ETA: 31s - loss: 0.0025 - accuracy: 0.999 - ETA: 30s - loss: 0.0025 - accuracy: 0.999 - ETA: 29s - loss: 0.0025 - accuracy: 0.999 - ETA: 29s - loss: 0.0025 - accuracy: 0.999 - ETA: 28s - loss: 0.0025 - accuracy: 0.999 - ETA: 27s - loss: 0.0025 - accuracy: 0.999 - ETA: 26s - loss: 0.0026 - accuracy: 0.999 - ETA: 26s - loss: 0.0026 - accuracy: 0.999 - ETA: 25s - loss: 0.0026 - accuracy: 0.999 - ETA: 24s - loss: 0.0026 - accuracy: 0.999 - ETA: 24s - loss: 0.0026 - accuracy: 0.999 - ETA: 23s - loss: 0.0026 - accuracy: 0.999 - ETA: 22s - loss: 0.0026 - accuracy: 0.999 - ETA: 21s - loss: 0.0026 - accuracy: 0.999 - ETA: 21s - loss: 0.0026 - accuracy: 0.999 - ETA: 20s - loss: 0.0026 - accuracy: 0.999 - ETA: 19s - loss: 0.0026 - accuracy: 0.999 - ETA: 18s - loss: 0.0028 - accuracy: 0.999 - ETA: 18s - loss: 0.0028 - accuracy: 0.999 - ETA: 17s - loss: 0.0028 - accuracy: 0.999 - ETA: 16s - loss: 0.0028 - accuracy: 0.999 - ETA: 15s - loss: 0.0028 - accuracy: 0.999 - ETA: 15s - loss: 0.0028 - accuracy: 0.999 - ETA: 14s - loss: 0.0028 - accuracy: 0.999 - ETA: 13s - loss: 0.0028 - accuracy: 0.999 - ETA: 13s - loss: 0.0027 - accuracy: 0.999 - ETA: 12s - loss: 0.0027 - accuracy: 0.999 - ETA: 11s - loss: 0.0027 - accuracy: 0.999 - ETA: 10s - loss: 0.0027 - accuracy: 0.999 - ETA: 10s - loss: 0.0027 - accuracy: 0.999 - ETA: 9s - loss: 0.0027 - accuracy: 0.999 - ETA: 8s - loss: 0.0027 - accuracy: 0.99 - ETA: 7s - loss: 0.0027 - accuracy: 0.99 - ETA: 7s - loss: 0.0027 - accuracy: 0.99 - ETA: 6s - loss: 0.0027 - accuracy: 0.99 - ETA: 5s - loss: 0.0027 - accuracy: 0.99 - ETA: 5s - loss: 0.0026 - accuracy: 0.99 - ETA: 4s - loss: 0.0026 - accuracy: 0.99 - ETA: 3s - loss: 0.0026 - accuracy: 0.99 - ETA: 2s - loss: 0.0026 - accuracy: 0.99 - ETA: 2s - loss: 0.0026 - accuracy: 0.99 - ETA: 1s - loss: 0.0026 - accuracy: 0.99 - ETA: 0s - loss: 0.0026 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 1.0022 - val_accuracy: 0.8082\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:55 - loss: 0.0014 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0012 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0015 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0015 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0012 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0012 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0013 - accuracy: 1.00 - ETA: 1:37 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0020 - accuracy: 0.99 - ETA: 59s - loss: 0.0020 - accuracy: 0.9997 - ETA: 59s - loss: 0.0020 - accuracy: 0.999 - ETA: 58s - loss: 0.0020 - accuracy: 0.999 - ETA: 57s - loss: 0.0020 - accuracy: 0.999 - ETA: 56s - loss: 0.0022 - accuracy: 0.999 - ETA: 55s - loss: 0.0025 - accuracy: 0.999 - ETA: 55s - loss: 0.0025 - accuracy: 0.999 - ETA: 54s - loss: 0.0024 - accuracy: 0.999 - ETA: 53s - loss: 0.0024 - accuracy: 0.999 - ETA: 52s - loss: 0.0025 - accuracy: 0.999 - ETA: 52s - loss: 0.0025 - accuracy: 0.999 - ETA: 51s - loss: 0.0025 - accuracy: 0.999 - ETA: 50s - loss: 0.0025 - accuracy: 0.999 - ETA: 49s - loss: 0.0025 - accuracy: 0.999 - ETA: 49s - loss: 0.0024 - accuracy: 0.999 - ETA: 48s - loss: 0.0025 - accuracy: 0.999 - ETA: 47s - loss: 0.0024 - accuracy: 0.999 - ETA: 46s - loss: 0.0024 - accuracy: 0.999 - ETA: 46s - loss: 0.0024 - accuracy: 0.999 - ETA: 45s - loss: 0.0024 - accuracy: 0.999 - ETA: 44s - loss: 0.0024 - accuracy: 0.999 - ETA: 43s - loss: 0.0024 - accuracy: 0.999 - ETA: 42s - loss: 0.0024 - accuracy: 0.999 - ETA: 42s - loss: 0.0024 - accuracy: 0.999 - ETA: 41s - loss: 0.0023 - accuracy: 0.999 - ETA: 40s - loss: 0.0023 - accuracy: 0.999 - ETA: 39s - loss: 0.0023 - accuracy: 0.999 - ETA: 39s - loss: 0.0023 - accuracy: 0.999 - ETA: 38s - loss: 0.0023 - accuracy: 0.999 - ETA: 37s - loss: 0.0023 - accuracy: 0.999 - ETA: 36s - loss: 0.0023 - accuracy: 0.999 - ETA: 36s - loss: 0.0024 - accuracy: 0.999 - ETA: 35s - loss: 0.0023 - accuracy: 0.999 - ETA: 34s - loss: 0.0023 - accuracy: 0.999 - ETA: 34s - loss: 0.0023 - accuracy: 0.999 - ETA: 33s - loss: 0.0023 - accuracy: 0.999 - ETA: 32s - loss: 0.0025 - accuracy: 0.999 - ETA: 31s - loss: 0.0025 - accuracy: 0.999 - ETA: 31s - loss: 0.0025 - accuracy: 0.999 - ETA: 30s - loss: 0.0026 - accuracy: 0.999 - ETA: 29s - loss: 0.0025 - accuracy: 0.999 - ETA: 28s - loss: 0.0025 - accuracy: 0.999 - ETA: 28s - loss: 0.0025 - accuracy: 0.999 - ETA: 27s - loss: 0.0025 - accuracy: 0.999 - ETA: 26s - loss: 0.0025 - accuracy: 0.999 - ETA: 25s - loss: 0.0025 - accuracy: 0.999 - ETA: 25s - loss: 0.0025 - accuracy: 0.999 - ETA: 24s - loss: 0.0025 - accuracy: 0.999 - ETA: 23s - loss: 0.0025 - accuracy: 0.999 - ETA: 22s - loss: 0.0025 - accuracy: 0.999 - ETA: 22s - loss: 0.0025 - accuracy: 0.999 - ETA: 21s - loss: 0.0025 - accuracy: 0.999 - ETA: 20s - loss: 0.0025 - accuracy: 0.999 - ETA: 19s - loss: 0.0025 - accuracy: 0.999 - ETA: 19s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 17s - loss: 0.0025 - accuracy: 0.999 - ETA: 16s - loss: 0.0024 - accuracy: 0.999 - ETA: 16s - loss: 0.0024 - accuracy: 0.999 - ETA: 15s - loss: 0.0024 - accuracy: 0.999 - ETA: 14s - loss: 0.0024 - accuracy: 0.999 - ETA: 13s - loss: 0.0024 - accuracy: 0.999 - ETA: 13s - loss: 0.0024 - accuracy: 0.999 - ETA: 12s - loss: 0.0024 - accuracy: 0.999 - ETA: 11s - loss: 0.0024 - accuracy: 0.999 - ETA: 10s - loss: 0.0024 - accuracy: 0.999 - ETA: 10s - loss: 0.0024 - accuracy: 0.999 - ETA: 9s - loss: 0.0024 - accuracy: 0.999 - ETA: 8s - loss: 0.0023 - accuracy: 0.99 - ETA: 8s - loss: 0.0023 - accuracy: 0.99 - ETA: 7s - loss: 0.0023 - accuracy: 0.99 - ETA: 6s - loss: 0.0023 - accuracy: 0.99 - ETA: 5s - loss: 0.0024 - accuracy: 0.99 - ETA: 5s - loss: 0.0024 - accuracy: 0.99 - ETA: 4s - loss: 0.0024 - accuracy: 0.99 - ETA: 3s - loss: 0.0024 - accuracy: 0.99 - ETA: 2s - loss: 0.0024 - accuracy: 0.99 - ETA: 2s - loss: 0.0024 - accuracy: 0.99 - ETA: 1s - loss: 0.0024 - accuracy: 0.99 - ETA: 0s - loss: 0.0024 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.0007 - val_accuracy: 0.8120\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:02 - loss: 0.0150 - accuracy: 1.00 - ETA: 1:57 - loss: 0.0084 - accuracy: 1.00 - ETA: 1:55 - loss: 0.0058 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0047 - accuracy: 1.00 - ETA: 1:52 - loss: 0.0039 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0034 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0027 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0026 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0025 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0023 - accuracy: 0.99 - ETA: 59s - loss: 0.0023 - accuracy: 0.9997 - ETA: 58s - loss: 0.0023 - accuracy: 0.999 - ETA: 57s - loss: 0.0023 - accuracy: 0.999 - ETA: 57s - loss: 0.0023 - accuracy: 0.999 - ETA: 56s - loss: 0.0022 - accuracy: 0.999 - ETA: 55s - loss: 0.0025 - accuracy: 0.999 - ETA: 54s - loss: 0.0025 - accuracy: 0.999 - ETA: 54s - loss: 0.0025 - accuracy: 0.999 - ETA: 53s - loss: 0.0025 - accuracy: 0.999 - ETA: 52s - loss: 0.0024 - accuracy: 0.999 - ETA: 52s - loss: 0.0025 - accuracy: 0.999 - ETA: 51s - loss: 0.0025 - accuracy: 0.999 - ETA: 50s - loss: 0.0024 - accuracy: 0.999 - ETA: 49s - loss: 0.0024 - accuracy: 0.999 - ETA: 49s - loss: 0.0024 - accuracy: 0.999 - ETA: 48s - loss: 0.0024 - accuracy: 0.999 - ETA: 47s - loss: 0.0027 - accuracy: 0.999 - ETA: 46s - loss: 0.0027 - accuracy: 0.999 - ETA: 46s - loss: 0.0026 - accuracy: 0.999 - ETA: 45s - loss: 0.0026 - accuracy: 0.999 - ETA: 44s - loss: 0.0026 - accuracy: 0.999 - ETA: 43s - loss: 0.0026 - accuracy: 0.999 - ETA: 43s - loss: 0.0026 - accuracy: 0.999 - ETA: 42s - loss: 0.0026 - accuracy: 0.999 - ETA: 41s - loss: 0.0026 - accuracy: 0.999 - ETA: 40s - loss: 0.0026 - accuracy: 0.999 - ETA: 40s - loss: 0.0026 - accuracy: 0.999 - ETA: 39s - loss: 0.0026 - accuracy: 0.999 - ETA: 38s - loss: 0.0026 - accuracy: 0.999 - ETA: 37s - loss: 0.0026 - accuracy: 0.999 - ETA: 37s - loss: 0.0026 - accuracy: 0.999 - ETA: 36s - loss: 0.0026 - accuracy: 0.999 - ETA: 35s - loss: 0.0026 - accuracy: 0.999 - ETA: 35s - loss: 0.0027 - accuracy: 0.999 - ETA: 34s - loss: 0.0027 - accuracy: 0.999 - ETA: 33s - loss: 0.0026 - accuracy: 0.999 - ETA: 32s - loss: 0.0027 - accuracy: 0.999 - ETA: 32s - loss: 0.0027 - accuracy: 0.999 - ETA: 31s - loss: 0.0027 - accuracy: 0.999 - ETA: 30s - loss: 0.0027 - accuracy: 0.999 - ETA: 29s - loss: 0.0027 - accuracy: 0.999 - ETA: 29s - loss: 0.0027 - accuracy: 0.999 - ETA: 28s - loss: 0.0027 - accuracy: 0.999 - ETA: 27s - loss: 0.0026 - accuracy: 0.999 - ETA: 27s - loss: 0.0026 - accuracy: 0.999 - ETA: 26s - loss: 0.0026 - accuracy: 0.999 - ETA: 25s - loss: 0.0026 - accuracy: 0.999 - ETA: 24s - loss: 0.0026 - accuracy: 0.999 - ETA: 24s - loss: 0.0028 - accuracy: 0.999 - ETA: 23s - loss: 0.0028 - accuracy: 0.999 - ETA: 22s - loss: 0.0028 - accuracy: 0.999 - ETA: 21s - loss: 0.0028 - accuracy: 0.999 - ETA: 21s - loss: 0.0028 - accuracy: 0.999 - ETA: 20s - loss: 0.0028 - accuracy: 0.999 - ETA: 19s - loss: 0.0028 - accuracy: 0.999 - ETA: 18s - loss: 0.0027 - accuracy: 0.999 - ETA: 18s - loss: 0.0027 - accuracy: 0.999 - ETA: 17s - loss: 0.0027 - accuracy: 0.999 - ETA: 16s - loss: 0.0027 - accuracy: 0.999 - ETA: 16s - loss: 0.0027 - accuracy: 0.999 - ETA: 15s - loss: 0.0027 - accuracy: 0.999 - ETA: 14s - loss: 0.0027 - accuracy: 0.999 - ETA: 13s - loss: 0.0027 - accuracy: 0.999 - ETA: 13s - loss: 0.0027 - accuracy: 0.999 - ETA: 12s - loss: 0.0027 - accuracy: 0.999 - ETA: 11s - loss: 0.0027 - accuracy: 0.999 - ETA: 10s - loss: 0.0027 - accuracy: 0.999 - ETA: 10s - loss: 0.0027 - accuracy: 0.999 - ETA: 9s - loss: 0.0026 - accuracy: 0.999 - ETA: 8s - loss: 0.0026 - accuracy: 0.99 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 6s - loss: 0.0026 - accuracy: 0.99 - ETA: 5s - loss: 0.0026 - accuracy: 0.99 - ETA: 5s - loss: 0.0026 - accuracy: 0.99 - ETA: 4s - loss: 0.0027 - accuracy: 0.99 - ETA: 3s - loss: 0.0027 - accuracy: 0.99 - ETA: 2s - loss: 0.0027 - accuracy: 0.99 - ETA: 2s - loss: 0.0027 - accuracy: 0.99 - ETA: 1s - loss: 0.0027 - accuracy: 0.99 - ETA: 0s - loss: 0.0027 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.9887 - val_accuracy: 0.8091\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:52 - loss: 0.0037 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:50 - loss: 0.0021 - accuracy: 1.00 - ETA: 1:49 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0016 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0016 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0015 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0014 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0016 - accuracy: 1.00 - ETA: 1:41 - loss: 0.0016 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0016 - accuracy: 1.00 - ETA: 1:40 - loss: 0.0016 - accuracy: 1.00 - ETA: 1:39 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:38 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0028 - accuracy: 0.99 - ETA: 59s - loss: 0.0028 - accuracy: 0.9997 - ETA: 59s - loss: 0.0028 - accuracy: 0.999 - ETA: 58s - loss: 0.0028 - accuracy: 0.999 - ETA: 57s - loss: 0.0028 - accuracy: 0.999 - ETA: 56s - loss: 0.0028 - accuracy: 0.999 - ETA: 56s - loss: 0.0027 - accuracy: 0.999 - ETA: 55s - loss: 0.0029 - accuracy: 0.999 - ETA: 54s - loss: 0.0029 - accuracy: 0.999 - ETA: 54s - loss: 0.0028 - accuracy: 0.999 - ETA: 53s - loss: 0.0029 - accuracy: 0.999 - ETA: 52s - loss: 0.0029 - accuracy: 0.999 - ETA: 51s - loss: 0.0029 - accuracy: 0.999 - ETA: 51s - loss: 0.0028 - accuracy: 0.999 - ETA: 50s - loss: 0.0028 - accuracy: 0.999 - ETA: 49s - loss: 0.0028 - accuracy: 0.999 - ETA: 48s - loss: 0.0028 - accuracy: 0.999 - ETA: 48s - loss: 0.0028 - accuracy: 0.999 - ETA: 47s - loss: 0.0029 - accuracy: 0.999 - ETA: 46s - loss: 0.0029 - accuracy: 0.999 - ETA: 45s - loss: 0.0028 - accuracy: 0.999 - ETA: 45s - loss: 0.0028 - accuracy: 0.999 - ETA: 44s - loss: 0.0028 - accuracy: 0.999 - ETA: 43s - loss: 0.0028 - accuracy: 0.999 - ETA: 43s - loss: 0.0028 - accuracy: 0.999 - ETA: 42s - loss: 0.0028 - accuracy: 0.999 - ETA: 41s - loss: 0.0028 - accuracy: 0.999 - ETA: 40s - loss: 0.0027 - accuracy: 0.999 - ETA: 40s - loss: 0.0027 - accuracy: 0.999 - ETA: 39s - loss: 0.0027 - accuracy: 0.999 - ETA: 38s - loss: 0.0027 - accuracy: 0.999 - ETA: 38s - loss: 0.0027 - accuracy: 0.999 - ETA: 37s - loss: 0.0027 - accuracy: 0.999 - ETA: 36s - loss: 0.0027 - accuracy: 0.999 - ETA: 35s - loss: 0.0026 - accuracy: 0.999 - ETA: 35s - loss: 0.0026 - accuracy: 0.999 - ETA: 34s - loss: 0.0026 - accuracy: 0.999 - ETA: 33s - loss: 0.0026 - accuracy: 0.999 - ETA: 32s - loss: 0.0026 - accuracy: 0.999 - ETA: 32s - loss: 0.0026 - accuracy: 0.999 - ETA: 31s - loss: 0.0026 - accuracy: 0.999 - ETA: 30s - loss: 0.0025 - accuracy: 0.999 - ETA: 29s - loss: 0.0025 - accuracy: 0.999 - ETA: 29s - loss: 0.0025 - accuracy: 0.999 - ETA: 28s - loss: 0.0026 - accuracy: 0.999 - ETA: 27s - loss: 0.0025 - accuracy: 0.999 - ETA: 26s - loss: 0.0026 - accuracy: 0.999 - ETA: 26s - loss: 0.0025 - accuracy: 0.999 - ETA: 25s - loss: 0.0025 - accuracy: 0.999 - ETA: 24s - loss: 0.0025 - accuracy: 0.999 - ETA: 24s - loss: 0.0025 - accuracy: 0.999 - ETA: 23s - loss: 0.0025 - accuracy: 0.999 - ETA: 22s - loss: 0.0025 - accuracy: 0.999 - ETA: 21s - loss: 0.0025 - accuracy: 0.999 - ETA: 21s - loss: 0.0025 - accuracy: 0.999 - ETA: 20s - loss: 0.0025 - accuracy: 0.999 - ETA: 19s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 17s - loss: 0.0025 - accuracy: 0.999 - ETA: 16s - loss: 0.0025 - accuracy: 0.999 - ETA: 15s - loss: 0.0024 - accuracy: 0.999 - ETA: 15s - loss: 0.0024 - accuracy: 0.999 - ETA: 14s - loss: 0.0025 - accuracy: 0.999 - ETA: 13s - loss: 0.0025 - accuracy: 0.999 - ETA: 13s - loss: 0.0025 - accuracy: 0.999 - ETA: 12s - loss: 0.0027 - accuracy: 0.999 - ETA: 11s - loss: 0.0026 - accuracy: 0.999 - ETA: 10s - loss: 0.0026 - accuracy: 0.999 - ETA: 10s - loss: 0.0026 - accuracy: 0.999 - ETA: 9s - loss: 0.0026 - accuracy: 0.999 - ETA: 8s - loss: 0.0026 - accuracy: 0.99 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 6s - loss: 0.0026 - accuracy: 0.99 - ETA: 5s - loss: 0.0026 - accuracy: 0.99 - ETA: 5s - loss: 0.0026 - accuracy: 0.99 - ETA: 4s - loss: 0.0026 - accuracy: 0.99 - ETA: 3s - loss: 0.0026 - accuracy: 0.99 - ETA: 2s - loss: 0.0026 - accuracy: 0.99 - ETA: 2s - loss: 0.0026 - accuracy: 0.99 - ETA: 1s - loss: 0.0026 - accuracy: 0.99 - ETA: 0s - loss: 0.0025 - accuracy: 0.99 - 122s 6ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.9872 - val_accuracy: 0.8093\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:53 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0030 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0017 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0020 - accuracy: 0.99 - ETA: 59s - loss: 0.0019 - accuracy: 0.9998 - ETA: 58s - loss: 0.0019 - accuracy: 0.999 - ETA: 58s - loss: 0.0019 - accuracy: 0.999 - ETA: 57s - loss: 0.0019 - accuracy: 0.999 - ETA: 56s - loss: 0.0019 - accuracy: 0.999 - ETA: 55s - loss: 0.0019 - accuracy: 0.999 - ETA: 55s - loss: 0.0019 - accuracy: 0.999 - ETA: 54s - loss: 0.0019 - accuracy: 0.999 - ETA: 53s - loss: 0.0019 - accuracy: 0.999 - ETA: 52s - loss: 0.0019 - accuracy: 0.999 - ETA: 52s - loss: 0.0019 - accuracy: 0.999 - ETA: 51s - loss: 0.0019 - accuracy: 0.999 - ETA: 50s - loss: 0.0020 - accuracy: 0.999 - ETA: 50s - loss: 0.0020 - accuracy: 0.999 - ETA: 49s - loss: 0.0019 - accuracy: 0.999 - ETA: 48s - loss: 0.0019 - accuracy: 0.999 - ETA: 47s - loss: 0.0019 - accuracy: 0.999 - ETA: 47s - loss: 0.0020 - accuracy: 0.999 - ETA: 46s - loss: 0.0020 - accuracy: 0.999 - ETA: 45s - loss: 0.0020 - accuracy: 0.999 - ETA: 45s - loss: 0.0020 - accuracy: 0.999 - ETA: 44s - loss: 0.0020 - accuracy: 0.999 - ETA: 43s - loss: 0.0019 - accuracy: 0.999 - ETA: 42s - loss: 0.0019 - accuracy: 0.999 - ETA: 42s - loss: 0.0020 - accuracy: 0.999 - ETA: 41s - loss: 0.0019 - accuracy: 0.999 - ETA: 40s - loss: 0.0020 - accuracy: 0.999 - ETA: 39s - loss: 0.0019 - accuracy: 0.999 - ETA: 39s - loss: 0.0019 - accuracy: 0.999 - ETA: 38s - loss: 0.0019 - accuracy: 0.999 - ETA: 37s - loss: 0.0020 - accuracy: 0.999 - ETA: 36s - loss: 0.0019 - accuracy: 0.999 - ETA: 36s - loss: 0.0020 - accuracy: 0.999 - ETA: 35s - loss: 0.0020 - accuracy: 0.999 - ETA: 34s - loss: 0.0020 - accuracy: 0.999 - ETA: 34s - loss: 0.0021 - accuracy: 0.999 - ETA: 33s - loss: 0.0020 - accuracy: 0.999 - ETA: 32s - loss: 0.0020 - accuracy: 0.999 - ETA: 31s - loss: 0.0020 - accuracy: 0.999 - ETA: 31s - loss: 0.0020 - accuracy: 0.999 - ETA: 30s - loss: 0.0020 - accuracy: 0.999 - ETA: 29s - loss: 0.0020 - accuracy: 0.999 - ETA: 29s - loss: 0.0020 - accuracy: 0.999 - ETA: 28s - loss: 0.0020 - accuracy: 0.999 - ETA: 27s - loss: 0.0020 - accuracy: 0.999 - ETA: 26s - loss: 0.0020 - accuracy: 0.999 - ETA: 26s - loss: 0.0020 - accuracy: 0.999 - ETA: 25s - loss: 0.0020 - accuracy: 0.999 - ETA: 24s - loss: 0.0020 - accuracy: 0.999 - ETA: 23s - loss: 0.0020 - accuracy: 0.999 - ETA: 23s - loss: 0.0020 - accuracy: 0.999 - ETA: 22s - loss: 0.0020 - accuracy: 0.999 - ETA: 21s - loss: 0.0020 - accuracy: 0.999 - ETA: 20s - loss: 0.0019 - accuracy: 0.999 - ETA: 20s - loss: 0.0019 - accuracy: 0.999 - ETA: 19s - loss: 0.0019 - accuracy: 0.999 - ETA: 18s - loss: 0.0019 - accuracy: 0.999 - ETA: 18s - loss: 0.0019 - accuracy: 0.999 - ETA: 17s - loss: 0.0020 - accuracy: 0.999 - ETA: 16s - loss: 0.0021 - accuracy: 0.999 - ETA: 15s - loss: 0.0023 - accuracy: 0.999 - ETA: 15s - loss: 0.0023 - accuracy: 0.999 - ETA: 14s - loss: 0.0023 - accuracy: 0.999 - ETA: 13s - loss: 0.0026 - accuracy: 0.999 - ETA: 13s - loss: 0.0025 - accuracy: 0.999 - ETA: 12s - loss: 0.0025 - accuracy: 0.999 - ETA: 11s - loss: 0.0026 - accuracy: 0.999 - ETA: 10s - loss: 0.0025 - accuracy: 0.999 - ETA: 10s - loss: 0.0026 - accuracy: 0.999 - ETA: 9s - loss: 0.0025 - accuracy: 0.999 - ETA: 8s - loss: 0.0025 - accuracy: 0.99 - ETA: 7s - loss: 0.0028 - accuracy: 0.99 - ETA: 7s - loss: 0.0027 - accuracy: 0.99 - ETA: 6s - loss: 0.0028 - accuracy: 0.99 - ETA: 5s - loss: 0.0028 - accuracy: 0.99 - ETA: 5s - loss: 0.0028 - accuracy: 0.99 - ETA: 4s - loss: 0.0028 - accuracy: 0.99 - ETA: 3s - loss: 0.0028 - accuracy: 0.99 - ETA: 2s - loss: 0.0028 - accuracy: 0.99 - ETA: 2s - loss: 0.0028 - accuracy: 0.99 - ETA: 1s - loss: 0.0028 - accuracy: 0.99 - ETA: 0s - loss: 0.0028 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.9938 - val_accuracy: 0.8105\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:45 - loss: 0.0031 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0023 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0022 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:46 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:47 - loss: 0.0020 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:44 - loss: 0.0018 - accuracy: 1.00 - ETA: 1:43 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:42 - loss: 0.0039 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0040 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0037 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0028 - accuracy: 0.99 - ETA: 59s - loss: 0.0028 - accuracy: 0.9996 - ETA: 58s - loss: 0.0027 - accuracy: 0.999 - ETA: 57s - loss: 0.0027 - accuracy: 0.999 - ETA: 57s - loss: 0.0027 - accuracy: 0.999 - ETA: 56s - loss: 0.0027 - accuracy: 0.999 - ETA: 55s - loss: 0.0029 - accuracy: 0.999 - ETA: 54s - loss: 0.0029 - accuracy: 0.999 - ETA: 54s - loss: 0.0029 - accuracy: 0.999 - ETA: 53s - loss: 0.0028 - accuracy: 0.999 - ETA: 52s - loss: 0.0029 - accuracy: 0.999 - ETA: 51s - loss: 0.0028 - accuracy: 0.999 - ETA: 51s - loss: 0.0029 - accuracy: 0.999 - ETA: 50s - loss: 0.0029 - accuracy: 0.999 - ETA: 49s - loss: 0.0029 - accuracy: 0.999 - ETA: 49s - loss: 0.0029 - accuracy: 0.999 - ETA: 48s - loss: 0.0029 - accuracy: 0.999 - ETA: 47s - loss: 0.0029 - accuracy: 0.999 - ETA: 46s - loss: 0.0029 - accuracy: 0.999 - ETA: 46s - loss: 0.0028 - accuracy: 0.999 - ETA: 45s - loss: 0.0028 - accuracy: 0.999 - ETA: 44s - loss: 0.0028 - accuracy: 0.999 - ETA: 43s - loss: 0.0028 - accuracy: 0.999 - ETA: 43s - loss: 0.0028 - accuracy: 0.999 - ETA: 42s - loss: 0.0028 - accuracy: 0.999 - ETA: 41s - loss: 0.0028 - accuracy: 0.999 - ETA: 41s - loss: 0.0027 - accuracy: 0.999 - ETA: 40s - loss: 0.0027 - accuracy: 0.999 - ETA: 39s - loss: 0.0027 - accuracy: 0.999 - ETA: 38s - loss: 0.0027 - accuracy: 0.999 - ETA: 38s - loss: 0.0027 - accuracy: 0.999 - ETA: 37s - loss: 0.0027 - accuracy: 0.999 - ETA: 36s - loss: 0.0027 - accuracy: 0.999 - ETA: 35s - loss: 0.0027 - accuracy: 0.999 - ETA: 35s - loss: 0.0027 - accuracy: 0.999 - ETA: 34s - loss: 0.0027 - accuracy: 0.999 - ETA: 33s - loss: 0.0027 - accuracy: 0.999 - ETA: 32s - loss: 0.0027 - accuracy: 0.999 - ETA: 32s - loss: 0.0027 - accuracy: 0.999 - ETA: 31s - loss: 0.0027 - accuracy: 0.999 - ETA: 30s - loss: 0.0027 - accuracy: 0.999 - ETA: 29s - loss: 0.0027 - accuracy: 0.999 - ETA: 29s - loss: 0.0027 - accuracy: 0.999 - ETA: 28s - loss: 0.0027 - accuracy: 0.999 - ETA: 27s - loss: 0.0026 - accuracy: 0.999 - ETA: 27s - loss: 0.0026 - accuracy: 0.999 - ETA: 26s - loss: 0.0026 - accuracy: 0.999 - ETA: 25s - loss: 0.0026 - accuracy: 0.999 - ETA: 24s - loss: 0.0026 - accuracy: 0.999 - ETA: 24s - loss: 0.0026 - accuracy: 0.999 - ETA: 23s - loss: 0.0026 - accuracy: 0.999 - ETA: 22s - loss: 0.0026 - accuracy: 0.999 - ETA: 21s - loss: 0.0025 - accuracy: 0.999 - ETA: 21s - loss: 0.0025 - accuracy: 0.999 - ETA: 20s - loss: 0.0025 - accuracy: 0.999 - ETA: 19s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 17s - loss: 0.0025 - accuracy: 0.999 - ETA: 16s - loss: 0.0025 - accuracy: 0.999 - ETA: 16s - loss: 0.0024 - accuracy: 0.999 - ETA: 15s - loss: 0.0024 - accuracy: 0.999 - ETA: 14s - loss: 0.0024 - accuracy: 0.999 - ETA: 13s - loss: 0.0024 - accuracy: 0.999 - ETA: 13s - loss: 0.0024 - accuracy: 0.999 - ETA: 12s - loss: 0.0024 - accuracy: 0.999 - ETA: 11s - loss: 0.0024 - accuracy: 0.999 - ETA: 10s - loss: 0.0026 - accuracy: 0.999 - ETA: 10s - loss: 0.0026 - accuracy: 0.999 - ETA: 9s - loss: 0.0026 - accuracy: 0.999 - ETA: 8s - loss: 0.0026 - accuracy: 0.99 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 6s - loss: 0.0026 - accuracy: 0.99 - ETA: 5s - loss: 0.0026 - accuracy: 0.99 - ETA: 5s - loss: 0.0026 - accuracy: 0.99 - ETA: 4s - loss: 0.0025 - accuracy: 0.99 - ETA: 3s - loss: 0.0025 - accuracy: 0.99 - ETA: 2s - loss: 0.0025 - accuracy: 0.99 - ETA: 2s - loss: 0.0025 - accuracy: 0.99 - ETA: 1s - loss: 0.0025 - accuracy: 0.99 - ETA: 0s - loss: 0.0025 - accuracy: 0.99 - 121s 6ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.9950 - val_accuracy: 0.8087\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 1:46 - loss: 0.0011 - accuracy: 1.00 - ETA: 1:45 - loss: 0.0076 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0056 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0078 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0072 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0061 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0055 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0049 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0045 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0041 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0038 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0024 - accuracy: 0.99 - ETA: 59s - loss: 0.0024 - accuracy: 0.9994 - ETA: 58s - loss: 0.0024 - accuracy: 0.999 - ETA: 58s - loss: 0.0024 - accuracy: 0.999 - ETA: 57s - loss: 0.0024 - accuracy: 0.999 - ETA: 56s - loss: 0.0025 - accuracy: 0.999 - ETA: 55s - loss: 0.0025 - accuracy: 0.999 - ETA: 55s - loss: 0.0024 - accuracy: 0.999 - ETA: 54s - loss: 0.0024 - accuracy: 0.999 - ETA: 53s - loss: 0.0024 - accuracy: 0.999 - ETA: 52s - loss: 0.0024 - accuracy: 0.999 - ETA: 52s - loss: 0.0024 - accuracy: 0.999 - ETA: 51s - loss: 0.0025 - accuracy: 0.999 - ETA: 50s - loss: 0.0025 - accuracy: 0.999 - ETA: 49s - loss: 0.0025 - accuracy: 0.999 - ETA: 49s - loss: 0.0025 - accuracy: 0.999 - ETA: 48s - loss: 0.0025 - accuracy: 0.999 - ETA: 47s - loss: 0.0025 - accuracy: 0.999 - ETA: 46s - loss: 0.0025 - accuracy: 0.999 - ETA: 46s - loss: 0.0026 - accuracy: 0.999 - ETA: 45s - loss: 0.0025 - accuracy: 0.999 - ETA: 44s - loss: 0.0025 - accuracy: 0.999 - ETA: 44s - loss: 0.0025 - accuracy: 0.999 - ETA: 43s - loss: 0.0025 - accuracy: 0.999 - ETA: 43s - loss: 0.0025 - accuracy: 0.999 - ETA: 42s - loss: 0.0025 - accuracy: 0.999 - ETA: 42s - loss: 0.0025 - accuracy: 0.999 - ETA: 41s - loss: 0.0025 - accuracy: 0.999 - ETA: 41s - loss: 0.0025 - accuracy: 0.999 - ETA: 41s - loss: 0.0025 - accuracy: 0.999 - ETA: 40s - loss: 0.0025 - accuracy: 0.999 - ETA: 40s - loss: 0.0025 - accuracy: 0.999 - ETA: 39s - loss: 0.0025 - accuracy: 0.999 - ETA: 39s - loss: 0.0026 - accuracy: 0.999 - ETA: 38s - loss: 0.0026 - accuracy: 0.999 - ETA: 37s - loss: 0.0026 - accuracy: 0.999 - ETA: 37s - loss: 0.0026 - accuracy: 0.999 - ETA: 36s - loss: 0.0026 - accuracy: 0.999 - ETA: 36s - loss: 0.0026 - accuracy: 0.999 - ETA: 35s - loss: 0.0025 - accuracy: 0.999 - ETA: 34s - loss: 0.0025 - accuracy: 0.999 - ETA: 34s - loss: 0.0025 - accuracy: 0.999 - ETA: 33s - loss: 0.0025 - accuracy: 0.999 - ETA: 32s - loss: 0.0025 - accuracy: 0.999 - ETA: 32s - loss: 0.0025 - accuracy: 0.999 - ETA: 31s - loss: 0.0025 - accuracy: 0.999 - ETA: 30s - loss: 0.0025 - accuracy: 0.999 - ETA: 29s - loss: 0.0025 - accuracy: 0.999 - ETA: 29s - loss: 0.0025 - accuracy: 0.999 - ETA: 28s - loss: 0.0025 - accuracy: 0.999 - ETA: 27s - loss: 0.0025 - accuracy: 0.999 - ETA: 26s - loss: 0.0025 - accuracy: 0.999 - ETA: 26s - loss: 0.0025 - accuracy: 0.999 - ETA: 25s - loss: 0.0025 - accuracy: 0.999 - ETA: 24s - loss: 0.0025 - accuracy: 0.999 - ETA: 23s - loss: 0.0025 - accuracy: 0.999 - ETA: 23s - loss: 0.0026 - accuracy: 0.999 - ETA: 22s - loss: 0.0025 - accuracy: 0.999 - ETA: 21s - loss: 0.0025 - accuracy: 0.999 - ETA: 20s - loss: 0.0025 - accuracy: 0.999 - ETA: 19s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 17s - loss: 0.0025 - accuracy: 0.999 - ETA: 16s - loss: 0.0025 - accuracy: 0.999 - ETA: 15s - loss: 0.0025 - accuracy: 0.999 - ETA: 14s - loss: 0.0025 - accuracy: 0.999 - ETA: 13s - loss: 0.0025 - accuracy: 0.999 - ETA: 12s - loss: 0.0026 - accuracy: 0.999 - ETA: 11s - loss: 0.0025 - accuracy: 0.999 - ETA: 11s - loss: 0.0026 - accuracy: 0.999 - ETA: 10s - loss: 0.0026 - accuracy: 0.999 - ETA: 9s - loss: 0.0026 - accuracy: 0.999 - ETA: 8s - loss: 0.0027 - accuracy: 0.99 - ETA: 7s - loss: 0.0027 - accuracy: 0.99 - ETA: 6s - loss: 0.0027 - accuracy: 0.99 - ETA: 5s - loss: 0.0027 - accuracy: 0.99 - ETA: 4s - loss: 0.0027 - accuracy: 0.99 - ETA: 3s - loss: 0.0027 - accuracy: 0.99 - ETA: 2s - loss: 0.0026 - accuracy: 0.99 - ETA: 1s - loss: 0.0026 - accuracy: 0.99 - ETA: 0s - loss: 0.0027 - accuracy: 0.99 - 168s 9ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.9949 - val_accuracy: 0.8103\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:20 - loss: 0.0011 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0038 - accuracy: 1.00 - ETA: 3:12 - loss: 0.0027 - accuracy: 1.00 - ETA: 3:12 - loss: 0.0023 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0021 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0021 - accuracy: 1.00 - ETA: 3:03 - loss: 0.0019 - accuracy: 1.00 - ETA: 3:02 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:59 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:57 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:57 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:56 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:55 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:54 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:53 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:52 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:51 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:49 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:48 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:46 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:45 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:43 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:42 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:41 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:40 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:38 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:37 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:35 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:34 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:33 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:31 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:30 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:29 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:27 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:26 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:25 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:24 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:22 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:21 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:20 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:19 - loss: 0.0019 - accuracy: 1.00 - ETA: 2:17 - loss: 0.0019 - accuracy: 1.00 - ETA: 2:16 - loss: 0.0021 - accuracy: 1.00 - ETA: 2:15 - loss: 0.0021 - accuracy: 1.00 - ETA: 2:13 - loss: 0.0020 - accuracy: 1.00 - ETA: 2:12 - loss: 0.0020 - accuracy: 1.00 - ETA: 2:11 - loss: 0.0020 - accuracy: 1.00 - ETA: 2:10 - loss: 0.0020 - accuracy: 1.00 - ETA: 2:09 - loss: 0.0020 - accuracy: 1.00 - ETA: 2:08 - loss: 0.0019 - accuracy: 1.00 - ETA: 2:07 - loss: 0.0020 - accuracy: 1.00 - ETA: 2:06 - loss: 0.0020 - accuracy: 1.00 - ETA: 2:04 - loss: 0.0019 - accuracy: 1.00 - ETA: 2:03 - loss: 0.0019 - accuracy: 1.00 - ETA: 2:02 - loss: 0.0019 - accuracy: 1.00 - ETA: 2:00 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:59 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:58 - loss: 0.0019 - accuracy: 1.00 - ETA: 1:57 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0023 - accuracy: 0.99 - ETA: 58s - loss: 0.0023 - accuracy: 0.9997 - ETA: 57s - loss: 0.0022 - accuracy: 0.999 - ETA: 56s - loss: 0.0022 - accuracy: 0.999 - ETA: 54s - loss: 0.0022 - accuracy: 0.999 - ETA: 53s - loss: 0.0022 - accuracy: 0.999 - ETA: 52s - loss: 0.0022 - accuracy: 0.999 - ETA: 51s - loss: 0.0022 - accuracy: 0.999 - ETA: 49s - loss: 0.0022 - accuracy: 0.999 - ETA: 48s - loss: 0.0022 - accuracy: 0.999 - ETA: 47s - loss: 0.0022 - accuracy: 0.999 - ETA: 45s - loss: 0.0022 - accuracy: 0.999 - ETA: 44s - loss: 0.0022 - accuracy: 0.999 - ETA: 43s - loss: 0.0022 - accuracy: 0.999 - ETA: 42s - loss: 0.0022 - accuracy: 0.999 - ETA: 40s - loss: 0.0022 - accuracy: 0.999 - ETA: 39s - loss: 0.0022 - accuracy: 0.999 - ETA: 38s - loss: 0.0022 - accuracy: 0.999 - ETA: 37s - loss: 0.0024 - accuracy: 0.999 - ETA: 35s - loss: 0.0024 - accuracy: 0.999 - ETA: 34s - loss: 0.0024 - accuracy: 0.999 - ETA: 33s - loss: 0.0024 - accuracy: 0.999 - ETA: 31s - loss: 0.0024 - accuracy: 0.999 - ETA: 30s - loss: 0.0024 - accuracy: 0.999 - ETA: 29s - loss: 0.0024 - accuracy: 0.999 - ETA: 28s - loss: 0.0024 - accuracy: 0.999 - ETA: 26s - loss: 0.0024 - accuracy: 0.999 - ETA: 25s - loss: 0.0024 - accuracy: 0.999 - ETA: 24s - loss: 0.0024 - accuracy: 0.999 - ETA: 22s - loss: 0.0024 - accuracy: 0.999 - ETA: 21s - loss: 0.0024 - accuracy: 0.999 - ETA: 20s - loss: 0.0024 - accuracy: 0.999 - ETA: 19s - loss: 0.0024 - accuracy: 0.999 - ETA: 17s - loss: 0.0024 - accuracy: 0.999 - ETA: 16s - loss: 0.0024 - accuracy: 0.999 - ETA: 15s - loss: 0.0024 - accuracy: 0.999 - ETA: 13s - loss: 0.0024 - accuracy: 0.999 - ETA: 12s - loss: 0.0024 - accuracy: 0.999 - ETA: 11s - loss: 0.0024 - accuracy: 0.999 - ETA: 10s - loss: 0.0024 - accuracy: 0.999 - ETA: 8s - loss: 0.0024 - accuracy: 0.999 - ETA: 7s - loss: 0.0024 - accuracy: 0.99 - ETA: 6s - loss: 0.0024 - accuracy: 0.99 - ETA: 4s - loss: 0.0024 - accuracy: 0.99 - ETA: 3s - loss: 0.0024 - accuracy: 0.99 - ETA: 2s - loss: 0.0024 - accuracy: 0.99 - ETA: 1s - loss: 0.0024 - accuracy: 0.99 - 218s 11ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 1.0075 - val_accuracy: 0.8084\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:17 - loss: 0.0093 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0059 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0044 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0034 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0030 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0028 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0026 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0028 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0028 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0021 - accuracy: 0.99 - ETA: 59s - loss: 0.0021 - accuracy: 0.9998 - ETA: 58s - loss: 0.0021 - accuracy: 0.999 - ETA: 57s - loss: 0.0021 - accuracy: 0.999 - ETA: 55s - loss: 0.0021 - accuracy: 0.999 - ETA: 54s - loss: 0.0023 - accuracy: 0.999 - ETA: 53s - loss: 0.0023 - accuracy: 0.999 - ETA: 51s - loss: 0.0023 - accuracy: 0.999 - ETA: 50s - loss: 0.0024 - accuracy: 0.999 - ETA: 49s - loss: 0.0024 - accuracy: 0.999 - ETA: 47s - loss: 0.0024 - accuracy: 0.999 - ETA: 46s - loss: 0.0024 - accuracy: 0.999 - ETA: 45s - loss: 0.0024 - accuracy: 0.999 - ETA: 44s - loss: 0.0024 - accuracy: 0.999 - ETA: 42s - loss: 0.0024 - accuracy: 0.999 - ETA: 41s - loss: 0.0024 - accuracy: 0.999 - ETA: 40s - loss: 0.0024 - accuracy: 0.999 - ETA: 38s - loss: 0.0024 - accuracy: 0.999 - ETA: 37s - loss: 0.0024 - accuracy: 0.999 - ETA: 36s - loss: 0.0024 - accuracy: 0.999 - ETA: 34s - loss: 0.0024 - accuracy: 0.999 - ETA: 33s - loss: 0.0024 - accuracy: 0.999 - ETA: 32s - loss: 0.0024 - accuracy: 0.999 - ETA: 31s - loss: 0.0024 - accuracy: 0.999 - ETA: 29s - loss: 0.0024 - accuracy: 0.999 - ETA: 28s - loss: 0.0024 - accuracy: 0.999 - ETA: 27s - loss: 0.0024 - accuracy: 0.999 - ETA: 25s - loss: 0.0023 - accuracy: 0.999 - ETA: 24s - loss: 0.0023 - accuracy: 0.999 - ETA: 23s - loss: 0.0023 - accuracy: 0.999 - ETA: 21s - loss: 0.0023 - accuracy: 0.999 - ETA: 20s - loss: 0.0023 - accuracy: 0.999 - ETA: 19s - loss: 0.0023 - accuracy: 0.999 - ETA: 18s - loss: 0.0023 - accuracy: 0.999 - ETA: 16s - loss: 0.0023 - accuracy: 0.999 - ETA: 15s - loss: 0.0023 - accuracy: 0.999 - ETA: 14s - loss: 0.0023 - accuracy: 0.999 - ETA: 12s - loss: 0.0023 - accuracy: 0.999 - ETA: 11s - loss: 0.0023 - accuracy: 0.999 - ETA: 10s - loss: 0.0023 - accuracy: 0.999 - ETA: 8s - loss: 0.0023 - accuracy: 0.999 - ETA: 7s - loss: 0.0023 - accuracy: 0.99 - ETA: 6s - loss: 0.0023 - accuracy: 0.99 - ETA: 5s - loss: 0.0023 - accuracy: 0.99 - ETA: 3s - loss: 0.0023 - accuracy: 0.99 - ETA: 2s - loss: 0.0022 - accuracy: 0.99 - ETA: 1s - loss: 0.0022 - accuracy: 0.99 - 220s 11ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 1.0037 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:08 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:03 - loss: 0.0019 - accuracy: 1.00 - ETA: 3:14 - loss: 0.0015 - accuracy: 1.00 - ETA: 3:19 - loss: 0.0016 - accuracy: 1.00 - ETA: 3:15 - loss: 0.0015 - accuracy: 1.00 - ETA: 3:13 - loss: 0.0013 - accuracy: 1.00 - ETA: 3:14 - loss: 0.0016 - accuracy: 1.00 - ETA: 3:13 - loss: 0.0016 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0022 - accuracy: 1.00 - ETA: 3:09 - loss: 0.0020 - accuracy: 1.00 - ETA: 3:07 - loss: 0.0021 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0024 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0023 - accuracy: 1.00 - ETA: 3:04 - loss: 0.0021 - accuracy: 1.00 - ETA: 3:01 - loss: 0.0022 - accuracy: 1.00 - ETA: 3:00 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0039 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0038 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0037 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0036 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0035 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0034 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0034 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0034 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0034 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0033 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0033 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0033 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0033 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0033 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0025 - accuracy: 0.99 - ETA: 59s - loss: 0.0027 - accuracy: 0.9996 - ETA: 58s - loss: 0.0027 - accuracy: 0.999 - ETA: 57s - loss: 0.0026 - accuracy: 0.999 - ETA: 55s - loss: 0.0026 - accuracy: 0.999 - ETA: 54s - loss: 0.0027 - accuracy: 0.999 - ETA: 53s - loss: 0.0027 - accuracy: 0.999 - ETA: 51s - loss: 0.0026 - accuracy: 0.999 - ETA: 50s - loss: 0.0027 - accuracy: 0.999 - ETA: 49s - loss: 0.0026 - accuracy: 0.999 - ETA: 48s - loss: 0.0027 - accuracy: 0.999 - ETA: 46s - loss: 0.0026 - accuracy: 0.999 - ETA: 45s - loss: 0.0026 - accuracy: 0.999 - ETA: 43s - loss: 0.0026 - accuracy: 0.999 - ETA: 42s - loss: 0.0026 - accuracy: 0.999 - ETA: 41s - loss: 0.0026 - accuracy: 0.999 - ETA: 39s - loss: 0.0027 - accuracy: 0.999 - ETA: 38s - loss: 0.0027 - accuracy: 0.999 - ETA: 37s - loss: 0.0027 - accuracy: 0.999 - ETA: 35s - loss: 0.0027 - accuracy: 0.999 - ETA: 34s - loss: 0.0026 - accuracy: 0.999 - ETA: 33s - loss: 0.0026 - accuracy: 0.999 - ETA: 31s - loss: 0.0026 - accuracy: 0.999 - ETA: 30s - loss: 0.0026 - accuracy: 0.999 - ETA: 29s - loss: 0.0026 - accuracy: 0.999 - ETA: 27s - loss: 0.0026 - accuracy: 0.999 - ETA: 26s - loss: 0.0026 - accuracy: 0.999 - ETA: 25s - loss: 0.0026 - accuracy: 0.999 - ETA: 23s - loss: 0.0026 - accuracy: 0.999 - ETA: 22s - loss: 0.0025 - accuracy: 0.999 - ETA: 21s - loss: 0.0025 - accuracy: 0.999 - ETA: 19s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 17s - loss: 0.0025 - accuracy: 0.999 - ETA: 15s - loss: 0.0025 - accuracy: 0.999 - ETA: 14s - loss: 0.0025 - accuracy: 0.999 - ETA: 13s - loss: 0.0025 - accuracy: 0.999 - ETA: 11s - loss: 0.0025 - accuracy: 0.999 - ETA: 10s - loss: 0.0025 - accuracy: 0.999 - ETA: 9s - loss: 0.0025 - accuracy: 0.999 - ETA: 7s - loss: 0.0026 - accuracy: 0.99 - ETA: 6s - loss: 0.0026 - accuracy: 0.99 - ETA: 5s - loss: 0.0026 - accuracy: 0.99 - ETA: 3s - loss: 0.0026 - accuracy: 0.99 - ETA: 2s - loss: 0.0026 - accuracy: 0.99 - ETA: 1s - loss: 0.0026 - accuracy: 0.99 - 226s 12ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.9968 - val_accuracy: 0.8084\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:11 - loss: 0.0023 - accuracy: 1.00 - ETA: 3:07 - loss: 0.0014 - accuracy: 1.00 - ETA: 3:13 - loss: 0.0011 - accuracy: 1.00 - ETA: 3:10 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:07 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0011 - accuracy: 1.00 - ETA: 3:10 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:09 - loss: 0.0011 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:06 - loss: 0.0017 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0017 - accuracy: 1.00 - ETA: 3:03 - loss: 0.0018 - accuracy: 1.00 - ETA: 3:03 - loss: 0.0017 - accuracy: 1.00 - ETA: 3:02 - loss: 0.0017 - accuracy: 1.00 - ETA: 3:01 - loss: 0.0020 - accuracy: 1.00 - ETA: 2:59 - loss: 0.0019 - accuracy: 1.00 - ETA: 2:57 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:57 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:56 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:54 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:53 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:52 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:51 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0021 - accuracy: 0.99 - ETA: 59s - loss: 0.0023 - accuracy: 0.9995 - ETA: 57s - loss: 0.0023 - accuracy: 0.999 - ETA: 56s - loss: 0.0023 - accuracy: 0.999 - ETA: 55s - loss: 0.0023 - accuracy: 0.999 - ETA: 53s - loss: 0.0023 - accuracy: 0.999 - ETA: 52s - loss: 0.0023 - accuracy: 0.999 - ETA: 51s - loss: 0.0023 - accuracy: 0.999 - ETA: 49s - loss: 0.0023 - accuracy: 0.999 - ETA: 48s - loss: 0.0023 - accuracy: 0.999 - ETA: 47s - loss: 0.0023 - accuracy: 0.999 - ETA: 45s - loss: 0.0023 - accuracy: 0.999 - ETA: 44s - loss: 0.0022 - accuracy: 0.999 - ETA: 43s - loss: 0.0022 - accuracy: 0.999 - ETA: 41s - loss: 0.0022 - accuracy: 0.999 - ETA: 40s - loss: 0.0022 - accuracy: 0.999 - ETA: 39s - loss: 0.0022 - accuracy: 0.999 - ETA: 37s - loss: 0.0022 - accuracy: 0.999 - ETA: 36s - loss: 0.0022 - accuracy: 0.999 - ETA: 34s - loss: 0.0022 - accuracy: 0.999 - ETA: 33s - loss: 0.0022 - accuracy: 0.999 - ETA: 32s - loss: 0.0022 - accuracy: 0.999 - ETA: 30s - loss: 0.0022 - accuracy: 0.999 - ETA: 29s - loss: 0.0022 - accuracy: 0.999 - ETA: 28s - loss: 0.0022 - accuracy: 0.999 - ETA: 26s - loss: 0.0022 - accuracy: 0.999 - ETA: 25s - loss: 0.0022 - accuracy: 0.999 - ETA: 24s - loss: 0.0022 - accuracy: 0.999 - ETA: 22s - loss: 0.0022 - accuracy: 0.999 - ETA: 21s - loss: 0.0022 - accuracy: 0.999 - ETA: 20s - loss: 0.0022 - accuracy: 0.999 - ETA: 18s - loss: 0.0022 - accuracy: 0.999 - ETA: 17s - loss: 0.0023 - accuracy: 0.999 - ETA: 16s - loss: 0.0023 - accuracy: 0.999 - ETA: 14s - loss: 0.0022 - accuracy: 0.999 - ETA: 13s - loss: 0.0022 - accuracy: 0.999 - ETA: 11s - loss: 0.0022 - accuracy: 0.999 - ETA: 10s - loss: 0.0022 - accuracy: 0.999 - ETA: 9s - loss: 0.0022 - accuracy: 0.999 - ETA: 7s - loss: 0.0022 - accuracy: 0.99 - ETA: 6s - loss: 0.0022 - accuracy: 0.99 - ETA: 5s - loss: 0.0022 - accuracy: 0.99 - ETA: 3s - loss: 0.0022 - accuracy: 0.99 - ETA: 2s - loss: 0.0022 - accuracy: 0.99 - ETA: 1s - loss: 0.0022 - accuracy: 0.99 - 227s 12ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 1.0057 - val_accuracy: 0.8078\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:23 - loss: 6.8907e-04 - accuracy: 1.00 - ETA: 3:27 - loss: 5.8410e-04 - accuracy: 1.00 - ETA: 3:19 - loss: 0.0019 - accuracy: 1.0000   - ETA: 3:17 - loss: 0.0030 - accuracy: 1.00 - ETA: 3:16 - loss: 0.0027 - accuracy: 1.00 - ETA: 3:15 - loss: 0.0030 - accuracy: 1.00 - ETA: 3:14 - loss: 0.0027 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0027 - accuracy: 1.00 - ETA: 3:12 - loss: 0.0025 - accuracy: 1.00 - ETA: 3:09 - loss: 0.0023 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0022 - accuracy: 1.00 - ETA: 3:07 - loss: 0.0021 - accuracy: 1.00 - ETA: 3:06 - loss: 0.0021 - accuracy: 1.00 - ETA: 3:03 - loss: 0.0021 - accuracy: 1.00 - ETA: 3:01 - loss: 0.0020 - accuracy: 1.00 - ETA: 3:01 - loss: 0.0019 - accuracy: 1.00 - ETA: 3:00 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:59 - loss: 0.0018 - accuracy: 1.00 - ETA: 2:57 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:56 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:55 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:53 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:52 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:51 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:49 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:47 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:46 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:45 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:43 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:42 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:40 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:39 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:37 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:36 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:34 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:33 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:32 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:30 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:29 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:28 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:26 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:25 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:24 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:22 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:21 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:19 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:18 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:17 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:15 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:14 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:13 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:11 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:10 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:09 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0020 - accuracy: 0.99 - ETA: 59s - loss: 0.0020 - accuracy: 0.9999 - ETA: 57s - loss: 0.0020 - accuracy: 0.999 - ETA: 56s - loss: 0.0020 - accuracy: 0.999 - ETA: 55s - loss: 0.0019 - accuracy: 0.999 - ETA: 53s - loss: 0.0019 - accuracy: 0.999 - ETA: 52s - loss: 0.0019 - accuracy: 0.999 - ETA: 51s - loss: 0.0019 - accuracy: 0.999 - ETA: 49s - loss: 0.0019 - accuracy: 0.999 - ETA: 48s - loss: 0.0019 - accuracy: 0.999 - ETA: 47s - loss: 0.0019 - accuracy: 0.999 - ETA: 45s - loss: 0.0019 - accuracy: 0.999 - ETA: 44s - loss: 0.0019 - accuracy: 0.999 - ETA: 43s - loss: 0.0019 - accuracy: 0.999 - ETA: 41s - loss: 0.0019 - accuracy: 0.999 - ETA: 40s - loss: 0.0019 - accuracy: 0.999 - ETA: 38s - loss: 0.0020 - accuracy: 0.999 - ETA: 37s - loss: 0.0020 - accuracy: 0.999 - ETA: 36s - loss: 0.0020 - accuracy: 0.999 - ETA: 34s - loss: 0.0021 - accuracy: 0.999 - ETA: 33s - loss: 0.0021 - accuracy: 0.999 - ETA: 32s - loss: 0.0021 - accuracy: 0.999 - ETA: 30s - loss: 0.0021 - accuracy: 0.999 - ETA: 29s - loss: 0.0021 - accuracy: 0.999 - ETA: 28s - loss: 0.0021 - accuracy: 0.999 - ETA: 26s - loss: 0.0021 - accuracy: 0.999 - ETA: 25s - loss: 0.0021 - accuracy: 0.999 - ETA: 24s - loss: 0.0021 - accuracy: 0.999 - ETA: 22s - loss: 0.0021 - accuracy: 0.999 - ETA: 21s - loss: 0.0021 - accuracy: 0.999 - ETA: 20s - loss: 0.0020 - accuracy: 0.999 - ETA: 18s - loss: 0.0020 - accuracy: 0.999 - ETA: 17s - loss: 0.0020 - accuracy: 0.999 - ETA: 15s - loss: 0.0020 - accuracy: 0.999 - ETA: 14s - loss: 0.0020 - accuracy: 0.999 - ETA: 13s - loss: 0.0020 - accuracy: 0.999 - ETA: 11s - loss: 0.0020 - accuracy: 0.999 - ETA: 10s - loss: 0.0020 - accuracy: 0.999 - ETA: 9s - loss: 0.0020 - accuracy: 0.999 - ETA: 7s - loss: 0.0020 - accuracy: 0.99 - ETA: 6s - loss: 0.0020 - accuracy: 0.99 - ETA: 5s - loss: 0.0020 - accuracy: 0.99 - ETA: 3s - loss: 0.0021 - accuracy: 0.99 - ETA: 2s - loss: 0.0021 - accuracy: 0.99 - ETA: 1s - loss: 0.0021 - accuracy: 0.99 - 227s 12ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 1.0044 - val_accuracy: 0.8091\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:17 - loss: 0.0014 - accuracy: 1.00 - ETA: 3:21 - loss: 9.7924e-04 - accuracy: 1.00 - ETA: 3:19 - loss: 0.0011 - accuracy: 1.0000   - ETA: 3:19 - loss: 9.3859e-04 - accuracy: 1.00 - ETA: 3:15 - loss: 8.8759e-04 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0010 - accuracy: 1.0000   - ETA: 3:11 - loss: 0.0018 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0016 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0018 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0017 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0016 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0017 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0017 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0014 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0014 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0020 - accuracy: 0.99 - ETA: 59s - loss: 0.0020 - accuracy: 0.9998 - ETA: 57s - loss: 0.0019 - accuracy: 0.999 - ETA: 56s - loss: 0.0019 - accuracy: 0.999 - ETA: 55s - loss: 0.0019 - accuracy: 0.999 - ETA: 53s - loss: 0.0019 - accuracy: 0.999 - ETA: 52s - loss: 0.0019 - accuracy: 0.999 - ETA: 51s - loss: 0.0020 - accuracy: 0.999 - ETA: 49s - loss: 0.0020 - accuracy: 0.999 - ETA: 48s - loss: 0.0020 - accuracy: 0.999 - ETA: 46s - loss: 0.0020 - accuracy: 0.999 - ETA: 45s - loss: 0.0020 - accuracy: 0.999 - ETA: 44s - loss: 0.0021 - accuracy: 0.999 - ETA: 42s - loss: 0.0021 - accuracy: 0.999 - ETA: 41s - loss: 0.0021 - accuracy: 0.999 - ETA: 40s - loss: 0.0021 - accuracy: 0.999 - ETA: 38s - loss: 0.0021 - accuracy: 0.999 - ETA: 37s - loss: 0.0021 - accuracy: 0.999 - ETA: 36s - loss: 0.0021 - accuracy: 0.999 - ETA: 34s - loss: 0.0021 - accuracy: 0.999 - ETA: 33s - loss: 0.0021 - accuracy: 0.999 - ETA: 32s - loss: 0.0021 - accuracy: 0.999 - ETA: 30s - loss: 0.0021 - accuracy: 0.999 - ETA: 29s - loss: 0.0021 - accuracy: 0.999 - ETA: 28s - loss: 0.0022 - accuracy: 0.999 - ETA: 26s - loss: 0.0021 - accuracy: 0.999 - ETA: 25s - loss: 0.0021 - accuracy: 0.999 - ETA: 24s - loss: 0.0021 - accuracy: 0.999 - ETA: 22s - loss: 0.0021 - accuracy: 0.999 - ETA: 21s - loss: 0.0021 - accuracy: 0.999 - ETA: 20s - loss: 0.0021 - accuracy: 0.999 - ETA: 18s - loss: 0.0021 - accuracy: 0.999 - ETA: 17s - loss: 0.0021 - accuracy: 0.999 - ETA: 16s - loss: 0.0021 - accuracy: 0.999 - ETA: 14s - loss: 0.0021 - accuracy: 0.999 - ETA: 13s - loss: 0.0021 - accuracy: 0.999 - ETA: 11s - loss: 0.0021 - accuracy: 0.999 - ETA: 10s - loss: 0.0021 - accuracy: 0.999 - ETA: 9s - loss: 0.0021 - accuracy: 0.999 - ETA: 7s - loss: 0.0021 - accuracy: 0.99 - ETA: 6s - loss: 0.0021 - accuracy: 0.99 - ETA: 5s - loss: 0.0021 - accuracy: 0.99 - ETA: 3s - loss: 0.0021 - accuracy: 0.99 - ETA: 2s - loss: 0.0021 - accuracy: 0.99 - ETA: 1s - loss: 0.0020 - accuracy: 0.99 - 227s 12ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 1.0029 - val_accuracy: 0.8080\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:14 - loss: 0.0016 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0010 - accuracy: 1.00 - ETA: 3:10 - loss: 8.1170e-04 - accuracy: 1.00 - ETA: 3:10 - loss: 7.4738e-04 - accuracy: 1.00 - ETA: 3:09 - loss: 7.7485e-04 - accuracy: 1.00 - ETA: 3:09 - loss: 7.1845e-04 - accuracy: 1.00 - ETA: 3:06 - loss: 8.2201e-04 - accuracy: 1.00 - ETA: 3:04 - loss: 9.6973e-04 - accuracy: 1.00 - ETA: 3:02 - loss: 9.5669e-04 - accuracy: 1.00 - ETA: 3:01 - loss: 9.1083e-04 - accuracy: 1.00 - ETA: 3:01 - loss: 8.7640e-04 - accuracy: 1.00 - ETA: 3:01 - loss: 0.0012 - accuracy: 1.0000   - ETA: 3:00 - loss: 0.0012 - accuracy: 1.00 - ETA: 2:59 - loss: 0.0012 - accuracy: 1.00 - ETA: 2:57 - loss: 0.0012 - accuracy: 1.00 - ETA: 2:55 - loss: 0.0012 - accuracy: 1.00 - ETA: 2:54 - loss: 0.0012 - accuracy: 1.00 - ETA: 2:53 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0019 - accuracy: 0.99 - ETA: 59s - loss: 0.0019 - accuracy: 0.9998 - ETA: 57s - loss: 0.0019 - accuracy: 0.999 - ETA: 56s - loss: 0.0019 - accuracy: 0.999 - ETA: 55s - loss: 0.0019 - accuracy: 0.999 - ETA: 53s - loss: 0.0018 - accuracy: 0.999 - ETA: 52s - loss: 0.0018 - accuracy: 0.999 - ETA: 50s - loss: 0.0018 - accuracy: 0.999 - ETA: 49s - loss: 0.0018 - accuracy: 0.999 - ETA: 48s - loss: 0.0018 - accuracy: 0.999 - ETA: 46s - loss: 0.0018 - accuracy: 0.999 - ETA: 45s - loss: 0.0018 - accuracy: 0.999 - ETA: 44s - loss: 0.0018 - accuracy: 0.999 - ETA: 42s - loss: 0.0018 - accuracy: 0.999 - ETA: 41s - loss: 0.0018 - accuracy: 0.999 - ETA: 40s - loss: 0.0018 - accuracy: 0.999 - ETA: 38s - loss: 0.0018 - accuracy: 0.999 - ETA: 37s - loss: 0.0018 - accuracy: 0.999 - ETA: 36s - loss: 0.0017 - accuracy: 0.999 - ETA: 34s - loss: 0.0018 - accuracy: 0.999 - ETA: 33s - loss: 0.0018 - accuracy: 0.999 - ETA: 32s - loss: 0.0018 - accuracy: 0.999 - ETA: 30s - loss: 0.0018 - accuracy: 0.999 - ETA: 29s - loss: 0.0018 - accuracy: 0.999 - ETA: 28s - loss: 0.0018 - accuracy: 0.999 - ETA: 26s - loss: 0.0018 - accuracy: 0.999 - ETA: 25s - loss: 0.0018 - accuracy: 0.999 - ETA: 24s - loss: 0.0018 - accuracy: 0.999 - ETA: 22s - loss: 0.0018 - accuracy: 0.999 - ETA: 21s - loss: 0.0018 - accuracy: 0.999 - ETA: 20s - loss: 0.0018 - accuracy: 0.999 - ETA: 18s - loss: 0.0018 - accuracy: 0.999 - ETA: 17s - loss: 0.0018 - accuracy: 0.999 - ETA: 15s - loss: 0.0018 - accuracy: 0.999 - ETA: 14s - loss: 0.0018 - accuracy: 0.999 - ETA: 13s - loss: 0.0018 - accuracy: 0.999 - ETA: 11s - loss: 0.0018 - accuracy: 0.999 - ETA: 10s - loss: 0.0018 - accuracy: 0.999 - ETA: 9s - loss: 0.0018 - accuracy: 0.999 - ETA: 7s - loss: 0.0018 - accuracy: 0.99 - ETA: 6s - loss: 0.0018 - accuracy: 0.99 - ETA: 5s - loss: 0.0018 - accuracy: 0.99 - ETA: 3s - loss: 0.0018 - accuracy: 0.99 - ETA: 2s - loss: 0.0018 - accuracy: 0.99 - ETA: 1s - loss: 0.0018 - accuracy: 0.99 - 226s 12ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 1.0141 - val_accuracy: 0.8087\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:20 - loss: 4.1191e-04 - accuracy: 1.00 - ETA: 3:17 - loss: 9.4278e-04 - accuracy: 1.00 - ETA: 3:22 - loss: 9.7111e-04 - accuracy: 1.00 - ETA: 3:18 - loss: 0.0013 - accuracy: 1.0000   - ETA: 3:17 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:14 - loss: 0.0015 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0015 - accuracy: 1.00 - ETA: 3:09 - loss: 0.0013 - accuracy: 1.00 - ETA: 3:10 - loss: 0.0014 - accuracy: 1.00 - ETA: 3:09 - loss: 0.0031 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0029 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0044 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0042 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0042 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0040 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0041 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0041 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0040 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0039 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0039 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0037 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0036 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0041 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0041 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0040 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0039 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0037 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0037 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0036 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0035 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0034 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0033 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0024 - accuracy: 0.99 - ETA: 58s - loss: 0.0025 - accuracy: 0.9996 - ETA: 57s - loss: 0.0025 - accuracy: 0.999 - ETA: 56s - loss: 0.0025 - accuracy: 0.999 - ETA: 54s - loss: 0.0025 - accuracy: 0.999 - ETA: 53s - loss: 0.0025 - accuracy: 0.999 - ETA: 52s - loss: 0.0024 - accuracy: 0.999 - ETA: 50s - loss: 0.0024 - accuracy: 0.999 - ETA: 49s - loss: 0.0024 - accuracy: 0.999 - ETA: 48s - loss: 0.0024 - accuracy: 0.999 - ETA: 46s - loss: 0.0024 - accuracy: 0.999 - ETA: 45s - loss: 0.0024 - accuracy: 0.999 - ETA: 44s - loss: 0.0024 - accuracy: 0.999 - ETA: 42s - loss: 0.0024 - accuracy: 0.999 - ETA: 41s - loss: 0.0024 - accuracy: 0.999 - ETA: 39s - loss: 0.0024 - accuracy: 0.999 - ETA: 38s - loss: 0.0024 - accuracy: 0.999 - ETA: 37s - loss: 0.0024 - accuracy: 0.999 - ETA: 35s - loss: 0.0024 - accuracy: 0.999 - ETA: 34s - loss: 0.0024 - accuracy: 0.999 - ETA: 33s - loss: 0.0023 - accuracy: 0.999 - ETA: 31s - loss: 0.0023 - accuracy: 0.999 - ETA: 30s - loss: 0.0023 - accuracy: 0.999 - ETA: 29s - loss: 0.0023 - accuracy: 0.999 - ETA: 27s - loss: 0.0023 - accuracy: 0.999 - ETA: 26s - loss: 0.0023 - accuracy: 0.999 - ETA: 25s - loss: 0.0023 - accuracy: 0.999 - ETA: 23s - loss: 0.0023 - accuracy: 0.999 - ETA: 22s - loss: 0.0023 - accuracy: 0.999 - ETA: 21s - loss: 0.0023 - accuracy: 0.999 - ETA: 19s - loss: 0.0023 - accuracy: 0.999 - ETA: 18s - loss: 0.0023 - accuracy: 0.999 - ETA: 17s - loss: 0.0023 - accuracy: 0.999 - ETA: 15s - loss: 0.0023 - accuracy: 0.999 - ETA: 14s - loss: 0.0023 - accuracy: 0.999 - ETA: 13s - loss: 0.0023 - accuracy: 0.999 - ETA: 11s - loss: 0.0023 - accuracy: 0.999 - ETA: 10s - loss: 0.0023 - accuracy: 0.999 - ETA: 9s - loss: 0.0023 - accuracy: 0.999 - ETA: 7s - loss: 0.0023 - accuracy: 0.99 - ETA: 6s - loss: 0.0022 - accuracy: 0.99 - ETA: 5s - loss: 0.0022 - accuracy: 0.99 - ETA: 3s - loss: 0.0023 - accuracy: 0.99 - ETA: 2s - loss: 0.0022 - accuracy: 0.99 - ETA: 1s - loss: 0.0022 - accuracy: 0.99 - 225s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 1.0144 - val_accuracy: 0.8078\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:19 - loss: 7.1878e-04 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0018 - accuracy: 1.0000   - ETA: 3:12 - loss: 0.0015 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0022 - accuracy: 1.00 - ETA: 3:10 - loss: 0.0018 - accuracy: 1.00 - ETA: 3:10 - loss: 0.0018 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0018 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0017 - accuracy: 1.00 - ETA: 3:07 - loss: 0.0016 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0015 - accuracy: 1.00 - ETA: 3:04 - loss: 0.0014 - accuracy: 1.00 - ETA: 3:02 - loss: 0.0014 - accuracy: 1.00 - ETA: 3:01 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:59 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:58 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:57 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:56 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:55 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:53 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:52 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:52 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:50 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:49 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:49 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:47 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:46 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:44 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:43 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:41 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:40 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:39 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:38 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:37 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:36 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:35 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:33 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:32 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:31 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:29 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:28 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:27 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:25 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:24 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:23 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:21 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:20 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:19 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0018 - accuracy: 0.99 - ETA: 59s - loss: 0.0018 - accuracy: 0.9998 - ETA: 58s - loss: 0.0018 - accuracy: 0.999 - ETA: 57s - loss: 0.0018 - accuracy: 0.999 - ETA: 55s - loss: 0.0018 - accuracy: 0.999 - ETA: 54s - loss: 0.0018 - accuracy: 0.999 - ETA: 53s - loss: 0.0018 - accuracy: 0.999 - ETA: 51s - loss: 0.0018 - accuracy: 0.999 - ETA: 50s - loss: 0.0017 - accuracy: 0.999 - ETA: 49s - loss: 0.0017 - accuracy: 0.999 - ETA: 47s - loss: 0.0017 - accuracy: 0.999 - ETA: 46s - loss: 0.0017 - accuracy: 0.999 - ETA: 45s - loss: 0.0019 - accuracy: 0.999 - ETA: 43s - loss: 0.0018 - accuracy: 0.999 - ETA: 42s - loss: 0.0018 - accuracy: 0.999 - ETA: 41s - loss: 0.0018 - accuracy: 0.999 - ETA: 39s - loss: 0.0018 - accuracy: 0.999 - ETA: 38s - loss: 0.0018 - accuracy: 0.999 - ETA: 37s - loss: 0.0018 - accuracy: 0.999 - ETA: 35s - loss: 0.0018 - accuracy: 0.999 - ETA: 34s - loss: 0.0018 - accuracy: 0.999 - ETA: 33s - loss: 0.0018 - accuracy: 0.999 - ETA: 31s - loss: 0.0018 - accuracy: 0.999 - ETA: 30s - loss: 0.0018 - accuracy: 0.999 - ETA: 29s - loss: 0.0018 - accuracy: 0.999 - ETA: 27s - loss: 0.0018 - accuracy: 0.999 - ETA: 26s - loss: 0.0018 - accuracy: 0.999 - ETA: 25s - loss: 0.0018 - accuracy: 0.999 - ETA: 23s - loss: 0.0018 - accuracy: 0.999 - ETA: 22s - loss: 0.0018 - accuracy: 0.999 - ETA: 21s - loss: 0.0017 - accuracy: 0.999 - ETA: 19s - loss: 0.0017 - accuracy: 0.999 - ETA: 18s - loss: 0.0018 - accuracy: 0.999 - ETA: 17s - loss: 0.0018 - accuracy: 0.999 - ETA: 15s - loss: 0.0017 - accuracy: 0.999 - ETA: 14s - loss: 0.0017 - accuracy: 0.999 - ETA: 13s - loss: 0.0017 - accuracy: 0.999 - ETA: 11s - loss: 0.0017 - accuracy: 0.999 - ETA: 10s - loss: 0.0017 - accuracy: 0.999 - ETA: 9s - loss: 0.0018 - accuracy: 0.999 - ETA: 7s - loss: 0.0018 - accuracy: 0.99 - ETA: 6s - loss: 0.0018 - accuracy: 0.99 - ETA: 5s - loss: 0.0018 - accuracy: 0.99 - ETA: 3s - loss: 0.0018 - accuracy: 0.99 - ETA: 2s - loss: 0.0018 - accuracy: 0.99 - ETA: 1s - loss: 0.0018 - accuracy: 0.99 - 225s 12ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 1.0176 - val_accuracy: 0.8091\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:10 - loss: 0.0033 - accuracy: 1.00 - ETA: 3:07 - loss: 0.0082 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0056 - accuracy: 0.99 - ETA: 3:12 - loss: 0.0044 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0037 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0038 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0033 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0030 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0028 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0026 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0024 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0024 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0023 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0022 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0022 - accuracy: 0.99 - ETA: 59s - loss: 0.0022 - accuracy: 0.9997 - ETA: 58s - loss: 0.0022 - accuracy: 0.999 - ETA: 56s - loss: 0.0022 - accuracy: 0.999 - ETA: 55s - loss: 0.0022 - accuracy: 0.999 - ETA: 54s - loss: 0.0021 - accuracy: 0.999 - ETA: 52s - loss: 0.0021 - accuracy: 0.999 - ETA: 51s - loss: 0.0021 - accuracy: 0.999 - ETA: 50s - loss: 0.0021 - accuracy: 0.999 - ETA: 49s - loss: 0.0021 - accuracy: 0.999 - ETA: 47s - loss: 0.0021 - accuracy: 0.999 - ETA: 46s - loss: 0.0021 - accuracy: 0.999 - ETA: 44s - loss: 0.0022 - accuracy: 0.999 - ETA: 43s - loss: 0.0022 - accuracy: 0.999 - ETA: 42s - loss: 0.0022 - accuracy: 0.999 - ETA: 40s - loss: 0.0022 - accuracy: 0.999 - ETA: 39s - loss: 0.0022 - accuracy: 0.999 - ETA: 38s - loss: 0.0022 - accuracy: 0.999 - ETA: 37s - loss: 0.0022 - accuracy: 0.999 - ETA: 35s - loss: 0.0022 - accuracy: 0.999 - ETA: 34s - loss: 0.0022 - accuracy: 0.999 - ETA: 33s - loss: 0.0022 - accuracy: 0.999 - ETA: 31s - loss: 0.0022 - accuracy: 0.999 - ETA: 30s - loss: 0.0021 - accuracy: 0.999 - ETA: 29s - loss: 0.0021 - accuracy: 0.999 - ETA: 27s - loss: 0.0022 - accuracy: 0.999 - ETA: 26s - loss: 0.0021 - accuracy: 0.999 - ETA: 25s - loss: 0.0022 - accuracy: 0.999 - ETA: 23s - loss: 0.0021 - accuracy: 0.999 - ETA: 22s - loss: 0.0021 - accuracy: 0.999 - ETA: 21s - loss: 0.0021 - accuracy: 0.999 - ETA: 19s - loss: 0.0021 - accuracy: 0.999 - ETA: 18s - loss: 0.0021 - accuracy: 0.999 - ETA: 17s - loss: 0.0021 - accuracy: 0.999 - ETA: 15s - loss: 0.0021 - accuracy: 0.999 - ETA: 14s - loss: 0.0021 - accuracy: 0.999 - ETA: 13s - loss: 0.0021 - accuracy: 0.999 - ETA: 11s - loss: 0.0021 - accuracy: 0.999 - ETA: 10s - loss: 0.0021 - accuracy: 0.999 - ETA: 9s - loss: 0.0021 - accuracy: 0.999 - ETA: 7s - loss: 0.0021 - accuracy: 0.99 - ETA: 6s - loss: 0.0021 - accuracy: 0.99 - ETA: 5s - loss: 0.0021 - accuracy: 0.99 - ETA: 3s - loss: 0.0021 - accuracy: 0.99 - ETA: 2s - loss: 0.0020 - accuracy: 0.99 - ETA: 1s - loss: 0.0021 - accuracy: 0.99 - 223s 12ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 1.0034 - val_accuracy: 0.8111\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:21 - loss: 5.0179e-04 - accuracy: 1.00 - ETA: 3:18 - loss: 9.1948e-04 - accuracy: 1.00 - ETA: 3:12 - loss: 0.0010 - accuracy: 1.0000   - ETA: 3:10 - loss: 0.0010 - accuracy: 1.00 - ETA: 3:10 - loss: 9.9072e-04 - accuracy: 1.00 - ETA: 3:10 - loss: 9.7508e-04 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0011 - accuracy: 1.0000   - ETA: 3:05 - loss: 0.0011 - accuracy: 1.00 - ETA: 3:04 - loss: 0.0010 - accuracy: 1.00 - ETA: 3:03 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:00 - loss: 0.0012 - accuracy: 1.00 - ETA: 2:59 - loss: 0.0011 - accuracy: 1.00 - ETA: 2:58 - loss: 0.0011 - accuracy: 1.00 - ETA: 2:56 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:55 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:53 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:52 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:50 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:48 - loss: 0.0013 - accuracy: 1.00 - ETA: 2:47 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:46 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:45 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:44 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:42 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:41 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:40 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:39 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:37 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:36 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:35 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:33 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:32 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:31 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:30 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:29 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:27 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:26 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:25 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:24 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:23 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:22 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:21 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:20 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:19 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:18 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:17 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:16 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:15 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:13 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:12 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:11 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:09 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:08 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:07 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:05 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:04 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0019 - accuracy: 0.99 - ETA: 59s - loss: 0.0019 - accuracy: 0.9997 - ETA: 57s - loss: 0.0019 - accuracy: 0.999 - ETA: 56s - loss: 0.0019 - accuracy: 0.999 - ETA: 55s - loss: 0.0019 - accuracy: 0.999 - ETA: 53s - loss: 0.0019 - accuracy: 0.999 - ETA: 52s - loss: 0.0019 - accuracy: 0.999 - ETA: 51s - loss: 0.0019 - accuracy: 0.999 - ETA: 50s - loss: 0.0019 - accuracy: 0.999 - ETA: 48s - loss: 0.0019 - accuracy: 0.999 - ETA: 47s - loss: 0.0019 - accuracy: 0.999 - ETA: 46s - loss: 0.0019 - accuracy: 0.999 - ETA: 44s - loss: 0.0019 - accuracy: 0.999 - ETA: 43s - loss: 0.0019 - accuracy: 0.999 - ETA: 42s - loss: 0.0020 - accuracy: 0.999 - ETA: 40s - loss: 0.0020 - accuracy: 0.999 - ETA: 39s - loss: 0.0020 - accuracy: 0.999 - ETA: 38s - loss: 0.0020 - accuracy: 0.999 - ETA: 36s - loss: 0.0020 - accuracy: 0.999 - ETA: 35s - loss: 0.0020 - accuracy: 0.999 - ETA: 34s - loss: 0.0020 - accuracy: 0.999 - ETA: 32s - loss: 0.0021 - accuracy: 0.999 - ETA: 31s - loss: 0.0021 - accuracy: 0.999 - ETA: 30s - loss: 0.0020 - accuracy: 0.999 - ETA: 28s - loss: 0.0020 - accuracy: 0.999 - ETA: 27s - loss: 0.0021 - accuracy: 0.999 - ETA: 26s - loss: 0.0021 - accuracy: 0.999 - ETA: 24s - loss: 0.0020 - accuracy: 0.999 - ETA: 23s - loss: 0.0020 - accuracy: 0.999 - ETA: 22s - loss: 0.0020 - accuracy: 0.999 - ETA: 20s - loss: 0.0020 - accuracy: 0.999 - ETA: 19s - loss: 0.0020 - accuracy: 0.999 - ETA: 18s - loss: 0.0020 - accuracy: 0.999 - ETA: 17s - loss: 0.0020 - accuracy: 0.999 - ETA: 15s - loss: 0.0020 - accuracy: 0.999 - ETA: 14s - loss: 0.0020 - accuracy: 0.999 - ETA: 13s - loss: 0.0020 - accuracy: 0.999 - ETA: 11s - loss: 0.0021 - accuracy: 0.999 - ETA: 10s - loss: 0.0020 - accuracy: 0.999 - ETA: 9s - loss: 0.0020 - accuracy: 0.999 - ETA: 7s - loss: 0.0020 - accuracy: 0.99 - ETA: 6s - loss: 0.0020 - accuracy: 0.99 - ETA: 5s - loss: 0.0020 - accuracy: 0.99 - ETA: 3s - loss: 0.0020 - accuracy: 0.99 - ETA: 2s - loss: 0.0020 - accuracy: 0.99 - ETA: 1s - loss: 0.0020 - accuracy: 0.99 - 222s 12ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 1.0115 - val_accuracy: 0.8084\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:22 - loss: 0.0094 - accuracy: 0.99 - ETA: 3:17 - loss: 0.0060 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0043 - accuracy: 0.99 - ETA: 3:22 - loss: 0.0036 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0031 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0032 - accuracy: 0.99 - ETA: 3:15 - loss: 0.0040 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0036 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0036 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0033 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0032 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0032 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0031 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0029 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0029 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0024 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0022 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0023 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0022 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0020 - accuracy: 0.99 - ETA: 59s - loss: 0.0019 - accuracy: 0.9997 - ETA: 58s - loss: 0.0019 - accuracy: 0.999 - ETA: 56s - loss: 0.0019 - accuracy: 0.999 - ETA: 55s - loss: 0.0020 - accuracy: 0.999 - ETA: 54s - loss: 0.0020 - accuracy: 0.999 - ETA: 52s - loss: 0.0020 - accuracy: 0.999 - ETA: 51s - loss: 0.0020 - accuracy: 0.999 - ETA: 50s - loss: 0.0020 - accuracy: 0.999 - ETA: 48s - loss: 0.0020 - accuracy: 0.999 - ETA: 47s - loss: 0.0020 - accuracy: 0.999 - ETA: 46s - loss: 0.0020 - accuracy: 0.999 - ETA: 44s - loss: 0.0020 - accuracy: 0.999 - ETA: 43s - loss: 0.0019 - accuracy: 0.999 - ETA: 42s - loss: 0.0019 - accuracy: 0.999 - ETA: 40s - loss: 0.0019 - accuracy: 0.999 - ETA: 39s - loss: 0.0019 - accuracy: 0.999 - ETA: 38s - loss: 0.0019 - accuracy: 0.999 - ETA: 37s - loss: 0.0019 - accuracy: 0.999 - ETA: 35s - loss: 0.0019 - accuracy: 0.999 - ETA: 34s - loss: 0.0019 - accuracy: 0.999 - ETA: 33s - loss: 0.0019 - accuracy: 0.999 - ETA: 31s - loss: 0.0019 - accuracy: 0.999 - ETA: 30s - loss: 0.0018 - accuracy: 0.999 - ETA: 29s - loss: 0.0018 - accuracy: 0.999 - ETA: 27s - loss: 0.0018 - accuracy: 0.999 - ETA: 26s - loss: 0.0018 - accuracy: 0.999 - ETA: 25s - loss: 0.0018 - accuracy: 0.999 - ETA: 23s - loss: 0.0018 - accuracy: 0.999 - ETA: 22s - loss: 0.0018 - accuracy: 0.999 - ETA: 21s - loss: 0.0018 - accuracy: 0.999 - ETA: 19s - loss: 0.0018 - accuracy: 0.999 - ETA: 18s - loss: 0.0018 - accuracy: 0.999 - ETA: 17s - loss: 0.0018 - accuracy: 0.999 - ETA: 15s - loss: 0.0018 - accuracy: 0.999 - ETA: 14s - loss: 0.0019 - accuracy: 0.999 - ETA: 13s - loss: 0.0019 - accuracy: 0.999 - ETA: 11s - loss: 0.0019 - accuracy: 0.999 - ETA: 10s - loss: 0.0019 - accuracy: 0.999 - ETA: 9s - loss: 0.0019 - accuracy: 0.999 - ETA: 7s - loss: 0.0019 - accuracy: 0.99 - ETA: 6s - loss: 0.0019 - accuracy: 0.99 - ETA: 5s - loss: 0.0019 - accuracy: 0.99 - ETA: 3s - loss: 0.0019 - accuracy: 0.99 - ETA: 2s - loss: 0.0019 - accuracy: 0.99 - ETA: 1s - loss: 0.0019 - accuracy: 0.99 - 225s 12ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 1.0029 - val_accuracy: 0.8107\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:26 - loss: 0.0021 - accuracy: 1.00 - ETA: 3:31 - loss: 0.0019 - accuracy: 1.00 - ETA: 3:29 - loss: 0.0024 - accuracy: 1.00 - ETA: 3:27 - loss: 0.0019 - accuracy: 1.00 - ETA: 3:25 - loss: 0.0018 - accuracy: 1.00 - ETA: 3:19 - loss: 0.0026 - accuracy: 1.00 - ETA: 3:15 - loss: 0.0024 - accuracy: 1.00 - ETA: 3:15 - loss: 0.0023 - accuracy: 1.00 - ETA: 3:11 - loss: 0.0022 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0021 - accuracy: 1.00 - ETA: 3:07 - loss: 0.0020 - accuracy: 1.00 - ETA: 3:06 - loss: 0.0019 - accuracy: 1.00 - ETA: 3:04 - loss: 0.0018 - accuracy: 1.00 - ETA: 3:02 - loss: 0.0018 - accuracy: 1.00 - ETA: 3:01 - loss: 0.0017 - accuracy: 1.00 - ETA: 3:00 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:59 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:57 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:55 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:54 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:52 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:51 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:50 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:49 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:47 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:45 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:44 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:43 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:41 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:40 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:39 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:37 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:36 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:35 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:34 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0016 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0015 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0014 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0014 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0014 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0016 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0015 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0019 - accuracy: 0.99 - ETA: 59s - loss: 0.0019 - accuracy: 0.9998 - ETA: 58s - loss: 0.0019 - accuracy: 0.999 - ETA: 57s - loss: 0.0019 - accuracy: 0.999 - ETA: 55s - loss: 0.0019 - accuracy: 0.999 - ETA: 54s - loss: 0.0020 - accuracy: 0.999 - ETA: 53s - loss: 0.0021 - accuracy: 0.999 - ETA: 51s - loss: 0.0021 - accuracy: 0.999 - ETA: 50s - loss: 0.0021 - accuracy: 0.999 - ETA: 49s - loss: 0.0021 - accuracy: 0.999 - ETA: 47s - loss: 0.0021 - accuracy: 0.999 - ETA: 46s - loss: 0.0021 - accuracy: 0.999 - ETA: 45s - loss: 0.0021 - accuracy: 0.999 - ETA: 43s - loss: 0.0021 - accuracy: 0.999 - ETA: 42s - loss: 0.0021 - accuracy: 0.999 - ETA: 41s - loss: 0.0021 - accuracy: 0.999 - ETA: 39s - loss: 0.0021 - accuracy: 0.999 - ETA: 38s - loss: 0.0021 - accuracy: 0.999 - ETA: 37s - loss: 0.0021 - accuracy: 0.999 - ETA: 35s - loss: 0.0021 - accuracy: 0.999 - ETA: 34s - loss: 0.0021 - accuracy: 0.999 - ETA: 33s - loss: 0.0021 - accuracy: 0.999 - ETA: 31s - loss: 0.0021 - accuracy: 0.999 - ETA: 30s - loss: 0.0021 - accuracy: 0.999 - ETA: 29s - loss: 0.0021 - accuracy: 0.999 - ETA: 27s - loss: 0.0021 - accuracy: 0.999 - ETA: 26s - loss: 0.0021 - accuracy: 0.999 - ETA: 25s - loss: 0.0021 - accuracy: 0.999 - ETA: 23s - loss: 0.0021 - accuracy: 0.999 - ETA: 22s - loss: 0.0021 - accuracy: 0.999 - ETA: 21s - loss: 0.0021 - accuracy: 0.999 - ETA: 19s - loss: 0.0021 - accuracy: 0.999 - ETA: 18s - loss: 0.0021 - accuracy: 0.999 - ETA: 17s - loss: 0.0020 - accuracy: 0.999 - ETA: 15s - loss: 0.0020 - accuracy: 0.999 - ETA: 14s - loss: 0.0021 - accuracy: 0.999 - ETA: 13s - loss: 0.0021 - accuracy: 0.999 - ETA: 11s - loss: 0.0021 - accuracy: 0.999 - ETA: 10s - loss: 0.0021 - accuracy: 0.999 - ETA: 9s - loss: 0.0021 - accuracy: 0.999 - ETA: 7s - loss: 0.0021 - accuracy: 0.99 - ETA: 6s - loss: 0.0021 - accuracy: 0.99 - ETA: 5s - loss: 0.0021 - accuracy: 0.99 - ETA: 3s - loss: 0.0021 - accuracy: 0.99 - ETA: 2s - loss: 0.0021 - accuracy: 0.99 - ETA: 1s - loss: 0.0021 - accuracy: 0.99 - 225s 12ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 1.0116 - val_accuracy: 0.8122\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:12 - loss: 0.0053 - accuracy: 1.00 - ETA: 3:10 - loss: 0.0028 - accuracy: 1.00 - ETA: 3:04 - loss: 0.0021 - accuracy: 1.00 - ETA: 3:03 - loss: 0.0017 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0016 - accuracy: 1.00 - ETA: 3:03 - loss: 0.0015 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0013 - accuracy: 1.00 - ETA: 3:04 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:03 - loss: 0.0011 - accuracy: 1.00 - ETA: 3:01 - loss: 0.0015 - accuracy: 1.00 - ETA: 3:02 - loss: 0.0016 - accuracy: 1.00 - ETA: 3:01 - loss: 0.0016 - accuracy: 1.00 - ETA: 3:00 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:59 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:58 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:58 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:57 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:55 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:54 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:54 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:52 - loss: 0.0017 - accuracy: 1.00 - ETA: 2:50 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:49 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:48 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:47 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:45 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:44 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:43 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:41 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:39 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:38 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:37 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:36 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:35 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0019 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0020 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0021 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0021 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0020 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0017 - accuracy: 0.99 - ETA: 58s - loss: 0.0017 - accuracy: 0.9999 - ETA: 57s - loss: 0.0017 - accuracy: 0.999 - ETA: 56s - loss: 0.0017 - accuracy: 0.999 - ETA: 54s - loss: 0.0018 - accuracy: 0.999 - ETA: 53s - loss: 0.0018 - accuracy: 0.999 - ETA: 52s - loss: 0.0018 - accuracy: 0.999 - ETA: 50s - loss: 0.0017 - accuracy: 0.999 - ETA: 49s - loss: 0.0017 - accuracy: 0.999 - ETA: 48s - loss: 0.0018 - accuracy: 0.999 - ETA: 46s - loss: 0.0018 - accuracy: 0.999 - ETA: 45s - loss: 0.0018 - accuracy: 0.999 - ETA: 44s - loss: 0.0018 - accuracy: 0.999 - ETA: 42s - loss: 0.0018 - accuracy: 0.999 - ETA: 41s - loss: 0.0017 - accuracy: 0.999 - ETA: 40s - loss: 0.0018 - accuracy: 0.999 - ETA: 38s - loss: 0.0018 - accuracy: 0.999 - ETA: 37s - loss: 0.0018 - accuracy: 0.999 - ETA: 36s - loss: 0.0018 - accuracy: 0.999 - ETA: 34s - loss: 0.0017 - accuracy: 0.999 - ETA: 33s - loss: 0.0018 - accuracy: 0.999 - ETA: 32s - loss: 0.0018 - accuracy: 0.999 - ETA: 30s - loss: 0.0018 - accuracy: 0.999 - ETA: 29s - loss: 0.0018 - accuracy: 0.999 - ETA: 28s - loss: 0.0018 - accuracy: 0.999 - ETA: 26s - loss: 0.0018 - accuracy: 0.999 - ETA: 25s - loss: 0.0018 - accuracy: 0.999 - ETA: 24s - loss: 0.0019 - accuracy: 0.999 - ETA: 22s - loss: 0.0019 - accuracy: 0.999 - ETA: 21s - loss: 0.0019 - accuracy: 0.999 - ETA: 19s - loss: 0.0020 - accuracy: 0.999 - ETA: 18s - loss: 0.0020 - accuracy: 0.999 - ETA: 17s - loss: 0.0020 - accuracy: 0.999 - ETA: 15s - loss: 0.0020 - accuracy: 0.999 - ETA: 14s - loss: 0.0020 - accuracy: 0.999 - ETA: 13s - loss: 0.0019 - accuracy: 0.999 - ETA: 11s - loss: 0.0019 - accuracy: 0.999 - ETA: 10s - loss: 0.0019 - accuracy: 0.999 - ETA: 9s - loss: 0.0021 - accuracy: 0.999 - ETA: 7s - loss: 0.0021 - accuracy: 0.99 - ETA: 6s - loss: 0.0021 - accuracy: 0.99 - ETA: 5s - loss: 0.0021 - accuracy: 0.99 - ETA: 3s - loss: 0.0021 - accuracy: 0.99 - ETA: 2s - loss: 0.0021 - accuracy: 0.99 - ETA: 1s - loss: 0.0021 - accuracy: 0.99 - 227s 12ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 1.0169 - val_accuracy: 0.8101\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:33 - loss: 0.0558 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0283 - accuracy: 0.99 - ETA: 3:27 - loss: 0.0193 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0152 - accuracy: 0.99 - ETA: 3:17 - loss: 0.0124 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0108 - accuracy: 0.99 - ETA: 3:12 - loss: 0.0093 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0088 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0079 - accuracy: 0.99 - ETA: 3:11 - loss: 0.0072 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0066 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0061 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0057 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0079 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0074 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0070 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0067 - accuracy: 0.99 - ETA: 3:00 - loss: 0.0064 - accuracy: 0.99 - ETA: 2:58 - loss: 0.0061 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0058 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0056 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0054 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0052 - accuracy: 0.99 - ETA: 2:51 - loss: 0.0050 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0048 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0047 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0047 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0045 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0044 - accuracy: 0.99 - ETA: 2:43 - loss: 0.0043 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0042 - accuracy: 0.99 - ETA: 2:39 - loss: 0.0045 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0044 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0043 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0042 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0041 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0040 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0039 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0038 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0044 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0043 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0043 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0043 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0042 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0041 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0041 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0043 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0042 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0041 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0041 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0040 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0040 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0039 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0039 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0038 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0038 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0038 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0037 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0037 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0037 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0036 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0036 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0035 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0034 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0033 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0032 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0031 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0030 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0028 - accuracy: 0.99 - ETA: 58s - loss: 0.0028 - accuracy: 0.9995 - ETA: 57s - loss: 0.0028 - accuracy: 0.999 - ETA: 56s - loss: 0.0028 - accuracy: 0.999 - ETA: 54s - loss: 0.0028 - accuracy: 0.999 - ETA: 53s - loss: 0.0027 - accuracy: 0.999 - ETA: 52s - loss: 0.0027 - accuracy: 0.999 - ETA: 50s - loss: 0.0027 - accuracy: 0.999 - ETA: 49s - loss: 0.0027 - accuracy: 0.999 - ETA: 48s - loss: 0.0027 - accuracy: 0.999 - ETA: 46s - loss: 0.0027 - accuracy: 0.999 - ETA: 45s - loss: 0.0027 - accuracy: 0.999 - ETA: 44s - loss: 0.0026 - accuracy: 0.999 - ETA: 42s - loss: 0.0026 - accuracy: 0.999 - ETA: 41s - loss: 0.0026 - accuracy: 0.999 - ETA: 40s - loss: 0.0026 - accuracy: 0.999 - ETA: 38s - loss: 0.0026 - accuracy: 0.999 - ETA: 37s - loss: 0.0026 - accuracy: 0.999 - ETA: 36s - loss: 0.0026 - accuracy: 0.999 - ETA: 34s - loss: 0.0026 - accuracy: 0.999 - ETA: 33s - loss: 0.0026 - accuracy: 0.999 - ETA: 32s - loss: 0.0025 - accuracy: 0.999 - ETA: 30s - loss: 0.0025 - accuracy: 0.999 - ETA: 29s - loss: 0.0025 - accuracy: 0.999 - ETA: 28s - loss: 0.0025 - accuracy: 0.999 - ETA: 26s - loss: 0.0025 - accuracy: 0.999 - ETA: 25s - loss: 0.0025 - accuracy: 0.999 - ETA: 24s - loss: 0.0025 - accuracy: 0.999 - ETA: 22s - loss: 0.0025 - accuracy: 0.999 - ETA: 21s - loss: 0.0025 - accuracy: 0.999 - ETA: 20s - loss: 0.0025 - accuracy: 0.999 - ETA: 18s - loss: 0.0025 - accuracy: 0.999 - ETA: 17s - loss: 0.0025 - accuracy: 0.999 - ETA: 15s - loss: 0.0025 - accuracy: 0.999 - ETA: 14s - loss: 0.0025 - accuracy: 0.999 - ETA: 13s - loss: 0.0025 - accuracy: 0.999 - ETA: 11s - loss: 0.0025 - accuracy: 0.999 - ETA: 10s - loss: 0.0025 - accuracy: 0.999 - ETA: 9s - loss: 0.0024 - accuracy: 0.999 - ETA: 7s - loss: 0.0025 - accuracy: 0.99 - ETA: 6s - loss: 0.0025 - accuracy: 0.99 - ETA: 5s - loss: 0.0025 - accuracy: 0.99 - ETA: 3s - loss: 0.0026 - accuracy: 0.99 - ETA: 2s - loss: 0.0026 - accuracy: 0.99 - ETA: 1s - loss: 0.0026 - accuracy: 0.99 - 227s 12ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.0163 - val_accuracy: 0.8103\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:42 - loss: 0.0011 - accuracy: 1.00 - ETA: 3:30 - loss: 8.4857e-04 - accuracy: 1.00 - ETA: 3:23 - loss: 0.0013 - accuracy: 1.0000   - ETA: 3:17 - loss: 0.0017 - accuracy: 1.00 - ETA: 3:17 - loss: 0.0014 - accuracy: 1.00 - ETA: 3:14 - loss: 0.0013 - accuracy: 1.00 - ETA: 3:12 - loss: 0.0015 - accuracy: 1.00 - ETA: 3:12 - loss: 0.0014 - accuracy: 1.00 - ETA: 3:10 - loss: 0.0013 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0013 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:04 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:02 - loss: 0.0011 - accuracy: 1.00 - ETA: 3:00 - loss: 0.0012 - accuracy: 1.00 - ETA: 2:59 - loss: 0.0013 - accuracy: 1.00 - ETA: 2:58 - loss: 0.0013 - accuracy: 1.00 - ETA: 2:58 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:56 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:55 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:54 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:52 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:51 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:50 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:48 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:47 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:46 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:45 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:44 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:42 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:41 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:40 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:39 - loss: 0.0016 - accuracy: 1.00 - ETA: 2:37 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:36 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:34 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:33 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:33 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:31 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:30 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:29 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:28 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:26 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:25 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:23 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:22 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:21 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:20 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:18 - loss: 0.0015 - accuracy: 1.00 - ETA: 2:17 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:15 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:14 - loss: 0.0014 - accuracy: 1.00 - ETA: 2:13 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0018 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0017 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0017 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0019 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0018 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0018 - accuracy: 0.99 - ETA: 59s - loss: 0.0018 - accuracy: 0.9998 - ETA: 57s - loss: 0.0018 - accuracy: 0.999 - ETA: 56s - loss: 0.0018 - accuracy: 0.999 - ETA: 54s - loss: 0.0018 - accuracy: 0.999 - ETA: 53s - loss: 0.0018 - accuracy: 0.999 - ETA: 52s - loss: 0.0020 - accuracy: 0.999 - ETA: 50s - loss: 0.0020 - accuracy: 0.999 - ETA: 49s - loss: 0.0020 - accuracy: 0.999 - ETA: 48s - loss: 0.0020 - accuracy: 0.999 - ETA: 46s - loss: 0.0020 - accuracy: 0.999 - ETA: 45s - loss: 0.0020 - accuracy: 0.999 - ETA: 44s - loss: 0.0020 - accuracy: 0.999 - ETA: 42s - loss: 0.0020 - accuracy: 0.999 - ETA: 41s - loss: 0.0020 - accuracy: 0.999 - ETA: 40s - loss: 0.0020 - accuracy: 0.999 - ETA: 38s - loss: 0.0020 - accuracy: 0.999 - ETA: 37s - loss: 0.0020 - accuracy: 0.999 - ETA: 36s - loss: 0.0020 - accuracy: 0.999 - ETA: 34s - loss: 0.0020 - accuracy: 0.999 - ETA: 33s - loss: 0.0020 - accuracy: 0.999 - ETA: 32s - loss: 0.0021 - accuracy: 0.999 - ETA: 30s - loss: 0.0021 - accuracy: 0.999 - ETA: 29s - loss: 0.0020 - accuracy: 0.999 - ETA: 28s - loss: 0.0020 - accuracy: 0.999 - ETA: 26s - loss: 0.0021 - accuracy: 0.999 - ETA: 25s - loss: 0.0021 - accuracy: 0.999 - ETA: 24s - loss: 0.0020 - accuracy: 0.999 - ETA: 22s - loss: 0.0020 - accuracy: 0.999 - ETA: 21s - loss: 0.0020 - accuracy: 0.999 - ETA: 20s - loss: 0.0020 - accuracy: 0.999 - ETA: 18s - loss: 0.0020 - accuracy: 0.999 - ETA: 17s - loss: 0.0020 - accuracy: 0.999 - ETA: 15s - loss: 0.0020 - accuracy: 0.999 - ETA: 14s - loss: 0.0020 - accuracy: 0.999 - ETA: 13s - loss: 0.0020 - accuracy: 0.999 - ETA: 11s - loss: 0.0020 - accuracy: 0.999 - ETA: 10s - loss: 0.0020 - accuracy: 0.999 - ETA: 9s - loss: 0.0020 - accuracy: 0.999 - ETA: 7s - loss: 0.0020 - accuracy: 0.99 - ETA: 6s - loss: 0.0020 - accuracy: 0.99 - ETA: 5s - loss: 0.0020 - accuracy: 0.99 - ETA: 3s - loss: 0.0020 - accuracy: 0.99 - ETA: 2s - loss: 0.0020 - accuracy: 0.99 - ETA: 1s - loss: 0.0020 - accuracy: 0.99 - 225s 12ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 1.0147 - val_accuracy: 0.8099\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:05 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:11 - loss: 8.2996e-04 - accuracy: 1.00 - ETA: 3:08 - loss: 0.0016 - accuracy: 1.0000   - ETA: 3:09 - loss: 0.0013 - accuracy: 1.00 - ETA: 3:07 - loss: 0.0012 - accuracy: 1.00 - ETA: 3:05 - loss: 0.0043 - accuracy: 0.99 - ETA: 3:03 - loss: 0.0056 - accuracy: 0.99 - ETA: 3:04 - loss: 0.0050 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0046 - accuracy: 0.99 - ETA: 3:01 - loss: 0.0042 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0039 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0037 - accuracy: 0.99 - ETA: 2:57 - loss: 0.0035 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0034 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0036 - accuracy: 0.99 - ETA: 2:55 - loss: 0.0034 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0033 - accuracy: 0.99 - ETA: 2:53 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:49 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:47 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:37 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0033 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0032 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0031 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0030 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0029 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0028 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0027 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0026 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0025 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0023 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0024 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0025 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0029 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0028 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0027 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0026 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0026 - accuracy: 0.99 - ETA: 59s - loss: 0.0026 - accuracy: 0.9995 - ETA: 57s - loss: 0.0026 - accuracy: 0.999 - ETA: 56s - loss: 0.0026 - accuracy: 0.999 - ETA: 55s - loss: 0.0026 - accuracy: 0.999 - ETA: 54s - loss: 0.0026 - accuracy: 0.999 - ETA: 52s - loss: 0.0025 - accuracy: 0.999 - ETA: 51s - loss: 0.0025 - accuracy: 0.999 - ETA: 50s - loss: 0.0025 - accuracy: 0.999 - ETA: 48s - loss: 0.0025 - accuracy: 0.999 - ETA: 47s - loss: 0.0025 - accuracy: 0.999 - ETA: 46s - loss: 0.0025 - accuracy: 0.999 - ETA: 44s - loss: 0.0025 - accuracy: 0.999 - ETA: 43s - loss: 0.0025 - accuracy: 0.999 - ETA: 42s - loss: 0.0025 - accuracy: 0.999 - ETA: 40s - loss: 0.0024 - accuracy: 0.999 - ETA: 39s - loss: 0.0024 - accuracy: 0.999 - ETA: 38s - loss: 0.0025 - accuracy: 0.999 - ETA: 36s - loss: 0.0024 - accuracy: 0.999 - ETA: 35s - loss: 0.0024 - accuracy: 0.999 - ETA: 34s - loss: 0.0024 - accuracy: 0.999 - ETA: 32s - loss: 0.0024 - accuracy: 0.999 - ETA: 31s - loss: 0.0024 - accuracy: 0.999 - ETA: 30s - loss: 0.0024 - accuracy: 0.999 - ETA: 28s - loss: 0.0024 - accuracy: 0.999 - ETA: 27s - loss: 0.0024 - accuracy: 0.999 - ETA: 26s - loss: 0.0024 - accuracy: 0.999 - ETA: 24s - loss: 0.0024 - accuracy: 0.999 - ETA: 23s - loss: 0.0024 - accuracy: 0.999 - ETA: 22s - loss: 0.0023 - accuracy: 0.999 - ETA: 20s - loss: 0.0023 - accuracy: 0.999 - ETA: 19s - loss: 0.0023 - accuracy: 0.999 - ETA: 18s - loss: 0.0023 - accuracy: 0.999 - ETA: 17s - loss: 0.0024 - accuracy: 0.999 - ETA: 15s - loss: 0.0024 - accuracy: 0.999 - ETA: 14s - loss: 0.0024 - accuracy: 0.999 - ETA: 13s - loss: 0.0024 - accuracy: 0.999 - ETA: 11s - loss: 0.0024 - accuracy: 0.999 - ETA: 10s - loss: 0.0023 - accuracy: 0.999 - ETA: 9s - loss: 0.0023 - accuracy: 0.999 - ETA: 7s - loss: 0.0023 - accuracy: 0.99 - ETA: 6s - loss: 0.0023 - accuracy: 0.99 - ETA: 5s - loss: 0.0023 - accuracy: 0.99 - ETA: 3s - loss: 0.0023 - accuracy: 0.99 - ETA: 2s - loss: 0.0023 - accuracy: 0.99 - ETA: 1s - loss: 0.0023 - accuracy: 0.99 - 223s 12ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 1.0021 - val_accuracy: 0.8101\n",
      "2020-12-06 16:49:11.745502\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "t5=datetime.datetime.now()\n",
    "print(t5)\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n",
    "t6=datetime.datetime.now()\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [1.3617180194833012, 1.1041281200462456, 0.9835185135316838, 0.9327398257414533, 0.928535130693444, 0.9283316958935568, 0.9148873678026892, 0.9184062403041795, 0.918456641110507, 0.9270483902039353, 0.9246683958204273, 0.9170498443232434, 0.9186490222419806, 0.9397142647240418, 0.9313924811744967, 0.9236706707462264, 0.9363509155401015, 0.9246393762703242, 0.9447596589214043, 0.9453934942819386, 0.9423263107404671, 0.942134283830177, 0.9418799072152266, 0.9198186132053234, 0.9444197324596594, 0.9509662398765684, 0.9601552145627745, 0.9589991424241208, 0.973294967559831, 0.9450972123184568, 0.9651991292837367, 0.9533719067668343, 0.9596891399742185, 0.9699562487702953, 0.9692796922465688, 0.9778146277576975, 0.9720129204428352, 0.9648666820261488, 0.9740647939599851, 0.9679135150928185, 0.9707198642529077, 0.9744063626784275, 0.9738588659850725, 0.9605784457794848, 0.974652566322754, 0.9655225227945067, 0.974549763035789, 0.9770324038136052, 0.9595876552224727, 0.9757450817657766, 0.9710722677602509, 0.9788630681517801, 0.9617806263136849, 0.9724663006738492, 0.9726794309857025, 0.9808211445586236, 0.9893784750739741, 0.9802641593958187, 0.9788069548160547, 0.9869649310145573, 0.9893497695066736, 0.9789897442036817, 0.9936449133256228, 0.9936234034300098, 0.9860739335186315, 0.9867279361459034, 0.9924076343451654, 1.0037168728241295, 0.993173439104282, 1.0018726756518908, 1.0122572994177867, 0.9893269104033332, 0.9838595468574836, 0.9850623485686049, 0.9892085608080273, 0.9995237468043873, 1.0022032156349043, 1.0006805870764546, 0.9887079870041716, 0.9872464451342543, 0.9938481470200062, 0.9950100914196189, 0.994873964853182, 1.0074739859671444, 1.0036764327821635, 0.9968213994055215, 1.0057405715503167, 1.0043640686478716, 1.002854583462861, 1.0141498620872, 1.01440652011961, 1.0175851525838737, 1.0034228839546435, 1.0115455983464676, 1.0028686886200082, 1.011642258615073, 1.0169128007858184, 1.0163027125501958, 1.014652758694801, 1.0021293392263355], 'val_accuracy': [0.6574860215187073, 0.7223027348518372, 0.7562642097473145, 0.7755228877067566, 0.7757299542427063, 0.7844274044036865, 0.7881549000740051, 0.7912611365318298, 0.7918823957443237, 0.7906398773193359, 0.7931248545646667, 0.7983019351959229, 0.7966452836990356, 0.7964381575584412, 0.7991302609443665, 0.7993373274803162, 0.8016152381896973, 0.8012011051177979, 0.7995443940162659, 0.7993373274803162, 0.7991302609443665, 0.8020294308662415, 0.8053427338600159, 0.8053427338600159, 0.8057568669319153, 0.8030648231506348, 0.8041002154350281, 0.8032718896865845, 0.8043072819709778, 0.8072064518928528, 0.8036860823631287, 0.8043072819709778, 0.8063781261444092, 0.8045144081115723, 0.8036860823631287, 0.8041002154350281, 0.8001656532287598, 0.8057568669319153, 0.8043072819709778, 0.8053427338600159, 0.8055498003959656, 0.8051356673240662, 0.8057568669319153, 0.807620644569397, 0.8059639930725098, 0.80886310338974, 0.8034789562225342, 0.8041002154350281, 0.8074135184288025, 0.8053427338600159, 0.807620644569397, 0.8092772960662842, 0.8127976655960083, 0.8086560368537903, 0.8094843626022339, 0.8086560368537903, 0.8067923188209534, 0.8090702295303345, 0.8098985552787781, 0.8065851926803589, 0.8090702295303345, 0.8101056218147278, 0.8057568669319153, 0.8074135184288025, 0.8086560368537903, 0.80886310338974, 0.8090702295303345, 0.8096914291381836, 0.8101056218147278, 0.8094843626022339, 0.8080347776412964, 0.8101056218147278, 0.8080347776412964, 0.8115552067756653, 0.8109339475631714, 0.8090702295303345, 0.8082418441772461, 0.8119693398475647, 0.8090702295303345, 0.8092772960662842, 0.8105197548866272, 0.8086560368537903, 0.8103126883506775, 0.8084489703178406, 0.8101056218147278, 0.8084489703178406, 0.8078277111053467, 0.8090702295303345, 0.8080347776412964, 0.8086560368537903, 0.8078277111053467, 0.8090702295303345, 0.8111410140991211, 0.8084489703178406, 0.8107268810272217, 0.8121764063835144, 0.8101056218147278, 0.8103126883506775, 0.8098985552787781, 0.8101056218147278], 'loss': [2.5374487358968714, 1.0008499024817048, 0.5471898034375466, 0.32098619668268424, 0.194401408214656, 0.1300216093103848, 0.09641829772536777, 0.0720185466672432, 0.06255511457429212, 0.04769689317209323, 0.040017749194453944, 0.033111737110492305, 0.02939603837436897, 0.026343963637503593, 0.021518585865494627, 0.02461268417166844, 0.01933787708952344, 0.019616523063135917, 0.017601020796982187, 0.013992902335912211, 0.013816663637362241, 0.013006416500901747, 0.011902800962551132, 0.011852419516187417, 0.010603230173430268, 0.01020676027921699, 0.010202742408569084, 0.009710468896398476, 0.0077625861425761385, 0.008750287379202214, 0.008139123499714448, 0.008232921942167274, 0.007111370688892265, 0.005937067823648119, 0.006999405923661372, 0.007206103497114597, 0.006642015963173977, 0.0057537145567355735, 0.006368894709463987, 0.005521150114510113, 0.004787451428667563, 0.005688417496509979, 0.005148533653767275, 0.005457268673181997, 0.005040697612612205, 0.00410620212229316, 0.004623662016231817, 0.0038445941591133807, 0.004435705904507054, 0.003872624730290853, 0.0042885696117969906, 0.004451296683640066, 0.0038083681648453604, 0.004529425936852147, 0.0034269194065920344, 0.003207495906363244, 0.00410269924795198, 0.004004838965931952, 0.0036483711611082917, 0.0034119565703064304, 0.003832511943529646, 0.003277467269189625, 0.0034380378331811583, 0.003410963508838289, 0.004113875219251963, 0.0033109855682642354, 0.0030400911849547663, 0.00293913143555778, 0.00295215300241888, 0.002941054228366088, 0.0028040859325115307, 0.003161324243957845, 0.003389276217672335, 0.0029201128037049193, 0.0025525346736700676, 0.0026441859881923702, 0.002616238769517275, 0.00247746226246613, 0.0026499625454929157, 0.0025434075660275197, 0.0027628011260102192, 0.0025077133683307218, 0.0026464951093452915, 0.0023700822656028985, 0.002232864872402378, 0.00259072797957618, 0.0022093207286416174, 0.00207880784959209, 0.0020400285097757274, 0.0017672404266859912, 0.0022277044546219434, 0.0017552067919780114, 0.002050678288788236, 0.002023181512050235, 0.0018794751393723717, 0.0020489433265075876, 0.002113109457261425, 0.002544118649910367, 0.001962878389811404, 0.002284582081093054], 'accuracy': [0.45044532, 0.7282519, 0.84579533, 0.9071044, 0.9488401, 0.96649754, 0.9761806, 0.98260146, 0.98544943, 0.98876345, 0.99176675, 0.9930095, 0.9944076, 0.9947183, 0.99601287, 0.9947701, 0.9967896, 0.9962717, 0.9963235, 0.99798054, 0.9975663, 0.99818766, 0.99803233, 0.99787694, 0.99813586, 0.99808407, 0.9983948, 0.99803233, 0.99886084, 0.99813586, 0.9986537, 0.9985501, 0.99901617, 0.9992233, 0.9984983, 0.99886084, 0.99880904, 0.9991715, 0.99870545, 0.9993268, 0.99953395, 0.99906796, 0.99901617, 0.9991715, 0.9992751, 0.9994822, 0.9994822, 0.99963754, 0.9993786, 0.9994822, 0.9993786, 0.9993786, 0.9994822, 0.9992233, 0.9994304, 0.9994304, 0.9992751, 0.9994304, 0.9991715, 0.99958575, 0.9991715, 0.9994822, 0.9994304, 0.9994304, 0.9992233, 0.9994822, 0.99953395, 0.99963754, 0.9994304, 0.99953395, 0.99968934, 0.9994822, 0.9993268, 0.99958575, 0.99963754, 0.99953395, 0.99958575, 0.99953395, 0.99958575, 0.99953395, 0.99953395, 0.99963754, 0.99953395, 0.9997411, 0.9997411, 0.99958575, 0.99958575, 0.9997929, 0.9997411, 0.9998447, 0.9997411, 0.9997929, 0.9997411, 0.99963754, 0.9997929, 0.99963754, 0.99968934, 0.9994822, 0.9997411, 0.99953395]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = np.arange(0, len(history.history['loss']))\n",
    "\n",
    "# You can chose the style of your preference\n",
    "# print(plt.style.available) to see the available options\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "plt.figure()\n",
    "plt.plot(N, history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(N, history.history['accuracy'], label = \"train_acc\")\n",
    "plt.plot(N, history.history['val_loss'], label = \"val_loss\")\n",
    "plt.plot(N, history.history['val_accuracy'], label = \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# Make sure there exists a folder called output in the current directory\n",
    "# or replace 'output' with whatever direcory you want to put in the plots\n",
    "plt.show()\n",
    "plt.savefig('../Output/EpochResNet101V2.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
