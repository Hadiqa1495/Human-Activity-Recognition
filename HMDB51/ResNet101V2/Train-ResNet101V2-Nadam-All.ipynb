{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet_v2 import ResNet101V2\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24136</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24137</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24138</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24139</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24140</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image class\n",
       "24136  winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg  wave\n",
       "24137  winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg  wave\n",
       "24138  winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg  wave\n",
       "24139  winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg  wave\n",
       "24140  winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg  wave"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_2.csv')\n",
    "train.sort_values(by=['class', 'image'])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24141/24141 [04:11<00:00, 95.90it/s] \n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/train_frame/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24141, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X = np.array(train_image,np.float16)\n",
    "train_image=[]\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 224, 224, 3)\n",
      "(4829, 224, 224, 3)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained ResNet101V2 model\n",
    "base_model = ResNet101V2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet101v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, None, None, 6 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, None, None, 6 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, None, None, 2 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, None, None, 2 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, None, None, 2 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, None, None, 2 0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, None, None, 2 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, None, None, 5 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, None, None, 5 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, None, None, 5 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, None, None, 5 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, None, None, 5 0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, None, None, 5 0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, None, None, 1 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, None, None, 1 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, None, None, 1 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, None, None, 1 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, None, None, 1 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, None, None, 1 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, None, None, 1 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block7_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, None, None, 2 0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, None, None, 2 0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, None, None, 1 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, None, None, 1 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, None, None, 2 0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, None, None, 2 0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, None, None, 1 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, None, None, 1 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, None, None, 2 0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, None, None, 2 0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, None, None, 1 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, None, None, 1 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, None, None, 1 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, None, None, 2 0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, None, None, 2 0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block10_2_relu[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, None, None, 1 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, None, None, 1 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, None, None, 1 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, None, None, 2 0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, None, None, 2 0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, None, None, 1 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, None, None, 1 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, None, None, 1 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, None, None, 2 0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, None, None, 2 0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, None, None, 1 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, None, None, 1 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, None, None, 1 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, None, None, 2 0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, None, None, 2 0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, None, None, 1 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, None, None, 1 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, None, None, 1 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, None, None, 2 0           conv4_block14_1_bn[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, None, None, 2 0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, None, None, 1 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, None, None, 1 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, None, None, 1 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, None, None, 2 0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, None, None, 2 0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, None, None, 1 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, None, None, 1 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, None, None, 1 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, None, None, 2 0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, None, None, 2 0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, None, None, 1 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, None, None, 1 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, None, None, 1 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, None, None, 2 0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, None, None, 2 0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, None, None, 1 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, None, None, 1 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, None, None, 1 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, None, None, 2 0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, None, None, 2 0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, None, None, 1 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, None, None, 1 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, None, None, 1 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, None, None, 2 0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, None, None, 2 0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, None, None, 1 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, None, None, 1 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, None, None, 1 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, None, None, 2 0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, None, None, 2 0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, None, None, 1 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, None, None, 1 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, None, None, 1 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, None, None, 2 0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block21_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, None, None, 2 0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, None, None, 1 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, None, None, 1 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, None, None, 1 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, None, None, 2 0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, None, None, 2 0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, None, None, 1 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, None, None, 1 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, None, None, 1 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, None, None, 2 0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, None, None, 2 0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, None, None, 1 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, None, None, 1 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, None, None, 2 0           conv5_block1_0_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, None, None, 2 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, None, None, 2 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, None, None, 2 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, None, None, 2 0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 42,626,560\n",
      "Trainable params: 42,528,896\n",
      "Non-trainable params: 97,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'resnet101v2',\n",
       " 'layers': [{'name': 'input_1',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_1'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'conv1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((3, 3), (3, 3)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (7, 7),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'pool1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pool',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'pool1_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool1_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_0_conv', 0, 0, {}],\n",
       "     ['conv2_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}],\n",
       "     ['conv2_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_1',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_1', 0, 0, {}],\n",
       "     ['conv2_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_0_conv', 0, 0, {}],\n",
       "     ['conv3_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}],\n",
       "     ['conv3_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}],\n",
       "     ['conv3_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_2',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}],\n",
       "     ['conv3_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_0_conv', 0, 0, {}],\n",
       "     ['conv4_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}],\n",
       "     ['conv4_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}],\n",
       "     ['conv4_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}],\n",
       "     ['conv4_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block5_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block5_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}],\n",
       "     ['conv4_block5_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block6_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block6_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}],\n",
       "     ['conv4_block6_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block7_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block7_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}],\n",
       "     ['conv4_block7_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block8_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block8_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}],\n",
       "     ['conv4_block8_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block9_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block9_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}],\n",
       "     ['conv4_block9_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block10_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block10_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}],\n",
       "     ['conv4_block10_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block11_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block11_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}],\n",
       "     ['conv4_block11_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block12_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block12_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}],\n",
       "     ['conv4_block12_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block13_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block13_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}],\n",
       "     ['conv4_block13_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block14_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block14_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}],\n",
       "     ['conv4_block14_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block15_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block15_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}],\n",
       "     ['conv4_block15_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block16_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block16_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}],\n",
       "     ['conv4_block16_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block17_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block17_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}],\n",
       "     ['conv4_block17_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block18_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block18_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}],\n",
       "     ['conv4_block18_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block19_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block19_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}],\n",
       "     ['conv4_block19_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block20_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block20_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}],\n",
       "     ['conv4_block20_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block21_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block21_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}],\n",
       "     ['conv4_block21_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block22_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block22_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}],\n",
       "     ['conv4_block22_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block23_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_3',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block23_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_3', 0, 0, {}],\n",
       "     ['conv4_block23_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_0_conv', 0, 0, {}],\n",
       "     ['conv5_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}],\n",
       "     ['conv5_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}],\n",
       "     ['conv5_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'post_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'post_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'post_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'post_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['post_bn', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['post_relu', 0, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1=datetime.datetime.now()\n",
    "print(t1)\n",
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "print(X_train.shape)\n",
    "t2=datetime.datetime.now()\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(19312, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(X_train, '../Pickle/ResNet101V2_X_train_2.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t3=datetime.datetime.now()\n",
    "print(t3)\n",
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "print(X_test.shape)\n",
    "t4=datetime.datetime.now()\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test = X_test.reshape(4829, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib.dump(X_test, '../Pickle/ResNet101V2_X_test_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "X_train = joblib.load('../Pickle/ResNet101V2_X_train_2.pkl') \n",
    "X_test = joblib.load('../Pickle/ResNet101V2_X_test_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 100352)\n",
      "(4829, 100352)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "# shape of images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 51)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 51)                52275     \n",
      "=================================================================\n",
      "Total params: 102,813,747\n",
      "Trainable params: 102,813,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('../Models/weightResNet101V2_8.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Nadam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-08 18:05:27.227280\n",
      "Train on 19312 samples, validate on 4829 samples\n",
      "Epoch 1/100\n",
      "19312/19312 [==============================] - ETA: 28:07 - loss: 9.1987 - accuracy: 0.031 - ETA: 18:10 - loss: 48.6683 - accuracy: 0.07 - ETA: 14:31 - loss: 65.8559 - accuracy: 0.08 - ETA: 13:28 - loss: 74.2749 - accuracy: 0.08 - ETA: 12:28 - loss: 80.6952 - accuracy: 0.08 - ETA: 11:41 - loss: 80.2847 - accuracy: 0.08 - ETA: 10:53 - loss: 75.8770 - accuracy: 0.09 - ETA: 10:19 - loss: 70.1482 - accuracy: 0.09 - ETA: 9:53 - loss: 64.1430 - accuracy: 0.1120 - ETA: 9:18 - loss: 59.0597 - accuracy: 0.119 - ETA: 8:53 - loss: 54.4528 - accuracy: 0.129 - ETA: 8:30 - loss: 50.5510 - accuracy: 0.136 - ETA: 8:07 - loss: 47.1067 - accuracy: 0.144 - ETA: 7:57 - loss: 44.0487 - accuracy: 0.150 - ETA: 7:48 - loss: 41.3866 - accuracy: 0.154 - ETA: 7:40 - loss: 39.0118 - accuracy: 0.159 - ETA: 7:34 - loss: 36.9403 - accuracy: 0.161 - ETA: 7:28 - loss: 35.0696 - accuracy: 0.164 - ETA: 7:21 - loss: 33.3977 - accuracy: 0.166 - ETA: 7:17 - loss: 31.8987 - accuracy: 0.167 - ETA: 7:10 - loss: 30.5425 - accuracy: 0.170 - ETA: 7:04 - loss: 29.2976 - accuracy: 0.174 - ETA: 6:59 - loss: 28.1795 - accuracy: 0.174 - ETA: 6:53 - loss: 27.1346 - accuracy: 0.181 - ETA: 6:48 - loss: 26.1794 - accuracy: 0.182 - ETA: 6:45 - loss: 25.2910 - accuracy: 0.186 - ETA: 6:41 - loss: 24.4757 - accuracy: 0.188 - ETA: 6:38 - loss: 23.7191 - accuracy: 0.190 - ETA: 6:34 - loss: 23.0118 - accuracy: 0.191 - ETA: 6:30 - loss: 22.3473 - accuracy: 0.192 - ETA: 6:26 - loss: 21.7278 - accuracy: 0.194 - ETA: 6:23 - loss: 21.1429 - accuracy: 0.196 - ETA: 6:20 - loss: 20.6063 - accuracy: 0.195 - ETA: 6:17 - loss: 20.0881 - accuracy: 0.198 - ETA: 6:12 - loss: 19.6073 - accuracy: 0.199 - ETA: 6:07 - loss: 19.1418 - accuracy: 0.202 - ETA: 6:02 - loss: 18.7142 - accuracy: 0.203 - ETA: 5:56 - loss: 18.3064 - accuracy: 0.205 - ETA: 5:53 - loss: 17.9225 - accuracy: 0.206 - ETA: 5:51 - loss: 17.5632 - accuracy: 0.207 - ETA: 5:48 - loss: 17.2095 - accuracy: 0.207 - ETA: 5:43 - loss: 16.8664 - accuracy: 0.209 - ETA: 5:40 - loss: 16.5614 - accuracy: 0.210 - ETA: 5:38 - loss: 16.2619 - accuracy: 0.210 - ETA: 5:34 - loss: 15.9733 - accuracy: 0.211 - ETA: 5:31 - loss: 15.6957 - accuracy: 0.212 - ETA: 5:28 - loss: 15.4295 - accuracy: 0.215 - ETA: 5:25 - loss: 15.1754 - accuracy: 0.217 - ETA: 5:21 - loss: 14.9272 - accuracy: 0.218 - ETA: 5:16 - loss: 14.6885 - accuracy: 0.220 - ETA: 5:13 - loss: 14.4621 - accuracy: 0.222 - ETA: 5:09 - loss: 14.2438 - accuracy: 0.224 - ETA: 5:06 - loss: 14.0336 - accuracy: 0.226 - ETA: 5:05 - loss: 13.8233 - accuracy: 0.228 - ETA: 5:03 - loss: 13.6309 - accuracy: 0.229 - ETA: 5:00 - loss: 13.4439 - accuracy: 0.231 - ETA: 4:56 - loss: 13.2563 - accuracy: 0.233 - ETA: 4:53 - loss: 13.0788 - accuracy: 0.234 - ETA: 4:50 - loss: 12.9100 - accuracy: 0.236 - ETA: 4:47 - loss: 12.7571 - accuracy: 0.236 - ETA: 4:44 - loss: 12.5956 - accuracy: 0.237 - ETA: 4:41 - loss: 12.4319 - accuracy: 0.240 - ETA: 4:39 - loss: 12.2830 - accuracy: 0.242 - ETA: 4:36 - loss: 12.1382 - accuracy: 0.242 - ETA: 4:33 - loss: 11.9954 - accuracy: 0.244 - ETA: 4:30 - loss: 11.8592 - accuracy: 0.244 - ETA: 4:27 - loss: 11.7276 - accuracy: 0.245 - ETA: 4:25 - loss: 11.5982 - accuracy: 0.246 - ETA: 4:22 - loss: 11.4693 - accuracy: 0.248 - ETA: 4:19 - loss: 11.3486 - accuracy: 0.249 - ETA: 4:16 - loss: 11.2311 - accuracy: 0.250 - ETA: 4:13 - loss: 11.1153 - accuracy: 0.251 - ETA: 4:11 - loss: 11.0022 - accuracy: 0.252 - ETA: 4:08 - loss: 10.8956 - accuracy: 0.253 - ETA: 4:05 - loss: 10.7888 - accuracy: 0.254 - ETA: 4:02 - loss: 10.6889 - accuracy: 0.254 - ETA: 3:59 - loss: 10.5885 - accuracy: 0.254 - ETA: 3:57 - loss: 10.4863 - accuracy: 0.255 - ETA: 3:53 - loss: 10.3850 - accuracy: 0.257 - ETA: 3:51 - loss: 10.2967 - accuracy: 0.258 - ETA: 3:50 - loss: 10.2083 - accuracy: 0.259 - ETA: 3:46 - loss: 10.1190 - accuracy: 0.260 - ETA: 3:43 - loss: 10.0317 - accuracy: 0.261 - ETA: 3:40 - loss: 9.9468 - accuracy: 0.262 - ETA: 3:37 - loss: 9.8664 - accuracy: 0.26 - ETA: 3:33 - loss: 9.7862 - accuracy: 0.26 - ETA: 3:30 - loss: 9.7045 - accuracy: 0.26 - ETA: 3:27 - loss: 9.6306 - accuracy: 0.26 - ETA: 3:24 - loss: 9.5550 - accuracy: 0.26 - ETA: 3:21 - loss: 9.4804 - accuracy: 0.26 - ETA: 3:17 - loss: 9.4090 - accuracy: 0.26 - ETA: 3:14 - loss: 9.3378 - accuracy: 0.27 - ETA: 3:11 - loss: 9.2699 - accuracy: 0.27 - ETA: 3:08 - loss: 9.1996 - accuracy: 0.27 - ETA: 3:04 - loss: 9.1296 - accuracy: 0.27 - ETA: 3:01 - loss: 9.0650 - accuracy: 0.27 - ETA: 2:58 - loss: 9.0020 - accuracy: 0.27 - ETA: 2:55 - loss: 8.9410 - accuracy: 0.27 - ETA: 2:52 - loss: 8.8810 - accuracy: 0.27 - ETA: 2:48 - loss: 8.8196 - accuracy: 0.27 - ETA: 2:45 - loss: 8.7578 - accuracy: 0.27 - ETA: 2:42 - loss: 8.7026 - accuracy: 0.27 - ETA: 2:38 - loss: 8.6467 - accuracy: 0.27 - ETA: 2:35 - loss: 8.5899 - accuracy: 0.27 - ETA: 2:32 - loss: 8.5321 - accuracy: 0.27 - ETA: 2:29 - loss: 8.4782 - accuracy: 0.27 - ETA: 2:26 - loss: 8.4227 - accuracy: 0.28 - ETA: 2:26 - loss: 8.3718 - accuracy: 0.28 - ETA: 2:23 - loss: 8.3190 - accuracy: 0.28 - ETA: 2:21 - loss: 8.2709 - accuracy: 0.28 - ETA: 2:17 - loss: 8.2229 - accuracy: 0.28 - ETA: 2:14 - loss: 8.1779 - accuracy: 0.28 - ETA: 2:10 - loss: 8.1309 - accuracy: 0.28 - ETA: 2:07 - loss: 8.0892 - accuracy: 0.28 - ETA: 2:03 - loss: 8.0416 - accuracy: 0.28 - ETA: 2:00 - loss: 7.9944 - accuracy: 0.28 - ETA: 1:56 - loss: 7.9498 - accuracy: 0.28 - ETA: 1:53 - loss: 7.9048 - accuracy: 0.28 - ETA: 1:49 - loss: 7.8634 - accuracy: 0.28 - ETA: 1:46 - loss: 7.8221 - accuracy: 0.28 - ETA: 1:43 - loss: 7.7806 - accuracy: 0.29 - ETA: 1:39 - loss: 7.7388 - accuracy: 0.29 - ETA: 1:36 - loss: 7.6989 - accuracy: 0.29 - ETA: 1:32 - loss: 7.6611 - accuracy: 0.29 - ETA: 1:29 - loss: 7.6195 - accuracy: 0.29 - ETA: 1:26 - loss: 7.5825 - accuracy: 0.29 - ETA: 1:22 - loss: 7.5415 - accuracy: 0.29 - ETA: 1:19 - loss: 7.5048 - accuracy: 0.29 - ETA: 1:15 - loss: 7.4668 - accuracy: 0.29 - ETA: 1:12 - loss: 7.4284 - accuracy: 0.29 - ETA: 1:09 - loss: 7.3954 - accuracy: 0.29 - ETA: 1:05 - loss: 7.3608 - accuracy: 0.29 - ETA: 1:02 - loss: 7.3315 - accuracy: 0.29 - ETA: 58s - loss: 7.2944 - accuracy: 0.2984 - ETA: 55s - loss: 7.2627 - accuracy: 0.299 - ETA: 51s - loss: 7.2282 - accuracy: 0.299 - ETA: 48s - loss: 7.1953 - accuracy: 0.299 - ETA: 44s - loss: 7.1658 - accuracy: 0.300 - ETA: 41s - loss: 7.1357 - accuracy: 0.299 - ETA: 37s - loss: 7.1041 - accuracy: 0.300 - ETA: 34s - loss: 7.0724 - accuracy: 0.301 - ETA: 30s - loss: 7.0421 - accuracy: 0.301 - ETA: 27s - loss: 7.0140 - accuracy: 0.302 - ETA: 23s - loss: 6.9858 - accuracy: 0.302 - ETA: 20s - loss: 6.9565 - accuracy: 0.302 - ETA: 16s - loss: 6.9300 - accuracy: 0.303 - ETA: 13s - loss: 6.9012 - accuracy: 0.303 - ETA: 9s - loss: 6.8742 - accuracy: 0.304 - ETA: 6s - loss: 6.8474 - accuracy: 0.30 - ETA: 3s - loss: 6.8223 - accuracy: 0.30 - 576s 30ms/step - loss: 6.7987 - accuracy: 0.3053 - val_loss: 2.1431 - val_accuracy: 0.5055\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 9:36 - loss: 2.7262 - accuracy: 0.35 - ETA: 8:41 - loss: 2.8023 - accuracy: 0.36 - ETA: 8:25 - loss: 4.2415 - accuracy: 0.34 - ETA: 8:09 - loss: 3.8570 - accuracy: 0.35 - ETA: 8:12 - loss: 3.5912 - accuracy: 0.37 - ETA: 8:09 - loss: 3.6347 - accuracy: 0.36 - ETA: 8:09 - loss: 3.4285 - accuracy: 0.38 - ETA: 7:56 - loss: 3.3477 - accuracy: 0.38 - ETA: 7:49 - loss: 3.2992 - accuracy: 0.38 - ETA: 7:49 - loss: 3.1608 - accuracy: 0.39 - ETA: 7:48 - loss: 3.0925 - accuracy: 0.39 - ETA: 7:46 - loss: 3.0122 - accuracy: 0.40 - ETA: 7:45 - loss: 2.9703 - accuracy: 0.41 - ETA: 7:42 - loss: 2.9529 - accuracy: 0.40 - ETA: 7:39 - loss: 2.9165 - accuracy: 0.40 - ETA: 7:36 - loss: 2.8733 - accuracy: 0.41 - ETA: 7:32 - loss: 2.8462 - accuracy: 0.41 - ETA: 7:28 - loss: 2.8623 - accuracy: 0.41 - ETA: 7:24 - loss: 2.8363 - accuracy: 0.41 - ETA: 7:21 - loss: 2.8249 - accuracy: 0.41 - ETA: 7:20 - loss: 2.8152 - accuracy: 0.41 - ETA: 7:18 - loss: 2.7925 - accuracy: 0.41 - ETA: 7:14 - loss: 2.7849 - accuracy: 0.41 - ETA: 7:11 - loss: 2.7732 - accuracy: 0.41 - ETA: 7:08 - loss: 2.7656 - accuracy: 0.41 - ETA: 7:04 - loss: 2.7503 - accuracy: 0.41 - ETA: 7:01 - loss: 2.7405 - accuracy: 0.41 - ETA: 6:56 - loss: 2.7332 - accuracy: 0.41 - ETA: 6:53 - loss: 2.7154 - accuracy: 0.41 - ETA: 6:49 - loss: 2.7106 - accuracy: 0.41 - ETA: 6:45 - loss: 2.7116 - accuracy: 0.41 - ETA: 6:41 - loss: 2.6955 - accuracy: 0.41 - ETA: 6:37 - loss: 2.6865 - accuracy: 0.41 - ETA: 6:35 - loss: 2.6746 - accuracy: 0.41 - ETA: 6:30 - loss: 2.6791 - accuracy: 0.41 - ETA: 6:29 - loss: 2.6747 - accuracy: 0.41 - ETA: 6:28 - loss: 2.6759 - accuracy: 0.41 - ETA: 6:24 - loss: 2.6662 - accuracy: 0.41 - ETA: 6:20 - loss: 2.6576 - accuracy: 0.41 - ETA: 6:18 - loss: 2.6412 - accuracy: 0.42 - ETA: 6:13 - loss: 2.6324 - accuracy: 0.42 - ETA: 6:09 - loss: 2.6263 - accuracy: 0.42 - ETA: 6:06 - loss: 2.6190 - accuracy: 0.42 - ETA: 6:02 - loss: 2.6253 - accuracy: 0.42 - ETA: 5:57 - loss: 2.6280 - accuracy: 0.42 - ETA: 5:54 - loss: 2.6227 - accuracy: 0.42 - ETA: 5:51 - loss: 2.6282 - accuracy: 0.42 - ETA: 5:47 - loss: 2.6286 - accuracy: 0.42 - ETA: 5:44 - loss: 2.6216 - accuracy: 0.42 - ETA: 5:41 - loss: 2.6239 - accuracy: 0.41 - ETA: 5:37 - loss: 2.6199 - accuracy: 0.41 - ETA: 5:33 - loss: 2.6672 - accuracy: 0.41 - ETA: 5:30 - loss: 2.6644 - accuracy: 0.41 - ETA: 5:26 - loss: 2.6619 - accuracy: 0.41 - ETA: 5:22 - loss: 2.6617 - accuracy: 0.41 - ETA: 5:18 - loss: 2.6612 - accuracy: 0.41 - ETA: 5:14 - loss: 2.6612 - accuracy: 0.41 - ETA: 5:11 - loss: 2.7015 - accuracy: 0.41 - ETA: 5:07 - loss: 2.6934 - accuracy: 0.41 - ETA: 5:04 - loss: 2.6997 - accuracy: 0.41 - ETA: 5:01 - loss: 2.6910 - accuracy: 0.41 - ETA: 4:57 - loss: 2.6847 - accuracy: 0.41 - ETA: 4:53 - loss: 2.6830 - accuracy: 0.41 - ETA: 4:50 - loss: 2.6785 - accuracy: 0.41 - ETA: 4:46 - loss: 2.6790 - accuracy: 0.41 - ETA: 4:42 - loss: 2.6779 - accuracy: 0.41 - ETA: 4:39 - loss: 2.6743 - accuracy: 0.41 - ETA: 4:35 - loss: 2.6680 - accuracy: 0.41 - ETA: 4:32 - loss: 2.6626 - accuracy: 0.41 - ETA: 4:29 - loss: 2.6580 - accuracy: 0.41 - ETA: 4:26 - loss: 2.6524 - accuracy: 0.41 - ETA: 4:22 - loss: 2.6551 - accuracy: 0.41 - ETA: 4:18 - loss: 2.6560 - accuracy: 0.41 - ETA: 4:15 - loss: 2.6697 - accuracy: 0.41 - ETA: 4:11 - loss: 2.6636 - accuracy: 0.41 - ETA: 4:08 - loss: 2.6677 - accuracy: 0.41 - ETA: 4:05 - loss: 2.6677 - accuracy: 0.41 - ETA: 4:01 - loss: 2.6641 - accuracy: 0.41 - ETA: 3:58 - loss: 2.6692 - accuracy: 0.41 - ETA: 3:56 - loss: 2.6701 - accuracy: 0.41 - ETA: 3:52 - loss: 2.6662 - accuracy: 0.41 - ETA: 3:49 - loss: 2.6605 - accuracy: 0.41 - ETA: 3:45 - loss: 2.6553 - accuracy: 0.41 - ETA: 3:42 - loss: 2.6467 - accuracy: 0.41 - ETA: 3:38 - loss: 2.6464 - accuracy: 0.42 - ETA: 3:35 - loss: 2.6399 - accuracy: 0.42 - ETA: 3:32 - loss: 2.6376 - accuracy: 0.42 - ETA: 3:28 - loss: 2.6325 - accuracy: 0.42 - ETA: 3:25 - loss: 2.6307 - accuracy: 0.42 - ETA: 3:21 - loss: 2.6291 - accuracy: 0.42 - ETA: 3:18 - loss: 2.6296 - accuracy: 0.42 - ETA: 3:14 - loss: 2.6280 - accuracy: 0.42 - ETA: 3:11 - loss: 2.6227 - accuracy: 0.42 - ETA: 3:08 - loss: 2.6199 - accuracy: 0.42 - ETA: 3:04 - loss: 2.6160 - accuracy: 0.42 - ETA: 3:01 - loss: 2.6095 - accuracy: 0.42 - ETA: 2:58 - loss: 2.6061 - accuracy: 0.42 - ETA: 2:54 - loss: 2.6039 - accuracy: 0.42 - ETA: 2:51 - loss: 2.6019 - accuracy: 0.42 - ETA: 2:48 - loss: 2.6026 - accuracy: 0.42 - ETA: 2:44 - loss: 2.6019 - accuracy: 0.42 - ETA: 2:41 - loss: 2.5973 - accuracy: 0.42 - ETA: 2:37 - loss: 2.5953 - accuracy: 0.42 - ETA: 2:34 - loss: 2.5951 - accuracy: 0.42 - ETA: 2:31 - loss: 2.5937 - accuracy: 0.42 - ETA: 2:27 - loss: 2.5955 - accuracy: 0.42 - ETA: 2:24 - loss: 2.5954 - accuracy: 0.42 - ETA: 2:21 - loss: 2.5924 - accuracy: 0.42 - ETA: 2:17 - loss: 2.5897 - accuracy: 0.42 - ETA: 2:14 - loss: 2.5858 - accuracy: 0.42 - ETA: 2:11 - loss: 2.5849 - accuracy: 0.42 - ETA: 2:07 - loss: 2.5826 - accuracy: 0.42 - ETA: 2:04 - loss: 2.5838 - accuracy: 0.42 - ETA: 2:01 - loss: 2.6007 - accuracy: 0.42 - ETA: 1:57 - loss: 2.5977 - accuracy: 0.42 - ETA: 1:54 - loss: 2.5950 - accuracy: 0.42 - ETA: 1:51 - loss: 2.5976 - accuracy: 0.42 - ETA: 1:47 - loss: 2.6107 - accuracy: 0.42 - ETA: 1:44 - loss: 2.6079 - accuracy: 0.42 - ETA: 1:41 - loss: 2.6019 - accuracy: 0.42 - ETA: 1:37 - loss: 2.5969 - accuracy: 0.42 - ETA: 1:34 - loss: 2.5976 - accuracy: 0.42 - ETA: 1:31 - loss: 2.5975 - accuracy: 0.42 - ETA: 1:28 - loss: 2.5986 - accuracy: 0.42 - ETA: 1:24 - loss: 2.5967 - accuracy: 0.42 - ETA: 1:21 - loss: 2.5963 - accuracy: 0.42 - ETA: 1:18 - loss: 2.5955 - accuracy: 0.42 - ETA: 1:15 - loss: 2.6015 - accuracy: 0.42 - ETA: 1:11 - loss: 2.5996 - accuracy: 0.42 - ETA: 1:09 - loss: 2.5980 - accuracy: 0.42 - ETA: 1:05 - loss: 2.5954 - accuracy: 0.42 - ETA: 1:02 - loss: 2.5939 - accuracy: 0.42 - ETA: 59s - loss: 2.5937 - accuracy: 0.4277 - ETA: 56s - loss: 2.5916 - accuracy: 0.427 - ETA: 52s - loss: 2.5896 - accuracy: 0.428 - ETA: 49s - loss: 2.5879 - accuracy: 0.428 - ETA: 46s - loss: 2.5873 - accuracy: 0.428 - ETA: 42s - loss: 2.5843 - accuracy: 0.428 - ETA: 39s - loss: 2.5861 - accuracy: 0.428 - ETA: 36s - loss: 2.5842 - accuracy: 0.428 - ETA: 32s - loss: 2.5842 - accuracy: 0.428 - ETA: 29s - loss: 2.5969 - accuracy: 0.428 - ETA: 26s - loss: 2.5986 - accuracy: 0.428 - ETA: 23s - loss: 2.5988 - accuracy: 0.428 - ETA: 19s - loss: 2.5964 - accuracy: 0.428 - ETA: 16s - loss: 2.5990 - accuracy: 0.428 - ETA: 13s - loss: 2.5972 - accuracy: 0.428 - ETA: 9s - loss: 2.5946 - accuracy: 0.429 - ETA: 6s - loss: 2.5965 - accuracy: 0.42 - ETA: 2s - loss: 2.5966 - accuracy: 0.42 - 567s 29ms/step - loss: 2.5950 - accuracy: 0.4287 - val_loss: 1.8712 - val_accuracy: 0.5523\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 9:10 - loss: 2.4861 - accuracy: 0.51 - ETA: 8:44 - loss: 2.4726 - accuracy: 0.46 - ETA: 8:38 - loss: 2.4822 - accuracy: 0.44 - ETA: 8:28 - loss: 2.5239 - accuracy: 0.44 - ETA: 8:24 - loss: 2.5009 - accuracy: 0.45 - ETA: 8:14 - loss: 2.4232 - accuracy: 0.45 - ETA: 8:08 - loss: 2.4204 - accuracy: 0.45 - ETA: 8:02 - loss: 2.3703 - accuracy: 0.46 - ETA: 7:56 - loss: 2.3698 - accuracy: 0.46 - ETA: 7:54 - loss: 2.3687 - accuracy: 0.45 - ETA: 7:50 - loss: 2.3446 - accuracy: 0.46 - ETA: 7:47 - loss: 2.4455 - accuracy: 0.45 - ETA: 7:43 - loss: 2.4563 - accuracy: 0.46 - ETA: 7:41 - loss: 2.4751 - accuracy: 0.46 - ETA: 7:36 - loss: 2.4603 - accuracy: 0.46 - ETA: 7:31 - loss: 2.4568 - accuracy: 0.46 - ETA: 7:28 - loss: 2.4477 - accuracy: 0.46 - ETA: 7:26 - loss: 2.4146 - accuracy: 0.47 - ETA: 7:23 - loss: 2.4033 - accuracy: 0.47 - ETA: 7:21 - loss: 2.3904 - accuracy: 0.47 - ETA: 7:19 - loss: 2.3850 - accuracy: 0.47 - ETA: 7:15 - loss: 2.3907 - accuracy: 0.47 - ETA: 7:12 - loss: 2.3889 - accuracy: 0.47 - ETA: 7:09 - loss: 2.3765 - accuracy: 0.47 - ETA: 7:06 - loss: 2.3728 - accuracy: 0.47 - ETA: 7:03 - loss: 2.3641 - accuracy: 0.47 - ETA: 6:58 - loss: 2.3729 - accuracy: 0.46 - ETA: 6:54 - loss: 2.3786 - accuracy: 0.46 - ETA: 6:51 - loss: 2.3933 - accuracy: 0.46 - ETA: 6:49 - loss: 2.3769 - accuracy: 0.46 - ETA: 6:45 - loss: 2.3601 - accuracy: 0.46 - ETA: 6:41 - loss: 2.3523 - accuracy: 0.47 - ETA: 6:39 - loss: 2.3583 - accuracy: 0.46 - ETA: 6:36 - loss: 2.3646 - accuracy: 0.46 - ETA: 6:33 - loss: 2.3606 - accuracy: 0.46 - ETA: 6:29 - loss: 2.3723 - accuracy: 0.46 - ETA: 6:25 - loss: 2.3786 - accuracy: 0.46 - ETA: 6:22 - loss: 2.3742 - accuracy: 0.46 - ETA: 6:18 - loss: 2.3665 - accuracy: 0.46 - ETA: 6:15 - loss: 2.3625 - accuracy: 0.46 - ETA: 6:11 - loss: 2.3555 - accuracy: 0.46 - ETA: 6:08 - loss: 2.3513 - accuracy: 0.46 - ETA: 6:05 - loss: 2.3453 - accuracy: 0.46 - ETA: 6:01 - loss: 2.3406 - accuracy: 0.46 - ETA: 5:58 - loss: 2.3335 - accuracy: 0.46 - ETA: 5:54 - loss: 2.3333 - accuracy: 0.46 - ETA: 5:51 - loss: 2.3316 - accuracy: 0.46 - ETA: 5:48 - loss: 2.3341 - accuracy: 0.46 - ETA: 5:45 - loss: 2.3351 - accuracy: 0.46 - ETA: 5:41 - loss: 2.3388 - accuracy: 0.46 - ETA: 5:37 - loss: 2.3363 - accuracy: 0.46 - ETA: 5:33 - loss: 2.3470 - accuracy: 0.46 - ETA: 5:30 - loss: 2.3440 - accuracy: 0.46 - ETA: 5:26 - loss: 2.3495 - accuracy: 0.46 - ETA: 5:22 - loss: 2.3458 - accuracy: 0.46 - ETA: 5:18 - loss: 2.3451 - accuracy: 0.46 - ETA: 5:15 - loss: 2.3541 - accuracy: 0.46 - ETA: 5:11 - loss: 2.3520 - accuracy: 0.46 - ETA: 5:08 - loss: 2.3485 - accuracy: 0.46 - ETA: 5:04 - loss: 2.3451 - accuracy: 0.46 - ETA: 5:01 - loss: 2.3510 - accuracy: 0.46 - ETA: 4:58 - loss: 2.3577 - accuracy: 0.46 - ETA: 4:54 - loss: 2.3534 - accuracy: 0.46 - ETA: 4:50 - loss: 2.3485 - accuracy: 0.46 - ETA: 4:47 - loss: 2.3453 - accuracy: 0.47 - ETA: 4:44 - loss: 2.3438 - accuracy: 0.47 - ETA: 4:41 - loss: 2.3451 - accuracy: 0.46 - ETA: 4:37 - loss: 2.3410 - accuracy: 0.47 - ETA: 4:34 - loss: 2.3454 - accuracy: 0.46 - ETA: 4:31 - loss: 2.3428 - accuracy: 0.46 - ETA: 4:27 - loss: 2.3383 - accuracy: 0.46 - ETA: 4:24 - loss: 2.3363 - accuracy: 0.46 - ETA: 4:21 - loss: 2.3319 - accuracy: 0.46 - ETA: 4:18 - loss: 2.3350 - accuracy: 0.46 - ETA: 4:14 - loss: 2.3354 - accuracy: 0.46 - ETA: 4:11 - loss: 2.3345 - accuracy: 0.46 - ETA: 4:07 - loss: 2.3342 - accuracy: 0.46 - ETA: 4:04 - loss: 2.3337 - accuracy: 0.46 - ETA: 4:00 - loss: 2.3403 - accuracy: 0.46 - ETA: 3:57 - loss: 2.3577 - accuracy: 0.46 - ETA: 3:54 - loss: 2.4722 - accuracy: 0.46 - ETA: 3:50 - loss: 2.4786 - accuracy: 0.46 - ETA: 3:47 - loss: 2.4891 - accuracy: 0.46 - ETA: 3:43 - loss: 2.4902 - accuracy: 0.46 - ETA: 3:40 - loss: 2.4864 - accuracy: 0.46 - ETA: 3:37 - loss: 2.4839 - accuracy: 0.46 - ETA: 3:34 - loss: 2.4835 - accuracy: 0.46 - ETA: 3:30 - loss: 2.4859 - accuracy: 0.46 - ETA: 3:27 - loss: 2.4810 - accuracy: 0.46 - ETA: 3:24 - loss: 2.4819 - accuracy: 0.46 - ETA: 3:20 - loss: 2.4837 - accuracy: 0.46 - ETA: 3:17 - loss: 2.4777 - accuracy: 0.46 - ETA: 3:13 - loss: 2.4730 - accuracy: 0.46 - ETA: 3:10 - loss: 2.4730 - accuracy: 0.46 - ETA: 3:07 - loss: 2.4807 - accuracy: 0.46 - ETA: 3:03 - loss: 2.4841 - accuracy: 0.46 - ETA: 3:00 - loss: 2.4853 - accuracy: 0.46 - ETA: 2:57 - loss: 2.4830 - accuracy: 0.46 - ETA: 2:53 - loss: 2.4844 - accuracy: 0.46 - ETA: 2:50 - loss: 2.4877 - accuracy: 0.46 - ETA: 2:47 - loss: 2.4911 - accuracy: 0.46 - ETA: 2:44 - loss: 2.4841 - accuracy: 0.46 - ETA: 2:40 - loss: 2.4797 - accuracy: 0.46 - ETA: 2:37 - loss: 2.4782 - accuracy: 0.46 - ETA: 2:34 - loss: 2.4761 - accuracy: 0.46 - ETA: 2:30 - loss: 2.4707 - accuracy: 0.46 - ETA: 2:27 - loss: 2.4680 - accuracy: 0.46 - ETA: 2:24 - loss: 2.4668 - accuracy: 0.46 - ETA: 2:20 - loss: 2.4645 - accuracy: 0.46 - ETA: 2:17 - loss: 2.4682 - accuracy: 0.46 - ETA: 2:14 - loss: 2.4652 - accuracy: 0.46 - ETA: 2:10 - loss: 2.4637 - accuracy: 0.46 - ETA: 2:07 - loss: 2.4731 - accuracy: 0.46 - ETA: 2:04 - loss: 2.4729 - accuracy: 0.46 - ETA: 2:00 - loss: 2.4725 - accuracy: 0.46 - ETA: 1:57 - loss: 2.4683 - accuracy: 0.46 - ETA: 1:54 - loss: 2.4675 - accuracy: 0.46 - ETA: 1:50 - loss: 2.4643 - accuracy: 0.46 - ETA: 1:47 - loss: 2.4631 - accuracy: 0.46 - ETA: 1:43 - loss: 2.4621 - accuracy: 0.46 - ETA: 1:40 - loss: 2.4622 - accuracy: 0.46 - ETA: 1:37 - loss: 2.4586 - accuracy: 0.46 - ETA: 1:33 - loss: 2.4571 - accuracy: 0.46 - ETA: 1:30 - loss: 2.4605 - accuracy: 0.46 - ETA: 1:26 - loss: 2.4621 - accuracy: 0.46 - ETA: 1:23 - loss: 2.4601 - accuracy: 0.46 - ETA: 1:20 - loss: 2.4592 - accuracy: 0.46 - ETA: 1:16 - loss: 2.4558 - accuracy: 0.46 - ETA: 1:13 - loss: 2.4532 - accuracy: 0.46 - ETA: 1:10 - loss: 2.4501 - accuracy: 0.46 - ETA: 1:06 - loss: 2.4461 - accuracy: 0.46 - ETA: 1:03 - loss: 2.4524 - accuracy: 0.46 - ETA: 59s - loss: 2.4525 - accuracy: 0.4693 - ETA: 56s - loss: 2.4507 - accuracy: 0.469 - ETA: 53s - loss: 2.4481 - accuracy: 0.470 - ETA: 49s - loss: 2.4487 - accuracy: 0.470 - ETA: 46s - loss: 2.4463 - accuracy: 0.470 - ETA: 43s - loss: 2.4459 - accuracy: 0.470 - ETA: 39s - loss: 2.4492 - accuracy: 0.469 - ETA: 36s - loss: 2.4464 - accuracy: 0.469 - ETA: 33s - loss: 2.4443 - accuracy: 0.469 - ETA: 29s - loss: 2.4418 - accuracy: 0.469 - ETA: 26s - loss: 2.4383 - accuracy: 0.470 - ETA: 23s - loss: 2.4364 - accuracy: 0.469 - ETA: 19s - loss: 2.4376 - accuracy: 0.469 - ETA: 16s - loss: 2.4385 - accuracy: 0.470 - ETA: 12s - loss: 2.4367 - accuracy: 0.470 - ETA: 9s - loss: 2.4332 - accuracy: 0.470 - ETA: 6s - loss: 2.4323 - accuracy: 0.47 - ETA: 2s - loss: 2.4310 - accuracy: 0.47 - 561s 29ms/step - loss: 2.4301 - accuracy: 0.4707 - val_loss: 1.8111 - val_accuracy: 0.5645\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 8:35 - loss: 2.1749 - accuracy: 0.50 - ETA: 8:24 - loss: 1.9590 - accuracy: 0.52 - ETA: 8:20 - loss: 2.0250 - accuracy: 0.51 - ETA: 8:07 - loss: 2.1685 - accuracy: 0.50 - ETA: 8:01 - loss: 2.1288 - accuracy: 0.50 - ETA: 7:54 - loss: 2.1922 - accuracy: 0.49 - ETA: 7:51 - loss: 2.2064 - accuracy: 0.49 - ETA: 7:48 - loss: 2.2141 - accuracy: 0.48 - ETA: 7:39 - loss: 2.2270 - accuracy: 0.48 - ETA: 7:39 - loss: 2.2733 - accuracy: 0.48 - ETA: 7:34 - loss: 2.2855 - accuracy: 0.47 - ETA: 7:27 - loss: 2.3117 - accuracy: 0.47 - ETA: 7:26 - loss: 2.3032 - accuracy: 0.48 - ETA: 7:22 - loss: 2.2882 - accuracy: 0.48 - ETA: 7:23 - loss: 2.2933 - accuracy: 0.47 - ETA: 7:19 - loss: 2.2978 - accuracy: 0.47 - ETA: 7:14 - loss: 2.2923 - accuracy: 0.47 - ETA: 7:11 - loss: 2.2742 - accuracy: 0.47 - ETA: 7:08 - loss: 2.2383 - accuracy: 0.47 - ETA: 7:06 - loss: 2.2409 - accuracy: 0.47 - ETA: 7:02 - loss: 2.2573 - accuracy: 0.47 - ETA: 6:58 - loss: 2.2536 - accuracy: 0.47 - ETA: 6:56 - loss: 2.2484 - accuracy: 0.47 - ETA: 6:53 - loss: 2.2385 - accuracy: 0.47 - ETA: 6:50 - loss: 2.2379 - accuracy: 0.48 - ETA: 6:47 - loss: 2.2394 - accuracy: 0.48 - ETA: 6:43 - loss: 2.2389 - accuracy: 0.48 - ETA: 6:40 - loss: 2.2446 - accuracy: 0.48 - ETA: 6:38 - loss: 2.2331 - accuracy: 0.48 - ETA: 6:34 - loss: 2.2401 - accuracy: 0.48 - ETA: 6:29 - loss: 2.2246 - accuracy: 0.48 - ETA: 6:26 - loss: 2.2200 - accuracy: 0.48 - ETA: 6:23 - loss: 2.2160 - accuracy: 0.48 - ETA: 6:20 - loss: 2.2243 - accuracy: 0.49 - ETA: 6:17 - loss: 2.2357 - accuracy: 0.48 - ETA: 6:14 - loss: 2.2531 - accuracy: 0.48 - ETA: 6:10 - loss: 2.2580 - accuracy: 0.48 - ETA: 6:08 - loss: 2.2513 - accuracy: 0.48 - ETA: 6:05 - loss: 2.2490 - accuracy: 0.48 - ETA: 6:02 - loss: 2.2493 - accuracy: 0.48 - ETA: 5:58 - loss: 2.2409 - accuracy: 0.48 - ETA: 5:58 - loss: 2.2378 - accuracy: 0.48 - ETA: 5:55 - loss: 2.2314 - accuracy: 0.48 - ETA: 5:51 - loss: 2.2325 - accuracy: 0.48 - ETA: 5:46 - loss: 2.2436 - accuracy: 0.48 - ETA: 5:44 - loss: 2.2362 - accuracy: 0.48 - ETA: 5:40 - loss: 2.2349 - accuracy: 0.48 - ETA: 5:36 - loss: 2.2351 - accuracy: 0.48 - ETA: 5:34 - loss: 2.2305 - accuracy: 0.48 - ETA: 5:30 - loss: 2.2269 - accuracy: 0.48 - ETA: 5:27 - loss: 2.2191 - accuracy: 0.48 - ETA: 5:24 - loss: 2.2143 - accuracy: 0.48 - ETA: 5:21 - loss: 2.2265 - accuracy: 0.48 - ETA: 5:18 - loss: 2.2217 - accuracy: 0.48 - ETA: 5:14 - loss: 2.2219 - accuracy: 0.48 - ETA: 5:11 - loss: 2.2201 - accuracy: 0.48 - ETA: 5:08 - loss: 2.2151 - accuracy: 0.48 - ETA: 5:09 - loss: 2.2195 - accuracy: 0.48 - ETA: 5:06 - loss: 2.2082 - accuracy: 0.49 - ETA: 5:02 - loss: 2.2042 - accuracy: 0.49 - ETA: 5:00 - loss: 2.2024 - accuracy: 0.49 - ETA: 4:56 - loss: 2.2048 - accuracy: 0.49 - ETA: 4:52 - loss: 2.2194 - accuracy: 0.48 - ETA: 4:49 - loss: 2.2167 - accuracy: 0.48 - ETA: 4:45 - loss: 2.2169 - accuracy: 0.48 - ETA: 4:42 - loss: 2.2087 - accuracy: 0.48 - ETA: 4:38 - loss: 2.2083 - accuracy: 0.48 - ETA: 4:35 - loss: 2.2150 - accuracy: 0.48 - ETA: 4:32 - loss: 2.2074 - accuracy: 0.48 - ETA: 4:28 - loss: 2.2063 - accuracy: 0.48 - ETA: 4:25 - loss: 2.2210 - accuracy: 0.48 - ETA: 4:21 - loss: 2.2221 - accuracy: 0.48 - ETA: 4:18 - loss: 2.2213 - accuracy: 0.48 - ETA: 4:14 - loss: 2.2167 - accuracy: 0.48 - ETA: 4:11 - loss: 2.2151 - accuracy: 0.48 - ETA: 4:07 - loss: 2.2169 - accuracy: 0.48 - ETA: 4:04 - loss: 2.2190 - accuracy: 0.48 - ETA: 4:01 - loss: 2.2158 - accuracy: 0.48 - ETA: 3:57 - loss: 2.2201 - accuracy: 0.48 - ETA: 3:54 - loss: 2.2216 - accuracy: 0.48 - ETA: 3:50 - loss: 2.2173 - accuracy: 0.48 - ETA: 3:47 - loss: 2.2202 - accuracy: 0.48 - ETA: 3:44 - loss: 2.2159 - accuracy: 0.48 - ETA: 3:40 - loss: 2.2178 - accuracy: 0.48 - ETA: 3:37 - loss: 2.2170 - accuracy: 0.48 - ETA: 3:34 - loss: 2.2147 - accuracy: 0.48 - ETA: 3:31 - loss: 2.2182 - accuracy: 0.48 - ETA: 3:27 - loss: 2.2168 - accuracy: 0.48 - ETA: 3:24 - loss: 2.2158 - accuracy: 0.48 - ETA: 3:21 - loss: 2.2141 - accuracy: 0.48 - ETA: 3:18 - loss: 2.2207 - accuracy: 0.48 - ETA: 3:14 - loss: 2.2201 - accuracy: 0.48 - ETA: 3:11 - loss: 2.2227 - accuracy: 0.48 - ETA: 3:08 - loss: 2.2322 - accuracy: 0.48 - ETA: 3:05 - loss: 2.2314 - accuracy: 0.48 - ETA: 3:01 - loss: 2.2321 - accuracy: 0.48 - ETA: 2:58 - loss: 2.2293 - accuracy: 0.48 - ETA: 2:55 - loss: 2.2281 - accuracy: 0.48 - ETA: 2:52 - loss: 2.2270 - accuracy: 0.48 - ETA: 2:49 - loss: 2.2258 - accuracy: 0.48 - ETA: 2:45 - loss: 2.2215 - accuracy: 0.48 - ETA: 2:42 - loss: 2.2216 - accuracy: 0.48 - ETA: 2:39 - loss: 2.2193 - accuracy: 0.48 - ETA: 2:35 - loss: 2.2181 - accuracy: 0.48 - ETA: 2:32 - loss: 2.2168 - accuracy: 0.48 - ETA: 2:29 - loss: 2.2173 - accuracy: 0.48 - ETA: 2:25 - loss: 2.2180 - accuracy: 0.48 - ETA: 2:22 - loss: 2.2140 - accuracy: 0.48 - ETA: 2:19 - loss: 2.2140 - accuracy: 0.48 - ETA: 2:15 - loss: 2.2107 - accuracy: 0.48 - ETA: 2:12 - loss: 2.2065 - accuracy: 0.48 - ETA: 2:09 - loss: 2.2038 - accuracy: 0.48 - ETA: 2:05 - loss: 2.2009 - accuracy: 0.48 - ETA: 2:02 - loss: 2.1996 - accuracy: 0.48 - ETA: 1:59 - loss: 2.1997 - accuracy: 0.48 - ETA: 1:55 - loss: 2.1958 - accuracy: 0.48 - ETA: 1:52 - loss: 2.1980 - accuracy: 0.48 - ETA: 1:49 - loss: 2.2003 - accuracy: 0.48 - ETA: 1:45 - loss: 2.2022 - accuracy: 0.48 - ETA: 1:42 - loss: 2.2004 - accuracy: 0.48 - ETA: 1:39 - loss: 2.2039 - accuracy: 0.48 - ETA: 1:36 - loss: 2.2033 - accuracy: 0.48 - ETA: 1:32 - loss: 2.2011 - accuracy: 0.48 - ETA: 1:29 - loss: 2.2019 - accuracy: 0.48 - ETA: 1:26 - loss: 2.1995 - accuracy: 0.48 - ETA: 1:22 - loss: 2.2017 - accuracy: 0.48 - ETA: 1:19 - loss: 2.2140 - accuracy: 0.48 - ETA: 1:16 - loss: 2.2203 - accuracy: 0.48 - ETA: 1:12 - loss: 2.2214 - accuracy: 0.48 - ETA: 1:09 - loss: 2.2221 - accuracy: 0.48 - ETA: 1:06 - loss: 2.2470 - accuracy: 0.48 - ETA: 1:02 - loss: 2.2528 - accuracy: 0.48 - ETA: 59s - loss: 2.2568 - accuracy: 0.4828 - ETA: 56s - loss: 2.2559 - accuracy: 0.482 - ETA: 52s - loss: 2.2547 - accuracy: 0.483 - ETA: 49s - loss: 2.2520 - accuracy: 0.483 - ETA: 46s - loss: 2.2533 - accuracy: 0.483 - ETA: 42s - loss: 2.2542 - accuracy: 0.483 - ETA: 39s - loss: 2.2539 - accuracy: 0.483 - ETA: 36s - loss: 2.2517 - accuracy: 0.484 - ETA: 32s - loss: 2.2489 - accuracy: 0.484 - ETA: 29s - loss: 2.2521 - accuracy: 0.484 - ETA: 26s - loss: 2.2487 - accuracy: 0.484 - ETA: 22s - loss: 2.2495 - accuracy: 0.484 - ETA: 19s - loss: 2.2496 - accuracy: 0.485 - ETA: 16s - loss: 2.2517 - accuracy: 0.485 - ETA: 12s - loss: 2.2516 - accuracy: 0.485 - ETA: 9s - loss: 2.2501 - accuracy: 0.485 - ETA: 6s - loss: 2.2493 - accuracy: 0.48 - ETA: 2s - loss: 2.2473 - accuracy: 0.48 - 552s 29ms/step - loss: 2.2549 - accuracy: 0.4858 - val_loss: 1.7069 - val_accuracy: 0.5811\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 8:02 - loss: 2.0235 - accuracy: 0.54 - ETA: 7:49 - loss: 1.9588 - accuracy: 0.51 - ETA: 7:44 - loss: 2.1171 - accuracy: 0.48 - ETA: 7:41 - loss: 2.0869 - accuracy: 0.49 - ETA: 7:36 - loss: 2.1438 - accuracy: 0.49 - ETA: 7:34 - loss: 2.1583 - accuracy: 0.48 - ETA: 7:34 - loss: 2.2072 - accuracy: 0.48 - ETA: 7:26 - loss: 2.1840 - accuracy: 0.49 - ETA: 7:22 - loss: 2.1988 - accuracy: 0.49 - ETA: 7:19 - loss: 2.1949 - accuracy: 0.48 - ETA: 7:18 - loss: 2.1891 - accuracy: 0.49 - ETA: 7:12 - loss: 2.2022 - accuracy: 0.49 - ETA: 7:08 - loss: 2.2270 - accuracy: 0.49 - ETA: 7:06 - loss: 2.2594 - accuracy: 0.48 - ETA: 7:04 - loss: 2.2374 - accuracy: 0.49 - ETA: 7:00 - loss: 2.2464 - accuracy: 0.48 - ETA: 7:00 - loss: 2.2329 - accuracy: 0.49 - ETA: 6:58 - loss: 2.2361 - accuracy: 0.49 - ETA: 6:53 - loss: 2.2201 - accuracy: 0.49 - ETA: 6:51 - loss: 2.2164 - accuracy: 0.49 - ETA: 6:46 - loss: 2.2098 - accuracy: 0.49 - ETA: 6:44 - loss: 2.1875 - accuracy: 0.49 - ETA: 6:40 - loss: 2.1909 - accuracy: 0.49 - ETA: 6:36 - loss: 2.1906 - accuracy: 0.49 - ETA: 6:33 - loss: 2.1972 - accuracy: 0.50 - ETA: 6:29 - loss: 2.2105 - accuracy: 0.49 - ETA: 6:25 - loss: 2.1956 - accuracy: 0.49 - ETA: 6:21 - loss: 2.1910 - accuracy: 0.49 - ETA: 6:18 - loss: 2.2008 - accuracy: 0.49 - ETA: 6:14 - loss: 2.1950 - accuracy: 0.49 - ETA: 6:10 - loss: 2.2080 - accuracy: 0.49 - ETA: 6:07 - loss: 2.2087 - accuracy: 0.49 - ETA: 6:05 - loss: 2.2128 - accuracy: 0.49 - ETA: 6:01 - loss: 2.2226 - accuracy: 0.49 - ETA: 5:58 - loss: 2.2495 - accuracy: 0.49 - ETA: 5:55 - loss: 2.2947 - accuracy: 0.49 - ETA: 5:52 - loss: 2.2859 - accuracy: 0.49 - ETA: 5:48 - loss: 2.2775 - accuracy: 0.49 - ETA: 5:45 - loss: 2.2709 - accuracy: 0.49 - ETA: 5:42 - loss: 2.2631 - accuracy: 0.49 - ETA: 5:39 - loss: 2.2614 - accuracy: 0.49 - ETA: 5:36 - loss: 2.2490 - accuracy: 0.49 - ETA: 5:33 - loss: 2.2377 - accuracy: 0.49 - ETA: 5:30 - loss: 2.2311 - accuracy: 0.50 - ETA: 5:27 - loss: 2.2292 - accuracy: 0.49 - ETA: 5:24 - loss: 2.2291 - accuracy: 0.50 - ETA: 5:21 - loss: 2.2267 - accuracy: 0.49 - ETA: 5:18 - loss: 2.2296 - accuracy: 0.49 - ETA: 5:14 - loss: 2.2418 - accuracy: 0.49 - ETA: 5:11 - loss: 2.2466 - accuracy: 0.49 - ETA: 5:08 - loss: 2.2356 - accuracy: 0.50 - ETA: 5:05 - loss: 2.2220 - accuracy: 0.50 - ETA: 5:02 - loss: 2.2325 - accuracy: 0.49 - ETA: 4:59 - loss: 2.2294 - accuracy: 0.49 - ETA: 4:55 - loss: 2.2547 - accuracy: 0.49 - ETA: 4:53 - loss: 2.2532 - accuracy: 0.49 - ETA: 4:49 - loss: 2.2632 - accuracy: 0.49 - ETA: 4:47 - loss: 2.2657 - accuracy: 0.49 - ETA: 4:44 - loss: 2.2669 - accuracy: 0.49 - ETA: 4:41 - loss: 2.2648 - accuracy: 0.49 - ETA: 4:38 - loss: 2.2638 - accuracy: 0.49 - ETA: 4:35 - loss: 2.2595 - accuracy: 0.49 - ETA: 4:32 - loss: 2.2565 - accuracy: 0.49 - ETA: 4:29 - loss: 2.2506 - accuracy: 0.49 - ETA: 4:26 - loss: 2.2457 - accuracy: 0.49 - ETA: 4:23 - loss: 2.2449 - accuracy: 0.49 - ETA: 4:19 - loss: 2.2403 - accuracy: 0.49 - ETA: 4:17 - loss: 2.2404 - accuracy: 0.49 - ETA: 4:14 - loss: 2.2376 - accuracy: 0.49 - ETA: 4:11 - loss: 2.2371 - accuracy: 0.49 - ETA: 4:08 - loss: 2.2377 - accuracy: 0.49 - ETA: 4:04 - loss: 2.2336 - accuracy: 0.49 - ETA: 4:01 - loss: 2.2361 - accuracy: 0.49 - ETA: 3:58 - loss: 2.2321 - accuracy: 0.49 - ETA: 3:55 - loss: 2.2265 - accuracy: 0.49 - ETA: 3:52 - loss: 2.2262 - accuracy: 0.49 - ETA: 3:49 - loss: 2.2308 - accuracy: 0.49 - ETA: 3:46 - loss: 2.2274 - accuracy: 0.49 - ETA: 3:44 - loss: 2.2255 - accuracy: 0.49 - ETA: 3:42 - loss: 2.2207 - accuracy: 0.49 - ETA: 3:39 - loss: 2.2205 - accuracy: 0.49 - ETA: 3:36 - loss: 2.2229 - accuracy: 0.49 - ETA: 3:33 - loss: 2.2232 - accuracy: 0.49 - ETA: 3:30 - loss: 2.2279 - accuracy: 0.49 - ETA: 3:27 - loss: 2.2264 - accuracy: 0.49 - ETA: 3:24 - loss: 2.2268 - accuracy: 0.49 - ETA: 3:21 - loss: 2.2250 - accuracy: 0.49 - ETA: 3:18 - loss: 2.2205 - accuracy: 0.49 - ETA: 3:14 - loss: 2.2211 - accuracy: 0.49 - ETA: 3:11 - loss: 2.2224 - accuracy: 0.49 - ETA: 3:08 - loss: 2.2201 - accuracy: 0.49 - ETA: 3:05 - loss: 2.2169 - accuracy: 0.49 - ETA: 3:02 - loss: 2.2133 - accuracy: 0.49 - ETA: 2:59 - loss: 2.2191 - accuracy: 0.49 - ETA: 2:55 - loss: 2.2179 - accuracy: 0.49 - ETA: 2:52 - loss: 2.2150 - accuracy: 0.49 - ETA: 2:49 - loss: 2.2165 - accuracy: 0.49 - ETA: 2:46 - loss: 2.2197 - accuracy: 0.49 - ETA: 2:43 - loss: 2.2150 - accuracy: 0.49 - ETA: 2:39 - loss: 2.2135 - accuracy: 0.49 - ETA: 2:36 - loss: 2.2121 - accuracy: 0.49 - ETA: 2:33 - loss: 2.2097 - accuracy: 0.49 - ETA: 2:30 - loss: 2.2048 - accuracy: 0.49 - ETA: 2:27 - loss: 2.2033 - accuracy: 0.49 - ETA: 2:24 - loss: 2.2034 - accuracy: 0.49 - ETA: 2:21 - loss: 2.2039 - accuracy: 0.49 - ETA: 2:17 - loss: 2.2039 - accuracy: 0.49 - ETA: 2:14 - loss: 2.2038 - accuracy: 0.49 - ETA: 2:11 - loss: 2.2046 - accuracy: 0.49 - ETA: 2:08 - loss: 2.2029 - accuracy: 0.49 - ETA: 2:05 - loss: 2.1989 - accuracy: 0.49 - ETA: 2:02 - loss: 2.1971 - accuracy: 0.49 - ETA: 1:59 - loss: 2.1921 - accuracy: 0.49 - ETA: 1:56 - loss: 2.1940 - accuracy: 0.49 - ETA: 1:52 - loss: 2.1905 - accuracy: 0.49 - ETA: 1:49 - loss: 2.2059 - accuracy: 0.49 - ETA: 1:46 - loss: 2.2060 - accuracy: 0.49 - ETA: 1:43 - loss: 2.2068 - accuracy: 0.49 - ETA: 1:40 - loss: 2.2042 - accuracy: 0.49 - ETA: 1:37 - loss: 2.2028 - accuracy: 0.49 - ETA: 1:34 - loss: 2.2037 - accuracy: 0.49 - ETA: 1:31 - loss: 2.2046 - accuracy: 0.49 - ETA: 1:27 - loss: 2.2028 - accuracy: 0.49 - ETA: 1:24 - loss: 2.2044 - accuracy: 0.49 - ETA: 1:21 - loss: 2.2025 - accuracy: 0.49 - ETA: 1:18 - loss: 2.2033 - accuracy: 0.49 - ETA: 1:15 - loss: 2.2028 - accuracy: 0.49 - ETA: 1:12 - loss: 2.2017 - accuracy: 0.49 - ETA: 1:09 - loss: 2.2053 - accuracy: 0.49 - ETA: 1:05 - loss: 2.2052 - accuracy: 0.49 - ETA: 1:02 - loss: 2.2044 - accuracy: 0.49 - ETA: 59s - loss: 2.2042 - accuracy: 0.4941 - ETA: 56s - loss: 2.2024 - accuracy: 0.494 - ETA: 53s - loss: 2.2013 - accuracy: 0.494 - ETA: 50s - loss: 2.2011 - accuracy: 0.493 - ETA: 47s - loss: 2.2003 - accuracy: 0.492 - ETA: 43s - loss: 2.1994 - accuracy: 0.492 - ETA: 40s - loss: 2.1994 - accuracy: 0.492 - ETA: 37s - loss: 2.1988 - accuracy: 0.492 - ETA: 34s - loss: 2.1958 - accuracy: 0.493 - ETA: 31s - loss: 2.1974 - accuracy: 0.492 - ETA: 28s - loss: 2.1968 - accuracy: 0.492 - ETA: 24s - loss: 2.1961 - accuracy: 0.492 - ETA: 21s - loss: 2.1977 - accuracy: 0.492 - ETA: 18s - loss: 2.1971 - accuracy: 0.492 - ETA: 15s - loss: 2.1975 - accuracy: 0.492 - ETA: 12s - loss: 2.1954 - accuracy: 0.493 - ETA: 9s - loss: 2.1966 - accuracy: 0.493 - ETA: 5s - loss: 2.1976 - accuracy: 0.49 - ETA: 2s - loss: 2.1955 - accuracy: 0.49 - 530s 27ms/step - loss: 2.1934 - accuracy: 0.4937 - val_loss: 1.6511 - val_accuracy: 0.5916\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:32 - loss: 1.9686 - accuracy: 0.50 - ETA: 7:19 - loss: 2.1093 - accuracy: 0.50 - ETA: 7:31 - loss: 2.0415 - accuracy: 0.51 - ETA: 7:34 - loss: 2.0402 - accuracy: 0.51 - ETA: 8:02 - loss: 2.0363 - accuracy: 0.51 - ETA: 7:53 - loss: 2.0365 - accuracy: 0.51 - ETA: 7:48 - loss: 2.0717 - accuracy: 0.50 - ETA: 7:46 - loss: 2.0929 - accuracy: 0.50 - ETA: 7:33 - loss: 2.1308 - accuracy: 0.49 - ETA: 7:33 - loss: 2.1237 - accuracy: 0.50 - ETA: 7:29 - loss: 2.2345 - accuracy: 0.50 - ETA: 7:22 - loss: 2.2349 - accuracy: 0.50 - ETA: 7:20 - loss: 2.3030 - accuracy: 0.50 - ETA: 7:15 - loss: 2.2678 - accuracy: 0.50 - ETA: 7:10 - loss: 2.2591 - accuracy: 0.50 - ETA: 7:05 - loss: 2.2224 - accuracy: 0.50 - ETA: 7:00 - loss: 2.2199 - accuracy: 0.50 - ETA: 6:57 - loss: 2.2129 - accuracy: 0.50 - ETA: 6:54 - loss: 2.2423 - accuracy: 0.50 - ETA: 6:49 - loss: 2.2042 - accuracy: 0.50 - ETA: 6:45 - loss: 2.2021 - accuracy: 0.50 - ETA: 6:43 - loss: 2.2021 - accuracy: 0.50 - ETA: 6:38 - loss: 2.1884 - accuracy: 0.50 - ETA: 6:37 - loss: 2.1828 - accuracy: 0.50 - ETA: 6:32 - loss: 2.1793 - accuracy: 0.50 - ETA: 6:30 - loss: 2.1926 - accuracy: 0.50 - ETA: 6:27 - loss: 2.1774 - accuracy: 0.50 - ETA: 6:24 - loss: 2.1888 - accuracy: 0.50 - ETA: 6:21 - loss: 2.1948 - accuracy: 0.49 - ETA: 6:19 - loss: 2.2032 - accuracy: 0.50 - ETA: 6:15 - loss: 2.2017 - accuracy: 0.49 - ETA: 6:11 - loss: 2.1949 - accuracy: 0.50 - ETA: 6:08 - loss: 2.2018 - accuracy: 0.50 - ETA: 6:05 - loss: 2.1963 - accuracy: 0.50 - ETA: 6:01 - loss: 2.1834 - accuracy: 0.50 - ETA: 5:57 - loss: 2.1675 - accuracy: 0.50 - ETA: 5:54 - loss: 2.1805 - accuracy: 0.50 - ETA: 5:50 - loss: 2.1738 - accuracy: 0.50 - ETA: 5:46 - loss: 2.1696 - accuracy: 0.50 - ETA: 5:43 - loss: 2.1651 - accuracy: 0.50 - ETA: 5:40 - loss: 2.1615 - accuracy: 0.50 - ETA: 5:36 - loss: 2.1503 - accuracy: 0.50 - ETA: 5:33 - loss: 2.1510 - accuracy: 0.50 - ETA: 5:30 - loss: 2.1532 - accuracy: 0.50 - ETA: 5:27 - loss: 2.1580 - accuracy: 0.50 - ETA: 5:24 - loss: 2.1503 - accuracy: 0.50 - ETA: 5:21 - loss: 2.1461 - accuracy: 0.50 - ETA: 5:18 - loss: 2.1415 - accuracy: 0.50 - ETA: 5:14 - loss: 2.1438 - accuracy: 0.50 - ETA: 5:11 - loss: 2.1470 - accuracy: 0.50 - ETA: 5:08 - loss: 2.1561 - accuracy: 0.50 - ETA: 5:05 - loss: 2.1606 - accuracy: 0.50 - ETA: 5:02 - loss: 2.1534 - accuracy: 0.50 - ETA: 4:58 - loss: 2.1457 - accuracy: 0.50 - ETA: 4:56 - loss: 2.1442 - accuracy: 0.50 - ETA: 4:52 - loss: 2.1435 - accuracy: 0.50 - ETA: 4:49 - loss: 2.1501 - accuracy: 0.50 - ETA: 4:46 - loss: 2.1609 - accuracy: 0.49 - ETA: 4:42 - loss: 2.1580 - accuracy: 0.49 - ETA: 4:39 - loss: 2.1578 - accuracy: 0.49 - ETA: 4:36 - loss: 2.1511 - accuracy: 0.49 - ETA: 4:33 - loss: 2.1489 - accuracy: 0.49 - ETA: 4:29 - loss: 2.1454 - accuracy: 0.49 - ETA: 4:26 - loss: 2.1453 - accuracy: 0.50 - ETA: 4:23 - loss: 2.1405 - accuracy: 0.50 - ETA: 4:20 - loss: 2.1380 - accuracy: 0.50 - ETA: 4:17 - loss: 2.1404 - accuracy: 0.50 - ETA: 4:14 - loss: 2.1391 - accuracy: 0.50 - ETA: 4:10 - loss: 2.1392 - accuracy: 0.49 - ETA: 4:07 - loss: 2.1353 - accuracy: 0.50 - ETA: 4:04 - loss: 2.1346 - accuracy: 0.50 - ETA: 4:01 - loss: 2.1381 - accuracy: 0.50 - ETA: 3:58 - loss: 2.1407 - accuracy: 0.50 - ETA: 3:55 - loss: 2.1393 - accuracy: 0.50 - ETA: 3:51 - loss: 2.1390 - accuracy: 0.50 - ETA: 3:48 - loss: 2.1439 - accuracy: 0.49 - ETA: 3:45 - loss: 2.1460 - accuracy: 0.49 - ETA: 3:42 - loss: 2.1428 - accuracy: 0.49 - ETA: 3:39 - loss: 2.1424 - accuracy: 0.49 - ETA: 3:36 - loss: 2.1426 - accuracy: 0.49 - ETA: 3:33 - loss: 2.1427 - accuracy: 0.49 - ETA: 3:30 - loss: 2.1395 - accuracy: 0.50 - ETA: 3:27 - loss: 2.1359 - accuracy: 0.50 - ETA: 3:24 - loss: 2.1349 - accuracy: 0.50 - ETA: 3:21 - loss: 2.1286 - accuracy: 0.50 - ETA: 3:17 - loss: 2.1258 - accuracy: 0.50 - ETA: 3:14 - loss: 2.1287 - accuracy: 0.50 - ETA: 3:12 - loss: 2.1520 - accuracy: 0.50 - ETA: 3:08 - loss: 2.1556 - accuracy: 0.50 - ETA: 3:05 - loss: 2.1549 - accuracy: 0.50 - ETA: 3:02 - loss: 2.1491 - accuracy: 0.50 - ETA: 2:59 - loss: 2.1477 - accuracy: 0.50 - ETA: 2:56 - loss: 2.1447 - accuracy: 0.50 - ETA: 2:53 - loss: 2.1463 - accuracy: 0.50 - ETA: 2:50 - loss: 2.1440 - accuracy: 0.50 - ETA: 2:47 - loss: 2.1463 - accuracy: 0.50 - ETA: 2:44 - loss: 2.1465 - accuracy: 0.50 - ETA: 2:41 - loss: 2.1469 - accuracy: 0.50 - ETA: 2:38 - loss: 2.1483 - accuracy: 0.50 - ETA: 2:35 - loss: 2.1469 - accuracy: 0.50 - ETA: 2:32 - loss: 2.1436 - accuracy: 0.50 - ETA: 2:29 - loss: 2.1422 - accuracy: 0.50 - ETA: 2:26 - loss: 2.1404 - accuracy: 0.50 - ETA: 2:23 - loss: 2.1406 - accuracy: 0.50 - ETA: 2:20 - loss: 2.1384 - accuracy: 0.50 - ETA: 2:17 - loss: 2.1355 - accuracy: 0.50 - ETA: 2:14 - loss: 2.1346 - accuracy: 0.50 - ETA: 2:11 - loss: 2.1329 - accuracy: 0.50 - ETA: 2:08 - loss: 2.1322 - accuracy: 0.50 - ETA: 2:05 - loss: 2.1312 - accuracy: 0.50 - ETA: 2:02 - loss: 2.1302 - accuracy: 0.50 - ETA: 1:59 - loss: 2.1311 - accuracy: 0.50 - ETA: 1:56 - loss: 2.1301 - accuracy: 0.50 - ETA: 1:53 - loss: 2.1288 - accuracy: 0.50 - ETA: 1:49 - loss: 2.1276 - accuracy: 0.50 - ETA: 1:46 - loss: 2.1317 - accuracy: 0.50 - ETA: 1:43 - loss: 2.1324 - accuracy: 0.50 - ETA: 1:40 - loss: 2.1305 - accuracy: 0.50 - ETA: 1:37 - loss: 2.1282 - accuracy: 0.50 - ETA: 1:34 - loss: 2.1257 - accuracy: 0.50 - ETA: 1:31 - loss: 2.1251 - accuracy: 0.50 - ETA: 1:28 - loss: 2.1269 - accuracy: 0.50 - ETA: 1:25 - loss: 2.1266 - accuracy: 0.50 - ETA: 1:22 - loss: 2.1250 - accuracy: 0.50 - ETA: 1:19 - loss: 2.1238 - accuracy: 0.50 - ETA: 1:16 - loss: 2.1249 - accuracy: 0.50 - ETA: 1:13 - loss: 2.1207 - accuracy: 0.50 - ETA: 1:10 - loss: 2.1195 - accuracy: 0.50 - ETA: 1:07 - loss: 2.1212 - accuracy: 0.50 - ETA: 1:04 - loss: 2.1244 - accuracy: 0.50 - ETA: 1:01 - loss: 2.1262 - accuracy: 0.50 - ETA: 58s - loss: 2.1252 - accuracy: 0.5004 - ETA: 55s - loss: 2.1272 - accuracy: 0.500 - ETA: 52s - loss: 2.1275 - accuracy: 0.500 - ETA: 49s - loss: 2.1272 - accuracy: 0.500 - ETA: 45s - loss: 2.1284 - accuracy: 0.500 - ETA: 42s - loss: 2.1269 - accuracy: 0.500 - ETA: 39s - loss: 2.1304 - accuracy: 0.499 - ETA: 36s - loss: 2.1334 - accuracy: 0.500 - ETA: 33s - loss: 2.1319 - accuracy: 0.500 - ETA: 30s - loss: 2.1304 - accuracy: 0.500 - ETA: 27s - loss: 2.1293 - accuracy: 0.500 - ETA: 24s - loss: 2.1310 - accuracy: 0.500 - ETA: 21s - loss: 2.1305 - accuracy: 0.500 - ETA: 18s - loss: 2.1313 - accuracy: 0.500 - ETA: 15s - loss: 2.1394 - accuracy: 0.499 - ETA: 12s - loss: 2.1381 - accuracy: 0.499 - ETA: 8s - loss: 2.1386 - accuracy: 0.499 - ETA: 5s - loss: 2.1392 - accuracy: 0.49 - ETA: 2s - loss: 2.1416 - accuracy: 0.49 - 520s 27ms/step - loss: 2.1396 - accuracy: 0.4996 - val_loss: 1.7256 - val_accuracy: 0.5732\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:40 - loss: 1.8623 - accuracy: 0.58 - ETA: 7:36 - loss: 1.9256 - accuracy: 0.55 - ETA: 7:23 - loss: 2.0828 - accuracy: 0.54 - ETA: 7:11 - loss: 2.0827 - accuracy: 0.53 - ETA: 7:21 - loss: 2.0602 - accuracy: 0.53 - ETA: 7:14 - loss: 2.0552 - accuracy: 0.52 - ETA: 7:10 - loss: 2.0229 - accuracy: 0.53 - ETA: 7:02 - loss: 2.3608 - accuracy: 0.52 - ETA: 7:12 - loss: 2.3654 - accuracy: 0.52 - ETA: 7:10 - loss: 2.3131 - accuracy: 0.52 - ETA: 7:08 - loss: 2.2710 - accuracy: 0.52 - ETA: 7:06 - loss: 2.2476 - accuracy: 0.51 - ETA: 7:00 - loss: 2.2441 - accuracy: 0.51 - ETA: 6:59 - loss: 2.2323 - accuracy: 0.51 - ETA: 6:55 - loss: 2.2130 - accuracy: 0.51 - ETA: 6:50 - loss: 2.2128 - accuracy: 0.51 - ETA: 6:51 - loss: 2.2017 - accuracy: 0.51 - ETA: 6:48 - loss: 2.1774 - accuracy: 0.51 - ETA: 6:44 - loss: 2.1571 - accuracy: 0.51 - ETA: 6:40 - loss: 2.1604 - accuracy: 0.51 - ETA: 6:39 - loss: 2.1743 - accuracy: 0.51 - ETA: 6:36 - loss: 2.1826 - accuracy: 0.51 - ETA: 6:34 - loss: 2.1608 - accuracy: 0.51 - ETA: 6:31 - loss: 2.1543 - accuracy: 0.51 - ETA: 6:29 - loss: 2.1874 - accuracy: 0.51 - ETA: 6:26 - loss: 2.1724 - accuracy: 0.51 - ETA: 6:23 - loss: 2.1632 - accuracy: 0.51 - ETA: 6:21 - loss: 2.1594 - accuracy: 0.51 - ETA: 6:18 - loss: 2.1527 - accuracy: 0.51 - ETA: 6:14 - loss: 2.1794 - accuracy: 0.51 - ETA: 6:11 - loss: 2.1812 - accuracy: 0.50 - ETA: 6:08 - loss: 2.1753 - accuracy: 0.50 - ETA: 6:07 - loss: 2.1823 - accuracy: 0.50 - ETA: 6:04 - loss: 2.1783 - accuracy: 0.50 - ETA: 6:00 - loss: 2.1798 - accuracy: 0.50 - ETA: 5:55 - loss: 2.1863 - accuracy: 0.50 - ETA: 5:54 - loss: 2.2109 - accuracy: 0.49 - ETA: 5:50 - loss: 2.2047 - accuracy: 0.50 - ETA: 5:47 - loss: 2.2012 - accuracy: 0.50 - ETA: 5:44 - loss: 2.1929 - accuracy: 0.50 - ETA: 5:40 - loss: 2.1955 - accuracy: 0.49 - ETA: 5:37 - loss: 2.1896 - accuracy: 0.50 - ETA: 5:34 - loss: 2.1811 - accuracy: 0.50 - ETA: 5:31 - loss: 2.1938 - accuracy: 0.50 - ETA: 5:27 - loss: 2.1797 - accuracy: 0.50 - ETA: 5:24 - loss: 2.1742 - accuracy: 0.50 - ETA: 5:20 - loss: 2.1745 - accuracy: 0.50 - ETA: 5:18 - loss: 2.1703 - accuracy: 0.50 - ETA: 5:14 - loss: 2.1655 - accuracy: 0.50 - ETA: 5:11 - loss: 2.1668 - accuracy: 0.50 - ETA: 5:07 - loss: 2.1652 - accuracy: 0.50 - ETA: 5:05 - loss: 2.1617 - accuracy: 0.50 - ETA: 5:02 - loss: 2.1610 - accuracy: 0.50 - ETA: 4:58 - loss: 2.1570 - accuracy: 0.50 - ETA: 4:55 - loss: 2.1559 - accuracy: 0.50 - ETA: 4:52 - loss: 2.1521 - accuracy: 0.50 - ETA: 4:49 - loss: 2.1475 - accuracy: 0.50 - ETA: 4:46 - loss: 2.1428 - accuracy: 0.50 - ETA: 4:43 - loss: 2.1337 - accuracy: 0.51 - ETA: 4:40 - loss: 2.1239 - accuracy: 0.51 - ETA: 4:37 - loss: 2.1205 - accuracy: 0.51 - ETA: 4:34 - loss: 2.1220 - accuracy: 0.51 - ETA: 4:31 - loss: 2.1199 - accuracy: 0.51 - ETA: 4:27 - loss: 2.1299 - accuracy: 0.51 - ETA: 4:24 - loss: 2.1261 - accuracy: 0.51 - ETA: 4:21 - loss: 2.1343 - accuracy: 0.51 - ETA: 4:18 - loss: 2.1302 - accuracy: 0.51 - ETA: 4:15 - loss: 2.1269 - accuracy: 0.51 - ETA: 4:12 - loss: 2.1226 - accuracy: 0.51 - ETA: 4:09 - loss: 2.1186 - accuracy: 0.51 - ETA: 4:05 - loss: 2.1099 - accuracy: 0.51 - ETA: 4:02 - loss: 2.1046 - accuracy: 0.51 - ETA: 3:59 - loss: 2.1067 - accuracy: 0.51 - ETA: 3:56 - loss: 2.1069 - accuracy: 0.51 - ETA: 3:53 - loss: 2.1049 - accuracy: 0.51 - ETA: 3:50 - loss: 2.1047 - accuracy: 0.51 - ETA: 3:47 - loss: 2.1052 - accuracy: 0.51 - ETA: 3:43 - loss: 2.1028 - accuracy: 0.51 - ETA: 3:41 - loss: 2.0958 - accuracy: 0.51 - ETA: 3:38 - loss: 2.0947 - accuracy: 0.51 - ETA: 3:35 - loss: 2.0912 - accuracy: 0.51 - ETA: 3:32 - loss: 2.0878 - accuracy: 0.51 - ETA: 3:28 - loss: 2.0945 - accuracy: 0.51 - ETA: 3:25 - loss: 2.0943 - accuracy: 0.51 - ETA: 3:22 - loss: 2.0939 - accuracy: 0.50 - ETA: 3:19 - loss: 2.0957 - accuracy: 0.50 - ETA: 3:16 - loss: 2.0946 - accuracy: 0.50 - ETA: 3:13 - loss: 2.0901 - accuracy: 0.50 - ETA: 3:10 - loss: 2.0887 - accuracy: 0.50 - ETA: 3:07 - loss: 2.0852 - accuracy: 0.51 - ETA: 3:04 - loss: 2.0844 - accuracy: 0.50 - ETA: 3:01 - loss: 2.0838 - accuracy: 0.51 - ETA: 2:58 - loss: 2.0820 - accuracy: 0.51 - ETA: 2:55 - loss: 2.0827 - accuracy: 0.50 - ETA: 2:52 - loss: 2.0825 - accuracy: 0.50 - ETA: 2:49 - loss: 2.0808 - accuracy: 0.50 - ETA: 2:45 - loss: 2.0758 - accuracy: 0.51 - ETA: 2:42 - loss: 2.0749 - accuracy: 0.50 - ETA: 2:39 - loss: 2.0747 - accuracy: 0.50 - ETA: 2:36 - loss: 2.0732 - accuracy: 0.50 - ETA: 2:33 - loss: 2.0705 - accuracy: 0.51 - ETA: 2:30 - loss: 2.0737 - accuracy: 0.51 - ETA: 2:27 - loss: 2.0734 - accuracy: 0.51 - ETA: 2:24 - loss: 2.0728 - accuracy: 0.51 - ETA: 2:21 - loss: 2.0728 - accuracy: 0.51 - ETA: 2:18 - loss: 2.0726 - accuracy: 0.51 - ETA: 2:15 - loss: 2.0706 - accuracy: 0.51 - ETA: 2:12 - loss: 2.0727 - accuracy: 0.51 - ETA: 2:09 - loss: 2.0725 - accuracy: 0.51 - ETA: 2:06 - loss: 2.0730 - accuracy: 0.50 - ETA: 2:03 - loss: 2.0711 - accuracy: 0.50 - ETA: 1:59 - loss: 2.0733 - accuracy: 0.50 - ETA: 1:56 - loss: 2.0715 - accuracy: 0.50 - ETA: 1:53 - loss: 2.0723 - accuracy: 0.50 - ETA: 1:50 - loss: 2.0720 - accuracy: 0.50 - ETA: 1:47 - loss: 2.0701 - accuracy: 0.50 - ETA: 1:44 - loss: 2.0727 - accuracy: 0.50 - ETA: 1:41 - loss: 2.0752 - accuracy: 0.50 - ETA: 1:38 - loss: 2.0782 - accuracy: 0.50 - ETA: 1:35 - loss: 2.0823 - accuracy: 0.50 - ETA: 1:32 - loss: 2.0778 - accuracy: 0.50 - ETA: 1:29 - loss: 2.0776 - accuracy: 0.50 - ETA: 1:26 - loss: 2.0815 - accuracy: 0.50 - ETA: 1:23 - loss: 2.0816 - accuracy: 0.50 - ETA: 1:20 - loss: 2.0819 - accuracy: 0.50 - ETA: 1:17 - loss: 2.0836 - accuracy: 0.50 - ETA: 1:14 - loss: 2.0844 - accuracy: 0.50 - ETA: 1:10 - loss: 2.0834 - accuracy: 0.50 - ETA: 1:07 - loss: 2.0840 - accuracy: 0.50 - ETA: 1:04 - loss: 2.0829 - accuracy: 0.50 - ETA: 1:01 - loss: 2.0864 - accuracy: 0.50 - ETA: 58s - loss: 2.0841 - accuracy: 0.5080 - ETA: 55s - loss: 2.0817 - accuracy: 0.508 - ETA: 52s - loss: 2.0817 - accuracy: 0.508 - ETA: 49s - loss: 2.0834 - accuracy: 0.507 - ETA: 46s - loss: 2.0803 - accuracy: 0.508 - ETA: 43s - loss: 2.0783 - accuracy: 0.508 - ETA: 40s - loss: 2.0762 - accuracy: 0.508 - ETA: 37s - loss: 2.0754 - accuracy: 0.508 - ETA: 34s - loss: 2.0757 - accuracy: 0.508 - ETA: 30s - loss: 2.0774 - accuracy: 0.509 - ETA: 27s - loss: 2.0748 - accuracy: 0.509 - ETA: 24s - loss: 2.0750 - accuracy: 0.508 - ETA: 21s - loss: 2.0822 - accuracy: 0.508 - ETA: 18s - loss: 2.0820 - accuracy: 0.508 - ETA: 15s - loss: 2.0793 - accuracy: 0.509 - ETA: 12s - loss: 2.0814 - accuracy: 0.508 - ETA: 8s - loss: 2.0798 - accuracy: 0.509 - ETA: 5s - loss: 2.0837 - accuracy: 0.50 - ETA: 2s - loss: 2.0871 - accuracy: 0.50 - 524s 27ms/step - loss: 2.0835 - accuracy: 0.5094 - val_loss: 1.6497 - val_accuracy: 0.5734\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 8:24 - loss: 1.6946 - accuracy: 0.60 - ETA: 7:37 - loss: 1.7813 - accuracy: 0.60 - ETA: 7:34 - loss: 1.8904 - accuracy: 0.57 - ETA: 7:32 - loss: 1.8910 - accuracy: 0.55 - ETA: 7:27 - loss: 1.8930 - accuracy: 0.55 - ETA: 7:14 - loss: 1.8785 - accuracy: 0.54 - ETA: 7:08 - loss: 1.8894 - accuracy: 0.54 - ETA: 7:04 - loss: 1.9936 - accuracy: 0.53 - ETA: 7:01 - loss: 1.9713 - accuracy: 0.53 - ETA: 6:59 - loss: 1.9729 - accuracy: 0.53 - ETA: 6:54 - loss: 1.9928 - accuracy: 0.52 - ETA: 6:53 - loss: 2.0075 - accuracy: 0.52 - ETA: 6:51 - loss: 1.9893 - accuracy: 0.52 - ETA: 6:47 - loss: 2.0096 - accuracy: 0.52 - ETA: 6:45 - loss: 2.0287 - accuracy: 0.51 - ETA: 6:41 - loss: 2.0260 - accuracy: 0.51 - ETA: 6:39 - loss: 2.0499 - accuracy: 0.51 - ETA: 6:35 - loss: 2.0458 - accuracy: 0.51 - ETA: 6:31 - loss: 2.0586 - accuracy: 0.51 - ETA: 6:28 - loss: 2.0701 - accuracy: 0.51 - ETA: 6:26 - loss: 2.0519 - accuracy: 0.51 - ETA: 6:22 - loss: 2.0557 - accuracy: 0.51 - ETA: 6:20 - loss: 2.0581 - accuracy: 0.51 - ETA: 6:16 - loss: 2.0507 - accuracy: 0.51 - ETA: 6:14 - loss: 2.0531 - accuracy: 0.51 - ETA: 6:12 - loss: 2.0244 - accuracy: 0.51 - ETA: 6:09 - loss: 2.0176 - accuracy: 0.51 - ETA: 6:06 - loss: 2.0122 - accuracy: 0.51 - ETA: 6:03 - loss: 2.0103 - accuracy: 0.51 - ETA: 5:58 - loss: 2.0111 - accuracy: 0.51 - ETA: 5:56 - loss: 1.9972 - accuracy: 0.51 - ETA: 5:53 - loss: 1.9914 - accuracy: 0.51 - ETA: 5:50 - loss: 1.9912 - accuracy: 0.51 - ETA: 5:47 - loss: 1.9810 - accuracy: 0.52 - ETA: 5:44 - loss: 1.9852 - accuracy: 0.52 - ETA: 5:40 - loss: 2.0015 - accuracy: 0.51 - ETA: 5:38 - loss: 2.0027 - accuracy: 0.51 - ETA: 5:35 - loss: 2.0038 - accuracy: 0.51 - ETA: 5:32 - loss: 1.9984 - accuracy: 0.51 - ETA: 5:29 - loss: 1.9952 - accuracy: 0.51 - ETA: 5:26 - loss: 2.0049 - accuracy: 0.51 - ETA: 5:22 - loss: 1.9969 - accuracy: 0.51 - ETA: 5:20 - loss: 1.9892 - accuracy: 0.51 - ETA: 5:17 - loss: 1.9911 - accuracy: 0.51 - ETA: 5:15 - loss: 1.9901 - accuracy: 0.51 - ETA: 5:12 - loss: 1.9844 - accuracy: 0.51 - ETA: 5:09 - loss: 1.9768 - accuracy: 0.51 - ETA: 5:06 - loss: 2.0134 - accuracy: 0.51 - ETA: 5:03 - loss: 2.0146 - accuracy: 0.51 - ETA: 5:00 - loss: 2.0236 - accuracy: 0.51 - ETA: 4:57 - loss: 2.0239 - accuracy: 0.51 - ETA: 4:55 - loss: 2.0207 - accuracy: 0.51 - ETA: 4:52 - loss: 2.0202 - accuracy: 0.51 - ETA: 4:50 - loss: 2.0222 - accuracy: 0.51 - ETA: 4:47 - loss: 2.0165 - accuracy: 0.51 - ETA: 4:44 - loss: 2.0105 - accuracy: 0.51 - ETA: 4:40 - loss: 2.0132 - accuracy: 0.51 - ETA: 4:38 - loss: 2.0081 - accuracy: 0.51 - ETA: 4:35 - loss: 2.0056 - accuracy: 0.51 - ETA: 4:32 - loss: 2.0099 - accuracy: 0.51 - ETA: 4:29 - loss: 2.0071 - accuracy: 0.52 - ETA: 4:26 - loss: 2.0087 - accuracy: 0.52 - ETA: 4:23 - loss: 2.0019 - accuracy: 0.52 - ETA: 4:21 - loss: 1.9999 - accuracy: 0.52 - ETA: 4:18 - loss: 1.9990 - accuracy: 0.52 - ETA: 4:14 - loss: 2.0011 - accuracy: 0.51 - ETA: 4:11 - loss: 1.9933 - accuracy: 0.52 - ETA: 4:09 - loss: 1.9919 - accuracy: 0.52 - ETA: 4:05 - loss: 1.9952 - accuracy: 0.51 - ETA: 4:02 - loss: 1.9901 - accuracy: 0.52 - ETA: 3:59 - loss: 1.9870 - accuracy: 0.52 - ETA: 3:56 - loss: 1.9918 - accuracy: 0.51 - ETA: 3:53 - loss: 1.9963 - accuracy: 0.51 - ETA: 3:50 - loss: 2.0019 - accuracy: 0.51 - ETA: 3:47 - loss: 2.0043 - accuracy: 0.51 - ETA: 3:44 - loss: 2.0278 - accuracy: 0.51 - ETA: 3:41 - loss: 2.0329 - accuracy: 0.51 - ETA: 3:39 - loss: 2.0340 - accuracy: 0.51 - ETA: 3:36 - loss: 2.0289 - accuracy: 0.51 - ETA: 3:33 - loss: 2.0280 - accuracy: 0.51 - ETA: 3:30 - loss: 2.0227 - accuracy: 0.51 - ETA: 3:27 - loss: 2.0188 - accuracy: 0.51 - ETA: 3:24 - loss: 2.0239 - accuracy: 0.51 - ETA: 3:21 - loss: 2.0261 - accuracy: 0.51 - ETA: 3:18 - loss: 2.0225 - accuracy: 0.51 - ETA: 3:15 - loss: 2.0237 - accuracy: 0.51 - ETA: 3:12 - loss: 2.0233 - accuracy: 0.51 - ETA: 3:09 - loss: 2.0250 - accuracy: 0.51 - ETA: 3:06 - loss: 2.0248 - accuracy: 0.51 - ETA: 3:03 - loss: 2.0276 - accuracy: 0.51 - ETA: 3:00 - loss: 2.0288 - accuracy: 0.51 - ETA: 2:57 - loss: 2.0266 - accuracy: 0.51 - ETA: 2:54 - loss: 2.0233 - accuracy: 0.51 - ETA: 2:51 - loss: 2.0266 - accuracy: 0.51 - ETA: 2:48 - loss: 2.0294 - accuracy: 0.51 - ETA: 2:45 - loss: 2.0261 - accuracy: 0.51 - ETA: 2:42 - loss: 2.0248 - accuracy: 0.51 - ETA: 2:38 - loss: 2.0249 - accuracy: 0.51 - ETA: 2:36 - loss: 2.0298 - accuracy: 0.51 - ETA: 2:33 - loss: 2.0320 - accuracy: 0.51 - ETA: 2:30 - loss: 2.0281 - accuracy: 0.51 - ETA: 2:27 - loss: 2.0288 - accuracy: 0.51 - ETA: 2:24 - loss: 2.0237 - accuracy: 0.51 - ETA: 2:21 - loss: 2.0238 - accuracy: 0.51 - ETA: 2:18 - loss: 2.0234 - accuracy: 0.51 - ETA: 2:15 - loss: 2.0207 - accuracy: 0.51 - ETA: 2:12 - loss: 2.0193 - accuracy: 0.51 - ETA: 2:09 - loss: 2.0154 - accuracy: 0.51 - ETA: 2:06 - loss: 2.0167 - accuracy: 0.51 - ETA: 2:03 - loss: 2.0166 - accuracy: 0.51 - ETA: 2:00 - loss: 2.0171 - accuracy: 0.51 - ETA: 1:57 - loss: 2.0135 - accuracy: 0.51 - ETA: 1:54 - loss: 2.0144 - accuracy: 0.51 - ETA: 1:51 - loss: 2.0160 - accuracy: 0.51 - ETA: 1:48 - loss: 2.0159 - accuracy: 0.51 - ETA: 1:45 - loss: 2.0156 - accuracy: 0.51 - ETA: 1:42 - loss: 2.0149 - accuracy: 0.51 - ETA: 1:39 - loss: 2.0127 - accuracy: 0.51 - ETA: 1:36 - loss: 2.0095 - accuracy: 0.51 - ETA: 1:33 - loss: 2.0080 - accuracy: 0.51 - ETA: 1:30 - loss: 2.0064 - accuracy: 0.51 - ETA: 1:27 - loss: 2.0056 - accuracy: 0.51 - ETA: 1:24 - loss: 2.0025 - accuracy: 0.51 - ETA: 1:21 - loss: 2.0022 - accuracy: 0.51 - ETA: 1:18 - loss: 2.0012 - accuracy: 0.51 - ETA: 1:15 - loss: 1.9994 - accuracy: 0.51 - ETA: 1:12 - loss: 1.9996 - accuracy: 0.51 - ETA: 1:09 - loss: 1.9999 - accuracy: 0.51 - ETA: 1:06 - loss: 1.9977 - accuracy: 0.51 - ETA: 1:03 - loss: 1.9996 - accuracy: 0.51 - ETA: 1:00 - loss: 1.9992 - accuracy: 0.51 - ETA: 57s - loss: 1.9950 - accuracy: 0.5181 - ETA: 54s - loss: 1.9930 - accuracy: 0.518 - ETA: 51s - loss: 2.0009 - accuracy: 0.518 - ETA: 48s - loss: 2.0006 - accuracy: 0.517 - ETA: 45s - loss: 2.0114 - accuracy: 0.517 - ETA: 42s - loss: 2.0228 - accuracy: 0.518 - ETA: 39s - loss: 2.0218 - accuracy: 0.518 - ETA: 36s - loss: 2.0234 - accuracy: 0.518 - ETA: 33s - loss: 2.0214 - accuracy: 0.518 - ETA: 30s - loss: 2.0239 - accuracy: 0.518 - ETA: 27s - loss: 2.0210 - accuracy: 0.518 - ETA: 24s - loss: 2.0227 - accuracy: 0.518 - ETA: 20s - loss: 2.0235 - accuracy: 0.517 - ETA: 17s - loss: 2.0215 - accuracy: 0.518 - ETA: 14s - loss: 2.0220 - accuracy: 0.517 - ETA: 11s - loss: 2.0221 - accuracy: 0.517 - ETA: 8s - loss: 2.0223 - accuracy: 0.518 - ETA: 5s - loss: 2.0236 - accuracy: 0.51 - ETA: 2s - loss: 2.0232 - accuracy: 0.51 - 512s 26ms/step - loss: 2.0225 - accuracy: 0.5174 - val_loss: 1.7379 - val_accuracy: 0.5891\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:36 - loss: 2.6520 - accuracy: 0.46 - ETA: 7:45 - loss: 2.3463 - accuracy: 0.51 - ETA: 7:27 - loss: 2.3043 - accuracy: 0.50 - ETA: 7:19 - loss: 2.2265 - accuracy: 0.51 - ETA: 7:17 - loss: 2.1257 - accuracy: 0.53 - ETA: 7:12 - loss: 2.0977 - accuracy: 0.54 - ETA: 7:10 - loss: 2.0709 - accuracy: 0.53 - ETA: 7:05 - loss: 2.1285 - accuracy: 0.52 - ETA: 7:02 - loss: 2.0502 - accuracy: 0.53 - ETA: 7:00 - loss: 2.0783 - accuracy: 0.53 - ETA: 6:58 - loss: 2.1889 - accuracy: 0.53 - ETA: 6:53 - loss: 2.1564 - accuracy: 0.53 - ETA: 6:48 - loss: 2.1758 - accuracy: 0.53 - ETA: 6:46 - loss: 2.1739 - accuracy: 0.53 - ETA: 6:43 - loss: 2.1689 - accuracy: 0.53 - ETA: 6:42 - loss: 2.1694 - accuracy: 0.52 - ETA: 6:38 - loss: 2.1596 - accuracy: 0.52 - ETA: 6:34 - loss: 2.1404 - accuracy: 0.52 - ETA: 6:31 - loss: 2.1403 - accuracy: 0.52 - ETA: 6:27 - loss: 2.1317 - accuracy: 0.51 - ETA: 6:25 - loss: 2.1162 - accuracy: 0.52 - ETA: 6:23 - loss: 2.1244 - accuracy: 0.51 - ETA: 6:19 - loss: 2.1202 - accuracy: 0.52 - ETA: 6:16 - loss: 2.0964 - accuracy: 0.52 - ETA: 6:13 - loss: 2.1180 - accuracy: 0.52 - ETA: 6:11 - loss: 2.1055 - accuracy: 0.52 - ETA: 6:09 - loss: 2.0889 - accuracy: 0.52 - ETA: 6:05 - loss: 2.0760 - accuracy: 0.52 - ETA: 6:00 - loss: 2.0677 - accuracy: 0.52 - ETA: 5:59 - loss: 2.0689 - accuracy: 0.52 - ETA: 5:57 - loss: 2.0879 - accuracy: 0.52 - ETA: 5:54 - loss: 2.0764 - accuracy: 0.52 - ETA: 5:51 - loss: 2.0702 - accuracy: 0.52 - ETA: 5:47 - loss: 2.0549 - accuracy: 0.52 - ETA: 5:44 - loss: 2.0509 - accuracy: 0.52 - ETA: 5:41 - loss: 2.0781 - accuracy: 0.52 - ETA: 5:40 - loss: 2.0748 - accuracy: 0.52 - ETA: 5:38 - loss: 2.0578 - accuracy: 0.52 - ETA: 5:34 - loss: 2.0485 - accuracy: 0.53 - ETA: 5:30 - loss: 2.0412 - accuracy: 0.53 - ETA: 5:27 - loss: 2.0525 - accuracy: 0.52 - ETA: 5:26 - loss: 2.0563 - accuracy: 0.52 - ETA: 5:23 - loss: 2.0684 - accuracy: 0.52 - ETA: 5:20 - loss: 2.0643 - accuracy: 0.52 - ETA: 5:17 - loss: 2.0644 - accuracy: 0.52 - ETA: 5:13 - loss: 2.0565 - accuracy: 0.52 - ETA: 5:11 - loss: 2.0549 - accuracy: 0.52 - ETA: 5:08 - loss: 2.0588 - accuracy: 0.52 - ETA: 5:04 - loss: 2.0577 - accuracy: 0.52 - ETA: 5:02 - loss: 2.0566 - accuracy: 0.52 - ETA: 4:59 - loss: 2.0543 - accuracy: 0.52 - ETA: 4:56 - loss: 2.0558 - accuracy: 0.52 - ETA: 4:52 - loss: 2.0502 - accuracy: 0.52 - ETA: 4:50 - loss: 2.0522 - accuracy: 0.52 - ETA: 4:47 - loss: 2.0555 - accuracy: 0.52 - ETA: 4:44 - loss: 2.0565 - accuracy: 0.52 - ETA: 4:41 - loss: 2.0623 - accuracy: 0.51 - ETA: 4:38 - loss: 2.0564 - accuracy: 0.52 - ETA: 4:35 - loss: 2.0661 - accuracy: 0.52 - ETA: 4:32 - loss: 2.0602 - accuracy: 0.52 - ETA: 4:29 - loss: 2.0622 - accuracy: 0.52 - ETA: 4:26 - loss: 2.0585 - accuracy: 0.52 - ETA: 4:23 - loss: 2.0566 - accuracy: 0.52 - ETA: 4:20 - loss: 2.0620 - accuracy: 0.52 - ETA: 4:17 - loss: 2.0620 - accuracy: 0.52 - ETA: 4:14 - loss: 2.0657 - accuracy: 0.51 - ETA: 4:11 - loss: 2.0603 - accuracy: 0.52 - ETA: 4:09 - loss: 2.0600 - accuracy: 0.51 - ETA: 4:07 - loss: 2.0597 - accuracy: 0.51 - ETA: 4:04 - loss: 2.0591 - accuracy: 0.51 - ETA: 4:01 - loss: 2.0664 - accuracy: 0.51 - ETA: 3:57 - loss: 2.0662 - accuracy: 0.51 - ETA: 3:55 - loss: 2.0708 - accuracy: 0.51 - ETA: 3:52 - loss: 2.0694 - accuracy: 0.51 - ETA: 3:49 - loss: 2.0649 - accuracy: 0.51 - ETA: 3:46 - loss: 2.0638 - accuracy: 0.51 - ETA: 3:42 - loss: 2.0682 - accuracy: 0.51 - ETA: 3:39 - loss: 2.0686 - accuracy: 0.51 - ETA: 3:37 - loss: 2.0639 - accuracy: 0.51 - ETA: 3:34 - loss: 2.0588 - accuracy: 0.51 - ETA: 3:31 - loss: 2.0557 - accuracy: 0.51 - ETA: 3:28 - loss: 2.0569 - accuracy: 0.51 - ETA: 3:25 - loss: 2.0513 - accuracy: 0.51 - ETA: 3:21 - loss: 2.0498 - accuracy: 0.51 - ETA: 3:19 - loss: 2.0468 - accuracy: 0.51 - ETA: 3:16 - loss: 2.0445 - accuracy: 0.51 - ETA: 3:13 - loss: 2.0426 - accuracy: 0.51 - ETA: 3:09 - loss: 2.0433 - accuracy: 0.51 - ETA: 3:06 - loss: 2.0428 - accuracy: 0.51 - ETA: 3:03 - loss: 2.0444 - accuracy: 0.51 - ETA: 3:00 - loss: 2.0394 - accuracy: 0.51 - ETA: 2:57 - loss: 2.0363 - accuracy: 0.51 - ETA: 2:54 - loss: 2.0357 - accuracy: 0.51 - ETA: 2:51 - loss: 2.0355 - accuracy: 0.51 - ETA: 2:48 - loss: 2.0417 - accuracy: 0.51 - ETA: 2:45 - loss: 2.0417 - accuracy: 0.51 - ETA: 2:42 - loss: 2.0397 - accuracy: 0.51 - ETA: 2:39 - loss: 2.0414 - accuracy: 0.51 - ETA: 2:36 - loss: 2.0608 - accuracy: 0.51 - ETA: 2:33 - loss: 2.0574 - accuracy: 0.51 - ETA: 2:30 - loss: 2.0539 - accuracy: 0.51 - ETA: 2:27 - loss: 2.0494 - accuracy: 0.51 - ETA: 2:24 - loss: 2.0486 - accuracy: 0.51 - ETA: 2:21 - loss: 2.0468 - accuracy: 0.51 - ETA: 2:18 - loss: 2.0427 - accuracy: 0.51 - ETA: 2:15 - loss: 2.0378 - accuracy: 0.51 - ETA: 2:12 - loss: 2.0355 - accuracy: 0.51 - ETA: 2:09 - loss: 2.0338 - accuracy: 0.51 - ETA: 2:06 - loss: 2.0300 - accuracy: 0.51 - ETA: 2:03 - loss: 2.0302 - accuracy: 0.52 - ETA: 2:00 - loss: 2.0714 - accuracy: 0.51 - ETA: 1:57 - loss: 2.0709 - accuracy: 0.51 - ETA: 1:54 - loss: 2.0703 - accuracy: 0.51 - ETA: 1:51 - loss: 2.0712 - accuracy: 0.51 - ETA: 1:48 - loss: 2.0745 - accuracy: 0.51 - ETA: 1:45 - loss: 2.0736 - accuracy: 0.51 - ETA: 1:42 - loss: 2.0734 - accuracy: 0.51 - ETA: 1:39 - loss: 2.0696 - accuracy: 0.51 - ETA: 1:36 - loss: 2.0727 - accuracy: 0.51 - ETA: 1:33 - loss: 2.0701 - accuracy: 0.51 - ETA: 1:30 - loss: 2.0739 - accuracy: 0.51 - ETA: 1:27 - loss: 2.0737 - accuracy: 0.51 - ETA: 1:24 - loss: 2.0721 - accuracy: 0.51 - ETA: 1:21 - loss: 2.0698 - accuracy: 0.51 - ETA: 1:18 - loss: 2.0684 - accuracy: 0.51 - ETA: 1:15 - loss: 2.0684 - accuracy: 0.51 - ETA: 1:12 - loss: 2.0705 - accuracy: 0.51 - ETA: 1:09 - loss: 2.0714 - accuracy: 0.51 - ETA: 1:06 - loss: 2.0731 - accuracy: 0.51 - ETA: 1:03 - loss: 2.0725 - accuracy: 0.51 - ETA: 1:00 - loss: 2.0738 - accuracy: 0.51 - ETA: 57s - loss: 2.0695 - accuracy: 0.5181 - ETA: 54s - loss: 2.0706 - accuracy: 0.518 - ETA: 51s - loss: 2.0708 - accuracy: 0.518 - ETA: 48s - loss: 2.0713 - accuracy: 0.518 - ETA: 45s - loss: 2.0670 - accuracy: 0.519 - ETA: 42s - loss: 2.0700 - accuracy: 0.519 - ETA: 39s - loss: 2.0677 - accuracy: 0.519 - ETA: 36s - loss: 2.0719 - accuracy: 0.519 - ETA: 33s - loss: 2.0700 - accuracy: 0.519 - ETA: 30s - loss: 2.0684 - accuracy: 0.519 - ETA: 26s - loss: 2.0687 - accuracy: 0.519 - ETA: 23s - loss: 2.0737 - accuracy: 0.518 - ETA: 20s - loss: 2.0723 - accuracy: 0.518 - ETA: 17s - loss: 2.0721 - accuracy: 0.518 - ETA: 14s - loss: 2.0692 - accuracy: 0.518 - ETA: 11s - loss: 2.0668 - accuracy: 0.519 - ETA: 8s - loss: 2.0661 - accuracy: 0.518 - ETA: 5s - loss: 2.0651 - accuracy: 0.51 - ETA: 2s - loss: 2.0653 - accuracy: 0.51 - 512s 26ms/step - loss: 2.0666 - accuracy: 0.5181 - val_loss: 1.7531 - val_accuracy: 0.5819\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:24 - loss: 1.9107 - accuracy: 0.51 - ETA: 7:33 - loss: 1.8375 - accuracy: 0.52 - ETA: 7:16 - loss: 1.8722 - accuracy: 0.52 - ETA: 7:25 - loss: 1.9557 - accuracy: 0.51 - ETA: 7:25 - loss: 1.9876 - accuracy: 0.51 - ETA: 7:17 - loss: 1.9961 - accuracy: 0.51 - ETA: 7:16 - loss: 2.0075 - accuracy: 0.51 - ETA: 7:08 - loss: 1.9624 - accuracy: 0.51 - ETA: 7:09 - loss: 2.0074 - accuracy: 0.51 - ETA: 7:04 - loss: 1.9648 - accuracy: 0.52 - ETA: 7:05 - loss: 1.9716 - accuracy: 0.52 - ETA: 7:03 - loss: 1.9948 - accuracy: 0.52 - ETA: 6:59 - loss: 1.9412 - accuracy: 0.52 - ETA: 6:56 - loss: 1.9418 - accuracy: 0.52 - ETA: 6:53 - loss: 1.9478 - accuracy: 0.52 - ETA: 6:50 - loss: 1.9388 - accuracy: 0.51 - ETA: 6:46 - loss: 1.9258 - accuracy: 0.52 - ETA: 6:42 - loss: 1.9367 - accuracy: 0.51 - ETA: 6:39 - loss: 1.9346 - accuracy: 0.51 - ETA: 6:37 - loss: 1.9331 - accuracy: 0.51 - ETA: 6:35 - loss: 1.9221 - accuracy: 0.51 - ETA: 6:32 - loss: 1.9177 - accuracy: 0.51 - ETA: 6:29 - loss: 1.9451 - accuracy: 0.51 - ETA: 6:26 - loss: 1.9489 - accuracy: 0.51 - ETA: 6:22 - loss: 1.9527 - accuracy: 0.51 - ETA: 6:19 - loss: 1.9498 - accuracy: 0.51 - ETA: 6:18 - loss: 1.9481 - accuracy: 0.51 - ETA: 6:14 - loss: 1.9567 - accuracy: 0.51 - ETA: 6:11 - loss: 1.9593 - accuracy: 0.51 - ETA: 6:07 - loss: 1.9481 - accuracy: 0.52 - ETA: 6:03 - loss: 1.9552 - accuracy: 0.51 - ETA: 6:02 - loss: 1.9560 - accuracy: 0.51 - ETA: 5:59 - loss: 1.9616 - accuracy: 0.51 - ETA: 5:55 - loss: 1.9516 - accuracy: 0.52 - ETA: 5:52 - loss: 1.9500 - accuracy: 0.52 - ETA: 5:48 - loss: 1.9434 - accuracy: 0.52 - ETA: 5:47 - loss: 1.9362 - accuracy: 0.52 - ETA: 5:43 - loss: 1.9262 - accuracy: 0.52 - ETA: 5:39 - loss: 1.9234 - accuracy: 0.52 - ETA: 5:36 - loss: 1.9217 - accuracy: 0.52 - ETA: 5:33 - loss: 1.9289 - accuracy: 0.52 - ETA: 5:30 - loss: 1.9285 - accuracy: 0.52 - ETA: 5:27 - loss: 1.9286 - accuracy: 0.52 - ETA: 5:23 - loss: 1.9391 - accuracy: 0.52 - ETA: 5:20 - loss: 1.9356 - accuracy: 0.52 - ETA: 5:17 - loss: 1.9315 - accuracy: 0.52 - ETA: 5:14 - loss: 1.9360 - accuracy: 0.52 - ETA: 5:12 - loss: 1.9360 - accuracy: 0.52 - ETA: 5:09 - loss: 1.9460 - accuracy: 0.52 - ETA: 5:06 - loss: 1.9438 - accuracy: 0.52 - ETA: 5:03 - loss: 1.9517 - accuracy: 0.52 - ETA: 5:00 - loss: 1.9448 - accuracy: 0.52 - ETA: 4:57 - loss: 1.9469 - accuracy: 0.52 - ETA: 4:54 - loss: 1.9446 - accuracy: 0.52 - ETA: 4:51 - loss: 1.9625 - accuracy: 0.52 - ETA: 4:48 - loss: 1.9661 - accuracy: 0.52 - ETA: 4:45 - loss: 1.9673 - accuracy: 0.52 - ETA: 4:42 - loss: 1.9649 - accuracy: 0.51 - ETA: 4:39 - loss: 1.9623 - accuracy: 0.52 - ETA: 4:36 - loss: 1.9578 - accuracy: 0.52 - ETA: 4:32 - loss: 1.9656 - accuracy: 0.52 - ETA: 4:29 - loss: 1.9627 - accuracy: 0.52 - ETA: 4:27 - loss: 1.9599 - accuracy: 0.52 - ETA: 4:23 - loss: 1.9597 - accuracy: 0.51 - ETA: 4:20 - loss: 1.9567 - accuracy: 0.52 - ETA: 4:17 - loss: 1.9565 - accuracy: 0.52 - ETA: 4:14 - loss: 1.9535 - accuracy: 0.52 - ETA: 4:11 - loss: 1.9603 - accuracy: 0.51 - ETA: 4:09 - loss: 1.9577 - accuracy: 0.51 - ETA: 4:06 - loss: 1.9505 - accuracy: 0.52 - ETA: 4:03 - loss: 1.9472 - accuracy: 0.52 - ETA: 3:59 - loss: 1.9452 - accuracy: 0.52 - ETA: 3:57 - loss: 1.9445 - accuracy: 0.52 - ETA: 3:54 - loss: 1.9401 - accuracy: 0.52 - ETA: 3:51 - loss: 1.9364 - accuracy: 0.52 - ETA: 3:48 - loss: 1.9388 - accuracy: 0.52 - ETA: 3:45 - loss: 1.9386 - accuracy: 0.52 - ETA: 3:42 - loss: 1.9414 - accuracy: 0.52 - ETA: 3:39 - loss: 1.9370 - accuracy: 0.52 - ETA: 3:36 - loss: 1.9348 - accuracy: 0.52 - ETA: 3:32 - loss: 1.9379 - accuracy: 0.52 - ETA: 3:29 - loss: 1.9352 - accuracy: 0.52 - ETA: 3:26 - loss: 1.9438 - accuracy: 0.52 - ETA: 3:23 - loss: 1.9457 - accuracy: 0.52 - ETA: 3:20 - loss: 1.9464 - accuracy: 0.52 - ETA: 3:17 - loss: 1.9489 - accuracy: 0.52 - ETA: 3:14 - loss: 1.9483 - accuracy: 0.52 - ETA: 3:11 - loss: 1.9494 - accuracy: 0.52 - ETA: 3:08 - loss: 1.9463 - accuracy: 0.52 - ETA: 3:05 - loss: 1.9474 - accuracy: 0.52 - ETA: 3:02 - loss: 1.9492 - accuracy: 0.52 - ETA: 2:58 - loss: 1.9545 - accuracy: 0.52 - ETA: 2:55 - loss: 1.9521 - accuracy: 0.52 - ETA: 2:52 - loss: 1.9499 - accuracy: 0.52 - ETA: 2:50 - loss: 1.9503 - accuracy: 0.52 - ETA: 2:46 - loss: 1.9525 - accuracy: 0.52 - ETA: 2:43 - loss: 1.9567 - accuracy: 0.52 - ETA: 2:41 - loss: 1.9506 - accuracy: 0.52 - ETA: 2:38 - loss: 1.9491 - accuracy: 0.52 - ETA: 2:35 - loss: 1.9461 - accuracy: 0.52 - ETA: 2:32 - loss: 1.9458 - accuracy: 0.52 - ETA: 2:29 - loss: 1.9508 - accuracy: 0.52 - ETA: 2:26 - loss: 1.9619 - accuracy: 0.52 - ETA: 2:23 - loss: 1.9599 - accuracy: 0.52 - ETA: 2:19 - loss: 1.9590 - accuracy: 0.52 - ETA: 2:16 - loss: 1.9595 - accuracy: 0.52 - ETA: 2:13 - loss: 1.9622 - accuracy: 0.52 - ETA: 2:10 - loss: 1.9622 - accuracy: 0.52 - ETA: 2:07 - loss: 1.9579 - accuracy: 0.52 - ETA: 2:04 - loss: 1.9560 - accuracy: 0.52 - ETA: 2:01 - loss: 1.9542 - accuracy: 0.52 - ETA: 1:58 - loss: 1.9503 - accuracy: 0.52 - ETA: 1:55 - loss: 1.9486 - accuracy: 0.52 - ETA: 1:52 - loss: 1.9488 - accuracy: 0.52 - ETA: 1:49 - loss: 1.9480 - accuracy: 0.52 - ETA: 1:46 - loss: 1.9448 - accuracy: 0.52 - ETA: 1:43 - loss: 1.9517 - accuracy: 0.52 - ETA: 1:40 - loss: 1.9509 - accuracy: 0.52 - ETA: 1:37 - loss: 1.9486 - accuracy: 0.52 - ETA: 1:34 - loss: 1.9479 - accuracy: 0.52 - ETA: 1:31 - loss: 1.9503 - accuracy: 0.52 - ETA: 1:28 - loss: 1.9488 - accuracy: 0.52 - ETA: 1:25 - loss: 1.9517 - accuracy: 0.52 - ETA: 1:22 - loss: 1.9520 - accuracy: 0.52 - ETA: 1:19 - loss: 1.9490 - accuracy: 0.52 - ETA: 1:16 - loss: 1.9516 - accuracy: 0.52 - ETA: 1:13 - loss: 1.9504 - accuracy: 0.52 - ETA: 1:10 - loss: 1.9505 - accuracy: 0.52 - ETA: 1:06 - loss: 1.9489 - accuracy: 0.52 - ETA: 1:03 - loss: 1.9469 - accuracy: 0.52 - ETA: 1:00 - loss: 1.9477 - accuracy: 0.52 - ETA: 57s - loss: 1.9498 - accuracy: 0.5251 - ETA: 54s - loss: 1.9482 - accuracy: 0.525 - ETA: 51s - loss: 1.9468 - accuracy: 0.525 - ETA: 48s - loss: 1.9477 - accuracy: 0.525 - ETA: 45s - loss: 1.9504 - accuracy: 0.525 - ETA: 42s - loss: 1.9489 - accuracy: 0.525 - ETA: 39s - loss: 1.9515 - accuracy: 0.525 - ETA: 36s - loss: 1.9522 - accuracy: 0.525 - ETA: 33s - loss: 1.9549 - accuracy: 0.524 - ETA: 30s - loss: 1.9530 - accuracy: 0.524 - ETA: 27s - loss: 1.9517 - accuracy: 0.524 - ETA: 24s - loss: 1.9527 - accuracy: 0.524 - ETA: 20s - loss: 1.9545 - accuracy: 0.524 - ETA: 17s - loss: 1.9532 - accuracy: 0.524 - ETA: 14s - loss: 1.9528 - accuracy: 0.524 - ETA: 11s - loss: 1.9544 - accuracy: 0.523 - ETA: 8s - loss: 1.9556 - accuracy: 0.523 - ETA: 5s - loss: 1.9544 - accuracy: 0.52 - ETA: 2s - loss: 1.9523 - accuracy: 0.52 - 504s 26ms/step - loss: 1.9509 - accuracy: 0.5242 - val_loss: 1.6176 - val_accuracy: 0.5910\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:02 - loss: 1.4866 - accuracy: 0.56 - ETA: 5:49 - loss: 3.8817 - accuracy: 0.51 - ETA: 5:41 - loss: 3.3444 - accuracy: 0.53 - ETA: 5:34 - loss: 3.0026 - accuracy: 0.52 - ETA: 5:30 - loss: 2.7792 - accuracy: 0.52 - ETA: 5:23 - loss: 2.6405 - accuracy: 0.52 - ETA: 5:19 - loss: 2.5729 - accuracy: 0.52 - ETA: 5:15 - loss: 2.5346 - accuracy: 0.52 - ETA: 5:11 - loss: 2.4858 - accuracy: 0.52 - ETA: 5:07 - loss: 2.3916 - accuracy: 0.52 - ETA: 5:04 - loss: 2.3272 - accuracy: 0.52 - ETA: 5:02 - loss: 2.2902 - accuracy: 0.52 - ETA: 4:59 - loss: 2.2347 - accuracy: 0.52 - ETA: 4:57 - loss: 2.2248 - accuracy: 0.52 - ETA: 4:53 - loss: 2.2257 - accuracy: 0.51 - ETA: 4:50 - loss: 2.1964 - accuracy: 0.52 - ETA: 4:49 - loss: 2.1823 - accuracy: 0.52 - ETA: 4:46 - loss: 2.1691 - accuracy: 0.52 - ETA: 4:44 - loss: 2.1425 - accuracy: 0.52 - ETA: 4:42 - loss: 2.1423 - accuracy: 0.51 - ETA: 4:40 - loss: 2.1633 - accuracy: 0.51 - ETA: 4:37 - loss: 2.1454 - accuracy: 0.51 - ETA: 4:36 - loss: 2.1337 - accuracy: 0.51 - ETA: 4:33 - loss: 2.1904 - accuracy: 0.51 - ETA: 4:31 - loss: 2.1704 - accuracy: 0.51 - ETA: 4:29 - loss: 2.1652 - accuracy: 0.51 - ETA: 4:27 - loss: 2.1486 - accuracy: 0.51 - ETA: 4:25 - loss: 2.1399 - accuracy: 0.51 - ETA: 4:22 - loss: 2.1310 - accuracy: 0.51 - ETA: 4:20 - loss: 2.1247 - accuracy: 0.51 - ETA: 4:18 - loss: 2.1216 - accuracy: 0.51 - ETA: 4:16 - loss: 2.1178 - accuracy: 0.51 - ETA: 4:14 - loss: 2.1209 - accuracy: 0.51 - ETA: 4:11 - loss: 2.1113 - accuracy: 0.51 - ETA: 4:10 - loss: 2.0971 - accuracy: 0.52 - ETA: 4:08 - loss: 2.0927 - accuracy: 0.52 - ETA: 4:06 - loss: 2.0912 - accuracy: 0.52 - ETA: 4:04 - loss: 2.1005 - accuracy: 0.52 - ETA: 4:01 - loss: 2.0927 - accuracy: 0.52 - ETA: 3:59 - loss: 2.0823 - accuracy: 0.52 - ETA: 3:57 - loss: 2.0769 - accuracy: 0.52 - ETA: 3:55 - loss: 2.0662 - accuracy: 0.52 - ETA: 3:53 - loss: 2.0563 - accuracy: 0.52 - ETA: 3:51 - loss: 2.0511 - accuracy: 0.52 - ETA: 3:49 - loss: 2.0457 - accuracy: 0.52 - ETA: 3:47 - loss: 2.0424 - accuracy: 0.52 - ETA: 3:45 - loss: 2.0306 - accuracy: 0.52 - ETA: 3:43 - loss: 2.0197 - accuracy: 0.52 - ETA: 3:41 - loss: 2.0193 - accuracy: 0.52 - ETA: 3:38 - loss: 2.0201 - accuracy: 0.52 - ETA: 3:36 - loss: 2.0181 - accuracy: 0.52 - ETA: 3:34 - loss: 2.0186 - accuracy: 0.52 - ETA: 3:31 - loss: 2.0144 - accuracy: 0.52 - ETA: 3:29 - loss: 2.0102 - accuracy: 0.52 - ETA: 3:27 - loss: 1.9992 - accuracy: 0.52 - ETA: 3:25 - loss: 1.9916 - accuracy: 0.52 - ETA: 3:23 - loss: 1.9921 - accuracy: 0.52 - ETA: 3:21 - loss: 1.9865 - accuracy: 0.52 - ETA: 3:18 - loss: 1.9852 - accuracy: 0.52 - ETA: 3:16 - loss: 1.9875 - accuracy: 0.52 - ETA: 3:14 - loss: 1.9886 - accuracy: 0.52 - ETA: 3:12 - loss: 1.9841 - accuracy: 0.52 - ETA: 3:10 - loss: 1.9804 - accuracy: 0.52 - ETA: 3:07 - loss: 1.9729 - accuracy: 0.52 - ETA: 3:05 - loss: 1.9676 - accuracy: 0.52 - ETA: 3:03 - loss: 1.9698 - accuracy: 0.52 - ETA: 3:01 - loss: 1.9743 - accuracy: 0.52 - ETA: 2:59 - loss: 1.9753 - accuracy: 0.52 - ETA: 2:57 - loss: 1.9776 - accuracy: 0.52 - ETA: 2:55 - loss: 1.9755 - accuracy: 0.52 - ETA: 2:53 - loss: 1.9710 - accuracy: 0.52 - ETA: 2:51 - loss: 1.9718 - accuracy: 0.52 - ETA: 2:49 - loss: 1.9664 - accuracy: 0.52 - ETA: 2:47 - loss: 1.9724 - accuracy: 0.52 - ETA: 2:45 - loss: 1.9680 - accuracy: 0.52 - ETA: 2:43 - loss: 1.9659 - accuracy: 0.52 - ETA: 2:41 - loss: 1.9650 - accuracy: 0.52 - ETA: 2:39 - loss: 1.9687 - accuracy: 0.52 - ETA: 2:37 - loss: 1.9729 - accuracy: 0.52 - ETA: 2:35 - loss: 1.9676 - accuracy: 0.52 - ETA: 2:33 - loss: 1.9704 - accuracy: 0.52 - ETA: 2:31 - loss: 1.9685 - accuracy: 0.52 - ETA: 2:29 - loss: 1.9666 - accuracy: 0.52 - ETA: 2:27 - loss: 1.9704 - accuracy: 0.52 - ETA: 2:25 - loss: 1.9700 - accuracy: 0.52 - ETA: 2:22 - loss: 1.9702 - accuracy: 0.52 - ETA: 2:20 - loss: 1.9686 - accuracy: 0.52 - ETA: 2:18 - loss: 1.9664 - accuracy: 0.52 - ETA: 2:17 - loss: 1.9645 - accuracy: 0.52 - ETA: 2:14 - loss: 1.9588 - accuracy: 0.52 - ETA: 2:12 - loss: 1.9549 - accuracy: 0.52 - ETA: 2:10 - loss: 1.9550 - accuracy: 0.52 - ETA: 2:08 - loss: 1.9539 - accuracy: 0.52 - ETA: 2:06 - loss: 1.9518 - accuracy: 0.52 - ETA: 2:04 - loss: 1.9518 - accuracy: 0.52 - ETA: 2:01 - loss: 1.9498 - accuracy: 0.52 - ETA: 1:59 - loss: 1.9478 - accuracy: 0.52 - ETA: 1:57 - loss: 1.9468 - accuracy: 0.52 - ETA: 1:55 - loss: 1.9447 - accuracy: 0.52 - ETA: 1:53 - loss: 1.9479 - accuracy: 0.52 - ETA: 1:51 - loss: 1.9480 - accuracy: 0.52 - ETA: 1:49 - loss: 1.9452 - accuracy: 0.52 - ETA: 1:46 - loss: 1.9419 - accuracy: 0.52 - ETA: 1:44 - loss: 1.9395 - accuracy: 0.52 - ETA: 1:42 - loss: 1.9395 - accuracy: 0.52 - ETA: 1:40 - loss: 1.9408 - accuracy: 0.52 - ETA: 1:38 - loss: 1.9400 - accuracy: 0.52 - ETA: 1:35 - loss: 1.9363 - accuracy: 0.52 - ETA: 1:33 - loss: 1.9393 - accuracy: 0.52 - ETA: 1:31 - loss: 1.9365 - accuracy: 0.52 - ETA: 1:29 - loss: 1.9348 - accuracy: 0.52 - ETA: 1:26 - loss: 1.9336 - accuracy: 0.52 - ETA: 1:24 - loss: 1.9337 - accuracy: 0.52 - ETA: 1:22 - loss: 1.9337 - accuracy: 0.52 - ETA: 1:20 - loss: 1.9340 - accuracy: 0.52 - ETA: 1:17 - loss: 1.9317 - accuracy: 0.52 - ETA: 1:15 - loss: 1.9371 - accuracy: 0.52 - ETA: 1:13 - loss: 1.9517 - accuracy: 0.52 - ETA: 1:11 - loss: 1.9501 - accuracy: 0.52 - ETA: 1:09 - loss: 1.9493 - accuracy: 0.52 - ETA: 1:06 - loss: 1.9474 - accuracy: 0.52 - ETA: 1:04 - loss: 1.9476 - accuracy: 0.52 - ETA: 1:02 - loss: 1.9491 - accuracy: 0.52 - ETA: 1:00 - loss: 1.9542 - accuracy: 0.52 - ETA: 58s - loss: 1.9534 - accuracy: 0.5276 - ETA: 55s - loss: 1.9508 - accuracy: 0.527 - ETA: 53s - loss: 1.9488 - accuracy: 0.528 - ETA: 51s - loss: 1.9478 - accuracy: 0.528 - ETA: 49s - loss: 1.9450 - accuracy: 0.528 - ETA: 46s - loss: 1.9472 - accuracy: 0.528 - ETA: 44s - loss: 1.9460 - accuracy: 0.528 - ETA: 42s - loss: 1.9439 - accuracy: 0.528 - ETA: 40s - loss: 1.9443 - accuracy: 0.528 - ETA: 37s - loss: 1.9430 - accuracy: 0.528 - ETA: 35s - loss: 1.9424 - accuracy: 0.528 - ETA: 33s - loss: 1.9430 - accuracy: 0.528 - ETA: 31s - loss: 1.9428 - accuracy: 0.528 - ETA: 28s - loss: 1.9422 - accuracy: 0.528 - ETA: 26s - loss: 1.9415 - accuracy: 0.528 - ETA: 24s - loss: 1.9447 - accuracy: 0.527 - ETA: 22s - loss: 1.9437 - accuracy: 0.527 - ETA: 20s - loss: 1.9465 - accuracy: 0.527 - ETA: 18s - loss: 1.9463 - accuracy: 0.527 - ETA: 15s - loss: 1.9486 - accuracy: 0.527 - ETA: 13s - loss: 1.9449 - accuracy: 0.528 - ETA: 11s - loss: 1.9411 - accuracy: 0.528 - ETA: 8s - loss: 1.9388 - accuracy: 0.528 - ETA: 6s - loss: 1.9392 - accuracy: 0.52 - ETA: 4s - loss: 1.9391 - accuracy: 0.52 - ETA: 2s - loss: 1.9378 - accuracy: 0.52 - 382s 20ms/step - loss: 1.9366 - accuracy: 0.5288 - val_loss: 1.6193 - val_accuracy: 0.6024\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:09 - loss: 1.7686 - accuracy: 0.53 - ETA: 5:17 - loss: 1.7813 - accuracy: 0.53 - ETA: 5:22 - loss: 1.7809 - accuracy: 0.54 - ETA: 5:22 - loss: 1.8039 - accuracy: 0.52 - ETA: 5:18 - loss: 1.8014 - accuracy: 0.52 - ETA: 5:14 - loss: 1.8517 - accuracy: 0.52 - ETA: 5:19 - loss: 1.9094 - accuracy: 0.52 - ETA: 5:18 - loss: 1.8959 - accuracy: 0.52 - ETA: 5:14 - loss: 1.9632 - accuracy: 0.51 - ETA: 5:12 - loss: 1.9725 - accuracy: 0.51 - ETA: 5:09 - loss: 1.9574 - accuracy: 0.51 - ETA: 5:07 - loss: 1.9183 - accuracy: 0.52 - ETA: 5:06 - loss: 1.9451 - accuracy: 0.51 - ETA: 5:03 - loss: 1.9549 - accuracy: 0.51 - ETA: 5:01 - loss: 1.9595 - accuracy: 0.51 - ETA: 4:57 - loss: 2.0014 - accuracy: 0.51 - ETA: 4:54 - loss: 1.9999 - accuracy: 0.51 - ETA: 4:52 - loss: 2.0010 - accuracy: 0.51 - ETA: 4:49 - loss: 1.9696 - accuracy: 0.51 - ETA: 4:47 - loss: 1.9863 - accuracy: 0.51 - ETA: 4:45 - loss: 1.9739 - accuracy: 0.52 - ETA: 4:45 - loss: 1.9787 - accuracy: 0.51 - ETA: 4:42 - loss: 1.9800 - accuracy: 0.52 - ETA: 4:40 - loss: 1.9664 - accuracy: 0.52 - ETA: 4:38 - loss: 1.9674 - accuracy: 0.52 - ETA: 4:35 - loss: 1.9684 - accuracy: 0.52 - ETA: 4:33 - loss: 1.9564 - accuracy: 0.52 - ETA: 4:31 - loss: 1.9519 - accuracy: 0.52 - ETA: 4:29 - loss: 1.9615 - accuracy: 0.52 - ETA: 4:27 - loss: 1.9456 - accuracy: 0.52 - ETA: 4:24 - loss: 1.9510 - accuracy: 0.52 - ETA: 4:22 - loss: 1.9411 - accuracy: 0.52 - ETA: 4:20 - loss: 1.9450 - accuracy: 0.52 - ETA: 4:18 - loss: 1.9348 - accuracy: 0.52 - ETA: 4:16 - loss: 1.9267 - accuracy: 0.53 - ETA: 4:14 - loss: 1.9276 - accuracy: 0.52 - ETA: 4:12 - loss: 1.9197 - accuracy: 0.53 - ETA: 4:10 - loss: 1.9161 - accuracy: 0.53 - ETA: 4:07 - loss: 1.9298 - accuracy: 0.53 - ETA: 4:05 - loss: 1.9326 - accuracy: 0.53 - ETA: 4:02 - loss: 1.9311 - accuracy: 0.53 - ETA: 4:00 - loss: 1.9235 - accuracy: 0.53 - ETA: 3:58 - loss: 1.9218 - accuracy: 0.53 - ETA: 3:56 - loss: 1.9178 - accuracy: 0.53 - ETA: 3:54 - loss: 1.9491 - accuracy: 0.52 - ETA: 3:52 - loss: 1.9475 - accuracy: 0.52 - ETA: 3:50 - loss: 1.9493 - accuracy: 0.52 - ETA: 3:47 - loss: 1.9579 - accuracy: 0.52 - ETA: 3:45 - loss: 1.9641 - accuracy: 0.52 - ETA: 3:43 - loss: 1.9677 - accuracy: 0.52 - ETA: 3:41 - loss: 1.9590 - accuracy: 0.52 - ETA: 3:39 - loss: 1.9567 - accuracy: 0.52 - ETA: 3:36 - loss: 1.9553 - accuracy: 0.52 - ETA: 3:33 - loss: 1.9592 - accuracy: 0.52 - ETA: 3:31 - loss: 1.9555 - accuracy: 0.52 - ETA: 3:29 - loss: 1.9618 - accuracy: 0.52 - ETA: 3:27 - loss: 1.9575 - accuracy: 0.52 - ETA: 3:24 - loss: 1.9661 - accuracy: 0.52 - ETA: 3:22 - loss: 1.9692 - accuracy: 0.52 - ETA: 3:20 - loss: 1.9728 - accuracy: 0.51 - ETA: 3:18 - loss: 1.9748 - accuracy: 0.51 - ETA: 3:15 - loss: 1.9688 - accuracy: 0.51 - ETA: 3:13 - loss: 1.9787 - accuracy: 0.51 - ETA: 3:11 - loss: 1.9793 - accuracy: 0.51 - ETA: 3:08 - loss: 1.9769 - accuracy: 0.51 - ETA: 3:06 - loss: 1.9711 - accuracy: 0.51 - ETA: 3:04 - loss: 1.9761 - accuracy: 0.51 - ETA: 3:02 - loss: 1.9795 - accuracy: 0.51 - ETA: 2:59 - loss: 1.9809 - accuracy: 0.51 - ETA: 2:57 - loss: 1.9743 - accuracy: 0.51 - ETA: 2:55 - loss: 1.9680 - accuracy: 0.52 - ETA: 2:53 - loss: 1.9694 - accuracy: 0.51 - ETA: 2:51 - loss: 1.9681 - accuracy: 0.51 - ETA: 2:48 - loss: 1.9687 - accuracy: 0.51 - ETA: 2:46 - loss: 1.9702 - accuracy: 0.51 - ETA: 2:44 - loss: 1.9728 - accuracy: 0.51 - ETA: 2:42 - loss: 1.9884 - accuracy: 0.51 - ETA: 2:40 - loss: 1.9836 - accuracy: 0.51 - ETA: 2:37 - loss: 1.9861 - accuracy: 0.51 - ETA: 2:35 - loss: 1.9892 - accuracy: 0.51 - ETA: 2:33 - loss: 1.9891 - accuracy: 0.51 - ETA: 2:31 - loss: 1.9851 - accuracy: 0.51 - ETA: 2:29 - loss: 1.9877 - accuracy: 0.51 - ETA: 2:26 - loss: 1.9867 - accuracy: 0.51 - ETA: 2:24 - loss: 1.9851 - accuracy: 0.51 - ETA: 2:22 - loss: 1.9867 - accuracy: 0.51 - ETA: 2:20 - loss: 1.9808 - accuracy: 0.51 - ETA: 2:17 - loss: 1.9823 - accuracy: 0.51 - ETA: 2:15 - loss: 1.9807 - accuracy: 0.51 - ETA: 2:13 - loss: 1.9780 - accuracy: 0.51 - ETA: 2:11 - loss: 1.9766 - accuracy: 0.51 - ETA: 2:09 - loss: 1.9766 - accuracy: 0.51 - ETA: 2:06 - loss: 1.9753 - accuracy: 0.52 - ETA: 2:04 - loss: 1.9737 - accuracy: 0.52 - ETA: 2:02 - loss: 1.9715 - accuracy: 0.52 - ETA: 2:00 - loss: 1.9776 - accuracy: 0.51 - ETA: 1:58 - loss: 1.9747 - accuracy: 0.52 - ETA: 1:55 - loss: 1.9701 - accuracy: 0.52 - ETA: 1:53 - loss: 1.9707 - accuracy: 0.52 - ETA: 1:51 - loss: 1.9714 - accuracy: 0.52 - ETA: 1:49 - loss: 1.9765 - accuracy: 0.52 - ETA: 1:47 - loss: 1.9768 - accuracy: 0.51 - ETA: 1:44 - loss: 1.9731 - accuracy: 0.52 - ETA: 1:42 - loss: 1.9739 - accuracy: 0.52 - ETA: 1:40 - loss: 1.9746 - accuracy: 0.52 - ETA: 1:38 - loss: 1.9741 - accuracy: 0.52 - ETA: 1:36 - loss: 1.9742 - accuracy: 0.52 - ETA: 1:33 - loss: 1.9709 - accuracy: 0.52 - ETA: 1:31 - loss: 1.9704 - accuracy: 0.51 - ETA: 1:29 - loss: 1.9692 - accuracy: 0.51 - ETA: 1:27 - loss: 1.9674 - accuracy: 0.52 - ETA: 1:25 - loss: 1.9647 - accuracy: 0.52 - ETA: 1:23 - loss: 1.9637 - accuracy: 0.52 - ETA: 1:20 - loss: 1.9660 - accuracy: 0.51 - ETA: 1:18 - loss: 1.9675 - accuracy: 0.51 - ETA: 1:16 - loss: 1.9660 - accuracy: 0.52 - ETA: 1:14 - loss: 1.9667 - accuracy: 0.51 - ETA: 1:12 - loss: 1.9665 - accuracy: 0.51 - ETA: 1:09 - loss: 1.9656 - accuracy: 0.51 - ETA: 1:07 - loss: 1.9655 - accuracy: 0.51 - ETA: 1:05 - loss: 1.9646 - accuracy: 0.51 - ETA: 1:03 - loss: 1.9617 - accuracy: 0.51 - ETA: 1:01 - loss: 1.9610 - accuracy: 0.52 - ETA: 58s - loss: 1.9674 - accuracy: 0.5203 - ETA: 56s - loss: 1.9675 - accuracy: 0.520 - ETA: 54s - loss: 1.9717 - accuracy: 0.520 - ETA: 52s - loss: 1.9733 - accuracy: 0.519 - ETA: 50s - loss: 1.9739 - accuracy: 0.519 - ETA: 47s - loss: 1.9744 - accuracy: 0.519 - ETA: 45s - loss: 1.9727 - accuracy: 0.520 - ETA: 43s - loss: 1.9728 - accuracy: 0.519 - ETA: 41s - loss: 1.9726 - accuracy: 0.519 - ETA: 39s - loss: 1.9765 - accuracy: 0.518 - ETA: 37s - loss: 1.9758 - accuracy: 0.519 - ETA: 34s - loss: 1.9728 - accuracy: 0.519 - ETA: 32s - loss: 1.9693 - accuracy: 0.520 - ETA: 30s - loss: 1.9658 - accuracy: 0.521 - ETA: 28s - loss: 1.9642 - accuracy: 0.521 - ETA: 26s - loss: 1.9636 - accuracy: 0.521 - ETA: 23s - loss: 1.9619 - accuracy: 0.522 - ETA: 21s - loss: 1.9597 - accuracy: 0.521 - ETA: 19s - loss: 1.9584 - accuracy: 0.522 - ETA: 17s - loss: 1.9599 - accuracy: 0.522 - ETA: 15s - loss: 1.9582 - accuracy: 0.522 - ETA: 13s - loss: 1.9623 - accuracy: 0.521 - ETA: 10s - loss: 1.9613 - accuracy: 0.521 - ETA: 8s - loss: 1.9608 - accuracy: 0.521 - ETA: 6s - loss: 1.9623 - accuracy: 0.52 - ETA: 4s - loss: 1.9597 - accuracy: 0.52 - ETA: 1s - loss: 1.9573 - accuracy: 0.52 - 367s 19ms/step - loss: 1.9549 - accuracy: 0.5225 - val_loss: 1.6519 - val_accuracy: 0.5887\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:25 - loss: 1.1987 - accuracy: 0.58 - ETA: 5:23 - loss: 1.4073 - accuracy: 0.57 - ETA: 5:18 - loss: 1.6036 - accuracy: 0.55 - ETA: 5:19 - loss: 1.8146 - accuracy: 0.53 - ETA: 5:20 - loss: 1.8265 - accuracy: 0.52 - ETA: 5:18 - loss: 1.7816 - accuracy: 0.53 - ETA: 5:16 - loss: 1.7539 - accuracy: 0.53 - ETA: 5:29 - loss: 1.7871 - accuracy: 0.53 - ETA: 5:26 - loss: 1.7704 - accuracy: 0.53 - ETA: 5:22 - loss: 1.8130 - accuracy: 0.52 - ETA: 5:19 - loss: 1.8227 - accuracy: 0.52 - ETA: 5:14 - loss: 1.8268 - accuracy: 0.52 - ETA: 5:10 - loss: 1.7967 - accuracy: 0.53 - ETA: 5:07 - loss: 1.8130 - accuracy: 0.52 - ETA: 5:03 - loss: 1.8148 - accuracy: 0.52 - ETA: 5:00 - loss: 1.7964 - accuracy: 0.53 - ETA: 4:57 - loss: 1.8181 - accuracy: 0.53 - ETA: 4:54 - loss: 1.8610 - accuracy: 0.52 - ETA: 4:52 - loss: 1.8658 - accuracy: 0.52 - ETA: 4:49 - loss: 1.8721 - accuracy: 0.52 - ETA: 4:47 - loss: 1.8606 - accuracy: 0.53 - ETA: 4:44 - loss: 1.8470 - accuracy: 0.53 - ETA: 4:43 - loss: 1.8543 - accuracy: 0.52 - ETA: 4:40 - loss: 1.8629 - accuracy: 0.52 - ETA: 4:38 - loss: 1.8493 - accuracy: 0.52 - ETA: 4:35 - loss: 1.8482 - accuracy: 0.52 - ETA: 4:33 - loss: 1.9000 - accuracy: 0.52 - ETA: 4:30 - loss: 1.8917 - accuracy: 0.52 - ETA: 4:28 - loss: 1.9009 - accuracy: 0.52 - ETA: 4:28 - loss: 1.9037 - accuracy: 0.52 - ETA: 4:25 - loss: 1.9104 - accuracy: 0.53 - ETA: 4:23 - loss: 1.9021 - accuracy: 0.53 - ETA: 4:20 - loss: 1.9000 - accuracy: 0.53 - ETA: 4:18 - loss: 1.9035 - accuracy: 0.53 - ETA: 4:16 - loss: 1.9164 - accuracy: 0.52 - ETA: 4:13 - loss: 1.9268 - accuracy: 0.52 - ETA: 4:11 - loss: 1.9270 - accuracy: 0.52 - ETA: 4:09 - loss: 1.9323 - accuracy: 0.52 - ETA: 4:07 - loss: 1.9525 - accuracy: 0.52 - ETA: 4:04 - loss: 1.9561 - accuracy: 0.52 - ETA: 4:01 - loss: 1.9695 - accuracy: 0.52 - ETA: 4:00 - loss: 1.9684 - accuracy: 0.52 - ETA: 3:57 - loss: 1.9650 - accuracy: 0.52 - ETA: 3:55 - loss: 1.9681 - accuracy: 0.52 - ETA: 3:52 - loss: 1.9628 - accuracy: 0.52 - ETA: 3:50 - loss: 1.9706 - accuracy: 0.52 - ETA: 3:48 - loss: 1.9733 - accuracy: 0.52 - ETA: 3:45 - loss: 1.9606 - accuracy: 0.52 - ETA: 3:43 - loss: 1.9584 - accuracy: 0.52 - ETA: 3:43 - loss: 1.9625 - accuracy: 0.52 - ETA: 3:41 - loss: 1.9580 - accuracy: 0.52 - ETA: 3:39 - loss: 1.9582 - accuracy: 0.52 - ETA: 3:36 - loss: 1.9584 - accuracy: 0.52 - ETA: 3:34 - loss: 1.9551 - accuracy: 0.52 - ETA: 3:32 - loss: 1.9486 - accuracy: 0.52 - ETA: 3:30 - loss: 1.9446 - accuracy: 0.52 - ETA: 3:28 - loss: 1.9504 - accuracy: 0.52 - ETA: 3:26 - loss: 1.9497 - accuracy: 0.52 - ETA: 3:24 - loss: 1.9483 - accuracy: 0.52 - ETA: 3:22 - loss: 1.9494 - accuracy: 0.52 - ETA: 3:19 - loss: 1.9514 - accuracy: 0.52 - ETA: 3:17 - loss: 1.9503 - accuracy: 0.52 - ETA: 3:15 - loss: 1.9442 - accuracy: 0.52 - ETA: 3:12 - loss: 1.9410 - accuracy: 0.52 - ETA: 3:10 - loss: 1.9443 - accuracy: 0.52 - ETA: 3:08 - loss: 1.9442 - accuracy: 0.52 - ETA: 3:06 - loss: 1.9422 - accuracy: 0.52 - ETA: 3:04 - loss: 1.9435 - accuracy: 0.52 - ETA: 3:02 - loss: 1.9387 - accuracy: 0.53 - ETA: 2:59 - loss: 1.9342 - accuracy: 0.53 - ETA: 2:57 - loss: 1.9326 - accuracy: 0.53 - ETA: 2:55 - loss: 1.9338 - accuracy: 0.53 - ETA: 2:53 - loss: 1.9354 - accuracy: 0.52 - ETA: 2:51 - loss: 1.9356 - accuracy: 0.52 - ETA: 2:48 - loss: 1.9429 - accuracy: 0.52 - ETA: 2:46 - loss: 1.9424 - accuracy: 0.52 - ETA: 2:44 - loss: 1.9447 - accuracy: 0.52 - ETA: 2:42 - loss: 1.9513 - accuracy: 0.52 - ETA: 2:39 - loss: 1.9494 - accuracy: 0.52 - ETA: 2:37 - loss: 1.9512 - accuracy: 0.52 - ETA: 2:35 - loss: 1.9522 - accuracy: 0.52 - ETA: 2:32 - loss: 1.9544 - accuracy: 0.52 - ETA: 2:30 - loss: 1.9556 - accuracy: 0.52 - ETA: 2:28 - loss: 1.9512 - accuracy: 0.52 - ETA: 2:26 - loss: 1.9537 - accuracy: 0.52 - ETA: 2:23 - loss: 1.9500 - accuracy: 0.52 - ETA: 2:22 - loss: 1.9534 - accuracy: 0.52 - ETA: 2:19 - loss: 1.9531 - accuracy: 0.52 - ETA: 2:17 - loss: 1.9505 - accuracy: 0.52 - ETA: 2:15 - loss: 1.9482 - accuracy: 0.52 - ETA: 2:13 - loss: 1.9554 - accuracy: 0.52 - ETA: 2:10 - loss: 1.9508 - accuracy: 0.52 - ETA: 2:08 - loss: 1.9485 - accuracy: 0.52 - ETA: 2:06 - loss: 1.9517 - accuracy: 0.52 - ETA: 2:04 - loss: 1.9528 - accuracy: 0.52 - ETA: 2:01 - loss: 1.9511 - accuracy: 0.52 - ETA: 1:59 - loss: 1.9476 - accuracy: 0.52 - ETA: 1:57 - loss: 1.9502 - accuracy: 0.52 - ETA: 1:55 - loss: 1.9506 - accuracy: 0.52 - ETA: 1:52 - loss: 1.9485 - accuracy: 0.52 - ETA: 1:50 - loss: 1.9489 - accuracy: 0.52 - ETA: 1:48 - loss: 1.9489 - accuracy: 0.52 - ETA: 1:46 - loss: 1.9505 - accuracy: 0.52 - ETA: 1:44 - loss: 1.9479 - accuracy: 0.52 - ETA: 1:42 - loss: 1.9479 - accuracy: 0.52 - ETA: 1:39 - loss: 1.9421 - accuracy: 0.52 - ETA: 1:37 - loss: 1.9651 - accuracy: 0.52 - ETA: 1:35 - loss: 1.9654 - accuracy: 0.52 - ETA: 1:33 - loss: 1.9670 - accuracy: 0.52 - ETA: 1:31 - loss: 1.9629 - accuracy: 0.52 - ETA: 1:28 - loss: 1.9659 - accuracy: 0.52 - ETA: 1:26 - loss: 1.9622 - accuracy: 0.52 - ETA: 1:24 - loss: 1.9603 - accuracy: 0.52 - ETA: 1:22 - loss: 1.9612 - accuracy: 0.52 - ETA: 1:19 - loss: 1.9574 - accuracy: 0.52 - ETA: 1:17 - loss: 1.9578 - accuracy: 0.52 - ETA: 1:15 - loss: 1.9583 - accuracy: 0.52 - ETA: 1:13 - loss: 1.9568 - accuracy: 0.52 - ETA: 1:11 - loss: 1.9558 - accuracy: 0.52 - ETA: 1:08 - loss: 1.9540 - accuracy: 0.52 - ETA: 1:06 - loss: 1.9502 - accuracy: 0.52 - ETA: 1:04 - loss: 1.9511 - accuracy: 0.52 - ETA: 1:02 - loss: 1.9543 - accuracy: 0.52 - ETA: 59s - loss: 1.9529 - accuracy: 0.5240 - ETA: 57s - loss: 1.9530 - accuracy: 0.523 - ETA: 55s - loss: 1.9505 - accuracy: 0.524 - ETA: 53s - loss: 1.9501 - accuracy: 0.525 - ETA: 51s - loss: 1.9504 - accuracy: 0.524 - ETA: 48s - loss: 1.9511 - accuracy: 0.524 - ETA: 46s - loss: 1.9542 - accuracy: 0.524 - ETA: 44s - loss: 1.9551 - accuracy: 0.524 - ETA: 42s - loss: 1.9530 - accuracy: 0.524 - ETA: 40s - loss: 1.9508 - accuracy: 0.524 - ETA: 37s - loss: 1.9512 - accuracy: 0.524 - ETA: 35s - loss: 1.9512 - accuracy: 0.525 - ETA: 33s - loss: 1.9484 - accuracy: 0.525 - ETA: 31s - loss: 1.9470 - accuracy: 0.525 - ETA: 28s - loss: 1.9475 - accuracy: 0.524 - ETA: 26s - loss: 1.9475 - accuracy: 0.525 - ETA: 24s - loss: 1.9465 - accuracy: 0.525 - ETA: 22s - loss: 1.9441 - accuracy: 0.525 - ETA: 20s - loss: 1.9438 - accuracy: 0.525 - ETA: 17s - loss: 1.9416 - accuracy: 0.525 - ETA: 15s - loss: 1.9425 - accuracy: 0.525 - ETA: 13s - loss: 1.9455 - accuracy: 0.525 - ETA: 11s - loss: 1.9442 - accuracy: 0.525 - ETA: 8s - loss: 1.9441 - accuracy: 0.525 - ETA: 6s - loss: 1.9429 - accuracy: 0.52 - ETA: 4s - loss: 1.9401 - accuracy: 0.52 - ETA: 1s - loss: 1.9388 - accuracy: 0.52 - 383s 20ms/step - loss: 1.9377 - accuracy: 0.5259 - val_loss: 1.6920 - val_accuracy: 0.5767\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:24 - loss: 2.1698 - accuracy: 0.46 - ETA: 5:15 - loss: 1.8662 - accuracy: 0.51 - ETA: 5:11 - loss: 1.9004 - accuracy: 0.52 - ETA: 5:08 - loss: 1.9077 - accuracy: 0.52 - ETA: 5:07 - loss: 1.8351 - accuracy: 0.53 - ETA: 5:04 - loss: 1.8431 - accuracy: 0.53 - ETA: 5:00 - loss: 1.8477 - accuracy: 0.53 - ETA: 5:00 - loss: 1.8811 - accuracy: 0.52 - ETA: 4:58 - loss: 1.8471 - accuracy: 0.53 - ETA: 4:57 - loss: 1.8504 - accuracy: 0.53 - ETA: 4:55 - loss: 1.8661 - accuracy: 0.52 - ETA: 4:53 - loss: 1.8589 - accuracy: 0.52 - ETA: 4:51 - loss: 1.8413 - accuracy: 0.53 - ETA: 4:51 - loss: 1.8425 - accuracy: 0.53 - ETA: 4:50 - loss: 1.8719 - accuracy: 0.52 - ETA: 4:47 - loss: 1.8567 - accuracy: 0.52 - ETA: 4:47 - loss: 1.8693 - accuracy: 0.53 - ETA: 4:45 - loss: 1.8799 - accuracy: 0.52 - ETA: 4:43 - loss: 1.8722 - accuracy: 0.52 - ETA: 4:40 - loss: 1.8853 - accuracy: 0.52 - ETA: 4:37 - loss: 1.8874 - accuracy: 0.52 - ETA: 4:35 - loss: 1.8972 - accuracy: 0.52 - ETA: 4:33 - loss: 1.9079 - accuracy: 0.52 - ETA: 4:31 - loss: 1.9252 - accuracy: 0.52 - ETA: 4:29 - loss: 1.9231 - accuracy: 0.52 - ETA: 4:27 - loss: 1.9099 - accuracy: 0.52 - ETA: 4:25 - loss: 1.8921 - accuracy: 0.52 - ETA: 4:23 - loss: 1.8825 - accuracy: 0.52 - ETA: 4:20 - loss: 1.8862 - accuracy: 0.52 - ETA: 4:18 - loss: 1.8978 - accuracy: 0.52 - ETA: 4:16 - loss: 1.9018 - accuracy: 0.52 - ETA: 4:14 - loss: 1.8956 - accuracy: 0.52 - ETA: 4:12 - loss: 1.8923 - accuracy: 0.52 - ETA: 4:10 - loss: 1.8840 - accuracy: 0.52 - ETA: 4:07 - loss: 1.8823 - accuracy: 0.52 - ETA: 4:05 - loss: 1.8807 - accuracy: 0.52 - ETA: 4:03 - loss: 1.8853 - accuracy: 0.52 - ETA: 4:00 - loss: 1.8972 - accuracy: 0.52 - ETA: 3:58 - loss: 1.8886 - accuracy: 0.52 - ETA: 3:56 - loss: 1.8848 - accuracy: 0.52 - ETA: 3:54 - loss: 1.8889 - accuracy: 0.52 - ETA: 3:52 - loss: 1.8842 - accuracy: 0.52 - ETA: 3:50 - loss: 1.8771 - accuracy: 0.52 - ETA: 3:48 - loss: 1.8786 - accuracy: 0.52 - ETA: 3:46 - loss: 1.8792 - accuracy: 0.52 - ETA: 3:44 - loss: 1.8805 - accuracy: 0.52 - ETA: 3:41 - loss: 1.8818 - accuracy: 0.52 - ETA: 3:39 - loss: 1.8806 - accuracy: 0.52 - ETA: 3:37 - loss: 1.8825 - accuracy: 0.52 - ETA: 3:35 - loss: 1.8875 - accuracy: 0.52 - ETA: 3:32 - loss: 1.8866 - accuracy: 0.52 - ETA: 3:30 - loss: 1.8885 - accuracy: 0.52 - ETA: 3:28 - loss: 1.8921 - accuracy: 0.52 - ETA: 3:26 - loss: 1.8879 - accuracy: 0.52 - ETA: 3:24 - loss: 1.8862 - accuracy: 0.52 - ETA: 3:22 - loss: 1.8892 - accuracy: 0.52 - ETA: 3:19 - loss: 1.8889 - accuracy: 0.52 - ETA: 3:17 - loss: 1.8878 - accuracy: 0.52 - ETA: 3:15 - loss: 1.8866 - accuracy: 0.52 - ETA: 3:13 - loss: 1.8896 - accuracy: 0.52 - ETA: 3:11 - loss: 1.8883 - accuracy: 0.52 - ETA: 3:09 - loss: 1.8905 - accuracy: 0.52 - ETA: 3:07 - loss: 1.8927 - accuracy: 0.51 - ETA: 3:05 - loss: 1.8947 - accuracy: 0.51 - ETA: 3:03 - loss: 1.8932 - accuracy: 0.51 - ETA: 3:00 - loss: 1.8898 - accuracy: 0.51 - ETA: 2:58 - loss: 1.8897 - accuracy: 0.51 - ETA: 2:56 - loss: 1.8958 - accuracy: 0.52 - ETA: 2:54 - loss: 1.8985 - accuracy: 0.51 - ETA: 2:52 - loss: 1.8982 - accuracy: 0.51 - ETA: 2:50 - loss: 1.8896 - accuracy: 0.52 - ETA: 2:48 - loss: 1.8854 - accuracy: 0.52 - ETA: 2:46 - loss: 1.8848 - accuracy: 0.52 - ETA: 2:44 - loss: 1.8848 - accuracy: 0.52 - ETA: 2:42 - loss: 1.8831 - accuracy: 0.52 - ETA: 2:40 - loss: 1.8860 - accuracy: 0.52 - ETA: 2:38 - loss: 1.8938 - accuracy: 0.52 - ETA: 2:36 - loss: 1.8910 - accuracy: 0.52 - ETA: 2:33 - loss: 1.8994 - accuracy: 0.52 - ETA: 2:31 - loss: 1.8966 - accuracy: 0.52 - ETA: 2:29 - loss: 1.8945 - accuracy: 0.52 - ETA: 2:27 - loss: 1.8937 - accuracy: 0.52 - ETA: 2:25 - loss: 1.8951 - accuracy: 0.52 - ETA: 2:23 - loss: 1.8918 - accuracy: 0.52 - ETA: 2:20 - loss: 1.8942 - accuracy: 0.52 - ETA: 2:18 - loss: 1.8881 - accuracy: 0.52 - ETA: 2:16 - loss: 1.8856 - accuracy: 0.52 - ETA: 2:14 - loss: 1.8854 - accuracy: 0.52 - ETA: 2:12 - loss: 1.8882 - accuracy: 0.52 - ETA: 2:10 - loss: 1.8885 - accuracy: 0.52 - ETA: 2:08 - loss: 1.8880 - accuracy: 0.52 - ETA: 2:05 - loss: 1.8837 - accuracy: 0.52 - ETA: 2:03 - loss: 1.8825 - accuracy: 0.52 - ETA: 2:01 - loss: 1.8817 - accuracy: 0.52 - ETA: 1:59 - loss: 1.8868 - accuracy: 0.52 - ETA: 1:57 - loss: 1.8861 - accuracy: 0.52 - ETA: 1:55 - loss: 1.8826 - accuracy: 0.52 - ETA: 1:53 - loss: 1.8807 - accuracy: 0.52 - ETA: 1:50 - loss: 1.8826 - accuracy: 0.52 - ETA: 1:48 - loss: 1.8816 - accuracy: 0.52 - ETA: 1:46 - loss: 1.8799 - accuracy: 0.52 - ETA: 1:44 - loss: 1.8814 - accuracy: 0.52 - ETA: 1:42 - loss: 1.8820 - accuracy: 0.52 - ETA: 1:40 - loss: 1.8830 - accuracy: 0.52 - ETA: 1:38 - loss: 1.8818 - accuracy: 0.52 - ETA: 1:35 - loss: 1.8817 - accuracy: 0.52 - ETA: 1:33 - loss: 1.8772 - accuracy: 0.52 - ETA: 1:31 - loss: 1.8754 - accuracy: 0.52 - ETA: 1:29 - loss: 1.8797 - accuracy: 0.52 - ETA: 1:27 - loss: 1.8784 - accuracy: 0.52 - ETA: 1:25 - loss: 1.8795 - accuracy: 0.52 - ETA: 1:23 - loss: 1.8773 - accuracy: 0.52 - ETA: 1:21 - loss: 1.8746 - accuracy: 0.52 - ETA: 1:18 - loss: 1.8728 - accuracy: 0.52 - ETA: 1:16 - loss: 1.8702 - accuracy: 0.52 - ETA: 1:14 - loss: 1.8708 - accuracy: 0.52 - ETA: 1:12 - loss: 1.8724 - accuracy: 0.52 - ETA: 1:10 - loss: 1.8703 - accuracy: 0.52 - ETA: 1:08 - loss: 1.8745 - accuracy: 0.52 - ETA: 1:06 - loss: 1.8762 - accuracy: 0.52 - ETA: 1:03 - loss: 1.8718 - accuracy: 0.52 - ETA: 1:01 - loss: 1.8699 - accuracy: 0.52 - ETA: 59s - loss: 1.8678 - accuracy: 0.5250 - ETA: 57s - loss: 1.8667 - accuracy: 0.525 - ETA: 55s - loss: 1.8702 - accuracy: 0.524 - ETA: 53s - loss: 1.8681 - accuracy: 0.525 - ETA: 51s - loss: 1.8682 - accuracy: 0.525 - ETA: 48s - loss: 1.8664 - accuracy: 0.525 - ETA: 46s - loss: 1.8662 - accuracy: 0.525 - ETA: 44s - loss: 1.8655 - accuracy: 0.525 - ETA: 42s - loss: 1.8651 - accuracy: 0.526 - ETA: 40s - loss: 1.8663 - accuracy: 0.525 - ETA: 38s - loss: 1.8683 - accuracy: 0.525 - ETA: 36s - loss: 1.8676 - accuracy: 0.525 - ETA: 33s - loss: 1.8672 - accuracy: 0.525 - ETA: 31s - loss: 1.8706 - accuracy: 0.524 - ETA: 29s - loss: 1.8691 - accuracy: 0.524 - ETA: 27s - loss: 1.8685 - accuracy: 0.524 - ETA: 25s - loss: 1.8690 - accuracy: 0.524 - ETA: 23s - loss: 1.8684 - accuracy: 0.524 - ETA: 21s - loss: 1.8697 - accuracy: 0.524 - ETA: 18s - loss: 1.8725 - accuracy: 0.524 - ETA: 16s - loss: 1.8735 - accuracy: 0.524 - ETA: 14s - loss: 1.8719 - accuracy: 0.525 - ETA: 12s - loss: 1.8708 - accuracy: 0.525 - ETA: 10s - loss: 1.8724 - accuracy: 0.525 - ETA: 8s - loss: 1.8745 - accuracy: 0.524 - ETA: 6s - loss: 1.8752 - accuracy: 0.52 - ETA: 4s - loss: 1.8753 - accuracy: 0.52 - ETA: 1s - loss: 1.8760 - accuracy: 0.52 - 359s 19ms/step - loss: 1.8750 - accuracy: 0.5251 - val_loss: 1.6633 - val_accuracy: 0.5889\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:22 - loss: 1.9993 - accuracy: 0.43 - ETA: 5:15 - loss: 1.8015 - accuracy: 0.48 - ETA: 5:16 - loss: 1.8993 - accuracy: 0.50 - ETA: 5:13 - loss: 1.7921 - accuracy: 0.52 - ETA: 5:10 - loss: 1.7740 - accuracy: 0.53 - ETA: 5:23 - loss: 1.7601 - accuracy: 0.54 - ETA: 5:21 - loss: 1.8127 - accuracy: 0.52 - ETA: 5:18 - loss: 1.9676 - accuracy: 0.53 - ETA: 5:15 - loss: 1.9450 - accuracy: 0.53 - ETA: 5:09 - loss: 1.9206 - accuracy: 0.52 - ETA: 5:06 - loss: 1.9069 - accuracy: 0.52 - ETA: 5:03 - loss: 1.9103 - accuracy: 0.52 - ETA: 5:00 - loss: 1.9120 - accuracy: 0.52 - ETA: 4:59 - loss: 1.8784 - accuracy: 0.52 - ETA: 4:55 - loss: 1.8682 - accuracy: 0.52 - ETA: 4:53 - loss: 1.8997 - accuracy: 0.52 - ETA: 4:50 - loss: 1.8812 - accuracy: 0.52 - ETA: 4:46 - loss: 1.8821 - accuracy: 0.52 - ETA: 4:45 - loss: 1.8921 - accuracy: 0.52 - ETA: 4:42 - loss: 1.8925 - accuracy: 0.52 - ETA: 4:42 - loss: 1.8802 - accuracy: 0.52 - ETA: 4:39 - loss: 1.8594 - accuracy: 0.53 - ETA: 4:37 - loss: 1.8597 - accuracy: 0.53 - ETA: 4:35 - loss: 1.8589 - accuracy: 0.52 - ETA: 4:33 - loss: 1.8568 - accuracy: 0.52 - ETA: 4:30 - loss: 1.8470 - accuracy: 0.52 - ETA: 4:28 - loss: 1.8352 - accuracy: 0.53 - ETA: 4:29 - loss: 1.8215 - accuracy: 0.53 - ETA: 4:26 - loss: 1.8367 - accuracy: 0.53 - ETA: 4:24 - loss: 1.8330 - accuracy: 0.53 - ETA: 4:22 - loss: 1.8127 - accuracy: 0.53 - ETA: 4:19 - loss: 1.8080 - accuracy: 0.53 - ETA: 4:16 - loss: 1.8200 - accuracy: 0.53 - ETA: 4:14 - loss: 1.8230 - accuracy: 0.54 - ETA: 4:12 - loss: 1.8289 - accuracy: 0.54 - ETA: 4:09 - loss: 1.8225 - accuracy: 0.54 - ETA: 4:07 - loss: 1.8294 - accuracy: 0.54 - ETA: 4:05 - loss: 1.8304 - accuracy: 0.54 - ETA: 4:03 - loss: 1.8405 - accuracy: 0.53 - ETA: 4:00 - loss: 1.8431 - accuracy: 0.53 - ETA: 3:58 - loss: 1.8499 - accuracy: 0.53 - ETA: 3:56 - loss: 1.8777 - accuracy: 0.53 - ETA: 3:54 - loss: 1.8719 - accuracy: 0.53 - ETA: 3:51 - loss: 1.8699 - accuracy: 0.53 - ETA: 3:49 - loss: 1.8606 - accuracy: 0.53 - ETA: 3:47 - loss: 1.8657 - accuracy: 0.53 - ETA: 3:44 - loss: 1.8647 - accuracy: 0.53 - ETA: 3:42 - loss: 1.8679 - accuracy: 0.53 - ETA: 3:40 - loss: 1.8661 - accuracy: 0.53 - ETA: 3:38 - loss: 1.8684 - accuracy: 0.53 - ETA: 3:36 - loss: 1.8740 - accuracy: 0.53 - ETA: 3:34 - loss: 1.8709 - accuracy: 0.53 - ETA: 3:31 - loss: 1.8693 - accuracy: 0.53 - ETA: 3:29 - loss: 1.8723 - accuracy: 0.53 - ETA: 3:27 - loss: 1.8706 - accuracy: 0.53 - ETA: 3:25 - loss: 1.8717 - accuracy: 0.53 - ETA: 3:22 - loss: 1.8681 - accuracy: 0.53 - ETA: 3:20 - loss: 1.8762 - accuracy: 0.53 - ETA: 3:17 - loss: 1.8779 - accuracy: 0.53 - ETA: 3:15 - loss: 1.8873 - accuracy: 0.53 - ETA: 3:13 - loss: 1.8867 - accuracy: 0.53 - ETA: 3:11 - loss: 1.8848 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8788 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8807 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8782 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8801 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8767 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8889 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8938 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8883 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8908 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8904 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8872 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8835 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8916 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8936 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8930 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8952 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8924 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8994 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8964 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8948 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8983 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8954 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8937 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8927 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8942 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8964 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8949 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8955 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8952 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8979 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8953 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8943 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8962 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8923 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8892 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8860 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8840 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8830 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8830 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8854 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8918 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8950 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8972 - accuracy: 0.53 - ETA: 1:36 - loss: 1.9006 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8984 - accuracy: 0.53 - ETA: 1:32 - loss: 1.9011 - accuracy: 0.53 - ETA: 1:30 - loss: 1.9000 - accuracy: 0.53 - ETA: 1:27 - loss: 1.9033 - accuracy: 0.53 - ETA: 1:25 - loss: 1.9036 - accuracy: 0.53 - ETA: 1:23 - loss: 1.9056 - accuracy: 0.53 - ETA: 1:21 - loss: 1.9077 - accuracy: 0.53 - ETA: 1:19 - loss: 1.9063 - accuracy: 0.53 - ETA: 1:17 - loss: 1.9057 - accuracy: 0.53 - ETA: 1:14 - loss: 1.9041 - accuracy: 0.53 - ETA: 1:12 - loss: 1.9046 - accuracy: 0.53 - ETA: 1:10 - loss: 1.9062 - accuracy: 0.53 - ETA: 1:08 - loss: 1.9024 - accuracy: 0.53 - ETA: 1:06 - loss: 1.9091 - accuracy: 0.52 - ETA: 1:04 - loss: 1.9120 - accuracy: 0.52 - ETA: 1:02 - loss: 1.9152 - accuracy: 0.52 - ETA: 59s - loss: 1.9166 - accuracy: 0.5279 - ETA: 57s - loss: 1.9145 - accuracy: 0.528 - ETA: 55s - loss: 1.9154 - accuracy: 0.527 - ETA: 53s - loss: 1.9164 - accuracy: 0.527 - ETA: 51s - loss: 1.9184 - accuracy: 0.527 - ETA: 49s - loss: 1.9153 - accuracy: 0.527 - ETA: 46s - loss: 1.9155 - accuracy: 0.527 - ETA: 44s - loss: 1.9145 - accuracy: 0.526 - ETA: 42s - loss: 1.9117 - accuracy: 0.527 - ETA: 40s - loss: 1.9126 - accuracy: 0.526 - ETA: 38s - loss: 1.9115 - accuracy: 0.527 - ETA: 36s - loss: 1.9106 - accuracy: 0.527 - ETA: 34s - loss: 1.9129 - accuracy: 0.526 - ETA: 31s - loss: 1.9164 - accuracy: 0.526 - ETA: 29s - loss: 1.9163 - accuracy: 0.526 - ETA: 27s - loss: 1.9181 - accuracy: 0.526 - ETA: 25s - loss: 1.9160 - accuracy: 0.527 - ETA: 23s - loss: 1.9179 - accuracy: 0.527 - ETA: 21s - loss: 1.9166 - accuracy: 0.527 - ETA: 19s - loss: 1.9159 - accuracy: 0.527 - ETA: 16s - loss: 1.9148 - accuracy: 0.527 - ETA: 14s - loss: 1.9139 - accuracy: 0.527 - ETA: 12s - loss: 1.9133 - accuracy: 0.527 - ETA: 10s - loss: 1.9093 - accuracy: 0.528 - ETA: 8s - loss: 1.9124 - accuracy: 0.527 - ETA: 6s - loss: 1.9135 - accuracy: 0.52 - ETA: 4s - loss: 1.9126 - accuracy: 0.52 - ETA: 1s - loss: 1.9120 - accuracy: 0.52 - 349s 18ms/step - loss: 1.9095 - accuracy: 0.5273 - val_loss: 1.6492 - val_accuracy: 0.5871\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:22 - loss: 1.7465 - accuracy: 0.52 - ETA: 5:15 - loss: 1.7626 - accuracy: 0.55 - ETA: 5:16 - loss: 1.6986 - accuracy: 0.56 - ETA: 5:17 - loss: 1.6828 - accuracy: 0.56 - ETA: 5:15 - loss: 1.7633 - accuracy: 0.54 - ETA: 5:11 - loss: 1.7705 - accuracy: 0.53 - ETA: 5:08 - loss: 1.7591 - accuracy: 0.52 - ETA: 5:03 - loss: 1.7930 - accuracy: 0.53 - ETA: 4:59 - loss: 1.7881 - accuracy: 0.53 - ETA: 4:58 - loss: 1.7707 - accuracy: 0.53 - ETA: 4:56 - loss: 1.7780 - accuracy: 0.53 - ETA: 4:54 - loss: 1.8125 - accuracy: 0.54 - ETA: 4:52 - loss: 1.8292 - accuracy: 0.53 - ETA: 4:50 - loss: 1.8802 - accuracy: 0.53 - ETA: 4:48 - loss: 1.8646 - accuracy: 0.53 - ETA: 4:45 - loss: 1.8536 - accuracy: 0.53 - ETA: 4:44 - loss: 1.8534 - accuracy: 0.53 - ETA: 4:41 - loss: 1.8437 - accuracy: 0.53 - ETA: 4:40 - loss: 1.8238 - accuracy: 0.54 - ETA: 4:38 - loss: 1.8134 - accuracy: 0.54 - ETA: 4:36 - loss: 1.8303 - accuracy: 0.53 - ETA: 4:34 - loss: 1.8399 - accuracy: 0.53 - ETA: 4:31 - loss: 1.8538 - accuracy: 0.53 - ETA: 4:29 - loss: 1.8299 - accuracy: 0.53 - ETA: 4:26 - loss: 1.8246 - accuracy: 0.54 - ETA: 4:25 - loss: 1.8246 - accuracy: 0.53 - ETA: 4:23 - loss: 1.8370 - accuracy: 0.53 - ETA: 4:21 - loss: 1.8283 - accuracy: 0.53 - ETA: 4:19 - loss: 1.8313 - accuracy: 0.53 - ETA: 4:17 - loss: 1.8363 - accuracy: 0.53 - ETA: 4:15 - loss: 1.8502 - accuracy: 0.53 - ETA: 4:12 - loss: 1.9638 - accuracy: 0.53 - ETA: 4:11 - loss: 1.9575 - accuracy: 0.53 - ETA: 4:09 - loss: 1.9640 - accuracy: 0.53 - ETA: 4:07 - loss: 1.9619 - accuracy: 0.52 - ETA: 4:05 - loss: 1.9676 - accuracy: 0.52 - ETA: 4:03 - loss: 1.9803 - accuracy: 0.52 - ETA: 4:01 - loss: 1.9716 - accuracy: 0.52 - ETA: 3:59 - loss: 1.9732 - accuracy: 0.52 - ETA: 3:57 - loss: 1.9697 - accuracy: 0.52 - ETA: 3:55 - loss: 1.9626 - accuracy: 0.52 - ETA: 3:53 - loss: 1.9535 - accuracy: 0.52 - ETA: 3:51 - loss: 1.9708 - accuracy: 0.52 - ETA: 3:49 - loss: 1.9636 - accuracy: 0.52 - ETA: 3:47 - loss: 1.9657 - accuracy: 0.52 - ETA: 3:45 - loss: 1.9642 - accuracy: 0.52 - ETA: 3:43 - loss: 1.9562 - accuracy: 0.52 - ETA: 3:41 - loss: 1.9601 - accuracy: 0.52 - ETA: 3:39 - loss: 1.9571 - accuracy: 0.52 - ETA: 3:37 - loss: 1.9553 - accuracy: 0.52 - ETA: 3:34 - loss: 1.9603 - accuracy: 0.52 - ETA: 3:32 - loss: 1.9574 - accuracy: 0.52 - ETA: 3:30 - loss: 1.9533 - accuracy: 0.52 - ETA: 3:28 - loss: 1.9479 - accuracy: 0.52 - ETA: 3:26 - loss: 1.9377 - accuracy: 0.52 - ETA: 3:24 - loss: 1.9381 - accuracy: 0.52 - ETA: 3:22 - loss: 1.9306 - accuracy: 0.52 - ETA: 3:19 - loss: 1.9284 - accuracy: 0.52 - ETA: 3:17 - loss: 1.9249 - accuracy: 0.52 - ETA: 3:15 - loss: 1.9221 - accuracy: 0.52 - ETA: 3:13 - loss: 1.9370 - accuracy: 0.52 - ETA: 3:10 - loss: 1.9365 - accuracy: 0.52 - ETA: 3:08 - loss: 1.9364 - accuracy: 0.52 - ETA: 3:06 - loss: 1.9426 - accuracy: 0.52 - ETA: 3:04 - loss: 1.9496 - accuracy: 0.52 - ETA: 3:02 - loss: 1.9477 - accuracy: 0.52 - ETA: 3:00 - loss: 1.9465 - accuracy: 0.52 - ETA: 2:58 - loss: 1.9485 - accuracy: 0.52 - ETA: 2:55 - loss: 1.9485 - accuracy: 0.52 - ETA: 2:53 - loss: 1.9476 - accuracy: 0.52 - ETA: 2:51 - loss: 1.9524 - accuracy: 0.52 - ETA: 2:49 - loss: 1.9484 - accuracy: 0.53 - ETA: 2:47 - loss: 1.9488 - accuracy: 0.52 - ETA: 2:45 - loss: 1.9423 - accuracy: 0.53 - ETA: 2:43 - loss: 1.9415 - accuracy: 0.52 - ETA: 2:41 - loss: 1.9409 - accuracy: 0.53 - ETA: 2:38 - loss: 1.9356 - accuracy: 0.53 - ETA: 2:36 - loss: 1.9318 - accuracy: 0.53 - ETA: 2:34 - loss: 1.9320 - accuracy: 0.53 - ETA: 2:32 - loss: 1.9294 - accuracy: 0.53 - ETA: 2:30 - loss: 1.9267 - accuracy: 0.53 - ETA: 2:28 - loss: 1.9304 - accuracy: 0.53 - ETA: 2:25 - loss: 1.9268 - accuracy: 0.53 - ETA: 2:23 - loss: 1.9270 - accuracy: 0.53 - ETA: 2:21 - loss: 1.9269 - accuracy: 0.53 - ETA: 2:19 - loss: 1.9265 - accuracy: 0.52 - ETA: 2:17 - loss: 1.9304 - accuracy: 0.52 - ETA: 2:15 - loss: 1.9308 - accuracy: 0.52 - ETA: 2:12 - loss: 1.9324 - accuracy: 0.52 - ETA: 2:10 - loss: 1.9312 - accuracy: 0.52 - ETA: 2:08 - loss: 1.9315 - accuracy: 0.52 - ETA: 2:06 - loss: 1.9377 - accuracy: 0.52 - ETA: 2:04 - loss: 1.9408 - accuracy: 0.52 - ETA: 2:02 - loss: 1.9429 - accuracy: 0.52 - ETA: 1:59 - loss: 1.9383 - accuracy: 0.52 - ETA: 1:57 - loss: 1.9412 - accuracy: 0.52 - ETA: 1:55 - loss: 1.9377 - accuracy: 0.52 - ETA: 1:53 - loss: 1.9394 - accuracy: 0.52 - ETA: 1:51 - loss: 1.9362 - accuracy: 0.52 - ETA: 1:49 - loss: 1.9344 - accuracy: 0.52 - ETA: 1:46 - loss: 1.9289 - accuracy: 0.52 - ETA: 1:44 - loss: 1.9259 - accuracy: 0.52 - ETA: 1:42 - loss: 1.9217 - accuracy: 0.52 - ETA: 1:40 - loss: 1.9175 - accuracy: 0.52 - ETA: 1:38 - loss: 1.9174 - accuracy: 0.52 - ETA: 1:36 - loss: 1.9203 - accuracy: 0.52 - ETA: 1:34 - loss: 1.9210 - accuracy: 0.52 - ETA: 1:31 - loss: 1.9199 - accuracy: 0.52 - ETA: 1:29 - loss: 1.9177 - accuracy: 0.52 - ETA: 1:27 - loss: 1.9157 - accuracy: 0.52 - ETA: 1:25 - loss: 1.9145 - accuracy: 0.52 - ETA: 1:23 - loss: 1.9109 - accuracy: 0.52 - ETA: 1:21 - loss: 1.9087 - accuracy: 0.52 - ETA: 1:18 - loss: 1.9064 - accuracy: 0.52 - ETA: 1:16 - loss: 1.9053 - accuracy: 0.52 - ETA: 1:14 - loss: 1.9059 - accuracy: 0.52 - ETA: 1:12 - loss: 1.9064 - accuracy: 0.52 - ETA: 1:10 - loss: 1.9081 - accuracy: 0.52 - ETA: 1:08 - loss: 1.9049 - accuracy: 0.52 - ETA: 1:06 - loss: 1.9031 - accuracy: 0.52 - ETA: 1:03 - loss: 1.9017 - accuracy: 0.52 - ETA: 1:01 - loss: 1.9033 - accuracy: 0.52 - ETA: 59s - loss: 1.9072 - accuracy: 0.5281 - ETA: 57s - loss: 1.9076 - accuracy: 0.528 - ETA: 55s - loss: 1.9059 - accuracy: 0.528 - ETA: 53s - loss: 1.9086 - accuracy: 0.528 - ETA: 51s - loss: 1.9118 - accuracy: 0.528 - ETA: 48s - loss: 1.9086 - accuracy: 0.528 - ETA: 46s - loss: 1.9140 - accuracy: 0.528 - ETA: 44s - loss: 1.9164 - accuracy: 0.529 - ETA: 42s - loss: 1.9130 - accuracy: 0.529 - ETA: 40s - loss: 1.9136 - accuracy: 0.529 - ETA: 38s - loss: 1.9149 - accuracy: 0.528 - ETA: 36s - loss: 1.9138 - accuracy: 0.529 - ETA: 33s - loss: 1.9114 - accuracy: 0.529 - ETA: 31s - loss: 1.9102 - accuracy: 0.529 - ETA: 29s - loss: 1.9114 - accuracy: 0.529 - ETA: 27s - loss: 1.9117 - accuracy: 0.529 - ETA: 25s - loss: 1.9103 - accuracy: 0.528 - ETA: 23s - loss: 1.9129 - accuracy: 0.528 - ETA: 21s - loss: 1.9159 - accuracy: 0.528 - ETA: 18s - loss: 1.9164 - accuracy: 0.527 - ETA: 16s - loss: 1.9170 - accuracy: 0.527 - ETA: 14s - loss: 1.9161 - accuracy: 0.527 - ETA: 12s - loss: 1.9149 - accuracy: 0.527 - ETA: 10s - loss: 1.9164 - accuracy: 0.527 - ETA: 8s - loss: 1.9173 - accuracy: 0.527 - ETA: 6s - loss: 1.9163 - accuracy: 0.52 - ETA: 4s - loss: 1.9179 - accuracy: 0.52 - ETA: 1s - loss: 1.9160 - accuracy: 0.52 - 348s 18ms/step - loss: 1.9159 - accuracy: 0.5284 - val_loss: 1.8092 - val_accuracy: 0.5848\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:21 - loss: 1.8169 - accuracy: 0.52 - ETA: 5:13 - loss: 2.1181 - accuracy: 0.51 - ETA: 5:14 - loss: 2.0358 - accuracy: 0.52 - ETA: 5:08 - loss: 1.8999 - accuracy: 0.53 - ETA: 5:10 - loss: 1.8490 - accuracy: 0.54 - ETA: 5:07 - loss: 1.8440 - accuracy: 0.53 - ETA: 5:07 - loss: 1.8651 - accuracy: 0.54 - ETA: 5:05 - loss: 1.8681 - accuracy: 0.54 - ETA: 5:02 - loss: 1.8490 - accuracy: 0.55 - ETA: 5:00 - loss: 1.8761 - accuracy: 0.54 - ETA: 4:56 - loss: 1.8840 - accuracy: 0.53 - ETA: 4:54 - loss: 1.9217 - accuracy: 0.54 - ETA: 4:52 - loss: 1.8766 - accuracy: 0.54 - ETA: 4:49 - loss: 1.9007 - accuracy: 0.54 - ETA: 4:47 - loss: 1.9133 - accuracy: 0.54 - ETA: 4:45 - loss: 1.8988 - accuracy: 0.55 - ETA: 4:43 - loss: 1.8926 - accuracy: 0.55 - ETA: 4:40 - loss: 1.8846 - accuracy: 0.54 - ETA: 4:38 - loss: 1.8835 - accuracy: 0.54 - ETA: 4:36 - loss: 1.8787 - accuracy: 0.54 - ETA: 4:33 - loss: 1.8683 - accuracy: 0.54 - ETA: 4:31 - loss: 1.9020 - accuracy: 0.54 - ETA: 4:29 - loss: 1.8797 - accuracy: 0.54 - ETA: 4:27 - loss: 1.8671 - accuracy: 0.54 - ETA: 4:25 - loss: 1.8743 - accuracy: 0.54 - ETA: 4:24 - loss: 1.8642 - accuracy: 0.54 - ETA: 4:22 - loss: 1.8719 - accuracy: 0.54 - ETA: 4:20 - loss: 1.8677 - accuracy: 0.54 - ETA: 4:18 - loss: 1.8696 - accuracy: 0.54 - ETA: 4:16 - loss: 1.8717 - accuracy: 0.54 - ETA: 4:13 - loss: 1.8660 - accuracy: 0.54 - ETA: 4:11 - loss: 1.8651 - accuracy: 0.54 - ETA: 4:09 - loss: 1.8601 - accuracy: 0.54 - ETA: 4:07 - loss: 1.8571 - accuracy: 0.54 - ETA: 4:05 - loss: 1.8505 - accuracy: 0.54 - ETA: 4:03 - loss: 1.8453 - accuracy: 0.54 - ETA: 4:01 - loss: 1.8371 - accuracy: 0.54 - ETA: 3:59 - loss: 1.8387 - accuracy: 0.54 - ETA: 3:56 - loss: 1.8356 - accuracy: 0.54 - ETA: 3:54 - loss: 1.8296 - accuracy: 0.54 - ETA: 3:52 - loss: 1.8291 - accuracy: 0.54 - ETA: 3:50 - loss: 1.8220 - accuracy: 0.54 - ETA: 3:48 - loss: 1.8237 - accuracy: 0.54 - ETA: 3:46 - loss: 1.8305 - accuracy: 0.54 - ETA: 3:44 - loss: 1.8284 - accuracy: 0.54 - ETA: 3:42 - loss: 1.8272 - accuracy: 0.54 - ETA: 3:40 - loss: 1.8276 - accuracy: 0.54 - ETA: 3:38 - loss: 1.8460 - accuracy: 0.53 - ETA: 3:36 - loss: 1.8539 - accuracy: 0.53 - ETA: 3:34 - loss: 1.8588 - accuracy: 0.53 - ETA: 3:31 - loss: 1.8675 - accuracy: 0.53 - ETA: 3:29 - loss: 1.8692 - accuracy: 0.53 - ETA: 3:27 - loss: 1.8702 - accuracy: 0.53 - ETA: 3:25 - loss: 1.8711 - accuracy: 0.53 - ETA: 3:23 - loss: 1.8700 - accuracy: 0.53 - ETA: 3:21 - loss: 1.8726 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8747 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8710 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8682 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8651 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8670 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8697 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8672 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8701 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8722 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8701 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8827 - accuracy: 0.52 - ETA: 2:55 - loss: 1.8805 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8786 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8770 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8784 - accuracy: 0.52 - ETA: 2:47 - loss: 1.8800 - accuracy: 0.52 - ETA: 2:45 - loss: 1.8798 - accuracy: 0.52 - ETA: 2:43 - loss: 1.8783 - accuracy: 0.52 - ETA: 2:40 - loss: 1.8723 - accuracy: 0.52 - ETA: 2:38 - loss: 1.8741 - accuracy: 0.52 - ETA: 2:36 - loss: 1.8743 - accuracy: 0.52 - ETA: 2:34 - loss: 1.8680 - accuracy: 0.52 - ETA: 2:32 - loss: 1.8657 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8640 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8650 - accuracy: 0.53 - ETA: 2:26 - loss: 1.8673 - accuracy: 0.52 - ETA: 2:24 - loss: 1.8662 - accuracy: 0.52 - ETA: 2:22 - loss: 1.8674 - accuracy: 0.52 - ETA: 2:19 - loss: 1.8648 - accuracy: 0.52 - ETA: 2:17 - loss: 1.8634 - accuracy: 0.52 - ETA: 2:15 - loss: 1.8610 - accuracy: 0.52 - ETA: 2:13 - loss: 1.8595 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8571 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8552 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8530 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8537 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8542 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8576 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8626 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8618 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8694 - accuracy: 0.52 - ETA: 1:52 - loss: 1.8790 - accuracy: 0.52 - ETA: 1:50 - loss: 1.8795 - accuracy: 0.52 - ETA: 1:48 - loss: 1.8811 - accuracy: 0.52 - ETA: 1:46 - loss: 1.8995 - accuracy: 0.52 - ETA: 1:43 - loss: 1.9005 - accuracy: 0.52 - ETA: 1:41 - loss: 1.8996 - accuracy: 0.52 - ETA: 1:39 - loss: 1.8977 - accuracy: 0.52 - ETA: 1:37 - loss: 1.8995 - accuracy: 0.52 - ETA: 1:35 - loss: 1.9046 - accuracy: 0.52 - ETA: 1:33 - loss: 1.9055 - accuracy: 0.52 - ETA: 1:31 - loss: 1.9031 - accuracy: 0.52 - ETA: 1:29 - loss: 1.9066 - accuracy: 0.52 - ETA: 1:27 - loss: 1.9057 - accuracy: 0.52 - ETA: 1:24 - loss: 1.9065 - accuracy: 0.52 - ETA: 1:22 - loss: 1.9056 - accuracy: 0.52 - ETA: 1:20 - loss: 1.9020 - accuracy: 0.52 - ETA: 1:18 - loss: 1.9025 - accuracy: 0.52 - ETA: 1:16 - loss: 1.9053 - accuracy: 0.52 - ETA: 1:14 - loss: 1.9129 - accuracy: 0.52 - ETA: 1:12 - loss: 1.9144 - accuracy: 0.52 - ETA: 1:09 - loss: 1.9117 - accuracy: 0.52 - ETA: 1:07 - loss: 1.9096 - accuracy: 0.52 - ETA: 1:05 - loss: 1.9125 - accuracy: 0.52 - ETA: 1:03 - loss: 1.9094 - accuracy: 0.52 - ETA: 1:01 - loss: 1.9078 - accuracy: 0.52 - ETA: 59s - loss: 1.9089 - accuracy: 0.5274 - ETA: 57s - loss: 1.9098 - accuracy: 0.527 - ETA: 55s - loss: 1.9130 - accuracy: 0.526 - ETA: 52s - loss: 1.9125 - accuracy: 0.526 - ETA: 50s - loss: 1.9123 - accuracy: 0.527 - ETA: 48s - loss: 1.9089 - accuracy: 0.527 - ETA: 46s - loss: 1.9097 - accuracy: 0.527 - ETA: 44s - loss: 1.9133 - accuracy: 0.526 - ETA: 42s - loss: 1.9108 - accuracy: 0.527 - ETA: 40s - loss: 1.9086 - accuracy: 0.527 - ETA: 38s - loss: 1.9054 - accuracy: 0.528 - ETA: 35s - loss: 1.9054 - accuracy: 0.528 - ETA: 33s - loss: 1.9049 - accuracy: 0.528 - ETA: 31s - loss: 1.9052 - accuracy: 0.528 - ETA: 29s - loss: 1.9037 - accuracy: 0.528 - ETA: 27s - loss: 1.9027 - accuracy: 0.528 - ETA: 25s - loss: 1.9027 - accuracy: 0.527 - ETA: 23s - loss: 1.8995 - accuracy: 0.528 - ETA: 21s - loss: 1.8987 - accuracy: 0.528 - ETA: 18s - loss: 1.8978 - accuracy: 0.527 - ETA: 16s - loss: 1.8966 - accuracy: 0.527 - ETA: 14s - loss: 1.8959 - accuracy: 0.528 - ETA: 12s - loss: 1.8955 - accuracy: 0.527 - ETA: 10s - loss: 1.8944 - accuracy: 0.527 - ETA: 8s - loss: 1.8922 - accuracy: 0.528 - ETA: 6s - loss: 1.8940 - accuracy: 0.52 - ETA: 4s - loss: 1.8942 - accuracy: 0.52 - ETA: 1s - loss: 1.8946 - accuracy: 0.52 - 347s 18ms/step - loss: 1.8953 - accuracy: 0.5277 - val_loss: 1.7180 - val_accuracy: 0.5925\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:15 - loss: 1.8051 - accuracy: 0.53 - ETA: 5:17 - loss: 1.8244 - accuracy: 0.56 - ETA: 5:15 - loss: 1.9584 - accuracy: 0.54 - ETA: 5:13 - loss: 1.9319 - accuracy: 0.55 - ETA: 5:10 - loss: 1.9210 - accuracy: 0.54 - ETA: 5:09 - loss: 1.8665 - accuracy: 0.54 - ETA: 5:07 - loss: 1.8758 - accuracy: 0.53 - ETA: 5:03 - loss: 1.8557 - accuracy: 0.53 - ETA: 5:01 - loss: 1.9078 - accuracy: 0.53 - ETA: 4:58 - loss: 1.9272 - accuracy: 0.53 - ETA: 4:56 - loss: 1.9186 - accuracy: 0.53 - ETA: 4:54 - loss: 1.8961 - accuracy: 0.53 - ETA: 4:52 - loss: 1.8610 - accuracy: 0.53 - ETA: 4:50 - loss: 1.8798 - accuracy: 0.53 - ETA: 4:48 - loss: 1.8666 - accuracy: 0.53 - ETA: 4:46 - loss: 1.9399 - accuracy: 0.53 - ETA: 4:44 - loss: 1.9425 - accuracy: 0.53 - ETA: 4:41 - loss: 1.9682 - accuracy: 0.53 - ETA: 4:39 - loss: 1.9436 - accuracy: 0.53 - ETA: 4:37 - loss: 1.9248 - accuracy: 0.53 - ETA: 4:35 - loss: 1.9325 - accuracy: 0.53 - ETA: 4:33 - loss: 1.9514 - accuracy: 0.53 - ETA: 4:31 - loss: 1.9559 - accuracy: 0.53 - ETA: 4:29 - loss: 1.9500 - accuracy: 0.52 - ETA: 4:27 - loss: 1.9563 - accuracy: 0.52 - ETA: 4:25 - loss: 1.9449 - accuracy: 0.52 - ETA: 4:22 - loss: 1.9790 - accuracy: 0.52 - ETA: 4:21 - loss: 1.9848 - accuracy: 0.52 - ETA: 4:19 - loss: 1.9788 - accuracy: 0.52 - ETA: 4:16 - loss: 1.9729 - accuracy: 0.52 - ETA: 4:14 - loss: 1.9728 - accuracy: 0.52 - ETA: 4:12 - loss: 1.9604 - accuracy: 0.52 - ETA: 4:10 - loss: 1.9649 - accuracy: 0.52 - ETA: 4:08 - loss: 1.9655 - accuracy: 0.52 - ETA: 4:05 - loss: 1.9564 - accuracy: 0.52 - ETA: 4:03 - loss: 1.9616 - accuracy: 0.52 - ETA: 4:01 - loss: 1.9789 - accuracy: 0.52 - ETA: 3:59 - loss: 1.9741 - accuracy: 0.52 - ETA: 3:57 - loss: 1.9662 - accuracy: 0.52 - ETA: 3:55 - loss: 1.9581 - accuracy: 0.52 - ETA: 3:53 - loss: 1.9534 - accuracy: 0.52 - ETA: 3:51 - loss: 1.9466 - accuracy: 0.52 - ETA: 3:48 - loss: 1.9593 - accuracy: 0.52 - ETA: 3:46 - loss: 1.9535 - accuracy: 0.52 - ETA: 3:45 - loss: 1.9545 - accuracy: 0.52 - ETA: 3:42 - loss: 1.9573 - accuracy: 0.52 - ETA: 3:41 - loss: 1.9553 - accuracy: 0.52 - ETA: 3:39 - loss: 1.9576 - accuracy: 0.52 - ETA: 3:37 - loss: 1.9643 - accuracy: 0.52 - ETA: 3:34 - loss: 1.9578 - accuracy: 0.52 - ETA: 3:32 - loss: 1.9537 - accuracy: 0.52 - ETA: 3:30 - loss: 1.9538 - accuracy: 0.52 - ETA: 3:28 - loss: 1.9491 - accuracy: 0.52 - ETA: 3:26 - loss: 1.9472 - accuracy: 0.52 - ETA: 3:24 - loss: 1.9413 - accuracy: 0.52 - ETA: 3:22 - loss: 1.9395 - accuracy: 0.52 - ETA: 3:20 - loss: 1.9484 - accuracy: 0.52 - ETA: 3:18 - loss: 1.9476 - accuracy: 0.52 - ETA: 3:16 - loss: 1.9487 - accuracy: 0.52 - ETA: 3:14 - loss: 1.9438 - accuracy: 0.52 - ETA: 3:11 - loss: 1.9626 - accuracy: 0.52 - ETA: 3:09 - loss: 1.9534 - accuracy: 0.52 - ETA: 3:07 - loss: 1.9477 - accuracy: 0.52 - ETA: 3:05 - loss: 1.9444 - accuracy: 0.52 - ETA: 3:03 - loss: 1.9409 - accuracy: 0.52 - ETA: 3:01 - loss: 1.9439 - accuracy: 0.52 - ETA: 2:59 - loss: 1.9425 - accuracy: 0.52 - ETA: 2:57 - loss: 1.9395 - accuracy: 0.52 - ETA: 2:54 - loss: 1.9482 - accuracy: 0.52 - ETA: 2:52 - loss: 1.9466 - accuracy: 0.52 - ETA: 2:50 - loss: 1.9433 - accuracy: 0.52 - ETA: 2:48 - loss: 1.9424 - accuracy: 0.52 - ETA: 2:46 - loss: 1.9424 - accuracy: 0.52 - ETA: 2:44 - loss: 1.9404 - accuracy: 0.52 - ETA: 2:41 - loss: 1.9375 - accuracy: 0.52 - ETA: 2:39 - loss: 1.9378 - accuracy: 0.52 - ETA: 2:37 - loss: 1.9353 - accuracy: 0.52 - ETA: 2:35 - loss: 1.9319 - accuracy: 0.52 - ETA: 2:33 - loss: 1.9274 - accuracy: 0.52 - ETA: 2:31 - loss: 1.9290 - accuracy: 0.52 - ETA: 2:28 - loss: 1.9342 - accuracy: 0.53 - ETA: 2:26 - loss: 1.9301 - accuracy: 0.53 - ETA: 2:24 - loss: 1.9280 - accuracy: 0.53 - ETA: 2:22 - loss: 1.9292 - accuracy: 0.53 - ETA: 2:20 - loss: 1.9289 - accuracy: 0.53 - ETA: 2:18 - loss: 1.9247 - accuracy: 0.53 - ETA: 2:16 - loss: 1.9265 - accuracy: 0.53 - ETA: 2:14 - loss: 1.9271 - accuracy: 0.53 - ETA: 2:12 - loss: 1.9227 - accuracy: 0.53 - ETA: 2:10 - loss: 1.9202 - accuracy: 0.53 - ETA: 2:07 - loss: 1.9210 - accuracy: 0.53 - ETA: 2:05 - loss: 1.9331 - accuracy: 0.53 - ETA: 2:03 - loss: 1.9292 - accuracy: 0.53 - ETA: 2:01 - loss: 1.9272 - accuracy: 0.53 - ETA: 1:59 - loss: 1.9325 - accuracy: 0.53 - ETA: 1:57 - loss: 1.9316 - accuracy: 0.53 - ETA: 1:55 - loss: 1.9320 - accuracy: 0.53 - ETA: 1:53 - loss: 1.9321 - accuracy: 0.53 - ETA: 1:51 - loss: 1.9323 - accuracy: 0.53 - ETA: 1:48 - loss: 1.9346 - accuracy: 0.53 - ETA: 1:46 - loss: 1.9392 - accuracy: 0.53 - ETA: 1:44 - loss: 1.9389 - accuracy: 0.53 - ETA: 1:42 - loss: 1.9390 - accuracy: 0.53 - ETA: 1:40 - loss: 1.9384 - accuracy: 0.53 - ETA: 1:38 - loss: 1.9385 - accuracy: 0.53 - ETA: 1:36 - loss: 1.9363 - accuracy: 0.53 - ETA: 1:33 - loss: 1.9306 - accuracy: 0.53 - ETA: 1:31 - loss: 1.9293 - accuracy: 0.53 - ETA: 1:29 - loss: 1.9323 - accuracy: 0.53 - ETA: 1:27 - loss: 1.9322 - accuracy: 0.53 - ETA: 1:25 - loss: 1.9327 - accuracy: 0.53 - ETA: 1:23 - loss: 1.9324 - accuracy: 0.53 - ETA: 1:21 - loss: 1.9304 - accuracy: 0.53 - ETA: 1:18 - loss: 1.9281 - accuracy: 0.53 - ETA: 1:16 - loss: 1.9327 - accuracy: 0.53 - ETA: 1:14 - loss: 1.9332 - accuracy: 0.53 - ETA: 1:12 - loss: 1.9334 - accuracy: 0.53 - ETA: 1:10 - loss: 1.9333 - accuracy: 0.53 - ETA: 1:08 - loss: 1.9314 - accuracy: 0.53 - ETA: 1:06 - loss: 1.9302 - accuracy: 0.53 - ETA: 1:03 - loss: 1.9339 - accuracy: 0.53 - ETA: 1:01 - loss: 1.9357 - accuracy: 0.53 - ETA: 59s - loss: 1.9381 - accuracy: 0.5308 - ETA: 57s - loss: 1.9414 - accuracy: 0.529 - ETA: 55s - loss: 1.9396 - accuracy: 0.530 - ETA: 53s - loss: 1.9384 - accuracy: 0.530 - ETA: 51s - loss: 1.9386 - accuracy: 0.531 - ETA: 48s - loss: 1.9410 - accuracy: 0.531 - ETA: 46s - loss: 1.9393 - accuracy: 0.531 - ETA: 44s - loss: 1.9380 - accuracy: 0.531 - ETA: 42s - loss: 1.9384 - accuracy: 0.531 - ETA: 40s - loss: 1.9413 - accuracy: 0.530 - ETA: 38s - loss: 1.9463 - accuracy: 0.530 - ETA: 36s - loss: 1.9450 - accuracy: 0.530 - ETA: 33s - loss: 1.9437 - accuracy: 0.530 - ETA: 31s - loss: 1.9436 - accuracy: 0.530 - ETA: 29s - loss: 1.9436 - accuracy: 0.530 - ETA: 27s - loss: 1.9463 - accuracy: 0.530 - ETA: 25s - loss: 1.9442 - accuracy: 0.530 - ETA: 23s - loss: 1.9462 - accuracy: 0.530 - ETA: 21s - loss: 1.9428 - accuracy: 0.531 - ETA: 18s - loss: 1.9458 - accuracy: 0.531 - ETA: 16s - loss: 1.9440 - accuracy: 0.531 - ETA: 14s - loss: 1.9450 - accuracy: 0.531 - ETA: 12s - loss: 1.9431 - accuracy: 0.531 - ETA: 10s - loss: 1.9429 - accuracy: 0.531 - ETA: 8s - loss: 1.9415 - accuracy: 0.531 - ETA: 6s - loss: 1.9387 - accuracy: 0.53 - ETA: 4s - loss: 1.9368 - accuracy: 0.53 - ETA: 1s - loss: 1.9336 - accuracy: 0.53 - 347s 18ms/step - loss: 1.9336 - accuracy: 0.5321 - val_loss: 1.6977 - val_accuracy: 0.5947\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:23 - loss: 1.4767 - accuracy: 0.59 - ETA: 5:20 - loss: 1.6725 - accuracy: 0.54 - ETA: 5:17 - loss: 1.7297 - accuracy: 0.52 - ETA: 5:13 - loss: 1.7338 - accuracy: 0.52 - ETA: 5:14 - loss: 1.8112 - accuracy: 0.52 - ETA: 5:13 - loss: 1.8047 - accuracy: 0.51 - ETA: 5:07 - loss: 1.8664 - accuracy: 0.50 - ETA: 5:06 - loss: 1.8556 - accuracy: 0.50 - ETA: 5:03 - loss: 1.8718 - accuracy: 0.50 - ETA: 4:59 - loss: 1.8538 - accuracy: 0.50 - ETA: 4:56 - loss: 1.8387 - accuracy: 0.51 - ETA: 4:54 - loss: 1.8442 - accuracy: 0.51 - ETA: 4:52 - loss: 1.8500 - accuracy: 0.51 - ETA: 4:49 - loss: 1.8630 - accuracy: 0.51 - ETA: 4:47 - loss: 1.8370 - accuracy: 0.52 - ETA: 4:46 - loss: 1.8334 - accuracy: 0.52 - ETA: 4:43 - loss: 1.8423 - accuracy: 0.52 - ETA: 4:42 - loss: 1.8427 - accuracy: 0.52 - ETA: 4:40 - loss: 1.8210 - accuracy: 0.53 - ETA: 4:38 - loss: 1.8149 - accuracy: 0.53 - ETA: 4:36 - loss: 1.8109 - accuracy: 0.53 - ETA: 4:34 - loss: 1.8225 - accuracy: 0.53 - ETA: 4:32 - loss: 1.8190 - accuracy: 0.53 - ETA: 4:31 - loss: 1.8290 - accuracy: 0.53 - ETA: 4:29 - loss: 1.8383 - accuracy: 0.53 - ETA: 4:27 - loss: 1.8330 - accuracy: 0.53 - ETA: 4:24 - loss: 1.8271 - accuracy: 0.53 - ETA: 4:21 - loss: 1.8220 - accuracy: 0.53 - ETA: 4:19 - loss: 1.8319 - accuracy: 0.53 - ETA: 4:17 - loss: 1.8405 - accuracy: 0.53 - ETA: 4:16 - loss: 1.8399 - accuracy: 0.53 - ETA: 4:14 - loss: 1.8330 - accuracy: 0.53 - ETA: 4:11 - loss: 1.8624 - accuracy: 0.53 - ETA: 4:09 - loss: 1.8620 - accuracy: 0.53 - ETA: 4:07 - loss: 1.8595 - accuracy: 0.53 - ETA: 4:05 - loss: 1.8649 - accuracy: 0.53 - ETA: 4:02 - loss: 1.8716 - accuracy: 0.53 - ETA: 4:00 - loss: 1.8647 - accuracy: 0.53 - ETA: 3:59 - loss: 1.8657 - accuracy: 0.53 - ETA: 3:56 - loss: 1.8676 - accuracy: 0.53 - ETA: 3:54 - loss: 1.8750 - accuracy: 0.53 - ETA: 3:52 - loss: 1.8724 - accuracy: 0.53 - ETA: 3:50 - loss: 1.8708 - accuracy: 0.53 - ETA: 3:48 - loss: 1.8697 - accuracy: 0.53 - ETA: 3:45 - loss: 1.8699 - accuracy: 0.53 - ETA: 3:44 - loss: 1.8764 - accuracy: 0.53 - ETA: 3:42 - loss: 1.8788 - accuracy: 0.53 - ETA: 3:39 - loss: 1.8997 - accuracy: 0.53 - ETA: 3:37 - loss: 1.9053 - accuracy: 0.53 - ETA: 3:35 - loss: 1.9156 - accuracy: 0.52 - ETA: 3:33 - loss: 1.9218 - accuracy: 0.52 - ETA: 3:31 - loss: 1.9204 - accuracy: 0.52 - ETA: 3:29 - loss: 1.9224 - accuracy: 0.52 - ETA: 3:27 - loss: 1.9174 - accuracy: 0.52 - ETA: 3:24 - loss: 1.9185 - accuracy: 0.52 - ETA: 3:22 - loss: 1.9176 - accuracy: 0.52 - ETA: 3:20 - loss: 1.9212 - accuracy: 0.52 - ETA: 3:18 - loss: 1.9172 - accuracy: 0.52 - ETA: 3:16 - loss: 1.9104 - accuracy: 0.52 - ETA: 3:13 - loss: 1.9214 - accuracy: 0.52 - ETA: 3:11 - loss: 1.9214 - accuracy: 0.52 - ETA: 3:09 - loss: 1.9272 - accuracy: 0.52 - ETA: 3:07 - loss: 1.9322 - accuracy: 0.52 - ETA: 3:05 - loss: 1.9342 - accuracy: 0.52 - ETA: 3:03 - loss: 1.9329 - accuracy: 0.52 - ETA: 3:00 - loss: 1.9274 - accuracy: 0.52 - ETA: 2:58 - loss: 1.9269 - accuracy: 0.52 - ETA: 2:56 - loss: 1.9270 - accuracy: 0.52 - ETA: 2:54 - loss: 1.9212 - accuracy: 0.52 - ETA: 2:52 - loss: 1.9281 - accuracy: 0.52 - ETA: 2:50 - loss: 1.9300 - accuracy: 0.52 - ETA: 2:48 - loss: 1.9254 - accuracy: 0.52 - ETA: 2:45 - loss: 1.9251 - accuracy: 0.52 - ETA: 2:43 - loss: 1.9271 - accuracy: 0.52 - ETA: 2:41 - loss: 1.9449 - accuracy: 0.52 - ETA: 2:39 - loss: 1.9463 - accuracy: 0.52 - ETA: 2:37 - loss: 1.9425 - accuracy: 0.52 - ETA: 2:35 - loss: 1.9469 - accuracy: 0.52 - ETA: 2:33 - loss: 1.9433 - accuracy: 0.52 - ETA: 2:30 - loss: 1.9417 - accuracy: 0.52 - ETA: 2:28 - loss: 1.9403 - accuracy: 0.52 - ETA: 2:26 - loss: 1.9380 - accuracy: 0.52 - ETA: 2:24 - loss: 1.9339 - accuracy: 0.52 - ETA: 2:22 - loss: 1.9375 - accuracy: 0.52 - ETA: 2:20 - loss: 1.9365 - accuracy: 0.52 - ETA: 2:18 - loss: 1.9331 - accuracy: 0.52 - ETA: 2:16 - loss: 1.9307 - accuracy: 0.52 - ETA: 2:13 - loss: 1.9316 - accuracy: 0.52 - ETA: 2:11 - loss: 1.9323 - accuracy: 0.52 - ETA: 2:09 - loss: 1.9301 - accuracy: 0.52 - ETA: 2:07 - loss: 1.9255 - accuracy: 0.52 - ETA: 2:05 - loss: 1.9235 - accuracy: 0.52 - ETA: 2:03 - loss: 1.9232 - accuracy: 0.52 - ETA: 2:01 - loss: 1.9246 - accuracy: 0.52 - ETA: 1:59 - loss: 1.9248 - accuracy: 0.52 - ETA: 1:56 - loss: 1.9297 - accuracy: 0.52 - ETA: 1:54 - loss: 1.9261 - accuracy: 0.52 - ETA: 1:52 - loss: 1.9269 - accuracy: 0.52 - ETA: 1:50 - loss: 1.9243 - accuracy: 0.52 - ETA: 1:48 - loss: 1.9266 - accuracy: 0.52 - ETA: 1:46 - loss: 1.9369 - accuracy: 0.52 - ETA: 1:44 - loss: 1.9357 - accuracy: 0.52 - ETA: 1:41 - loss: 1.9347 - accuracy: 0.52 - ETA: 1:39 - loss: 1.9335 - accuracy: 0.52 - ETA: 1:37 - loss: 1.9327 - accuracy: 0.52 - ETA: 1:35 - loss: 1.9320 - accuracy: 0.52 - ETA: 1:33 - loss: 1.9359 - accuracy: 0.52 - ETA: 1:31 - loss: 1.9379 - accuracy: 0.52 - ETA: 1:29 - loss: 1.9348 - accuracy: 0.52 - ETA: 1:27 - loss: 1.9361 - accuracy: 0.52 - ETA: 1:24 - loss: 1.9346 - accuracy: 0.52 - ETA: 1:22 - loss: 1.9303 - accuracy: 0.52 - ETA: 1:20 - loss: 1.9328 - accuracy: 0.52 - ETA: 1:18 - loss: 1.9320 - accuracy: 0.52 - ETA: 1:16 - loss: 1.9305 - accuracy: 0.52 - ETA: 1:14 - loss: 1.9306 - accuracy: 0.52 - ETA: 1:12 - loss: 1.9281 - accuracy: 0.52 - ETA: 1:10 - loss: 1.9278 - accuracy: 0.52 - ETA: 1:07 - loss: 1.9276 - accuracy: 0.52 - ETA: 1:05 - loss: 1.9270 - accuracy: 0.52 - ETA: 1:03 - loss: 1.9261 - accuracy: 0.52 - ETA: 1:01 - loss: 1.9262 - accuracy: 0.52 - ETA: 59s - loss: 1.9218 - accuracy: 0.5297 - ETA: 57s - loss: 1.9210 - accuracy: 0.529 - ETA: 55s - loss: 1.9190 - accuracy: 0.530 - ETA: 52s - loss: 1.9178 - accuracy: 0.530 - ETA: 50s - loss: 1.9180 - accuracy: 0.530 - ETA: 48s - loss: 1.9168 - accuracy: 0.530 - ETA: 46s - loss: 1.9155 - accuracy: 0.530 - ETA: 44s - loss: 1.9174 - accuracy: 0.529 - ETA: 42s - loss: 1.9135 - accuracy: 0.530 - ETA: 40s - loss: 1.9116 - accuracy: 0.530 - ETA: 38s - loss: 1.9164 - accuracy: 0.530 - ETA: 35s - loss: 1.9148 - accuracy: 0.530 - ETA: 33s - loss: 1.9150 - accuracy: 0.530 - ETA: 31s - loss: 1.9153 - accuracy: 0.530 - ETA: 29s - loss: 1.9137 - accuracy: 0.530 - ETA: 27s - loss: 1.9153 - accuracy: 0.530 - ETA: 25s - loss: 1.9138 - accuracy: 0.530 - ETA: 23s - loss: 1.9126 - accuracy: 0.530 - ETA: 21s - loss: 1.9117 - accuracy: 0.531 - ETA: 18s - loss: 1.9091 - accuracy: 0.531 - ETA: 16s - loss: 1.9103 - accuracy: 0.531 - ETA: 14s - loss: 1.9131 - accuracy: 0.530 - ETA: 12s - loss: 1.9114 - accuracy: 0.531 - ETA: 10s - loss: 1.9112 - accuracy: 0.531 - ETA: 8s - loss: 1.9097 - accuracy: 0.531 - ETA: 6s - loss: 1.9081 - accuracy: 0.53 - ETA: 3s - loss: 1.9083 - accuracy: 0.53 - ETA: 1s - loss: 1.9033 - accuracy: 0.53 - 346s 18ms/step - loss: 1.9038 - accuracy: 0.5315 - val_loss: 1.6814 - val_accuracy: 0.5939\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:15 - loss: 1.7298 - accuracy: 0.54 - ETA: 5:12 - loss: 1.6995 - accuracy: 0.54 - ETA: 5:12 - loss: 1.6944 - accuracy: 0.55 - ETA: 5:11 - loss: 1.8007 - accuracy: 0.52 - ETA: 5:05 - loss: 1.8663 - accuracy: 0.51 - ETA: 5:05 - loss: 1.9590 - accuracy: 0.50 - ETA: 5:05 - loss: 1.9150 - accuracy: 0.51 - ETA: 5:02 - loss: 1.9078 - accuracy: 0.52 - ETA: 4:58 - loss: 1.8835 - accuracy: 0.52 - ETA: 4:55 - loss: 1.8704 - accuracy: 0.53 - ETA: 4:53 - loss: 1.8345 - accuracy: 0.53 - ETA: 4:51 - loss: 1.8478 - accuracy: 0.53 - ETA: 4:50 - loss: 1.8681 - accuracy: 0.53 - ETA: 4:48 - loss: 1.8629 - accuracy: 0.53 - ETA: 4:46 - loss: 1.8554 - accuracy: 0.53 - ETA: 4:44 - loss: 1.8576 - accuracy: 0.53 - ETA: 4:41 - loss: 1.8579 - accuracy: 0.53 - ETA: 4:39 - loss: 1.8526 - accuracy: 0.53 - ETA: 4:37 - loss: 1.8805 - accuracy: 0.53 - ETA: 4:35 - loss: 1.8561 - accuracy: 0.53 - ETA: 4:32 - loss: 1.8475 - accuracy: 0.53 - ETA: 4:30 - loss: 1.8564 - accuracy: 0.53 - ETA: 4:28 - loss: 1.8758 - accuracy: 0.53 - ETA: 4:26 - loss: 1.8711 - accuracy: 0.53 - ETA: 4:24 - loss: 1.8721 - accuracy: 0.52 - ETA: 4:22 - loss: 1.8823 - accuracy: 0.52 - ETA: 4:20 - loss: 1.8803 - accuracy: 0.52 - ETA: 4:18 - loss: 1.8842 - accuracy: 0.52 - ETA: 4:16 - loss: 1.8901 - accuracy: 0.52 - ETA: 4:14 - loss: 1.8824 - accuracy: 0.52 - ETA: 4:12 - loss: 1.8873 - accuracy: 0.52 - ETA: 4:10 - loss: 1.8762 - accuracy: 0.52 - ETA: 4:08 - loss: 1.8741 - accuracy: 0.52 - ETA: 4:06 - loss: 1.8769 - accuracy: 0.52 - ETA: 4:03 - loss: 1.8702 - accuracy: 0.52 - ETA: 4:01 - loss: 1.8772 - accuracy: 0.52 - ETA: 3:59 - loss: 1.8757 - accuracy: 0.52 - ETA: 3:57 - loss: 1.8861 - accuracy: 0.52 - ETA: 3:55 - loss: 1.8899 - accuracy: 0.52 - ETA: 3:53 - loss: 1.8859 - accuracy: 0.52 - ETA: 3:51 - loss: 1.8835 - accuracy: 0.52 - ETA: 3:49 - loss: 1.8804 - accuracy: 0.52 - ETA: 3:46 - loss: 1.8840 - accuracy: 0.52 - ETA: 3:45 - loss: 1.8940 - accuracy: 0.52 - ETA: 3:43 - loss: 1.8887 - accuracy: 0.52 - ETA: 3:41 - loss: 1.8932 - accuracy: 0.52 - ETA: 3:39 - loss: 1.8918 - accuracy: 0.52 - ETA: 3:36 - loss: 1.8886 - accuracy: 0.52 - ETA: 3:34 - loss: 1.8877 - accuracy: 0.52 - ETA: 3:32 - loss: 1.8888 - accuracy: 0.52 - ETA: 3:30 - loss: 1.8917 - accuracy: 0.52 - ETA: 3:28 - loss: 1.8878 - accuracy: 0.52 - ETA: 3:26 - loss: 1.8972 - accuracy: 0.52 - ETA: 3:24 - loss: 1.9001 - accuracy: 0.52 - ETA: 3:22 - loss: 1.8929 - accuracy: 0.52 - ETA: 3:20 - loss: 1.8993 - accuracy: 0.52 - ETA: 3:18 - loss: 1.9024 - accuracy: 0.52 - ETA: 3:16 - loss: 1.8967 - accuracy: 0.52 - ETA: 3:14 - loss: 1.8934 - accuracy: 0.52 - ETA: 3:12 - loss: 1.8889 - accuracy: 0.52 - ETA: 3:10 - loss: 1.8850 - accuracy: 0.52 - ETA: 3:07 - loss: 1.8888 - accuracy: 0.52 - ETA: 3:05 - loss: 1.8898 - accuracy: 0.52 - ETA: 3:03 - loss: 1.8896 - accuracy: 0.52 - ETA: 3:01 - loss: 1.8869 - accuracy: 0.52 - ETA: 2:59 - loss: 1.8906 - accuracy: 0.52 - ETA: 2:57 - loss: 1.8954 - accuracy: 0.52 - ETA: 2:55 - loss: 1.8962 - accuracy: 0.52 - ETA: 2:52 - loss: 1.8934 - accuracy: 0.52 - ETA: 2:50 - loss: 1.8927 - accuracy: 0.52 - ETA: 2:48 - loss: 1.8872 - accuracy: 0.52 - ETA: 2:46 - loss: 1.8917 - accuracy: 0.52 - ETA: 2:44 - loss: 1.8901 - accuracy: 0.52 - ETA: 2:42 - loss: 1.8885 - accuracy: 0.52 - ETA: 2:40 - loss: 1.8916 - accuracy: 0.52 - ETA: 2:38 - loss: 1.8935 - accuracy: 0.52 - ETA: 2:36 - loss: 1.8921 - accuracy: 0.52 - ETA: 2:33 - loss: 1.8898 - accuracy: 0.52 - ETA: 2:31 - loss: 1.8954 - accuracy: 0.52 - ETA: 2:29 - loss: 1.8914 - accuracy: 0.52 - ETA: 2:27 - loss: 1.8968 - accuracy: 0.52 - ETA: 2:25 - loss: 1.9015 - accuracy: 0.52 - ETA: 2:23 - loss: 1.9029 - accuracy: 0.52 - ETA: 2:21 - loss: 1.9044 - accuracy: 0.52 - ETA: 2:19 - loss: 1.9006 - accuracy: 0.52 - ETA: 2:17 - loss: 1.9007 - accuracy: 0.52 - ETA: 2:15 - loss: 1.8986 - accuracy: 0.52 - ETA: 2:13 - loss: 1.8968 - accuracy: 0.52 - ETA: 2:10 - loss: 1.8982 - accuracy: 0.52 - ETA: 2:08 - loss: 1.8966 - accuracy: 0.52 - ETA: 2:06 - loss: 1.8930 - accuracy: 0.52 - ETA: 2:04 - loss: 1.8942 - accuracy: 0.52 - ETA: 2:02 - loss: 1.8944 - accuracy: 0.52 - ETA: 2:00 - loss: 1.8923 - accuracy: 0.52 - ETA: 1:58 - loss: 1.8948 - accuracy: 0.52 - ETA: 1:56 - loss: 1.8936 - accuracy: 0.52 - ETA: 1:54 - loss: 1.8992 - accuracy: 0.52 - ETA: 1:51 - loss: 1.8952 - accuracy: 0.52 - ETA: 1:49 - loss: 1.8948 - accuracy: 0.52 - ETA: 1:47 - loss: 1.8899 - accuracy: 0.52 - ETA: 1:45 - loss: 1.8944 - accuracy: 0.52 - ETA: 1:43 - loss: 1.8965 - accuracy: 0.52 - ETA: 1:41 - loss: 1.8992 - accuracy: 0.52 - ETA: 1:39 - loss: 1.8974 - accuracy: 0.52 - ETA: 1:37 - loss: 1.8982 - accuracy: 0.52 - ETA: 1:35 - loss: 1.8986 - accuracy: 0.52 - ETA: 1:32 - loss: 1.9000 - accuracy: 0.52 - ETA: 1:30 - loss: 1.8976 - accuracy: 0.52 - ETA: 1:28 - loss: 1.9012 - accuracy: 0.52 - ETA: 1:26 - loss: 1.9044 - accuracy: 0.52 - ETA: 1:24 - loss: 1.9042 - accuracy: 0.52 - ETA: 1:22 - loss: 1.9004 - accuracy: 0.52 - ETA: 1:20 - loss: 1.8989 - accuracy: 0.52 - ETA: 1:18 - loss: 1.9018 - accuracy: 0.52 - ETA: 1:15 - loss: 1.9010 - accuracy: 0.52 - ETA: 1:13 - loss: 1.9013 - accuracy: 0.52 - ETA: 1:11 - loss: 1.9013 - accuracy: 0.52 - ETA: 1:09 - loss: 1.8992 - accuracy: 0.52 - ETA: 1:07 - loss: 1.9058 - accuracy: 0.52 - ETA: 1:05 - loss: 1.9082 - accuracy: 0.52 - ETA: 1:03 - loss: 1.9080 - accuracy: 0.52 - ETA: 1:01 - loss: 1.9074 - accuracy: 0.52 - ETA: 59s - loss: 1.9051 - accuracy: 0.5231 - ETA: 56s - loss: 1.9054 - accuracy: 0.523 - ETA: 54s - loss: 1.9081 - accuracy: 0.523 - ETA: 52s - loss: 1.9072 - accuracy: 0.523 - ETA: 50s - loss: 1.9055 - accuracy: 0.523 - ETA: 48s - loss: 1.9104 - accuracy: 0.523 - ETA: 46s - loss: 1.9098 - accuracy: 0.523 - ETA: 44s - loss: 1.9117 - accuracy: 0.523 - ETA: 42s - loss: 1.9107 - accuracy: 0.523 - ETA: 40s - loss: 1.9214 - accuracy: 0.523 - ETA: 37s - loss: 1.9181 - accuracy: 0.524 - ETA: 35s - loss: 1.9145 - accuracy: 0.524 - ETA: 33s - loss: 1.9136 - accuracy: 0.524 - ETA: 31s - loss: 1.9144 - accuracy: 0.524 - ETA: 29s - loss: 1.9165 - accuracy: 0.524 - ETA: 27s - loss: 1.9157 - accuracy: 0.525 - ETA: 25s - loss: 1.9152 - accuracy: 0.525 - ETA: 23s - loss: 1.9146 - accuracy: 0.525 - ETA: 20s - loss: 1.9120 - accuracy: 0.526 - ETA: 18s - loss: 1.9140 - accuracy: 0.526 - ETA: 16s - loss: 1.9138 - accuracy: 0.526 - ETA: 14s - loss: 1.9139 - accuracy: 0.525 - ETA: 12s - loss: 1.9116 - accuracy: 0.526 - ETA: 10s - loss: 1.9121 - accuracy: 0.525 - ETA: 8s - loss: 1.9096 - accuracy: 0.525 - ETA: 6s - loss: 1.9066 - accuracy: 0.52 - ETA: 3s - loss: 1.9110 - accuracy: 0.52 - ETA: 1s - loss: 1.9095 - accuracy: 0.52 - 345s 18ms/step - loss: 1.9076 - accuracy: 0.5264 - val_loss: 1.7100 - val_accuracy: 0.6068\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:22 - loss: 2.5084 - accuracy: 0.42 - ETA: 5:17 - loss: 2.1141 - accuracy: 0.50 - ETA: 5:18 - loss: 2.1386 - accuracy: 0.49 - ETA: 5:12 - loss: 1.9591 - accuracy: 0.53 - ETA: 5:10 - loss: 1.9486 - accuracy: 0.52 - ETA: 5:09 - loss: 1.9424 - accuracy: 0.52 - ETA: 5:06 - loss: 2.0100 - accuracy: 0.52 - ETA: 5:05 - loss: 1.9908 - accuracy: 0.53 - ETA: 5:02 - loss: 1.9914 - accuracy: 0.53 - ETA: 5:01 - loss: 1.9664 - accuracy: 0.53 - ETA: 4:59 - loss: 1.9398 - accuracy: 0.53 - ETA: 4:56 - loss: 1.9209 - accuracy: 0.53 - ETA: 4:55 - loss: 1.9205 - accuracy: 0.53 - ETA: 4:52 - loss: 1.8942 - accuracy: 0.53 - ETA: 4:51 - loss: 1.8696 - accuracy: 0.54 - ETA: 4:48 - loss: 1.9315 - accuracy: 0.53 - ETA: 4:46 - loss: 1.9031 - accuracy: 0.54 - ETA: 4:44 - loss: 1.8880 - accuracy: 0.54 - ETA: 4:41 - loss: 1.8813 - accuracy: 0.54 - ETA: 4:38 - loss: 1.8866 - accuracy: 0.54 - ETA: 4:37 - loss: 1.8917 - accuracy: 0.53 - ETA: 4:35 - loss: 1.9184 - accuracy: 0.53 - ETA: 4:33 - loss: 1.9171 - accuracy: 0.53 - ETA: 4:30 - loss: 1.9117 - accuracy: 0.53 - ETA: 4:28 - loss: 1.8897 - accuracy: 0.54 - ETA: 4:25 - loss: 1.8846 - accuracy: 0.54 - ETA: 4:23 - loss: 1.8799 - accuracy: 0.54 - ETA: 4:21 - loss: 1.8908 - accuracy: 0.53 - ETA: 4:19 - loss: 1.8949 - accuracy: 0.53 - ETA: 4:17 - loss: 1.8965 - accuracy: 0.53 - ETA: 4:15 - loss: 1.8940 - accuracy: 0.53 - ETA: 4:13 - loss: 1.8795 - accuracy: 0.53 - ETA: 4:11 - loss: 1.8780 - accuracy: 0.53 - ETA: 4:09 - loss: 1.8761 - accuracy: 0.53 - ETA: 4:07 - loss: 1.8731 - accuracy: 0.53 - ETA: 4:05 - loss: 1.8783 - accuracy: 0.53 - ETA: 4:03 - loss: 1.8849 - accuracy: 0.53 - ETA: 4:01 - loss: 1.8856 - accuracy: 0.53 - ETA: 3:59 - loss: 1.8841 - accuracy: 0.53 - ETA: 3:57 - loss: 1.8795 - accuracy: 0.53 - ETA: 3:55 - loss: 1.8801 - accuracy: 0.53 - ETA: 3:53 - loss: 1.8742 - accuracy: 0.53 - ETA: 3:51 - loss: 1.8742 - accuracy: 0.53 - ETA: 3:49 - loss: 1.8717 - accuracy: 0.53 - ETA: 3:47 - loss: 1.8708 - accuracy: 0.53 - ETA: 3:44 - loss: 1.8756 - accuracy: 0.53 - ETA: 3:42 - loss: 1.8767 - accuracy: 0.53 - ETA: 3:40 - loss: 1.8741 - accuracy: 0.53 - ETA: 3:38 - loss: 1.8687 - accuracy: 0.53 - ETA: 3:36 - loss: 1.8646 - accuracy: 0.53 - ETA: 3:34 - loss: 1.8620 - accuracy: 0.53 - ETA: 3:32 - loss: 1.8572 - accuracy: 0.54 - ETA: 3:30 - loss: 1.8561 - accuracy: 0.53 - ETA: 3:28 - loss: 1.8545 - accuracy: 0.54 - ETA: 3:25 - loss: 1.8561 - accuracy: 0.54 - ETA: 3:23 - loss: 1.8651 - accuracy: 0.54 - ETA: 3:21 - loss: 1.8578 - accuracy: 0.54 - ETA: 3:19 - loss: 1.8662 - accuracy: 0.54 - ETA: 3:17 - loss: 1.8651 - accuracy: 0.53 - ETA: 3:15 - loss: 1.8618 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8631 - accuracy: 0.54 - ETA: 3:10 - loss: 1.8645 - accuracy: 0.54 - ETA: 3:08 - loss: 1.8681 - accuracy: 0.54 - ETA: 3:06 - loss: 1.8697 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8760 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8743 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8725 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8751 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8708 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8793 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8725 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8732 - accuracy: 0.53 - ETA: 2:46 - loss: 1.8698 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8719 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8760 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8844 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8809 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8795 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8800 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8799 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8820 - accuracy: 0.53 - ETA: 2:27 - loss: 1.8804 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8795 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8816 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8870 - accuracy: 0.53 - ETA: 2:18 - loss: 1.9032 - accuracy: 0.53 - ETA: 2:16 - loss: 1.9024 - accuracy: 0.53 - ETA: 2:14 - loss: 1.9004 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8965 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8998 - accuracy: 0.53 - ETA: 2:08 - loss: 1.9021 - accuracy: 0.53 - ETA: 2:06 - loss: 1.9047 - accuracy: 0.52 - ETA: 2:03 - loss: 1.9058 - accuracy: 0.52 - ETA: 2:01 - loss: 1.9100 - accuracy: 0.52 - ETA: 1:59 - loss: 1.9102 - accuracy: 0.52 - ETA: 1:57 - loss: 1.9121 - accuracy: 0.52 - ETA: 1:55 - loss: 1.9137 - accuracy: 0.52 - ETA: 1:53 - loss: 1.9109 - accuracy: 0.52 - ETA: 1:50 - loss: 1.9089 - accuracy: 0.52 - ETA: 1:48 - loss: 1.9074 - accuracy: 0.52 - ETA: 1:46 - loss: 1.9076 - accuracy: 0.52 - ETA: 1:44 - loss: 1.9068 - accuracy: 0.52 - ETA: 1:42 - loss: 1.9035 - accuracy: 0.52 - ETA: 1:40 - loss: 1.9027 - accuracy: 0.52 - ETA: 1:37 - loss: 1.8996 - accuracy: 0.52 - ETA: 1:35 - loss: 1.8962 - accuracy: 0.52 - ETA: 1:33 - loss: 1.8944 - accuracy: 0.52 - ETA: 1:31 - loss: 1.8962 - accuracy: 0.52 - ETA: 1:29 - loss: 1.9149 - accuracy: 0.52 - ETA: 1:27 - loss: 1.9105 - accuracy: 0.52 - ETA: 1:25 - loss: 1.9083 - accuracy: 0.52 - ETA: 1:22 - loss: 1.9064 - accuracy: 0.52 - ETA: 1:20 - loss: 1.9055 - accuracy: 0.52 - ETA: 1:18 - loss: 1.9059 - accuracy: 0.52 - ETA: 1:16 - loss: 1.9019 - accuracy: 0.52 - ETA: 1:14 - loss: 1.9055 - accuracy: 0.52 - ETA: 1:12 - loss: 1.9063 - accuracy: 0.52 - ETA: 1:10 - loss: 1.9061 - accuracy: 0.52 - ETA: 1:08 - loss: 1.9030 - accuracy: 0.53 - ETA: 1:05 - loss: 1.9082 - accuracy: 0.52 - ETA: 1:03 - loss: 1.9060 - accuracy: 0.53 - ETA: 1:01 - loss: 1.9028 - accuracy: 0.53 - ETA: 59s - loss: 1.9003 - accuracy: 0.5309 - ETA: 57s - loss: 1.8992 - accuracy: 0.530 - ETA: 55s - loss: 1.9022 - accuracy: 0.530 - ETA: 53s - loss: 1.9025 - accuracy: 0.530 - ETA: 50s - loss: 1.9037 - accuracy: 0.529 - ETA: 48s - loss: 1.9056 - accuracy: 0.529 - ETA: 46s - loss: 1.9070 - accuracy: 0.529 - ETA: 44s - loss: 1.9037 - accuracy: 0.529 - ETA: 42s - loss: 1.9016 - accuracy: 0.530 - ETA: 40s - loss: 1.9005 - accuracy: 0.529 - ETA: 38s - loss: 1.8992 - accuracy: 0.529 - ETA: 35s - loss: 1.8999 - accuracy: 0.530 - ETA: 33s - loss: 1.9023 - accuracy: 0.530 - ETA: 31s - loss: 1.9006 - accuracy: 0.530 - ETA: 29s - loss: 1.8988 - accuracy: 0.531 - ETA: 27s - loss: 1.8985 - accuracy: 0.531 - ETA: 25s - loss: 1.8989 - accuracy: 0.531 - ETA: 23s - loss: 1.9026 - accuracy: 0.530 - ETA: 21s - loss: 1.9037 - accuracy: 0.530 - ETA: 18s - loss: 1.9007 - accuracy: 0.531 - ETA: 16s - loss: 1.8992 - accuracy: 0.531 - ETA: 14s - loss: 1.9016 - accuracy: 0.531 - ETA: 12s - loss: 1.9000 - accuracy: 0.530 - ETA: 10s - loss: 1.9012 - accuracy: 0.530 - ETA: 8s - loss: 1.8999 - accuracy: 0.530 - ETA: 6s - loss: 1.9014 - accuracy: 0.53 - ETA: 3s - loss: 1.9083 - accuracy: 0.53 - ETA: 1s - loss: 1.9076 - accuracy: 0.53 - 347s 18ms/step - loss: 1.9092 - accuracy: 0.5304 - val_loss: 1.7845 - val_accuracy: 0.5887\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:20 - loss: 1.9919 - accuracy: 0.45 - ETA: 5:12 - loss: 1.9892 - accuracy: 0.46 - ETA: 5:11 - loss: 1.8212 - accuracy: 0.50 - ETA: 5:06 - loss: 1.8270 - accuracy: 0.50 - ETA: 5:04 - loss: 1.7510 - accuracy: 0.52 - ETA: 5:04 - loss: 1.7658 - accuracy: 0.52 - ETA: 5:02 - loss: 1.8335 - accuracy: 0.51 - ETA: 5:00 - loss: 1.8401 - accuracy: 0.51 - ETA: 4:59 - loss: 1.8100 - accuracy: 0.52 - ETA: 4:57 - loss: 1.8143 - accuracy: 0.52 - ETA: 4:56 - loss: 1.8147 - accuracy: 0.52 - ETA: 4:54 - loss: 1.8382 - accuracy: 0.52 - ETA: 4:52 - loss: 1.8228 - accuracy: 0.52 - ETA: 4:49 - loss: 1.8126 - accuracy: 0.52 - ETA: 4:47 - loss: 1.8257 - accuracy: 0.52 - ETA: 4:45 - loss: 1.8559 - accuracy: 0.52 - ETA: 4:43 - loss: 1.8585 - accuracy: 0.52 - ETA: 4:40 - loss: 1.8788 - accuracy: 0.51 - ETA: 4:39 - loss: 1.8776 - accuracy: 0.52 - ETA: 4:37 - loss: 1.8635 - accuracy: 0.52 - ETA: 4:36 - loss: 1.8624 - accuracy: 0.52 - ETA: 4:33 - loss: 1.8522 - accuracy: 0.52 - ETA: 4:31 - loss: 1.8309 - accuracy: 0.52 - ETA: 4:29 - loss: 1.8376 - accuracy: 0.52 - ETA: 4:27 - loss: 1.8272 - accuracy: 0.53 - ETA: 4:25 - loss: 1.8209 - accuracy: 0.53 - ETA: 4:23 - loss: 1.8230 - accuracy: 0.53 - ETA: 4:21 - loss: 1.8386 - accuracy: 0.53 - ETA: 4:19 - loss: 1.8372 - accuracy: 0.53 - ETA: 4:17 - loss: 1.8403 - accuracy: 0.53 - ETA: 4:15 - loss: 1.8337 - accuracy: 0.53 - ETA: 4:13 - loss: 1.8280 - accuracy: 0.53 - ETA: 4:12 - loss: 1.8446 - accuracy: 0.53 - ETA: 4:09 - loss: 1.8337 - accuracy: 0.53 - ETA: 4:07 - loss: 1.8293 - accuracy: 0.53 - ETA: 4:05 - loss: 1.8449 - accuracy: 0.53 - ETA: 4:03 - loss: 1.8526 - accuracy: 0.53 - ETA: 4:00 - loss: 1.8490 - accuracy: 0.53 - ETA: 3:58 - loss: 1.8435 - accuracy: 0.53 - ETA: 3:56 - loss: 1.8408 - accuracy: 0.53 - ETA: 3:54 - loss: 1.8419 - accuracy: 0.53 - ETA: 3:52 - loss: 1.8416 - accuracy: 0.53 - ETA: 3:50 - loss: 1.8413 - accuracy: 0.53 - ETA: 3:48 - loss: 1.8360 - accuracy: 0.53 - ETA: 3:46 - loss: 1.8340 - accuracy: 0.53 - ETA: 3:44 - loss: 1.8263 - accuracy: 0.53 - ETA: 3:41 - loss: 1.8325 - accuracy: 0.53 - ETA: 3:39 - loss: 1.8340 - accuracy: 0.53 - ETA: 3:37 - loss: 1.8306 - accuracy: 0.53 - ETA: 3:35 - loss: 1.8316 - accuracy: 0.53 - ETA: 3:33 - loss: 1.8317 - accuracy: 0.53 - ETA: 3:31 - loss: 1.8301 - accuracy: 0.53 - ETA: 3:29 - loss: 1.8378 - accuracy: 0.53 - ETA: 3:27 - loss: 1.8359 - accuracy: 0.53 - ETA: 3:25 - loss: 1.8378 - accuracy: 0.53 - ETA: 3:23 - loss: 1.8463 - accuracy: 0.53 - ETA: 3:21 - loss: 1.8435 - accuracy: 0.53 - ETA: 3:19 - loss: 1.8393 - accuracy: 0.53 - ETA: 3:17 - loss: 1.8411 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8375 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8385 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8325 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8352 - accuracy: 0.53 - ETA: 3:05 - loss: 1.8291 - accuracy: 0.53 - ETA: 3:03 - loss: 1.8244 - accuracy: 0.53 - ETA: 3:01 - loss: 1.8238 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8206 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8186 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8204 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8145 - accuracy: 0.53 - ETA: 2:50 - loss: 1.8111 - accuracy: 0.53 - ETA: 2:48 - loss: 1.8152 - accuracy: 0.54 - ETA: 2:46 - loss: 1.8201 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8175 - accuracy: 0.54 - ETA: 2:42 - loss: 1.8207 - accuracy: 0.54 - ETA: 2:40 - loss: 1.8196 - accuracy: 0.54 - ETA: 2:37 - loss: 1.8168 - accuracy: 0.54 - ETA: 2:35 - loss: 1.8169 - accuracy: 0.54 - ETA: 2:33 - loss: 1.8205 - accuracy: 0.54 - ETA: 2:31 - loss: 1.8221 - accuracy: 0.54 - ETA: 2:29 - loss: 1.8232 - accuracy: 0.54 - ETA: 2:27 - loss: 1.8259 - accuracy: 0.54 - ETA: 2:25 - loss: 1.8274 - accuracy: 0.54 - ETA: 2:23 - loss: 1.8328 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8342 - accuracy: 0.53 - ETA: 2:18 - loss: 1.8325 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8326 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8308 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8269 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8302 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8292 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8280 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8245 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8195 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8253 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8425 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8441 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8443 - accuracy: 0.53 - ETA: 1:50 - loss: 1.8486 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8488 - accuracy: 0.53 - ETA: 1:46 - loss: 1.8473 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8465 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8465 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8432 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8439 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8495 - accuracy: 0.54 - ETA: 1:33 - loss: 1.8470 - accuracy: 0.54 - ETA: 1:31 - loss: 1.8488 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8477 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8480 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8486 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8472 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8481 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8454 - accuracy: 0.54 - ETA: 1:16 - loss: 1.8426 - accuracy: 0.54 - ETA: 1:14 - loss: 1.8420 - accuracy: 0.54 - ETA: 1:12 - loss: 1.8418 - accuracy: 0.54 - ETA: 1:10 - loss: 1.8410 - accuracy: 0.54 - ETA: 1:07 - loss: 1.8400 - accuracy: 0.54 - ETA: 1:05 - loss: 1.8412 - accuracy: 0.54 - ETA: 1:03 - loss: 1.8394 - accuracy: 0.54 - ETA: 1:01 - loss: 1.8397 - accuracy: 0.53 - ETA: 59s - loss: 1.8388 - accuracy: 0.5396 - ETA: 57s - loss: 1.8384 - accuracy: 0.539 - ETA: 55s - loss: 1.8373 - accuracy: 0.539 - ETA: 52s - loss: 1.8361 - accuracy: 0.539 - ETA: 50s - loss: 1.8359 - accuracy: 0.538 - ETA: 48s - loss: 1.8356 - accuracy: 0.538 - ETA: 46s - loss: 1.8359 - accuracy: 0.538 - ETA: 44s - loss: 1.8368 - accuracy: 0.538 - ETA: 42s - loss: 1.8370 - accuracy: 0.538 - ETA: 40s - loss: 1.8326 - accuracy: 0.538 - ETA: 38s - loss: 1.8326 - accuracy: 0.538 - ETA: 35s - loss: 1.8294 - accuracy: 0.539 - ETA: 33s - loss: 1.8287 - accuracy: 0.539 - ETA: 31s - loss: 1.8269 - accuracy: 0.539 - ETA: 29s - loss: 1.8268 - accuracy: 0.539 - ETA: 27s - loss: 1.8257 - accuracy: 0.539 - ETA: 25s - loss: 1.8254 - accuracy: 0.539 - ETA: 23s - loss: 1.8260 - accuracy: 0.540 - ETA: 21s - loss: 1.8253 - accuracy: 0.539 - ETA: 18s - loss: 1.8256 - accuracy: 0.539 - ETA: 16s - loss: 1.8232 - accuracy: 0.539 - ETA: 14s - loss: 1.8240 - accuracy: 0.539 - ETA: 12s - loss: 1.8218 - accuracy: 0.539 - ETA: 10s - loss: 1.8212 - accuracy: 0.539 - ETA: 8s - loss: 1.8239 - accuracy: 0.539 - ETA: 6s - loss: 1.8224 - accuracy: 0.54 - ETA: 3s - loss: 1.8216 - accuracy: 0.54 - ETA: 1s - loss: 1.8243 - accuracy: 0.53 - 346s 18ms/step - loss: 1.8252 - accuracy: 0.5396 - val_loss: 1.7222 - val_accuracy: 0.5943\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:03 - loss: 2.0230 - accuracy: 0.53 - ETA: 5:05 - loss: 1.9325 - accuracy: 0.53 - ETA: 5:00 - loss: 1.9142 - accuracy: 0.53 - ETA: 5:03 - loss: 2.2248 - accuracy: 0.52 - ETA: 5:04 - loss: 2.2079 - accuracy: 0.50 - ETA: 5:02 - loss: 2.1068 - accuracy: 0.51 - ETA: 5:00 - loss: 2.0724 - accuracy: 0.52 - ETA: 4:57 - loss: 2.0745 - accuracy: 0.52 - ETA: 4:57 - loss: 2.0325 - accuracy: 0.52 - ETA: 4:55 - loss: 1.9810 - accuracy: 0.52 - ETA: 4:55 - loss: 1.9370 - accuracy: 0.53 - ETA: 4:53 - loss: 2.0061 - accuracy: 0.53 - ETA: 4:51 - loss: 2.0011 - accuracy: 0.53 - ETA: 4:48 - loss: 1.9827 - accuracy: 0.53 - ETA: 4:44 - loss: 1.9653 - accuracy: 0.53 - ETA: 4:43 - loss: 1.9546 - accuracy: 0.53 - ETA: 4:40 - loss: 1.9336 - accuracy: 0.54 - ETA: 4:38 - loss: 1.9350 - accuracy: 0.53 - ETA: 4:37 - loss: 1.9344 - accuracy: 0.53 - ETA: 4:34 - loss: 1.9416 - accuracy: 0.53 - ETA: 4:33 - loss: 1.9293 - accuracy: 0.53 - ETA: 4:31 - loss: 1.9191 - accuracy: 0.53 - ETA: 4:29 - loss: 1.9098 - accuracy: 0.54 - ETA: 4:27 - loss: 1.8976 - accuracy: 0.54 - ETA: 4:25 - loss: 1.8915 - accuracy: 0.54 - ETA: 4:23 - loss: 1.8830 - accuracy: 0.54 - ETA: 4:21 - loss: 1.8895 - accuracy: 0.53 - ETA: 4:19 - loss: 1.8964 - accuracy: 0.53 - ETA: 4:17 - loss: 1.8968 - accuracy: 0.53 - ETA: 4:15 - loss: 1.8997 - accuracy: 0.53 - ETA: 4:13 - loss: 1.9019 - accuracy: 0.53 - ETA: 4:11 - loss: 1.8985 - accuracy: 0.53 - ETA: 4:09 - loss: 1.8983 - accuracy: 0.53 - ETA: 4:06 - loss: 1.9146 - accuracy: 0.53 - ETA: 4:04 - loss: 1.9029 - accuracy: 0.53 - ETA: 4:02 - loss: 1.8973 - accuracy: 0.53 - ETA: 4:00 - loss: 1.8892 - accuracy: 0.53 - ETA: 3:58 - loss: 1.8835 - accuracy: 0.53 - ETA: 3:56 - loss: 1.8794 - accuracy: 0.53 - ETA: 3:53 - loss: 1.8802 - accuracy: 0.53 - ETA: 3:51 - loss: 1.8824 - accuracy: 0.53 - ETA: 3:50 - loss: 1.8800 - accuracy: 0.53 - ETA: 3:47 - loss: 1.8722 - accuracy: 0.53 - ETA: 3:45 - loss: 1.8726 - accuracy: 0.53 - ETA: 3:43 - loss: 1.8673 - accuracy: 0.53 - ETA: 3:41 - loss: 1.8624 - accuracy: 0.53 - ETA: 3:39 - loss: 1.8590 - accuracy: 0.53 - ETA: 3:37 - loss: 1.8459 - accuracy: 0.53 - ETA: 3:35 - loss: 1.8526 - accuracy: 0.53 - ETA: 3:33 - loss: 1.8563 - accuracy: 0.53 - ETA: 3:31 - loss: 1.8637 - accuracy: 0.53 - ETA: 3:29 - loss: 1.8631 - accuracy: 0.53 - ETA: 3:26 - loss: 1.8564 - accuracy: 0.53 - ETA: 3:24 - loss: 1.8575 - accuracy: 0.53 - ETA: 3:22 - loss: 1.8603 - accuracy: 0.53 - ETA: 3:20 - loss: 1.8629 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8682 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8708 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8789 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8798 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8780 - accuracy: 0.53 - ETA: 3:07 - loss: 1.8832 - accuracy: 0.53 - ETA: 3:05 - loss: 1.8798 - accuracy: 0.53 - ETA: 3:03 - loss: 1.8851 - accuracy: 0.53 - ETA: 3:01 - loss: 1.9017 - accuracy: 0.53 - ETA: 2:59 - loss: 1.9020 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8987 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8952 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8939 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8966 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8943 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8924 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8948 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8941 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8936 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8969 - accuracy: 0.53 - ETA: 2:36 - loss: 1.9014 - accuracy: 0.53 - ETA: 2:34 - loss: 1.9056 - accuracy: 0.53 - ETA: 2:32 - loss: 1.9098 - accuracy: 0.53 - ETA: 2:30 - loss: 1.9107 - accuracy: 0.53 - ETA: 2:27 - loss: 1.9147 - accuracy: 0.53 - ETA: 2:25 - loss: 1.9161 - accuracy: 0.53 - ETA: 2:23 - loss: 1.9129 - accuracy: 0.53 - ETA: 2:21 - loss: 1.9097 - accuracy: 0.53 - ETA: 2:19 - loss: 1.9121 - accuracy: 0.53 - ETA: 2:17 - loss: 1.9088 - accuracy: 0.53 - ETA: 2:15 - loss: 1.9118 - accuracy: 0.53 - ETA: 2:13 - loss: 1.9071 - accuracy: 0.53 - ETA: 2:11 - loss: 1.9048 - accuracy: 0.53 - ETA: 2:08 - loss: 1.9013 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8993 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8995 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8984 - accuracy: 0.53 - ETA: 2:00 - loss: 1.9094 - accuracy: 0.53 - ETA: 1:58 - loss: 1.9131 - accuracy: 0.53 - ETA: 1:56 - loss: 1.9117 - accuracy: 0.53 - ETA: 1:54 - loss: 1.9093 - accuracy: 0.53 - ETA: 1:51 - loss: 1.9140 - accuracy: 0.53 - ETA: 1:49 - loss: 1.9178 - accuracy: 0.53 - ETA: 1:47 - loss: 1.9185 - accuracy: 0.53 - ETA: 1:45 - loss: 1.9179 - accuracy: 0.53 - ETA: 1:43 - loss: 1.9210 - accuracy: 0.52 - ETA: 1:41 - loss: 1.9209 - accuracy: 0.53 - ETA: 1:39 - loss: 1.9198 - accuracy: 0.52 - ETA: 1:37 - loss: 1.9232 - accuracy: 0.52 - ETA: 1:35 - loss: 1.9217 - accuracy: 0.52 - ETA: 1:33 - loss: 1.9209 - accuracy: 0.52 - ETA: 1:30 - loss: 1.9191 - accuracy: 0.52 - ETA: 1:28 - loss: 1.9185 - accuracy: 0.52 - ETA: 1:26 - loss: 1.9166 - accuracy: 0.52 - ETA: 1:24 - loss: 1.9149 - accuracy: 0.52 - ETA: 1:22 - loss: 1.9179 - accuracy: 0.52 - ETA: 1:20 - loss: 1.9153 - accuracy: 0.52 - ETA: 1:18 - loss: 1.9141 - accuracy: 0.52 - ETA: 1:16 - loss: 1.9119 - accuracy: 0.52 - ETA: 1:14 - loss: 1.9125 - accuracy: 0.52 - ETA: 1:11 - loss: 1.9090 - accuracy: 0.52 - ETA: 1:09 - loss: 1.9082 - accuracy: 0.52 - ETA: 1:07 - loss: 1.9079 - accuracy: 0.52 - ETA: 1:05 - loss: 1.9141 - accuracy: 0.53 - ETA: 1:03 - loss: 1.9140 - accuracy: 0.52 - ETA: 1:01 - loss: 1.9211 - accuracy: 0.52 - ETA: 59s - loss: 1.9198 - accuracy: 0.5293 - ETA: 56s - loss: 1.9183 - accuracy: 0.529 - ETA: 54s - loss: 1.9211 - accuracy: 0.528 - ETA: 52s - loss: 1.9197 - accuracy: 0.529 - ETA: 50s - loss: 1.9220 - accuracy: 0.529 - ETA: 48s - loss: 1.9237 - accuracy: 0.529 - ETA: 46s - loss: 1.9222 - accuracy: 0.529 - ETA: 44s - loss: 1.9213 - accuracy: 0.529 - ETA: 42s - loss: 1.9197 - accuracy: 0.529 - ETA: 40s - loss: 1.9207 - accuracy: 0.528 - ETA: 37s - loss: 1.9183 - accuracy: 0.528 - ETA: 35s - loss: 1.9157 - accuracy: 0.529 - ETA: 33s - loss: 1.9146 - accuracy: 0.529 - ETA: 31s - loss: 1.9139 - accuracy: 0.529 - ETA: 29s - loss: 1.9124 - accuracy: 0.529 - ETA: 27s - loss: 1.9145 - accuracy: 0.529 - ETA: 25s - loss: 1.9168 - accuracy: 0.529 - ETA: 23s - loss: 1.9160 - accuracy: 0.529 - ETA: 20s - loss: 1.9198 - accuracy: 0.529 - ETA: 18s - loss: 1.9245 - accuracy: 0.529 - ETA: 16s - loss: 1.9239 - accuracy: 0.529 - ETA: 14s - loss: 1.9229 - accuracy: 0.530 - ETA: 12s - loss: 1.9216 - accuracy: 0.530 - ETA: 10s - loss: 1.9246 - accuracy: 0.529 - ETA: 8s - loss: 1.9239 - accuracy: 0.529 - ETA: 6s - loss: 1.9244 - accuracy: 0.52 - ETA: 3s - loss: 1.9244 - accuracy: 0.52 - ETA: 1s - loss: 1.9235 - accuracy: 0.52 - 345s 18ms/step - loss: 1.9247 - accuracy: 0.5293 - val_loss: 1.6903 - val_accuracy: 0.5786\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:07 - loss: 1.7638 - accuracy: 0.57 - ETA: 5:19 - loss: 1.7099 - accuracy: 0.55 - ETA: 5:14 - loss: 1.6630 - accuracy: 0.55 - ETA: 5:14 - loss: 1.6968 - accuracy: 0.54 - ETA: 5:09 - loss: 1.7036 - accuracy: 0.53 - ETA: 5:06 - loss: 1.8569 - accuracy: 0.53 - ETA: 5:06 - loss: 1.8611 - accuracy: 0.52 - ETA: 5:02 - loss: 1.8564 - accuracy: 0.52 - ETA: 5:00 - loss: 1.8982 - accuracy: 0.50 - ETA: 4:57 - loss: 1.8787 - accuracy: 0.51 - ETA: 4:56 - loss: 1.8962 - accuracy: 0.51 - ETA: 4:53 - loss: 1.8926 - accuracy: 0.51 - ETA: 4:51 - loss: 1.8748 - accuracy: 0.51 - ETA: 4:50 - loss: 1.8927 - accuracy: 0.50 - ETA: 4:48 - loss: 1.8909 - accuracy: 0.51 - ETA: 4:47 - loss: 1.8826 - accuracy: 0.51 - ETA: 4:44 - loss: 1.8824 - accuracy: 0.51 - ETA: 4:44 - loss: 1.8698 - accuracy: 0.51 - ETA: 4:41 - loss: 1.8927 - accuracy: 0.51 - ETA: 4:38 - loss: 1.9458 - accuracy: 0.50 - ETA: 4:35 - loss: 1.9314 - accuracy: 0.51 - ETA: 4:33 - loss: 1.9197 - accuracy: 0.51 - ETA: 4:31 - loss: 1.9136 - accuracy: 0.51 - ETA: 4:29 - loss: 1.9516 - accuracy: 0.51 - ETA: 4:27 - loss: 1.9581 - accuracy: 0.51 - ETA: 4:25 - loss: 1.9544 - accuracy: 0.51 - ETA: 4:23 - loss: 1.9450 - accuracy: 0.51 - ETA: 4:21 - loss: 1.9438 - accuracy: 0.51 - ETA: 4:18 - loss: 1.9419 - accuracy: 0.51 - ETA: 4:16 - loss: 1.9378 - accuracy: 0.51 - ETA: 4:14 - loss: 1.9277 - accuracy: 0.51 - ETA: 4:12 - loss: 1.9267 - accuracy: 0.51 - ETA: 4:09 - loss: 1.9065 - accuracy: 0.52 - ETA: 4:07 - loss: 1.8984 - accuracy: 0.52 - ETA: 4:05 - loss: 1.8980 - accuracy: 0.52 - ETA: 4:03 - loss: 1.8839 - accuracy: 0.52 - ETA: 4:01 - loss: 1.8747 - accuracy: 0.52 - ETA: 3:59 - loss: 1.8674 - accuracy: 0.53 - ETA: 3:56 - loss: 1.8685 - accuracy: 0.53 - ETA: 3:54 - loss: 1.8704 - accuracy: 0.52 - ETA: 3:52 - loss: 1.8620 - accuracy: 0.53 - ETA: 3:50 - loss: 1.8661 - accuracy: 0.53 - ETA: 3:47 - loss: 1.8688 - accuracy: 0.53 - ETA: 3:46 - loss: 1.8640 - accuracy: 0.53 - ETA: 3:43 - loss: 1.8653 - accuracy: 0.53 - ETA: 3:41 - loss: 1.8532 - accuracy: 0.53 - ETA: 3:39 - loss: 1.8466 - accuracy: 0.53 - ETA: 3:37 - loss: 1.8534 - accuracy: 0.53 - ETA: 3:35 - loss: 1.8635 - accuracy: 0.53 - ETA: 3:33 - loss: 1.8588 - accuracy: 0.53 - ETA: 3:31 - loss: 1.8618 - accuracy: 0.53 - ETA: 3:29 - loss: 1.8709 - accuracy: 0.53 - ETA: 3:26 - loss: 1.8703 - accuracy: 0.53 - ETA: 3:25 - loss: 1.8715 - accuracy: 0.53 - ETA: 3:22 - loss: 1.8708 - accuracy: 0.53 - ETA: 3:20 - loss: 1.8706 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8718 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8706 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8688 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8927 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8921 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8834 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8851 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8888 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8856 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8811 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8840 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8866 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8831 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8791 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8873 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8838 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8769 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8711 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8696 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8671 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8664 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8679 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8696 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8669 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8663 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8713 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8668 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8629 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8619 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8607 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8585 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8669 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8822 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8834 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8800 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8997 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8991 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8968 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8968 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8990 - accuracy: 0.53 - ETA: 1:54 - loss: 1.9005 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8972 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8941 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8907 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8919 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8941 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8935 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8882 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8865 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8874 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8857 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8859 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8889 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8873 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8878 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8893 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8893 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8883 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8837 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8861 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8862 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8877 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8856 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8835 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8809 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8833 - accuracy: 0.53 - ETA: 58s - loss: 1.8815 - accuracy: 0.5350 - ETA: 56s - loss: 1.8851 - accuracy: 0.534 - ETA: 54s - loss: 1.8844 - accuracy: 0.534 - ETA: 52s - loss: 1.8852 - accuracy: 0.534 - ETA: 50s - loss: 1.8874 - accuracy: 0.533 - ETA: 48s - loss: 1.8837 - accuracy: 0.534 - ETA: 46s - loss: 1.8823 - accuracy: 0.534 - ETA: 44s - loss: 1.8825 - accuracy: 0.534 - ETA: 42s - loss: 1.8827 - accuracy: 0.534 - ETA: 39s - loss: 1.8812 - accuracy: 0.535 - ETA: 37s - loss: 1.8822 - accuracy: 0.534 - ETA: 35s - loss: 1.8797 - accuracy: 0.534 - ETA: 33s - loss: 1.8809 - accuracy: 0.534 - ETA: 31s - loss: 1.8843 - accuracy: 0.533 - ETA: 29s - loss: 1.8828 - accuracy: 0.534 - ETA: 27s - loss: 1.8849 - accuracy: 0.534 - ETA: 25s - loss: 1.8824 - accuracy: 0.534 - ETA: 23s - loss: 1.8834 - accuracy: 0.534 - ETA: 20s - loss: 1.8831 - accuracy: 0.534 - ETA: 18s - loss: 1.8834 - accuracy: 0.534 - ETA: 16s - loss: 1.8843 - accuracy: 0.534 - ETA: 14s - loss: 1.8853 - accuracy: 0.534 - ETA: 12s - loss: 1.8845 - accuracy: 0.533 - ETA: 10s - loss: 1.8828 - accuracy: 0.534 - ETA: 8s - loss: 1.8832 - accuracy: 0.534 - ETA: 6s - loss: 1.8820 - accuracy: 0.53 - ETA: 3s - loss: 1.8832 - accuracy: 0.53 - ETA: 1s - loss: 1.8827 - accuracy: 0.53 - 345s 18ms/step - loss: 1.8820 - accuracy: 0.5339 - val_loss: 1.7603 - val_accuracy: 0.5891\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:07 - loss: 1.5346 - accuracy: 0.56 - ETA: 5:07 - loss: 1.5288 - accuracy: 0.57 - ETA: 5:06 - loss: 1.6234 - accuracy: 0.56 - ETA: 5:02 - loss: 1.7852 - accuracy: 0.56 - ETA: 5:04 - loss: 1.8302 - accuracy: 0.55 - ETA: 5:04 - loss: 1.7748 - accuracy: 0.55 - ETA: 5:00 - loss: 1.7991 - accuracy: 0.55 - ETA: 4:58 - loss: 1.7787 - accuracy: 0.55 - ETA: 4:56 - loss: 1.7534 - accuracy: 0.55 - ETA: 4:55 - loss: 1.7691 - accuracy: 0.55 - ETA: 4:54 - loss: 1.7484 - accuracy: 0.55 - ETA: 4:50 - loss: 1.7526 - accuracy: 0.55 - ETA: 4:49 - loss: 1.7315 - accuracy: 0.55 - ETA: 4:47 - loss: 1.7333 - accuracy: 0.55 - ETA: 4:45 - loss: 1.7388 - accuracy: 0.55 - ETA: 4:42 - loss: 1.7453 - accuracy: 0.54 - ETA: 4:41 - loss: 1.7531 - accuracy: 0.54 - ETA: 4:39 - loss: 1.7545 - accuracy: 0.54 - ETA: 4:37 - loss: 1.7393 - accuracy: 0.54 - ETA: 4:33 - loss: 1.7389 - accuracy: 0.54 - ETA: 4:31 - loss: 1.7595 - accuracy: 0.54 - ETA: 4:29 - loss: 1.7429 - accuracy: 0.55 - ETA: 4:27 - loss: 1.7397 - accuracy: 0.55 - ETA: 4:25 - loss: 1.7898 - accuracy: 0.54 - ETA: 4:23 - loss: 1.8007 - accuracy: 0.54 - ETA: 4:21 - loss: 1.7975 - accuracy: 0.54 - ETA: 4:19 - loss: 1.7976 - accuracy: 0.54 - ETA: 4:17 - loss: 1.8066 - accuracy: 0.54 - ETA: 4:15 - loss: 1.8182 - accuracy: 0.54 - ETA: 4:13 - loss: 1.8165 - accuracy: 0.54 - ETA: 4:11 - loss: 1.8191 - accuracy: 0.54 - ETA: 4:08 - loss: 1.8171 - accuracy: 0.54 - ETA: 4:06 - loss: 1.8150 - accuracy: 0.53 - ETA: 4:04 - loss: 1.8136 - accuracy: 0.53 - ETA: 4:02 - loss: 1.8119 - accuracy: 0.54 - ETA: 3:59 - loss: 1.8101 - accuracy: 0.53 - ETA: 3:57 - loss: 1.8043 - accuracy: 0.53 - ETA: 3:55 - loss: 1.8380 - accuracy: 0.54 - ETA: 3:54 - loss: 1.8481 - accuracy: 0.54 - ETA: 3:52 - loss: 1.8503 - accuracy: 0.53 - ETA: 3:50 - loss: 1.8494 - accuracy: 0.53 - ETA: 3:48 - loss: 1.8444 - accuracy: 0.53 - ETA: 3:46 - loss: 1.8350 - accuracy: 0.54 - ETA: 3:43 - loss: 1.8328 - accuracy: 0.54 - ETA: 3:41 - loss: 1.8350 - accuracy: 0.53 - ETA: 3:39 - loss: 1.8337 - accuracy: 0.53 - ETA: 3:37 - loss: 1.8343 - accuracy: 0.53 - ETA: 3:35 - loss: 1.8326 - accuracy: 0.53 - ETA: 3:32 - loss: 1.8304 - accuracy: 0.53 - ETA: 3:30 - loss: 1.8277 - accuracy: 0.53 - ETA: 3:28 - loss: 1.8274 - accuracy: 0.53 - ETA: 3:26 - loss: 1.8243 - accuracy: 0.53 - ETA: 3:24 - loss: 1.8205 - accuracy: 0.53 - ETA: 3:22 - loss: 1.8134 - accuracy: 0.53 - ETA: 3:20 - loss: 1.8174 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8124 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8203 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8276 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8242 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8224 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8175 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8193 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8199 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8182 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8157 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8151 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8182 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8211 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8201 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8184 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8164 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8105 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8082 - accuracy: 0.53 - ETA: 2:41 - loss: 1.8071 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8008 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8057 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8010 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7981 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7991 - accuracy: 0.54 - ETA: 2:28 - loss: 1.8058 - accuracy: 0.53 - ETA: 2:26 - loss: 1.8063 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8057 - accuracy: 0.53 - ETA: 2:22 - loss: 1.8043 - accuracy: 0.54 - ETA: 2:20 - loss: 1.8038 - accuracy: 0.54 - ETA: 2:18 - loss: 1.8009 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7999 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7968 - accuracy: 0.54 - ETA: 2:11 - loss: 1.7942 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7902 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7900 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7891 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7913 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7941 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7930 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7917 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7935 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7949 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7979 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7973 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7979 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7952 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7940 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7952 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7982 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7982 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7976 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7954 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7973 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7986 - accuracy: 0.54 - ETA: 1:25 - loss: 1.8012 - accuracy: 0.54 - ETA: 1:23 - loss: 1.8019 - accuracy: 0.54 - ETA: 1:21 - loss: 1.8023 - accuracy: 0.54 - ETA: 1:19 - loss: 1.8029 - accuracy: 0.54 - ETA: 1:17 - loss: 1.8002 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7993 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7981 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7979 - accuracy: 0.54 - ETA: 1:08 - loss: 1.7996 - accuracy: 0.54 - ETA: 1:06 - loss: 1.8020 - accuracy: 0.54 - ETA: 1:04 - loss: 1.8022 - accuracy: 0.54 - ETA: 1:02 - loss: 1.8031 - accuracy: 0.54 - ETA: 1:00 - loss: 1.8030 - accuracy: 0.54 - ETA: 58s - loss: 1.8030 - accuracy: 0.5447 - ETA: 56s - loss: 1.8041 - accuracy: 0.544 - ETA: 54s - loss: 1.8056 - accuracy: 0.543 - ETA: 52s - loss: 1.8046 - accuracy: 0.543 - ETA: 50s - loss: 1.8090 - accuracy: 0.543 - ETA: 48s - loss: 1.8066 - accuracy: 0.543 - ETA: 45s - loss: 1.8070 - accuracy: 0.543 - ETA: 43s - loss: 1.8072 - accuracy: 0.543 - ETA: 41s - loss: 1.8064 - accuracy: 0.543 - ETA: 39s - loss: 1.8196 - accuracy: 0.543 - ETA: 37s - loss: 1.8206 - accuracy: 0.543 - ETA: 35s - loss: 1.8190 - accuracy: 0.543 - ETA: 33s - loss: 1.8164 - accuracy: 0.543 - ETA: 31s - loss: 1.8146 - accuracy: 0.543 - ETA: 29s - loss: 1.8190 - accuracy: 0.542 - ETA: 27s - loss: 1.8177 - accuracy: 0.542 - ETA: 24s - loss: 1.8181 - accuracy: 0.543 - ETA: 22s - loss: 1.8182 - accuracy: 0.543 - ETA: 20s - loss: 1.8183 - accuracy: 0.543 - ETA: 18s - loss: 1.8173 - accuracy: 0.544 - ETA: 16s - loss: 1.8171 - accuracy: 0.543 - ETA: 14s - loss: 1.8181 - accuracy: 0.543 - ETA: 12s - loss: 1.8177 - accuracy: 0.543 - ETA: 10s - loss: 1.8203 - accuracy: 0.543 - ETA: 8s - loss: 1.8279 - accuracy: 0.542 - ETA: 6s - loss: 1.8276 - accuracy: 0.54 - ETA: 3s - loss: 1.8265 - accuracy: 0.54 - ETA: 1s - loss: 1.8246 - accuracy: 0.54 - 342s 18ms/step - loss: 1.8239 - accuracy: 0.5434 - val_loss: 1.7622 - val_accuracy: 0.5819\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:16 - loss: 1.9227 - accuracy: 0.59 - ETA: 5:19 - loss: 1.9241 - accuracy: 0.52 - ETA: 5:13 - loss: 1.8097 - accuracy: 0.53 - ETA: 5:14 - loss: 1.9075 - accuracy: 0.53 - ETA: 5:13 - loss: 1.8712 - accuracy: 0.53 - ETA: 5:08 - loss: 1.8527 - accuracy: 0.52 - ETA: 5:06 - loss: 1.8566 - accuracy: 0.52 - ETA: 5:02 - loss: 1.8330 - accuracy: 0.53 - ETA: 4:58 - loss: 1.9209 - accuracy: 0.52 - ETA: 4:56 - loss: 1.9377 - accuracy: 0.52 - ETA: 4:56 - loss: 1.9123 - accuracy: 0.52 - ETA: 4:53 - loss: 1.9191 - accuracy: 0.52 - ETA: 4:51 - loss: 1.9034 - accuracy: 0.52 - ETA: 4:48 - loss: 1.8962 - accuracy: 0.52 - ETA: 4:45 - loss: 1.8816 - accuracy: 0.52 - ETA: 4:43 - loss: 1.8690 - accuracy: 0.52 - ETA: 4:40 - loss: 1.8683 - accuracy: 0.52 - ETA: 4:39 - loss: 1.8690 - accuracy: 0.52 - ETA: 4:37 - loss: 1.8707 - accuracy: 0.53 - ETA: 4:36 - loss: 1.8644 - accuracy: 0.52 - ETA: 4:34 - loss: 1.8501 - accuracy: 0.52 - ETA: 4:32 - loss: 1.8402 - accuracy: 0.53 - ETA: 4:29 - loss: 1.8623 - accuracy: 0.53 - ETA: 4:26 - loss: 1.8590 - accuracy: 0.52 - ETA: 4:24 - loss: 1.8728 - accuracy: 0.52 - ETA: 4:22 - loss: 1.8751 - accuracy: 0.52 - ETA: 4:19 - loss: 1.8778 - accuracy: 0.52 - ETA: 4:17 - loss: 1.8770 - accuracy: 0.52 - ETA: 4:14 - loss: 1.8831 - accuracy: 0.52 - ETA: 4:13 - loss: 1.9128 - accuracy: 0.53 - ETA: 4:10 - loss: 1.9114 - accuracy: 0.53 - ETA: 4:08 - loss: 1.9032 - accuracy: 0.53 - ETA: 4:06 - loss: 1.9099 - accuracy: 0.52 - ETA: 4:04 - loss: 1.8991 - accuracy: 0.53 - ETA: 4:02 - loss: 1.9027 - accuracy: 0.53 - ETA: 4:01 - loss: 1.9001 - accuracy: 0.53 - ETA: 3:58 - loss: 1.8886 - accuracy: 0.53 - ETA: 3:57 - loss: 1.8853 - accuracy: 0.53 - ETA: 3:54 - loss: 1.8751 - accuracy: 0.53 - ETA: 3:52 - loss: 1.8757 - accuracy: 0.53 - ETA: 3:50 - loss: 1.8740 - accuracy: 0.53 - ETA: 3:48 - loss: 1.8710 - accuracy: 0.53 - ETA: 3:46 - loss: 1.8706 - accuracy: 0.53 - ETA: 3:44 - loss: 1.8685 - accuracy: 0.53 - ETA: 3:42 - loss: 1.8655 - accuracy: 0.53 - ETA: 3:39 - loss: 1.8629 - accuracy: 0.53 - ETA: 3:38 - loss: 1.8623 - accuracy: 0.53 - ETA: 3:36 - loss: 1.8590 - accuracy: 0.53 - ETA: 3:34 - loss: 1.8588 - accuracy: 0.53 - ETA: 3:32 - loss: 1.8635 - accuracy: 0.53 - ETA: 3:29 - loss: 1.8567 - accuracy: 0.53 - ETA: 3:27 - loss: 1.8554 - accuracy: 0.53 - ETA: 3:25 - loss: 1.8631 - accuracy: 0.53 - ETA: 3:23 - loss: 1.8648 - accuracy: 0.53 - ETA: 3:21 - loss: 1.8680 - accuracy: 0.53 - ETA: 3:19 - loss: 1.8682 - accuracy: 0.53 - ETA: 3:17 - loss: 1.8662 - accuracy: 0.53 - ETA: 3:15 - loss: 1.8614 - accuracy: 0.53 - ETA: 3:13 - loss: 1.8629 - accuracy: 0.53 - ETA: 3:11 - loss: 1.8578 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8561 - accuracy: 0.53 - ETA: 3:07 - loss: 1.8566 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8565 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8543 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8581 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8595 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8580 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8597 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8652 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8689 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8686 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8690 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8658 - accuracy: 0.53 - ETA: 2:41 - loss: 1.8639 - accuracy: 0.53 - ETA: 2:39 - loss: 1.8605 - accuracy: 0.53 - ETA: 2:37 - loss: 1.8646 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8656 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8648 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8637 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8618 - accuracy: 0.53 - ETA: 2:26 - loss: 1.8619 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8629 - accuracy: 0.53 - ETA: 2:22 - loss: 1.8624 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8656 - accuracy: 0.53 - ETA: 2:18 - loss: 1.8667 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8729 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8772 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8742 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8808 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8795 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8769 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8782 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8802 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8804 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8776 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8752 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8740 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8711 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8704 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8707 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8709 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8711 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8707 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8711 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8710 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8681 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8676 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8631 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8646 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8648 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8699 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8702 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8667 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8670 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8657 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8652 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8639 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8639 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8629 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8609 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8604 - accuracy: 0.53 - ETA: 1:00 - loss: 1.8619 - accuracy: 0.53 - ETA: 58s - loss: 1.8592 - accuracy: 0.5372 - ETA: 56s - loss: 1.8610 - accuracy: 0.537 - ETA: 54s - loss: 1.8790 - accuracy: 0.537 - ETA: 52s - loss: 1.8783 - accuracy: 0.537 - ETA: 50s - loss: 1.8815 - accuracy: 0.536 - ETA: 48s - loss: 1.8849 - accuracy: 0.536 - ETA: 46s - loss: 1.8847 - accuracy: 0.536 - ETA: 44s - loss: 1.8794 - accuracy: 0.537 - ETA: 42s - loss: 1.8836 - accuracy: 0.537 - ETA: 39s - loss: 1.8814 - accuracy: 0.537 - ETA: 37s - loss: 1.8820 - accuracy: 0.537 - ETA: 35s - loss: 1.8810 - accuracy: 0.537 - ETA: 33s - loss: 1.8816 - accuracy: 0.537 - ETA: 31s - loss: 1.8811 - accuracy: 0.537 - ETA: 29s - loss: 1.8805 - accuracy: 0.536 - ETA: 27s - loss: 1.8828 - accuracy: 0.536 - ETA: 25s - loss: 1.8810 - accuracy: 0.536 - ETA: 23s - loss: 1.8817 - accuracy: 0.536 - ETA: 20s - loss: 1.8845 - accuracy: 0.535 - ETA: 18s - loss: 1.8822 - accuracy: 0.536 - ETA: 16s - loss: 1.8862 - accuracy: 0.535 - ETA: 14s - loss: 1.8872 - accuracy: 0.535 - ETA: 12s - loss: 1.8844 - accuracy: 0.535 - ETA: 10s - loss: 1.8831 - accuracy: 0.535 - ETA: 8s - loss: 1.8842 - accuracy: 0.535 - ETA: 6s - loss: 1.8827 - accuracy: 0.53 - ETA: 3s - loss: 1.8830 - accuracy: 0.53 - ETA: 1s - loss: 1.8809 - accuracy: 0.53 - 345s 18ms/step - loss: 1.8791 - accuracy: 0.5359 - val_loss: 1.7119 - val_accuracy: 0.5935\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:24 - loss: 1.5971 - accuracy: 0.57 - ETA: 5:14 - loss: 1.6247 - accuracy: 0.58 - ETA: 5:07 - loss: 1.7172 - accuracy: 0.57 - ETA: 5:08 - loss: 1.7032 - accuracy: 0.56 - ETA: 5:04 - loss: 1.7171 - accuracy: 0.55 - ETA: 5:00 - loss: 1.6826 - accuracy: 0.56 - ETA: 4:59 - loss: 1.7052 - accuracy: 0.56 - ETA: 4:59 - loss: 1.6781 - accuracy: 0.57 - ETA: 4:58 - loss: 1.6483 - accuracy: 0.57 - ETA: 4:57 - loss: 1.6732 - accuracy: 0.56 - ETA: 4:54 - loss: 1.6699 - accuracy: 0.56 - ETA: 4:52 - loss: 1.7078 - accuracy: 0.56 - ETA: 4:49 - loss: 1.6978 - accuracy: 0.55 - ETA: 4:47 - loss: 1.6952 - accuracy: 0.56 - ETA: 4:46 - loss: 1.6778 - accuracy: 0.56 - ETA: 4:44 - loss: 1.6589 - accuracy: 0.56 - ETA: 4:41 - loss: 1.6645 - accuracy: 0.56 - ETA: 4:40 - loss: 1.6573 - accuracy: 0.56 - ETA: 4:38 - loss: 1.6592 - accuracy: 0.56 - ETA: 4:36 - loss: 1.6833 - accuracy: 0.56 - ETA: 4:34 - loss: 1.7047 - accuracy: 0.56 - ETA: 4:32 - loss: 1.7156 - accuracy: 0.55 - ETA: 4:29 - loss: 1.7196 - accuracy: 0.55 - ETA: 4:27 - loss: 1.7260 - accuracy: 0.54 - ETA: 4:25 - loss: 1.7172 - accuracy: 0.55 - ETA: 4:23 - loss: 1.7197 - accuracy: 0.55 - ETA: 4:21 - loss: 1.7229 - accuracy: 0.55 - ETA: 4:19 - loss: 1.7249 - accuracy: 0.55 - ETA: 4:17 - loss: 1.7201 - accuracy: 0.55 - ETA: 4:15 - loss: 1.7143 - accuracy: 0.55 - ETA: 4:13 - loss: 1.7112 - accuracy: 0.55 - ETA: 4:10 - loss: 1.7224 - accuracy: 0.55 - ETA: 4:08 - loss: 1.7323 - accuracy: 0.54 - ETA: 4:06 - loss: 1.7526 - accuracy: 0.54 - ETA: 4:04 - loss: 1.7521 - accuracy: 0.54 - ETA: 4:02 - loss: 1.7489 - accuracy: 0.54 - ETA: 3:59 - loss: 1.7526 - accuracy: 0.54 - ETA: 3:57 - loss: 1.7512 - accuracy: 0.54 - ETA: 3:55 - loss: 1.7549 - accuracy: 0.54 - ETA: 3:53 - loss: 1.7669 - accuracy: 0.54 - ETA: 3:51 - loss: 1.7620 - accuracy: 0.54 - ETA: 3:48 - loss: 1.7628 - accuracy: 0.54 - ETA: 3:46 - loss: 1.7572 - accuracy: 0.54 - ETA: 3:44 - loss: 1.7575 - accuracy: 0.54 - ETA: 3:42 - loss: 1.7542 - accuracy: 0.54 - ETA: 3:40 - loss: 1.7607 - accuracy: 0.54 - ETA: 3:38 - loss: 1.7574 - accuracy: 0.54 - ETA: 3:36 - loss: 1.7605 - accuracy: 0.54 - ETA: 3:34 - loss: 1.7647 - accuracy: 0.54 - ETA: 3:32 - loss: 1.7650 - accuracy: 0.54 - ETA: 3:30 - loss: 1.7669 - accuracy: 0.54 - ETA: 3:28 - loss: 1.7705 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7703 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7754 - accuracy: 0.54 - ETA: 3:22 - loss: 1.7720 - accuracy: 0.54 - ETA: 3:20 - loss: 1.7784 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7841 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7848 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7772 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7775 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7801 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7859 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7783 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7887 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7914 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7944 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7937 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7904 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7936 - accuracy: 0.54 - ETA: 2:50 - loss: 1.8008 - accuracy: 0.54 - ETA: 2:48 - loss: 1.8009 - accuracy: 0.54 - ETA: 2:46 - loss: 1.8045 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8105 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8154 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8092 - accuracy: 0.54 - ETA: 2:37 - loss: 1.8069 - accuracy: 0.54 - ETA: 2:35 - loss: 1.8069 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8098 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8107 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8167 - accuracy: 0.53 - ETA: 2:27 - loss: 1.8157 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8127 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8150 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8138 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8177 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8174 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8253 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8234 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8229 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8209 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8202 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8246 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8208 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8206 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8202 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8208 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8163 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8166 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8177 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8184 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8177 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8176 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8194 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8164 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8156 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8159 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8212 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8217 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8206 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8217 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8256 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8259 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8220 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8193 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8247 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8234 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8228 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8233 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8201 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8188 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8158 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8197 - accuracy: 0.53 - ETA: 59s - loss: 1.8177 - accuracy: 0.5383 - ETA: 56s - loss: 1.8182 - accuracy: 0.538 - ETA: 54s - loss: 1.8159 - accuracy: 0.539 - ETA: 52s - loss: 1.8132 - accuracy: 0.539 - ETA: 50s - loss: 1.8213 - accuracy: 0.538 - ETA: 48s - loss: 1.8252 - accuracy: 0.539 - ETA: 46s - loss: 1.8298 - accuracy: 0.538 - ETA: 44s - loss: 1.8288 - accuracy: 0.539 - ETA: 42s - loss: 1.8313 - accuracy: 0.538 - ETA: 39s - loss: 1.8333 - accuracy: 0.538 - ETA: 37s - loss: 1.8360 - accuracy: 0.538 - ETA: 35s - loss: 1.8357 - accuracy: 0.538 - ETA: 33s - loss: 1.8346 - accuracy: 0.538 - ETA: 31s - loss: 1.8361 - accuracy: 0.538 - ETA: 29s - loss: 1.8383 - accuracy: 0.537 - ETA: 27s - loss: 1.8419 - accuracy: 0.537 - ETA: 25s - loss: 1.8399 - accuracy: 0.537 - ETA: 23s - loss: 1.8427 - accuracy: 0.537 - ETA: 20s - loss: 1.8423 - accuracy: 0.537 - ETA: 18s - loss: 1.8412 - accuracy: 0.537 - ETA: 16s - loss: 1.8404 - accuracy: 0.538 - ETA: 14s - loss: 1.8386 - accuracy: 0.538 - ETA: 12s - loss: 1.8402 - accuracy: 0.537 - ETA: 10s - loss: 1.8420 - accuracy: 0.537 - ETA: 8s - loss: 1.8397 - accuracy: 0.537 - ETA: 6s - loss: 1.8388 - accuracy: 0.53 - ETA: 3s - loss: 1.8402 - accuracy: 0.53 - ETA: 1s - loss: 1.8420 - accuracy: 0.53 - 344s 18ms/step - loss: 1.8493 - accuracy: 0.5371 - val_loss: 1.7886 - val_accuracy: 0.5954\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:37 - loss: 1.5312 - accuracy: 0.56 - ETA: 5:24 - loss: 1.6957 - accuracy: 0.54 - ETA: 5:19 - loss: 1.6848 - accuracy: 0.54 - ETA: 5:17 - loss: 1.6117 - accuracy: 0.55 - ETA: 5:13 - loss: 1.7454 - accuracy: 0.53 - ETA: 5:08 - loss: 1.8122 - accuracy: 0.53 - ETA: 5:05 - loss: 1.8620 - accuracy: 0.53 - ETA: 5:01 - loss: 1.8553 - accuracy: 0.53 - ETA: 5:01 - loss: 1.8610 - accuracy: 0.52 - ETA: 4:58 - loss: 1.8961 - accuracy: 0.52 - ETA: 4:56 - loss: 1.8765 - accuracy: 0.52 - ETA: 4:53 - loss: 1.8796 - accuracy: 0.52 - ETA: 4:51 - loss: 1.8547 - accuracy: 0.53 - ETA: 4:48 - loss: 1.8288 - accuracy: 0.53 - ETA: 4:45 - loss: 1.8237 - accuracy: 0.53 - ETA: 4:44 - loss: 1.8165 - accuracy: 0.53 - ETA: 4:41 - loss: 1.8216 - accuracy: 0.53 - ETA: 4:40 - loss: 1.8019 - accuracy: 0.53 - ETA: 4:38 - loss: 1.7917 - accuracy: 0.53 - ETA: 4:36 - loss: 1.7984 - accuracy: 0.53 - ETA: 4:34 - loss: 1.7943 - accuracy: 0.53 - ETA: 4:31 - loss: 1.7799 - accuracy: 0.53 - ETA: 4:29 - loss: 1.7629 - accuracy: 0.53 - ETA: 4:27 - loss: 1.7734 - accuracy: 0.53 - ETA: 4:25 - loss: 1.7677 - accuracy: 0.53 - ETA: 4:22 - loss: 1.7613 - accuracy: 0.54 - ETA: 4:21 - loss: 1.7695 - accuracy: 0.54 - ETA: 4:19 - loss: 1.7709 - accuracy: 0.54 - ETA: 4:17 - loss: 1.7771 - accuracy: 0.54 - ETA: 4:15 - loss: 1.7856 - accuracy: 0.54 - ETA: 4:13 - loss: 1.7852 - accuracy: 0.54 - ETA: 4:11 - loss: 1.7917 - accuracy: 0.54 - ETA: 4:09 - loss: 1.7891 - accuracy: 0.54 - ETA: 4:06 - loss: 1.7866 - accuracy: 0.54 - ETA: 4:05 - loss: 1.7910 - accuracy: 0.54 - ETA: 4:02 - loss: 1.7898 - accuracy: 0.54 - ETA: 4:00 - loss: 1.7954 - accuracy: 0.53 - ETA: 3:58 - loss: 1.7919 - accuracy: 0.53 - ETA: 3:56 - loss: 1.8047 - accuracy: 0.53 - ETA: 3:53 - loss: 1.8069 - accuracy: 0.53 - ETA: 3:51 - loss: 1.8096 - accuracy: 0.53 - ETA: 3:50 - loss: 1.8128 - accuracy: 0.53 - ETA: 3:47 - loss: 1.8109 - accuracy: 0.53 - ETA: 3:45 - loss: 1.8226 - accuracy: 0.53 - ETA: 3:43 - loss: 1.8320 - accuracy: 0.53 - ETA: 3:41 - loss: 1.8275 - accuracy: 0.53 - ETA: 3:39 - loss: 1.8240 - accuracy: 0.53 - ETA: 3:37 - loss: 1.8579 - accuracy: 0.53 - ETA: 3:34 - loss: 1.8558 - accuracy: 0.53 - ETA: 3:33 - loss: 1.8553 - accuracy: 0.53 - ETA: 3:30 - loss: 1.8585 - accuracy: 0.53 - ETA: 3:28 - loss: 1.8553 - accuracy: 0.53 - ETA: 3:26 - loss: 1.8606 - accuracy: 0.53 - ETA: 3:24 - loss: 1.8590 - accuracy: 0.53 - ETA: 3:22 - loss: 1.8510 - accuracy: 0.53 - ETA: 3:20 - loss: 1.8514 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8442 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8409 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8415 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8342 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8310 - accuracy: 0.53 - ETA: 3:07 - loss: 1.8245 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8159 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8193 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8230 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8196 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8309 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8284 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8249 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8245 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8269 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8202 - accuracy: 0.54 - ETA: 2:44 - loss: 1.8217 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8272 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8290 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8300 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8295 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8362 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8363 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8358 - accuracy: 0.53 - ETA: 2:27 - loss: 1.8401 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8511 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8571 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8688 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8703 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8709 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8688 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8686 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8700 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8713 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8816 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8818 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8824 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8836 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8840 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8818 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8884 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8872 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8870 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8867 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8875 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8904 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8894 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8877 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8860 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8850 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8838 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8844 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8851 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8849 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8857 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8845 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8844 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8880 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8880 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8871 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8860 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8864 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8884 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8919 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8916 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8913 - accuracy: 0.53 - ETA: 59s - loss: 1.8898 - accuracy: 0.5336 - ETA: 56s - loss: 1.8867 - accuracy: 0.533 - ETA: 54s - loss: 1.8874 - accuracy: 0.533 - ETA: 52s - loss: 1.8905 - accuracy: 0.533 - ETA: 50s - loss: 1.8880 - accuracy: 0.533 - ETA: 48s - loss: 1.8898 - accuracy: 0.533 - ETA: 46s - loss: 1.8907 - accuracy: 0.532 - ETA: 44s - loss: 1.8891 - accuracy: 0.533 - ETA: 42s - loss: 1.8880 - accuracy: 0.533 - ETA: 39s - loss: 1.8860 - accuracy: 0.533 - ETA: 37s - loss: 1.8871 - accuracy: 0.533 - ETA: 35s - loss: 1.8889 - accuracy: 0.533 - ETA: 33s - loss: 1.8907 - accuracy: 0.532 - ETA: 31s - loss: 1.8913 - accuracy: 0.532 - ETA: 29s - loss: 1.8910 - accuracy: 0.532 - ETA: 27s - loss: 1.8900 - accuracy: 0.532 - ETA: 25s - loss: 1.8917 - accuracy: 0.531 - ETA: 23s - loss: 1.8883 - accuracy: 0.532 - ETA: 20s - loss: 1.8883 - accuracy: 0.532 - ETA: 18s - loss: 1.8886 - accuracy: 0.532 - ETA: 16s - loss: 1.8887 - accuracy: 0.532 - ETA: 14s - loss: 1.8899 - accuracy: 0.532 - ETA: 12s - loss: 1.8892 - accuracy: 0.532 - ETA: 10s - loss: 1.8909 - accuracy: 0.531 - ETA: 8s - loss: 1.8886 - accuracy: 0.532 - ETA: 6s - loss: 1.8860 - accuracy: 0.53 - ETA: 3s - loss: 1.8883 - accuracy: 0.53 - ETA: 1s - loss: 1.8900 - accuracy: 0.53 - 345s 18ms/step - loss: 1.8911 - accuracy: 0.5319 - val_loss: 1.7863 - val_accuracy: 0.5817\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:34 - loss: 2.0072 - accuracy: 0.48 - ETA: 5:13 - loss: 1.9355 - accuracy: 0.50 - ETA: 5:14 - loss: 2.6900 - accuracy: 0.50 - ETA: 5:15 - loss: 2.4708 - accuracy: 0.51 - ETA: 5:09 - loss: 2.3652 - accuracy: 0.52 - ETA: 5:08 - loss: 2.2014 - accuracy: 0.53 - ETA: 5:05 - loss: 2.1666 - accuracy: 0.54 - ETA: 5:03 - loss: 2.1608 - accuracy: 0.53 - ETA: 5:01 - loss: 2.1562 - accuracy: 0.53 - ETA: 4:59 - loss: 2.2080 - accuracy: 0.53 - ETA: 4:56 - loss: 2.2130 - accuracy: 0.53 - ETA: 4:53 - loss: 2.1766 - accuracy: 0.53 - ETA: 4:52 - loss: 2.1506 - accuracy: 0.53 - ETA: 4:49 - loss: 2.1020 - accuracy: 0.53 - ETA: 4:47 - loss: 2.0710 - accuracy: 0.53 - ETA: 4:45 - loss: 2.0569 - accuracy: 0.53 - ETA: 4:43 - loss: 2.0542 - accuracy: 0.53 - ETA: 4:41 - loss: 2.0447 - accuracy: 0.53 - ETA: 4:39 - loss: 2.0498 - accuracy: 0.53 - ETA: 4:38 - loss: 2.0391 - accuracy: 0.52 - ETA: 4:36 - loss: 2.0335 - accuracy: 0.53 - ETA: 4:33 - loss: 2.0215 - accuracy: 0.53 - ETA: 4:31 - loss: 2.0215 - accuracy: 0.52 - ETA: 4:29 - loss: 2.0292 - accuracy: 0.52 - ETA: 4:26 - loss: 2.0215 - accuracy: 0.52 - ETA: 4:25 - loss: 1.9995 - accuracy: 0.52 - ETA: 4:22 - loss: 1.9926 - accuracy: 0.52 - ETA: 4:20 - loss: 1.9937 - accuracy: 0.52 - ETA: 4:18 - loss: 2.0154 - accuracy: 0.52 - ETA: 4:16 - loss: 2.0126 - accuracy: 0.52 - ETA: 4:14 - loss: 2.0264 - accuracy: 0.52 - ETA: 4:12 - loss: 2.0335 - accuracy: 0.52 - ETA: 4:08 - loss: 2.0233 - accuracy: 0.52 - ETA: 4:05 - loss: 2.0045 - accuracy: 0.52 - ETA: 4:03 - loss: 1.9982 - accuracy: 0.52 - ETA: 4:01 - loss: 1.9951 - accuracy: 0.52 - ETA: 4:00 - loss: 1.9942 - accuracy: 0.52 - ETA: 3:58 - loss: 1.9833 - accuracy: 0.52 - ETA: 3:56 - loss: 1.9777 - accuracy: 0.52 - ETA: 3:54 - loss: 1.9634 - accuracy: 0.53 - ETA: 3:52 - loss: 1.9637 - accuracy: 0.53 - ETA: 3:50 - loss: 1.9644 - accuracy: 0.52 - ETA: 3:49 - loss: 1.9532 - accuracy: 0.53 - ETA: 3:46 - loss: 1.9519 - accuracy: 0.53 - ETA: 3:45 - loss: 1.9436 - accuracy: 0.52 - ETA: 3:43 - loss: 1.9341 - accuracy: 0.53 - ETA: 3:41 - loss: 1.9285 - accuracy: 0.53 - ETA: 3:38 - loss: 1.9278 - accuracy: 0.53 - ETA: 3:36 - loss: 1.9230 - accuracy: 0.53 - ETA: 3:34 - loss: 1.9158 - accuracy: 0.53 - ETA: 3:32 - loss: 1.9108 - accuracy: 0.53 - ETA: 3:30 - loss: 1.9153 - accuracy: 0.53 - ETA: 3:28 - loss: 1.9140 - accuracy: 0.53 - ETA: 3:26 - loss: 1.9130 - accuracy: 0.53 - ETA: 3:24 - loss: 1.9086 - accuracy: 0.53 - ETA: 3:21 - loss: 1.9048 - accuracy: 0.53 - ETA: 3:19 - loss: 1.9053 - accuracy: 0.53 - ETA: 3:17 - loss: 1.8996 - accuracy: 0.53 - ETA: 3:15 - loss: 1.8963 - accuracy: 0.53 - ETA: 3:13 - loss: 1.8884 - accuracy: 0.53 - ETA: 3:11 - loss: 1.8868 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8860 - accuracy: 0.53 - ETA: 3:07 - loss: 1.8838 - accuracy: 0.53 - ETA: 3:05 - loss: 1.8826 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8819 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8817 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8868 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8886 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8828 - accuracy: 0.53 - ETA: 2:52 - loss: 1.8940 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8974 - accuracy: 0.53 - ETA: 2:47 - loss: 1.9041 - accuracy: 0.53 - ETA: 2:45 - loss: 1.9051 - accuracy: 0.53 - ETA: 2:43 - loss: 1.9095 - accuracy: 0.53 - ETA: 2:41 - loss: 1.9187 - accuracy: 0.52 - ETA: 2:39 - loss: 1.9260 - accuracy: 0.53 - ETA: 2:37 - loss: 1.9237 - accuracy: 0.53 - ETA: 2:35 - loss: 1.9183 - accuracy: 0.53 - ETA: 2:32 - loss: 1.9194 - accuracy: 0.53 - ETA: 1:19:20 - loss: 1.9200 - accuracy: 0.532 - ETA: 1:17:16 - loss: 1.9198 - accuracy: 0.532 - ETA: 1:15:17 - loss: 1.9210 - accuracy: 0.533 - ETA: 1:13:19 - loss: 1.9234 - accuracy: 0.533 - ETA: 1:11:24 - loss: 1.9178 - accuracy: 0.533 - ETA: 1:09:32 - loss: 1.9146 - accuracy: 0.533 - ETA: 1:07:42 - loss: 1.9190 - accuracy: 0.532 - ETA: 1:05:54 - loss: 1.9253 - accuracy: 0.532 - ETA: 1:04:09 - loss: 1.9241 - accuracy: 0.532 - ETA: 1:02:26 - loss: 1.9235 - accuracy: 0.532 - ETA: 1:00:46 - loss: 1.9222 - accuracy: 0.531 - ETA: 59:08 - loss: 1.9218 - accuracy: 0.5311  - ETA: 57:32 - loss: 1.9242 - accuracy: 0.531 - ETA: 55:57 - loss: 1.9240 - accuracy: 0.531 - ETA: 54:25 - loss: 1.9261 - accuracy: 0.531 - ETA: 52:55 - loss: 1.9280 - accuracy: 0.530 - ETA: 51:27 - loss: 1.9308 - accuracy: 0.530 - ETA: 50:00 - loss: 1.9253 - accuracy: 0.531 - ETA: 48:35 - loss: 1.9261 - accuracy: 0.531 - ETA: 47:12 - loss: 1.9266 - accuracy: 0.531 - ETA: 45:50 - loss: 1.9245 - accuracy: 0.531 - ETA: 44:30 - loss: 1.9260 - accuracy: 0.530 - ETA: 43:12 - loss: 1.9211 - accuracy: 0.531 - ETA: 41:55 - loss: 1.9213 - accuracy: 0.531 - ETA: 40:39 - loss: 1.9179 - accuracy: 0.532 - ETA: 39:25 - loss: 1.9236 - accuracy: 0.532 - ETA: 38:12 - loss: 1.9229 - accuracy: 0.532 - ETA: 37:01 - loss: 1.9225 - accuracy: 0.532 - ETA: 35:51 - loss: 1.9255 - accuracy: 0.532 - ETA: 34:42 - loss: 1.9234 - accuracy: 0.533 - ETA: 33:34 - loss: 1.9237 - accuracy: 0.533 - ETA: 32:28 - loss: 1.9246 - accuracy: 0.533 - ETA: 31:23 - loss: 1.9254 - accuracy: 0.533 - ETA: 30:19 - loss: 1.9249 - accuracy: 0.532 - ETA: 29:15 - loss: 1.9240 - accuracy: 0.533 - ETA: 28:13 - loss: 1.9239 - accuracy: 0.532 - ETA: 27:12 - loss: 1.9234 - accuracy: 0.533 - ETA: 26:13 - loss: 1.9210 - accuracy: 0.533 - ETA: 25:14 - loss: 1.9230 - accuracy: 0.533 - ETA: 24:16 - loss: 1.9223 - accuracy: 0.533 - ETA: 23:19 - loss: 1.9183 - accuracy: 0.533 - ETA: 22:22 - loss: 1.9175 - accuracy: 0.534 - ETA: 21:27 - loss: 1.9155 - accuracy: 0.534 - ETA: 20:33 - loss: 1.9152 - accuracy: 0.533 - ETA: 19:39 - loss: 1.9136 - accuracy: 0.533 - ETA: 18:47 - loss: 1.9157 - accuracy: 0.533 - ETA: 17:55 - loss: 1.9138 - accuracy: 0.533 - ETA: 17:04 - loss: 1.9121 - accuracy: 0.533 - ETA: 16:13 - loss: 1.9108 - accuracy: 0.533 - ETA: 15:24 - loss: 1.9110 - accuracy: 0.533 - ETA: 14:35 - loss: 1.9096 - accuracy: 0.534 - ETA: 13:47 - loss: 1.9078 - accuracy: 0.534 - ETA: 13:00 - loss: 1.9071 - accuracy: 0.534 - ETA: 12:13 - loss: 1.9070 - accuracy: 0.534 - ETA: 11:27 - loss: 1.9044 - accuracy: 0.534 - ETA: 10:42 - loss: 1.9035 - accuracy: 0.534 - ETA: 9:57 - loss: 1.9012 - accuracy: 0.534 - ETA: 9:13 - loss: 1.9041 - accuracy: 0.53 - ETA: 8:29 - loss: 1.9045 - accuracy: 0.53 - ETA: 7:47 - loss: 1.9085 - accuracy: 0.53 - ETA: 7:04 - loss: 1.9099 - accuracy: 0.53 - ETA: 6:23 - loss: 1.9081 - accuracy: 0.53 - ETA: 5:41 - loss: 1.9061 - accuracy: 0.53 - ETA: 5:01 - loss: 1.9077 - accuracy: 0.53 - ETA: 4:21 - loss: 1.9070 - accuracy: 0.53 - ETA: 3:41 - loss: 1.9055 - accuracy: 0.53 - ETA: 3:02 - loss: 1.9064 - accuracy: 0.53 - ETA: 2:24 - loss: 1.9071 - accuracy: 0.53 - ETA: 1:46 - loss: 1.9032 - accuracy: 0.53 - ETA: 1:08 - loss: 1.9037 - accuracy: 0.53 - ETA: 31s - loss: 1.9023 - accuracy: 0.5333 - 5506s 285ms/step - loss: 1.9044 - accuracy: 0.5330 - val_loss: 1.7751 - val_accuracy: 0.5854\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:59 - loss: 1.9939 - accuracy: 0.53 - ETA: 3:44 - loss: 1.7379 - accuracy: 0.55 - ETA: 3:39 - loss: 1.6352 - accuracy: 0.56 - ETA: 3:34 - loss: 1.7925 - accuracy: 0.55 - ETA: 3:33 - loss: 1.9457 - accuracy: 0.55 - ETA: 3:37 - loss: 1.8997 - accuracy: 0.55 - ETA: 3:38 - loss: 1.8419 - accuracy: 0.55 - ETA: 3:38 - loss: 1.8628 - accuracy: 0.54 - ETA: 3:42 - loss: 1.8848 - accuracy: 0.55 - ETA: 3:44 - loss: 1.8748 - accuracy: 0.54 - ETA: 3:42 - loss: 1.8443 - accuracy: 0.55 - ETA: 3:41 - loss: 1.8368 - accuracy: 0.55 - ETA: 3:40 - loss: 1.8334 - accuracy: 0.54 - ETA: 3:38 - loss: 1.8248 - accuracy: 0.54 - ETA: 3:34 - loss: 1.8573 - accuracy: 0.54 - ETA: 3:31 - loss: 1.8359 - accuracy: 0.54 - ETA: 3:30 - loss: 1.8470 - accuracy: 0.54 - ETA: 3:28 - loss: 1.8398 - accuracy: 0.55 - ETA: 3:26 - loss: 1.8641 - accuracy: 0.54 - ETA: 3:23 - loss: 1.8669 - accuracy: 0.53 - ETA: 3:21 - loss: 1.8627 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8589 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8518 - accuracy: 0.53 - ETA: 3:13 - loss: 1.8539 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8517 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8399 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8459 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8488 - accuracy: 0.53 - ETA: 3:05 - loss: 1.8340 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8293 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8228 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8337 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8274 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8161 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8134 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8221 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8356 - accuracy: 0.53 - ETA: 2:52 - loss: 1.8233 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8225 - accuracy: 0.53 - ETA: 2:50 - loss: 1.8302 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8247 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8289 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8262 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8309 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8294 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8377 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8285 - accuracy: 0.53 - ETA: 2:37 - loss: 1.8268 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8281 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8283 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8255 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8284 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8336 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8285 - accuracy: 0.53 - ETA: 2:27 - loss: 1.8260 - accuracy: 0.53 - ETA: 2:26 - loss: 1.8208 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8290 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8382 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8328 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8466 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8441 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8463 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8387 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8368 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8369 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8477 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8477 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8473 - accuracy: 0.53 - ETA: 2:18 - loss: 1.8448 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8449 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8455 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8424 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8406 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8410 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8524 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8510 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8508 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8511 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8544 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8546 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8562 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8528 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8613 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8650 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8624 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8638 - accuracy: 0.53 - ETA: 1:46 - loss: 1.8641 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8708 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8695 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8683 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8726 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8733 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8709 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8676 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8678 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8656 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8638 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8632 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8656 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8619 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8611 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8602 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8629 - accuracy: 0.53 - ETA: 1:21 - loss: 1.8646 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8650 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8634 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8653 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8644 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8612 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8636 - accuracy: 0.53 - ETA: 1:10 - loss: 1.8615 - accuracy: 0.53 - ETA: 1:08 - loss: 1.8591 - accuracy: 0.53 - ETA: 1:06 - loss: 1.8610 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8593 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8612 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8626 - accuracy: 0.53 - ETA: 1:00 - loss: 1.8607 - accuracy: 0.53 - ETA: 58s - loss: 1.8580 - accuracy: 0.5354 - ETA: 57s - loss: 1.8608 - accuracy: 0.534 - ETA: 55s - loss: 1.8616 - accuracy: 0.534 - ETA: 53s - loss: 1.8600 - accuracy: 0.533 - ETA: 51s - loss: 1.8602 - accuracy: 0.533 - ETA: 50s - loss: 1.8569 - accuracy: 0.534 - ETA: 48s - loss: 1.8576 - accuracy: 0.534 - ETA: 46s - loss: 1.8559 - accuracy: 0.534 - ETA: 45s - loss: 1.8558 - accuracy: 0.534 - ETA: 43s - loss: 1.8567 - accuracy: 0.533 - ETA: 41s - loss: 1.8585 - accuracy: 0.534 - ETA: 39s - loss: 1.8577 - accuracy: 0.534 - ETA: 38s - loss: 1.8579 - accuracy: 0.534 - ETA: 36s - loss: 1.8573 - accuracy: 0.534 - ETA: 34s - loss: 1.8558 - accuracy: 0.534 - ETA: 32s - loss: 1.8560 - accuracy: 0.534 - ETA: 31s - loss: 1.8584 - accuracy: 0.534 - ETA: 29s - loss: 1.8560 - accuracy: 0.534 - ETA: 27s - loss: 1.8562 - accuracy: 0.534 - ETA: 25s - loss: 1.8570 - accuracy: 0.533 - ETA: 23s - loss: 1.8599 - accuracy: 0.533 - ETA: 22s - loss: 1.8574 - accuracy: 0.534 - ETA: 20s - loss: 1.8578 - accuracy: 0.533 - ETA: 18s - loss: 1.8571 - accuracy: 0.534 - ETA: 16s - loss: 1.8567 - accuracy: 0.534 - ETA: 14s - loss: 1.8558 - accuracy: 0.533 - ETA: 12s - loss: 1.8548 - accuracy: 0.534 - ETA: 11s - loss: 1.8580 - accuracy: 0.533 - ETA: 9s - loss: 1.8580 - accuracy: 0.533 - ETA: 7s - loss: 1.8560 - accuracy: 0.53 - ETA: 5s - loss: 1.8550 - accuracy: 0.53 - ETA: 3s - loss: 1.8560 - accuracy: 0.53 - ETA: 1s - loss: 1.8564 - accuracy: 0.53 - 318s 16ms/step - loss: 1.8548 - accuracy: 0.5330 - val_loss: 1.7768 - val_accuracy: 0.5906\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:57 - loss: 2.4753 - accuracy: 0.57 - ETA: 5:19 - loss: 2.0944 - accuracy: 0.56 - ETA: 5:10 - loss: 1.9464 - accuracy: 0.54 - ETA: 5:10 - loss: 2.0896 - accuracy: 0.53 - ETA: 5:04 - loss: 2.0522 - accuracy: 0.53 - ETA: 4:54 - loss: 1.9968 - accuracy: 0.52 - ETA: 5:06 - loss: 1.9827 - accuracy: 0.53 - ETA: 5:03 - loss: 1.9520 - accuracy: 0.53 - ETA: 4:59 - loss: 2.0365 - accuracy: 0.53 - ETA: 4:55 - loss: 2.0551 - accuracy: 0.53 - ETA: 4:50 - loss: 1.9988 - accuracy: 0.53 - ETA: 4:50 - loss: 1.9721 - accuracy: 0.54 - ETA: 4:48 - loss: 1.9301 - accuracy: 0.54 - ETA: 4:44 - loss: 1.9043 - accuracy: 0.54 - ETA: 4:41 - loss: 1.9064 - accuracy: 0.54 - ETA: 4:42 - loss: 1.8923 - accuracy: 0.54 - ETA: 4:40 - loss: 1.8789 - accuracy: 0.54 - ETA: 4:37 - loss: 1.8579 - accuracy: 0.54 - ETA: 4:33 - loss: 1.8433 - accuracy: 0.54 - ETA: 4:30 - loss: 1.8606 - accuracy: 0.54 - ETA: 4:27 - loss: 1.8610 - accuracy: 0.53 - ETA: 4:24 - loss: 1.8417 - accuracy: 0.53 - ETA: 4:23 - loss: 1.8392 - accuracy: 0.53 - ETA: 4:20 - loss: 1.8339 - accuracy: 0.53 - ETA: 4:17 - loss: 1.8412 - accuracy: 0.53 - ETA: 4:15 - loss: 1.8386 - accuracy: 0.53 - ETA: 4:13 - loss: 1.8360 - accuracy: 0.53 - ETA: 4:12 - loss: 1.8264 - accuracy: 0.53 - ETA: 4:10 - loss: 1.8201 - accuracy: 0.53 - ETA: 4:07 - loss: 1.8199 - accuracy: 0.53 - ETA: 4:05 - loss: 1.8264 - accuracy: 0.53 - ETA: 4:03 - loss: 1.8202 - accuracy: 0.53 - ETA: 4:00 - loss: 1.8281 - accuracy: 0.53 - ETA: 3:58 - loss: 1.8300 - accuracy: 0.53 - ETA: 3:56 - loss: 1.8347 - accuracy: 0.53 - ETA: 3:54 - loss: 1.8325 - accuracy: 0.53 - ETA: 3:52 - loss: 1.8344 - accuracy: 0.53 - ETA: 3:51 - loss: 1.8285 - accuracy: 0.53 - ETA: 3:49 - loss: 1.8335 - accuracy: 0.53 - ETA: 3:47 - loss: 1.8273 - accuracy: 0.53 - ETA: 3:44 - loss: 1.8255 - accuracy: 0.53 - ETA: 3:43 - loss: 1.8272 - accuracy: 0.53 - ETA: 3:43 - loss: 1.8224 - accuracy: 0.53 - ETA: 3:40 - loss: 1.8234 - accuracy: 0.53 - ETA: 3:38 - loss: 1.8224 - accuracy: 0.53 - ETA: 3:35 - loss: 1.8233 - accuracy: 0.53 - ETA: 3:33 - loss: 1.8388 - accuracy: 0.53 - ETA: 3:31 - loss: 1.8383 - accuracy: 0.53 - ETA: 3:29 - loss: 1.8321 - accuracy: 0.53 - ETA: 3:27 - loss: 1.8371 - accuracy: 0.53 - ETA: 3:25 - loss: 1.8312 - accuracy: 0.53 - ETA: 3:22 - loss: 1.8365 - accuracy: 0.53 - ETA: 3:20 - loss: 1.8387 - accuracy: 0.53 - ETA: 3:19 - loss: 1.8396 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8378 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8347 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8350 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8335 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8340 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8331 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8278 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8308 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8330 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8373 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8374 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8368 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8396 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8440 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8471 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8424 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8484 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8497 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8489 - accuracy: 0.53 - ETA: 2:37 - loss: 1.8508 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8513 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8486 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8605 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8772 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8760 - accuracy: 0.53 - ETA: 2:26 - loss: 1.8777 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8799 - accuracy: 0.53 - ETA: 2:22 - loss: 1.8787 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8819 - accuracy: 0.52 - ETA: 2:17 - loss: 1.8803 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8792 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8796 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8823 - accuracy: 0.52 - ETA: 2:09 - loss: 1.8795 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8781 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8798 - accuracy: 0.52 - ETA: 2:03 - loss: 1.8822 - accuracy: 0.52 - ETA: 2:01 - loss: 1.8917 - accuracy: 0.52 - ETA: 1:59 - loss: 1.8902 - accuracy: 0.52 - ETA: 1:57 - loss: 1.8899 - accuracy: 0.52 - ETA: 1:55 - loss: 1.8910 - accuracy: 0.52 - ETA: 1:53 - loss: 1.8896 - accuracy: 0.52 - ETA: 1:51 - loss: 1.8853 - accuracy: 0.52 - ETA: 1:49 - loss: 1.8850 - accuracy: 0.52 - ETA: 1:47 - loss: 1.8852 - accuracy: 0.52 - ETA: 1:45 - loss: 1.8834 - accuracy: 0.52 - ETA: 1:42 - loss: 1.8810 - accuracy: 0.52 - ETA: 1:40 - loss: 1.8771 - accuracy: 0.52 - ETA: 1:38 - loss: 1.8801 - accuracy: 0.52 - ETA: 1:36 - loss: 1.8795 - accuracy: 0.52 - ETA: 1:34 - loss: 1.8772 - accuracy: 0.52 - ETA: 1:32 - loss: 1.8734 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8748 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8766 - accuracy: 0.52 - ETA: 1:26 - loss: 1.8762 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8777 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8798 - accuracy: 0.52 - ETA: 1:20 - loss: 1.8786 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8782 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8757 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8717 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8794 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8825 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8810 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8791 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8772 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8751 - accuracy: 0.53 - ETA: 59s - loss: 1.8909 - accuracy: 0.5317 - ETA: 57s - loss: 1.8895 - accuracy: 0.532 - ETA: 55s - loss: 1.8855 - accuracy: 0.533 - ETA: 53s - loss: 1.8895 - accuracy: 0.533 - ETA: 51s - loss: 1.8889 - accuracy: 0.532 - ETA: 49s - loss: 1.8863 - accuracy: 0.532 - ETA: 47s - loss: 1.8861 - accuracy: 0.532 - ETA: 45s - loss: 1.8843 - accuracy: 0.532 - ETA: 43s - loss: 1.8816 - accuracy: 0.532 - ETA: 41s - loss: 1.8850 - accuracy: 0.532 - ETA: 39s - loss: 1.8832 - accuracy: 0.532 - ETA: 36s - loss: 1.8802 - accuracy: 0.533 - ETA: 34s - loss: 1.8777 - accuracy: 0.533 - ETA: 32s - loss: 1.8806 - accuracy: 0.533 - ETA: 30s - loss: 1.8806 - accuracy: 0.533 - ETA: 28s - loss: 1.8804 - accuracy: 0.533 - ETA: 26s - loss: 1.8805 - accuracy: 0.533 - ETA: 24s - loss: 1.8789 - accuracy: 0.534 - ETA: 22s - loss: 1.8756 - accuracy: 0.534 - ETA: 20s - loss: 1.8730 - accuracy: 0.534 - ETA: 18s - loss: 1.8755 - accuracy: 0.534 - ETA: 16s - loss: 1.8752 - accuracy: 0.534 - ETA: 14s - loss: 1.8804 - accuracy: 0.534 - ETA: 12s - loss: 1.8800 - accuracy: 0.534 - ETA: 10s - loss: 1.8812 - accuracy: 0.534 - ETA: 8s - loss: 1.8823 - accuracy: 0.534 - ETA: 5s - loss: 1.8833 - accuracy: 0.53 - ETA: 3s - loss: 1.8821 - accuracy: 0.53 - ETA: 1s - loss: 1.8834 - accuracy: 0.53 - 344s 18ms/step - loss: 1.8808 - accuracy: 0.5350 - val_loss: 1.8099 - val_accuracy: 0.5885\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:16 - loss: 1.7526 - accuracy: 0.52 - ETA: 4:54 - loss: 1.7002 - accuracy: 0.51 - ETA: 5:05 - loss: 1.6452 - accuracy: 0.51 - ETA: 5:04 - loss: 1.7716 - accuracy: 0.53 - ETA: 4:57 - loss: 1.7721 - accuracy: 0.52 - ETA: 4:56 - loss: 1.7594 - accuracy: 0.52 - ETA: 4:52 - loss: 1.7717 - accuracy: 0.52 - ETA: 4:48 - loss: 1.7607 - accuracy: 0.52 - ETA: 4:47 - loss: 1.7979 - accuracy: 0.52 - ETA: 4:44 - loss: 1.8368 - accuracy: 0.52 - ETA: 4:43 - loss: 1.8269 - accuracy: 0.52 - ETA: 4:40 - loss: 1.8022 - accuracy: 0.52 - ETA: 4:37 - loss: 1.7981 - accuracy: 0.52 - ETA: 4:36 - loss: 1.8040 - accuracy: 0.52 - ETA: 4:32 - loss: 1.8119 - accuracy: 0.52 - ETA: 4:31 - loss: 1.8054 - accuracy: 0.52 - ETA: 4:29 - loss: 1.7972 - accuracy: 0.53 - ETA: 4:28 - loss: 1.8016 - accuracy: 0.52 - ETA: 4:27 - loss: 1.7924 - accuracy: 0.53 - ETA: 4:31 - loss: 1.8057 - accuracy: 0.52 - ETA: 4:30 - loss: 1.8270 - accuracy: 0.53 - ETA: 4:27 - loss: 1.8237 - accuracy: 0.52 - ETA: 4:25 - loss: 1.8305 - accuracy: 0.52 - ETA: 4:22 - loss: 1.8274 - accuracy: 0.52 - ETA: 4:21 - loss: 1.8107 - accuracy: 0.53 - ETA: 4:20 - loss: 1.8037 - accuracy: 0.53 - ETA: 4:17 - loss: 1.8075 - accuracy: 0.53 - ETA: 4:15 - loss: 1.8000 - accuracy: 0.53 - ETA: 4:12 - loss: 1.7930 - accuracy: 0.53 - ETA: 4:10 - loss: 1.7814 - accuracy: 0.53 - ETA: 4:06 - loss: 1.7731 - accuracy: 0.53 - ETA: 4:04 - loss: 1.7831 - accuracy: 0.53 - ETA: 4:01 - loss: 1.7825 - accuracy: 0.53 - ETA: 4:00 - loss: 1.7838 - accuracy: 0.53 - ETA: 3:57 - loss: 1.7763 - accuracy: 0.53 - ETA: 3:54 - loss: 1.7808 - accuracy: 0.53 - ETA: 3:51 - loss: 1.7963 - accuracy: 0.53 - ETA: 3:48 - loss: 1.8119 - accuracy: 0.53 - ETA: 3:46 - loss: 1.8032 - accuracy: 0.53 - ETA: 3:43 - loss: 1.8072 - accuracy: 0.54 - ETA: 3:40 - loss: 1.8114 - accuracy: 0.53 - ETA: 3:38 - loss: 1.8085 - accuracy: 0.54 - ETA: 3:36 - loss: 1.8103 - accuracy: 0.53 - ETA: 3:35 - loss: 1.8111 - accuracy: 0.53 - ETA: 3:33 - loss: 1.8110 - accuracy: 0.53 - ETA: 3:31 - loss: 1.8051 - accuracy: 0.53 - ETA: 3:28 - loss: 1.8045 - accuracy: 0.53 - ETA: 3:26 - loss: 1.8134 - accuracy: 0.53 - ETA: 3:24 - loss: 1.8110 - accuracy: 0.53 - ETA: 3:22 - loss: 1.8013 - accuracy: 0.54 - ETA: 3:20 - loss: 1.8061 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8051 - accuracy: 0.54 - ETA: 3:16 - loss: 1.8060 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8035 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8067 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8077 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8024 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8038 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8165 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8134 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8273 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8264 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8223 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8223 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8264 - accuracy: 0.53 - ETA: 2:50 - loss: 1.8279 - accuracy: 0.53 - ETA: 2:48 - loss: 1.8281 - accuracy: 0.53 - ETA: 2:46 - loss: 1.8291 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8262 - accuracy: 0.53 - ETA: 2:41 - loss: 1.8235 - accuracy: 0.53 - ETA: 2:39 - loss: 1.8250 - accuracy: 0.53 - ETA: 2:37 - loss: 1.8221 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8231 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8229 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8256 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8218 - accuracy: 0.53 - ETA: 2:27 - loss: 1.8342 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8334 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8300 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8266 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8288 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8343 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8376 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8376 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8365 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8326 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8286 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8278 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8276 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8261 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8256 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8288 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8318 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8297 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8330 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8278 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8272 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8250 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8252 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8272 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8289 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8330 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8315 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8322 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8311 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8335 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8283 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8305 - accuracy: 0.53 - ETA: 1:23 - loss: 1.8292 - accuracy: 0.53 - ETA: 1:21 - loss: 1.8279 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8281 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8294 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8270 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8246 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8258 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8258 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8273 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8255 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8237 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8231 - accuracy: 0.53 - ETA: 59s - loss: 1.8204 - accuracy: 0.5373 - ETA: 57s - loss: 1.8227 - accuracy: 0.537 - ETA: 55s - loss: 1.8284 - accuracy: 0.537 - ETA: 53s - loss: 1.8320 - accuracy: 0.537 - ETA: 51s - loss: 1.8286 - accuracy: 0.537 - ETA: 49s - loss: 1.8259 - accuracy: 0.537 - ETA: 47s - loss: 1.8249 - accuracy: 0.538 - ETA: 45s - loss: 1.8269 - accuracy: 0.538 - ETA: 43s - loss: 1.8271 - accuracy: 0.538 - ETA: 41s - loss: 1.8258 - accuracy: 0.538 - ETA: 39s - loss: 1.8267 - accuracy: 0.537 - ETA: 37s - loss: 1.8253 - accuracy: 0.538 - ETA: 35s - loss: 1.8251 - accuracy: 0.537 - ETA: 33s - loss: 1.8250 - accuracy: 0.537 - ETA: 31s - loss: 1.8267 - accuracy: 0.536 - ETA: 29s - loss: 1.8286 - accuracy: 0.537 - ETA: 27s - loss: 1.8313 - accuracy: 0.536 - ETA: 25s - loss: 1.8310 - accuracy: 0.537 - ETA: 23s - loss: 1.8304 - accuracy: 0.537 - ETA: 21s - loss: 1.8289 - accuracy: 0.537 - ETA: 19s - loss: 1.8265 - accuracy: 0.537 - ETA: 17s - loss: 1.8258 - accuracy: 0.537 - ETA: 15s - loss: 1.8273 - accuracy: 0.537 - ETA: 13s - loss: 1.8268 - accuracy: 0.537 - ETA: 11s - loss: 1.8265 - accuracy: 0.538 - ETA: 9s - loss: 1.8285 - accuracy: 0.537 - ETA: 7s - loss: 1.8272 - accuracy: 0.53 - ETA: 5s - loss: 1.8273 - accuracy: 0.53 - ETA: 3s - loss: 1.8249 - accuracy: 0.53 - ETA: 1s - loss: 1.8268 - accuracy: 0.53 - 331s 17ms/step - loss: 1.8260 - accuracy: 0.5380 - val_loss: 1.7608 - val_accuracy: 0.5910\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:57 - loss: 1.6578 - accuracy: 0.59 - ETA: 4:53 - loss: 1.6505 - accuracy: 0.58 - ETA: 4:51 - loss: 1.8030 - accuracy: 0.55 - ETA: 5:11 - loss: 1.7860 - accuracy: 0.56 - ETA: 5:04 - loss: 1.7149 - accuracy: 0.56 - ETA: 5:20 - loss: 1.7294 - accuracy: 0.55 - ETA: 5:14 - loss: 1.6990 - accuracy: 0.56 - ETA: 5:10 - loss: 1.6780 - accuracy: 0.55 - ETA: 5:02 - loss: 1.6622 - accuracy: 0.55 - ETA: 4:59 - loss: 1.7023 - accuracy: 0.55 - ETA: 4:55 - loss: 1.7047 - accuracy: 0.55 - ETA: 4:50 - loss: 1.8085 - accuracy: 0.54 - ETA: 4:44 - loss: 1.8114 - accuracy: 0.54 - ETA: 4:42 - loss: 1.7929 - accuracy: 0.54 - ETA: 4:39 - loss: 1.7863 - accuracy: 0.54 - ETA: 4:36 - loss: 1.8034 - accuracy: 0.54 - ETA: 4:34 - loss: 1.8105 - accuracy: 0.54 - ETA: 4:32 - loss: 1.8042 - accuracy: 0.54 - ETA: 4:29 - loss: 1.8070 - accuracy: 0.53 - ETA: 4:26 - loss: 1.7890 - accuracy: 0.54 - ETA: 4:22 - loss: 1.7854 - accuracy: 0.54 - ETA: 4:19 - loss: 1.7723 - accuracy: 0.54 - ETA: 4:20 - loss: 1.7661 - accuracy: 0.54 - ETA: 4:18 - loss: 1.7612 - accuracy: 0.54 - ETA: 4:16 - loss: 1.7336 - accuracy: 0.55 - ETA: 4:14 - loss: 1.7293 - accuracy: 0.55 - ETA: 4:10 - loss: 1.7292 - accuracy: 0.55 - ETA: 4:08 - loss: 1.7272 - accuracy: 0.54 - ETA: 4:05 - loss: 1.7582 - accuracy: 0.54 - ETA: 4:03 - loss: 1.7499 - accuracy: 0.54 - ETA: 4:03 - loss: 1.7600 - accuracy: 0.54 - ETA: 4:00 - loss: 1.7541 - accuracy: 0.54 - ETA: 3:57 - loss: 1.7555 - accuracy: 0.54 - ETA: 3:55 - loss: 1.7493 - accuracy: 0.54 - ETA: 3:53 - loss: 1.7445 - accuracy: 0.54 - ETA: 3:51 - loss: 1.7570 - accuracy: 0.54 - ETA: 3:49 - loss: 1.7566 - accuracy: 0.54 - ETA: 3:46 - loss: 1.7491 - accuracy: 0.54 - ETA: 3:43 - loss: 1.7490 - accuracy: 0.54 - ETA: 3:40 - loss: 1.7541 - accuracy: 0.54 - ETA: 3:38 - loss: 1.7548 - accuracy: 0.54 - ETA: 3:37 - loss: 1.7649 - accuracy: 0.54 - ETA: 3:35 - loss: 1.7604 - accuracy: 0.54 - ETA: 3:32 - loss: 1.7605 - accuracy: 0.54 - ETA: 3:30 - loss: 1.7684 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7740 - accuracy: 0.54 - ETA: 3:28 - loss: 1.7819 - accuracy: 0.53 - ETA: 3:26 - loss: 1.7795 - accuracy: 0.54 - ETA: 3:25 - loss: 1.7811 - accuracy: 0.53 - ETA: 3:23 - loss: 1.7764 - accuracy: 0.54 - ETA: 3:22 - loss: 1.7757 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7722 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7749 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7849 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7850 - accuracy: 0.53 - ETA: 3:08 - loss: 1.7878 - accuracy: 0.53 - ETA: 3:06 - loss: 1.7866 - accuracy: 0.53 - ETA: 3:05 - loss: 1.7883 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7848 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7839 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7898 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7926 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7961 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8019 - accuracy: 0.53 - ETA: 2:52 - loss: 1.7978 - accuracy: 0.53 - ETA: 2:50 - loss: 1.7979 - accuracy: 0.53 - ETA: 2:48 - loss: 1.7983 - accuracy: 0.53 - ETA: 2:46 - loss: 1.7992 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8004 - accuracy: 0.53 - ETA: 2:43 - loss: 1.7996 - accuracy: 0.53 - ETA: 2:41 - loss: 1.8008 - accuracy: 0.53 - ETA: 2:39 - loss: 1.7980 - accuracy: 0.53 - ETA: 2:37 - loss: 1.8038 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8043 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8098 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8072 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8088 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8079 - accuracy: 0.53 - ETA: 2:26 - loss: 1.8067 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8028 - accuracy: 0.53 - ETA: 2:23 - loss: 1.7981 - accuracy: 0.53 - ETA: 2:21 - loss: 1.7981 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8031 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8053 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8056 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8020 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8011 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8009 - accuracy: 0.53 - ETA: 2:07 - loss: 1.7989 - accuracy: 0.53 - ETA: 2:05 - loss: 1.7977 - accuracy: 0.53 - ETA: 2:03 - loss: 1.7956 - accuracy: 0.53 - ETA: 2:01 - loss: 1.7948 - accuracy: 0.53 - ETA: 1:59 - loss: 1.7973 - accuracy: 0.53 - ETA: 1:57 - loss: 1.7993 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8024 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8007 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8077 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8085 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8086 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8105 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8091 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8050 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8074 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8055 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8068 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8063 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8080 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8051 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8052 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8049 - accuracy: 0.53 - ETA: 1:23 - loss: 1.8066 - accuracy: 0.53 - ETA: 1:21 - loss: 1.8052 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8063 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8053 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8008 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8015 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8026 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8027 - accuracy: 0.53 - ETA: 1:06 - loss: 1.8043 - accuracy: 0.53 - ETA: 1:04 - loss: 1.8065 - accuracy: 0.53 - ETA: 1:02 - loss: 1.8058 - accuracy: 0.53 - ETA: 1:00 - loss: 1.8064 - accuracy: 0.53 - ETA: 58s - loss: 1.8059 - accuracy: 0.5324 - ETA: 56s - loss: 1.8054 - accuracy: 0.532 - ETA: 54s - loss: 1.8092 - accuracy: 0.532 - ETA: 52s - loss: 1.8069 - accuracy: 0.532 - ETA: 50s - loss: 1.8061 - accuracy: 0.532 - ETA: 48s - loss: 1.8064 - accuracy: 0.532 - ETA: 46s - loss: 1.8160 - accuracy: 0.532 - ETA: 44s - loss: 1.8170 - accuracy: 0.532 - ETA: 42s - loss: 1.8180 - accuracy: 0.531 - ETA: 39s - loss: 1.8259 - accuracy: 0.532 - ETA: 37s - loss: 1.8261 - accuracy: 0.532 - ETA: 35s - loss: 1.8265 - accuracy: 0.532 - ETA: 33s - loss: 1.8265 - accuracy: 0.532 - ETA: 31s - loss: 1.8242 - accuracy: 0.532 - ETA: 29s - loss: 1.8247 - accuracy: 0.532 - ETA: 27s - loss: 1.8252 - accuracy: 0.532 - ETA: 25s - loss: 1.8263 - accuracy: 0.532 - ETA: 23s - loss: 1.8251 - accuracy: 0.533 - ETA: 20s - loss: 1.8273 - accuracy: 0.532 - ETA: 18s - loss: 1.8260 - accuracy: 0.532 - ETA: 16s - loss: 1.8219 - accuracy: 0.533 - ETA: 14s - loss: 1.8215 - accuracy: 0.533 - ETA: 12s - loss: 1.8221 - accuracy: 0.533 - ETA: 10s - loss: 1.8251 - accuracy: 0.533 - ETA: 8s - loss: 1.8286 - accuracy: 0.532 - ETA: 6s - loss: 1.8303 - accuracy: 0.53 - ETA: 3s - loss: 1.8308 - accuracy: 0.53 - ETA: 1s - loss: 1.8296 - accuracy: 0.53 - 356s 18ms/step - loss: 1.8269 - accuracy: 0.5331 - val_loss: 1.8215 - val_accuracy: 0.5968\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:01 - loss: 1.7279 - accuracy: 0.51 - ETA: 4:57 - loss: 1.8660 - accuracy: 0.55 - ETA: 5:04 - loss: 1.8366 - accuracy: 0.54 - ETA: 5:14 - loss: 1.9660 - accuracy: 0.54 - ETA: 5:24 - loss: 1.9049 - accuracy: 0.53 - ETA: 5:24 - loss: 1.8581 - accuracy: 0.53 - ETA: 5:42 - loss: 1.9172 - accuracy: 0.52 - ETA: 5:49 - loss: 1.9317 - accuracy: 0.52 - ETA: 5:58 - loss: 1.8831 - accuracy: 0.53 - ETA: 6:04 - loss: 1.8416 - accuracy: 0.53 - ETA: 6:05 - loss: 1.8407 - accuracy: 0.54 - ETA: 6:05 - loss: 1.8116 - accuracy: 0.54 - ETA: 6:00 - loss: 1.8065 - accuracy: 0.54 - ETA: 5:53 - loss: 1.8087 - accuracy: 0.54 - ETA: 5:42 - loss: 1.8153 - accuracy: 0.54 - ETA: 5:32 - loss: 1.8339 - accuracy: 0.54 - ETA: 5:24 - loss: 1.8232 - accuracy: 0.54 - ETA: 5:17 - loss: 1.8223 - accuracy: 0.54 - ETA: 5:10 - loss: 1.8366 - accuracy: 0.53 - ETA: 5:02 - loss: 1.8562 - accuracy: 0.53 - ETA: 4:55 - loss: 1.8415 - accuracy: 0.53 - ETA: 4:48 - loss: 1.8404 - accuracy: 0.53 - ETA: 4:42 - loss: 1.8258 - accuracy: 0.53 - ETA: 4:37 - loss: 1.8304 - accuracy: 0.53 - ETA: 4:32 - loss: 1.8225 - accuracy: 0.53 - ETA: 4:27 - loss: 1.8150 - accuracy: 0.53 - ETA: 4:23 - loss: 1.7979 - accuracy: 0.53 - ETA: 4:18 - loss: 1.7930 - accuracy: 0.53 - ETA: 4:13 - loss: 1.8027 - accuracy: 0.53 - ETA: 4:09 - loss: 1.7977 - accuracy: 0.53 - ETA: 4:05 - loss: 1.7872 - accuracy: 0.53 - ETA: 4:01 - loss: 1.7863 - accuracy: 0.53 - ETA: 3:57 - loss: 1.7788 - accuracy: 0.54 - ETA: 3:53 - loss: 1.7722 - accuracy: 0.54 - ETA: 3:50 - loss: 1.7775 - accuracy: 0.54 - ETA: 3:46 - loss: 1.7978 - accuracy: 0.54 - ETA: 3:43 - loss: 1.7895 - accuracy: 0.54 - ETA: 3:39 - loss: 1.7914 - accuracy: 0.54 - ETA: 3:36 - loss: 1.7845 - accuracy: 0.54 - ETA: 3:33 - loss: 1.7853 - accuracy: 0.54 - ETA: 3:30 - loss: 1.7894 - accuracy: 0.54 - ETA: 3:27 - loss: 1.8004 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7975 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7989 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7975 - accuracy: 0.53 - ETA: 3:15 - loss: 1.7897 - accuracy: 0.54 - ETA: 3:13 - loss: 1.8011 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8042 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8053 - accuracy: 0.53 - ETA: 3:05 - loss: 1.8023 - accuracy: 0.53 - ETA: 3:03 - loss: 1.8120 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8173 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8129 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8129 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8207 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8186 - accuracy: 0.53 - ETA: 2:48 - loss: 1.8143 - accuracy: 0.53 - ETA: 2:46 - loss: 1.8133 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8153 - accuracy: 0.53 - ETA: 2:41 - loss: 1.8266 - accuracy: 0.53 - ETA: 2:39 - loss: 1.8331 - accuracy: 0.53 - ETA: 2:37 - loss: 1.8367 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8327 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8274 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8274 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8220 - accuracy: 0.53 - ETA: 2:26 - loss: 1.8243 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8264 - accuracy: 0.53 - ETA: 2:22 - loss: 1.8224 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8190 - accuracy: 0.53 - ETA: 2:18 - loss: 1.8149 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8147 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8143 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8164 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8127 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8156 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8204 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8235 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8211 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8180 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8166 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8166 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8162 - accuracy: 0.53 - ETA: 1:52 - loss: 1.8207 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8193 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8181 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8134 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8142 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8162 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8195 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8194 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8196 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8211 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8246 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8266 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8253 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8234 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8229 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8186 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8151 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8173 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8162 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8170 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8165 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8133 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8128 - accuracy: 0.53 - ETA: 1:12 - loss: 1.8120 - accuracy: 0.53 - ETA: 1:10 - loss: 1.8140 - accuracy: 0.53 - ETA: 1:08 - loss: 1.8167 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8172 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8239 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8239 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8232 - accuracy: 0.53 - ETA: 1:00 - loss: 1.8267 - accuracy: 0.53 - ETA: 58s - loss: 1.8303 - accuracy: 0.5339 - ETA: 56s - loss: 1.8288 - accuracy: 0.534 - ETA: 55s - loss: 1.8271 - accuracy: 0.534 - ETA: 53s - loss: 1.8234 - accuracy: 0.535 - ETA: 51s - loss: 1.8230 - accuracy: 0.534 - ETA: 50s - loss: 1.8240 - accuracy: 0.534 - ETA: 48s - loss: 1.8260 - accuracy: 0.534 - ETA: 46s - loss: 1.8274 - accuracy: 0.534 - ETA: 45s - loss: 1.8253 - accuracy: 0.534 - ETA: 43s - loss: 1.8250 - accuracy: 0.534 - ETA: 41s - loss: 1.8261 - accuracy: 0.534 - ETA: 40s - loss: 1.8251 - accuracy: 0.534 - ETA: 38s - loss: 1.8251 - accuracy: 0.534 - ETA: 36s - loss: 1.8240 - accuracy: 0.534 - ETA: 35s - loss: 1.8241 - accuracy: 0.535 - ETA: 33s - loss: 1.8241 - accuracy: 0.535 - ETA: 31s - loss: 1.8285 - accuracy: 0.534 - ETA: 30s - loss: 1.8275 - accuracy: 0.534 - ETA: 28s - loss: 1.8298 - accuracy: 0.534 - ETA: 26s - loss: 1.8276 - accuracy: 0.535 - ETA: 25s - loss: 1.8281 - accuracy: 0.535 - ETA: 23s - loss: 1.8309 - accuracy: 0.535 - ETA: 22s - loss: 1.8316 - accuracy: 0.534 - ETA: 20s - loss: 1.8333 - accuracy: 0.534 - ETA: 18s - loss: 1.8355 - accuracy: 0.533 - ETA: 17s - loss: 1.8351 - accuracy: 0.533 - ETA: 15s - loss: 1.8376 - accuracy: 0.532 - ETA: 14s - loss: 1.8397 - accuracy: 0.533 - ETA: 12s - loss: 1.8391 - accuracy: 0.533 - ETA: 10s - loss: 1.8408 - accuracy: 0.533 - ETA: 9s - loss: 1.8445 - accuracy: 0.533 - ETA: 7s - loss: 1.8437 - accuracy: 0.53 - ETA: 6s - loss: 1.8425 - accuracy: 0.53 - ETA: 4s - loss: 1.8422 - accuracy: 0.53 - ETA: 2s - loss: 1.8425 - accuracy: 0.53 - ETA: 1s - loss: 1.8393 - accuracy: 0.53 - 253s 13ms/step - loss: 1.8408 - accuracy: 0.5323 - val_loss: 1.8418 - val_accuracy: 0.5825\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:45 - loss: 1.5953 - accuracy: 0.51 - ETA: 3:40 - loss: 1.5898 - accuracy: 0.52 - ETA: 3:36 - loss: 1.9291 - accuracy: 0.52 - ETA: 3:34 - loss: 1.8474 - accuracy: 0.55 - ETA: 3:33 - loss: 1.8106 - accuracy: 0.55 - ETA: 3:36 - loss: 1.8012 - accuracy: 0.54 - ETA: 3:33 - loss: 1.8070 - accuracy: 0.54 - ETA: 3:35 - loss: 1.7825 - accuracy: 0.54 - ETA: 3:32 - loss: 1.7870 - accuracy: 0.53 - ETA: 3:30 - loss: 1.8102 - accuracy: 0.53 - ETA: 3:28 - loss: 1.8076 - accuracy: 0.53 - ETA: 3:25 - loss: 1.8573 - accuracy: 0.53 - ETA: 3:23 - loss: 1.8574 - accuracy: 0.53 - ETA: 3:21 - loss: 1.8398 - accuracy: 0.53 - ETA: 3:19 - loss: 1.8277 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8327 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8532 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8668 - accuracy: 0.53 - ETA: 3:10 - loss: 1.9040 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8965 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8816 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8968 - accuracy: 0.53 - ETA: 3:03 - loss: 1.8827 - accuracy: 0.53 - ETA: 3:01 - loss: 1.8739 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8818 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8819 - accuracy: 0.53 - ETA: 2:56 - loss: 1.9085 - accuracy: 0.53 - ETA: 2:54 - loss: 1.9128 - accuracy: 0.53 - ETA: 2:52 - loss: 1.9157 - accuracy: 0.53 - ETA: 2:51 - loss: 1.9099 - accuracy: 0.53 - ETA: 2:49 - loss: 1.9049 - accuracy: 0.53 - ETA: 2:48 - loss: 1.8984 - accuracy: 0.53 - ETA: 2:47 - loss: 1.9249 - accuracy: 0.53 - ETA: 2:46 - loss: 1.9281 - accuracy: 0.52 - ETA: 2:44 - loss: 1.9210 - accuracy: 0.52 - ETA: 2:42 - loss: 1.9186 - accuracy: 0.53 - ETA: 2:41 - loss: 1.9090 - accuracy: 0.53 - ETA: 2:39 - loss: 1.9044 - accuracy: 0.53 - ETA: 2:38 - loss: 1.9205 - accuracy: 0.52 - ETA: 2:36 - loss: 1.9157 - accuracy: 0.53 - ETA: 2:34 - loss: 1.9036 - accuracy: 0.53 - ETA: 2:33 - loss: 1.9018 - accuracy: 0.53 - ETA: 2:32 - loss: 1.9011 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8936 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8927 - accuracy: 0.53 - ETA: 2:27 - loss: 1.8873 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8851 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8822 - accuracy: 0.53 - ETA: 2:22 - loss: 1.8779 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8848 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8779 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8763 - accuracy: 0.53 - ETA: 2:18 - loss: 1.8786 - accuracy: 0.53 - ETA: 2:18 - loss: 1.8705 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8692 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8679 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8680 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8707 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8659 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8595 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8643 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8599 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8598 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8543 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8484 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8474 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8501 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8465 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8503 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8481 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8475 - accuracy: 0.53 - ETA: 1:52 - loss: 1.8481 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8500 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8515 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8525 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8490 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8529 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8580 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8580 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8598 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8601 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8590 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8576 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8616 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8575 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8574 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8574 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8633 - accuracy: 0.52 - ETA: 1:27 - loss: 1.8596 - accuracy: 0.52 - ETA: 1:26 - loss: 1.8581 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8551 - accuracy: 0.53 - ETA: 1:23 - loss: 1.8560 - accuracy: 0.53 - ETA: 1:21 - loss: 1.8664 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8658 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8656 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8636 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8615 - accuracy: 0.53 - ETA: 1:14 - loss: 1.8611 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8614 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8642 - accuracy: 0.53 - ETA: 1:10 - loss: 1.8659 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8631 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8614 - accuracy: 0.53 - ETA: 1:06 - loss: 1.8666 - accuracy: 0.53 - ETA: 1:04 - loss: 1.8623 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8626 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8588 - accuracy: 0.53 - ETA: 1:00 - loss: 1.8620 - accuracy: 0.53 - ETA: 58s - loss: 1.8627 - accuracy: 0.5319 - ETA: 57s - loss: 1.8675 - accuracy: 0.532 - ETA: 56s - loss: 1.8685 - accuracy: 0.531 - ETA: 54s - loss: 1.8677 - accuracy: 0.531 - ETA: 53s - loss: 1.8652 - accuracy: 0.532 - ETA: 51s - loss: 1.8667 - accuracy: 0.531 - ETA: 50s - loss: 1.8666 - accuracy: 0.530 - ETA: 48s - loss: 1.8653 - accuracy: 0.531 - ETA: 47s - loss: 1.8652 - accuracy: 0.530 - ETA: 46s - loss: 1.8641 - accuracy: 0.531 - ETA: 44s - loss: 1.8641 - accuracy: 0.531 - ETA: 43s - loss: 1.8632 - accuracy: 0.531 - ETA: 41s - loss: 1.8637 - accuracy: 0.531 - ETA: 40s - loss: 1.8613 - accuracy: 0.531 - ETA: 39s - loss: 1.8593 - accuracy: 0.531 - ETA: 37s - loss: 1.8606 - accuracy: 0.531 - ETA: 36s - loss: 1.8630 - accuracy: 0.531 - ETA: 34s - loss: 1.8634 - accuracy: 0.531 - ETA: 33s - loss: 1.8605 - accuracy: 0.531 - ETA: 32s - loss: 1.8620 - accuracy: 0.530 - ETA: 30s - loss: 1.8621 - accuracy: 0.530 - ETA: 29s - loss: 1.8603 - accuracy: 0.530 - ETA: 27s - loss: 1.8606 - accuracy: 0.530 - ETA: 26s - loss: 1.8612 - accuracy: 0.530 - ETA: 24s - loss: 1.8627 - accuracy: 0.529 - ETA: 23s - loss: 1.8646 - accuracy: 0.529 - ETA: 22s - loss: 1.8643 - accuracy: 0.529 - ETA: 20s - loss: 1.8648 - accuracy: 0.529 - ETA: 19s - loss: 1.8619 - accuracy: 0.529 - ETA: 17s - loss: 1.8606 - accuracy: 0.529 - ETA: 16s - loss: 1.8604 - accuracy: 0.528 - ETA: 15s - loss: 1.8605 - accuracy: 0.529 - ETA: 13s - loss: 1.8709 - accuracy: 0.529 - ETA: 12s - loss: 1.8751 - accuracy: 0.528 - ETA: 11s - loss: 1.8732 - accuracy: 0.529 - ETA: 9s - loss: 1.8776 - accuracy: 0.528 - ETA: 8s - loss: 1.8770 - accuracy: 0.52 - ETA: 6s - loss: 1.8758 - accuracy: 0.52 - ETA: 5s - loss: 1.8738 - accuracy: 0.52 - ETA: 4s - loss: 1.8742 - accuracy: 0.52 - ETA: 2s - loss: 1.8750 - accuracy: 0.52 - ETA: 1s - loss: 1.8731 - accuracy: 0.52 - 227s 12ms/step - loss: 1.8718 - accuracy: 0.5293 - val_loss: 1.7675 - val_accuracy: 0.5968\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:49 - loss: 2.1521 - accuracy: 0.47 - ETA: 3:37 - loss: 1.9276 - accuracy: 0.52 - ETA: 3:30 - loss: 1.8569 - accuracy: 0.53 - ETA: 3:29 - loss: 1.7966 - accuracy: 0.54 - ETA: 3:29 - loss: 1.8430 - accuracy: 0.53 - ETA: 3:28 - loss: 1.8240 - accuracy: 0.54 - ETA: 3:28 - loss: 1.8082 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7704 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7687 - accuracy: 0.54 - ETA: 3:22 - loss: 1.7680 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7589 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7426 - accuracy: 0.54 - ETA: 3:17 - loss: 1.7503 - accuracy: 0.54 - ETA: 3:15 - loss: 1.8530 - accuracy: 0.53 - ETA: 3:13 - loss: 1.8857 - accuracy: 0.53 - ETA: 3:11 - loss: 1.8566 - accuracy: 0.54 - ETA: 3:10 - loss: 1.8575 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8367 - accuracy: 0.54 - ETA: 3:08 - loss: 1.8315 - accuracy: 0.54 - ETA: 3:06 - loss: 1.8711 - accuracy: 0.54 - ETA: 3:04 - loss: 1.9033 - accuracy: 0.54 - ETA: 3:03 - loss: 1.8923 - accuracy: 0.54 - ETA: 3:01 - loss: 1.8832 - accuracy: 0.54 - ETA: 2:59 - loss: 1.8884 - accuracy: 0.54 - ETA: 2:57 - loss: 1.8848 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8868 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8783 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8680 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8662 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8649 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8621 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8701 - accuracy: 0.53 - ETA: 2:50 - loss: 1.8624 - accuracy: 0.53 - ETA: 2:48 - loss: 1.8870 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8818 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8856 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8868 - accuracy: 0.52 - ETA: 2:42 - loss: 1.8846 - accuracy: 0.53 - ETA: 2:41 - loss: 1.8863 - accuracy: 0.53 - ETA: 2:39 - loss: 1.8859 - accuracy: 0.52 - ETA: 2:38 - loss: 1.8881 - accuracy: 0.52 - ETA: 2:36 - loss: 1.8938 - accuracy: 0.52 - ETA: 2:34 - loss: 1.8931 - accuracy: 0.52 - ETA: 2:32 - loss: 1.8921 - accuracy: 0.52 - ETA: 2:31 - loss: 1.8974 - accuracy: 0.52 - ETA: 2:29 - loss: 1.9003 - accuracy: 0.52 - ETA: 2:28 - loss: 1.8942 - accuracy: 0.52 - ETA: 2:26 - loss: 1.8934 - accuracy: 0.52 - ETA: 2:25 - loss: 1.8886 - accuracy: 0.52 - ETA: 2:23 - loss: 1.8877 - accuracy: 0.52 - ETA: 2:22 - loss: 1.9128 - accuracy: 0.52 - ETA: 2:20 - loss: 1.9101 - accuracy: 0.52 - ETA: 2:19 - loss: 1.9058 - accuracy: 0.52 - ETA: 2:17 - loss: 1.9031 - accuracy: 0.52 - ETA: 2:16 - loss: 1.9088 - accuracy: 0.52 - ETA: 2:14 - loss: 1.9035 - accuracy: 0.52 - ETA: 2:12 - loss: 1.9077 - accuracy: 0.53 - ETA: 2:11 - loss: 1.9071 - accuracy: 0.52 - ETA: 2:09 - loss: 1.9032 - accuracy: 0.53 - ETA: 2:08 - loss: 1.9027 - accuracy: 0.52 - ETA: 2:06 - loss: 1.8943 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8971 - accuracy: 0.52 - ETA: 2:04 - loss: 1.8988 - accuracy: 0.53 - ETA: 2:02 - loss: 1.9128 - accuracy: 0.52 - ETA: 2:01 - loss: 1.9061 - accuracy: 0.52 - ETA: 1:59 - loss: 1.9058 - accuracy: 0.53 - ETA: 1:58 - loss: 1.9030 - accuracy: 0.53 - ETA: 1:57 - loss: 1.9044 - accuracy: 0.52 - ETA: 1:55 - loss: 1.9008 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8968 - accuracy: 0.53 - ETA: 1:52 - loss: 1.8937 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8960 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8949 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8874 - accuracy: 0.53 - ETA: 1:46 - loss: 1.8849 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8842 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8848 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8889 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8865 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8839 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8828 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8809 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8782 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8772 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8775 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8741 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8767 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8786 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8800 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8821 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8896 - accuracy: 0.52 - ETA: 1:29 - loss: 1.8906 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8879 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8893 - accuracy: 0.52 - ETA: 1:26 - loss: 1.8828 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8778 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8766 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8755 - accuracy: 0.53 - ETA: 1:21 - loss: 1.8764 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8757 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8747 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8757 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8730 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8711 - accuracy: 0.53 - ETA: 1:14 - loss: 1.8699 - accuracy: 0.53 - ETA: 1:12 - loss: 1.8745 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8719 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8726 - accuracy: 0.53 - ETA: 1:08 - loss: 1.8720 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8693 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8667 - accuracy: 0.53 - ETA: 1:04 - loss: 1.8657 - accuracy: 0.53 - ETA: 1:02 - loss: 1.8681 - accuracy: 0.53 - ETA: 1:01 - loss: 1.9451 - accuracy: 0.53 - ETA: 59s - loss: 1.9432 - accuracy: 0.5318 - ETA: 58s - loss: 1.9475 - accuracy: 0.531 - ETA: 56s - loss: 1.9467 - accuracy: 0.531 - ETA: 55s - loss: 1.9455 - accuracy: 0.532 - ETA: 53s - loss: 1.9431 - accuracy: 0.532 - ETA: 52s - loss: 1.9411 - accuracy: 0.532 - ETA: 50s - loss: 1.9391 - accuracy: 0.532 - ETA: 48s - loss: 1.9436 - accuracy: 0.532 - ETA: 47s - loss: 1.9381 - accuracy: 0.534 - ETA: 45s - loss: 1.9383 - accuracy: 0.534 - ETA: 44s - loss: 1.9334 - accuracy: 0.535 - ETA: 42s - loss: 1.9320 - accuracy: 0.535 - ETA: 40s - loss: 1.9300 - accuracy: 0.535 - ETA: 39s - loss: 1.9310 - accuracy: 0.534 - ETA: 37s - loss: 1.9299 - accuracy: 0.535 - ETA: 36s - loss: 1.9309 - accuracy: 0.534 - ETA: 34s - loss: 1.9302 - accuracy: 0.534 - ETA: 32s - loss: 1.9254 - accuracy: 0.535 - ETA: 30s - loss: 1.9257 - accuracy: 0.535 - ETA: 29s - loss: 1.9255 - accuracy: 0.535 - ETA: 27s - loss: 1.9269 - accuracy: 0.534 - ETA: 25s - loss: 1.9259 - accuracy: 0.534 - ETA: 24s - loss: 1.9244 - accuracy: 0.534 - ETA: 22s - loss: 1.9272 - accuracy: 0.534 - ETA: 20s - loss: 1.9296 - accuracy: 0.533 - ETA: 19s - loss: 1.9280 - accuracy: 0.533 - ETA: 17s - loss: 1.9249 - accuracy: 0.533 - ETA: 15s - loss: 1.9215 - accuracy: 0.534 - ETA: 13s - loss: 1.9210 - accuracy: 0.533 - ETA: 12s - loss: 1.9204 - accuracy: 0.534 - ETA: 10s - loss: 1.9178 - accuracy: 0.534 - ETA: 8s - loss: 1.9152 - accuracy: 0.534 - ETA: 6s - loss: 1.9126 - accuracy: 0.53 - ETA: 5s - loss: 1.9095 - accuracy: 0.53 - ETA: 3s - loss: 1.9096 - accuracy: 0.53 - ETA: 1s - loss: 1.9087 - accuracy: 0.53 - 301s 16ms/step - loss: 1.9072 - accuracy: 0.5347 - val_loss: 1.7855 - val_accuracy: 0.5916\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:08 - loss: 1.7108 - accuracy: 0.51 - ETA: 5:13 - loss: 1.5682 - accuracy: 0.53 - ETA: 5:07 - loss: 1.7024 - accuracy: 0.51 - ETA: 5:01 - loss: 1.7557 - accuracy: 0.51 - ETA: 5:00 - loss: 1.8987 - accuracy: 0.50 - ETA: 4:57 - loss: 1.8458 - accuracy: 0.51 - ETA: 4:58 - loss: 1.8667 - accuracy: 0.51 - ETA: 5:00 - loss: 1.8655 - accuracy: 0.52 - ETA: 4:56 - loss: 1.8081 - accuracy: 0.53 - ETA: 4:54 - loss: 1.7607 - accuracy: 0.54 - ETA: 4:53 - loss: 1.9282 - accuracy: 0.54 - ETA: 4:51 - loss: 1.9039 - accuracy: 0.55 - ETA: 4:49 - loss: 1.8929 - accuracy: 0.55 - ETA: 4:49 - loss: 1.8601 - accuracy: 0.55 - ETA: 4:48 - loss: 1.9714 - accuracy: 0.55 - ETA: 4:45 - loss: 1.9666 - accuracy: 0.55 - ETA: 4:43 - loss: 1.9548 - accuracy: 0.55 - ETA: 4:40 - loss: 1.9303 - accuracy: 0.55 - ETA: 4:39 - loss: 1.9207 - accuracy: 0.55 - ETA: 4:37 - loss: 1.9056 - accuracy: 0.55 - ETA: 4:35 - loss: 1.8940 - accuracy: 0.55 - ETA: 4:33 - loss: 1.8856 - accuracy: 0.55 - ETA: 4:31 - loss: 1.8796 - accuracy: 0.55 - ETA: 4:29 - loss: 1.8725 - accuracy: 0.55 - ETA: 4:27 - loss: 1.8695 - accuracy: 0.55 - ETA: 4:24 - loss: 1.8658 - accuracy: 0.55 - ETA: 4:22 - loss: 1.8590 - accuracy: 0.55 - ETA: 4:20 - loss: 1.8510 - accuracy: 0.55 - ETA: 4:18 - loss: 1.8442 - accuracy: 0.55 - ETA: 4:17 - loss: 1.8422 - accuracy: 0.55 - ETA: 4:15 - loss: 1.8537 - accuracy: 0.54 - ETA: 4:13 - loss: 1.8438 - accuracy: 0.55 - ETA: 4:11 - loss: 1.8291 - accuracy: 0.55 - ETA: 4:08 - loss: 1.8263 - accuracy: 0.55 - ETA: 4:06 - loss: 1.8201 - accuracy: 0.55 - ETA: 4:05 - loss: 1.8312 - accuracy: 0.55 - ETA: 4:02 - loss: 1.8220 - accuracy: 0.55 - ETA: 4:00 - loss: 1.8316 - accuracy: 0.55 - ETA: 3:58 - loss: 1.8345 - accuracy: 0.55 - ETA: 3:55 - loss: 1.8320 - accuracy: 0.55 - ETA: 3:53 - loss: 1.8398 - accuracy: 0.54 - ETA: 3:52 - loss: 1.8388 - accuracy: 0.54 - ETA: 3:51 - loss: 1.8299 - accuracy: 0.54 - ETA: 3:49 - loss: 1.8400 - accuracy: 0.54 - ETA: 3:48 - loss: 1.8322 - accuracy: 0.54 - ETA: 3:46 - loss: 1.8361 - accuracy: 0.54 - ETA: 3:43 - loss: 1.8318 - accuracy: 0.54 - ETA: 3:41 - loss: 1.8310 - accuracy: 0.54 - ETA: 3:39 - loss: 1.8348 - accuracy: 0.54 - ETA: 3:37 - loss: 1.8298 - accuracy: 0.54 - ETA: 3:35 - loss: 1.8333 - accuracy: 0.54 - ETA: 3:32 - loss: 1.8296 - accuracy: 0.54 - ETA: 3:30 - loss: 1.8260 - accuracy: 0.54 - ETA: 3:28 - loss: 1.8225 - accuracy: 0.54 - ETA: 3:26 - loss: 1.8242 - accuracy: 0.54 - ETA: 3:24 - loss: 1.8317 - accuracy: 0.54 - ETA: 3:21 - loss: 1.8331 - accuracy: 0.54 - ETA: 3:19 - loss: 1.8301 - accuracy: 0.54 - ETA: 3:17 - loss: 1.8305 - accuracy: 0.54 - ETA: 3:15 - loss: 1.8293 - accuracy: 0.54 - ETA: 3:12 - loss: 1.8314 - accuracy: 0.54 - ETA: 3:10 - loss: 1.8330 - accuracy: 0.54 - ETA: 3:08 - loss: 1.8353 - accuracy: 0.54 - ETA: 3:05 - loss: 1.8359 - accuracy: 0.54 - ETA: 3:03 - loss: 1.8342 - accuracy: 0.54 - ETA: 3:01 - loss: 1.8395 - accuracy: 0.54 - ETA: 2:59 - loss: 1.8377 - accuracy: 0.54 - ETA: 2:57 - loss: 1.8353 - accuracy: 0.54 - ETA: 2:54 - loss: 1.8337 - accuracy: 0.54 - ETA: 2:52 - loss: 1.8331 - accuracy: 0.54 - ETA: 2:50 - loss: 1.8286 - accuracy: 0.54 - ETA: 2:48 - loss: 1.8286 - accuracy: 0.54 - ETA: 2:46 - loss: 1.8258 - accuracy: 0.54 - ETA: 2:44 - loss: 1.8229 - accuracy: 0.54 - ETA: 2:42 - loss: 1.8234 - accuracy: 0.54 - ETA: 2:40 - loss: 1.8255 - accuracy: 0.54 - ETA: 2:37 - loss: 1.8321 - accuracy: 0.54 - ETA: 2:35 - loss: 1.8332 - accuracy: 0.54 - ETA: 2:33 - loss: 1.8283 - accuracy: 0.54 - ETA: 2:31 - loss: 1.8340 - accuracy: 0.54 - ETA: 2:29 - loss: 1.8320 - accuracy: 0.54 - ETA: 2:27 - loss: 1.8309 - accuracy: 0.54 - ETA: 2:25 - loss: 1.8332 - accuracy: 0.54 - ETA: 2:22 - loss: 1.8337 - accuracy: 0.54 - ETA: 2:20 - loss: 1.8307 - accuracy: 0.54 - ETA: 2:18 - loss: 1.8299 - accuracy: 0.54 - ETA: 2:16 - loss: 1.8273 - accuracy: 0.54 - ETA: 2:14 - loss: 1.8315 - accuracy: 0.54 - ETA: 2:12 - loss: 1.8339 - accuracy: 0.54 - ETA: 2:09 - loss: 1.8349 - accuracy: 0.54 - ETA: 2:07 - loss: 1.8321 - accuracy: 0.54 - ETA: 2:05 - loss: 1.8303 - accuracy: 0.54 - ETA: 2:03 - loss: 1.8326 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8334 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8316 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8346 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8326 - accuracy: 0.53 - ETA: 1:52 - loss: 1.8359 - accuracy: 0.53 - ETA: 1:50 - loss: 1.8398 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8424 - accuracy: 0.53 - ETA: 1:46 - loss: 1.8411 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8425 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8523 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8502 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8469 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8475 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8475 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8512 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8534 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8531 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8550 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8580 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8581 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8562 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8524 - accuracy: 0.53 - ETA: 1:14 - loss: 1.8495 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8582 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8583 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8545 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8525 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8565 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8575 - accuracy: 0.53 - ETA: 59s - loss: 1.8559 - accuracy: 0.5365 - ETA: 57s - loss: 1.8536 - accuracy: 0.536 - ETA: 54s - loss: 1.8531 - accuracy: 0.536 - ETA: 52s - loss: 1.8530 - accuracy: 0.536 - ETA: 50s - loss: 1.8515 - accuracy: 0.536 - ETA: 48s - loss: 1.8515 - accuracy: 0.535 - ETA: 46s - loss: 1.8538 - accuracy: 0.535 - ETA: 44s - loss: 1.8518 - accuracy: 0.536 - ETA: 42s - loss: 1.8528 - accuracy: 0.535 - ETA: 40s - loss: 1.8547 - accuracy: 0.535 - ETA: 37s - loss: 1.8583 - accuracy: 0.534 - ETA: 35s - loss: 1.8574 - accuracy: 0.534 - ETA: 33s - loss: 1.8581 - accuracy: 0.535 - ETA: 31s - loss: 1.8572 - accuracy: 0.535 - ETA: 29s - loss: 1.8636 - accuracy: 0.534 - ETA: 27s - loss: 1.8625 - accuracy: 0.535 - ETA: 25s - loss: 1.8612 - accuracy: 0.534 - ETA: 23s - loss: 1.8591 - accuracy: 0.535 - ETA: 20s - loss: 1.8584 - accuracy: 0.535 - ETA: 18s - loss: 1.8577 - accuracy: 0.535 - ETA: 16s - loss: 1.8560 - accuracy: 0.535 - ETA: 14s - loss: 1.8548 - accuracy: 0.535 - ETA: 12s - loss: 1.8541 - accuracy: 0.535 - ETA: 10s - loss: 1.8558 - accuracy: 0.535 - ETA: 8s - loss: 1.8550 - accuracy: 0.535 - ETA: 6s - loss: 1.8527 - accuracy: 0.53 - ETA: 3s - loss: 1.8512 - accuracy: 0.53 - ETA: 1s - loss: 1.8494 - accuracy: 0.53 - 351s 18ms/step - loss: 1.8486 - accuracy: 0.5370 - val_loss: 1.7708 - val_accuracy: 0.5923\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:21 - loss: 2.9780 - accuracy: 0.56 - ETA: 5:22 - loss: 2.3397 - accuracy: 0.55 - ETA: 5:18 - loss: 2.1299 - accuracy: 0.54 - ETA: 5:13 - loss: 2.0199 - accuracy: 0.54 - ETA: 5:11 - loss: 1.9581 - accuracy: 0.54 - ETA: 5:09 - loss: 2.0009 - accuracy: 0.54 - ETA: 5:06 - loss: 1.9733 - accuracy: 0.54 - ETA: 5:03 - loss: 1.9760 - accuracy: 0.53 - ETA: 5:00 - loss: 1.9111 - accuracy: 0.54 - ETA: 4:58 - loss: 1.8819 - accuracy: 0.54 - ETA: 4:55 - loss: 1.9086 - accuracy: 0.53 - ETA: 4:54 - loss: 1.8977 - accuracy: 0.54 - ETA: 4:53 - loss: 1.9109 - accuracy: 0.53 - ETA: 4:50 - loss: 2.0143 - accuracy: 0.53 - ETA: 4:44 - loss: 1.9801 - accuracy: 0.53 - ETA: 4:42 - loss: 1.9910 - accuracy: 0.53 - ETA: 4:41 - loss: 1.9755 - accuracy: 0.53 - ETA: 4:40 - loss: 1.9524 - accuracy: 0.53 - ETA: 4:38 - loss: 1.9484 - accuracy: 0.53 - ETA: 4:36 - loss: 1.9345 - accuracy: 0.54 - ETA: 4:33 - loss: 1.9410 - accuracy: 0.54 - ETA: 4:30 - loss: 1.9331 - accuracy: 0.54 - ETA: 4:28 - loss: 1.9552 - accuracy: 0.53 - ETA: 4:27 - loss: 1.9409 - accuracy: 0.53 - ETA: 4:25 - loss: 1.9335 - accuracy: 0.53 - ETA: 4:22 - loss: 1.9158 - accuracy: 0.53 - ETA: 4:20 - loss: 1.9055 - accuracy: 0.53 - ETA: 4:17 - loss: 1.9168 - accuracy: 0.53 - ETA: 4:16 - loss: 1.9005 - accuracy: 0.53 - ETA: 4:13 - loss: 1.8926 - accuracy: 0.53 - ETA: 4:10 - loss: 1.8892 - accuracy: 0.54 - ETA: 4:08 - loss: 1.8835 - accuracy: 0.53 - ETA: 4:06 - loss: 1.8761 - accuracy: 0.54 - ETA: 4:04 - loss: 1.8705 - accuracy: 0.53 - ETA: 4:02 - loss: 1.8842 - accuracy: 0.53 - ETA: 4:00 - loss: 1.8717 - accuracy: 0.53 - ETA: 3:57 - loss: 1.8651 - accuracy: 0.53 - ETA: 3:54 - loss: 1.8682 - accuracy: 0.53 - ETA: 3:52 - loss: 1.8656 - accuracy: 0.53 - ETA: 3:50 - loss: 1.8617 - accuracy: 0.54 - ETA: 3:47 - loss: 1.8599 - accuracy: 0.54 - ETA: 3:44 - loss: 1.8686 - accuracy: 0.54 - ETA: 3:42 - loss: 1.8597 - accuracy: 0.54 - ETA: 3:40 - loss: 1.8546 - accuracy: 0.54 - ETA: 3:38 - loss: 1.8500 - accuracy: 0.54 - ETA: 3:35 - loss: 1.8458 - accuracy: 0.54 - ETA: 3:33 - loss: 1.8434 - accuracy: 0.54 - ETA: 3:32 - loss: 1.8437 - accuracy: 0.54 - ETA: 3:30 - loss: 1.8384 - accuracy: 0.54 - ETA: 3:28 - loss: 1.8355 - accuracy: 0.54 - ETA: 3:26 - loss: 1.8496 - accuracy: 0.54 - ETA: 3:24 - loss: 1.8565 - accuracy: 0.54 - ETA: 3:22 - loss: 1.8530 - accuracy: 0.54 - ETA: 3:20 - loss: 1.8547 - accuracy: 0.54 - ETA: 3:18 - loss: 1.8521 - accuracy: 0.54 - ETA: 3:16 - loss: 1.8511 - accuracy: 0.54 - ETA: 3:15 - loss: 1.8515 - accuracy: 0.54 - ETA: 3:12 - loss: 1.8565 - accuracy: 0.54 - ETA: 3:10 - loss: 1.8550 - accuracy: 0.54 - ETA: 3:09 - loss: 1.8533 - accuracy: 0.54 - ETA: 3:07 - loss: 1.8509 - accuracy: 0.54 - ETA: 3:05 - loss: 1.8472 - accuracy: 0.54 - ETA: 3:03 - loss: 1.8440 - accuracy: 0.54 - ETA: 3:01 - loss: 1.8463 - accuracy: 0.54 - ETA: 2:59 - loss: 1.8451 - accuracy: 0.54 - ETA: 2:57 - loss: 1.8435 - accuracy: 0.54 - ETA: 2:55 - loss: 1.8441 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8410 - accuracy: 0.54 - ETA: 2:51 - loss: 1.8420 - accuracy: 0.54 - ETA: 2:49 - loss: 1.8421 - accuracy: 0.54 - ETA: 2:47 - loss: 1.8407 - accuracy: 0.54 - ETA: 2:45 - loss: 1.8405 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8379 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8371 - accuracy: 0.53 - ETA: 2:37 - loss: 1.8369 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8399 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8370 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8315 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8320 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8292 - accuracy: 0.53 - ETA: 2:26 - loss: 1.8306 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8307 - accuracy: 0.53 - ETA: 2:22 - loss: 1.8316 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8333 - accuracy: 0.53 - ETA: 2:18 - loss: 1.8290 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8251 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8263 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8302 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8265 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8255 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8267 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8245 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8232 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8224 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8245 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8287 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8314 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8299 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8259 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8270 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8242 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8293 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8278 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8300 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8322 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8332 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8318 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8284 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8279 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8274 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8301 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8284 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8275 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8287 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8251 - accuracy: 0.53 - ETA: 1:14 - loss: 1.8275 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8244 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8236 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8218 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8217 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8250 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8269 - accuracy: 0.53 - ETA: 59s - loss: 1.8243 - accuracy: 0.5354 - ETA: 57s - loss: 1.8204 - accuracy: 0.535 - ETA: 55s - loss: 1.8197 - accuracy: 0.535 - ETA: 53s - loss: 1.8188 - accuracy: 0.536 - ETA: 50s - loss: 1.8205 - accuracy: 0.535 - ETA: 48s - loss: 1.8201 - accuracy: 0.535 - ETA: 46s - loss: 1.8165 - accuracy: 0.536 - ETA: 44s - loss: 1.8137 - accuracy: 0.536 - ETA: 42s - loss: 1.8137 - accuracy: 0.536 - ETA: 40s - loss: 1.8102 - accuracy: 0.537 - ETA: 38s - loss: 1.8099 - accuracy: 0.537 - ETA: 36s - loss: 1.8125 - accuracy: 0.537 - ETA: 33s - loss: 1.8149 - accuracy: 0.536 - ETA: 31s - loss: 1.8148 - accuracy: 0.536 - ETA: 29s - loss: 1.8154 - accuracy: 0.537 - ETA: 27s - loss: 1.8160 - accuracy: 0.537 - ETA: 25s - loss: 1.8187 - accuracy: 0.536 - ETA: 23s - loss: 1.8174 - accuracy: 0.537 - ETA: 21s - loss: 1.8163 - accuracy: 0.537 - ETA: 19s - loss: 1.8157 - accuracy: 0.537 - ETA: 16s - loss: 1.8149 - accuracy: 0.538 - ETA: 14s - loss: 1.8136 - accuracy: 0.538 - ETA: 12s - loss: 1.8116 - accuracy: 0.538 - ETA: 10s - loss: 1.8135 - accuracy: 0.537 - ETA: 8s - loss: 1.8152 - accuracy: 0.537 - ETA: 6s - loss: 1.8130 - accuracy: 0.53 - ETA: 4s - loss: 1.8141 - accuracy: 0.53 - ETA: 1s - loss: 1.8140 - accuracy: 0.53 - 360s 19ms/step - loss: 1.8146 - accuracy: 0.5368 - val_loss: 1.9114 - val_accuracy: 0.5898\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:22 - loss: 1.7660 - accuracy: 0.49 - ETA: 5:28 - loss: 1.6918 - accuracy: 0.53 - ETA: 5:23 - loss: 1.6464 - accuracy: 0.54 - ETA: 5:22 - loss: 1.6882 - accuracy: 0.53 - ETA: 5:22 - loss: 1.7130 - accuracy: 0.53 - ETA: 5:22 - loss: 1.7643 - accuracy: 0.52 - ETA: 5:22 - loss: 1.7344 - accuracy: 0.53 - ETA: 5:21 - loss: 1.7169 - accuracy: 0.53 - ETA: 5:19 - loss: 1.7269 - accuracy: 0.53 - ETA: 5:16 - loss: 1.7297 - accuracy: 0.53 - ETA: 5:23 - loss: 1.7445 - accuracy: 0.53 - ETA: 5:20 - loss: 1.7475 - accuracy: 0.53 - ETA: 5:17 - loss: 1.7294 - accuracy: 0.53 - ETA: 5:14 - loss: 1.7167 - accuracy: 0.54 - ETA: 5:11 - loss: 1.7282 - accuracy: 0.54 - ETA: 5:08 - loss: 1.7466 - accuracy: 0.53 - ETA: 5:05 - loss: 1.7501 - accuracy: 0.54 - ETA: 5:02 - loss: 1.7517 - accuracy: 0.54 - ETA: 4:59 - loss: 1.7457 - accuracy: 0.53 - ETA: 4:57 - loss: 1.7499 - accuracy: 0.54 - ETA: 4:54 - loss: 1.7575 - accuracy: 0.54 - ETA: 4:51 - loss: 1.7456 - accuracy: 0.54 - ETA: 4:48 - loss: 1.7627 - accuracy: 0.53 - ETA: 4:46 - loss: 1.7691 - accuracy: 0.53 - ETA: 4:43 - loss: 1.7693 - accuracy: 0.54 - ETA: 4:40 - loss: 1.7624 - accuracy: 0.54 - ETA: 4:38 - loss: 1.7768 - accuracy: 0.54 - ETA: 4:36 - loss: 1.7826 - accuracy: 0.53 - ETA: 4:33 - loss: 1.7804 - accuracy: 0.53 - ETA: 4:31 - loss: 1.7738 - accuracy: 0.54 - ETA: 4:28 - loss: 1.7804 - accuracy: 0.53 - ETA: 4:26 - loss: 1.7887 - accuracy: 0.53 - ETA: 4:23 - loss: 1.7981 - accuracy: 0.53 - ETA: 4:21 - loss: 1.7932 - accuracy: 0.53 - ETA: 4:19 - loss: 1.8318 - accuracy: 0.53 - ETA: 4:16 - loss: 1.8334 - accuracy: 0.53 - ETA: 4:14 - loss: 1.8320 - accuracy: 0.53 - ETA: 4:11 - loss: 1.8341 - accuracy: 0.53 - ETA: 4:09 - loss: 1.8465 - accuracy: 0.53 - ETA: 4:06 - loss: 1.8468 - accuracy: 0.53 - ETA: 4:04 - loss: 1.8440 - accuracy: 0.53 - ETA: 4:01 - loss: 1.8389 - accuracy: 0.53 - ETA: 3:59 - loss: 1.8427 - accuracy: 0.53 - ETA: 3:57 - loss: 1.8461 - accuracy: 0.53 - ETA: 3:55 - loss: 1.8600 - accuracy: 0.53 - ETA: 3:52 - loss: 1.8600 - accuracy: 0.53 - ETA: 3:50 - loss: 1.8611 - accuracy: 0.53 - ETA: 3:48 - loss: 1.8610 - accuracy: 0.53 - ETA: 3:45 - loss: 1.8554 - accuracy: 0.53 - ETA: 3:43 - loss: 1.8611 - accuracy: 0.53 - ETA: 3:41 - loss: 1.8651 - accuracy: 0.53 - ETA: 3:39 - loss: 1.8664 - accuracy: 0.53 - ETA: 3:36 - loss: 1.8685 - accuracy: 0.53 - ETA: 3:34 - loss: 1.8706 - accuracy: 0.52 - ETA: 3:32 - loss: 1.8682 - accuracy: 0.52 - ETA: 3:30 - loss: 1.8657 - accuracy: 0.53 - ETA: 3:27 - loss: 1.8680 - accuracy: 0.53 - ETA: 3:25 - loss: 1.8672 - accuracy: 0.53 - ETA: 3:23 - loss: 1.8620 - accuracy: 0.53 - ETA: 3:21 - loss: 1.8642 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8631 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8585 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8536 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8722 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8721 - accuracy: 0.53 - ETA: 3:07 - loss: 1.8638 - accuracy: 0.53 - ETA: 3:05 - loss: 1.8565 - accuracy: 0.53 - ETA: 3:03 - loss: 1.8590 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8603 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8587 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8698 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8732 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8737 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8687 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8727 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8690 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8714 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8665 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8646 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8643 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8625 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8566 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8553 - accuracy: 0.53 - ETA: 2:27 - loss: 1.8522 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8511 - accuracy: 0.53 - ETA: 2:22 - loss: 1.8488 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8483 - accuracy: 0.53 - ETA: 2:18 - loss: 1.8440 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8427 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8419 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8387 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8483 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8549 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8542 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8509 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8495 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8499 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8482 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8486 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8454 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8438 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8431 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8429 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8456 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8506 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8506 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8509 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8478 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8467 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8465 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8449 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8442 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8447 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8444 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8459 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8481 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8443 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8425 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8426 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8415 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8442 - accuracy: 0.53 - ETA: 1:02 - loss: 1.8421 - accuracy: 0.53 - ETA: 1:00 - loss: 1.8414 - accuracy: 0.53 - ETA: 58s - loss: 1.8639 - accuracy: 0.5362 - ETA: 56s - loss: 1.8650 - accuracy: 0.536 - ETA: 54s - loss: 1.8630 - accuracy: 0.536 - ETA: 51s - loss: 1.8774 - accuracy: 0.536 - ETA: 49s - loss: 1.8762 - accuracy: 0.535 - ETA: 47s - loss: 1.8760 - accuracy: 0.536 - ETA: 45s - loss: 1.8760 - accuracy: 0.535 - ETA: 43s - loss: 1.8755 - accuracy: 0.534 - ETA: 41s - loss: 1.8743 - accuracy: 0.534 - ETA: 38s - loss: 1.8766 - accuracy: 0.534 - ETA: 36s - loss: 1.8733 - accuracy: 0.535 - ETA: 34s - loss: 1.8713 - accuracy: 0.535 - ETA: 32s - loss: 1.8690 - accuracy: 0.535 - ETA: 30s - loss: 1.8680 - accuracy: 0.535 - ETA: 28s - loss: 1.8650 - accuracy: 0.536 - ETA: 25s - loss: 1.8662 - accuracy: 0.536 - ETA: 23s - loss: 1.8651 - accuracy: 0.536 - ETA: 21s - loss: 1.8625 - accuracy: 0.536 - ETA: 19s - loss: 1.8631 - accuracy: 0.536 - ETA: 17s - loss: 1.8636 - accuracy: 0.535 - ETA: 14s - loss: 1.8611 - accuracy: 0.535 - ETA: 12s - loss: 1.8619 - accuracy: 0.535 - ETA: 10s - loss: 1.8610 - accuracy: 0.535 - ETA: 8s - loss: 1.8611 - accuracy: 0.535 - ETA: 6s - loss: 1.8594 - accuracy: 0.53 - ETA: 4s - loss: 1.8579 - accuracy: 0.53 - ETA: 1s - loss: 1.8579 - accuracy: 0.53 - 357s 18ms/step - loss: 1.8567 - accuracy: 0.5364 - val_loss: 1.8274 - val_accuracy: 0.5927\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:24 - loss: 1.8253 - accuracy: 0.50 - ETA: 5:23 - loss: 1.9895 - accuracy: 0.49 - ETA: 5:17 - loss: 2.1414 - accuracy: 0.50 - ETA: 5:15 - loss: 2.0893 - accuracy: 0.49 - ETA: 5:16 - loss: 2.0164 - accuracy: 0.51 - ETA: 5:11 - loss: 1.9400 - accuracy: 0.52 - ETA: 5:09 - loss: 1.8980 - accuracy: 0.53 - ETA: 5:06 - loss: 1.9289 - accuracy: 0.52 - ETA: 5:04 - loss: 1.9631 - accuracy: 0.52 - ETA: 5:01 - loss: 1.9277 - accuracy: 0.53 - ETA: 4:59 - loss: 1.9375 - accuracy: 0.52 - ETA: 4:56 - loss: 1.9326 - accuracy: 0.52 - ETA: 4:53 - loss: 1.9446 - accuracy: 0.52 - ETA: 4:51 - loss: 1.9513 - accuracy: 0.52 - ETA: 4:48 - loss: 1.9149 - accuracy: 0.52 - ETA: 4:46 - loss: 1.9144 - accuracy: 0.52 - ETA: 4:43 - loss: 1.9398 - accuracy: 0.52 - ETA: 4:40 - loss: 1.9299 - accuracy: 0.52 - ETA: 4:38 - loss: 1.9442 - accuracy: 0.52 - ETA: 4:35 - loss: 1.9286 - accuracy: 0.52 - ETA: 4:34 - loss: 1.9519 - accuracy: 0.52 - ETA: 4:32 - loss: 1.9417 - accuracy: 0.52 - ETA: 4:30 - loss: 1.9315 - accuracy: 0.52 - ETA: 4:28 - loss: 1.9456 - accuracy: 0.52 - ETA: 4:26 - loss: 1.9392 - accuracy: 0.52 - ETA: 4:24 - loss: 1.9285 - accuracy: 0.52 - ETA: 4:21 - loss: 1.9213 - accuracy: 0.52 - ETA: 4:19 - loss: 1.9040 - accuracy: 0.52 - ETA: 4:18 - loss: 1.9108 - accuracy: 0.52 - ETA: 4:15 - loss: 1.9127 - accuracy: 0.52 - ETA: 4:13 - loss: 1.9096 - accuracy: 0.52 - ETA: 4:11 - loss: 1.9049 - accuracy: 0.52 - ETA: 4:09 - loss: 1.9504 - accuracy: 0.52 - ETA: 4:07 - loss: 1.9443 - accuracy: 0.52 - ETA: 4:05 - loss: 1.9328 - accuracy: 0.52 - ETA: 4:02 - loss: 1.9328 - accuracy: 0.52 - ETA: 4:00 - loss: 1.9301 - accuracy: 0.52 - ETA: 3:59 - loss: 1.9274 - accuracy: 0.52 - ETA: 3:56 - loss: 1.9204 - accuracy: 0.52 - ETA: 3:54 - loss: 1.9166 - accuracy: 0.52 - ETA: 3:52 - loss: 1.9056 - accuracy: 0.52 - ETA: 3:50 - loss: 1.9033 - accuracy: 0.52 - ETA: 3:48 - loss: 1.8996 - accuracy: 0.52 - ETA: 3:46 - loss: 1.8987 - accuracy: 0.52 - ETA: 3:43 - loss: 1.8987 - accuracy: 0.52 - ETA: 3:41 - loss: 1.8922 - accuracy: 0.52 - ETA: 3:39 - loss: 1.8880 - accuracy: 0.52 - ETA: 3:37 - loss: 1.8844 - accuracy: 0.52 - ETA: 3:35 - loss: 1.8899 - accuracy: 0.52 - ETA: 3:33 - loss: 1.8849 - accuracy: 0.52 - ETA: 3:31 - loss: 1.8880 - accuracy: 0.52 - ETA: 3:29 - loss: 1.8870 - accuracy: 0.52 - ETA: 3:26 - loss: 1.8797 - accuracy: 0.52 - ETA: 3:24 - loss: 1.8737 - accuracy: 0.52 - ETA: 3:22 - loss: 1.8716 - accuracy: 0.53 - ETA: 3:20 - loss: 1.8708 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8672 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8635 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8572 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8556 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8504 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8455 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8457 - accuracy: 0.53 - ETA: 3:03 - loss: 1.8448 - accuracy: 0.53 - ETA: 3:01 - loss: 1.8446 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8457 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8467 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8481 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8556 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8533 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8479 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8499 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8441 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8460 - accuracy: 0.53 - ETA: 2:41 - loss: 1.8454 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8408 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8400 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8441 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8403 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8376 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8369 - accuracy: 0.53 - ETA: 2:26 - loss: 1.8330 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8309 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8289 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8262 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8281 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8242 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8203 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8157 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8139 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8135 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8118 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8141 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8137 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8117 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8084 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8054 - accuracy: 0.53 - ETA: 1:52 - loss: 1.8040 - accuracy: 0.53 - ETA: 1:50 - loss: 1.8058 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8086 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8045 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8047 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8008 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8023 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8032 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8061 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8064 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8056 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8030 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8024 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8004 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8039 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8016 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8033 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8021 - accuracy: 0.53 - ETA: 1:14 - loss: 1.7977 - accuracy: 0.53 - ETA: 1:12 - loss: 1.7976 - accuracy: 0.53 - ETA: 1:10 - loss: 1.7990 - accuracy: 0.53 - ETA: 1:07 - loss: 1.7974 - accuracy: 0.53 - ETA: 1:05 - loss: 1.7978 - accuracy: 0.53 - ETA: 1:03 - loss: 1.7959 - accuracy: 0.53 - ETA: 1:01 - loss: 1.7929 - accuracy: 0.53 - ETA: 59s - loss: 1.7923 - accuracy: 0.5380 - ETA: 57s - loss: 1.7968 - accuracy: 0.538 - ETA: 55s - loss: 1.7959 - accuracy: 0.537 - ETA: 52s - loss: 1.7962 - accuracy: 0.537 - ETA: 50s - loss: 1.7938 - accuracy: 0.538 - ETA: 48s - loss: 1.7943 - accuracy: 0.538 - ETA: 46s - loss: 1.7979 - accuracy: 0.537 - ETA: 44s - loss: 1.7997 - accuracy: 0.537 - ETA: 42s - loss: 1.8002 - accuracy: 0.536 - ETA: 40s - loss: 1.7988 - accuracy: 0.536 - ETA: 38s - loss: 1.7943 - accuracy: 0.537 - ETA: 35s - loss: 1.7919 - accuracy: 0.538 - ETA: 33s - loss: 1.7902 - accuracy: 0.538 - ETA: 31s - loss: 1.7902 - accuracy: 0.538 - ETA: 29s - loss: 1.7957 - accuracy: 0.538 - ETA: 27s - loss: 1.7948 - accuracy: 0.538 - ETA: 25s - loss: 1.7927 - accuracy: 0.538 - ETA: 23s - loss: 1.7933 - accuracy: 0.537 - ETA: 21s - loss: 1.7917 - accuracy: 0.537 - ETA: 18s - loss: 1.7907 - accuracy: 0.538 - ETA: 16s - loss: 1.7904 - accuracy: 0.538 - ETA: 14s - loss: 1.7885 - accuracy: 0.538 - ETA: 12s - loss: 1.7893 - accuracy: 0.538 - ETA: 10s - loss: 1.7882 - accuracy: 0.538 - ETA: 8s - loss: 1.7864 - accuracy: 0.538 - ETA: 6s - loss: 1.7879 - accuracy: 0.53 - ETA: 4s - loss: 1.7887 - accuracy: 0.53 - ETA: 1s - loss: 1.7889 - accuracy: 0.53 - 353s 18ms/step - loss: 1.7883 - accuracy: 0.5381 - val_loss: 1.8461 - val_accuracy: 0.5947\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:26 - loss: 1.7623 - accuracy: 0.51 - ETA: 5:13 - loss: 1.6569 - accuracy: 0.52 - ETA: 5:12 - loss: 1.7513 - accuracy: 0.50 - ETA: 5:09 - loss: 1.7235 - accuracy: 0.52 - ETA: 5:04 - loss: 1.6855 - accuracy: 0.53 - ETA: 5:04 - loss: 1.6584 - accuracy: 0.54 - ETA: 5:01 - loss: 1.6519 - accuracy: 0.54 - ETA: 4:59 - loss: 1.6577 - accuracy: 0.54 - ETA: 4:57 - loss: 1.7114 - accuracy: 0.53 - ETA: 4:57 - loss: 1.7046 - accuracy: 0.53 - ETA: 4:54 - loss: 1.7142 - accuracy: 0.53 - ETA: 4:52 - loss: 1.7440 - accuracy: 0.53 - ETA: 4:51 - loss: 1.7880 - accuracy: 0.53 - ETA: 4:49 - loss: 1.7981 - accuracy: 0.53 - ETA: 4:47 - loss: 1.7728 - accuracy: 0.53 - ETA: 4:45 - loss: 1.7863 - accuracy: 0.54 - ETA: 4:44 - loss: 1.8037 - accuracy: 0.53 - ETA: 4:41 - loss: 1.7986 - accuracy: 0.53 - ETA: 4:38 - loss: 1.8088 - accuracy: 0.53 - ETA: 4:37 - loss: 1.7951 - accuracy: 0.54 - ETA: 4:35 - loss: 1.8031 - accuracy: 0.53 - ETA: 4:33 - loss: 1.8052 - accuracy: 0.53 - ETA: 4:30 - loss: 1.7982 - accuracy: 0.53 - ETA: 4:32 - loss: 1.7908 - accuracy: 0.53 - ETA: 4:30 - loss: 1.7817 - accuracy: 0.54 - ETA: 4:28 - loss: 1.7835 - accuracy: 0.54 - ETA: 4:25 - loss: 1.7828 - accuracy: 0.53 - ETA: 4:23 - loss: 1.7909 - accuracy: 0.53 - ETA: 4:21 - loss: 1.7869 - accuracy: 0.53 - ETA: 4:19 - loss: 1.7951 - accuracy: 0.53 - ETA: 4:20 - loss: 1.7970 - accuracy: 0.53 - ETA: 4:18 - loss: 1.7979 - accuracy: 0.53 - ETA: 4:15 - loss: 1.8060 - accuracy: 0.53 - ETA: 4:12 - loss: 1.8028 - accuracy: 0.53 - ETA: 4:10 - loss: 1.8111 - accuracy: 0.53 - ETA: 4:08 - loss: 1.8106 - accuracy: 0.53 - ETA: 4:06 - loss: 1.8097 - accuracy: 0.53 - ETA: 4:03 - loss: 1.8071 - accuracy: 0.53 - ETA: 4:01 - loss: 1.7989 - accuracy: 0.53 - ETA: 3:59 - loss: 1.7852 - accuracy: 0.53 - ETA: 3:56 - loss: 1.7815 - accuracy: 0.53 - ETA: 3:54 - loss: 1.7852 - accuracy: 0.53 - ETA: 3:52 - loss: 1.7841 - accuracy: 0.53 - ETA: 3:50 - loss: 1.7944 - accuracy: 0.53 - ETA: 3:47 - loss: 1.7884 - accuracy: 0.54 - ETA: 3:45 - loss: 1.7885 - accuracy: 0.54 - ETA: 3:43 - loss: 1.7868 - accuracy: 0.54 - ETA: 3:40 - loss: 1.7926 - accuracy: 0.54 - ETA: 3:38 - loss: 1.7955 - accuracy: 0.54 - ETA: 3:36 - loss: 1.7881 - accuracy: 0.54 - ETA: 3:33 - loss: 1.7885 - accuracy: 0.54 - ETA: 3:31 - loss: 1.7924 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7967 - accuracy: 0.54 - ETA: 3:28 - loss: 1.7975 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7953 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7967 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7932 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7889 - accuracy: 0.54 - ETA: 3:17 - loss: 1.7910 - accuracy: 0.54 - ETA: 3:15 - loss: 1.7899 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7931 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7912 - accuracy: 0.54 - ETA: 3:09 - loss: 1.8022 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7978 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7947 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7964 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7930 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7991 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7976 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7946 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7940 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7924 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7936 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7990 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7985 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7965 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7997 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7997 - accuracy: 0.54 - ETA: 2:34 - loss: 1.8051 - accuracy: 0.54 - ETA: 2:32 - loss: 1.8007 - accuracy: 0.54 - ETA: 2:30 - loss: 1.8066 - accuracy: 0.54 - ETA: 2:28 - loss: 1.8052 - accuracy: 0.54 - ETA: 2:25 - loss: 1.8045 - accuracy: 0.54 - ETA: 2:23 - loss: 1.8017 - accuracy: 0.54 - ETA: 2:21 - loss: 1.8034 - accuracy: 0.54 - ETA: 2:19 - loss: 1.8014 - accuracy: 0.54 - ETA: 2:17 - loss: 1.8056 - accuracy: 0.54 - ETA: 2:14 - loss: 1.8053 - accuracy: 0.54 - ETA: 2:12 - loss: 1.8111 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8133 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8131 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8127 - accuracy: 0.54 - ETA: 2:04 - loss: 1.8138 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8137 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8170 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8158 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8157 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8132 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8141 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8126 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8133 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8124 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8096 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8098 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8099 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8131 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8114 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8136 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8141 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8130 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8137 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8136 - accuracy: 0.53 - ETA: 1:23 - loss: 1.8120 - accuracy: 0.53 - ETA: 1:21 - loss: 1.8131 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8139 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8139 - accuracy: 0.53 - ETA: 1:14 - loss: 1.8120 - accuracy: 0.53 - ETA: 1:12 - loss: 1.8148 - accuracy: 0.53 - ETA: 1:10 - loss: 1.8146 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8126 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8167 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8173 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8173 - accuracy: 0.53 - ETA: 59s - loss: 1.8163 - accuracy: 0.5373 - ETA: 56s - loss: 1.8134 - accuracy: 0.537 - ETA: 54s - loss: 1.8124 - accuracy: 0.537 - ETA: 52s - loss: 1.8134 - accuracy: 0.537 - ETA: 50s - loss: 1.8136 - accuracy: 0.536 - ETA: 48s - loss: 1.8109 - accuracy: 0.537 - ETA: 45s - loss: 1.8129 - accuracy: 0.537 - ETA: 43s - loss: 1.8144 - accuracy: 0.537 - ETA: 41s - loss: 1.8134 - accuracy: 0.537 - ETA: 39s - loss: 1.8141 - accuracy: 0.537 - ETA: 37s - loss: 1.8138 - accuracy: 0.537 - ETA: 34s - loss: 1.8130 - accuracy: 0.537 - ETA: 32s - loss: 1.8121 - accuracy: 0.537 - ETA: 30s - loss: 1.8102 - accuracy: 0.537 - ETA: 28s - loss: 1.8075 - accuracy: 0.538 - ETA: 26s - loss: 1.8083 - accuracy: 0.537 - ETA: 23s - loss: 1.8060 - accuracy: 0.538 - ETA: 21s - loss: 1.8085 - accuracy: 0.537 - ETA: 19s - loss: 1.8098 - accuracy: 0.537 - ETA: 17s - loss: 1.8129 - accuracy: 0.537 - ETA: 15s - loss: 1.8172 - accuracy: 0.537 - ETA: 12s - loss: 1.8194 - accuracy: 0.537 - ETA: 10s - loss: 1.8213 - accuracy: 0.537 - ETA: 8s - loss: 1.8232 - accuracy: 0.536 - ETA: 6s - loss: 1.8236 - accuracy: 0.53 - ETA: 4s - loss: 1.8239 - accuracy: 0.53 - ETA: 1s - loss: 1.8212 - accuracy: 0.53 - 355s 18ms/step - loss: 1.8257 - accuracy: 0.5363 - val_loss: 1.8912 - val_accuracy: 0.5920\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:18 - loss: 1.3851 - accuracy: 0.54 - ETA: 5:15 - loss: 1.5264 - accuracy: 0.54 - ETA: 5:12 - loss: 1.6277 - accuracy: 0.52 - ETA: 5:13 - loss: 1.7256 - accuracy: 0.52 - ETA: 5:12 - loss: 1.6994 - accuracy: 0.52 - ETA: 5:08 - loss: 1.7097 - accuracy: 0.52 - ETA: 5:04 - loss: 1.6454 - accuracy: 0.53 - ETA: 5:03 - loss: 1.6671 - accuracy: 0.53 - ETA: 5:02 - loss: 1.9700 - accuracy: 0.52 - ETA: 4:59 - loss: 1.9222 - accuracy: 0.53 - ETA: 4:58 - loss: 1.9234 - accuracy: 0.53 - ETA: 4:55 - loss: 1.9501 - accuracy: 0.53 - ETA: 4:53 - loss: 1.9107 - accuracy: 0.54 - ETA: 4:51 - loss: 1.9224 - accuracy: 0.54 - ETA: 4:49 - loss: 1.9057 - accuracy: 0.54 - ETA: 4:46 - loss: 1.9109 - accuracy: 0.53 - ETA: 4:45 - loss: 1.8901 - accuracy: 0.53 - ETA: 4:43 - loss: 1.8550 - accuracy: 0.54 - ETA: 4:41 - loss: 1.8614 - accuracy: 0.54 - ETA: 4:40 - loss: 1.8399 - accuracy: 0.54 - ETA: 4:38 - loss: 1.8627 - accuracy: 0.54 - ETA: 4:35 - loss: 1.8563 - accuracy: 0.53 - ETA: 4:33 - loss: 1.8602 - accuracy: 0.53 - ETA: 4:30 - loss: 1.8465 - accuracy: 0.54 - ETA: 4:28 - loss: 1.8466 - accuracy: 0.54 - ETA: 4:26 - loss: 1.8508 - accuracy: 0.53 - ETA: 4:24 - loss: 1.8530 - accuracy: 0.53 - ETA: 4:22 - loss: 1.8592 - accuracy: 0.53 - ETA: 4:19 - loss: 1.8646 - accuracy: 0.53 - ETA: 4:17 - loss: 1.8888 - accuracy: 0.53 - ETA: 4:15 - loss: 1.8942 - accuracy: 0.53 - ETA: 4:12 - loss: 1.9081 - accuracy: 0.53 - ETA: 4:10 - loss: 1.9111 - accuracy: 0.53 - ETA: 4:08 - loss: 1.9036 - accuracy: 0.53 - ETA: 4:06 - loss: 1.8997 - accuracy: 0.53 - ETA: 4:04 - loss: 1.8926 - accuracy: 0.53 - ETA: 4:02 - loss: 1.8846 - accuracy: 0.53 - ETA: 4:00 - loss: 1.8836 - accuracy: 0.53 - ETA: 3:57 - loss: 1.8742 - accuracy: 0.54 - ETA: 3:55 - loss: 1.8688 - accuracy: 0.53 - ETA: 3:53 - loss: 1.8650 - accuracy: 0.53 - ETA: 3:51 - loss: 1.8608 - accuracy: 0.54 - ETA: 3:49 - loss: 1.8602 - accuracy: 0.54 - ETA: 3:47 - loss: 1.8497 - accuracy: 0.54 - ETA: 3:45 - loss: 1.8509 - accuracy: 0.54 - ETA: 3:43 - loss: 1.8554 - accuracy: 0.54 - ETA: 3:41 - loss: 1.8546 - accuracy: 0.53 - ETA: 3:39 - loss: 1.8549 - accuracy: 0.53 - ETA: 3:36 - loss: 1.8602 - accuracy: 0.53 - ETA: 3:34 - loss: 1.8560 - accuracy: 0.53 - ETA: 3:32 - loss: 1.8487 - accuracy: 0.53 - ETA: 3:30 - loss: 1.8501 - accuracy: 0.54 - ETA: 3:28 - loss: 1.8512 - accuracy: 0.53 - ETA: 3:26 - loss: 1.8520 - accuracy: 0.53 - ETA: 3:24 - loss: 1.8503 - accuracy: 0.53 - ETA: 3:21 - loss: 1.8461 - accuracy: 0.53 - ETA: 3:19 - loss: 1.8417 - accuracy: 0.54 - ETA: 3:17 - loss: 1.8361 - accuracy: 0.54 - ETA: 3:15 - loss: 1.8388 - accuracy: 0.54 - ETA: 3:13 - loss: 1.8552 - accuracy: 0.54 - ETA: 3:11 - loss: 1.8591 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8515 - accuracy: 0.54 - ETA: 3:06 - loss: 1.8495 - accuracy: 0.54 - ETA: 3:04 - loss: 1.8528 - accuracy: 0.54 - ETA: 3:02 - loss: 1.8496 - accuracy: 0.54 - ETA: 3:00 - loss: 1.8504 - accuracy: 0.54 - ETA: 2:58 - loss: 1.8549 - accuracy: 0.54 - ETA: 2:56 - loss: 1.8535 - accuracy: 0.54 - ETA: 2:54 - loss: 1.8525 - accuracy: 0.54 - ETA: 2:52 - loss: 1.8546 - accuracy: 0.54 - ETA: 2:50 - loss: 1.8482 - accuracy: 0.54 - ETA: 2:47 - loss: 1.8437 - accuracy: 0.54 - ETA: 2:45 - loss: 1.8421 - accuracy: 0.54 - ETA: 2:43 - loss: 1.8404 - accuracy: 0.54 - ETA: 2:41 - loss: 1.8361 - accuracy: 0.54 - ETA: 2:39 - loss: 1.8331 - accuracy: 0.54 - ETA: 2:37 - loss: 1.8323 - accuracy: 0.54 - ETA: 2:35 - loss: 1.8303 - accuracy: 0.54 - ETA: 2:32 - loss: 1.8300 - accuracy: 0.54 - ETA: 2:30 - loss: 1.8310 - accuracy: 0.54 - ETA: 2:28 - loss: 1.8417 - accuracy: 0.54 - ETA: 2:26 - loss: 1.8386 - accuracy: 0.54 - ETA: 2:24 - loss: 1.8456 - accuracy: 0.54 - ETA: 2:22 - loss: 1.8400 - accuracy: 0.54 - ETA: 2:20 - loss: 1.8388 - accuracy: 0.54 - ETA: 2:18 - loss: 1.8356 - accuracy: 0.54 - ETA: 2:15 - loss: 1.8348 - accuracy: 0.54 - ETA: 2:13 - loss: 1.8335 - accuracy: 0.54 - ETA: 2:11 - loss: 1.8313 - accuracy: 0.54 - ETA: 2:09 - loss: 1.8289 - accuracy: 0.54 - ETA: 2:07 - loss: 1.8279 - accuracy: 0.54 - ETA: 2:05 - loss: 1.8287 - accuracy: 0.54 - ETA: 2:03 - loss: 1.8280 - accuracy: 0.54 - ETA: 2:01 - loss: 1.8275 - accuracy: 0.54 - ETA: 1:59 - loss: 1.8307 - accuracy: 0.54 - ETA: 1:56 - loss: 1.8320 - accuracy: 0.54 - ETA: 1:54 - loss: 1.8304 - accuracy: 0.54 - ETA: 1:52 - loss: 1.8290 - accuracy: 0.54 - ETA: 1:50 - loss: 1.8317 - accuracy: 0.54 - ETA: 1:48 - loss: 1.8306 - accuracy: 0.54 - ETA: 1:46 - loss: 1.8291 - accuracy: 0.54 - ETA: 1:44 - loss: 1.8271 - accuracy: 0.54 - ETA: 1:41 - loss: 1.8252 - accuracy: 0.54 - ETA: 1:39 - loss: 1.8229 - accuracy: 0.54 - ETA: 1:37 - loss: 1.8227 - accuracy: 0.54 - ETA: 1:35 - loss: 1.8216 - accuracy: 0.54 - ETA: 1:33 - loss: 1.8268 - accuracy: 0.54 - ETA: 1:31 - loss: 1.8249 - accuracy: 0.54 - ETA: 1:29 - loss: 1.8260 - accuracy: 0.54 - ETA: 1:26 - loss: 1.8270 - accuracy: 0.54 - ETA: 1:24 - loss: 1.8289 - accuracy: 0.54 - ETA: 1:22 - loss: 1.8315 - accuracy: 0.54 - ETA: 1:20 - loss: 1.8284 - accuracy: 0.54 - ETA: 1:18 - loss: 1.8312 - accuracy: 0.54 - ETA: 1:16 - loss: 1.8282 - accuracy: 0.54 - ETA: 1:14 - loss: 1.8301 - accuracy: 0.54 - ETA: 1:12 - loss: 1.8510 - accuracy: 0.54 - ETA: 1:09 - loss: 1.8481 - accuracy: 0.54 - ETA: 1:07 - loss: 1.8484 - accuracy: 0.54 - ETA: 1:05 - loss: 1.8461 - accuracy: 0.54 - ETA: 1:03 - loss: 1.8464 - accuracy: 0.54 - ETA: 1:01 - loss: 1.8461 - accuracy: 0.54 - ETA: 59s - loss: 1.8453 - accuracy: 0.5443 - ETA: 57s - loss: 1.8460 - accuracy: 0.544 - ETA: 55s - loss: 1.8475 - accuracy: 0.543 - ETA: 52s - loss: 1.8481 - accuracy: 0.543 - ETA: 50s - loss: 1.8457 - accuracy: 0.543 - ETA: 48s - loss: 1.8470 - accuracy: 0.543 - ETA: 46s - loss: 1.8488 - accuracy: 0.543 - ETA: 44s - loss: 1.8466 - accuracy: 0.543 - ETA: 42s - loss: 1.8458 - accuracy: 0.543 - ETA: 40s - loss: 1.8487 - accuracy: 0.542 - ETA: 38s - loss: 1.8472 - accuracy: 0.543 - ETA: 35s - loss: 1.8454 - accuracy: 0.543 - ETA: 33s - loss: 1.8434 - accuracy: 0.543 - ETA: 31s - loss: 1.8413 - accuracy: 0.543 - ETA: 29s - loss: 1.8403 - accuracy: 0.543 - ETA: 27s - loss: 1.8384 - accuracy: 0.543 - ETA: 25s - loss: 1.8375 - accuracy: 0.543 - ETA: 23s - loss: 1.8350 - accuracy: 0.543 - ETA: 20s - loss: 1.8379 - accuracy: 0.543 - ETA: 18s - loss: 1.8366 - accuracy: 0.544 - ETA: 16s - loss: 1.8370 - accuracy: 0.543 - ETA: 14s - loss: 1.8351 - accuracy: 0.543 - ETA: 12s - loss: 1.8363 - accuracy: 0.543 - ETA: 10s - loss: 1.8345 - accuracy: 0.543 - ETA: 8s - loss: 1.8333 - accuracy: 0.543 - ETA: 6s - loss: 1.8340 - accuracy: 0.54 - ETA: 3s - loss: 1.8318 - accuracy: 0.54 - ETA: 1s - loss: 1.8305 - accuracy: 0.54 - 345s 18ms/step - loss: 1.8302 - accuracy: 0.5436 - val_loss: 1.8324 - val_accuracy: 0.6014\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:51 - loss: 1.9060 - accuracy: 0.48 - ETA: 5:37 - loss: 1.7760 - accuracy: 0.51 - ETA: 5:25 - loss: 1.7324 - accuracy: 0.55 - ETA: 5:17 - loss: 1.6790 - accuracy: 0.57 - ETA: 5:14 - loss: 1.6508 - accuracy: 0.57 - ETA: 5:14 - loss: 1.6536 - accuracy: 0.57 - ETA: 5:09 - loss: 1.6213 - accuracy: 0.57 - ETA: 5:06 - loss: 1.6492 - accuracy: 0.57 - ETA: 5:05 - loss: 1.6306 - accuracy: 0.57 - ETA: 5:02 - loss: 1.6078 - accuracy: 0.57 - ETA: 4:59 - loss: 1.6013 - accuracy: 0.57 - ETA: 4:57 - loss: 1.6148 - accuracy: 0.56 - ETA: 4:55 - loss: 1.6859 - accuracy: 0.57 - ETA: 4:51 - loss: 1.6689 - accuracy: 0.57 - ETA: 4:50 - loss: 1.6741 - accuracy: 0.57 - ETA: 4:47 - loss: 1.6793 - accuracy: 0.57 - ETA: 4:45 - loss: 1.7072 - accuracy: 0.56 - ETA: 4:42 - loss: 1.7421 - accuracy: 0.56 - ETA: 4:40 - loss: 1.7524 - accuracy: 0.55 - ETA: 4:38 - loss: 1.7502 - accuracy: 0.55 - ETA: 4:36 - loss: 1.7717 - accuracy: 0.55 - ETA: 4:34 - loss: 1.7701 - accuracy: 0.55 - ETA: 4:32 - loss: 1.7692 - accuracy: 0.55 - ETA: 4:30 - loss: 1.7828 - accuracy: 0.54 - ETA: 4:28 - loss: 1.8067 - accuracy: 0.54 - ETA: 4:26 - loss: 1.8078 - accuracy: 0.54 - ETA: 4:24 - loss: 1.7932 - accuracy: 0.54 - ETA: 4:22 - loss: 1.7960 - accuracy: 0.54 - ETA: 4:20 - loss: 1.7829 - accuracy: 0.54 - ETA: 4:18 - loss: 1.7795 - accuracy: 0.54 - ETA: 4:16 - loss: 1.7779 - accuracy: 0.54 - ETA: 4:14 - loss: 1.7853 - accuracy: 0.54 - ETA: 4:12 - loss: 1.7780 - accuracy: 0.54 - ETA: 4:10 - loss: 1.7677 - accuracy: 0.54 - ETA: 4:08 - loss: 1.7697 - accuracy: 0.54 - ETA: 4:06 - loss: 1.7557 - accuracy: 0.54 - ETA: 4:04 - loss: 1.7470 - accuracy: 0.54 - ETA: 4:02 - loss: 1.7538 - accuracy: 0.54 - ETA: 3:59 - loss: 1.7594 - accuracy: 0.54 - ETA: 3:57 - loss: 1.7550 - accuracy: 0.54 - ETA: 3:55 - loss: 1.7510 - accuracy: 0.54 - ETA: 3:52 - loss: 1.7530 - accuracy: 0.54 - ETA: 3:51 - loss: 1.7506 - accuracy: 0.54 - ETA: 3:48 - loss: 1.7501 - accuracy: 0.54 - ETA: 3:46 - loss: 1.7534 - accuracy: 0.54 - ETA: 3:44 - loss: 1.7623 - accuracy: 0.54 - ETA: 3:42 - loss: 1.7637 - accuracy: 0.54 - ETA: 3:40 - loss: 1.7619 - accuracy: 0.54 - ETA: 3:37 - loss: 1.7620 - accuracy: 0.54 - ETA: 3:35 - loss: 1.7613 - accuracy: 0.54 - ETA: 3:33 - loss: 1.7588 - accuracy: 0.54 - ETA: 3:31 - loss: 1.7589 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7591 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7577 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7600 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7532 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7516 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7494 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7514 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7489 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7519 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7539 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7561 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7586 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7561 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7566 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7570 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7571 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7563 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7585 - accuracy: 0.54 - ETA: 2:51 - loss: 1.7563 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7584 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7585 - accuracy: 0.54 - ETA: 2:44 - loss: 1.7608 - accuracy: 0.54 - ETA: 2:42 - loss: 1.7625 - accuracy: 0.54 - ETA: 2:40 - loss: 1.7601 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7620 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7689 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7754 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7803 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7813 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7794 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7830 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7812 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7843 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7879 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7915 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7919 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7934 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7913 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7894 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7916 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7900 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7941 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7932 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7942 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7928 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7917 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7885 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7908 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7879 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7882 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7885 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7867 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7866 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7945 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7938 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7944 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7939 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7931 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7927 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7914 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7880 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7878 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7879 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7884 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7854 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7832 - accuracy: 0.54 - ETA: 1:08 - loss: 1.7827 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7814 - accuracy: 0.54 - ETA: 1:04 - loss: 1.7823 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7800 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7825 - accuracy: 0.54 - ETA: 58s - loss: 1.7801 - accuracy: 0.5435 - ETA: 55s - loss: 1.7805 - accuracy: 0.543 - ETA: 53s - loss: 1.7793 - accuracy: 0.543 - ETA: 51s - loss: 1.7814 - accuracy: 0.543 - ETA: 48s - loss: 1.7825 - accuracy: 0.542 - ETA: 46s - loss: 1.7828 - accuracy: 0.542 - ETA: 44s - loss: 1.7811 - accuracy: 0.542 - ETA: 42s - loss: 1.7835 - accuracy: 0.542 - ETA: 40s - loss: 1.7836 - accuracy: 0.543 - ETA: 37s - loss: 1.7847 - accuracy: 0.542 - ETA: 35s - loss: 1.7835 - accuracy: 0.543 - ETA: 33s - loss: 1.7827 - accuracy: 0.543 - ETA: 31s - loss: 1.7855 - accuracy: 0.542 - ETA: 29s - loss: 1.7874 - accuracy: 0.542 - ETA: 26s - loss: 1.7883 - accuracy: 0.542 - ETA: 24s - loss: 1.7868 - accuracy: 0.542 - ETA: 22s - loss: 1.7924 - accuracy: 0.542 - ETA: 20s - loss: 1.7954 - accuracy: 0.541 - ETA: 18s - loss: 1.8009 - accuracy: 0.540 - ETA: 16s - loss: 1.7987 - accuracy: 0.540 - ETA: 14s - loss: 1.7983 - accuracy: 0.540 - ETA: 12s - loss: 1.7966 - accuracy: 0.540 - ETA: 9s - loss: 1.7964 - accuracy: 0.540 - ETA: 7s - loss: 1.8017 - accuracy: 0.54 - ETA: 5s - loss: 1.8005 - accuracy: 0.54 - ETA: 3s - loss: 1.8000 - accuracy: 0.54 - ETA: 1s - loss: 1.8010 - accuracy: 0.54 - 320s 17ms/step - loss: 1.8004 - accuracy: 0.5418 - val_loss: 1.9782 - val_accuracy: 0.5949\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:33 - loss: 1.4109 - accuracy: 0.63 - ETA: 3:23 - loss: 1.6874 - accuracy: 0.57 - ETA: 3:26 - loss: 1.8355 - accuracy: 0.54 - ETA: 3:27 - loss: 1.8292 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7767 - accuracy: 0.55 - ETA: 3:20 - loss: 1.7643 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7536 - accuracy: 0.54 - ETA: 3:15 - loss: 1.8546 - accuracy: 0.53 - ETA: 3:13 - loss: 1.8354 - accuracy: 0.53 - ETA: 3:11 - loss: 1.8279 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7929 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7949 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7958 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7888 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7733 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7779 - accuracy: 0.54 - ETA: 3:01 - loss: 1.8195 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8156 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8297 - accuracy: 0.53 - ETA: 2:57 - loss: 1.9625 - accuracy: 0.53 - ETA: 2:55 - loss: 1.9538 - accuracy: 0.53 - ETA: 2:53 - loss: 1.9586 - accuracy: 0.53 - ETA: 2:52 - loss: 1.9486 - accuracy: 0.53 - ETA: 2:51 - loss: 1.9799 - accuracy: 0.53 - ETA: 2:49 - loss: 1.9777 - accuracy: 0.53 - ETA: 2:48 - loss: 1.9706 - accuracy: 0.53 - ETA: 2:47 - loss: 1.9568 - accuracy: 0.53 - ETA: 2:46 - loss: 1.9451 - accuracy: 0.53 - ETA: 2:44 - loss: 1.9443 - accuracy: 0.53 - ETA: 2:43 - loss: 1.9230 - accuracy: 0.53 - ETA: 2:42 - loss: 1.9121 - accuracy: 0.53 - ETA: 2:40 - loss: 1.9128 - accuracy: 0.53 - ETA: 2:39 - loss: 1.9166 - accuracy: 0.53 - ETA: 2:37 - loss: 1.9087 - accuracy: 0.53 - ETA: 2:36 - loss: 1.9095 - accuracy: 0.53 - ETA: 2:35 - loss: 1.9168 - accuracy: 0.53 - ETA: 2:33 - loss: 1.9102 - accuracy: 0.53 - ETA: 2:32 - loss: 1.9063 - accuracy: 0.53 - ETA: 2:31 - loss: 1.9031 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8957 - accuracy: 0.53 - ETA: 2:28 - loss: 1.9141 - accuracy: 0.53 - ETA: 2:27 - loss: 1.9095 - accuracy: 0.53 - ETA: 2:26 - loss: 1.9025 - accuracy: 0.53 - ETA: 2:24 - loss: 1.9031 - accuracy: 0.53 - ETA: 2:23 - loss: 1.9087 - accuracy: 0.53 - ETA: 2:21 - loss: 1.9142 - accuracy: 0.52 - ETA: 2:20 - loss: 1.9183 - accuracy: 0.53 - ETA: 2:19 - loss: 1.9143 - accuracy: 0.53 - ETA: 2:17 - loss: 1.9101 - accuracy: 0.53 - ETA: 2:16 - loss: 1.9132 - accuracy: 0.53 - ETA: 2:15 - loss: 1.9166 - accuracy: 0.53 - ETA: 2:14 - loss: 1.9271 - accuracy: 0.53 - ETA: 2:12 - loss: 1.9159 - accuracy: 0.53 - ETA: 2:11 - loss: 1.9324 - accuracy: 0.53 - ETA: 2:09 - loss: 1.9303 - accuracy: 0.53 - ETA: 2:08 - loss: 1.9280 - accuracy: 0.53 - ETA: 2:07 - loss: 1.9275 - accuracy: 0.53 - ETA: 2:05 - loss: 1.9208 - accuracy: 0.53 - ETA: 2:04 - loss: 1.9213 - accuracy: 0.53 - ETA: 2:02 - loss: 1.9153 - accuracy: 0.53 - ETA: 2:01 - loss: 1.9130 - accuracy: 0.53 - ETA: 2:00 - loss: 1.9126 - accuracy: 0.53 - ETA: 1:59 - loss: 1.9148 - accuracy: 0.53 - ETA: 1:57 - loss: 1.9138 - accuracy: 0.53 - ETA: 1:56 - loss: 1.9153 - accuracy: 0.53 - ETA: 1:54 - loss: 1.9107 - accuracy: 0.53 - ETA: 1:53 - loss: 1.9101 - accuracy: 0.53 - ETA: 1:52 - loss: 1.9059 - accuracy: 0.53 - ETA: 1:50 - loss: 1.9022 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8989 - accuracy: 0.53 - ETA: 1:48 - loss: 1.9005 - accuracy: 0.53 - ETA: 1:46 - loss: 1.9011 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8981 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8978 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8957 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8983 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8998 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8986 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8993 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8939 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8888 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8833 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8878 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8869 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8859 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8825 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8788 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8820 - accuracy: 0.53 - ETA: 1:23 - loss: 1.8774 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8777 - accuracy: 0.53 - ETA: 1:21 - loss: 1.8744 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8735 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8729 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8692 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8697 - accuracy: 0.53 - ETA: 1:14 - loss: 1.8780 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8748 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8760 - accuracy: 0.53 - ETA: 1:10 - loss: 1.8758 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8749 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8752 - accuracy: 0.53 - ETA: 1:06 - loss: 1.8712 - accuracy: 0.53 - ETA: 1:04 - loss: 1.8780 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8736 - accuracy: 0.53 - ETA: 1:02 - loss: 1.8737 - accuracy: 0.53 - ETA: 1:00 - loss: 1.8704 - accuracy: 0.53 - ETA: 59s - loss: 1.8728 - accuracy: 0.5363 - ETA: 58s - loss: 1.8736 - accuracy: 0.535 - ETA: 56s - loss: 1.8709 - accuracy: 0.536 - ETA: 55s - loss: 1.8709 - accuracy: 0.535 - ETA: 54s - loss: 1.8699 - accuracy: 0.535 - ETA: 52s - loss: 1.8650 - accuracy: 0.536 - ETA: 51s - loss: 1.8657 - accuracy: 0.535 - ETA: 50s - loss: 1.8655 - accuracy: 0.535 - ETA: 48s - loss: 1.8652 - accuracy: 0.535 - ETA: 47s - loss: 1.8631 - accuracy: 0.536 - ETA: 45s - loss: 1.8641 - accuracy: 0.536 - ETA: 44s - loss: 1.8636 - accuracy: 0.537 - ETA: 43s - loss: 1.8646 - accuracy: 0.537 - ETA: 41s - loss: 1.8635 - accuracy: 0.537 - ETA: 40s - loss: 1.8615 - accuracy: 0.537 - ETA: 39s - loss: 1.8605 - accuracy: 0.538 - ETA: 37s - loss: 1.8607 - accuracy: 0.537 - ETA: 36s - loss: 1.8636 - accuracy: 0.537 - ETA: 35s - loss: 1.8635 - accuracy: 0.537 - ETA: 33s - loss: 1.8621 - accuracy: 0.537 - ETA: 32s - loss: 1.8667 - accuracy: 0.536 - ETA: 31s - loss: 1.8663 - accuracy: 0.536 - ETA: 29s - loss: 1.8660 - accuracy: 0.536 - ETA: 28s - loss: 1.8662 - accuracy: 0.536 - ETA: 26s - loss: 1.8657 - accuracy: 0.537 - ETA: 25s - loss: 1.8646 - accuracy: 0.537 - ETA: 24s - loss: 1.8634 - accuracy: 0.537 - ETA: 22s - loss: 1.8620 - accuracy: 0.537 - ETA: 21s - loss: 1.8622 - accuracy: 0.537 - ETA: 20s - loss: 1.8629 - accuracy: 0.537 - ETA: 18s - loss: 1.8621 - accuracy: 0.537 - ETA: 17s - loss: 1.8579 - accuracy: 0.538 - ETA: 16s - loss: 1.8601 - accuracy: 0.538 - ETA: 14s - loss: 1.8621 - accuracy: 0.538 - ETA: 13s - loss: 1.8632 - accuracy: 0.537 - ETA: 12s - loss: 1.8641 - accuracy: 0.537 - ETA: 10s - loss: 1.8627 - accuracy: 0.537 - ETA: 9s - loss: 1.8613 - accuracy: 0.537 - ETA: 8s - loss: 1.8679 - accuracy: 0.53 - ETA: 6s - loss: 1.8652 - accuracy: 0.53 - ETA: 5s - loss: 1.8631 - accuracy: 0.53 - ETA: 3s - loss: 1.8634 - accuracy: 0.53 - ETA: 2s - loss: 1.8654 - accuracy: 0.53 - ETA: 1s - loss: 1.8683 - accuracy: 0.53 - 225s 12ms/step - loss: 1.8679 - accuracy: 0.5373 - val_loss: 1.8493 - val_accuracy: 0.5865\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:33 - loss: 1.8069 - accuracy: 0.50 - ETA: 3:26 - loss: 1.6606 - accuracy: 0.53 - ETA: 3:29 - loss: 1.6986 - accuracy: 0.52 - ETA: 3:29 - loss: 1.6685 - accuracy: 0.53 - ETA: 3:26 - loss: 1.7338 - accuracy: 0.51 - ETA: 3:22 - loss: 1.7172 - accuracy: 0.53 - ETA: 3:20 - loss: 1.6657 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7223 - accuracy: 0.53 - ETA: 3:17 - loss: 1.7339 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7492 - accuracy: 0.53 - ETA: 3:13 - loss: 1.7309 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7471 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7296 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7293 - accuracy: 0.55 - ETA: 3:08 - loss: 1.7094 - accuracy: 0.55 - ETA: 3:06 - loss: 1.7093 - accuracy: 0.55 - ETA: 3:04 - loss: 1.7278 - accuracy: 0.55 - ETA: 3:02 - loss: 1.7176 - accuracy: 0.55 - ETA: 3:00 - loss: 1.7006 - accuracy: 0.55 - ETA: 2:59 - loss: 1.7346 - accuracy: 0.55 - ETA: 2:57 - loss: 1.7391 - accuracy: 0.55 - ETA: 2:56 - loss: 1.7465 - accuracy: 0.55 - ETA: 2:54 - loss: 1.7819 - accuracy: 0.54 - ETA: 2:53 - loss: 1.8028 - accuracy: 0.54 - ETA: 2:51 - loss: 1.8119 - accuracy: 0.54 - ETA: 2:50 - loss: 1.8149 - accuracy: 0.54 - ETA: 2:49 - loss: 1.8077 - accuracy: 0.54 - ETA: 2:47 - loss: 1.8100 - accuracy: 0.54 - ETA: 2:45 - loss: 1.8120 - accuracy: 0.54 - ETA: 2:44 - loss: 1.8532 - accuracy: 0.54 - ETA: 2:42 - loss: 1.8469 - accuracy: 0.54 - ETA: 2:41 - loss: 1.8510 - accuracy: 0.54 - ETA: 2:39 - loss: 1.8547 - accuracy: 0.54 - ETA: 2:38 - loss: 1.8453 - accuracy: 0.54 - ETA: 2:36 - loss: 1.8334 - accuracy: 0.54 - ETA: 2:35 - loss: 1.8213 - accuracy: 0.54 - ETA: 2:33 - loss: 1.8148 - accuracy: 0.54 - ETA: 2:32 - loss: 1.8205 - accuracy: 0.54 - ETA: 2:31 - loss: 1.8189 - accuracy: 0.54 - ETA: 2:30 - loss: 1.8167 - accuracy: 0.54 - ETA: 2:28 - loss: 1.8189 - accuracy: 0.54 - ETA: 2:27 - loss: 1.8180 - accuracy: 0.54 - ETA: 2:25 - loss: 1.8296 - accuracy: 0.54 - ETA: 2:24 - loss: 1.8351 - accuracy: 0.54 - ETA: 2:22 - loss: 1.8287 - accuracy: 0.54 - ETA: 2:21 - loss: 1.8389 - accuracy: 0.54 - ETA: 2:20 - loss: 1.8354 - accuracy: 0.54 - ETA: 2:18 - loss: 1.8558 - accuracy: 0.54 - ETA: 2:17 - loss: 1.8644 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8735 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8706 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8742 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8675 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8667 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8609 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8586 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8564 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8549 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8549 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8504 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8479 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8504 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8540 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8540 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8491 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8455 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8445 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8433 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8399 - accuracy: 0.54 - ETA: 1:50 - loss: 1.8394 - accuracy: 0.54 - ETA: 1:48 - loss: 1.8352 - accuracy: 0.54 - ETA: 1:47 - loss: 1.8440 - accuracy: 0.53 - ETA: 1:45 - loss: 1.9235 - accuracy: 0.53 - ETA: 1:44 - loss: 1.9212 - accuracy: 0.53 - ETA: 1:43 - loss: 1.9280 - accuracy: 0.53 - ETA: 1:41 - loss: 1.9257 - accuracy: 0.53 - ETA: 1:40 - loss: 1.9238 - accuracy: 0.53 - ETA: 1:39 - loss: 1.9255 - accuracy: 0.53 - ETA: 1:37 - loss: 1.9255 - accuracy: 0.53 - ETA: 1:36 - loss: 1.9274 - accuracy: 0.53 - ETA: 1:35 - loss: 1.9282 - accuracy: 0.53 - ETA: 1:33 - loss: 1.9257 - accuracy: 0.53 - ETA: 1:32 - loss: 1.9245 - accuracy: 0.53 - ETA: 1:30 - loss: 1.9282 - accuracy: 0.53 - ETA: 1:29 - loss: 1.9219 - accuracy: 0.53 - ETA: 1:28 - loss: 1.9219 - accuracy: 0.53 - ETA: 1:26 - loss: 1.9214 - accuracy: 0.53 - ETA: 1:25 - loss: 1.9166 - accuracy: 0.53 - ETA: 1:24 - loss: 1.9187 - accuracy: 0.53 - ETA: 1:22 - loss: 1.9118 - accuracy: 0.53 - ETA: 1:21 - loss: 1.9119 - accuracy: 0.53 - ETA: 1:20 - loss: 1.9104 - accuracy: 0.53 - ETA: 1:18 - loss: 1.9132 - accuracy: 0.53 - ETA: 1:17 - loss: 1.9089 - accuracy: 0.53 - ETA: 1:15 - loss: 1.9113 - accuracy: 0.53 - ETA: 1:14 - loss: 1.9097 - accuracy: 0.53 - ETA: 1:13 - loss: 1.9125 - accuracy: 0.53 - ETA: 1:11 - loss: 1.9110 - accuracy: 0.53 - ETA: 1:10 - loss: 1.9142 - accuracy: 0.53 - ETA: 1:09 - loss: 1.9153 - accuracy: 0.53 - ETA: 1:07 - loss: 1.9121 - accuracy: 0.53 - ETA: 1:06 - loss: 1.9064 - accuracy: 0.53 - ETA: 1:05 - loss: 1.9059 - accuracy: 0.53 - ETA: 1:03 - loss: 1.9037 - accuracy: 0.53 - ETA: 1:02 - loss: 1.9042 - accuracy: 0.53 - ETA: 1:01 - loss: 1.9018 - accuracy: 0.53 - ETA: 59s - loss: 1.9035 - accuracy: 0.5375 - ETA: 58s - loss: 1.9025 - accuracy: 0.537 - ETA: 56s - loss: 1.8992 - accuracy: 0.537 - ETA: 55s - loss: 1.8974 - accuracy: 0.538 - ETA: 54s - loss: 1.8966 - accuracy: 0.538 - ETA: 53s - loss: 1.8947 - accuracy: 0.537 - ETA: 51s - loss: 1.9004 - accuracy: 0.537 - ETA: 50s - loss: 1.8994 - accuracy: 0.537 - ETA: 48s - loss: 1.9006 - accuracy: 0.536 - ETA: 47s - loss: 1.9012 - accuracy: 0.536 - ETA: 46s - loss: 1.9019 - accuracy: 0.536 - ETA: 44s - loss: 1.8986 - accuracy: 0.536 - ETA: 43s - loss: 1.8956 - accuracy: 0.536 - ETA: 42s - loss: 1.8947 - accuracy: 0.536 - ETA: 40s - loss: 1.8913 - accuracy: 0.536 - ETA: 39s - loss: 1.8881 - accuracy: 0.537 - ETA: 37s - loss: 1.8877 - accuracy: 0.537 - ETA: 36s - loss: 1.8861 - accuracy: 0.537 - ETA: 35s - loss: 1.8859 - accuracy: 0.537 - ETA: 33s - loss: 1.8835 - accuracy: 0.536 - ETA: 32s - loss: 1.8795 - accuracy: 0.537 - ETA: 31s - loss: 1.8801 - accuracy: 0.536 - ETA: 29s - loss: 1.8806 - accuracy: 0.536 - ETA: 28s - loss: 1.8807 - accuracy: 0.536 - ETA: 27s - loss: 1.8787 - accuracy: 0.536 - ETA: 25s - loss: 1.8771 - accuracy: 0.536 - ETA: 24s - loss: 1.8744 - accuracy: 0.537 - ETA: 22s - loss: 1.8765 - accuracy: 0.537 - ETA: 21s - loss: 1.8746 - accuracy: 0.537 - ETA: 20s - loss: 1.8713 - accuracy: 0.538 - ETA: 18s - loss: 1.8697 - accuracy: 0.538 - ETA: 17s - loss: 1.8679 - accuracy: 0.538 - ETA: 16s - loss: 1.8674 - accuracy: 0.538 - ETA: 14s - loss: 1.8682 - accuracy: 0.538 - ETA: 13s - loss: 1.8686 - accuracy: 0.538 - ETA: 12s - loss: 1.8683 - accuracy: 0.538 - ETA: 10s - loss: 1.8668 - accuracy: 0.538 - ETA: 9s - loss: 1.8657 - accuracy: 0.538 - ETA: 8s - loss: 1.8666 - accuracy: 0.53 - ETA: 6s - loss: 1.8662 - accuracy: 0.53 - ETA: 5s - loss: 1.8701 - accuracy: 0.53 - ETA: 3s - loss: 1.8690 - accuracy: 0.53 - ETA: 2s - loss: 1.8678 - accuracy: 0.53 - ETA: 1s - loss: 1.8696 - accuracy: 0.53 - 220s 11ms/step - loss: 1.8697 - accuracy: 0.5376 - val_loss: 1.9272 - val_accuracy: 0.5898\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:39 - loss: 1.9490 - accuracy: 0.49 - ETA: 3:35 - loss: 1.8602 - accuracy: 0.52 - ETA: 3:32 - loss: 1.9799 - accuracy: 0.54 - ETA: 3:28 - loss: 1.8495 - accuracy: 0.55 - ETA: 3:25 - loss: 1.7934 - accuracy: 0.56 - ETA: 3:23 - loss: 1.8707 - accuracy: 0.55 - ETA: 3:20 - loss: 1.8514 - accuracy: 0.55 - ETA: 3:19 - loss: 1.8571 - accuracy: 0.55 - ETA: 3:16 - loss: 1.8280 - accuracy: 0.55 - ETA: 3:14 - loss: 1.7987 - accuracy: 0.56 - ETA: 3:11 - loss: 1.8737 - accuracy: 0.56 - ETA: 3:09 - loss: 1.8649 - accuracy: 0.55 - ETA: 3:07 - loss: 1.8509 - accuracy: 0.55 - ETA: 3:05 - loss: 1.8726 - accuracy: 0.54 - ETA: 3:04 - loss: 1.9332 - accuracy: 0.53 - ETA: 3:03 - loss: 1.9427 - accuracy: 0.54 - ETA: 3:02 - loss: 1.9198 - accuracy: 0.54 - ETA: 3:01 - loss: 1.8923 - accuracy: 0.54 - ETA: 3:00 - loss: 1.8962 - accuracy: 0.54 - ETA: 2:58 - loss: 1.8824 - accuracy: 0.54 - ETA: 2:56 - loss: 1.8857 - accuracy: 0.54 - ETA: 2:55 - loss: 1.8665 - accuracy: 0.54 - ETA: 2:54 - loss: 1.8733 - accuracy: 0.54 - ETA: 2:52 - loss: 1.8844 - accuracy: 0.54 - ETA: 2:50 - loss: 1.8765 - accuracy: 0.54 - ETA: 2:49 - loss: 1.8652 - accuracy: 0.54 - ETA: 2:47 - loss: 1.8677 - accuracy: 0.54 - ETA: 2:46 - loss: 1.8544 - accuracy: 0.55 - ETA: 2:44 - loss: 1.8507 - accuracy: 0.54 - ETA: 2:43 - loss: 1.8617 - accuracy: 0.54 - ETA: 2:42 - loss: 1.8566 - accuracy: 0.54 - ETA: 2:40 - loss: 1.8698 - accuracy: 0.54 - ETA: 2:39 - loss: 1.8810 - accuracy: 0.54 - ETA: 2:37 - loss: 1.8744 - accuracy: 0.55 - ETA: 2:36 - loss: 1.8798 - accuracy: 0.54 - ETA: 2:34 - loss: 1.8818 - accuracy: 0.54 - ETA: 2:33 - loss: 1.9467 - accuracy: 0.54 - ETA: 2:31 - loss: 1.9345 - accuracy: 0.54 - ETA: 2:30 - loss: 1.9425 - accuracy: 0.54 - ETA: 2:28 - loss: 1.9315 - accuracy: 0.54 - ETA: 2:27 - loss: 1.9214 - accuracy: 0.54 - ETA: 2:26 - loss: 1.9186 - accuracy: 0.54 - ETA: 2:25 - loss: 1.9173 - accuracy: 0.54 - ETA: 2:23 - loss: 1.9126 - accuracy: 0.54 - ETA: 2:22 - loss: 1.9069 - accuracy: 0.54 - ETA: 2:20 - loss: 1.9080 - accuracy: 0.54 - ETA: 2:19 - loss: 1.9039 - accuracy: 0.54 - ETA: 2:17 - loss: 1.9055 - accuracy: 0.54 - ETA: 2:16 - loss: 1.9006 - accuracy: 0.54 - ETA: 2:14 - loss: 1.9055 - accuracy: 0.54 - ETA: 2:13 - loss: 1.9075 - accuracy: 0.54 - ETA: 2:12 - loss: 1.9160 - accuracy: 0.54 - ETA: 2:10 - loss: 1.9136 - accuracy: 0.54 - ETA: 2:09 - loss: 1.9107 - accuracy: 0.54 - ETA: 2:08 - loss: 1.9135 - accuracy: 0.54 - ETA: 2:07 - loss: 1.9120 - accuracy: 0.54 - ETA: 2:05 - loss: 1.9034 - accuracy: 0.54 - ETA: 2:04 - loss: 1.8946 - accuracy: 0.54 - ETA: 2:02 - loss: 1.8926 - accuracy: 0.54 - ETA: 2:01 - loss: 1.8900 - accuracy: 0.54 - ETA: 2:00 - loss: 1.8839 - accuracy: 0.54 - ETA: 1:58 - loss: 1.8839 - accuracy: 0.54 - ETA: 1:57 - loss: 1.8859 - accuracy: 0.54 - ETA: 1:56 - loss: 1.8805 - accuracy: 0.54 - ETA: 1:54 - loss: 1.8797 - accuracy: 0.54 - ETA: 1:53 - loss: 1.8811 - accuracy: 0.54 - ETA: 1:52 - loss: 1.8776 - accuracy: 0.54 - ETA: 1:50 - loss: 1.8802 - accuracy: 0.54 - ETA: 1:49 - loss: 1.8779 - accuracy: 0.54 - ETA: 1:48 - loss: 1.8802 - accuracy: 0.54 - ETA: 1:47 - loss: 1.8784 - accuracy: 0.54 - ETA: 1:45 - loss: 1.8766 - accuracy: 0.54 - ETA: 1:44 - loss: 1.8748 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8669 - accuracy: 0.54 - ETA: 1:41 - loss: 1.8721 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8822 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8836 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8815 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8769 - accuracy: 0.54 - ETA: 1:35 - loss: 1.8724 - accuracy: 0.54 - ETA: 1:33 - loss: 1.8696 - accuracy: 0.54 - ETA: 1:32 - loss: 1.8670 - accuracy: 0.54 - ETA: 1:31 - loss: 1.8642 - accuracy: 0.54 - ETA: 1:29 - loss: 1.8598 - accuracy: 0.54 - ETA: 1:28 - loss: 1.8626 - accuracy: 0.54 - ETA: 1:26 - loss: 1.8617 - accuracy: 0.54 - ETA: 1:25 - loss: 1.8616 - accuracy: 0.54 - ETA: 1:24 - loss: 1.8617 - accuracy: 0.54 - ETA: 1:22 - loss: 1.8583 - accuracy: 0.54 - ETA: 1:21 - loss: 1.8668 - accuracy: 0.54 - ETA: 1:20 - loss: 1.8729 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8738 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8731 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8765 - accuracy: 0.53 - ETA: 1:14 - loss: 1.8779 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8752 - accuracy: 0.53 - ETA: 1:12 - loss: 1.8774 - accuracy: 0.53 - ETA: 1:10 - loss: 1.8787 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8758 - accuracy: 0.53 - ETA: 1:08 - loss: 1.8764 - accuracy: 0.53 - ETA: 1:06 - loss: 1.8761 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8743 - accuracy: 0.53 - ETA: 1:04 - loss: 1.8745 - accuracy: 0.53 - ETA: 1:02 - loss: 1.8797 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8841 - accuracy: 0.53 - ETA: 1:00 - loss: 1.8811 - accuracy: 0.53 - ETA: 58s - loss: 1.8843 - accuracy: 0.5375 - ETA: 57s - loss: 1.8811 - accuracy: 0.538 - ETA: 56s - loss: 1.8777 - accuracy: 0.538 - ETA: 54s - loss: 1.8751 - accuracy: 0.539 - ETA: 53s - loss: 1.8734 - accuracy: 0.539 - ETA: 52s - loss: 1.8741 - accuracy: 0.539 - ETA: 50s - loss: 1.8749 - accuracy: 0.538 - ETA: 49s - loss: 1.8709 - accuracy: 0.539 - ETA: 48s - loss: 1.8718 - accuracy: 0.539 - ETA: 46s - loss: 1.8695 - accuracy: 0.539 - ETA: 45s - loss: 1.8693 - accuracy: 0.539 - ETA: 44s - loss: 1.8688 - accuracy: 0.539 - ETA: 42s - loss: 1.8680 - accuracy: 0.539 - ETA: 41s - loss: 1.8667 - accuracy: 0.539 - ETA: 40s - loss: 1.8665 - accuracy: 0.538 - ETA: 38s - loss: 1.8644 - accuracy: 0.539 - ETA: 37s - loss: 1.8636 - accuracy: 0.539 - ETA: 36s - loss: 1.8652 - accuracy: 0.538 - ETA: 34s - loss: 1.8644 - accuracy: 0.538 - ETA: 33s - loss: 1.8665 - accuracy: 0.538 - ETA: 32s - loss: 1.8655 - accuracy: 0.538 - ETA: 30s - loss: 1.8640 - accuracy: 0.538 - ETA: 29s - loss: 1.8639 - accuracy: 0.537 - ETA: 28s - loss: 1.8616 - accuracy: 0.538 - ETA: 26s - loss: 1.8619 - accuracy: 0.537 - ETA: 25s - loss: 1.8612 - accuracy: 0.537 - ETA: 24s - loss: 1.8593 - accuracy: 0.537 - ETA: 22s - loss: 1.8614 - accuracy: 0.537 - ETA: 21s - loss: 1.8601 - accuracy: 0.537 - ETA: 20s - loss: 1.8590 - accuracy: 0.537 - ETA: 18s - loss: 1.8622 - accuracy: 0.536 - ETA: 17s - loss: 1.8642 - accuracy: 0.536 - ETA: 15s - loss: 1.8626 - accuracy: 0.536 - ETA: 14s - loss: 1.8646 - accuracy: 0.536 - ETA: 13s - loss: 1.8645 - accuracy: 0.535 - ETA: 11s - loss: 1.8650 - accuracy: 0.535 - ETA: 10s - loss: 1.8626 - accuracy: 0.535 - ETA: 9s - loss: 1.8620 - accuracy: 0.535 - ETA: 7s - loss: 1.8592 - accuracy: 0.53 - ETA: 6s - loss: 1.8584 - accuracy: 0.53 - ETA: 5s - loss: 1.8572 - accuracy: 0.53 - ETA: 3s - loss: 1.8551 - accuracy: 0.53 - ETA: 2s - loss: 1.8542 - accuracy: 0.53 - ETA: 1s - loss: 1.8528 - accuracy: 0.53 - 215s 11ms/step - loss: 1.8522 - accuracy: 0.5355 - val_loss: 1.8676 - val_accuracy: 0.5941\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:38 - loss: 1.7093 - accuracy: 0.51 - ETA: 3:27 - loss: 1.8217 - accuracy: 0.52 - ETA: 3:21 - loss: 1.7921 - accuracy: 0.53 - ETA: 3:19 - loss: 1.8016 - accuracy: 0.52 - ETA: 3:19 - loss: 1.7564 - accuracy: 0.53 - ETA: 3:18 - loss: 1.7572 - accuracy: 0.53 - ETA: 3:17 - loss: 1.7739 - accuracy: 0.53 - ETA: 3:14 - loss: 1.7706 - accuracy: 0.53 - ETA: 3:13 - loss: 1.7631 - accuracy: 0.53 - ETA: 3:12 - loss: 1.7346 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7574 - accuracy: 0.53 - ETA: 3:10 - loss: 1.7426 - accuracy: 0.53 - ETA: 3:10 - loss: 1.7375 - accuracy: 0.53 - ETA: 3:08 - loss: 1.7278 - accuracy: 0.53 - ETA: 3:07 - loss: 1.7322 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7240 - accuracy: 0.54 - ETA: 3:04 - loss: 1.6978 - accuracy: 0.55 - ETA: 3:02 - loss: 1.7008 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7002 - accuracy: 0.54 - ETA: 2:59 - loss: 1.6985 - accuracy: 0.54 - ETA: 2:57 - loss: 1.6947 - accuracy: 0.54 - ETA: 2:56 - loss: 1.6809 - accuracy: 0.55 - ETA: 2:54 - loss: 1.6724 - accuracy: 0.55 - ETA: 2:53 - loss: 1.6769 - accuracy: 0.55 - ETA: 2:52 - loss: 1.6722 - accuracy: 0.55 - ETA: 2:51 - loss: 1.6663 - accuracy: 0.55 - ETA: 2:49 - loss: 1.6787 - accuracy: 0.55 - ETA: 2:48 - loss: 1.6810 - accuracy: 0.55 - ETA: 2:46 - loss: 1.6889 - accuracy: 0.55 - ETA: 2:45 - loss: 1.6916 - accuracy: 0.55 - ETA: 2:43 - loss: 1.6982 - accuracy: 0.54 - ETA: 2:42 - loss: 1.7011 - accuracy: 0.54 - ETA: 2:40 - loss: 1.7069 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7093 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7088 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7172 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7192 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7177 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7155 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7169 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7210 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7158 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7160 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7224 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7265 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7286 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7407 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7469 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7439 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7437 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7471 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7394 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7427 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7476 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7477 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7492 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7486 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7457 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7417 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7469 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7449 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7437 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7488 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7480 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7499 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7454 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7439 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7465 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7434 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7403 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7430 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7471 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7601 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7605 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7617 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7691 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7713 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7690 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7666 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7660 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7696 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7691 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7708 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7708 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7683 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7658 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7629 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7620 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7587 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7581 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7633 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7662 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7703 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7673 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7738 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7710 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7706 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7713 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7692 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7658 - accuracy: 0.54 - ETA: 1:08 - loss: 1.7656 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7658 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7666 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7693 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7695 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7715 - accuracy: 0.54 - ETA: 59s - loss: 1.7719 - accuracy: 0.5399 - ETA: 58s - loss: 1.7716 - accuracy: 0.540 - ETA: 57s - loss: 1.7728 - accuracy: 0.540 - ETA: 55s - loss: 1.7704 - accuracy: 0.540 - ETA: 54s - loss: 1.7709 - accuracy: 0.540 - ETA: 52s - loss: 1.7687 - accuracy: 0.540 - ETA: 51s - loss: 1.7675 - accuracy: 0.541 - ETA: 50s - loss: 1.7679 - accuracy: 0.541 - ETA: 48s - loss: 1.7667 - accuracy: 0.541 - ETA: 47s - loss: 1.7680 - accuracy: 0.540 - ETA: 46s - loss: 1.7689 - accuracy: 0.540 - ETA: 44s - loss: 1.7692 - accuracy: 0.540 - ETA: 43s - loss: 1.7701 - accuracy: 0.539 - ETA: 42s - loss: 1.7706 - accuracy: 0.539 - ETA: 40s - loss: 1.7688 - accuracy: 0.539 - ETA: 39s - loss: 1.7692 - accuracy: 0.539 - ETA: 38s - loss: 1.7665 - accuracy: 0.539 - ETA: 36s - loss: 1.7684 - accuracy: 0.539 - ETA: 35s - loss: 1.7692 - accuracy: 0.539 - ETA: 34s - loss: 1.7685 - accuracy: 0.538 - ETA: 32s - loss: 1.7687 - accuracy: 0.538 - ETA: 31s - loss: 1.7693 - accuracy: 0.538 - ETA: 29s - loss: 1.7700 - accuracy: 0.538 - ETA: 28s - loss: 1.7682 - accuracy: 0.538 - ETA: 27s - loss: 1.7675 - accuracy: 0.538 - ETA: 25s - loss: 1.7703 - accuracy: 0.538 - ETA: 24s - loss: 1.7684 - accuracy: 0.538 - ETA: 23s - loss: 1.7691 - accuracy: 0.538 - ETA: 21s - loss: 1.7688 - accuracy: 0.538 - ETA: 20s - loss: 1.7679 - accuracy: 0.538 - ETA: 18s - loss: 1.7684 - accuracy: 0.538 - ETA: 17s - loss: 1.7709 - accuracy: 0.537 - ETA: 16s - loss: 1.7733 - accuracy: 0.537 - ETA: 14s - loss: 1.7748 - accuracy: 0.537 - ETA: 13s - loss: 1.7742 - accuracy: 0.537 - ETA: 12s - loss: 1.7734 - accuracy: 0.537 - ETA: 10s - loss: 1.7732 - accuracy: 0.537 - ETA: 9s - loss: 1.7733 - accuracy: 0.537 - ETA: 8s - loss: 1.7703 - accuracy: 0.53 - ETA: 6s - loss: 1.7697 - accuracy: 0.53 - ETA: 5s - loss: 1.7678 - accuracy: 0.53 - ETA: 3s - loss: 1.7691 - accuracy: 0.53 - ETA: 2s - loss: 1.7695 - accuracy: 0.53 - ETA: 1s - loss: 1.7696 - accuracy: 0.53 - 218s 11ms/step - loss: 1.7684 - accuracy: 0.5386 - val_loss: 1.8122 - val_accuracy: 0.5962\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:33 - loss: 1.6954 - accuracy: 0.62 - ETA: 3:25 - loss: 1.7657 - accuracy: 0.57 - ETA: 3:20 - loss: 1.6776 - accuracy: 0.56 - ETA: 3:20 - loss: 1.6772 - accuracy: 0.56 - ETA: 3:21 - loss: 1.7146 - accuracy: 0.55 - ETA: 3:20 - loss: 1.7239 - accuracy: 0.54 - ETA: 3:19 - loss: 1.8599 - accuracy: 0.55 - ETA: 3:16 - loss: 1.8458 - accuracy: 0.54 - ETA: 3:14 - loss: 1.8518 - accuracy: 0.54 - ETA: 3:12 - loss: 1.8311 - accuracy: 0.54 - ETA: 3:10 - loss: 1.8307 - accuracy: 0.54 - ETA: 3:08 - loss: 1.8249 - accuracy: 0.54 - ETA: 3:06 - loss: 1.8520 - accuracy: 0.54 - ETA: 3:05 - loss: 1.8724 - accuracy: 0.54 - ETA: 3:04 - loss: 1.8600 - accuracy: 0.54 - ETA: 3:02 - loss: 1.8435 - accuracy: 0.54 - ETA: 3:02 - loss: 1.8348 - accuracy: 0.54 - ETA: 3:02 - loss: 1.8299 - accuracy: 0.54 - ETA: 3:00 - loss: 1.8264 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8130 - accuracy: 0.54 - ETA: 2:57 - loss: 1.8066 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7843 - accuracy: 0.54 - ETA: 2:54 - loss: 1.8031 - accuracy: 0.53 - ETA: 2:53 - loss: 1.7934 - accuracy: 0.53 - ETA: 2:51 - loss: 1.7993 - accuracy: 0.53 - ETA: 2:50 - loss: 1.8085 - accuracy: 0.53 - ETA: 2:48 - loss: 1.8088 - accuracy: 0.53 - ETA: 2:47 - loss: 1.7933 - accuracy: 0.54 - ETA: 2:46 - loss: 1.7898 - accuracy: 0.54 - ETA: 2:44 - loss: 1.7915 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7913 - accuracy: 0.54 - ETA: 2:42 - loss: 1.8092 - accuracy: 0.53 - ETA: 2:40 - loss: 1.7957 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7912 - accuracy: 0.54 - ETA: 2:37 - loss: 1.7863 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7939 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7904 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7799 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7779 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7859 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7867 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7846 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7860 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7809 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7816 - accuracy: 0.54 - ETA: 2:22 - loss: 1.7827 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7842 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7853 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7860 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7811 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7775 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7800 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7799 - accuracy: 0.54 - ETA: 2:11 - loss: 1.7781 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7746 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7721 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7746 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7655 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7629 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7605 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7592 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7631 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7678 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7677 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7630 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7632 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7580 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7592 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7569 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7560 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7552 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7529 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7556 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7543 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7548 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7553 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7555 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7530 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7552 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7568 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7547 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7551 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7689 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7682 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7776 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7775 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7897 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7934 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7967 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7965 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7989 - accuracy: 0.53 - ETA: 1:20 - loss: 1.7959 - accuracy: 0.53 - ETA: 1:18 - loss: 1.7936 - accuracy: 0.53 - ETA: 1:17 - loss: 1.7921 - accuracy: 0.53 - ETA: 1:16 - loss: 1.7941 - accuracy: 0.53 - ETA: 1:14 - loss: 1.7963 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8015 - accuracy: 0.53 - ETA: 1:12 - loss: 1.7996 - accuracy: 0.53 - ETA: 1:10 - loss: 1.7975 - accuracy: 0.53 - ETA: 1:09 - loss: 1.7993 - accuracy: 0.53 - ETA: 1:08 - loss: 1.7978 - accuracy: 0.53 - ETA: 1:06 - loss: 1.7977 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8024 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8035 - accuracy: 0.53 - ETA: 1:02 - loss: 1.8042 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8076 - accuracy: 0.53 - ETA: 59s - loss: 1.8075 - accuracy: 0.5364 - ETA: 58s - loss: 1.8060 - accuracy: 0.536 - ETA: 57s - loss: 1.8072 - accuracy: 0.536 - ETA: 55s - loss: 1.8084 - accuracy: 0.535 - ETA: 54s - loss: 1.8116 - accuracy: 0.534 - ETA: 53s - loss: 1.8123 - accuracy: 0.534 - ETA: 51s - loss: 1.8121 - accuracy: 0.534 - ETA: 50s - loss: 1.8111 - accuracy: 0.534 - ETA: 48s - loss: 1.8115 - accuracy: 0.534 - ETA: 47s - loss: 1.8106 - accuracy: 0.534 - ETA: 46s - loss: 1.8085 - accuracy: 0.534 - ETA: 44s - loss: 1.8084 - accuracy: 0.534 - ETA: 43s - loss: 1.8100 - accuracy: 0.534 - ETA: 42s - loss: 1.8116 - accuracy: 0.534 - ETA: 40s - loss: 1.8116 - accuracy: 0.534 - ETA: 39s - loss: 1.8096 - accuracy: 0.534 - ETA: 38s - loss: 1.8128 - accuracy: 0.534 - ETA: 36s - loss: 1.8115 - accuracy: 0.534 - ETA: 35s - loss: 1.8093 - accuracy: 0.535 - ETA: 33s - loss: 1.8074 - accuracy: 0.535 - ETA: 32s - loss: 1.8044 - accuracy: 0.536 - ETA: 31s - loss: 1.8023 - accuracy: 0.536 - ETA: 29s - loss: 1.8059 - accuracy: 0.536 - ETA: 28s - loss: 1.8068 - accuracy: 0.536 - ETA: 27s - loss: 1.8087 - accuracy: 0.535 - ETA: 25s - loss: 1.8164 - accuracy: 0.536 - ETA: 24s - loss: 1.8158 - accuracy: 0.536 - ETA: 23s - loss: 1.8184 - accuracy: 0.536 - ETA: 21s - loss: 1.8178 - accuracy: 0.536 - ETA: 20s - loss: 1.8190 - accuracy: 0.536 - ETA: 18s - loss: 1.8209 - accuracy: 0.535 - ETA: 17s - loss: 1.8200 - accuracy: 0.535 - ETA: 16s - loss: 1.8196 - accuracy: 0.535 - ETA: 14s - loss: 1.8194 - accuracy: 0.535 - ETA: 13s - loss: 1.8196 - accuracy: 0.535 - ETA: 12s - loss: 1.8210 - accuracy: 0.534 - ETA: 10s - loss: 1.8195 - accuracy: 0.535 - ETA: 9s - loss: 1.8196 - accuracy: 0.535 - ETA: 7s - loss: 1.8224 - accuracy: 0.53 - ETA: 6s - loss: 1.8216 - accuracy: 0.53 - ETA: 5s - loss: 1.8227 - accuracy: 0.53 - ETA: 3s - loss: 1.8236 - accuracy: 0.53 - ETA: 2s - loss: 1.8235 - accuracy: 0.53 - ETA: 1s - loss: 1.8248 - accuracy: 0.53 - 217s 11ms/step - loss: 1.8254 - accuracy: 0.5348 - val_loss: 1.9128 - val_accuracy: 0.5858\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:50 - loss: 1.9043 - accuracy: 0.54 - ETA: 3:40 - loss: 1.9086 - accuracy: 0.51 - ETA: 3:39 - loss: 1.9313 - accuracy: 0.50 - ETA: 3:37 - loss: 1.8856 - accuracy: 0.50 - ETA: 3:34 - loss: 1.8709 - accuracy: 0.50 - ETA: 3:32 - loss: 1.8647 - accuracy: 0.50 - ETA: 3:30 - loss: 1.8352 - accuracy: 0.51 - ETA: 3:28 - loss: 1.8551 - accuracy: 0.51 - ETA: 3:26 - loss: 1.8611 - accuracy: 0.51 - ETA: 3:24 - loss: 1.8716 - accuracy: 0.52 - ETA: 3:23 - loss: 1.8696 - accuracy: 0.51 - ETA: 3:20 - loss: 1.8824 - accuracy: 0.51 - ETA: 3:17 - loss: 1.8731 - accuracy: 0.51 - ETA: 3:15 - loss: 1.8691 - accuracy: 0.52 - ETA: 3:14 - loss: 1.9144 - accuracy: 0.52 - ETA: 3:13 - loss: 1.9357 - accuracy: 0.52 - ETA: 3:12 - loss: 1.9251 - accuracy: 0.52 - ETA: 3:10 - loss: 1.9304 - accuracy: 0.51 - ETA: 3:08 - loss: 1.9169 - accuracy: 0.52 - ETA: 3:07 - loss: 1.9259 - accuracy: 0.51 - ETA: 3:06 - loss: 1.9369 - accuracy: 0.51 - ETA: 3:04 - loss: 1.9127 - accuracy: 0.51 - ETA: 3:02 - loss: 1.9275 - accuracy: 0.51 - ETA: 3:00 - loss: 1.9138 - accuracy: 0.51 - ETA: 2:58 - loss: 1.9372 - accuracy: 0.51 - ETA: 2:56 - loss: 1.9501 - accuracy: 0.51 - ETA: 2:55 - loss: 1.9540 - accuracy: 0.51 - ETA: 2:53 - loss: 1.9497 - accuracy: 0.51 - ETA: 2:51 - loss: 1.9507 - accuracy: 0.51 - ETA: 2:49 - loss: 1.9589 - accuracy: 0.51 - ETA: 2:48 - loss: 1.9467 - accuracy: 0.51 - ETA: 2:46 - loss: 1.9398 - accuracy: 0.51 - ETA: 2:45 - loss: 1.9364 - accuracy: 0.51 - ETA: 2:44 - loss: 1.9435 - accuracy: 0.51 - ETA: 2:42 - loss: 1.9285 - accuracy: 0.51 - ETA: 2:41 - loss: 1.9293 - accuracy: 0.51 - ETA: 2:39 - loss: 1.9219 - accuracy: 0.51 - ETA: 2:38 - loss: 1.9179 - accuracy: 0.51 - ETA: 2:36 - loss: 1.9136 - accuracy: 0.51 - ETA: 2:35 - loss: 1.9011 - accuracy: 0.51 - ETA: 2:33 - loss: 1.8947 - accuracy: 0.51 - ETA: 2:32 - loss: 1.8928 - accuracy: 0.52 - ETA: 2:30 - loss: 1.9074 - accuracy: 0.52 - ETA: 2:28 - loss: 1.9033 - accuracy: 0.52 - ETA: 2:27 - loss: 1.8935 - accuracy: 0.52 - ETA: 2:26 - loss: 1.8904 - accuracy: 0.52 - ETA: 2:24 - loss: 1.8834 - accuracy: 0.52 - ETA: 2:23 - loss: 1.8833 - accuracy: 0.52 - ETA: 2:21 - loss: 1.8948 - accuracy: 0.52 - ETA: 2:20 - loss: 1.8967 - accuracy: 0.52 - ETA: 2:18 - loss: 1.8932 - accuracy: 0.52 - ETA: 2:17 - loss: 1.8999 - accuracy: 0.52 - ETA: 2:15 - loss: 1.8976 - accuracy: 0.52 - ETA: 2:14 - loss: 1.8970 - accuracy: 0.52 - ETA: 2:12 - loss: 1.8913 - accuracy: 0.52 - ETA: 2:11 - loss: 1.8907 - accuracy: 0.52 - ETA: 2:10 - loss: 1.8914 - accuracy: 0.52 - ETA: 2:09 - loss: 1.8858 - accuracy: 0.52 - ETA: 2:07 - loss: 1.8865 - accuracy: 0.52 - ETA: 2:05 - loss: 1.8820 - accuracy: 0.52 - ETA: 2:04 - loss: 1.8734 - accuracy: 0.52 - ETA: 2:03 - loss: 1.8692 - accuracy: 0.52 - ETA: 2:01 - loss: 1.8697 - accuracy: 0.52 - ETA: 2:00 - loss: 1.8689 - accuracy: 0.52 - ETA: 1:58 - loss: 1.8690 - accuracy: 0.52 - ETA: 1:57 - loss: 1.8653 - accuracy: 0.52 - ETA: 1:55 - loss: 1.8630 - accuracy: 0.52 - ETA: 1:54 - loss: 1.8662 - accuracy: 0.52 - ETA: 1:53 - loss: 1.8619 - accuracy: 0.52 - ETA: 1:51 - loss: 1.8673 - accuracy: 0.52 - ETA: 1:50 - loss: 1.8661 - accuracy: 0.52 - ETA: 1:48 - loss: 1.8664 - accuracy: 0.52 - ETA: 1:47 - loss: 1.8638 - accuracy: 0.52 - ETA: 1:46 - loss: 1.8593 - accuracy: 0.52 - ETA: 1:44 - loss: 1.8604 - accuracy: 0.52 - ETA: 1:43 - loss: 1.8580 - accuracy: 0.52 - ETA: 1:42 - loss: 1.8578 - accuracy: 0.52 - ETA: 1:40 - loss: 1.8683 - accuracy: 0.52 - ETA: 1:39 - loss: 1.8643 - accuracy: 0.52 - ETA: 1:37 - loss: 1.8626 - accuracy: 0.52 - ETA: 1:36 - loss: 1.8827 - accuracy: 0.52 - ETA: 1:35 - loss: 1.8832 - accuracy: 0.52 - ETA: 1:33 - loss: 1.8815 - accuracy: 0.52 - ETA: 1:32 - loss: 1.8831 - accuracy: 0.52 - ETA: 1:30 - loss: 1.8804 - accuracy: 0.52 - ETA: 1:29 - loss: 1.8829 - accuracy: 0.52 - ETA: 1:28 - loss: 1.8843 - accuracy: 0.52 - ETA: 1:26 - loss: 1.8820 - accuracy: 0.52 - ETA: 1:25 - loss: 1.8801 - accuracy: 0.52 - ETA: 1:23 - loss: 1.8781 - accuracy: 0.52 - ETA: 1:22 - loss: 1.8793 - accuracy: 0.52 - ETA: 1:21 - loss: 1.8788 - accuracy: 0.52 - ETA: 1:19 - loss: 1.8797 - accuracy: 0.52 - ETA: 1:18 - loss: 1.8811 - accuracy: 0.52 - ETA: 1:16 - loss: 1.8792 - accuracy: 0.52 - ETA: 1:15 - loss: 1.8769 - accuracy: 0.52 - ETA: 1:14 - loss: 1.8768 - accuracy: 0.52 - ETA: 1:12 - loss: 1.8738 - accuracy: 0.52 - ETA: 1:11 - loss: 1.8727 - accuracy: 0.52 - ETA: 1:09 - loss: 1.8730 - accuracy: 0.52 - ETA: 1:08 - loss: 1.8721 - accuracy: 0.52 - ETA: 1:07 - loss: 1.8660 - accuracy: 0.52 - ETA: 1:05 - loss: 1.8624 - accuracy: 0.52 - ETA: 1:04 - loss: 1.8648 - accuracy: 0.52 - ETA: 1:03 - loss: 1.8649 - accuracy: 0.52 - ETA: 1:01 - loss: 1.8629 - accuracy: 0.52 - ETA: 1:00 - loss: 1.8587 - accuracy: 0.52 - ETA: 58s - loss: 1.8553 - accuracy: 0.5293 - ETA: 57s - loss: 1.8551 - accuracy: 0.528 - ETA: 56s - loss: 1.8613 - accuracy: 0.529 - ETA: 54s - loss: 1.8609 - accuracy: 0.529 - ETA: 53s - loss: 1.8587 - accuracy: 0.529 - ETA: 51s - loss: 1.8577 - accuracy: 0.529 - ETA: 50s - loss: 1.8569 - accuracy: 0.529 - ETA: 49s - loss: 1.8534 - accuracy: 0.529 - ETA: 47s - loss: 1.8522 - accuracy: 0.529 - ETA: 46s - loss: 1.8576 - accuracy: 0.528 - ETA: 45s - loss: 1.8598 - accuracy: 0.528 - ETA: 43s - loss: 1.8568 - accuracy: 0.529 - ETA: 42s - loss: 1.8549 - accuracy: 0.529 - ETA: 41s - loss: 1.8524 - accuracy: 0.529 - ETA: 39s - loss: 1.8535 - accuracy: 0.529 - ETA: 38s - loss: 1.8530 - accuracy: 0.529 - ETA: 36s - loss: 1.8500 - accuracy: 0.530 - ETA: 35s - loss: 1.8478 - accuracy: 0.530 - ETA: 34s - loss: 1.8488 - accuracy: 0.530 - ETA: 32s - loss: 1.8502 - accuracy: 0.530 - ETA: 31s - loss: 1.8505 - accuracy: 0.530 - ETA: 30s - loss: 1.8522 - accuracy: 0.530 - ETA: 28s - loss: 1.8540 - accuracy: 0.529 - ETA: 27s - loss: 1.8537 - accuracy: 0.529 - ETA: 25s - loss: 1.8539 - accuracy: 0.529 - ETA: 24s - loss: 1.8515 - accuracy: 0.529 - ETA: 23s - loss: 1.8511 - accuracy: 0.529 - ETA: 21s - loss: 1.8509 - accuracy: 0.529 - ETA: 20s - loss: 1.8502 - accuracy: 0.529 - ETA: 19s - loss: 1.8541 - accuracy: 0.529 - ETA: 17s - loss: 1.8542 - accuracy: 0.529 - ETA: 16s - loss: 1.8555 - accuracy: 0.528 - ETA: 14s - loss: 1.8593 - accuracy: 0.529 - ETA: 13s - loss: 1.8618 - accuracy: 0.528 - ETA: 12s - loss: 1.8611 - accuracy: 0.528 - ETA: 10s - loss: 1.8609 - accuracy: 0.528 - ETA: 9s - loss: 1.8608 - accuracy: 0.528 - ETA: 8s - loss: 1.8586 - accuracy: 0.52 - ETA: 6s - loss: 1.8582 - accuracy: 0.52 - ETA: 5s - loss: 1.8577 - accuracy: 0.52 - ETA: 3s - loss: 1.8547 - accuracy: 0.52 - ETA: 2s - loss: 1.8557 - accuracy: 0.52 - ETA: 1s - loss: 1.8567 - accuracy: 0.52 - 219s 11ms/step - loss: 1.8562 - accuracy: 0.5291 - val_loss: 1.9052 - val_accuracy: 0.5846\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:25 - loss: 1.7751 - accuracy: 0.51 - ETA: 3:26 - loss: 1.7938 - accuracy: 0.50 - ETA: 3:27 - loss: 1.7896 - accuracy: 0.50 - ETA: 3:23 - loss: 1.7657 - accuracy: 0.50 - ETA: 3:22 - loss: 1.7829 - accuracy: 0.50 - ETA: 3:19 - loss: 1.7604 - accuracy: 0.50 - ETA: 3:18 - loss: 1.7762 - accuracy: 0.50 - ETA: 3:16 - loss: 1.7553 - accuracy: 0.51 - ETA: 3:15 - loss: 1.7691 - accuracy: 0.50 - ETA: 3:13 - loss: 1.7803 - accuracy: 0.51 - ETA: 3:12 - loss: 1.7607 - accuracy: 0.51 - ETA: 3:09 - loss: 1.7670 - accuracy: 0.51 - ETA: 3:09 - loss: 1.7684 - accuracy: 0.51 - ETA: 3:07 - loss: 1.7592 - accuracy: 0.51 - ETA: 3:06 - loss: 1.7618 - accuracy: 0.52 - ETA: 3:05 - loss: 1.7405 - accuracy: 0.52 - ETA: 3:04 - loss: 1.7513 - accuracy: 0.52 - ETA: 3:02 - loss: 1.7663 - accuracy: 0.52 - ETA: 3:01 - loss: 1.7851 - accuracy: 0.51 - ETA: 3:00 - loss: 1.7639 - accuracy: 0.52 - ETA: 2:58 - loss: 1.7616 - accuracy: 0.52 - ETA: 2:56 - loss: 1.7586 - accuracy: 0.52 - ETA: 2:54 - loss: 1.7765 - accuracy: 0.52 - ETA: 2:53 - loss: 1.7764 - accuracy: 0.52 - ETA: 2:51 - loss: 1.7679 - accuracy: 0.52 - ETA: 2:50 - loss: 1.7672 - accuracy: 0.52 - ETA: 2:49 - loss: 1.7615 - accuracy: 0.52 - ETA: 2:48 - loss: 1.7674 - accuracy: 0.52 - ETA: 2:46 - loss: 1.7851 - accuracy: 0.52 - ETA: 2:45 - loss: 1.7792 - accuracy: 0.52 - ETA: 2:43 - loss: 1.7999 - accuracy: 0.52 - ETA: 2:42 - loss: 1.8052 - accuracy: 0.52 - ETA: 2:40 - loss: 1.8112 - accuracy: 0.51 - ETA: 2:39 - loss: 1.8067 - accuracy: 0.52 - ETA: 2:38 - loss: 1.8055 - accuracy: 0.52 - ETA: 2:36 - loss: 1.7988 - accuracy: 0.52 - ETA: 2:35 - loss: 1.7987 - accuracy: 0.52 - ETA: 2:33 - loss: 1.7955 - accuracy: 0.52 - ETA: 2:32 - loss: 1.7867 - accuracy: 0.52 - ETA: 2:31 - loss: 1.7863 - accuracy: 0.52 - ETA: 2:29 - loss: 1.7851 - accuracy: 0.52 - ETA: 2:28 - loss: 1.7717 - accuracy: 0.52 - ETA: 2:26 - loss: 1.7722 - accuracy: 0.52 - ETA: 2:25 - loss: 1.7707 - accuracy: 0.52 - ETA: 2:23 - loss: 1.7722 - accuracy: 0.52 - ETA: 2:22 - loss: 1.7709 - accuracy: 0.53 - ETA: 2:21 - loss: 1.7706 - accuracy: 0.52 - ETA: 2:19 - loss: 1.7674 - accuracy: 0.53 - ETA: 2:18 - loss: 1.7656 - accuracy: 0.53 - ETA: 2:17 - loss: 1.7686 - accuracy: 0.53 - ETA: 2:15 - loss: 1.7784 - accuracy: 0.52 - ETA: 2:14 - loss: 1.7820 - accuracy: 0.52 - ETA: 2:13 - loss: 1.7851 - accuracy: 0.52 - ETA: 2:11 - loss: 1.7866 - accuracy: 0.52 - ETA: 2:10 - loss: 1.7871 - accuracy: 0.52 - ETA: 2:09 - loss: 1.7912 - accuracy: 0.52 - ETA: 2:07 - loss: 1.7909 - accuracy: 0.52 - ETA: 2:06 - loss: 1.7967 - accuracy: 0.52 - ETA: 2:04 - loss: 1.7924 - accuracy: 0.53 - ETA: 2:03 - loss: 1.7912 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8016 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8009 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8076 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8097 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8118 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8200 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8187 - accuracy: 0.53 - ETA: 1:52 - loss: 1.8182 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8149 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8181 - accuracy: 0.52 - ETA: 1:48 - loss: 1.8231 - accuracy: 0.52 - ETA: 1:46 - loss: 1.8173 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8185 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8135 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8140 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8183 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8149 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8099 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8096 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8110 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8118 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8117 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8107 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8085 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8086 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8069 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8076 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8097 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8063 - accuracy: 0.53 - ETA: 1:23 - loss: 1.8073 - accuracy: 0.53 - ETA: 1:21 - loss: 1.8101 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8084 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8075 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8107 - accuracy: 0.52 - ETA: 1:16 - loss: 1.8104 - accuracy: 0.52 - ETA: 1:14 - loss: 1.8083 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8072 - accuracy: 0.53 - ETA: 1:12 - loss: 1.8060 - accuracy: 0.53 - ETA: 1:10 - loss: 1.8047 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8032 - accuracy: 0.53 - ETA: 1:08 - loss: 1.8043 - accuracy: 0.53 - ETA: 1:06 - loss: 1.8066 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8060 - accuracy: 0.52 - ETA: 1:04 - loss: 1.8046 - accuracy: 0.52 - ETA: 1:02 - loss: 1.8011 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8013 - accuracy: 0.53 - ETA: 59s - loss: 1.8002 - accuracy: 0.5307 - ETA: 58s - loss: 1.7969 - accuracy: 0.531 - ETA: 57s - loss: 1.7944 - accuracy: 0.531 - ETA: 55s - loss: 1.7983 - accuracy: 0.531 - ETA: 54s - loss: 1.7998 - accuracy: 0.530 - ETA: 53s - loss: 1.7968 - accuracy: 0.531 - ETA: 51s - loss: 1.7950 - accuracy: 0.531 - ETA: 50s - loss: 1.7924 - accuracy: 0.532 - ETA: 48s - loss: 1.7919 - accuracy: 0.532 - ETA: 47s - loss: 1.7883 - accuracy: 0.532 - ETA: 46s - loss: 1.7897 - accuracy: 0.532 - ETA: 44s - loss: 1.7889 - accuracy: 0.532 - ETA: 43s - loss: 1.7864 - accuracy: 0.533 - ETA: 42s - loss: 1.7873 - accuracy: 0.532 - ETA: 40s - loss: 1.7897 - accuracy: 0.532 - ETA: 39s - loss: 1.7868 - accuracy: 0.532 - ETA: 38s - loss: 1.7857 - accuracy: 0.532 - ETA: 36s - loss: 1.7843 - accuracy: 0.533 - ETA: 35s - loss: 1.7840 - accuracy: 0.533 - ETA: 33s - loss: 1.7818 - accuracy: 0.533 - ETA: 32s - loss: 1.7789 - accuracy: 0.534 - ETA: 31s - loss: 1.7778 - accuracy: 0.534 - ETA: 29s - loss: 1.7765 - accuracy: 0.534 - ETA: 28s - loss: 1.7767 - accuracy: 0.534 - ETA: 27s - loss: 1.7790 - accuracy: 0.534 - ETA: 25s - loss: 1.7772 - accuracy: 0.534 - ETA: 24s - loss: 1.7771 - accuracy: 0.534 - ETA: 22s - loss: 1.7780 - accuracy: 0.534 - ETA: 21s - loss: 1.7792 - accuracy: 0.534 - ETA: 20s - loss: 1.7768 - accuracy: 0.534 - ETA: 18s - loss: 1.7759 - accuracy: 0.534 - ETA: 17s - loss: 1.7751 - accuracy: 0.534 - ETA: 16s - loss: 1.7776 - accuracy: 0.534 - ETA: 14s - loss: 1.7782 - accuracy: 0.534 - ETA: 13s - loss: 1.7793 - accuracy: 0.534 - ETA: 12s - loss: 1.7767 - accuracy: 0.534 - ETA: 10s - loss: 1.7757 - accuracy: 0.534 - ETA: 9s - loss: 1.7742 - accuracy: 0.534 - ETA: 8s - loss: 1.7737 - accuracy: 0.53 - ETA: 6s - loss: 1.7733 - accuracy: 0.53 - ETA: 5s - loss: 1.7722 - accuracy: 0.53 - ETA: 3s - loss: 1.7718 - accuracy: 0.53 - ETA: 2s - loss: 1.7713 - accuracy: 0.53 - ETA: 1s - loss: 1.7720 - accuracy: 0.53 - 217s 11ms/step - loss: 1.7741 - accuracy: 0.5342 - val_loss: 1.8947 - val_accuracy: 0.5925\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:24 - loss: 1.4895 - accuracy: 0.60 - ETA: 3:18 - loss: 1.6278 - accuracy: 0.56 - ETA: 3:15 - loss: 1.6494 - accuracy: 0.55 - ETA: 3:14 - loss: 1.6224 - accuracy: 0.56 - ETA: 3:14 - loss: 1.5923 - accuracy: 0.56 - ETA: 3:12 - loss: 1.6282 - accuracy: 0.55 - ETA: 3:11 - loss: 1.6039 - accuracy: 0.55 - ETA: 3:12 - loss: 1.6233 - accuracy: 0.55 - ETA: 3:11 - loss: 1.6137 - accuracy: 0.55 - ETA: 3:11 - loss: 1.6239 - accuracy: 0.55 - ETA: 3:10 - loss: 1.6224 - accuracy: 0.55 - ETA: 3:08 - loss: 1.6135 - accuracy: 0.55 - ETA: 3:07 - loss: 1.5995 - accuracy: 0.56 - ETA: 3:06 - loss: 1.7412 - accuracy: 0.55 - ETA: 3:04 - loss: 1.7447 - accuracy: 0.55 - ETA: 3:03 - loss: 1.7286 - accuracy: 0.55 - ETA: 3:01 - loss: 1.7446 - accuracy: 0.55 - ETA: 2:59 - loss: 1.7418 - accuracy: 0.55 - ETA: 2:59 - loss: 1.7739 - accuracy: 0.55 - ETA: 2:58 - loss: 1.7829 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7783 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7767 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7939 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7940 - accuracy: 0.54 - ETA: 2:51 - loss: 1.8026 - accuracy: 0.53 - ETA: 2:50 - loss: 1.8022 - accuracy: 0.53 - ETA: 2:48 - loss: 1.8096 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8211 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8265 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8479 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8412 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8367 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8431 - accuracy: 0.53 - ETA: 2:39 - loss: 1.8300 - accuracy: 0.53 - ETA: 2:37 - loss: 1.8209 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8054 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8036 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8006 - accuracy: 0.53 - ETA: 2:32 - loss: 1.7915 - accuracy: 0.53 - ETA: 2:30 - loss: 1.7894 - accuracy: 0.53 - ETA: 2:29 - loss: 1.7880 - accuracy: 0.53 - ETA: 2:28 - loss: 1.7914 - accuracy: 0.53 - ETA: 2:27 - loss: 1.7908 - accuracy: 0.53 - ETA: 2:25 - loss: 1.7924 - accuracy: 0.53 - ETA: 2:24 - loss: 1.7949 - accuracy: 0.53 - ETA: 2:22 - loss: 1.7884 - accuracy: 0.53 - ETA: 2:21 - loss: 1.7895 - accuracy: 0.53 - ETA: 2:20 - loss: 1.7981 - accuracy: 0.53 - ETA: 2:18 - loss: 1.8006 - accuracy: 0.53 - ETA: 2:17 - loss: 1.7959 - accuracy: 0.53 - ETA: 2:15 - loss: 1.7980 - accuracy: 0.53 - ETA: 2:14 - loss: 1.7936 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7984 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8063 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8081 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8056 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8129 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8103 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8095 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8058 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8237 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8229 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8202 - accuracy: 0.54 - ETA: 1:58 - loss: 1.8177 - accuracy: 0.54 - ETA: 1:56 - loss: 1.8194 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8258 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8223 - accuracy: 0.54 - ETA: 1:52 - loss: 1.8197 - accuracy: 0.54 - ETA: 1:51 - loss: 1.8249 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8244 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8241 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8199 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8151 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8178 - accuracy: 0.54 - ETA: 1:43 - loss: 1.8148 - accuracy: 0.54 - ETA: 1:41 - loss: 1.8178 - accuracy: 0.54 - ETA: 1:40 - loss: 1.8127 - accuracy: 0.54 - ETA: 1:38 - loss: 1.8175 - accuracy: 0.54 - ETA: 1:37 - loss: 1.8144 - accuracy: 0.54 - ETA: 1:36 - loss: 1.8122 - accuracy: 0.54 - ETA: 1:34 - loss: 1.8133 - accuracy: 0.54 - ETA: 1:33 - loss: 1.8165 - accuracy: 0.54 - ETA: 1:32 - loss: 1.8162 - accuracy: 0.54 - ETA: 1:30 - loss: 1.8110 - accuracy: 0.54 - ETA: 1:29 - loss: 1.8103 - accuracy: 0.54 - ETA: 1:28 - loss: 1.8097 - accuracy: 0.54 - ETA: 1:26 - loss: 1.8141 - accuracy: 0.54 - ETA: 1:25 - loss: 1.8132 - accuracy: 0.54 - ETA: 1:24 - loss: 1.8109 - accuracy: 0.54 - ETA: 1:22 - loss: 1.8061 - accuracy: 0.54 - ETA: 1:21 - loss: 1.8096 - accuracy: 0.54 - ETA: 1:19 - loss: 1.8107 - accuracy: 0.54 - ETA: 1:18 - loss: 1.8088 - accuracy: 0.54 - ETA: 1:17 - loss: 1.8073 - accuracy: 0.54 - ETA: 1:15 - loss: 1.8061 - accuracy: 0.54 - ETA: 1:14 - loss: 1.8044 - accuracy: 0.54 - ETA: 1:13 - loss: 1.8012 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7985 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7946 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7920 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7895 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7893 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7870 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7884 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7889 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7882 - accuracy: 0.54 - ETA: 59s - loss: 1.7876 - accuracy: 0.5442 - ETA: 58s - loss: 1.7910 - accuracy: 0.543 - ETA: 56s - loss: 1.7906 - accuracy: 0.543 - ETA: 55s - loss: 1.7896 - accuracy: 0.543 - ETA: 54s - loss: 1.7897 - accuracy: 0.542 - ETA: 52s - loss: 1.7894 - accuracy: 0.542 - ETA: 51s - loss: 1.7896 - accuracy: 0.542 - ETA: 50s - loss: 1.7891 - accuracy: 0.542 - ETA: 48s - loss: 1.7896 - accuracy: 0.541 - ETA: 47s - loss: 1.7896 - accuracy: 0.541 - ETA: 46s - loss: 1.7901 - accuracy: 0.540 - ETA: 44s - loss: 1.7915 - accuracy: 0.540 - ETA: 43s - loss: 1.7910 - accuracy: 0.540 - ETA: 42s - loss: 1.7909 - accuracy: 0.540 - ETA: 40s - loss: 1.7901 - accuracy: 0.540 - ETA: 39s - loss: 1.7871 - accuracy: 0.540 - ETA: 37s - loss: 1.7883 - accuracy: 0.540 - ETA: 36s - loss: 1.7921 - accuracy: 0.540 - ETA: 35s - loss: 1.7926 - accuracy: 0.540 - ETA: 33s - loss: 1.7907 - accuracy: 0.540 - ETA: 32s - loss: 1.7907 - accuracy: 0.540 - ETA: 31s - loss: 1.7894 - accuracy: 0.540 - ETA: 29s - loss: 1.7953 - accuracy: 0.540 - ETA: 28s - loss: 1.7952 - accuracy: 0.540 - ETA: 27s - loss: 1.7964 - accuracy: 0.539 - ETA: 25s - loss: 1.7979 - accuracy: 0.539 - ETA: 24s - loss: 1.7974 - accuracy: 0.539 - ETA: 22s - loss: 1.7961 - accuracy: 0.539 - ETA: 21s - loss: 1.7978 - accuracy: 0.539 - ETA: 20s - loss: 1.7982 - accuracy: 0.539 - ETA: 18s - loss: 1.7942 - accuracy: 0.539 - ETA: 17s - loss: 1.7914 - accuracy: 0.540 - ETA: 16s - loss: 1.7897 - accuracy: 0.540 - ETA: 14s - loss: 1.7912 - accuracy: 0.540 - ETA: 13s - loss: 1.7923 - accuracy: 0.540 - ETA: 12s - loss: 1.7940 - accuracy: 0.539 - ETA: 10s - loss: 1.7941 - accuracy: 0.539 - ETA: 9s - loss: 1.7934 - accuracy: 0.539 - ETA: 8s - loss: 1.7926 - accuracy: 0.53 - ETA: 6s - loss: 1.7908 - accuracy: 0.54 - ETA: 5s - loss: 1.7949 - accuracy: 0.53 - ETA: 3s - loss: 1.7980 - accuracy: 0.53 - ETA: 2s - loss: 1.7996 - accuracy: 0.53 - ETA: 1s - loss: 1.7969 - accuracy: 0.53 - 217s 11ms/step - loss: 1.7940 - accuracy: 0.5387 - val_loss: 1.9874 - val_accuracy: 0.5862\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:39 - loss: 1.6965 - accuracy: 0.56 - ETA: 3:38 - loss: 1.7110 - accuracy: 0.55 - ETA: 3:33 - loss: 1.9852 - accuracy: 0.54 - ETA: 3:26 - loss: 1.9208 - accuracy: 0.53 - ETA: 3:23 - loss: 1.9127 - accuracy: 0.54 - ETA: 3:22 - loss: 1.8962 - accuracy: 0.52 - ETA: 3:21 - loss: 1.9258 - accuracy: 0.53 - ETA: 3:19 - loss: 1.8833 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8553 - accuracy: 0.53 - ETA: 3:17 - loss: 1.9358 - accuracy: 0.53 - ETA: 3:14 - loss: 1.9268 - accuracy: 0.53 - ETA: 3:13 - loss: 1.9163 - accuracy: 0.53 - ETA: 3:12 - loss: 1.9045 - accuracy: 0.53 - ETA: 3:11 - loss: 1.9260 - accuracy: 0.53 - ETA: 3:09 - loss: 1.9577 - accuracy: 0.52 - ETA: 3:06 - loss: 1.9342 - accuracy: 0.52 - ETA: 3:04 - loss: 1.9273 - accuracy: 0.52 - ETA: 3:03 - loss: 1.9120 - accuracy: 0.52 - ETA: 3:00 - loss: 1.8889 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8784 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8857 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8806 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8744 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8815 - accuracy: 0.53 - ETA: 2:52 - loss: 1.8699 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8867 - accuracy: 0.52 - ETA: 2:49 - loss: 1.8833 - accuracy: 0.52 - ETA: 2:48 - loss: 1.8809 - accuracy: 0.52 - ETA: 2:46 - loss: 1.8827 - accuracy: 0.52 - ETA: 2:45 - loss: 1.8746 - accuracy: 0.52 - ETA: 2:43 - loss: 1.8759 - accuracy: 0.52 - ETA: 2:42 - loss: 1.8788 - accuracy: 0.52 - ETA: 2:40 - loss: 1.8895 - accuracy: 0.52 - ETA: 2:39 - loss: 1.8901 - accuracy: 0.52 - ETA: 2:37 - loss: 1.8842 - accuracy: 0.52 - ETA: 2:36 - loss: 1.8747 - accuracy: 0.52 - ETA: 2:35 - loss: 1.8682 - accuracy: 0.52 - ETA: 2:34 - loss: 1.8568 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8507 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8430 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8405 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8439 - accuracy: 0.53 - ETA: 2:27 - loss: 1.8429 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8375 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8385 - accuracy: 0.53 - ETA: 2:22 - loss: 1.8358 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8336 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8317 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8269 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8217 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8140 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8137 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8116 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8082 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8112 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8084 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8106 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8155 - accuracy: 0.53 - ETA: 2:05 - loss: 1.8168 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8155 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8163 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8170 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8212 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8147 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8135 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8110 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8071 - accuracy: 0.53 - ETA: 1:52 - loss: 1.8160 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8148 - accuracy: 0.53 - ETA: 1:50 - loss: 1.8165 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8152 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8123 - accuracy: 0.53 - ETA: 1:46 - loss: 1.8079 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8120 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8118 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8147 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8205 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8209 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8203 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8213 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8168 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8142 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8119 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8095 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8063 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8053 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8047 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8039 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8012 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8010 - accuracy: 0.53 - ETA: 1:21 - loss: 1.8075 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8086 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8052 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8045 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8043 - accuracy: 0.53 - ETA: 1:14 - loss: 1.8034 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8014 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8032 - accuracy: 0.53 - ETA: 1:10 - loss: 1.8056 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8040 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8122 - accuracy: 0.53 - ETA: 1:06 - loss: 1.8104 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8207 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8193 - accuracy: 0.53 - ETA: 1:02 - loss: 1.8171 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8139 - accuracy: 0.53 - ETA: 59s - loss: 1.8140 - accuracy: 0.5373 - ETA: 58s - loss: 1.8159 - accuracy: 0.536 - ETA: 56s - loss: 1.8126 - accuracy: 0.537 - ETA: 55s - loss: 1.8151 - accuracy: 0.537 - ETA: 54s - loss: 1.8199 - accuracy: 0.537 - ETA: 52s - loss: 1.8178 - accuracy: 0.537 - ETA: 51s - loss: 1.8167 - accuracy: 0.537 - ETA: 50s - loss: 1.8182 - accuracy: 0.537 - ETA: 48s - loss: 1.8217 - accuracy: 0.537 - ETA: 47s - loss: 1.8250 - accuracy: 0.537 - ETA: 46s - loss: 1.8235 - accuracy: 0.537 - ETA: 44s - loss: 1.8248 - accuracy: 0.536 - ETA: 43s - loss: 1.8219 - accuracy: 0.537 - ETA: 42s - loss: 1.8243 - accuracy: 0.537 - ETA: 40s - loss: 1.8226 - accuracy: 0.537 - ETA: 39s - loss: 1.8229 - accuracy: 0.537 - ETA: 37s - loss: 1.8256 - accuracy: 0.537 - ETA: 36s - loss: 1.8240 - accuracy: 0.537 - ETA: 35s - loss: 1.8237 - accuracy: 0.537 - ETA: 33s - loss: 1.8259 - accuracy: 0.537 - ETA: 32s - loss: 1.8249 - accuracy: 0.537 - ETA: 31s - loss: 1.8251 - accuracy: 0.537 - ETA: 29s - loss: 1.8263 - accuracy: 0.536 - ETA: 28s - loss: 1.8307 - accuracy: 0.536 - ETA: 27s - loss: 1.8302 - accuracy: 0.536 - ETA: 25s - loss: 1.8336 - accuracy: 0.536 - ETA: 24s - loss: 1.8332 - accuracy: 0.536 - ETA: 22s - loss: 1.8334 - accuracy: 0.536 - ETA: 21s - loss: 1.8333 - accuracy: 0.536 - ETA: 20s - loss: 1.8311 - accuracy: 0.537 - ETA: 18s - loss: 1.8283 - accuracy: 0.537 - ETA: 17s - loss: 1.8305 - accuracy: 0.537 - ETA: 16s - loss: 1.8281 - accuracy: 0.537 - ETA: 14s - loss: 1.8261 - accuracy: 0.537 - ETA: 13s - loss: 1.8361 - accuracy: 0.536 - ETA: 12s - loss: 1.8328 - accuracy: 0.537 - ETA: 10s - loss: 1.8306 - accuracy: 0.537 - ETA: 9s - loss: 1.8309 - accuracy: 0.537 - ETA: 7s - loss: 1.8301 - accuracy: 0.53 - ETA: 6s - loss: 1.8295 - accuracy: 0.53 - ETA: 5s - loss: 1.8287 - accuracy: 0.53 - ETA: 3s - loss: 1.8277 - accuracy: 0.53 - ETA: 2s - loss: 1.8279 - accuracy: 0.53 - ETA: 1s - loss: 1.8271 - accuracy: 0.53 - 217s 11ms/step - loss: 1.8292 - accuracy: 0.5376 - val_loss: 1.9551 - val_accuracy: 0.5927\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:19 - loss: 1.6985 - accuracy: 0.60 - ETA: 3:18 - loss: 1.7830 - accuracy: 0.54 - ETA: 3:15 - loss: 1.8153 - accuracy: 0.53 - ETA: 3:16 - loss: 1.7808 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8155 - accuracy: 0.51 - ETA: 3:14 - loss: 1.8167 - accuracy: 0.51 - ETA: 3:15 - loss: 1.8073 - accuracy: 0.51 - ETA: 3:14 - loss: 1.7861 - accuracy: 0.52 - ETA: 3:12 - loss: 1.7929 - accuracy: 0.52 - ETA: 3:11 - loss: 1.7855 - accuracy: 0.52 - ETA: 3:10 - loss: 1.7928 - accuracy: 0.52 - ETA: 3:09 - loss: 1.7779 - accuracy: 0.53 - ETA: 3:08 - loss: 1.7740 - accuracy: 0.52 - ETA: 3:06 - loss: 1.7562 - accuracy: 0.53 - ETA: 3:04 - loss: 1.7663 - accuracy: 0.53 - ETA: 3:03 - loss: 1.7909 - accuracy: 0.53 - ETA: 3:02 - loss: 1.7959 - accuracy: 0.52 - ETA: 3:01 - loss: 1.7773 - accuracy: 0.53 - ETA: 3:00 - loss: 1.7719 - accuracy: 0.53 - ETA: 2:59 - loss: 1.7719 - accuracy: 0.53 - ETA: 2:57 - loss: 1.7893 - accuracy: 0.53 - ETA: 2:56 - loss: 1.7951 - accuracy: 0.52 - ETA: 2:54 - loss: 1.7841 - accuracy: 0.53 - ETA: 2:53 - loss: 1.7864 - accuracy: 0.53 - ETA: 2:52 - loss: 1.7981 - accuracy: 0.52 - ETA: 2:50 - loss: 1.7996 - accuracy: 0.52 - ETA: 2:48 - loss: 1.8103 - accuracy: 0.52 - ETA: 2:47 - loss: 1.8006 - accuracy: 0.52 - ETA: 2:45 - loss: 1.7835 - accuracy: 0.53 - ETA: 2:44 - loss: 1.7974 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8259 - accuracy: 0.53 - ETA: 2:41 - loss: 1.8235 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8216 - accuracy: 0.53 - ETA: 2:39 - loss: 1.8206 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8128 - accuracy: 0.53 - ETA: 2:37 - loss: 1.8207 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8123 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8048 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8028 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8001 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8046 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8019 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8071 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8064 - accuracy: 0.53 - ETA: 2:31 - loss: 1.7971 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8001 - accuracy: 0.53 - ETA: 2:28 - loss: 1.8001 - accuracy: 0.53 - ETA: 2:26 - loss: 1.8063 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8075 - accuracy: 0.53 - ETA: 2:23 - loss: 1.8059 - accuracy: 0.53 - ETA: 2:22 - loss: 1.8106 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8126 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8041 - accuracy: 0.53 - ETA: 2:17 - loss: 1.7976 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8006 - accuracy: 0.53 - ETA: 2:14 - loss: 1.7983 - accuracy: 0.53 - ETA: 2:13 - loss: 1.7983 - accuracy: 0.53 - ETA: 2:11 - loss: 1.7957 - accuracy: 0.53 - ETA: 2:10 - loss: 1.7955 - accuracy: 0.53 - ETA: 2:08 - loss: 1.7900 - accuracy: 0.53 - ETA: 2:07 - loss: 1.7871 - accuracy: 0.53 - ETA: 2:05 - loss: 1.7835 - accuracy: 0.53 - ETA: 2:04 - loss: 1.7894 - accuracy: 0.53 - ETA: 2:03 - loss: 1.7955 - accuracy: 0.53 - ETA: 2:01 - loss: 1.7976 - accuracy: 0.53 - ETA: 2:00 - loss: 1.7992 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8010 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8036 - accuracy: 0.53 - ETA: 1:55 - loss: 1.7979 - accuracy: 0.53 - ETA: 1:54 - loss: 1.7957 - accuracy: 0.53 - ETA: 1:52 - loss: 1.7957 - accuracy: 0.53 - ETA: 1:51 - loss: 1.7947 - accuracy: 0.53 - ETA: 1:49 - loss: 1.7915 - accuracy: 0.53 - ETA: 1:48 - loss: 1.7918 - accuracy: 0.53 - ETA: 1:46 - loss: 1.7928 - accuracy: 0.53 - ETA: 1:45 - loss: 1.7905 - accuracy: 0.53 - ETA: 1:43 - loss: 1.7871 - accuracy: 0.53 - ETA: 1:42 - loss: 1.7860 - accuracy: 0.53 - ETA: 1:40 - loss: 1.7861 - accuracy: 0.53 - ETA: 1:39 - loss: 1.7938 - accuracy: 0.53 - ETA: 1:38 - loss: 1.7935 - accuracy: 0.53 - ETA: 1:36 - loss: 1.7956 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8045 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8022 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8020 - accuracy: 0.53 - ETA: 1:30 - loss: 1.7996 - accuracy: 0.53 - ETA: 1:29 - loss: 1.7978 - accuracy: 0.53 - ETA: 1:28 - loss: 1.7971 - accuracy: 0.53 - ETA: 1:26 - loss: 1.7960 - accuracy: 0.53 - ETA: 1:25 - loss: 1.7985 - accuracy: 0.53 - ETA: 1:23 - loss: 1.8005 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8039 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8056 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8072 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8062 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8058 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8046 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8040 - accuracy: 0.53 - ETA: 1:12 - loss: 1.8035 - accuracy: 0.53 - ETA: 1:10 - loss: 1.7995 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8047 - accuracy: 0.53 - ETA: 1:08 - loss: 1.8063 - accuracy: 0.53 - ETA: 1:06 - loss: 1.8052 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8048 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8065 - accuracy: 0.53 - ETA: 1:02 - loss: 1.8037 - accuracy: 0.53 - ETA: 1:01 - loss: 1.7993 - accuracy: 0.53 - ETA: 59s - loss: 1.8018 - accuracy: 0.5386 - ETA: 58s - loss: 1.8021 - accuracy: 0.538 - ETA: 56s - loss: 1.8198 - accuracy: 0.538 - ETA: 55s - loss: 1.8177 - accuracy: 0.538 - ETA: 54s - loss: 1.8167 - accuracy: 0.538 - ETA: 52s - loss: 1.8160 - accuracy: 0.538 - ETA: 51s - loss: 1.8136 - accuracy: 0.538 - ETA: 49s - loss: 1.8151 - accuracy: 0.538 - ETA: 48s - loss: 1.8133 - accuracy: 0.538 - ETA: 47s - loss: 1.8150 - accuracy: 0.538 - ETA: 45s - loss: 1.8139 - accuracy: 0.538 - ETA: 44s - loss: 1.8126 - accuracy: 0.538 - ETA: 42s - loss: 1.8194 - accuracy: 0.537 - ETA: 41s - loss: 1.8210 - accuracy: 0.537 - ETA: 40s - loss: 1.8178 - accuracy: 0.537 - ETA: 38s - loss: 1.8175 - accuracy: 0.537 - ETA: 37s - loss: 1.8180 - accuracy: 0.537 - ETA: 35s - loss: 1.8179 - accuracy: 0.536 - ETA: 34s - loss: 1.8176 - accuracy: 0.536 - ETA: 33s - loss: 1.8187 - accuracy: 0.536 - ETA: 31s - loss: 1.8180 - accuracy: 0.535 - ETA: 30s - loss: 1.8176 - accuracy: 0.535 - ETA: 28s - loss: 1.8164 - accuracy: 0.536 - ETA: 27s - loss: 1.8165 - accuracy: 0.536 - ETA: 26s - loss: 1.8156 - accuracy: 0.536 - ETA: 24s - loss: 1.8145 - accuracy: 0.536 - ETA: 23s - loss: 1.8133 - accuracy: 0.536 - ETA: 22s - loss: 1.8129 - accuracy: 0.536 - ETA: 20s - loss: 1.8172 - accuracy: 0.536 - ETA: 19s - loss: 1.8145 - accuracy: 0.536 - ETA: 17s - loss: 1.8136 - accuracy: 0.536 - ETA: 16s - loss: 1.8136 - accuracy: 0.536 - ETA: 15s - loss: 1.8152 - accuracy: 0.536 - ETA: 13s - loss: 1.8130 - accuracy: 0.536 - ETA: 12s - loss: 1.8106 - accuracy: 0.536 - ETA: 10s - loss: 1.8114 - accuracy: 0.536 - ETA: 9s - loss: 1.8130 - accuracy: 0.536 - ETA: 8s - loss: 1.8122 - accuracy: 0.53 - ETA: 6s - loss: 1.8117 - accuracy: 0.53 - ETA: 5s - loss: 1.8111 - accuracy: 0.53 - ETA: 3s - loss: 1.8094 - accuracy: 0.53 - ETA: 2s - loss: 1.8261 - accuracy: 0.53 - ETA: 1s - loss: 1.8261 - accuracy: 0.53 - 220s 11ms/step - loss: 1.8267 - accuracy: 0.5369 - val_loss: 1.9386 - val_accuracy: 0.5898\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:15 - loss: 1.8655 - accuracy: 0.47 - ETA: 3:21 - loss: 1.7379 - accuracy: 0.49 - ETA: 3:22 - loss: 1.8365 - accuracy: 0.49 - ETA: 3:21 - loss: 1.8200 - accuracy: 0.50 - ETA: 3:19 - loss: 1.9113 - accuracy: 0.50 - ETA: 3:16 - loss: 1.9580 - accuracy: 0.49 - ETA: 3:15 - loss: 1.9305 - accuracy: 0.49 - ETA: 3:14 - loss: 1.9420 - accuracy: 0.49 - ETA: 3:13 - loss: 1.9485 - accuracy: 0.49 - ETA: 3:13 - loss: 1.9088 - accuracy: 0.50 - ETA: 3:11 - loss: 1.9132 - accuracy: 0.51 - ETA: 3:10 - loss: 1.8831 - accuracy: 0.51 - ETA: 3:09 - loss: 1.8714 - accuracy: 0.51 - ETA: 3:07 - loss: 1.8193 - accuracy: 0.52 - ETA: 3:05 - loss: 1.8106 - accuracy: 0.53 - ETA: 3:03 - loss: 1.8066 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8230 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8189 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8160 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8101 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8108 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8228 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8216 - accuracy: 0.53 - ETA: 2:52 - loss: 1.7973 - accuracy: 0.54 - ETA: 2:51 - loss: 1.8006 - accuracy: 0.54 - ETA: 2:50 - loss: 1.8030 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7921 - accuracy: 0.54 - ETA: 2:47 - loss: 1.8030 - accuracy: 0.53 - ETA: 2:46 - loss: 1.8014 - accuracy: 0.53 - ETA: 2:44 - loss: 1.7998 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8005 - accuracy: 0.54 - ETA: 2:42 - loss: 1.7952 - accuracy: 0.54 - ETA: 2:40 - loss: 1.8052 - accuracy: 0.53 - ETA: 2:39 - loss: 1.7969 - accuracy: 0.53 - ETA: 2:38 - loss: 1.7968 - accuracy: 0.53 - ETA: 2:36 - loss: 1.7898 - accuracy: 0.53 - ETA: 2:35 - loss: 1.7778 - accuracy: 0.54 - ETA: 2:33 - loss: 1.8366 - accuracy: 0.54 - ETA: 2:32 - loss: 1.8342 - accuracy: 0.54 - ETA: 2:31 - loss: 1.8301 - accuracy: 0.54 - ETA: 2:29 - loss: 1.8264 - accuracy: 0.54 - ETA: 2:28 - loss: 1.8215 - accuracy: 0.54 - ETA: 2:27 - loss: 1.8131 - accuracy: 0.54 - ETA: 2:25 - loss: 1.8059 - accuracy: 0.54 - ETA: 2:24 - loss: 1.8026 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7979 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7917 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7902 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7852 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7923 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7956 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7984 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7946 - accuracy: 0.54 - ETA: 2:11 - loss: 1.7965 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7914 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7877 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7867 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7873 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7870 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7871 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7894 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7857 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7839 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7825 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7811 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7810 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7781 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7737 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7769 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7729 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7723 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7718 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7779 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7793 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7784 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7769 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7777 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7744 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7699 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7661 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7646 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7633 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7672 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7664 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7669 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7639 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7625 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7629 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7640 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7663 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7698 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7710 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7731 - accuracy: 0.53 - ETA: 1:17 - loss: 1.7722 - accuracy: 0.53 - ETA: 1:15 - loss: 1.7713 - accuracy: 0.53 - ETA: 1:14 - loss: 1.7681 - accuracy: 0.53 - ETA: 1:13 - loss: 1.7715 - accuracy: 0.53 - ETA: 1:12 - loss: 1.7735 - accuracy: 0.53 - ETA: 1:10 - loss: 1.7744 - accuracy: 0.53 - ETA: 1:09 - loss: 1.7739 - accuracy: 0.53 - ETA: 1:08 - loss: 1.7728 - accuracy: 0.53 - ETA: 1:06 - loss: 1.7728 - accuracy: 0.53 - ETA: 1:05 - loss: 1.7758 - accuracy: 0.53 - ETA: 1:03 - loss: 1.7748 - accuracy: 0.53 - ETA: 1:02 - loss: 1.7730 - accuracy: 0.53 - ETA: 1:01 - loss: 1.7709 - accuracy: 0.53 - ETA: 59s - loss: 1.7713 - accuracy: 0.5394 - ETA: 58s - loss: 1.7761 - accuracy: 0.538 - ETA: 57s - loss: 1.7735 - accuracy: 0.539 - ETA: 55s - loss: 1.7754 - accuracy: 0.538 - ETA: 54s - loss: 1.7765 - accuracy: 0.539 - ETA: 53s - loss: 1.7760 - accuracy: 0.539 - ETA: 51s - loss: 1.7753 - accuracy: 0.539 - ETA: 50s - loss: 1.7808 - accuracy: 0.538 - ETA: 48s - loss: 1.7807 - accuracy: 0.538 - ETA: 47s - loss: 1.7826 - accuracy: 0.537 - ETA: 46s - loss: 1.7846 - accuracy: 0.537 - ETA: 44s - loss: 1.7830 - accuracy: 0.537 - ETA: 43s - loss: 1.7826 - accuracy: 0.537 - ETA: 42s - loss: 1.7820 - accuracy: 0.537 - ETA: 40s - loss: 1.7833 - accuracy: 0.537 - ETA: 39s - loss: 1.7835 - accuracy: 0.537 - ETA: 38s - loss: 1.7855 - accuracy: 0.536 - ETA: 36s - loss: 1.7845 - accuracy: 0.536 - ETA: 35s - loss: 1.7829 - accuracy: 0.537 - ETA: 33s - loss: 1.7818 - accuracy: 0.537 - ETA: 32s - loss: 1.7835 - accuracy: 0.536 - ETA: 31s - loss: 1.7835 - accuracy: 0.536 - ETA: 29s - loss: 1.7802 - accuracy: 0.536 - ETA: 28s - loss: 1.7792 - accuracy: 0.537 - ETA: 27s - loss: 1.7786 - accuracy: 0.537 - ETA: 25s - loss: 1.7792 - accuracy: 0.537 - ETA: 24s - loss: 1.7791 - accuracy: 0.537 - ETA: 23s - loss: 1.7782 - accuracy: 0.537 - ETA: 21s - loss: 1.7769 - accuracy: 0.537 - ETA: 20s - loss: 1.7769 - accuracy: 0.537 - ETA: 18s - loss: 1.7765 - accuracy: 0.537 - ETA: 17s - loss: 1.7742 - accuracy: 0.538 - ETA: 16s - loss: 1.7746 - accuracy: 0.538 - ETA: 14s - loss: 1.7748 - accuracy: 0.538 - ETA: 13s - loss: 1.7775 - accuracy: 0.538 - ETA: 12s - loss: 1.7782 - accuracy: 0.537 - ETA: 10s - loss: 1.7773 - accuracy: 0.537 - ETA: 9s - loss: 1.7759 - accuracy: 0.537 - ETA: 8s - loss: 1.7756 - accuracy: 0.53 - ETA: 6s - loss: 1.7749 - accuracy: 0.53 - ETA: 5s - loss: 1.7730 - accuracy: 0.53 - ETA: 3s - loss: 1.7711 - accuracy: 0.53 - ETA: 2s - loss: 1.7693 - accuracy: 0.53 - ETA: 1s - loss: 1.7685 - accuracy: 0.53 - 216s 11ms/step - loss: 1.7687 - accuracy: 0.5387 - val_loss: 1.8710 - val_accuracy: 0.5947\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:35 - loss: 1.7328 - accuracy: 0.53 - ETA: 3:30 - loss: 1.7083 - accuracy: 0.55 - ETA: 3:28 - loss: 1.6979 - accuracy: 0.53 - ETA: 3:26 - loss: 1.6602 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7187 - accuracy: 0.54 - ETA: 3:22 - loss: 1.6879 - accuracy: 0.55 - ETA: 3:20 - loss: 1.7456 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7156 - accuracy: 0.54 - ETA: 3:15 - loss: 1.6964 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7109 - accuracy: 0.55 - ETA: 3:12 - loss: 1.7256 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7094 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7131 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7138 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7224 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7354 - accuracy: 0.53 - ETA: 3:03 - loss: 1.7394 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7303 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7310 - accuracy: 0.53 - ETA: 2:58 - loss: 1.7381 - accuracy: 0.53 - ETA: 2:56 - loss: 1.7473 - accuracy: 0.53 - ETA: 2:55 - loss: 1.7409 - accuracy: 0.53 - ETA: 2:53 - loss: 1.7303 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7402 - accuracy: 0.54 - ETA: 2:50 - loss: 1.7341 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7662 - accuracy: 0.53 - ETA: 2:48 - loss: 1.7613 - accuracy: 0.53 - ETA: 2:47 - loss: 1.7652 - accuracy: 0.53 - ETA: 2:46 - loss: 1.7659 - accuracy: 0.53 - ETA: 2:44 - loss: 1.7698 - accuracy: 0.53 - ETA: 2:43 - loss: 1.7590 - accuracy: 0.53 - ETA: 2:42 - loss: 1.7505 - accuracy: 0.53 - ETA: 2:40 - loss: 1.7538 - accuracy: 0.53 - ETA: 2:39 - loss: 1.7589 - accuracy: 0.53 - ETA: 2:37 - loss: 1.7706 - accuracy: 0.53 - ETA: 2:36 - loss: 1.7688 - accuracy: 0.53 - ETA: 2:35 - loss: 1.7722 - accuracy: 0.53 - ETA: 2:33 - loss: 1.7813 - accuracy: 0.53 - ETA: 2:32 - loss: 1.7811 - accuracy: 0.53 - ETA: 2:31 - loss: 1.7800 - accuracy: 0.53 - ETA: 2:30 - loss: 1.7848 - accuracy: 0.53 - ETA: 2:28 - loss: 1.7839 - accuracy: 0.53 - ETA: 2:27 - loss: 1.7897 - accuracy: 0.53 - ETA: 2:25 - loss: 1.7957 - accuracy: 0.53 - ETA: 2:24 - loss: 1.7896 - accuracy: 0.53 - ETA: 2:22 - loss: 1.7914 - accuracy: 0.53 - ETA: 2:21 - loss: 1.7860 - accuracy: 0.53 - ETA: 2:20 - loss: 1.7809 - accuracy: 0.53 - ETA: 2:18 - loss: 1.7772 - accuracy: 0.53 - ETA: 2:17 - loss: 1.7802 - accuracy: 0.53 - ETA: 2:16 - loss: 1.7769 - accuracy: 0.53 - ETA: 2:15 - loss: 1.7799 - accuracy: 0.53 - ETA: 2:13 - loss: 1.7792 - accuracy: 0.53 - ETA: 2:12 - loss: 1.7807 - accuracy: 0.53 - ETA: 2:10 - loss: 1.7818 - accuracy: 0.53 - ETA: 2:09 - loss: 1.7818 - accuracy: 0.53 - ETA: 2:08 - loss: 1.7803 - accuracy: 0.53 - ETA: 2:06 - loss: 1.7769 - accuracy: 0.53 - ETA: 2:05 - loss: 1.7749 - accuracy: 0.53 - ETA: 2:03 - loss: 1.7717 - accuracy: 0.53 - ETA: 2:02 - loss: 1.7714 - accuracy: 0.53 - ETA: 2:01 - loss: 1.7719 - accuracy: 0.53 - ETA: 1:59 - loss: 1.7710 - accuracy: 0.53 - ETA: 1:58 - loss: 1.7673 - accuracy: 0.53 - ETA: 1:57 - loss: 1.7677 - accuracy: 0.53 - ETA: 1:55 - loss: 1.7664 - accuracy: 0.53 - ETA: 1:54 - loss: 1.7688 - accuracy: 0.53 - ETA: 1:52 - loss: 1.7686 - accuracy: 0.53 - ETA: 1:51 - loss: 1.7671 - accuracy: 0.53 - ETA: 1:50 - loss: 1.7697 - accuracy: 0.53 - ETA: 1:48 - loss: 1.7708 - accuracy: 0.53 - ETA: 1:47 - loss: 1.7706 - accuracy: 0.53 - ETA: 1:45 - loss: 1.7751 - accuracy: 0.53 - ETA: 1:44 - loss: 1.7751 - accuracy: 0.53 - ETA: 1:43 - loss: 1.7689 - accuracy: 0.53 - ETA: 1:42 - loss: 1.7661 - accuracy: 0.53 - ETA: 1:40 - loss: 1.7618 - accuracy: 0.53 - ETA: 1:39 - loss: 1.7616 - accuracy: 0.53 - ETA: 1:38 - loss: 1.7615 - accuracy: 0.53 - ETA: 1:36 - loss: 1.7602 - accuracy: 0.53 - ETA: 1:35 - loss: 1.7608 - accuracy: 0.53 - ETA: 1:33 - loss: 1.7611 - accuracy: 0.53 - ETA: 1:32 - loss: 1.7611 - accuracy: 0.53 - ETA: 1:31 - loss: 1.7943 - accuracy: 0.53 - ETA: 1:29 - loss: 1.7962 - accuracy: 0.53 - ETA: 1:28 - loss: 1.7960 - accuracy: 0.53 - ETA: 1:27 - loss: 1.7931 - accuracy: 0.53 - ETA: 1:25 - loss: 1.7927 - accuracy: 0.53 - ETA: 1:24 - loss: 1.7941 - accuracy: 0.53 - ETA: 1:23 - loss: 1.7910 - accuracy: 0.53 - ETA: 1:21 - loss: 1.7836 - accuracy: 0.53 - ETA: 1:20 - loss: 1.7788 - accuracy: 0.53 - ETA: 1:19 - loss: 1.7826 - accuracy: 0.53 - ETA: 1:17 - loss: 1.7820 - accuracy: 0.53 - ETA: 1:16 - loss: 1.7775 - accuracy: 0.53 - ETA: 1:14 - loss: 1.7787 - accuracy: 0.53 - ETA: 1:13 - loss: 1.7803 - accuracy: 0.53 - ETA: 1:12 - loss: 1.7804 - accuracy: 0.53 - ETA: 1:10 - loss: 1.7801 - accuracy: 0.53 - ETA: 1:09 - loss: 1.7775 - accuracy: 0.53 - ETA: 1:08 - loss: 1.7761 - accuracy: 0.53 - ETA: 1:06 - loss: 1.7767 - accuracy: 0.53 - ETA: 1:05 - loss: 1.7789 - accuracy: 0.53 - ETA: 1:04 - loss: 1.7790 - accuracy: 0.53 - ETA: 1:02 - loss: 1.7840 - accuracy: 0.53 - ETA: 1:01 - loss: 1.7821 - accuracy: 0.53 - ETA: 59s - loss: 1.7818 - accuracy: 0.5374 - ETA: 58s - loss: 1.7824 - accuracy: 0.537 - ETA: 57s - loss: 1.7857 - accuracy: 0.536 - ETA: 55s - loss: 1.7838 - accuracy: 0.537 - ETA: 54s - loss: 1.7795 - accuracy: 0.538 - ETA: 53s - loss: 1.7806 - accuracy: 0.538 - ETA: 51s - loss: 1.7844 - accuracy: 0.538 - ETA: 50s - loss: 1.7853 - accuracy: 0.538 - ETA: 49s - loss: 1.7823 - accuracy: 0.538 - ETA: 47s - loss: 1.7813 - accuracy: 0.538 - ETA: 46s - loss: 1.7825 - accuracy: 0.538 - ETA: 45s - loss: 1.7845 - accuracy: 0.537 - ETA: 43s - loss: 1.7881 - accuracy: 0.537 - ETA: 42s - loss: 1.7891 - accuracy: 0.537 - ETA: 40s - loss: 1.7864 - accuracy: 0.538 - ETA: 39s - loss: 1.7861 - accuracy: 0.537 - ETA: 38s - loss: 1.7890 - accuracy: 0.537 - ETA: 36s - loss: 1.7875 - accuracy: 0.537 - ETA: 35s - loss: 1.7897 - accuracy: 0.537 - ETA: 34s - loss: 1.7881 - accuracy: 0.537 - ETA: 32s - loss: 1.7874 - accuracy: 0.538 - ETA: 31s - loss: 1.7909 - accuracy: 0.537 - ETA: 29s - loss: 1.7878 - accuracy: 0.537 - ETA: 28s - loss: 1.7878 - accuracy: 0.537 - ETA: 27s - loss: 1.7896 - accuracy: 0.537 - ETA: 25s - loss: 1.7884 - accuracy: 0.537 - ETA: 24s - loss: 1.7896 - accuracy: 0.537 - ETA: 23s - loss: 1.7887 - accuracy: 0.537 - ETA: 21s - loss: 1.7896 - accuracy: 0.536 - ETA: 20s - loss: 1.7888 - accuracy: 0.536 - ETA: 18s - loss: 1.7864 - accuracy: 0.537 - ETA: 17s - loss: 1.7857 - accuracy: 0.537 - ETA: 16s - loss: 1.7843 - accuracy: 0.537 - ETA: 14s - loss: 1.7820 - accuracy: 0.537 - ETA: 13s - loss: 1.7832 - accuracy: 0.537 - ETA: 12s - loss: 1.7795 - accuracy: 0.538 - ETA: 10s - loss: 1.7781 - accuracy: 0.538 - ETA: 9s - loss: 1.7794 - accuracy: 0.538 - ETA: 8s - loss: 1.7782 - accuracy: 0.53 - ETA: 6s - loss: 1.7808 - accuracy: 0.53 - ETA: 5s - loss: 1.7796 - accuracy: 0.53 - ETA: 3s - loss: 1.7773 - accuracy: 0.53 - ETA: 2s - loss: 1.7773 - accuracy: 0.53 - ETA: 1s - loss: 1.7759 - accuracy: 0.53 - 218s 11ms/step - loss: 1.7758 - accuracy: 0.5389 - val_loss: 2.0374 - val_accuracy: 0.6043\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:28 - loss: 1.3792 - accuracy: 0.63 - ETA: 3:25 - loss: 1.5648 - accuracy: 0.58 - ETA: 3:22 - loss: 1.6039 - accuracy: 0.58 - ETA: 3:20 - loss: 1.6178 - accuracy: 0.57 - ETA: 3:17 - loss: 1.6565 - accuracy: 0.56 - ETA: 3:17 - loss: 1.7140 - accuracy: 0.55 - ETA: 3:16 - loss: 1.7345 - accuracy: 0.54 - ETA: 3:15 - loss: 1.7354 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7615 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7524 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7623 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7574 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7689 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7755 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7608 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7624 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7584 - accuracy: 0.55 - ETA: 2:58 - loss: 1.7724 - accuracy: 0.55 - ETA: 2:57 - loss: 1.7609 - accuracy: 0.55 - ETA: 2:57 - loss: 1.7708 - accuracy: 0.55 - ETA: 2:55 - loss: 1.7709 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7696 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7719 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7737 - accuracy: 0.54 - ETA: 2:50 - loss: 1.7664 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7495 - accuracy: 0.55 - ETA: 2:48 - loss: 1.7550 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7552 - accuracy: 0.54 - ETA: 2:45 - loss: 1.8840 - accuracy: 0.54 - ETA: 2:43 - loss: 1.8697 - accuracy: 0.54 - ETA: 2:42 - loss: 1.8857 - accuracy: 0.54 - ETA: 2:41 - loss: 1.8796 - accuracy: 0.54 - ETA: 2:40 - loss: 1.8930 - accuracy: 0.54 - ETA: 2:38 - loss: 1.8917 - accuracy: 0.54 - ETA: 2:37 - loss: 1.8958 - accuracy: 0.54 - ETA: 2:35 - loss: 1.8886 - accuracy: 0.54 - ETA: 2:34 - loss: 1.8760 - accuracy: 0.55 - ETA: 2:32 - loss: 1.8755 - accuracy: 0.54 - ETA: 2:31 - loss: 1.8762 - accuracy: 0.54 - ETA: 2:30 - loss: 1.8763 - accuracy: 0.54 - ETA: 2:28 - loss: 1.8775 - accuracy: 0.54 - ETA: 2:27 - loss: 1.8720 - accuracy: 0.54 - ETA: 2:26 - loss: 1.8713 - accuracy: 0.54 - ETA: 2:24 - loss: 1.8728 - accuracy: 0.54 - ETA: 2:23 - loss: 1.8785 - accuracy: 0.54 - ETA: 2:22 - loss: 1.8742 - accuracy: 0.54 - ETA: 2:20 - loss: 1.8682 - accuracy: 0.54 - ETA: 2:19 - loss: 1.8658 - accuracy: 0.54 - ETA: 2:18 - loss: 1.8553 - accuracy: 0.54 - ETA: 2:16 - loss: 1.8464 - accuracy: 0.54 - ETA: 2:15 - loss: 1.8489 - accuracy: 0.54 - ETA: 2:14 - loss: 1.8435 - accuracy: 0.54 - ETA: 2:12 - loss: 1.8417 - accuracy: 0.54 - ETA: 2:11 - loss: 1.8489 - accuracy: 0.54 - ETA: 2:10 - loss: 1.8527 - accuracy: 0.54 - ETA: 2:09 - loss: 1.8494 - accuracy: 0.54 - ETA: 2:07 - loss: 1.8460 - accuracy: 0.54 - ETA: 2:06 - loss: 1.8563 - accuracy: 0.54 - ETA: 2:04 - loss: 1.8504 - accuracy: 0.54 - ETA: 2:03 - loss: 1.8652 - accuracy: 0.54 - ETA: 2:02 - loss: 1.8590 - accuracy: 0.54 - ETA: 2:00 - loss: 1.8558 - accuracy: 0.54 - ETA: 1:59 - loss: 1.8548 - accuracy: 0.54 - ETA: 1:58 - loss: 1.8487 - accuracy: 0.54 - ETA: 1:56 - loss: 1.8480 - accuracy: 0.54 - ETA: 1:55 - loss: 1.8428 - accuracy: 0.54 - ETA: 1:54 - loss: 1.8483 - accuracy: 0.54 - ETA: 1:52 - loss: 1.8444 - accuracy: 0.54 - ETA: 1:51 - loss: 1.8431 - accuracy: 0.54 - ETA: 1:50 - loss: 1.8444 - accuracy: 0.54 - ETA: 1:48 - loss: 1.8384 - accuracy: 0.54 - ETA: 1:47 - loss: 1.8349 - accuracy: 0.54 - ETA: 1:45 - loss: 1.8376 - accuracy: 0.54 - ETA: 1:44 - loss: 1.8342 - accuracy: 0.54 - ETA: 1:43 - loss: 1.8458 - accuracy: 0.54 - ETA: 1:41 - loss: 1.8428 - accuracy: 0.54 - ETA: 1:40 - loss: 1.8398 - accuracy: 0.54 - ETA: 1:39 - loss: 1.8381 - accuracy: 0.54 - ETA: 1:37 - loss: 1.8387 - accuracy: 0.54 - ETA: 1:36 - loss: 1.8395 - accuracy: 0.54 - ETA: 1:35 - loss: 1.8372 - accuracy: 0.54 - ETA: 1:33 - loss: 1.8381 - accuracy: 0.54 - ETA: 1:32 - loss: 1.8392 - accuracy: 0.54 - ETA: 1:31 - loss: 1.8350 - accuracy: 0.54 - ETA: 1:29 - loss: 1.8359 - accuracy: 0.54 - ETA: 1:28 - loss: 1.8355 - accuracy: 0.54 - ETA: 1:26 - loss: 1.8332 - accuracy: 0.54 - ETA: 1:25 - loss: 1.8366 - accuracy: 0.54 - ETA: 1:24 - loss: 1.8377 - accuracy: 0.54 - ETA: 1:22 - loss: 1.8366 - accuracy: 0.54 - ETA: 1:21 - loss: 1.8379 - accuracy: 0.54 - ETA: 1:20 - loss: 1.8345 - accuracy: 0.54 - ETA: 1:18 - loss: 1.8353 - accuracy: 0.54 - ETA: 1:17 - loss: 1.8355 - accuracy: 0.54 - ETA: 1:16 - loss: 1.8331 - accuracy: 0.54 - ETA: 1:14 - loss: 1.8312 - accuracy: 0.54 - ETA: 1:13 - loss: 1.8306 - accuracy: 0.54 - ETA: 1:12 - loss: 1.8284 - accuracy: 0.54 - ETA: 1:10 - loss: 1.8299 - accuracy: 0.54 - ETA: 1:09 - loss: 1.8313 - accuracy: 0.54 - ETA: 1:07 - loss: 1.8292 - accuracy: 0.54 - ETA: 1:06 - loss: 1.8267 - accuracy: 0.54 - ETA: 1:05 - loss: 1.8270 - accuracy: 0.54 - ETA: 1:03 - loss: 1.8286 - accuracy: 0.54 - ETA: 1:02 - loss: 1.8277 - accuracy: 0.54 - ETA: 1:01 - loss: 1.8270 - accuracy: 0.54 - ETA: 59s - loss: 1.8246 - accuracy: 0.5439 - ETA: 58s - loss: 1.8272 - accuracy: 0.543 - ETA: 56s - loss: 1.8274 - accuracy: 0.542 - ETA: 55s - loss: 1.8301 - accuracy: 0.543 - ETA: 54s - loss: 1.8289 - accuracy: 0.543 - ETA: 52s - loss: 1.8320 - accuracy: 0.543 - ETA: 51s - loss: 1.8309 - accuracy: 0.543 - ETA: 50s - loss: 1.8508 - accuracy: 0.542 - ETA: 48s - loss: 1.8488 - accuracy: 0.542 - ETA: 47s - loss: 1.8456 - accuracy: 0.543 - ETA: 46s - loss: 1.8489 - accuracy: 0.542 - ETA: 44s - loss: 1.8461 - accuracy: 0.543 - ETA: 43s - loss: 1.8473 - accuracy: 0.543 - ETA: 42s - loss: 1.8446 - accuracy: 0.543 - ETA: 40s - loss: 1.8427 - accuracy: 0.544 - ETA: 39s - loss: 1.8456 - accuracy: 0.544 - ETA: 37s - loss: 1.8453 - accuracy: 0.544 - ETA: 36s - loss: 1.8531 - accuracy: 0.544 - ETA: 35s - loss: 1.8526 - accuracy: 0.544 - ETA: 33s - loss: 1.8536 - accuracy: 0.544 - ETA: 32s - loss: 1.8570 - accuracy: 0.543 - ETA: 31s - loss: 1.8587 - accuracy: 0.543 - ETA: 29s - loss: 1.8573 - accuracy: 0.543 - ETA: 28s - loss: 1.8700 - accuracy: 0.543 - ETA: 27s - loss: 1.8690 - accuracy: 0.543 - ETA: 25s - loss: 1.8711 - accuracy: 0.543 - ETA: 24s - loss: 1.8698 - accuracy: 0.543 - ETA: 22s - loss: 1.8714 - accuracy: 0.543 - ETA: 21s - loss: 1.8746 - accuracy: 0.543 - ETA: 20s - loss: 1.8732 - accuracy: 0.543 - ETA: 18s - loss: 1.8722 - accuracy: 0.544 - ETA: 17s - loss: 1.8704 - accuracy: 0.543 - ETA: 16s - loss: 1.8717 - accuracy: 0.543 - ETA: 14s - loss: 1.8706 - accuracy: 0.542 - ETA: 13s - loss: 1.8695 - accuracy: 0.542 - ETA: 12s - loss: 1.8685 - accuracy: 0.542 - ETA: 10s - loss: 1.8657 - accuracy: 0.543 - ETA: 9s - loss: 1.8640 - accuracy: 0.543 - ETA: 7s - loss: 1.8639 - accuracy: 0.54 - ETA: 6s - loss: 1.8656 - accuracy: 0.54 - ETA: 5s - loss: 1.8676 - accuracy: 0.54 - ETA: 3s - loss: 1.8666 - accuracy: 0.54 - ETA: 2s - loss: 1.8668 - accuracy: 0.54 - ETA: 1s - loss: 1.8663 - accuracy: 0.54 - 217s 11ms/step - loss: 1.8643 - accuracy: 0.5435 - val_loss: 1.9928 - val_accuracy: 0.6053\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:27 - loss: 2.0007 - accuracy: 0.53 - ETA: 3:27 - loss: 2.2044 - accuracy: 0.49 - ETA: 3:25 - loss: 2.0976 - accuracy: 0.48 - ETA: 3:22 - loss: 1.9467 - accuracy: 0.50 - ETA: 3:20 - loss: 1.9004 - accuracy: 0.51 - ETA: 3:17 - loss: 1.7932 - accuracy: 0.53 - ETA: 3:16 - loss: 1.7570 - accuracy: 0.53 - ETA: 3:15 - loss: 1.7443 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7411 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7296 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7462 - accuracy: 0.54 - ETA: 3:09 - loss: 1.7455 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7453 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7283 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7124 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7381 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7489 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7336 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7386 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7375 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7367 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7333 - accuracy: 0.55 - ETA: 2:54 - loss: 1.7497 - accuracy: 0.55 - ETA: 2:52 - loss: 1.7509 - accuracy: 0.55 - ETA: 2:51 - loss: 1.7444 - accuracy: 0.55 - ETA: 2:50 - loss: 1.7367 - accuracy: 0.55 - ETA: 2:49 - loss: 1.7353 - accuracy: 0.55 - ETA: 2:47 - loss: 1.7373 - accuracy: 0.54 - ETA: 2:46 - loss: 1.7259 - accuracy: 0.55 - ETA: 2:45 - loss: 1.7201 - accuracy: 0.55 - ETA: 2:43 - loss: 1.7248 - accuracy: 0.55 - ETA: 2:42 - loss: 1.7179 - accuracy: 0.55 - ETA: 2:40 - loss: 1.7326 - accuracy: 0.55 - ETA: 2:39 - loss: 1.7291 - accuracy: 0.55 - ETA: 2:37 - loss: 1.7266 - accuracy: 0.55 - ETA: 2:36 - loss: 1.7261 - accuracy: 0.55 - ETA: 2:35 - loss: 1.7247 - accuracy: 0.55 - ETA: 2:34 - loss: 1.7183 - accuracy: 0.55 - ETA: 2:32 - loss: 1.7142 - accuracy: 0.55 - ETA: 2:31 - loss: 1.7148 - accuracy: 0.55 - ETA: 2:29 - loss: 1.7177 - accuracy: 0.55 - ETA: 2:28 - loss: 1.7158 - accuracy: 0.55 - ETA: 2:27 - loss: 1.7107 - accuracy: 0.55 - ETA: 2:25 - loss: 1.7159 - accuracy: 0.55 - ETA: 2:24 - loss: 1.7160 - accuracy: 0.55 - ETA: 2:22 - loss: 1.7248 - accuracy: 0.55 - ETA: 2:21 - loss: 1.7242 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7234 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7224 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7272 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7283 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7278 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7321 - accuracy: 0.54 - ETA: 2:11 - loss: 1.7325 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7279 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7275 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7297 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7376 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7416 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7441 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7439 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7457 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7466 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7457 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7459 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7460 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7503 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7454 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7451 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7447 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7401 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7415 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7421 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7421 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7420 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7385 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7396 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7367 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7390 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7398 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7391 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7430 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7403 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7460 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7470 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7462 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7465 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7449 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7447 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7482 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7479 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7490 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7471 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7486 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7466 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7490 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7484 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7457 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7463 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7491 - accuracy: 0.54 - ETA: 1:08 - loss: 1.7511 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7486 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7488 - accuracy: 0.54 - ETA: 1:04 - loss: 1.7471 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7462 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7522 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7524 - accuracy: 0.54 - ETA: 59s - loss: 1.7504 - accuracy: 0.5435 - ETA: 57s - loss: 1.7508 - accuracy: 0.543 - ETA: 56s - loss: 1.7501 - accuracy: 0.543 - ETA: 55s - loss: 1.7525 - accuracy: 0.543 - ETA: 53s - loss: 1.7513 - accuracy: 0.543 - ETA: 52s - loss: 1.7529 - accuracy: 0.542 - ETA: 50s - loss: 1.7524 - accuracy: 0.542 - ETA: 49s - loss: 1.7502 - accuracy: 0.543 - ETA: 48s - loss: 1.7495 - accuracy: 0.542 - ETA: 46s - loss: 1.7499 - accuracy: 0.542 - ETA: 45s - loss: 1.7496 - accuracy: 0.542 - ETA: 43s - loss: 1.7509 - accuracy: 0.542 - ETA: 42s - loss: 1.7506 - accuracy: 0.542 - ETA: 41s - loss: 1.7491 - accuracy: 0.542 - ETA: 39s - loss: 1.7565 - accuracy: 0.542 - ETA: 38s - loss: 1.7571 - accuracy: 0.542 - ETA: 37s - loss: 1.7631 - accuracy: 0.541 - ETA: 35s - loss: 1.7620 - accuracy: 0.541 - ETA: 34s - loss: 1.7606 - accuracy: 0.541 - ETA: 32s - loss: 1.7577 - accuracy: 0.542 - ETA: 31s - loss: 1.7602 - accuracy: 0.541 - ETA: 30s - loss: 1.7591 - accuracy: 0.542 - ETA: 28s - loss: 1.7574 - accuracy: 0.542 - ETA: 27s - loss: 1.7597 - accuracy: 0.541 - ETA: 25s - loss: 1.7599 - accuracy: 0.541 - ETA: 24s - loss: 1.7585 - accuracy: 0.541 - ETA: 23s - loss: 1.7572 - accuracy: 0.541 - ETA: 21s - loss: 1.7595 - accuracy: 0.541 - ETA: 20s - loss: 1.7611 - accuracy: 0.541 - ETA: 19s - loss: 1.7613 - accuracy: 0.541 - ETA: 17s - loss: 1.7612 - accuracy: 0.540 - ETA: 16s - loss: 1.7632 - accuracy: 0.541 - ETA: 14s - loss: 1.7619 - accuracy: 0.541 - ETA: 13s - loss: 1.7617 - accuracy: 0.541 - ETA: 12s - loss: 1.7609 - accuracy: 0.541 - ETA: 10s - loss: 1.7601 - accuracy: 0.541 - ETA: 9s - loss: 1.7574 - accuracy: 0.542 - ETA: 8s - loss: 1.7552 - accuracy: 0.54 - ETA: 6s - loss: 1.7549 - accuracy: 0.54 - ETA: 5s - loss: 1.7542 - accuracy: 0.54 - ETA: 3s - loss: 1.7531 - accuracy: 0.54 - ETA: 2s - loss: 1.7544 - accuracy: 0.54 - ETA: 1s - loss: 1.7556 - accuracy: 0.54 - 219s 11ms/step - loss: 1.7539 - accuracy: 0.5432 - val_loss: 1.8539 - val_accuracy: 0.5939\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:27 - loss: 1.1895 - accuracy: 0.64 - ETA: 3:20 - loss: 1.4072 - accuracy: 0.60 - ETA: 3:18 - loss: 1.6183 - accuracy: 0.55 - ETA: 3:18 - loss: 1.6278 - accuracy: 0.55 - ETA: 3:19 - loss: 1.7149 - accuracy: 0.55 - ETA: 3:19 - loss: 1.7594 - accuracy: 0.54 - ETA: 3:17 - loss: 1.7625 - accuracy: 0.55 - ETA: 3:14 - loss: 1.7568 - accuracy: 0.54 - ETA: 3:13 - loss: 1.7554 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7440 - accuracy: 0.54 - ETA: 3:09 - loss: 1.7122 - accuracy: 0.55 - ETA: 3:07 - loss: 1.7223 - accuracy: 0.55 - ETA: 3:06 - loss: 1.7235 - accuracy: 0.55 - ETA: 3:05 - loss: 1.7140 - accuracy: 0.55 - ETA: 3:03 - loss: 1.7182 - accuracy: 0.54 - ETA: 3:03 - loss: 1.6972 - accuracy: 0.55 - ETA: 3:02 - loss: 1.7017 - accuracy: 0.55 - ETA: 3:01 - loss: 1.6831 - accuracy: 0.55 - ETA: 3:01 - loss: 1.6865 - accuracy: 0.55 - ETA: 2:59 - loss: 1.6627 - accuracy: 0.55 - ETA: 2:58 - loss: 1.6570 - accuracy: 0.55 - ETA: 2:56 - loss: 1.6667 - accuracy: 0.55 - ETA: 2:55 - loss: 1.6780 - accuracy: 0.55 - ETA: 2:54 - loss: 1.6718 - accuracy: 0.55 - ETA: 2:52 - loss: 1.6699 - accuracy: 0.55 - ETA: 2:51 - loss: 1.6738 - accuracy: 0.55 - ETA: 2:49 - loss: 1.6677 - accuracy: 0.55 - ETA: 2:48 - loss: 1.6703 - accuracy: 0.55 - ETA: 2:47 - loss: 1.6666 - accuracy: 0.55 - ETA: 2:46 - loss: 1.6620 - accuracy: 0.55 - ETA: 2:44 - loss: 1.6642 - accuracy: 0.55 - ETA: 2:43 - loss: 1.6645 - accuracy: 0.55 - ETA: 2:41 - loss: 1.6645 - accuracy: 0.55 - ETA: 2:40 - loss: 1.6645 - accuracy: 0.55 - ETA: 2:38 - loss: 1.6749 - accuracy: 0.55 - ETA: 2:37 - loss: 1.6725 - accuracy: 0.55 - ETA: 2:35 - loss: 1.6722 - accuracy: 0.55 - ETA: 2:34 - loss: 1.6857 - accuracy: 0.55 - ETA: 2:33 - loss: 1.6948 - accuracy: 0.55 - ETA: 2:32 - loss: 1.6912 - accuracy: 0.55 - ETA: 2:30 - loss: 1.6926 - accuracy: 0.55 - ETA: 2:29 - loss: 1.6886 - accuracy: 0.55 - ETA: 2:27 - loss: 1.6866 - accuracy: 0.55 - ETA: 2:26 - loss: 1.6869 - accuracy: 0.55 - ETA: 2:24 - loss: 1.6848 - accuracy: 0.55 - ETA: 2:23 - loss: 1.6902 - accuracy: 0.54 - ETA: 2:21 - loss: 1.6881 - accuracy: 0.54 - ETA: 2:20 - loss: 1.6919 - accuracy: 0.54 - ETA: 2:19 - loss: 1.6983 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7035 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7018 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7050 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7286 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7331 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7365 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7354 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7347 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7281 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7309 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7333 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7418 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7413 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7448 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7544 - accuracy: 0.53 - ETA: 1:57 - loss: 1.7510 - accuracy: 0.53 - ETA: 1:56 - loss: 1.7539 - accuracy: 0.53 - ETA: 1:54 - loss: 1.7510 - accuracy: 0.53 - ETA: 1:53 - loss: 1.7551 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7519 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7550 - accuracy: 0.53 - ETA: 1:49 - loss: 1.7540 - accuracy: 0.53 - ETA: 1:47 - loss: 1.7524 - accuracy: 0.53 - ETA: 1:46 - loss: 1.7509 - accuracy: 0.53 - ETA: 1:44 - loss: 1.7489 - accuracy: 0.53 - ETA: 1:43 - loss: 1.7472 - accuracy: 0.53 - ETA: 1:42 - loss: 1.7449 - accuracy: 0.53 - ETA: 1:41 - loss: 1.7509 - accuracy: 0.53 - ETA: 1:39 - loss: 1.7550 - accuracy: 0.53 - ETA: 1:38 - loss: 1.7535 - accuracy: 0.53 - ETA: 1:36 - loss: 1.7514 - accuracy: 0.53 - ETA: 1:35 - loss: 1.7525 - accuracy: 0.53 - ETA: 1:34 - loss: 1.7494 - accuracy: 0.53 - ETA: 1:32 - loss: 1.7483 - accuracy: 0.53 - ETA: 1:31 - loss: 1.7490 - accuracy: 0.53 - ETA: 1:29 - loss: 1.7511 - accuracy: 0.53 - ETA: 1:28 - loss: 1.7534 - accuracy: 0.53 - ETA: 1:27 - loss: 1.7522 - accuracy: 0.53 - ETA: 1:25 - loss: 1.7504 - accuracy: 0.53 - ETA: 1:24 - loss: 1.7510 - accuracy: 0.53 - ETA: 1:23 - loss: 1.7494 - accuracy: 0.53 - ETA: 1:21 - loss: 1.7505 - accuracy: 0.53 - ETA: 1:20 - loss: 1.7552 - accuracy: 0.53 - ETA: 1:18 - loss: 1.7554 - accuracy: 0.53 - ETA: 1:17 - loss: 1.7573 - accuracy: 0.53 - ETA: 1:16 - loss: 1.7557 - accuracy: 0.53 - ETA: 1:14 - loss: 1.7523 - accuracy: 0.53 - ETA: 1:13 - loss: 1.7520 - accuracy: 0.53 - ETA: 1:12 - loss: 1.7518 - accuracy: 0.53 - ETA: 1:10 - loss: 1.7505 - accuracy: 0.53 - ETA: 1:09 - loss: 1.7537 - accuracy: 0.53 - ETA: 1:08 - loss: 1.7568 - accuracy: 0.53 - ETA: 1:06 - loss: 1.7591 - accuracy: 0.53 - ETA: 1:05 - loss: 1.7567 - accuracy: 0.53 - ETA: 1:03 - loss: 1.7542 - accuracy: 0.53 - ETA: 1:02 - loss: 1.7522 - accuracy: 0.53 - ETA: 1:01 - loss: 1.7488 - accuracy: 0.53 - ETA: 59s - loss: 1.7456 - accuracy: 0.5401 - ETA: 58s - loss: 1.7459 - accuracy: 0.539 - ETA: 57s - loss: 1.7435 - accuracy: 0.540 - ETA: 55s - loss: 1.7436 - accuracy: 0.540 - ETA: 54s - loss: 1.7419 - accuracy: 0.540 - ETA: 53s - loss: 1.7417 - accuracy: 0.540 - ETA: 51s - loss: 1.7407 - accuracy: 0.540 - ETA: 50s - loss: 1.7406 - accuracy: 0.541 - ETA: 48s - loss: 1.7394 - accuracy: 0.541 - ETA: 47s - loss: 1.7367 - accuracy: 0.541 - ETA: 46s - loss: 1.7393 - accuracy: 0.542 - ETA: 44s - loss: 1.7427 - accuracy: 0.542 - ETA: 43s - loss: 1.7430 - accuracy: 0.542 - ETA: 42s - loss: 1.7427 - accuracy: 0.542 - ETA: 40s - loss: 1.7415 - accuracy: 0.543 - ETA: 39s - loss: 1.7400 - accuracy: 0.543 - ETA: 38s - loss: 1.7396 - accuracy: 0.542 - ETA: 36s - loss: 1.7389 - accuracy: 0.543 - ETA: 35s - loss: 1.7371 - accuracy: 0.543 - ETA: 34s - loss: 1.7383 - accuracy: 0.543 - ETA: 32s - loss: 1.7373 - accuracy: 0.543 - ETA: 31s - loss: 1.7383 - accuracy: 0.542 - ETA: 30s - loss: 1.7373 - accuracy: 0.543 - ETA: 28s - loss: 1.7377 - accuracy: 0.543 - ETA: 27s - loss: 1.7382 - accuracy: 0.543 - ETA: 25s - loss: 1.7370 - accuracy: 0.543 - ETA: 24s - loss: 1.7414 - accuracy: 0.542 - ETA: 23s - loss: 1.7433 - accuracy: 0.542 - ETA: 21s - loss: 1.7412 - accuracy: 0.542 - ETA: 20s - loss: 1.7426 - accuracy: 0.542 - ETA: 19s - loss: 1.7393 - accuracy: 0.543 - ETA: 17s - loss: 1.7408 - accuracy: 0.543 - ETA: 16s - loss: 1.7388 - accuracy: 0.543 - ETA: 14s - loss: 1.7394 - accuracy: 0.543 - ETA: 13s - loss: 1.7388 - accuracy: 0.543 - ETA: 12s - loss: 1.7380 - accuracy: 0.543 - ETA: 10s - loss: 1.7387 - accuracy: 0.543 - ETA: 9s - loss: 1.7416 - accuracy: 0.542 - ETA: 8s - loss: 1.7405 - accuracy: 0.54 - ETA: 6s - loss: 1.7386 - accuracy: 0.54 - ETA: 5s - loss: 1.7383 - accuracy: 0.54 - ETA: 3s - loss: 1.7367 - accuracy: 0.54 - ETA: 2s - loss: 1.7364 - accuracy: 0.54 - ETA: 1s - loss: 1.7354 - accuracy: 0.54 - 219s 11ms/step - loss: 1.7348 - accuracy: 0.5431 - val_loss: 1.8733 - val_accuracy: 0.5887\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:38 - loss: 1.6403 - accuracy: 0.54 - ETA: 3:28 - loss: 1.7847 - accuracy: 0.51 - ETA: 3:22 - loss: 1.8662 - accuracy: 0.51 - ETA: 3:21 - loss: 1.8016 - accuracy: 0.52 - ETA: 3:18 - loss: 1.8314 - accuracy: 0.52 - ETA: 3:18 - loss: 1.8110 - accuracy: 0.53 - ETA: 3:15 - loss: 1.7556 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7594 - accuracy: 0.54 - ETA: 3:13 - loss: 1.7550 - accuracy: 0.53 - ETA: 3:13 - loss: 1.7275 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7185 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7423 - accuracy: 0.54 - ETA: 3:09 - loss: 1.7456 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7478 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7666 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7580 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7494 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7444 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7724 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7736 - accuracy: 0.53 - ETA: 2:57 - loss: 1.7745 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8038 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8153 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8170 - accuracy: 0.53 - ETA: 2:52 - loss: 1.8226 - accuracy: 0.53 - ETA: 2:50 - loss: 1.8211 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8197 - accuracy: 0.53 - ETA: 2:48 - loss: 1.8117 - accuracy: 0.53 - ETA: 2:46 - loss: 1.8095 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8023 - accuracy: 0.53 - ETA: 2:43 - loss: 1.7924 - accuracy: 0.53 - ETA: 2:42 - loss: 1.7907 - accuracy: 0.53 - ETA: 2:41 - loss: 1.7901 - accuracy: 0.53 - ETA: 2:40 - loss: 1.7830 - accuracy: 0.53 - ETA: 2:38 - loss: 1.7814 - accuracy: 0.53 - ETA: 2:37 - loss: 1.7866 - accuracy: 0.53 - ETA: 2:35 - loss: 1.7795 - accuracy: 0.53 - ETA: 2:34 - loss: 1.7780 - accuracy: 0.53 - ETA: 2:33 - loss: 1.7751 - accuracy: 0.53 - ETA: 2:31 - loss: 1.7707 - accuracy: 0.53 - ETA: 2:30 - loss: 1.7745 - accuracy: 0.53 - ETA: 2:29 - loss: 1.7762 - accuracy: 0.53 - ETA: 2:27 - loss: 1.7724 - accuracy: 0.53 - ETA: 2:26 - loss: 1.7650 - accuracy: 0.53 - ETA: 2:25 - loss: 1.7648 - accuracy: 0.53 - ETA: 2:23 - loss: 1.7705 - accuracy: 0.53 - ETA: 2:22 - loss: 1.7767 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8057 - accuracy: 0.53 - ETA: 2:19 - loss: 1.7978 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8080 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8059 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8101 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8059 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8041 - accuracy: 0.53 - ETA: 2:10 - loss: 1.7997 - accuracy: 0.54 - ETA: 2:09 - loss: 1.8035 - accuracy: 0.54 - ETA: 2:08 - loss: 1.8014 - accuracy: 0.54 - ETA: 2:06 - loss: 1.8025 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7987 - accuracy: 0.54 - ETA: 2:04 - loss: 1.8034 - accuracy: 0.54 - ETA: 2:02 - loss: 1.8083 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8081 - accuracy: 0.54 - ETA: 1:59 - loss: 1.8061 - accuracy: 0.54 - ETA: 1:58 - loss: 1.8077 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8092 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8132 - accuracy: 0.53 - ETA: 1:54 - loss: 1.8106 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8077 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8040 - accuracy: 0.53 - ETA: 1:50 - loss: 1.8043 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8064 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8092 - accuracy: 0.53 - ETA: 1:46 - loss: 1.8093 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8107 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8081 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8112 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8063 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8067 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8091 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8116 - accuracy: 0.54 - ETA: 1:35 - loss: 1.8086 - accuracy: 0.54 - ETA: 1:34 - loss: 1.8077 - accuracy: 0.54 - ETA: 1:32 - loss: 1.8047 - accuracy: 0.54 - ETA: 1:31 - loss: 1.8076 - accuracy: 0.54 - ETA: 1:29 - loss: 1.8063 - accuracy: 0.54 - ETA: 1:28 - loss: 1.8080 - accuracy: 0.54 - ETA: 1:27 - loss: 1.8086 - accuracy: 0.54 - ETA: 1:25 - loss: 1.8093 - accuracy: 0.54 - ETA: 1:24 - loss: 1.8151 - accuracy: 0.54 - ETA: 1:23 - loss: 1.8129 - accuracy: 0.54 - ETA: 1:21 - loss: 1.8111 - accuracy: 0.54 - ETA: 1:20 - loss: 1.8079 - accuracy: 0.54 - ETA: 1:19 - loss: 1.8060 - accuracy: 0.54 - ETA: 1:17 - loss: 1.8091 - accuracy: 0.54 - ETA: 1:16 - loss: 1.8094 - accuracy: 0.54 - ETA: 1:14 - loss: 1.8085 - accuracy: 0.54 - ETA: 1:13 - loss: 1.8100 - accuracy: 0.54 - ETA: 1:12 - loss: 1.8086 - accuracy: 0.53 - ETA: 1:10 - loss: 1.8093 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8062 - accuracy: 0.53 - ETA: 1:08 - loss: 1.8049 - accuracy: 0.53 - ETA: 1:06 - loss: 1.8064 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8080 - accuracy: 0.53 - ETA: 1:04 - loss: 1.8067 - accuracy: 0.53 - ETA: 1:02 - loss: 1.8066 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8119 - accuracy: 0.53 - ETA: 59s - loss: 1.8111 - accuracy: 0.5386 - ETA: 58s - loss: 1.8103 - accuracy: 0.538 - ETA: 57s - loss: 1.8100 - accuracy: 0.538 - ETA: 55s - loss: 1.8074 - accuracy: 0.538 - ETA: 54s - loss: 1.8072 - accuracy: 0.538 - ETA: 53s - loss: 1.8087 - accuracy: 0.537 - ETA: 51s - loss: 1.8099 - accuracy: 0.537 - ETA: 50s - loss: 1.8073 - accuracy: 0.537 - ETA: 49s - loss: 1.8051 - accuracy: 0.538 - ETA: 47s - loss: 1.8031 - accuracy: 0.538 - ETA: 46s - loss: 1.8015 - accuracy: 0.538 - ETA: 44s - loss: 1.8030 - accuracy: 0.538 - ETA: 43s - loss: 1.8036 - accuracy: 0.537 - ETA: 42s - loss: 1.8060 - accuracy: 0.537 - ETA: 40s - loss: 1.8062 - accuracy: 0.536 - ETA: 39s - loss: 1.8058 - accuracy: 0.536 - ETA: 38s - loss: 1.8060 - accuracy: 0.536 - ETA: 36s - loss: 1.8072 - accuracy: 0.536 - ETA: 35s - loss: 1.8142 - accuracy: 0.536 - ETA: 34s - loss: 1.8163 - accuracy: 0.535 - ETA: 32s - loss: 1.8220 - accuracy: 0.534 - ETA: 31s - loss: 1.8242 - accuracy: 0.534 - ETA: 29s - loss: 1.8255 - accuracy: 0.534 - ETA: 28s - loss: 1.8246 - accuracy: 0.534 - ETA: 27s - loss: 1.8275 - accuracy: 0.534 - ETA: 25s - loss: 1.8279 - accuracy: 0.534 - ETA: 24s - loss: 1.8284 - accuracy: 0.533 - ETA: 23s - loss: 1.8271 - accuracy: 0.534 - ETA: 21s - loss: 1.8288 - accuracy: 0.533 - ETA: 20s - loss: 1.8291 - accuracy: 0.533 - ETA: 18s - loss: 1.8321 - accuracy: 0.533 - ETA: 17s - loss: 1.8316 - accuracy: 0.532 - ETA: 16s - loss: 1.8319 - accuracy: 0.533 - ETA: 14s - loss: 1.8358 - accuracy: 0.533 - ETA: 13s - loss: 1.8360 - accuracy: 0.532 - ETA: 12s - loss: 1.8347 - accuracy: 0.532 - ETA: 10s - loss: 1.8330 - accuracy: 0.532 - ETA: 9s - loss: 1.8341 - accuracy: 0.532 - ETA: 8s - loss: 1.8357 - accuracy: 0.53 - ETA: 6s - loss: 1.8363 - accuracy: 0.53 - ETA: 5s - loss: 1.8384 - accuracy: 0.53 - ETA: 3s - loss: 1.8378 - accuracy: 0.53 - ETA: 2s - loss: 1.8378 - accuracy: 0.53 - ETA: 1s - loss: 1.8451 - accuracy: 0.53 - 217s 11ms/step - loss: 1.8477 - accuracy: 0.5321 - val_loss: 2.0039 - val_accuracy: 0.5817\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:35 - loss: 2.0707 - accuracy: 0.46 - ETA: 3:30 - loss: 1.9500 - accuracy: 0.51 - ETA: 3:31 - loss: 1.9135 - accuracy: 0.51 - ETA: 3:30 - loss: 1.8364 - accuracy: 0.53 - ETA: 3:25 - loss: 1.8466 - accuracy: 0.52 - ETA: 3:23 - loss: 1.8523 - accuracy: 0.52 - ETA: 3:21 - loss: 1.8665 - accuracy: 0.51 - ETA: 3:21 - loss: 1.8434 - accuracy: 0.52 - ETA: 3:18 - loss: 1.8495 - accuracy: 0.52 - ETA: 3:16 - loss: 1.9689 - accuracy: 0.51 - ETA: 3:13 - loss: 1.9641 - accuracy: 0.51 - ETA: 3:11 - loss: 1.9482 - accuracy: 0.51 - ETA: 3:09 - loss: 1.9451 - accuracy: 0.51 - ETA: 3:08 - loss: 1.9478 - accuracy: 0.51 - ETA: 3:07 - loss: 1.9237 - accuracy: 0.51 - ETA: 3:05 - loss: 1.9012 - accuracy: 0.51 - ETA: 3:03 - loss: 1.9219 - accuracy: 0.51 - ETA: 3:02 - loss: 1.9529 - accuracy: 0.51 - ETA: 3:01 - loss: 1.9550 - accuracy: 0.51 - ETA: 3:00 - loss: 1.9632 - accuracy: 0.51 - ETA: 3:00 - loss: 1.9564 - accuracy: 0.51 - ETA: 2:59 - loss: 1.9711 - accuracy: 0.51 - ETA: 2:58 - loss: 1.9454 - accuracy: 0.51 - ETA: 2:56 - loss: 1.9306 - accuracy: 0.51 - ETA: 2:55 - loss: 1.9146 - accuracy: 0.52 - ETA: 2:54 - loss: 1.9164 - accuracy: 0.52 - ETA: 2:53 - loss: 1.8951 - accuracy: 0.52 - ETA: 2:51 - loss: 1.8837 - accuracy: 0.52 - ETA: 2:50 - loss: 1.8799 - accuracy: 0.52 - ETA: 2:48 - loss: 1.8670 - accuracy: 0.52 - ETA: 2:46 - loss: 1.8727 - accuracy: 0.52 - ETA: 2:45 - loss: 1.8695 - accuracy: 0.52 - ETA: 2:43 - loss: 1.8727 - accuracy: 0.52 - ETA: 2:42 - loss: 1.8857 - accuracy: 0.52 - ETA: 2:40 - loss: 1.8823 - accuracy: 0.52 - ETA: 2:38 - loss: 1.8743 - accuracy: 0.52 - ETA: 2:37 - loss: 1.8703 - accuracy: 0.52 - ETA: 2:36 - loss: 1.8665 - accuracy: 0.52 - ETA: 2:35 - loss: 1.8660 - accuracy: 0.52 - ETA: 2:33 - loss: 1.8663 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8687 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8710 - accuracy: 0.52 - ETA: 2:28 - loss: 1.8654 - accuracy: 0.53 - ETA: 2:27 - loss: 1.8638 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8620 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8629 - accuracy: 0.52 - ETA: 2:23 - loss: 1.8556 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8522 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8569 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8576 - accuracy: 0.52 - ETA: 2:17 - loss: 1.8514 - accuracy: 0.52 - ETA: 2:16 - loss: 1.8473 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8479 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8539 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8548 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8473 - accuracy: 0.53 - ETA: 2:09 - loss: 1.8427 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8398 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8390 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8365 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8372 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8370 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8356 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8320 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8311 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8276 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8277 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8357 - accuracy: 0.53 - ETA: 1:52 - loss: 1.8297 - accuracy: 0.53 - ETA: 1:50 - loss: 1.8287 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8340 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8306 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8262 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8284 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8269 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8223 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8204 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8215 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8236 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8193 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8169 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8177 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8126 - accuracy: 0.53 - ETA: 1:31 - loss: 1.8107 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8096 - accuracy: 0.53 - ETA: 1:29 - loss: 1.8201 - accuracy: 0.53 - ETA: 1:27 - loss: 1.8199 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8180 - accuracy: 0.53 - ETA: 1:25 - loss: 1.8147 - accuracy: 0.53 - ETA: 1:23 - loss: 1.8120 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8105 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8092 - accuracy: 0.53 - ETA: 1:19 - loss: 1.8101 - accuracy: 0.53 - ETA: 1:18 - loss: 1.8125 - accuracy: 0.53 - ETA: 1:16 - loss: 1.8131 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8101 - accuracy: 0.53 - ETA: 1:14 - loss: 1.8068 - accuracy: 0.53 - ETA: 1:12 - loss: 1.8067 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8065 - accuracy: 0.53 - ETA: 1:09 - loss: 1.8050 - accuracy: 0.53 - ETA: 1:08 - loss: 1.8083 - accuracy: 0.53 - ETA: 1:07 - loss: 1.8165 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8146 - accuracy: 0.53 - ETA: 1:04 - loss: 1.8128 - accuracy: 0.53 - ETA: 1:03 - loss: 1.8126 - accuracy: 0.53 - ETA: 1:01 - loss: 1.8144 - accuracy: 0.53 - ETA: 1:00 - loss: 1.8156 - accuracy: 0.53 - ETA: 58s - loss: 1.8144 - accuracy: 0.5355 - ETA: 57s - loss: 1.8107 - accuracy: 0.536 - ETA: 56s - loss: 1.8108 - accuracy: 0.535 - ETA: 54s - loss: 1.8124 - accuracy: 0.535 - ETA: 53s - loss: 1.8123 - accuracy: 0.534 - ETA: 51s - loss: 1.8107 - accuracy: 0.535 - ETA: 50s - loss: 1.8083 - accuracy: 0.535 - ETA: 49s - loss: 1.8084 - accuracy: 0.535 - ETA: 47s - loss: 1.8073 - accuracy: 0.535 - ETA: 46s - loss: 1.8065 - accuracy: 0.536 - ETA: 45s - loss: 1.8072 - accuracy: 0.535 - ETA: 43s - loss: 1.8075 - accuracy: 0.536 - ETA: 42s - loss: 1.8047 - accuracy: 0.537 - ETA: 41s - loss: 1.8096 - accuracy: 0.536 - ETA: 39s - loss: 1.8083 - accuracy: 0.536 - ETA: 38s - loss: 1.8072 - accuracy: 0.536 - ETA: 36s - loss: 1.8060 - accuracy: 0.537 - ETA: 35s - loss: 1.8071 - accuracy: 0.536 - ETA: 34s - loss: 1.8054 - accuracy: 0.537 - ETA: 32s - loss: 1.8018 - accuracy: 0.537 - ETA: 31s - loss: 1.8016 - accuracy: 0.537 - ETA: 30s - loss: 1.8027 - accuracy: 0.537 - ETA: 28s - loss: 1.8028 - accuracy: 0.536 - ETA: 27s - loss: 1.8020 - accuracy: 0.536 - ETA: 25s - loss: 1.8023 - accuracy: 0.536 - ETA: 24s - loss: 1.8029 - accuracy: 0.537 - ETA: 23s - loss: 1.8050 - accuracy: 0.537 - ETA: 21s - loss: 1.8054 - accuracy: 0.537 - ETA: 20s - loss: 1.8064 - accuracy: 0.536 - ETA: 19s - loss: 1.8055 - accuracy: 0.536 - ETA: 17s - loss: 1.8059 - accuracy: 0.536 - ETA: 16s - loss: 1.8035 - accuracy: 0.536 - ETA: 14s - loss: 1.8016 - accuracy: 0.537 - ETA: 13s - loss: 1.8014 - accuracy: 0.537 - ETA: 12s - loss: 1.8006 - accuracy: 0.536 - ETA: 10s - loss: 1.8009 - accuracy: 0.536 - ETA: 9s - loss: 1.7993 - accuracy: 0.537 - ETA: 8s - loss: 1.8050 - accuracy: 0.53 - ETA: 6s - loss: 1.8044 - accuracy: 0.53 - ETA: 5s - loss: 1.8016 - accuracy: 0.53 - ETA: 3s - loss: 1.7998 - accuracy: 0.53 - ETA: 2s - loss: 1.7972 - accuracy: 0.53 - ETA: 1s - loss: 1.7982 - accuracy: 0.53 - 219s 11ms/step - loss: 1.7989 - accuracy: 0.5382 - val_loss: 2.0331 - val_accuracy: 0.6012\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:20 - loss: 1.8551 - accuracy: 0.47 - ETA: 3:19 - loss: 1.6657 - accuracy: 0.53 - ETA: 3:15 - loss: 1.7861 - accuracy: 0.53 - ETA: 3:16 - loss: 1.7278 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7497 - accuracy: 0.53 - ETA: 3:15 - loss: 1.7544 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7830 - accuracy: 0.53 - ETA: 3:15 - loss: 1.7700 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7691 - accuracy: 0.53 - ETA: 3:13 - loss: 1.7866 - accuracy: 0.53 - ETA: 3:12 - loss: 1.7989 - accuracy: 0.53 - ETA: 3:10 - loss: 1.7843 - accuracy: 0.53 - ETA: 3:08 - loss: 1.7567 - accuracy: 0.53 - ETA: 3:06 - loss: 1.7712 - accuracy: 0.53 - ETA: 3:05 - loss: 1.7595 - accuracy: 0.53 - ETA: 3:03 - loss: 1.7700 - accuracy: 0.53 - ETA: 3:02 - loss: 1.7628 - accuracy: 0.53 - ETA: 3:01 - loss: 1.8329 - accuracy: 0.52 - ETA: 3:00 - loss: 1.8311 - accuracy: 0.52 - ETA: 2:58 - loss: 1.8234 - accuracy: 0.52 - ETA: 2:57 - loss: 1.8019 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8060 - accuracy: 0.53 - ETA: 2:54 - loss: 1.7941 - accuracy: 0.53 - ETA: 2:53 - loss: 1.7978 - accuracy: 0.53 - ETA: 2:52 - loss: 1.8041 - accuracy: 0.53 - ETA: 2:50 - loss: 1.8049 - accuracy: 0.53 - ETA: 2:48 - loss: 1.8130 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8018 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8119 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8168 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8150 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8112 - accuracy: 0.53 - ETA: 2:40 - loss: 1.7992 - accuracy: 0.53 - ETA: 2:39 - loss: 1.7965 - accuracy: 0.53 - ETA: 2:37 - loss: 1.7842 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7990 - accuracy: 0.53 - ETA: 2:35 - loss: 1.7957 - accuracy: 0.53 - ETA: 2:33 - loss: 1.7890 - accuracy: 0.53 - ETA: 2:32 - loss: 1.7855 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7872 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7885 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7872 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7981 - accuracy: 0.54 - ETA: 2:25 - loss: 1.8030 - accuracy: 0.54 - ETA: 2:24 - loss: 1.8006 - accuracy: 0.54 - ETA: 2:22 - loss: 1.8007 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7989 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7927 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7921 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7931 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7888 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7874 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7877 - accuracy: 0.54 - ETA: 2:11 - loss: 1.7901 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7877 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7853 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7825 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7800 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7800 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7731 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7756 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7689 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7709 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7733 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7704 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7683 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7668 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7646 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7752 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7752 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7801 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7801 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7795 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7825 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7833 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7877 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7852 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7825 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7777 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7754 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7743 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7737 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7765 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7810 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7782 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7782 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7746 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7775 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7780 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7753 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7746 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7717 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7673 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7691 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7726 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7739 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7732 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7768 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7740 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7731 - accuracy: 0.54 - ETA: 1:08 - loss: 1.7737 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7705 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7712 - accuracy: 0.54 - ETA: 1:04 - loss: 1.7695 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7702 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7697 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7692 - accuracy: 0.54 - ETA: 58s - loss: 1.7686 - accuracy: 0.5415 - ETA: 57s - loss: 1.7688 - accuracy: 0.541 - ETA: 56s - loss: 1.7676 - accuracy: 0.541 - ETA: 54s - loss: 1.7679 - accuracy: 0.541 - ETA: 53s - loss: 1.7682 - accuracy: 0.540 - ETA: 52s - loss: 1.7685 - accuracy: 0.540 - ETA: 50s - loss: 1.7671 - accuracy: 0.541 - ETA: 49s - loss: 1.7657 - accuracy: 0.541 - ETA: 47s - loss: 1.7637 - accuracy: 0.541 - ETA: 46s - loss: 1.7642 - accuracy: 0.541 - ETA: 45s - loss: 1.7633 - accuracy: 0.541 - ETA: 43s - loss: 1.7600 - accuracy: 0.542 - ETA: 42s - loss: 1.7637 - accuracy: 0.542 - ETA: 41s - loss: 1.7619 - accuracy: 0.542 - ETA: 39s - loss: 1.7598 - accuracy: 0.543 - ETA: 38s - loss: 1.7586 - accuracy: 0.543 - ETA: 36s - loss: 1.7585 - accuracy: 0.543 - ETA: 35s - loss: 1.7586 - accuracy: 0.543 - ETA: 34s - loss: 1.7555 - accuracy: 0.543 - ETA: 32s - loss: 1.7531 - accuracy: 0.544 - ETA: 31s - loss: 1.7563 - accuracy: 0.543 - ETA: 30s - loss: 1.7593 - accuracy: 0.543 - ETA: 28s - loss: 1.7575 - accuracy: 0.543 - ETA: 27s - loss: 1.7552 - accuracy: 0.544 - ETA: 25s - loss: 1.7579 - accuracy: 0.544 - ETA: 24s - loss: 1.7584 - accuracy: 0.543 - ETA: 23s - loss: 1.7579 - accuracy: 0.543 - ETA: 21s - loss: 1.7595 - accuracy: 0.543 - ETA: 20s - loss: 1.7619 - accuracy: 0.543 - ETA: 19s - loss: 1.7656 - accuracy: 0.543 - ETA: 17s - loss: 1.7684 - accuracy: 0.542 - ETA: 16s - loss: 1.7690 - accuracy: 0.542 - ETA: 14s - loss: 1.7693 - accuracy: 0.542 - ETA: 13s - loss: 1.7665 - accuracy: 0.542 - ETA: 12s - loss: 1.7666 - accuracy: 0.542 - ETA: 10s - loss: 1.7650 - accuracy: 0.543 - ETA: 9s - loss: 1.7748 - accuracy: 0.543 - ETA: 8s - loss: 1.7745 - accuracy: 0.54 - ETA: 6s - loss: 1.7751 - accuracy: 0.54 - ETA: 5s - loss: 1.7735 - accuracy: 0.54 - ETA: 3s - loss: 1.7713 - accuracy: 0.54 - ETA: 2s - loss: 1.7743 - accuracy: 0.54 - ETA: 1s - loss: 1.7763 - accuracy: 0.54 - 219s 11ms/step - loss: 1.7746 - accuracy: 0.5435 - val_loss: 1.8827 - val_accuracy: 0.6007\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:23 - loss: 1.7362 - accuracy: 0.53 - ETA: 3:17 - loss: 1.9677 - accuracy: 0.57 - ETA: 3:17 - loss: 1.8693 - accuracy: 0.58 - ETA: 3:14 - loss: 1.8458 - accuracy: 0.57 - ETA: 3:14 - loss: 1.8953 - accuracy: 0.56 - ETA: 3:13 - loss: 1.8668 - accuracy: 0.56 - ETA: 3:13 - loss: 1.8350 - accuracy: 0.56 - ETA: 3:11 - loss: 1.8614 - accuracy: 0.56 - ETA: 3:09 - loss: 1.8733 - accuracy: 0.55 - ETA: 3:08 - loss: 1.8882 - accuracy: 0.55 - ETA: 3:08 - loss: 1.8659 - accuracy: 0.55 - ETA: 3:07 - loss: 1.8478 - accuracy: 0.54 - ETA: 3:06 - loss: 1.8662 - accuracy: 0.54 - ETA: 3:05 - loss: 1.8530 - accuracy: 0.54 - ETA: 3:04 - loss: 1.8560 - accuracy: 0.54 - ETA: 3:02 - loss: 1.8570 - accuracy: 0.54 - ETA: 3:02 - loss: 1.8429 - accuracy: 0.54 - ETA: 3:00 - loss: 1.8484 - accuracy: 0.54 - ETA: 2:59 - loss: 1.8538 - accuracy: 0.54 - ETA: 2:57 - loss: 1.8389 - accuracy: 0.54 - ETA: 2:56 - loss: 1.8267 - accuracy: 0.54 - ETA: 2:55 - loss: 1.8381 - accuracy: 0.54 - ETA: 2:54 - loss: 1.8255 - accuracy: 0.54 - ETA: 2:52 - loss: 1.8480 - accuracy: 0.54 - ETA: 2:51 - loss: 1.8429 - accuracy: 0.54 - ETA: 2:49 - loss: 1.8321 - accuracy: 0.54 - ETA: 2:48 - loss: 1.8338 - accuracy: 0.54 - ETA: 2:47 - loss: 1.8250 - accuracy: 0.54 - ETA: 2:45 - loss: 1.8271 - accuracy: 0.54 - ETA: 2:44 - loss: 1.8144 - accuracy: 0.54 - ETA: 2:42 - loss: 1.8102 - accuracy: 0.54 - ETA: 2:41 - loss: 1.8037 - accuracy: 0.54 - ETA: 2:39 - loss: 1.8194 - accuracy: 0.54 - ETA: 2:38 - loss: 1.8171 - accuracy: 0.54 - ETA: 2:37 - loss: 1.8237 - accuracy: 0.54 - ETA: 2:36 - loss: 1.8313 - accuracy: 0.54 - ETA: 2:34 - loss: 1.8263 - accuracy: 0.54 - ETA: 2:33 - loss: 1.8226 - accuracy: 0.54 - ETA: 2:32 - loss: 1.8209 - accuracy: 0.54 - ETA: 2:30 - loss: 1.8224 - accuracy: 0.54 - ETA: 2:29 - loss: 1.8254 - accuracy: 0.54 - ETA: 2:28 - loss: 1.8219 - accuracy: 0.54 - ETA: 2:26 - loss: 1.8127 - accuracy: 0.54 - ETA: 2:25 - loss: 1.8269 - accuracy: 0.54 - ETA: 2:24 - loss: 1.8241 - accuracy: 0.54 - ETA: 2:23 - loss: 1.8261 - accuracy: 0.54 - ETA: 2:21 - loss: 1.8248 - accuracy: 0.54 - ETA: 2:20 - loss: 1.8179 - accuracy: 0.54 - ETA: 2:19 - loss: 1.8167 - accuracy: 0.54 - ETA: 2:17 - loss: 1.8055 - accuracy: 0.54 - ETA: 2:16 - loss: 1.8089 - accuracy: 0.54 - ETA: 2:14 - loss: 1.8059 - accuracy: 0.54 - ETA: 2:13 - loss: 1.8052 - accuracy: 0.54 - ETA: 2:12 - loss: 1.8056 - accuracy: 0.54 - ETA: 2:10 - loss: 1.8096 - accuracy: 0.54 - ETA: 2:09 - loss: 1.8082 - accuracy: 0.54 - ETA: 2:07 - loss: 1.8055 - accuracy: 0.54 - ETA: 2:06 - loss: 1.8055 - accuracy: 0.54 - ETA: 2:05 - loss: 1.8005 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7965 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7928 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7895 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7882 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7993 - accuracy: 0.54 - ETA: 1:57 - loss: 1.8003 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7991 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7964 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7909 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7878 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7879 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7847 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7847 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7889 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7851 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7826 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7841 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7800 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7784 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7776 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7781 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7838 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7858 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7839 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7877 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7849 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7842 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7842 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7824 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7807 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7822 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7883 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7862 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7847 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7800 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7776 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7776 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7772 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7768 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7787 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7782 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7766 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7747 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7753 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7765 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7825 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7809 - accuracy: 0.54 - ETA: 59s - loss: 1.7820 - accuracy: 0.5457 - ETA: 58s - loss: 1.7808 - accuracy: 0.545 - ETA: 57s - loss: 1.7790 - accuracy: 0.545 - ETA: 55s - loss: 1.7784 - accuracy: 0.545 - ETA: 54s - loss: 1.7796 - accuracy: 0.545 - ETA: 52s - loss: 1.7770 - accuracy: 0.545 - ETA: 51s - loss: 1.7811 - accuracy: 0.545 - ETA: 50s - loss: 1.7798 - accuracy: 0.545 - ETA: 48s - loss: 1.7757 - accuracy: 0.546 - ETA: 47s - loss: 1.7761 - accuracy: 0.545 - ETA: 46s - loss: 1.7743 - accuracy: 0.546 - ETA: 44s - loss: 1.7764 - accuracy: 0.545 - ETA: 43s - loss: 1.7758 - accuracy: 0.545 - ETA: 42s - loss: 1.7786 - accuracy: 0.545 - ETA: 40s - loss: 1.7777 - accuracy: 0.546 - ETA: 39s - loss: 1.7780 - accuracy: 0.546 - ETA: 38s - loss: 1.7800 - accuracy: 0.545 - ETA: 36s - loss: 1.7830 - accuracy: 0.545 - ETA: 35s - loss: 1.7825 - accuracy: 0.545 - ETA: 33s - loss: 1.7831 - accuracy: 0.545 - ETA: 32s - loss: 1.7833 - accuracy: 0.544 - ETA: 31s - loss: 1.7823 - accuracy: 0.544 - ETA: 29s - loss: 1.7818 - accuracy: 0.544 - ETA: 28s - loss: 1.7823 - accuracy: 0.544 - ETA: 27s - loss: 1.7803 - accuracy: 0.545 - ETA: 25s - loss: 1.7777 - accuracy: 0.545 - ETA: 24s - loss: 1.7775 - accuracy: 0.545 - ETA: 23s - loss: 1.7780 - accuracy: 0.545 - ETA: 21s - loss: 1.7771 - accuracy: 0.545 - ETA: 20s - loss: 1.7763 - accuracy: 0.545 - ETA: 18s - loss: 1.7773 - accuracy: 0.544 - ETA: 17s - loss: 1.7762 - accuracy: 0.544 - ETA: 16s - loss: 1.7761 - accuracy: 0.544 - ETA: 14s - loss: 1.7748 - accuracy: 0.544 - ETA: 13s - loss: 1.7755 - accuracy: 0.544 - ETA: 12s - loss: 1.7737 - accuracy: 0.545 - ETA: 10s - loss: 1.7750 - accuracy: 0.544 - ETA: 9s - loss: 1.7751 - accuracy: 0.544 - ETA: 8s - loss: 1.7735 - accuracy: 0.54 - ETA: 6s - loss: 1.7735 - accuracy: 0.54 - ETA: 5s - loss: 1.7712 - accuracy: 0.54 - ETA: 3s - loss: 1.7710 - accuracy: 0.54 - ETA: 2s - loss: 1.7721 - accuracy: 0.54 - ETA: 1s - loss: 1.7770 - accuracy: 0.54 - 219s 11ms/step - loss: 1.7775 - accuracy: 0.5445 - val_loss: 2.8003 - val_accuracy: 0.5678\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:40 - loss: 2.4289 - accuracy: 0.60 - ETA: 3:42 - loss: 2.1056 - accuracy: 0.55 - ETA: 3:38 - loss: 1.9249 - accuracy: 0.57 - ETA: 3:31 - loss: 1.9420 - accuracy: 0.53 - ETA: 3:29 - loss: 1.9174 - accuracy: 0.52 - ETA: 3:26 - loss: 1.8996 - accuracy: 0.52 - ETA: 3:23 - loss: 1.8778 - accuracy: 0.53 - ETA: 3:20 - loss: 1.8258 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8525 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8964 - accuracy: 0.54 - ETA: 3:14 - loss: 1.8984 - accuracy: 0.54 - ETA: 3:12 - loss: 1.8992 - accuracy: 0.53 - ETA: 3:10 - loss: 1.8808 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8691 - accuracy: 0.53 - ETA: 3:08 - loss: 1.8795 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8746 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8529 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8492 - accuracy: 0.53 - ETA: 3:01 - loss: 1.8364 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8391 - accuracy: 0.53 - ETA: 2:58 - loss: 1.8638 - accuracy: 0.53 - ETA: 2:56 - loss: 1.8556 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8540 - accuracy: 0.53 - ETA: 2:53 - loss: 1.8478 - accuracy: 0.53 - ETA: 2:51 - loss: 1.8386 - accuracy: 0.53 - ETA: 2:50 - loss: 1.8390 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8312 - accuracy: 0.53 - ETA: 2:47 - loss: 1.8369 - accuracy: 0.53 - ETA: 2:46 - loss: 1.8266 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8119 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8074 - accuracy: 0.53 - ETA: 2:41 - loss: 1.8114 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8037 - accuracy: 0.53 - ETA: 2:39 - loss: 1.8046 - accuracy: 0.53 - ETA: 2:37 - loss: 1.7974 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8086 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8127 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8201 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8108 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8113 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8058 - accuracy: 0.53 - ETA: 2:28 - loss: 1.7962 - accuracy: 0.53 - ETA: 2:27 - loss: 1.7943 - accuracy: 0.53 - ETA: 2:25 - loss: 1.7961 - accuracy: 0.53 - ETA: 2:24 - loss: 1.7929 - accuracy: 0.53 - ETA: 2:22 - loss: 1.7888 - accuracy: 0.53 - ETA: 2:21 - loss: 1.7836 - accuracy: 0.53 - ETA: 2:20 - loss: 1.7858 - accuracy: 0.53 - ETA: 2:18 - loss: 1.7822 - accuracy: 0.53 - ETA: 2:17 - loss: 1.7778 - accuracy: 0.53 - ETA: 2:16 - loss: 1.7726 - accuracy: 0.53 - ETA: 2:14 - loss: 1.7657 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7650 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7643 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7624 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7540 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7490 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7446 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7458 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7478 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7554 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7547 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7513 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7587 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7655 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7642 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7659 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7665 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7611 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7607 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7607 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7642 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7619 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7597 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7603 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7645 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7617 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7711 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7782 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7827 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7829 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7847 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7867 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7866 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7840 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7836 - accuracy: 0.53 - ETA: 1:27 - loss: 1.7804 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7807 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7778 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7770 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7763 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7765 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7743 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7726 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7685 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7713 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7700 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7697 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7704 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7696 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7690 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7689 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7715 - accuracy: 0.54 - ETA: 1:08 - loss: 1.7723 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7713 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7668 - accuracy: 0.54 - ETA: 1:04 - loss: 1.7662 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7653 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7640 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7665 - accuracy: 0.54 - ETA: 59s - loss: 1.7658 - accuracy: 0.5424 - ETA: 58s - loss: 1.7666 - accuracy: 0.542 - ETA: 57s - loss: 1.7652 - accuracy: 0.542 - ETA: 55s - loss: 1.7646 - accuracy: 0.542 - ETA: 54s - loss: 1.7638 - accuracy: 0.543 - ETA: 53s - loss: 1.7636 - accuracy: 0.543 - ETA: 51s - loss: 1.7635 - accuracy: 0.543 - ETA: 50s - loss: 1.7632 - accuracy: 0.543 - ETA: 49s - loss: 1.7674 - accuracy: 0.542 - ETA: 47s - loss: 1.7681 - accuracy: 0.542 - ETA: 46s - loss: 1.7674 - accuracy: 0.542 - ETA: 44s - loss: 1.7669 - accuracy: 0.542 - ETA: 43s - loss: 1.7686 - accuracy: 0.541 - ETA: 42s - loss: 1.7680 - accuracy: 0.541 - ETA: 40s - loss: 1.7699 - accuracy: 0.541 - ETA: 39s - loss: 1.7698 - accuracy: 0.540 - ETA: 37s - loss: 1.7680 - accuracy: 0.541 - ETA: 36s - loss: 1.7657 - accuracy: 0.541 - ETA: 34s - loss: 1.7660 - accuracy: 0.541 - ETA: 33s - loss: 1.7677 - accuracy: 0.540 - ETA: 31s - loss: 1.7653 - accuracy: 0.541 - ETA: 30s - loss: 1.7714 - accuracy: 0.540 - ETA: 28s - loss: 1.7732 - accuracy: 0.541 - ETA: 27s - loss: 1.7712 - accuracy: 0.541 - ETA: 25s - loss: 1.7693 - accuracy: 0.542 - ETA: 24s - loss: 1.7682 - accuracy: 0.541 - ETA: 22s - loss: 1.7707 - accuracy: 0.541 - ETA: 20s - loss: 1.7706 - accuracy: 0.541 - ETA: 19s - loss: 1.7707 - accuracy: 0.541 - ETA: 17s - loss: 1.7691 - accuracy: 0.542 - ETA: 16s - loss: 1.7708 - accuracy: 0.541 - ETA: 14s - loss: 1.7714 - accuracy: 0.541 - ETA: 12s - loss: 1.7702 - accuracy: 0.541 - ETA: 11s - loss: 1.7708 - accuracy: 0.542 - ETA: 9s - loss: 1.7719 - accuracy: 0.541 - ETA: 8s - loss: 1.7719 - accuracy: 0.54 - ETA: 6s - loss: 1.7739 - accuracy: 0.54 - ETA: 4s - loss: 1.7719 - accuracy: 0.54 - ETA: 3s - loss: 1.7721 - accuracy: 0.54 - ETA: 1s - loss: 1.7747 - accuracy: 0.54 - 278s 14ms/step - loss: 1.7772 - accuracy: 0.5412 - val_loss: 1.9349 - val_accuracy: 0.6036\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:24 - loss: 1.6540 - accuracy: 0.56 - ETA: 5:24 - loss: 1.6784 - accuracy: 0.53 - ETA: 5:19 - loss: 1.7535 - accuracy: 0.52 - ETA: 5:19 - loss: 1.7692 - accuracy: 0.52 - ETA: 5:18 - loss: 1.7572 - accuracy: 0.53 - ETA: 5:18 - loss: 1.7483 - accuracy: 0.54 - ETA: 5:13 - loss: 1.7317 - accuracy: 0.54 - ETA: 5:10 - loss: 1.7157 - accuracy: 0.54 - ETA: 5:07 - loss: 1.7126 - accuracy: 0.55 - ETA: 5:04 - loss: 1.7144 - accuracy: 0.54 - ETA: 5:02 - loss: 1.7416 - accuracy: 0.53 - ETA: 4:58 - loss: 1.7491 - accuracy: 0.53 - ETA: 4:56 - loss: 1.7580 - accuracy: 0.53 - ETA: 4:54 - loss: 1.7593 - accuracy: 0.53 - ETA: 4:49 - loss: 1.7475 - accuracy: 0.53 - ETA: 4:47 - loss: 1.7451 - accuracy: 0.53 - ETA: 4:45 - loss: 1.7556 - accuracy: 0.53 - ETA: 4:43 - loss: 1.7641 - accuracy: 0.53 - ETA: 4:41 - loss: 1.7477 - accuracy: 0.53 - ETA: 4:39 - loss: 1.7462 - accuracy: 0.53 - ETA: 4:37 - loss: 1.7699 - accuracy: 0.53 - ETA: 4:33 - loss: 1.7741 - accuracy: 0.53 - ETA: 4:30 - loss: 1.7750 - accuracy: 0.53 - ETA: 4:28 - loss: 1.7765 - accuracy: 0.53 - ETA: 4:26 - loss: 1.7949 - accuracy: 0.53 - ETA: 4:24 - loss: 1.7865 - accuracy: 0.53 - ETA: 4:23 - loss: 1.7996 - accuracy: 0.53 - ETA: 4:20 - loss: 1.8019 - accuracy: 0.53 - ETA: 4:18 - loss: 1.8094 - accuracy: 0.53 - ETA: 4:14 - loss: 1.7953 - accuracy: 0.53 - ETA: 4:12 - loss: 1.7914 - accuracy: 0.53 - ETA: 4:10 - loss: 1.7902 - accuracy: 0.53 - ETA: 4:08 - loss: 1.7951 - accuracy: 0.53 - ETA: 4:05 - loss: 1.7844 - accuracy: 0.53 - ETA: 4:03 - loss: 1.7769 - accuracy: 0.54 - ETA: 4:01 - loss: 1.7752 - accuracy: 0.53 - ETA: 3:59 - loss: 1.7712 - accuracy: 0.53 - ETA: 3:57 - loss: 1.7688 - accuracy: 0.53 - ETA: 3:55 - loss: 1.7651 - accuracy: 0.54 - ETA: 3:53 - loss: 1.7670 - accuracy: 0.54 - ETA: 3:51 - loss: 1.7643 - accuracy: 0.54 - ETA: 3:50 - loss: 1.7650 - accuracy: 0.54 - ETA: 3:49 - loss: 1.7599 - accuracy: 0.54 - ETA: 3:47 - loss: 1.7547 - accuracy: 0.54 - ETA: 3:45 - loss: 1.7530 - accuracy: 0.54 - ETA: 3:41 - loss: 1.7588 - accuracy: 0.54 - ETA: 3:37 - loss: 1.7563 - accuracy: 0.54 - ETA: 3:34 - loss: 1.7569 - accuracy: 0.54 - ETA: 3:30 - loss: 1.7655 - accuracy: 0.53 - ETA: 3:26 - loss: 1.7660 - accuracy: 0.53 - ETA: 3:23 - loss: 1.7697 - accuracy: 0.53 - ETA: 3:19 - loss: 1.7911 - accuracy: 0.53 - ETA: 3:16 - loss: 1.7852 - accuracy: 0.53 - ETA: 3:13 - loss: 1.7870 - accuracy: 0.53 - ETA: 3:10 - loss: 1.7853 - accuracy: 0.53 - ETA: 3:07 - loss: 1.7785 - accuracy: 0.53 - ETA: 3:04 - loss: 1.7778 - accuracy: 0.53 - ETA: 3:01 - loss: 1.7942 - accuracy: 0.53 - ETA: 2:58 - loss: 1.7967 - accuracy: 0.53 - ETA: 2:55 - loss: 1.8000 - accuracy: 0.53 - ETA: 2:52 - loss: 1.8022 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8027 - accuracy: 0.53 - ETA: 2:46 - loss: 1.7996 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8060 - accuracy: 0.53 - ETA: 2:41 - loss: 1.8020 - accuracy: 0.53 - ETA: 2:39 - loss: 1.8011 - accuracy: 0.53 - ETA: 2:36 - loss: 1.7983 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8017 - accuracy: 0.53 - ETA: 2:31 - loss: 1.7987 - accuracy: 0.53 - ETA: 2:29 - loss: 1.7981 - accuracy: 0.53 - ETA: 2:26 - loss: 1.7996 - accuracy: 0.53 - ETA: 2:24 - loss: 1.7980 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8100 - accuracy: 0.53 - ETA: 2:19 - loss: 1.8073 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8028 - accuracy: 0.53 - ETA: 2:14 - loss: 1.7994 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8012 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8001 - accuracy: 0.53 - ETA: 2:08 - loss: 1.7988 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8017 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8038 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8069 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8082 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8056 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8046 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8046 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8014 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8037 - accuracy: 0.53 - ETA: 1:47 - loss: 1.7997 - accuracy: 0.53 - ETA: 1:45 - loss: 1.7963 - accuracy: 0.53 - ETA: 1:43 - loss: 1.7966 - accuracy: 0.53 - ETA: 1:41 - loss: 1.7930 - accuracy: 0.53 - ETA: 1:39 - loss: 1.7968 - accuracy: 0.53 - ETA: 1:37 - loss: 1.7945 - accuracy: 0.53 - ETA: 1:35 - loss: 1.7964 - accuracy: 0.53 - ETA: 1:33 - loss: 1.7935 - accuracy: 0.53 - ETA: 1:31 - loss: 1.7916 - accuracy: 0.53 - ETA: 1:29 - loss: 1.7901 - accuracy: 0.53 - ETA: 1:28 - loss: 1.7855 - accuracy: 0.53 - ETA: 1:26 - loss: 1.7874 - accuracy: 0.53 - ETA: 1:24 - loss: 1.7848 - accuracy: 0.53 - ETA: 1:22 - loss: 1.7830 - accuracy: 0.53 - ETA: 1:20 - loss: 1.7808 - accuracy: 0.53 - ETA: 1:18 - loss: 1.7818 - accuracy: 0.53 - ETA: 1:17 - loss: 1.7791 - accuracy: 0.53 - ETA: 1:15 - loss: 1.7831 - accuracy: 0.53 - ETA: 1:13 - loss: 1.7832 - accuracy: 0.53 - ETA: 1:11 - loss: 1.7854 - accuracy: 0.53 - ETA: 1:09 - loss: 1.7835 - accuracy: 0.53 - ETA: 1:08 - loss: 1.7829 - accuracy: 0.53 - ETA: 1:06 - loss: 1.7835 - accuracy: 0.53 - ETA: 1:04 - loss: 1.7819 - accuracy: 0.53 - ETA: 1:02 - loss: 1.7822 - accuracy: 0.53 - ETA: 1:00 - loss: 1.7854 - accuracy: 0.53 - ETA: 59s - loss: 1.7863 - accuracy: 0.5380 - ETA: 57s - loss: 1.7881 - accuracy: 0.537 - ETA: 55s - loss: 1.7892 - accuracy: 0.537 - ETA: 54s - loss: 1.7914 - accuracy: 0.536 - ETA: 52s - loss: 1.7915 - accuracy: 0.536 - ETA: 50s - loss: 1.7912 - accuracy: 0.536 - ETA: 48s - loss: 1.7945 - accuracy: 0.536 - ETA: 47s - loss: 1.7930 - accuracy: 0.536 - ETA: 45s - loss: 1.7922 - accuracy: 0.537 - ETA: 43s - loss: 1.7906 - accuracy: 0.537 - ETA: 42s - loss: 1.7912 - accuracy: 0.537 - ETA: 40s - loss: 1.7900 - accuracy: 0.537 - ETA: 38s - loss: 1.7909 - accuracy: 0.537 - ETA: 37s - loss: 1.7927 - accuracy: 0.537 - ETA: 35s - loss: 1.7960 - accuracy: 0.537 - ETA: 33s - loss: 1.7976 - accuracy: 0.536 - ETA: 32s - loss: 1.7948 - accuracy: 0.537 - ETA: 30s - loss: 1.7914 - accuracy: 0.537 - ETA: 28s - loss: 1.7956 - accuracy: 0.538 - ETA: 27s - loss: 1.7955 - accuracy: 0.538 - ETA: 25s - loss: 1.7955 - accuracy: 0.538 - ETA: 23s - loss: 1.7953 - accuracy: 0.537 - ETA: 22s - loss: 1.7949 - accuracy: 0.537 - ETA: 20s - loss: 1.7961 - accuracy: 0.537 - ETA: 19s - loss: 1.7961 - accuracy: 0.537 - ETA: 17s - loss: 1.7998 - accuracy: 0.537 - ETA: 15s - loss: 1.8017 - accuracy: 0.537 - ETA: 14s - loss: 1.8071 - accuracy: 0.537 - ETA: 12s - loss: 1.8049 - accuracy: 0.537 - ETA: 10s - loss: 1.8041 - accuracy: 0.537 - ETA: 9s - loss: 1.8032 - accuracy: 0.537 - ETA: 7s - loss: 1.8029 - accuracy: 0.53 - ETA: 6s - loss: 1.8023 - accuracy: 0.53 - ETA: 4s - loss: 1.8089 - accuracy: 0.53 - ETA: 2s - loss: 1.8127 - accuracy: 0.53 - ETA: 1s - loss: 1.8140 - accuracy: 0.53 - 252s 13ms/step - loss: 1.8152 - accuracy: 0.5362 - val_loss: 1.9709 - val_accuracy: 0.6012\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:18 - loss: 1.8661 - accuracy: 0.50 - ETA: 3:21 - loss: 1.8282 - accuracy: 0.49 - ETA: 3:20 - loss: 1.8270 - accuracy: 0.49 - ETA: 3:15 - loss: 1.7565 - accuracy: 0.51 - ETA: 3:13 - loss: 1.7260 - accuracy: 0.52 - ETA: 3:10 - loss: 1.7743 - accuracy: 0.52 - ETA: 3:08 - loss: 1.7692 - accuracy: 0.53 - ETA: 3:08 - loss: 1.7761 - accuracy: 0.53 - ETA: 3:06 - loss: 1.7347 - accuracy: 0.53 - ETA: 3:05 - loss: 1.7190 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7072 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7414 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7376 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7574 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7383 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7331 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7389 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7370 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7442 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7249 - accuracy: 0.55 - ETA: 2:50 - loss: 1.7202 - accuracy: 0.55 - ETA: 2:49 - loss: 1.7008 - accuracy: 0.55 - ETA: 2:48 - loss: 1.6993 - accuracy: 0.55 - ETA: 2:47 - loss: 1.6959 - accuracy: 0.55 - ETA: 2:45 - loss: 1.6926 - accuracy: 0.55 - ETA: 2:45 - loss: 1.6879 - accuracy: 0.55 - ETA: 2:44 - loss: 1.6989 - accuracy: 0.55 - ETA: 2:42 - loss: 1.7015 - accuracy: 0.55 - ETA: 2:41 - loss: 1.6905 - accuracy: 0.55 - ETA: 2:40 - loss: 1.6844 - accuracy: 0.55 - ETA: 2:38 - loss: 1.6861 - accuracy: 0.55 - ETA: 2:37 - loss: 1.6988 - accuracy: 0.55 - ETA: 2:36 - loss: 1.7155 - accuracy: 0.55 - ETA: 2:34 - loss: 1.7192 - accuracy: 0.55 - ETA: 2:33 - loss: 1.7179 - accuracy: 0.55 - ETA: 2:31 - loss: 1.7201 - accuracy: 0.55 - ETA: 2:30 - loss: 1.7382 - accuracy: 0.55 - ETA: 2:29 - loss: 1.7424 - accuracy: 0.55 - ETA: 2:28 - loss: 1.7506 - accuracy: 0.55 - ETA: 2:26 - loss: 1.7483 - accuracy: 0.55 - ETA: 2:25 - loss: 1.7394 - accuracy: 0.55 - ETA: 2:24 - loss: 1.7353 - accuracy: 0.55 - ETA: 2:23 - loss: 1.7395 - accuracy: 0.55 - ETA: 2:21 - loss: 1.7408 - accuracy: 0.55 - ETA: 2:20 - loss: 1.7498 - accuracy: 0.55 - ETA: 2:19 - loss: 1.7539 - accuracy: 0.55 - ETA: 2:17 - loss: 1.7474 - accuracy: 0.55 - ETA: 2:16 - loss: 1.7475 - accuracy: 0.55 - ETA: 2:15 - loss: 1.7473 - accuracy: 0.55 - ETA: 2:13 - loss: 1.7416 - accuracy: 0.55 - ETA: 2:12 - loss: 1.7421 - accuracy: 0.55 - ETA: 2:11 - loss: 1.7460 - accuracy: 0.55 - ETA: 2:10 - loss: 1.7461 - accuracy: 0.55 - ETA: 2:08 - loss: 1.7433 - accuracy: 0.55 - ETA: 2:07 - loss: 1.7470 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7475 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7497 - accuracy: 0.55 - ETA: 2:03 - loss: 1.7501 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7496 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7510 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7493 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7609 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7628 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7591 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7575 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7563 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7648 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7732 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7694 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7659 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7625 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7624 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7602 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7609 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7640 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7670 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7674 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7688 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7724 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7808 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7882 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7932 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7951 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7978 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7945 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7918 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7915 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7889 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7883 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7872 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7868 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7845 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7846 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7856 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7864 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7850 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7869 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7907 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7928 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7976 - accuracy: 0.54 - ETA: 1:07 - loss: 1.8017 - accuracy: 0.54 - ETA: 1:06 - loss: 1.8026 - accuracy: 0.54 - ETA: 1:04 - loss: 1.8013 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7986 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7985 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7956 - accuracy: 0.54 - ETA: 59s - loss: 1.7980 - accuracy: 0.5413 - ETA: 58s - loss: 1.7987 - accuracy: 0.540 - ETA: 56s - loss: 1.8007 - accuracy: 0.540 - ETA: 55s - loss: 1.7998 - accuracy: 0.540 - ETA: 54s - loss: 1.8028 - accuracy: 0.540 - ETA: 52s - loss: 1.8012 - accuracy: 0.540 - ETA: 51s - loss: 1.8001 - accuracy: 0.540 - ETA: 49s - loss: 1.7995 - accuracy: 0.540 - ETA: 48s - loss: 1.8013 - accuracy: 0.539 - ETA: 47s - loss: 1.8009 - accuracy: 0.540 - ETA: 45s - loss: 1.7999 - accuracy: 0.540 - ETA: 44s - loss: 1.8003 - accuracy: 0.540 - ETA: 43s - loss: 1.8008 - accuracy: 0.539 - ETA: 42s - loss: 1.7995 - accuracy: 0.539 - ETA: 40s - loss: 1.8002 - accuracy: 0.539 - ETA: 39s - loss: 1.8033 - accuracy: 0.539 - ETA: 37s - loss: 1.8064 - accuracy: 0.538 - ETA: 36s - loss: 1.8052 - accuracy: 0.538 - ETA: 35s - loss: 1.8076 - accuracy: 0.538 - ETA: 33s - loss: 1.8079 - accuracy: 0.538 - ETA: 32s - loss: 1.8094 - accuracy: 0.537 - ETA: 31s - loss: 1.8108 - accuracy: 0.537 - ETA: 29s - loss: 1.8305 - accuracy: 0.537 - ETA: 28s - loss: 1.8294 - accuracy: 0.538 - ETA: 27s - loss: 1.8303 - accuracy: 0.537 - ETA: 25s - loss: 1.8280 - accuracy: 0.538 - ETA: 24s - loss: 1.8294 - accuracy: 0.537 - ETA: 22s - loss: 1.8328 - accuracy: 0.537 - ETA: 21s - loss: 1.8314 - accuracy: 0.537 - ETA: 20s - loss: 1.8356 - accuracy: 0.537 - ETA: 18s - loss: 1.8364 - accuracy: 0.537 - ETA: 17s - loss: 1.8374 - accuracy: 0.537 - ETA: 16s - loss: 1.8383 - accuracy: 0.536 - ETA: 14s - loss: 1.8398 - accuracy: 0.536 - ETA: 13s - loss: 1.8362 - accuracy: 0.537 - ETA: 12s - loss: 1.8339 - accuracy: 0.537 - ETA: 10s - loss: 1.8331 - accuracy: 0.537 - ETA: 9s - loss: 1.8298 - accuracy: 0.538 - ETA: 7s - loss: 1.8276 - accuracy: 0.53 - ETA: 6s - loss: 1.8264 - accuracy: 0.53 - ETA: 5s - loss: 1.8271 - accuracy: 0.53 - ETA: 3s - loss: 1.8259 - accuracy: 0.53 - ETA: 2s - loss: 1.8247 - accuracy: 0.53 - ETA: 1s - loss: 1.8228 - accuracy: 0.53 - 216s 11ms/step - loss: 1.8223 - accuracy: 0.5398 - val_loss: 1.9803 - val_accuracy: 0.5954\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:22 - loss: 1.6666 - accuracy: 0.54 - ETA: 3:23 - loss: 1.5743 - accuracy: 0.57 - ETA: 3:20 - loss: 1.7707 - accuracy: 0.53 - ETA: 3:17 - loss: 1.6837 - accuracy: 0.55 - ETA: 3:15 - loss: 1.7454 - accuracy: 0.54 - ETA: 3:15 - loss: 1.7659 - accuracy: 0.54 - ETA: 3:14 - loss: 1.8899 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8548 - accuracy: 0.52 - ETA: 3:13 - loss: 1.8356 - accuracy: 0.53 - ETA: 3:12 - loss: 1.7918 - accuracy: 0.53 - ETA: 3:12 - loss: 1.7730 - accuracy: 0.55 - ETA: 3:11 - loss: 1.7489 - accuracy: 0.55 - ETA: 3:10 - loss: 1.7556 - accuracy: 0.55 - ETA: 3:08 - loss: 1.7761 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7823 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7680 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7890 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7706 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7652 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7491 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7439 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7520 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7519 - accuracy: 0.55 - ETA: 2:54 - loss: 1.7466 - accuracy: 0.55 - ETA: 2:53 - loss: 1.7540 - accuracy: 0.55 - ETA: 2:51 - loss: 1.7475 - accuracy: 0.55 - ETA: 2:50 - loss: 1.7354 - accuracy: 0.55 - ETA: 2:48 - loss: 1.7400 - accuracy: 0.55 - ETA: 2:47 - loss: 1.7370 - accuracy: 0.55 - ETA: 2:46 - loss: 1.7399 - accuracy: 0.55 - ETA: 2:45 - loss: 1.7472 - accuracy: 0.55 - ETA: 2:43 - loss: 1.7444 - accuracy: 0.55 - ETA: 2:42 - loss: 1.7582 - accuracy: 0.55 - ETA: 2:40 - loss: 1.7593 - accuracy: 0.55 - ETA: 2:39 - loss: 1.7587 - accuracy: 0.55 - ETA: 2:37 - loss: 1.7551 - accuracy: 0.55 - ETA: 2:36 - loss: 1.7613 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7607 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7715 - accuracy: 0.55 - ETA: 2:32 - loss: 1.7696 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7752 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7786 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7743 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7798 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7794 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7741 - accuracy: 0.54 - ETA: 2:22 - loss: 1.7728 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7687 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7703 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7687 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7718 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7661 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7702 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7708 - accuracy: 0.54 - ETA: 2:11 - loss: 1.7752 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7745 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7818 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7800 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7969 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7954 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7955 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7947 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7889 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7902 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7868 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7867 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7860 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7867 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7900 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7907 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7874 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7836 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7838 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7826 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7857 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7919 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7951 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7914 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7942 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7984 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7957 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7962 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7959 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7978 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7960 - accuracy: 0.54 - ETA: 1:28 - loss: 1.8150 - accuracy: 0.54 - ETA: 1:27 - loss: 1.8144 - accuracy: 0.54 - ETA: 1:25 - loss: 1.8147 - accuracy: 0.54 - ETA: 1:24 - loss: 1.8137 - accuracy: 0.54 - ETA: 1:23 - loss: 1.8104 - accuracy: 0.54 - ETA: 1:21 - loss: 1.8081 - accuracy: 0.54 - ETA: 1:20 - loss: 1.8105 - accuracy: 0.54 - ETA: 1:19 - loss: 1.8092 - accuracy: 0.54 - ETA: 1:17 - loss: 1.8094 - accuracy: 0.54 - ETA: 1:16 - loss: 1.8070 - accuracy: 0.54 - ETA: 1:14 - loss: 1.8043 - accuracy: 0.54 - ETA: 1:13 - loss: 1.8077 - accuracy: 0.54 - ETA: 1:12 - loss: 1.8024 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7988 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7985 - accuracy: 0.54 - ETA: 1:08 - loss: 1.8009 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7991 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7958 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7970 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7942 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7944 - accuracy: 0.54 - ETA: 59s - loss: 1.7942 - accuracy: 0.5411 - ETA: 58s - loss: 1.7938 - accuracy: 0.540 - ETA: 57s - loss: 1.7926 - accuracy: 0.541 - ETA: 55s - loss: 1.7968 - accuracy: 0.540 - ETA: 54s - loss: 1.7964 - accuracy: 0.540 - ETA: 53s - loss: 1.8018 - accuracy: 0.539 - ETA: 51s - loss: 1.8018 - accuracy: 0.539 - ETA: 50s - loss: 1.8051 - accuracy: 0.538 - ETA: 49s - loss: 1.8028 - accuracy: 0.539 - ETA: 47s - loss: 1.8011 - accuracy: 0.539 - ETA: 46s - loss: 1.7986 - accuracy: 0.540 - ETA: 44s - loss: 1.8007 - accuracy: 0.539 - ETA: 43s - loss: 1.7991 - accuracy: 0.540 - ETA: 42s - loss: 1.8021 - accuracy: 0.539 - ETA: 40s - loss: 1.8040 - accuracy: 0.539 - ETA: 39s - loss: 1.8027 - accuracy: 0.539 - ETA: 38s - loss: 1.8023 - accuracy: 0.539 - ETA: 36s - loss: 1.8037 - accuracy: 0.538 - ETA: 35s - loss: 1.8072 - accuracy: 0.538 - ETA: 34s - loss: 1.8079 - accuracy: 0.537 - ETA: 32s - loss: 1.8085 - accuracy: 0.537 - ETA: 31s - loss: 1.8094 - accuracy: 0.537 - ETA: 29s - loss: 1.8084 - accuracy: 0.537 - ETA: 28s - loss: 1.8080 - accuracy: 0.537 - ETA: 27s - loss: 1.8059 - accuracy: 0.537 - ETA: 25s - loss: 1.8037 - accuracy: 0.537 - ETA: 24s - loss: 1.8056 - accuracy: 0.537 - ETA: 23s - loss: 1.8032 - accuracy: 0.537 - ETA: 21s - loss: 1.8080 - accuracy: 0.537 - ETA: 20s - loss: 1.8078 - accuracy: 0.537 - ETA: 18s - loss: 1.8127 - accuracy: 0.537 - ETA: 17s - loss: 1.8119 - accuracy: 0.537 - ETA: 16s - loss: 1.8142 - accuracy: 0.537 - ETA: 14s - loss: 1.8119 - accuracy: 0.537 - ETA: 13s - loss: 1.8133 - accuracy: 0.537 - ETA: 12s - loss: 1.8142 - accuracy: 0.536 - ETA: 10s - loss: 1.8134 - accuracy: 0.536 - ETA: 9s - loss: 1.8130 - accuracy: 0.536 - ETA: 8s - loss: 1.8134 - accuracy: 0.53 - ETA: 6s - loss: 1.8134 - accuracy: 0.53 - ETA: 5s - loss: 1.8140 - accuracy: 0.53 - ETA: 3s - loss: 1.8113 - accuracy: 0.53 - ETA: 2s - loss: 1.8158 - accuracy: 0.53 - ETA: 1s - loss: 1.8154 - accuracy: 0.53 - 218s 11ms/step - loss: 1.8135 - accuracy: 0.5372 - val_loss: 2.0750 - val_accuracy: 0.5968\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:31 - loss: 1.5658 - accuracy: 0.58 - ETA: 3:20 - loss: 1.5250 - accuracy: 0.58 - ETA: 3:16 - loss: 1.6385 - accuracy: 0.57 - ETA: 3:16 - loss: 1.7424 - accuracy: 0.56 - ETA: 3:14 - loss: 1.6764 - accuracy: 0.57 - ETA: 3:12 - loss: 1.6394 - accuracy: 0.58 - ETA: 3:12 - loss: 1.6411 - accuracy: 0.58 - ETA: 3:11 - loss: 1.6458 - accuracy: 0.57 - ETA: 3:10 - loss: 1.7607 - accuracy: 0.57 - ETA: 3:09 - loss: 1.7284 - accuracy: 0.57 - ETA: 3:08 - loss: 1.7432 - accuracy: 0.57 - ETA: 3:07 - loss: 1.7437 - accuracy: 0.57 - ETA: 3:06 - loss: 1.7300 - accuracy: 0.57 - ETA: 3:04 - loss: 1.7217 - accuracy: 0.57 - ETA: 3:03 - loss: 1.7195 - accuracy: 0.57 - ETA: 3:02 - loss: 1.7356 - accuracy: 0.57 - ETA: 3:00 - loss: 1.7433 - accuracy: 0.57 - ETA: 2:59 - loss: 1.7705 - accuracy: 0.57 - ETA: 2:58 - loss: 1.7728 - accuracy: 0.57 - ETA: 2:56 - loss: 1.7625 - accuracy: 0.57 - ETA: 2:55 - loss: 1.7562 - accuracy: 0.56 - ETA: 2:53 - loss: 1.7518 - accuracy: 0.56 - ETA: 2:52 - loss: 1.7476 - accuracy: 0.56 - ETA: 2:51 - loss: 1.7348 - accuracy: 0.56 - ETA: 2:50 - loss: 1.7286 - accuracy: 0.56 - ETA: 2:49 - loss: 1.7509 - accuracy: 0.56 - ETA: 2:47 - loss: 1.7599 - accuracy: 0.56 - ETA: 2:46 - loss: 1.7545 - accuracy: 0.56 - ETA: 2:45 - loss: 1.7451 - accuracy: 0.56 - ETA: 2:43 - loss: 1.7433 - accuracy: 0.56 - ETA: 2:42 - loss: 1.7450 - accuracy: 0.55 - ETA: 2:40 - loss: 1.7430 - accuracy: 0.55 - ETA: 2:39 - loss: 1.7400 - accuracy: 0.55 - ETA: 2:38 - loss: 1.7465 - accuracy: 0.55 - ETA: 2:37 - loss: 1.7395 - accuracy: 0.55 - ETA: 2:35 - loss: 1.7427 - accuracy: 0.55 - ETA: 2:34 - loss: 1.7483 - accuracy: 0.55 - ETA: 2:33 - loss: 1.7457 - accuracy: 0.55 - ETA: 2:31 - loss: 1.7529 - accuracy: 0.55 - ETA: 2:30 - loss: 1.7552 - accuracy: 0.55 - ETA: 2:29 - loss: 1.7536 - accuracy: 0.55 - ETA: 2:27 - loss: 1.7573 - accuracy: 0.55 - ETA: 2:26 - loss: 1.7508 - accuracy: 0.55 - ETA: 2:24 - loss: 1.7500 - accuracy: 0.55 - ETA: 2:23 - loss: 1.7461 - accuracy: 0.55 - ETA: 2:22 - loss: 1.7375 - accuracy: 0.55 - ETA: 2:20 - loss: 1.7371 - accuracy: 0.55 - ETA: 2:19 - loss: 1.7369 - accuracy: 0.55 - ETA: 2:18 - loss: 1.7357 - accuracy: 0.55 - ETA: 2:17 - loss: 1.7402 - accuracy: 0.55 - ETA: 2:15 - loss: 1.7394 - accuracy: 0.55 - ETA: 2:14 - loss: 1.7450 - accuracy: 0.55 - ETA: 2:13 - loss: 1.7440 - accuracy: 0.55 - ETA: 2:11 - loss: 1.7530 - accuracy: 0.55 - ETA: 2:10 - loss: 1.7510 - accuracy: 0.55 - ETA: 2:08 - loss: 1.7540 - accuracy: 0.55 - ETA: 2:07 - loss: 1.7507 - accuracy: 0.55 - ETA: 2:06 - loss: 1.7511 - accuracy: 0.55 - ETA: 2:05 - loss: 1.7551 - accuracy: 0.55 - ETA: 2:03 - loss: 1.7559 - accuracy: 0.55 - ETA: 2:02 - loss: 1.7665 - accuracy: 0.55 - ETA: 2:00 - loss: 1.7651 - accuracy: 0.55 - ETA: 1:59 - loss: 1.7607 - accuracy: 0.55 - ETA: 1:58 - loss: 1.7606 - accuracy: 0.55 - ETA: 1:56 - loss: 1.7583 - accuracy: 0.55 - ETA: 1:55 - loss: 1.7532 - accuracy: 0.55 - ETA: 1:54 - loss: 1.7528 - accuracy: 0.55 - ETA: 1:52 - loss: 1.7527 - accuracy: 0.55 - ETA: 1:51 - loss: 1.7526 - accuracy: 0.55 - ETA: 1:50 - loss: 1.7595 - accuracy: 0.55 - ETA: 1:48 - loss: 1.7612 - accuracy: 0.55 - ETA: 1:47 - loss: 1.7587 - accuracy: 0.55 - ETA: 1:46 - loss: 1.7564 - accuracy: 0.55 - ETA: 1:44 - loss: 1.7746 - accuracy: 0.55 - ETA: 1:43 - loss: 1.7741 - accuracy: 0.55 - ETA: 1:41 - loss: 1.7751 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7744 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7742 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7689 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7737 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7798 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7802 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7811 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7828 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7804 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7795 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7799 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7795 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7815 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7790 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7804 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7767 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7777 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7798 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7770 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7799 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7809 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7793 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7780 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7800 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7789 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7799 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7811 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7803 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7809 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7815 - accuracy: 0.54 - ETA: 59s - loss: 1.7840 - accuracy: 0.5442 - ETA: 58s - loss: 1.7862 - accuracy: 0.544 - ETA: 56s - loss: 1.7843 - accuracy: 0.544 - ETA: 55s - loss: 1.7817 - accuracy: 0.544 - ETA: 54s - loss: 1.7815 - accuracy: 0.544 - ETA: 52s - loss: 1.7829 - accuracy: 0.543 - ETA: 51s - loss: 1.7840 - accuracy: 0.544 - ETA: 50s - loss: 1.7833 - accuracy: 0.544 - ETA: 48s - loss: 1.7850 - accuracy: 0.543 - ETA: 47s - loss: 1.7859 - accuracy: 0.543 - ETA: 46s - loss: 1.7867 - accuracy: 0.542 - ETA: 44s - loss: 1.7894 - accuracy: 0.542 - ETA: 43s - loss: 1.7885 - accuracy: 0.542 - ETA: 41s - loss: 1.7876 - accuracy: 0.542 - ETA: 40s - loss: 1.7914 - accuracy: 0.542 - ETA: 39s - loss: 1.7921 - accuracy: 0.542 - ETA: 37s - loss: 1.7902 - accuracy: 0.542 - ETA: 36s - loss: 1.7960 - accuracy: 0.541 - ETA: 35s - loss: 1.7969 - accuracy: 0.541 - ETA: 33s - loss: 1.7964 - accuracy: 0.540 - ETA: 32s - loss: 1.7978 - accuracy: 0.540 - ETA: 31s - loss: 1.7984 - accuracy: 0.540 - ETA: 29s - loss: 1.7968 - accuracy: 0.540 - ETA: 28s - loss: 1.7972 - accuracy: 0.540 - ETA: 27s - loss: 1.7970 - accuracy: 0.540 - ETA: 25s - loss: 1.7967 - accuracy: 0.540 - ETA: 24s - loss: 1.7959 - accuracy: 0.539 - ETA: 22s - loss: 1.7933 - accuracy: 0.540 - ETA: 21s - loss: 1.7922 - accuracy: 0.540 - ETA: 20s - loss: 1.7925 - accuracy: 0.539 - ETA: 18s - loss: 1.7936 - accuracy: 0.539 - ETA: 17s - loss: 1.7925 - accuracy: 0.539 - ETA: 16s - loss: 1.7935 - accuracy: 0.539 - ETA: 14s - loss: 1.7987 - accuracy: 0.538 - ETA: 13s - loss: 1.8004 - accuracy: 0.538 - ETA: 12s - loss: 1.7998 - accuracy: 0.538 - ETA: 10s - loss: 1.7988 - accuracy: 0.538 - ETA: 9s - loss: 1.7996 - accuracy: 0.538 - ETA: 7s - loss: 1.7983 - accuracy: 0.53 - ETA: 6s - loss: 1.7976 - accuracy: 0.53 - ETA: 5s - loss: 1.7977 - accuracy: 0.53 - ETA: 3s - loss: 1.7960 - accuracy: 0.53 - ETA: 2s - loss: 1.7962 - accuracy: 0.53 - ETA: 1s - loss: 1.7966 - accuracy: 0.53 - 216s 11ms/step - loss: 1.7963 - accuracy: 0.5379 - val_loss: 2.0163 - val_accuracy: 0.5943\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:31 - loss: 1.4890 - accuracy: 0.59 - ETA: 3:21 - loss: 1.4763 - accuracy: 0.60 - ETA: 3:22 - loss: 1.5383 - accuracy: 0.57 - ETA: 3:17 - loss: 1.5833 - accuracy: 0.56 - ETA: 3:15 - loss: 1.5575 - accuracy: 0.57 - ETA: 3:16 - loss: 1.6302 - accuracy: 0.56 - ETA: 3:16 - loss: 1.6270 - accuracy: 0.56 - ETA: 3:14 - loss: 1.6615 - accuracy: 0.55 - ETA: 3:12 - loss: 1.6501 - accuracy: 0.55 - ETA: 3:11 - loss: 1.6251 - accuracy: 0.56 - ETA: 3:10 - loss: 1.7808 - accuracy: 0.55 - ETA: 3:08 - loss: 1.7830 - accuracy: 0.55 - ETA: 3:07 - loss: 1.8105 - accuracy: 0.54 - ETA: 3:06 - loss: 1.8487 - accuracy: 0.54 - ETA: 3:04 - loss: 1.8728 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8813 - accuracy: 0.53 - ETA: 3:01 - loss: 1.8622 - accuracy: 0.53 - ETA: 3:00 - loss: 1.9084 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8914 - accuracy: 0.54 - ETA: 2:57 - loss: 1.8997 - accuracy: 0.54 - ETA: 2:56 - loss: 1.8634 - accuracy: 0.54 - ETA: 2:54 - loss: 1.8720 - accuracy: 0.54 - ETA: 2:53 - loss: 1.8607 - accuracy: 0.54 - ETA: 2:51 - loss: 1.8475 - accuracy: 0.54 - ETA: 2:50 - loss: 1.8390 - accuracy: 0.54 - ETA: 2:49 - loss: 1.8253 - accuracy: 0.55 - ETA: 2:47 - loss: 1.8339 - accuracy: 0.54 - ETA: 2:46 - loss: 1.8392 - accuracy: 0.54 - ETA: 2:45 - loss: 1.8336 - accuracy: 0.54 - ETA: 2:44 - loss: 1.8440 - accuracy: 0.54 - ETA: 2:43 - loss: 1.8439 - accuracy: 0.54 - ETA: 2:41 - loss: 1.8373 - accuracy: 0.54 - ETA: 2:40 - loss: 1.8457 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8443 - accuracy: 0.53 - ETA: 2:37 - loss: 1.8316 - accuracy: 0.54 - ETA: 2:36 - loss: 1.8341 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8215 - accuracy: 0.54 - ETA: 2:33 - loss: 1.8277 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8169 - accuracy: 0.54 - ETA: 2:31 - loss: 1.8257 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8352 - accuracy: 0.54 - ETA: 2:29 - loss: 1.8321 - accuracy: 0.54 - ETA: 2:28 - loss: 1.8315 - accuracy: 0.54 - ETA: 2:27 - loss: 1.8357 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8422 - accuracy: 0.53 - ETA: 2:24 - loss: 1.8438 - accuracy: 0.53 - ETA: 2:22 - loss: 1.8449 - accuracy: 0.53 - ETA: 2:21 - loss: 1.8499 - accuracy: 0.53 - ETA: 2:20 - loss: 1.8445 - accuracy: 0.53 - ETA: 2:18 - loss: 1.8417 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8372 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8332 - accuracy: 0.53 - ETA: 2:14 - loss: 1.8293 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8279 - accuracy: 0.53 - ETA: 2:11 - loss: 1.8244 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8279 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8253 - accuracy: 0.53 - ETA: 2:07 - loss: 1.8253 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8255 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8298 - accuracy: 0.53 - ETA: 2:03 - loss: 1.8242 - accuracy: 0.53 - ETA: 2:01 - loss: 1.8222 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8323 - accuracy: 0.53 - ETA: 1:59 - loss: 1.8280 - accuracy: 0.53 - ETA: 1:57 - loss: 1.8286 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8362 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8349 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8307 - accuracy: 0.53 - ETA: 1:52 - loss: 1.8355 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8301 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8215 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8158 - accuracy: 0.53 - ETA: 1:46 - loss: 1.8149 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8139 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8115 - accuracy: 0.53 - ETA: 1:42 - loss: 1.8092 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8079 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8043 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8096 - accuracy: 0.53 - ETA: 1:37 - loss: 1.8058 - accuracy: 0.53 - ETA: 1:35 - loss: 1.8076 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8046 - accuracy: 0.53 - ETA: 1:33 - loss: 1.8033 - accuracy: 0.53 - ETA: 1:31 - loss: 1.7993 - accuracy: 0.53 - ETA: 1:30 - loss: 1.7982 - accuracy: 0.53 - ETA: 1:28 - loss: 1.7966 - accuracy: 0.53 - ETA: 1:27 - loss: 1.7940 - accuracy: 0.53 - ETA: 1:26 - loss: 1.7911 - accuracy: 0.53 - ETA: 1:24 - loss: 1.7943 - accuracy: 0.53 - ETA: 1:23 - loss: 1.7948 - accuracy: 0.53 - ETA: 1:21 - loss: 1.7924 - accuracy: 0.53 - ETA: 1:20 - loss: 1.7918 - accuracy: 0.53 - ETA: 1:19 - loss: 1.7931 - accuracy: 0.53 - ETA: 1:17 - loss: 1.7925 - accuracy: 0.53 - ETA: 1:16 - loss: 1.7922 - accuracy: 0.53 - ETA: 1:15 - loss: 1.7966 - accuracy: 0.53 - ETA: 1:13 - loss: 1.7967 - accuracy: 0.53 - ETA: 1:12 - loss: 1.7937 - accuracy: 0.53 - ETA: 1:10 - loss: 1.7926 - accuracy: 0.53 - ETA: 1:09 - loss: 1.7916 - accuracy: 0.53 - ETA: 1:08 - loss: 1.7893 - accuracy: 0.53 - ETA: 1:06 - loss: 1.8008 - accuracy: 0.53 - ETA: 1:05 - loss: 1.8010 - accuracy: 0.53 - ETA: 1:04 - loss: 1.7998 - accuracy: 0.53 - ETA: 1:02 - loss: 1.8009 - accuracy: 0.53 - ETA: 1:01 - loss: 1.7984 - accuracy: 0.53 - ETA: 1:00 - loss: 1.7982 - accuracy: 0.53 - ETA: 58s - loss: 1.7976 - accuracy: 0.5391 - ETA: 57s - loss: 1.7947 - accuracy: 0.539 - ETA: 55s - loss: 1.7969 - accuracy: 0.539 - ETA: 54s - loss: 1.7932 - accuracy: 0.540 - ETA: 53s - loss: 1.7936 - accuracy: 0.540 - ETA: 51s - loss: 1.7919 - accuracy: 0.540 - ETA: 50s - loss: 1.7938 - accuracy: 0.539 - ETA: 49s - loss: 1.7927 - accuracy: 0.539 - ETA: 47s - loss: 1.7898 - accuracy: 0.540 - ETA: 46s - loss: 1.7895 - accuracy: 0.540 - ETA: 44s - loss: 1.7892 - accuracy: 0.539 - ETA: 43s - loss: 1.7908 - accuracy: 0.539 - ETA: 42s - loss: 1.7926 - accuracy: 0.539 - ETA: 40s - loss: 1.7922 - accuracy: 0.538 - ETA: 39s - loss: 1.7919 - accuracy: 0.538 - ETA: 38s - loss: 1.7909 - accuracy: 0.538 - ETA: 36s - loss: 1.7905 - accuracy: 0.539 - ETA: 35s - loss: 1.7879 - accuracy: 0.539 - ETA: 34s - loss: 1.7884 - accuracy: 0.539 - ETA: 32s - loss: 1.7865 - accuracy: 0.539 - ETA: 31s - loss: 1.7865 - accuracy: 0.538 - ETA: 29s - loss: 1.7876 - accuracy: 0.539 - ETA: 28s - loss: 1.7891 - accuracy: 0.539 - ETA: 27s - loss: 1.7887 - accuracy: 0.539 - ETA: 25s - loss: 1.7866 - accuracy: 0.539 - ETA: 24s - loss: 1.7855 - accuracy: 0.540 - ETA: 23s - loss: 1.7863 - accuracy: 0.539 - ETA: 21s - loss: 1.7872 - accuracy: 0.539 - ETA: 20s - loss: 1.7861 - accuracy: 0.539 - ETA: 18s - loss: 1.7856 - accuracy: 0.539 - ETA: 17s - loss: 1.7867 - accuracy: 0.540 - ETA: 16s - loss: 1.7858 - accuracy: 0.540 - ETA: 14s - loss: 1.7835 - accuracy: 0.540 - ETA: 13s - loss: 1.7813 - accuracy: 0.540 - ETA: 12s - loss: 1.7816 - accuracy: 0.540 - ETA: 10s - loss: 1.7809 - accuracy: 0.540 - ETA: 9s - loss: 1.7804 - accuracy: 0.540 - ETA: 8s - loss: 1.7823 - accuracy: 0.54 - ETA: 6s - loss: 1.7847 - accuracy: 0.54 - ETA: 5s - loss: 1.7834 - accuracy: 0.54 - ETA: 3s - loss: 1.7827 - accuracy: 0.54 - ETA: 2s - loss: 1.7821 - accuracy: 0.54 - ETA: 1s - loss: 1.7801 - accuracy: 0.54 - 217s 11ms/step - loss: 1.7792 - accuracy: 0.5414 - val_loss: 1.9104 - val_accuracy: 0.5896\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:18 - loss: 1.6613 - accuracy: 0.53 - ETA: 3:18 - loss: 1.4721 - accuracy: 0.59 - ETA: 3:19 - loss: 1.4701 - accuracy: 0.59 - ETA: 3:16 - loss: 1.5120 - accuracy: 0.59 - ETA: 3:14 - loss: 1.5293 - accuracy: 0.59 - ETA: 3:15 - loss: 1.5675 - accuracy: 0.58 - ETA: 3:15 - loss: 1.6139 - accuracy: 0.56 - ETA: 3:14 - loss: 1.6799 - accuracy: 0.54 - ETA: 3:12 - loss: 1.6719 - accuracy: 0.54 - ETA: 3:11 - loss: 1.6456 - accuracy: 0.55 - ETA: 3:11 - loss: 1.6339 - accuracy: 0.55 - ETA: 3:10 - loss: 1.6096 - accuracy: 0.56 - ETA: 3:09 - loss: 1.5937 - accuracy: 0.56 - ETA: 3:07 - loss: 1.6224 - accuracy: 0.56 - ETA: 3:05 - loss: 1.6106 - accuracy: 0.56 - ETA: 3:03 - loss: 1.6097 - accuracy: 0.56 - ETA: 3:02 - loss: 1.6222 - accuracy: 0.56 - ETA: 3:00 - loss: 1.6737 - accuracy: 0.55 - ETA: 2:59 - loss: 1.6804 - accuracy: 0.55 - ETA: 2:57 - loss: 1.6789 - accuracy: 0.55 - ETA: 2:56 - loss: 1.6893 - accuracy: 0.55 - ETA: 2:55 - loss: 1.7290 - accuracy: 0.55 - ETA: 2:54 - loss: 1.7292 - accuracy: 0.55 - ETA: 2:53 - loss: 1.7303 - accuracy: 0.55 - ETA: 2:51 - loss: 1.7157 - accuracy: 0.55 - ETA: 2:50 - loss: 1.7177 - accuracy: 0.55 - ETA: 2:48 - loss: 1.7176 - accuracy: 0.55 - ETA: 2:47 - loss: 1.7178 - accuracy: 0.55 - ETA: 2:46 - loss: 1.7037 - accuracy: 0.55 - ETA: 2:45 - loss: 1.7011 - accuracy: 0.55 - ETA: 2:44 - loss: 1.6989 - accuracy: 0.55 - ETA: 2:42 - loss: 1.7049 - accuracy: 0.55 - ETA: 2:41 - loss: 1.7063 - accuracy: 0.55 - ETA: 2:39 - loss: 1.7087 - accuracy: 0.55 - ETA: 2:38 - loss: 1.7130 - accuracy: 0.55 - ETA: 2:37 - loss: 1.7230 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7139 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7357 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7479 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7664 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7646 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7662 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7782 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7802 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7698 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7696 - accuracy: 0.54 - ETA: 2:22 - loss: 1.7639 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7645 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7660 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7625 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7610 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7673 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7712 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7711 - accuracy: 0.54 - ETA: 2:11 - loss: 1.7726 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7700 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7753 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7868 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7865 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7822 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7806 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7763 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7776 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7716 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7758 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7726 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7750 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7725 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7709 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7743 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7699 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7674 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7656 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7656 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7599 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7564 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7563 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7569 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7563 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7579 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7593 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7563 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7559 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7571 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7583 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7597 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7674 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7656 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7687 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7696 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7714 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7773 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7778 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7836 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7832 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7791 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7814 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7823 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7831 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7835 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7815 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7828 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7797 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7804 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7805 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7816 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7776 - accuracy: 0.54 - ETA: 59s - loss: 1.7791 - accuracy: 0.5440 - ETA: 58s - loss: 1.7776 - accuracy: 0.544 - ETA: 56s - loss: 1.7783 - accuracy: 0.543 - ETA: 55s - loss: 1.7774 - accuracy: 0.544 - ETA: 53s - loss: 1.7751 - accuracy: 0.544 - ETA: 52s - loss: 1.7747 - accuracy: 0.544 - ETA: 51s - loss: 1.7729 - accuracy: 0.544 - ETA: 49s - loss: 1.7726 - accuracy: 0.544 - ETA: 48s - loss: 1.7724 - accuracy: 0.544 - ETA: 46s - loss: 1.7694 - accuracy: 0.545 - ETA: 45s - loss: 1.7706 - accuracy: 0.545 - ETA: 44s - loss: 1.7717 - accuracy: 0.544 - ETA: 42s - loss: 1.7708 - accuracy: 0.544 - ETA: 41s - loss: 1.7709 - accuracy: 0.545 - ETA: 40s - loss: 1.7751 - accuracy: 0.544 - ETA: 38s - loss: 1.7741 - accuracy: 0.544 - ETA: 37s - loss: 1.7759 - accuracy: 0.544 - ETA: 35s - loss: 1.7780 - accuracy: 0.543 - ETA: 34s - loss: 1.7766 - accuracy: 0.543 - ETA: 33s - loss: 1.7776 - accuracy: 0.543 - ETA: 31s - loss: 1.7754 - accuracy: 0.543 - ETA: 30s - loss: 1.7745 - accuracy: 0.543 - ETA: 28s - loss: 1.7752 - accuracy: 0.544 - ETA: 27s - loss: 1.7760 - accuracy: 0.544 - ETA: 26s - loss: 1.7745 - accuracy: 0.544 - ETA: 24s - loss: 1.7764 - accuracy: 0.544 - ETA: 23s - loss: 1.7751 - accuracy: 0.544 - ETA: 21s - loss: 1.7739 - accuracy: 0.544 - ETA: 20s - loss: 1.7720 - accuracy: 0.544 - ETA: 19s - loss: 1.7728 - accuracy: 0.544 - ETA: 17s - loss: 1.7720 - accuracy: 0.544 - ETA: 16s - loss: 1.7711 - accuracy: 0.544 - ETA: 15s - loss: 1.7699 - accuracy: 0.544 - ETA: 13s - loss: 1.7697 - accuracy: 0.544 - ETA: 12s - loss: 1.7674 - accuracy: 0.545 - ETA: 10s - loss: 1.7678 - accuracy: 0.544 - ETA: 9s - loss: 1.7675 - accuracy: 0.544 - ETA: 8s - loss: 1.7667 - accuracy: 0.54 - ETA: 6s - loss: 1.7656 - accuracy: 0.54 - ETA: 5s - loss: 1.7637 - accuracy: 0.54 - ETA: 3s - loss: 1.7656 - accuracy: 0.54 - ETA: 2s - loss: 1.7654 - accuracy: 0.54 - ETA: 1s - loss: 1.7656 - accuracy: 0.54 - 219s 11ms/step - loss: 1.7643 - accuracy: 0.5447 - val_loss: 2.0955 - val_accuracy: 0.5985\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:21 - loss: 1.4219 - accuracy: 0.59 - ETA: 3:22 - loss: 1.6469 - accuracy: 0.55 - ETA: 3:29 - loss: 1.6611 - accuracy: 0.54 - ETA: 3:27 - loss: 1.6708 - accuracy: 0.54 - ETA: 3:23 - loss: 1.6515 - accuracy: 0.55 - ETA: 3:23 - loss: 1.6971 - accuracy: 0.55 - ETA: 3:20 - loss: 1.6962 - accuracy: 0.55 - ETA: 3:16 - loss: 1.6906 - accuracy: 0.55 - ETA: 3:14 - loss: 1.7198 - accuracy: 0.54 - ETA: 3:13 - loss: 1.6998 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7437 - accuracy: 0.54 - ETA: 3:09 - loss: 1.7189 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7143 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7290 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7236 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7224 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7123 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7136 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7157 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7088 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7049 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7145 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7205 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7330 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7300 - accuracy: 0.54 - ETA: 2:51 - loss: 1.7330 - accuracy: 0.54 - ETA: 2:50 - loss: 1.7473 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7543 - accuracy: 0.53 - ETA: 2:47 - loss: 1.7574 - accuracy: 0.53 - ETA: 2:45 - loss: 1.7561 - accuracy: 0.53 - ETA: 2:44 - loss: 1.7636 - accuracy: 0.53 - ETA: 2:42 - loss: 1.7585 - accuracy: 0.53 - ETA: 2:41 - loss: 1.7571 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7531 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7483 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7490 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7459 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7470 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7505 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7447 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7533 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7571 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7628 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7671 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7605 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7553 - accuracy: 0.54 - ETA: 2:22 - loss: 1.7477 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7530 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7505 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7491 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7491 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7507 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7725 - accuracy: 0.53 - ETA: 2:12 - loss: 1.7785 - accuracy: 0.53 - ETA: 2:10 - loss: 1.7840 - accuracy: 0.53 - ETA: 2:09 - loss: 1.7866 - accuracy: 0.53 - ETA: 2:07 - loss: 1.7888 - accuracy: 0.53 - ETA: 2:06 - loss: 1.7880 - accuracy: 0.53 - ETA: 2:05 - loss: 1.7873 - accuracy: 0.53 - ETA: 2:03 - loss: 1.7832 - accuracy: 0.53 - ETA: 2:02 - loss: 1.7873 - accuracy: 0.53 - ETA: 2:01 - loss: 1.7848 - accuracy: 0.53 - ETA: 1:59 - loss: 1.7830 - accuracy: 0.53 - ETA: 1:58 - loss: 1.7773 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7750 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7768 - accuracy: 0.53 - ETA: 1:54 - loss: 1.7749 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7735 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7729 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7761 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7732 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7749 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7754 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7760 - accuracy: 0.53 - ETA: 1:43 - loss: 1.7750 - accuracy: 0.53 - ETA: 1:42 - loss: 1.7729 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7698 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7711 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7688 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7678 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7686 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7896 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7891 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7881 - accuracy: 0.53 - ETA: 1:29 - loss: 1.7873 - accuracy: 0.53 - ETA: 1:28 - loss: 1.7852 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7850 - accuracy: 0.53 - ETA: 1:25 - loss: 1.7867 - accuracy: 0.53 - ETA: 1:24 - loss: 1.7880 - accuracy: 0.53 - ETA: 1:22 - loss: 1.7846 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7840 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7853 - accuracy: 0.53 - ETA: 1:18 - loss: 1.7870 - accuracy: 0.53 - ETA: 1:17 - loss: 1.7880 - accuracy: 0.53 - ETA: 1:16 - loss: 1.7855 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7860 - accuracy: 0.53 - ETA: 1:13 - loss: 1.7899 - accuracy: 0.53 - ETA: 1:12 - loss: 1.7867 - accuracy: 0.53 - ETA: 1:10 - loss: 1.7890 - accuracy: 0.53 - ETA: 1:09 - loss: 1.7872 - accuracy: 0.53 - ETA: 1:07 - loss: 1.7878 - accuracy: 0.53 - ETA: 1:06 - loss: 1.7892 - accuracy: 0.53 - ETA: 1:05 - loss: 1.7866 - accuracy: 0.53 - ETA: 1:03 - loss: 1.7875 - accuracy: 0.53 - ETA: 1:02 - loss: 1.7838 - accuracy: 0.53 - ETA: 1:01 - loss: 1.7840 - accuracy: 0.53 - ETA: 59s - loss: 1.7868 - accuracy: 0.5383 - ETA: 58s - loss: 1.7892 - accuracy: 0.537 - ETA: 57s - loss: 1.7880 - accuracy: 0.537 - ETA: 55s - loss: 1.7859 - accuracy: 0.538 - ETA: 54s - loss: 1.7863 - accuracy: 0.538 - ETA: 52s - loss: 1.7848 - accuracy: 0.538 - ETA: 51s - loss: 1.7844 - accuracy: 0.538 - ETA: 50s - loss: 1.7819 - accuracy: 0.539 - ETA: 49s - loss: 1.7802 - accuracy: 0.539 - ETA: 47s - loss: 1.7798 - accuracy: 0.540 - ETA: 46s - loss: 1.7799 - accuracy: 0.539 - ETA: 45s - loss: 1.7775 - accuracy: 0.540 - ETA: 43s - loss: 1.7758 - accuracy: 0.540 - ETA: 42s - loss: 1.7742 - accuracy: 0.540 - ETA: 40s - loss: 1.7713 - accuracy: 0.541 - ETA: 39s - loss: 1.7709 - accuracy: 0.541 - ETA: 38s - loss: 1.7703 - accuracy: 0.541 - ETA: 36s - loss: 1.7706 - accuracy: 0.541 - ETA: 35s - loss: 1.7706 - accuracy: 0.541 - ETA: 34s - loss: 1.7707 - accuracy: 0.541 - ETA: 32s - loss: 1.7701 - accuracy: 0.541 - ETA: 31s - loss: 1.7693 - accuracy: 0.541 - ETA: 30s - loss: 1.7683 - accuracy: 0.541 - ETA: 29s - loss: 1.7673 - accuracy: 0.541 - ETA: 27s - loss: 1.7671 - accuracy: 0.542 - ETA: 26s - loss: 1.7719 - accuracy: 0.541 - ETA: 25s - loss: 1.7713 - accuracy: 0.542 - ETA: 24s - loss: 1.7695 - accuracy: 0.542 - ETA: 22s - loss: 1.7682 - accuracy: 0.542 - ETA: 21s - loss: 1.7675 - accuracy: 0.542 - ETA: 19s - loss: 1.7678 - accuracy: 0.542 - ETA: 18s - loss: 1.7672 - accuracy: 0.543 - ETA: 17s - loss: 1.7648 - accuracy: 0.543 - ETA: 15s - loss: 1.7636 - accuracy: 0.543 - ETA: 14s - loss: 1.7626 - accuracy: 0.543 - ETA: 12s - loss: 1.7629 - accuracy: 0.542 - ETA: 11s - loss: 1.7630 - accuracy: 0.542 - ETA: 10s - loss: 1.7616 - accuracy: 0.542 - ETA: 8s - loss: 1.7618 - accuracy: 0.542 - ETA: 7s - loss: 1.7615 - accuracy: 0.54 - ETA: 5s - loss: 1.7595 - accuracy: 0.54 - ETA: 4s - loss: 1.7596 - accuracy: 0.54 - ETA: 2s - loss: 1.7633 - accuracy: 0.54 - ETA: 1s - loss: 1.7620 - accuracy: 0.54 - 251s 13ms/step - loss: 1.7613 - accuracy: 0.5435 - val_loss: 2.0926 - val_accuracy: 0.5920\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:08 - loss: 1.5972 - accuracy: 0.55 - ETA: 5:16 - loss: 1.6301 - accuracy: 0.57 - ETA: 5:10 - loss: 1.6469 - accuracy: 0.57 - ETA: 5:10 - loss: 1.6212 - accuracy: 0.57 - ETA: 5:08 - loss: 1.7411 - accuracy: 0.56 - ETA: 5:06 - loss: 1.7028 - accuracy: 0.56 - ETA: 5:04 - loss: 1.6979 - accuracy: 0.56 - ETA: 5:01 - loss: 1.6767 - accuracy: 0.57 - ETA: 4:59 - loss: 1.6609 - accuracy: 0.57 - ETA: 4:57 - loss: 1.7105 - accuracy: 0.56 - ETA: 4:55 - loss: 1.7136 - accuracy: 0.56 - ETA: 4:52 - loss: 1.6906 - accuracy: 0.56 - ETA: 4:50 - loss: 1.6916 - accuracy: 0.56 - ETA: 4:48 - loss: 1.6870 - accuracy: 0.56 - ETA: 4:44 - loss: 1.6782 - accuracy: 0.56 - ETA: 4:43 - loss: 1.6622 - accuracy: 0.56 - ETA: 4:41 - loss: 1.6882 - accuracy: 0.55 - ETA: 4:39 - loss: 1.6880 - accuracy: 0.55 - ETA: 4:36 - loss: 1.7072 - accuracy: 0.55 - ETA: 4:34 - loss: 1.7085 - accuracy: 0.55 - ETA: 4:31 - loss: 1.7015 - accuracy: 0.55 - ETA: 4:30 - loss: 1.7062 - accuracy: 0.55 - ETA: 4:28 - loss: 1.7204 - accuracy: 0.55 - ETA: 4:26 - loss: 1.7140 - accuracy: 0.55 - ETA: 4:24 - loss: 1.7141 - accuracy: 0.55 - ETA: 4:22 - loss: 1.7082 - accuracy: 0.55 - ETA: 4:20 - loss: 1.7078 - accuracy: 0.55 - ETA: 4:17 - loss: 1.7001 - accuracy: 0.55 - ETA: 4:16 - loss: 1.7098 - accuracy: 0.55 - ETA: 4:14 - loss: 1.7049 - accuracy: 0.55 - ETA: 4:12 - loss: 1.6954 - accuracy: 0.55 - ETA: 4:09 - loss: 1.6996 - accuracy: 0.55 - ETA: 4:07 - loss: 1.7097 - accuracy: 0.55 - ETA: 4:05 - loss: 1.7088 - accuracy: 0.55 - ETA: 4:03 - loss: 1.7127 - accuracy: 0.55 - ETA: 4:01 - loss: 1.7034 - accuracy: 0.55 - ETA: 3:59 - loss: 1.7097 - accuracy: 0.55 - ETA: 3:57 - loss: 1.7091 - accuracy: 0.55 - ETA: 3:55 - loss: 1.7052 - accuracy: 0.55 - ETA: 3:53 - loss: 1.7109 - accuracy: 0.55 - ETA: 3:51 - loss: 1.7050 - accuracy: 0.55 - ETA: 3:49 - loss: 1.6977 - accuracy: 0.55 - ETA: 3:47 - loss: 1.6968 - accuracy: 0.55 - ETA: 3:44 - loss: 1.6971 - accuracy: 0.55 - ETA: 3:43 - loss: 1.7019 - accuracy: 0.55 - ETA: 3:40 - loss: 1.7032 - accuracy: 0.55 - ETA: 3:38 - loss: 1.7019 - accuracy: 0.55 - ETA: 3:36 - loss: 1.7033 - accuracy: 0.55 - ETA: 3:35 - loss: 1.7098 - accuracy: 0.55 - ETA: 3:33 - loss: 1.7118 - accuracy: 0.55 - ETA: 3:31 - loss: 1.7311 - accuracy: 0.54 - ETA: 3:28 - loss: 1.7294 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7278 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7274 - accuracy: 0.54 - ETA: 3:22 - loss: 1.7319 - accuracy: 0.54 - ETA: 3:20 - loss: 1.7297 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7299 - accuracy: 0.54 - ETA: 3:15 - loss: 1.7395 - accuracy: 0.54 - ETA: 3:13 - loss: 1.7423 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7422 - accuracy: 0.54 - ETA: 3:09 - loss: 1.7390 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7446 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7493 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7494 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7498 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7470 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7591 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7642 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7651 - accuracy: 0.54 - ETA: 2:50 - loss: 1.7663 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7669 - accuracy: 0.54 - ETA: 2:46 - loss: 1.7649 - accuracy: 0.54 - ETA: 2:44 - loss: 1.7654 - accuracy: 0.54 - ETA: 2:42 - loss: 1.7633 - accuracy: 0.54 - ETA: 2:40 - loss: 1.7598 - accuracy: 0.54 - ETA: 2:37 - loss: 1.7612 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7583 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7555 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7572 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7570 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7524 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7548 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7554 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7545 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7529 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7523 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7507 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7474 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7493 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7480 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7459 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7501 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7501 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7543 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7583 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7572 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7557 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7547 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7549 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7541 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7546 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7561 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7562 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7585 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7563 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7545 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7537 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7554 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7542 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7519 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7496 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7478 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7484 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7492 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7517 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7501 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7478 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7495 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7485 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7480 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7471 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7456 - accuracy: 0.54 - ETA: 58s - loss: 1.7481 - accuracy: 0.5435 - ETA: 56s - loss: 1.7474 - accuracy: 0.543 - ETA: 54s - loss: 1.7492 - accuracy: 0.543 - ETA: 52s - loss: 1.7495 - accuracy: 0.544 - ETA: 50s - loss: 1.7472 - accuracy: 0.544 - ETA: 48s - loss: 1.7479 - accuracy: 0.544 - ETA: 46s - loss: 1.7520 - accuracy: 0.544 - ETA: 44s - loss: 1.7507 - accuracy: 0.544 - ETA: 41s - loss: 1.7569 - accuracy: 0.544 - ETA: 39s - loss: 1.7554 - accuracy: 0.544 - ETA: 37s - loss: 1.7573 - accuracy: 0.544 - ETA: 35s - loss: 1.7574 - accuracy: 0.544 - ETA: 33s - loss: 1.7555 - accuracy: 0.544 - ETA: 31s - loss: 1.7576 - accuracy: 0.544 - ETA: 29s - loss: 1.7567 - accuracy: 0.544 - ETA: 27s - loss: 1.7555 - accuracy: 0.544 - ETA: 25s - loss: 1.7541 - accuracy: 0.544 - ETA: 22s - loss: 1.7544 - accuracy: 0.544 - ETA: 20s - loss: 1.7544 - accuracy: 0.544 - ETA: 18s - loss: 1.7562 - accuracy: 0.544 - ETA: 16s - loss: 1.7581 - accuracy: 0.544 - ETA: 14s - loss: 1.7582 - accuracy: 0.544 - ETA: 12s - loss: 1.7566 - accuracy: 0.544 - ETA: 10s - loss: 1.7637 - accuracy: 0.544 - ETA: 8s - loss: 1.7659 - accuracy: 0.543 - ETA: 6s - loss: 1.7662 - accuracy: 0.54 - ETA: 3s - loss: 1.7647 - accuracy: 0.54 - ETA: 1s - loss: 1.7652 - accuracy: 0.54 - 344s 18ms/step - loss: 1.7641 - accuracy: 0.5438 - val_loss: 1.9287 - val_accuracy: 0.6016\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:20 - loss: 2.1066 - accuracy: 0.46 - ETA: 5:21 - loss: 1.9767 - accuracy: 0.50 - ETA: 5:06 - loss: 1.7654 - accuracy: 0.53 - ETA: 5:00 - loss: 1.7932 - accuracy: 0.52 - ETA: 5:01 - loss: 1.7840 - accuracy: 0.52 - ETA: 4:58 - loss: 1.8426 - accuracy: 0.52 - ETA: 4:56 - loss: 1.8299 - accuracy: 0.52 - ETA: 4:55 - loss: 1.7858 - accuracy: 0.53 - ETA: 4:53 - loss: 1.7722 - accuracy: 0.53 - ETA: 4:50 - loss: 1.7446 - accuracy: 0.54 - ETA: 4:49 - loss: 1.7531 - accuracy: 0.54 - ETA: 4:47 - loss: 1.7332 - accuracy: 0.54 - ETA: 4:45 - loss: 1.7357 - accuracy: 0.54 - ETA: 4:43 - loss: 1.7421 - accuracy: 0.54 - ETA: 4:41 - loss: 1.7258 - accuracy: 0.55 - ETA: 4:40 - loss: 1.7271 - accuracy: 0.55 - ETA: 4:38 - loss: 1.7183 - accuracy: 0.55 - ETA: 4:35 - loss: 1.7132 - accuracy: 0.55 - ETA: 4:34 - loss: 1.7051 - accuracy: 0.55 - ETA: 4:32 - loss: 1.7130 - accuracy: 0.55 - ETA: 4:31 - loss: 1.6982 - accuracy: 0.55 - ETA: 4:29 - loss: 1.6796 - accuracy: 0.55 - ETA: 4:27 - loss: 1.6745 - accuracy: 0.55 - ETA: 4:25 - loss: 1.6779 - accuracy: 0.55 - ETA: 4:23 - loss: 1.6808 - accuracy: 0.55 - ETA: 4:20 - loss: 1.6793 - accuracy: 0.55 - ETA: 4:19 - loss: 1.6697 - accuracy: 0.55 - ETA: 4:16 - loss: 1.6674 - accuracy: 0.56 - ETA: 4:14 - loss: 1.6810 - accuracy: 0.55 - ETA: 4:12 - loss: 1.6779 - accuracy: 0.55 - ETA: 4:10 - loss: 1.6836 - accuracy: 0.55 - ETA: 4:09 - loss: 1.6846 - accuracy: 0.55 - ETA: 4:07 - loss: 1.6938 - accuracy: 0.55 - ETA: 4:04 - loss: 1.6946 - accuracy: 0.54 - ETA: 4:02 - loss: 1.6845 - accuracy: 0.55 - ETA: 4:01 - loss: 1.6846 - accuracy: 0.55 - ETA: 3:59 - loss: 1.6835 - accuracy: 0.54 - ETA: 3:57 - loss: 1.6822 - accuracy: 0.55 - ETA: 3:55 - loss: 1.6753 - accuracy: 0.55 - ETA: 3:53 - loss: 1.6651 - accuracy: 0.55 - ETA: 3:50 - loss: 1.6686 - accuracy: 0.55 - ETA: 3:48 - loss: 1.6683 - accuracy: 0.55 - ETA: 3:46 - loss: 1.6621 - accuracy: 0.55 - ETA: 3:44 - loss: 1.6671 - accuracy: 0.55 - ETA: 3:42 - loss: 1.6582 - accuracy: 0.55 - ETA: 3:40 - loss: 1.6536 - accuracy: 0.55 - ETA: 3:38 - loss: 1.6529 - accuracy: 0.55 - ETA: 3:36 - loss: 1.6511 - accuracy: 0.55 - ETA: 3:34 - loss: 1.6502 - accuracy: 0.55 - ETA: 3:32 - loss: 1.6553 - accuracy: 0.55 - ETA: 3:30 - loss: 1.6515 - accuracy: 0.55 - ETA: 3:28 - loss: 1.6490 - accuracy: 0.55 - ETA: 3:26 - loss: 1.6453 - accuracy: 0.56 - ETA: 3:23 - loss: 1.6460 - accuracy: 0.56 - ETA: 3:21 - loss: 1.6420 - accuracy: 0.56 - ETA: 3:19 - loss: 1.6439 - accuracy: 0.56 - ETA: 3:17 - loss: 1.6549 - accuracy: 0.55 - ETA: 3:15 - loss: 1.6554 - accuracy: 0.55 - ETA: 3:13 - loss: 1.6566 - accuracy: 0.55 - ETA: 3:11 - loss: 1.6663 - accuracy: 0.55 - ETA: 3:09 - loss: 1.6714 - accuracy: 0.55 - ETA: 3:07 - loss: 1.6772 - accuracy: 0.55 - ETA: 3:05 - loss: 1.6794 - accuracy: 0.55 - ETA: 3:02 - loss: 1.6804 - accuracy: 0.55 - ETA: 3:00 - loss: 1.6804 - accuracy: 0.55 - ETA: 2:58 - loss: 1.6802 - accuracy: 0.55 - ETA: 2:56 - loss: 1.6847 - accuracy: 0.55 - ETA: 2:54 - loss: 1.6857 - accuracy: 0.55 - ETA: 2:52 - loss: 1.6870 - accuracy: 0.55 - ETA: 2:50 - loss: 1.6896 - accuracy: 0.55 - ETA: 2:48 - loss: 1.6881 - accuracy: 0.55 - ETA: 2:46 - loss: 1.6864 - accuracy: 0.55 - ETA: 2:44 - loss: 1.6872 - accuracy: 0.55 - ETA: 2:41 - loss: 1.6877 - accuracy: 0.55 - ETA: 2:39 - loss: 1.6869 - accuracy: 0.55 - ETA: 2:37 - loss: 1.6924 - accuracy: 0.54 - ETA: 2:35 - loss: 1.6930 - accuracy: 0.54 - ETA: 2:33 - loss: 1.6911 - accuracy: 0.54 - ETA: 2:31 - loss: 1.6912 - accuracy: 0.54 - ETA: 2:29 - loss: 1.6934 - accuracy: 0.54 - ETA: 2:27 - loss: 1.6920 - accuracy: 0.54 - ETA: 2:24 - loss: 1.6957 - accuracy: 0.54 - ETA: 2:22 - loss: 1.6976 - accuracy: 0.54 - ETA: 2:20 - loss: 1.6996 - accuracy: 0.54 - ETA: 2:18 - loss: 1.6971 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7190 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7184 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7150 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7178 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7205 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7179 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7192 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7205 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7218 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7224 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7200 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7257 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7233 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7235 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7209 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7218 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7232 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7242 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7249 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7231 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7236 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7257 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7270 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7270 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7280 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7295 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7302 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7292 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7313 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7316 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7323 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7324 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7333 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7339 - accuracy: 0.54 - ETA: 1:04 - loss: 1.7349 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7379 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7348 - accuracy: 0.54 - ETA: 58s - loss: 1.7368 - accuracy: 0.5447 - ETA: 56s - loss: 1.7392 - accuracy: 0.544 - ETA: 54s - loss: 1.7385 - accuracy: 0.545 - ETA: 52s - loss: 1.7426 - accuracy: 0.544 - ETA: 50s - loss: 1.7422 - accuracy: 0.544 - ETA: 48s - loss: 1.7403 - accuracy: 0.545 - ETA: 46s - loss: 1.7411 - accuracy: 0.545 - ETA: 43s - loss: 1.7466 - accuracy: 0.544 - ETA: 41s - loss: 1.7467 - accuracy: 0.544 - ETA: 39s - loss: 1.7468 - accuracy: 0.544 - ETA: 37s - loss: 1.7488 - accuracy: 0.543 - ETA: 35s - loss: 1.7533 - accuracy: 0.543 - ETA: 33s - loss: 1.7541 - accuracy: 0.543 - ETA: 31s - loss: 1.7538 - accuracy: 0.543 - ETA: 29s - loss: 1.7514 - accuracy: 0.544 - ETA: 27s - loss: 1.7495 - accuracy: 0.544 - ETA: 24s - loss: 1.7468 - accuracy: 0.544 - ETA: 22s - loss: 1.7458 - accuracy: 0.544 - ETA: 20s - loss: 1.7463 - accuracy: 0.544 - ETA: 18s - loss: 1.7455 - accuracy: 0.544 - ETA: 16s - loss: 1.7451 - accuracy: 0.544 - ETA: 14s - loss: 1.7451 - accuracy: 0.544 - ETA: 12s - loss: 1.7478 - accuracy: 0.544 - ETA: 10s - loss: 1.7491 - accuracy: 0.543 - ETA: 8s - loss: 1.7494 - accuracy: 0.544 - ETA: 6s - loss: 1.7480 - accuracy: 0.54 - ETA: 3s - loss: 1.7462 - accuracy: 0.54 - ETA: 1s - loss: 1.7496 - accuracy: 0.54 - 342s 18ms/step - loss: 1.7495 - accuracy: 0.5444 - val_loss: 2.0834 - val_accuracy: 0.6024\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:30 - loss: 1.6155 - accuracy: 0.61 - ETA: 5:22 - loss: 1.6868 - accuracy: 0.54 - ETA: 5:16 - loss: 1.7181 - accuracy: 0.55 - ETA: 5:10 - loss: 1.6809 - accuracy: 0.57 - ETA: 5:09 - loss: 1.6742 - accuracy: 0.56 - ETA: 5:06 - loss: 1.6553 - accuracy: 0.56 - ETA: 5:03 - loss: 1.6488 - accuracy: 0.56 - ETA: 5:01 - loss: 1.6767 - accuracy: 0.55 - ETA: 4:58 - loss: 1.6915 - accuracy: 0.55 - ETA: 4:57 - loss: 1.7027 - accuracy: 0.55 - ETA: 4:55 - loss: 1.7108 - accuracy: 0.54 - ETA: 4:52 - loss: 1.6936 - accuracy: 0.55 - ETA: 4:51 - loss: 1.6857 - accuracy: 0.55 - ETA: 4:48 - loss: 1.7022 - accuracy: 0.54 - ETA: 4:45 - loss: 1.7106 - accuracy: 0.54 - ETA: 4:43 - loss: 1.7100 - accuracy: 0.54 - ETA: 4:41 - loss: 1.8347 - accuracy: 0.54 - ETA: 4:40 - loss: 1.8383 - accuracy: 0.54 - ETA: 4:38 - loss: 1.8223 - accuracy: 0.55 - ETA: 4:38 - loss: 1.8283 - accuracy: 0.54 - ETA: 4:35 - loss: 1.8163 - accuracy: 0.54 - ETA: 4:33 - loss: 1.7986 - accuracy: 0.55 - ETA: 4:31 - loss: 1.7771 - accuracy: 0.55 - ETA: 4:29 - loss: 1.7675 - accuracy: 0.55 - ETA: 4:27 - loss: 1.7594 - accuracy: 0.55 - ETA: 4:25 - loss: 1.7529 - accuracy: 0.55 - ETA: 4:23 - loss: 1.7647 - accuracy: 0.55 - ETA: 4:21 - loss: 1.7667 - accuracy: 0.55 - ETA: 4:19 - loss: 1.7620 - accuracy: 0.55 - ETA: 4:16 - loss: 1.7667 - accuracy: 0.55 - ETA: 4:14 - loss: 1.7660 - accuracy: 0.55 - ETA: 4:12 - loss: 1.7805 - accuracy: 0.55 - ETA: 4:10 - loss: 1.7760 - accuracy: 0.55 - ETA: 4:08 - loss: 1.7833 - accuracy: 0.54 - ETA: 4:06 - loss: 1.7946 - accuracy: 0.54 - ETA: 4:04 - loss: 1.7913 - accuracy: 0.54 - ETA: 4:02 - loss: 1.7832 - accuracy: 0.54 - ETA: 4:00 - loss: 1.7840 - accuracy: 0.54 - ETA: 3:58 - loss: 1.7829 - accuracy: 0.54 - ETA: 3:55 - loss: 1.7839 - accuracy: 0.54 - ETA: 3:54 - loss: 1.7847 - accuracy: 0.54 - ETA: 3:51 - loss: 1.7842 - accuracy: 0.54 - ETA: 3:49 - loss: 1.7812 - accuracy: 0.54 - ETA: 3:47 - loss: 1.7735 - accuracy: 0.54 - ETA: 3:45 - loss: 1.7775 - accuracy: 0.54 - ETA: 3:43 - loss: 1.7830 - accuracy: 0.54 - ETA: 3:40 - loss: 1.7755 - accuracy: 0.54 - ETA: 3:38 - loss: 1.7706 - accuracy: 0.54 - ETA: 3:36 - loss: 1.7746 - accuracy: 0.54 - ETA: 3:33 - loss: 1.7682 - accuracy: 0.54 - ETA: 3:31 - loss: 1.7672 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7659 - accuracy: 0.54 - ETA: 3:27 - loss: 1.7621 - accuracy: 0.54 - ETA: 3:25 - loss: 1.7559 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7599 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7637 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7634 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7642 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7678 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7652 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7667 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7764 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7731 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7738 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7719 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7681 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7706 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7684 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7678 - accuracy: 0.54 - ETA: 2:51 - loss: 1.7746 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7745 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7755 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7840 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7819 - accuracy: 0.54 - ETA: 2:40 - loss: 1.7793 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7777 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7817 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7850 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7820 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7817 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7846 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7824 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7780 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7788 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7745 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7747 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7744 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7717 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7724 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7717 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7742 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7719 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7727 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7716 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7716 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7671 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7716 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7729 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7738 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7734 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7718 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7737 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7786 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7801 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7812 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7844 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7842 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7860 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7834 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7860 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7858 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7846 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7844 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7831 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7845 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7854 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7872 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7879 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7858 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7851 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7836 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7823 - accuracy: 0.54 - ETA: 58s - loss: 1.7822 - accuracy: 0.5420 - ETA: 56s - loss: 1.7843 - accuracy: 0.542 - ETA: 54s - loss: 1.7831 - accuracy: 0.541 - ETA: 52s - loss: 1.7814 - accuracy: 0.542 - ETA: 50s - loss: 1.7796 - accuracy: 0.542 - ETA: 48s - loss: 1.7798 - accuracy: 0.542 - ETA: 46s - loss: 1.7795 - accuracy: 0.542 - ETA: 44s - loss: 1.7788 - accuracy: 0.542 - ETA: 41s - loss: 1.7784 - accuracy: 0.542 - ETA: 39s - loss: 1.7762 - accuracy: 0.542 - ETA: 37s - loss: 1.7806 - accuracy: 0.542 - ETA: 35s - loss: 1.7814 - accuracy: 0.542 - ETA: 33s - loss: 1.7830 - accuracy: 0.542 - ETA: 31s - loss: 1.7833 - accuracy: 0.542 - ETA: 29s - loss: 1.7828 - accuracy: 0.542 - ETA: 27s - loss: 1.7834 - accuracy: 0.541 - ETA: 25s - loss: 1.7816 - accuracy: 0.542 - ETA: 22s - loss: 1.7863 - accuracy: 0.542 - ETA: 20s - loss: 1.7859 - accuracy: 0.541 - ETA: 18s - loss: 1.7851 - accuracy: 0.542 - ETA: 16s - loss: 1.7881 - accuracy: 0.542 - ETA: 14s - loss: 1.7874 - accuracy: 0.542 - ETA: 12s - loss: 1.7884 - accuracy: 0.541 - ETA: 10s - loss: 1.7892 - accuracy: 0.541 - ETA: 8s - loss: 1.7865 - accuracy: 0.541 - ETA: 6s - loss: 1.7891 - accuracy: 0.54 - ETA: 3s - loss: 1.7872 - accuracy: 0.54 - ETA: 1s - loss: 1.7883 - accuracy: 0.54 - 343s 18ms/step - loss: 1.7853 - accuracy: 0.5415 - val_loss: 2.0427 - val_accuracy: 0.5800\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:17 - loss: 1.8205 - accuracy: 0.52 - ETA: 5:18 - loss: 1.7363 - accuracy: 0.54 - ETA: 5:12 - loss: 1.7351 - accuracy: 0.54 - ETA: 5:08 - loss: 1.6760 - accuracy: 0.55 - ETA: 5:10 - loss: 1.6330 - accuracy: 0.56 - ETA: 5:09 - loss: 1.5980 - accuracy: 0.56 - ETA: 5:05 - loss: 1.6052 - accuracy: 0.56 - ETA: 5:02 - loss: 1.6582 - accuracy: 0.55 - ETA: 5:00 - loss: 1.6760 - accuracy: 0.55 - ETA: 4:58 - loss: 1.6878 - accuracy: 0.54 - ETA: 4:54 - loss: 1.7019 - accuracy: 0.54 - ETA: 4:53 - loss: 1.7001 - accuracy: 0.54 - ETA: 4:51 - loss: 1.7067 - accuracy: 0.54 - ETA: 4:48 - loss: 1.6827 - accuracy: 0.54 - ETA: 4:45 - loss: 1.6822 - accuracy: 0.54 - ETA: 4:43 - loss: 1.6770 - accuracy: 0.54 - ETA: 4:41 - loss: 1.6757 - accuracy: 0.54 - ETA: 4:39 - loss: 1.6691 - accuracy: 0.54 - ETA: 4:38 - loss: 1.6717 - accuracy: 0.54 - ETA: 4:35 - loss: 1.7062 - accuracy: 0.54 - ETA: 4:33 - loss: 1.7060 - accuracy: 0.54 - ETA: 4:31 - loss: 1.7131 - accuracy: 0.54 - ETA: 4:29 - loss: 1.7123 - accuracy: 0.54 - ETA: 4:26 - loss: 1.7139 - accuracy: 0.54 - ETA: 4:24 - loss: 1.7094 - accuracy: 0.54 - ETA: 4:21 - loss: 1.7108 - accuracy: 0.54 - ETA: 4:19 - loss: 1.7019 - accuracy: 0.54 - ETA: 4:17 - loss: 1.6961 - accuracy: 0.54 - ETA: 4:15 - loss: 1.6882 - accuracy: 0.54 - ETA: 4:13 - loss: 1.6978 - accuracy: 0.54 - ETA: 4:11 - loss: 1.6941 - accuracy: 0.54 - ETA: 4:09 - loss: 1.6882 - accuracy: 0.54 - ETA: 4:07 - loss: 1.6880 - accuracy: 0.54 - ETA: 4:05 - loss: 1.6889 - accuracy: 0.54 - ETA: 4:03 - loss: 1.6850 - accuracy: 0.54 - ETA: 4:00 - loss: 1.7062 - accuracy: 0.54 - ETA: 3:58 - loss: 1.7033 - accuracy: 0.54 - ETA: 3:56 - loss: 1.7119 - accuracy: 0.54 - ETA: 3:54 - loss: 1.7159 - accuracy: 0.54 - ETA: 3:52 - loss: 1.7122 - accuracy: 0.54 - ETA: 3:50 - loss: 1.7122 - accuracy: 0.54 - ETA: 3:48 - loss: 1.7123 - accuracy: 0.54 - ETA: 3:46 - loss: 1.7095 - accuracy: 0.54 - ETA: 3:44 - loss: 1.7135 - accuracy: 0.54 - ETA: 3:42 - loss: 1.7140 - accuracy: 0.54 - ETA: 3:39 - loss: 1.7211 - accuracy: 0.54 - ETA: 3:37 - loss: 1.7195 - accuracy: 0.54 - ETA: 3:35 - loss: 1.7148 - accuracy: 0.54 - ETA: 3:33 - loss: 1.7162 - accuracy: 0.54 - ETA: 3:31 - loss: 1.7208 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7158 - accuracy: 0.54 - ETA: 3:27 - loss: 1.7164 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7221 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7211 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7212 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7239 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7262 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7289 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7261 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7322 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7310 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7364 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7362 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7337 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7380 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7335 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7349 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7375 - accuracy: 0.54 - ETA: 2:51 - loss: 1.7375 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7377 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7371 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7343 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7362 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7345 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7337 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7354 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7363 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7362 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7361 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7452 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7456 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7461 - accuracy: 0.53 - ETA: 2:22 - loss: 1.7458 - accuracy: 0.53 - ETA: 2:20 - loss: 1.7421 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7408 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7421 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7428 - accuracy: 0.53 - ETA: 2:11 - loss: 1.7445 - accuracy: 0.53 - ETA: 2:09 - loss: 1.7503 - accuracy: 0.53 - ETA: 2:07 - loss: 1.7451 - accuracy: 0.53 - ETA: 2:05 - loss: 1.7417 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7388 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7413 - accuracy: 0.53 - ETA: 1:59 - loss: 1.7406 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7413 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7397 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7391 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7397 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7410 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7406 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7424 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7389 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7372 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7451 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7608 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7611 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7655 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7699 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7657 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7679 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7676 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7727 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7755 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7739 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7737 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7738 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7785 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7774 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7792 - accuracy: 0.54 - ETA: 1:04 - loss: 1.7900 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7908 - accuracy: 0.53 - ETA: 1:00 - loss: 1.7893 - accuracy: 0.54 - ETA: 58s - loss: 1.7942 - accuracy: 0.5397 - ETA: 56s - loss: 1.7907 - accuracy: 0.540 - ETA: 54s - loss: 1.7878 - accuracy: 0.540 - ETA: 52s - loss: 1.7876 - accuracy: 0.540 - ETA: 50s - loss: 1.7863 - accuracy: 0.540 - ETA: 48s - loss: 1.7862 - accuracy: 0.540 - ETA: 46s - loss: 1.7846 - accuracy: 0.541 - ETA: 43s - loss: 1.7870 - accuracy: 0.540 - ETA: 41s - loss: 1.7846 - accuracy: 0.540 - ETA: 39s - loss: 1.7833 - accuracy: 0.541 - ETA: 37s - loss: 1.7831 - accuracy: 0.541 - ETA: 35s - loss: 1.7814 - accuracy: 0.541 - ETA: 33s - loss: 1.7823 - accuracy: 0.541 - ETA: 31s - loss: 1.7814 - accuracy: 0.541 - ETA: 29s - loss: 1.7803 - accuracy: 0.541 - ETA: 27s - loss: 1.7799 - accuracy: 0.541 - ETA: 24s - loss: 1.7798 - accuracy: 0.541 - ETA: 22s - loss: 1.7813 - accuracy: 0.541 - ETA: 20s - loss: 1.7815 - accuracy: 0.540 - ETA: 18s - loss: 1.7816 - accuracy: 0.540 - ETA: 16s - loss: 1.7806 - accuracy: 0.540 - ETA: 14s - loss: 1.7796 - accuracy: 0.540 - ETA: 12s - loss: 1.7798 - accuracy: 0.540 - ETA: 10s - loss: 1.7800 - accuracy: 0.539 - ETA: 8s - loss: 1.7784 - accuracy: 0.540 - ETA: 6s - loss: 1.7766 - accuracy: 0.54 - ETA: 3s - loss: 1.7750 - accuracy: 0.54 - ETA: 1s - loss: 1.7746 - accuracy: 0.54 - 342s 18ms/step - loss: 1.7734 - accuracy: 0.5406 - val_loss: 2.2943 - val_accuracy: 0.6051\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:13 - loss: 1.2782 - accuracy: 0.64 - ETA: 5:07 - loss: 1.4056 - accuracy: 0.62 - ETA: 5:06 - loss: 1.5564 - accuracy: 0.58 - ETA: 5:07 - loss: 1.5810 - accuracy: 0.58 - ETA: 5:03 - loss: 1.7202 - accuracy: 0.56 - ETA: 4:59 - loss: 1.6838 - accuracy: 0.57 - ETA: 4:58 - loss: 1.7503 - accuracy: 0.56 - ETA: 4:56 - loss: 1.7070 - accuracy: 0.57 - ETA: 4:53 - loss: 1.6870 - accuracy: 0.57 - ETA: 4:48 - loss: 1.7449 - accuracy: 0.57 - ETA: 4:46 - loss: 1.7300 - accuracy: 0.57 - ETA: 4:45 - loss: 1.7231 - accuracy: 0.57 - ETA: 4:43 - loss: 1.7351 - accuracy: 0.56 - ETA: 4:42 - loss: 1.7529 - accuracy: 0.56 - ETA: 4:41 - loss: 1.7362 - accuracy: 0.56 - ETA: 4:39 - loss: 1.7415 - accuracy: 0.55 - ETA: 4:37 - loss: 1.7522 - accuracy: 0.55 - ETA: 4:35 - loss: 1.7629 - accuracy: 0.55 - ETA: 4:33 - loss: 1.7578 - accuracy: 0.55 - ETA: 4:31 - loss: 1.7542 - accuracy: 0.55 - ETA: 4:29 - loss: 1.7656 - accuracy: 0.54 - ETA: 4:27 - loss: 1.7541 - accuracy: 0.55 - ETA: 4:24 - loss: 1.7542 - accuracy: 0.55 - ETA: 4:22 - loss: 1.7586 - accuracy: 0.54 - ETA: 4:19 - loss: 1.7545 - accuracy: 0.55 - ETA: 4:17 - loss: 1.7510 - accuracy: 0.55 - ETA: 4:15 - loss: 1.7522 - accuracy: 0.55 - ETA: 4:13 - loss: 1.7484 - accuracy: 0.55 - ETA: 4:11 - loss: 1.7454 - accuracy: 0.55 - ETA: 4:10 - loss: 1.7370 - accuracy: 0.55 - ETA: 4:08 - loss: 1.7384 - accuracy: 0.55 - ETA: 4:06 - loss: 1.7408 - accuracy: 0.55 - ETA: 4:04 - loss: 1.7551 - accuracy: 0.54 - ETA: 4:02 - loss: 1.7466 - accuracy: 0.55 - ETA: 4:00 - loss: 1.7480 - accuracy: 0.55 - ETA: 3:58 - loss: 1.7478 - accuracy: 0.55 - ETA: 3:56 - loss: 1.7401 - accuracy: 0.55 - ETA: 3:54 - loss: 1.7447 - accuracy: 0.54 - ETA: 3:52 - loss: 1.7381 - accuracy: 0.55 - ETA: 3:50 - loss: 1.7338 - accuracy: 0.55 - ETA: 3:48 - loss: 1.7384 - accuracy: 0.54 - ETA: 3:46 - loss: 1.7396 - accuracy: 0.54 - ETA: 3:44 - loss: 1.7400 - accuracy: 0.54 - ETA: 3:42 - loss: 1.7399 - accuracy: 0.54 - ETA: 3:40 - loss: 1.7386 - accuracy: 0.54 - ETA: 3:38 - loss: 1.7417 - accuracy: 0.54 - ETA: 3:36 - loss: 1.7418 - accuracy: 0.54 - ETA: 3:34 - loss: 1.7437 - accuracy: 0.54 - ETA: 3:32 - loss: 1.7461 - accuracy: 0.54 - ETA: 3:30 - loss: 1.7434 - accuracy: 0.54 - ETA: 3:28 - loss: 1.7390 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7527 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7543 - accuracy: 0.54 - ETA: 3:22 - loss: 1.7535 - accuracy: 0.54 - ETA: 3:20 - loss: 1.7579 - accuracy: 0.54 - ETA: 3:17 - loss: 1.7589 - accuracy: 0.54 - ETA: 3:15 - loss: 1.7590 - accuracy: 0.54 - ETA: 3:13 - loss: 1.7638 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7626 - accuracy: 0.54 - ETA: 3:09 - loss: 1.7664 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7706 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7699 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7694 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7678 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7686 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7654 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7807 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7784 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7774 - accuracy: 0.54 - ETA: 2:51 - loss: 1.7782 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7770 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7717 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7671 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7691 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7687 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7683 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7709 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7683 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7667 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7636 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7639 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7623 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7586 - accuracy: 0.54 - ETA: 2:22 - loss: 1.7601 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7602 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7571 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7597 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7591 - accuracy: 0.54 - ETA: 2:11 - loss: 1.7621 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7613 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7599 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7596 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7590 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7596 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7579 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7549 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7562 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7544 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7554 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7531 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7534 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7522 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7487 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7488 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7548 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7542 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7533 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7543 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7555 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7543 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7531 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7516 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7562 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7580 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7595 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7594 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7566 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7574 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7572 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7561 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7560 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7567 - accuracy: 0.54 - ETA: 59s - loss: 1.7573 - accuracy: 0.5464 - ETA: 57s - loss: 1.7556 - accuracy: 0.546 - ETA: 55s - loss: 1.7603 - accuracy: 0.546 - ETA: 52s - loss: 1.7584 - accuracy: 0.547 - ETA: 50s - loss: 1.7593 - accuracy: 0.546 - ETA: 48s - loss: 1.7581 - accuracy: 0.546 - ETA: 46s - loss: 1.7613 - accuracy: 0.546 - ETA: 44s - loss: 1.7621 - accuracy: 0.546 - ETA: 42s - loss: 1.7577 - accuracy: 0.547 - ETA: 40s - loss: 1.7580 - accuracy: 0.546 - ETA: 38s - loss: 1.7574 - accuracy: 0.547 - ETA: 35s - loss: 1.7574 - accuracy: 0.546 - ETA: 33s - loss: 1.7563 - accuracy: 0.546 - ETA: 31s - loss: 1.7548 - accuracy: 0.547 - ETA: 29s - loss: 1.7530 - accuracy: 0.547 - ETA: 27s - loss: 1.7550 - accuracy: 0.547 - ETA: 25s - loss: 1.7574 - accuracy: 0.546 - ETA: 23s - loss: 1.7609 - accuracy: 0.545 - ETA: 21s - loss: 1.7614 - accuracy: 0.545 - ETA: 18s - loss: 1.7597 - accuracy: 0.546 - ETA: 16s - loss: 1.7579 - accuracy: 0.546 - ETA: 14s - loss: 1.7596 - accuracy: 0.545 - ETA: 12s - loss: 1.7599 - accuracy: 0.545 - ETA: 10s - loss: 1.7599 - accuracy: 0.545 - ETA: 8s - loss: 1.7590 - accuracy: 0.545 - ETA: 6s - loss: 1.7574 - accuracy: 0.54 - ETA: 3s - loss: 1.7569 - accuracy: 0.54 - ETA: 1s - loss: 1.7573 - accuracy: 0.54 - 345s 18ms/step - loss: 1.7582 - accuracy: 0.5452 - val_loss: 2.0777 - val_accuracy: 0.5941\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:36 - loss: 1.6083 - accuracy: 0.57 - ETA: 5:18 - loss: 1.5614 - accuracy: 0.57 - ETA: 5:13 - loss: 1.5986 - accuracy: 0.55 - ETA: 5:08 - loss: 1.6305 - accuracy: 0.54 - ETA: 5:02 - loss: 1.6477 - accuracy: 0.53 - ETA: 5:04 - loss: 1.6504 - accuracy: 0.54 - ETA: 5:04 - loss: 1.6440 - accuracy: 0.53 - ETA: 5:00 - loss: 1.6561 - accuracy: 0.54 - ETA: 5:01 - loss: 1.6840 - accuracy: 0.53 - ETA: 5:00 - loss: 1.7254 - accuracy: 0.53 - ETA: 4:57 - loss: 1.7443 - accuracy: 0.53 - ETA: 4:54 - loss: 1.7734 - accuracy: 0.52 - ETA: 4:53 - loss: 1.7858 - accuracy: 0.52 - ETA: 4:50 - loss: 1.7894 - accuracy: 0.52 - ETA: 4:48 - loss: 1.8207 - accuracy: 0.51 - ETA: 4:45 - loss: 1.8049 - accuracy: 0.52 - ETA: 4:43 - loss: 1.7995 - accuracy: 0.52 - ETA: 4:41 - loss: 1.8005 - accuracy: 0.52 - ETA: 4:39 - loss: 1.7859 - accuracy: 0.52 - ETA: 4:37 - loss: 1.7910 - accuracy: 0.52 - ETA: 4:35 - loss: 1.7833 - accuracy: 0.52 - ETA: 4:33 - loss: 1.7748 - accuracy: 0.52 - ETA: 4:30 - loss: 1.7679 - accuracy: 0.52 - ETA: 4:28 - loss: 1.7810 - accuracy: 0.52 - ETA: 4:26 - loss: 1.7803 - accuracy: 0.52 - ETA: 4:24 - loss: 1.7672 - accuracy: 0.52 - ETA: 4:22 - loss: 1.7779 - accuracy: 0.52 - ETA: 4:20 - loss: 1.7786 - accuracy: 0.52 - ETA: 4:17 - loss: 1.7917 - accuracy: 0.52 - ETA: 4:15 - loss: 1.7911 - accuracy: 0.52 - ETA: 4:13 - loss: 1.7943 - accuracy: 0.52 - ETA: 4:11 - loss: 1.7981 - accuracy: 0.52 - ETA: 4:08 - loss: 1.7946 - accuracy: 0.52 - ETA: 4:06 - loss: 1.7911 - accuracy: 0.52 - ETA: 4:04 - loss: 1.7835 - accuracy: 0.52 - ETA: 4:02 - loss: 1.7781 - accuracy: 0.52 - ETA: 3:59 - loss: 1.7736 - accuracy: 0.52 - ETA: 3:57 - loss: 1.7709 - accuracy: 0.52 - ETA: 3:55 - loss: 1.7692 - accuracy: 0.52 - ETA: 3:53 - loss: 1.7791 - accuracy: 0.52 - ETA: 3:51 - loss: 1.7763 - accuracy: 0.52 - ETA: 3:49 - loss: 1.7739 - accuracy: 0.52 - ETA: 3:47 - loss: 1.7738 - accuracy: 0.52 - ETA: 3:45 - loss: 1.7704 - accuracy: 0.52 - ETA: 3:43 - loss: 1.7760 - accuracy: 0.52 - ETA: 3:41 - loss: 1.7705 - accuracy: 0.53 - ETA: 3:39 - loss: 1.7667 - accuracy: 0.53 - ETA: 3:37 - loss: 1.7659 - accuracy: 0.53 - ETA: 3:34 - loss: 1.7660 - accuracy: 0.53 - ETA: 3:32 - loss: 1.7658 - accuracy: 0.53 - ETA: 3:31 - loss: 1.7871 - accuracy: 0.53 - ETA: 3:28 - loss: 1.7886 - accuracy: 0.52 - ETA: 3:27 - loss: 1.7878 - accuracy: 0.53 - ETA: 3:24 - loss: 1.7923 - accuracy: 0.53 - ETA: 3:22 - loss: 1.7879 - accuracy: 0.53 - ETA: 3:20 - loss: 1.7819 - accuracy: 0.53 - ETA: 3:18 - loss: 1.7980 - accuracy: 0.53 - ETA: 3:16 - loss: 1.7999 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8015 - accuracy: 0.53 - ETA: 3:12 - loss: 1.7908 - accuracy: 0.53 - ETA: 3:09 - loss: 1.7888 - accuracy: 0.53 - ETA: 3:07 - loss: 1.7821 - accuracy: 0.53 - ETA: 3:05 - loss: 1.7815 - accuracy: 0.53 - ETA: 3:03 - loss: 1.7853 - accuracy: 0.53 - ETA: 3:01 - loss: 1.7819 - accuracy: 0.53 - ETA: 2:59 - loss: 1.7860 - accuracy: 0.53 - ETA: 2:57 - loss: 1.7889 - accuracy: 0.53 - ETA: 2:55 - loss: 1.7848 - accuracy: 0.53 - ETA: 2:53 - loss: 1.7889 - accuracy: 0.53 - ETA: 2:51 - loss: 1.7863 - accuracy: 0.53 - ETA: 2:49 - loss: 1.8185 - accuracy: 0.53 - ETA: 2:46 - loss: 1.8186 - accuracy: 0.53 - ETA: 2:44 - loss: 1.8185 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8191 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8152 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8122 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8094 - accuracy: 0.53 - ETA: 2:34 - loss: 1.8063 - accuracy: 0.53 - ETA: 2:32 - loss: 1.8023 - accuracy: 0.53 - ETA: 2:30 - loss: 1.7986 - accuracy: 0.53 - ETA: 2:27 - loss: 1.7966 - accuracy: 0.53 - ETA: 2:25 - loss: 1.7984 - accuracy: 0.53 - ETA: 2:23 - loss: 1.7970 - accuracy: 0.53 - ETA: 2:21 - loss: 1.7944 - accuracy: 0.53 - ETA: 2:19 - loss: 1.7917 - accuracy: 0.53 - ETA: 2:17 - loss: 1.7922 - accuracy: 0.53 - ETA: 2:15 - loss: 1.7893 - accuracy: 0.53 - ETA: 2:13 - loss: 1.7907 - accuracy: 0.53 - ETA: 2:11 - loss: 1.7898 - accuracy: 0.53 - ETA: 2:09 - loss: 1.7855 - accuracy: 0.53 - ETA: 2:07 - loss: 1.7856 - accuracy: 0.53 - ETA: 2:05 - loss: 1.7828 - accuracy: 0.53 - ETA: 2:03 - loss: 1.7819 - accuracy: 0.53 - ETA: 2:00 - loss: 1.7779 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7840 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7819 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7845 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7798 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7780 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7769 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7761 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7749 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7737 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7714 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7679 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7664 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7661 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7691 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7723 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7697 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7703 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7714 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7706 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7701 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7729 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7705 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7724 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7741 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7748 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7728 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7710 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7685 - accuracy: 0.54 - ETA: 59s - loss: 1.7682 - accuracy: 0.5419 - ETA: 57s - loss: 1.7698 - accuracy: 0.541 - ETA: 55s - loss: 1.7688 - accuracy: 0.541 - ETA: 52s - loss: 1.7699 - accuracy: 0.541 - ETA: 50s - loss: 1.7696 - accuracy: 0.541 - ETA: 48s - loss: 1.7679 - accuracy: 0.541 - ETA: 46s - loss: 1.7683 - accuracy: 0.540 - ETA: 44s - loss: 1.7683 - accuracy: 0.540 - ETA: 42s - loss: 1.7673 - accuracy: 0.540 - ETA: 40s - loss: 1.7665 - accuracy: 0.540 - ETA: 38s - loss: 1.7652 - accuracy: 0.541 - ETA: 35s - loss: 1.7627 - accuracy: 0.541 - ETA: 33s - loss: 1.7632 - accuracy: 0.541 - ETA: 31s - loss: 1.7617 - accuracy: 0.541 - ETA: 29s - loss: 1.7576 - accuracy: 0.542 - ETA: 27s - loss: 1.7570 - accuracy: 0.542 - ETA: 25s - loss: 1.7601 - accuracy: 0.542 - ETA: 23s - loss: 1.7600 - accuracy: 0.542 - ETA: 21s - loss: 1.7589 - accuracy: 0.542 - ETA: 18s - loss: 1.7561 - accuracy: 0.542 - ETA: 16s - loss: 1.7560 - accuracy: 0.542 - ETA: 14s - loss: 1.7579 - accuracy: 0.541 - ETA: 12s - loss: 1.7574 - accuracy: 0.541 - ETA: 10s - loss: 1.7606 - accuracy: 0.541 - ETA: 8s - loss: 1.7599 - accuracy: 0.541 - ETA: 6s - loss: 1.7614 - accuracy: 0.54 - ETA: 3s - loss: 1.7612 - accuracy: 0.54 - ETA: 1s - loss: 1.7608 - accuracy: 0.54 - 345s 18ms/step - loss: 1.7605 - accuracy: 0.5407 - val_loss: 2.0877 - val_accuracy: 0.6041\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:06 - loss: 1.6892 - accuracy: 0.53 - ETA: 5:06 - loss: 1.6951 - accuracy: 0.52 - ETA: 5:02 - loss: 1.7094 - accuracy: 0.51 - ETA: 5:06 - loss: 1.7397 - accuracy: 0.50 - ETA: 4:58 - loss: 1.6836 - accuracy: 0.53 - ETA: 4:59 - loss: 1.6687 - accuracy: 0.54 - ETA: 4:56 - loss: 1.6877 - accuracy: 0.54 - ETA: 4:52 - loss: 1.6757 - accuracy: 0.55 - ETA: 4:52 - loss: 1.6931 - accuracy: 0.54 - ETA: 4:49 - loss: 1.7288 - accuracy: 0.55 - ETA: 4:49 - loss: 1.7239 - accuracy: 0.55 - ETA: 4:46 - loss: 1.7209 - accuracy: 0.55 - ETA: 4:44 - loss: 1.7309 - accuracy: 0.54 - ETA: 4:44 - loss: 1.7187 - accuracy: 0.54 - ETA: 4:42 - loss: 1.7352 - accuracy: 0.54 - ETA: 4:41 - loss: 1.7405 - accuracy: 0.53 - ETA: 4:41 - loss: 1.7256 - accuracy: 0.54 - ETA: 4:40 - loss: 1.7130 - accuracy: 0.54 - ETA: 4:37 - loss: 1.7185 - accuracy: 0.54 - ETA: 4:36 - loss: 1.7113 - accuracy: 0.54 - ETA: 4:34 - loss: 1.7080 - accuracy: 0.54 - ETA: 4:31 - loss: 1.7244 - accuracy: 0.54 - ETA: 4:29 - loss: 1.7342 - accuracy: 0.54 - ETA: 4:27 - loss: 1.7404 - accuracy: 0.54 - ETA: 4:24 - loss: 1.7393 - accuracy: 0.54 - ETA: 4:22 - loss: 1.7394 - accuracy: 0.54 - ETA: 4:21 - loss: 1.7399 - accuracy: 0.54 - ETA: 4:19 - loss: 1.7327 - accuracy: 0.54 - ETA: 4:17 - loss: 1.7377 - accuracy: 0.54 - ETA: 4:15 - loss: 1.7353 - accuracy: 0.54 - ETA: 4:13 - loss: 1.7406 - accuracy: 0.54 - ETA: 4:10 - loss: 1.7347 - accuracy: 0.54 - ETA: 4:08 - loss: 1.7376 - accuracy: 0.54 - ETA: 4:06 - loss: 1.7456 - accuracy: 0.54 - ETA: 4:04 - loss: 1.7470 - accuracy: 0.54 - ETA: 4:02 - loss: 1.7486 - accuracy: 0.54 - ETA: 3:59 - loss: 1.7489 - accuracy: 0.54 - ETA: 3:57 - loss: 1.7449 - accuracy: 0.54 - ETA: 3:55 - loss: 1.7485 - accuracy: 0.54 - ETA: 3:53 - loss: 1.7534 - accuracy: 0.54 - ETA: 3:51 - loss: 1.7787 - accuracy: 0.54 - ETA: 3:49 - loss: 1.7883 - accuracy: 0.54 - ETA: 3:47 - loss: 1.7783 - accuracy: 0.54 - ETA: 3:45 - loss: 1.7781 - accuracy: 0.54 - ETA: 3:43 - loss: 1.7852 - accuracy: 0.54 - ETA: 3:41 - loss: 1.7772 - accuracy: 0.54 - ETA: 3:39 - loss: 1.7674 - accuracy: 0.54 - ETA: 3:36 - loss: 1.7631 - accuracy: 0.54 - ETA: 3:34 - loss: 1.7611 - accuracy: 0.54 - ETA: 3:32 - loss: 1.7612 - accuracy: 0.54 - ETA: 3:30 - loss: 1.7677 - accuracy: 0.54 - ETA: 3:28 - loss: 1.7676 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7553 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7564 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7558 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7530 - accuracy: 0.55 - ETA: 3:17 - loss: 1.7489 - accuracy: 0.55 - ETA: 3:15 - loss: 1.7524 - accuracy: 0.55 - ETA: 3:13 - loss: 1.7599 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7591 - accuracy: 0.55 - ETA: 3:09 - loss: 1.7736 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7755 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7740 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7705 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7711 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7696 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7668 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7807 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7779 - accuracy: 0.54 - ETA: 2:50 - loss: 1.7787 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7816 - accuracy: 0.54 - ETA: 2:46 - loss: 1.7770 - accuracy: 0.54 - ETA: 2:44 - loss: 1.7743 - accuracy: 0.54 - ETA: 2:42 - loss: 1.7772 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7793 - accuracy: 0.54 - ETA: 2:37 - loss: 1.7739 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7741 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7737 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7735 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7716 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7695 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7758 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7779 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7762 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7815 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7868 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7886 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7934 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7911 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7917 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7871 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7876 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7900 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7925 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7915 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7902 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7879 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7867 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7869 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7848 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7890 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7907 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7897 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7870 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7872 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7884 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7924 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7911 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7891 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7882 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7885 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7891 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7894 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7862 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7843 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7844 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7833 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7818 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7813 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7802 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7787 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7812 - accuracy: 0.54 - ETA: 58s - loss: 1.7785 - accuracy: 0.5464 - ETA: 56s - loss: 1.7798 - accuracy: 0.545 - ETA: 54s - loss: 1.7794 - accuracy: 0.545 - ETA: 52s - loss: 1.7818 - accuracy: 0.545 - ETA: 50s - loss: 1.7809 - accuracy: 0.545 - ETA: 48s - loss: 1.7816 - accuracy: 0.545 - ETA: 46s - loss: 1.7814 - accuracy: 0.545 - ETA: 44s - loss: 1.7799 - accuracy: 0.545 - ETA: 41s - loss: 1.7793 - accuracy: 0.545 - ETA: 39s - loss: 1.7775 - accuracy: 0.545 - ETA: 37s - loss: 1.7781 - accuracy: 0.545 - ETA: 35s - loss: 1.7835 - accuracy: 0.545 - ETA: 33s - loss: 1.7893 - accuracy: 0.545 - ETA: 31s - loss: 1.7859 - accuracy: 0.546 - ETA: 29s - loss: 1.7851 - accuracy: 0.545 - ETA: 27s - loss: 1.7836 - accuracy: 0.546 - ETA: 25s - loss: 1.7833 - accuracy: 0.546 - ETA: 22s - loss: 1.7838 - accuracy: 0.546 - ETA: 20s - loss: 1.7829 - accuracy: 0.546 - ETA: 18s - loss: 1.7809 - accuracy: 0.546 - ETA: 16s - loss: 1.7824 - accuracy: 0.546 - ETA: 14s - loss: 1.7827 - accuracy: 0.546 - ETA: 12s - loss: 1.7868 - accuracy: 0.545 - ETA: 10s - loss: 1.7882 - accuracy: 0.545 - ETA: 8s - loss: 1.7906 - accuracy: 0.545 - ETA: 6s - loss: 1.7906 - accuracy: 0.54 - ETA: 3s - loss: 1.7897 - accuracy: 0.54 - ETA: 1s - loss: 1.7890 - accuracy: 0.54 - 342s 18ms/step - loss: 1.7899 - accuracy: 0.5440 - val_loss: 2.0811 - val_accuracy: 0.6039\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:59 - loss: 1.4259 - accuracy: 0.64 - ETA: 5:04 - loss: 1.5116 - accuracy: 0.62 - ETA: 5:11 - loss: 1.4878 - accuracy: 0.60 - ETA: 5:08 - loss: 1.6465 - accuracy: 0.58 - ETA: 5:05 - loss: 1.6622 - accuracy: 0.57 - ETA: 5:03 - loss: 1.6876 - accuracy: 0.56 - ETA: 5:01 - loss: 1.9480 - accuracy: 0.55 - ETA: 5:01 - loss: 1.8915 - accuracy: 0.55 - ETA: 4:58 - loss: 1.8815 - accuracy: 0.55 - ETA: 4:54 - loss: 1.8773 - accuracy: 0.55 - ETA: 4:56 - loss: 1.8506 - accuracy: 0.55 - ETA: 4:53 - loss: 1.9096 - accuracy: 0.55 - ETA: 4:51 - loss: 1.8725 - accuracy: 0.55 - ETA: 4:50 - loss: 1.8254 - accuracy: 0.56 - ETA: 4:48 - loss: 1.8287 - accuracy: 0.56 - ETA: 4:46 - loss: 1.8383 - accuracy: 0.55 - ETA: 4:44 - loss: 1.8263 - accuracy: 0.55 - ETA: 4:42 - loss: 1.8299 - accuracy: 0.55 - ETA: 4:39 - loss: 1.8221 - accuracy: 0.55 - ETA: 4:37 - loss: 1.8088 - accuracy: 0.55 - ETA: 4:35 - loss: 1.8048 - accuracy: 0.55 - ETA: 4:33 - loss: 1.8001 - accuracy: 0.55 - ETA: 4:30 - loss: 1.7987 - accuracy: 0.55 - ETA: 4:28 - loss: 1.8010 - accuracy: 0.55 - ETA: 4:26 - loss: 1.7955 - accuracy: 0.55 - ETA: 4:24 - loss: 1.7874 - accuracy: 0.55 - ETA: 4:22 - loss: 1.8053 - accuracy: 0.55 - ETA: 4:19 - loss: 1.7993 - accuracy: 0.55 - ETA: 4:18 - loss: 1.7919 - accuracy: 0.55 - ETA: 4:15 - loss: 1.8040 - accuracy: 0.55 - ETA: 4:13 - loss: 1.7962 - accuracy: 0.55 - ETA: 4:11 - loss: 1.8019 - accuracy: 0.55 - ETA: 4:08 - loss: 1.7991 - accuracy: 0.55 - ETA: 4:06 - loss: 1.8033 - accuracy: 0.55 - ETA: 4:04 - loss: 1.7983 - accuracy: 0.55 - ETA: 4:02 - loss: 1.8035 - accuracy: 0.55 - ETA: 3:59 - loss: 1.7987 - accuracy: 0.55 - ETA: 3:57 - loss: 1.7984 - accuracy: 0.55 - ETA: 3:55 - loss: 1.8429 - accuracy: 0.55 - ETA: 3:53 - loss: 1.8348 - accuracy: 0.55 - ETA: 3:51 - loss: 1.8270 - accuracy: 0.55 - ETA: 3:48 - loss: 1.8206 - accuracy: 0.55 - ETA: 3:47 - loss: 1.8194 - accuracy: 0.55 - ETA: 3:44 - loss: 1.8133 - accuracy: 0.55 - ETA: 3:42 - loss: 1.8160 - accuracy: 0.55 - ETA: 3:40 - loss: 1.8101 - accuracy: 0.55 - ETA: 3:38 - loss: 1.8036 - accuracy: 0.55 - ETA: 3:36 - loss: 1.8023 - accuracy: 0.55 - ETA: 3:34 - loss: 1.8038 - accuracy: 0.55 - ETA: 3:32 - loss: 1.8000 - accuracy: 0.55 - ETA: 3:30 - loss: 1.8124 - accuracy: 0.55 - ETA: 3:28 - loss: 1.8129 - accuracy: 0.55 - ETA: 3:26 - loss: 1.8218 - accuracy: 0.54 - ETA: 3:24 - loss: 1.8141 - accuracy: 0.55 - ETA: 3:22 - loss: 1.8093 - accuracy: 0.55 - ETA: 3:20 - loss: 1.8040 - accuracy: 0.55 - ETA: 3:17 - loss: 1.8236 - accuracy: 0.55 - ETA: 3:15 - loss: 1.8200 - accuracy: 0.55 - ETA: 3:13 - loss: 1.8159 - accuracy: 0.55 - ETA: 3:12 - loss: 1.8114 - accuracy: 0.55 - ETA: 3:09 - loss: 1.8075 - accuracy: 0.55 - ETA: 3:07 - loss: 1.8058 - accuracy: 0.55 - ETA: 3:05 - loss: 1.8016 - accuracy: 0.55 - ETA: 3:03 - loss: 1.7969 - accuracy: 0.55 - ETA: 3:01 - loss: 1.7958 - accuracy: 0.55 - ETA: 2:59 - loss: 1.7908 - accuracy: 0.55 - ETA: 2:57 - loss: 1.7870 - accuracy: 0.55 - ETA: 2:54 - loss: 1.7839 - accuracy: 0.55 - ETA: 2:52 - loss: 1.7996 - accuracy: 0.55 - ETA: 2:50 - loss: 1.8003 - accuracy: 0.55 - ETA: 2:48 - loss: 1.7979 - accuracy: 0.55 - ETA: 2:46 - loss: 1.7953 - accuracy: 0.55 - ETA: 2:44 - loss: 1.7975 - accuracy: 0.55 - ETA: 2:42 - loss: 1.7980 - accuracy: 0.55 - ETA: 2:40 - loss: 1.7945 - accuracy: 0.55 - ETA: 2:38 - loss: 1.7923 - accuracy: 0.55 - ETA: 2:35 - loss: 1.7885 - accuracy: 0.55 - ETA: 2:33 - loss: 1.8097 - accuracy: 0.55 - ETA: 2:31 - loss: 1.8049 - accuracy: 0.55 - ETA: 2:29 - loss: 1.8016 - accuracy: 0.55 - ETA: 2:27 - loss: 1.8000 - accuracy: 0.55 - ETA: 2:25 - loss: 1.7996 - accuracy: 0.55 - ETA: 2:23 - loss: 1.7983 - accuracy: 0.55 - ETA: 2:21 - loss: 1.7948 - accuracy: 0.55 - ETA: 2:19 - loss: 1.7983 - accuracy: 0.55 - ETA: 2:17 - loss: 1.7961 - accuracy: 0.55 - ETA: 2:14 - loss: 1.7937 - accuracy: 0.55 - ETA: 2:12 - loss: 1.7926 - accuracy: 0.55 - ETA: 2:10 - loss: 1.7984 - accuracy: 0.55 - ETA: 2:08 - loss: 1.8107 - accuracy: 0.55 - ETA: 2:06 - loss: 1.8115 - accuracy: 0.55 - ETA: 2:04 - loss: 1.8188 - accuracy: 0.55 - ETA: 2:02 - loss: 1.8163 - accuracy: 0.55 - ETA: 2:00 - loss: 1.8166 - accuracy: 0.55 - ETA: 1:58 - loss: 1.8125 - accuracy: 0.55 - ETA: 1:55 - loss: 1.8121 - accuracy: 0.55 - ETA: 1:53 - loss: 1.8080 - accuracy: 0.55 - ETA: 1:51 - loss: 1.8046 - accuracy: 0.55 - ETA: 1:49 - loss: 1.8040 - accuracy: 0.55 - ETA: 1:47 - loss: 1.8042 - accuracy: 0.55 - ETA: 1:45 - loss: 1.8045 - accuracy: 0.55 - ETA: 1:43 - loss: 1.8033 - accuracy: 0.55 - ETA: 1:41 - loss: 1.8004 - accuracy: 0.55 - ETA: 1:38 - loss: 1.8009 - accuracy: 0.55 - ETA: 1:36 - loss: 1.7987 - accuracy: 0.55 - ETA: 1:34 - loss: 1.7946 - accuracy: 0.55 - ETA: 1:32 - loss: 1.7942 - accuracy: 0.55 - ETA: 1:30 - loss: 1.7941 - accuracy: 0.55 - ETA: 1:28 - loss: 1.7925 - accuracy: 0.55 - ETA: 1:26 - loss: 1.7940 - accuracy: 0.55 - ETA: 1:24 - loss: 1.7959 - accuracy: 0.55 - ETA: 1:22 - loss: 1.7943 - accuracy: 0.55 - ETA: 1:19 - loss: 1.7953 - accuracy: 0.55 - ETA: 1:17 - loss: 1.7925 - accuracy: 0.55 - ETA: 1:15 - loss: 1.7935 - accuracy: 0.55 - ETA: 1:13 - loss: 1.7889 - accuracy: 0.55 - ETA: 1:11 - loss: 1.7870 - accuracy: 0.55 - ETA: 1:09 - loss: 1.7870 - accuracy: 0.55 - ETA: 1:07 - loss: 1.7880 - accuracy: 0.55 - ETA: 1:05 - loss: 1.7877 - accuracy: 0.55 - ETA: 1:02 - loss: 1.7873 - accuracy: 0.55 - ETA: 1:00 - loss: 1.7869 - accuracy: 0.55 - ETA: 58s - loss: 1.7892 - accuracy: 0.5539 - ETA: 56s - loss: 1.7884 - accuracy: 0.553 - ETA: 54s - loss: 1.7882 - accuracy: 0.553 - ETA: 52s - loss: 1.7878 - accuracy: 0.553 - ETA: 50s - loss: 1.7866 - accuracy: 0.553 - ETA: 48s - loss: 1.7878 - accuracy: 0.552 - ETA: 46s - loss: 1.7850 - accuracy: 0.553 - ETA: 44s - loss: 1.7834 - accuracy: 0.553 - ETA: 41s - loss: 1.7824 - accuracy: 0.553 - ETA: 39s - loss: 1.7816 - accuracy: 0.553 - ETA: 37s - loss: 1.7830 - accuracy: 0.553 - ETA: 35s - loss: 1.7840 - accuracy: 0.552 - ETA: 33s - loss: 1.7824 - accuracy: 0.552 - ETA: 31s - loss: 1.7818 - accuracy: 0.552 - ETA: 29s - loss: 1.7795 - accuracy: 0.553 - ETA: 27s - loss: 1.7772 - accuracy: 0.553 - ETA: 25s - loss: 1.7753 - accuracy: 0.553 - ETA: 22s - loss: 1.7760 - accuracy: 0.553 - ETA: 20s - loss: 1.7792 - accuracy: 0.553 - ETA: 18s - loss: 1.7794 - accuracy: 0.553 - ETA: 16s - loss: 1.7776 - accuracy: 0.553 - ETA: 14s - loss: 1.7786 - accuracy: 0.552 - ETA: 12s - loss: 1.7771 - accuracy: 0.552 - ETA: 10s - loss: 1.7759 - accuracy: 0.553 - ETA: 8s - loss: 1.7752 - accuracy: 0.552 - ETA: 6s - loss: 1.7742 - accuracy: 0.55 - ETA: 3s - loss: 1.7738 - accuracy: 0.55 - ETA: 1s - loss: 1.7743 - accuracy: 0.55 - 343s 18ms/step - loss: 1.7731 - accuracy: 0.5528 - val_loss: 2.1013 - val_accuracy: 0.6043\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:19 - loss: 1.6147 - accuracy: 0.54 - ETA: 5:18 - loss: 1.5267 - accuracy: 0.55 - ETA: 5:12 - loss: 1.4907 - accuracy: 0.57 - ETA: 5:14 - loss: 1.4814 - accuracy: 0.58 - ETA: 5:10 - loss: 1.4879 - accuracy: 0.57 - ETA: 5:09 - loss: 1.5371 - accuracy: 0.56 - ETA: 5:06 - loss: 1.5703 - accuracy: 0.56 - ETA: 5:03 - loss: 1.5832 - accuracy: 0.56 - ETA: 5:00 - loss: 1.6288 - accuracy: 0.55 - ETA: 4:59 - loss: 1.6627 - accuracy: 0.54 - ETA: 4:54 - loss: 1.6641 - accuracy: 0.54 - ETA: 4:52 - loss: 1.6901 - accuracy: 0.55 - ETA: 4:50 - loss: 1.7117 - accuracy: 0.54 - ETA: 4:50 - loss: 1.7089 - accuracy: 0.54 - ETA: 4:47 - loss: 1.8259 - accuracy: 0.54 - ETA: 4:45 - loss: 1.8336 - accuracy: 0.54 - ETA: 4:43 - loss: 1.8326 - accuracy: 0.54 - ETA: 4:41 - loss: 1.8182 - accuracy: 0.54 - ETA: 4:38 - loss: 1.8086 - accuracy: 0.54 - ETA: 4:37 - loss: 1.8130 - accuracy: 0.54 - ETA: 4:35 - loss: 1.8076 - accuracy: 0.54 - ETA: 4:33 - loss: 1.7908 - accuracy: 0.54 - ETA: 4:32 - loss: 1.8010 - accuracy: 0.54 - ETA: 4:29 - loss: 1.7867 - accuracy: 0.54 - ETA: 4:27 - loss: 1.7879 - accuracy: 0.54 - ETA: 4:25 - loss: 1.7886 - accuracy: 0.54 - ETA: 4:23 - loss: 1.7761 - accuracy: 0.54 - ETA: 4:21 - loss: 1.7702 - accuracy: 0.54 - ETA: 4:18 - loss: 1.7640 - accuracy: 0.54 - ETA: 4:16 - loss: 1.7608 - accuracy: 0.54 - ETA: 4:14 - loss: 1.7600 - accuracy: 0.54 - ETA: 4:12 - loss: 1.7547 - accuracy: 0.54 - ETA: 4:10 - loss: 1.7473 - accuracy: 0.55 - ETA: 4:08 - loss: 1.7509 - accuracy: 0.55 - ETA: 4:06 - loss: 1.7442 - accuracy: 0.55 - ETA: 4:03 - loss: 1.7506 - accuracy: 0.55 - ETA: 4:01 - loss: 1.7590 - accuracy: 0.55 - ETA: 3:59 - loss: 1.7570 - accuracy: 0.55 - ETA: 3:57 - loss: 1.7563 - accuracy: 0.55 - ETA: 3:54 - loss: 1.7614 - accuracy: 0.54 - ETA: 3:52 - loss: 1.7558 - accuracy: 0.54 - ETA: 3:50 - loss: 1.7540 - accuracy: 0.55 - ETA: 3:48 - loss: 1.7460 - accuracy: 0.55 - ETA: 3:46 - loss: 1.7456 - accuracy: 0.55 - ETA: 3:44 - loss: 1.7419 - accuracy: 0.55 - ETA: 3:42 - loss: 1.7371 - accuracy: 0.55 - ETA: 3:40 - loss: 1.7401 - accuracy: 0.55 - ETA: 3:38 - loss: 1.7361 - accuracy: 0.55 - ETA: 3:36 - loss: 1.7393 - accuracy: 0.55 - ETA: 3:33 - loss: 1.7397 - accuracy: 0.55 - ETA: 3:31 - loss: 1.7420 - accuracy: 0.55 - ETA: 3:29 - loss: 1.7377 - accuracy: 0.55 - ETA: 3:27 - loss: 1.7388 - accuracy: 0.55 - ETA: 3:25 - loss: 1.7408 - accuracy: 0.55 - ETA: 3:23 - loss: 1.7374 - accuracy: 0.55 - ETA: 3:21 - loss: 1.7331 - accuracy: 0.55 - ETA: 3:18 - loss: 1.7349 - accuracy: 0.55 - ETA: 3:16 - loss: 1.7330 - accuracy: 0.55 - ETA: 3:14 - loss: 1.7330 - accuracy: 0.55 - ETA: 3:12 - loss: 1.7366 - accuracy: 0.55 - ETA: 3:10 - loss: 1.7554 - accuracy: 0.55 - ETA: 3:08 - loss: 1.7881 - accuracy: 0.55 - ETA: 3:06 - loss: 1.7851 - accuracy: 0.55 - ETA: 3:04 - loss: 1.7871 - accuracy: 0.55 - ETA: 3:01 - loss: 1.7925 - accuracy: 0.55 - ETA: 2:59 - loss: 1.7954 - accuracy: 0.55 - ETA: 2:57 - loss: 1.7950 - accuracy: 0.55 - ETA: 2:55 - loss: 1.7927 - accuracy: 0.55 - ETA: 2:53 - loss: 1.7863 - accuracy: 0.55 - ETA: 2:51 - loss: 1.7868 - accuracy: 0.55 - ETA: 2:49 - loss: 1.7857 - accuracy: 0.55 - ETA: 2:47 - loss: 1.7867 - accuracy: 0.55 - ETA: 2:44 - loss: 1.7899 - accuracy: 0.54 - ETA: 2:42 - loss: 1.7967 - accuracy: 0.54 - ETA: 2:40 - loss: 1.7950 - accuracy: 0.54 - ETA: 2:38 - loss: 1.8044 - accuracy: 0.54 - ETA: 2:36 - loss: 1.8099 - accuracy: 0.54 - ETA: 2:34 - loss: 1.8061 - accuracy: 0.54 - ETA: 2:32 - loss: 1.8067 - accuracy: 0.54 - ETA: 2:30 - loss: 1.8050 - accuracy: 0.54 - ETA: 2:28 - loss: 1.8019 - accuracy: 0.54 - ETA: 2:26 - loss: 1.8004 - accuracy: 0.54 - ETA: 2:23 - loss: 1.8021 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7991 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7941 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7994 - accuracy: 0.54 - ETA: 2:15 - loss: 1.8005 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7989 - accuracy: 0.54 - ETA: 2:11 - loss: 1.7971 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7956 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7972 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7975 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7989 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7940 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7922 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7998 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7979 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7963 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7954 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7938 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7925 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7915 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7887 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7871 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7842 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7856 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7827 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7803 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7814 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7808 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7811 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7819 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7797 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7807 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7798 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7783 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7797 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7796 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7767 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7786 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7767 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7774 - accuracy: 0.54 - ETA: 58s - loss: 1.7775 - accuracy: 0.5463 - ETA: 56s - loss: 1.7788 - accuracy: 0.545 - ETA: 54s - loss: 1.7783 - accuracy: 0.545 - ETA: 52s - loss: 1.7801 - accuracy: 0.545 - ETA: 50s - loss: 1.7794 - accuracy: 0.545 - ETA: 48s - loss: 1.7772 - accuracy: 0.545 - ETA: 46s - loss: 1.7757 - accuracy: 0.546 - ETA: 44s - loss: 1.7760 - accuracy: 0.546 - ETA: 41s - loss: 1.7765 - accuracy: 0.545 - ETA: 39s - loss: 1.7749 - accuracy: 0.545 - ETA: 37s - loss: 1.7748 - accuracy: 0.545 - ETA: 35s - loss: 1.7753 - accuracy: 0.545 - ETA: 33s - loss: 1.7753 - accuracy: 0.545 - ETA: 31s - loss: 1.7728 - accuracy: 0.545 - ETA: 29s - loss: 1.7717 - accuracy: 0.546 - ETA: 27s - loss: 1.7724 - accuracy: 0.546 - ETA: 25s - loss: 1.7711 - accuracy: 0.546 - ETA: 22s - loss: 1.7688 - accuracy: 0.546 - ETA: 20s - loss: 1.7701 - accuracy: 0.547 - ETA: 18s - loss: 1.7687 - accuracy: 0.547 - ETA: 16s - loss: 1.7702 - accuracy: 0.547 - ETA: 14s - loss: 1.7733 - accuracy: 0.547 - ETA: 12s - loss: 1.7725 - accuracy: 0.547 - ETA: 10s - loss: 1.7740 - accuracy: 0.546 - ETA: 8s - loss: 1.7741 - accuracy: 0.546 - ETA: 6s - loss: 1.7762 - accuracy: 0.54 - ETA: 3s - loss: 1.7733 - accuracy: 0.54 - ETA: 1s - loss: 1.7741 - accuracy: 0.54 - 344s 18ms/step - loss: 1.7734 - accuracy: 0.5465 - val_loss: 2.0710 - val_accuracy: 0.5968\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:11 - loss: 1.8120 - accuracy: 0.46 - ETA: 5:11 - loss: 1.7680 - accuracy: 0.44 - ETA: 5:13 - loss: 1.7694 - accuracy: 0.46 - ETA: 5:11 - loss: 1.9115 - accuracy: 0.46 - ETA: 5:07 - loss: 1.7942 - accuracy: 0.49 - ETA: 5:05 - loss: 1.8232 - accuracy: 0.48 - ETA: 5:04 - loss: 1.8222 - accuracy: 0.49 - ETA: 5:04 - loss: 1.7961 - accuracy: 0.49 - ETA: 5:02 - loss: 1.7869 - accuracy: 0.50 - ETA: 4:59 - loss: 2.0028 - accuracy: 0.50 - ETA: 4:58 - loss: 1.9843 - accuracy: 0.51 - ETA: 4:56 - loss: 1.9930 - accuracy: 0.50 - ETA: 4:54 - loss: 1.9903 - accuracy: 0.50 - ETA: 4:52 - loss: 1.9748 - accuracy: 0.50 - ETA: 4:49 - loss: 1.9708 - accuracy: 0.50 - ETA: 4:46 - loss: 1.9505 - accuracy: 0.50 - ETA: 4:45 - loss: 1.9384 - accuracy: 0.50 - ETA: 4:42 - loss: 1.9129 - accuracy: 0.51 - ETA: 4:40 - loss: 1.9166 - accuracy: 0.50 - ETA: 4:37 - loss: 1.9073 - accuracy: 0.51 - ETA: 4:34 - loss: 1.9014 - accuracy: 0.51 - ETA: 4:32 - loss: 1.9012 - accuracy: 0.51 - ETA: 4:30 - loss: 1.8932 - accuracy: 0.51 - ETA: 4:27 - loss: 1.8860 - accuracy: 0.51 - ETA: 4:26 - loss: 1.8706 - accuracy: 0.52 - ETA: 4:23 - loss: 1.8674 - accuracy: 0.51 - ETA: 4:21 - loss: 1.8585 - accuracy: 0.52 - ETA: 4:19 - loss: 1.8523 - accuracy: 0.52 - ETA: 4:16 - loss: 1.8405 - accuracy: 0.52 - ETA: 4:14 - loss: 1.8390 - accuracy: 0.52 - ETA: 4:12 - loss: 1.8462 - accuracy: 0.52 - ETA: 4:10 - loss: 1.8381 - accuracy: 0.52 - ETA: 4:08 - loss: 1.8446 - accuracy: 0.52 - ETA: 4:06 - loss: 1.8399 - accuracy: 0.52 - ETA: 4:04 - loss: 1.8443 - accuracy: 0.52 - ETA: 4:01 - loss: 1.8414 - accuracy: 0.52 - ETA: 3:59 - loss: 1.8383 - accuracy: 0.52 - ETA: 3:57 - loss: 1.8315 - accuracy: 0.52 - ETA: 3:54 - loss: 1.8244 - accuracy: 0.52 - ETA: 3:53 - loss: 1.8318 - accuracy: 0.52 - ETA: 3:50 - loss: 1.8289 - accuracy: 0.52 - ETA: 3:49 - loss: 1.8280 - accuracy: 0.52 - ETA: 3:47 - loss: 1.8278 - accuracy: 0.52 - ETA: 3:45 - loss: 1.8211 - accuracy: 0.52 - ETA: 3:43 - loss: 1.8119 - accuracy: 0.53 - ETA: 3:41 - loss: 1.8096 - accuracy: 0.53 - ETA: 3:38 - loss: 1.8081 - accuracy: 0.53 - ETA: 3:36 - loss: 1.8089 - accuracy: 0.53 - ETA: 3:34 - loss: 1.8171 - accuracy: 0.53 - ETA: 3:32 - loss: 1.8211 - accuracy: 0.53 - ETA: 3:30 - loss: 1.8138 - accuracy: 0.53 - ETA: 3:27 - loss: 1.8170 - accuracy: 0.53 - ETA: 3:25 - loss: 1.8162 - accuracy: 0.53 - ETA: 3:23 - loss: 1.8066 - accuracy: 0.53 - ETA: 3:21 - loss: 1.8056 - accuracy: 0.53 - ETA: 3:19 - loss: 1.8010 - accuracy: 0.53 - ETA: 3:17 - loss: 1.7990 - accuracy: 0.53 - ETA: 3:15 - loss: 1.7963 - accuracy: 0.53 - ETA: 3:13 - loss: 1.7905 - accuracy: 0.53 - ETA: 3:11 - loss: 1.7893 - accuracy: 0.53 - ETA: 3:09 - loss: 1.7885 - accuracy: 0.53 - ETA: 3:07 - loss: 1.7839 - accuracy: 0.53 - ETA: 3:05 - loss: 1.7837 - accuracy: 0.53 - ETA: 3:03 - loss: 1.7794 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7806 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7882 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7858 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7835 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7828 - accuracy: 0.54 - ETA: 2:50 - loss: 1.7801 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7822 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7876 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7900 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7891 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7846 - accuracy: 0.54 - ETA: 2:37 - loss: 1.7919 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7997 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8005 - accuracy: 0.53 - ETA: 2:31 - loss: 1.7973 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7952 - accuracy: 0.53 - ETA: 2:26 - loss: 1.7961 - accuracy: 0.53 - ETA: 2:24 - loss: 1.7967 - accuracy: 0.53 - ETA: 2:22 - loss: 1.7961 - accuracy: 0.53 - ETA: 2:20 - loss: 1.7938 - accuracy: 0.53 - ETA: 2:18 - loss: 1.7981 - accuracy: 0.53 - ETA: 2:16 - loss: 1.7992 - accuracy: 0.53 - ETA: 2:14 - loss: 1.7961 - accuracy: 0.53 - ETA: 2:12 - loss: 1.7927 - accuracy: 0.53 - ETA: 2:10 - loss: 1.7906 - accuracy: 0.53 - ETA: 2:08 - loss: 1.7858 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7846 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7820 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7803 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7766 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7799 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7825 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7854 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7849 - accuracy: 0.53 - ETA: 1:49 - loss: 1.7828 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7814 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7826 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7827 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7802 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7829 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7855 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7840 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7831 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7817 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7818 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7826 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7797 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7798 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7783 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7795 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7784 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7750 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7742 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7758 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7772 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7765 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7747 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7737 - accuracy: 0.54 - ETA: 58s - loss: 1.7752 - accuracy: 0.5421 - ETA: 56s - loss: 1.7737 - accuracy: 0.542 - ETA: 54s - loss: 1.7758 - accuracy: 0.542 - ETA: 52s - loss: 1.7787 - accuracy: 0.542 - ETA: 50s - loss: 1.7780 - accuracy: 0.543 - ETA: 48s - loss: 1.7760 - accuracy: 0.543 - ETA: 46s - loss: 1.7763 - accuracy: 0.543 - ETA: 44s - loss: 1.7747 - accuracy: 0.543 - ETA: 42s - loss: 1.7749 - accuracy: 0.543 - ETA: 39s - loss: 1.7763 - accuracy: 0.543 - ETA: 37s - loss: 1.7751 - accuracy: 0.543 - ETA: 35s - loss: 1.7779 - accuracy: 0.544 - ETA: 33s - loss: 1.7764 - accuracy: 0.544 - ETA: 31s - loss: 1.7749 - accuracy: 0.544 - ETA: 29s - loss: 1.7733 - accuracy: 0.545 - ETA: 27s - loss: 1.7710 - accuracy: 0.545 - ETA: 25s - loss: 1.7712 - accuracy: 0.545 - ETA: 23s - loss: 1.7746 - accuracy: 0.545 - ETA: 20s - loss: 1.7748 - accuracy: 0.544 - ETA: 18s - loss: 1.7737 - accuracy: 0.545 - ETA: 16s - loss: 1.7748 - accuracy: 0.545 - ETA: 14s - loss: 1.7752 - accuracy: 0.544 - ETA: 12s - loss: 1.7739 - accuracy: 0.545 - ETA: 10s - loss: 1.7736 - accuracy: 0.544 - ETA: 8s - loss: 1.7726 - accuracy: 0.544 - ETA: 6s - loss: 1.7712 - accuracy: 0.54 - ETA: 3s - loss: 1.7718 - accuracy: 0.54 - ETA: 1s - loss: 1.7742 - accuracy: 0.54 - 344s 18ms/step - loss: 1.7736 - accuracy: 0.5449 - val_loss: 2.1074 - val_accuracy: 0.5920\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:07 - loss: 1.7867 - accuracy: 0.53 - ETA: 5:14 - loss: 1.6092 - accuracy: 0.56 - ETA: 5:07 - loss: 1.6320 - accuracy: 0.55 - ETA: 5:09 - loss: 1.6788 - accuracy: 0.56 - ETA: 5:07 - loss: 1.6448 - accuracy: 0.57 - ETA: 5:03 - loss: 1.7108 - accuracy: 0.55 - ETA: 5:03 - loss: 1.7450 - accuracy: 0.55 - ETA: 5:01 - loss: 1.6971 - accuracy: 0.56 - ETA: 4:59 - loss: 1.7477 - accuracy: 0.55 - ETA: 4:57 - loss: 1.7407 - accuracy: 0.55 - ETA: 4:55 - loss: 1.7421 - accuracy: 0.54 - ETA: 4:52 - loss: 1.7390 - accuracy: 0.54 - ETA: 4:50 - loss: 1.7530 - accuracy: 0.54 - ETA: 4:50 - loss: 1.7336 - accuracy: 0.55 - ETA: 4:46 - loss: 1.7301 - accuracy: 0.55 - ETA: 4:44 - loss: 1.7726 - accuracy: 0.54 - ETA: 4:42 - loss: 1.7820 - accuracy: 0.54 - ETA: 4:40 - loss: 1.7762 - accuracy: 0.55 - ETA: 4:38 - loss: 1.7653 - accuracy: 0.55 - ETA: 4:36 - loss: 1.7914 - accuracy: 0.54 - ETA: 4:35 - loss: 1.7949 - accuracy: 0.54 - ETA: 4:32 - loss: 1.7877 - accuracy: 0.54 - ETA: 4:29 - loss: 1.7847 - accuracy: 0.54 - ETA: 4:27 - loss: 1.7960 - accuracy: 0.54 - ETA: 4:24 - loss: 1.7913 - accuracy: 0.54 - ETA: 4:22 - loss: 1.8122 - accuracy: 0.54 - ETA: 4:20 - loss: 1.8014 - accuracy: 0.54 - ETA: 4:18 - loss: 1.7996 - accuracy: 0.54 - ETA: 4:16 - loss: 1.8006 - accuracy: 0.54 - ETA: 4:14 - loss: 1.8024 - accuracy: 0.54 - ETA: 4:11 - loss: 1.7994 - accuracy: 0.54 - ETA: 4:09 - loss: 1.7908 - accuracy: 0.54 - ETA: 4:07 - loss: 1.8651 - accuracy: 0.54 - ETA: 4:05 - loss: 1.8634 - accuracy: 0.54 - ETA: 4:03 - loss: 1.8696 - accuracy: 0.54 - ETA: 4:01 - loss: 1.8571 - accuracy: 0.54 - ETA: 3:59 - loss: 1.8608 - accuracy: 0.54 - ETA: 3:57 - loss: 1.8591 - accuracy: 0.54 - ETA: 3:55 - loss: 1.8557 - accuracy: 0.54 - ETA: 3:52 - loss: 1.8524 - accuracy: 0.54 - ETA: 3:50 - loss: 1.8468 - accuracy: 0.54 - ETA: 3:48 - loss: 1.8405 - accuracy: 0.54 - ETA: 3:46 - loss: 1.8512 - accuracy: 0.54 - ETA: 3:44 - loss: 1.8483 - accuracy: 0.54 - ETA: 3:42 - loss: 1.8436 - accuracy: 0.54 - ETA: 3:40 - loss: 1.8431 - accuracy: 0.54 - ETA: 3:38 - loss: 1.8380 - accuracy: 0.54 - ETA: 3:35 - loss: 1.8333 - accuracy: 0.54 - ETA: 3:33 - loss: 1.8338 - accuracy: 0.54 - ETA: 3:31 - loss: 1.8379 - accuracy: 0.53 - ETA: 3:29 - loss: 1.8358 - accuracy: 0.53 - ETA: 3:27 - loss: 1.8308 - accuracy: 0.54 - ETA: 3:25 - loss: 1.8324 - accuracy: 0.54 - ETA: 3:23 - loss: 1.8289 - accuracy: 0.54 - ETA: 3:21 - loss: 1.8260 - accuracy: 0.54 - ETA: 3:19 - loss: 1.8216 - accuracy: 0.54 - ETA: 3:17 - loss: 1.8170 - accuracy: 0.54 - ETA: 3:14 - loss: 1.8093 - accuracy: 0.54 - ETA: 3:12 - loss: 1.8061 - accuracy: 0.54 - ETA: 3:10 - loss: 1.8023 - accuracy: 0.54 - ETA: 3:08 - loss: 1.8000 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7986 - accuracy: 0.54 - ETA: 3:04 - loss: 1.8019 - accuracy: 0.54 - ETA: 3:02 - loss: 1.8044 - accuracy: 0.54 - ETA: 3:00 - loss: 1.8022 - accuracy: 0.54 - ETA: 2:58 - loss: 1.8031 - accuracy: 0.54 - ETA: 2:56 - loss: 1.8056 - accuracy: 0.54 - ETA: 2:54 - loss: 1.8030 - accuracy: 0.54 - ETA: 2:52 - loss: 1.8001 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7975 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7932 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7920 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7908 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7890 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7908 - accuracy: 0.54 - ETA: 2:37 - loss: 1.7898 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7886 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7948 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7954 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7997 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7977 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7982 - accuracy: 0.54 - ETA: 2:22 - loss: 1.7959 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7949 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7946 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7915 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7968 - accuracy: 0.54 - ETA: 2:12 - loss: 1.8002 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7968 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7967 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7938 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7929 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7959 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7934 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7925 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7908 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7975 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7993 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7983 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7991 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7975 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7973 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7961 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7966 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7953 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7961 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7946 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7956 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7980 - accuracy: 0.54 - ETA: 1:25 - loss: 1.8001 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7988 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7979 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7971 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7933 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7907 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7890 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7900 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7871 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7835 - accuracy: 0.54 - ETA: 1:04 - loss: 1.7817 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7849 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7830 - accuracy: 0.54 - ETA: 58s - loss: 1.7830 - accuracy: 0.5416 - ETA: 56s - loss: 1.7824 - accuracy: 0.541 - ETA: 54s - loss: 1.7805 - accuracy: 0.541 - ETA: 52s - loss: 1.7789 - accuracy: 0.542 - ETA: 50s - loss: 1.7774 - accuracy: 0.542 - ETA: 48s - loss: 1.7789 - accuracy: 0.542 - ETA: 46s - loss: 1.7789 - accuracy: 0.542 - ETA: 43s - loss: 1.7800 - accuracy: 0.541 - ETA: 41s - loss: 1.7772 - accuracy: 0.542 - ETA: 39s - loss: 1.7755 - accuracy: 0.542 - ETA: 37s - loss: 1.7755 - accuracy: 0.542 - ETA: 35s - loss: 1.7758 - accuracy: 0.541 - ETA: 33s - loss: 1.7745 - accuracy: 0.542 - ETA: 31s - loss: 1.7751 - accuracy: 0.541 - ETA: 29s - loss: 1.7742 - accuracy: 0.541 - ETA: 27s - loss: 1.7732 - accuracy: 0.541 - ETA: 25s - loss: 1.7785 - accuracy: 0.541 - ETA: 22s - loss: 1.7756 - accuracy: 0.542 - ETA: 20s - loss: 1.7740 - accuracy: 0.542 - ETA: 18s - loss: 1.7732 - accuracy: 0.542 - ETA: 16s - loss: 1.7732 - accuracy: 0.542 - ETA: 14s - loss: 1.7717 - accuracy: 0.543 - ETA: 12s - loss: 1.7713 - accuracy: 0.542 - ETA: 10s - loss: 1.7718 - accuracy: 0.542 - ETA: 8s - loss: 1.7711 - accuracy: 0.543 - ETA: 6s - loss: 1.7722 - accuracy: 0.54 - ETA: 3s - loss: 1.7723 - accuracy: 0.54 - ETA: 1s - loss: 1.7703 - accuracy: 0.54 - 343s 18ms/step - loss: 1.7717 - accuracy: 0.5423 - val_loss: 2.0457 - val_accuracy: 0.6018\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:31 - loss: 2.0625 - accuracy: 0.50 - ETA: 5:14 - loss: 2.0328 - accuracy: 0.50 - ETA: 5:12 - loss: 1.9263 - accuracy: 0.52 - ETA: 5:06 - loss: 1.9128 - accuracy: 0.52 - ETA: 5:03 - loss: 1.8654 - accuracy: 0.52 - ETA: 5:02 - loss: 1.8317 - accuracy: 0.53 - ETA: 5:01 - loss: 1.7855 - accuracy: 0.53 - ETA: 4:58 - loss: 1.7558 - accuracy: 0.53 - ETA: 4:56 - loss: 1.7523 - accuracy: 0.54 - ETA: 4:54 - loss: 1.7785 - accuracy: 0.53 - ETA: 4:52 - loss: 1.7428 - accuracy: 0.53 - ETA: 4:50 - loss: 1.7652 - accuracy: 0.54 - ETA: 4:49 - loss: 1.7363 - accuracy: 0.54 - ETA: 4:46 - loss: 1.7502 - accuracy: 0.54 - ETA: 4:44 - loss: 1.7366 - accuracy: 0.54 - ETA: 4:43 - loss: 1.7339 - accuracy: 0.54 - ETA: 4:41 - loss: 1.7314 - accuracy: 0.54 - ETA: 4:39 - loss: 1.7404 - accuracy: 0.54 - ETA: 4:37 - loss: 1.7534 - accuracy: 0.54 - ETA: 4:35 - loss: 1.7424 - accuracy: 0.54 - ETA: 4:33 - loss: 1.7337 - accuracy: 0.54 - ETA: 4:30 - loss: 1.7390 - accuracy: 0.54 - ETA: 4:28 - loss: 1.7398 - accuracy: 0.54 - ETA: 4:26 - loss: 1.7365 - accuracy: 0.54 - ETA: 4:24 - loss: 1.7313 - accuracy: 0.54 - ETA: 4:22 - loss: 1.7420 - accuracy: 0.54 - ETA: 4:20 - loss: 1.7367 - accuracy: 0.54 - ETA: 4:18 - loss: 1.7362 - accuracy: 0.54 - ETA: 4:16 - loss: 1.7377 - accuracy: 0.54 - ETA: 4:14 - loss: 1.7317 - accuracy: 0.54 - ETA: 4:12 - loss: 1.7178 - accuracy: 0.54 - ETA: 4:10 - loss: 1.7089 - accuracy: 0.55 - ETA: 4:08 - loss: 1.7042 - accuracy: 0.55 - ETA: 4:06 - loss: 1.7072 - accuracy: 0.54 - ETA: 4:03 - loss: 1.7100 - accuracy: 0.54 - ETA: 4:01 - loss: 1.6988 - accuracy: 0.55 - ETA: 3:59 - loss: 1.7063 - accuracy: 0.54 - ETA: 3:57 - loss: 1.6993 - accuracy: 0.55 - ETA: 3:55 - loss: 1.6982 - accuracy: 0.55 - ETA: 3:52 - loss: 1.7002 - accuracy: 0.55 - ETA: 3:50 - loss: 1.6920 - accuracy: 0.55 - ETA: 3:49 - loss: 1.7000 - accuracy: 0.55 - ETA: 3:46 - loss: 1.7073 - accuracy: 0.55 - ETA: 3:44 - loss: 1.7045 - accuracy: 0.55 - ETA: 3:42 - loss: 1.6990 - accuracy: 0.55 - ETA: 3:40 - loss: 1.6984 - accuracy: 0.55 - ETA: 3:38 - loss: 1.7016 - accuracy: 0.55 - ETA: 3:36 - loss: 1.7051 - accuracy: 0.54 - ETA: 3:34 - loss: 1.7032 - accuracy: 0.54 - ETA: 3:32 - loss: 1.7066 - accuracy: 0.54 - ETA: 3:30 - loss: 1.7045 - accuracy: 0.54 - ETA: 3:27 - loss: 1.6987 - accuracy: 0.54 - ETA: 3:25 - loss: 1.7057 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7052 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7081 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7070 - accuracy: 0.54 - ETA: 3:17 - loss: 1.7122 - accuracy: 0.54 - ETA: 3:15 - loss: 1.7106 - accuracy: 0.54 - ETA: 3:13 - loss: 1.7069 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7107 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7148 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7165 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7189 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7161 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7140 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7113 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7176 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7160 - accuracy: 0.54 - ETA: 2:51 - loss: 1.7160 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7144 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7141 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7145 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7152 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7172 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7197 - accuracy: 0.54 - ETA: 2:37 - loss: 1.7203 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7254 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7251 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7229 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7199 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7223 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7246 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7262 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7254 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7276 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7259 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7257 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7251 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7237 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7229 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7245 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7297 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7306 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7369 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7436 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7451 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7462 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7455 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7476 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7481 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7478 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7473 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7470 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7467 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7455 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7450 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7461 - accuracy: 0.53 - ETA: 1:30 - loss: 1.7440 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7428 - accuracy: 0.53 - ETA: 1:26 - loss: 1.7428 - accuracy: 0.53 - ETA: 1:24 - loss: 1.7437 - accuracy: 0.53 - ETA: 1:22 - loss: 1.7442 - accuracy: 0.53 - ETA: 1:20 - loss: 1.7432 - accuracy: 0.53 - ETA: 1:18 - loss: 1.7422 - accuracy: 0.53 - ETA: 1:16 - loss: 1.7508 - accuracy: 0.53 - ETA: 1:13 - loss: 1.7455 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7485 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7492 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7469 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7467 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7491 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7495 - accuracy: 0.54 - ETA: 59s - loss: 1.7503 - accuracy: 0.5399 - ETA: 56s - loss: 1.7514 - accuracy: 0.539 - ETA: 54s - loss: 1.7537 - accuracy: 0.539 - ETA: 52s - loss: 1.7531 - accuracy: 0.539 - ETA: 50s - loss: 1.7542 - accuracy: 0.539 - ETA: 48s - loss: 1.7518 - accuracy: 0.539 - ETA: 46s - loss: 1.7548 - accuracy: 0.539 - ETA: 44s - loss: 1.7546 - accuracy: 0.539 - ETA: 42s - loss: 1.7594 - accuracy: 0.539 - ETA: 39s - loss: 1.7596 - accuracy: 0.539 - ETA: 37s - loss: 1.7574 - accuracy: 0.540 - ETA: 35s - loss: 1.7575 - accuracy: 0.540 - ETA: 33s - loss: 1.7576 - accuracy: 0.540 - ETA: 31s - loss: 1.7578 - accuracy: 0.539 - ETA: 29s - loss: 1.7595 - accuracy: 0.539 - ETA: 27s - loss: 1.7588 - accuracy: 0.539 - ETA: 25s - loss: 1.7577 - accuracy: 0.540 - ETA: 23s - loss: 1.7586 - accuracy: 0.539 - ETA: 20s - loss: 1.7572 - accuracy: 0.540 - ETA: 18s - loss: 1.7615 - accuracy: 0.539 - ETA: 16s - loss: 1.7597 - accuracy: 0.539 - ETA: 14s - loss: 1.7599 - accuracy: 0.539 - ETA: 12s - loss: 1.7568 - accuracy: 0.540 - ETA: 10s - loss: 1.7546 - accuracy: 0.541 - ETA: 8s - loss: 1.7554 - accuracy: 0.541 - ETA: 6s - loss: 1.7535 - accuracy: 0.54 - ETA: 3s - loss: 1.7526 - accuracy: 0.54 - ETA: 1s - loss: 1.7521 - accuracy: 0.54 - 345s 18ms/step - loss: 1.7510 - accuracy: 0.5418 - val_loss: 2.2086 - val_accuracy: 0.5941\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:22 - loss: 1.4484 - accuracy: 0.57 - ETA: 5:16 - loss: 1.6546 - accuracy: 0.53 - ETA: 5:15 - loss: 1.6248 - accuracy: 0.54 - ETA: 5:11 - loss: 1.6557 - accuracy: 0.53 - ETA: 5:07 - loss: 1.6401 - accuracy: 0.54 - ETA: 5:03 - loss: 1.6623 - accuracy: 0.54 - ETA: 4:59 - loss: 1.6636 - accuracy: 0.55 - ETA: 4:59 - loss: 1.6295 - accuracy: 0.55 - ETA: 4:56 - loss: 1.6376 - accuracy: 0.55 - ETA: 4:56 - loss: 1.6405 - accuracy: 0.55 - ETA: 4:54 - loss: 1.6265 - accuracy: 0.55 - ETA: 4:52 - loss: 1.6263 - accuracy: 0.55 - ETA: 4:49 - loss: 1.6587 - accuracy: 0.54 - ETA: 4:46 - loss: 1.6745 - accuracy: 0.54 - ETA: 4:44 - loss: 1.6737 - accuracy: 0.54 - ETA: 4:41 - loss: 1.6702 - accuracy: 0.55 - ETA: 4:39 - loss: 1.6697 - accuracy: 0.55 - ETA: 4:37 - loss: 1.6747 - accuracy: 0.54 - ETA: 4:34 - loss: 1.6689 - accuracy: 0.55 - ETA: 4:34 - loss: 1.6822 - accuracy: 0.54 - ETA: 4:32 - loss: 1.6671 - accuracy: 0.55 - ETA: 4:30 - loss: 1.6801 - accuracy: 0.54 - ETA: 4:29 - loss: 1.6725 - accuracy: 0.54 - ETA: 4:27 - loss: 1.6708 - accuracy: 0.55 - ETA: 4:25 - loss: 1.6971 - accuracy: 0.55 - ETA: 4:23 - loss: 1.6904 - accuracy: 0.55 - ETA: 4:21 - loss: 1.6903 - accuracy: 0.55 - ETA: 4:19 - loss: 1.6808 - accuracy: 0.55 - ETA: 4:17 - loss: 1.6889 - accuracy: 0.55 - ETA: 4:15 - loss: 1.6881 - accuracy: 0.55 - ETA: 4:13 - loss: 1.6859 - accuracy: 0.55 - ETA: 4:11 - loss: 1.6811 - accuracy: 0.55 - ETA: 4:08 - loss: 1.6846 - accuracy: 0.55 - ETA: 4:06 - loss: 1.6933 - accuracy: 0.55 - ETA: 4:04 - loss: 1.6842 - accuracy: 0.55 - ETA: 4:02 - loss: 1.6773 - accuracy: 0.55 - ETA: 4:00 - loss: 1.6767 - accuracy: 0.55 - ETA: 3:58 - loss: 1.6857 - accuracy: 0.55 - ETA: 3:56 - loss: 1.6882 - accuracy: 0.55 - ETA: 3:53 - loss: 1.6932 - accuracy: 0.55 - ETA: 3:52 - loss: 1.6998 - accuracy: 0.55 - ETA: 3:50 - loss: 1.6958 - accuracy: 0.55 - ETA: 3:48 - loss: 1.6874 - accuracy: 0.55 - ETA: 3:46 - loss: 1.6986 - accuracy: 0.55 - ETA: 3:44 - loss: 1.6998 - accuracy: 0.55 - ETA: 3:41 - loss: 1.7027 - accuracy: 0.55 - ETA: 3:39 - loss: 1.7007 - accuracy: 0.55 - ETA: 3:37 - loss: 1.7036 - accuracy: 0.54 - ETA: 3:35 - loss: 1.7107 - accuracy: 0.54 - ETA: 3:33 - loss: 1.7114 - accuracy: 0.54 - ETA: 3:31 - loss: 1.7110 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7169 - accuracy: 0.54 - ETA: 3:27 - loss: 1.7211 - accuracy: 0.54 - ETA: 3:25 - loss: 1.7281 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7255 - accuracy: 0.54 - ETA: 3:20 - loss: 1.7290 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7295 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7303 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7264 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7293 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7304 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7458 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7426 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7398 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7364 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7375 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7359 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7362 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7413 - accuracy: 0.54 - ETA: 2:50 - loss: 1.7438 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7471 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7426 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7394 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7412 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7437 - accuracy: 0.54 - ETA: 2:37 - loss: 1.7433 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7429 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7434 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7451 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7436 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7459 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7433 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7394 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7357 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7366 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7355 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7393 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7423 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7469 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7462 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7444 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7421 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7414 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7395 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7380 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7401 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7387 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7390 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7391 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7365 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7382 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7376 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7375 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7391 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7381 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7370 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7354 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7356 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7337 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7346 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7331 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7315 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7310 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7322 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7315 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7306 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7302 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7294 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7296 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7296 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7278 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7277 - accuracy: 0.54 - ETA: 58s - loss: 1.7266 - accuracy: 0.5478 - ETA: 56s - loss: 1.7276 - accuracy: 0.547 - ETA: 54s - loss: 1.7277 - accuracy: 0.547 - ETA: 52s - loss: 1.7269 - accuracy: 0.547 - ETA: 50s - loss: 1.7256 - accuracy: 0.547 - ETA: 48s - loss: 1.7237 - accuracy: 0.548 - ETA: 46s - loss: 1.7234 - accuracy: 0.548 - ETA: 44s - loss: 1.7244 - accuracy: 0.548 - ETA: 41s - loss: 1.7257 - accuracy: 0.548 - ETA: 39s - loss: 1.7242 - accuracy: 0.548 - ETA: 37s - loss: 1.7259 - accuracy: 0.548 - ETA: 35s - loss: 1.7255 - accuracy: 0.547 - ETA: 33s - loss: 1.7256 - accuracy: 0.547 - ETA: 31s - loss: 1.7251 - accuracy: 0.547 - ETA: 29s - loss: 1.7254 - accuracy: 0.547 - ETA: 27s - loss: 1.7239 - accuracy: 0.547 - ETA: 25s - loss: 1.7231 - accuracy: 0.547 - ETA: 23s - loss: 1.7237 - accuracy: 0.546 - ETA: 20s - loss: 1.7239 - accuracy: 0.546 - ETA: 18s - loss: 1.7252 - accuracy: 0.546 - ETA: 16s - loss: 1.7238 - accuracy: 0.546 - ETA: 14s - loss: 1.7235 - accuracy: 0.546 - ETA: 12s - loss: 1.7214 - accuracy: 0.546 - ETA: 10s - loss: 1.7207 - accuracy: 0.547 - ETA: 8s - loss: 1.7208 - accuracy: 0.547 - ETA: 6s - loss: 1.7198 - accuracy: 0.54 - ETA: 3s - loss: 1.7194 - accuracy: 0.54 - ETA: 1s - loss: 1.7178 - accuracy: 0.54 - 343s 18ms/step - loss: 1.7196 - accuracy: 0.5473 - val_loss: 2.1721 - val_accuracy: 0.6022\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:33 - loss: 1.9179 - accuracy: 0.54 - ETA: 5:22 - loss: 1.7823 - accuracy: 0.58 - ETA: 5:12 - loss: 1.6595 - accuracy: 0.60 - ETA: 5:16 - loss: 1.6257 - accuracy: 0.59 - ETA: 5:10 - loss: 1.6527 - accuracy: 0.57 - ETA: 5:09 - loss: 1.6724 - accuracy: 0.56 - ETA: 5:05 - loss: 1.6886 - accuracy: 0.56 - ETA: 5:02 - loss: 1.7021 - accuracy: 0.55 - ETA: 4:59 - loss: 1.7154 - accuracy: 0.55 - ETA: 4:56 - loss: 1.7203 - accuracy: 0.55 - ETA: 4:55 - loss: 1.7207 - accuracy: 0.55 - ETA: 4:52 - loss: 1.7437 - accuracy: 0.54 - ETA: 4:50 - loss: 1.7427 - accuracy: 0.54 - ETA: 4:47 - loss: 1.7471 - accuracy: 0.54 - ETA: 4:44 - loss: 1.7315 - accuracy: 0.54 - ETA: 4:42 - loss: 1.7326 - accuracy: 0.54 - ETA: 4:41 - loss: 1.7338 - accuracy: 0.54 - ETA: 4:40 - loss: 1.7378 - accuracy: 0.54 - ETA: 4:37 - loss: 1.7248 - accuracy: 0.54 - ETA: 4:34 - loss: 1.7228 - accuracy: 0.54 - ETA: 4:33 - loss: 1.7282 - accuracy: 0.54 - ETA: 4:30 - loss: 1.7376 - accuracy: 0.54 - ETA: 4:28 - loss: 1.7212 - accuracy: 0.54 - ETA: 4:25 - loss: 1.7441 - accuracy: 0.54 - ETA: 4:23 - loss: 1.7261 - accuracy: 0.54 - ETA: 4:21 - loss: 1.7377 - accuracy: 0.54 - ETA: 4:19 - loss: 1.7342 - accuracy: 0.54 - ETA: 4:16 - loss: 1.7430 - accuracy: 0.54 - ETA: 4:14 - loss: 1.7445 - accuracy: 0.54 - ETA: 4:12 - loss: 1.7409 - accuracy: 0.54 - ETA: 4:10 - loss: 1.7328 - accuracy: 0.54 - ETA: 4:08 - loss: 1.7257 - accuracy: 0.54 - ETA: 4:06 - loss: 1.7156 - accuracy: 0.54 - ETA: 4:04 - loss: 1.7077 - accuracy: 0.55 - ETA: 4:02 - loss: 1.7084 - accuracy: 0.54 - ETA: 4:00 - loss: 1.7021 - accuracy: 0.55 - ETA: 3:58 - loss: 1.7006 - accuracy: 0.55 - ETA: 3:56 - loss: 1.7046 - accuracy: 0.55 - ETA: 3:54 - loss: 1.7051 - accuracy: 0.55 - ETA: 3:53 - loss: 1.7011 - accuracy: 0.55 - ETA: 3:50 - loss: 1.7026 - accuracy: 0.55 - ETA: 3:49 - loss: 1.7054 - accuracy: 0.55 - ETA: 3:47 - loss: 1.7043 - accuracy: 0.55 - ETA: 3:45 - loss: 1.6971 - accuracy: 0.55 - ETA: 3:43 - loss: 1.7011 - accuracy: 0.55 - ETA: 3:41 - loss: 1.7023 - accuracy: 0.55 - ETA: 3:39 - loss: 1.7047 - accuracy: 0.55 - ETA: 3:37 - loss: 1.6993 - accuracy: 0.55 - ETA: 3:34 - loss: 1.6972 - accuracy: 0.55 - ETA: 3:32 - loss: 1.6905 - accuracy: 0.55 - ETA: 3:30 - loss: 1.6875 - accuracy: 0.55 - ETA: 3:28 - loss: 1.6871 - accuracy: 0.55 - ETA: 3:25 - loss: 1.6895 - accuracy: 0.55 - ETA: 3:23 - loss: 1.6850 - accuracy: 0.55 - ETA: 3:21 - loss: 1.6871 - accuracy: 0.55 - ETA: 3:19 - loss: 1.6902 - accuracy: 0.55 - ETA: 3:17 - loss: 1.6958 - accuracy: 0.54 - ETA: 3:15 - loss: 1.6961 - accuracy: 0.54 - ETA: 3:13 - loss: 1.6959 - accuracy: 0.54 - ETA: 3:11 - loss: 1.6960 - accuracy: 0.54 - ETA: 3:09 - loss: 1.6990 - accuracy: 0.54 - ETA: 3:07 - loss: 1.6974 - accuracy: 0.54 - ETA: 3:05 - loss: 1.6989 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7063 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7028 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7091 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7098 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7064 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7080 - accuracy: 0.55 - ETA: 2:49 - loss: 1.7117 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7111 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7075 - accuracy: 0.55 - ETA: 2:43 - loss: 1.7068 - accuracy: 0.55 - ETA: 2:41 - loss: 1.7124 - accuracy: 0.55 - ETA: 2:39 - loss: 1.7119 - accuracy: 0.55 - ETA: 2:37 - loss: 1.7123 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7113 - accuracy: 0.55 - ETA: 2:33 - loss: 1.7101 - accuracy: 0.55 - ETA: 2:31 - loss: 1.7103 - accuracy: 0.55 - ETA: 2:29 - loss: 1.7097 - accuracy: 0.55 - ETA: 2:27 - loss: 1.7082 - accuracy: 0.55 - ETA: 2:25 - loss: 1.7183 - accuracy: 0.54 - ETA: 2:22 - loss: 1.7194 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7206 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7187 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7176 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7203 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7241 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7228 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7208 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7198 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7199 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7215 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7278 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7320 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7299 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7312 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7328 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7322 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7315 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7290 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7279 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7284 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7281 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7269 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7253 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7244 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7232 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7216 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7207 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7209 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7202 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7262 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7238 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7233 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7262 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7257 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7239 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7222 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7265 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7264 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7252 - accuracy: 0.54 - ETA: 58s - loss: 1.7251 - accuracy: 0.5487 - ETA: 56s - loss: 1.7245 - accuracy: 0.549 - ETA: 54s - loss: 1.7245 - accuracy: 0.549 - ETA: 52s - loss: 1.7264 - accuracy: 0.548 - ETA: 50s - loss: 1.7287 - accuracy: 0.548 - ETA: 48s - loss: 1.7298 - accuracy: 0.548 - ETA: 46s - loss: 1.7282 - accuracy: 0.548 - ETA: 43s - loss: 1.7295 - accuracy: 0.548 - ETA: 41s - loss: 1.7295 - accuracy: 0.548 - ETA: 39s - loss: 1.7285 - accuracy: 0.548 - ETA: 37s - loss: 1.7280 - accuracy: 0.548 - ETA: 35s - loss: 1.7278 - accuracy: 0.547 - ETA: 33s - loss: 1.7284 - accuracy: 0.547 - ETA: 31s - loss: 1.7258 - accuracy: 0.548 - ETA: 29s - loss: 1.7267 - accuracy: 0.547 - ETA: 27s - loss: 1.7265 - accuracy: 0.547 - ETA: 25s - loss: 1.7254 - accuracy: 0.547 - ETA: 22s - loss: 1.7253 - accuracy: 0.547 - ETA: 20s - loss: 1.7253 - accuracy: 0.547 - ETA: 18s - loss: 1.7261 - accuracy: 0.547 - ETA: 16s - loss: 1.7270 - accuracy: 0.547 - ETA: 14s - loss: 1.7280 - accuracy: 0.546 - ETA: 12s - loss: 1.7270 - accuracy: 0.547 - ETA: 10s - loss: 1.7242 - accuracy: 0.547 - ETA: 8s - loss: 1.7245 - accuracy: 0.547 - ETA: 6s - loss: 1.7231 - accuracy: 0.54 - ETA: 3s - loss: 1.7253 - accuracy: 0.54 - ETA: 1s - loss: 1.7288 - accuracy: 0.54 - 343s 18ms/step - loss: 1.7319 - accuracy: 0.5466 - val_loss: 2.1699 - val_accuracy: 0.5960\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:16 - loss: 1.6077 - accuracy: 0.57 - ETA: 5:18 - loss: 1.5903 - accuracy: 0.57 - ETA: 5:17 - loss: 1.5156 - accuracy: 0.58 - ETA: 5:11 - loss: 1.6343 - accuracy: 0.55 - ETA: 5:11 - loss: 1.6954 - accuracy: 0.54 - ETA: 5:06 - loss: 1.6320 - accuracy: 0.56 - ETA: 5:03 - loss: 1.6657 - accuracy: 0.55 - ETA: 4:59 - loss: 1.7176 - accuracy: 0.54 - ETA: 4:58 - loss: 1.6951 - accuracy: 0.55 - ETA: 4:56 - loss: 1.7008 - accuracy: 0.54 - ETA: 4:53 - loss: 1.6910 - accuracy: 0.54 - ETA: 4:50 - loss: 1.7873 - accuracy: 0.55 - ETA: 4:48 - loss: 1.7914 - accuracy: 0.55 - ETA: 4:47 - loss: 1.7882 - accuracy: 0.55 - ETA: 4:45 - loss: 1.7839 - accuracy: 0.55 - ETA: 4:43 - loss: 1.7470 - accuracy: 0.56 - ETA: 4:41 - loss: 1.7374 - accuracy: 0.56 - ETA: 4:37 - loss: 1.7356 - accuracy: 0.56 - ETA: 4:35 - loss: 1.7382 - accuracy: 0.56 - ETA: 4:33 - loss: 1.7414 - accuracy: 0.56 - ETA: 4:31 - loss: 1.7297 - accuracy: 0.56 - ETA: 4:29 - loss: 1.7286 - accuracy: 0.56 - ETA: 4:27 - loss: 1.7144 - accuracy: 0.56 - ETA: 4:25 - loss: 1.7126 - accuracy: 0.56 - ETA: 4:23 - loss: 1.7024 - accuracy: 0.56 - ETA: 4:21 - loss: 1.6957 - accuracy: 0.56 - ETA: 4:19 - loss: 1.6984 - accuracy: 0.56 - ETA: 4:17 - loss: 1.7210 - accuracy: 0.56 - ETA: 4:14 - loss: 1.7170 - accuracy: 0.56 - ETA: 4:12 - loss: 1.7294 - accuracy: 0.56 - ETA: 4:10 - loss: 1.7285 - accuracy: 0.56 - ETA: 4:08 - loss: 1.7257 - accuracy: 0.56 - ETA: 4:06 - loss: 1.7195 - accuracy: 0.56 - ETA: 4:04 - loss: 1.7300 - accuracy: 0.56 - ETA: 4:03 - loss: 1.7297 - accuracy: 0.56 - ETA: 4:01 - loss: 1.7262 - accuracy: 0.56 - ETA: 3:59 - loss: 1.7311 - accuracy: 0.55 - ETA: 3:57 - loss: 1.7396 - accuracy: 0.55 - ETA: 3:55 - loss: 1.7288 - accuracy: 0.55 - ETA: 3:53 - loss: 1.7225 - accuracy: 0.55 - ETA: 3:51 - loss: 1.7246 - accuracy: 0.55 - ETA: 3:49 - loss: 1.7253 - accuracy: 0.55 - ETA: 3:47 - loss: 1.7247 - accuracy: 0.55 - ETA: 3:44 - loss: 1.7171 - accuracy: 0.56 - ETA: 3:42 - loss: 1.7108 - accuracy: 0.56 - ETA: 3:40 - loss: 1.7162 - accuracy: 0.56 - ETA: 3:38 - loss: 1.7164 - accuracy: 0.56 - ETA: 3:36 - loss: 1.7153 - accuracy: 0.56 - ETA: 3:34 - loss: 1.7150 - accuracy: 0.56 - ETA: 3:32 - loss: 1.7132 - accuracy: 0.56 - ETA: 3:30 - loss: 1.7083 - accuracy: 0.56 - ETA: 3:28 - loss: 1.7056 - accuracy: 0.56 - ETA: 3:26 - loss: 1.7053 - accuracy: 0.56 - ETA: 3:24 - loss: 1.7065 - accuracy: 0.56 - ETA: 3:21 - loss: 1.7061 - accuracy: 0.56 - ETA: 3:19 - loss: 1.7067 - accuracy: 0.56 - ETA: 3:18 - loss: 1.7102 - accuracy: 0.56 - ETA: 3:16 - loss: 1.7056 - accuracy: 0.56 - ETA: 3:14 - loss: 1.7097 - accuracy: 0.56 - ETA: 3:12 - loss: 1.7088 - accuracy: 0.56 - ETA: 3:10 - loss: 1.7095 - accuracy: 0.56 - ETA: 3:08 - loss: 1.7088 - accuracy: 0.56 - ETA: 3:05 - loss: 1.7094 - accuracy: 0.55 - ETA: 3:03 - loss: 1.7133 - accuracy: 0.55 - ETA: 3:01 - loss: 1.7114 - accuracy: 0.55 - ETA: 2:59 - loss: 1.7096 - accuracy: 0.55 - ETA: 2:56 - loss: 1.7082 - accuracy: 0.55 - ETA: 2:54 - loss: 1.7072 - accuracy: 0.55 - ETA: 2:52 - loss: 1.7072 - accuracy: 0.55 - ETA: 2:50 - loss: 1.7117 - accuracy: 0.55 - ETA: 2:48 - loss: 1.7113 - accuracy: 0.55 - ETA: 2:46 - loss: 1.7100 - accuracy: 0.55 - ETA: 2:44 - loss: 1.7118 - accuracy: 0.55 - ETA: 2:42 - loss: 1.7126 - accuracy: 0.55 - ETA: 2:40 - loss: 1.7131 - accuracy: 0.55 - ETA: 2:38 - loss: 1.7108 - accuracy: 0.55 - ETA: 2:36 - loss: 1.7131 - accuracy: 0.55 - ETA: 2:33 - loss: 1.7112 - accuracy: 0.55 - ETA: 2:31 - loss: 1.7126 - accuracy: 0.55 - ETA: 2:29 - loss: 1.7125 - accuracy: 0.55 - ETA: 2:27 - loss: 1.7117 - accuracy: 0.55 - ETA: 2:25 - loss: 1.7142 - accuracy: 0.55 - ETA: 2:23 - loss: 1.7131 - accuracy: 0.55 - ETA: 2:21 - loss: 1.7146 - accuracy: 0.55 - ETA: 2:19 - loss: 1.7132 - accuracy: 0.55 - ETA: 2:17 - loss: 1.7132 - accuracy: 0.55 - ETA: 2:15 - loss: 1.7099 - accuracy: 0.55 - ETA: 2:12 - loss: 1.7074 - accuracy: 0.55 - ETA: 2:10 - loss: 1.7154 - accuracy: 0.55 - ETA: 2:08 - loss: 1.7145 - accuracy: 0.55 - ETA: 2:06 - loss: 1.7162 - accuracy: 0.55 - ETA: 2:04 - loss: 1.7196 - accuracy: 0.55 - ETA: 2:02 - loss: 1.7195 - accuracy: 0.55 - ETA: 2:00 - loss: 1.7215 - accuracy: 0.55 - ETA: 1:57 - loss: 1.7225 - accuracy: 0.55 - ETA: 1:55 - loss: 1.7227 - accuracy: 0.55 - ETA: 1:53 - loss: 1.7209 - accuracy: 0.55 - ETA: 1:51 - loss: 1.7200 - accuracy: 0.55 - ETA: 1:49 - loss: 1.7177 - accuracy: 0.55 - ETA: 1:47 - loss: 1.7200 - accuracy: 0.55 - ETA: 1:45 - loss: 1.7204 - accuracy: 0.55 - ETA: 1:43 - loss: 1.7210 - accuracy: 0.55 - ETA: 1:41 - loss: 1.7202 - accuracy: 0.55 - ETA: 1:38 - loss: 1.7201 - accuracy: 0.55 - ETA: 1:36 - loss: 1.7203 - accuracy: 0.55 - ETA: 1:34 - loss: 1.7213 - accuracy: 0.55 - ETA: 1:32 - loss: 1.7225 - accuracy: 0.55 - ETA: 1:30 - loss: 1.7227 - accuracy: 0.55 - ETA: 1:28 - loss: 1.7213 - accuracy: 0.55 - ETA: 1:26 - loss: 1.7222 - accuracy: 0.55 - ETA: 1:23 - loss: 1.7257 - accuracy: 0.55 - ETA: 1:21 - loss: 1.7250 - accuracy: 0.55 - ETA: 1:19 - loss: 1.7232 - accuracy: 0.55 - ETA: 1:17 - loss: 1.7230 - accuracy: 0.55 - ETA: 1:15 - loss: 1.7238 - accuracy: 0.55 - ETA: 1:13 - loss: 1.7223 - accuracy: 0.55 - ETA: 1:11 - loss: 1.7223 - accuracy: 0.55 - ETA: 1:09 - loss: 1.7222 - accuracy: 0.55 - ETA: 1:07 - loss: 1.7227 - accuracy: 0.55 - ETA: 1:05 - loss: 1.7238 - accuracy: 0.55 - ETA: 1:02 - loss: 1.7252 - accuracy: 0.55 - ETA: 1:00 - loss: 1.7248 - accuracy: 0.55 - ETA: 58s - loss: 1.7258 - accuracy: 0.5513 - ETA: 56s - loss: 1.7295 - accuracy: 0.550 - ETA: 54s - loss: 1.7285 - accuracy: 0.551 - ETA: 52s - loss: 1.7279 - accuracy: 0.551 - ETA: 50s - loss: 1.7289 - accuracy: 0.550 - ETA: 48s - loss: 1.7317 - accuracy: 0.550 - ETA: 46s - loss: 1.7316 - accuracy: 0.551 - ETA: 43s - loss: 1.7325 - accuracy: 0.551 - ETA: 41s - loss: 1.7326 - accuracy: 0.551 - ETA: 39s - loss: 1.7317 - accuracy: 0.551 - ETA: 37s - loss: 1.7355 - accuracy: 0.550 - ETA: 35s - loss: 1.7381 - accuracy: 0.550 - ETA: 33s - loss: 1.7387 - accuracy: 0.550 - ETA: 31s - loss: 1.7382 - accuracy: 0.550 - ETA: 29s - loss: 1.7380 - accuracy: 0.550 - ETA: 27s - loss: 1.7384 - accuracy: 0.550 - ETA: 24s - loss: 1.7440 - accuracy: 0.549 - ETA: 22s - loss: 1.7457 - accuracy: 0.548 - ETA: 20s - loss: 1.7438 - accuracy: 0.549 - ETA: 18s - loss: 1.7469 - accuracy: 0.548 - ETA: 16s - loss: 1.7473 - accuracy: 0.548 - ETA: 14s - loss: 1.7505 - accuracy: 0.549 - ETA: 12s - loss: 1.7505 - accuracy: 0.549 - ETA: 10s - loss: 1.7500 - accuracy: 0.549 - ETA: 8s - loss: 1.7530 - accuracy: 0.548 - ETA: 6s - loss: 1.7525 - accuracy: 0.54 - ETA: 3s - loss: 1.7531 - accuracy: 0.54 - ETA: 1s - loss: 1.7524 - accuracy: 0.54 - 342s 18ms/step - loss: 1.7517 - accuracy: 0.5487 - val_loss: 2.0494 - val_accuracy: 0.5939\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:01 - loss: 1.7131 - accuracy: 0.56 - ETA: 5:05 - loss: 1.5358 - accuracy: 0.57 - ETA: 5:00 - loss: 1.6249 - accuracy: 0.55 - ETA: 5:05 - loss: 1.6707 - accuracy: 0.54 - ETA: 5:03 - loss: 1.7038 - accuracy: 0.53 - ETA: 5:02 - loss: 1.6940 - accuracy: 0.53 - ETA: 5:01 - loss: 1.6725 - accuracy: 0.54 - ETA: 5:01 - loss: 1.7330 - accuracy: 0.53 - ETA: 4:58 - loss: 1.7393 - accuracy: 0.54 - ETA: 4:55 - loss: 1.7319 - accuracy: 0.54 - ETA: 4:53 - loss: 1.6984 - accuracy: 0.54 - ETA: 4:50 - loss: 1.6973 - accuracy: 0.55 - ETA: 4:47 - loss: 1.7357 - accuracy: 0.55 - ETA: 4:44 - loss: 1.7209 - accuracy: 0.55 - ETA: 4:41 - loss: 1.7208 - accuracy: 0.55 - ETA: 4:40 - loss: 1.7300 - accuracy: 0.54 - ETA: 4:38 - loss: 1.7266 - accuracy: 0.54 - ETA: 4:37 - loss: 1.7269 - accuracy: 0.54 - ETA: 4:35 - loss: 1.7252 - accuracy: 0.54 - ETA: 4:32 - loss: 1.7251 - accuracy: 0.54 - ETA: 4:31 - loss: 1.7404 - accuracy: 0.54 - ETA: 4:28 - loss: 1.7371 - accuracy: 0.55 - ETA: 4:29 - loss: 1.7274 - accuracy: 0.55 - ETA: 4:27 - loss: 1.7121 - accuracy: 0.55 - ETA: 4:25 - loss: 1.7070 - accuracy: 0.55 - ETA: 4:23 - loss: 1.7108 - accuracy: 0.55 - ETA: 4:21 - loss: 1.7124 - accuracy: 0.55 - ETA: 4:19 - loss: 1.7269 - accuracy: 0.55 - ETA: 4:17 - loss: 1.7215 - accuracy: 0.55 - ETA: 4:15 - loss: 1.7214 - accuracy: 0.55 - ETA: 4:14 - loss: 1.7134 - accuracy: 0.55 - ETA: 4:12 - loss: 1.6992 - accuracy: 0.55 - ETA: 4:10 - loss: 1.7048 - accuracy: 0.55 - ETA: 4:08 - loss: 1.7121 - accuracy: 0.55 - ETA: 4:06 - loss: 1.7239 - accuracy: 0.55 - ETA: 4:04 - loss: 1.7136 - accuracy: 0.55 - ETA: 4:02 - loss: 1.7130 - accuracy: 0.55 - ETA: 4:00 - loss: 1.7274 - accuracy: 0.55 - ETA: 3:58 - loss: 1.7326 - accuracy: 0.55 - ETA: 3:55 - loss: 1.7276 - accuracy: 0.55 - ETA: 3:53 - loss: 1.7261 - accuracy: 0.55 - ETA: 3:51 - loss: 1.7304 - accuracy: 0.55 - ETA: 3:49 - loss: 1.7296 - accuracy: 0.55 - ETA: 3:47 - loss: 1.7426 - accuracy: 0.55 - ETA: 3:44 - loss: 1.7428 - accuracy: 0.55 - ETA: 3:42 - loss: 1.7403 - accuracy: 0.55 - ETA: 3:40 - loss: 1.7375 - accuracy: 0.55 - ETA: 3:39 - loss: 1.7326 - accuracy: 0.55 - ETA: 3:37 - loss: 1.7333 - accuracy: 0.55 - ETA: 3:35 - loss: 1.7349 - accuracy: 0.55 - ETA: 3:33 - loss: 1.7339 - accuracy: 0.55 - ETA: 3:31 - loss: 1.7405 - accuracy: 0.55 - ETA: 3:29 - loss: 1.7448 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7409 - accuracy: 0.55 - ETA: 3:24 - loss: 1.7481 - accuracy: 0.54 - ETA: 3:22 - loss: 1.7462 - accuracy: 0.55 - ETA: 3:20 - loss: 1.7475 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7516 - accuracy: 0.55 - ETA: 3:15 - loss: 1.7585 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7546 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7534 - accuracy: 0.54 - ETA: 3:09 - loss: 1.7536 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7536 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7569 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7579 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7565 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7585 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7697 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7707 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7713 - accuracy: 0.54 - ETA: 2:50 - loss: 1.7742 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7698 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7665 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7969 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7963 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7919 - accuracy: 0.54 - ETA: 2:37 - loss: 1.7883 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7851 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7813 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7890 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7871 - accuracy: 0.54 - ETA: 2:26 - loss: 1.8113 - accuracy: 0.54 - ETA: 2:24 - loss: 1.8069 - accuracy: 0.54 - ETA: 2:22 - loss: 1.8072 - accuracy: 0.54 - ETA: 2:19 - loss: 1.8052 - accuracy: 0.54 - ETA: 2:17 - loss: 1.8061 - accuracy: 0.54 - ETA: 2:15 - loss: 1.8048 - accuracy: 0.54 - ETA: 2:13 - loss: 1.8038 - accuracy: 0.54 - ETA: 2:11 - loss: 1.8059 - accuracy: 0.54 - ETA: 2:08 - loss: 1.8031 - accuracy: 0.54 - ETA: 2:06 - loss: 1.8035 - accuracy: 0.54 - ETA: 2:04 - loss: 1.8014 - accuracy: 0.54 - ETA: 2:02 - loss: 1.8016 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7999 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7996 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7984 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7952 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7953 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7944 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7972 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7920 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7954 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7917 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7889 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7868 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7843 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7821 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7813 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7805 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7797 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7840 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7862 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7836 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7821 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7800 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7761 - accuracy: 0.55 - ETA: 1:11 - loss: 1.7751 - accuracy: 0.55 - ETA: 1:09 - loss: 1.7754 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7734 - accuracy: 0.55 - ETA: 1:05 - loss: 1.7756 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7761 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7772 - accuracy: 0.54 - ETA: 58s - loss: 1.7776 - accuracy: 0.5488 - ETA: 56s - loss: 1.7751 - accuracy: 0.549 - ETA: 54s - loss: 1.7759 - accuracy: 0.548 - ETA: 52s - loss: 1.7762 - accuracy: 0.548 - ETA: 50s - loss: 1.7757 - accuracy: 0.548 - ETA: 48s - loss: 1.7720 - accuracy: 0.548 - ETA: 46s - loss: 1.7702 - accuracy: 0.548 - ETA: 44s - loss: 1.7721 - accuracy: 0.548 - ETA: 42s - loss: 1.7707 - accuracy: 0.548 - ETA: 39s - loss: 1.7694 - accuracy: 0.548 - ETA: 37s - loss: 1.7687 - accuracy: 0.548 - ETA: 35s - loss: 1.7713 - accuracy: 0.548 - ETA: 33s - loss: 1.7691 - accuracy: 0.548 - ETA: 31s - loss: 1.7704 - accuracy: 0.548 - ETA: 29s - loss: 1.7699 - accuracy: 0.548 - ETA: 27s - loss: 1.7752 - accuracy: 0.548 - ETA: 25s - loss: 1.7747 - accuracy: 0.548 - ETA: 23s - loss: 1.7734 - accuracy: 0.548 - ETA: 20s - loss: 1.7721 - accuracy: 0.548 - ETA: 18s - loss: 1.7744 - accuracy: 0.547 - ETA: 16s - loss: 1.7742 - accuracy: 0.547 - ETA: 14s - loss: 1.7734 - accuracy: 0.547 - ETA: 12s - loss: 1.7729 - accuracy: 0.547 - ETA: 10s - loss: 1.7730 - accuracy: 0.547 - ETA: 8s - loss: 1.7755 - accuracy: 0.547 - ETA: 6s - loss: 1.7736 - accuracy: 0.54 - ETA: 3s - loss: 1.7808 - accuracy: 0.54 - ETA: 1s - loss: 1.7814 - accuracy: 0.54 - 344s 18ms/step - loss: 1.7820 - accuracy: 0.5468 - val_loss: 2.2492 - val_accuracy: 0.6020\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:58 - loss: 3.5135 - accuracy: 0.57 - ETA: 5:12 - loss: 2.5734 - accuracy: 0.57 - ETA: 5:14 - loss: 2.3268 - accuracy: 0.55 - ETA: 5:18 - loss: 2.2110 - accuracy: 0.53 - ETA: 5:12 - loss: 2.2258 - accuracy: 0.53 - ETA: 5:09 - loss: 2.1634 - accuracy: 0.52 - ETA: 5:06 - loss: 2.1799 - accuracy: 0.52 - ETA: 5:02 - loss: 2.0944 - accuracy: 0.52 - ETA: 5:00 - loss: 2.0689 - accuracy: 0.52 - ETA: 4:57 - loss: 2.0534 - accuracy: 0.52 - ETA: 4:54 - loss: 2.0199 - accuracy: 0.52 - ETA: 4:52 - loss: 1.9796 - accuracy: 0.53 - ETA: 4:51 - loss: 1.9698 - accuracy: 0.53 - ETA: 4:48 - loss: 1.9591 - accuracy: 0.53 - ETA: 4:43 - loss: 1.9566 - accuracy: 0.53 - ETA: 4:42 - loss: 1.9841 - accuracy: 0.53 - ETA: 4:40 - loss: 1.9761 - accuracy: 0.53 - ETA: 4:38 - loss: 1.9582 - accuracy: 0.53 - ETA: 4:36 - loss: 1.9560 - accuracy: 0.53 - ETA: 4:34 - loss: 1.9571 - accuracy: 0.53 - ETA: 4:32 - loss: 1.9778 - accuracy: 0.53 - ETA: 4:29 - loss: 1.9630 - accuracy: 0.53 - ETA: 4:27 - loss: 1.9455 - accuracy: 0.53 - ETA: 4:25 - loss: 1.9703 - accuracy: 0.53 - ETA: 4:23 - loss: 2.0466 - accuracy: 0.53 - ETA: 4:21 - loss: 2.0690 - accuracy: 0.53 - ETA: 4:19 - loss: 2.0586 - accuracy: 0.53 - ETA: 4:18 - loss: 2.0591 - accuracy: 0.53 - ETA: 4:16 - loss: 2.0607 - accuracy: 0.53 - ETA: 4:14 - loss: 2.0507 - accuracy: 0.53 - ETA: 4:12 - loss: 2.0418 - accuracy: 0.53 - ETA: 4:09 - loss: 2.0327 - accuracy: 0.53 - ETA: 4:08 - loss: 2.0229 - accuracy: 0.53 - ETA: 4:05 - loss: 2.0185 - accuracy: 0.53 - ETA: 4:03 - loss: 2.0184 - accuracy: 0.53 - ETA: 4:01 - loss: 2.0226 - accuracy: 0.53 - ETA: 3:59 - loss: 2.0098 - accuracy: 0.53 - ETA: 3:57 - loss: 2.0024 - accuracy: 0.53 - ETA: 3:55 - loss: 1.9940 - accuracy: 0.53 - ETA: 3:53 - loss: 1.9882 - accuracy: 0.53 - ETA: 3:51 - loss: 1.9855 - accuracy: 0.53 - ETA: 3:49 - loss: 1.9763 - accuracy: 0.53 - ETA: 3:47 - loss: 1.9695 - accuracy: 0.53 - ETA: 3:45 - loss: 1.9623 - accuracy: 0.53 - ETA: 3:43 - loss: 1.9531 - accuracy: 0.53 - ETA: 3:40 - loss: 1.9554 - accuracy: 0.53 - ETA: 3:38 - loss: 1.9545 - accuracy: 0.53 - ETA: 3:36 - loss: 1.9513 - accuracy: 0.53 - ETA: 3:34 - loss: 1.9452 - accuracy: 0.53 - ETA: 3:32 - loss: 1.9419 - accuracy: 0.53 - ETA: 3:30 - loss: 1.9434 - accuracy: 0.53 - ETA: 3:28 - loss: 1.9358 - accuracy: 0.53 - ETA: 3:26 - loss: 1.9330 - accuracy: 0.53 - ETA: 3:24 - loss: 1.9358 - accuracy: 0.53 - ETA: 3:22 - loss: 1.9296 - accuracy: 0.53 - ETA: 3:20 - loss: 1.9250 - accuracy: 0.53 - ETA: 3:18 - loss: 1.9173 - accuracy: 0.53 - ETA: 3:16 - loss: 1.9101 - accuracy: 0.53 - ETA: 3:13 - loss: 1.9001 - accuracy: 0.53 - ETA: 3:11 - loss: 1.8892 - accuracy: 0.54 - ETA: 3:09 - loss: 1.8926 - accuracy: 0.54 - ETA: 3:07 - loss: 1.8948 - accuracy: 0.53 - ETA: 3:05 - loss: 1.8939 - accuracy: 0.53 - ETA: 3:03 - loss: 1.8877 - accuracy: 0.53 - ETA: 3:01 - loss: 1.8920 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8890 - accuracy: 0.53 - ETA: 2:57 - loss: 1.9009 - accuracy: 0.53 - ETA: 2:54 - loss: 1.9188 - accuracy: 0.53 - ETA: 2:52 - loss: 1.9188 - accuracy: 0.53 - ETA: 2:50 - loss: 1.9170 - accuracy: 0.53 - ETA: 2:48 - loss: 1.9158 - accuracy: 0.53 - ETA: 2:46 - loss: 1.9175 - accuracy: 0.53 - ETA: 2:44 - loss: 1.9143 - accuracy: 0.53 - ETA: 2:42 - loss: 1.9083 - accuracy: 0.53 - ETA: 2:40 - loss: 1.9072 - accuracy: 0.53 - ETA: 2:38 - loss: 1.9062 - accuracy: 0.53 - ETA: 2:36 - loss: 1.9053 - accuracy: 0.53 - ETA: 2:33 - loss: 1.9122 - accuracy: 0.53 - ETA: 2:31 - loss: 1.9121 - accuracy: 0.53 - ETA: 2:29 - loss: 1.9105 - accuracy: 0.53 - ETA: 2:27 - loss: 1.9067 - accuracy: 0.53 - ETA: 2:25 - loss: 1.9050 - accuracy: 0.53 - ETA: 2:23 - loss: 1.9047 - accuracy: 0.53 - ETA: 2:21 - loss: 1.9054 - accuracy: 0.53 - ETA: 2:19 - loss: 1.9036 - accuracy: 0.53 - ETA: 2:17 - loss: 1.9025 - accuracy: 0.53 - ETA: 2:14 - loss: 1.9013 - accuracy: 0.53 - ETA: 2:12 - loss: 1.9024 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8989 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8974 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8959 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8967 - accuracy: 0.53 - ETA: 2:02 - loss: 1.9037 - accuracy: 0.53 - ETA: 2:00 - loss: 1.9025 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8986 - accuracy: 0.53 - ETA: 1:55 - loss: 1.8953 - accuracy: 0.53 - ETA: 1:53 - loss: 1.8943 - accuracy: 0.53 - ETA: 1:51 - loss: 1.8893 - accuracy: 0.53 - ETA: 1:49 - loss: 1.8861 - accuracy: 0.53 - ETA: 1:47 - loss: 1.8843 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8795 - accuracy: 0.53 - ETA: 1:43 - loss: 1.8785 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8806 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8777 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8730 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8689 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8690 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8695 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8671 - accuracy: 0.53 - ETA: 1:26 - loss: 1.8669 - accuracy: 0.53 - ETA: 1:24 - loss: 1.8685 - accuracy: 0.53 - ETA: 1:22 - loss: 1.8676 - accuracy: 0.53 - ETA: 1:20 - loss: 1.8644 - accuracy: 0.53 - ETA: 1:17 - loss: 1.8617 - accuracy: 0.53 - ETA: 1:15 - loss: 1.8613 - accuracy: 0.53 - ETA: 1:13 - loss: 1.8595 - accuracy: 0.53 - ETA: 1:11 - loss: 1.8550 - accuracy: 0.54 - ETA: 1:09 - loss: 1.8540 - accuracy: 0.54 - ETA: 1:07 - loss: 1.8538 - accuracy: 0.54 - ETA: 1:05 - loss: 1.8590 - accuracy: 0.54 - ETA: 1:03 - loss: 1.8561 - accuracy: 0.54 - ETA: 1:00 - loss: 1.8540 - accuracy: 0.54 - ETA: 58s - loss: 1.8530 - accuracy: 0.5417 - ETA: 56s - loss: 1.8552 - accuracy: 0.542 - ETA: 54s - loss: 1.8583 - accuracy: 0.541 - ETA: 52s - loss: 1.8610 - accuracy: 0.540 - ETA: 50s - loss: 1.8577 - accuracy: 0.541 - ETA: 48s - loss: 1.8531 - accuracy: 0.542 - ETA: 46s - loss: 1.8509 - accuracy: 0.542 - ETA: 44s - loss: 1.8516 - accuracy: 0.541 - ETA: 41s - loss: 1.8502 - accuracy: 0.542 - ETA: 39s - loss: 1.8504 - accuracy: 0.542 - ETA: 37s - loss: 1.8486 - accuracy: 0.542 - ETA: 35s - loss: 1.8467 - accuracy: 0.542 - ETA: 33s - loss: 1.8449 - accuracy: 0.542 - ETA: 31s - loss: 1.8460 - accuracy: 0.541 - ETA: 29s - loss: 1.8438 - accuracy: 0.541 - ETA: 27s - loss: 1.8442 - accuracy: 0.541 - ETA: 25s - loss: 1.8429 - accuracy: 0.541 - ETA: 22s - loss: 1.8392 - accuracy: 0.542 - ETA: 20s - loss: 1.8372 - accuracy: 0.542 - ETA: 18s - loss: 1.8374 - accuracy: 0.541 - ETA: 16s - loss: 1.8360 - accuracy: 0.541 - ETA: 14s - loss: 1.8330 - accuracy: 0.542 - ETA: 12s - loss: 1.8322 - accuracy: 0.541 - ETA: 10s - loss: 1.8301 - accuracy: 0.542 - ETA: 8s - loss: 1.8290 - accuracy: 0.542 - ETA: 6s - loss: 1.8285 - accuracy: 0.54 - ETA: 3s - loss: 1.8286 - accuracy: 0.54 - ETA: 1s - loss: 1.8265 - accuracy: 0.54 - 343s 18ms/step - loss: 1.8251 - accuracy: 0.5426 - val_loss: 2.0933 - val_accuracy: 0.5960\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:57 - loss: 1.7017 - accuracy: 0.55 - ETA: 5:05 - loss: 1.7651 - accuracy: 0.53 - ETA: 5:07 - loss: 1.6853 - accuracy: 0.53 - ETA: 5:07 - loss: 1.7379 - accuracy: 0.53 - ETA: 5:05 - loss: 1.6939 - accuracy: 0.54 - ETA: 5:06 - loss: 1.6786 - accuracy: 0.54 - ETA: 5:03 - loss: 1.6817 - accuracy: 0.53 - ETA: 5:02 - loss: 1.6760 - accuracy: 0.54 - ETA: 5:00 - loss: 1.6787 - accuracy: 0.54 - ETA: 4:57 - loss: 1.6869 - accuracy: 0.53 - ETA: 4:55 - loss: 1.6923 - accuracy: 0.53 - ETA: 4:53 - loss: 1.6985 - accuracy: 0.53 - ETA: 4:52 - loss: 1.7025 - accuracy: 0.53 - ETA: 4:49 - loss: 1.6899 - accuracy: 0.53 - ETA: 4:47 - loss: 1.7119 - accuracy: 0.53 - ETA: 4:45 - loss: 1.7098 - accuracy: 0.53 - ETA: 4:43 - loss: 1.7084 - accuracy: 0.53 - ETA: 4:40 - loss: 1.6993 - accuracy: 0.53 - ETA: 4:38 - loss: 1.7134 - accuracy: 0.53 - ETA: 4:34 - loss: 1.7325 - accuracy: 0.53 - ETA: 4:32 - loss: 1.7318 - accuracy: 0.53 - ETA: 4:30 - loss: 1.7315 - accuracy: 0.53 - ETA: 4:28 - loss: 1.7230 - accuracy: 0.53 - ETA: 4:26 - loss: 1.7332 - accuracy: 0.53 - ETA: 4:24 - loss: 1.7581 - accuracy: 0.53 - ETA: 4:22 - loss: 1.7488 - accuracy: 0.53 - ETA: 4:20 - loss: 1.7582 - accuracy: 0.53 - ETA: 4:18 - loss: 1.7537 - accuracy: 0.53 - ETA: 4:16 - loss: 1.7530 - accuracy: 0.53 - ETA: 4:14 - loss: 1.7653 - accuracy: 0.53 - ETA: 4:12 - loss: 1.7668 - accuracy: 0.52 - ETA: 4:10 - loss: 1.7629 - accuracy: 0.53 - ETA: 4:07 - loss: 1.7671 - accuracy: 0.53 - ETA: 4:06 - loss: 1.7629 - accuracy: 0.52 - ETA: 4:03 - loss: 1.7585 - accuracy: 0.52 - ETA: 4:01 - loss: 1.7524 - accuracy: 0.53 - ETA: 3:59 - loss: 1.7434 - accuracy: 0.53 - ETA: 3:56 - loss: 1.7406 - accuracy: 0.53 - ETA: 3:54 - loss: 1.7366 - accuracy: 0.53 - ETA: 3:52 - loss: 1.7413 - accuracy: 0.53 - ETA: 3:50 - loss: 1.7377 - accuracy: 0.53 - ETA: 3:48 - loss: 1.7366 - accuracy: 0.53 - ETA: 3:46 - loss: 1.7431 - accuracy: 0.53 - ETA: 3:44 - loss: 1.7468 - accuracy: 0.53 - ETA: 3:41 - loss: 1.7412 - accuracy: 0.53 - ETA: 3:39 - loss: 1.7381 - accuracy: 0.53 - ETA: 3:37 - loss: 1.7383 - accuracy: 0.53 - ETA: 3:35 - loss: 1.7392 - accuracy: 0.53 - ETA: 3:33 - loss: 1.7337 - accuracy: 0.53 - ETA: 3:31 - loss: 1.7333 - accuracy: 0.53 - ETA: 3:29 - loss: 1.7347 - accuracy: 0.53 - ETA: 3:27 - loss: 1.7373 - accuracy: 0.53 - ETA: 3:25 - loss: 1.7443 - accuracy: 0.53 - ETA: 3:22 - loss: 1.7425 - accuracy: 0.53 - ETA: 3:20 - loss: 1.7436 - accuracy: 0.53 - ETA: 3:18 - loss: 1.7507 - accuracy: 0.53 - ETA: 3:17 - loss: 1.7461 - accuracy: 0.53 - ETA: 3:14 - loss: 1.7440 - accuracy: 0.53 - ETA: 3:12 - loss: 1.7438 - accuracy: 0.53 - ETA: 3:10 - loss: 1.7414 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7477 - accuracy: 0.53 - ETA: 3:06 - loss: 1.7556 - accuracy: 0.53 - ETA: 3:04 - loss: 1.7559 - accuracy: 0.53 - ETA: 3:02 - loss: 1.7538 - accuracy: 0.53 - ETA: 3:00 - loss: 1.7522 - accuracy: 0.53 - ETA: 2:58 - loss: 1.7548 - accuracy: 0.53 - ETA: 2:56 - loss: 1.7615 - accuracy: 0.53 - ETA: 2:54 - loss: 1.7632 - accuracy: 0.53 - ETA: 2:52 - loss: 1.7708 - accuracy: 0.53 - ETA: 2:50 - loss: 1.7680 - accuracy: 0.53 - ETA: 2:47 - loss: 1.7656 - accuracy: 0.53 - ETA: 2:45 - loss: 1.7657 - accuracy: 0.53 - ETA: 2:43 - loss: 1.7619 - accuracy: 0.53 - ETA: 2:41 - loss: 1.7621 - accuracy: 0.53 - ETA: 2:39 - loss: 1.7657 - accuracy: 0.53 - ETA: 2:37 - loss: 1.7609 - accuracy: 0.53 - ETA: 2:35 - loss: 1.7608 - accuracy: 0.53 - ETA: 2:33 - loss: 1.7598 - accuracy: 0.53 - ETA: 2:31 - loss: 1.7590 - accuracy: 0.53 - ETA: 2:29 - loss: 1.7650 - accuracy: 0.53 - ETA: 2:27 - loss: 1.7658 - accuracy: 0.53 - ETA: 2:24 - loss: 1.7660 - accuracy: 0.53 - ETA: 2:22 - loss: 1.7724 - accuracy: 0.53 - ETA: 2:20 - loss: 1.7838 - accuracy: 0.53 - ETA: 2:18 - loss: 1.7824 - accuracy: 0.53 - ETA: 2:16 - loss: 1.7862 - accuracy: 0.53 - ETA: 2:14 - loss: 1.7915 - accuracy: 0.53 - ETA: 2:12 - loss: 1.7968 - accuracy: 0.53 - ETA: 2:10 - loss: 1.7951 - accuracy: 0.53 - ETA: 2:07 - loss: 1.7951 - accuracy: 0.53 - ETA: 2:05 - loss: 1.7958 - accuracy: 0.53 - ETA: 2:03 - loss: 1.7962 - accuracy: 0.53 - ETA: 2:01 - loss: 1.7963 - accuracy: 0.53 - ETA: 1:59 - loss: 1.7940 - accuracy: 0.53 - ETA: 1:57 - loss: 1.7956 - accuracy: 0.53 - ETA: 1:55 - loss: 1.7967 - accuracy: 0.53 - ETA: 1:53 - loss: 1.7970 - accuracy: 0.53 - ETA: 1:51 - loss: 1.7970 - accuracy: 0.53 - ETA: 1:48 - loss: 1.8035 - accuracy: 0.53 - ETA: 1:46 - loss: 1.8039 - accuracy: 0.53 - ETA: 1:44 - loss: 1.8009 - accuracy: 0.53 - ETA: 1:42 - loss: 1.7985 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8001 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8004 - accuracy: 0.53 - ETA: 1:36 - loss: 1.8026 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8015 - accuracy: 0.53 - ETA: 1:32 - loss: 1.7997 - accuracy: 0.53 - ETA: 1:29 - loss: 1.7988 - accuracy: 0.53 - ETA: 1:27 - loss: 1.7962 - accuracy: 0.53 - ETA: 1:25 - loss: 1.7968 - accuracy: 0.53 - ETA: 1:23 - loss: 1.7967 - accuracy: 0.53 - ETA: 1:21 - loss: 1.7976 - accuracy: 0.53 - ETA: 1:19 - loss: 1.7982 - accuracy: 0.53 - ETA: 1:17 - loss: 1.7958 - accuracy: 0.53 - ETA: 1:15 - loss: 1.7950 - accuracy: 0.53 - ETA: 1:13 - loss: 1.7930 - accuracy: 0.53 - ETA: 1:11 - loss: 1.7934 - accuracy: 0.53 - ETA: 1:08 - loss: 1.7914 - accuracy: 0.53 - ETA: 1:06 - loss: 1.7917 - accuracy: 0.53 - ETA: 1:04 - loss: 1.7916 - accuracy: 0.53 - ETA: 1:02 - loss: 1.7897 - accuracy: 0.53 - ETA: 1:00 - loss: 1.7914 - accuracy: 0.53 - ETA: 58s - loss: 1.7920 - accuracy: 0.5387 - ETA: 56s - loss: 1.7916 - accuracy: 0.538 - ETA: 54s - loss: 1.7889 - accuracy: 0.539 - ETA: 52s - loss: 1.7873 - accuracy: 0.539 - ETA: 50s - loss: 1.7848 - accuracy: 0.539 - ETA: 48s - loss: 1.7844 - accuracy: 0.539 - ETA: 45s - loss: 1.7834 - accuracy: 0.539 - ETA: 43s - loss: 1.7843 - accuracy: 0.539 - ETA: 41s - loss: 1.7825 - accuracy: 0.539 - ETA: 39s - loss: 1.7833 - accuracy: 0.539 - ETA: 37s - loss: 1.7848 - accuracy: 0.539 - ETA: 35s - loss: 1.7832 - accuracy: 0.539 - ETA: 33s - loss: 1.7833 - accuracy: 0.539 - ETA: 31s - loss: 1.7819 - accuracy: 0.540 - ETA: 29s - loss: 1.7818 - accuracy: 0.539 - ETA: 27s - loss: 1.7800 - accuracy: 0.540 - ETA: 24s - loss: 1.7769 - accuracy: 0.541 - ETA: 22s - loss: 1.7775 - accuracy: 0.540 - ETA: 20s - loss: 1.7776 - accuracy: 0.540 - ETA: 18s - loss: 1.7756 - accuracy: 0.540 - ETA: 16s - loss: 1.7769 - accuracy: 0.540 - ETA: 14s - loss: 1.7744 - accuracy: 0.541 - ETA: 12s - loss: 1.7744 - accuracy: 0.541 - ETA: 10s - loss: 1.7775 - accuracy: 0.541 - ETA: 8s - loss: 1.7785 - accuracy: 0.541 - ETA: 6s - loss: 1.7782 - accuracy: 0.54 - ETA: 3s - loss: 1.7779 - accuracy: 0.54 - ETA: 1s - loss: 1.7773 - accuracy: 0.54 - 343s 18ms/step - loss: 1.7776 - accuracy: 0.5410 - val_loss: 2.2292 - val_accuracy: 0.5931\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:09 - loss: 1.7585 - accuracy: 0.49 - ETA: 5:08 - loss: 2.0129 - accuracy: 0.46 - ETA: 5:08 - loss: 1.9817 - accuracy: 0.48 - ETA: 5:04 - loss: 1.9124 - accuracy: 0.49 - ETA: 5:01 - loss: 1.9426 - accuracy: 0.50 - ETA: 5:02 - loss: 1.9533 - accuracy: 0.50 - ETA: 5:01 - loss: 1.9050 - accuracy: 0.51 - ETA: 4:59 - loss: 1.8912 - accuracy: 0.52 - ETA: 4:57 - loss: 1.8541 - accuracy: 0.52 - ETA: 4:55 - loss: 1.8429 - accuracy: 0.52 - ETA: 4:53 - loss: 1.8496 - accuracy: 0.52 - ETA: 4:51 - loss: 1.8124 - accuracy: 0.53 - ETA: 4:50 - loss: 1.8106 - accuracy: 0.53 - ETA: 4:47 - loss: 1.8246 - accuracy: 0.53 - ETA: 4:46 - loss: 1.8093 - accuracy: 0.53 - ETA: 4:44 - loss: 1.8155 - accuracy: 0.53 - ETA: 4:42 - loss: 1.7871 - accuracy: 0.54 - ETA: 4:40 - loss: 1.7852 - accuracy: 0.54 - ETA: 4:39 - loss: 1.7673 - accuracy: 0.54 - ETA: 4:37 - loss: 1.7747 - accuracy: 0.54 - ETA: 4:35 - loss: 1.7667 - accuracy: 0.54 - ETA: 4:32 - loss: 1.7713 - accuracy: 0.54 - ETA: 4:30 - loss: 1.7692 - accuracy: 0.54 - ETA: 4:28 - loss: 1.7837 - accuracy: 0.54 - ETA: 4:26 - loss: 1.7893 - accuracy: 0.54 - ETA: 4:24 - loss: 1.7897 - accuracy: 0.54 - ETA: 4:22 - loss: 1.7924 - accuracy: 0.54 - ETA: 4:19 - loss: 1.7949 - accuracy: 0.54 - ETA: 4:17 - loss: 1.7936 - accuracy: 0.53 - ETA: 4:15 - loss: 1.7882 - accuracy: 0.53 - ETA: 4:13 - loss: 1.7871 - accuracy: 0.53 - ETA: 4:11 - loss: 1.7856 - accuracy: 0.54 - ETA: 4:09 - loss: 1.7855 - accuracy: 0.53 - ETA: 4:07 - loss: 1.7834 - accuracy: 0.53 - ETA: 4:04 - loss: 1.8011 - accuracy: 0.53 - ETA: 4:02 - loss: 1.7985 - accuracy: 0.53 - ETA: 4:00 - loss: 1.7974 - accuracy: 0.53 - ETA: 3:58 - loss: 1.7918 - accuracy: 0.53 - ETA: 3:56 - loss: 1.7869 - accuracy: 0.53 - ETA: 3:54 - loss: 1.7857 - accuracy: 0.53 - ETA: 3:52 - loss: 1.7810 - accuracy: 0.53 - ETA: 3:49 - loss: 1.7749 - accuracy: 0.54 - ETA: 3:47 - loss: 1.7651 - accuracy: 0.54 - ETA: 3:45 - loss: 1.7635 - accuracy: 0.54 - ETA: 3:43 - loss: 1.7679 - accuracy: 0.54 - ETA: 3:41 - loss: 1.7603 - accuracy: 0.54 - ETA: 3:38 - loss: 1.7657 - accuracy: 0.54 - ETA: 3:36 - loss: 1.7685 - accuracy: 0.54 - ETA: 3:34 - loss: 1.7638 - accuracy: 0.54 - ETA: 3:32 - loss: 1.7565 - accuracy: 0.54 - ETA: 3:30 - loss: 1.7576 - accuracy: 0.54 - ETA: 3:28 - loss: 1.7536 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7529 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7681 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7716 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7716 - accuracy: 0.54 - ETA: 3:17 - loss: 1.7757 - accuracy: 0.54 - ETA: 3:15 - loss: 1.7711 - accuracy: 0.54 - ETA: 3:13 - loss: 1.7709 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7691 - accuracy: 0.54 - ETA: 3:09 - loss: 1.7726 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7698 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7707 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7730 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7723 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7677 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7656 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7663 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7658 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7655 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7628 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7606 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7622 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7628 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7629 - accuracy: 0.54 - ETA: 2:37 - loss: 1.7586 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7641 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7598 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7525 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7494 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7494 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7495 - accuracy: 0.54 - ETA: 2:22 - loss: 1.7463 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7449 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7429 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7416 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7413 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7385 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7348 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7354 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7369 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7386 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7388 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7359 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7372 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7359 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7321 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7321 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7301 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7273 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7266 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7263 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7269 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7267 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7261 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7248 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7248 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7261 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7270 - accuracy: 0.55 - ETA: 1:26 - loss: 1.7331 - accuracy: 0.55 - ETA: 1:23 - loss: 1.7323 - accuracy: 0.55 - ETA: 1:21 - loss: 1.7329 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7324 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7376 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7381 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7402 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7378 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7334 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7350 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7374 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7357 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7349 - accuracy: 0.54 - ETA: 58s - loss: 1.7337 - accuracy: 0.5483 - ETA: 56s - loss: 1.7343 - accuracy: 0.548 - ETA: 54s - loss: 1.7353 - accuracy: 0.548 - ETA: 52s - loss: 1.7358 - accuracy: 0.548 - ETA: 50s - loss: 1.7354 - accuracy: 0.548 - ETA: 48s - loss: 1.7344 - accuracy: 0.549 - ETA: 45s - loss: 1.7321 - accuracy: 0.549 - ETA: 43s - loss: 1.7345 - accuracy: 0.548 - ETA: 41s - loss: 1.7336 - accuracy: 0.548 - ETA: 39s - loss: 1.7342 - accuracy: 0.548 - ETA: 37s - loss: 1.7333 - accuracy: 0.548 - ETA: 35s - loss: 1.7359 - accuracy: 0.548 - ETA: 33s - loss: 1.7384 - accuracy: 0.548 - ETA: 31s - loss: 1.7372 - accuracy: 0.548 - ETA: 29s - loss: 1.7350 - accuracy: 0.548 - ETA: 27s - loss: 1.7361 - accuracy: 0.548 - ETA: 25s - loss: 1.7358 - accuracy: 0.547 - ETA: 22s - loss: 1.7359 - accuracy: 0.547 - ETA: 20s - loss: 1.7367 - accuracy: 0.547 - ETA: 18s - loss: 1.7362 - accuracy: 0.547 - ETA: 16s - loss: 1.7378 - accuracy: 0.547 - ETA: 14s - loss: 1.7384 - accuracy: 0.547 - ETA: 12s - loss: 1.7407 - accuracy: 0.547 - ETA: 10s - loss: 1.7397 - accuracy: 0.547 - ETA: 8s - loss: 1.7400 - accuracy: 0.547 - ETA: 6s - loss: 1.7393 - accuracy: 0.54 - ETA: 3s - loss: 1.7390 - accuracy: 0.54 - ETA: 1s - loss: 1.7386 - accuracy: 0.54 - 343s 18ms/step - loss: 1.7368 - accuracy: 0.5477 - val_loss: 2.4217 - val_accuracy: 0.5954\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:59 - loss: 1.6464 - accuracy: 0.54 - ETA: 5:07 - loss: 1.5845 - accuracy: 0.57 - ETA: 5:06 - loss: 2.0265 - accuracy: 0.56 - ETA: 5:07 - loss: 1.9954 - accuracy: 0.56 - ETA: 5:05 - loss: 1.9759 - accuracy: 0.54 - ETA: 5:03 - loss: 1.9512 - accuracy: 0.54 - ETA: 5:02 - loss: 2.0373 - accuracy: 0.54 - ETA: 4:59 - loss: 2.0260 - accuracy: 0.54 - ETA: 4:56 - loss: 1.9741 - accuracy: 0.55 - ETA: 4:55 - loss: 1.9932 - accuracy: 0.53 - ETA: 4:52 - loss: 1.9655 - accuracy: 0.53 - ETA: 4:51 - loss: 1.9196 - accuracy: 0.54 - ETA: 4:49 - loss: 1.8968 - accuracy: 0.54 - ETA: 4:47 - loss: 1.9056 - accuracy: 0.53 - ETA: 4:45 - loss: 1.9029 - accuracy: 0.53 - ETA: 4:43 - loss: 1.8742 - accuracy: 0.53 - ETA: 4:41 - loss: 1.8648 - accuracy: 0.53 - ETA: 4:40 - loss: 1.8863 - accuracy: 0.53 - ETA: 4:38 - loss: 1.9031 - accuracy: 0.53 - ETA: 4:36 - loss: 1.9051 - accuracy: 0.53 - ETA: 4:34 - loss: 1.9414 - accuracy: 0.52 - ETA: 4:31 - loss: 1.9242 - accuracy: 0.53 - ETA: 4:29 - loss: 1.9134 - accuracy: 0.53 - ETA: 4:27 - loss: 1.9099 - accuracy: 0.53 - ETA: 4:25 - loss: 1.9043 - accuracy: 0.53 - ETA: 4:23 - loss: 1.8933 - accuracy: 0.53 - ETA: 4:21 - loss: 1.8968 - accuracy: 0.53 - ETA: 4:19 - loss: 1.8901 - accuracy: 0.53 - ETA: 4:17 - loss: 1.9032 - accuracy: 0.53 - ETA: 4:15 - loss: 1.8865 - accuracy: 0.53 - ETA: 4:13 - loss: 1.8809 - accuracy: 0.53 - ETA: 4:11 - loss: 1.8733 - accuracy: 0.53 - ETA: 4:09 - loss: 1.8841 - accuracy: 0.53 - ETA: 4:07 - loss: 1.8774 - accuracy: 0.53 - ETA: 4:05 - loss: 1.8740 - accuracy: 0.53 - ETA: 4:03 - loss: 1.8829 - accuracy: 0.53 - ETA: 4:01 - loss: 1.8822 - accuracy: 0.53 - ETA: 3:59 - loss: 1.8762 - accuracy: 0.53 - ETA: 3:57 - loss: 1.8860 - accuracy: 0.53 - ETA: 3:55 - loss: 1.8852 - accuracy: 0.53 - ETA: 3:53 - loss: 1.8877 - accuracy: 0.53 - ETA: 3:50 - loss: 1.8895 - accuracy: 0.53 - ETA: 3:48 - loss: 1.8954 - accuracy: 0.53 - ETA: 3:46 - loss: 1.8943 - accuracy: 0.53 - ETA: 3:44 - loss: 1.8912 - accuracy: 0.53 - ETA: 3:42 - loss: 1.8979 - accuracy: 0.53 - ETA: 3:40 - loss: 1.8916 - accuracy: 0.53 - ETA: 3:38 - loss: 1.8919 - accuracy: 0.53 - ETA: 3:35 - loss: 1.8913 - accuracy: 0.53 - ETA: 3:33 - loss: 1.8909 - accuracy: 0.53 - ETA: 3:31 - loss: 1.8953 - accuracy: 0.53 - ETA: 3:29 - loss: 1.8913 - accuracy: 0.53 - ETA: 3:27 - loss: 1.8887 - accuracy: 0.53 - ETA: 3:24 - loss: 1.8868 - accuracy: 0.53 - ETA: 3:22 - loss: 1.8831 - accuracy: 0.53 - ETA: 3:20 - loss: 1.8776 - accuracy: 0.53 - ETA: 3:18 - loss: 1.8710 - accuracy: 0.53 - ETA: 3:16 - loss: 1.8662 - accuracy: 0.53 - ETA: 3:14 - loss: 1.8623 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8551 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8487 - accuracy: 0.53 - ETA: 3:07 - loss: 1.8425 - accuracy: 0.53 - ETA: 3:05 - loss: 1.8485 - accuracy: 0.53 - ETA: 3:03 - loss: 1.8482 - accuracy: 0.53 - ETA: 3:01 - loss: 1.8485 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8432 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8400 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8486 - accuracy: 0.53 - ETA: 2:52 - loss: 1.8451 - accuracy: 0.54 - ETA: 2:50 - loss: 1.8424 - accuracy: 0.54 - ETA: 2:48 - loss: 1.8413 - accuracy: 0.54 - ETA: 2:46 - loss: 1.8386 - accuracy: 0.54 - ETA: 2:44 - loss: 1.8388 - accuracy: 0.54 - ETA: 2:42 - loss: 1.8416 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8471 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8462 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8514 - accuracy: 0.53 - ETA: 2:33 - loss: 1.8473 - accuracy: 0.53 - ETA: 2:31 - loss: 1.8429 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8412 - accuracy: 0.53 - ETA: 2:27 - loss: 1.8429 - accuracy: 0.53 - ETA: 2:25 - loss: 1.8368 - accuracy: 0.54 - ETA: 2:23 - loss: 1.8335 - accuracy: 0.54 - ETA: 2:21 - loss: 1.8325 - accuracy: 0.54 - ETA: 2:19 - loss: 1.8338 - accuracy: 0.53 - ETA: 2:17 - loss: 1.8322 - accuracy: 0.53 - ETA: 2:15 - loss: 1.8339 - accuracy: 0.53 - ETA: 2:12 - loss: 1.8322 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8289 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8266 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8260 - accuracy: 0.53 - ETA: 2:04 - loss: 1.8230 - accuracy: 0.53 - ETA: 2:02 - loss: 1.8218 - accuracy: 0.53 - ETA: 2:00 - loss: 1.8213 - accuracy: 0.53 - ETA: 1:58 - loss: 1.8183 - accuracy: 0.53 - ETA: 1:56 - loss: 1.8150 - accuracy: 0.54 - ETA: 1:53 - loss: 1.8124 - accuracy: 0.54 - ETA: 1:51 - loss: 1.8115 - accuracy: 0.54 - ETA: 1:49 - loss: 1.8123 - accuracy: 0.54 - ETA: 1:47 - loss: 1.8109 - accuracy: 0.53 - ETA: 1:45 - loss: 1.8084 - accuracy: 0.54 - ETA: 1:43 - loss: 1.8097 - accuracy: 0.54 - ETA: 1:41 - loss: 1.8105 - accuracy: 0.53 - ETA: 1:39 - loss: 1.8071 - accuracy: 0.54 - ETA: 1:36 - loss: 1.8063 - accuracy: 0.53 - ETA: 1:34 - loss: 1.8059 - accuracy: 0.53 - ETA: 1:32 - loss: 1.8058 - accuracy: 0.53 - ETA: 1:30 - loss: 1.8046 - accuracy: 0.53 - ETA: 1:28 - loss: 1.8020 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7989 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7970 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7982 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7990 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7973 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7961 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7984 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7978 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7985 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7982 - accuracy: 0.54 - ETA: 1:05 - loss: 1.8003 - accuracy: 0.53 - ETA: 1:03 - loss: 1.7982 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7964 - accuracy: 0.54 - ETA: 58s - loss: 1.7950 - accuracy: 0.5407 - ETA: 56s - loss: 1.7995 - accuracy: 0.540 - ETA: 54s - loss: 1.8002 - accuracy: 0.540 - ETA: 52s - loss: 1.7982 - accuracy: 0.540 - ETA: 50s - loss: 1.8011 - accuracy: 0.540 - ETA: 48s - loss: 1.7989 - accuracy: 0.541 - ETA: 46s - loss: 1.7968 - accuracy: 0.541 - ETA: 44s - loss: 1.7961 - accuracy: 0.542 - ETA: 41s - loss: 1.7941 - accuracy: 0.542 - ETA: 39s - loss: 1.7913 - accuracy: 0.543 - ETA: 37s - loss: 1.7900 - accuracy: 0.543 - ETA: 35s - loss: 1.7882 - accuracy: 0.543 - ETA: 33s - loss: 1.7863 - accuracy: 0.544 - ETA: 31s - loss: 1.7854 - accuracy: 0.544 - ETA: 29s - loss: 1.7810 - accuracy: 0.545 - ETA: 27s - loss: 1.7787 - accuracy: 0.545 - ETA: 25s - loss: 1.7793 - accuracy: 0.545 - ETA: 22s - loss: 1.7772 - accuracy: 0.545 - ETA: 20s - loss: 1.7781 - accuracy: 0.545 - ETA: 18s - loss: 1.7782 - accuracy: 0.545 - ETA: 16s - loss: 1.7768 - accuracy: 0.545 - ETA: 14s - loss: 1.7773 - accuracy: 0.544 - ETA: 12s - loss: 1.7793 - accuracy: 0.544 - ETA: 10s - loss: 1.7787 - accuracy: 0.544 - ETA: 8s - loss: 1.7783 - accuracy: 0.544 - ETA: 6s - loss: 1.7780 - accuracy: 0.54 - ETA: 3s - loss: 1.7872 - accuracy: 0.54 - ETA: 1s - loss: 1.7872 - accuracy: 0.54 - 343s 18ms/step - loss: 1.7865 - accuracy: 0.5447 - val_loss: 2.1094 - val_accuracy: 0.5920\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:22 - loss: 1.9440 - accuracy: 0.51 - ETA: 5:24 - loss: 1.8973 - accuracy: 0.51 - ETA: 5:21 - loss: 1.8794 - accuracy: 0.51 - ETA: 5:18 - loss: 1.9315 - accuracy: 0.51 - ETA: 5:13 - loss: 1.8612 - accuracy: 0.52 - ETA: 5:11 - loss: 1.9882 - accuracy: 0.52 - ETA: 5:09 - loss: 1.9241 - accuracy: 0.52 - ETA: 5:07 - loss: 1.8591 - accuracy: 0.54 - ETA: 5:05 - loss: 1.8646 - accuracy: 0.53 - ETA: 5:04 - loss: 1.8326 - accuracy: 0.53 - ETA: 5:00 - loss: 1.8308 - accuracy: 0.53 - ETA: 4:57 - loss: 1.8420 - accuracy: 0.53 - ETA: 4:54 - loss: 1.8551 - accuracy: 0.53 - ETA: 4:51 - loss: 1.8323 - accuracy: 0.53 - ETA: 4:49 - loss: 1.8208 - accuracy: 0.53 - ETA: 4:46 - loss: 1.8114 - accuracy: 0.53 - ETA: 4:44 - loss: 1.8185 - accuracy: 0.53 - ETA: 4:42 - loss: 1.8102 - accuracy: 0.53 - ETA: 4:40 - loss: 1.7922 - accuracy: 0.53 - ETA: 4:38 - loss: 1.7936 - accuracy: 0.53 - ETA: 4:36 - loss: 1.7905 - accuracy: 0.53 - ETA: 4:34 - loss: 1.7893 - accuracy: 0.53 - ETA: 4:32 - loss: 1.7799 - accuracy: 0.53 - ETA: 4:29 - loss: 1.7776 - accuracy: 0.53 - ETA: 4:27 - loss: 1.7685 - accuracy: 0.54 - ETA: 4:24 - loss: 1.7859 - accuracy: 0.54 - ETA: 4:22 - loss: 1.7861 - accuracy: 0.54 - ETA: 4:20 - loss: 1.7824 - accuracy: 0.54 - ETA: 4:18 - loss: 1.7746 - accuracy: 0.54 - ETA: 4:16 - loss: 1.7808 - accuracy: 0.54 - ETA: 4:13 - loss: 1.7730 - accuracy: 0.54 - ETA: 4:11 - loss: 1.7715 - accuracy: 0.54 - ETA: 4:09 - loss: 1.7711 - accuracy: 0.54 - ETA: 4:07 - loss: 1.7788 - accuracy: 0.54 - ETA: 4:05 - loss: 1.7738 - accuracy: 0.54 - ETA: 4:03 - loss: 1.7764 - accuracy: 0.53 - ETA: 4:01 - loss: 1.7788 - accuracy: 0.53 - ETA: 3:59 - loss: 1.7691 - accuracy: 0.53 - ETA: 3:57 - loss: 1.7648 - accuracy: 0.54 - ETA: 3:55 - loss: 1.7647 - accuracy: 0.53 - ETA: 3:53 - loss: 1.7633 - accuracy: 0.53 - ETA: 3:50 - loss: 1.7623 - accuracy: 0.53 - ETA: 3:48 - loss: 1.7642 - accuracy: 0.53 - ETA: 3:46 - loss: 1.7684 - accuracy: 0.53 - ETA: 3:43 - loss: 1.7641 - accuracy: 0.53 - ETA: 3:41 - loss: 1.7606 - accuracy: 0.53 - ETA: 3:39 - loss: 1.7572 - accuracy: 0.53 - ETA: 3:37 - loss: 1.7577 - accuracy: 0.53 - ETA: 3:35 - loss: 1.7557 - accuracy: 0.53 - ETA: 3:32 - loss: 1.7560 - accuracy: 0.53 - ETA: 3:30 - loss: 1.7536 - accuracy: 0.53 - ETA: 3:28 - loss: 1.7534 - accuracy: 0.53 - ETA: 3:26 - loss: 1.7534 - accuracy: 0.53 - ETA: 3:24 - loss: 1.7537 - accuracy: 0.53 - ETA: 3:22 - loss: 1.7484 - accuracy: 0.53 - ETA: 3:20 - loss: 1.7523 - accuracy: 0.53 - ETA: 3:18 - loss: 1.7492 - accuracy: 0.53 - ETA: 3:15 - loss: 1.7447 - accuracy: 0.53 - ETA: 3:13 - loss: 1.7457 - accuracy: 0.53 - ETA: 3:11 - loss: 1.7495 - accuracy: 0.53 - ETA: 3:09 - loss: 1.7513 - accuracy: 0.53 - ETA: 3:07 - loss: 1.7488 - accuracy: 0.53 - ETA: 3:05 - loss: 1.7476 - accuracy: 0.53 - ETA: 3:03 - loss: 1.7538 - accuracy: 0.53 - ETA: 3:01 - loss: 1.7509 - accuracy: 0.53 - ETA: 2:59 - loss: 1.7514 - accuracy: 0.53 - ETA: 2:57 - loss: 1.7469 - accuracy: 0.53 - ETA: 2:55 - loss: 1.7478 - accuracy: 0.53 - ETA: 2:52 - loss: 1.7499 - accuracy: 0.53 - ETA: 2:50 - loss: 1.7477 - accuracy: 0.53 - ETA: 2:48 - loss: 1.7488 - accuracy: 0.53 - ETA: 2:46 - loss: 1.7564 - accuracy: 0.53 - ETA: 2:44 - loss: 1.7552 - accuracy: 0.53 - ETA: 2:42 - loss: 1.7519 - accuracy: 0.53 - ETA: 2:40 - loss: 1.7493 - accuracy: 0.53 - ETA: 2:38 - loss: 1.7472 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7471 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7515 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7508 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7469 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7482 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7482 - accuracy: 0.53 - ETA: 2:23 - loss: 1.7441 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7415 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7480 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7421 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7423 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7437 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7420 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7415 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7395 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7473 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7455 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7470 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7460 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7465 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7456 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7456 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7458 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7447 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7439 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7438 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7449 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7455 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7451 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7426 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7405 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7422 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7396 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7387 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7388 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7400 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7405 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7418 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7424 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7408 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7410 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7411 - accuracy: 0.54 - ETA: 1:08 - loss: 1.7418 - accuracy: 0.54 - ETA: 1:06 - loss: 1.7417 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7420 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7414 - accuracy: 0.54 - ETA: 59s - loss: 1.7428 - accuracy: 0.5446 - ETA: 57s - loss: 1.7403 - accuracy: 0.544 - ETA: 55s - loss: 1.7398 - accuracy: 0.545 - ETA: 53s - loss: 1.7422 - accuracy: 0.544 - ETA: 51s - loss: 1.7423 - accuracy: 0.544 - ETA: 48s - loss: 1.7416 - accuracy: 0.544 - ETA: 46s - loss: 1.7416 - accuracy: 0.544 - ETA: 44s - loss: 1.7418 - accuracy: 0.544 - ETA: 42s - loss: 1.7402 - accuracy: 0.545 - ETA: 40s - loss: 1.7384 - accuracy: 0.545 - ETA: 38s - loss: 1.7389 - accuracy: 0.545 - ETA: 36s - loss: 1.7383 - accuracy: 0.544 - ETA: 33s - loss: 1.7372 - accuracy: 0.545 - ETA: 31s - loss: 1.7371 - accuracy: 0.545 - ETA: 29s - loss: 1.7374 - accuracy: 0.545 - ETA: 27s - loss: 1.7358 - accuracy: 0.545 - ETA: 25s - loss: 1.7347 - accuracy: 0.545 - ETA: 23s - loss: 1.7361 - accuracy: 0.545 - ETA: 21s - loss: 1.7339 - accuracy: 0.545 - ETA: 18s - loss: 1.7360 - accuracy: 0.545 - ETA: 16s - loss: 1.7349 - accuracy: 0.545 - ETA: 14s - loss: 1.7350 - accuracy: 0.545 - ETA: 12s - loss: 1.7336 - accuracy: 0.546 - ETA: 10s - loss: 1.7326 - accuracy: 0.545 - ETA: 8s - loss: 1.7324 - accuracy: 0.545 - ETA: 6s - loss: 1.7303 - accuracy: 0.54 - ETA: 4s - loss: 1.7304 - accuracy: 0.54 - ETA: 1s - loss: 1.7307 - accuracy: 0.54 - 347s 18ms/step - loss: 1.7294 - accuracy: 0.5465 - val_loss: 2.1213 - val_accuracy: 0.5916\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:22 - loss: 1.7178 - accuracy: 0.51 - ETA: 5:19 - loss: 1.6110 - accuracy: 0.55 - ETA: 5:18 - loss: 1.5676 - accuracy: 0.56 - ETA: 5:14 - loss: 1.6582 - accuracy: 0.56 - ETA: 5:09 - loss: 1.6343 - accuracy: 0.57 - ETA: 5:08 - loss: 1.6528 - accuracy: 0.56 - ETA: 5:05 - loss: 1.6251 - accuracy: 0.57 - ETA: 5:01 - loss: 1.6290 - accuracy: 0.57 - ETA: 5:01 - loss: 1.6349 - accuracy: 0.57 - ETA: 4:59 - loss: 1.6491 - accuracy: 0.56 - ETA: 4:57 - loss: 1.6450 - accuracy: 0.56 - ETA: 4:55 - loss: 1.6361 - accuracy: 0.57 - ETA: 4:53 - loss: 1.6440 - accuracy: 0.56 - ETA: 4:51 - loss: 1.6618 - accuracy: 0.55 - ETA: 4:49 - loss: 1.6736 - accuracy: 0.55 - ETA: 4:48 - loss: 1.6679 - accuracy: 0.56 - ETA: 4:45 - loss: 1.6959 - accuracy: 0.55 - ETA: 4:43 - loss: 1.7048 - accuracy: 0.55 - ETA: 4:41 - loss: 1.7037 - accuracy: 0.55 - ETA: 4:39 - loss: 1.7091 - accuracy: 0.54 - ETA: 4:37 - loss: 1.7298 - accuracy: 0.54 - ETA: 4:34 - loss: 1.7360 - accuracy: 0.54 - ETA: 4:32 - loss: 1.7195 - accuracy: 0.54 - ETA: 4:29 - loss: 1.7049 - accuracy: 0.55 - ETA: 4:27 - loss: 1.6980 - accuracy: 0.55 - ETA: 4:26 - loss: 1.6916 - accuracy: 0.55 - ETA: 4:23 - loss: 1.6883 - accuracy: 0.55 - ETA: 4:20 - loss: 1.6814 - accuracy: 0.55 - ETA: 4:18 - loss: 1.6751 - accuracy: 0.55 - ETA: 4:16 - loss: 1.6880 - accuracy: 0.55 - ETA: 4:14 - loss: 1.7324 - accuracy: 0.55 - ETA: 4:12 - loss: 1.7369 - accuracy: 0.55 - ETA: 4:10 - loss: 1.7278 - accuracy: 0.55 - ETA: 4:08 - loss: 1.7297 - accuracy: 0.55 - ETA: 4:06 - loss: 1.7414 - accuracy: 0.55 - ETA: 4:04 - loss: 1.7432 - accuracy: 0.55 - ETA: 4:02 - loss: 1.7384 - accuracy: 0.55 - ETA: 4:00 - loss: 1.7431 - accuracy: 0.55 - ETA: 3:57 - loss: 1.7358 - accuracy: 0.55 - ETA: 3:55 - loss: 1.7353 - accuracy: 0.55 - ETA: 3:53 - loss: 1.7326 - accuracy: 0.55 - ETA: 3:51 - loss: 1.7315 - accuracy: 0.55 - ETA: 3:49 - loss: 1.7301 - accuracy: 0.55 - ETA: 3:46 - loss: 1.7352 - accuracy: 0.55 - ETA: 3:44 - loss: 1.7416 - accuracy: 0.54 - ETA: 3:42 - loss: 1.7398 - accuracy: 0.54 - ETA: 3:40 - loss: 1.7336 - accuracy: 0.55 - ETA: 3:37 - loss: 1.7336 - accuracy: 0.55 - ETA: 3:35 - loss: 1.7335 - accuracy: 0.55 - ETA: 3:33 - loss: 1.7405 - accuracy: 0.55 - ETA: 3:31 - loss: 1.7413 - accuracy: 0.55 - ETA: 3:29 - loss: 1.7398 - accuracy: 0.55 - ETA: 3:27 - loss: 1.7440 - accuracy: 0.55 - ETA: 3:25 - loss: 1.7476 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7428 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7425 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7427 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7431 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7549 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7556 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7533 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7504 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7528 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7572 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7547 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7553 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7562 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7574 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7541 - accuracy: 0.54 - ETA: 2:51 - loss: 1.7524 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7497 - accuracy: 0.54 - ETA: 2:46 - loss: 1.7508 - accuracy: 0.54 - ETA: 2:44 - loss: 1.7505 - accuracy: 0.54 - ETA: 2:42 - loss: 1.7492 - accuracy: 0.54 - ETA: 2:40 - loss: 1.7528 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7518 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7508 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7587 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7589 - accuracy: 0.54 - ETA: 2:29 - loss: 1.7549 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7559 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7576 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7585 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7561 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7549 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7518 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7516 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7508 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7498 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7506 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7510 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7487 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7451 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7447 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7448 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7471 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7501 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7492 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7477 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7462 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7494 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7539 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7521 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7531 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7510 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7494 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7486 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7481 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7461 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7501 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7509 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7683 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7686 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7708 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7731 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7724 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7722 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7723 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7707 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7694 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7648 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7655 - accuracy: 0.54 - ETA: 59s - loss: 1.7627 - accuracy: 0.5447 - ETA: 56s - loss: 1.7637 - accuracy: 0.544 - ETA: 54s - loss: 1.7645 - accuracy: 0.544 - ETA: 52s - loss: 1.7633 - accuracy: 0.544 - ETA: 50s - loss: 1.7647 - accuracy: 0.543 - ETA: 48s - loss: 1.7661 - accuracy: 0.543 - ETA: 46s - loss: 1.7657 - accuracy: 0.544 - ETA: 44s - loss: 1.7657 - accuracy: 0.544 - ETA: 42s - loss: 1.7654 - accuracy: 0.544 - ETA: 39s - loss: 1.7649 - accuracy: 0.544 - ETA: 37s - loss: 1.7655 - accuracy: 0.544 - ETA: 35s - loss: 1.7667 - accuracy: 0.543 - ETA: 33s - loss: 1.7659 - accuracy: 0.543 - ETA: 31s - loss: 1.7634 - accuracy: 0.544 - ETA: 29s - loss: 1.7630 - accuracy: 0.544 - ETA: 27s - loss: 1.7629 - accuracy: 0.544 - ETA: 25s - loss: 1.7625 - accuracy: 0.544 - ETA: 22s - loss: 1.7611 - accuracy: 0.544 - ETA: 20s - loss: 1.7594 - accuracy: 0.545 - ETA: 18s - loss: 1.7585 - accuracy: 0.545 - ETA: 16s - loss: 1.7588 - accuracy: 0.545 - ETA: 14s - loss: 1.7577 - accuracy: 0.545 - ETA: 12s - loss: 1.7571 - accuracy: 0.545 - ETA: 10s - loss: 1.7570 - accuracy: 0.545 - ETA: 8s - loss: 1.7651 - accuracy: 0.544 - ETA: 6s - loss: 1.7631 - accuracy: 0.54 - ETA: 3s - loss: 1.7631 - accuracy: 0.54 - ETA: 1s - loss: 1.7609 - accuracy: 0.54 - 344s 18ms/step - loss: 1.7610 - accuracy: 0.5455 - val_loss: 2.3103 - val_accuracy: 0.5902\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:55 - loss: 1.8699 - accuracy: 0.52 - ETA: 4:55 - loss: 1.8036 - accuracy: 0.51 - ETA: 5:04 - loss: 1.7734 - accuracy: 0.51 - ETA: 5:05 - loss: 1.8060 - accuracy: 0.53 - ETA: 5:03 - loss: 1.7812 - accuracy: 0.53 - ETA: 5:00 - loss: 1.7978 - accuracy: 0.52 - ETA: 4:57 - loss: 1.8324 - accuracy: 0.52 - ETA: 4:56 - loss: 1.7691 - accuracy: 0.54 - ETA: 4:54 - loss: 1.8572 - accuracy: 0.54 - ETA: 4:53 - loss: 1.8174 - accuracy: 0.55 - ETA: 4:51 - loss: 1.8107 - accuracy: 0.54 - ETA: 4:48 - loss: 1.7863 - accuracy: 0.55 - ETA: 4:46 - loss: 1.7484 - accuracy: 0.56 - ETA: 4:43 - loss: 1.7384 - accuracy: 0.56 - ETA: 4:42 - loss: 1.7140 - accuracy: 0.56 - ETA: 4:39 - loss: 1.8701 - accuracy: 0.56 - ETA: 4:37 - loss: 1.8582 - accuracy: 0.56 - ETA: 4:35 - loss: 1.8517 - accuracy: 0.56 - ETA: 4:33 - loss: 1.8649 - accuracy: 0.55 - ETA: 4:31 - loss: 1.8484 - accuracy: 0.55 - ETA: 4:29 - loss: 1.8428 - accuracy: 0.55 - ETA: 4:27 - loss: 1.8436 - accuracy: 0.55 - ETA: 4:25 - loss: 1.8337 - accuracy: 0.55 - ETA: 4:23 - loss: 1.8247 - accuracy: 0.55 - ETA: 4:22 - loss: 1.8142 - accuracy: 0.55 - ETA: 4:20 - loss: 1.8012 - accuracy: 0.56 - ETA: 4:18 - loss: 1.8026 - accuracy: 0.55 - ETA: 4:16 - loss: 1.7967 - accuracy: 0.55 - ETA: 4:13 - loss: 1.7904 - accuracy: 0.55 - ETA: 4:11 - loss: 1.7738 - accuracy: 0.56 - ETA: 4:09 - loss: 1.7714 - accuracy: 0.55 - ETA: 4:07 - loss: 1.7661 - accuracy: 0.55 - ETA: 4:05 - loss: 1.7609 - accuracy: 0.55 - ETA: 4:03 - loss: 1.7584 - accuracy: 0.56 - ETA: 4:01 - loss: 1.8162 - accuracy: 0.55 - ETA: 3:59 - loss: 1.8161 - accuracy: 0.55 - ETA: 3:57 - loss: 1.8117 - accuracy: 0.55 - ETA: 3:56 - loss: 1.8056 - accuracy: 0.55 - ETA: 3:54 - loss: 1.8180 - accuracy: 0.55 - ETA: 3:52 - loss: 1.8186 - accuracy: 0.55 - ETA: 3:50 - loss: 1.8192 - accuracy: 0.55 - ETA: 3:48 - loss: 1.8231 - accuracy: 0.55 - ETA: 3:46 - loss: 1.8123 - accuracy: 0.55 - ETA: 3:44 - loss: 1.8111 - accuracy: 0.55 - ETA: 3:42 - loss: 1.8113 - accuracy: 0.55 - ETA: 3:39 - loss: 1.8139 - accuracy: 0.55 - ETA: 3:37 - loss: 1.8207 - accuracy: 0.55 - ETA: 3:35 - loss: 1.8125 - accuracy: 0.55 - ETA: 3:33 - loss: 1.8207 - accuracy: 0.55 - ETA: 3:31 - loss: 1.8155 - accuracy: 0.55 - ETA: 3:29 - loss: 1.8125 - accuracy: 0.55 - ETA: 3:27 - loss: 1.8254 - accuracy: 0.55 - ETA: 3:25 - loss: 1.8307 - accuracy: 0.55 - ETA: 3:23 - loss: 1.8272 - accuracy: 0.55 - ETA: 3:21 - loss: 1.8235 - accuracy: 0.55 - ETA: 3:19 - loss: 1.8229 - accuracy: 0.55 - ETA: 3:17 - loss: 1.8170 - accuracy: 0.55 - ETA: 3:15 - loss: 1.8124 - accuracy: 0.55 - ETA: 3:12 - loss: 1.8126 - accuracy: 0.55 - ETA: 3:10 - loss: 1.8126 - accuracy: 0.55 - ETA: 3:08 - loss: 1.8092 - accuracy: 0.55 - ETA: 3:06 - loss: 1.8063 - accuracy: 0.55 - ETA: 3:04 - loss: 1.8107 - accuracy: 0.55 - ETA: 3:02 - loss: 1.8146 - accuracy: 0.55 - ETA: 3:00 - loss: 1.8149 - accuracy: 0.54 - ETA: 2:58 - loss: 1.8143 - accuracy: 0.54 - ETA: 2:56 - loss: 1.8140 - accuracy: 0.54 - ETA: 2:54 - loss: 1.8161 - accuracy: 0.54 - ETA: 2:51 - loss: 1.8212 - accuracy: 0.54 - ETA: 2:49 - loss: 1.8252 - accuracy: 0.54 - ETA: 2:47 - loss: 1.8192 - accuracy: 0.54 - ETA: 2:45 - loss: 1.8163 - accuracy: 0.54 - ETA: 2:43 - loss: 1.8227 - accuracy: 0.54 - ETA: 2:41 - loss: 1.8192 - accuracy: 0.54 - ETA: 2:39 - loss: 1.8180 - accuracy: 0.54 - ETA: 2:37 - loss: 1.8137 - accuracy: 0.54 - ETA: 2:35 - loss: 1.8134 - accuracy: 0.54 - ETA: 2:32 - loss: 1.8137 - accuracy: 0.54 - ETA: 2:30 - loss: 1.8136 - accuracy: 0.54 - ETA: 2:28 - loss: 1.8122 - accuracy: 0.54 - ETA: 2:26 - loss: 1.8084 - accuracy: 0.54 - ETA: 2:24 - loss: 1.8076 - accuracy: 0.54 - ETA: 2:22 - loss: 1.8085 - accuracy: 0.54 - ETA: 2:20 - loss: 1.8066 - accuracy: 0.54 - ETA: 2:18 - loss: 1.8072 - accuracy: 0.54 - ETA: 2:16 - loss: 1.8062 - accuracy: 0.54 - ETA: 2:14 - loss: 1.8053 - accuracy: 0.54 - ETA: 2:12 - loss: 1.8012 - accuracy: 0.54 - ETA: 2:10 - loss: 1.8005 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7976 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7953 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7999 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7991 - accuracy: 0.54 - ETA: 1:59 - loss: 1.8024 - accuracy: 0.54 - ETA: 1:57 - loss: 1.8029 - accuracy: 0.54 - ETA: 1:55 - loss: 1.8010 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7992 - accuracy: 0.54 - ETA: 1:51 - loss: 1.8004 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7999 - accuracy: 0.54 - ETA: 1:47 - loss: 1.8051 - accuracy: 0.54 - ETA: 1:44 - loss: 1.8057 - accuracy: 0.54 - ETA: 1:42 - loss: 1.8048 - accuracy: 0.54 - ETA: 1:40 - loss: 1.8001 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7963 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7975 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7964 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7965 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7981 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7976 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7983 - accuracy: 0.54 - ETA: 1:23 - loss: 1.8005 - accuracy: 0.54 - ETA: 1:21 - loss: 1.8010 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7990 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7967 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7974 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7971 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7987 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7983 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7939 - accuracy: 0.54 - ETA: 1:04 - loss: 1.7939 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7976 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7987 - accuracy: 0.54 - ETA: 58s - loss: 1.7987 - accuracy: 0.5470 - ETA: 56s - loss: 1.7963 - accuracy: 0.547 - ETA: 54s - loss: 1.7973 - accuracy: 0.546 - ETA: 52s - loss: 1.7954 - accuracy: 0.546 - ETA: 50s - loss: 1.7981 - accuracy: 0.545 - ETA: 48s - loss: 1.7985 - accuracy: 0.545 - ETA: 46s - loss: 1.7963 - accuracy: 0.545 - ETA: 43s - loss: 1.7939 - accuracy: 0.546 - ETA: 41s - loss: 1.7935 - accuracy: 0.546 - ETA: 39s - loss: 1.7918 - accuracy: 0.546 - ETA: 37s - loss: 1.7920 - accuracy: 0.545 - ETA: 35s - loss: 1.7920 - accuracy: 0.545 - ETA: 33s - loss: 1.7916 - accuracy: 0.545 - ETA: 31s - loss: 1.7931 - accuracy: 0.545 - ETA: 29s - loss: 1.7931 - accuracy: 0.545 - ETA: 27s - loss: 1.7977 - accuracy: 0.545 - ETA: 24s - loss: 1.7976 - accuracy: 0.545 - ETA: 22s - loss: 1.7977 - accuracy: 0.544 - ETA: 20s - loss: 1.7981 - accuracy: 0.544 - ETA: 18s - loss: 1.7963 - accuracy: 0.544 - ETA: 16s - loss: 1.7981 - accuracy: 0.544 - ETA: 14s - loss: 1.7974 - accuracy: 0.544 - ETA: 12s - loss: 1.7932 - accuracy: 0.545 - ETA: 10s - loss: 1.7951 - accuracy: 0.544 - ETA: 8s - loss: 1.7996 - accuracy: 0.545 - ETA: 6s - loss: 1.7982 - accuracy: 0.54 - ETA: 3s - loss: 1.7958 - accuracy: 0.54 - ETA: 1s - loss: 1.7939 - accuracy: 0.54 - 341s 18ms/step - loss: 1.7931 - accuracy: 0.5459 - val_loss: 2.4872 - val_accuracy: 0.5989\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:12 - loss: 1.8085 - accuracy: 0.50 - ETA: 5:14 - loss: 1.8105 - accuracy: 0.51 - ETA: 5:06 - loss: 1.7475 - accuracy: 0.51 - ETA: 5:07 - loss: 1.6549 - accuracy: 0.55 - ETA: 5:06 - loss: 1.6317 - accuracy: 0.55 - ETA: 5:04 - loss: 1.6395 - accuracy: 0.54 - ETA: 5:04 - loss: 1.6478 - accuracy: 0.54 - ETA: 5:02 - loss: 1.6580 - accuracy: 0.54 - ETA: 4:59 - loss: 1.6378 - accuracy: 0.55 - ETA: 4:58 - loss: 1.6639 - accuracy: 0.54 - ETA: 4:54 - loss: 1.7067 - accuracy: 0.53 - ETA: 4:52 - loss: 1.7190 - accuracy: 0.53 - ETA: 4:51 - loss: 1.7115 - accuracy: 0.54 - ETA: 4:49 - loss: 1.7262 - accuracy: 0.53 - ETA: 4:47 - loss: 1.7483 - accuracy: 0.54 - ETA: 4:46 - loss: 1.7379 - accuracy: 0.54 - ETA: 4:44 - loss: 1.7416 - accuracy: 0.54 - ETA: 4:42 - loss: 1.7213 - accuracy: 0.55 - ETA: 4:39 - loss: 1.7473 - accuracy: 0.54 - ETA: 4:36 - loss: 1.7303 - accuracy: 0.55 - ETA: 4:34 - loss: 1.7326 - accuracy: 0.55 - ETA: 4:32 - loss: 1.7328 - accuracy: 0.55 - ETA: 4:30 - loss: 1.7571 - accuracy: 0.54 - ETA: 4:28 - loss: 1.7532 - accuracy: 0.54 - ETA: 4:26 - loss: 1.7763 - accuracy: 0.54 - ETA: 4:24 - loss: 1.7758 - accuracy: 0.54 - ETA: 4:22 - loss: 1.7757 - accuracy: 0.54 - ETA: 4:20 - loss: 1.7815 - accuracy: 0.54 - ETA: 4:17 - loss: 1.7842 - accuracy: 0.54 - ETA: 4:15 - loss: 1.7834 - accuracy: 0.54 - ETA: 4:13 - loss: 1.7830 - accuracy: 0.54 - ETA: 4:11 - loss: 1.7761 - accuracy: 0.54 - ETA: 4:09 - loss: 1.7742 - accuracy: 0.54 - ETA: 4:06 - loss: 1.7827 - accuracy: 0.54 - ETA: 4:04 - loss: 1.7906 - accuracy: 0.54 - ETA: 4:12 - loss: 1.7890 - accuracy: 0.53 - ETA: 4:09 - loss: 1.7807 - accuracy: 0.54 - ETA: 4:07 - loss: 1.7719 - accuracy: 0.54 - ETA: 4:04 - loss: 1.7771 - accuracy: 0.54 - ETA: 4:01 - loss: 1.7752 - accuracy: 0.54 - ETA: 4:00 - loss: 1.7683 - accuracy: 0.54 - ETA: 3:57 - loss: 1.7759 - accuracy: 0.54 - ETA: 3:55 - loss: 1.7709 - accuracy: 0.54 - ETA: 3:52 - loss: 1.7685 - accuracy: 0.54 - ETA: 3:50 - loss: 1.7761 - accuracy: 0.54 - ETA: 3:47 - loss: 1.7725 - accuracy: 0.54 - ETA: 3:45 - loss: 1.7699 - accuracy: 0.54 - ETA: 3:43 - loss: 1.7636 - accuracy: 0.54 - ETA: 3:40 - loss: 1.7663 - accuracy: 0.54 - ETA: 3:38 - loss: 1.7697 - accuracy: 0.54 - ETA: 3:36 - loss: 1.7667 - accuracy: 0.54 - ETA: 3:33 - loss: 1.7662 - accuracy: 0.54 - ETA: 3:31 - loss: 1.7758 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7736 - accuracy: 0.54 - ETA: 3:27 - loss: 1.7658 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7643 - accuracy: 0.54 - ETA: 3:22 - loss: 1.7615 - accuracy: 0.54 - ETA: 3:20 - loss: 1.7630 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7571 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7581 - accuracy: 0.54 - ETA: 3:13 - loss: 1.7559 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7503 - accuracy: 0.54 - ETA: 3:09 - loss: 1.7497 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7498 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7536 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7519 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7525 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7522 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7480 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7503 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7502 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7447 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7489 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7502 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7511 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7550 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7536 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7535 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7547 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7548 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7546 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7551 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7518 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7494 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7488 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7485 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7464 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7473 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7466 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7501 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7587 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7585 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7572 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7578 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7566 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7570 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7568 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7578 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7551 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7558 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7538 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7555 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7588 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7594 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7614 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7604 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7615 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7631 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7624 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7612 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7590 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7602 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7593 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7606 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7591 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7586 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7597 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7562 - accuracy: 0.54 - ETA: 1:08 - loss: 1.7571 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7547 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7600 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7606 - accuracy: 0.54 - ETA: 59s - loss: 1.7605 - accuracy: 0.5416 - ETA: 57s - loss: 1.7598 - accuracy: 0.541 - ETA: 55s - loss: 1.7599 - accuracy: 0.541 - ETA: 53s - loss: 1.7585 - accuracy: 0.542 - ETA: 50s - loss: 1.7596 - accuracy: 0.542 - ETA: 48s - loss: 1.7568 - accuracy: 0.542 - ETA: 46s - loss: 1.7554 - accuracy: 0.542 - ETA: 44s - loss: 1.7551 - accuracy: 0.543 - ETA: 42s - loss: 1.7554 - accuracy: 0.543 - ETA: 40s - loss: 1.7576 - accuracy: 0.542 - ETA: 38s - loss: 1.7561 - accuracy: 0.542 - ETA: 35s - loss: 1.7590 - accuracy: 0.543 - ETA: 33s - loss: 1.7579 - accuracy: 0.542 - ETA: 31s - loss: 1.7569 - accuracy: 0.543 - ETA: 29s - loss: 1.7657 - accuracy: 0.542 - ETA: 27s - loss: 1.7635 - accuracy: 0.543 - ETA: 25s - loss: 1.7623 - accuracy: 0.543 - ETA: 23s - loss: 1.7646 - accuracy: 0.543 - ETA: 21s - loss: 1.7659 - accuracy: 0.542 - ETA: 18s - loss: 1.7659 - accuracy: 0.542 - ETA: 16s - loss: 1.7705 - accuracy: 0.542 - ETA: 14s - loss: 1.7695 - accuracy: 0.542 - ETA: 12s - loss: 1.7703 - accuracy: 0.542 - ETA: 10s - loss: 1.7712 - accuracy: 0.542 - ETA: 8s - loss: 1.7715 - accuracy: 0.542 - ETA: 6s - loss: 1.7717 - accuracy: 0.54 - ETA: 3s - loss: 1.7703 - accuracy: 0.54 - ETA: 1s - loss: 1.7682 - accuracy: 0.54 - 346s 18ms/step - loss: 1.7671 - accuracy: 0.5426 - val_loss: 2.3625 - val_accuracy: 0.5935\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:42 - loss: 2.0665 - accuracy: 0.50 - ETA: 5:24 - loss: 1.7547 - accuracy: 0.53 - ETA: 5:11 - loss: 1.6323 - accuracy: 0.57 - ETA: 5:12 - loss: 1.6338 - accuracy: 0.57 - ETA: 5:07 - loss: 1.6579 - accuracy: 0.57 - ETA: 5:07 - loss: 1.6541 - accuracy: 0.57 - ETA: 5:05 - loss: 1.6950 - accuracy: 0.56 - ETA: 5:02 - loss: 1.6884 - accuracy: 0.56 - ETA: 5:01 - loss: 1.6750 - accuracy: 0.56 - ETA: 4:59 - loss: 1.6565 - accuracy: 0.56 - ETA: 4:57 - loss: 1.6708 - accuracy: 0.56 - ETA: 4:55 - loss: 1.6807 - accuracy: 0.56 - ETA: 4:54 - loss: 1.6705 - accuracy: 0.56 - ETA: 4:53 - loss: 1.6780 - accuracy: 0.55 - ETA: 4:50 - loss: 1.6687 - accuracy: 0.55 - ETA: 4:47 - loss: 1.6795 - accuracy: 0.55 - ETA: 4:44 - loss: 1.7183 - accuracy: 0.55 - ETA: 4:42 - loss: 1.7009 - accuracy: 0.55 - ETA: 4:40 - loss: 1.6911 - accuracy: 0.55 - ETA: 4:37 - loss: 1.7029 - accuracy: 0.55 - ETA: 4:35 - loss: 1.7090 - accuracy: 0.55 - ETA: 4:33 - loss: 1.7298 - accuracy: 0.55 - ETA: 4:30 - loss: 1.7415 - accuracy: 0.55 - ETA: 4:27 - loss: 1.7355 - accuracy: 0.55 - ETA: 4:25 - loss: 1.7365 - accuracy: 0.55 - ETA: 4:23 - loss: 1.7310 - accuracy: 0.54 - ETA: 4:21 - loss: 1.7348 - accuracy: 0.54 - ETA: 4:19 - loss: 1.7268 - accuracy: 0.55 - ETA: 4:17 - loss: 1.7133 - accuracy: 0.55 - ETA: 4:14 - loss: 1.7063 - accuracy: 0.55 - ETA: 4:12 - loss: 1.7136 - accuracy: 0.55 - ETA: 4:09 - loss: 1.7114 - accuracy: 0.55 - ETA: 4:07 - loss: 1.7092 - accuracy: 0.55 - ETA: 4:05 - loss: 1.7179 - accuracy: 0.55 - ETA: 4:03 - loss: 1.7139 - accuracy: 0.55 - ETA: 4:01 - loss: 1.7116 - accuracy: 0.55 - ETA: 3:59 - loss: 1.7104 - accuracy: 0.54 - ETA: 3:57 - loss: 1.7101 - accuracy: 0.54 - ETA: 3:55 - loss: 1.7107 - accuracy: 0.54 - ETA: 3:53 - loss: 1.7101 - accuracy: 0.54 - ETA: 3:50 - loss: 1.7078 - accuracy: 0.54 - ETA: 3:48 - loss: 1.7038 - accuracy: 0.54 - ETA: 3:46 - loss: 1.7004 - accuracy: 0.54 - ETA: 3:44 - loss: 1.7054 - accuracy: 0.54 - ETA: 3:42 - loss: 1.7102 - accuracy: 0.54 - ETA: 3:39 - loss: 1.7119 - accuracy: 0.54 - ETA: 3:37 - loss: 1.7185 - accuracy: 0.54 - ETA: 3:35 - loss: 1.7180 - accuracy: 0.54 - ETA: 3:33 - loss: 1.7177 - accuracy: 0.54 - ETA: 3:31 - loss: 1.7166 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7165 - accuracy: 0.54 - ETA: 3:27 - loss: 1.7180 - accuracy: 0.54 - ETA: 3:25 - loss: 1.7238 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7258 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7263 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7300 - accuracy: 0.54 - ETA: 3:17 - loss: 1.7318 - accuracy: 0.54 - ETA: 3:15 - loss: 1.7287 - accuracy: 0.54 - ETA: 3:13 - loss: 1.7292 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7294 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7284 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7250 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7220 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7190 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7144 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7181 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7196 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7213 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7203 - accuracy: 0.54 - ETA: 2:50 - loss: 1.7248 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7261 - accuracy: 0.54 - ETA: 2:46 - loss: 1.7280 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7287 - accuracy: 0.54 - ETA: 2:41 - loss: 1.7270 - accuracy: 0.54 - ETA: 2:39 - loss: 1.7300 - accuracy: 0.54 - ETA: 2:37 - loss: 1.7267 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7275 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7297 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7289 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7280 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7301 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7271 - accuracy: 0.54 - ETA: 2:22 - loss: 1.7247 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7279 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7269 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7228 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7227 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7239 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7263 - accuracy: 0.54 - ETA: 2:07 - loss: 1.7266 - accuracy: 0.54 - ETA: 2:05 - loss: 1.7254 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7240 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7239 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7225 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7232 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7260 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7246 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7221 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7228 - accuracy: 0.54 - ETA: 1:46 - loss: 1.7199 - accuracy: 0.54 - ETA: 1:44 - loss: 1.7187 - accuracy: 0.54 - ETA: 1:42 - loss: 1.7177 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7155 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7160 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7139 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7142 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7164 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7187 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7168 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7164 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7173 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7186 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7177 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7176 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7151 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7167 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7161 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7175 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7173 - accuracy: 0.54 - ETA: 1:04 - loss: 1.7194 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7174 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7162 - accuracy: 0.54 - ETA: 58s - loss: 1.7156 - accuracy: 0.5456 - ETA: 56s - loss: 1.7148 - accuracy: 0.545 - ETA: 54s - loss: 1.7169 - accuracy: 0.545 - ETA: 52s - loss: 1.7164 - accuracy: 0.545 - ETA: 50s - loss: 1.7170 - accuracy: 0.545 - ETA: 48s - loss: 1.7199 - accuracy: 0.544 - ETA: 46s - loss: 1.7217 - accuracy: 0.545 - ETA: 43s - loss: 1.7236 - accuracy: 0.544 - ETA: 41s - loss: 1.7214 - accuracy: 0.545 - ETA: 39s - loss: 1.7207 - accuracy: 0.545 - ETA: 37s - loss: 1.7216 - accuracy: 0.544 - ETA: 35s - loss: 1.7218 - accuracy: 0.545 - ETA: 33s - loss: 1.7203 - accuracy: 0.545 - ETA: 31s - loss: 1.7193 - accuracy: 0.545 - ETA: 29s - loss: 1.7199 - accuracy: 0.545 - ETA: 27s - loss: 1.7201 - accuracy: 0.545 - ETA: 25s - loss: 1.7210 - accuracy: 0.546 - ETA: 22s - loss: 1.7208 - accuracy: 0.546 - ETA: 20s - loss: 1.7191 - accuracy: 0.546 - ETA: 18s - loss: 1.7180 - accuracy: 0.546 - ETA: 16s - loss: 1.7171 - accuracy: 0.546 - ETA: 14s - loss: 1.7169 - accuracy: 0.546 - ETA: 12s - loss: 1.7158 - accuracy: 0.547 - ETA: 10s - loss: 1.7150 - accuracy: 0.547 - ETA: 8s - loss: 1.7146 - accuracy: 0.547 - ETA: 6s - loss: 1.7164 - accuracy: 0.54 - ETA: 3s - loss: 1.7163 - accuracy: 0.54 - ETA: 1s - loss: 1.7163 - accuracy: 0.54 - 343s 18ms/step - loss: 1.7164 - accuracy: 0.5458 - val_loss: 2.3390 - val_accuracy: 0.5987\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:06 - loss: 1.8747 - accuracy: 0.53 - ETA: 5:04 - loss: 1.8416 - accuracy: 0.53 - ETA: 5:07 - loss: 1.8516 - accuracy: 0.54 - ETA: 5:00 - loss: 1.8012 - accuracy: 0.54 - ETA: 4:58 - loss: 1.8791 - accuracy: 0.53 - ETA: 4:57 - loss: 1.8574 - accuracy: 0.53 - ETA: 4:58 - loss: 1.8377 - accuracy: 0.54 - ETA: 4:57 - loss: 1.8309 - accuracy: 0.54 - ETA: 4:55 - loss: 1.8389 - accuracy: 0.54 - ETA: 4:54 - loss: 1.8348 - accuracy: 0.53 - ETA: 4:52 - loss: 1.8255 - accuracy: 0.53 - ETA: 4:52 - loss: 1.7890 - accuracy: 0.54 - ETA: 4:48 - loss: 1.7879 - accuracy: 0.53 - ETA: 4:47 - loss: 1.7828 - accuracy: 0.54 - ETA: 4:46 - loss: 1.7791 - accuracy: 0.54 - ETA: 4:44 - loss: 1.7792 - accuracy: 0.54 - ETA: 4:42 - loss: 1.7576 - accuracy: 0.54 - ETA: 4:39 - loss: 1.7553 - accuracy: 0.54 - ETA: 4:38 - loss: 1.7603 - accuracy: 0.54 - ETA: 4:35 - loss: 1.7538 - accuracy: 0.54 - ETA: 4:33 - loss: 1.7685 - accuracy: 0.54 - ETA: 4:31 - loss: 1.7622 - accuracy: 0.54 - ETA: 4:28 - loss: 1.7645 - accuracy: 0.54 - ETA: 4:26 - loss: 1.7682 - accuracy: 0.54 - ETA: 4:23 - loss: 1.7566 - accuracy: 0.54 - ETA: 4:21 - loss: 1.7535 - accuracy: 0.54 - ETA: 4:18 - loss: 1.7489 - accuracy: 0.54 - ETA: 4:16 - loss: 1.7407 - accuracy: 0.54 - ETA: 4:14 - loss: 1.7400 - accuracy: 0.54 - ETA: 4:12 - loss: 1.7421 - accuracy: 0.54 - ETA: 4:10 - loss: 1.7401 - accuracy: 0.54 - ETA: 4:07 - loss: 1.7354 - accuracy: 0.54 - ETA: 4:05 - loss: 1.7360 - accuracy: 0.54 - ETA: 4:03 - loss: 1.7335 - accuracy: 0.54 - ETA: 4:01 - loss: 1.7288 - accuracy: 0.54 - ETA: 3:59 - loss: 1.7179 - accuracy: 0.54 - ETA: 3:57 - loss: 1.7194 - accuracy: 0.54 - ETA: 3:55 - loss: 1.7114 - accuracy: 0.54 - ETA: 3:53 - loss: 1.7082 - accuracy: 0.55 - ETA: 3:51 - loss: 1.7145 - accuracy: 0.54 - ETA: 3:50 - loss: 1.7154 - accuracy: 0.54 - ETA: 3:47 - loss: 1.7238 - accuracy: 0.54 - ETA: 3:45 - loss: 1.7267 - accuracy: 0.54 - ETA: 3:43 - loss: 1.7248 - accuracy: 0.54 - ETA: 3:41 - loss: 1.7232 - accuracy: 0.54 - ETA: 3:40 - loss: 1.7386 - accuracy: 0.54 - ETA: 3:38 - loss: 1.7402 - accuracy: 0.54 - ETA: 3:36 - loss: 1.7378 - accuracy: 0.54 - ETA: 3:34 - loss: 1.7345 - accuracy: 0.54 - ETA: 3:31 - loss: 1.7336 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7342 - accuracy: 0.54 - ETA: 3:27 - loss: 1.7301 - accuracy: 0.54 - ETA: 3:25 - loss: 1.7334 - accuracy: 0.54 - ETA: 3:23 - loss: 1.7358 - accuracy: 0.54 - ETA: 3:21 - loss: 1.7342 - accuracy: 0.54 - ETA: 3:19 - loss: 1.7350 - accuracy: 0.54 - ETA: 3:17 - loss: 1.7370 - accuracy: 0.54 - ETA: 3:15 - loss: 1.7404 - accuracy: 0.54 - ETA: 3:13 - loss: 1.7397 - accuracy: 0.54 - ETA: 3:11 - loss: 1.7359 - accuracy: 0.54 - ETA: 3:08 - loss: 1.7367 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7341 - accuracy: 0.54 - ETA: 3:04 - loss: 1.7355 - accuracy: 0.54 - ETA: 3:02 - loss: 1.7356 - accuracy: 0.54 - ETA: 3:00 - loss: 1.7308 - accuracy: 0.54 - ETA: 2:58 - loss: 1.7324 - accuracy: 0.54 - ETA: 2:56 - loss: 1.7295 - accuracy: 0.54 - ETA: 2:54 - loss: 1.7280 - accuracy: 0.54 - ETA: 2:52 - loss: 1.7252 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7243 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7243 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7199 - accuracy: 0.54 - ETA: 2:43 - loss: 1.7181 - accuracy: 0.55 - ETA: 2:41 - loss: 1.7154 - accuracy: 0.55 - ETA: 2:39 - loss: 1.7141 - accuracy: 0.55 - ETA: 2:37 - loss: 1.7168 - accuracy: 0.54 - ETA: 2:35 - loss: 1.7197 - accuracy: 0.54 - ETA: 2:33 - loss: 1.7221 - accuracy: 0.54 - ETA: 2:31 - loss: 1.7209 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7254 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7260 - accuracy: 0.54 - ETA: 2:24 - loss: 1.7262 - accuracy: 0.54 - ETA: 2:22 - loss: 1.7273 - accuracy: 0.54 - ETA: 2:20 - loss: 1.7330 - accuracy: 0.54 - ETA: 2:18 - loss: 1.7318 - accuracy: 0.54 - ETA: 2:16 - loss: 1.7320 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7317 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7320 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7320 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7335 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7439 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7432 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7449 - accuracy: 0.54 - ETA: 1:59 - loss: 1.7440 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7457 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7452 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7484 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7479 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7481 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7473 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7563 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7557 - accuracy: 0.54 - ETA: 1:40 - loss: 1.7537 - accuracy: 0.54 - ETA: 1:38 - loss: 1.7557 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7563 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7566 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7563 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7557 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7537 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7508 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7529 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7547 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7549 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7519 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7509 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7502 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7513 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7488 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7482 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7467 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7448 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7438 - accuracy: 0.54 - ETA: 58s - loss: 1.7435 - accuracy: 0.5464 - ETA: 56s - loss: 1.7461 - accuracy: 0.545 - ETA: 54s - loss: 1.7466 - accuracy: 0.545 - ETA: 52s - loss: 1.7474 - accuracy: 0.544 - ETA: 50s - loss: 1.7458 - accuracy: 0.545 - ETA: 48s - loss: 1.7448 - accuracy: 0.545 - ETA: 46s - loss: 1.7451 - accuracy: 0.545 - ETA: 44s - loss: 1.7474 - accuracy: 0.545 - ETA: 41s - loss: 1.7479 - accuracy: 0.545 - ETA: 39s - loss: 1.7497 - accuracy: 0.545 - ETA: 37s - loss: 1.7483 - accuracy: 0.545 - ETA: 35s - loss: 1.7491 - accuracy: 0.545 - ETA: 33s - loss: 1.7481 - accuracy: 0.545 - ETA: 31s - loss: 1.7490 - accuracy: 0.545 - ETA: 29s - loss: 1.7508 - accuracy: 0.544 - ETA: 27s - loss: 1.7495 - accuracy: 0.544 - ETA: 25s - loss: 1.7471 - accuracy: 0.545 - ETA: 22s - loss: 1.7539 - accuracy: 0.545 - ETA: 20s - loss: 1.7540 - accuracy: 0.545 - ETA: 18s - loss: 1.7533 - accuracy: 0.545 - ETA: 16s - loss: 1.7563 - accuracy: 0.545 - ETA: 14s - loss: 1.7560 - accuracy: 0.545 - ETA: 12s - loss: 1.7569 - accuracy: 0.545 - ETA: 10s - loss: 1.7587 - accuracy: 0.545 - ETA: 8s - loss: 1.7602 - accuracy: 0.545 - ETA: 6s - loss: 1.7604 - accuracy: 0.54 - ETA: 3s - loss: 1.7643 - accuracy: 0.54 - ETA: 1s - loss: 1.7651 - accuracy: 0.54 - 345s 18ms/step - loss: 1.7662 - accuracy: 0.5441 - val_loss: 2.2296 - val_accuracy: 0.5862\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:17 - loss: 1.4974 - accuracy: 0.58 - ETA: 5:14 - loss: 1.7154 - accuracy: 0.55 - ETA: 5:02 - loss: 1.7129 - accuracy: 0.55 - ETA: 4:57 - loss: 1.7511 - accuracy: 0.55 - ETA: 4:53 - loss: 1.6819 - accuracy: 0.56 - ETA: 4:52 - loss: 1.7079 - accuracy: 0.56 - ETA: 4:53 - loss: 1.6844 - accuracy: 0.56 - ETA: 4:54 - loss: 1.7032 - accuracy: 0.56 - ETA: 4:53 - loss: 1.7083 - accuracy: 0.55 - ETA: 4:52 - loss: 1.7558 - accuracy: 0.55 - ETA: 4:51 - loss: 1.7528 - accuracy: 0.56 - ETA: 4:48 - loss: 1.7600 - accuracy: 0.55 - ETA: 4:47 - loss: 1.7301 - accuracy: 0.56 - ETA: 4:46 - loss: 1.7266 - accuracy: 0.55 - ETA: 4:45 - loss: 1.7689 - accuracy: 0.55 - ETA: 4:44 - loss: 1.7538 - accuracy: 0.55 - ETA: 4:42 - loss: 1.7408 - accuracy: 0.55 - ETA: 4:41 - loss: 1.7174 - accuracy: 0.55 - ETA: 4:38 - loss: 1.7205 - accuracy: 0.56 - ETA: 4:36 - loss: 1.7413 - accuracy: 0.55 - ETA: 4:35 - loss: 1.7521 - accuracy: 0.55 - ETA: 4:33 - loss: 1.7536 - accuracy: 0.55 - ETA: 4:31 - loss: 1.7584 - accuracy: 0.55 - ETA: 4:30 - loss: 1.7569 - accuracy: 0.55 - ETA: 4:27 - loss: 1.7512 - accuracy: 0.55 - ETA: 4:25 - loss: 1.7538 - accuracy: 0.55 - ETA: 4:23 - loss: 1.7418 - accuracy: 0.55 - ETA: 4:20 - loss: 1.7412 - accuracy: 0.55 - ETA: 4:18 - loss: 1.7254 - accuracy: 0.55 - ETA: 4:16 - loss: 1.7373 - accuracy: 0.55 - ETA: 4:13 - loss: 1.7223 - accuracy: 0.55 - ETA: 4:11 - loss: 1.7291 - accuracy: 0.55 - ETA: 4:09 - loss: 1.7334 - accuracy: 0.55 - ETA: 4:06 - loss: 1.7377 - accuracy: 0.55 - ETA: 4:05 - loss: 1.7284 - accuracy: 0.55 - ETA: 4:03 - loss: 1.7370 - accuracy: 0.55 - ETA: 4:01 - loss: 1.7355 - accuracy: 0.55 - ETA: 3:59 - loss: 1.7356 - accuracy: 0.55 - ETA: 3:56 - loss: 1.7432 - accuracy: 0.55 - ETA: 3:54 - loss: 1.7411 - accuracy: 0.54 - ETA: 3:52 - loss: 1.7494 - accuracy: 0.54 - ETA: 3:50 - loss: 1.7476 - accuracy: 0.54 - ETA: 3:48 - loss: 1.7414 - accuracy: 0.55 - ETA: 3:46 - loss: 1.7400 - accuracy: 0.55 - ETA: 3:44 - loss: 1.7652 - accuracy: 0.54 - ETA: 3:41 - loss: 1.7562 - accuracy: 0.55 - ETA: 3:39 - loss: 1.7586 - accuracy: 0.54 - ETA: 3:37 - loss: 1.7606 - accuracy: 0.54 - ETA: 3:35 - loss: 1.7622 - accuracy: 0.54 - ETA: 3:33 - loss: 1.7687 - accuracy: 0.54 - ETA: 3:31 - loss: 1.7689 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7689 - accuracy: 0.54 - ETA: 3:27 - loss: 1.7667 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7637 - accuracy: 0.54 - ETA: 3:22 - loss: 1.7652 - accuracy: 0.54 - ETA: 3:20 - loss: 1.7633 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7538 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7515 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7550 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7608 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7569 - accuracy: 0.54 - ETA: 3:07 - loss: 1.7616 - accuracy: 0.54 - ETA: 3:05 - loss: 1.7563 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7574 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7610 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7616 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7619 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7599 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7629 - accuracy: 0.54 - ETA: 2:51 - loss: 1.7620 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7589 - accuracy: 0.54 - ETA: 2:46 - loss: 1.7605 - accuracy: 0.54 - ETA: 2:45 - loss: 1.7636 - accuracy: 0.54 - ETA: 2:42 - loss: 1.7677 - accuracy: 0.54 - ETA: 2:40 - loss: 1.7659 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7594 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7569 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7568 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7598 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7628 - accuracy: 0.54 - ETA: 2:28 - loss: 1.7650 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7652 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7628 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7782 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7759 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7770 - accuracy: 0.54 - ETA: 2:15 - loss: 1.7755 - accuracy: 0.54 - ETA: 2:13 - loss: 1.7746 - accuracy: 0.54 - ETA: 2:11 - loss: 1.7735 - accuracy: 0.54 - ETA: 2:09 - loss: 1.7719 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7750 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7756 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7743 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7759 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7773 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7776 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7765 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7740 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7740 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7737 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7703 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7702 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7723 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7709 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7707 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7699 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7676 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7676 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7651 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7625 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7607 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7615 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7623 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7648 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7679 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7681 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7654 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7655 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7649 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7688 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7687 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7698 - accuracy: 0.54 - ETA: 59s - loss: 1.7691 - accuracy: 0.5419 - ETA: 57s - loss: 1.7682 - accuracy: 0.541 - ETA: 54s - loss: 1.7687 - accuracy: 0.541 - ETA: 52s - loss: 1.7674 - accuracy: 0.541 - ETA: 50s - loss: 1.7676 - accuracy: 0.541 - ETA: 48s - loss: 1.7825 - accuracy: 0.541 - ETA: 46s - loss: 1.7831 - accuracy: 0.541 - ETA: 44s - loss: 1.7818 - accuracy: 0.541 - ETA: 42s - loss: 1.7820 - accuracy: 0.540 - ETA: 40s - loss: 1.7792 - accuracy: 0.541 - ETA: 37s - loss: 1.7757 - accuracy: 0.541 - ETA: 35s - loss: 1.7738 - accuracy: 0.542 - ETA: 33s - loss: 1.7738 - accuracy: 0.542 - ETA: 31s - loss: 1.7722 - accuracy: 0.542 - ETA: 29s - loss: 1.7707 - accuracy: 0.542 - ETA: 27s - loss: 1.7705 - accuracy: 0.542 - ETA: 25s - loss: 1.7696 - accuracy: 0.542 - ETA: 23s - loss: 1.7682 - accuracy: 0.542 - ETA: 20s - loss: 1.7721 - accuracy: 0.542 - ETA: 18s - loss: 1.7694 - accuracy: 0.543 - ETA: 16s - loss: 1.7700 - accuracy: 0.543 - ETA: 14s - loss: 1.7708 - accuracy: 0.542 - ETA: 12s - loss: 1.7711 - accuracy: 0.542 - ETA: 10s - loss: 1.7703 - accuracy: 0.542 - ETA: 8s - loss: 1.7698 - accuracy: 0.542 - ETA: 6s - loss: 1.7689 - accuracy: 0.54 - ETA: 3s - loss: 1.7679 - accuracy: 0.54 - ETA: 1s - loss: 1.7695 - accuracy: 0.54 - 344s 18ms/step - loss: 1.7672 - accuracy: 0.5433 - val_loss: 2.2054 - val_accuracy: 0.5834\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:20 - loss: 1.6760 - accuracy: 0.54 - ETA: 5:13 - loss: 1.6243 - accuracy: 0.55 - ETA: 5:17 - loss: 1.6272 - accuracy: 0.55 - ETA: 5:09 - loss: 1.5995 - accuracy: 0.57 - ETA: 5:09 - loss: 1.6624 - accuracy: 0.56 - ETA: 5:05 - loss: 1.7053 - accuracy: 0.56 - ETA: 5:04 - loss: 1.6921 - accuracy: 0.56 - ETA: 5:03 - loss: 1.6629 - accuracy: 0.57 - ETA: 5:01 - loss: 1.6574 - accuracy: 0.56 - ETA: 5:00 - loss: 1.6486 - accuracy: 0.56 - ETA: 4:57 - loss: 1.6570 - accuracy: 0.56 - ETA: 4:55 - loss: 1.6522 - accuracy: 0.56 - ETA: 4:52 - loss: 1.6659 - accuracy: 0.56 - ETA: 4:49 - loss: 1.6728 - accuracy: 0.55 - ETA: 4:47 - loss: 1.6682 - accuracy: 0.56 - ETA: 4:45 - loss: 1.6746 - accuracy: 0.55 - ETA: 4:43 - loss: 1.6882 - accuracy: 0.55 - ETA: 4:40 - loss: 1.6843 - accuracy: 0.55 - ETA: 4:38 - loss: 1.6894 - accuracy: 0.55 - ETA: 4:36 - loss: 1.6904 - accuracy: 0.55 - ETA: 4:34 - loss: 1.6933 - accuracy: 0.55 - ETA: 4:32 - loss: 1.6943 - accuracy: 0.55 - ETA: 4:30 - loss: 1.6946 - accuracy: 0.55 - ETA: 4:28 - loss: 1.7032 - accuracy: 0.55 - ETA: 4:26 - loss: 1.6912 - accuracy: 0.55 - ETA: 4:24 - loss: 1.6955 - accuracy: 0.55 - ETA: 4:21 - loss: 1.7064 - accuracy: 0.55 - ETA: 4:19 - loss: 1.7115 - accuracy: 0.55 - ETA: 4:17 - loss: 1.7114 - accuracy: 0.55 - ETA: 4:15 - loss: 1.7076 - accuracy: 0.55 - ETA: 4:13 - loss: 1.7011 - accuracy: 0.55 - ETA: 4:10 - loss: 1.6985 - accuracy: 0.55 - ETA: 4:08 - loss: 1.7005 - accuracy: 0.55 - ETA: 4:06 - loss: 1.6958 - accuracy: 0.55 - ETA: 4:04 - loss: 1.6962 - accuracy: 0.55 - ETA: 4:02 - loss: 1.6993 - accuracy: 0.55 - ETA: 4:00 - loss: 1.6943 - accuracy: 0.55 - ETA: 3:58 - loss: 1.7091 - accuracy: 0.55 - ETA: 3:56 - loss: 1.7238 - accuracy: 0.55 - ETA: 3:54 - loss: 1.7207 - accuracy: 0.55 - ETA: 3:51 - loss: 1.7180 - accuracy: 0.55 - ETA: 3:49 - loss: 1.7195 - accuracy: 0.55 - ETA: 3:47 - loss: 1.7264 - accuracy: 0.55 - ETA: 3:45 - loss: 1.7270 - accuracy: 0.55 - ETA: 3:44 - loss: 1.7277 - accuracy: 0.55 - ETA: 3:41 - loss: 1.7283 - accuracy: 0.55 - ETA: 3:39 - loss: 1.7312 - accuracy: 0.55 - ETA: 3:37 - loss: 1.7311 - accuracy: 0.55 - ETA: 3:35 - loss: 1.7334 - accuracy: 0.55 - ETA: 3:33 - loss: 1.7330 - accuracy: 0.55 - ETA: 3:31 - loss: 1.7345 - accuracy: 0.55 - ETA: 3:29 - loss: 1.7314 - accuracy: 0.55 - ETA: 3:26 - loss: 1.7296 - accuracy: 0.55 - ETA: 3:24 - loss: 1.7308 - accuracy: 0.55 - ETA: 3:22 - loss: 1.7322 - accuracy: 0.55 - ETA: 3:20 - loss: 1.7319 - accuracy: 0.55 - ETA: 3:18 - loss: 1.7356 - accuracy: 0.55 - ETA: 3:16 - loss: 1.7339 - accuracy: 0.55 - ETA: 3:14 - loss: 1.7318 - accuracy: 0.55 - ETA: 3:12 - loss: 1.7262 - accuracy: 0.55 - ETA: 3:10 - loss: 1.7274 - accuracy: 0.55 - ETA: 3:08 - loss: 1.7358 - accuracy: 0.55 - ETA: 3:06 - loss: 1.7346 - accuracy: 0.55 - ETA: 3:04 - loss: 1.7384 - accuracy: 0.55 - ETA: 3:01 - loss: 1.7593 - accuracy: 0.55 - ETA: 2:59 - loss: 1.7579 - accuracy: 0.55 - ETA: 2:57 - loss: 1.7571 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7552 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7605 - accuracy: 0.54 - ETA: 2:51 - loss: 1.7642 - accuracy: 0.54 - ETA: 2:49 - loss: 1.7601 - accuracy: 0.54 - ETA: 2:47 - loss: 1.7540 - accuracy: 0.55 - ETA: 2:45 - loss: 1.7520 - accuracy: 0.55 - ETA: 2:43 - loss: 1.7529 - accuracy: 0.54 - ETA: 2:40 - loss: 1.7493 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7490 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7478 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7466 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7446 - accuracy: 0.55 - ETA: 2:30 - loss: 1.7438 - accuracy: 0.55 - ETA: 2:28 - loss: 1.7424 - accuracy: 0.55 - ETA: 2:26 - loss: 1.7418 - accuracy: 0.55 - ETA: 2:23 - loss: 1.7377 - accuracy: 0.55 - ETA: 2:21 - loss: 1.7397 - accuracy: 0.55 - ETA: 2:19 - loss: 1.7407 - accuracy: 0.55 - ETA: 2:17 - loss: 1.7393 - accuracy: 0.55 - ETA: 2:15 - loss: 1.7349 - accuracy: 0.55 - ETA: 2:13 - loss: 1.7343 - accuracy: 0.55 - ETA: 2:11 - loss: 1.7326 - accuracy: 0.55 - ETA: 2:09 - loss: 1.7325 - accuracy: 0.55 - ETA: 2:06 - loss: 1.7337 - accuracy: 0.55 - ETA: 2:04 - loss: 1.7335 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7337 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7328 - accuracy: 0.54 - ETA: 1:58 - loss: 1.7334 - accuracy: 0.54 - ETA: 1:56 - loss: 1.7331 - accuracy: 0.54 - ETA: 1:54 - loss: 1.7389 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7380 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7389 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7389 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7409 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7413 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7409 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7410 - accuracy: 0.54 - ETA: 1:37 - loss: 1.7422 - accuracy: 0.54 - ETA: 1:35 - loss: 1.7449 - accuracy: 0.54 - ETA: 1:33 - loss: 1.7432 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7434 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7446 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7421 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7409 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7418 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7449 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7464 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7458 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7476 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7506 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7541 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7535 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7534 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7525 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7535 - accuracy: 0.54 - ETA: 59s - loss: 1.7545 - accuracy: 0.5421 - ETA: 56s - loss: 1.7565 - accuracy: 0.541 - ETA: 54s - loss: 1.7570 - accuracy: 0.541 - ETA: 52s - loss: 1.7581 - accuracy: 0.541 - ETA: 50s - loss: 1.7601 - accuracy: 0.541 - ETA: 48s - loss: 1.7607 - accuracy: 0.541 - ETA: 46s - loss: 1.7625 - accuracy: 0.541 - ETA: 44s - loss: 1.7603 - accuracy: 0.541 - ETA: 42s - loss: 1.7595 - accuracy: 0.541 - ETA: 39s - loss: 1.7584 - accuracy: 0.542 - ETA: 37s - loss: 1.7583 - accuracy: 0.542 - ETA: 35s - loss: 1.7566 - accuracy: 0.542 - ETA: 33s - loss: 1.7570 - accuracy: 0.542 - ETA: 31s - loss: 1.7572 - accuracy: 0.542 - ETA: 29s - loss: 1.7566 - accuracy: 0.542 - ETA: 27s - loss: 1.7549 - accuracy: 0.542 - ETA: 25s - loss: 1.7555 - accuracy: 0.542 - ETA: 23s - loss: 1.7562 - accuracy: 0.542 - ETA: 20s - loss: 1.7550 - accuracy: 0.542 - ETA: 18s - loss: 1.7578 - accuracy: 0.541 - ETA: 16s - loss: 1.7625 - accuracy: 0.541 - ETA: 14s - loss: 1.7628 - accuracy: 0.540 - ETA: 12s - loss: 1.7624 - accuracy: 0.540 - ETA: 10s - loss: 1.7597 - accuracy: 0.540 - ETA: 8s - loss: 1.7607 - accuracy: 0.540 - ETA: 6s - loss: 1.7604 - accuracy: 0.54 - ETA: 3s - loss: 1.7602 - accuracy: 0.54 - ETA: 1s - loss: 1.7593 - accuracy: 0.54 - 343s 18ms/step - loss: 1.7597 - accuracy: 0.5405 - val_loss: 2.0717 - val_accuracy: 0.5929\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:37 - loss: 1.7020 - accuracy: 0.54 - ETA: 5:20 - loss: 1.6277 - accuracy: 0.55 - ETA: 5:16 - loss: 1.5854 - accuracy: 0.56 - ETA: 5:09 - loss: 1.6289 - accuracy: 0.54 - ETA: 5:05 - loss: 1.6157 - accuracy: 0.56 - ETA: 5:03 - loss: 1.5994 - accuracy: 0.56 - ETA: 5:00 - loss: 1.6299 - accuracy: 0.55 - ETA: 5:01 - loss: 1.6338 - accuracy: 0.56 - ETA: 4:58 - loss: 1.6770 - accuracy: 0.55 - ETA: 4:55 - loss: 1.7031 - accuracy: 0.55 - ETA: 4:54 - loss: 1.6970 - accuracy: 0.55 - ETA: 4:53 - loss: 1.7084 - accuracy: 0.55 - ETA: 4:51 - loss: 1.7221 - accuracy: 0.54 - ETA: 4:48 - loss: 1.7130 - accuracy: 0.54 - ETA: 4:46 - loss: 1.7110 - accuracy: 0.54 - ETA: 4:44 - loss: 1.7137 - accuracy: 0.54 - ETA: 4:41 - loss: 1.7154 - accuracy: 0.54 - ETA: 4:39 - loss: 1.7296 - accuracy: 0.54 - ETA: 4:37 - loss: 1.7284 - accuracy: 0.54 - ETA: 4:35 - loss: 1.7237 - accuracy: 0.54 - ETA: 4:33 - loss: 1.7278 - accuracy: 0.54 - ETA: 4:30 - loss: 1.7205 - accuracy: 0.54 - ETA: 4:28 - loss: 1.7287 - accuracy: 0.54 - ETA: 4:26 - loss: 1.7263 - accuracy: 0.54 - ETA: 4:24 - loss: 1.7288 - accuracy: 0.54 - ETA: 4:22 - loss: 1.7356 - accuracy: 0.53 - ETA: 4:20 - loss: 1.7224 - accuracy: 0.54 - ETA: 4:18 - loss: 1.7292 - accuracy: 0.54 - ETA: 4:17 - loss: 1.7315 - accuracy: 0.54 - ETA: 4:15 - loss: 1.7248 - accuracy: 0.54 - ETA: 4:12 - loss: 1.7210 - accuracy: 0.54 - ETA: 4:10 - loss: 1.7210 - accuracy: 0.54 - ETA: 4:08 - loss: 1.7159 - accuracy: 0.54 - ETA: 4:06 - loss: 1.7064 - accuracy: 0.54 - ETA: 4:04 - loss: 1.7209 - accuracy: 0.54 - ETA: 4:02 - loss: 1.7232 - accuracy: 0.54 - ETA: 4:00 - loss: 1.7201 - accuracy: 0.54 - ETA: 3:57 - loss: 1.7219 - accuracy: 0.54 - ETA: 3:55 - loss: 1.7170 - accuracy: 0.54 - ETA: 3:53 - loss: 1.7158 - accuracy: 0.54 - ETA: 3:51 - loss: 1.7201 - accuracy: 0.54 - ETA: 3:49 - loss: 1.7136 - accuracy: 0.54 - ETA: 3:47 - loss: 1.7095 - accuracy: 0.54 - ETA: 3:45 - loss: 1.7090 - accuracy: 0.54 - ETA: 3:43 - loss: 1.7159 - accuracy: 0.54 - ETA: 3:41 - loss: 1.7160 - accuracy: 0.54 - ETA: 3:38 - loss: 1.7162 - accuracy: 0.54 - ETA: 3:36 - loss: 1.7217 - accuracy: 0.54 - ETA: 3:34 - loss: 1.7184 - accuracy: 0.54 - ETA: 3:32 - loss: 1.7217 - accuracy: 0.54 - ETA: 3:30 - loss: 1.7269 - accuracy: 0.54 - ETA: 3:28 - loss: 1.7274 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7233 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7271 - accuracy: 0.54 - ETA: 3:22 - loss: 1.7306 - accuracy: 0.53 - ETA: 3:20 - loss: 1.7316 - accuracy: 0.53 - ETA: 3:18 - loss: 1.7297 - accuracy: 0.53 - ETA: 3:16 - loss: 1.7346 - accuracy: 0.53 - ETA: 3:14 - loss: 1.7405 - accuracy: 0.53 - ETA: 3:12 - loss: 1.7424 - accuracy: 0.53 - ETA: 3:10 - loss: 1.7436 - accuracy: 0.53 - ETA: 3:08 - loss: 1.7378 - accuracy: 0.53 - ETA: 3:05 - loss: 1.7396 - accuracy: 0.53 - ETA: 3:03 - loss: 1.7468 - accuracy: 0.53 - ETA: 3:01 - loss: 1.7502 - accuracy: 0.53 - ETA: 2:59 - loss: 1.7583 - accuracy: 0.53 - ETA: 2:57 - loss: 1.7574 - accuracy: 0.53 - ETA: 2:55 - loss: 1.7609 - accuracy: 0.53 - ETA: 2:53 - loss: 1.7615 - accuracy: 0.53 - ETA: 2:51 - loss: 1.7586 - accuracy: 0.53 - ETA: 2:49 - loss: 1.7605 - accuracy: 0.53 - ETA: 2:46 - loss: 1.7589 - accuracy: 0.53 - ETA: 2:44 - loss: 1.7598 - accuracy: 0.53 - ETA: 2:42 - loss: 1.7720 - accuracy: 0.53 - ETA: 2:40 - loss: 1.7738 - accuracy: 0.53 - ETA: 2:38 - loss: 1.7723 - accuracy: 0.53 - ETA: 2:36 - loss: 1.7726 - accuracy: 0.53 - ETA: 2:34 - loss: 1.7678 - accuracy: 0.53 - ETA: 2:32 - loss: 1.7678 - accuracy: 0.53 - ETA: 2:30 - loss: 1.7771 - accuracy: 0.53 - ETA: 2:28 - loss: 1.7739 - accuracy: 0.53 - ETA: 2:25 - loss: 1.7736 - accuracy: 0.53 - ETA: 2:23 - loss: 1.7724 - accuracy: 0.53 - ETA: 2:21 - loss: 1.7706 - accuracy: 0.53 - ETA: 2:19 - loss: 1.7669 - accuracy: 0.53 - ETA: 2:17 - loss: 1.7621 - accuracy: 0.53 - ETA: 2:15 - loss: 1.7638 - accuracy: 0.53 - ETA: 2:13 - loss: 1.7636 - accuracy: 0.53 - ETA: 2:11 - loss: 1.7645 - accuracy: 0.53 - ETA: 2:09 - loss: 1.7685 - accuracy: 0.53 - ETA: 2:07 - loss: 1.7648 - accuracy: 0.53 - ETA: 2:04 - loss: 1.7650 - accuracy: 0.53 - ETA: 2:02 - loss: 1.7658 - accuracy: 0.53 - ETA: 2:00 - loss: 1.7649 - accuracy: 0.53 - ETA: 1:58 - loss: 1.7665 - accuracy: 0.53 - ETA: 1:56 - loss: 1.7652 - accuracy: 0.53 - ETA: 1:54 - loss: 1.7644 - accuracy: 0.53 - ETA: 1:52 - loss: 1.7638 - accuracy: 0.53 - ETA: 1:50 - loss: 1.7670 - accuracy: 0.53 - ETA: 1:48 - loss: 1.7666 - accuracy: 0.53 - ETA: 1:46 - loss: 1.7668 - accuracy: 0.53 - ETA: 1:44 - loss: 1.7660 - accuracy: 0.53 - ETA: 1:42 - loss: 1.7653 - accuracy: 0.53 - ETA: 1:40 - loss: 1.7638 - accuracy: 0.53 - ETA: 1:37 - loss: 1.7592 - accuracy: 0.53 - ETA: 1:35 - loss: 1.7572 - accuracy: 0.53 - ETA: 1:33 - loss: 1.7575 - accuracy: 0.54 - ETA: 1:31 - loss: 1.7618 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7595 - accuracy: 0.54 - ETA: 1:27 - loss: 1.7583 - accuracy: 0.54 - ETA: 1:25 - loss: 1.7589 - accuracy: 0.54 - ETA: 1:23 - loss: 1.7574 - accuracy: 0.54 - ETA: 1:20 - loss: 1.7572 - accuracy: 0.54 - ETA: 1:18 - loss: 1.7559 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7551 - accuracy: 0.54 - ETA: 1:14 - loss: 1.7539 - accuracy: 0.54 - ETA: 1:12 - loss: 1.7587 - accuracy: 0.54 - ETA: 1:10 - loss: 1.7596 - accuracy: 0.54 - ETA: 1:08 - loss: 1.7621 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7623 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7603 - accuracy: 0.54 - ETA: 1:01 - loss: 1.7588 - accuracy: 0.54 - ETA: 59s - loss: 1.7567 - accuracy: 0.5429 - ETA: 57s - loss: 1.7592 - accuracy: 0.542 - ETA: 55s - loss: 1.7602 - accuracy: 0.542 - ETA: 53s - loss: 1.7608 - accuracy: 0.542 - ETA: 50s - loss: 1.7594 - accuracy: 0.542 - ETA: 48s - loss: 1.7600 - accuracy: 0.542 - ETA: 46s - loss: 1.7619 - accuracy: 0.541 - ETA: 44s - loss: 1.7625 - accuracy: 0.541 - ETA: 42s - loss: 1.7616 - accuracy: 0.541 - ETA: 40s - loss: 1.7631 - accuracy: 0.542 - ETA: 38s - loss: 1.7627 - accuracy: 0.542 - ETA: 36s - loss: 1.7626 - accuracy: 0.542 - ETA: 33s - loss: 1.7597 - accuracy: 0.543 - ETA: 31s - loss: 1.7584 - accuracy: 0.543 - ETA: 29s - loss: 1.7573 - accuracy: 0.544 - ETA: 27s - loss: 1.7550 - accuracy: 0.544 - ETA: 25s - loss: 1.7555 - accuracy: 0.544 - ETA: 23s - loss: 1.7557 - accuracy: 0.544 - ETA: 21s - loss: 1.7548 - accuracy: 0.544 - ETA: 18s - loss: 1.7549 - accuracy: 0.544 - ETA: 16s - loss: 1.7534 - accuracy: 0.545 - ETA: 14s - loss: 1.7537 - accuracy: 0.544 - ETA: 12s - loss: 1.7519 - accuracy: 0.545 - ETA: 10s - loss: 1.7491 - accuracy: 0.545 - ETA: 8s - loss: 1.7513 - accuracy: 0.545 - ETA: 6s - loss: 1.7509 - accuracy: 0.54 - ETA: 3s - loss: 1.7495 - accuracy: 0.54 - ETA: 1s - loss: 1.7495 - accuracy: 0.54 - 347s 18ms/step - loss: 1.7486 - accuracy: 0.5458 - val_loss: 2.1499 - val_accuracy: 0.6024\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:05 - loss: 1.4587 - accuracy: 0.58 - ETA: 5:16 - loss: 1.4422 - accuracy: 0.59 - ETA: 5:06 - loss: 1.4694 - accuracy: 0.58 - ETA: 5:06 - loss: 1.5380 - accuracy: 0.57 - ETA: 5:04 - loss: 1.5640 - accuracy: 0.55 - ETA: 5:04 - loss: 1.5347 - accuracy: 0.57 - ETA: 5:02 - loss: 1.5355 - accuracy: 0.57 - ETA: 5:00 - loss: 1.5488 - accuracy: 0.56 - ETA: 4:57 - loss: 1.5804 - accuracy: 0.55 - ETA: 4:57 - loss: 1.5923 - accuracy: 0.55 - ETA: 4:54 - loss: 1.6203 - accuracy: 0.55 - ETA: 4:53 - loss: 1.6175 - accuracy: 0.55 - ETA: 4:51 - loss: 1.6132 - accuracy: 0.55 - ETA: 4:48 - loss: 1.6237 - accuracy: 0.54 - ETA: 4:45 - loss: 1.6369 - accuracy: 0.54 - ETA: 4:42 - loss: 1.6186 - accuracy: 0.55 - ETA: 4:40 - loss: 1.6313 - accuracy: 0.55 - ETA: 4:38 - loss: 1.6718 - accuracy: 0.55 - ETA: 4:37 - loss: 1.6728 - accuracy: 0.55 - ETA: 4:34 - loss: 1.6625 - accuracy: 0.55 - ETA: 4:32 - loss: 1.6649 - accuracy: 0.55 - ETA: 4:29 - loss: 1.6670 - accuracy: 0.55 - ETA: 4:28 - loss: 1.6786 - accuracy: 0.54 - ETA: 4:26 - loss: 1.6856 - accuracy: 0.54 - ETA: 4:24 - loss: 1.6784 - accuracy: 0.54 - ETA: 4:22 - loss: 1.6732 - accuracy: 0.54 - ETA: 4:20 - loss: 1.6721 - accuracy: 0.54 - ETA: 4:18 - loss: 1.6788 - accuracy: 0.54 - ETA: 4:16 - loss: 1.6782 - accuracy: 0.54 - ETA: 4:14 - loss: 1.6793 - accuracy: 0.54 - ETA: 4:13 - loss: 1.6877 - accuracy: 0.54 - ETA: 4:11 - loss: 1.6886 - accuracy: 0.54 - ETA: 4:08 - loss: 1.6895 - accuracy: 0.54 - ETA: 4:07 - loss: 1.6953 - accuracy: 0.54 - ETA: 4:04 - loss: 1.6945 - accuracy: 0.54 - ETA: 4:02 - loss: 1.6989 - accuracy: 0.54 - ETA: 4:00 - loss: 1.6992 - accuracy: 0.54 - ETA: 3:58 - loss: 1.6977 - accuracy: 0.54 - ETA: 3:56 - loss: 1.6964 - accuracy: 0.54 - ETA: 3:54 - loss: 1.6977 - accuracy: 0.54 - ETA: 3:52 - loss: 1.6950 - accuracy: 0.54 - ETA: 3:50 - loss: 1.6995 - accuracy: 0.54 - ETA: 3:48 - loss: 1.6998 - accuracy: 0.54 - ETA: 3:46 - loss: 1.7054 - accuracy: 0.54 - ETA: 3:44 - loss: 1.7046 - accuracy: 0.54 - ETA: 3:41 - loss: 1.7056 - accuracy: 0.54 - ETA: 3:39 - loss: 1.7115 - accuracy: 0.54 - ETA: 3:37 - loss: 1.7128 - accuracy: 0.54 - ETA: 3:35 - loss: 1.7135 - accuracy: 0.54 - ETA: 3:33 - loss: 1.7158 - accuracy: 0.54 - ETA: 3:31 - loss: 1.7119 - accuracy: 0.54 - ETA: 3:29 - loss: 1.7132 - accuracy: 0.54 - ETA: 3:26 - loss: 1.7106 - accuracy: 0.54 - ETA: 3:24 - loss: 1.7082 - accuracy: 0.54 - ETA: 3:22 - loss: 1.7083 - accuracy: 0.54 - ETA: 3:20 - loss: 1.7070 - accuracy: 0.54 - ETA: 3:18 - loss: 1.7055 - accuracy: 0.54 - ETA: 3:16 - loss: 1.7010 - accuracy: 0.54 - ETA: 3:14 - loss: 1.7060 - accuracy: 0.54 - ETA: 3:12 - loss: 1.7074 - accuracy: 0.54 - ETA: 3:10 - loss: 1.7041 - accuracy: 0.54 - ETA: 3:08 - loss: 1.6989 - accuracy: 0.54 - ETA: 3:06 - loss: 1.7049 - accuracy: 0.54 - ETA: 3:03 - loss: 1.7057 - accuracy: 0.54 - ETA: 3:01 - loss: 1.7070 - accuracy: 0.54 - ETA: 2:59 - loss: 1.7078 - accuracy: 0.54 - ETA: 2:57 - loss: 1.7065 - accuracy: 0.54 - ETA: 2:55 - loss: 1.7066 - accuracy: 0.54 - ETA: 2:53 - loss: 1.7096 - accuracy: 0.54 - ETA: 2:51 - loss: 1.7078 - accuracy: 0.54 - ETA: 2:48 - loss: 1.7111 - accuracy: 0.54 - ETA: 2:46 - loss: 1.7085 - accuracy: 0.54 - ETA: 2:44 - loss: 1.7090 - accuracy: 0.54 - ETA: 2:42 - loss: 1.7116 - accuracy: 0.54 - ETA: 2:40 - loss: 1.7186 - accuracy: 0.54 - ETA: 2:38 - loss: 1.7203 - accuracy: 0.54 - ETA: 2:36 - loss: 1.7185 - accuracy: 0.54 - ETA: 2:34 - loss: 1.7188 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7256 - accuracy: 0.54 - ETA: 2:30 - loss: 1.7283 - accuracy: 0.54 - ETA: 2:27 - loss: 1.7286 - accuracy: 0.54 - ETA: 2:25 - loss: 1.7325 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7327 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7349 - accuracy: 0.54 - ETA: 2:19 - loss: 1.7376 - accuracy: 0.54 - ETA: 2:17 - loss: 1.7408 - accuracy: 0.54 - ETA: 2:14 - loss: 1.7392 - accuracy: 0.54 - ETA: 2:12 - loss: 1.7491 - accuracy: 0.54 - ETA: 2:10 - loss: 1.7483 - accuracy: 0.54 - ETA: 2:08 - loss: 1.7492 - accuracy: 0.54 - ETA: 2:06 - loss: 1.7486 - accuracy: 0.54 - ETA: 2:04 - loss: 1.7487 - accuracy: 0.54 - ETA: 2:02 - loss: 1.7472 - accuracy: 0.54 - ETA: 2:00 - loss: 1.7464 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7449 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7463 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7450 - accuracy: 0.54 - ETA: 1:51 - loss: 1.7484 - accuracy: 0.54 - ETA: 1:49 - loss: 1.7483 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7449 - accuracy: 0.54 - ETA: 1:45 - loss: 1.7414 - accuracy: 0.54 - ETA: 1:43 - loss: 1.7502 - accuracy: 0.54 - ETA: 1:41 - loss: 1.7481 - accuracy: 0.54 - ETA: 1:39 - loss: 1.7479 - accuracy: 0.54 - ETA: 1:36 - loss: 1.7483 - accuracy: 0.54 - ETA: 1:34 - loss: 1.7473 - accuracy: 0.54 - ETA: 1:32 - loss: 1.7528 - accuracy: 0.54 - ETA: 1:30 - loss: 1.7549 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7542 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7534 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7538 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7548 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7520 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7530 - accuracy: 0.54 - ETA: 1:15 - loss: 1.7526 - accuracy: 0.54 - ETA: 1:13 - loss: 1.7515 - accuracy: 0.54 - ETA: 1:11 - loss: 1.7525 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7552 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7551 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7560 - accuracy: 0.54 - ETA: 1:03 - loss: 1.7556 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7543 - accuracy: 0.54 - ETA: 58s - loss: 1.7545 - accuracy: 0.5448 - ETA: 56s - loss: 1.7569 - accuracy: 0.545 - ETA: 54s - loss: 1.7540 - accuracy: 0.545 - ETA: 52s - loss: 1.7556 - accuracy: 0.545 - ETA: 50s - loss: 1.7545 - accuracy: 0.545 - ETA: 48s - loss: 1.7526 - accuracy: 0.545 - ETA: 46s - loss: 1.7522 - accuracy: 0.545 - ETA: 44s - loss: 1.7526 - accuracy: 0.545 - ETA: 41s - loss: 1.7533 - accuracy: 0.545 - ETA: 39s - loss: 1.7527 - accuracy: 0.545 - ETA: 37s - loss: 1.7549 - accuracy: 0.545 - ETA: 35s - loss: 1.7528 - accuracy: 0.545 - ETA: 33s - loss: 1.7532 - accuracy: 0.545 - ETA: 31s - loss: 1.7563 - accuracy: 0.545 - ETA: 29s - loss: 1.7527 - accuracy: 0.546 - ETA: 27s - loss: 1.7498 - accuracy: 0.547 - ETA: 25s - loss: 1.7520 - accuracy: 0.546 - ETA: 22s - loss: 1.7503 - accuracy: 0.546 - ETA: 20s - loss: 1.7488 - accuracy: 0.546 - ETA: 18s - loss: 1.7483 - accuracy: 0.547 - ETA: 16s - loss: 1.7464 - accuracy: 0.547 - ETA: 14s - loss: 1.7516 - accuracy: 0.547 - ETA: 12s - loss: 1.7525 - accuracy: 0.547 - ETA: 10s - loss: 1.7540 - accuracy: 0.547 - ETA: 8s - loss: 1.7583 - accuracy: 0.547 - ETA: 6s - loss: 1.7568 - accuracy: 0.54 - ETA: 3s - loss: 1.7556 - accuracy: 0.54 - ETA: 1s - loss: 1.7575 - accuracy: 0.54 - 343s 18ms/step - loss: 1.7604 - accuracy: 0.5480 - val_loss: 2.5360 - val_accuracy: 0.5947\n",
      "2020-12-09 04:41:30.398495\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "t5=datetime.datetime.now()\n",
    "print(t5)\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n",
    "t6=datetime.datetime.now()\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [2.143079996306498, 1.8711823611359193, 1.8111261528307026, 1.7069350545710968, 1.651108425506328, 1.7255563149666484, 1.649727874079657, 1.7379362565139531, 1.753119312203629, 1.6176455932069354, 1.6192845297442333, 1.651926605097624, 1.6920277404103818, 1.663318316149993, 1.6492499188869285, 1.809238104845925, 1.7179990766161495, 1.697679412910523, 1.681444836196062, 1.7100093046511446, 1.7845078899293094, 1.7221619184280335, 1.6903434209039576, 1.7602791184839883, 1.7621624398661044, 1.711890895659446, 1.788616825567069, 1.7862531912699573, 1.775094618262107, 1.7767582883941484, 1.8098691465149115, 1.76084914323977, 1.821471023001664, 1.8418041550365138, 1.7675484614383115, 1.785536348856762, 1.7707795975592893, 1.9113936381301517, 1.827444949488779, 1.8461086135839768, 1.891169455782625, 1.8324176469533482, 1.978238717742923, 1.8493189929953073, 1.927216328432111, 1.8675808536510188, 1.8121931711865598, 1.9128474664382003, 1.9051779918627207, 1.894657901513895, 1.9874023452607907, 1.9550914288949561, 1.9386206462926858, 1.870966285399261, 2.03736056306886, 1.9928065157252628, 1.8539137287301835, 1.8732767268030952, 2.00393665604622, 2.0330951074360075, 1.8826740893253162, 2.8003042594422265, 1.9349364952953194, 1.970914302614812, 1.9802990997027698, 2.074959438936783, 2.016288019381934, 1.9103566419512965, 2.09545198010717, 2.092555552467991, 1.9286986385030662, 2.0834369817908738, 2.0427219800806906, 2.2942900576930185, 2.077734631345642, 2.087657572394154, 2.0811108931865125, 2.1012967969596597, 2.0710133212919586, 2.1074045530928665, 2.0457188771313626, 2.2086281232346066, 2.1720968265418903, 2.1699252222408343, 2.049384724503843, 2.249182683559006, 2.0932642224660003, 2.229224354392822, 2.4217324519310464, 2.1093769739764796, 2.1212931883510384, 2.3102801263048476, 2.4872331870320568, 2.362502675319118, 2.3390256721649045, 2.2295627569554877, 2.205435027960641, 2.0717264041073156, 2.1499393731077947, 2.53600155978895], 'val_accuracy': [0.5054876804351807, 0.5522882342338562, 0.5645061135292053, 0.5810726881027222, 0.5916338562965393, 0.5732035636901855, 0.5734106302261353, 0.5891488790512085, 0.5819010138511658, 0.5910126566886902, 0.6024021506309509, 0.5887347459793091, 0.5767239332199097, 0.5889418125152588, 0.5870780944824219, 0.5848001837730408, 0.5924621820449829, 0.594740092754364, 0.5939117670059204, 0.6067509055137634, 0.5887347459793091, 0.5943259596824646, 0.5785877108573914, 0.5891488790512085, 0.5819010138511658, 0.593497633934021, 0.5953613519668579, 0.5816939473152161, 0.5854213833808899, 0.590598464012146, 0.5885276198387146, 0.5910126566886902, 0.5968109369277954, 0.5825222730636597, 0.5968109369277954, 0.5916338562965393, 0.5922551155090332, 0.5897701382637024, 0.5926693081855774, 0.594740092754364, 0.5920480489730835, 0.6013667583465576, 0.5949472188949585, 0.586456835269928, 0.5897701382637024, 0.5941188931465149, 0.5961896777153015, 0.5858355760574341, 0.5845930576324463, 0.5924621820449829, 0.5862497687339783, 0.5926693081855774, 0.5897701382637024, 0.594740092754364, 0.6042658686637878, 0.6053013205528259, 0.5939117670059204, 0.5887347459793091, 0.5816939473152161, 0.6011596322059631, 0.6007454991340637, 0.5678194165229797, 0.6036446690559387, 0.6011596322059631, 0.5953613519668579, 0.5968109369277954, 0.5943259596824646, 0.5895630717277527, 0.5984675884246826, 0.5920480489730835, 0.6015738248825073, 0.6024021506309509, 0.5800372958183289, 0.6050941944122314, 0.5941188931465149, 0.6040588021278381, 0.6038517355918884, 0.6042658686637878, 0.5968109369277954, 0.5920480489730835, 0.601780891418457, 0.5941188931465149, 0.6021950840950012, 0.5959826111793518, 0.5939117670059204, 0.6019880175590515, 0.5959826111793518, 0.5930834412574768, 0.5953613519668579, 0.5920480489730835, 0.5916338562965393, 0.5901843309402466, 0.5988817811012268, 0.593497633934021, 0.5986746549606323, 0.5862497687339783, 0.5833505988121033, 0.5928763747215271, 0.6024021506309509, 0.594740092754364], 'loss': [6.798679623015182, 2.594997218945052, 2.430134373848954, 2.254901454778575, 2.193445119269149, 2.139621755162249, 2.0834532661090335, 2.0225423279140444, 2.0665514785194556, 1.9508833625441064, 1.9366213774621832, 1.9548757750828007, 1.937701049775453, 1.874975717057842, 1.9095195956534359, 1.9158636019461, 1.8952960209502794, 1.9336018921821296, 1.9038237654283803, 1.907564501873007, 1.9091515047251932, 1.8251917181473285, 1.9246559441336542, 1.881997581444798, 1.8239272904968893, 1.8791178599209852, 1.8492684654687788, 1.8910709233351157, 1.9043776262073153, 1.8548324093309037, 1.8807956746716883, 1.8260477216360287, 1.8268823657237308, 1.8407909291385123, 1.8718455482734169, 1.9072072311383985, 1.8486001397719933, 1.8146238859369426, 1.8567427593316534, 1.7882633617127741, 1.8256764990688852, 1.8302219841434824, 1.800429588324192, 1.8678515331747123, 1.8696955715019838, 1.8522352107616131, 1.7683662754894784, 1.8253946224321682, 1.8562032688523287, 1.7740862369537354, 1.793992592464722, 1.829230749024373, 1.8267485683578644, 1.7686762435434273, 1.7757567787525963, 1.8643353811057026, 1.7539213699255487, 1.7347529158675186, 1.847665699237422, 1.7989346892160132, 1.7745752976566873, 1.7774985258304687, 1.7771707398889474, 1.8151891705608605, 1.82232693353762, 1.813476795585272, 1.7963386015548326, 1.7792155484868755, 1.764250903951302, 1.7612668871385753, 1.7640901111628067, 1.749469546019389, 1.7853355583516448, 1.7733793305086516, 1.758223626568185, 1.7605233197382095, 1.7898749773820373, 1.7730990776664082, 1.77340212851985, 1.7736205006791426, 1.7716935763402526, 1.7509531547140265, 1.7195693213977197, 1.7319044266837436, 1.7516834178836067, 1.7819559773632387, 1.8250695968721165, 1.7776367084586926, 1.7367782751785, 1.786490712169783, 1.7294384165055117, 1.7610134986578776, 1.7931417346296967, 1.7670914131249884, 1.7163579806673102, 1.766177136244217, 1.767245187281377, 1.759700285864943, 1.7485617982916528, 1.7604381887993739], 'accuracy': [0.3052506, 0.42869717, 0.47074357, 0.48581192, 0.49373448, 0.49963754, 0.5093724, 0.51739854, 0.51812345, 0.52423364, 0.52884215, 0.5224731, 0.52594244, 0.52506214, 0.52728873, 0.52837616, 0.527703, 0.5321044, 0.531483, 0.52640843, 0.53044736, 0.5395609, 0.5293082, 0.533865, 0.5434445, 0.5359362, 0.5370754, 0.53194904, 0.5329847, 0.5330365, 0.53495234, 0.5379557, 0.53314, 0.5323115, 0.5292564, 0.5346935, 0.5369718, 0.5368165, 0.5363504, 0.53805923, 0.5362987, 0.54359984, 0.5417875, 0.5373343, 0.537645, 0.535522, 0.5386288, 0.534797, 0.5291011, 0.53422743, 0.5387324, 0.537645, 0.5369201, 0.5387324, 0.53888774, 0.54349625, 0.5431856, 0.543082, 0.5321044, 0.53821456, 0.54354805, 0.54448014, 0.5412179, 0.5362469, 0.5398198, 0.53723073, 0.5378521, 0.54142505, 0.5446872, 0.54354805, 0.54380697, 0.54437655, 0.5414768, 0.5406483, 0.54515326, 0.5407001, 0.5440141, 0.55276513, 0.5464996, 0.54494613, 0.5423053, 0.54183924, 0.5472763, 0.54660314, 0.5486744, 0.5467585, 0.542616, 0.540959, 0.5477423, 0.5446872, 0.5464996, 0.5455157, 0.54587823, 0.542616, 0.54582644, 0.5441176, 0.5432891, 0.54054475, 0.54577464, 0.5480012]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = np.arange(0, len(history.history['loss']))\n",
    "\n",
    "# You can chose the style of your preference\n",
    "# print(plt.style.available) to see the available options\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "plt.figure()\n",
    "plt.plot(N, history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(N, history.history['accuracy'], label = \"train_acc\")\n",
    "plt.plot(N, history.history['val_loss'], label = \"val_loss\")\n",
    "plt.plot(N, history.history['val_accuracy'], label = \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# Make sure there exists a folder called output in the current directory\n",
    "# or replace 'output' with whatever direcory you want to put in the plots\n",
    "plt.show()\n",
    "plt.savefig('../Output/EpochResNet101V2.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
