{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet_v2 import ResNet101V2\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24136</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24137</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24138</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24139</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24140</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image class\n",
       "24136  winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg  wave\n",
       "24137  winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg  wave\n",
       "24138  winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg  wave\n",
       "24139  winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg  wave\n",
       "24140  winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg  wave"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_2.csv')\n",
    "train.sort_values(by=['class', 'image'])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24141/24141 [03:25<00:00, 117.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/train_frame2/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24141, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X = np.array(train_image,np.float16)\n",
    "train_image=[]\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 224, 224, 3)\n",
      "(4829, 224, 224, 3)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained ResNet101V2 model\n",
    "base_model = ResNet101V2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet101v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, None, None, 6 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, None, None, 6 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, None, None, 2 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, None, None, 2 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, None, None, 2 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, None, None, 2 0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, None, None, 2 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, None, None, 5 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, None, None, 5 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, None, None, 5 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, None, None, 5 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, None, None, 5 0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, None, None, 5 0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, None, None, 1 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, None, None, 1 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, None, None, 1 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, None, None, 1 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, None, None, 1 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, None, None, 1 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, None, None, 1 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block7_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, None, None, 2 0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, None, None, 2 0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, None, None, 1 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, None, None, 1 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, None, None, 2 0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, None, None, 2 0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, None, None, 1 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, None, None, 1 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, None, None, 2 0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, None, None, 2 0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, None, None, 1 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, None, None, 1 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, None, None, 1 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, None, None, 2 0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, None, None, 2 0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, None, None, 1 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, None, None, 1 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, None, None, 1 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, None, None, 2 0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, None, None, 2 0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, None, None, 1 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, None, None, 1 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, None, None, 1 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, None, None, 2 0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, None, None, 2 0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, None, None, 1 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, None, None, 1 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, None, None, 1 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, None, None, 2 0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, None, None, 2 0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, None, None, 1 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, None, None, 1 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, None, None, 1 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, None, None, 2 0           conv4_block14_1_bn[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, None, None, 2 0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, None, None, 1 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, None, None, 1 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, None, None, 1 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, None, None, 2 0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, None, None, 2 0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, None, None, 1 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, None, None, 1 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, None, None, 1 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, None, None, 2 0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, None, None, 2 0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, None, None, 1 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, None, None, 1 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, None, None, 1 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, None, None, 2 0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, None, None, 2 0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, None, None, 1 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, None, None, 1 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, None, None, 1 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, None, None, 2 0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, None, None, 2 0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, None, None, 1 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, None, None, 1 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, None, None, 1 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, None, None, 2 0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, None, None, 2 0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, None, None, 1 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, None, None, 1 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, None, None, 1 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, None, None, 2 0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, None, None, 2 0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, None, None, 1 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, None, None, 1 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, None, None, 1 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, None, None, 2 0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block21_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, None, None, 2 0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, None, None, 1 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, None, None, 1 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, None, None, 1 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, None, None, 2 0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, None, None, 2 0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, None, None, 1 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, None, None, 1 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, None, None, 1 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, None, None, 2 0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, None, None, 2 0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, None, None, 1 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, None, None, 1 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, None, None, 2 0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, None, None, 2 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, None, None, 2 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, None, None, 2 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, None, None, 2 0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 42,626,560\n",
      "Trainable params: 42,528,896\n",
      "Non-trainable params: 97,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'resnet101v2',\n",
       " 'layers': [{'name': 'input_1',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_1'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'conv1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((3, 3), (3, 3)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (7, 7),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'pool1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pool',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'pool1_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool1_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_0_conv', 0, 0, {}],\n",
       "     ['conv2_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}],\n",
       "     ['conv2_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_1',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_1', 0, 0, {}],\n",
       "     ['conv2_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_0_conv', 0, 0, {}],\n",
       "     ['conv3_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}],\n",
       "     ['conv3_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}],\n",
       "     ['conv3_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_2',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}],\n",
       "     ['conv3_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_0_conv', 0, 0, {}],\n",
       "     ['conv4_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}],\n",
       "     ['conv4_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}],\n",
       "     ['conv4_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}],\n",
       "     ['conv4_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block5_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block5_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}],\n",
       "     ['conv4_block5_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block6_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block6_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}],\n",
       "     ['conv4_block6_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block7_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block7_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}],\n",
       "     ['conv4_block7_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block8_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block8_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}],\n",
       "     ['conv4_block8_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block9_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block9_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}],\n",
       "     ['conv4_block9_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block10_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block10_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}],\n",
       "     ['conv4_block10_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block11_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block11_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}],\n",
       "     ['conv4_block11_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block12_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block12_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}],\n",
       "     ['conv4_block12_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block13_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block13_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}],\n",
       "     ['conv4_block13_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block14_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block14_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}],\n",
       "     ['conv4_block14_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block15_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block15_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}],\n",
       "     ['conv4_block15_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block16_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block16_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}],\n",
       "     ['conv4_block16_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block17_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block17_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}],\n",
       "     ['conv4_block17_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block18_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block18_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}],\n",
       "     ['conv4_block18_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block19_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block19_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}],\n",
       "     ['conv4_block19_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block20_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block20_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}],\n",
       "     ['conv4_block20_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block21_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block21_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}],\n",
       "     ['conv4_block21_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block22_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block22_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}],\n",
       "     ['conv4_block22_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block23_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_3',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block23_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_3', 0, 0, {}],\n",
       "     ['conv4_block23_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_0_conv', 0, 0, {}],\n",
       "     ['conv5_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}],\n",
       "     ['conv5_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}],\n",
       "     ['conv5_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'post_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'post_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'post_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'post_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['post_bn', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['post_relu', 0, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1=datetime.datetime.now()\n",
    "print(t1)\n",
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "print(X_train.shape)\n",
    "t2=datetime.datetime.now()\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(19312, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(X_train, '../Pickle/ResNet101V2_X_train_2.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t3=datetime.datetime.now()\n",
    "print(t3)\n",
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "print(X_test.shape)\n",
    "t4=datetime.datetime.now()\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test = X_test.reshape(4829, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib.dump(X_test, '../Pickle/ResNet101V2_X_test_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "X_train = joblib.load('../Pickle/ResNet101V2_X_train_2.pkl') \n",
    "X_test = joblib.load('../Pickle/ResNet101V2_X_test_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 100352)\n",
      "(4829, 100352)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "# shape of images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 51)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 51)                52275     \n",
      "=================================================================\n",
      "Total params: 102,813,747\n",
      "Trainable params: 102,813,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('../Models/weightResNet101V2_7.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adamax',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-08 00:28:31.559229\n",
      "Train on 19312 samples, validate on 4829 samples\n",
      "Epoch 1/100\n",
      "19312/19312 [==============================] - ETA: 12:04 - loss: 9.2388 - accuracy: 0.007 - ETA: 10:06 - loss: 26.2194 - accuracy: 0.05 - ETA: 9:28 - loss: 40.0241 - accuracy: 0.0521 - ETA: 8:44 - loss: 42.8583 - accuracy: 0.060 - ETA: 8:09 - loss: 46.7801 - accuracy: 0.071 - ETA: 7:43 - loss: 47.6548 - accuracy: 0.076 - ETA: 7:20 - loss: 46.1145 - accuracy: 0.083 - ETA: 7:03 - loss: 43.8418 - accuracy: 0.097 - ETA: 6:49 - loss: 41.8089 - accuracy: 0.108 - ETA: 6:36 - loss: 39.3934 - accuracy: 0.118 - ETA: 6:30 - loss: 36.8353 - accuracy: 0.129 - ETA: 6:22 - loss: 34.6562 - accuracy: 0.135 - ETA: 6:13 - loss: 32.6160 - accuracy: 0.145 - ETA: 6:08 - loss: 30.8517 - accuracy: 0.146 - ETA: 6:02 - loss: 29.2381 - accuracy: 0.148 - ETA: 5:58 - loss: 27.7671 - accuracy: 0.150 - ETA: 5:55 - loss: 26.3963 - accuracy: 0.154 - ETA: 5:51 - loss: 25.1448 - accuracy: 0.160 - ETA: 5:45 - loss: 24.0196 - accuracy: 0.166 - ETA: 5:41 - loss: 22.9978 - accuracy: 0.169 - ETA: 5:36 - loss: 22.0750 - accuracy: 0.171 - ETA: 5:33 - loss: 21.2539 - accuracy: 0.172 - ETA: 5:29 - loss: 20.4758 - accuracy: 0.175 - ETA: 5:25 - loss: 19.7654 - accuracy: 0.176 - ETA: 5:24 - loss: 19.1057 - accuracy: 0.178 - ETA: 5:20 - loss: 18.5104 - accuracy: 0.177 - ETA: 5:18 - loss: 17.9478 - accuracy: 0.178 - ETA: 5:14 - loss: 17.4254 - accuracy: 0.178 - ETA: 5:11 - loss: 16.9346 - accuracy: 0.180 - ETA: 5:08 - loss: 16.4812 - accuracy: 0.180 - ETA: 5:05 - loss: 16.0570 - accuracy: 0.179 - ETA: 5:02 - loss: 15.6541 - accuracy: 0.180 - ETA: 4:59 - loss: 15.2792 - accuracy: 0.180 - ETA: 4:56 - loss: 14.9304 - accuracy: 0.181 - ETA: 4:52 - loss: 14.6069 - accuracy: 0.182 - ETA: 4:48 - loss: 14.2927 - accuracy: 0.183 - ETA: 4:45 - loss: 13.9927 - accuracy: 0.184 - ETA: 4:42 - loss: 13.7104 - accuracy: 0.185 - ETA: 4:39 - loss: 13.4489 - accuracy: 0.185 - ETA: 4:36 - loss: 13.1988 - accuracy: 0.185 - ETA: 4:32 - loss: 12.9511 - accuracy: 0.187 - ETA: 4:29 - loss: 12.7242 - accuracy: 0.186 - ETA: 4:26 - loss: 12.4960 - accuracy: 0.189 - ETA: 4:24 - loss: 12.2795 - accuracy: 0.191 - ETA: 4:21 - loss: 12.0747 - accuracy: 0.194 - ETA: 4:19 - loss: 11.8801 - accuracy: 0.196 - ETA: 4:16 - loss: 11.6897 - accuracy: 0.197 - ETA: 4:13 - loss: 11.5134 - accuracy: 0.198 - ETA: 4:10 - loss: 11.3408 - accuracy: 0.200 - ETA: 4:07 - loss: 11.1780 - accuracy: 0.200 - ETA: 4:05 - loss: 11.0148 - accuracy: 0.201 - ETA: 4:02 - loss: 10.8576 - accuracy: 0.204 - ETA: 3:59 - loss: 10.7091 - accuracy: 0.205 - ETA: 3:57 - loss: 10.5681 - accuracy: 0.206 - ETA: 3:54 - loss: 10.4303 - accuracy: 0.207 - ETA: 3:51 - loss: 10.2930 - accuracy: 0.210 - ETA: 3:48 - loss: 10.1603 - accuracy: 0.212 - ETA: 3:46 - loss: 10.0344 - accuracy: 0.215 - ETA: 3:44 - loss: 9.9184 - accuracy: 0.216 - ETA: 3:41 - loss: 9.8013 - accuracy: 0.21 - ETA: 3:38 - loss: 9.6904 - accuracy: 0.22 - ETA: 3:35 - loss: 9.5791 - accuracy: 0.22 - ETA: 3:33 - loss: 9.4766 - accuracy: 0.22 - ETA: 3:30 - loss: 9.3786 - accuracy: 0.22 - ETA: 3:28 - loss: 9.2846 - accuracy: 0.22 - ETA: 3:25 - loss: 9.1905 - accuracy: 0.22 - ETA: 3:22 - loss: 9.1014 - accuracy: 0.22 - ETA: 3:20 - loss: 9.0105 - accuracy: 0.22 - ETA: 3:17 - loss: 8.9176 - accuracy: 0.23 - ETA: 3:15 - loss: 8.8309 - accuracy: 0.23 - ETA: 3:12 - loss: 8.7484 - accuracy: 0.23 - ETA: 3:10 - loss: 8.6700 - accuracy: 0.23 - ETA: 3:08 - loss: 8.5885 - accuracy: 0.23 - ETA: 3:06 - loss: 8.5092 - accuracy: 0.23 - ETA: 3:03 - loss: 8.4324 - accuracy: 0.24 - ETA: 3:01 - loss: 8.3574 - accuracy: 0.24 - ETA: 2:59 - loss: 8.2865 - accuracy: 0.24 - ETA: 2:56 - loss: 8.2159 - accuracy: 0.24 - ETA: 2:54 - loss: 8.1466 - accuracy: 0.24 - ETA: 2:52 - loss: 8.0785 - accuracy: 0.24 - ETA: 2:49 - loss: 8.0127 - accuracy: 0.24 - ETA: 2:47 - loss: 7.9498 - accuracy: 0.24 - ETA: 2:45 - loss: 7.8852 - accuracy: 0.25 - ETA: 2:42 - loss: 7.8241 - accuracy: 0.25 - ETA: 2:40 - loss: 7.7692 - accuracy: 0.25 - ETA: 2:38 - loss: 7.7141 - accuracy: 0.25 - ETA: 2:35 - loss: 7.6577 - accuracy: 0.25 - ETA: 2:33 - loss: 7.6011 - accuracy: 0.25 - ETA: 2:30 - loss: 7.5497 - accuracy: 0.25 - ETA: 2:28 - loss: 7.4992 - accuracy: 0.25 - ETA: 2:26 - loss: 7.4512 - accuracy: 0.25 - ETA: 2:23 - loss: 7.3985 - accuracy: 0.25 - ETA: 2:21 - loss: 7.3448 - accuracy: 0.26 - ETA: 2:18 - loss: 7.2945 - accuracy: 0.26 - ETA: 2:16 - loss: 7.2475 - accuracy: 0.26 - ETA: 2:14 - loss: 7.2010 - accuracy: 0.26 - ETA: 2:11 - loss: 7.1523 - accuracy: 0.26 - ETA: 2:09 - loss: 7.1051 - accuracy: 0.26 - ETA: 2:07 - loss: 7.0592 - accuracy: 0.26 - ETA: 2:04 - loss: 7.0152 - accuracy: 0.26 - ETA: 2:02 - loss: 6.9701 - accuracy: 0.27 - ETA: 2:00 - loss: 6.9268 - accuracy: 0.27 - ETA: 1:58 - loss: 6.8858 - accuracy: 0.27 - ETA: 1:55 - loss: 6.8450 - accuracy: 0.27 - ETA: 1:53 - loss: 6.8049 - accuracy: 0.27 - ETA: 1:50 - loss: 6.7675 - accuracy: 0.27 - ETA: 1:48 - loss: 6.7326 - accuracy: 0.27 - ETA: 1:46 - loss: 6.6949 - accuracy: 0.27 - ETA: 1:43 - loss: 6.6567 - accuracy: 0.27 - ETA: 1:41 - loss: 6.6187 - accuracy: 0.27 - ETA: 1:38 - loss: 6.5818 - accuracy: 0.27 - ETA: 1:36 - loss: 6.5453 - accuracy: 0.28 - ETA: 1:33 - loss: 6.5075 - accuracy: 0.28 - ETA: 1:31 - loss: 6.4734 - accuracy: 0.28 - ETA: 1:28 - loss: 6.4384 - accuracy: 0.28 - ETA: 1:26 - loss: 6.4054 - accuracy: 0.28 - ETA: 1:24 - loss: 6.3728 - accuracy: 0.28 - ETA: 1:21 - loss: 6.3394 - accuracy: 0.28 - ETA: 1:19 - loss: 6.3045 - accuracy: 0.28 - ETA: 1:16 - loss: 6.2715 - accuracy: 0.28 - ETA: 1:14 - loss: 6.2410 - accuracy: 0.29 - ETA: 1:11 - loss: 6.2107 - accuracy: 0.29 - ETA: 1:09 - loss: 6.1790 - accuracy: 0.29 - ETA: 1:06 - loss: 6.1474 - accuracy: 0.29 - ETA: 1:04 - loss: 6.1180 - accuracy: 0.29 - ETA: 1:01 - loss: 6.0872 - accuracy: 0.29 - ETA: 59s - loss: 6.0591 - accuracy: 0.2969 - ETA: 56s - loss: 6.0324 - accuracy: 0.298 - ETA: 54s - loss: 6.0066 - accuracy: 0.298 - ETA: 51s - loss: 5.9819 - accuracy: 0.299 - ETA: 49s - loss: 5.9556 - accuracy: 0.299 - ETA: 46s - loss: 5.9277 - accuracy: 0.300 - ETA: 44s - loss: 5.9024 - accuracy: 0.301 - ETA: 41s - loss: 5.8755 - accuracy: 0.302 - ETA: 39s - loss: 5.8495 - accuracy: 0.303 - ETA: 36s - loss: 5.8248 - accuracy: 0.304 - ETA: 34s - loss: 5.7990 - accuracy: 0.306 - ETA: 31s - loss: 5.7747 - accuracy: 0.306 - ETA: 29s - loss: 5.7521 - accuracy: 0.307 - ETA: 27s - loss: 5.7282 - accuracy: 0.308 - ETA: 24s - loss: 5.7062 - accuracy: 0.309 - ETA: 22s - loss: 5.6823 - accuracy: 0.310 - ETA: 19s - loss: 5.6607 - accuracy: 0.310 - ETA: 17s - loss: 5.6353 - accuracy: 0.312 - ETA: 14s - loss: 5.6114 - accuracy: 0.313 - ETA: 12s - loss: 5.5900 - accuracy: 0.313 - ETA: 9s - loss: 5.5699 - accuracy: 0.314 - ETA: 7s - loss: 5.5533 - accuracy: 0.31 - ETA: 4s - loss: 5.5310 - accuracy: 0.31 - ETA: 2s - loss: 5.5101 - accuracy: 0.31 - 423s 22ms/step - loss: 5.4916 - accuracy: 0.3170 - val_loss: 1.9313 - val_accuracy: 0.5484\n",
      "Epoch 2/100\n",
      "19312/19312 [==============================] - ETA: 6:39 - loss: 2.2418 - accuracy: 0.43 - ETA: 6:18 - loss: 2.1972 - accuracy: 0.43 - ETA: 6:00 - loss: 2.2132 - accuracy: 0.44 - ETA: 5:53 - loss: 2.1700 - accuracy: 0.44 - ETA: 6:00 - loss: 2.1325 - accuracy: 0.45 - ETA: 5:54 - loss: 2.1152 - accuracy: 0.46 - ETA: 5:50 - loss: 2.1301 - accuracy: 0.46 - ETA: 5:45 - loss: 2.1182 - accuracy: 0.46 - ETA: 5:38 - loss: 2.0828 - accuracy: 0.47 - ETA: 5:35 - loss: 2.0566 - accuracy: 0.47 - ETA: 5:31 - loss: 2.0559 - accuracy: 0.47 - ETA: 5:30 - loss: 2.0717 - accuracy: 0.46 - ETA: 5:25 - loss: 2.0917 - accuracy: 0.46 - ETA: 5:24 - loss: 2.0740 - accuracy: 0.46 - ETA: 5:21 - loss: 2.0802 - accuracy: 0.46 - ETA: 5:19 - loss: 2.0836 - accuracy: 0.46 - ETA: 5:15 - loss: 2.0895 - accuracy: 0.46 - ETA: 5:13 - loss: 2.0845 - accuracy: 0.46 - ETA: 5:12 - loss: 2.0697 - accuracy: 0.47 - ETA: 5:09 - loss: 2.0650 - accuracy: 0.46 - ETA: 5:06 - loss: 2.0556 - accuracy: 0.47 - ETA: 5:03 - loss: 2.0554 - accuracy: 0.47 - ETA: 5:00 - loss: 2.0473 - accuracy: 0.47 - ETA: 4:56 - loss: 2.0507 - accuracy: 0.47 - ETA: 4:55 - loss: 2.0384 - accuracy: 0.47 - ETA: 4:54 - loss: 2.0279 - accuracy: 0.47 - ETA: 4:52 - loss: 2.0303 - accuracy: 0.47 - ETA: 4:48 - loss: 2.0169 - accuracy: 0.48 - ETA: 4:47 - loss: 2.0244 - accuracy: 0.48 - ETA: 4:45 - loss: 2.0242 - accuracy: 0.48 - ETA: 4:42 - loss: 2.0234 - accuracy: 0.47 - ETA: 4:40 - loss: 2.0156 - accuracy: 0.48 - ETA: 4:38 - loss: 2.0298 - accuracy: 0.47 - ETA: 4:35 - loss: 2.0280 - accuracy: 0.48 - ETA: 4:32 - loss: 2.0256 - accuracy: 0.48 - ETA: 4:30 - loss: 2.0263 - accuracy: 0.48 - ETA: 4:28 - loss: 2.0186 - accuracy: 0.48 - ETA: 4:26 - loss: 2.0203 - accuracy: 0.48 - ETA: 4:24 - loss: 2.0079 - accuracy: 0.48 - ETA: 4:21 - loss: 2.0109 - accuracy: 0.48 - ETA: 4:19 - loss: 2.0101 - accuracy: 0.48 - ETA: 4:16 - loss: 2.0053 - accuracy: 0.48 - ETA: 4:14 - loss: 2.0017 - accuracy: 0.48 - ETA: 4:12 - loss: 1.9995 - accuracy: 0.48 - ETA: 4:10 - loss: 1.9961 - accuracy: 0.49 - ETA: 4:08 - loss: 1.9919 - accuracy: 0.49 - ETA: 4:06 - loss: 1.9904 - accuracy: 0.49 - ETA: 4:04 - loss: 1.9931 - accuracy: 0.49 - ETA: 4:01 - loss: 2.0043 - accuracy: 0.49 - ETA: 3:59 - loss: 2.0047 - accuracy: 0.49 - ETA: 3:56 - loss: 2.0044 - accuracy: 0.49 - ETA: 3:54 - loss: 2.0084 - accuracy: 0.49 - ETA: 3:52 - loss: 2.0086 - accuracy: 0.49 - ETA: 3:50 - loss: 2.0045 - accuracy: 0.49 - ETA: 3:48 - loss: 2.0009 - accuracy: 0.49 - ETA: 3:46 - loss: 2.0017 - accuracy: 0.49 - ETA: 3:43 - loss: 1.9952 - accuracy: 0.49 - ETA: 3:41 - loss: 1.9902 - accuracy: 0.49 - ETA: 3:39 - loss: 1.9934 - accuracy: 0.49 - ETA: 3:37 - loss: 1.9881 - accuracy: 0.50 - ETA: 3:34 - loss: 1.9841 - accuracy: 0.50 - ETA: 3:32 - loss: 1.9828 - accuracy: 0.50 - ETA: 3:30 - loss: 1.9843 - accuracy: 0.50 - ETA: 3:27 - loss: 1.9801 - accuracy: 0.50 - ETA: 3:25 - loss: 1.9821 - accuracy: 0.50 - ETA: 3:23 - loss: 1.9794 - accuracy: 0.50 - ETA: 3:21 - loss: 1.9820 - accuracy: 0.50 - ETA: 3:18 - loss: 1.9794 - accuracy: 0.50 - ETA: 3:16 - loss: 1.9764 - accuracy: 0.50 - ETA: 3:14 - loss: 1.9737 - accuracy: 0.50 - ETA: 3:11 - loss: 1.9762 - accuracy: 0.50 - ETA: 3:08 - loss: 1.9706 - accuracy: 0.50 - ETA: 3:06 - loss: 1.9683 - accuracy: 0.50 - ETA: 3:03 - loss: 1.9659 - accuracy: 0.50 - ETA: 3:00 - loss: 1.9655 - accuracy: 0.50 - ETA: 2:58 - loss: 1.9608 - accuracy: 0.50 - ETA: 2:56 - loss: 1.9597 - accuracy: 0.50 - ETA: 2:53 - loss: 1.9575 - accuracy: 0.50 - ETA: 2:51 - loss: 1.9582 - accuracy: 0.50 - ETA: 2:48 - loss: 1.9534 - accuracy: 0.50 - ETA: 2:46 - loss: 1.9490 - accuracy: 0.50 - ETA: 2:44 - loss: 1.9448 - accuracy: 0.50 - ETA: 2:41 - loss: 1.9452 - accuracy: 0.50 - ETA: 2:39 - loss: 1.9466 - accuracy: 0.50 - ETA: 2:37 - loss: 1.9473 - accuracy: 0.50 - ETA: 2:35 - loss: 1.9471 - accuracy: 0.51 - ETA: 2:32 - loss: 1.9492 - accuracy: 0.50 - ETA: 2:30 - loss: 1.9424 - accuracy: 0.51 - ETA: 2:27 - loss: 1.9390 - accuracy: 0.51 - ETA: 2:25 - loss: 1.9391 - accuracy: 0.51 - ETA: 2:23 - loss: 1.9367 - accuracy: 0.51 - ETA: 2:20 - loss: 1.9341 - accuracy: 0.51 - ETA: 2:18 - loss: 1.9327 - accuracy: 0.51 - ETA: 2:15 - loss: 1.9345 - accuracy: 0.51 - ETA: 2:13 - loss: 1.9348 - accuracy: 0.51 - ETA: 2:11 - loss: 1.9338 - accuracy: 0.51 - ETA: 2:08 - loss: 1.9340 - accuracy: 0.51 - ETA: 2:06 - loss: 1.9318 - accuracy: 0.51 - ETA: 2:04 - loss: 1.9311 - accuracy: 0.51 - ETA: 2:01 - loss: 1.9285 - accuracy: 0.51 - ETA: 1:59 - loss: 1.9277 - accuracy: 0.51 - ETA: 1:56 - loss: 1.9243 - accuracy: 0.51 - ETA: 1:54 - loss: 1.9232 - accuracy: 0.51 - ETA: 1:52 - loss: 1.9208 - accuracy: 0.51 - ETA: 1:49 - loss: 1.9221 - accuracy: 0.51 - ETA: 1:47 - loss: 1.9215 - accuracy: 0.51 - ETA: 1:44 - loss: 1.9235 - accuracy: 0.51 - ETA: 1:42 - loss: 1.9238 - accuracy: 0.51 - ETA: 1:40 - loss: 1.9214 - accuracy: 0.51 - ETA: 1:37 - loss: 1.9178 - accuracy: 0.51 - ETA: 1:35 - loss: 1.9167 - accuracy: 0.51 - ETA: 1:33 - loss: 1.9123 - accuracy: 0.51 - ETA: 1:30 - loss: 1.9121 - accuracy: 0.51 - ETA: 1:28 - loss: 1.9095 - accuracy: 0.51 - ETA: 1:26 - loss: 1.9101 - accuracy: 0.51 - ETA: 1:23 - loss: 1.9099 - accuracy: 0.51 - ETA: 1:21 - loss: 1.9076 - accuracy: 0.51 - ETA: 1:18 - loss: 1.9064 - accuracy: 0.51 - ETA: 1:16 - loss: 1.9067 - accuracy: 0.51 - ETA: 1:14 - loss: 1.9060 - accuracy: 0.51 - ETA: 1:11 - loss: 1.9063 - accuracy: 0.51 - ETA: 1:09 - loss: 1.9041 - accuracy: 0.51 - ETA: 1:07 - loss: 1.9046 - accuracy: 0.51 - ETA: 1:04 - loss: 1.9030 - accuracy: 0.51 - ETA: 1:02 - loss: 1.9033 - accuracy: 0.51 - ETA: 59s - loss: 1.9036 - accuracy: 0.5196 - ETA: 57s - loss: 1.9020 - accuracy: 0.519 - ETA: 55s - loss: 1.8992 - accuracy: 0.520 - ETA: 52s - loss: 1.9002 - accuracy: 0.519 - ETA: 50s - loss: 1.9009 - accuracy: 0.518 - ETA: 48s - loss: 1.9001 - accuracy: 0.519 - ETA: 45s - loss: 1.8977 - accuracy: 0.519 - ETA: 43s - loss: 1.8991 - accuracy: 0.519 - ETA: 40s - loss: 1.8975 - accuracy: 0.520 - ETA: 38s - loss: 1.8973 - accuracy: 0.520 - ETA: 36s - loss: 1.8978 - accuracy: 0.520 - ETA: 33s - loss: 1.8971 - accuracy: 0.520 - ETA: 31s - loss: 1.8967 - accuracy: 0.520 - ETA: 28s - loss: 1.8971 - accuracy: 0.520 - ETA: 26s - loss: 1.8992 - accuracy: 0.520 - ETA: 24s - loss: 1.8971 - accuracy: 0.521 - ETA: 21s - loss: 1.8967 - accuracy: 0.521 - ETA: 19s - loss: 1.8950 - accuracy: 0.521 - ETA: 16s - loss: 1.8950 - accuracy: 0.521 - ETA: 14s - loss: 1.8916 - accuracy: 0.522 - ETA: 11s - loss: 1.8907 - accuracy: 0.522 - ETA: 9s - loss: 1.8903 - accuracy: 0.522 - ETA: 7s - loss: 1.8909 - accuracy: 0.52 - ETA: 4s - loss: 1.8897 - accuracy: 0.52 - ETA: 2s - loss: 1.8886 - accuracy: 0.52 - 417s 22ms/step - loss: 1.8869 - accuracy: 0.5239 - val_loss: 1.5108 - val_accuracy: 0.6415\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:56 - loss: 1.6377 - accuracy: 0.58 - ETA: 5:45 - loss: 1.6697 - accuracy: 0.56 - ETA: 5:39 - loss: 1.5414 - accuracy: 0.58 - ETA: 5:38 - loss: 1.5571 - accuracy: 0.58 - ETA: 5:43 - loss: 1.5222 - accuracy: 0.59 - ETA: 5:36 - loss: 1.5092 - accuracy: 0.59 - ETA: 5:39 - loss: 1.5319 - accuracy: 0.59 - ETA: 5:36 - loss: 1.4787 - accuracy: 0.60 - ETA: 5:33 - loss: 1.4906 - accuracy: 0.60 - ETA: 5:32 - loss: 1.4697 - accuracy: 0.60 - ETA: 5:31 - loss: 1.4735 - accuracy: 0.60 - ETA: 5:27 - loss: 1.4586 - accuracy: 0.61 - ETA: 5:27 - loss: 1.4752 - accuracy: 0.60 - ETA: 5:28 - loss: 1.4754 - accuracy: 0.60 - ETA: 5:25 - loss: 1.4731 - accuracy: 0.60 - ETA: 5:24 - loss: 1.4810 - accuracy: 0.60 - ETA: 5:22 - loss: 1.4747 - accuracy: 0.60 - ETA: 5:19 - loss: 1.4907 - accuracy: 0.60 - ETA: 5:16 - loss: 1.4862 - accuracy: 0.60 - ETA: 5:14 - loss: 1.4798 - accuracy: 0.60 - ETA: 5:12 - loss: 1.4727 - accuracy: 0.60 - ETA: 5:10 - loss: 1.4736 - accuracy: 0.60 - ETA: 5:06 - loss: 1.4701 - accuracy: 0.60 - ETA: 5:03 - loss: 1.4698 - accuracy: 0.60 - ETA: 5:02 - loss: 1.4747 - accuracy: 0.60 - ETA: 4:58 - loss: 1.4698 - accuracy: 0.60 - ETA: 4:57 - loss: 1.4607 - accuracy: 0.60 - ETA: 4:53 - loss: 1.4541 - accuracy: 0.60 - ETA: 4:52 - loss: 1.4512 - accuracy: 0.61 - ETA: 4:49 - loss: 1.4548 - accuracy: 0.61 - ETA: 4:46 - loss: 1.4542 - accuracy: 0.60 - ETA: 4:43 - loss: 1.4528 - accuracy: 0.61 - ETA: 4:41 - loss: 1.4563 - accuracy: 0.60 - ETA: 4:39 - loss: 1.4567 - accuracy: 0.60 - ETA: 4:37 - loss: 1.4583 - accuracy: 0.60 - ETA: 4:35 - loss: 1.4587 - accuracy: 0.61 - ETA: 4:32 - loss: 1.4584 - accuracy: 0.61 - ETA: 4:30 - loss: 1.4591 - accuracy: 0.60 - ETA: 4:27 - loss: 1.4624 - accuracy: 0.60 - ETA: 4:26 - loss: 1.4668 - accuracy: 0.60 - ETA: 4:23 - loss: 1.4747 - accuracy: 0.60 - ETA: 4:20 - loss: 1.4778 - accuracy: 0.60 - ETA: 4:18 - loss: 1.4753 - accuracy: 0.60 - ETA: 4:16 - loss: 1.4706 - accuracy: 0.60 - ETA: 4:14 - loss: 1.4678 - accuracy: 0.60 - ETA: 4:12 - loss: 1.4618 - accuracy: 0.60 - ETA: 4:10 - loss: 1.4655 - accuracy: 0.60 - ETA: 4:07 - loss: 1.4619 - accuracy: 0.60 - ETA: 4:05 - loss: 1.4574 - accuracy: 0.60 - ETA: 4:03 - loss: 1.4619 - accuracy: 0.60 - ETA: 4:01 - loss: 1.4597 - accuracy: 0.60 - ETA: 3:58 - loss: 1.4586 - accuracy: 0.60 - ETA: 3:56 - loss: 1.4612 - accuracy: 0.60 - ETA: 3:54 - loss: 1.4633 - accuracy: 0.60 - ETA: 3:52 - loss: 1.4630 - accuracy: 0.60 - ETA: 3:49 - loss: 1.4617 - accuracy: 0.60 - ETA: 3:46 - loss: 1.4614 - accuracy: 0.60 - ETA: 3:44 - loss: 1.4576 - accuracy: 0.60 - ETA: 3:42 - loss: 1.4572 - accuracy: 0.60 - ETA: 3:40 - loss: 1.4579 - accuracy: 0.60 - ETA: 3:37 - loss: 1.4601 - accuracy: 0.60 - ETA: 3:35 - loss: 1.4636 - accuracy: 0.60 - ETA: 3:32 - loss: 1.4564 - accuracy: 0.60 - ETA: 3:30 - loss: 1.4553 - accuracy: 0.60 - ETA: 3:28 - loss: 1.4525 - accuracy: 0.60 - ETA: 3:25 - loss: 1.4516 - accuracy: 0.60 - ETA: 3:23 - loss: 1.4527 - accuracy: 0.60 - ETA: 3:21 - loss: 1.4524 - accuracy: 0.60 - ETA: 3:18 - loss: 1.4508 - accuracy: 0.60 - ETA: 3:16 - loss: 1.4517 - accuracy: 0.60 - ETA: 3:14 - loss: 1.4487 - accuracy: 0.61 - ETA: 3:11 - loss: 1.4439 - accuracy: 0.61 - ETA: 3:09 - loss: 1.4407 - accuracy: 0.61 - ETA: 3:07 - loss: 1.4435 - accuracy: 0.61 - ETA: 3:04 - loss: 1.4424 - accuracy: 0.61 - ETA: 3:02 - loss: 1.4391 - accuracy: 0.61 - ETA: 2:59 - loss: 1.4405 - accuracy: 0.61 - ETA: 2:57 - loss: 1.4402 - accuracy: 0.61 - ETA: 2:55 - loss: 1.4382 - accuracy: 0.61 - ETA: 2:52 - loss: 1.4379 - accuracy: 0.61 - ETA: 2:50 - loss: 1.4344 - accuracy: 0.61 - ETA: 2:48 - loss: 1.4315 - accuracy: 0.61 - ETA: 2:45 - loss: 1.4339 - accuracy: 0.61 - ETA: 2:43 - loss: 1.4337 - accuracy: 0.61 - ETA: 2:40 - loss: 1.4325 - accuracy: 0.61 - ETA: 2:38 - loss: 1.4315 - accuracy: 0.61 - ETA: 2:36 - loss: 1.4331 - accuracy: 0.61 - ETA: 2:33 - loss: 1.4320 - accuracy: 0.61 - ETA: 2:31 - loss: 1.4302 - accuracy: 0.61 - ETA: 2:28 - loss: 1.4295 - accuracy: 0.61 - ETA: 2:26 - loss: 1.4302 - accuracy: 0.61 - ETA: 2:24 - loss: 1.4278 - accuracy: 0.61 - ETA: 2:21 - loss: 1.4292 - accuracy: 0.61 - ETA: 2:19 - loss: 1.4301 - accuracy: 0.61 - ETA: 2:16 - loss: 1.4288 - accuracy: 0.61 - ETA: 2:13 - loss: 1.4293 - accuracy: 0.61 - ETA: 2:11 - loss: 1.4281 - accuracy: 0.61 - ETA: 2:09 - loss: 1.4265 - accuracy: 0.61 - ETA: 2:06 - loss: 1.4258 - accuracy: 0.61 - ETA: 2:04 - loss: 1.4258 - accuracy: 0.61 - ETA: 2:02 - loss: 1.4254 - accuracy: 0.61 - ETA: 1:59 - loss: 1.4229 - accuracy: 0.61 - ETA: 1:57 - loss: 1.4239 - accuracy: 0.61 - ETA: 1:55 - loss: 1.4224 - accuracy: 0.61 - ETA: 1:53 - loss: 1.4246 - accuracy: 0.61 - ETA: 1:51 - loss: 1.4256 - accuracy: 0.61 - ETA: 1:49 - loss: 1.4251 - accuracy: 0.61 - ETA: 1:46 - loss: 1.4261 - accuracy: 0.61 - ETA: 1:43 - loss: 1.4252 - accuracy: 0.61 - ETA: 1:41 - loss: 1.4268 - accuracy: 0.61 - ETA: 1:39 - loss: 1.4264 - accuracy: 0.61 - ETA: 1:36 - loss: 1.4263 - accuracy: 0.61 - ETA: 1:34 - loss: 1.4251 - accuracy: 0.61 - ETA: 1:32 - loss: 1.4253 - accuracy: 0.61 - ETA: 1:29 - loss: 1.4262 - accuracy: 0.61 - ETA: 1:27 - loss: 1.4243 - accuracy: 0.61 - ETA: 1:24 - loss: 1.4267 - accuracy: 0.61 - ETA: 1:22 - loss: 1.4261 - accuracy: 0.61 - ETA: 1:19 - loss: 1.4263 - accuracy: 0.61 - ETA: 1:17 - loss: 1.4235 - accuracy: 0.61 - ETA: 1:14 - loss: 1.4226 - accuracy: 0.61 - ETA: 1:12 - loss: 1.4219 - accuracy: 0.61 - ETA: 1:09 - loss: 1.4219 - accuracy: 0.61 - ETA: 1:07 - loss: 1.4215 - accuracy: 0.61 - ETA: 1:04 - loss: 1.4219 - accuracy: 0.61 - ETA: 1:02 - loss: 1.4215 - accuracy: 0.61 - ETA: 59s - loss: 1.4217 - accuracy: 0.6184 - ETA: 57s - loss: 1.4211 - accuracy: 0.618 - ETA: 54s - loss: 1.4191 - accuracy: 0.618 - ETA: 52s - loss: 1.4184 - accuracy: 0.619 - ETA: 49s - loss: 1.4170 - accuracy: 0.619 - ETA: 47s - loss: 1.4182 - accuracy: 0.619 - ETA: 44s - loss: 1.4181 - accuracy: 0.619 - ETA: 42s - loss: 1.4184 - accuracy: 0.619 - ETA: 39s - loss: 1.4190 - accuracy: 0.619 - ETA: 37s - loss: 1.4193 - accuracy: 0.619 - ETA: 34s - loss: 1.4178 - accuracy: 0.619 - ETA: 32s - loss: 1.4162 - accuracy: 0.620 - ETA: 29s - loss: 1.4161 - accuracy: 0.620 - ETA: 27s - loss: 1.4149 - accuracy: 0.620 - ETA: 24s - loss: 1.4177 - accuracy: 0.620 - ETA: 22s - loss: 1.4195 - accuracy: 0.619 - ETA: 19s - loss: 1.4191 - accuracy: 0.620 - ETA: 17s - loss: 1.4186 - accuracy: 0.620 - ETA: 14s - loss: 1.4179 - accuracy: 0.620 - ETA: 12s - loss: 1.4177 - accuracy: 0.620 - ETA: 9s - loss: 1.4176 - accuracy: 0.620 - ETA: 7s - loss: 1.4182 - accuracy: 0.62 - ETA: 4s - loss: 1.4184 - accuracy: 0.62 - ETA: 2s - loss: 1.4177 - accuracy: 0.62 - 426s 22ms/step - loss: 1.4167 - accuracy: 0.6205 - val_loss: 1.3324 - val_accuracy: 0.6844\n",
      "Epoch 4/100\n",
      "19312/19312 [==============================] - ETA: 5:59 - loss: 1.0877 - accuracy: 0.67 - ETA: 5:54 - loss: 1.0343 - accuracy: 0.69 - ETA: 5:37 - loss: 1.0635 - accuracy: 0.68 - ETA: 5:44 - loss: 1.0427 - accuracy: 0.68 - ETA: 5:44 - loss: 1.0381 - accuracy: 0.70 - ETA: 5:42 - loss: 1.0850 - accuracy: 0.68 - ETA: 5:34 - loss: 1.0706 - accuracy: 0.68 - ETA: 5:32 - loss: 1.0767 - accuracy: 0.68 - ETA: 5:30 - loss: 1.0857 - accuracy: 0.68 - ETA: 5:24 - loss: 1.0749 - accuracy: 0.68 - ETA: 5:23 - loss: 1.0649 - accuracy: 0.68 - ETA: 5:21 - loss: 1.0756 - accuracy: 0.68 - ETA: 5:18 - loss: 1.0875 - accuracy: 0.68 - ETA: 5:15 - loss: 1.0867 - accuracy: 0.68 - ETA: 5:13 - loss: 1.0974 - accuracy: 0.68 - ETA: 5:11 - loss: 1.0990 - accuracy: 0.68 - ETA: 5:09 - loss: 1.1160 - accuracy: 0.67 - ETA: 5:07 - loss: 1.1199 - accuracy: 0.67 - ETA: 5:05 - loss: 1.1240 - accuracy: 0.67 - ETA: 5:02 - loss: 1.1317 - accuracy: 0.67 - ETA: 5:00 - loss: 1.1328 - accuracy: 0.67 - ETA: 4:58 - loss: 1.1256 - accuracy: 0.67 - ETA: 4:56 - loss: 1.1259 - accuracy: 0.67 - ETA: 4:54 - loss: 1.1247 - accuracy: 0.67 - ETA: 4:52 - loss: 1.1265 - accuracy: 0.67 - ETA: 4:51 - loss: 1.1205 - accuracy: 0.67 - ETA: 4:49 - loss: 1.1215 - accuracy: 0.67 - ETA: 4:47 - loss: 1.1240 - accuracy: 0.67 - ETA: 4:43 - loss: 1.1274 - accuracy: 0.67 - ETA: 4:41 - loss: 1.1293 - accuracy: 0.67 - ETA: 4:39 - loss: 1.1300 - accuracy: 0.67 - ETA: 4:38 - loss: 1.1269 - accuracy: 0.67 - ETA: 4:36 - loss: 1.1186 - accuracy: 0.67 - ETA: 4:34 - loss: 1.1216 - accuracy: 0.67 - ETA: 4:32 - loss: 1.1224 - accuracy: 0.67 - ETA: 4:29 - loss: 1.1194 - accuracy: 0.67 - ETA: 4:27 - loss: 1.1172 - accuracy: 0.67 - ETA: 4:25 - loss: 1.1135 - accuracy: 0.67 - ETA: 4:24 - loss: 1.1149 - accuracy: 0.67 - ETA: 4:22 - loss: 1.1142 - accuracy: 0.67 - ETA: 4:19 - loss: 1.1112 - accuracy: 0.67 - ETA: 4:17 - loss: 1.1136 - accuracy: 0.67 - ETA: 4:15 - loss: 1.1141 - accuracy: 0.67 - ETA: 4:12 - loss: 1.1163 - accuracy: 0.67 - ETA: 4:11 - loss: 1.1198 - accuracy: 0.67 - ETA: 4:08 - loss: 1.1226 - accuracy: 0.67 - ETA: 4:06 - loss: 1.1230 - accuracy: 0.67 - ETA: 4:04 - loss: 1.1184 - accuracy: 0.67 - ETA: 4:02 - loss: 1.1224 - accuracy: 0.67 - ETA: 3:59 - loss: 1.1243 - accuracy: 0.67 - ETA: 3:57 - loss: 1.1222 - accuracy: 0.67 - ETA: 3:55 - loss: 1.1268 - accuracy: 0.67 - ETA: 3:53 - loss: 1.1265 - accuracy: 0.67 - ETA: 3:50 - loss: 1.1298 - accuracy: 0.67 - ETA: 3:48 - loss: 1.1262 - accuracy: 0.67 - ETA: 3:45 - loss: 1.1285 - accuracy: 0.67 - ETA: 3:43 - loss: 1.1295 - accuracy: 0.67 - ETA: 3:41 - loss: 1.1301 - accuracy: 0.67 - ETA: 3:39 - loss: 1.1280 - accuracy: 0.67 - ETA: 3:37 - loss: 1.1268 - accuracy: 0.67 - ETA: 3:34 - loss: 1.1250 - accuracy: 0.67 - ETA: 3:32 - loss: 1.1273 - accuracy: 0.67 - ETA: 3:30 - loss: 1.1260 - accuracy: 0.67 - ETA: 3:27 - loss: 1.1266 - accuracy: 0.67 - ETA: 3:25 - loss: 1.1245 - accuracy: 0.67 - ETA: 3:23 - loss: 1.1200 - accuracy: 0.67 - ETA: 3:21 - loss: 1.1224 - accuracy: 0.67 - ETA: 3:19 - loss: 1.1206 - accuracy: 0.68 - ETA: 3:16 - loss: 1.1228 - accuracy: 0.67 - ETA: 3:14 - loss: 1.1205 - accuracy: 0.67 - ETA: 3:12 - loss: 1.1237 - accuracy: 0.67 - ETA: 3:10 - loss: 1.1226 - accuracy: 0.67 - ETA: 3:07 - loss: 1.1204 - accuracy: 0.67 - ETA: 3:05 - loss: 1.1188 - accuracy: 0.68 - ETA: 3:03 - loss: 1.1194 - accuracy: 0.67 - ETA: 3:00 - loss: 1.1219 - accuracy: 0.67 - ETA: 2:58 - loss: 1.1250 - accuracy: 0.67 - ETA: 2:56 - loss: 1.1253 - accuracy: 0.67 - ETA: 2:53 - loss: 1.1258 - accuracy: 0.67 - ETA: 2:51 - loss: 1.1277 - accuracy: 0.67 - ETA: 2:49 - loss: 1.1277 - accuracy: 0.67 - ETA: 2:46 - loss: 1.1248 - accuracy: 0.67 - ETA: 2:44 - loss: 1.1217 - accuracy: 0.67 - ETA: 2:42 - loss: 1.1235 - accuracy: 0.67 - ETA: 2:40 - loss: 1.1242 - accuracy: 0.67 - ETA: 2:37 - loss: 1.1264 - accuracy: 0.67 - ETA: 2:35 - loss: 1.1246 - accuracy: 0.67 - ETA: 2:32 - loss: 1.1241 - accuracy: 0.67 - ETA: 2:30 - loss: 1.1251 - accuracy: 0.67 - ETA: 2:28 - loss: 1.1254 - accuracy: 0.67 - ETA: 2:25 - loss: 1.1250 - accuracy: 0.67 - ETA: 2:23 - loss: 1.1225 - accuracy: 0.67 - ETA: 2:20 - loss: 1.1242 - accuracy: 0.67 - ETA: 2:18 - loss: 1.1229 - accuracy: 0.67 - ETA: 2:15 - loss: 1.1239 - accuracy: 0.67 - ETA: 2:13 - loss: 1.1213 - accuracy: 0.67 - ETA: 2:10 - loss: 1.1222 - accuracy: 0.67 - ETA: 2:08 - loss: 1.1262 - accuracy: 0.67 - ETA: 2:05 - loss: 1.1252 - accuracy: 0.67 - ETA: 2:03 - loss: 1.1248 - accuracy: 0.67 - ETA: 2:00 - loss: 1.1205 - accuracy: 0.67 - ETA: 1:58 - loss: 1.1199 - accuracy: 0.67 - ETA: 1:56 - loss: 1.1195 - accuracy: 0.67 - ETA: 1:53 - loss: 1.1179 - accuracy: 0.67 - ETA: 1:51 - loss: 1.1192 - accuracy: 0.67 - ETA: 1:48 - loss: 1.1183 - accuracy: 0.67 - ETA: 1:46 - loss: 1.1171 - accuracy: 0.67 - ETA: 1:44 - loss: 1.1138 - accuracy: 0.68 - ETA: 1:41 - loss: 1.1124 - accuracy: 0.68 - ETA: 1:39 - loss: 1.1138 - accuracy: 0.68 - ETA: 1:36 - loss: 1.1132 - accuracy: 0.68 - ETA: 1:34 - loss: 1.1144 - accuracy: 0.68 - ETA: 1:31 - loss: 1.1146 - accuracy: 0.68 - ETA: 1:29 - loss: 1.1165 - accuracy: 0.68 - ETA: 1:27 - loss: 1.1163 - accuracy: 0.68 - ETA: 1:24 - loss: 1.1160 - accuracy: 0.68 - ETA: 1:22 - loss: 1.1187 - accuracy: 0.68 - ETA: 1:19 - loss: 1.1188 - accuracy: 0.68 - ETA: 1:17 - loss: 1.1211 - accuracy: 0.68 - ETA: 1:15 - loss: 1.1207 - accuracy: 0.68 - ETA: 1:12 - loss: 1.1218 - accuracy: 0.68 - ETA: 1:10 - loss: 1.1211 - accuracy: 0.68 - ETA: 1:07 - loss: 1.1225 - accuracy: 0.68 - ETA: 1:05 - loss: 1.1223 - accuracy: 0.68 - ETA: 1:02 - loss: 1.1214 - accuracy: 0.68 - ETA: 1:00 - loss: 1.1216 - accuracy: 0.68 - ETA: 57s - loss: 1.1225 - accuracy: 0.6817 - ETA: 55s - loss: 1.1229 - accuracy: 0.681 - ETA: 53s - loss: 1.1212 - accuracy: 0.682 - ETA: 50s - loss: 1.1209 - accuracy: 0.682 - ETA: 48s - loss: 1.1209 - accuracy: 0.682 - ETA: 45s - loss: 1.1214 - accuracy: 0.682 - ETA: 43s - loss: 1.1217 - accuracy: 0.682 - ETA: 40s - loss: 1.1211 - accuracy: 0.682 - ETA: 38s - loss: 1.1208 - accuracy: 0.682 - ETA: 36s - loss: 1.1208 - accuracy: 0.682 - ETA: 33s - loss: 1.1219 - accuracy: 0.681 - ETA: 31s - loss: 1.1235 - accuracy: 0.681 - ETA: 28s - loss: 1.1246 - accuracy: 0.681 - ETA: 26s - loss: 1.1244 - accuracy: 0.680 - ETA: 24s - loss: 1.1234 - accuracy: 0.681 - ETA: 21s - loss: 1.1240 - accuracy: 0.681 - ETA: 19s - loss: 1.1232 - accuracy: 0.681 - ETA: 16s - loss: 1.1237 - accuracy: 0.681 - ETA: 14s - loss: 1.1230 - accuracy: 0.681 - ETA: 11s - loss: 1.1236 - accuracy: 0.681 - ETA: 9s - loss: 1.1234 - accuracy: 0.681 - ETA: 7s - loss: 1.1232 - accuracy: 0.68 - ETA: 4s - loss: 1.1241 - accuracy: 0.68 - ETA: 2s - loss: 1.1250 - accuracy: 0.68 - 418s 22ms/step - loss: 1.1243 - accuracy: 0.6803 - val_loss: 1.1925 - val_accuracy: 0.7090\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:17 - loss: 0.8274 - accuracy: 0.71 - ETA: 6:05 - loss: 0.7417 - accuracy: 0.75 - ETA: 5:52 - loss: 0.7559 - accuracy: 0.75 - ETA: 5:50 - loss: 0.8066 - accuracy: 0.73 - ETA: 5:45 - loss: 0.7872 - accuracy: 0.74 - ETA: 5:36 - loss: 0.7798 - accuracy: 0.75 - ETA: 5:35 - loss: 0.7711 - accuracy: 0.75 - ETA: 5:33 - loss: 0.7593 - accuracy: 0.76 - ETA: 5:31 - loss: 0.7616 - accuracy: 0.76 - ETA: 5:29 - loss: 0.7704 - accuracy: 0.75 - ETA: 5:26 - loss: 0.7922 - accuracy: 0.75 - ETA: 5:24 - loss: 0.8001 - accuracy: 0.74 - ETA: 5:23 - loss: 0.8228 - accuracy: 0.74 - ETA: 5:21 - loss: 0.8298 - accuracy: 0.74 - ETA: 5:17 - loss: 0.8310 - accuracy: 0.73 - ETA: 5:15 - loss: 0.8487 - accuracy: 0.73 - ETA: 5:12 - loss: 0.8515 - accuracy: 0.73 - ETA: 5:09 - loss: 0.8442 - accuracy: 0.73 - ETA: 5:07 - loss: 0.8584 - accuracy: 0.73 - ETA: 5:05 - loss: 0.8562 - accuracy: 0.73 - ETA: 5:03 - loss: 0.8511 - accuracy: 0.73 - ETA: 5:00 - loss: 0.8544 - accuracy: 0.73 - ETA: 4:57 - loss: 0.8543 - accuracy: 0.73 - ETA: 4:54 - loss: 0.8484 - accuracy: 0.73 - ETA: 4:52 - loss: 0.8494 - accuracy: 0.73 - ETA: 4:50 - loss: 0.8523 - accuracy: 0.73 - ETA: 4:49 - loss: 0.8572 - accuracy: 0.73 - ETA: 4:46 - loss: 0.8589 - accuracy: 0.73 - ETA: 4:42 - loss: 0.8573 - accuracy: 0.73 - ETA: 4:40 - loss: 0.8572 - accuracy: 0.73 - ETA: 4:37 - loss: 0.8542 - accuracy: 0.73 - ETA: 4:35 - loss: 0.8510 - accuracy: 0.74 - ETA: 4:33 - loss: 0.8541 - accuracy: 0.74 - ETA: 4:31 - loss: 0.8561 - accuracy: 0.74 - ETA: 4:28 - loss: 0.8598 - accuracy: 0.74 - ETA: 4:26 - loss: 0.8613 - accuracy: 0.73 - ETA: 4:23 - loss: 0.8601 - accuracy: 0.73 - ETA: 4:21 - loss: 0.8571 - accuracy: 0.74 - ETA: 4:19 - loss: 0.8598 - accuracy: 0.73 - ETA: 4:17 - loss: 0.8573 - accuracy: 0.74 - ETA: 4:15 - loss: 0.8546 - accuracy: 0.74 - ETA: 4:12 - loss: 0.8555 - accuracy: 0.74 - ETA: 4:10 - loss: 0.8561 - accuracy: 0.74 - ETA: 4:07 - loss: 0.8606 - accuracy: 0.74 - ETA: 4:05 - loss: 0.8639 - accuracy: 0.73 - ETA: 4:02 - loss: 0.8646 - accuracy: 0.73 - ETA: 4:00 - loss: 0.8677 - accuracy: 0.73 - ETA: 3:58 - loss: 0.8720 - accuracy: 0.73 - ETA: 3:56 - loss: 0.8744 - accuracy: 0.73 - ETA: 3:54 - loss: 0.8749 - accuracy: 0.73 - ETA: 3:52 - loss: 0.8776 - accuracy: 0.73 - ETA: 3:50 - loss: 0.8760 - accuracy: 0.73 - ETA: 3:47 - loss: 0.8792 - accuracy: 0.73 - ETA: 3:45 - loss: 0.8781 - accuracy: 0.73 - ETA: 3:43 - loss: 0.8803 - accuracy: 0.73 - ETA: 3:41 - loss: 0.8819 - accuracy: 0.73 - ETA: 3:39 - loss: 0.8841 - accuracy: 0.73 - ETA: 3:37 - loss: 0.8850 - accuracy: 0.73 - ETA: 3:35 - loss: 0.8842 - accuracy: 0.73 - ETA: 3:32 - loss: 0.8854 - accuracy: 0.73 - ETA: 3:30 - loss: 0.8886 - accuracy: 0.73 - ETA: 3:28 - loss: 0.8890 - accuracy: 0.73 - ETA: 3:25 - loss: 0.8872 - accuracy: 0.73 - ETA: 3:23 - loss: 0.8907 - accuracy: 0.73 - ETA: 3:21 - loss: 0.8911 - accuracy: 0.73 - ETA: 3:19 - loss: 0.8937 - accuracy: 0.73 - ETA: 3:17 - loss: 0.8922 - accuracy: 0.73 - ETA: 3:15 - loss: 0.8937 - accuracy: 0.73 - ETA: 3:12 - loss: 0.8923 - accuracy: 0.73 - ETA: 3:10 - loss: 0.8936 - accuracy: 0.73 - ETA: 3:08 - loss: 0.8923 - accuracy: 0.73 - ETA: 3:05 - loss: 0.8911 - accuracy: 0.73 - ETA: 3:03 - loss: 0.8891 - accuracy: 0.73 - ETA: 3:01 - loss: 0.8901 - accuracy: 0.73 - ETA: 2:59 - loss: 0.8875 - accuracy: 0.73 - ETA: 2:56 - loss: 0.8897 - accuracy: 0.73 - ETA: 2:54 - loss: 0.8868 - accuracy: 0.73 - ETA: 2:52 - loss: 0.8853 - accuracy: 0.73 - ETA: 2:49 - loss: 0.8868 - accuracy: 0.73 - ETA: 2:47 - loss: 0.8866 - accuracy: 0.73 - ETA: 2:45 - loss: 0.8851 - accuracy: 0.73 - ETA: 2:42 - loss: 0.8869 - accuracy: 0.73 - ETA: 2:40 - loss: 0.8846 - accuracy: 0.73 - ETA: 2:38 - loss: 0.8844 - accuracy: 0.73 - ETA: 2:35 - loss: 0.8832 - accuracy: 0.73 - ETA: 2:33 - loss: 0.8814 - accuracy: 0.73 - ETA: 2:31 - loss: 0.8812 - accuracy: 0.73 - ETA: 2:29 - loss: 0.8833 - accuracy: 0.73 - ETA: 2:26 - loss: 0.8817 - accuracy: 0.73 - ETA: 2:24 - loss: 0.8797 - accuracy: 0.73 - ETA: 2:22 - loss: 0.8817 - accuracy: 0.73 - ETA: 2:19 - loss: 0.8829 - accuracy: 0.73 - ETA: 2:17 - loss: 0.8824 - accuracy: 0.73 - ETA: 2:15 - loss: 0.8832 - accuracy: 0.73 - ETA: 2:12 - loss: 0.8816 - accuracy: 0.73 - ETA: 2:10 - loss: 0.8812 - accuracy: 0.73 - ETA: 2:08 - loss: 0.8825 - accuracy: 0.73 - ETA: 2:05 - loss: 0.8818 - accuracy: 0.73 - ETA: 2:03 - loss: 0.8806 - accuracy: 0.73 - ETA: 2:01 - loss: 0.8801 - accuracy: 0.73 - ETA: 1:58 - loss: 0.8796 - accuracy: 0.73 - ETA: 1:56 - loss: 0.8776 - accuracy: 0.73 - ETA: 1:54 - loss: 0.8763 - accuracy: 0.73 - ETA: 1:51 - loss: 0.8751 - accuracy: 0.73 - ETA: 1:49 - loss: 0.8748 - accuracy: 0.73 - ETA: 1:46 - loss: 0.8737 - accuracy: 0.73 - ETA: 1:44 - loss: 0.8740 - accuracy: 0.73 - ETA: 1:42 - loss: 0.8756 - accuracy: 0.73 - ETA: 1:39 - loss: 0.8750 - accuracy: 0.73 - ETA: 1:37 - loss: 0.8779 - accuracy: 0.73 - ETA: 1:35 - loss: 0.8794 - accuracy: 0.73 - ETA: 1:32 - loss: 0.8780 - accuracy: 0.73 - ETA: 1:30 - loss: 0.8780 - accuracy: 0.73 - ETA: 1:28 - loss: 0.8772 - accuracy: 0.73 - ETA: 1:25 - loss: 0.8789 - accuracy: 0.73 - ETA: 1:23 - loss: 0.8784 - accuracy: 0.73 - ETA: 1:20 - loss: 0.8771 - accuracy: 0.73 - ETA: 1:18 - loss: 0.8773 - accuracy: 0.73 - ETA: 1:16 - loss: 0.8775 - accuracy: 0.73 - ETA: 1:13 - loss: 0.8781 - accuracy: 0.73 - ETA: 1:11 - loss: 0.8780 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8782 - accuracy: 0.73 - ETA: 1:06 - loss: 0.8790 - accuracy: 0.73 - ETA: 1:04 - loss: 0.8770 - accuracy: 0.73 - ETA: 1:01 - loss: 0.8774 - accuracy: 0.73 - ETA: 59s - loss: 0.8784 - accuracy: 0.7380 - ETA: 57s - loss: 0.8790 - accuracy: 0.737 - ETA: 54s - loss: 0.8797 - accuracy: 0.737 - ETA: 52s - loss: 0.8809 - accuracy: 0.737 - ETA: 50s - loss: 0.8808 - accuracy: 0.737 - ETA: 47s - loss: 0.8826 - accuracy: 0.736 - ETA: 45s - loss: 0.8829 - accuracy: 0.736 - ETA: 43s - loss: 0.8840 - accuracy: 0.736 - ETA: 40s - loss: 0.8825 - accuracy: 0.736 - ETA: 38s - loss: 0.8835 - accuracy: 0.736 - ETA: 35s - loss: 0.8845 - accuracy: 0.736 - ETA: 33s - loss: 0.8849 - accuracy: 0.735 - ETA: 31s - loss: 0.8852 - accuracy: 0.735 - ETA: 28s - loss: 0.8841 - accuracy: 0.736 - ETA: 26s - loss: 0.8848 - accuracy: 0.736 - ETA: 24s - loss: 0.8833 - accuracy: 0.736 - ETA: 21s - loss: 0.8828 - accuracy: 0.736 - ETA: 19s - loss: 0.8828 - accuracy: 0.736 - ETA: 16s - loss: 0.8839 - accuracy: 0.736 - ETA: 14s - loss: 0.8837 - accuracy: 0.736 - ETA: 11s - loss: 0.8840 - accuracy: 0.736 - ETA: 9s - loss: 0.8860 - accuracy: 0.736 - ETA: 7s - loss: 0.8858 - accuracy: 0.73 - ETA: 4s - loss: 0.8854 - accuracy: 0.73 - ETA: 2s - loss: 0.8869 - accuracy: 0.73 - 424s 22ms/step - loss: 0.8867 - accuracy: 0.7361 - val_loss: 1.1586 - val_accuracy: 0.7279\n",
      "Epoch 6/100\n",
      "19312/19312 [==============================] - ETA: 21:33 - loss: 0.6565 - accuracy: 0.773 - ETA: 13:39 - loss: 0.7802 - accuracy: 0.753 - ETA: 11:11 - loss: 0.7470 - accuracy: 0.755 - ETA: 9:38 - loss: 0.7897 - accuracy: 0.740 - ETA: 8:47 - loss: 0.7500 - accuracy: 0.75 - ETA: 8:16 - loss: 0.7486 - accuracy: 0.75 - ETA: 7:57 - loss: 0.7549 - accuracy: 0.75 - ETA: 7:38 - loss: 0.7483 - accuracy: 0.75 - ETA: 7:20 - loss: 0.7485 - accuracy: 0.76 - ETA: 7:09 - loss: 0.7588 - accuracy: 0.75 - ETA: 6:58 - loss: 0.7652 - accuracy: 0.75 - ETA: 6:46 - loss: 0.7568 - accuracy: 0.75 - ETA: 6:42 - loss: 0.7498 - accuracy: 0.75 - ETA: 6:32 - loss: 0.7427 - accuracy: 0.76 - ETA: 6:22 - loss: 0.7490 - accuracy: 0.75 - ETA: 6:18 - loss: 0.7486 - accuracy: 0.75 - ETA: 6:12 - loss: 0.7480 - accuracy: 0.75 - ETA: 6:06 - loss: 0.7446 - accuracy: 0.75 - ETA: 6:02 - loss: 0.7518 - accuracy: 0.75 - ETA: 5:57 - loss: 0.7564 - accuracy: 0.75 - ETA: 5:51 - loss: 0.7625 - accuracy: 0.75 - ETA: 5:49 - loss: 0.7633 - accuracy: 0.75 - ETA: 5:45 - loss: 0.7585 - accuracy: 0.75 - ETA: 5:40 - loss: 0.7545 - accuracy: 0.75 - ETA: 5:35 - loss: 0.7556 - accuracy: 0.75 - ETA: 5:31 - loss: 0.7499 - accuracy: 0.76 - ETA: 5:27 - loss: 0.7439 - accuracy: 0.76 - ETA: 5:22 - loss: 0.7428 - accuracy: 0.76 - ETA: 5:20 - loss: 0.7458 - accuracy: 0.76 - ETA: 5:15 - loss: 0.7468 - accuracy: 0.76 - ETA: 5:11 - loss: 0.7482 - accuracy: 0.76 - ETA: 5:09 - loss: 0.7458 - accuracy: 0.76 - ETA: 5:06 - loss: 0.7467 - accuracy: 0.76 - ETA: 5:03 - loss: 0.7437 - accuracy: 0.76 - ETA: 4:59 - loss: 0.7402 - accuracy: 0.76 - ETA: 4:57 - loss: 0.7399 - accuracy: 0.76 - ETA: 4:54 - loss: 0.7399 - accuracy: 0.76 - ETA: 4:51 - loss: 0.7415 - accuracy: 0.76 - ETA: 4:48 - loss: 0.7445 - accuracy: 0.76 - ETA: 4:45 - loss: 0.7456 - accuracy: 0.76 - ETA: 4:42 - loss: 0.7412 - accuracy: 0.76 - ETA: 4:39 - loss: 0.7424 - accuracy: 0.76 - ETA: 4:36 - loss: 0.7442 - accuracy: 0.76 - ETA: 4:34 - loss: 0.7461 - accuracy: 0.76 - ETA: 4:31 - loss: 0.7414 - accuracy: 0.76 - ETA: 4:28 - loss: 0.7453 - accuracy: 0.76 - ETA: 4:25 - loss: 0.7457 - accuracy: 0.76 - ETA: 4:22 - loss: 0.7491 - accuracy: 0.76 - ETA: 4:19 - loss: 0.7462 - accuracy: 0.76 - ETA: 4:16 - loss: 0.7462 - accuracy: 0.76 - ETA: 4:13 - loss: 0.7446 - accuracy: 0.76 - ETA: 4:11 - loss: 0.7436 - accuracy: 0.76 - ETA: 4:08 - loss: 0.7413 - accuracy: 0.76 - ETA: 4:05 - loss: 0.7414 - accuracy: 0.76 - ETA: 4:02 - loss: 0.7431 - accuracy: 0.76 - ETA: 4:00 - loss: 0.7452 - accuracy: 0.76 - ETA: 3:57 - loss: 0.7486 - accuracy: 0.76 - ETA: 3:54 - loss: 0.7481 - accuracy: 0.76 - ETA: 3:52 - loss: 0.7502 - accuracy: 0.76 - ETA: 3:48 - loss: 0.7492 - accuracy: 0.76 - ETA: 3:46 - loss: 0.7492 - accuracy: 0.76 - ETA: 3:44 - loss: 0.7471 - accuracy: 0.76 - ETA: 3:41 - loss: 0.7455 - accuracy: 0.76 - ETA: 3:38 - loss: 0.7451 - accuracy: 0.76 - ETA: 3:36 - loss: 0.7458 - accuracy: 0.76 - ETA: 3:33 - loss: 0.7467 - accuracy: 0.76 - ETA: 3:31 - loss: 0.7460 - accuracy: 0.76 - ETA: 3:28 - loss: 0.7484 - accuracy: 0.76 - ETA: 3:25 - loss: 0.7532 - accuracy: 0.76 - ETA: 3:23 - loss: 0.7522 - accuracy: 0.76 - ETA: 3:20 - loss: 0.7525 - accuracy: 0.76 - ETA: 3:17 - loss: 0.7507 - accuracy: 0.76 - ETA: 3:15 - loss: 0.7496 - accuracy: 0.76 - ETA: 3:12 - loss: 0.7502 - accuracy: 0.76 - ETA: 3:10 - loss: 0.7515 - accuracy: 0.76 - ETA: 3:07 - loss: 0.7498 - accuracy: 0.76 - ETA: 3:04 - loss: 0.7512 - accuracy: 0.76 - ETA: 3:02 - loss: 0.7529 - accuracy: 0.76 - ETA: 2:59 - loss: 0.7513 - accuracy: 0.76 - ETA: 2:57 - loss: 0.7525 - accuracy: 0.76 - ETA: 2:54 - loss: 0.7510 - accuracy: 0.76 - ETA: 2:51 - loss: 0.7527 - accuracy: 0.76 - ETA: 2:49 - loss: 0.7511 - accuracy: 0.76 - ETA: 2:46 - loss: 0.7505 - accuracy: 0.76 - ETA: 2:44 - loss: 0.7491 - accuracy: 0.76 - ETA: 2:41 - loss: 0.7476 - accuracy: 0.76 - ETA: 2:39 - loss: 0.7462 - accuracy: 0.76 - ETA: 2:36 - loss: 0.7451 - accuracy: 0.76 - ETA: 2:34 - loss: 0.7443 - accuracy: 0.76 - ETA: 2:31 - loss: 0.7440 - accuracy: 0.76 - ETA: 2:29 - loss: 0.7482 - accuracy: 0.76 - ETA: 2:26 - loss: 0.7475 - accuracy: 0.76 - ETA: 2:23 - loss: 0.7480 - accuracy: 0.76 - ETA: 2:21 - loss: 0.7511 - accuracy: 0.76 - ETA: 2:18 - loss: 0.7529 - accuracy: 0.76 - ETA: 2:16 - loss: 0.7513 - accuracy: 0.76 - ETA: 2:13 - loss: 0.7511 - accuracy: 0.76 - ETA: 2:11 - loss: 0.7509 - accuracy: 0.76 - ETA: 2:08 - loss: 0.7528 - accuracy: 0.76 - ETA: 2:06 - loss: 0.7526 - accuracy: 0.76 - ETA: 2:03 - loss: 0.7528 - accuracy: 0.76 - ETA: 2:01 - loss: 0.7530 - accuracy: 0.76 - ETA: 1:58 - loss: 0.7530 - accuracy: 0.76 - ETA: 1:56 - loss: 0.7528 - accuracy: 0.76 - ETA: 1:53 - loss: 0.7511 - accuracy: 0.76 - ETA: 1:51 - loss: 0.7528 - accuracy: 0.76 - ETA: 1:48 - loss: 0.7518 - accuracy: 0.76 - ETA: 1:46 - loss: 0.7532 - accuracy: 0.76 - ETA: 1:44 - loss: 0.7518 - accuracy: 0.76 - ETA: 1:41 - loss: 0.7509 - accuracy: 0.76 - ETA: 1:38 - loss: 0.7544 - accuracy: 0.76 - ETA: 1:36 - loss: 0.7543 - accuracy: 0.76 - ETA: 1:34 - loss: 0.7535 - accuracy: 0.76 - ETA: 1:31 - loss: 0.7540 - accuracy: 0.76 - ETA: 1:29 - loss: 0.7536 - accuracy: 0.76 - ETA: 1:26 - loss: 0.7525 - accuracy: 0.76 - ETA: 1:24 - loss: 0.7505 - accuracy: 0.76 - ETA: 1:21 - loss: 0.7484 - accuracy: 0.76 - ETA: 1:19 - loss: 0.7483 - accuracy: 0.76 - ETA: 1:16 - loss: 0.7479 - accuracy: 0.76 - ETA: 1:14 - loss: 0.7485 - accuracy: 0.76 - ETA: 1:11 - loss: 0.7478 - accuracy: 0.76 - ETA: 1:09 - loss: 0.7478 - accuracy: 0.76 - ETA: 1:06 - loss: 0.7471 - accuracy: 0.77 - ETA: 1:04 - loss: 0.7475 - accuracy: 0.76 - ETA: 1:01 - loss: 0.7474 - accuracy: 0.76 - ETA: 59s - loss: 0.7466 - accuracy: 0.7697 - ETA: 56s - loss: 0.7447 - accuracy: 0.770 - ETA: 54s - loss: 0.7449 - accuracy: 0.770 - ETA: 51s - loss: 0.7439 - accuracy: 0.770 - ETA: 49s - loss: 0.7431 - accuracy: 0.770 - ETA: 46s - loss: 0.7427 - accuracy: 0.771 - ETA: 44s - loss: 0.7428 - accuracy: 0.771 - ETA: 42s - loss: 0.7439 - accuracy: 0.771 - ETA: 39s - loss: 0.7431 - accuracy: 0.771 - ETA: 37s - loss: 0.7433 - accuracy: 0.771 - ETA: 34s - loss: 0.7429 - accuracy: 0.771 - ETA: 32s - loss: 0.7429 - accuracy: 0.771 - ETA: 29s - loss: 0.7419 - accuracy: 0.771 - ETA: 27s - loss: 0.7410 - accuracy: 0.771 - ETA: 24s - loss: 0.7406 - accuracy: 0.772 - ETA: 22s - loss: 0.7389 - accuracy: 0.772 - ETA: 19s - loss: 0.7399 - accuracy: 0.772 - ETA: 17s - loss: 0.7396 - accuracy: 0.772 - ETA: 14s - loss: 0.7389 - accuracy: 0.772 - ETA: 12s - loss: 0.7395 - accuracy: 0.772 - ETA: 9s - loss: 0.7404 - accuracy: 0.772 - ETA: 7s - loss: 0.7407 - accuracy: 0.77 - ETA: 4s - loss: 0.7420 - accuracy: 0.77 - ETA: 2s - loss: 0.7416 - accuracy: 0.77 - 433s 22ms/step - loss: 0.7421 - accuracy: 0.7719 - val_loss: 1.1014 - val_accuracy: 0.7393\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 21:01 - loss: 0.5815 - accuracy: 0.820 - ETA: 13:29 - loss: 0.6634 - accuracy: 0.800 - ETA: 10:52 - loss: 0.6819 - accuracy: 0.796 - ETA: 9:31 - loss: 0.7094 - accuracy: 0.787 - ETA: 8:41 - loss: 0.6784 - accuracy: 0.79 - ETA: 8:10 - loss: 0.6819 - accuracy: 0.78 - ETA: 7:43 - loss: 0.6868 - accuracy: 0.79 - ETA: 7:24 - loss: 0.6789 - accuracy: 0.79 - ETA: 7:08 - loss: 0.6738 - accuracy: 0.79 - ETA: 6:52 - loss: 0.6600 - accuracy: 0.79 - ETA: 6:41 - loss: 0.6473 - accuracy: 0.80 - ETA: 6:31 - loss: 0.6418 - accuracy: 0.80 - ETA: 6:22 - loss: 0.6507 - accuracy: 0.80 - ETA: 6:15 - loss: 0.6468 - accuracy: 0.80 - ETA: 6:08 - loss: 0.6463 - accuracy: 0.80 - ETA: 6:00 - loss: 0.6538 - accuracy: 0.80 - ETA: 5:54 - loss: 0.6629 - accuracy: 0.80 - ETA: 5:49 - loss: 0.6601 - accuracy: 0.79 - ETA: 5:42 - loss: 0.6709 - accuracy: 0.79 - ETA: 5:39 - loss: 0.6580 - accuracy: 0.80 - ETA: 5:36 - loss: 0.6593 - accuracy: 0.80 - ETA: 5:33 - loss: 0.6628 - accuracy: 0.80 - ETA: 5:28 - loss: 0.6674 - accuracy: 0.79 - ETA: 5:25 - loss: 0.6654 - accuracy: 0.79 - ETA: 5:20 - loss: 0.6637 - accuracy: 0.79 - ETA: 5:16 - loss: 0.6631 - accuracy: 0.79 - ETA: 5:13 - loss: 0.6605 - accuracy: 0.79 - ETA: 5:11 - loss: 0.6580 - accuracy: 0.79 - ETA: 5:06 - loss: 0.6518 - accuracy: 0.79 - ETA: 5:03 - loss: 0.6430 - accuracy: 0.80 - ETA: 4:59 - loss: 0.6392 - accuracy: 0.80 - ETA: 4:55 - loss: 0.6439 - accuracy: 0.80 - ETA: 4:52 - loss: 0.6471 - accuracy: 0.79 - ETA: 4:50 - loss: 0.6535 - accuracy: 0.79 - ETA: 4:47 - loss: 0.6506 - accuracy: 0.79 - ETA: 4:45 - loss: 0.6490 - accuracy: 0.79 - ETA: 4:42 - loss: 0.6481 - accuracy: 0.79 - ETA: 4:39 - loss: 0.6422 - accuracy: 0.80 - ETA: 4:36 - loss: 0.6394 - accuracy: 0.80 - ETA: 4:34 - loss: 0.6436 - accuracy: 0.80 - ETA: 4:31 - loss: 0.6429 - accuracy: 0.80 - ETA: 4:29 - loss: 0.6403 - accuracy: 0.80 - ETA: 4:26 - loss: 0.6393 - accuracy: 0.80 - ETA: 4:24 - loss: 0.6341 - accuracy: 0.80 - ETA: 4:21 - loss: 0.6312 - accuracy: 0.80 - ETA: 4:18 - loss: 0.6337 - accuracy: 0.80 - ETA: 4:15 - loss: 0.6324 - accuracy: 0.80 - ETA: 4:13 - loss: 0.6317 - accuracy: 0.80 - ETA: 4:11 - loss: 0.6352 - accuracy: 0.80 - ETA: 4:08 - loss: 0.6369 - accuracy: 0.80 - ETA: 4:06 - loss: 0.6366 - accuracy: 0.80 - ETA: 4:03 - loss: 0.6358 - accuracy: 0.80 - ETA: 4:00 - loss: 0.6349 - accuracy: 0.80 - ETA: 3:58 - loss: 0.6344 - accuracy: 0.80 - ETA: 3:56 - loss: 0.6368 - accuracy: 0.80 - ETA: 3:53 - loss: 0.6391 - accuracy: 0.80 - ETA: 3:50 - loss: 0.6400 - accuracy: 0.80 - ETA: 3:48 - loss: 0.6390 - accuracy: 0.80 - ETA: 3:45 - loss: 0.6374 - accuracy: 0.80 - ETA: 3:43 - loss: 0.6370 - accuracy: 0.80 - ETA: 3:40 - loss: 0.6375 - accuracy: 0.80 - ETA: 3:38 - loss: 0.6401 - accuracy: 0.80 - ETA: 3:35 - loss: 0.6376 - accuracy: 0.80 - ETA: 3:33 - loss: 0.6370 - accuracy: 0.80 - ETA: 3:30 - loss: 0.6403 - accuracy: 0.80 - ETA: 3:28 - loss: 0.6388 - accuracy: 0.80 - ETA: 3:26 - loss: 0.6412 - accuracy: 0.80 - ETA: 3:23 - loss: 0.6431 - accuracy: 0.80 - ETA: 3:21 - loss: 0.6409 - accuracy: 0.80 - ETA: 3:18 - loss: 0.6413 - accuracy: 0.80 - ETA: 3:15 - loss: 0.6393 - accuracy: 0.80 - ETA: 3:13 - loss: 0.6382 - accuracy: 0.80 - ETA: 3:10 - loss: 0.6380 - accuracy: 0.80 - ETA: 3:08 - loss: 0.6370 - accuracy: 0.80 - ETA: 3:05 - loss: 0.6355 - accuracy: 0.80 - ETA: 3:03 - loss: 0.6359 - accuracy: 0.80 - ETA: 3:00 - loss: 0.6365 - accuracy: 0.80 - ETA: 2:58 - loss: 0.6373 - accuracy: 0.80 - ETA: 2:55 - loss: 0.6364 - accuracy: 0.80 - ETA: 2:53 - loss: 0.6373 - accuracy: 0.80 - ETA: 2:51 - loss: 0.6413 - accuracy: 0.80 - ETA: 2:48 - loss: 0.6394 - accuracy: 0.80 - ETA: 2:46 - loss: 0.6397 - accuracy: 0.80 - ETA: 2:43 - loss: 0.6392 - accuracy: 0.80 - ETA: 2:40 - loss: 0.6375 - accuracy: 0.80 - ETA: 2:38 - loss: 0.6357 - accuracy: 0.80 - ETA: 2:36 - loss: 0.6354 - accuracy: 0.80 - ETA: 2:33 - loss: 0.6372 - accuracy: 0.80 - ETA: 2:31 - loss: 0.6378 - accuracy: 0.80 - ETA: 2:28 - loss: 0.6349 - accuracy: 0.80 - ETA: 2:26 - loss: 0.6354 - accuracy: 0.80 - ETA: 2:23 - loss: 0.6348 - accuracy: 0.80 - ETA: 2:21 - loss: 0.6331 - accuracy: 0.80 - ETA: 2:18 - loss: 0.6326 - accuracy: 0.80 - ETA: 2:16 - loss: 0.6328 - accuracy: 0.80 - ETA: 2:13 - loss: 0.6338 - accuracy: 0.80 - ETA: 2:11 - loss: 0.6342 - accuracy: 0.80 - ETA: 2:08 - loss: 0.6336 - accuracy: 0.80 - ETA: 2:06 - loss: 0.6327 - accuracy: 0.80 - ETA: 2:04 - loss: 0.6328 - accuracy: 0.80 - ETA: 2:01 - loss: 0.6322 - accuracy: 0.80 - ETA: 1:59 - loss: 0.6310 - accuracy: 0.80 - ETA: 1:56 - loss: 0.6293 - accuracy: 0.80 - ETA: 1:54 - loss: 0.6297 - accuracy: 0.80 - ETA: 1:51 - loss: 0.6298 - accuracy: 0.80 - ETA: 1:49 - loss: 0.6293 - accuracy: 0.80 - ETA: 1:47 - loss: 0.6290 - accuracy: 0.80 - ETA: 1:44 - loss: 0.6290 - accuracy: 0.80 - ETA: 1:42 - loss: 0.6276 - accuracy: 0.80 - ETA: 1:39 - loss: 0.6290 - accuracy: 0.80 - ETA: 1:37 - loss: 0.6303 - accuracy: 0.80 - ETA: 1:34 - loss: 0.6309 - accuracy: 0.80 - ETA: 1:32 - loss: 0.6305 - accuracy: 0.80 - ETA: 1:30 - loss: 0.6314 - accuracy: 0.80 - ETA: 1:27 - loss: 0.6300 - accuracy: 0.80 - ETA: 1:25 - loss: 0.6296 - accuracy: 0.80 - ETA: 1:22 - loss: 0.6317 - accuracy: 0.80 - ETA: 1:20 - loss: 0.6305 - accuracy: 0.80 - ETA: 1:17 - loss: 0.6302 - accuracy: 0.80 - ETA: 1:15 - loss: 0.6307 - accuracy: 0.80 - ETA: 1:12 - loss: 0.6286 - accuracy: 0.80 - ETA: 1:10 - loss: 0.6282 - accuracy: 0.80 - ETA: 1:07 - loss: 0.6264 - accuracy: 0.80 - ETA: 1:05 - loss: 0.6266 - accuracy: 0.80 - ETA: 1:03 - loss: 0.6282 - accuracy: 0.80 - ETA: 1:00 - loss: 0.6292 - accuracy: 0.80 - ETA: 58s - loss: 0.6305 - accuracy: 0.8057 - ETA: 55s - loss: 0.6305 - accuracy: 0.805 - ETA: 53s - loss: 0.6301 - accuracy: 0.806 - ETA: 50s - loss: 0.6308 - accuracy: 0.805 - ETA: 48s - loss: 0.6301 - accuracy: 0.806 - ETA: 46s - loss: 0.6313 - accuracy: 0.805 - ETA: 43s - loss: 0.6306 - accuracy: 0.805 - ETA: 41s - loss: 0.6298 - accuracy: 0.806 - ETA: 38s - loss: 0.6289 - accuracy: 0.806 - ETA: 36s - loss: 0.6270 - accuracy: 0.807 - ETA: 33s - loss: 0.6285 - accuracy: 0.806 - ETA: 31s - loss: 0.6286 - accuracy: 0.806 - ETA: 28s - loss: 0.6283 - accuracy: 0.806 - ETA: 26s - loss: 0.6296 - accuracy: 0.806 - ETA: 24s - loss: 0.6299 - accuracy: 0.806 - ETA: 21s - loss: 0.6292 - accuracy: 0.806 - ETA: 19s - loss: 0.6284 - accuracy: 0.806 - ETA: 16s - loss: 0.6283 - accuracy: 0.806 - ETA: 14s - loss: 0.6265 - accuracy: 0.807 - ETA: 11s - loss: 0.6278 - accuracy: 0.806 - ETA: 9s - loss: 0.6275 - accuracy: 0.807 - ETA: 7s - loss: 0.6273 - accuracy: 0.80 - ETA: 4s - loss: 0.6277 - accuracy: 0.80 - ETA: 2s - loss: 0.6288 - accuracy: 0.80 - 412s 21ms/step - loss: 0.6293 - accuracy: 0.8072 - val_loss: 1.0931 - val_accuracy: 0.7538\n",
      "Epoch 8/100\n",
      "19312/19312 [==============================] - ETA: 15:27 - loss: 0.5545 - accuracy: 0.828 - ETA: 10:39 - loss: 0.6168 - accuracy: 0.820 - ETA: 9:03 - loss: 0.6018 - accuracy: 0.820 - ETA: 8:14 - loss: 0.5893 - accuracy: 0.82 - ETA: 7:43 - loss: 0.5930 - accuracy: 0.82 - ETA: 7:21 - loss: 0.5959 - accuracy: 0.81 - ETA: 7:03 - loss: 0.5862 - accuracy: 0.81 - ETA: 6:54 - loss: 0.5861 - accuracy: 0.81 - ETA: 6:44 - loss: 0.5660 - accuracy: 0.81 - ETA: 6:32 - loss: 0.5700 - accuracy: 0.81 - ETA: 6:25 - loss: 0.5681 - accuracy: 0.81 - ETA: 6:18 - loss: 0.5665 - accuracy: 0.82 - ETA: 6:13 - loss: 0.5591 - accuracy: 0.82 - ETA: 6:08 - loss: 0.5499 - accuracy: 0.82 - ETA: 6:04 - loss: 0.5408 - accuracy: 0.82 - ETA: 5:56 - loss: 0.5441 - accuracy: 0.82 - ETA: 5:51 - loss: 0.5402 - accuracy: 0.83 - ETA: 5:47 - loss: 0.5347 - accuracy: 0.83 - ETA: 5:42 - loss: 0.5356 - accuracy: 0.83 - ETA: 5:38 - loss: 0.5288 - accuracy: 0.83 - ETA: 5:35 - loss: 0.5311 - accuracy: 0.83 - ETA: 5:32 - loss: 0.5337 - accuracy: 0.83 - ETA: 5:29 - loss: 0.5290 - accuracy: 0.83 - ETA: 5:26 - loss: 0.5282 - accuracy: 0.83 - ETA: 5:22 - loss: 0.5336 - accuracy: 0.83 - ETA: 5:20 - loss: 0.5297 - accuracy: 0.83 - ETA: 5:16 - loss: 0.5240 - accuracy: 0.83 - ETA: 5:13 - loss: 0.5248 - accuracy: 0.83 - ETA: 5:09 - loss: 0.5216 - accuracy: 0.83 - ETA: 5:06 - loss: 0.5277 - accuracy: 0.83 - ETA: 5:04 - loss: 0.5257 - accuracy: 0.83 - ETA: 5:01 - loss: 0.5281 - accuracy: 0.83 - ETA: 4:58 - loss: 0.5289 - accuracy: 0.83 - ETA: 4:55 - loss: 0.5327 - accuracy: 0.83 - ETA: 4:52 - loss: 0.5306 - accuracy: 0.83 - ETA: 4:49 - loss: 0.5326 - accuracy: 0.83 - ETA: 4:45 - loss: 0.5304 - accuracy: 0.83 - ETA: 4:42 - loss: 0.5297 - accuracy: 0.83 - ETA: 4:39 - loss: 0.5305 - accuracy: 0.83 - ETA: 4:37 - loss: 0.5306 - accuracy: 0.83 - ETA: 4:34 - loss: 0.5339 - accuracy: 0.83 - ETA: 4:31 - loss: 0.5341 - accuracy: 0.83 - ETA: 4:29 - loss: 0.5305 - accuracy: 0.83 - ETA: 4:26 - loss: 0.5287 - accuracy: 0.83 - ETA: 4:23 - loss: 0.5256 - accuracy: 0.83 - ETA: 4:21 - loss: 0.5236 - accuracy: 0.83 - ETA: 4:18 - loss: 0.5276 - accuracy: 0.83 - ETA: 4:16 - loss: 0.5271 - accuracy: 0.83 - ETA: 4:13 - loss: 0.5263 - accuracy: 0.83 - ETA: 4:10 - loss: 0.5254 - accuracy: 0.83 - ETA: 4:07 - loss: 0.5244 - accuracy: 0.83 - ETA: 4:05 - loss: 0.5246 - accuracy: 0.83 - ETA: 4:02 - loss: 0.5253 - accuracy: 0.83 - ETA: 4:00 - loss: 0.5261 - accuracy: 0.83 - ETA: 3:57 - loss: 0.5271 - accuracy: 0.83 - ETA: 3:54 - loss: 0.5266 - accuracy: 0.83 - ETA: 3:52 - loss: 0.5261 - accuracy: 0.83 - ETA: 3:49 - loss: 0.5256 - accuracy: 0.83 - ETA: 3:46 - loss: 0.5259 - accuracy: 0.83 - ETA: 3:44 - loss: 0.5264 - accuracy: 0.83 - ETA: 3:42 - loss: 0.5282 - accuracy: 0.83 - ETA: 3:39 - loss: 0.5299 - accuracy: 0.83 - ETA: 3:36 - loss: 0.5319 - accuracy: 0.83 - ETA: 3:34 - loss: 0.5361 - accuracy: 0.83 - ETA: 3:31 - loss: 0.5374 - accuracy: 0.83 - ETA: 3:29 - loss: 0.5353 - accuracy: 0.83 - ETA: 3:27 - loss: 0.5345 - accuracy: 0.83 - ETA: 3:24 - loss: 0.5386 - accuracy: 0.83 - ETA: 3:22 - loss: 0.5385 - accuracy: 0.83 - ETA: 3:19 - loss: 0.5374 - accuracy: 0.83 - ETA: 3:16 - loss: 0.5407 - accuracy: 0.83 - ETA: 3:14 - loss: 0.5407 - accuracy: 0.83 - ETA: 3:12 - loss: 0.5428 - accuracy: 0.83 - ETA: 3:09 - loss: 0.5415 - accuracy: 0.83 - ETA: 3:07 - loss: 0.5441 - accuracy: 0.83 - ETA: 3:04 - loss: 0.5442 - accuracy: 0.82 - ETA: 3:01 - loss: 0.5428 - accuracy: 0.82 - ETA: 2:59 - loss: 0.5429 - accuracy: 0.82 - ETA: 2:57 - loss: 0.5429 - accuracy: 0.82 - ETA: 2:54 - loss: 0.5425 - accuracy: 0.82 - ETA: 2:52 - loss: 0.5422 - accuracy: 0.82 - ETA: 2:49 - loss: 0.5409 - accuracy: 0.83 - ETA: 2:46 - loss: 0.5424 - accuracy: 0.82 - ETA: 2:44 - loss: 0.5427 - accuracy: 0.82 - ETA: 2:41 - loss: 0.5421 - accuracy: 0.82 - ETA: 2:39 - loss: 0.5418 - accuracy: 0.82 - ETA: 2:37 - loss: 0.5420 - accuracy: 0.82 - ETA: 2:34 - loss: 0.5433 - accuracy: 0.82 - ETA: 2:32 - loss: 0.5443 - accuracy: 0.82 - ETA: 2:29 - loss: 0.5458 - accuracy: 0.82 - ETA: 2:26 - loss: 0.5454 - accuracy: 0.82 - ETA: 2:24 - loss: 0.5459 - accuracy: 0.82 - ETA: 2:22 - loss: 0.5470 - accuracy: 0.82 - ETA: 2:19 - loss: 0.5462 - accuracy: 0.82 - ETA: 2:17 - loss: 0.5452 - accuracy: 0.82 - ETA: 2:14 - loss: 0.5448 - accuracy: 0.82 - ETA: 2:12 - loss: 0.5433 - accuracy: 0.82 - ETA: 2:09 - loss: 0.5438 - accuracy: 0.82 - ETA: 2:07 - loss: 0.5449 - accuracy: 0.82 - ETA: 2:04 - loss: 0.5451 - accuracy: 0.82 - ETA: 2:02 - loss: 0.5439 - accuracy: 0.82 - ETA: 1:59 - loss: 0.5434 - accuracy: 0.82 - ETA: 1:57 - loss: 0.5436 - accuracy: 0.82 - ETA: 1:54 - loss: 0.5429 - accuracy: 0.82 - ETA: 1:52 - loss: 0.5419 - accuracy: 0.82 - ETA: 1:49 - loss: 0.5411 - accuracy: 0.82 - ETA: 1:47 - loss: 0.5402 - accuracy: 0.82 - ETA: 1:44 - loss: 0.5408 - accuracy: 0.82 - ETA: 1:42 - loss: 0.5426 - accuracy: 0.82 - ETA: 1:39 - loss: 0.5416 - accuracy: 0.82 - ETA: 1:37 - loss: 0.5425 - accuracy: 0.82 - ETA: 1:35 - loss: 0.5420 - accuracy: 0.82 - ETA: 1:32 - loss: 0.5433 - accuracy: 0.82 - ETA: 1:30 - loss: 0.5435 - accuracy: 0.82 - ETA: 1:27 - loss: 0.5456 - accuracy: 0.82 - ETA: 1:25 - loss: 0.5451 - accuracy: 0.82 - ETA: 1:22 - loss: 0.5450 - accuracy: 0.82 - ETA: 1:20 - loss: 0.5457 - accuracy: 0.82 - ETA: 1:17 - loss: 0.5453 - accuracy: 0.82 - ETA: 1:15 - loss: 0.5450 - accuracy: 0.82 - ETA: 1:13 - loss: 0.5469 - accuracy: 0.82 - ETA: 1:10 - loss: 0.5475 - accuracy: 0.82 - ETA: 1:08 - loss: 0.5467 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5484 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5486 - accuracy: 0.82 - ETA: 1:00 - loss: 0.5481 - accuracy: 0.82 - ETA: 58s - loss: 0.5491 - accuracy: 0.8266 - ETA: 55s - loss: 0.5496 - accuracy: 0.826 - ETA: 53s - loss: 0.5500 - accuracy: 0.826 - ETA: 50s - loss: 0.5491 - accuracy: 0.826 - ETA: 48s - loss: 0.5501 - accuracy: 0.826 - ETA: 46s - loss: 0.5505 - accuracy: 0.826 - ETA: 43s - loss: 0.5505 - accuracy: 0.826 - ETA: 41s - loss: 0.5494 - accuracy: 0.827 - ETA: 38s - loss: 0.5511 - accuracy: 0.826 - ETA: 36s - loss: 0.5522 - accuracy: 0.826 - ETA: 33s - loss: 0.5521 - accuracy: 0.826 - ETA: 31s - loss: 0.5513 - accuracy: 0.826 - ETA: 28s - loss: 0.5505 - accuracy: 0.826 - ETA: 26s - loss: 0.5504 - accuracy: 0.826 - ETA: 24s - loss: 0.5493 - accuracy: 0.827 - ETA: 21s - loss: 0.5486 - accuracy: 0.827 - ETA: 19s - loss: 0.5487 - accuracy: 0.827 - ETA: 16s - loss: 0.5484 - accuracy: 0.827 - ETA: 14s - loss: 0.5483 - accuracy: 0.827 - ETA: 11s - loss: 0.5474 - accuracy: 0.828 - ETA: 9s - loss: 0.5492 - accuracy: 0.827 - ETA: 7s - loss: 0.5484 - accuracy: 0.82 - ETA: 4s - loss: 0.5502 - accuracy: 0.82 - ETA: 2s - loss: 0.5500 - accuracy: 0.82 - 412s 21ms/step - loss: 0.5496 - accuracy: 0.8273 - val_loss: 1.0733 - val_accuracy: 0.7598\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:41 - loss: 0.5005 - accuracy: 0.84 - ETA: 6:24 - loss: 0.5684 - accuracy: 0.82 - ETA: 6:22 - loss: 0.5347 - accuracy: 0.82 - ETA: 6:12 - loss: 0.5021 - accuracy: 0.83 - ETA: 6:07 - loss: 0.5024 - accuracy: 0.83 - ETA: 6:03 - loss: 0.5246 - accuracy: 0.82 - ETA: 6:00 - loss: 0.5113 - accuracy: 0.84 - ETA: 5:51 - loss: 0.5163 - accuracy: 0.83 - ETA: 5:50 - loss: 0.5080 - accuracy: 0.83 - ETA: 5:49 - loss: 0.5040 - accuracy: 0.83 - ETA: 5:46 - loss: 0.4932 - accuracy: 0.84 - ETA: 5:44 - loss: 0.4887 - accuracy: 0.84 - ETA: 5:40 - loss: 0.5064 - accuracy: 0.83 - ETA: 5:36 - loss: 0.5096 - accuracy: 0.83 - ETA: 5:32 - loss: 0.5129 - accuracy: 0.83 - ETA: 5:30 - loss: 0.5181 - accuracy: 0.83 - ETA: 5:27 - loss: 0.5127 - accuracy: 0.83 - ETA: 5:25 - loss: 0.5073 - accuracy: 0.83 - ETA: 5:23 - loss: 0.5026 - accuracy: 0.83 - ETA: 5:19 - loss: 0.5127 - accuracy: 0.83 - ETA: 5:16 - loss: 0.5093 - accuracy: 0.83 - ETA: 5:13 - loss: 0.5064 - accuracy: 0.83 - ETA: 5:11 - loss: 0.5042 - accuracy: 0.83 - ETA: 5:09 - loss: 0.5061 - accuracy: 0.83 - ETA: 5:06 - loss: 0.5085 - accuracy: 0.83 - ETA: 5:04 - loss: 0.5037 - accuracy: 0.83 - ETA: 5:02 - loss: 0.5031 - accuracy: 0.83 - ETA: 4:58 - loss: 0.4997 - accuracy: 0.83 - ETA: 4:56 - loss: 0.4983 - accuracy: 0.83 - ETA: 4:54 - loss: 0.4926 - accuracy: 0.84 - ETA: 4:51 - loss: 0.4945 - accuracy: 0.83 - ETA: 4:49 - loss: 0.4916 - accuracy: 0.84 - ETA: 4:46 - loss: 0.4929 - accuracy: 0.83 - ETA: 4:44 - loss: 0.4905 - accuracy: 0.83 - ETA: 4:41 - loss: 0.4921 - accuracy: 0.83 - ETA: 4:39 - loss: 0.4920 - accuracy: 0.83 - ETA: 4:37 - loss: 0.4908 - accuracy: 0.83 - ETA: 4:34 - loss: 0.4966 - accuracy: 0.83 - ETA: 4:31 - loss: 0.4951 - accuracy: 0.83 - ETA: 4:28 - loss: 0.5000 - accuracy: 0.83 - ETA: 4:26 - loss: 0.4966 - accuracy: 0.83 - ETA: 4:24 - loss: 0.4968 - accuracy: 0.83 - ETA: 4:22 - loss: 0.4929 - accuracy: 0.84 - ETA: 4:19 - loss: 0.4935 - accuracy: 0.84 - ETA: 4:17 - loss: 0.4925 - accuracy: 0.84 - ETA: 4:14 - loss: 0.4943 - accuracy: 0.83 - ETA: 4:11 - loss: 0.4974 - accuracy: 0.83 - ETA: 4:08 - loss: 0.4965 - accuracy: 0.83 - ETA: 4:07 - loss: 0.4917 - accuracy: 0.83 - ETA: 4:04 - loss: 0.4880 - accuracy: 0.84 - ETA: 4:02 - loss: 0.4880 - accuracy: 0.84 - ETA: 3:59 - loss: 0.4898 - accuracy: 0.84 - ETA: 3:57 - loss: 0.4895 - accuracy: 0.84 - ETA: 3:54 - loss: 0.4912 - accuracy: 0.84 - ETA: 3:52 - loss: 0.4890 - accuracy: 0.84 - ETA: 3:50 - loss: 0.4868 - accuracy: 0.84 - ETA: 3:47 - loss: 0.4862 - accuracy: 0.84 - ETA: 3:45 - loss: 0.4865 - accuracy: 0.84 - ETA: 3:42 - loss: 0.4884 - accuracy: 0.84 - ETA: 3:40 - loss: 0.4897 - accuracy: 0.84 - ETA: 3:37 - loss: 0.4909 - accuracy: 0.84 - ETA: 3:34 - loss: 0.4895 - accuracy: 0.84 - ETA: 3:32 - loss: 0.4909 - accuracy: 0.84 - ETA: 3:30 - loss: 0.4930 - accuracy: 0.84 - ETA: 3:27 - loss: 0.4937 - accuracy: 0.84 - ETA: 3:25 - loss: 0.4969 - accuracy: 0.84 - ETA: 3:22 - loss: 0.4969 - accuracy: 0.84 - ETA: 3:20 - loss: 0.4966 - accuracy: 0.84 - ETA: 3:17 - loss: 0.4981 - accuracy: 0.84 - ETA: 3:15 - loss: 0.5023 - accuracy: 0.83 - ETA: 3:13 - loss: 0.5021 - accuracy: 0.83 - ETA: 3:10 - loss: 0.4997 - accuracy: 0.84 - ETA: 3:08 - loss: 0.4972 - accuracy: 0.84 - ETA: 3:05 - loss: 0.4954 - accuracy: 0.84 - ETA: 3:03 - loss: 0.4966 - accuracy: 0.84 - ETA: 3:01 - loss: 0.4966 - accuracy: 0.84 - ETA: 2:58 - loss: 0.4983 - accuracy: 0.84 - ETA: 2:56 - loss: 0.4982 - accuracy: 0.84 - ETA: 2:53 - loss: 0.4980 - accuracy: 0.84 - ETA: 2:51 - loss: 0.4986 - accuracy: 0.84 - ETA: 2:49 - loss: 0.5018 - accuracy: 0.83 - ETA: 2:46 - loss: 0.4998 - accuracy: 0.84 - ETA: 2:44 - loss: 0.4985 - accuracy: 0.84 - ETA: 2:41 - loss: 0.4973 - accuracy: 0.84 - ETA: 2:39 - loss: 0.4965 - accuracy: 0.84 - ETA: 2:36 - loss: 0.4938 - accuracy: 0.84 - ETA: 2:34 - loss: 0.4954 - accuracy: 0.84 - ETA: 2:31 - loss: 0.4936 - accuracy: 0.84 - ETA: 2:29 - loss: 0.4919 - accuracy: 0.84 - ETA: 2:27 - loss: 0.4918 - accuracy: 0.84 - ETA: 2:24 - loss: 0.4904 - accuracy: 0.84 - ETA: 2:22 - loss: 0.4893 - accuracy: 0.84 - ETA: 2:19 - loss: 0.4893 - accuracy: 0.84 - ETA: 2:17 - loss: 0.4873 - accuracy: 0.84 - ETA: 2:15 - loss: 0.4871 - accuracy: 0.84 - ETA: 2:12 - loss: 0.4874 - accuracy: 0.84 - ETA: 2:10 - loss: 0.4881 - accuracy: 0.84 - ETA: 2:07 - loss: 0.4893 - accuracy: 0.84 - ETA: 2:05 - loss: 0.4894 - accuracy: 0.84 - ETA: 2:02 - loss: 0.4890 - accuracy: 0.84 - ETA: 2:00 - loss: 0.4890 - accuracy: 0.84 - ETA: 1:58 - loss: 0.4907 - accuracy: 0.84 - ETA: 1:56 - loss: 0.4928 - accuracy: 0.84 - ETA: 1:53 - loss: 0.4918 - accuracy: 0.84 - ETA: 1:51 - loss: 0.4916 - accuracy: 0.84 - ETA: 1:48 - loss: 0.4912 - accuracy: 0.84 - ETA: 1:46 - loss: 0.4916 - accuracy: 0.84 - ETA: 1:43 - loss: 0.4923 - accuracy: 0.84 - ETA: 1:41 - loss: 0.4922 - accuracy: 0.84 - ETA: 1:38 - loss: 0.4929 - accuracy: 0.84 - ETA: 1:36 - loss: 0.4914 - accuracy: 0.84 - ETA: 1:34 - loss: 0.4898 - accuracy: 0.84 - ETA: 1:31 - loss: 0.4905 - accuracy: 0.84 - ETA: 1:29 - loss: 0.4896 - accuracy: 0.84 - ETA: 1:26 - loss: 0.4906 - accuracy: 0.84 - ETA: 1:24 - loss: 0.4916 - accuracy: 0.84 - ETA: 1:22 - loss: 0.4901 - accuracy: 0.84 - ETA: 1:19 - loss: 0.4907 - accuracy: 0.84 - ETA: 1:17 - loss: 0.4912 - accuracy: 0.84 - ETA: 1:14 - loss: 0.4909 - accuracy: 0.84 - ETA: 1:12 - loss: 0.4904 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4908 - accuracy: 0.84 - ETA: 1:07 - loss: 0.4912 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4908 - accuracy: 0.84 - ETA: 1:02 - loss: 0.4916 - accuracy: 0.84 - ETA: 1:00 - loss: 0.4908 - accuracy: 0.84 - ETA: 57s - loss: 0.4911 - accuracy: 0.8440 - ETA: 55s - loss: 0.4909 - accuracy: 0.844 - ETA: 52s - loss: 0.4910 - accuracy: 0.843 - ETA: 50s - loss: 0.4905 - accuracy: 0.843 - ETA: 48s - loss: 0.4918 - accuracy: 0.843 - ETA: 45s - loss: 0.4910 - accuracy: 0.843 - ETA: 43s - loss: 0.4914 - accuracy: 0.843 - ETA: 40s - loss: 0.4899 - accuracy: 0.844 - ETA: 38s - loss: 0.4894 - accuracy: 0.844 - ETA: 36s - loss: 0.4887 - accuracy: 0.844 - ETA: 33s - loss: 0.4892 - accuracy: 0.844 - ETA: 31s - loss: 0.4895 - accuracy: 0.844 - ETA: 28s - loss: 0.4892 - accuracy: 0.844 - ETA: 26s - loss: 0.4886 - accuracy: 0.844 - ETA: 23s - loss: 0.4893 - accuracy: 0.844 - ETA: 21s - loss: 0.4897 - accuracy: 0.844 - ETA: 19s - loss: 0.4898 - accuracy: 0.844 - ETA: 16s - loss: 0.4913 - accuracy: 0.844 - ETA: 14s - loss: 0.4908 - accuracy: 0.844 - ETA: 11s - loss: 0.4918 - accuracy: 0.844 - ETA: 9s - loss: 0.4914 - accuracy: 0.844 - ETA: 6s - loss: 0.4922 - accuracy: 0.84 - ETA: 4s - loss: 0.4921 - accuracy: 0.84 - ETA: 2s - loss: 0.4920 - accuracy: 0.84 - 422s 22ms/step - loss: 0.4907 - accuracy: 0.8443 - val_loss: 1.1166 - val_accuracy: 0.7687\n",
      "Epoch 10/100\n",
      "19312/19312 [==============================] - ETA: 6:38 - loss: 0.4188 - accuracy: 0.85 - ETA: 6:55 - loss: 0.4157 - accuracy: 0.85 - ETA: 6:25 - loss: 0.5050 - accuracy: 0.84 - ETA: 6:13 - loss: 0.4891 - accuracy: 0.84 - ETA: 6:03 - loss: 0.4538 - accuracy: 0.85 - ETA: 5:58 - loss: 0.4365 - accuracy: 0.86 - ETA: 6:00 - loss: 0.4495 - accuracy: 0.86 - ETA: 6:09 - loss: 0.4511 - accuracy: 0.86 - ETA: 6:00 - loss: 0.4346 - accuracy: 0.86 - ETA: 5:57 - loss: 0.4354 - accuracy: 0.86 - ETA: 5:54 - loss: 0.4405 - accuracy: 0.85 - ETA: 5:48 - loss: 0.4452 - accuracy: 0.85 - ETA: 5:47 - loss: 0.4511 - accuracy: 0.85 - ETA: 5:48 - loss: 0.4432 - accuracy: 0.85 - ETA: 5:43 - loss: 0.4384 - accuracy: 0.86 - ETA: 5:41 - loss: 0.4343 - accuracy: 0.86 - ETA: 5:36 - loss: 0.4439 - accuracy: 0.86 - ETA: 5:32 - loss: 0.4455 - accuracy: 0.86 - ETA: 5:30 - loss: 0.4478 - accuracy: 0.86 - ETA: 5:27 - loss: 0.4613 - accuracy: 0.85 - ETA: 5:25 - loss: 0.4581 - accuracy: 0.85 - ETA: 5:21 - loss: 0.4588 - accuracy: 0.85 - ETA: 5:19 - loss: 0.4539 - accuracy: 0.85 - ETA: 5:16 - loss: 0.4535 - accuracy: 0.85 - ETA: 5:12 - loss: 0.4506 - accuracy: 0.85 - ETA: 5:11 - loss: 0.4465 - accuracy: 0.85 - ETA: 5:10 - loss: 0.4459 - accuracy: 0.85 - ETA: 5:07 - loss: 0.4432 - accuracy: 0.85 - ETA: 5:03 - loss: 0.4448 - accuracy: 0.85 - ETA: 5:03 - loss: 0.4453 - accuracy: 0.85 - ETA: 5:00 - loss: 0.4461 - accuracy: 0.85 - ETA: 4:57 - loss: 0.4483 - accuracy: 0.85 - ETA: 4:54 - loss: 0.4493 - accuracy: 0.85 - ETA: 4:53 - loss: 0.4434 - accuracy: 0.85 - ETA: 4:51 - loss: 0.4411 - accuracy: 0.85 - ETA: 4:47 - loss: 0.4400 - accuracy: 0.85 - ETA: 4:46 - loss: 0.4432 - accuracy: 0.85 - ETA: 4:42 - loss: 0.4430 - accuracy: 0.85 - ETA: 4:40 - loss: 0.4429 - accuracy: 0.85 - ETA: 4:37 - loss: 0.4443 - accuracy: 0.85 - ETA: 4:35 - loss: 0.4426 - accuracy: 0.85 - ETA: 4:32 - loss: 0.4415 - accuracy: 0.85 - ETA: 4:29 - loss: 0.4393 - accuracy: 0.85 - ETA: 4:27 - loss: 0.4374 - accuracy: 0.85 - ETA: 4:24 - loss: 0.4407 - accuracy: 0.85 - ETA: 4:21 - loss: 0.4387 - accuracy: 0.86 - ETA: 4:19 - loss: 0.4427 - accuracy: 0.85 - ETA: 4:17 - loss: 0.4415 - accuracy: 0.85 - ETA: 4:14 - loss: 0.4425 - accuracy: 0.85 - ETA: 4:11 - loss: 0.4401 - accuracy: 0.86 - ETA: 4:09 - loss: 0.4426 - accuracy: 0.86 - ETA: 4:06 - loss: 0.4433 - accuracy: 0.85 - ETA: 4:05 - loss: 0.4432 - accuracy: 0.85 - ETA: 4:03 - loss: 0.4459 - accuracy: 0.85 - ETA: 4:00 - loss: 0.4449 - accuracy: 0.85 - ETA: 3:58 - loss: 0.4432 - accuracy: 0.85 - ETA: 3:55 - loss: 0.4408 - accuracy: 0.85 - ETA: 3:52 - loss: 0.4392 - accuracy: 0.86 - ETA: 3:50 - loss: 0.4378 - accuracy: 0.86 - ETA: 3:47 - loss: 0.4370 - accuracy: 0.86 - ETA: 3:44 - loss: 0.4370 - accuracy: 0.86 - ETA: 3:42 - loss: 0.4363 - accuracy: 0.86 - ETA: 3:39 - loss: 0.4359 - accuracy: 0.86 - ETA: 3:37 - loss: 0.4382 - accuracy: 0.85 - ETA: 3:34 - loss: 0.4384 - accuracy: 0.85 - ETA: 3:32 - loss: 0.4389 - accuracy: 0.85 - ETA: 3:29 - loss: 0.4378 - accuracy: 0.85 - ETA: 3:27 - loss: 0.4370 - accuracy: 0.85 - ETA: 3:24 - loss: 0.4370 - accuracy: 0.85 - ETA: 3:21 - loss: 0.4387 - accuracy: 0.85 - ETA: 3:19 - loss: 0.4383 - accuracy: 0.85 - ETA: 3:16 - loss: 0.4409 - accuracy: 0.85 - ETA: 3:14 - loss: 0.4408 - accuracy: 0.85 - ETA: 3:11 - loss: 0.4404 - accuracy: 0.85 - ETA: 3:08 - loss: 0.4389 - accuracy: 0.85 - ETA: 3:06 - loss: 0.4399 - accuracy: 0.85 - ETA: 3:03 - loss: 0.4423 - accuracy: 0.85 - ETA: 3:01 - loss: 0.4426 - accuracy: 0.85 - ETA: 2:58 - loss: 0.4425 - accuracy: 0.85 - ETA: 2:56 - loss: 0.4415 - accuracy: 0.85 - ETA: 2:53 - loss: 0.4401 - accuracy: 0.85 - ETA: 2:51 - loss: 0.4416 - accuracy: 0.85 - ETA: 2:48 - loss: 0.4421 - accuracy: 0.85 - ETA: 2:46 - loss: 0.4420 - accuracy: 0.85 - ETA: 2:43 - loss: 0.4415 - accuracy: 0.85 - ETA: 2:41 - loss: 0.4417 - accuracy: 0.85 - ETA: 2:38 - loss: 0.4405 - accuracy: 0.85 - ETA: 2:36 - loss: 0.4402 - accuracy: 0.85 - ETA: 2:33 - loss: 0.4396 - accuracy: 0.85 - ETA: 2:31 - loss: 0.4390 - accuracy: 0.85 - ETA: 2:28 - loss: 0.4383 - accuracy: 0.85 - ETA: 2:26 - loss: 0.4382 - accuracy: 0.85 - ETA: 2:23 - loss: 0.4386 - accuracy: 0.85 - ETA: 2:21 - loss: 0.4380 - accuracy: 0.85 - ETA: 2:18 - loss: 0.4384 - accuracy: 0.85 - ETA: 2:16 - loss: 0.4388 - accuracy: 0.85 - ETA: 2:13 - loss: 0.4398 - accuracy: 0.85 - ETA: 2:11 - loss: 0.4399 - accuracy: 0.85 - ETA: 2:08 - loss: 0.4390 - accuracy: 0.85 - ETA: 2:06 - loss: 0.4390 - accuracy: 0.85 - ETA: 2:03 - loss: 0.4397 - accuracy: 0.85 - ETA: 2:01 - loss: 0.4418 - accuracy: 0.85 - ETA: 1:58 - loss: 0.4398 - accuracy: 0.85 - ETA: 1:56 - loss: 0.4397 - accuracy: 0.85 - ETA: 1:53 - loss: 0.4396 - accuracy: 0.85 - ETA: 1:51 - loss: 0.4391 - accuracy: 0.85 - ETA: 1:49 - loss: 0.4384 - accuracy: 0.85 - ETA: 1:46 - loss: 0.4384 - accuracy: 0.85 - ETA: 1:44 - loss: 0.4395 - accuracy: 0.85 - ETA: 1:41 - loss: 0.4383 - accuracy: 0.85 - ETA: 1:39 - loss: 0.4378 - accuracy: 0.85 - ETA: 1:36 - loss: 0.4386 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4386 - accuracy: 0.85 - ETA: 1:31 - loss: 0.4389 - accuracy: 0.85 - ETA: 1:29 - loss: 0.4389 - accuracy: 0.85 - ETA: 1:26 - loss: 0.4390 - accuracy: 0.85 - ETA: 1:24 - loss: 0.4386 - accuracy: 0.85 - ETA: 1:21 - loss: 0.4393 - accuracy: 0.85 - ETA: 1:19 - loss: 0.4399 - accuracy: 0.85 - ETA: 1:16 - loss: 0.4412 - accuracy: 0.85 - ETA: 1:14 - loss: 0.4409 - accuracy: 0.85 - ETA: 1:11 - loss: 0.4418 - accuracy: 0.85 - ETA: 1:09 - loss: 0.4419 - accuracy: 0.85 - ETA: 1:06 - loss: 0.4429 - accuracy: 0.85 - ETA: 1:04 - loss: 0.4433 - accuracy: 0.85 - ETA: 1:01 - loss: 0.4432 - accuracy: 0.85 - ETA: 59s - loss: 0.4426 - accuracy: 0.8580 - ETA: 56s - loss: 0.4422 - accuracy: 0.858 - ETA: 54s - loss: 0.4420 - accuracy: 0.858 - ETA: 51s - loss: 0.4429 - accuracy: 0.857 - ETA: 49s - loss: 0.4433 - accuracy: 0.857 - ETA: 46s - loss: 0.4424 - accuracy: 0.858 - ETA: 44s - loss: 0.4415 - accuracy: 0.858 - ETA: 41s - loss: 0.4403 - accuracy: 0.858 - ETA: 39s - loss: 0.4401 - accuracy: 0.858 - ETA: 36s - loss: 0.4414 - accuracy: 0.858 - ETA: 34s - loss: 0.4408 - accuracy: 0.858 - ETA: 32s - loss: 0.4415 - accuracy: 0.858 - ETA: 29s - loss: 0.4419 - accuracy: 0.858 - ETA: 27s - loss: 0.4418 - accuracy: 0.858 - ETA: 24s - loss: 0.4417 - accuracy: 0.858 - ETA: 22s - loss: 0.4421 - accuracy: 0.857 - ETA: 19s - loss: 0.4413 - accuracy: 0.858 - ETA: 17s - loss: 0.4421 - accuracy: 0.858 - ETA: 14s - loss: 0.4411 - accuracy: 0.858 - ETA: 12s - loss: 0.4408 - accuracy: 0.858 - ETA: 9s - loss: 0.4419 - accuracy: 0.858 - ETA: 7s - loss: 0.4434 - accuracy: 0.85 - ETA: 4s - loss: 0.4432 - accuracy: 0.85 - ETA: 2s - loss: 0.4421 - accuracy: 0.85 - 434s 22ms/step - loss: 0.4416 - accuracy: 0.8590 - val_loss: 1.0830 - val_accuracy: 0.7683\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:51 - loss: 0.4292 - accuracy: 0.85 - ETA: 7:11 - loss: 0.3537 - accuracy: 0.88 - ETA: 6:40 - loss: 0.3330 - accuracy: 0.88 - ETA: 6:29 - loss: 0.3493 - accuracy: 0.87 - ETA: 6:25 - loss: 0.3494 - accuracy: 0.87 - ETA: 6:20 - loss: 0.3566 - accuracy: 0.87 - ETA: 6:12 - loss: 0.3472 - accuracy: 0.87 - ETA: 6:07 - loss: 0.3445 - accuracy: 0.88 - ETA: 6:03 - loss: 0.3549 - accuracy: 0.87 - ETA: 6:00 - loss: 0.3560 - accuracy: 0.87 - ETA: 5:55 - loss: 0.3482 - accuracy: 0.88 - ETA: 5:53 - loss: 0.3497 - accuracy: 0.88 - ETA: 5:49 - loss: 0.3519 - accuracy: 0.88 - ETA: 5:47 - loss: 0.3612 - accuracy: 0.88 - ETA: 5:44 - loss: 0.3704 - accuracy: 0.87 - ETA: 5:42 - loss: 0.3655 - accuracy: 0.88 - ETA: 5:40 - loss: 0.3570 - accuracy: 0.88 - ETA: 5:38 - loss: 0.3543 - accuracy: 0.88 - ETA: 5:35 - loss: 0.3596 - accuracy: 0.88 - ETA: 5:32 - loss: 0.3563 - accuracy: 0.88 - ETA: 5:29 - loss: 0.3524 - accuracy: 0.88 - ETA: 5:25 - loss: 0.3574 - accuracy: 0.88 - ETA: 5:24 - loss: 0.3554 - accuracy: 0.88 - ETA: 5:21 - loss: 0.3595 - accuracy: 0.88 - ETA: 5:18 - loss: 0.3606 - accuracy: 0.88 - ETA: 5:16 - loss: 0.3692 - accuracy: 0.88 - ETA: 5:13 - loss: 0.3693 - accuracy: 0.88 - ETA: 5:09 - loss: 0.3661 - accuracy: 0.88 - ETA: 5:07 - loss: 0.3669 - accuracy: 0.88 - ETA: 5:05 - loss: 0.3640 - accuracy: 0.88 - ETA: 5:01 - loss: 0.3663 - accuracy: 0.88 - ETA: 4:59 - loss: 0.3640 - accuracy: 0.88 - ETA: 4:56 - loss: 0.3635 - accuracy: 0.88 - ETA: 4:53 - loss: 0.3625 - accuracy: 0.88 - ETA: 4:51 - loss: 0.3623 - accuracy: 0.88 - ETA: 4:47 - loss: 0.3656 - accuracy: 0.88 - ETA: 4:45 - loss: 0.3658 - accuracy: 0.88 - ETA: 4:42 - loss: 0.3669 - accuracy: 0.88 - ETA: 4:40 - loss: 0.3660 - accuracy: 0.88 - ETA: 4:37 - loss: 0.3675 - accuracy: 0.88 - ETA: 4:34 - loss: 0.3681 - accuracy: 0.88 - ETA: 4:31 - loss: 0.3668 - accuracy: 0.88 - ETA: 4:28 - loss: 0.3648 - accuracy: 0.88 - ETA: 4:26 - loss: 0.3684 - accuracy: 0.88 - ETA: 4:23 - loss: 0.3694 - accuracy: 0.88 - ETA: 4:21 - loss: 0.3688 - accuracy: 0.88 - ETA: 4:18 - loss: 0.3697 - accuracy: 0.88 - ETA: 4:16 - loss: 0.3721 - accuracy: 0.88 - ETA: 4:13 - loss: 0.3733 - accuracy: 0.88 - ETA: 4:11 - loss: 0.3751 - accuracy: 0.87 - ETA: 4:08 - loss: 0.3785 - accuracy: 0.87 - ETA: 4:06 - loss: 0.3779 - accuracy: 0.87 - ETA: 4:03 - loss: 0.3755 - accuracy: 0.87 - ETA: 4:00 - loss: 0.3753 - accuracy: 0.87 - ETA: 3:58 - loss: 0.3739 - accuracy: 0.87 - ETA: 3:55 - loss: 0.3742 - accuracy: 0.87 - ETA: 3:53 - loss: 0.3763 - accuracy: 0.87 - ETA: 3:50 - loss: 0.3742 - accuracy: 0.88 - ETA: 3:48 - loss: 0.3768 - accuracy: 0.87 - ETA: 3:46 - loss: 0.3755 - accuracy: 0.87 - ETA: 3:43 - loss: 0.3748 - accuracy: 0.87 - ETA: 3:40 - loss: 0.3757 - accuracy: 0.87 - ETA: 3:38 - loss: 0.3775 - accuracy: 0.87 - ETA: 3:35 - loss: 0.3752 - accuracy: 0.87 - ETA: 3:33 - loss: 0.3782 - accuracy: 0.87 - ETA: 3:30 - loss: 0.3802 - accuracy: 0.87 - ETA: 3:27 - loss: 0.3789 - accuracy: 0.87 - ETA: 3:25 - loss: 0.3792 - accuracy: 0.87 - ETA: 3:22 - loss: 0.3802 - accuracy: 0.87 - ETA: 3:19 - loss: 0.3804 - accuracy: 0.87 - ETA: 3:17 - loss: 0.3790 - accuracy: 0.87 - ETA: 3:15 - loss: 0.3787 - accuracy: 0.87 - ETA: 3:12 - loss: 0.3802 - accuracy: 0.87 - ETA: 3:10 - loss: 0.3785 - accuracy: 0.87 - ETA: 3:07 - loss: 0.3769 - accuracy: 0.87 - ETA: 3:04 - loss: 0.3761 - accuracy: 0.87 - ETA: 3:02 - loss: 0.3769 - accuracy: 0.87 - ETA: 3:00 - loss: 0.3766 - accuracy: 0.87 - ETA: 2:57 - loss: 0.3755 - accuracy: 0.87 - ETA: 2:54 - loss: 0.3747 - accuracy: 0.87 - ETA: 2:52 - loss: 0.3763 - accuracy: 0.87 - ETA: 2:49 - loss: 0.3757 - accuracy: 0.87 - ETA: 2:47 - loss: 0.3764 - accuracy: 0.87 - ETA: 2:44 - loss: 0.3776 - accuracy: 0.87 - ETA: 2:42 - loss: 0.3762 - accuracy: 0.87 - ETA: 2:39 - loss: 0.3752 - accuracy: 0.87 - ETA: 2:37 - loss: 0.3739 - accuracy: 0.87 - ETA: 2:34 - loss: 0.3735 - accuracy: 0.87 - ETA: 2:32 - loss: 0.3740 - accuracy: 0.87 - ETA: 2:29 - loss: 0.3738 - accuracy: 0.87 - ETA: 2:27 - loss: 0.3745 - accuracy: 0.87 - ETA: 2:24 - loss: 0.3751 - accuracy: 0.87 - ETA: 2:22 - loss: 0.3746 - accuracy: 0.87 - ETA: 2:19 - loss: 0.3760 - accuracy: 0.87 - ETA: 2:17 - loss: 0.3759 - accuracy: 0.87 - ETA: 2:14 - loss: 0.3781 - accuracy: 0.87 - ETA: 2:12 - loss: 0.3772 - accuracy: 0.87 - ETA: 2:09 - loss: 0.3772 - accuracy: 0.87 - ETA: 2:07 - loss: 0.3775 - accuracy: 0.87 - ETA: 2:04 - loss: 0.3771 - accuracy: 0.87 - ETA: 2:02 - loss: 0.3755 - accuracy: 0.87 - ETA: 1:59 - loss: 0.3754 - accuracy: 0.87 - ETA: 1:57 - loss: 0.3748 - accuracy: 0.87 - ETA: 1:54 - loss: 0.3735 - accuracy: 0.87 - ETA: 1:52 - loss: 0.3728 - accuracy: 0.87 - ETA: 1:50 - loss: 0.3732 - accuracy: 0.87 - ETA: 1:47 - loss: 0.3740 - accuracy: 0.87 - ETA: 1:45 - loss: 0.3738 - accuracy: 0.87 - ETA: 1:42 - loss: 0.3733 - accuracy: 0.87 - ETA: 1:40 - loss: 0.3733 - accuracy: 0.87 - ETA: 1:37 - loss: 0.3733 - accuracy: 0.87 - ETA: 1:35 - loss: 0.3725 - accuracy: 0.87 - ETA: 1:32 - loss: 0.3742 - accuracy: 0.87 - ETA: 1:30 - loss: 0.3754 - accuracy: 0.87 - ETA: 1:27 - loss: 0.3751 - accuracy: 0.87 - ETA: 1:25 - loss: 0.3749 - accuracy: 0.87 - ETA: 1:22 - loss: 0.3749 - accuracy: 0.87 - ETA: 1:20 - loss: 0.3748 - accuracy: 0.87 - ETA: 1:18 - loss: 0.3743 - accuracy: 0.87 - ETA: 1:15 - loss: 0.3752 - accuracy: 0.87 - ETA: 1:13 - loss: 0.3746 - accuracy: 0.87 - ETA: 1:10 - loss: 0.3746 - accuracy: 0.87 - ETA: 1:08 - loss: 0.3745 - accuracy: 0.87 - ETA: 1:05 - loss: 0.3738 - accuracy: 0.87 - ETA: 1:03 - loss: 0.3744 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3751 - accuracy: 0.87 - ETA: 58s - loss: 0.3770 - accuracy: 0.8784 - ETA: 55s - loss: 0.3772 - accuracy: 0.878 - ETA: 53s - loss: 0.3772 - accuracy: 0.878 - ETA: 50s - loss: 0.3769 - accuracy: 0.878 - ETA: 48s - loss: 0.3753 - accuracy: 0.879 - ETA: 46s - loss: 0.3758 - accuracy: 0.879 - ETA: 43s - loss: 0.3754 - accuracy: 0.879 - ETA: 41s - loss: 0.3752 - accuracy: 0.879 - ETA: 38s - loss: 0.3764 - accuracy: 0.879 - ETA: 36s - loss: 0.3775 - accuracy: 0.879 - ETA: 33s - loss: 0.3776 - accuracy: 0.879 - ETA: 31s - loss: 0.3783 - accuracy: 0.878 - ETA: 28s - loss: 0.3792 - accuracy: 0.878 - ETA: 26s - loss: 0.3789 - accuracy: 0.878 - ETA: 24s - loss: 0.3792 - accuracy: 0.878 - ETA: 21s - loss: 0.3801 - accuracy: 0.877 - ETA: 19s - loss: 0.3800 - accuracy: 0.877 - ETA: 16s - loss: 0.3796 - accuracy: 0.877 - ETA: 14s - loss: 0.3796 - accuracy: 0.877 - ETA: 11s - loss: 0.3805 - accuracy: 0.877 - ETA: 9s - loss: 0.3810 - accuracy: 0.877 - ETA: 7s - loss: 0.3809 - accuracy: 0.87 - ETA: 4s - loss: 0.3806 - accuracy: 0.87 - ETA: 2s - loss: 0.3814 - accuracy: 0.87 - 418s 22ms/step - loss: 0.3810 - accuracy: 0.8770 - val_loss: 1.1303 - val_accuracy: 0.7743\n",
      "Epoch 12/100\n",
      "19312/19312 [==============================] - ETA: 5:48 - loss: 0.2448 - accuracy: 0.90 - ETA: 5:54 - loss: 0.3082 - accuracy: 0.89 - ETA: 5:52 - loss: 0.3137 - accuracy: 0.89 - ETA: 5:53 - loss: 0.3415 - accuracy: 0.89 - ETA: 5:45 - loss: 0.3300 - accuracy: 0.90 - ETA: 5:46 - loss: 0.3224 - accuracy: 0.90 - ETA: 5:45 - loss: 0.3531 - accuracy: 0.89 - ETA: 5:38 - loss: 0.3566 - accuracy: 0.89 - ETA: 5:36 - loss: 0.3678 - accuracy: 0.89 - ETA: 5:34 - loss: 0.3632 - accuracy: 0.89 - ETA: 5:33 - loss: 0.3528 - accuracy: 0.89 - ETA: 5:32 - loss: 0.3623 - accuracy: 0.89 - ETA: 5:32 - loss: 0.3641 - accuracy: 0.89 - ETA: 5:30 - loss: 0.3571 - accuracy: 0.89 - ETA: 5:26 - loss: 0.3497 - accuracy: 0.89 - ETA: 5:24 - loss: 0.3492 - accuracy: 0.89 - ETA: 5:20 - loss: 0.3522 - accuracy: 0.89 - ETA: 5:17 - loss: 0.3501 - accuracy: 0.89 - ETA: 5:15 - loss: 0.3439 - accuracy: 0.89 - ETA: 5:13 - loss: 0.3472 - accuracy: 0.89 - ETA: 5:11 - loss: 0.3403 - accuracy: 0.89 - ETA: 5:08 - loss: 0.3390 - accuracy: 0.89 - ETA: 5:05 - loss: 0.3400 - accuracy: 0.89 - ETA: 5:03 - loss: 0.3342 - accuracy: 0.89 - ETA: 5:01 - loss: 0.3385 - accuracy: 0.89 - ETA: 4:59 - loss: 0.3416 - accuracy: 0.89 - ETA: 4:57 - loss: 0.3347 - accuracy: 0.89 - ETA: 4:54 - loss: 0.3406 - accuracy: 0.89 - ETA: 4:51 - loss: 0.3419 - accuracy: 0.89 - ETA: 4:49 - loss: 0.3417 - accuracy: 0.89 - ETA: 4:46 - loss: 0.3424 - accuracy: 0.89 - ETA: 4:44 - loss: 0.3415 - accuracy: 0.89 - ETA: 4:42 - loss: 0.3389 - accuracy: 0.89 - ETA: 4:39 - loss: 0.3371 - accuracy: 0.89 - ETA: 4:37 - loss: 0.3440 - accuracy: 0.89 - ETA: 4:34 - loss: 0.3459 - accuracy: 0.88 - ETA: 4:32 - loss: 0.3469 - accuracy: 0.88 - ETA: 4:29 - loss: 0.3454 - accuracy: 0.88 - ETA: 4:27 - loss: 0.3470 - accuracy: 0.88 - ETA: 4:25 - loss: 0.3470 - accuracy: 0.88 - ETA: 4:22 - loss: 0.3457 - accuracy: 0.88 - ETA: 4:20 - loss: 0.3452 - accuracy: 0.88 - ETA: 4:17 - loss: 0.3491 - accuracy: 0.88 - ETA: 4:15 - loss: 0.3512 - accuracy: 0.88 - ETA: 4:12 - loss: 0.3488 - accuracy: 0.88 - ETA: 4:10 - loss: 0.3493 - accuracy: 0.88 - ETA: 4:08 - loss: 0.3474 - accuracy: 0.88 - ETA: 4:07 - loss: 0.3487 - accuracy: 0.88 - ETA: 4:04 - loss: 0.3473 - accuracy: 0.88 - ETA: 4:02 - loss: 0.3457 - accuracy: 0.88 - ETA: 3:59 - loss: 0.3461 - accuracy: 0.88 - ETA: 3:57 - loss: 0.3449 - accuracy: 0.88 - ETA: 3:55 - loss: 0.3429 - accuracy: 0.89 - ETA: 3:53 - loss: 0.3410 - accuracy: 0.89 - ETA: 3:51 - loss: 0.3417 - accuracy: 0.89 - ETA: 3:49 - loss: 0.3439 - accuracy: 0.89 - ETA: 3:46 - loss: 0.3459 - accuracy: 0.88 - ETA: 3:44 - loss: 0.3449 - accuracy: 0.89 - ETA: 3:41 - loss: 0.3453 - accuracy: 0.88 - ETA: 3:39 - loss: 0.3451 - accuracy: 0.88 - ETA: 3:36 - loss: 0.3464 - accuracy: 0.88 - ETA: 3:34 - loss: 0.3461 - accuracy: 0.88 - ETA: 3:32 - loss: 0.3449 - accuracy: 0.88 - ETA: 3:29 - loss: 0.3469 - accuracy: 0.88 - ETA: 3:27 - loss: 0.3438 - accuracy: 0.88 - ETA: 3:25 - loss: 0.3453 - accuracy: 0.88 - ETA: 3:23 - loss: 0.3440 - accuracy: 0.88 - ETA: 3:20 - loss: 0.3455 - accuracy: 0.88 - ETA: 3:17 - loss: 0.3454 - accuracy: 0.88 - ETA: 3:15 - loss: 0.3448 - accuracy: 0.88 - ETA: 3:13 - loss: 0.3440 - accuracy: 0.88 - ETA: 3:11 - loss: 0.3435 - accuracy: 0.88 - ETA: 3:08 - loss: 0.3434 - accuracy: 0.88 - ETA: 3:05 - loss: 0.3424 - accuracy: 0.88 - ETA: 3:03 - loss: 0.3434 - accuracy: 0.88 - ETA: 3:01 - loss: 0.3431 - accuracy: 0.88 - ETA: 2:58 - loss: 0.3430 - accuracy: 0.88 - ETA: 2:56 - loss: 0.3422 - accuracy: 0.88 - ETA: 2:53 - loss: 0.3431 - accuracy: 0.88 - ETA: 2:51 - loss: 0.3422 - accuracy: 0.88 - ETA: 2:49 - loss: 0.3416 - accuracy: 0.88 - ETA: 2:46 - loss: 0.3417 - accuracy: 0.88 - ETA: 2:44 - loss: 0.3409 - accuracy: 0.89 - ETA: 2:41 - loss: 0.3400 - accuracy: 0.89 - ETA: 2:38 - loss: 0.3403 - accuracy: 0.88 - ETA: 2:36 - loss: 0.3415 - accuracy: 0.88 - ETA: 2:34 - loss: 0.3415 - accuracy: 0.88 - ETA: 2:31 - loss: 0.3430 - accuracy: 0.88 - ETA: 2:29 - loss: 0.3438 - accuracy: 0.88 - ETA: 2:26 - loss: 0.3455 - accuracy: 0.88 - ETA: 2:24 - loss: 0.3466 - accuracy: 0.88 - ETA: 2:21 - loss: 0.3462 - accuracy: 0.88 - ETA: 2:19 - loss: 0.3464 - accuracy: 0.88 - ETA: 2:16 - loss: 0.3463 - accuracy: 0.88 - ETA: 2:14 - loss: 0.3466 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3458 - accuracy: 0.88 - ETA: 2:09 - loss: 0.3468 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3484 - accuracy: 0.88 - ETA: 2:04 - loss: 0.3480 - accuracy: 0.88 - ETA: 2:02 - loss: 0.3475 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3473 - accuracy: 0.88 - ETA: 1:57 - loss: 0.3487 - accuracy: 0.88 - ETA: 1:55 - loss: 0.3478 - accuracy: 0.88 - ETA: 1:52 - loss: 0.3484 - accuracy: 0.88 - ETA: 1:50 - loss: 0.3491 - accuracy: 0.88 - ETA: 1:48 - loss: 0.3487 - accuracy: 0.88 - ETA: 1:45 - loss: 0.3492 - accuracy: 0.88 - ETA: 1:43 - loss: 0.3494 - accuracy: 0.88 - ETA: 1:41 - loss: 0.3505 - accuracy: 0.88 - ETA: 1:38 - loss: 0.3499 - accuracy: 0.88 - ETA: 1:36 - loss: 0.3501 - accuracy: 0.88 - ETA: 1:33 - loss: 0.3495 - accuracy: 0.88 - ETA: 1:31 - loss: 0.3495 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3501 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3498 - accuracy: 0.88 - ETA: 1:23 - loss: 0.3501 - accuracy: 0.88 - ETA: 1:21 - loss: 0.3493 - accuracy: 0.88 - ETA: 1:19 - loss: 0.3495 - accuracy: 0.88 - ETA: 1:16 - loss: 0.3489 - accuracy: 0.88 - ETA: 1:14 - loss: 0.3487 - accuracy: 0.88 - ETA: 1:11 - loss: 0.3483 - accuracy: 0.88 - ETA: 1:09 - loss: 0.3492 - accuracy: 0.88 - ETA: 1:07 - loss: 0.3505 - accuracy: 0.88 - ETA: 1:04 - loss: 0.3500 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3505 - accuracy: 0.88 - ETA: 59s - loss: 0.3506 - accuracy: 0.8876 - ETA: 57s - loss: 0.3499 - accuracy: 0.887 - ETA: 55s - loss: 0.3485 - accuracy: 0.888 - ETA: 52s - loss: 0.3484 - accuracy: 0.888 - ETA: 50s - loss: 0.3479 - accuracy: 0.888 - ETA: 47s - loss: 0.3478 - accuracy: 0.888 - ETA: 45s - loss: 0.3471 - accuracy: 0.888 - ETA: 43s - loss: 0.3469 - accuracy: 0.888 - ETA: 40s - loss: 0.3472 - accuracy: 0.888 - ETA: 38s - loss: 0.3481 - accuracy: 0.888 - ETA: 35s - loss: 0.3500 - accuracy: 0.887 - ETA: 33s - loss: 0.3501 - accuracy: 0.887 - ETA: 30s - loss: 0.3512 - accuracy: 0.887 - ETA: 28s - loss: 0.3506 - accuracy: 0.887 - ETA: 26s - loss: 0.3500 - accuracy: 0.887 - ETA: 23s - loss: 0.3504 - accuracy: 0.887 - ETA: 21s - loss: 0.3498 - accuracy: 0.888 - ETA: 18s - loss: 0.3496 - accuracy: 0.888 - ETA: 16s - loss: 0.3494 - accuracy: 0.888 - ETA: 14s - loss: 0.3515 - accuracy: 0.887 - ETA: 11s - loss: 0.3524 - accuracy: 0.887 - ETA: 9s - loss: 0.3521 - accuracy: 0.887 - ETA: 6s - loss: 0.3526 - accuracy: 0.88 - ETA: 4s - loss: 0.3522 - accuracy: 0.88 - ETA: 2s - loss: 0.3529 - accuracy: 0.88 - 414s 21ms/step - loss: 0.3532 - accuracy: 0.8871 - val_loss: 1.1377 - val_accuracy: 0.7739\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:27 - loss: 0.3654 - accuracy: 0.87 - ETA: 6:10 - loss: 0.2929 - accuracy: 0.91 - ETA: 6:02 - loss: 0.2993 - accuracy: 0.90 - ETA: 5:50 - loss: 0.2999 - accuracy: 0.90 - ETA: 5:55 - loss: 0.2958 - accuracy: 0.90 - ETA: 5:49 - loss: 0.3064 - accuracy: 0.89 - ETA: 5:56 - loss: 0.3107 - accuracy: 0.90 - ETA: 5:52 - loss: 0.3197 - accuracy: 0.89 - ETA: 5:48 - loss: 0.3154 - accuracy: 0.89 - ETA: 5:43 - loss: 0.3037 - accuracy: 0.89 - ETA: 5:40 - loss: 0.3046 - accuracy: 0.89 - ETA: 5:37 - loss: 0.3027 - accuracy: 0.89 - ETA: 5:36 - loss: 0.3010 - accuracy: 0.89 - ETA: 5:33 - loss: 0.3051 - accuracy: 0.89 - ETA: 5:30 - loss: 0.3008 - accuracy: 0.89 - ETA: 5:28 - loss: 0.3007 - accuracy: 0.89 - ETA: 5:23 - loss: 0.3011 - accuracy: 0.89 - ETA: 5:22 - loss: 0.2985 - accuracy: 0.89 - ETA: 5:19 - loss: 0.2938 - accuracy: 0.90 - ETA: 5:17 - loss: 0.2947 - accuracy: 0.90 - ETA: 5:14 - loss: 0.2998 - accuracy: 0.89 - ETA: 5:10 - loss: 0.2992 - accuracy: 0.89 - ETA: 5:08 - loss: 0.2982 - accuracy: 0.89 - ETA: 5:05 - loss: 0.2975 - accuracy: 0.89 - ETA: 5:01 - loss: 0.2974 - accuracy: 0.90 - ETA: 4:59 - loss: 0.2982 - accuracy: 0.89 - ETA: 4:57 - loss: 0.2944 - accuracy: 0.90 - ETA: 4:54 - loss: 0.2960 - accuracy: 0.90 - ETA: 4:53 - loss: 0.2989 - accuracy: 0.90 - ETA: 4:51 - loss: 0.2989 - accuracy: 0.89 - ETA: 4:48 - loss: 0.3001 - accuracy: 0.89 - ETA: 4:46 - loss: 0.3016 - accuracy: 0.89 - ETA: 4:44 - loss: 0.3021 - accuracy: 0.89 - ETA: 4:43 - loss: 0.3021 - accuracy: 0.89 - ETA: 4:40 - loss: 0.2992 - accuracy: 0.89 - ETA: 4:38 - loss: 0.3016 - accuracy: 0.89 - ETA: 4:35 - loss: 0.3003 - accuracy: 0.89 - ETA: 4:32 - loss: 0.3029 - accuracy: 0.89 - ETA: 4:30 - loss: 0.3031 - accuracy: 0.89 - ETA: 4:28 - loss: 0.3063 - accuracy: 0.89 - ETA: 4:26 - loss: 0.3066 - accuracy: 0.89 - ETA: 4:23 - loss: 0.3047 - accuracy: 0.89 - ETA: 4:21 - loss: 0.3043 - accuracy: 0.89 - ETA: 4:18 - loss: 0.3047 - accuracy: 0.89 - ETA: 4:16 - loss: 0.3048 - accuracy: 0.89 - ETA: 4:14 - loss: 0.3048 - accuracy: 0.90 - ETA: 4:11 - loss: 0.3046 - accuracy: 0.89 - ETA: 4:09 - loss: 0.3024 - accuracy: 0.90 - ETA: 4:06 - loss: 0.3024 - accuracy: 0.90 - ETA: 4:03 - loss: 0.3044 - accuracy: 0.90 - ETA: 4:01 - loss: 0.3066 - accuracy: 0.89 - ETA: 3:58 - loss: 0.3050 - accuracy: 0.89 - ETA: 3:56 - loss: 0.3044 - accuracy: 0.89 - ETA: 3:54 - loss: 0.3043 - accuracy: 0.89 - ETA: 3:51 - loss: 0.3038 - accuracy: 0.90 - ETA: 3:49 - loss: 0.3037 - accuracy: 0.90 - ETA: 3:46 - loss: 0.3041 - accuracy: 0.90 - ETA: 3:44 - loss: 0.3042 - accuracy: 0.90 - ETA: 3:42 - loss: 0.3052 - accuracy: 0.89 - ETA: 3:40 - loss: 0.3036 - accuracy: 0.90 - ETA: 3:37 - loss: 0.3034 - accuracy: 0.90 - ETA: 3:35 - loss: 0.3024 - accuracy: 0.90 - ETA: 3:33 - loss: 0.3025 - accuracy: 0.90 - ETA: 3:30 - loss: 0.3009 - accuracy: 0.90 - ETA: 3:28 - loss: 0.3016 - accuracy: 0.90 - ETA: 3:26 - loss: 0.3030 - accuracy: 0.89 - ETA: 3:23 - loss: 0.3038 - accuracy: 0.89 - ETA: 3:21 - loss: 0.3056 - accuracy: 0.89 - ETA: 3:18 - loss: 0.3055 - accuracy: 0.89 - ETA: 3:16 - loss: 0.3051 - accuracy: 0.90 - ETA: 3:13 - loss: 0.3040 - accuracy: 0.90 - ETA: 3:11 - loss: 0.3040 - accuracy: 0.90 - ETA: 3:09 - loss: 0.3043 - accuracy: 0.90 - ETA: 3:06 - loss: 0.3049 - accuracy: 0.90 - ETA: 3:04 - loss: 0.3066 - accuracy: 0.90 - ETA: 3:01 - loss: 0.3061 - accuracy: 0.90 - ETA: 2:59 - loss: 0.3071 - accuracy: 0.89 - ETA: 2:57 - loss: 0.3070 - accuracy: 0.89 - ETA: 2:54 - loss: 0.3081 - accuracy: 0.89 - ETA: 2:52 - loss: 0.3092 - accuracy: 0.89 - ETA: 2:50 - loss: 0.3084 - accuracy: 0.89 - ETA: 2:47 - loss: 0.3075 - accuracy: 0.89 - ETA: 2:45 - loss: 0.3070 - accuracy: 0.89 - ETA: 2:42 - loss: 0.3078 - accuracy: 0.89 - ETA: 2:40 - loss: 0.3077 - accuracy: 0.89 - ETA: 2:38 - loss: 0.3086 - accuracy: 0.89 - ETA: 2:35 - loss: 0.3091 - accuracy: 0.89 - ETA: 2:33 - loss: 0.3084 - accuracy: 0.89 - ETA: 2:30 - loss: 0.3078 - accuracy: 0.89 - ETA: 2:28 - loss: 0.3069 - accuracy: 0.89 - ETA: 2:25 - loss: 0.3060 - accuracy: 0.89 - ETA: 2:23 - loss: 0.3058 - accuracy: 0.90 - ETA: 2:21 - loss: 0.3058 - accuracy: 0.90 - ETA: 2:18 - loss: 0.3054 - accuracy: 0.90 - ETA: 2:16 - loss: 0.3058 - accuracy: 0.90 - ETA: 2:13 - loss: 0.3065 - accuracy: 0.90 - ETA: 2:11 - loss: 0.3070 - accuracy: 0.90 - ETA: 2:08 - loss: 0.3082 - accuracy: 0.90 - ETA: 2:06 - loss: 0.3079 - accuracy: 0.90 - ETA: 2:03 - loss: 0.3079 - accuracy: 0.89 - ETA: 2:01 - loss: 0.3072 - accuracy: 0.89 - ETA: 1:58 - loss: 0.3069 - accuracy: 0.89 - ETA: 1:56 - loss: 0.3070 - accuracy: 0.89 - ETA: 1:53 - loss: 0.3064 - accuracy: 0.89 - ETA: 1:51 - loss: 0.3059 - accuracy: 0.90 - ETA: 1:49 - loss: 0.3068 - accuracy: 0.90 - ETA: 1:46 - loss: 0.3075 - accuracy: 0.89 - ETA: 1:44 - loss: 0.3090 - accuracy: 0.89 - ETA: 1:41 - loss: 0.3096 - accuracy: 0.89 - ETA: 1:39 - loss: 0.3098 - accuracy: 0.89 - ETA: 1:36 - loss: 0.3100 - accuracy: 0.89 - ETA: 1:34 - loss: 0.3099 - accuracy: 0.89 - ETA: 1:31 - loss: 0.3109 - accuracy: 0.89 - ETA: 1:29 - loss: 0.3108 - accuracy: 0.89 - ETA: 1:27 - loss: 0.3117 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3115 - accuracy: 0.89 - ETA: 1:22 - loss: 0.3122 - accuracy: 0.89 - ETA: 1:19 - loss: 0.3119 - accuracy: 0.89 - ETA: 1:17 - loss: 0.3121 - accuracy: 0.89 - ETA: 1:14 - loss: 0.3117 - accuracy: 0.89 - ETA: 1:12 - loss: 0.3111 - accuracy: 0.89 - ETA: 1:09 - loss: 0.3100 - accuracy: 0.89 - ETA: 1:07 - loss: 0.3092 - accuracy: 0.89 - ETA: 1:05 - loss: 0.3096 - accuracy: 0.89 - ETA: 1:02 - loss: 0.3098 - accuracy: 0.89 - ETA: 1:00 - loss: 0.3100 - accuracy: 0.89 - ETA: 57s - loss: 0.3102 - accuracy: 0.8989 - ETA: 55s - loss: 0.3100 - accuracy: 0.898 - ETA: 53s - loss: 0.3106 - accuracy: 0.898 - ETA: 50s - loss: 0.3103 - accuracy: 0.898 - ETA: 48s - loss: 0.3108 - accuracy: 0.898 - ETA: 45s - loss: 0.3115 - accuracy: 0.898 - ETA: 43s - loss: 0.3112 - accuracy: 0.898 - ETA: 40s - loss: 0.3111 - accuracy: 0.898 - ETA: 38s - loss: 0.3112 - accuracy: 0.898 - ETA: 36s - loss: 0.3114 - accuracy: 0.898 - ETA: 33s - loss: 0.3114 - accuracy: 0.898 - ETA: 31s - loss: 0.3109 - accuracy: 0.898 - ETA: 28s - loss: 0.3106 - accuracy: 0.898 - ETA: 26s - loss: 0.3110 - accuracy: 0.898 - ETA: 23s - loss: 0.3110 - accuracy: 0.898 - ETA: 21s - loss: 0.3102 - accuracy: 0.898 - ETA: 19s - loss: 0.3105 - accuracy: 0.898 - ETA: 16s - loss: 0.3109 - accuracy: 0.898 - ETA: 14s - loss: 0.3108 - accuracy: 0.898 - ETA: 11s - loss: 0.3108 - accuracy: 0.898 - ETA: 9s - loss: 0.3118 - accuracy: 0.898 - ETA: 6s - loss: 0.3120 - accuracy: 0.89 - ETA: 4s - loss: 0.3116 - accuracy: 0.89 - ETA: 2s - loss: 0.3116 - accuracy: 0.89 - 408s 21ms/step - loss: 0.3111 - accuracy: 0.8985 - val_loss: 1.1349 - val_accuracy: 0.7768\n",
      "Epoch 14/100\n",
      "19312/19312 [==============================] - ETA: 6:22 - loss: 0.3050 - accuracy: 0.90 - ETA: 6:10 - loss: 0.2936 - accuracy: 0.89 - ETA: 6:09 - loss: 0.2937 - accuracy: 0.90 - ETA: 6:06 - loss: 0.2878 - accuracy: 0.90 - ETA: 6:00 - loss: 0.2980 - accuracy: 0.90 - ETA: 5:57 - loss: 0.3075 - accuracy: 0.90 - ETA: 5:51 - loss: 0.3072 - accuracy: 0.90 - ETA: 5:47 - loss: 0.2911 - accuracy: 0.90 - ETA: 5:45 - loss: 0.2916 - accuracy: 0.90 - ETA: 5:41 - loss: 0.2930 - accuracy: 0.90 - ETA: 5:37 - loss: 0.2894 - accuracy: 0.90 - ETA: 5:37 - loss: 0.2831 - accuracy: 0.90 - ETA: 5:34 - loss: 0.2830 - accuracy: 0.90 - ETA: 5:32 - loss: 0.2795 - accuracy: 0.91 - ETA: 5:32 - loss: 0.2824 - accuracy: 0.90 - ETA: 5:30 - loss: 0.2793 - accuracy: 0.91 - ETA: 5:28 - loss: 0.2806 - accuracy: 0.90 - ETA: 5:25 - loss: 0.2820 - accuracy: 0.90 - ETA: 5:24 - loss: 0.2828 - accuracy: 0.90 - ETA: 5:20 - loss: 0.2780 - accuracy: 0.90 - ETA: 5:18 - loss: 0.2850 - accuracy: 0.90 - ETA: 5:13 - loss: 0.2823 - accuracy: 0.90 - ETA: 5:12 - loss: 0.2790 - accuracy: 0.90 - ETA: 5:10 - loss: 0.2798 - accuracy: 0.90 - ETA: 5:07 - loss: 0.2787 - accuracy: 0.90 - ETA: 5:04 - loss: 0.2786 - accuracy: 0.90 - ETA: 5:01 - loss: 0.2745 - accuracy: 0.91 - ETA: 4:58 - loss: 0.2740 - accuracy: 0.91 - ETA: 4:56 - loss: 0.2710 - accuracy: 0.91 - ETA: 4:53 - loss: 0.2696 - accuracy: 0.91 - ETA: 4:50 - loss: 0.2680 - accuracy: 0.91 - ETA: 4:48 - loss: 0.2668 - accuracy: 0.91 - ETA: 4:45 - loss: 0.2657 - accuracy: 0.91 - ETA: 4:43 - loss: 0.2678 - accuracy: 0.91 - ETA: 4:40 - loss: 0.2706 - accuracy: 0.91 - ETA: 4:38 - loss: 0.2726 - accuracy: 0.90 - ETA: 4:36 - loss: 0.2733 - accuracy: 0.90 - ETA: 4:34 - loss: 0.2747 - accuracy: 0.90 - ETA: 4:32 - loss: 0.2773 - accuracy: 0.90 - ETA: 4:29 - loss: 0.2779 - accuracy: 0.90 - ETA: 4:26 - loss: 0.2777 - accuracy: 0.90 - ETA: 4:24 - loss: 0.2756 - accuracy: 0.90 - ETA: 4:22 - loss: 0.2819 - accuracy: 0.90 - ETA: 4:19 - loss: 0.2784 - accuracy: 0.90 - ETA: 4:17 - loss: 0.2798 - accuracy: 0.90 - ETA: 4:14 - loss: 0.2807 - accuracy: 0.90 - ETA: 4:12 - loss: 0.2813 - accuracy: 0.90 - ETA: 4:09 - loss: 0.2802 - accuracy: 0.90 - ETA: 4:07 - loss: 0.2800 - accuracy: 0.90 - ETA: 4:05 - loss: 0.2823 - accuracy: 0.90 - ETA: 4:02 - loss: 0.2824 - accuracy: 0.90 - ETA: 4:00 - loss: 0.2827 - accuracy: 0.90 - ETA: 3:57 - loss: 0.2809 - accuracy: 0.90 - ETA: 3:54 - loss: 0.2805 - accuracy: 0.90 - ETA: 3:52 - loss: 0.2805 - accuracy: 0.90 - ETA: 3:50 - loss: 0.2798 - accuracy: 0.90 - ETA: 3:48 - loss: 0.2798 - accuracy: 0.90 - ETA: 3:45 - loss: 0.2797 - accuracy: 0.90 - ETA: 3:43 - loss: 0.2805 - accuracy: 0.90 - ETA: 3:40 - loss: 0.2812 - accuracy: 0.90 - ETA: 3:38 - loss: 0.2804 - accuracy: 0.90 - ETA: 3:35 - loss: 0.2824 - accuracy: 0.90 - ETA: 3:33 - loss: 0.2802 - accuracy: 0.90 - ETA: 3:30 - loss: 0.2813 - accuracy: 0.90 - ETA: 3:28 - loss: 0.2822 - accuracy: 0.90 - ETA: 3:25 - loss: 0.2817 - accuracy: 0.90 - ETA: 3:23 - loss: 0.2819 - accuracy: 0.90 - ETA: 3:20 - loss: 0.2816 - accuracy: 0.90 - ETA: 3:18 - loss: 0.2800 - accuracy: 0.90 - ETA: 3:16 - loss: 0.2785 - accuracy: 0.90 - ETA: 3:13 - loss: 0.2815 - accuracy: 0.90 - ETA: 3:11 - loss: 0.2823 - accuracy: 0.90 - ETA: 3:08 - loss: 0.2835 - accuracy: 0.90 - ETA: 3:06 - loss: 0.2845 - accuracy: 0.90 - ETA: 3:03 - loss: 0.2838 - accuracy: 0.90 - ETA: 3:01 - loss: 0.2843 - accuracy: 0.90 - ETA: 2:58 - loss: 0.2858 - accuracy: 0.90 - ETA: 2:55 - loss: 0.2846 - accuracy: 0.90 - ETA: 2:53 - loss: 0.2841 - accuracy: 0.90 - ETA: 2:50 - loss: 0.2852 - accuracy: 0.90 - ETA: 2:47 - loss: 0.2858 - accuracy: 0.90 - ETA: 2:44 - loss: 0.2855 - accuracy: 0.90 - ETA: 2:41 - loss: 0.2841 - accuracy: 0.90 - ETA: 2:39 - loss: 0.2855 - accuracy: 0.90 - ETA: 2:36 - loss: 0.2843 - accuracy: 0.90 - ETA: 2:33 - loss: 0.2837 - accuracy: 0.90 - ETA: 2:30 - loss: 0.2832 - accuracy: 0.90 - ETA: 2:27 - loss: 0.2837 - accuracy: 0.90 - ETA: 2:25 - loss: 0.2846 - accuracy: 0.90 - ETA: 2:22 - loss: 0.2841 - accuracy: 0.90 - ETA: 2:19 - loss: 0.2858 - accuracy: 0.90 - ETA: 2:17 - loss: 0.2870 - accuracy: 0.90 - ETA: 2:14 - loss: 0.2856 - accuracy: 0.90 - ETA: 2:11 - loss: 0.2860 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2853 - accuracy: 0.90 - ETA: 2:06 - loss: 0.2849 - accuracy: 0.90 - ETA: 2:03 - loss: 0.2845 - accuracy: 0.90 - ETA: 2:01 - loss: 0.2841 - accuracy: 0.90 - ETA: 1:58 - loss: 0.2845 - accuracy: 0.90 - ETA: 1:56 - loss: 0.2839 - accuracy: 0.90 - ETA: 1:53 - loss: 0.2840 - accuracy: 0.90 - ETA: 1:50 - loss: 0.2831 - accuracy: 0.90 - ETA: 1:48 - loss: 0.2831 - accuracy: 0.90 - ETA: 1:45 - loss: 0.2832 - accuracy: 0.90 - ETA: 1:43 - loss: 0.2828 - accuracy: 0.90 - ETA: 1:40 - loss: 0.2834 - accuracy: 0.90 - ETA: 1:38 - loss: 0.2826 - accuracy: 0.90 - ETA: 1:36 - loss: 0.2815 - accuracy: 0.90 - ETA: 1:33 - loss: 0.2813 - accuracy: 0.90 - ETA: 1:31 - loss: 0.2828 - accuracy: 0.90 - ETA: 1:28 - loss: 0.2838 - accuracy: 0.90 - ETA: 1:26 - loss: 0.2839 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2835 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2836 - accuracy: 0.90 - ETA: 1:19 - loss: 0.2842 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2847 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2844 - accuracy: 0.90 - ETA: 1:12 - loss: 0.2844 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2849 - accuracy: 0.90 - ETA: 1:08 - loss: 0.2840 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2849 - accuracy: 0.90 - ETA: 1:03 - loss: 0.2852 - accuracy: 0.90 - ETA: 1:01 - loss: 0.2848 - accuracy: 0.90 - ETA: 58s - loss: 0.2848 - accuracy: 0.9071 - ETA: 56s - loss: 0.2858 - accuracy: 0.906 - ETA: 54s - loss: 0.2857 - accuracy: 0.906 - ETA: 52s - loss: 0.2869 - accuracy: 0.906 - ETA: 49s - loss: 0.2872 - accuracy: 0.906 - ETA: 47s - loss: 0.2871 - accuracy: 0.906 - ETA: 45s - loss: 0.2861 - accuracy: 0.906 - ETA: 43s - loss: 0.2853 - accuracy: 0.906 - ETA: 41s - loss: 0.2848 - accuracy: 0.907 - ETA: 38s - loss: 0.2861 - accuracy: 0.907 - ETA: 36s - loss: 0.2862 - accuracy: 0.907 - ETA: 34s - loss: 0.2858 - accuracy: 0.907 - ETA: 32s - loss: 0.2861 - accuracy: 0.907 - ETA: 30s - loss: 0.2864 - accuracy: 0.906 - ETA: 27s - loss: 0.2861 - accuracy: 0.906 - ETA: 25s - loss: 0.2860 - accuracy: 0.906 - ETA: 23s - loss: 0.2871 - accuracy: 0.906 - ETA: 21s - loss: 0.2884 - accuracy: 0.906 - ETA: 19s - loss: 0.2880 - accuracy: 0.906 - ETA: 16s - loss: 0.2875 - accuracy: 0.906 - ETA: 14s - loss: 0.2876 - accuracy: 0.906 - ETA: 12s - loss: 0.2870 - accuracy: 0.906 - ETA: 10s - loss: 0.2871 - accuracy: 0.906 - ETA: 8s - loss: 0.2871 - accuracy: 0.906 - ETA: 6s - loss: 0.2864 - accuracy: 0.90 - ETA: 4s - loss: 0.2865 - accuracy: 0.90 - ETA: 1s - loss: 0.2873 - accuracy: 0.90 - 361s 19ms/step - loss: 0.2866 - accuracy: 0.9071 - val_loss: 1.1794 - val_accuracy: 0.7799\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:12 - loss: 0.3706 - accuracy: 0.85 - ETA: 6:36 - loss: 0.3158 - accuracy: 0.89 - ETA: 5:53 - loss: 0.3160 - accuracy: 0.90 - ETA: 5:28 - loss: 0.3170 - accuracy: 0.91 - ETA: 5:11 - loss: 0.3083 - accuracy: 0.90 - ETA: 4:57 - loss: 0.3147 - accuracy: 0.90 - ETA: 4:47 - loss: 0.2938 - accuracy: 0.91 - ETA: 4:43 - loss: 0.2875 - accuracy: 0.91 - ETA: 4:36 - loss: 0.2921 - accuracy: 0.91 - ETA: 4:32 - loss: 0.2858 - accuracy: 0.91 - ETA: 4:27 - loss: 0.2846 - accuracy: 0.90 - ETA: 4:24 - loss: 0.2796 - accuracy: 0.91 - ETA: 4:21 - loss: 0.2914 - accuracy: 0.90 - ETA: 4:17 - loss: 0.2843 - accuracy: 0.91 - ETA: 4:14 - loss: 0.2801 - accuracy: 0.91 - ETA: 4:13 - loss: 0.2751 - accuracy: 0.91 - ETA: 4:10 - loss: 0.2715 - accuracy: 0.91 - ETA: 4:08 - loss: 0.2740 - accuracy: 0.91 - ETA: 4:06 - loss: 0.2778 - accuracy: 0.90 - ETA: 4:03 - loss: 0.2745 - accuracy: 0.91 - ETA: 4:01 - loss: 0.2703 - accuracy: 0.91 - ETA: 3:59 - loss: 0.2766 - accuracy: 0.91 - ETA: 3:57 - loss: 0.2749 - accuracy: 0.91 - ETA: 3:54 - loss: 0.2762 - accuracy: 0.90 - ETA: 3:51 - loss: 0.2758 - accuracy: 0.90 - ETA: 3:50 - loss: 0.2702 - accuracy: 0.91 - ETA: 3:48 - loss: 0.2708 - accuracy: 0.91 - ETA: 3:45 - loss: 0.2700 - accuracy: 0.91 - ETA: 3:43 - loss: 0.2700 - accuracy: 0.91 - ETA: 3:42 - loss: 0.2707 - accuracy: 0.90 - ETA: 3:39 - loss: 0.2733 - accuracy: 0.90 - ETA: 3:37 - loss: 0.2708 - accuracy: 0.90 - ETA: 3:35 - loss: 0.2681 - accuracy: 0.90 - ETA: 3:33 - loss: 0.2699 - accuracy: 0.90 - ETA: 3:31 - loss: 0.2692 - accuracy: 0.90 - ETA: 3:30 - loss: 0.2703 - accuracy: 0.90 - ETA: 3:28 - loss: 0.2702 - accuracy: 0.90 - ETA: 3:25 - loss: 0.2696 - accuracy: 0.90 - ETA: 3:24 - loss: 0.2716 - accuracy: 0.90 - ETA: 3:22 - loss: 0.2724 - accuracy: 0.90 - ETA: 3:20 - loss: 0.2717 - accuracy: 0.90 - ETA: 3:18 - loss: 0.2716 - accuracy: 0.90 - ETA: 3:18 - loss: 0.2696 - accuracy: 0.90 - ETA: 3:16 - loss: 0.2669 - accuracy: 0.90 - ETA: 3:14 - loss: 0.2658 - accuracy: 0.91 - ETA: 3:12 - loss: 0.2630 - accuracy: 0.91 - ETA: 3:10 - loss: 0.2644 - accuracy: 0.91 - ETA: 3:08 - loss: 0.2656 - accuracy: 0.91 - ETA: 3:07 - loss: 0.2633 - accuracy: 0.91 - ETA: 3:05 - loss: 0.2625 - accuracy: 0.91 - ETA: 3:03 - loss: 0.2623 - accuracy: 0.91 - ETA: 3:01 - loss: 0.2620 - accuracy: 0.91 - ETA: 2:59 - loss: 0.2611 - accuracy: 0.91 - ETA: 2:57 - loss: 0.2626 - accuracy: 0.91 - ETA: 2:56 - loss: 0.2637 - accuracy: 0.91 - ETA: 2:54 - loss: 0.2656 - accuracy: 0.91 - ETA: 2:52 - loss: 0.2674 - accuracy: 0.91 - ETA: 2:50 - loss: 0.2674 - accuracy: 0.91 - ETA: 2:48 - loss: 0.2665 - accuracy: 0.91 - ETA: 2:46 - loss: 0.2664 - accuracy: 0.91 - ETA: 2:44 - loss: 0.2657 - accuracy: 0.91 - ETA: 2:42 - loss: 0.2648 - accuracy: 0.91 - ETA: 2:40 - loss: 0.2632 - accuracy: 0.91 - ETA: 2:38 - loss: 0.2615 - accuracy: 0.91 - ETA: 2:36 - loss: 0.2625 - accuracy: 0.91 - ETA: 2:35 - loss: 0.2610 - accuracy: 0.91 - ETA: 2:33 - loss: 0.2623 - accuracy: 0.91 - ETA: 2:31 - loss: 0.2620 - accuracy: 0.91 - ETA: 2:29 - loss: 0.2614 - accuracy: 0.91 - ETA: 2:27 - loss: 0.2625 - accuracy: 0.91 - ETA: 2:25 - loss: 0.2619 - accuracy: 0.91 - ETA: 2:23 - loss: 0.2623 - accuracy: 0.91 - ETA: 2:21 - loss: 0.2636 - accuracy: 0.91 - ETA: 2:19 - loss: 0.2635 - accuracy: 0.91 - ETA: 2:17 - loss: 0.2640 - accuracy: 0.91 - ETA: 2:16 - loss: 0.2647 - accuracy: 0.91 - ETA: 2:14 - loss: 0.2648 - accuracy: 0.91 - ETA: 2:12 - loss: 0.2647 - accuracy: 0.91 - ETA: 2:10 - loss: 0.2653 - accuracy: 0.91 - ETA: 2:09 - loss: 0.2657 - accuracy: 0.91 - ETA: 2:07 - loss: 0.2692 - accuracy: 0.91 - ETA: 2:05 - loss: 0.2684 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2677 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2677 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2666 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2682 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2674 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2672 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2665 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2694 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2680 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2686 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2686 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2693 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2690 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2693 - accuracy: 0.91 - ETA: 1:37 - loss: 0.2685 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2676 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2683 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2676 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2678 - accuracy: 0.91 - ETA: 1:28 - loss: 0.2677 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2665 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2677 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2671 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2672 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2665 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2668 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2669 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2671 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2669 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2662 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2660 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2661 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2656 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2654 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2650 - accuracy: 0.91 - ETA: 59s - loss: 0.2660 - accuracy: 0.9119 - ETA: 57s - loss: 0.2666 - accuracy: 0.911 - ETA: 55s - loss: 0.2668 - accuracy: 0.911 - ETA: 53s - loss: 0.2664 - accuracy: 0.911 - ETA: 51s - loss: 0.2658 - accuracy: 0.912 - ETA: 50s - loss: 0.2671 - accuracy: 0.912 - ETA: 48s - loss: 0.2667 - accuracy: 0.912 - ETA: 46s - loss: 0.2661 - accuracy: 0.912 - ETA: 44s - loss: 0.2669 - accuracy: 0.912 - ETA: 42s - loss: 0.2675 - accuracy: 0.911 - ETA: 41s - loss: 0.2677 - accuracy: 0.912 - ETA: 39s - loss: 0.2668 - accuracy: 0.912 - ETA: 37s - loss: 0.2676 - accuracy: 0.912 - ETA: 35s - loss: 0.2671 - accuracy: 0.911 - ETA: 33s - loss: 0.2667 - accuracy: 0.912 - ETA: 32s - loss: 0.2680 - accuracy: 0.911 - ETA: 30s - loss: 0.2681 - accuracy: 0.911 - ETA: 28s - loss: 0.2685 - accuracy: 0.911 - ETA: 26s - loss: 0.2682 - accuracy: 0.911 - ETA: 25s - loss: 0.2686 - accuracy: 0.911 - ETA: 23s - loss: 0.2681 - accuracy: 0.911 - ETA: 21s - loss: 0.2688 - accuracy: 0.911 - ETA: 19s - loss: 0.2688 - accuracy: 0.911 - ETA: 17s - loss: 0.2690 - accuracy: 0.911 - ETA: 16s - loss: 0.2688 - accuracy: 0.911 - ETA: 14s - loss: 0.2693 - accuracy: 0.911 - ETA: 12s - loss: 0.2689 - accuracy: 0.911 - ETA: 10s - loss: 0.2689 - accuracy: 0.911 - ETA: 8s - loss: 0.2694 - accuracy: 0.911 - ETA: 6s - loss: 0.2696 - accuracy: 0.91 - ETA: 5s - loss: 0.2698 - accuracy: 0.91 - ETA: 3s - loss: 0.2699 - accuracy: 0.91 - ETA: 1s - loss: 0.2705 - accuracy: 0.91 - 313s 16ms/step - loss: 0.2703 - accuracy: 0.9108 - val_loss: 1.2162 - val_accuracy: 0.7782\n",
      "Epoch 16/100\n",
      "19312/19312 [==============================] - ETA: 4:28 - loss: 0.3346 - accuracy: 0.87 - ETA: 4:26 - loss: 0.3058 - accuracy: 0.89 - ETA: 4:52 - loss: 0.2536 - accuracy: 0.90 - ETA: 4:47 - loss: 0.2577 - accuracy: 0.90 - ETA: 4:40 - loss: 0.2481 - accuracy: 0.91 - ETA: 4:37 - loss: 0.2327 - accuracy: 0.91 - ETA: 4:30 - loss: 0.2489 - accuracy: 0.91 - ETA: 4:26 - loss: 0.2465 - accuracy: 0.91 - ETA: 4:24 - loss: 0.2435 - accuracy: 0.91 - ETA: 4:21 - loss: 0.2399 - accuracy: 0.91 - ETA: 4:17 - loss: 0.2475 - accuracy: 0.91 - ETA: 4:12 - loss: 0.2540 - accuracy: 0.90 - ETA: 4:09 - loss: 0.2575 - accuracy: 0.90 - ETA: 4:06 - loss: 0.2530 - accuracy: 0.90 - ETA: 4:04 - loss: 0.2477 - accuracy: 0.91 - ETA: 4:02 - loss: 0.2391 - accuracy: 0.91 - ETA: 3:59 - loss: 0.2393 - accuracy: 0.91 - ETA: 3:58 - loss: 0.2437 - accuracy: 0.91 - ETA: 3:58 - loss: 0.2471 - accuracy: 0.91 - ETA: 3:56 - loss: 0.2446 - accuracy: 0.91 - ETA: 3:53 - loss: 0.2460 - accuracy: 0.91 - ETA: 3:52 - loss: 0.2420 - accuracy: 0.91 - ETA: 3:50 - loss: 0.2516 - accuracy: 0.91 - ETA: 3:48 - loss: 0.2542 - accuracy: 0.91 - ETA: 3:46 - loss: 0.2627 - accuracy: 0.91 - ETA: 3:44 - loss: 0.2563 - accuracy: 0.91 - ETA: 3:42 - loss: 0.2536 - accuracy: 0.91 - ETA: 3:40 - loss: 0.2536 - accuracy: 0.91 - ETA: 3:38 - loss: 0.2550 - accuracy: 0.91 - ETA: 3:37 - loss: 0.2561 - accuracy: 0.91 - ETA: 3:35 - loss: 0.2584 - accuracy: 0.91 - ETA: 3:33 - loss: 0.2566 - accuracy: 0.91 - ETA: 3:31 - loss: 0.2555 - accuracy: 0.91 - ETA: 3:29 - loss: 0.2562 - accuracy: 0.91 - ETA: 3:27 - loss: 0.2595 - accuracy: 0.91 - ETA: 3:25 - loss: 0.2597 - accuracy: 0.91 - ETA: 3:23 - loss: 0.2612 - accuracy: 0.91 - ETA: 3:21 - loss: 0.2620 - accuracy: 0.91 - ETA: 3:19 - loss: 0.2631 - accuracy: 0.91 - ETA: 3:17 - loss: 0.2626 - accuracy: 0.91 - ETA: 3:15 - loss: 0.2641 - accuracy: 0.91 - ETA: 3:13 - loss: 0.2644 - accuracy: 0.91 - ETA: 3:11 - loss: 0.2614 - accuracy: 0.91 - ETA: 3:10 - loss: 0.2599 - accuracy: 0.91 - ETA: 3:08 - loss: 0.2601 - accuracy: 0.91 - ETA: 3:06 - loss: 0.2608 - accuracy: 0.91 - ETA: 3:05 - loss: 0.2608 - accuracy: 0.91 - ETA: 3:02 - loss: 0.2588 - accuracy: 0.91 - ETA: 3:00 - loss: 0.2566 - accuracy: 0.91 - ETA: 2:59 - loss: 0.2557 - accuracy: 0.91 - ETA: 2:57 - loss: 0.2578 - accuracy: 0.91 - ETA: 2:55 - loss: 0.2565 - accuracy: 0.91 - ETA: 2:53 - loss: 0.2561 - accuracy: 0.91 - ETA: 2:52 - loss: 0.2543 - accuracy: 0.91 - ETA: 2:50 - loss: 0.2549 - accuracy: 0.91 - ETA: 2:48 - loss: 0.2532 - accuracy: 0.91 - ETA: 2:46 - loss: 0.2558 - accuracy: 0.91 - ETA: 2:45 - loss: 0.2559 - accuracy: 0.91 - ETA: 2:43 - loss: 0.2572 - accuracy: 0.91 - ETA: 2:41 - loss: 0.2565 - accuracy: 0.91 - ETA: 2:39 - loss: 0.2561 - accuracy: 0.91 - ETA: 2:37 - loss: 0.2548 - accuracy: 0.91 - ETA: 2:36 - loss: 0.2538 - accuracy: 0.91 - ETA: 2:34 - loss: 0.2543 - accuracy: 0.91 - ETA: 2:32 - loss: 0.2530 - accuracy: 0.91 - ETA: 2:30 - loss: 0.2542 - accuracy: 0.91 - ETA: 2:28 - loss: 0.2545 - accuracy: 0.91 - ETA: 2:26 - loss: 0.2539 - accuracy: 0.91 - ETA: 2:25 - loss: 0.2541 - accuracy: 0.91 - ETA: 2:23 - loss: 0.2527 - accuracy: 0.91 - ETA: 2:21 - loss: 0.2529 - accuracy: 0.91 - ETA: 2:19 - loss: 0.2519 - accuracy: 0.91 - ETA: 2:17 - loss: 0.2525 - accuracy: 0.91 - ETA: 2:15 - loss: 0.2525 - accuracy: 0.91 - ETA: 2:14 - loss: 0.2528 - accuracy: 0.91 - ETA: 2:12 - loss: 0.2531 - accuracy: 0.91 - ETA: 2:10 - loss: 0.2534 - accuracy: 0.91 - ETA: 2:08 - loss: 0.2536 - accuracy: 0.91 - ETA: 2:07 - loss: 0.2519 - accuracy: 0.91 - ETA: 2:05 - loss: 0.2504 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2515 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2503 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2500 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2492 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2496 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2487 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2484 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2483 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2479 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2481 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2484 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2482 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2493 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2497 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2502 - accuracy: 0.91 - ETA: 1:36 - loss: 0.2502 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2509 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2507 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2509 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2507 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2510 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2526 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2522 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2526 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2526 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2523 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2520 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2524 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2522 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2528 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2528 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2521 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2521 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2526 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2518 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2508 - accuracy: 0.91 - ETA: 59s - loss: 0.2497 - accuracy: 0.9179 - ETA: 58s - loss: 0.2492 - accuracy: 0.918 - ETA: 56s - loss: 0.2498 - accuracy: 0.918 - ETA: 54s - loss: 0.2495 - accuracy: 0.918 - ETA: 52s - loss: 0.2490 - accuracy: 0.918 - ETA: 50s - loss: 0.2493 - accuracy: 0.918 - ETA: 49s - loss: 0.2492 - accuracy: 0.918 - ETA: 47s - loss: 0.2486 - accuracy: 0.918 - ETA: 45s - loss: 0.2477 - accuracy: 0.918 - ETA: 43s - loss: 0.2478 - accuracy: 0.918 - ETA: 42s - loss: 0.2482 - accuracy: 0.918 - ETA: 40s - loss: 0.2476 - accuracy: 0.918 - ETA: 38s - loss: 0.2474 - accuracy: 0.918 - ETA: 36s - loss: 0.2478 - accuracy: 0.918 - ETA: 35s - loss: 0.2482 - accuracy: 0.918 - ETA: 33s - loss: 0.2474 - accuracy: 0.918 - ETA: 31s - loss: 0.2477 - accuracy: 0.918 - ETA: 29s - loss: 0.2483 - accuracy: 0.918 - ETA: 28s - loss: 0.2487 - accuracy: 0.917 - ETA: 26s - loss: 0.2486 - accuracy: 0.917 - ETA: 24s - loss: 0.2485 - accuracy: 0.917 - ETA: 22s - loss: 0.2485 - accuracy: 0.917 - ETA: 20s - loss: 0.2494 - accuracy: 0.917 - ETA: 19s - loss: 0.2491 - accuracy: 0.917 - ETA: 17s - loss: 0.2485 - accuracy: 0.917 - ETA: 15s - loss: 0.2483 - accuracy: 0.918 - ETA: 13s - loss: 0.2486 - accuracy: 0.917 - ETA: 12s - loss: 0.2486 - accuracy: 0.917 - ETA: 10s - loss: 0.2487 - accuracy: 0.917 - ETA: 8s - loss: 0.2489 - accuracy: 0.918 - ETA: 6s - loss: 0.2486 - accuracy: 0.91 - ETA: 5s - loss: 0.2480 - accuracy: 0.91 - ETA: 3s - loss: 0.2479 - accuracy: 0.91 - ETA: 1s - loss: 0.2476 - accuracy: 0.91 - 311s 16ms/step - loss: 0.2478 - accuracy: 0.9184 - val_loss: 1.1674 - val_accuracy: 0.7848\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:56 - loss: 0.1505 - accuracy: 0.95 - ETA: 4:47 - loss: 0.1635 - accuracy: 0.94 - ETA: 4:39 - loss: 0.1552 - accuracy: 0.95 - ETA: 4:36 - loss: 0.1583 - accuracy: 0.94 - ETA: 4:31 - loss: 0.1688 - accuracy: 0.94 - ETA: 4:30 - loss: 0.1683 - accuracy: 0.94 - ETA: 4:24 - loss: 0.1724 - accuracy: 0.94 - ETA: 4:18 - loss: 0.1778 - accuracy: 0.94 - ETA: 4:17 - loss: 0.1774 - accuracy: 0.94 - ETA: 4:14 - loss: 0.1822 - accuracy: 0.94 - ETA: 4:11 - loss: 0.1820 - accuracy: 0.94 - ETA: 4:11 - loss: 0.1955 - accuracy: 0.93 - ETA: 4:08 - loss: 0.2015 - accuracy: 0.93 - ETA: 4:07 - loss: 0.2019 - accuracy: 0.93 - ETA: 4:04 - loss: 0.2020 - accuracy: 0.93 - ETA: 4:02 - loss: 0.1989 - accuracy: 0.93 - ETA: 3:58 - loss: 0.1991 - accuracy: 0.93 - ETA: 3:59 - loss: 0.2043 - accuracy: 0.93 - ETA: 3:57 - loss: 0.2105 - accuracy: 0.93 - ETA: 3:55 - loss: 0.2121 - accuracy: 0.92 - ETA: 3:53 - loss: 0.2090 - accuracy: 0.92 - ETA: 3:51 - loss: 0.2096 - accuracy: 0.93 - ETA: 3:50 - loss: 0.2113 - accuracy: 0.92 - ETA: 3:47 - loss: 0.2115 - accuracy: 0.92 - ETA: 3:44 - loss: 0.2132 - accuracy: 0.92 - ETA: 3:42 - loss: 0.2190 - accuracy: 0.92 - ETA: 3:39 - loss: 0.2216 - accuracy: 0.92 - ETA: 3:37 - loss: 0.2234 - accuracy: 0.92 - ETA: 3:35 - loss: 0.2223 - accuracy: 0.92 - ETA: 3:33 - loss: 0.2250 - accuracy: 0.92 - ETA: 3:31 - loss: 0.2238 - accuracy: 0.92 - ETA: 3:30 - loss: 0.2245 - accuracy: 0.92 - ETA: 3:28 - loss: 0.2273 - accuracy: 0.92 - ETA: 3:27 - loss: 0.2309 - accuracy: 0.92 - ETA: 3:24 - loss: 0.2321 - accuracy: 0.92 - ETA: 3:23 - loss: 0.2327 - accuracy: 0.92 - ETA: 3:21 - loss: 0.2293 - accuracy: 0.92 - ETA: 3:20 - loss: 0.2267 - accuracy: 0.92 - ETA: 3:18 - loss: 0.2274 - accuracy: 0.92 - ETA: 3:17 - loss: 0.2278 - accuracy: 0.92 - ETA: 3:15 - loss: 0.2258 - accuracy: 0.92 - ETA: 3:13 - loss: 0.2257 - accuracy: 0.92 - ETA: 3:11 - loss: 0.2248 - accuracy: 0.92 - ETA: 3:09 - loss: 0.2253 - accuracy: 0.92 - ETA: 3:07 - loss: 0.2255 - accuracy: 0.92 - ETA: 3:05 - loss: 0.2264 - accuracy: 0.92 - ETA: 3:04 - loss: 0.2294 - accuracy: 0.92 - ETA: 3:02 - loss: 0.2290 - accuracy: 0.92 - ETA: 3:00 - loss: 0.2310 - accuracy: 0.92 - ETA: 2:58 - loss: 0.2310 - accuracy: 0.92 - ETA: 2:56 - loss: 0.2335 - accuracy: 0.92 - ETA: 2:55 - loss: 0.2325 - accuracy: 0.92 - ETA: 2:53 - loss: 0.2322 - accuracy: 0.92 - ETA: 2:51 - loss: 0.2347 - accuracy: 0.92 - ETA: 2:49 - loss: 0.2341 - accuracy: 0.92 - ETA: 2:48 - loss: 0.2337 - accuracy: 0.92 - ETA: 2:46 - loss: 0.2347 - accuracy: 0.92 - ETA: 2:44 - loss: 0.2347 - accuracy: 0.92 - ETA: 2:43 - loss: 0.2339 - accuracy: 0.92 - ETA: 2:41 - loss: 0.2334 - accuracy: 0.92 - ETA: 2:39 - loss: 0.2318 - accuracy: 0.92 - ETA: 2:37 - loss: 0.2317 - accuracy: 0.92 - ETA: 2:36 - loss: 0.2314 - accuracy: 0.92 - ETA: 2:34 - loss: 0.2307 - accuracy: 0.92 - ETA: 2:32 - loss: 0.2295 - accuracy: 0.92 - ETA: 2:30 - loss: 0.2318 - accuracy: 0.92 - ETA: 2:29 - loss: 0.2338 - accuracy: 0.92 - ETA: 2:27 - loss: 0.2358 - accuracy: 0.92 - ETA: 2:25 - loss: 0.2365 - accuracy: 0.92 - ETA: 2:23 - loss: 0.2368 - accuracy: 0.92 - ETA: 2:21 - loss: 0.2367 - accuracy: 0.92 - ETA: 2:20 - loss: 0.2362 - accuracy: 0.92 - ETA: 2:18 - loss: 0.2357 - accuracy: 0.92 - ETA: 2:16 - loss: 0.2351 - accuracy: 0.92 - ETA: 2:14 - loss: 0.2328 - accuracy: 0.92 - ETA: 2:13 - loss: 0.2335 - accuracy: 0.92 - ETA: 2:11 - loss: 0.2331 - accuracy: 0.92 - ETA: 2:09 - loss: 0.2342 - accuracy: 0.92 - ETA: 2:07 - loss: 0.2344 - accuracy: 0.92 - ETA: 2:05 - loss: 0.2354 - accuracy: 0.92 - ETA: 2:04 - loss: 0.2365 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2371 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2373 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2374 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2382 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2380 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2388 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2386 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2404 - accuracy: 0.92 - ETA: 1:47 - loss: 0.2398 - accuracy: 0.92 - ETA: 1:46 - loss: 0.2391 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2399 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2396 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2389 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2386 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2385 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2389 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2384 - accuracy: 0.92 - ETA: 1:32 - loss: 0.2386 - accuracy: 0.92 - ETA: 1:30 - loss: 0.2388 - accuracy: 0.92 - ETA: 1:28 - loss: 0.2391 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2382 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2377 - accuracy: 0.92 - ETA: 1:23 - loss: 0.2376 - accuracy: 0.92 - ETA: 1:21 - loss: 0.2372 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2364 - accuracy: 0.92 - ETA: 1:17 - loss: 0.2369 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2369 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2359 - accuracy: 0.92 - ETA: 1:12 - loss: 0.2352 - accuracy: 0.92 - ETA: 1:10 - loss: 0.2351 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2354 - accuracy: 0.92 - ETA: 1:07 - loss: 0.2351 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2351 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2358 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2353 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2350 - accuracy: 0.92 - ETA: 58s - loss: 0.2347 - accuracy: 0.9235 - ETA: 56s - loss: 0.2355 - accuracy: 0.923 - ETA: 54s - loss: 0.2355 - accuracy: 0.923 - ETA: 52s - loss: 0.2349 - accuracy: 0.923 - ETA: 51s - loss: 0.2346 - accuracy: 0.923 - ETA: 49s - loss: 0.2344 - accuracy: 0.923 - ETA: 47s - loss: 0.2341 - accuracy: 0.923 - ETA: 45s - loss: 0.2347 - accuracy: 0.923 - ETA: 44s - loss: 0.2339 - accuracy: 0.923 - ETA: 42s - loss: 0.2334 - accuracy: 0.923 - ETA: 40s - loss: 0.2331 - accuracy: 0.923 - ETA: 38s - loss: 0.2331 - accuracy: 0.923 - ETA: 37s - loss: 0.2331 - accuracy: 0.923 - ETA: 35s - loss: 0.2330 - accuracy: 0.923 - ETA: 33s - loss: 0.2335 - accuracy: 0.923 - ETA: 31s - loss: 0.2334 - accuracy: 0.923 - ETA: 29s - loss: 0.2348 - accuracy: 0.923 - ETA: 28s - loss: 0.2346 - accuracy: 0.923 - ETA: 26s - loss: 0.2350 - accuracy: 0.923 - ETA: 24s - loss: 0.2343 - accuracy: 0.923 - ETA: 22s - loss: 0.2339 - accuracy: 0.923 - ETA: 21s - loss: 0.2335 - accuracy: 0.923 - ETA: 19s - loss: 0.2327 - accuracy: 0.923 - ETA: 17s - loss: 0.2329 - accuracy: 0.923 - ETA: 15s - loss: 0.2327 - accuracy: 0.923 - ETA: 13s - loss: 0.2326 - accuracy: 0.923 - ETA: 12s - loss: 0.2336 - accuracy: 0.923 - ETA: 10s - loss: 0.2343 - accuracy: 0.923 - ETA: 8s - loss: 0.2342 - accuracy: 0.923 - ETA: 6s - loss: 0.2339 - accuracy: 0.92 - ETA: 5s - loss: 0.2343 - accuracy: 0.92 - ETA: 3s - loss: 0.2353 - accuracy: 0.92 - ETA: 1s - loss: 0.2356 - accuracy: 0.92 - 296s 15ms/step - loss: 0.2355 - accuracy: 0.9229 - val_loss: 1.2094 - val_accuracy: 0.7846\n",
      "Epoch 18/100\n",
      "19312/19312 [==============================] - ETA: 4:38 - loss: 0.1700 - accuracy: 0.94 - ETA: 4:35 - loss: 0.1699 - accuracy: 0.94 - ETA: 4:20 - loss: 0.1937 - accuracy: 0.93 - ETA: 4:13 - loss: 0.1925 - accuracy: 0.93 - ETA: 4:13 - loss: 0.1951 - accuracy: 0.93 - ETA: 3:57 - loss: 0.2013 - accuracy: 0.93 - ETA: 3:58 - loss: 0.2033 - accuracy: 0.93 - ETA: 4:00 - loss: 0.2054 - accuracy: 0.93 - ETA: 4:00 - loss: 0.2027 - accuracy: 0.93 - ETA: 3:59 - loss: 0.2103 - accuracy: 0.93 - ETA: 4:00 - loss: 0.2107 - accuracy: 0.93 - ETA: 3:58 - loss: 0.2134 - accuracy: 0.92 - ETA: 3:56 - loss: 0.2116 - accuracy: 0.93 - ETA: 3:55 - loss: 0.2062 - accuracy: 0.93 - ETA: 3:54 - loss: 0.2046 - accuracy: 0.93 - ETA: 3:51 - loss: 0.2127 - accuracy: 0.92 - ETA: 3:51 - loss: 0.2142 - accuracy: 0.92 - ETA: 3:49 - loss: 0.2125 - accuracy: 0.92 - ETA: 3:47 - loss: 0.2220 - accuracy: 0.92 - ETA: 3:46 - loss: 0.2266 - accuracy: 0.92 - ETA: 3:45 - loss: 0.2252 - accuracy: 0.92 - ETA: 3:42 - loss: 0.2241 - accuracy: 0.92 - ETA: 3:41 - loss: 0.2213 - accuracy: 0.92 - ETA: 3:39 - loss: 0.2244 - accuracy: 0.92 - ETA: 3:38 - loss: 0.2222 - accuracy: 0.92 - ETA: 3:36 - loss: 0.2291 - accuracy: 0.92 - ETA: 3:34 - loss: 0.2266 - accuracy: 0.92 - ETA: 3:32 - loss: 0.2254 - accuracy: 0.92 - ETA: 3:31 - loss: 0.2254 - accuracy: 0.92 - ETA: 3:29 - loss: 0.2297 - accuracy: 0.92 - ETA: 3:27 - loss: 0.2291 - accuracy: 0.92 - ETA: 3:25 - loss: 0.2258 - accuracy: 0.92 - ETA: 3:23 - loss: 0.2276 - accuracy: 0.92 - ETA: 3:22 - loss: 0.2257 - accuracy: 0.92 - ETA: 3:20 - loss: 0.2241 - accuracy: 0.92 - ETA: 3:19 - loss: 0.2238 - accuracy: 0.92 - ETA: 3:17 - loss: 0.2238 - accuracy: 0.92 - ETA: 3:15 - loss: 0.2235 - accuracy: 0.92 - ETA: 3:14 - loss: 0.2237 - accuracy: 0.92 - ETA: 3:12 - loss: 0.2223 - accuracy: 0.92 - ETA: 3:10 - loss: 0.2207 - accuracy: 0.92 - ETA: 3:08 - loss: 0.2190 - accuracy: 0.92 - ETA: 3:07 - loss: 0.2182 - accuracy: 0.92 - ETA: 3:05 - loss: 0.2166 - accuracy: 0.92 - ETA: 3:03 - loss: 0.2170 - accuracy: 0.92 - ETA: 3:02 - loss: 0.2179 - accuracy: 0.92 - ETA: 3:00 - loss: 0.2168 - accuracy: 0.92 - ETA: 2:58 - loss: 0.2189 - accuracy: 0.92 - ETA: 2:56 - loss: 0.2193 - accuracy: 0.92 - ETA: 2:54 - loss: 0.2180 - accuracy: 0.92 - ETA: 2:52 - loss: 0.2211 - accuracy: 0.92 - ETA: 2:51 - loss: 0.2240 - accuracy: 0.92 - ETA: 2:49 - loss: 0.2221 - accuracy: 0.92 - ETA: 2:47 - loss: 0.2244 - accuracy: 0.92 - ETA: 2:46 - loss: 0.2261 - accuracy: 0.92 - ETA: 2:44 - loss: 0.2256 - accuracy: 0.92 - ETA: 2:43 - loss: 0.2241 - accuracy: 0.92 - ETA: 2:41 - loss: 0.2243 - accuracy: 0.92 - ETA: 2:39 - loss: 0.2238 - accuracy: 0.92 - ETA: 2:38 - loss: 0.2246 - accuracy: 0.92 - ETA: 2:36 - loss: 0.2239 - accuracy: 0.92 - ETA: 2:34 - loss: 0.2227 - accuracy: 0.92 - ETA: 2:32 - loss: 0.2215 - accuracy: 0.92 - ETA: 2:31 - loss: 0.2202 - accuracy: 0.92 - ETA: 2:29 - loss: 0.2198 - accuracy: 0.92 - ETA: 2:27 - loss: 0.2189 - accuracy: 0.92 - ETA: 2:25 - loss: 0.2202 - accuracy: 0.92 - ETA: 2:24 - loss: 0.2194 - accuracy: 0.92 - ETA: 2:22 - loss: 0.2184 - accuracy: 0.92 - ETA: 2:20 - loss: 0.2180 - accuracy: 0.92 - ETA: 2:19 - loss: 0.2181 - accuracy: 0.92 - ETA: 2:17 - loss: 0.2185 - accuracy: 0.92 - ETA: 2:15 - loss: 0.2180 - accuracy: 0.92 - ETA: 2:13 - loss: 0.2171 - accuracy: 0.92 - ETA: 2:12 - loss: 0.2159 - accuracy: 0.92 - ETA: 2:10 - loss: 0.2162 - accuracy: 0.92 - ETA: 2:08 - loss: 0.2148 - accuracy: 0.92 - ETA: 2:07 - loss: 0.2163 - accuracy: 0.92 - ETA: 2:05 - loss: 0.2158 - accuracy: 0.92 - ETA: 2:03 - loss: 0.2156 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2151 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2142 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2134 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2142 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2162 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2154 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2153 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2148 - accuracy: 0.92 - ETA: 1:48 - loss: 0.2137 - accuracy: 0.92 - ETA: 1:46 - loss: 0.2134 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2124 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2126 - accuracy: 0.92 - ETA: 1:41 - loss: 0.2126 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2144 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2152 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2154 - accuracy: 0.92 - ETA: 1:34 - loss: 0.2175 - accuracy: 0.92 - ETA: 1:32 - loss: 0.2177 - accuracy: 0.92 - ETA: 1:30 - loss: 0.2192 - accuracy: 0.92 - ETA: 1:28 - loss: 0.2192 - accuracy: 0.92 - ETA: 1:27 - loss: 0.2178 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2170 - accuracy: 0.92 - ETA: 1:23 - loss: 0.2170 - accuracy: 0.92 - ETA: 1:21 - loss: 0.2169 - accuracy: 0.92 - ETA: 1:20 - loss: 0.2172 - accuracy: 0.92 - ETA: 1:18 - loss: 0.2163 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2162 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2163 - accuracy: 0.92 - ETA: 1:13 - loss: 0.2158 - accuracy: 0.92 - ETA: 1:11 - loss: 0.2149 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2158 - accuracy: 0.92 - ETA: 1:07 - loss: 0.2168 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2163 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2167 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2168 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2178 - accuracy: 0.92 - ETA: 59s - loss: 0.2169 - accuracy: 0.9278 - ETA: 57s - loss: 0.2167 - accuracy: 0.927 - ETA: 55s - loss: 0.2163 - accuracy: 0.927 - ETA: 53s - loss: 0.2170 - accuracy: 0.927 - ETA: 52s - loss: 0.2177 - accuracy: 0.927 - ETA: 50s - loss: 0.2179 - accuracy: 0.927 - ETA: 48s - loss: 0.2183 - accuracy: 0.927 - ETA: 46s - loss: 0.2175 - accuracy: 0.927 - ETA: 45s - loss: 0.2192 - accuracy: 0.926 - ETA: 43s - loss: 0.2190 - accuracy: 0.927 - ETA: 41s - loss: 0.2198 - accuracy: 0.926 - ETA: 39s - loss: 0.2204 - accuracy: 0.926 - ETA: 38s - loss: 0.2199 - accuracy: 0.926 - ETA: 36s - loss: 0.2197 - accuracy: 0.927 - ETA: 34s - loss: 0.2204 - accuracy: 0.926 - ETA: 32s - loss: 0.2202 - accuracy: 0.927 - ETA: 31s - loss: 0.2198 - accuracy: 0.927 - ETA: 29s - loss: 0.2197 - accuracy: 0.927 - ETA: 27s - loss: 0.2195 - accuracy: 0.927 - ETA: 25s - loss: 0.2204 - accuracy: 0.926 - ETA: 24s - loss: 0.2215 - accuracy: 0.926 - ETA: 22s - loss: 0.2219 - accuracy: 0.926 - ETA: 20s - loss: 0.2220 - accuracy: 0.926 - ETA: 18s - loss: 0.2221 - accuracy: 0.926 - ETA: 17s - loss: 0.2219 - accuracy: 0.926 - ETA: 15s - loss: 0.2220 - accuracy: 0.926 - ETA: 13s - loss: 0.2220 - accuracy: 0.926 - ETA: 11s - loss: 0.2221 - accuracy: 0.926 - ETA: 10s - loss: 0.2218 - accuracy: 0.926 - ETA: 8s - loss: 0.2216 - accuracy: 0.926 - ETA: 6s - loss: 0.2219 - accuracy: 0.92 - ETA: 5s - loss: 0.2221 - accuracy: 0.92 - ETA: 3s - loss: 0.2216 - accuracy: 0.92 - ETA: 1s - loss: 0.2212 - accuracy: 0.92 - 303s 16ms/step - loss: 0.2214 - accuracy: 0.9263 - val_loss: 1.1863 - val_accuracy: 0.7873\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:22 - loss: 0.1182 - accuracy: 0.96 - ETA: 4:21 - loss: 0.1334 - accuracy: 0.96 - ETA: 4:21 - loss: 0.1885 - accuracy: 0.94 - ETA: 4:17 - loss: 0.1598 - accuracy: 0.94 - ETA: 4:15 - loss: 0.1487 - accuracy: 0.95 - ETA: 4:11 - loss: 0.1481 - accuracy: 0.95 - ETA: 4:11 - loss: 0.1495 - accuracy: 0.95 - ETA: 4:12 - loss: 0.1524 - accuracy: 0.94 - ETA: 4:10 - loss: 0.1588 - accuracy: 0.94 - ETA: 4:09 - loss: 0.1596 - accuracy: 0.94 - ETA: 4:07 - loss: 0.1602 - accuracy: 0.94 - ETA: 4:04 - loss: 0.1655 - accuracy: 0.94 - ETA: 4:02 - loss: 0.1647 - accuracy: 0.94 - ETA: 4:00 - loss: 0.1703 - accuracy: 0.94 - ETA: 3:58 - loss: 0.1750 - accuracy: 0.94 - ETA: 3:55 - loss: 0.1763 - accuracy: 0.93 - ETA: 3:54 - loss: 0.1832 - accuracy: 0.93 - ETA: 3:53 - loss: 0.1848 - accuracy: 0.93 - ETA: 3:51 - loss: 0.1808 - accuracy: 0.93 - ETA: 3:49 - loss: 0.1773 - accuracy: 0.93 - ETA: 3:48 - loss: 0.1774 - accuracy: 0.93 - ETA: 3:45 - loss: 0.1751 - accuracy: 0.93 - ETA: 3:43 - loss: 0.1776 - accuracy: 0.93 - ETA: 3:42 - loss: 0.1746 - accuracy: 0.94 - ETA: 3:40 - loss: 0.1761 - accuracy: 0.94 - ETA: 3:38 - loss: 0.1753 - accuracy: 0.93 - ETA: 3:36 - loss: 0.1743 - accuracy: 0.94 - ETA: 3:35 - loss: 0.1712 - accuracy: 0.94 - ETA: 3:33 - loss: 0.1727 - accuracy: 0.94 - ETA: 3:31 - loss: 0.1690 - accuracy: 0.94 - ETA: 3:30 - loss: 0.1687 - accuracy: 0.94 - ETA: 3:28 - loss: 0.1695 - accuracy: 0.94 - ETA: 3:26 - loss: 0.1703 - accuracy: 0.94 - ETA: 3:24 - loss: 0.1713 - accuracy: 0.94 - ETA: 3:23 - loss: 0.1743 - accuracy: 0.94 - ETA: 3:21 - loss: 0.1748 - accuracy: 0.94 - ETA: 3:19 - loss: 0.1786 - accuracy: 0.94 - ETA: 3:18 - loss: 0.1800 - accuracy: 0.93 - ETA: 3:16 - loss: 0.1800 - accuracy: 0.93 - ETA: 3:14 - loss: 0.1820 - accuracy: 0.93 - ETA: 3:12 - loss: 0.1804 - accuracy: 0.93 - ETA: 3:10 - loss: 0.1821 - accuracy: 0.93 - ETA: 3:08 - loss: 0.1824 - accuracy: 0.93 - ETA: 3:07 - loss: 0.1828 - accuracy: 0.93 - ETA: 3:05 - loss: 0.1848 - accuracy: 0.93 - ETA: 3:03 - loss: 0.1847 - accuracy: 0.93 - ETA: 3:02 - loss: 0.1837 - accuracy: 0.93 - ETA: 3:00 - loss: 0.1846 - accuracy: 0.93 - ETA: 2:58 - loss: 0.1819 - accuracy: 0.93 - ETA: 2:56 - loss: 0.1838 - accuracy: 0.93 - ETA: 2:55 - loss: 0.1840 - accuracy: 0.93 - ETA: 2:53 - loss: 0.1849 - accuracy: 0.93 - ETA: 2:51 - loss: 0.1837 - accuracy: 0.93 - ETA: 2:49 - loss: 0.1858 - accuracy: 0.93 - ETA: 2:47 - loss: 0.1886 - accuracy: 0.93 - ETA: 2:46 - loss: 0.1893 - accuracy: 0.93 - ETA: 2:44 - loss: 0.1916 - accuracy: 0.93 - ETA: 2:42 - loss: 0.1917 - accuracy: 0.93 - ETA: 2:40 - loss: 0.1941 - accuracy: 0.93 - ETA: 2:38 - loss: 0.1949 - accuracy: 0.93 - ETA: 2:37 - loss: 0.1936 - accuracy: 0.93 - ETA: 2:35 - loss: 0.1940 - accuracy: 0.93 - ETA: 2:33 - loss: 0.1965 - accuracy: 0.93 - ETA: 2:31 - loss: 0.1955 - accuracy: 0.93 - ETA: 2:30 - loss: 0.1969 - accuracy: 0.93 - ETA: 2:28 - loss: 0.1954 - accuracy: 0.93 - ETA: 2:26 - loss: 0.1963 - accuracy: 0.93 - ETA: 2:24 - loss: 0.1955 - accuracy: 0.93 - ETA: 2:23 - loss: 0.1953 - accuracy: 0.93 - ETA: 2:21 - loss: 0.1951 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1952 - accuracy: 0.93 - ETA: 2:17 - loss: 0.1951 - accuracy: 0.93 - ETA: 2:16 - loss: 0.1965 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1951 - accuracy: 0.93 - ETA: 2:12 - loss: 0.1940 - accuracy: 0.93 - ETA: 2:10 - loss: 0.1934 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1926 - accuracy: 0.93 - ETA: 2:07 - loss: 0.1932 - accuracy: 0.93 - ETA: 2:05 - loss: 0.1933 - accuracy: 0.93 - ETA: 2:03 - loss: 0.1927 - accuracy: 0.93 - ETA: 2:02 - loss: 0.1932 - accuracy: 0.93 - ETA: 2:00 - loss: 0.1941 - accuracy: 0.93 - ETA: 1:58 - loss: 0.1939 - accuracy: 0.93 - ETA: 1:56 - loss: 0.1938 - accuracy: 0.93 - ETA: 1:55 - loss: 0.1947 - accuracy: 0.93 - ETA: 1:53 - loss: 0.1953 - accuracy: 0.93 - ETA: 1:51 - loss: 0.1963 - accuracy: 0.93 - ETA: 1:49 - loss: 0.1960 - accuracy: 0.93 - ETA: 1:48 - loss: 0.1949 - accuracy: 0.93 - ETA: 1:46 - loss: 0.1962 - accuracy: 0.93 - ETA: 1:44 - loss: 0.1954 - accuracy: 0.93 - ETA: 1:42 - loss: 0.1960 - accuracy: 0.93 - ETA: 1:40 - loss: 0.1958 - accuracy: 0.93 - ETA: 1:39 - loss: 0.1953 - accuracy: 0.93 - ETA: 1:37 - loss: 0.1966 - accuracy: 0.93 - ETA: 1:35 - loss: 0.1957 - accuracy: 0.93 - ETA: 1:33 - loss: 0.1950 - accuracy: 0.93 - ETA: 1:32 - loss: 0.1955 - accuracy: 0.93 - ETA: 1:30 - loss: 0.1960 - accuracy: 0.93 - ETA: 1:28 - loss: 0.1962 - accuracy: 0.93 - ETA: 1:27 - loss: 0.1964 - accuracy: 0.93 - ETA: 1:25 - loss: 0.1954 - accuracy: 0.93 - ETA: 1:23 - loss: 0.1952 - accuracy: 0.93 - ETA: 1:21 - loss: 0.1966 - accuracy: 0.93 - ETA: 1:20 - loss: 0.1962 - accuracy: 0.93 - ETA: 1:18 - loss: 0.1967 - accuracy: 0.93 - ETA: 1:16 - loss: 0.1973 - accuracy: 0.93 - ETA: 1:14 - loss: 0.1974 - accuracy: 0.93 - ETA: 1:13 - loss: 0.1970 - accuracy: 0.93 - ETA: 1:11 - loss: 0.1973 - accuracy: 0.93 - ETA: 1:09 - loss: 0.1969 - accuracy: 0.93 - ETA: 1:07 - loss: 0.1963 - accuracy: 0.93 - ETA: 1:06 - loss: 0.1960 - accuracy: 0.93 - ETA: 1:04 - loss: 0.1957 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1976 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1998 - accuracy: 0.93 - ETA: 59s - loss: 0.1995 - accuracy: 0.9346 - ETA: 57s - loss: 0.2004 - accuracy: 0.934 - ETA: 55s - loss: 0.2007 - accuracy: 0.934 - ETA: 53s - loss: 0.2008 - accuracy: 0.933 - ETA: 52s - loss: 0.2002 - accuracy: 0.934 - ETA: 50s - loss: 0.2000 - accuracy: 0.934 - ETA: 48s - loss: 0.2003 - accuracy: 0.934 - ETA: 47s - loss: 0.2001 - accuracy: 0.934 - ETA: 45s - loss: 0.2008 - accuracy: 0.933 - ETA: 43s - loss: 0.2009 - accuracy: 0.933 - ETA: 41s - loss: 0.2010 - accuracy: 0.933 - ETA: 40s - loss: 0.2012 - accuracy: 0.933 - ETA: 38s - loss: 0.2009 - accuracy: 0.933 - ETA: 36s - loss: 0.2007 - accuracy: 0.933 - ETA: 34s - loss: 0.2002 - accuracy: 0.934 - ETA: 33s - loss: 0.2002 - accuracy: 0.934 - ETA: 31s - loss: 0.2014 - accuracy: 0.934 - ETA: 29s - loss: 0.2013 - accuracy: 0.933 - ETA: 27s - loss: 0.2017 - accuracy: 0.933 - ETA: 26s - loss: 0.2017 - accuracy: 0.933 - ETA: 24s - loss: 0.2023 - accuracy: 0.933 - ETA: 22s - loss: 0.2024 - accuracy: 0.933 - ETA: 20s - loss: 0.2023 - accuracy: 0.933 - ETA: 19s - loss: 0.2017 - accuracy: 0.933 - ETA: 17s - loss: 0.2009 - accuracy: 0.933 - ETA: 15s - loss: 0.2011 - accuracy: 0.933 - ETA: 13s - loss: 0.2012 - accuracy: 0.933 - ETA: 12s - loss: 0.2003 - accuracy: 0.933 - ETA: 10s - loss: 0.2011 - accuracy: 0.933 - ETA: 8s - loss: 0.2005 - accuracy: 0.933 - ETA: 6s - loss: 0.2010 - accuracy: 0.93 - ETA: 5s - loss: 0.2010 - accuracy: 0.93 - ETA: 3s - loss: 0.2008 - accuracy: 0.93 - ETA: 1s - loss: 0.2009 - accuracy: 0.93 - 291s 15ms/step - loss: 0.2010 - accuracy: 0.9336 - val_loss: 1.2345 - val_accuracy: 0.7892\n",
      "Epoch 20/100\n",
      "19312/19312 [==============================] - ETA: 4:45 - loss: 0.2617 - accuracy: 0.92 - ETA: 4:28 - loss: 0.2053 - accuracy: 0.94 - ETA: 4:19 - loss: 0.2019 - accuracy: 0.93 - ETA: 4:20 - loss: 0.2404 - accuracy: 0.92 - ETA: 4:15 - loss: 0.2363 - accuracy: 0.92 - ETA: 4:16 - loss: 0.2452 - accuracy: 0.92 - ETA: 4:14 - loss: 0.2350 - accuracy: 0.93 - ETA: 4:11 - loss: 0.2331 - accuracy: 0.93 - ETA: 4:09 - loss: 0.2300 - accuracy: 0.92 - ETA: 4:07 - loss: 0.2244 - accuracy: 0.93 - ETA: 4:04 - loss: 0.2205 - accuracy: 0.93 - ETA: 4:02 - loss: 0.2181 - accuracy: 0.93 - ETA: 4:00 - loss: 0.2188 - accuracy: 0.93 - ETA: 3:56 - loss: 0.2184 - accuracy: 0.93 - ETA: 3:55 - loss: 0.2220 - accuracy: 0.93 - ETA: 3:54 - loss: 0.2243 - accuracy: 0.93 - ETA: 3:52 - loss: 0.2262 - accuracy: 0.93 - ETA: 3:50 - loss: 0.2253 - accuracy: 0.93 - ETA: 3:49 - loss: 0.2228 - accuracy: 0.93 - ETA: 3:47 - loss: 0.2239 - accuracy: 0.93 - ETA: 3:45 - loss: 0.2195 - accuracy: 0.93 - ETA: 3:43 - loss: 0.2239 - accuracy: 0.93 - ETA: 3:40 - loss: 0.2194 - accuracy: 0.93 - ETA: 3:39 - loss: 0.2176 - accuracy: 0.93 - ETA: 3:37 - loss: 0.2144 - accuracy: 0.93 - ETA: 3:35 - loss: 0.2172 - accuracy: 0.93 - ETA: 3:34 - loss: 0.2164 - accuracy: 0.93 - ETA: 3:33 - loss: 0.2180 - accuracy: 0.93 - ETA: 3:31 - loss: 0.2148 - accuracy: 0.93 - ETA: 3:29 - loss: 0.2114 - accuracy: 0.93 - ETA: 3:27 - loss: 0.2122 - accuracy: 0.93 - ETA: 3:26 - loss: 0.2100 - accuracy: 0.93 - ETA: 3:24 - loss: 0.2076 - accuracy: 0.93 - ETA: 3:22 - loss: 0.2043 - accuracy: 0.93 - ETA: 3:21 - loss: 0.2018 - accuracy: 0.93 - ETA: 3:19 - loss: 0.2035 - accuracy: 0.93 - ETA: 3:17 - loss: 0.2055 - accuracy: 0.93 - ETA: 3:16 - loss: 0.2113 - accuracy: 0.93 - ETA: 3:14 - loss: 0.2182 - accuracy: 0.93 - ETA: 3:12 - loss: 0.2161 - accuracy: 0.93 - ETA: 3:10 - loss: 0.2149 - accuracy: 0.93 - ETA: 3:09 - loss: 0.2133 - accuracy: 0.93 - ETA: 3:07 - loss: 0.2134 - accuracy: 0.93 - ETA: 3:05 - loss: 0.2111 - accuracy: 0.93 - ETA: 3:04 - loss: 0.2086 - accuracy: 0.93 - ETA: 3:02 - loss: 0.2092 - accuracy: 0.93 - ETA: 3:00 - loss: 0.2094 - accuracy: 0.93 - ETA: 2:58 - loss: 0.2095 - accuracy: 0.93 - ETA: 2:56 - loss: 0.2095 - accuracy: 0.93 - ETA: 2:54 - loss: 0.2082 - accuracy: 0.93 - ETA: 2:52 - loss: 0.2063 - accuracy: 0.93 - ETA: 2:51 - loss: 0.2046 - accuracy: 0.93 - ETA: 2:49 - loss: 0.2047 - accuracy: 0.93 - ETA: 2:47 - loss: 0.2045 - accuracy: 0.93 - ETA: 2:46 - loss: 0.2032 - accuracy: 0.93 - ETA: 2:44 - loss: 0.2018 - accuracy: 0.93 - ETA: 2:42 - loss: 0.2016 - accuracy: 0.93 - ETA: 2:40 - loss: 0.2016 - accuracy: 0.93 - ETA: 2:39 - loss: 0.2016 - accuracy: 0.93 - ETA: 2:37 - loss: 0.1999 - accuracy: 0.93 - ETA: 2:35 - loss: 0.1985 - accuracy: 0.93 - ETA: 2:34 - loss: 0.1986 - accuracy: 0.93 - ETA: 2:32 - loss: 0.1978 - accuracy: 0.93 - ETA: 2:30 - loss: 0.1971 - accuracy: 0.93 - ETA: 2:29 - loss: 0.1962 - accuracy: 0.93 - ETA: 2:27 - loss: 0.1959 - accuracy: 0.93 - ETA: 2:25 - loss: 0.1948 - accuracy: 0.93 - ETA: 2:23 - loss: 0.1941 - accuracy: 0.93 - ETA: 2:21 - loss: 0.1945 - accuracy: 0.93 - ETA: 2:20 - loss: 0.1950 - accuracy: 0.93 - ETA: 2:18 - loss: 0.1954 - accuracy: 0.93 - ETA: 2:16 - loss: 0.1962 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1961 - accuracy: 0.93 - ETA: 2:13 - loss: 0.1950 - accuracy: 0.93 - ETA: 2:11 - loss: 0.1942 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1949 - accuracy: 0.93 - ETA: 2:07 - loss: 0.1945 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1946 - accuracy: 0.93 - ETA: 2:04 - loss: 0.1951 - accuracy: 0.93 - ETA: 2:02 - loss: 0.1955 - accuracy: 0.93 - ETA: 2:01 - loss: 0.1951 - accuracy: 0.93 - ETA: 1:59 - loss: 0.1947 - accuracy: 0.93 - ETA: 1:57 - loss: 0.1939 - accuracy: 0.93 - ETA: 1:55 - loss: 0.1936 - accuracy: 0.93 - ETA: 1:54 - loss: 0.1937 - accuracy: 0.93 - ETA: 1:52 - loss: 0.1930 - accuracy: 0.93 - ETA: 1:50 - loss: 0.1937 - accuracy: 0.93 - ETA: 1:49 - loss: 0.1932 - accuracy: 0.93 - ETA: 1:47 - loss: 0.1928 - accuracy: 0.93 - ETA: 1:45 - loss: 0.1942 - accuracy: 0.93 - ETA: 1:43 - loss: 0.1969 - accuracy: 0.93 - ETA: 1:42 - loss: 0.1966 - accuracy: 0.93 - ETA: 1:40 - loss: 0.1971 - accuracy: 0.93 - ETA: 1:38 - loss: 0.1958 - accuracy: 0.93 - ETA: 1:36 - loss: 0.1979 - accuracy: 0.93 - ETA: 1:35 - loss: 0.1979 - accuracy: 0.93 - ETA: 1:33 - loss: 0.1973 - accuracy: 0.93 - ETA: 1:31 - loss: 0.1986 - accuracy: 0.93 - ETA: 1:29 - loss: 0.1979 - accuracy: 0.93 - ETA: 1:28 - loss: 0.1972 - accuracy: 0.93 - ETA: 1:26 - loss: 0.1977 - accuracy: 0.93 - ETA: 1:24 - loss: 0.1974 - accuracy: 0.93 - ETA: 1:22 - loss: 0.1985 - accuracy: 0.93 - ETA: 1:21 - loss: 0.1987 - accuracy: 0.93 - ETA: 1:19 - loss: 0.1988 - accuracy: 0.93 - ETA: 1:17 - loss: 0.1989 - accuracy: 0.93 - ETA: 1:15 - loss: 0.1986 - accuracy: 0.93 - ETA: 1:14 - loss: 0.1985 - accuracy: 0.93 - ETA: 1:12 - loss: 0.1980 - accuracy: 0.93 - ETA: 1:10 - loss: 0.1988 - accuracy: 0.93 - ETA: 1:09 - loss: 0.1994 - accuracy: 0.93 - ETA: 1:07 - loss: 0.2019 - accuracy: 0.93 - ETA: 1:05 - loss: 0.2023 - accuracy: 0.93 - ETA: 1:03 - loss: 0.2028 - accuracy: 0.93 - ETA: 1:02 - loss: 0.2022 - accuracy: 0.93 - ETA: 1:00 - loss: 0.2017 - accuracy: 0.93 - ETA: 58s - loss: 0.2019 - accuracy: 0.9364 - ETA: 57s - loss: 0.2026 - accuracy: 0.936 - ETA: 55s - loss: 0.2021 - accuracy: 0.936 - ETA: 53s - loss: 0.2023 - accuracy: 0.936 - ETA: 51s - loss: 0.2023 - accuracy: 0.936 - ETA: 50s - loss: 0.2026 - accuracy: 0.935 - ETA: 48s - loss: 0.2024 - accuracy: 0.935 - ETA: 46s - loss: 0.2021 - accuracy: 0.935 - ETA: 44s - loss: 0.2016 - accuracy: 0.935 - ETA: 43s - loss: 0.2021 - accuracy: 0.935 - ETA: 41s - loss: 0.2035 - accuracy: 0.935 - ETA: 39s - loss: 0.2033 - accuracy: 0.935 - ETA: 37s - loss: 0.2032 - accuracy: 0.935 - ETA: 36s - loss: 0.2028 - accuracy: 0.935 - ETA: 34s - loss: 0.2019 - accuracy: 0.935 - ETA: 32s - loss: 0.2011 - accuracy: 0.935 - ETA: 31s - loss: 0.2005 - accuracy: 0.935 - ETA: 29s - loss: 0.2011 - accuracy: 0.935 - ETA: 27s - loss: 0.2010 - accuracy: 0.935 - ETA: 25s - loss: 0.2010 - accuracy: 0.935 - ETA: 24s - loss: 0.2011 - accuracy: 0.935 - ETA: 22s - loss: 0.2020 - accuracy: 0.935 - ETA: 20s - loss: 0.2017 - accuracy: 0.935 - ETA: 18s - loss: 0.2016 - accuracy: 0.935 - ETA: 17s - loss: 0.2015 - accuracy: 0.935 - ETA: 15s - loss: 0.2019 - accuracy: 0.935 - ETA: 13s - loss: 0.2016 - accuracy: 0.935 - ETA: 11s - loss: 0.2025 - accuracy: 0.935 - ETA: 10s - loss: 0.2019 - accuracy: 0.935 - ETA: 8s - loss: 0.2019 - accuracy: 0.935 - ETA: 6s - loss: 0.2020 - accuracy: 0.93 - ETA: 4s - loss: 0.2020 - accuracy: 0.93 - ETA: 3s - loss: 0.2012 - accuracy: 0.93 - ETA: 1s - loss: 0.2014 - accuracy: 0.93 - 288s 15ms/step - loss: 0.2014 - accuracy: 0.9356 - val_loss: 1.2211 - val_accuracy: 0.7894\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:10 - loss: 0.1172 - accuracy: 0.96 - ETA: 4:11 - loss: 0.1180 - accuracy: 0.96 - ETA: 4:11 - loss: 0.1401 - accuracy: 0.95 - ETA: 4:15 - loss: 0.1452 - accuracy: 0.95 - ETA: 4:17 - loss: 0.1480 - accuracy: 0.95 - ETA: 4:12 - loss: 0.1487 - accuracy: 0.95 - ETA: 4:12 - loss: 0.1508 - accuracy: 0.95 - ETA: 4:12 - loss: 0.1590 - accuracy: 0.95 - ETA: 4:09 - loss: 0.1609 - accuracy: 0.95 - ETA: 4:07 - loss: 0.1622 - accuracy: 0.95 - ETA: 4:05 - loss: 0.1676 - accuracy: 0.95 - ETA: 4:02 - loss: 0.1718 - accuracy: 0.94 - ETA: 4:00 - loss: 0.1708 - accuracy: 0.94 - ETA: 3:59 - loss: 0.1688 - accuracy: 0.94 - ETA: 3:58 - loss: 0.1710 - accuracy: 0.94 - ETA: 3:57 - loss: 0.1680 - accuracy: 0.94 - ETA: 3:55 - loss: 0.1669 - accuracy: 0.94 - ETA: 3:53 - loss: 0.1668 - accuracy: 0.94 - ETA: 3:52 - loss: 0.1650 - accuracy: 0.94 - ETA: 3:51 - loss: 0.1662 - accuracy: 0.94 - ETA: 3:48 - loss: 0.1652 - accuracy: 0.94 - ETA: 3:47 - loss: 0.1617 - accuracy: 0.94 - ETA: 3:45 - loss: 0.1591 - accuracy: 0.94 - ETA: 3:43 - loss: 0.1593 - accuracy: 0.94 - ETA: 3:41 - loss: 0.1575 - accuracy: 0.94 - ETA: 3:39 - loss: 0.1569 - accuracy: 0.94 - ETA: 3:37 - loss: 0.1558 - accuracy: 0.94 - ETA: 3:35 - loss: 0.1530 - accuracy: 0.94 - ETA: 3:34 - loss: 0.1560 - accuracy: 0.94 - ETA: 3:31 - loss: 0.1565 - accuracy: 0.94 - ETA: 3:30 - loss: 0.1557 - accuracy: 0.94 - ETA: 3:27 - loss: 0.1558 - accuracy: 0.94 - ETA: 3:26 - loss: 0.1537 - accuracy: 0.94 - ETA: 3:24 - loss: 0.1540 - accuracy: 0.94 - ETA: 3:22 - loss: 0.1535 - accuracy: 0.94 - ETA: 3:21 - loss: 0.1541 - accuracy: 0.94 - ETA: 3:19 - loss: 0.1564 - accuracy: 0.94 - ETA: 3:17 - loss: 0.1576 - accuracy: 0.94 - ETA: 3:15 - loss: 0.1553 - accuracy: 0.94 - ETA: 3:13 - loss: 0.1547 - accuracy: 0.94 - ETA: 3:11 - loss: 0.1564 - accuracy: 0.94 - ETA: 3:10 - loss: 0.1554 - accuracy: 0.94 - ETA: 3:08 - loss: 0.1574 - accuracy: 0.94 - ETA: 3:06 - loss: 0.1570 - accuracy: 0.94 - ETA: 3:04 - loss: 0.1576 - accuracy: 0.94 - ETA: 3:03 - loss: 0.1602 - accuracy: 0.94 - ETA: 3:01 - loss: 0.1608 - accuracy: 0.94 - ETA: 2:59 - loss: 0.1625 - accuracy: 0.94 - ETA: 2:57 - loss: 0.1618 - accuracy: 0.94 - ETA: 2:55 - loss: 0.1652 - accuracy: 0.94 - ETA: 2:54 - loss: 0.1630 - accuracy: 0.94 - ETA: 2:52 - loss: 0.1676 - accuracy: 0.94 - ETA: 2:50 - loss: 0.1677 - accuracy: 0.94 - ETA: 2:49 - loss: 0.1670 - accuracy: 0.94 - ETA: 2:47 - loss: 0.1671 - accuracy: 0.94 - ETA: 2:46 - loss: 0.1670 - accuracy: 0.94 - ETA: 2:44 - loss: 0.1663 - accuracy: 0.94 - ETA: 2:42 - loss: 0.1667 - accuracy: 0.94 - ETA: 2:40 - loss: 0.1666 - accuracy: 0.94 - ETA: 2:39 - loss: 0.1665 - accuracy: 0.94 - ETA: 2:37 - loss: 0.1660 - accuracy: 0.94 - ETA: 2:35 - loss: 0.1669 - accuracy: 0.94 - ETA: 2:33 - loss: 0.1660 - accuracy: 0.94 - ETA: 2:32 - loss: 0.1657 - accuracy: 0.94 - ETA: 2:30 - loss: 0.1651 - accuracy: 0.94 - ETA: 2:28 - loss: 0.1653 - accuracy: 0.94 - ETA: 2:27 - loss: 0.1657 - accuracy: 0.94 - ETA: 2:25 - loss: 0.1659 - accuracy: 0.94 - ETA: 2:23 - loss: 0.1659 - accuracy: 0.94 - ETA: 2:21 - loss: 0.1666 - accuracy: 0.94 - ETA: 2:20 - loss: 0.1669 - accuracy: 0.94 - ETA: 2:18 - loss: 0.1664 - accuracy: 0.94 - ETA: 2:16 - loss: 0.1663 - accuracy: 0.94 - ETA: 2:14 - loss: 0.1657 - accuracy: 0.94 - ETA: 2:12 - loss: 0.1660 - accuracy: 0.94 - ETA: 2:11 - loss: 0.1651 - accuracy: 0.94 - ETA: 2:09 - loss: 0.1649 - accuracy: 0.94 - ETA: 2:07 - loss: 0.1649 - accuracy: 0.94 - ETA: 2:05 - loss: 0.1641 - accuracy: 0.94 - ETA: 2:04 - loss: 0.1644 - accuracy: 0.94 - ETA: 2:02 - loss: 0.1637 - accuracy: 0.94 - ETA: 2:00 - loss: 0.1644 - accuracy: 0.94 - ETA: 1:59 - loss: 0.1645 - accuracy: 0.94 - ETA: 1:57 - loss: 0.1649 - accuracy: 0.94 - ETA: 1:55 - loss: 0.1645 - accuracy: 0.94 - ETA: 1:53 - loss: 0.1647 - accuracy: 0.94 - ETA: 1:52 - loss: 0.1663 - accuracy: 0.94 - ETA: 1:50 - loss: 0.1652 - accuracy: 0.94 - ETA: 1:48 - loss: 0.1651 - accuracy: 0.94 - ETA: 1:46 - loss: 0.1656 - accuracy: 0.94 - ETA: 1:45 - loss: 0.1661 - accuracy: 0.94 - ETA: 1:43 - loss: 0.1661 - accuracy: 0.94 - ETA: 1:41 - loss: 0.1663 - accuracy: 0.94 - ETA: 1:39 - loss: 0.1664 - accuracy: 0.94 - ETA: 1:37 - loss: 0.1664 - accuracy: 0.94 - ETA: 1:36 - loss: 0.1680 - accuracy: 0.94 - ETA: 1:34 - loss: 0.1685 - accuracy: 0.94 - ETA: 1:32 - loss: 0.1681 - accuracy: 0.94 - ETA: 1:30 - loss: 0.1676 - accuracy: 0.94 - ETA: 1:28 - loss: 0.1684 - accuracy: 0.94 - ETA: 1:27 - loss: 0.1691 - accuracy: 0.94 - ETA: 1:25 - loss: 0.1692 - accuracy: 0.94 - ETA: 1:23 - loss: 0.1701 - accuracy: 0.94 - ETA: 1:21 - loss: 0.1708 - accuracy: 0.94 - ETA: 1:20 - loss: 0.1707 - accuracy: 0.94 - ETA: 1:18 - loss: 0.1700 - accuracy: 0.94 - ETA: 1:16 - loss: 0.1703 - accuracy: 0.94 - ETA: 1:14 - loss: 0.1710 - accuracy: 0.94 - ETA: 1:13 - loss: 0.1707 - accuracy: 0.94 - ETA: 1:11 - loss: 0.1711 - accuracy: 0.94 - ETA: 1:09 - loss: 0.1710 - accuracy: 0.94 - ETA: 1:08 - loss: 0.1705 - accuracy: 0.94 - ETA: 1:06 - loss: 0.1703 - accuracy: 0.94 - ETA: 1:04 - loss: 0.1700 - accuracy: 0.94 - ETA: 1:02 - loss: 0.1696 - accuracy: 0.94 - ETA: 1:00 - loss: 0.1697 - accuracy: 0.94 - ETA: 59s - loss: 0.1699 - accuracy: 0.9446 - ETA: 57s - loss: 0.1707 - accuracy: 0.944 - ETA: 55s - loss: 0.1711 - accuracy: 0.944 - ETA: 53s - loss: 0.1707 - accuracy: 0.944 - ETA: 52s - loss: 0.1707 - accuracy: 0.944 - ETA: 50s - loss: 0.1706 - accuracy: 0.944 - ETA: 48s - loss: 0.1705 - accuracy: 0.943 - ETA: 46s - loss: 0.1704 - accuracy: 0.943 - ETA: 45s - loss: 0.1703 - accuracy: 0.943 - ETA: 43s - loss: 0.1704 - accuracy: 0.943 - ETA: 41s - loss: 0.1697 - accuracy: 0.943 - ETA: 40s - loss: 0.1694 - accuracy: 0.943 - ETA: 38s - loss: 0.1704 - accuracy: 0.943 - ETA: 36s - loss: 0.1709 - accuracy: 0.943 - ETA: 34s - loss: 0.1704 - accuracy: 0.943 - ETA: 32s - loss: 0.1700 - accuracy: 0.943 - ETA: 31s - loss: 0.1695 - accuracy: 0.943 - ETA: 29s - loss: 0.1693 - accuracy: 0.943 - ETA: 27s - loss: 0.1695 - accuracy: 0.943 - ETA: 25s - loss: 0.1691 - accuracy: 0.944 - ETA: 24s - loss: 0.1687 - accuracy: 0.944 - ETA: 22s - loss: 0.1688 - accuracy: 0.944 - ETA: 20s - loss: 0.1684 - accuracy: 0.944 - ETA: 19s - loss: 0.1688 - accuracy: 0.944 - ETA: 17s - loss: 0.1689 - accuracy: 0.944 - ETA: 15s - loss: 0.1689 - accuracy: 0.944 - ETA: 13s - loss: 0.1683 - accuracy: 0.944 - ETA: 12s - loss: 0.1682 - accuracy: 0.944 - ETA: 10s - loss: 0.1683 - accuracy: 0.944 - ETA: 8s - loss: 0.1682 - accuracy: 0.944 - ETA: 6s - loss: 0.1688 - accuracy: 0.94 - ETA: 5s - loss: 0.1681 - accuracy: 0.94 - ETA: 3s - loss: 0.1683 - accuracy: 0.94 - ETA: 1s - loss: 0.1686 - accuracy: 0.94 - 289s 15ms/step - loss: 0.1687 - accuracy: 0.9442 - val_loss: 1.2126 - val_accuracy: 0.7904\n",
      "Epoch 22/100\n",
      "19312/19312 [==============================] - ETA: 4:15 - loss: 0.1509 - accuracy: 0.94 - ETA: 4:09 - loss: 0.1733 - accuracy: 0.94 - ETA: 4:07 - loss: 0.1608 - accuracy: 0.95 - ETA: 4:09 - loss: 0.1414 - accuracy: 0.95 - ETA: 4:11 - loss: 0.1752 - accuracy: 0.94 - ETA: 4:08 - loss: 0.1691 - accuracy: 0.94 - ETA: 4:05 - loss: 0.1672 - accuracy: 0.95 - ETA: 4:06 - loss: 0.1665 - accuracy: 0.95 - ETA: 4:04 - loss: 0.1641 - accuracy: 0.95 - ETA: 4:02 - loss: 0.1718 - accuracy: 0.94 - ETA: 4:00 - loss: 0.1742 - accuracy: 0.94 - ETA: 3:59 - loss: 0.1798 - accuracy: 0.94 - ETA: 3:58 - loss: 0.1782 - accuracy: 0.93 - ETA: 3:57 - loss: 0.1820 - accuracy: 0.93 - ETA: 3:54 - loss: 0.1869 - accuracy: 0.93 - ETA: 3:54 - loss: 0.1970 - accuracy: 0.93 - ETA: 3:53 - loss: 0.1995 - accuracy: 0.93 - ETA: 3:51 - loss: 0.2000 - accuracy: 0.93 - ETA: 3:50 - loss: 0.1954 - accuracy: 0.93 - ETA: 3:48 - loss: 0.1961 - accuracy: 0.93 - ETA: 3:46 - loss: 0.1945 - accuracy: 0.93 - ETA: 3:44 - loss: 0.1934 - accuracy: 0.93 - ETA: 3:43 - loss: 0.1927 - accuracy: 0.93 - ETA: 3:41 - loss: 0.1967 - accuracy: 0.93 - ETA: 3:40 - loss: 0.1931 - accuracy: 0.93 - ETA: 3:38 - loss: 0.1929 - accuracy: 0.93 - ETA: 3:36 - loss: 0.1910 - accuracy: 0.93 - ETA: 3:34 - loss: 0.1911 - accuracy: 0.93 - ETA: 3:32 - loss: 0.1873 - accuracy: 0.93 - ETA: 3:30 - loss: 0.1884 - accuracy: 0.93 - ETA: 3:29 - loss: 0.1879 - accuracy: 0.93 - ETA: 3:28 - loss: 0.1886 - accuracy: 0.93 - ETA: 3:26 - loss: 0.1852 - accuracy: 0.93 - ETA: 3:24 - loss: 0.1880 - accuracy: 0.93 - ETA: 3:22 - loss: 0.1858 - accuracy: 0.93 - ETA: 3:20 - loss: 0.1830 - accuracy: 0.93 - ETA: 3:19 - loss: 0.1808 - accuracy: 0.93 - ETA: 3:17 - loss: 0.1802 - accuracy: 0.93 - ETA: 3:15 - loss: 0.1798 - accuracy: 0.93 - ETA: 3:12 - loss: 0.1776 - accuracy: 0.93 - ETA: 3:11 - loss: 0.1760 - accuracy: 0.93 - ETA: 3:09 - loss: 0.1745 - accuracy: 0.94 - ETA: 3:07 - loss: 0.1739 - accuracy: 0.94 - ETA: 3:05 - loss: 0.1741 - accuracy: 0.94 - ETA: 3:04 - loss: 0.1757 - accuracy: 0.94 - ETA: 3:02 - loss: 0.1752 - accuracy: 0.93 - ETA: 3:00 - loss: 0.1743 - accuracy: 0.94 - ETA: 2:58 - loss: 0.1758 - accuracy: 0.93 - ETA: 2:56 - loss: 0.1746 - accuracy: 0.94 - ETA: 2:55 - loss: 0.1741 - accuracy: 0.94 - ETA: 2:53 - loss: 0.1736 - accuracy: 0.94 - ETA: 2:51 - loss: 0.1742 - accuracy: 0.94 - ETA: 2:49 - loss: 0.1736 - accuracy: 0.94 - ETA: 2:48 - loss: 0.1741 - accuracy: 0.94 - ETA: 2:46 - loss: 0.1741 - accuracy: 0.94 - ETA: 2:45 - loss: 0.1730 - accuracy: 0.94 - ETA: 2:43 - loss: 0.1752 - accuracy: 0.94 - ETA: 2:41 - loss: 0.1728 - accuracy: 0.94 - ETA: 2:40 - loss: 0.1718 - accuracy: 0.94 - ETA: 2:38 - loss: 0.1714 - accuracy: 0.94 - ETA: 2:36 - loss: 0.1719 - accuracy: 0.94 - ETA: 2:35 - loss: 0.1721 - accuracy: 0.94 - ETA: 2:33 - loss: 0.1727 - accuracy: 0.94 - ETA: 2:31 - loss: 0.1738 - accuracy: 0.94 - ETA: 2:30 - loss: 0.1745 - accuracy: 0.94 - ETA: 2:28 - loss: 0.1737 - accuracy: 0.94 - ETA: 2:26 - loss: 0.1744 - accuracy: 0.94 - ETA: 2:25 - loss: 0.1742 - accuracy: 0.94 - ETA: 2:23 - loss: 0.1728 - accuracy: 0.94 - ETA: 2:21 - loss: 0.1741 - accuracy: 0.94 - ETA: 2:19 - loss: 0.1738 - accuracy: 0.94 - ETA: 2:17 - loss: 0.1738 - accuracy: 0.94 - ETA: 2:15 - loss: 0.1740 - accuracy: 0.94 - ETA: 2:14 - loss: 0.1741 - accuracy: 0.94 - ETA: 2:12 - loss: 0.1747 - accuracy: 0.94 - ETA: 2:10 - loss: 0.1748 - accuracy: 0.94 - ETA: 2:08 - loss: 0.1754 - accuracy: 0.94 - ETA: 2:07 - loss: 0.1746 - accuracy: 0.94 - ETA: 2:05 - loss: 0.1763 - accuracy: 0.94 - ETA: 2:03 - loss: 0.1766 - accuracy: 0.94 - ETA: 2:02 - loss: 0.1762 - accuracy: 0.94 - ETA: 2:00 - loss: 0.1776 - accuracy: 0.94 - ETA: 1:58 - loss: 0.1772 - accuracy: 0.94 - ETA: 1:56 - loss: 0.1791 - accuracy: 0.94 - ETA: 1:55 - loss: 0.1789 - accuracy: 0.94 - ETA: 1:53 - loss: 0.1782 - accuracy: 0.94 - ETA: 1:51 - loss: 0.1778 - accuracy: 0.94 - ETA: 1:49 - loss: 0.1772 - accuracy: 0.94 - ETA: 1:47 - loss: 0.1773 - accuracy: 0.94 - ETA: 1:46 - loss: 0.1775 - accuracy: 0.94 - ETA: 1:44 - loss: 0.1785 - accuracy: 0.94 - ETA: 1:42 - loss: 0.1793 - accuracy: 0.94 - ETA: 1:40 - loss: 0.1786 - accuracy: 0.94 - ETA: 1:39 - loss: 0.1779 - accuracy: 0.94 - ETA: 1:37 - loss: 0.1772 - accuracy: 0.94 - ETA: 1:35 - loss: 0.1761 - accuracy: 0.94 - ETA: 1:33 - loss: 0.1767 - accuracy: 0.94 - ETA: 1:32 - loss: 0.1763 - accuracy: 0.94 - ETA: 1:30 - loss: 0.1755 - accuracy: 0.94 - ETA: 1:28 - loss: 0.1746 - accuracy: 0.94 - ETA: 1:26 - loss: 0.1740 - accuracy: 0.94 - ETA: 1:25 - loss: 0.1737 - accuracy: 0.94 - ETA: 1:23 - loss: 0.1741 - accuracy: 0.94 - ETA: 1:21 - loss: 0.1732 - accuracy: 0.94 - ETA: 1:19 - loss: 0.1725 - accuracy: 0.94 - ETA: 1:18 - loss: 0.1717 - accuracy: 0.94 - ETA: 1:16 - loss: 0.1713 - accuracy: 0.94 - ETA: 1:14 - loss: 0.1717 - accuracy: 0.94 - ETA: 1:12 - loss: 0.1723 - accuracy: 0.94 - ETA: 1:11 - loss: 0.1720 - accuracy: 0.94 - ETA: 1:09 - loss: 0.1718 - accuracy: 0.94 - ETA: 1:07 - loss: 0.1714 - accuracy: 0.94 - ETA: 1:06 - loss: 0.1717 - accuracy: 0.94 - ETA: 1:04 - loss: 0.1716 - accuracy: 0.94 - ETA: 1:02 - loss: 0.1714 - accuracy: 0.94 - ETA: 1:00 - loss: 0.1716 - accuracy: 0.94 - ETA: 59s - loss: 0.1713 - accuracy: 0.9423 - ETA: 57s - loss: 0.1713 - accuracy: 0.942 - ETA: 55s - loss: 0.1709 - accuracy: 0.942 - ETA: 53s - loss: 0.1709 - accuracy: 0.942 - ETA: 52s - loss: 0.1717 - accuracy: 0.942 - ETA: 50s - loss: 0.1725 - accuracy: 0.942 - ETA: 48s - loss: 0.1724 - accuracy: 0.942 - ETA: 46s - loss: 0.1722 - accuracy: 0.942 - ETA: 45s - loss: 0.1719 - accuracy: 0.942 - ETA: 43s - loss: 0.1716 - accuracy: 0.942 - ETA: 41s - loss: 0.1711 - accuracy: 0.942 - ETA: 39s - loss: 0.1716 - accuracy: 0.942 - ETA: 38s - loss: 0.1710 - accuracy: 0.942 - ETA: 36s - loss: 0.1719 - accuracy: 0.942 - ETA: 34s - loss: 0.1716 - accuracy: 0.942 - ETA: 32s - loss: 0.1716 - accuracy: 0.942 - ETA: 31s - loss: 0.1719 - accuracy: 0.942 - ETA: 29s - loss: 0.1716 - accuracy: 0.942 - ETA: 27s - loss: 0.1711 - accuracy: 0.942 - ETA: 25s - loss: 0.1714 - accuracy: 0.942 - ETA: 24s - loss: 0.1713 - accuracy: 0.942 - ETA: 22s - loss: 0.1715 - accuracy: 0.942 - ETA: 20s - loss: 0.1716 - accuracy: 0.942 - ETA: 18s - loss: 0.1718 - accuracy: 0.942 - ETA: 17s - loss: 0.1723 - accuracy: 0.942 - ETA: 15s - loss: 0.1727 - accuracy: 0.942 - ETA: 13s - loss: 0.1730 - accuracy: 0.941 - ETA: 12s - loss: 0.1724 - accuracy: 0.942 - ETA: 10s - loss: 0.1726 - accuracy: 0.942 - ETA: 8s - loss: 0.1718 - accuracy: 0.942 - ETA: 6s - loss: 0.1719 - accuracy: 0.94 - ETA: 5s - loss: 0.1720 - accuracy: 0.94 - ETA: 3s - loss: 0.1721 - accuracy: 0.94 - ETA: 1s - loss: 0.1727 - accuracy: 0.94 - 288s 15ms/step - loss: 0.1724 - accuracy: 0.9423 - val_loss: 1.2877 - val_accuracy: 0.7877\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:06 - loss: 0.1930 - accuracy: 0.93 - ETA: 4:11 - loss: 0.1742 - accuracy: 0.93 - ETA: 4:16 - loss: 0.1529 - accuracy: 0.94 - ETA: 4:13 - loss: 0.1415 - accuracy: 0.94 - ETA: 4:10 - loss: 0.1452 - accuracy: 0.94 - ETA: 4:11 - loss: 0.1495 - accuracy: 0.94 - ETA: 4:09 - loss: 0.1540 - accuracy: 0.94 - ETA: 4:07 - loss: 0.1532 - accuracy: 0.94 - ETA: 4:07 - loss: 0.1523 - accuracy: 0.94 - ETA: 4:05 - loss: 0.1490 - accuracy: 0.94 - ETA: 4:03 - loss: 0.1473 - accuracy: 0.94 - ETA: 4:01 - loss: 0.1386 - accuracy: 0.94 - ETA: 4:00 - loss: 0.1374 - accuracy: 0.94 - ETA: 3:58 - loss: 0.1447 - accuracy: 0.94 - ETA: 3:57 - loss: 0.1484 - accuracy: 0.94 - ETA: 3:55 - loss: 0.1473 - accuracy: 0.94 - ETA: 3:53 - loss: 0.1514 - accuracy: 0.94 - ETA: 3:51 - loss: 0.1524 - accuracy: 0.94 - ETA: 3:50 - loss: 0.1525 - accuracy: 0.94 - ETA: 3:47 - loss: 0.1543 - accuracy: 0.94 - ETA: 3:45 - loss: 0.1534 - accuracy: 0.94 - ETA: 3:43 - loss: 0.1529 - accuracy: 0.94 - ETA: 3:41 - loss: 0.1494 - accuracy: 0.94 - ETA: 3:39 - loss: 0.1483 - accuracy: 0.94 - ETA: 3:36 - loss: 0.1492 - accuracy: 0.94 - ETA: 3:35 - loss: 0.1463 - accuracy: 0.94 - ETA: 3:33 - loss: 0.1466 - accuracy: 0.94 - ETA: 3:32 - loss: 0.1520 - accuracy: 0.94 - ETA: 3:30 - loss: 0.1538 - accuracy: 0.94 - ETA: 3:28 - loss: 0.1531 - accuracy: 0.94 - ETA: 3:27 - loss: 0.1547 - accuracy: 0.94 - ETA: 3:25 - loss: 0.1567 - accuracy: 0.94 - ETA: 3:23 - loss: 0.1570 - accuracy: 0.94 - ETA: 3:21 - loss: 0.1568 - accuracy: 0.94 - ETA: 3:19 - loss: 0.1552 - accuracy: 0.94 - ETA: 3:18 - loss: 0.1594 - accuracy: 0.94 - ETA: 3:16 - loss: 0.1592 - accuracy: 0.94 - ETA: 3:14 - loss: 0.1605 - accuracy: 0.94 - ETA: 3:12 - loss: 0.1612 - accuracy: 0.94 - ETA: 3:10 - loss: 0.1635 - accuracy: 0.94 - ETA: 3:09 - loss: 0.1624 - accuracy: 0.94 - ETA: 3:07 - loss: 0.1613 - accuracy: 0.94 - ETA: 3:05 - loss: 0.1612 - accuracy: 0.94 - ETA: 3:04 - loss: 0.1609 - accuracy: 0.94 - ETA: 3:02 - loss: 0.1619 - accuracy: 0.94 - ETA: 3:01 - loss: 0.1622 - accuracy: 0.94 - ETA: 2:59 - loss: 0.1632 - accuracy: 0.94 - ETA: 2:57 - loss: 0.1676 - accuracy: 0.94 - ETA: 2:55 - loss: 0.1678 - accuracy: 0.94 - ETA: 2:54 - loss: 0.1675 - accuracy: 0.94 - ETA: 2:52 - loss: 0.1714 - accuracy: 0.94 - ETA: 2:51 - loss: 0.1727 - accuracy: 0.94 - ETA: 2:49 - loss: 0.1730 - accuracy: 0.94 - ETA: 2:47 - loss: 0.1746 - accuracy: 0.94 - ETA: 2:45 - loss: 0.1746 - accuracy: 0.94 - ETA: 2:44 - loss: 0.1735 - accuracy: 0.94 - ETA: 2:43 - loss: 0.1729 - accuracy: 0.94 - ETA: 2:41 - loss: 0.1737 - accuracy: 0.94 - ETA: 2:43 - loss: 0.1734 - accuracy: 0.94 - ETA: 2:43 - loss: 0.1735 - accuracy: 0.94 - ETA: 2:41 - loss: 0.1752 - accuracy: 0.94 - ETA: 2:40 - loss: 0.1757 - accuracy: 0.94 - ETA: 2:38 - loss: 0.1744 - accuracy: 0.94 - ETA: 2:36 - loss: 0.1755 - accuracy: 0.94 - ETA: 2:34 - loss: 0.1743 - accuracy: 0.94 - ETA: 2:32 - loss: 0.1744 - accuracy: 0.94 - ETA: 2:30 - loss: 0.1751 - accuracy: 0.94 - ETA: 2:28 - loss: 0.1738 - accuracy: 0.94 - ETA: 2:27 - loss: 0.1740 - accuracy: 0.94 - ETA: 2:25 - loss: 0.1737 - accuracy: 0.94 - ETA: 2:23 - loss: 0.1727 - accuracy: 0.94 - ETA: 2:21 - loss: 0.1728 - accuracy: 0.94 - ETA: 2:19 - loss: 0.1732 - accuracy: 0.94 - ETA: 2:17 - loss: 0.1733 - accuracy: 0.94 - ETA: 2:15 - loss: 0.1725 - accuracy: 0.94 - ETA: 2:13 - loss: 0.1734 - accuracy: 0.94 - ETA: 2:11 - loss: 0.1732 - accuracy: 0.94 - ETA: 2:10 - loss: 0.1721 - accuracy: 0.94 - ETA: 2:08 - loss: 0.1718 - accuracy: 0.94 - ETA: 2:06 - loss: 0.1709 - accuracy: 0.94 - ETA: 2:04 - loss: 0.1701 - accuracy: 0.94 - ETA: 2:02 - loss: 0.1713 - accuracy: 0.94 - ETA: 2:00 - loss: 0.1701 - accuracy: 0.94 - ETA: 1:59 - loss: 0.1695 - accuracy: 0.94 - ETA: 1:57 - loss: 0.1705 - accuracy: 0.94 - ETA: 1:55 - loss: 0.1696 - accuracy: 0.94 - ETA: 1:53 - loss: 0.1687 - accuracy: 0.94 - ETA: 1:51 - loss: 0.1680 - accuracy: 0.94 - ETA: 1:50 - loss: 0.1671 - accuracy: 0.94 - ETA: 1:48 - loss: 0.1666 - accuracy: 0.94 - ETA: 1:46 - loss: 0.1672 - accuracy: 0.94 - ETA: 1:44 - loss: 0.1678 - accuracy: 0.94 - ETA: 1:42 - loss: 0.1682 - accuracy: 0.94 - ETA: 1:41 - loss: 0.1683 - accuracy: 0.94 - ETA: 1:39 - loss: 0.1674 - accuracy: 0.94 - ETA: 1:37 - loss: 0.1666 - accuracy: 0.94 - ETA: 1:35 - loss: 0.1667 - accuracy: 0.94 - ETA: 1:33 - loss: 0.1665 - accuracy: 0.94 - ETA: 1:32 - loss: 0.1671 - accuracy: 0.94 - ETA: 1:30 - loss: 0.1676 - accuracy: 0.94 - ETA: 1:28 - loss: 0.1667 - accuracy: 0.94 - ETA: 1:26 - loss: 0.1670 - accuracy: 0.94 - ETA: 1:24 - loss: 0.1677 - accuracy: 0.94 - ETA: 1:23 - loss: 0.1683 - accuracy: 0.94 - ETA: 1:21 - loss: 0.1680 - accuracy: 0.94 - ETA: 1:19 - loss: 0.1688 - accuracy: 0.94 - ETA: 1:17 - loss: 0.1678 - accuracy: 0.94 - ETA: 1:15 - loss: 0.1682 - accuracy: 0.94 - ETA: 1:14 - loss: 0.1698 - accuracy: 0.94 - ETA: 1:12 - loss: 0.1690 - accuracy: 0.94 - ETA: 1:10 - loss: 0.1692 - accuracy: 0.94 - ETA: 1:08 - loss: 0.1691 - accuracy: 0.94 - ETA: 1:06 - loss: 0.1689 - accuracy: 0.94 - ETA: 1:05 - loss: 0.1687 - accuracy: 0.94 - ETA: 1:03 - loss: 0.1685 - accuracy: 0.94 - ETA: 1:01 - loss: 0.1691 - accuracy: 0.94 - ETA: 59s - loss: 0.1690 - accuracy: 0.9432 - ETA: 58s - loss: 0.1690 - accuracy: 0.943 - ETA: 56s - loss: 0.1690 - accuracy: 0.943 - ETA: 54s - loss: 0.1700 - accuracy: 0.943 - ETA: 52s - loss: 0.1695 - accuracy: 0.943 - ETA: 50s - loss: 0.1698 - accuracy: 0.943 - ETA: 49s - loss: 0.1707 - accuracy: 0.943 - ETA: 47s - loss: 0.1704 - accuracy: 0.943 - ETA: 45s - loss: 0.1710 - accuracy: 0.943 - ETA: 43s - loss: 0.1712 - accuracy: 0.942 - ETA: 41s - loss: 0.1720 - accuracy: 0.942 - ETA: 40s - loss: 0.1727 - accuracy: 0.942 - ETA: 38s - loss: 0.1727 - accuracy: 0.942 - ETA: 36s - loss: 0.1724 - accuracy: 0.942 - ETA: 34s - loss: 0.1724 - accuracy: 0.942 - ETA: 33s - loss: 0.1733 - accuracy: 0.942 - ETA: 31s - loss: 0.1732 - accuracy: 0.942 - ETA: 29s - loss: 0.1726 - accuracy: 0.942 - ETA: 27s - loss: 0.1724 - accuracy: 0.942 - ETA: 26s - loss: 0.1723 - accuracy: 0.942 - ETA: 24s - loss: 0.1728 - accuracy: 0.942 - ETA: 22s - loss: 0.1726 - accuracy: 0.942 - ETA: 20s - loss: 0.1722 - accuracy: 0.942 - ETA: 19s - loss: 0.1734 - accuracy: 0.942 - ETA: 17s - loss: 0.1728 - accuracy: 0.942 - ETA: 15s - loss: 0.1726 - accuracy: 0.942 - ETA: 13s - loss: 0.1727 - accuracy: 0.942 - ETA: 12s - loss: 0.1733 - accuracy: 0.942 - ETA: 10s - loss: 0.1731 - accuracy: 0.942 - ETA: 8s - loss: 0.1726 - accuracy: 0.942 - ETA: 6s - loss: 0.1719 - accuracy: 0.94 - ETA: 5s - loss: 0.1719 - accuracy: 0.94 - ETA: 3s - loss: 0.1720 - accuracy: 0.94 - ETA: 1s - loss: 0.1725 - accuracy: 0.94 - 289s 15ms/step - loss: 0.1723 - accuracy: 0.9429 - val_loss: 1.2642 - val_accuracy: 0.7917\n",
      "Epoch 24/100\n",
      "19312/19312 [==============================] - ETA: 3:56 - loss: 0.0814 - accuracy: 0.97 - ETA: 3:59 - loss: 0.1109 - accuracy: 0.96 - ETA: 4:02 - loss: 0.1056 - accuracy: 0.96 - ETA: 4:09 - loss: 0.1181 - accuracy: 0.96 - ETA: 4:09 - loss: 0.1169 - accuracy: 0.95 - ETA: 4:09 - loss: 0.1211 - accuracy: 0.95 - ETA: 4:06 - loss: 0.1107 - accuracy: 0.95 - ETA: 4:06 - loss: 0.1280 - accuracy: 0.95 - ETA: 4:03 - loss: 0.1379 - accuracy: 0.95 - ETA: 4:00 - loss: 0.1413 - accuracy: 0.95 - ETA: 3:58 - loss: 0.1454 - accuracy: 0.95 - ETA: 3:58 - loss: 0.1471 - accuracy: 0.95 - ETA: 3:57 - loss: 0.1523 - accuracy: 0.94 - ETA: 3:54 - loss: 0.1524 - accuracy: 0.94 - ETA: 3:50 - loss: 0.1590 - accuracy: 0.94 - ETA: 3:49 - loss: 0.1566 - accuracy: 0.94 - ETA: 3:46 - loss: 0.1581 - accuracy: 0.94 - ETA: 3:45 - loss: 0.1689 - accuracy: 0.94 - ETA: 3:43 - loss: 0.1664 - accuracy: 0.94 - ETA: 3:41 - loss: 0.1654 - accuracy: 0.94 - ETA: 3:39 - loss: 0.1627 - accuracy: 0.94 - ETA: 3:38 - loss: 0.1612 - accuracy: 0.94 - ETA: 3:37 - loss: 0.1603 - accuracy: 0.94 - ETA: 3:35 - loss: 0.1589 - accuracy: 0.94 - ETA: 3:33 - loss: 0.1594 - accuracy: 0.94 - ETA: 3:32 - loss: 0.1624 - accuracy: 0.94 - ETA: 3:30 - loss: 0.1663 - accuracy: 0.94 - ETA: 3:28 - loss: 0.1664 - accuracy: 0.94 - ETA: 3:27 - loss: 0.1683 - accuracy: 0.94 - ETA: 3:25 - loss: 0.1671 - accuracy: 0.94 - ETA: 3:23 - loss: 0.1710 - accuracy: 0.94 - ETA: 3:21 - loss: 0.1670 - accuracy: 0.94 - ETA: 3:20 - loss: 0.1657 - accuracy: 0.94 - ETA: 3:18 - loss: 0.1636 - accuracy: 0.94 - ETA: 3:16 - loss: 0.1647 - accuracy: 0.94 - ETA: 3:15 - loss: 0.1659 - accuracy: 0.94 - ETA: 3:13 - loss: 0.1629 - accuracy: 0.94 - ETA: 3:11 - loss: 0.1606 - accuracy: 0.94 - ETA: 3:10 - loss: 0.1600 - accuracy: 0.94 - ETA: 3:08 - loss: 0.1603 - accuracy: 0.94 - ETA: 3:06 - loss: 0.1593 - accuracy: 0.94 - ETA: 3:05 - loss: 0.1582 - accuracy: 0.94 - ETA: 3:03 - loss: 0.1576 - accuracy: 0.94 - ETA: 3:01 - loss: 0.1583 - accuracy: 0.94 - ETA: 3:00 - loss: 0.1596 - accuracy: 0.94 - ETA: 2:58 - loss: 0.1591 - accuracy: 0.94 - ETA: 2:56 - loss: 0.1572 - accuracy: 0.95 - ETA: 2:55 - loss: 0.1563 - accuracy: 0.95 - ETA: 2:53 - loss: 0.1551 - accuracy: 0.95 - ETA: 2:51 - loss: 0.1553 - accuracy: 0.95 - ETA: 2:50 - loss: 0.1549 - accuracy: 0.95 - ETA: 2:48 - loss: 0.1551 - accuracy: 0.95 - ETA: 2:46 - loss: 0.1540 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1551 - accuracy: 0.95 - ETA: 2:43 - loss: 0.1540 - accuracy: 0.95 - ETA: 2:41 - loss: 0.1531 - accuracy: 0.95 - ETA: 2:39 - loss: 0.1515 - accuracy: 0.95 - ETA: 2:38 - loss: 0.1501 - accuracy: 0.95 - ETA: 2:36 - loss: 0.1510 - accuracy: 0.95 - ETA: 2:34 - loss: 0.1496 - accuracy: 0.95 - ETA: 2:32 - loss: 0.1519 - accuracy: 0.95 - ETA: 2:31 - loss: 0.1515 - accuracy: 0.95 - ETA: 2:29 - loss: 0.1523 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1518 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1506 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1503 - accuracy: 0.95 - ETA: 2:23 - loss: 0.1509 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1500 - accuracy: 0.95 - ETA: 2:19 - loss: 0.1494 - accuracy: 0.95 - ETA: 2:18 - loss: 0.1502 - accuracy: 0.95 - ETA: 2:16 - loss: 0.1508 - accuracy: 0.95 - ETA: 2:14 - loss: 0.1512 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1506 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1503 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1501 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1501 - accuracy: 0.95 - ETA: 2:06 - loss: 0.1499 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1492 - accuracy: 0.95 - ETA: 2:02 - loss: 0.1481 - accuracy: 0.95 - ETA: 2:01 - loss: 0.1477 - accuracy: 0.95 - ETA: 1:59 - loss: 0.1484 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1487 - accuracy: 0.95 - ETA: 1:55 - loss: 0.1471 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1476 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1465 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1461 - accuracy: 0.95 - ETA: 1:49 - loss: 0.1457 - accuracy: 0.95 - ETA: 1:47 - loss: 0.1451 - accuracy: 0.95 - ETA: 1:45 - loss: 0.1456 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1459 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1458 - accuracy: 0.95 - ETA: 1:40 - loss: 0.1456 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1455 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1464 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1459 - accuracy: 0.95 - ETA: 1:33 - loss: 0.1454 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1449 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1445 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1456 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1470 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1464 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1467 - accuracy: 0.95 - ETA: 1:21 - loss: 0.1463 - accuracy: 0.95 - ETA: 1:20 - loss: 0.1459 - accuracy: 0.95 - ETA: 1:18 - loss: 0.1458 - accuracy: 0.95 - ETA: 1:16 - loss: 0.1453 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1461 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1455 - accuracy: 0.95 - ETA: 1:11 - loss: 0.1457 - accuracy: 0.95 - ETA: 1:10 - loss: 0.1463 - accuracy: 0.95 - ETA: 1:08 - loss: 0.1471 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1478 - accuracy: 0.95 - ETA: 1:04 - loss: 0.1482 - accuracy: 0.95 - ETA: 1:03 - loss: 0.1483 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1476 - accuracy: 0.95 - ETA: 59s - loss: 0.1476 - accuracy: 0.9525 - ETA: 58s - loss: 0.1482 - accuracy: 0.952 - ETA: 56s - loss: 0.1480 - accuracy: 0.952 - ETA: 54s - loss: 0.1478 - accuracy: 0.952 - ETA: 52s - loss: 0.1477 - accuracy: 0.952 - ETA: 51s - loss: 0.1475 - accuracy: 0.952 - ETA: 49s - loss: 0.1481 - accuracy: 0.952 - ETA: 47s - loss: 0.1499 - accuracy: 0.951 - ETA: 46s - loss: 0.1497 - accuracy: 0.951 - ETA: 44s - loss: 0.1504 - accuracy: 0.951 - ETA: 42s - loss: 0.1510 - accuracy: 0.951 - ETA: 40s - loss: 0.1503 - accuracy: 0.951 - ETA: 39s - loss: 0.1506 - accuracy: 0.951 - ETA: 37s - loss: 0.1501 - accuracy: 0.951 - ETA: 35s - loss: 0.1499 - accuracy: 0.951 - ETA: 34s - loss: 0.1510 - accuracy: 0.950 - ETA: 32s - loss: 0.1517 - accuracy: 0.950 - ETA: 30s - loss: 0.1515 - accuracy: 0.950 - ETA: 28s - loss: 0.1522 - accuracy: 0.950 - ETA: 27s - loss: 0.1524 - accuracy: 0.950 - ETA: 25s - loss: 0.1518 - accuracy: 0.950 - ETA: 23s - loss: 0.1515 - accuracy: 0.950 - ETA: 22s - loss: 0.1522 - accuracy: 0.950 - ETA: 20s - loss: 0.1521 - accuracy: 0.950 - ETA: 18s - loss: 0.1519 - accuracy: 0.950 - ETA: 16s - loss: 0.1515 - accuracy: 0.950 - ETA: 15s - loss: 0.1509 - accuracy: 0.950 - ETA: 13s - loss: 0.1504 - accuracy: 0.950 - ETA: 11s - loss: 0.1505 - accuracy: 0.950 - ETA: 10s - loss: 0.1506 - accuracy: 0.950 - ETA: 8s - loss: 0.1508 - accuracy: 0.950 - ETA: 6s - loss: 0.1519 - accuracy: 0.95 - ETA: 4s - loss: 0.1516 - accuracy: 0.95 - ETA: 3s - loss: 0.1523 - accuracy: 0.95 - ETA: 1s - loss: 0.1525 - accuracy: 0.94 - 284s 15ms/step - loss: 0.1530 - accuracy: 0.9497 - val_loss: 1.3700 - val_accuracy: 0.7902\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:17 - loss: 0.1816 - accuracy: 0.92 - ETA: 4:14 - loss: 0.1620 - accuracy: 0.92 - ETA: 4:08 - loss: 0.1774 - accuracy: 0.93 - ETA: 4:07 - loss: 0.1655 - accuracy: 0.93 - ETA: 4:07 - loss: 0.1573 - accuracy: 0.94 - ETA: 4:06 - loss: 0.1468 - accuracy: 0.94 - ETA: 4:04 - loss: 0.1556 - accuracy: 0.94 - ETA: 4:01 - loss: 0.1651 - accuracy: 0.93 - ETA: 3:59 - loss: 0.1595 - accuracy: 0.94 - ETA: 3:59 - loss: 0.1630 - accuracy: 0.93 - ETA: 3:58 - loss: 0.1539 - accuracy: 0.94 - ETA: 3:56 - loss: 0.1587 - accuracy: 0.94 - ETA: 3:54 - loss: 0.1518 - accuracy: 0.94 - ETA: 3:52 - loss: 0.1533 - accuracy: 0.94 - ETA: 3:49 - loss: 0.1549 - accuracy: 0.94 - ETA: 3:48 - loss: 0.1486 - accuracy: 0.94 - ETA: 3:46 - loss: 0.1451 - accuracy: 0.94 - ETA: 3:44 - loss: 0.1462 - accuracy: 0.94 - ETA: 3:44 - loss: 0.1483 - accuracy: 0.94 - ETA: 3:42 - loss: 0.1474 - accuracy: 0.94 - ETA: 3:42 - loss: 0.1476 - accuracy: 0.94 - ETA: 3:39 - loss: 0.1499 - accuracy: 0.94 - ETA: 3:38 - loss: 0.1532 - accuracy: 0.94 - ETA: 3:36 - loss: 0.1578 - accuracy: 0.94 - ETA: 3:35 - loss: 0.1576 - accuracy: 0.94 - ETA: 3:34 - loss: 0.1581 - accuracy: 0.94 - ETA: 3:32 - loss: 0.1592 - accuracy: 0.94 - ETA: 3:31 - loss: 0.1607 - accuracy: 0.94 - ETA: 3:28 - loss: 0.1635 - accuracy: 0.94 - ETA: 3:27 - loss: 0.1625 - accuracy: 0.94 - ETA: 3:25 - loss: 0.1622 - accuracy: 0.94 - ETA: 3:24 - loss: 0.1607 - accuracy: 0.94 - ETA: 3:22 - loss: 0.1590 - accuracy: 0.94 - ETA: 3:20 - loss: 0.1624 - accuracy: 0.94 - ETA: 3:19 - loss: 0.1639 - accuracy: 0.94 - ETA: 3:17 - loss: 0.1631 - accuracy: 0.94 - ETA: 3:15 - loss: 0.1643 - accuracy: 0.94 - ETA: 3:13 - loss: 0.1637 - accuracy: 0.94 - ETA: 3:12 - loss: 0.1627 - accuracy: 0.94 - ETA: 3:10 - loss: 0.1601 - accuracy: 0.94 - ETA: 3:09 - loss: 0.1596 - accuracy: 0.94 - ETA: 3:07 - loss: 0.1604 - accuracy: 0.94 - ETA: 3:05 - loss: 0.1593 - accuracy: 0.94 - ETA: 3:03 - loss: 0.1603 - accuracy: 0.94 - ETA: 3:01 - loss: 0.1599 - accuracy: 0.94 - ETA: 2:59 - loss: 0.1617 - accuracy: 0.94 - ETA: 2:58 - loss: 0.1608 - accuracy: 0.94 - ETA: 2:56 - loss: 0.1592 - accuracy: 0.94 - ETA: 2:54 - loss: 0.1583 - accuracy: 0.94 - ETA: 2:53 - loss: 0.1568 - accuracy: 0.94 - ETA: 2:51 - loss: 0.1560 - accuracy: 0.94 - ETA: 2:49 - loss: 0.1550 - accuracy: 0.94 - ETA: 2:48 - loss: 0.1547 - accuracy: 0.94 - ETA: 2:46 - loss: 0.1537 - accuracy: 0.94 - ETA: 2:44 - loss: 0.1549 - accuracy: 0.94 - ETA: 2:43 - loss: 0.1562 - accuracy: 0.94 - ETA: 2:41 - loss: 0.1561 - accuracy: 0.94 - ETA: 2:39 - loss: 0.1558 - accuracy: 0.94 - ETA: 2:38 - loss: 0.1565 - accuracy: 0.94 - ETA: 2:36 - loss: 0.1561 - accuracy: 0.94 - ETA: 2:34 - loss: 0.1555 - accuracy: 0.95 - ETA: 2:33 - loss: 0.1549 - accuracy: 0.95 - ETA: 2:31 - loss: 0.1555 - accuracy: 0.94 - ETA: 2:29 - loss: 0.1546 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1541 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1535 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1544 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1541 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1545 - accuracy: 0.94 - ETA: 2:19 - loss: 0.1544 - accuracy: 0.94 - ETA: 2:17 - loss: 0.1539 - accuracy: 0.94 - ETA: 2:15 - loss: 0.1527 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1529 - accuracy: 0.94 - ETA: 2:12 - loss: 0.1516 - accuracy: 0.95 - ETA: 2:10 - loss: 0.1516 - accuracy: 0.95 - ETA: 2:08 - loss: 0.1523 - accuracy: 0.94 - ETA: 2:06 - loss: 0.1519 - accuracy: 0.95 - ETA: 2:05 - loss: 0.1524 - accuracy: 0.94 - ETA: 2:03 - loss: 0.1516 - accuracy: 0.95 - ETA: 2:01 - loss: 0.1527 - accuracy: 0.94 - ETA: 1:59 - loss: 0.1541 - accuracy: 0.94 - ETA: 1:58 - loss: 0.1534 - accuracy: 0.94 - ETA: 1:56 - loss: 0.1525 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1535 - accuracy: 0.94 - ETA: 1:53 - loss: 0.1529 - accuracy: 0.95 - ETA: 1:51 - loss: 0.1520 - accuracy: 0.95 - ETA: 1:49 - loss: 0.1508 - accuracy: 0.95 - ETA: 1:47 - loss: 0.1510 - accuracy: 0.95 - ETA: 1:46 - loss: 0.1516 - accuracy: 0.95 - ETA: 1:44 - loss: 0.1509 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1504 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1511 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1509 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1505 - accuracy: 0.95 - ETA: 1:36 - loss: 0.1510 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1504 - accuracy: 0.95 - ETA: 1:33 - loss: 0.1503 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1506 - accuracy: 0.95 - ETA: 1:29 - loss: 0.1494 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1500 - accuracy: 0.95 - ETA: 1:26 - loss: 0.1493 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1493 - accuracy: 0.95 - ETA: 1:22 - loss: 0.1492 - accuracy: 0.95 - ETA: 1:20 - loss: 0.1490 - accuracy: 0.95 - ETA: 1:19 - loss: 0.1483 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1484 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1484 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1484 - accuracy: 0.95 - ETA: 1:12 - loss: 0.1477 - accuracy: 0.95 - ETA: 1:10 - loss: 0.1474 - accuracy: 0.95 - ETA: 1:08 - loss: 0.1477 - accuracy: 0.95 - ETA: 1:07 - loss: 0.1477 - accuracy: 0.95 - ETA: 1:05 - loss: 0.1475 - accuracy: 0.95 - ETA: 1:03 - loss: 0.1472 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1473 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1469 - accuracy: 0.95 - ETA: 58s - loss: 0.1466 - accuracy: 0.9527 - ETA: 56s - loss: 0.1467 - accuracy: 0.952 - ETA: 54s - loss: 0.1473 - accuracy: 0.952 - ETA: 53s - loss: 0.1474 - accuracy: 0.952 - ETA: 51s - loss: 0.1469 - accuracy: 0.952 - ETA: 49s - loss: 0.1467 - accuracy: 0.952 - ETA: 48s - loss: 0.1470 - accuracy: 0.952 - ETA: 46s - loss: 0.1472 - accuracy: 0.952 - ETA: 44s - loss: 0.1469 - accuracy: 0.952 - ETA: 42s - loss: 0.1466 - accuracy: 0.952 - ETA: 41s - loss: 0.1476 - accuracy: 0.952 - ETA: 39s - loss: 0.1480 - accuracy: 0.952 - ETA: 37s - loss: 0.1475 - accuracy: 0.952 - ETA: 35s - loss: 0.1476 - accuracy: 0.952 - ETA: 34s - loss: 0.1471 - accuracy: 0.952 - ETA: 32s - loss: 0.1476 - accuracy: 0.952 - ETA: 30s - loss: 0.1472 - accuracy: 0.952 - ETA: 29s - loss: 0.1469 - accuracy: 0.952 - ETA: 27s - loss: 0.1481 - accuracy: 0.951 - ETA: 25s - loss: 0.1479 - accuracy: 0.951 - ETA: 23s - loss: 0.1490 - accuracy: 0.951 - ETA: 22s - loss: 0.1492 - accuracy: 0.951 - ETA: 20s - loss: 0.1488 - accuracy: 0.951 - ETA: 18s - loss: 0.1492 - accuracy: 0.951 - ETA: 17s - loss: 0.1490 - accuracy: 0.951 - ETA: 15s - loss: 0.1487 - accuracy: 0.951 - ETA: 13s - loss: 0.1498 - accuracy: 0.951 - ETA: 11s - loss: 0.1502 - accuracy: 0.951 - ETA: 10s - loss: 0.1513 - accuracy: 0.951 - ETA: 8s - loss: 0.1511 - accuracy: 0.951 - ETA: 6s - loss: 0.1509 - accuracy: 0.95 - ETA: 4s - loss: 0.1504 - accuracy: 0.95 - ETA: 3s - loss: 0.1506 - accuracy: 0.95 - ETA: 1s - loss: 0.1505 - accuracy: 0.95 - 285s 15ms/step - loss: 0.1507 - accuracy: 0.9514 - val_loss: 1.2669 - val_accuracy: 0.7966\n",
      "Epoch 26/100\n",
      "19312/19312 [==============================] - ETA: 4:21 - loss: 0.1215 - accuracy: 0.93 - ETA: 4:22 - loss: 0.1340 - accuracy: 0.94 - ETA: 4:21 - loss: 0.1358 - accuracy: 0.94 - ETA: 4:20 - loss: 0.1490 - accuracy: 0.94 - ETA: 4:15 - loss: 0.1504 - accuracy: 0.94 - ETA: 4:12 - loss: 0.1522 - accuracy: 0.94 - ETA: 4:13 - loss: 0.1414 - accuracy: 0.94 - ETA: 4:10 - loss: 0.1396 - accuracy: 0.95 - ETA: 4:08 - loss: 0.1423 - accuracy: 0.95 - ETA: 4:05 - loss: 0.1392 - accuracy: 0.95 - ETA: 4:02 - loss: 0.1382 - accuracy: 0.95 - ETA: 4:00 - loss: 0.1323 - accuracy: 0.95 - ETA: 3:59 - loss: 0.1345 - accuracy: 0.95 - ETA: 3:57 - loss: 0.1312 - accuracy: 0.95 - ETA: 3:55 - loss: 0.1336 - accuracy: 0.95 - ETA: 3:53 - loss: 0.1311 - accuracy: 0.95 - ETA: 3:52 - loss: 0.1315 - accuracy: 0.95 - ETA: 3:50 - loss: 0.1320 - accuracy: 0.95 - ETA: 3:48 - loss: 0.1377 - accuracy: 0.95 - ETA: 3:46 - loss: 0.1376 - accuracy: 0.95 - ETA: 3:45 - loss: 0.1348 - accuracy: 0.95 - ETA: 3:44 - loss: 0.1334 - accuracy: 0.95 - ETA: 3:41 - loss: 0.1337 - accuracy: 0.95 - ETA: 3:39 - loss: 0.1353 - accuracy: 0.95 - ETA: 3:37 - loss: 0.1391 - accuracy: 0.95 - ETA: 3:35 - loss: 0.1415 - accuracy: 0.95 - ETA: 3:33 - loss: 0.1394 - accuracy: 0.95 - ETA: 3:32 - loss: 0.1383 - accuracy: 0.95 - ETA: 3:30 - loss: 0.1374 - accuracy: 0.95 - ETA: 3:29 - loss: 0.1363 - accuracy: 0.95 - ETA: 3:27 - loss: 0.1333 - accuracy: 0.95 - ETA: 3:26 - loss: 0.1312 - accuracy: 0.95 - ETA: 3:23 - loss: 0.1314 - accuracy: 0.95 - ETA: 3:22 - loss: 0.1313 - accuracy: 0.95 - ETA: 3:20 - loss: 0.1349 - accuracy: 0.95 - ETA: 3:18 - loss: 0.1350 - accuracy: 0.95 - ETA: 3:16 - loss: 0.1337 - accuracy: 0.95 - ETA: 3:14 - loss: 0.1327 - accuracy: 0.95 - ETA: 3:13 - loss: 0.1320 - accuracy: 0.95 - ETA: 3:11 - loss: 0.1320 - accuracy: 0.95 - ETA: 3:09 - loss: 0.1344 - accuracy: 0.95 - ETA: 3:07 - loss: 0.1341 - accuracy: 0.95 - ETA: 3:05 - loss: 0.1339 - accuracy: 0.95 - ETA: 3:04 - loss: 0.1326 - accuracy: 0.95 - ETA: 3:02 - loss: 0.1319 - accuracy: 0.95 - ETA: 3:00 - loss: 0.1315 - accuracy: 0.95 - ETA: 2:59 - loss: 0.1327 - accuracy: 0.95 - ETA: 2:57 - loss: 0.1329 - accuracy: 0.95 - ETA: 2:55 - loss: 0.1337 - accuracy: 0.95 - ETA: 2:53 - loss: 0.1329 - accuracy: 0.95 - ETA: 2:51 - loss: 0.1324 - accuracy: 0.95 - ETA: 2:50 - loss: 0.1324 - accuracy: 0.95 - ETA: 2:48 - loss: 0.1327 - accuracy: 0.95 - ETA: 2:46 - loss: 0.1328 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1323 - accuracy: 0.95 - ETA: 2:43 - loss: 0.1321 - accuracy: 0.95 - ETA: 2:41 - loss: 0.1311 - accuracy: 0.95 - ETA: 2:39 - loss: 0.1305 - accuracy: 0.95 - ETA: 2:38 - loss: 0.1296 - accuracy: 0.95 - ETA: 2:36 - loss: 0.1304 - accuracy: 0.95 - ETA: 2:35 - loss: 0.1306 - accuracy: 0.95 - ETA: 2:33 - loss: 0.1320 - accuracy: 0.95 - ETA: 2:31 - loss: 0.1325 - accuracy: 0.95 - ETA: 2:29 - loss: 0.1325 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1333 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1339 - accuracy: 0.95 - ETA: 2:25 - loss: 0.1338 - accuracy: 0.95 - ETA: 2:23 - loss: 0.1339 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1341 - accuracy: 0.95 - ETA: 2:19 - loss: 0.1339 - accuracy: 0.95 - ETA: 2:18 - loss: 0.1336 - accuracy: 0.95 - ETA: 2:16 - loss: 0.1358 - accuracy: 0.95 - ETA: 2:14 - loss: 0.1375 - accuracy: 0.95 - ETA: 2:12 - loss: 0.1374 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1375 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1386 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1375 - accuracy: 0.95 - ETA: 2:06 - loss: 0.1365 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1362 - accuracy: 0.95 - ETA: 2:02 - loss: 0.1365 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1359 - accuracy: 0.95 - ETA: 1:58 - loss: 0.1364 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1365 - accuracy: 0.95 - ETA: 1:55 - loss: 0.1367 - accuracy: 0.95 - ETA: 1:53 - loss: 0.1367 - accuracy: 0.95 - ETA: 1:51 - loss: 0.1362 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1358 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1358 - accuracy: 0.95 - ETA: 1:46 - loss: 0.1362 - accuracy: 0.95 - ETA: 1:44 - loss: 0.1377 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1380 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1378 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1388 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1391 - accuracy: 0.95 - ETA: 1:36 - loss: 0.1394 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1385 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1384 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1383 - accuracy: 0.95 - ETA: 1:29 - loss: 0.1384 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1389 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1386 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1382 - accuracy: 0.95 - ETA: 1:22 - loss: 0.1395 - accuracy: 0.95 - ETA: 1:20 - loss: 0.1393 - accuracy: 0.95 - ETA: 1:19 - loss: 0.1395 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1396 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1395 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1403 - accuracy: 0.95 - ETA: 1:12 - loss: 0.1408 - accuracy: 0.95 - ETA: 1:10 - loss: 0.1417 - accuracy: 0.95 - ETA: 1:08 - loss: 0.1419 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1412 - accuracy: 0.95 - ETA: 1:05 - loss: 0.1414 - accuracy: 0.95 - ETA: 1:03 - loss: 0.1421 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1417 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1417 - accuracy: 0.95 - ETA: 58s - loss: 0.1414 - accuracy: 0.9539 - ETA: 56s - loss: 0.1415 - accuracy: 0.953 - ETA: 54s - loss: 0.1409 - accuracy: 0.954 - ETA: 53s - loss: 0.1409 - accuracy: 0.953 - ETA: 51s - loss: 0.1413 - accuracy: 0.953 - ETA: 49s - loss: 0.1409 - accuracy: 0.953 - ETA: 48s - loss: 0.1409 - accuracy: 0.953 - ETA: 46s - loss: 0.1402 - accuracy: 0.954 - ETA: 44s - loss: 0.1403 - accuracy: 0.953 - ETA: 42s - loss: 0.1397 - accuracy: 0.954 - ETA: 41s - loss: 0.1394 - accuracy: 0.954 - ETA: 39s - loss: 0.1391 - accuracy: 0.954 - ETA: 37s - loss: 0.1395 - accuracy: 0.954 - ETA: 35s - loss: 0.1394 - accuracy: 0.954 - ETA: 34s - loss: 0.1390 - accuracy: 0.954 - ETA: 32s - loss: 0.1386 - accuracy: 0.954 - ETA: 30s - loss: 0.1389 - accuracy: 0.954 - ETA: 29s - loss: 0.1393 - accuracy: 0.954 - ETA: 27s - loss: 0.1394 - accuracy: 0.954 - ETA: 25s - loss: 0.1402 - accuracy: 0.954 - ETA: 23s - loss: 0.1404 - accuracy: 0.954 - ETA: 22s - loss: 0.1401 - accuracy: 0.954 - ETA: 20s - loss: 0.1399 - accuracy: 0.954 - ETA: 18s - loss: 0.1395 - accuracy: 0.954 - ETA: 17s - loss: 0.1396 - accuracy: 0.954 - ETA: 15s - loss: 0.1401 - accuracy: 0.954 - ETA: 13s - loss: 0.1397 - accuracy: 0.954 - ETA: 11s - loss: 0.1404 - accuracy: 0.954 - ETA: 10s - loss: 0.1410 - accuracy: 0.953 - ETA: 8s - loss: 0.1409 - accuracy: 0.953 - ETA: 6s - loss: 0.1420 - accuracy: 0.95 - ETA: 4s - loss: 0.1422 - accuracy: 0.95 - ETA: 3s - loss: 0.1419 - accuracy: 0.95 - ETA: 1s - loss: 0.1419 - accuracy: 0.95 - 285s 15ms/step - loss: 0.1420 - accuracy: 0.9536 - val_loss: 1.3336 - val_accuracy: 0.7919\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:27 - loss: 0.1003 - accuracy: 0.96 - ETA: 4:26 - loss: 0.0964 - accuracy: 0.96 - ETA: 4:21 - loss: 0.1030 - accuracy: 0.96 - ETA: 4:19 - loss: 0.1070 - accuracy: 0.96 - ETA: 4:16 - loss: 0.1227 - accuracy: 0.95 - ETA: 4:12 - loss: 0.1243 - accuracy: 0.95 - ETA: 4:07 - loss: 0.1283 - accuracy: 0.95 - ETA: 4:05 - loss: 0.1252 - accuracy: 0.95 - ETA: 4:03 - loss: 0.1188 - accuracy: 0.96 - ETA: 4:03 - loss: 0.1125 - accuracy: 0.96 - ETA: 4:02 - loss: 0.1149 - accuracy: 0.96 - ETA: 4:00 - loss: 0.1129 - accuracy: 0.96 - ETA: 3:59 - loss: 0.1113 - accuracy: 0.96 - ETA: 3:57 - loss: 0.1089 - accuracy: 0.96 - ETA: 3:56 - loss: 0.1062 - accuracy: 0.96 - ETA: 3:53 - loss: 0.1023 - accuracy: 0.96 - ETA: 3:52 - loss: 0.0983 - accuracy: 0.96 - ETA: 3:50 - loss: 0.1017 - accuracy: 0.96 - ETA: 3:49 - loss: 0.1055 - accuracy: 0.96 - ETA: 3:45 - loss: 0.1034 - accuracy: 0.96 - ETA: 3:44 - loss: 0.1057 - accuracy: 0.96 - ETA: 3:42 - loss: 0.1066 - accuracy: 0.96 - ETA: 3:40 - loss: 0.1069 - accuracy: 0.96 - ETA: 3:38 - loss: 0.1096 - accuracy: 0.96 - ETA: 3:36 - loss: 0.1089 - accuracy: 0.96 - ETA: 3:34 - loss: 0.1083 - accuracy: 0.96 - ETA: 3:33 - loss: 0.1065 - accuracy: 0.96 - ETA: 3:31 - loss: 0.1086 - accuracy: 0.96 - ETA: 3:29 - loss: 0.1088 - accuracy: 0.96 - ETA: 3:28 - loss: 0.1124 - accuracy: 0.96 - ETA: 3:26 - loss: 0.1113 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1106 - accuracy: 0.96 - ETA: 3:22 - loss: 0.1123 - accuracy: 0.96 - ETA: 3:21 - loss: 0.1121 - accuracy: 0.96 - ETA: 3:19 - loss: 0.1123 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1107 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1096 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1116 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1142 - accuracy: 0.96 - ETA: 3:11 - loss: 0.1141 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1138 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1127 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1140 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1147 - accuracy: 0.96 - ETA: 3:01 - loss: 0.1158 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1167 - accuracy: 0.96 - ETA: 2:58 - loss: 0.1187 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1193 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1206 - accuracy: 0.96 - ETA: 2:52 - loss: 0.1225 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1240 - accuracy: 0.95 - ETA: 2:49 - loss: 0.1232 - accuracy: 0.95 - ETA: 2:48 - loss: 0.1228 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1241 - accuracy: 0.95 - ETA: 2:44 - loss: 0.1266 - accuracy: 0.95 - ETA: 2:42 - loss: 0.1274 - accuracy: 0.95 - ETA: 2:41 - loss: 0.1264 - accuracy: 0.95 - ETA: 2:39 - loss: 0.1283 - accuracy: 0.95 - ETA: 2:37 - loss: 0.1284 - accuracy: 0.95 - ETA: 2:35 - loss: 0.1285 - accuracy: 0.95 - ETA: 2:34 - loss: 0.1279 - accuracy: 0.95 - ETA: 2:32 - loss: 0.1272 - accuracy: 0.95 - ETA: 2:30 - loss: 0.1270 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1285 - accuracy: 0.95 - ETA: 2:27 - loss: 0.1285 - accuracy: 0.95 - ETA: 2:25 - loss: 0.1297 - accuracy: 0.95 - ETA: 2:23 - loss: 0.1320 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1320 - accuracy: 0.95 - ETA: 2:20 - loss: 0.1333 - accuracy: 0.95 - ETA: 2:18 - loss: 0.1333 - accuracy: 0.95 - ETA: 2:17 - loss: 0.1329 - accuracy: 0.95 - ETA: 2:15 - loss: 0.1328 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1352 - accuracy: 0.95 - ETA: 2:12 - loss: 0.1341 - accuracy: 0.95 - ETA: 2:10 - loss: 0.1332 - accuracy: 0.95 - ETA: 2:08 - loss: 0.1326 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1331 - accuracy: 0.95 - ETA: 2:05 - loss: 0.1334 - accuracy: 0.95 - ETA: 2:03 - loss: 0.1341 - accuracy: 0.95 - ETA: 2:01 - loss: 0.1337 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1348 - accuracy: 0.95 - ETA: 1:58 - loss: 0.1352 - accuracy: 0.95 - ETA: 1:56 - loss: 0.1347 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1342 - accuracy: 0.95 - ETA: 1:53 - loss: 0.1355 - accuracy: 0.95 - ETA: 1:51 - loss: 0.1346 - accuracy: 0.95 - ETA: 1:49 - loss: 0.1356 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1350 - accuracy: 0.95 - ETA: 1:46 - loss: 0.1353 - accuracy: 0.95 - ETA: 1:44 - loss: 0.1348 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1347 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1341 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1338 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1338 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1344 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1353 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1363 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1359 - accuracy: 0.95 - ETA: 1:29 - loss: 0.1359 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1373 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1375 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1373 - accuracy: 0.95 - ETA: 1:22 - loss: 0.1373 - accuracy: 0.95 - ETA: 1:20 - loss: 0.1371 - accuracy: 0.95 - ETA: 1:18 - loss: 0.1371 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1369 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1367 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1376 - accuracy: 0.95 - ETA: 1:11 - loss: 0.1374 - accuracy: 0.95 - ETA: 1:10 - loss: 0.1377 - accuracy: 0.95 - ETA: 1:08 - loss: 0.1373 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1374 - accuracy: 0.95 - ETA: 1:05 - loss: 0.1372 - accuracy: 0.95 - ETA: 1:03 - loss: 0.1365 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1362 - accuracy: 0.95 - ETA: 59s - loss: 0.1365 - accuracy: 0.9547 - ETA: 58s - loss: 0.1362 - accuracy: 0.954 - ETA: 56s - loss: 0.1368 - accuracy: 0.954 - ETA: 54s - loss: 0.1361 - accuracy: 0.955 - ETA: 52s - loss: 0.1360 - accuracy: 0.955 - ETA: 51s - loss: 0.1362 - accuracy: 0.955 - ETA: 49s - loss: 0.1359 - accuracy: 0.955 - ETA: 47s - loss: 0.1363 - accuracy: 0.955 - ETA: 46s - loss: 0.1363 - accuracy: 0.955 - ETA: 44s - loss: 0.1365 - accuracy: 0.955 - ETA: 42s - loss: 0.1365 - accuracy: 0.955 - ETA: 41s - loss: 0.1365 - accuracy: 0.955 - ETA: 39s - loss: 0.1363 - accuracy: 0.955 - ETA: 37s - loss: 0.1372 - accuracy: 0.955 - ETA: 35s - loss: 0.1369 - accuracy: 0.955 - ETA: 34s - loss: 0.1378 - accuracy: 0.954 - ETA: 32s - loss: 0.1382 - accuracy: 0.954 - ETA: 30s - loss: 0.1383 - accuracy: 0.954 - ETA: 29s - loss: 0.1383 - accuracy: 0.954 - ETA: 27s - loss: 0.1383 - accuracy: 0.954 - ETA: 25s - loss: 0.1384 - accuracy: 0.954 - ETA: 23s - loss: 0.1382 - accuracy: 0.954 - ETA: 22s - loss: 0.1382 - accuracy: 0.954 - ETA: 20s - loss: 0.1382 - accuracy: 0.954 - ETA: 18s - loss: 0.1378 - accuracy: 0.954 - ETA: 16s - loss: 0.1375 - accuracy: 0.954 - ETA: 15s - loss: 0.1379 - accuracy: 0.954 - ETA: 13s - loss: 0.1379 - accuracy: 0.954 - ETA: 11s - loss: 0.1376 - accuracy: 0.954 - ETA: 10s - loss: 0.1374 - accuracy: 0.954 - ETA: 8s - loss: 0.1369 - accuracy: 0.954 - ETA: 6s - loss: 0.1376 - accuracy: 0.95 - ETA: 4s - loss: 0.1376 - accuracy: 0.95 - ETA: 3s - loss: 0.1369 - accuracy: 0.95 - ETA: 1s - loss: 0.1373 - accuracy: 0.95 - 283s 15ms/step - loss: 0.1371 - accuracy: 0.9549 - val_loss: 1.3243 - val_accuracy: 0.7973\n",
      "Epoch 28/100\n",
      "19312/19312 [==============================] - ETA: 4:11 - loss: 0.1631 - accuracy: 0.94 - ETA: 4:14 - loss: 0.1544 - accuracy: 0.94 - ETA: 4:10 - loss: 0.1551 - accuracy: 0.94 - ETA: 4:09 - loss: 0.1553 - accuracy: 0.94 - ETA: 4:07 - loss: 0.1354 - accuracy: 0.95 - ETA: 4:05 - loss: 0.1183 - accuracy: 0.95 - ETA: 4:04 - loss: 0.1105 - accuracy: 0.96 - ETA: 4:02 - loss: 0.1224 - accuracy: 0.95 - ETA: 4:00 - loss: 0.1139 - accuracy: 0.96 - ETA: 3:57 - loss: 0.1123 - accuracy: 0.96 - ETA: 3:56 - loss: 0.1212 - accuracy: 0.95 - ETA: 3:56 - loss: 0.1184 - accuracy: 0.96 - ETA: 3:54 - loss: 0.1170 - accuracy: 0.96 - ETA: 3:53 - loss: 0.1208 - accuracy: 0.96 - ETA: 3:51 - loss: 0.1193 - accuracy: 0.96 - ETA: 3:50 - loss: 0.1175 - accuracy: 0.96 - ETA: 3:50 - loss: 0.1219 - accuracy: 0.96 - ETA: 3:48 - loss: 0.1234 - accuracy: 0.96 - ETA: 3:46 - loss: 0.1245 - accuracy: 0.95 - ETA: 3:45 - loss: 0.1217 - accuracy: 0.96 - ETA: 3:43 - loss: 0.1182 - accuracy: 0.96 - ETA: 3:41 - loss: 0.1181 - accuracy: 0.96 - ETA: 3:39 - loss: 0.1174 - accuracy: 0.96 - ETA: 3:38 - loss: 0.1172 - accuracy: 0.96 - ETA: 3:36 - loss: 0.1153 - accuracy: 0.96 - ETA: 3:34 - loss: 0.1180 - accuracy: 0.96 - ETA: 3:33 - loss: 0.1170 - accuracy: 0.96 - ETA: 3:31 - loss: 0.1174 - accuracy: 0.96 - ETA: 3:29 - loss: 0.1162 - accuracy: 0.96 - ETA: 3:27 - loss: 0.1216 - accuracy: 0.95 - ETA: 3:25 - loss: 0.1198 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1195 - accuracy: 0.96 - ETA: 3:23 - loss: 0.1175 - accuracy: 0.96 - ETA: 3:21 - loss: 0.1179 - accuracy: 0.96 - ETA: 3:19 - loss: 0.1156 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1145 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1142 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1150 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1147 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1140 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1145 - accuracy: 0.96 - ETA: 3:06 - loss: 0.1153 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1167 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1158 - accuracy: 0.96 - ETA: 3:01 - loss: 0.1215 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1218 - accuracy: 0.95 - ETA: 2:58 - loss: 0.1213 - accuracy: 0.95 - ETA: 2:56 - loss: 0.1213 - accuracy: 0.96 - ETA: 2:55 - loss: 0.1222 - accuracy: 0.95 - ETA: 2:53 - loss: 0.1219 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1219 - accuracy: 0.95 - ETA: 2:50 - loss: 0.1215 - accuracy: 0.96 - ETA: 2:48 - loss: 0.1215 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1212 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1210 - accuracy: 0.95 - ETA: 2:43 - loss: 0.1216 - accuracy: 0.95 - ETA: 2:41 - loss: 0.1219 - accuracy: 0.95 - ETA: 2:39 - loss: 0.1222 - accuracy: 0.95 - ETA: 2:38 - loss: 0.1234 - accuracy: 0.95 - ETA: 2:36 - loss: 0.1260 - accuracy: 0.95 - ETA: 2:34 - loss: 0.1272 - accuracy: 0.95 - ETA: 2:32 - loss: 0.1275 - accuracy: 0.95 - ETA: 2:31 - loss: 0.1269 - accuracy: 0.95 - ETA: 2:29 - loss: 0.1262 - accuracy: 0.95 - ETA: 2:27 - loss: 0.1257 - accuracy: 0.95 - ETA: 2:25 - loss: 0.1275 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1284 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1274 - accuracy: 0.95 - ETA: 2:20 - loss: 0.1270 - accuracy: 0.95 - ETA: 2:19 - loss: 0.1277 - accuracy: 0.95 - ETA: 2:17 - loss: 0.1272 - accuracy: 0.95 - ETA: 2:15 - loss: 0.1279 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1277 - accuracy: 0.95 - ETA: 2:12 - loss: 0.1284 - accuracy: 0.95 - ETA: 2:10 - loss: 0.1284 - accuracy: 0.95 - ETA: 2:08 - loss: 0.1282 - accuracy: 0.95 - ETA: 2:06 - loss: 0.1280 - accuracy: 0.95 - ETA: 2:05 - loss: 0.1277 - accuracy: 0.95 - ETA: 2:03 - loss: 0.1280 - accuracy: 0.95 - ETA: 2:01 - loss: 0.1279 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1284 - accuracy: 0.95 - ETA: 1:58 - loss: 0.1274 - accuracy: 0.95 - ETA: 1:56 - loss: 0.1273 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1276 - accuracy: 0.95 - ETA: 1:53 - loss: 0.1280 - accuracy: 0.95 - ETA: 1:51 - loss: 0.1278 - accuracy: 0.95 - ETA: 1:49 - loss: 0.1275 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1288 - accuracy: 0.95 - ETA: 1:46 - loss: 0.1291 - accuracy: 0.95 - ETA: 1:44 - loss: 0.1293 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1296 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1303 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1294 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1298 - accuracy: 0.95 - ETA: 1:36 - loss: 0.1298 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1300 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1290 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1286 - accuracy: 0.95 - ETA: 1:29 - loss: 0.1284 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1277 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1275 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1287 - accuracy: 0.95 - ETA: 1:22 - loss: 0.1289 - accuracy: 0.95 - ETA: 1:20 - loss: 0.1282 - accuracy: 0.95 - ETA: 1:18 - loss: 0.1283 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1288 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1283 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1286 - accuracy: 0.95 - ETA: 1:12 - loss: 0.1282 - accuracy: 0.95 - ETA: 1:10 - loss: 0.1280 - accuracy: 0.95 - ETA: 1:08 - loss: 0.1275 - accuracy: 0.95 - ETA: 1:07 - loss: 0.1277 - accuracy: 0.95 - ETA: 1:05 - loss: 0.1278 - accuracy: 0.95 - ETA: 1:03 - loss: 0.1283 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1281 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1282 - accuracy: 0.95 - ETA: 58s - loss: 0.1287 - accuracy: 0.9572 - ETA: 56s - loss: 0.1286 - accuracy: 0.957 - ETA: 54s - loss: 0.1282 - accuracy: 0.957 - ETA: 53s - loss: 0.1280 - accuracy: 0.957 - ETA: 51s - loss: 0.1275 - accuracy: 0.957 - ETA: 49s - loss: 0.1274 - accuracy: 0.957 - ETA: 48s - loss: 0.1277 - accuracy: 0.957 - ETA: 46s - loss: 0.1278 - accuracy: 0.957 - ETA: 44s - loss: 0.1276 - accuracy: 0.957 - ETA: 42s - loss: 0.1277 - accuracy: 0.957 - ETA: 41s - loss: 0.1277 - accuracy: 0.957 - ETA: 39s - loss: 0.1284 - accuracy: 0.957 - ETA: 37s - loss: 0.1287 - accuracy: 0.956 - ETA: 36s - loss: 0.1290 - accuracy: 0.956 - ETA: 34s - loss: 0.1296 - accuracy: 0.956 - ETA: 32s - loss: 0.1296 - accuracy: 0.956 - ETA: 30s - loss: 0.1299 - accuracy: 0.956 - ETA: 29s - loss: 0.1302 - accuracy: 0.956 - ETA: 27s - loss: 0.1304 - accuracy: 0.956 - ETA: 25s - loss: 0.1297 - accuracy: 0.956 - ETA: 23s - loss: 0.1299 - accuracy: 0.956 - ETA: 22s - loss: 0.1295 - accuracy: 0.956 - ETA: 20s - loss: 0.1298 - accuracy: 0.956 - ETA: 18s - loss: 0.1307 - accuracy: 0.956 - ETA: 17s - loss: 0.1305 - accuracy: 0.956 - ETA: 15s - loss: 0.1299 - accuracy: 0.957 - ETA: 13s - loss: 0.1303 - accuracy: 0.956 - ETA: 11s - loss: 0.1297 - accuracy: 0.957 - ETA: 10s - loss: 0.1300 - accuracy: 0.957 - ETA: 8s - loss: 0.1304 - accuracy: 0.956 - ETA: 6s - loss: 0.1310 - accuracy: 0.95 - ETA: 4s - loss: 0.1312 - accuracy: 0.95 - ETA: 3s - loss: 0.1309 - accuracy: 0.95 - ETA: 1s - loss: 0.1306 - accuracy: 0.95 - 287s 15ms/step - loss: 0.1308 - accuracy: 0.9571 - val_loss: 1.3490 - val_accuracy: 0.7927\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:59 - loss: 0.1483 - accuracy: 0.96 - ETA: 4:06 - loss: 0.1828 - accuracy: 0.94 - ETA: 4:04 - loss: 0.1645 - accuracy: 0.95 - ETA: 4:08 - loss: 0.1711 - accuracy: 0.94 - ETA: 4:05 - loss: 0.1525 - accuracy: 0.95 - ETA: 4:04 - loss: 0.1392 - accuracy: 0.95 - ETA: 4:04 - loss: 0.1260 - accuracy: 0.95 - ETA: 4:03 - loss: 0.1309 - accuracy: 0.95 - ETA: 3:59 - loss: 0.1293 - accuracy: 0.95 - ETA: 3:57 - loss: 0.1249 - accuracy: 0.95 - ETA: 3:54 - loss: 0.1264 - accuracy: 0.95 - ETA: 3:53 - loss: 0.1218 - accuracy: 0.95 - ETA: 3:53 - loss: 0.1209 - accuracy: 0.95 - ETA: 3:53 - loss: 0.1145 - accuracy: 0.96 - ETA: 3:51 - loss: 0.1138 - accuracy: 0.96 - ETA: 3:51 - loss: 0.1112 - accuracy: 0.96 - ETA: 3:48 - loss: 0.1135 - accuracy: 0.96 - ETA: 3:48 - loss: 0.1118 - accuracy: 0.96 - ETA: 3:47 - loss: 0.1097 - accuracy: 0.96 - ETA: 3:41 - loss: 0.1099 - accuracy: 0.96 - ETA: 3:35 - loss: 0.1104 - accuracy: 0.96 - ETA: 3:30 - loss: 0.1120 - accuracy: 0.96 - ETA: 3:25 - loss: 0.1140 - accuracy: 0.96 - ETA: 35:35:50 - loss: 0.1186 - accuracy: 0.96 - ETA: 33:54:25 - loss: 0.1234 - accuracy: 0.95 - ETA: 32:20:52 - loss: 0.1242 - accuracy: 0.95 - ETA: 30:54:13 - loss: 0.1269 - accuracy: 0.95 - ETA: 29:33:50 - loss: 0.1271 - accuracy: 0.95 - ETA: 28:18:49 - loss: 0.1297 - accuracy: 0.95 - ETA: 27:08:52 - loss: 0.1300 - accuracy: 0.95 - ETA: 26:03:21 - loss: 0.1293 - accuracy: 0.95 - ETA: 25:01:57 - loss: 0.1311 - accuracy: 0.95 - ETA: 24:04:16 - loss: 0.1280 - accuracy: 0.95 - ETA: 23:09:58 - loss: 0.1273 - accuracy: 0.95 - ETA: 22:18:46 - loss: 0.1274 - accuracy: 0.95 - ETA: 21:30:26 - loss: 0.1274 - accuracy: 0.95 - ETA: 20:44:41 - loss: 0.1256 - accuracy: 0.95 - ETA: 20:01:21 - loss: 0.1249 - accuracy: 0.95 - ETA: 19:20:15 - loss: 0.1257 - accuracy: 0.95 - ETA: 18:41:11 - loss: 0.1275 - accuracy: 0.95 - ETA: 18:04:02 - loss: 0.1273 - accuracy: 0.95 - ETA: 17:28:39 - loss: 0.1287 - accuracy: 0.95 - ETA: 16:54:55 - loss: 0.1274 - accuracy: 0.95 - ETA: 16:22:43 - loss: 0.1276 - accuracy: 0.95 - ETA: 15:51:56 - loss: 0.1263 - accuracy: 0.95 - ETA: 15:22:30 - loss: 0.1273 - accuracy: 0.95 - ETA: 14:54:18 - loss: 0.1272 - accuracy: 0.95 - ETA: 14:27:17 - loss: 0.1269 - accuracy: 0.95 - ETA: 14:01:23 - loss: 0.1270 - accuracy: 0.95 - ETA: 13:36:30 - loss: 0.1269 - accuracy: 0.95 - ETA: 13:12:36 - loss: 0.1269 - accuracy: 0.95 - ETA: 12:49:37 - loss: 0.1264 - accuracy: 0.95 - ETA: 12:27:30 - loss: 0.1269 - accuracy: 0.95 - ETA: 12:06:12 - loss: 0.1272 - accuracy: 0.95 - ETA: 11:45:40 - loss: 0.1274 - accuracy: 0.95 - ETA: 11:25:52 - loss: 0.1267 - accuracy: 0.95 - ETA: 11:06:46 - loss: 0.1257 - accuracy: 0.95 - ETA: 10:48:20 - loss: 0.1251 - accuracy: 0.95 - ETA: 10:30:31 - loss: 0.1251 - accuracy: 0.95 - ETA: 10:13:17 - loss: 0.1250 - accuracy: 0.95 - ETA: 9:56:38 - loss: 0.1249 - accuracy: 0.9585 - ETA: 9:40:30 - loss: 0.1244 - accuracy: 0.958 - ETA: 9:24:53 - loss: 0.1235 - accuracy: 0.959 - ETA: 9:09:46 - loss: 0.1228 - accuracy: 0.959 - ETA: 8:55:06 - loss: 0.1217 - accuracy: 0.959 - ETA: 8:40:53 - loss: 0.1213 - accuracy: 0.959 - ETA: 8:27:05 - loss: 0.1201 - accuracy: 0.959 - ETA: 8:13:42 - loss: 0.1205 - accuracy: 0.959 - ETA: 8:00:42 - loss: 0.1200 - accuracy: 0.959 - ETA: 7:48:04 - loss: 0.1199 - accuracy: 0.959 - ETA: 7:35:48 - loss: 0.1190 - accuracy: 0.959 - ETA: 7:23:52 - loss: 0.1179 - accuracy: 0.960 - ETA: 7:12:15 - loss: 0.1192 - accuracy: 0.959 - ETA: 7:00:57 - loss: 0.1190 - accuracy: 0.960 - ETA: 6:49:57 - loss: 0.1183 - accuracy: 0.960 - ETA: 6:39:15 - loss: 0.1189 - accuracy: 0.959 - ETA: 6:28:49 - loss: 0.1180 - accuracy: 0.960 - ETA: 6:18:39 - loss: 0.1173 - accuracy: 0.960 - ETA: 6:08:45 - loss: 0.1174 - accuracy: 0.960 - ETA: 5:59:05 - loss: 0.1177 - accuracy: 0.960 - ETA: 5:49:40 - loss: 0.1173 - accuracy: 0.960 - ETA: 5:40:28 - loss: 0.1164 - accuracy: 0.960 - ETA: 5:31:30 - loss: 0.1160 - accuracy: 0.960 - ETA: 5:22:45 - loss: 0.1151 - accuracy: 0.960 - ETA: 5:14:12 - loss: 0.1147 - accuracy: 0.960 - ETA: 5:05:51 - loss: 0.1153 - accuracy: 0.960 - ETA: 4:57:41 - loss: 0.1148 - accuracy: 0.960 - ETA: 4:49:42 - loss: 0.1147 - accuracy: 0.960 - ETA: 4:41:54 - loss: 0.1137 - accuracy: 0.960 - ETA: 4:34:17 - loss: 0.1130 - accuracy: 0.960 - ETA: 4:26:49 - loss: 0.1133 - accuracy: 0.960 - ETA: 4:19:32 - loss: 0.1127 - accuracy: 0.961 - ETA: 4:12:23 - loss: 0.1126 - accuracy: 0.961 - ETA: 4:05:24 - loss: 0.1126 - accuracy: 0.961 - ETA: 3:58:33 - loss: 0.1122 - accuracy: 0.961 - ETA: 3:51:51 - loss: 0.1117 - accuracy: 0.961 - ETA: 3:45:18 - loss: 0.1121 - accuracy: 0.961 - ETA: 3:38:52 - loss: 0.1118 - accuracy: 0.961 - ETA: 3:32:34 - loss: 0.1118 - accuracy: 0.961 - ETA: 3:26:24 - loss: 0.1112 - accuracy: 0.961 - ETA: 3:20:21 - loss: 0.1110 - accuracy: 0.961 - ETA: 3:14:25 - loss: 0.1107 - accuracy: 0.961 - ETA: 3:08:36 - loss: 0.1106 - accuracy: 0.961 - ETA: 3:02:54 - loss: 0.1100 - accuracy: 0.961 - ETA: 2:57:18 - loss: 0.1109 - accuracy: 0.961 - ETA: 2:51:48 - loss: 0.1109 - accuracy: 0.961 - ETA: 2:46:25 - loss: 0.1122 - accuracy: 0.961 - ETA: 2:41:07 - loss: 0.1131 - accuracy: 0.960 - ETA: 2:35:56 - loss: 0.1134 - accuracy: 0.960 - ETA: 2:30:50 - loss: 0.1128 - accuracy: 0.961 - ETA: 2:25:49 - loss: 0.1120 - accuracy: 0.961 - ETA: 2:20:54 - loss: 0.1120 - accuracy: 0.961 - ETA: 2:16:04 - loss: 0.1121 - accuracy: 0.961 - ETA: 2:11:19 - loss: 0.1114 - accuracy: 0.961 - ETA: 2:06:39 - loss: 0.1117 - accuracy: 0.961 - ETA: 2:02:04 - loss: 0.1113 - accuracy: 0.961 - ETA: 1:57:33 - loss: 0.1107 - accuracy: 0.962 - ETA: 1:53:07 - loss: 0.1099 - accuracy: 0.962 - ETA: 1:48:46 - loss: 0.1097 - accuracy: 0.962 - ETA: 1:44:29 - loss: 0.1095 - accuracy: 0.962 - ETA: 1:40:16 - loss: 0.1102 - accuracy: 0.962 - ETA: 1:36:07 - loss: 0.1103 - accuracy: 0.962 - ETA: 1:32:02 - loss: 0.1121 - accuracy: 0.962 - ETA: 1:28:02 - loss: 0.1123 - accuracy: 0.961 - ETA: 1:24:05 - loss: 0.1122 - accuracy: 0.961 - ETA: 1:20:11 - loss: 0.1126 - accuracy: 0.961 - ETA: 1:16:22 - loss: 0.1127 - accuracy: 0.962 - ETA: 1:12:36 - loss: 0.1131 - accuracy: 0.961 - ETA: 1:08:53 - loss: 0.1123 - accuracy: 0.961 - ETA: 1:05:14 - loss: 0.1132 - accuracy: 0.961 - ETA: 1:01:38 - loss: 0.1132 - accuracy: 0.961 - ETA: 58:06 - loss: 0.1134 - accuracy: 0.9616  - ETA: 54:36 - loss: 0.1140 - accuracy: 0.961 - ETA: 51:10 - loss: 0.1142 - accuracy: 0.961 - ETA: 47:47 - loss: 0.1142 - accuracy: 0.961 - ETA: 44:27 - loss: 0.1144 - accuracy: 0.961 - ETA: 41:10 - loss: 0.1150 - accuracy: 0.961 - ETA: 37:56 - loss: 0.1158 - accuracy: 0.961 - ETA: 34:44 - loss: 0.1158 - accuracy: 0.961 - ETA: 31:35 - loss: 0.1155 - accuracy: 0.961 - ETA: 28:28 - loss: 0.1153 - accuracy: 0.961 - ETA: 25:25 - loss: 0.1153 - accuracy: 0.961 - ETA: 22:23 - loss: 0.1158 - accuracy: 0.961 - ETA: 19:25 - loss: 0.1156 - accuracy: 0.961 - ETA: 16:28 - loss: 0.1157 - accuracy: 0.961 - ETA: 13:34 - loss: 0.1154 - accuracy: 0.961 - ETA: 10:43 - loss: 0.1156 - accuracy: 0.961 - ETA: 7:54 - loss: 0.1155 - accuracy: 0.961 - ETA: 5:07 - loss: 0.1154 - accuracy: 0.96 - ETA: 2:22 - loss: 0.1161 - accuracy: 0.96 - 24446s 1s/step - loss: 0.1163 - accuracy: 0.9611 - val_loss: 1.3852 - val_accuracy: 0.7929\n",
      "Epoch 30/100\n",
      "19312/19312 [==============================] - ETA: 3:48 - loss: 0.1350 - accuracy: 0.97 - ETA: 3:19 - loss: 0.1070 - accuracy: 0.97 - ETA: 3:29 - loss: 0.1041 - accuracy: 0.97 - ETA: 3:42 - loss: 0.1127 - accuracy: 0.97 - ETA: 3:40 - loss: 0.1166 - accuracy: 0.96 - ETA: 3:37 - loss: 0.1106 - accuracy: 0.96 - ETA: 3:34 - loss: 0.1062 - accuracy: 0.96 - ETA: 3:32 - loss: 0.1054 - accuracy: 0.96 - ETA: 3:30 - loss: 0.1095 - accuracy: 0.96 - ETA: 3:33 - loss: 0.1022 - accuracy: 0.96 - ETA: 3:32 - loss: 0.1014 - accuracy: 0.97 - ETA: 3:31 - loss: 0.1011 - accuracy: 0.96 - ETA: 3:28 - loss: 0.1100 - accuracy: 0.96 - ETA: 3:30 - loss: 0.1147 - accuracy: 0.96 - ETA: 3:29 - loss: 0.1082 - accuracy: 0.97 - ETA: 3:27 - loss: 0.1043 - accuracy: 0.97 - ETA: 3:25 - loss: 0.1119 - accuracy: 0.96 - ETA: 3:23 - loss: 0.1132 - accuracy: 0.96 - ETA: 3:20 - loss: 0.1108 - accuracy: 0.96 - ETA: 3:21 - loss: 0.1069 - accuracy: 0.96 - ETA: 3:19 - loss: 0.1073 - accuracy: 0.96 - ETA: 3:18 - loss: 0.1105 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1095 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1080 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1080 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1084 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1100 - accuracy: 0.96 - ETA: 3:11 - loss: 0.1100 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1120 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1114 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1130 - accuracy: 0.96 - ETA: 3:06 - loss: 0.1123 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1126 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1098 - accuracy: 0.96 - ETA: 3:02 - loss: 0.1089 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1075 - accuracy: 0.96 - ETA: 2:58 - loss: 0.1084 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1091 - accuracy: 0.96 - ETA: 2:55 - loss: 0.1109 - accuracy: 0.96 - ETA: 2:53 - loss: 0.1108 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1139 - accuracy: 0.96 - ETA: 2:50 - loss: 0.1153 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1157 - accuracy: 0.96 - ETA: 2:48 - loss: 0.1149 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1163 - accuracy: 0.96 - ETA: 2:45 - loss: 0.1159 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1178 - accuracy: 0.96 - ETA: 2:41 - loss: 0.1185 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1170 - accuracy: 0.96 - ETA: 2:37 - loss: 0.1166 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1167 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1174 - accuracy: 0.96 - ETA: 2:33 - loss: 0.1178 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1195 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1199 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1191 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1191 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1192 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1200 - accuracy: 0.96 - ETA: 2:22 - loss: 0.1202 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1191 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1196 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1201 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1191 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1199 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1190 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1186 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1185 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1183 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1181 - accuracy: 0.96 - ETA: 2:07 - loss: 0.1181 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1193 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1183 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1187 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1184 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1193 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1198 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1200 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1190 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1197 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1196 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1194 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1187 - accuracy: 0.96 - ETA: 1:47 - loss: 0.1183 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1183 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1177 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1176 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1164 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1158 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1157 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1159 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1154 - accuracy: 0.96 - ETA: 1:32 - loss: 0.1151 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1154 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1161 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1165 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1163 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1165 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1172 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1168 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1160 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1156 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1160 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1159 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1157 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1155 - accuracy: 0.96 - ETA: 1:10 - loss: 0.1156 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1155 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1152 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1147 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1161 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1174 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1169 - accuracy: 0.96 - ETA: 59s - loss: 0.1172 - accuracy: 0.9614 - ETA: 57s - loss: 0.1173 - accuracy: 0.961 - ETA: 55s - loss: 0.1173 - accuracy: 0.961 - ETA: 54s - loss: 0.1170 - accuracy: 0.961 - ETA: 52s - loss: 0.1167 - accuracy: 0.961 - ETA: 50s - loss: 0.1166 - accuracy: 0.961 - ETA: 49s - loss: 0.1166 - accuracy: 0.961 - ETA: 47s - loss: 0.1167 - accuracy: 0.961 - ETA: 46s - loss: 0.1170 - accuracy: 0.961 - ETA: 44s - loss: 0.1167 - accuracy: 0.961 - ETA: 42s - loss: 0.1165 - accuracy: 0.961 - ETA: 41s - loss: 0.1167 - accuracy: 0.961 - ETA: 39s - loss: 0.1169 - accuracy: 0.961 - ETA: 38s - loss: 0.1170 - accuracy: 0.961 - ETA: 36s - loss: 0.1174 - accuracy: 0.961 - ETA: 34s - loss: 0.1175 - accuracy: 0.961 - ETA: 33s - loss: 0.1171 - accuracy: 0.961 - ETA: 31s - loss: 0.1177 - accuracy: 0.961 - ETA: 29s - loss: 0.1181 - accuracy: 0.961 - ETA: 28s - loss: 0.1182 - accuracy: 0.961 - ETA: 26s - loss: 0.1183 - accuracy: 0.961 - ETA: 25s - loss: 0.1188 - accuracy: 0.961 - ETA: 23s - loss: 0.1188 - accuracy: 0.961 - ETA: 21s - loss: 0.1185 - accuracy: 0.961 - ETA: 20s - loss: 0.1180 - accuracy: 0.961 - ETA: 18s - loss: 0.1194 - accuracy: 0.961 - ETA: 17s - loss: 0.1200 - accuracy: 0.961 - ETA: 15s - loss: 0.1206 - accuracy: 0.960 - ETA: 14s - loss: 0.1208 - accuracy: 0.960 - ETA: 12s - loss: 0.1213 - accuracy: 0.960 - ETA: 10s - loss: 0.1212 - accuracy: 0.960 - ETA: 9s - loss: 0.1214 - accuracy: 0.960 - ETA: 7s - loss: 0.1212 - accuracy: 0.96 - ETA: 6s - loss: 0.1218 - accuracy: 0.96 - ETA: 4s - loss: 0.1224 - accuracy: 0.96 - ETA: 2s - loss: 0.1223 - accuracy: 0.96 - ETA: 1s - loss: 0.1223 - accuracy: 0.96 - 276s 14ms/step - loss: 0.1222 - accuracy: 0.9602 - val_loss: 1.4147 - val_accuracy: 0.7921\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:16 - loss: 0.1267 - accuracy: 0.97 - ETA: 4:02 - loss: 0.1517 - accuracy: 0.96 - ETA: 3:57 - loss: 0.1681 - accuracy: 0.96 - ETA: 3:47 - loss: 0.1465 - accuracy: 0.96 - ETA: 3:41 - loss: 0.1460 - accuracy: 0.96 - ETA: 3:40 - loss: 0.1438 - accuracy: 0.96 - ETA: 3:41 - loss: 0.1268 - accuracy: 0.96 - ETA: 3:40 - loss: 0.1165 - accuracy: 0.96 - ETA: 3:36 - loss: 0.1142 - accuracy: 0.96 - ETA: 3:36 - loss: 0.1114 - accuracy: 0.96 - ETA: 3:34 - loss: 0.1188 - accuracy: 0.96 - ETA: 3:35 - loss: 0.1159 - accuracy: 0.96 - ETA: 3:33 - loss: 0.1205 - accuracy: 0.96 - ETA: 3:30 - loss: 0.1209 - accuracy: 0.96 - ETA: 3:28 - loss: 0.1186 - accuracy: 0.96 - ETA: 3:26 - loss: 0.1155 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1139 - accuracy: 0.96 - ETA: 3:22 - loss: 0.1142 - accuracy: 0.96 - ETA: 3:21 - loss: 0.1122 - accuracy: 0.96 - ETA: 3:19 - loss: 0.1104 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1111 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1108 - accuracy: 0.96 - ETA: 3:14 - loss: 0.1136 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1222 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1253 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1253 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1238 - accuracy: 0.96 - ETA: 3:06 - loss: 0.1232 - accuracy: 0.95 - ETA: 3:04 - loss: 0.1243 - accuracy: 0.95 - ETA: 3:03 - loss: 0.1240 - accuracy: 0.95 - ETA: 3:01 - loss: 0.1220 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1227 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1239 - accuracy: 0.95 - ETA: 2:56 - loss: 0.1236 - accuracy: 0.95 - ETA: 2:54 - loss: 0.1224 - accuracy: 0.96 - ETA: 2:53 - loss: 0.1236 - accuracy: 0.95 - ETA: 2:51 - loss: 0.1237 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1236 - accuracy: 0.96 - ETA: 2:48 - loss: 0.1219 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1211 - accuracy: 0.96 - ETA: 2:45 - loss: 0.1212 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1206 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1216 - accuracy: 0.96 - ETA: 2:40 - loss: 0.1239 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1272 - accuracy: 0.96 - ETA: 2:37 - loss: 0.1266 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1274 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1263 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1253 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1252 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1267 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1271 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1256 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1255 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1252 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1248 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1247 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1240 - accuracy: 0.96 - ETA: 2:17 - loss: 0.1242 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1243 - accuracy: 0.96 - ETA: 2:14 - loss: 0.1250 - accuracy: 0.95 - ETA: 2:12 - loss: 0.1244 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1240 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1226 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1237 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1243 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1252 - accuracy: 0.95 - ETA: 2:03 - loss: 0.1245 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1243 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1252 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1258 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1261 - accuracy: 0.95 - ETA: 1:55 - loss: 0.1280 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1274 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1266 - accuracy: 0.95 - ETA: 1:51 - loss: 0.1263 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1264 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1259 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1262 - accuracy: 0.95 - ETA: 1:45 - loss: 0.1260 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1262 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1266 - accuracy: 0.95 - ETA: 1:40 - loss: 0.1266 - accuracy: 0.95 - ETA: 1:39 - loss: 0.1263 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1265 - accuracy: 0.95 - ETA: 1:36 - loss: 0.1263 - accuracy: 0.95 - ETA: 1:34 - loss: 0.1262 - accuracy: 0.95 - ETA: 1:33 - loss: 0.1265 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1261 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1254 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1255 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1254 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1263 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1268 - accuracy: 0.95 - ETA: 1:22 - loss: 0.1263 - accuracy: 0.95 - ETA: 1:21 - loss: 0.1260 - accuracy: 0.95 - ETA: 1:19 - loss: 0.1272 - accuracy: 0.95 - ETA: 1:18 - loss: 0.1272 - accuracy: 0.95 - ETA: 1:16 - loss: 0.1288 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1287 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1277 - accuracy: 0.95 - ETA: 1:12 - loss: 0.1277 - accuracy: 0.95 - ETA: 1:10 - loss: 0.1267 - accuracy: 0.95 - ETA: 1:09 - loss: 0.1269 - accuracy: 0.95 - ETA: 1:07 - loss: 0.1268 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1264 - accuracy: 0.95 - ETA: 1:05 - loss: 0.1266 - accuracy: 0.95 - ETA: 1:03 - loss: 0.1271 - accuracy: 0.95 - ETA: 1:02 - loss: 0.1266 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1271 - accuracy: 0.95 - ETA: 59s - loss: 0.1273 - accuracy: 0.9589 - ETA: 57s - loss: 0.1280 - accuracy: 0.958 - ETA: 56s - loss: 0.1274 - accuracy: 0.959 - ETA: 54s - loss: 0.1271 - accuracy: 0.958 - ETA: 53s - loss: 0.1279 - accuracy: 0.958 - ETA: 52s - loss: 0.1282 - accuracy: 0.958 - ETA: 50s - loss: 0.1283 - accuracy: 0.958 - ETA: 49s - loss: 0.1282 - accuracy: 0.958 - ETA: 47s - loss: 0.1278 - accuracy: 0.958 - ETA: 46s - loss: 0.1274 - accuracy: 0.958 - ETA: 44s - loss: 0.1280 - accuracy: 0.958 - ETA: 43s - loss: 0.1289 - accuracy: 0.958 - ETA: 41s - loss: 0.1289 - accuracy: 0.958 - ETA: 40s - loss: 0.1288 - accuracy: 0.958 - ETA: 38s - loss: 0.1286 - accuracy: 0.958 - ETA: 37s - loss: 0.1288 - accuracy: 0.958 - ETA: 35s - loss: 0.1287 - accuracy: 0.958 - ETA: 34s - loss: 0.1280 - accuracy: 0.958 - ETA: 32s - loss: 0.1277 - accuracy: 0.958 - ETA: 31s - loss: 0.1274 - accuracy: 0.958 - ETA: 29s - loss: 0.1268 - accuracy: 0.958 - ETA: 28s - loss: 0.1274 - accuracy: 0.958 - ETA: 26s - loss: 0.1268 - accuracy: 0.958 - ETA: 25s - loss: 0.1264 - accuracy: 0.959 - ETA: 23s - loss: 0.1266 - accuracy: 0.959 - ETA: 22s - loss: 0.1266 - accuracy: 0.958 - ETA: 20s - loss: 0.1266 - accuracy: 0.958 - ETA: 19s - loss: 0.1271 - accuracy: 0.958 - ETA: 17s - loss: 0.1270 - accuracy: 0.959 - ETA: 16s - loss: 0.1269 - accuracy: 0.959 - ETA: 14s - loss: 0.1270 - accuracy: 0.958 - ETA: 13s - loss: 0.1265 - accuracy: 0.959 - ETA: 11s - loss: 0.1262 - accuracy: 0.959 - ETA: 10s - loss: 0.1266 - accuracy: 0.959 - ETA: 8s - loss: 0.1264 - accuracy: 0.959 - ETA: 7s - loss: 0.1259 - accuracy: 0.95 - ETA: 5s - loss: 0.1258 - accuracy: 0.95 - ETA: 4s - loss: 0.1256 - accuracy: 0.95 - ETA: 2s - loss: 0.1252 - accuracy: 0.95 - ETA: 1s - loss: 0.1252 - accuracy: 0.95 - 259s 13ms/step - loss: 0.1252 - accuracy: 0.9593 - val_loss: 1.4145 - val_accuracy: 0.7948\n",
      "Epoch 32/100\n",
      "19312/19312 [==============================] - ETA: 3:28 - loss: 0.0845 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0880 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0948 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0995 - accuracy: 0.96 - ETA: 3:28 - loss: 0.1093 - accuracy: 0.96 - ETA: 3:25 - loss: 0.1048 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1045 - accuracy: 0.96 - ETA: 3:23 - loss: 0.1020 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1033 - accuracy: 0.96 - ETA: 3:21 - loss: 0.1030 - accuracy: 0.96 - ETA: 3:22 - loss: 0.1071 - accuracy: 0.96 - ETA: 3:21 - loss: 0.1052 - accuracy: 0.96 - ETA: 3:20 - loss: 0.1105 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1101 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1065 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1053 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1148 - accuracy: 0.95 - ETA: 3:12 - loss: 0.1118 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1081 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1054 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1089 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1079 - accuracy: 0.96 - ETA: 3:06 - loss: 0.1056 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1041 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1032 - accuracy: 0.96 - ETA: 3:02 - loss: 0.1031 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1035 - accuracy: 0.96 - ETA: 2:58 - loss: 0.1084 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1064 - accuracy: 0.96 - ETA: 2:55 - loss: 0.1110 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1104 - accuracy: 0.96 - ETA: 2:53 - loss: 0.1096 - accuracy: 0.96 - ETA: 2:52 - loss: 0.1094 - accuracy: 0.96 - ETA: 2:50 - loss: 0.1077 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1069 - accuracy: 0.96 - ETA: 2:47 - loss: 0.1092 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1122 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1116 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1151 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1143 - accuracy: 0.96 - ETA: 2:40 - loss: 0.1139 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1127 - accuracy: 0.96 - ETA: 2:37 - loss: 0.1121 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1119 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1123 - accuracy: 0.96 - ETA: 2:33 - loss: 0.1123 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1114 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1105 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1116 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1107 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1109 - accuracy: 0.96 - ETA: 2:25 - loss: 0.1103 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1119 - accuracy: 0.96 - ETA: 2:22 - loss: 0.1132 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1174 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1166 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1169 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1166 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1164 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1177 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1172 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1162 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1154 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1156 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1144 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1160 - accuracy: 0.96 - ETA: 2:03 - loss: 0.1164 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1162 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1161 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1153 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1160 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1161 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1183 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1179 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1173 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1172 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1179 - accuracy: 0.96 - ETA: 1:47 - loss: 0.1173 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1168 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1160 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1168 - accuracy: 0.96 - ETA: 1:41 - loss: 0.1165 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1155 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1154 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1158 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1156 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1166 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1164 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1157 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1156 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1152 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1156 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1155 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1154 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1154 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1153 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1153 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1149 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1144 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1145 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1142 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1140 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1146 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1152 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1144 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1144 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1147 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1153 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1156 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1151 - accuracy: 0.96 - ETA: 59s - loss: 0.1149 - accuracy: 0.9621 - ETA: 58s - loss: 0.1150 - accuracy: 0.962 - ETA: 57s - loss: 0.1147 - accuracy: 0.962 - ETA: 55s - loss: 0.1145 - accuracy: 0.962 - ETA: 54s - loss: 0.1137 - accuracy: 0.962 - ETA: 52s - loss: 0.1148 - accuracy: 0.962 - ETA: 51s - loss: 0.1150 - accuracy: 0.962 - ETA: 49s - loss: 0.1145 - accuracy: 0.962 - ETA: 48s - loss: 0.1144 - accuracy: 0.962 - ETA: 46s - loss: 0.1143 - accuracy: 0.962 - ETA: 45s - loss: 0.1138 - accuracy: 0.962 - ETA: 43s - loss: 0.1139 - accuracy: 0.962 - ETA: 42s - loss: 0.1141 - accuracy: 0.962 - ETA: 40s - loss: 0.1143 - accuracy: 0.962 - ETA: 39s - loss: 0.1145 - accuracy: 0.962 - ETA: 37s - loss: 0.1140 - accuracy: 0.962 - ETA: 36s - loss: 0.1140 - accuracy: 0.962 - ETA: 34s - loss: 0.1139 - accuracy: 0.962 - ETA: 33s - loss: 0.1137 - accuracy: 0.962 - ETA: 31s - loss: 0.1135 - accuracy: 0.962 - ETA: 30s - loss: 0.1142 - accuracy: 0.962 - ETA: 29s - loss: 0.1140 - accuracy: 0.962 - ETA: 27s - loss: 0.1137 - accuracy: 0.962 - ETA: 26s - loss: 0.1145 - accuracy: 0.962 - ETA: 24s - loss: 0.1144 - accuracy: 0.962 - ETA: 23s - loss: 0.1140 - accuracy: 0.962 - ETA: 21s - loss: 0.1149 - accuracy: 0.962 - ETA: 19s - loss: 0.1145 - accuracy: 0.962 - ETA: 18s - loss: 0.1141 - accuracy: 0.962 - ETA: 16s - loss: 0.1139 - accuracy: 0.962 - ETA: 15s - loss: 0.1141 - accuracy: 0.962 - ETA: 13s - loss: 0.1149 - accuracy: 0.962 - ETA: 12s - loss: 0.1148 - accuracy: 0.962 - ETA: 10s - loss: 0.1145 - accuracy: 0.962 - ETA: 9s - loss: 0.1146 - accuracy: 0.962 - ETA: 7s - loss: 0.1143 - accuracy: 0.96 - ETA: 6s - loss: 0.1140 - accuracy: 0.96 - ETA: 4s - loss: 0.1136 - accuracy: 0.96 - ETA: 2s - loss: 0.1133 - accuracy: 0.96 - ETA: 1s - loss: 0.1131 - accuracy: 0.96 - 262s 14ms/step - loss: 0.1134 - accuracy: 0.9628 - val_loss: 1.4383 - val_accuracy: 0.7958\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:00 - loss: 0.0510 - accuracy: 0.96 - ETA: 3:42 - loss: 0.1183 - accuracy: 0.96 - ETA: 3:33 - loss: 0.1347 - accuracy: 0.95 - ETA: 3:37 - loss: 0.1538 - accuracy: 0.95 - ETA: 3:37 - loss: 0.1358 - accuracy: 0.95 - ETA: 3:34 - loss: 0.1338 - accuracy: 0.95 - ETA: 3:34 - loss: 0.1285 - accuracy: 0.95 - ETA: 3:31 - loss: 0.1336 - accuracy: 0.95 - ETA: 3:29 - loss: 0.1264 - accuracy: 0.96 - ETA: 3:30 - loss: 0.1207 - accuracy: 0.96 - ETA: 3:28 - loss: 0.1226 - accuracy: 0.95 - ETA: 3:26 - loss: 0.1220 - accuracy: 0.95 - ETA: 3:24 - loss: 0.1193 - accuracy: 0.95 - ETA: 3:22 - loss: 0.1250 - accuracy: 0.95 - ETA: 3:20 - loss: 0.1287 - accuracy: 0.95 - ETA: 3:19 - loss: 0.1238 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1217 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1189 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1142 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1163 - accuracy: 0.96 - ETA: 3:11 - loss: 0.1141 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1123 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1119 - accuracy: 0.96 - ETA: 3:06 - loss: 0.1083 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1099 - accuracy: 0.96 - ETA: 3:04 - loss: 0.1078 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1079 - accuracy: 0.96 - ETA: 3:02 - loss: 0.1128 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1141 - accuracy: 0.96 - ETA: 2:59 - loss: 0.1127 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1108 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1111 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1097 - accuracy: 0.96 - ETA: 2:53 - loss: 0.1081 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1081 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1089 - accuracy: 0.96 - ETA: 2:48 - loss: 0.1079 - accuracy: 0.96 - ETA: 2:47 - loss: 0.1082 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1076 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1076 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1078 - accuracy: 0.96 - ETA: 2:41 - loss: 0.1076 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1077 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1056 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1051 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1046 - accuracy: 0.96 - ETA: 2:33 - loss: 0.1044 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1036 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1027 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1022 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1011 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1001 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1022 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1017 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1028 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1052 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1052 - accuracy: 0.96 - ETA: 2:17 - loss: 0.1064 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1055 - accuracy: 0.96 - ETA: 2:14 - loss: 0.1055 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1065 - accuracy: 0.96 - ETA: 2:11 - loss: 0.1063 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1064 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1058 - accuracy: 0.96 - ETA: 2:07 - loss: 0.1056 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1044 - accuracy: 0.96 - ETA: 2:03 - loss: 0.1038 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1049 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1053 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1045 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1043 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1046 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1044 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1046 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1047 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1059 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1079 - accuracy: 0.96 - ETA: 1:47 - loss: 0.1081 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1084 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1089 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1099 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1119 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1114 - accuracy: 0.96 - ETA: 1:39 - loss: 0.1123 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1118 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1115 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1119 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1111 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1107 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1109 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1111 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1102 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1102 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1103 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1105 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1106 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1110 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1116 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1116 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1110 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1108 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1102 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1107 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1112 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1122 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1139 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1142 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1139 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1137 - accuracy: 0.96 - ETA: 1:00 - loss: 0.1132 - accuracy: 0.96 - ETA: 59s - loss: 0.1130 - accuracy: 0.9628 - ETA: 57s - loss: 0.1131 - accuracy: 0.962 - ETA: 56s - loss: 0.1132 - accuracy: 0.962 - ETA: 54s - loss: 0.1130 - accuracy: 0.962 - ETA: 53s - loss: 0.1127 - accuracy: 0.962 - ETA: 51s - loss: 0.1124 - accuracy: 0.963 - ETA: 50s - loss: 0.1124 - accuracy: 0.963 - ETA: 48s - loss: 0.1130 - accuracy: 0.962 - ETA: 47s - loss: 0.1125 - accuracy: 0.963 - ETA: 46s - loss: 0.1121 - accuracy: 0.963 - ETA: 44s - loss: 0.1117 - accuracy: 0.963 - ETA: 43s - loss: 0.1115 - accuracy: 0.963 - ETA: 41s - loss: 0.1114 - accuracy: 0.963 - ETA: 40s - loss: 0.1112 - accuracy: 0.963 - ETA: 38s - loss: 0.1113 - accuracy: 0.963 - ETA: 37s - loss: 0.1119 - accuracy: 0.963 - ETA: 35s - loss: 0.1115 - accuracy: 0.963 - ETA: 34s - loss: 0.1117 - accuracy: 0.963 - ETA: 32s - loss: 0.1121 - accuracy: 0.963 - ETA: 31s - loss: 0.1124 - accuracy: 0.963 - ETA: 29s - loss: 0.1128 - accuracy: 0.963 - ETA: 28s - loss: 0.1129 - accuracy: 0.963 - ETA: 26s - loss: 0.1130 - accuracy: 0.963 - ETA: 25s - loss: 0.1129 - accuracy: 0.963 - ETA: 23s - loss: 0.1124 - accuracy: 0.963 - ETA: 22s - loss: 0.1125 - accuracy: 0.963 - ETA: 20s - loss: 0.1126 - accuracy: 0.963 - ETA: 19s - loss: 0.1124 - accuracy: 0.963 - ETA: 17s - loss: 0.1127 - accuracy: 0.963 - ETA: 16s - loss: 0.1123 - accuracy: 0.963 - ETA: 14s - loss: 0.1127 - accuracy: 0.963 - ETA: 13s - loss: 0.1122 - accuracy: 0.963 - ETA: 11s - loss: 0.1122 - accuracy: 0.963 - ETA: 10s - loss: 0.1121 - accuracy: 0.963 - ETA: 8s - loss: 0.1121 - accuracy: 0.963 - ETA: 7s - loss: 0.1119 - accuracy: 0.96 - ETA: 5s - loss: 0.1121 - accuracy: 0.96 - ETA: 4s - loss: 0.1123 - accuracy: 0.96 - ETA: 2s - loss: 0.1121 - accuracy: 0.96 - ETA: 1s - loss: 0.1119 - accuracy: 0.96 - 256s 13ms/step - loss: 0.1120 - accuracy: 0.9630 - val_loss: 1.3836 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "19312/19312 [==============================] - ETA: 3:11 - loss: 0.0472 - accuracy: 0.98 - ETA: 3:19 - loss: 0.1119 - accuracy: 0.96 - ETA: 3:20 - loss: 0.1167 - accuracy: 0.96 - ETA: 3:21 - loss: 0.1138 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1076 - accuracy: 0.96 - ETA: 3:25 - loss: 0.1138 - accuracy: 0.96 - ETA: 3:25 - loss: 0.1156 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1193 - accuracy: 0.96 - ETA: 3:21 - loss: 0.1152 - accuracy: 0.96 - ETA: 3:18 - loss: 0.1260 - accuracy: 0.96 - ETA: 3:17 - loss: 0.1226 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1209 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1202 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1159 - accuracy: 0.96 - ETA: 3:14 - loss: 0.1191 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1162 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1153 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1150 - accuracy: 0.96 - ETA: 3:10 - loss: 0.1134 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1155 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1120 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1102 - accuracy: 0.96 - ETA: 3:04 - loss: 0.1136 - accuracy: 0.96 - ETA: 3:01 - loss: 0.1135 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1135 - accuracy: 0.96 - ETA: 2:59 - loss: 0.1150 - accuracy: 0.96 - ETA: 2:58 - loss: 0.1145 - accuracy: 0.96 - ETA: 2:57 - loss: 0.1168 - accuracy: 0.96 - ETA: 2:56 - loss: 0.1156 - accuracy: 0.96 - ETA: 2:54 - loss: 0.1147 - accuracy: 0.96 - ETA: 2:53 - loss: 0.1144 - accuracy: 0.96 - ETA: 2:51 - loss: 0.1156 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1142 - accuracy: 0.96 - ETA: 2:48 - loss: 0.1134 - accuracy: 0.96 - ETA: 2:47 - loss: 0.1129 - accuracy: 0.96 - ETA: 2:45 - loss: 0.1115 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1102 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1105 - accuracy: 0.96 - ETA: 2:41 - loss: 0.1106 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1126 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1128 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1115 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1099 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1086 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1084 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1092 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1086 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1080 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1089 - accuracy: 0.96 - ETA: 2:25 - loss: 0.1100 - accuracy: 0.96 - ETA: 2:25 - loss: 0.1103 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1107 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1098 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1115 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1104 - accuracy: 0.96 - ETA: 2:17 - loss: 0.1101 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1100 - accuracy: 0.96 - ETA: 2:14 - loss: 0.1103 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1097 - accuracy: 0.96 - ETA: 2:11 - loss: 0.1082 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1075 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1076 - accuracy: 0.96 - ETA: 2:07 - loss: 0.1083 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1080 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1076 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1067 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1061 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1074 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1075 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1070 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1073 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1076 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1075 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1073 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1068 - accuracy: 0.96 - ETA: 1:47 - loss: 0.1075 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1071 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1066 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1068 - accuracy: 0.96 - ETA: 1:41 - loss: 0.1062 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1059 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1059 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1052 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1042 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1041 - accuracy: 0.96 - ETA: 1:32 - loss: 0.1036 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1032 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1044 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1044 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1044 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1054 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1054 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1052 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1049 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1052 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1049 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1053 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1054 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1053 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1060 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1053 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1050 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1049 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1048 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1042 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1050 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1044 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1040 - accuracy: 0.96 - ETA: 59s - loss: 0.1036 - accuracy: 0.9668 - ETA: 58s - loss: 0.1037 - accuracy: 0.966 - ETA: 57s - loss: 0.1034 - accuracy: 0.966 - ETA: 55s - loss: 0.1043 - accuracy: 0.966 - ETA: 54s - loss: 0.1050 - accuracy: 0.966 - ETA: 52s - loss: 0.1056 - accuracy: 0.966 - ETA: 51s - loss: 0.1057 - accuracy: 0.966 - ETA: 49s - loss: 0.1052 - accuracy: 0.966 - ETA: 48s - loss: 0.1057 - accuracy: 0.966 - ETA: 47s - loss: 0.1056 - accuracy: 0.966 - ETA: 45s - loss: 0.1056 - accuracy: 0.966 - ETA: 44s - loss: 0.1057 - accuracy: 0.966 - ETA: 42s - loss: 0.1058 - accuracy: 0.966 - ETA: 41s - loss: 0.1055 - accuracy: 0.966 - ETA: 39s - loss: 0.1054 - accuracy: 0.966 - ETA: 38s - loss: 0.1057 - accuracy: 0.966 - ETA: 37s - loss: 0.1052 - accuracy: 0.966 - ETA: 35s - loss: 0.1051 - accuracy: 0.966 - ETA: 34s - loss: 0.1052 - accuracy: 0.966 - ETA: 32s - loss: 0.1048 - accuracy: 0.966 - ETA: 31s - loss: 0.1046 - accuracy: 0.966 - ETA: 29s - loss: 0.1047 - accuracy: 0.966 - ETA: 28s - loss: 0.1045 - accuracy: 0.966 - ETA: 27s - loss: 0.1041 - accuracy: 0.966 - ETA: 25s - loss: 0.1038 - accuracy: 0.966 - ETA: 24s - loss: 0.1037 - accuracy: 0.966 - ETA: 22s - loss: 0.1040 - accuracy: 0.966 - ETA: 21s - loss: 0.1035 - accuracy: 0.966 - ETA: 19s - loss: 0.1047 - accuracy: 0.966 - ETA: 18s - loss: 0.1050 - accuracy: 0.966 - ETA: 17s - loss: 0.1057 - accuracy: 0.966 - ETA: 15s - loss: 0.1055 - accuracy: 0.966 - ETA: 14s - loss: 0.1060 - accuracy: 0.966 - ETA: 12s - loss: 0.1060 - accuracy: 0.966 - ETA: 11s - loss: 0.1064 - accuracy: 0.966 - ETA: 9s - loss: 0.1061 - accuracy: 0.966 - ETA: 8s - loss: 0.1058 - accuracy: 0.96 - ETA: 7s - loss: 0.1057 - accuracy: 0.96 - ETA: 5s - loss: 0.1061 - accuracy: 0.96 - ETA: 4s - loss: 0.1061 - accuracy: 0.96 - ETA: 2s - loss: 0.1063 - accuracy: 0.96 - ETA: 1s - loss: 0.1067 - accuracy: 0.96 - 243s 13ms/step - loss: 0.1065 - accuracy: 0.9664 - val_loss: 1.4888 - val_accuracy: 0.7998\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:48 - loss: 0.1412 - accuracy: 0.96 - ETA: 3:45 - loss: 0.0985 - accuracy: 0.96 - ETA: 3:40 - loss: 0.1288 - accuracy: 0.95 - ETA: 3:38 - loss: 0.1160 - accuracy: 0.95 - ETA: 3:35 - loss: 0.1307 - accuracy: 0.95 - ETA: 3:35 - loss: 0.1232 - accuracy: 0.95 - ETA: 3:32 - loss: 0.1108 - accuracy: 0.95 - ETA: 3:30 - loss: 0.1120 - accuracy: 0.96 - ETA: 3:29 - loss: 0.1071 - accuracy: 0.96 - ETA: 3:27 - loss: 0.1002 - accuracy: 0.96 - ETA: 3:24 - loss: 0.0962 - accuracy: 0.96 - ETA: 3:22 - loss: 0.0989 - accuracy: 0.96 - ETA: 3:20 - loss: 0.1049 - accuracy: 0.96 - ETA: 3:20 - loss: 0.1018 - accuracy: 0.96 - ETA: 3:18 - loss: 0.0998 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1000 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1020 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1072 - accuracy: 0.96 - ETA: 3:11 - loss: 0.1047 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1011 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1011 - accuracy: 0.96 - ETA: 3:06 - loss: 0.0986 - accuracy: 0.96 - ETA: 3:04 - loss: 0.0973 - accuracy: 0.96 - ETA: 3:02 - loss: 0.0968 - accuracy: 0.96 - ETA: 3:01 - loss: 0.0975 - accuracy: 0.96 - ETA: 3:03 - loss: 0.0982 - accuracy: 0.96 - ETA: 3:02 - loss: 0.0958 - accuracy: 0.96 - ETA: 3:00 - loss: 0.0984 - accuracy: 0.96 - ETA: 2:58 - loss: 0.0966 - accuracy: 0.96 - ETA: 2:56 - loss: 0.0970 - accuracy: 0.96 - ETA: 2:54 - loss: 0.0948 - accuracy: 0.96 - ETA: 2:53 - loss: 0.0930 - accuracy: 0.96 - ETA: 2:51 - loss: 0.0956 - accuracy: 0.96 - ETA: 2:50 - loss: 0.0943 - accuracy: 0.96 - ETA: 2:48 - loss: 0.0931 - accuracy: 0.96 - ETA: 2:48 - loss: 0.0932 - accuracy: 0.96 - ETA: 2:47 - loss: 0.0922 - accuracy: 0.96 - ETA: 2:45 - loss: 0.0908 - accuracy: 0.96 - ETA: 2:43 - loss: 0.0902 - accuracy: 0.96 - ETA: 2:42 - loss: 0.0921 - accuracy: 0.96 - ETA: 2:40 - loss: 0.0922 - accuracy: 0.96 - ETA: 2:39 - loss: 0.0926 - accuracy: 0.96 - ETA: 2:37 - loss: 0.0923 - accuracy: 0.96 - ETA: 2:36 - loss: 0.0915 - accuracy: 0.96 - ETA: 2:34 - loss: 0.0916 - accuracy: 0.96 - ETA: 2:32 - loss: 0.0929 - accuracy: 0.96 - ETA: 2:31 - loss: 0.0928 - accuracy: 0.96 - ETA: 2:29 - loss: 0.0924 - accuracy: 0.96 - ETA: 2:28 - loss: 0.0930 - accuracy: 0.96 - ETA: 2:26 - loss: 0.0924 - accuracy: 0.96 - ETA: 2:25 - loss: 0.0931 - accuracy: 0.96 - ETA: 2:23 - loss: 0.0933 - accuracy: 0.96 - ETA: 2:22 - loss: 0.0924 - accuracy: 0.96 - ETA: 2:20 - loss: 0.0921 - accuracy: 0.96 - ETA: 2:19 - loss: 0.0926 - accuracy: 0.96 - ETA: 2:17 - loss: 0.0929 - accuracy: 0.96 - ETA: 2:16 - loss: 0.0917 - accuracy: 0.96 - ETA: 2:14 - loss: 0.0920 - accuracy: 0.96 - ETA: 2:13 - loss: 0.0926 - accuracy: 0.96 - ETA: 2:11 - loss: 0.0931 - accuracy: 0.96 - ETA: 2:10 - loss: 0.0927 - accuracy: 0.96 - ETA: 2:08 - loss: 0.0926 - accuracy: 0.96 - ETA: 2:07 - loss: 0.0943 - accuracy: 0.96 - ETA: 2:05 - loss: 0.0947 - accuracy: 0.96 - ETA: 2:04 - loss: 0.0944 - accuracy: 0.96 - ETA: 2:02 - loss: 0.0951 - accuracy: 0.96 - ETA: 2:01 - loss: 0.0951 - accuracy: 0.96 - ETA: 1:59 - loss: 0.0950 - accuracy: 0.96 - ETA: 1:58 - loss: 0.0958 - accuracy: 0.96 - ETA: 1:56 - loss: 0.0959 - accuracy: 0.96 - ETA: 1:55 - loss: 0.0954 - accuracy: 0.96 - ETA: 1:54 - loss: 0.0955 - accuracy: 0.96 - ETA: 1:52 - loss: 0.0958 - accuracy: 0.96 - ETA: 1:51 - loss: 0.0957 - accuracy: 0.96 - ETA: 1:49 - loss: 0.0959 - accuracy: 0.96 - ETA: 1:48 - loss: 0.0972 - accuracy: 0.96 - ETA: 1:46 - loss: 0.0970 - accuracy: 0.96 - ETA: 1:45 - loss: 0.0969 - accuracy: 0.96 - ETA: 1:43 - loss: 0.0971 - accuracy: 0.96 - ETA: 1:42 - loss: 0.0974 - accuracy: 0.96 - ETA: 1:40 - loss: 0.0968 - accuracy: 0.96 - ETA: 1:39 - loss: 0.0970 - accuracy: 0.96 - ETA: 1:38 - loss: 0.0987 - accuracy: 0.96 - ETA: 1:36 - loss: 0.0986 - accuracy: 0.96 - ETA: 1:35 - loss: 0.0983 - accuracy: 0.96 - ETA: 1:33 - loss: 0.0981 - accuracy: 0.96 - ETA: 1:32 - loss: 0.0985 - accuracy: 0.96 - ETA: 1:31 - loss: 0.0982 - accuracy: 0.96 - ETA: 1:30 - loss: 0.0979 - accuracy: 0.96 - ETA: 1:29 - loss: 0.0980 - accuracy: 0.96 - ETA: 1:28 - loss: 0.0972 - accuracy: 0.96 - ETA: 1:27 - loss: 0.0977 - accuracy: 0.96 - ETA: 1:26 - loss: 0.0986 - accuracy: 0.96 - ETA: 1:24 - loss: 0.0990 - accuracy: 0.96 - ETA: 1:23 - loss: 0.0989 - accuracy: 0.96 - ETA: 1:21 - loss: 0.0986 - accuracy: 0.96 - ETA: 1:20 - loss: 0.0986 - accuracy: 0.96 - ETA: 1:19 - loss: 0.0987 - accuracy: 0.96 - ETA: 1:17 - loss: 0.0982 - accuracy: 0.96 - ETA: 1:16 - loss: 0.0991 - accuracy: 0.96 - ETA: 1:14 - loss: 0.0985 - accuracy: 0.96 - ETA: 1:13 - loss: 0.0988 - accuracy: 0.96 - ETA: 1:11 - loss: 0.0980 - accuracy: 0.96 - ETA: 1:10 - loss: 0.0979 - accuracy: 0.96 - ETA: 1:09 - loss: 0.0979 - accuracy: 0.96 - ETA: 1:07 - loss: 0.0982 - accuracy: 0.96 - ETA: 1:05 - loss: 0.0976 - accuracy: 0.96 - ETA: 1:05 - loss: 0.0985 - accuracy: 0.96 - ETA: 1:03 - loss: 0.0985 - accuracy: 0.96 - ETA: 1:02 - loss: 0.0988 - accuracy: 0.96 - ETA: 1:00 - loss: 0.0989 - accuracy: 0.96 - ETA: 58s - loss: 0.0990 - accuracy: 0.9673 - ETA: 57s - loss: 0.0992 - accuracy: 0.967 - ETA: 55s - loss: 0.0992 - accuracy: 0.967 - ETA: 53s - loss: 0.0987 - accuracy: 0.967 - ETA: 52s - loss: 0.0992 - accuracy: 0.967 - ETA: 50s - loss: 0.0991 - accuracy: 0.967 - ETA: 48s - loss: 0.0988 - accuracy: 0.967 - ETA: 47s - loss: 0.0987 - accuracy: 0.967 - ETA: 45s - loss: 0.0985 - accuracy: 0.967 - ETA: 44s - loss: 0.0980 - accuracy: 0.967 - ETA: 43s - loss: 0.0979 - accuracy: 0.967 - ETA: 42s - loss: 0.0981 - accuracy: 0.967 - ETA: 40s - loss: 0.0979 - accuracy: 0.967 - ETA: 39s - loss: 0.0985 - accuracy: 0.967 - ETA: 37s - loss: 0.0984 - accuracy: 0.967 - ETA: 36s - loss: 0.0985 - accuracy: 0.967 - ETA: 34s - loss: 0.0984 - accuracy: 0.967 - ETA: 33s - loss: 0.0987 - accuracy: 0.967 - ETA: 31s - loss: 0.0987 - accuracy: 0.967 - ETA: 30s - loss: 0.0987 - accuracy: 0.967 - ETA: 28s - loss: 0.0989 - accuracy: 0.967 - ETA: 27s - loss: 0.0987 - accuracy: 0.967 - ETA: 25s - loss: 0.0988 - accuracy: 0.967 - ETA: 24s - loss: 0.0990 - accuracy: 0.967 - ETA: 22s - loss: 0.0991 - accuracy: 0.967 - ETA: 21s - loss: 0.0991 - accuracy: 0.967 - ETA: 19s - loss: 0.0991 - accuracy: 0.967 - ETA: 18s - loss: 0.0987 - accuracy: 0.967 - ETA: 16s - loss: 0.0982 - accuracy: 0.967 - ETA: 15s - loss: 0.0991 - accuracy: 0.967 - ETA: 13s - loss: 0.0987 - accuracy: 0.967 - ETA: 12s - loss: 0.0986 - accuracy: 0.967 - ETA: 10s - loss: 0.0984 - accuracy: 0.967 - ETA: 9s - loss: 0.0985 - accuracy: 0.967 - ETA: 7s - loss: 0.0989 - accuracy: 0.96 - ETA: 5s - loss: 0.0996 - accuracy: 0.96 - ETA: 4s - loss: 0.0995 - accuracy: 0.96 - ETA: 2s - loss: 0.0995 - accuracy: 0.96 - ETA: 1s - loss: 0.0997 - accuracy: 0.96 - 257s 13ms/step - loss: 0.0999 - accuracy: 0.9674 - val_loss: 1.5019 - val_accuracy: 0.7946\n",
      "Epoch 36/100\n",
      "19312/19312 [==============================] - ETA: 3:51 - loss: 0.1093 - accuracy: 0.96 - ETA: 3:48 - loss: 0.0945 - accuracy: 0.96 - ETA: 3:48 - loss: 0.1482 - accuracy: 0.95 - ETA: 3:46 - loss: 0.1280 - accuracy: 0.95 - ETA: 3:40 - loss: 0.1189 - accuracy: 0.95 - ETA: 3:35 - loss: 0.1061 - accuracy: 0.96 - ETA: 3:34 - loss: 0.1007 - accuracy: 0.96 - ETA: 3:29 - loss: 0.1072 - accuracy: 0.96 - ETA: 3:45 - loss: 0.1071 - accuracy: 0.96 - ETA: 3:43 - loss: 0.1110 - accuracy: 0.96 - ETA: 3:39 - loss: 0.1075 - accuracy: 0.96 - ETA: 3:37 - loss: 0.1107 - accuracy: 0.96 - ETA: 3:34 - loss: 0.1149 - accuracy: 0.96 - ETA: 3:30 - loss: 0.1132 - accuracy: 0.96 - ETA: 3:42 - loss: 0.1135 - accuracy: 0.96 - ETA: 3:39 - loss: 0.1137 - accuracy: 0.96 - ETA: 3:35 - loss: 0.1098 - accuracy: 0.96 - ETA: 3:32 - loss: 0.1058 - accuracy: 0.96 - ETA: 3:29 - loss: 0.1063 - accuracy: 0.96 - ETA: 3:26 - loss: 0.1021 - accuracy: 0.96 - ETA: 3:27 - loss: 0.1007 - accuracy: 0.96 - ETA: 3:26 - loss: 0.1018 - accuracy: 0.96 - ETA: 3:25 - loss: 0.0991 - accuracy: 0.96 - ETA: 3:22 - loss: 0.0986 - accuracy: 0.96 - ETA: 3:20 - loss: 0.0981 - accuracy: 0.96 - ETA: 3:17 - loss: 0.0954 - accuracy: 0.96 - ETA: 3:16 - loss: 0.0942 - accuracy: 0.96 - ETA: 3:15 - loss: 0.0986 - accuracy: 0.96 - ETA: 3:13 - loss: 0.1019 - accuracy: 0.96 - ETA: 3:11 - loss: 0.1004 - accuracy: 0.96 - ETA: 3:09 - loss: 0.1008 - accuracy: 0.96 - ETA: 3:08 - loss: 0.0998 - accuracy: 0.96 - ETA: 3:05 - loss: 0.0981 - accuracy: 0.96 - ETA: 3:04 - loss: 0.0962 - accuracy: 0.96 - ETA: 3:03 - loss: 0.0941 - accuracy: 0.96 - ETA: 3:01 - loss: 0.0943 - accuracy: 0.96 - ETA: 3:00 - loss: 0.0938 - accuracy: 0.96 - ETA: 2:58 - loss: 0.0930 - accuracy: 0.96 - ETA: 2:57 - loss: 0.0948 - accuracy: 0.96 - ETA: 2:56 - loss: 0.0958 - accuracy: 0.96 - ETA: 2:54 - loss: 0.0956 - accuracy: 0.96 - ETA: 2:52 - loss: 0.0967 - accuracy: 0.96 - ETA: 2:51 - loss: 0.0960 - accuracy: 0.96 - ETA: 2:49 - loss: 0.0945 - accuracy: 0.96 - ETA: 2:47 - loss: 0.0943 - accuracy: 0.96 - ETA: 2:45 - loss: 0.0934 - accuracy: 0.96 - ETA: 2:44 - loss: 0.0920 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0921 - accuracy: 0.96 - ETA: 2:41 - loss: 0.0927 - accuracy: 0.96 - ETA: 2:39 - loss: 0.0933 - accuracy: 0.96 - ETA: 2:37 - loss: 0.0931 - accuracy: 0.96 - ETA: 2:36 - loss: 0.0935 - accuracy: 0.96 - ETA: 2:35 - loss: 0.0942 - accuracy: 0.96 - ETA: 2:33 - loss: 0.0947 - accuracy: 0.96 - ETA: 2:31 - loss: 0.0962 - accuracy: 0.96 - ETA: 2:30 - loss: 0.0961 - accuracy: 0.96 - ETA: 2:28 - loss: 0.0954 - accuracy: 0.96 - ETA: 2:26 - loss: 0.0945 - accuracy: 0.96 - ETA: 2:25 - loss: 0.0942 - accuracy: 0.96 - ETA: 2:23 - loss: 0.0945 - accuracy: 0.96 - ETA: 2:21 - loss: 0.0934 - accuracy: 0.96 - ETA: 2:20 - loss: 0.0927 - accuracy: 0.96 - ETA: 2:18 - loss: 0.0930 - accuracy: 0.96 - ETA: 2:16 - loss: 0.0925 - accuracy: 0.96 - ETA: 2:15 - loss: 0.0923 - accuracy: 0.96 - ETA: 2:13 - loss: 0.0928 - accuracy: 0.96 - ETA: 2:12 - loss: 0.0930 - accuracy: 0.96 - ETA: 2:10 - loss: 0.0930 - accuracy: 0.96 - ETA: 2:09 - loss: 0.0932 - accuracy: 0.96 - ETA: 2:07 - loss: 0.0932 - accuracy: 0.96 - ETA: 2:06 - loss: 0.0932 - accuracy: 0.96 - ETA: 2:04 - loss: 0.0929 - accuracy: 0.96 - ETA: 2:02 - loss: 0.0924 - accuracy: 0.96 - ETA: 2:01 - loss: 0.0917 - accuracy: 0.96 - ETA: 2:00 - loss: 0.0912 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0918 - accuracy: 0.96 - ETA: 1:56 - loss: 0.0912 - accuracy: 0.96 - ETA: 1:55 - loss: 0.0913 - accuracy: 0.96 - ETA: 1:53 - loss: 0.0921 - accuracy: 0.96 - ETA: 1:51 - loss: 0.0915 - accuracy: 0.96 - ETA: 1:50 - loss: 0.0912 - accuracy: 0.96 - ETA: 1:48 - loss: 0.0906 - accuracy: 0.96 - ETA: 1:47 - loss: 0.0900 - accuracy: 0.96 - ETA: 1:45 - loss: 0.0897 - accuracy: 0.96 - ETA: 1:44 - loss: 0.0894 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0892 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0893 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0906 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0909 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0908 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0908 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0912 - accuracy: 0.96 - ETA: 1:31 - loss: 0.0915 - accuracy: 0.96 - ETA: 1:29 - loss: 0.0915 - accuracy: 0.96 - ETA: 1:28 - loss: 0.0908 - accuracy: 0.96 - ETA: 1:26 - loss: 0.0907 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0914 - accuracy: 0.96 - ETA: 1:23 - loss: 0.0910 - accuracy: 0.96 - ETA: 1:21 - loss: 0.0909 - accuracy: 0.96 - ETA: 1:20 - loss: 0.0919 - accuracy: 0.96 - ETA: 1:18 - loss: 0.0916 - accuracy: 0.96 - ETA: 1:17 - loss: 0.0913 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0914 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0907 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0903 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0911 - accuracy: 0.96 - ETA: 1:09 - loss: 0.0913 - accuracy: 0.96 - ETA: 1:07 - loss: 0.0911 - accuracy: 0.96 - ETA: 1:06 - loss: 0.0907 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0914 - accuracy: 0.96 - ETA: 1:03 - loss: 0.0913 - accuracy: 0.96 - ETA: 1:02 - loss: 0.0908 - accuracy: 0.96 - ETA: 1:00 - loss: 0.0913 - accuracy: 0.96 - ETA: 58s - loss: 0.0911 - accuracy: 0.9698 - ETA: 57s - loss: 0.0911 - accuracy: 0.969 - ETA: 55s - loss: 0.0910 - accuracy: 0.969 - ETA: 53s - loss: 0.0909 - accuracy: 0.969 - ETA: 52s - loss: 0.0907 - accuracy: 0.969 - ETA: 50s - loss: 0.0912 - accuracy: 0.969 - ETA: 49s - loss: 0.0910 - accuracy: 0.969 - ETA: 47s - loss: 0.0908 - accuracy: 0.969 - ETA: 45s - loss: 0.0905 - accuracy: 0.970 - ETA: 44s - loss: 0.0904 - accuracy: 0.970 - ETA: 42s - loss: 0.0911 - accuracy: 0.970 - ETA: 41s - loss: 0.0913 - accuracy: 0.970 - ETA: 39s - loss: 0.0914 - accuracy: 0.970 - ETA: 38s - loss: 0.0913 - accuracy: 0.970 - ETA: 36s - loss: 0.0912 - accuracy: 0.970 - ETA: 34s - loss: 0.0914 - accuracy: 0.970 - ETA: 33s - loss: 0.0911 - accuracy: 0.970 - ETA: 31s - loss: 0.0916 - accuracy: 0.970 - ETA: 30s - loss: 0.0910 - accuracy: 0.970 - ETA: 28s - loss: 0.0909 - accuracy: 0.970 - ETA: 26s - loss: 0.0911 - accuracy: 0.970 - ETA: 25s - loss: 0.0912 - accuracy: 0.970 - ETA: 23s - loss: 0.0910 - accuracy: 0.970 - ETA: 22s - loss: 0.0907 - accuracy: 0.970 - ETA: 20s - loss: 0.0910 - accuracy: 0.970 - ETA: 18s - loss: 0.0909 - accuracy: 0.970 - ETA: 17s - loss: 0.0907 - accuracy: 0.970 - ETA: 15s - loss: 0.0909 - accuracy: 0.970 - ETA: 14s - loss: 0.0907 - accuracy: 0.970 - ETA: 12s - loss: 0.0909 - accuracy: 0.970 - ETA: 11s - loss: 0.0909 - accuracy: 0.970 - ETA: 9s - loss: 0.0911 - accuracy: 0.970 - ETA: 7s - loss: 0.0913 - accuracy: 0.97 - ETA: 6s - loss: 0.0909 - accuracy: 0.97 - ETA: 4s - loss: 0.0915 - accuracy: 0.97 - ETA: 3s - loss: 0.0914 - accuracy: 0.97 - ETA: 1s - loss: 0.0917 - accuracy: 0.96 - 269s 14ms/step - loss: 0.0913 - accuracy: 0.9700 - val_loss: 1.4333 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:34 - loss: 0.0894 - accuracy: 0.95 - ETA: 3:38 - loss: 0.0514 - accuracy: 0.97 - ETA: 3:30 - loss: 0.0553 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0472 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0589 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0768 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0854 - accuracy: 0.96 - ETA: 3:30 - loss: 0.0882 - accuracy: 0.96 - ETA: 3:30 - loss: 0.0803 - accuracy: 0.96 - ETA: 3:26 - loss: 0.0760 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0724 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0747 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0731 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0734 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0766 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0758 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0747 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0771 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0795 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0804 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0792 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0774 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0781 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0804 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0798 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0836 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0828 - accuracy: 0.96 - ETA: 3:00 - loss: 0.0842 - accuracy: 0.96 - ETA: 2:59 - loss: 0.0816 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0825 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0811 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0819 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0818 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0800 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0813 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0835 - accuracy: 0.96 - ETA: 2:46 - loss: 0.0824 - accuracy: 0.96 - ETA: 2:44 - loss: 0.0813 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0826 - accuracy: 0.96 - ETA: 2:41 - loss: 0.0827 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0838 - accuracy: 0.96 - ETA: 2:37 - loss: 0.0839 - accuracy: 0.96 - ETA: 2:36 - loss: 0.0840 - accuracy: 0.96 - ETA: 2:34 - loss: 0.0853 - accuracy: 0.96 - ETA: 2:33 - loss: 0.0843 - accuracy: 0.96 - ETA: 2:31 - loss: 0.0841 - accuracy: 0.96 - ETA: 2:30 - loss: 0.0860 - accuracy: 0.96 - ETA: 2:28 - loss: 0.0863 - accuracy: 0.96 - ETA: 2:27 - loss: 0.0876 - accuracy: 0.96 - ETA: 2:25 - loss: 0.0891 - accuracy: 0.96 - ETA: 2:24 - loss: 0.0895 - accuracy: 0.96 - ETA: 2:23 - loss: 0.0896 - accuracy: 0.96 - ETA: 2:21 - loss: 0.0895 - accuracy: 0.96 - ETA: 2:19 - loss: 0.0899 - accuracy: 0.96 - ETA: 2:18 - loss: 0.0893 - accuracy: 0.96 - ETA: 2:16 - loss: 0.0891 - accuracy: 0.96 - ETA: 2:15 - loss: 0.0885 - accuracy: 0.96 - ETA: 2:14 - loss: 0.0889 - accuracy: 0.96 - ETA: 2:12 - loss: 0.0893 - accuracy: 0.96 - ETA: 2:11 - loss: 0.0899 - accuracy: 0.96 - ETA: 2:11 - loss: 0.0894 - accuracy: 0.96 - ETA: 2:09 - loss: 0.0888 - accuracy: 0.96 - ETA: 2:08 - loss: 0.0886 - accuracy: 0.96 - ETA: 2:07 - loss: 0.0887 - accuracy: 0.96 - ETA: 2:05 - loss: 0.0888 - accuracy: 0.96 - ETA: 2:04 - loss: 0.0887 - accuracy: 0.96 - ETA: 2:02 - loss: 0.0884 - accuracy: 0.96 - ETA: 2:01 - loss: 0.0881 - accuracy: 0.96 - ETA: 1:59 - loss: 0.0872 - accuracy: 0.96 - ETA: 1:58 - loss: 0.0877 - accuracy: 0.96 - ETA: 1:57 - loss: 0.0884 - accuracy: 0.96 - ETA: 1:56 - loss: 0.0879 - accuracy: 0.96 - ETA: 1:54 - loss: 0.0879 - accuracy: 0.96 - ETA: 1:53 - loss: 0.0885 - accuracy: 0.96 - ETA: 1:51 - loss: 0.0892 - accuracy: 0.96 - ETA: 1:50 - loss: 0.0892 - accuracy: 0.96 - ETA: 1:48 - loss: 0.0892 - accuracy: 0.96 - ETA: 1:46 - loss: 0.0893 - accuracy: 0.96 - ETA: 1:45 - loss: 0.0908 - accuracy: 0.96 - ETA: 1:44 - loss: 0.0905 - accuracy: 0.96 - ETA: 1:43 - loss: 0.0907 - accuracy: 0.96 - ETA: 1:41 - loss: 0.0907 - accuracy: 0.96 - ETA: 1:40 - loss: 0.0908 - accuracy: 0.96 - ETA: 1:38 - loss: 0.0915 - accuracy: 0.96 - ETA: 1:37 - loss: 0.0920 - accuracy: 0.96 - ETA: 1:35 - loss: 0.0931 - accuracy: 0.96 - ETA: 1:33 - loss: 0.0937 - accuracy: 0.96 - ETA: 1:32 - loss: 0.0936 - accuracy: 0.96 - ETA: 1:30 - loss: 0.0934 - accuracy: 0.96 - ETA: 1:29 - loss: 0.0931 - accuracy: 0.96 - ETA: 1:27 - loss: 0.0930 - accuracy: 0.96 - ETA: 1:26 - loss: 0.0934 - accuracy: 0.96 - ETA: 1:24 - loss: 0.0946 - accuracy: 0.96 - ETA: 1:23 - loss: 0.0960 - accuracy: 0.96 - ETA: 1:21 - loss: 0.0965 - accuracy: 0.96 - ETA: 1:20 - loss: 0.0965 - accuracy: 0.96 - ETA: 1:18 - loss: 0.0969 - accuracy: 0.96 - ETA: 1:16 - loss: 0.0965 - accuracy: 0.96 - ETA: 1:15 - loss: 0.0961 - accuracy: 0.96 - ETA: 1:14 - loss: 0.0961 - accuracy: 0.96 - ETA: 1:12 - loss: 0.0964 - accuracy: 0.96 - ETA: 1:11 - loss: 0.0962 - accuracy: 0.96 - ETA: 1:09 - loss: 0.0960 - accuracy: 0.96 - ETA: 1:08 - loss: 0.0962 - accuracy: 0.96 - ETA: 1:07 - loss: 0.0956 - accuracy: 0.96 - ETA: 1:05 - loss: 0.0958 - accuracy: 0.96 - ETA: 1:04 - loss: 0.0962 - accuracy: 0.96 - ETA: 1:02 - loss: 0.0960 - accuracy: 0.96 - ETA: 1:01 - loss: 0.0965 - accuracy: 0.96 - ETA: 59s - loss: 0.0981 - accuracy: 0.9662 - ETA: 58s - loss: 0.0973 - accuracy: 0.966 - ETA: 56s - loss: 0.0973 - accuracy: 0.966 - ETA: 55s - loss: 0.0969 - accuracy: 0.966 - ETA: 54s - loss: 0.0967 - accuracy: 0.966 - ETA: 52s - loss: 0.0964 - accuracy: 0.966 - ETA: 51s - loss: 0.0962 - accuracy: 0.966 - ETA: 49s - loss: 0.0961 - accuracy: 0.966 - ETA: 48s - loss: 0.0959 - accuracy: 0.966 - ETA: 46s - loss: 0.0967 - accuracy: 0.966 - ETA: 45s - loss: 0.0968 - accuracy: 0.966 - ETA: 44s - loss: 0.0975 - accuracy: 0.966 - ETA: 42s - loss: 0.0981 - accuracy: 0.966 - ETA: 41s - loss: 0.0978 - accuracy: 0.966 - ETA: 39s - loss: 0.0972 - accuracy: 0.967 - ETA: 38s - loss: 0.0973 - accuracy: 0.967 - ETA: 36s - loss: 0.0975 - accuracy: 0.967 - ETA: 35s - loss: 0.0973 - accuracy: 0.967 - ETA: 33s - loss: 0.0972 - accuracy: 0.967 - ETA: 32s - loss: 0.0970 - accuracy: 0.967 - ETA: 30s - loss: 0.0978 - accuracy: 0.966 - ETA: 29s - loss: 0.0977 - accuracy: 0.967 - ETA: 28s - loss: 0.0978 - accuracy: 0.966 - ETA: 26s - loss: 0.0975 - accuracy: 0.966 - ETA: 25s - loss: 0.0977 - accuracy: 0.966 - ETA: 23s - loss: 0.0978 - accuracy: 0.966 - ETA: 22s - loss: 0.0986 - accuracy: 0.966 - ETA: 20s - loss: 0.0985 - accuracy: 0.966 - ETA: 19s - loss: 0.0979 - accuracy: 0.966 - ETA: 17s - loss: 0.0978 - accuracy: 0.966 - ETA: 16s - loss: 0.0987 - accuracy: 0.966 - ETA: 14s - loss: 0.0990 - accuracy: 0.966 - ETA: 13s - loss: 0.0991 - accuracy: 0.966 - ETA: 11s - loss: 0.0990 - accuracy: 0.966 - ETA: 10s - loss: 0.0989 - accuracy: 0.966 - ETA: 8s - loss: 0.0985 - accuracy: 0.966 - ETA: 7s - loss: 0.0986 - accuracy: 0.96 - ETA: 5s - loss: 0.0983 - accuracy: 0.96 - ETA: 4s - loss: 0.0981 - accuracy: 0.96 - ETA: 2s - loss: 0.0977 - accuracy: 0.96 - ETA: 1s - loss: 0.0980 - accuracy: 0.96 - 263s 14ms/step - loss: 0.0981 - accuracy: 0.9667 - val_loss: 1.4367 - val_accuracy: 0.7995\n",
      "Epoch 38/100\n",
      "19312/19312 [==============================] - ETA: 3:49 - loss: 0.1477 - accuracy: 0.95 - ETA: 3:44 - loss: 0.1165 - accuracy: 0.96 - ETA: 3:37 - loss: 0.1237 - accuracy: 0.96 - ETA: 3:32 - loss: 0.1231 - accuracy: 0.96 - ETA: 3:33 - loss: 0.0999 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0947 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0957 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0958 - accuracy: 0.97 - ETA: 3:47 - loss: 0.0898 - accuracy: 0.97 - ETA: 3:44 - loss: 0.0828 - accuracy: 0.97 - ETA: 3:42 - loss: 0.0794 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0816 - accuracy: 0.97 - ETA: 3:35 - loss: 0.0900 - accuracy: 0.97 - ETA: 3:33 - loss: 0.0881 - accuracy: 0.97 - ETA: 3:30 - loss: 0.0863 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0856 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0824 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0805 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0823 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0804 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0793 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0787 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0757 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0744 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0777 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0775 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0767 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0789 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0802 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0820 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0796 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0798 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0807 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0827 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0826 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0844 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0835 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0835 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0870 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0865 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0869 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0865 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0883 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0890 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0886 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0875 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0872 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0876 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0871 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0866 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0867 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0880 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0885 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0905 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0923 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0926 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0925 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0939 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0943 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0943 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0940 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0931 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0924 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0914 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0905 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0900 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0897 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0899 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0912 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0920 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0914 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0922 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0931 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0939 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0941 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0947 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0953 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0954 - accuracy: 0.96 - ETA: 1:46 - loss: 0.0952 - accuracy: 0.96 - ETA: 1:44 - loss: 0.0950 - accuracy: 0.96 - ETA: 1:43 - loss: 0.0947 - accuracy: 0.96 - ETA: 1:41 - loss: 0.0948 - accuracy: 0.96 - ETA: 1:40 - loss: 0.0941 - accuracy: 0.96 - ETA: 1:38 - loss: 0.0940 - accuracy: 0.96 - ETA: 1:37 - loss: 0.0937 - accuracy: 0.96 - ETA: 1:35 - loss: 0.0937 - accuracy: 0.96 - ETA: 1:35 - loss: 0.0935 - accuracy: 0.96 - ETA: 1:33 - loss: 0.0934 - accuracy: 0.96 - ETA: 1:32 - loss: 0.0937 - accuracy: 0.96 - ETA: 1:30 - loss: 0.0931 - accuracy: 0.96 - ETA: 1:29 - loss: 0.0930 - accuracy: 0.96 - ETA: 1:27 - loss: 0.0927 - accuracy: 0.96 - ETA: 1:26 - loss: 0.0925 - accuracy: 0.96 - ETA: 1:24 - loss: 0.0923 - accuracy: 0.96 - ETA: 1:23 - loss: 0.0924 - accuracy: 0.96 - ETA: 1:21 - loss: 0.0921 - accuracy: 0.96 - ETA: 1:20 - loss: 0.0924 - accuracy: 0.96 - ETA: 1:18 - loss: 0.0918 - accuracy: 0.96 - ETA: 1:17 - loss: 0.0912 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0905 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0899 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0898 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0897 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0897 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0895 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0900 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0914 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0913 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0916 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0912 - accuracy: 0.97 - ETA: 59s - loss: 0.0911 - accuracy: 0.9703 - ETA: 57s - loss: 0.0913 - accuracy: 0.970 - ETA: 56s - loss: 0.0914 - accuracy: 0.970 - ETA: 54s - loss: 0.0912 - accuracy: 0.970 - ETA: 52s - loss: 0.0910 - accuracy: 0.970 - ETA: 51s - loss: 0.0905 - accuracy: 0.970 - ETA: 50s - loss: 0.0913 - accuracy: 0.970 - ETA: 48s - loss: 0.0910 - accuracy: 0.970 - ETA: 47s - loss: 0.0916 - accuracy: 0.970 - ETA: 45s - loss: 0.0918 - accuracy: 0.970 - ETA: 44s - loss: 0.0924 - accuracy: 0.970 - ETA: 42s - loss: 0.0923 - accuracy: 0.970 - ETA: 41s - loss: 0.0922 - accuracy: 0.970 - ETA: 39s - loss: 0.0925 - accuracy: 0.969 - ETA: 38s - loss: 0.0925 - accuracy: 0.970 - ETA: 36s - loss: 0.0928 - accuracy: 0.969 - ETA: 35s - loss: 0.0929 - accuracy: 0.969 - ETA: 33s - loss: 0.0925 - accuracy: 0.970 - ETA: 32s - loss: 0.0924 - accuracy: 0.970 - ETA: 30s - loss: 0.0924 - accuracy: 0.970 - ETA: 29s - loss: 0.0922 - accuracy: 0.970 - ETA: 27s - loss: 0.0919 - accuracy: 0.970 - ETA: 26s - loss: 0.0922 - accuracy: 0.970 - ETA: 25s - loss: 0.0923 - accuracy: 0.969 - ETA: 23s - loss: 0.0919 - accuracy: 0.969 - ETA: 22s - loss: 0.0921 - accuracy: 0.969 - ETA: 20s - loss: 0.0922 - accuracy: 0.969 - ETA: 19s - loss: 0.0923 - accuracy: 0.969 - ETA: 17s - loss: 0.0925 - accuracy: 0.970 - ETA: 16s - loss: 0.0921 - accuracy: 0.970 - ETA: 14s - loss: 0.0933 - accuracy: 0.969 - ETA: 13s - loss: 0.0928 - accuracy: 0.970 - ETA: 11s - loss: 0.0923 - accuracy: 0.970 - ETA: 10s - loss: 0.0922 - accuracy: 0.970 - ETA: 8s - loss: 0.0928 - accuracy: 0.970 - ETA: 7s - loss: 0.0926 - accuracy: 0.97 - ETA: 5s - loss: 0.0922 - accuracy: 0.97 - ETA: 4s - loss: 0.0921 - accuracy: 0.97 - ETA: 2s - loss: 0.0919 - accuracy: 0.97 - ETA: 1s - loss: 0.0916 - accuracy: 0.97 - 252s 13ms/step - loss: 0.0917 - accuracy: 0.9703 - val_loss: 1.4679 - val_accuracy: 0.7966\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:51 - loss: 0.0604 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0758 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0958 - accuracy: 0.96 - ETA: 3:44 - loss: 0.0945 - accuracy: 0.96 - ETA: 3:38 - loss: 0.0909 - accuracy: 0.96 - ETA: 3:35 - loss: 0.1125 - accuracy: 0.96 - ETA: 3:31 - loss: 0.1275 - accuracy: 0.96 - ETA: 3:32 - loss: 0.1310 - accuracy: 0.96 - ETA: 3:31 - loss: 0.1274 - accuracy: 0.96 - ETA: 3:27 - loss: 0.1272 - accuracy: 0.96 - ETA: 3:27 - loss: 0.1206 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1155 - accuracy: 0.96 - ETA: 3:24 - loss: 0.1118 - accuracy: 0.96 - ETA: 3:21 - loss: 0.1082 - accuracy: 0.96 - ETA: 3:20 - loss: 0.1055 - accuracy: 0.96 - ETA: 3:18 - loss: 0.0996 - accuracy: 0.96 - ETA: 3:16 - loss: 0.1001 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1013 - accuracy: 0.97 - ETA: 3:12 - loss: 0.1011 - accuracy: 0.97 - ETA: 3:10 - loss: 0.1019 - accuracy: 0.97 - ETA: 3:08 - loss: 0.1012 - accuracy: 0.97 - ETA: 3:06 - loss: 0.1041 - accuracy: 0.97 - ETA: 3:05 - loss: 0.1022 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0999 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0995 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0992 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0971 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0953 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0937 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0916 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0922 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0920 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0932 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0929 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0945 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0941 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0930 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0943 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0939 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0931 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0941 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0974 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0972 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0960 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0954 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0963 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0956 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0949 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0955 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0956 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0954 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0946 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0935 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0937 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0947 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0943 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0931 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0924 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0914 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0916 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0906 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0896 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0895 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0896 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0898 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0887 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0882 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0875 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0869 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0876 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0871 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0871 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0870 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0863 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0860 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0855 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0853 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0848 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0850 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0850 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0852 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0849 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0846 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0842 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0853 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0847 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0846 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0841 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0842 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0841 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0850 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0851 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0848 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0844 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0864 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0864 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0873 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0884 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0885 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0882 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0879 - accuracy: 0.97 - ETA: 59s - loss: 0.0879 - accuracy: 0.9714 - ETA: 58s - loss: 0.0891 - accuracy: 0.971 - ETA: 57s - loss: 0.0896 - accuracy: 0.971 - ETA: 55s - loss: 0.0893 - accuracy: 0.971 - ETA: 54s - loss: 0.0896 - accuracy: 0.971 - ETA: 52s - loss: 0.0891 - accuracy: 0.971 - ETA: 51s - loss: 0.0884 - accuracy: 0.971 - ETA: 50s - loss: 0.0881 - accuracy: 0.971 - ETA: 48s - loss: 0.0881 - accuracy: 0.971 - ETA: 47s - loss: 0.0882 - accuracy: 0.971 - ETA: 45s - loss: 0.0879 - accuracy: 0.971 - ETA: 44s - loss: 0.0874 - accuracy: 0.971 - ETA: 42s - loss: 0.0871 - accuracy: 0.971 - ETA: 41s - loss: 0.0872 - accuracy: 0.971 - ETA: 39s - loss: 0.0867 - accuracy: 0.971 - ETA: 38s - loss: 0.0868 - accuracy: 0.971 - ETA: 36s - loss: 0.0864 - accuracy: 0.971 - ETA: 35s - loss: 0.0868 - accuracy: 0.971 - ETA: 34s - loss: 0.0863 - accuracy: 0.971 - ETA: 32s - loss: 0.0861 - accuracy: 0.972 - ETA: 31s - loss: 0.0862 - accuracy: 0.972 - ETA: 29s - loss: 0.0861 - accuracy: 0.972 - ETA: 28s - loss: 0.0859 - accuracy: 0.972 - ETA: 26s - loss: 0.0858 - accuracy: 0.972 - ETA: 25s - loss: 0.0854 - accuracy: 0.972 - ETA: 23s - loss: 0.0860 - accuracy: 0.972 - ETA: 22s - loss: 0.0857 - accuracy: 0.972 - ETA: 20s - loss: 0.0859 - accuracy: 0.972 - ETA: 19s - loss: 0.0859 - accuracy: 0.972 - ETA: 17s - loss: 0.0857 - accuracy: 0.972 - ETA: 16s - loss: 0.0862 - accuracy: 0.972 - ETA: 14s - loss: 0.0857 - accuracy: 0.972 - ETA: 13s - loss: 0.0853 - accuracy: 0.972 - ETA: 11s - loss: 0.0850 - accuracy: 0.972 - ETA: 10s - loss: 0.0851 - accuracy: 0.972 - ETA: 8s - loss: 0.0858 - accuracy: 0.972 - ETA: 7s - loss: 0.0858 - accuracy: 0.97 - ETA: 5s - loss: 0.0863 - accuracy: 0.97 - ETA: 4s - loss: 0.0861 - accuracy: 0.97 - ETA: 2s - loss: 0.0868 - accuracy: 0.97 - ETA: 1s - loss: 0.0864 - accuracy: 0.97 - 256s 13ms/step - loss: 0.0864 - accuracy: 0.9720 - val_loss: 1.5000 - val_accuracy: 0.7998\n",
      "Epoch 40/100\n",
      "19312/19312 [==============================] - ETA: 3:45 - loss: 0.1207 - accuracy: 0.96 - ETA: 3:34 - loss: 0.1040 - accuracy: 0.97 - ETA: 3:41 - loss: 0.0945 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0934 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0790 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0813 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0856 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0840 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0914 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0892 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0917 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0857 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0845 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0864 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0943 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0933 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0956 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0935 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0948 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0946 - accuracy: 0.96 - ETA: 3:09 - loss: 0.0921 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0921 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0911 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0913 - accuracy: 0.96 - ETA: 3:04 - loss: 0.0904 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0895 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0894 - accuracy: 0.96 - ETA: 3:00 - loss: 0.0903 - accuracy: 0.96 - ETA: 2:58 - loss: 0.0912 - accuracy: 0.96 - ETA: 2:56 - loss: 0.0915 - accuracy: 0.96 - ETA: 2:55 - loss: 0.0911 - accuracy: 0.96 - ETA: 2:53 - loss: 0.0903 - accuracy: 0.96 - ETA: 2:51 - loss: 0.0888 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0925 - accuracy: 0.96 - ETA: 2:49 - loss: 0.0922 - accuracy: 0.96 - ETA: 2:47 - loss: 0.0912 - accuracy: 0.96 - ETA: 2:46 - loss: 0.0892 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0912 - accuracy: 0.96 - ETA: 2:43 - loss: 0.0916 - accuracy: 0.96 - ETA: 2:41 - loss: 0.0912 - accuracy: 0.96 - ETA: 2:40 - loss: 0.0925 - accuracy: 0.96 - ETA: 2:39 - loss: 0.0912 - accuracy: 0.96 - ETA: 2:37 - loss: 0.0903 - accuracy: 0.96 - ETA: 2:36 - loss: 0.0911 - accuracy: 0.96 - ETA: 2:34 - loss: 0.0915 - accuracy: 0.96 - ETA: 2:33 - loss: 0.0912 - accuracy: 0.96 - ETA: 2:31 - loss: 0.0933 - accuracy: 0.96 - ETA: 2:30 - loss: 0.0925 - accuracy: 0.96 - ETA: 2:28 - loss: 0.0924 - accuracy: 0.96 - ETA: 2:27 - loss: 0.0923 - accuracy: 0.96 - ETA: 2:25 - loss: 0.0916 - accuracy: 0.96 - ETA: 2:24 - loss: 0.0907 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0918 - accuracy: 0.96 - ETA: 2:21 - loss: 0.0915 - accuracy: 0.96 - ETA: 2:20 - loss: 0.0921 - accuracy: 0.96 - ETA: 2:18 - loss: 0.0942 - accuracy: 0.96 - ETA: 2:17 - loss: 0.0941 - accuracy: 0.96 - ETA: 2:16 - loss: 0.0943 - accuracy: 0.96 - ETA: 2:14 - loss: 0.0935 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0927 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0916 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0910 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0923 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0923 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0941 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0933 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0930 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0933 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0931 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0925 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0922 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0912 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0904 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0893 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0888 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0882 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0879 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0878 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0878 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0873 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0865 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0861 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0860 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0860 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0855 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0873 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0876 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0885 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0886 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0882 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0885 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0881 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0872 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0880 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0890 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0885 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0893 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0896 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0894 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0884 - accuracy: 0.97 - ETA: 59s - loss: 0.0884 - accuracy: 0.9717 - ETA: 57s - loss: 0.0889 - accuracy: 0.971 - ETA: 56s - loss: 0.0884 - accuracy: 0.971 - ETA: 54s - loss: 0.0885 - accuracy: 0.971 - ETA: 53s - loss: 0.0889 - accuracy: 0.971 - ETA: 51s - loss: 0.0885 - accuracy: 0.971 - ETA: 50s - loss: 0.0880 - accuracy: 0.971 - ETA: 48s - loss: 0.0881 - accuracy: 0.971 - ETA: 47s - loss: 0.0878 - accuracy: 0.971 - ETA: 45s - loss: 0.0882 - accuracy: 0.971 - ETA: 44s - loss: 0.0879 - accuracy: 0.971 - ETA: 42s - loss: 0.0874 - accuracy: 0.971 - ETA: 41s - loss: 0.0873 - accuracy: 0.971 - ETA: 39s - loss: 0.0870 - accuracy: 0.972 - ETA: 38s - loss: 0.0868 - accuracy: 0.972 - ETA: 36s - loss: 0.0869 - accuracy: 0.972 - ETA: 35s - loss: 0.0869 - accuracy: 0.972 - ETA: 33s - loss: 0.0875 - accuracy: 0.971 - ETA: 32s - loss: 0.0873 - accuracy: 0.972 - ETA: 30s - loss: 0.0878 - accuracy: 0.971 - ETA: 29s - loss: 0.0881 - accuracy: 0.971 - ETA: 27s - loss: 0.0877 - accuracy: 0.971 - ETA: 26s - loss: 0.0873 - accuracy: 0.972 - ETA: 24s - loss: 0.0874 - accuracy: 0.972 - ETA: 23s - loss: 0.0877 - accuracy: 0.972 - ETA: 21s - loss: 0.0879 - accuracy: 0.972 - ETA: 20s - loss: 0.0878 - accuracy: 0.971 - ETA: 19s - loss: 0.0878 - accuracy: 0.971 - ETA: 17s - loss: 0.0877 - accuracy: 0.971 - ETA: 16s - loss: 0.0876 - accuracy: 0.971 - ETA: 14s - loss: 0.0878 - accuracy: 0.971 - ETA: 13s - loss: 0.0880 - accuracy: 0.971 - ETA: 11s - loss: 0.0892 - accuracy: 0.971 - ETA: 10s - loss: 0.0893 - accuracy: 0.971 - ETA: 8s - loss: 0.0892 - accuracy: 0.971 - ETA: 7s - loss: 0.0892 - accuracy: 0.97 - ETA: 5s - loss: 0.0891 - accuracy: 0.97 - ETA: 4s - loss: 0.0890 - accuracy: 0.97 - ETA: 2s - loss: 0.0886 - accuracy: 0.97 - ETA: 1s - loss: 0.0885 - accuracy: 0.97 - 251s 13ms/step - loss: 0.0886 - accuracy: 0.9713 - val_loss: 1.5367 - val_accuracy: 0.7987\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:47 - loss: 0.1120 - accuracy: 0.96 - ETA: 3:34 - loss: 0.0942 - accuracy: 0.96 - ETA: 3:32 - loss: 0.0958 - accuracy: 0.97 - ETA: 3:33 - loss: 0.0945 - accuracy: 0.97 - ETA: 3:30 - loss: 0.0882 - accuracy: 0.97 - ETA: 3:31 - loss: 0.1005 - accuracy: 0.96 - ETA: 3:30 - loss: 0.0995 - accuracy: 0.96 - ETA: 3:28 - loss: 0.0966 - accuracy: 0.96 - ETA: 3:25 - loss: 0.0947 - accuracy: 0.96 - ETA: 3:24 - loss: 0.0910 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0914 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0887 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0907 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0889 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0867 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0867 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0873 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0861 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0839 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0857 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0846 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0830 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0839 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0851 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0876 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0890 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0886 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0889 - accuracy: 0.96 - ETA: 2:55 - loss: 0.0875 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0892 - accuracy: 0.96 - ETA: 2:53 - loss: 0.0879 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0888 - accuracy: 0.96 - ETA: 2:49 - loss: 0.0906 - accuracy: 0.96 - ETA: 2:48 - loss: 0.0896 - accuracy: 0.96 - ETA: 2:46 - loss: 0.0880 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0878 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0866 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0864 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0845 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0829 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0816 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0809 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0827 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0854 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0847 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0845 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0829 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0821 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0828 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0820 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0813 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0825 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0821 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0826 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0834 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0858 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0859 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0870 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0877 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0882 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0875 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0873 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0880 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0886 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0883 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0889 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0894 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0884 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0879 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0882 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0884 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0878 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0878 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0877 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0886 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0902 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0900 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0905 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0905 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0906 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0901 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0897 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0888 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0882 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0885 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0888 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0891 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0891 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0883 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0895 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0894 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0903 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0895 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0899 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0895 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0899 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0903 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0909 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0910 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0910 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0911 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0905 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0911 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0911 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0922 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0917 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0910 - accuracy: 0.97 - ETA: 58s - loss: 0.0905 - accuracy: 0.9716 - ETA: 57s - loss: 0.0911 - accuracy: 0.971 - ETA: 56s - loss: 0.0907 - accuracy: 0.971 - ETA: 54s - loss: 0.0905 - accuracy: 0.971 - ETA: 53s - loss: 0.0914 - accuracy: 0.971 - ETA: 51s - loss: 0.0918 - accuracy: 0.971 - ETA: 50s - loss: 0.0911 - accuracy: 0.971 - ETA: 48s - loss: 0.0909 - accuracy: 0.971 - ETA: 47s - loss: 0.0916 - accuracy: 0.971 - ETA: 45s - loss: 0.0915 - accuracy: 0.971 - ETA: 44s - loss: 0.0914 - accuracy: 0.971 - ETA: 42s - loss: 0.0915 - accuracy: 0.971 - ETA: 41s - loss: 0.0911 - accuracy: 0.971 - ETA: 39s - loss: 0.0907 - accuracy: 0.971 - ETA: 38s - loss: 0.0917 - accuracy: 0.971 - ETA: 36s - loss: 0.0914 - accuracy: 0.971 - ETA: 35s - loss: 0.0915 - accuracy: 0.971 - ETA: 33s - loss: 0.0916 - accuracy: 0.971 - ETA: 32s - loss: 0.0912 - accuracy: 0.971 - ETA: 30s - loss: 0.0910 - accuracy: 0.971 - ETA: 29s - loss: 0.0905 - accuracy: 0.971 - ETA: 27s - loss: 0.0904 - accuracy: 0.971 - ETA: 26s - loss: 0.0903 - accuracy: 0.971 - ETA: 25s - loss: 0.0902 - accuracy: 0.971 - ETA: 23s - loss: 0.0898 - accuracy: 0.971 - ETA: 22s - loss: 0.0895 - accuracy: 0.971 - ETA: 20s - loss: 0.0896 - accuracy: 0.971 - ETA: 19s - loss: 0.0896 - accuracy: 0.971 - ETA: 17s - loss: 0.0895 - accuracy: 0.971 - ETA: 16s - loss: 0.0897 - accuracy: 0.971 - ETA: 14s - loss: 0.0893 - accuracy: 0.971 - ETA: 13s - loss: 0.0890 - accuracy: 0.971 - ETA: 11s - loss: 0.0886 - accuracy: 0.972 - ETA: 10s - loss: 0.0882 - accuracy: 0.972 - ETA: 8s - loss: 0.0879 - accuracy: 0.972 - ETA: 7s - loss: 0.0879 - accuracy: 0.97 - ETA: 5s - loss: 0.0880 - accuracy: 0.97 - ETA: 4s - loss: 0.0879 - accuracy: 0.97 - ETA: 2s - loss: 0.0878 - accuracy: 0.97 - ETA: 1s - loss: 0.0878 - accuracy: 0.97 - 255s 13ms/step - loss: 0.0880 - accuracy: 0.9720 - val_loss: 1.5000 - val_accuracy: 0.8037\n",
      "Epoch 42/100\n",
      "19312/19312 [==============================] - ETA: 3:43 - loss: 0.0297 - accuracy: 0.99 - ETA: 3:43 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0709 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0734 - accuracy: 0.97 - ETA: 3:41 - loss: 0.0642 - accuracy: 0.97 - ETA: 3:44 - loss: 0.0638 - accuracy: 0.97 - ETA: 3:41 - loss: 0.0611 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0624 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0644 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0610 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0626 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0593 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0557 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0619 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0650 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0634 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0648 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0648 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0669 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0650 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0647 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0656 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0650 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0647 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0635 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0650 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0643 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0633 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0670 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0670 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0678 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0682 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0688 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0702 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0716 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0706 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0741 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0744 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0765 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0762 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0754 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0758 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0751 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0745 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0748 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0770 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0755 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0770 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0773 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0775 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0793 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0791 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0796 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0789 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0788 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0780 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0777 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0773 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0768 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0766 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0761 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0771 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0766 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0765 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0759 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0757 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0757 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0767 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0762 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0763 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0759 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0766 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0776 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0776 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0773 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0781 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0776 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0774 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0769 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0766 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0772 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0765 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0761 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0763 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0763 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0763 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0765 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0774 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0774 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0775 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0776 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0776 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0779 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0784 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0795 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0789 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0786 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0789 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0796 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0808 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0808 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0811 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0809 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0813 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0823 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0823 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0822 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0831 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0828 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0828 - accuracy: 0.97 - ETA: 58s - loss: 0.0833 - accuracy: 0.9735 - ETA: 56s - loss: 0.0832 - accuracy: 0.973 - ETA: 55s - loss: 0.0839 - accuracy: 0.973 - ETA: 53s - loss: 0.0841 - accuracy: 0.973 - ETA: 52s - loss: 0.0846 - accuracy: 0.973 - ETA: 50s - loss: 0.0844 - accuracy: 0.973 - ETA: 48s - loss: 0.0845 - accuracy: 0.973 - ETA: 47s - loss: 0.0841 - accuracy: 0.973 - ETA: 45s - loss: 0.0839 - accuracy: 0.973 - ETA: 43s - loss: 0.0840 - accuracy: 0.973 - ETA: 42s - loss: 0.0838 - accuracy: 0.973 - ETA: 40s - loss: 0.0834 - accuracy: 0.973 - ETA: 39s - loss: 0.0833 - accuracy: 0.973 - ETA: 37s - loss: 0.0839 - accuracy: 0.973 - ETA: 36s - loss: 0.0838 - accuracy: 0.973 - ETA: 34s - loss: 0.0843 - accuracy: 0.973 - ETA: 32s - loss: 0.0845 - accuracy: 0.972 - ETA: 31s - loss: 0.0841 - accuracy: 0.973 - ETA: 29s - loss: 0.0836 - accuracy: 0.973 - ETA: 28s - loss: 0.0834 - accuracy: 0.973 - ETA: 26s - loss: 0.0831 - accuracy: 0.973 - ETA: 25s - loss: 0.0827 - accuracy: 0.973 - ETA: 23s - loss: 0.0823 - accuracy: 0.973 - ETA: 22s - loss: 0.0821 - accuracy: 0.973 - ETA: 20s - loss: 0.0823 - accuracy: 0.973 - ETA: 18s - loss: 0.0823 - accuracy: 0.973 - ETA: 17s - loss: 0.0820 - accuracy: 0.973 - ETA: 15s - loss: 0.0826 - accuracy: 0.973 - ETA: 14s - loss: 0.0825 - accuracy: 0.973 - ETA: 12s - loss: 0.0822 - accuracy: 0.973 - ETA: 10s - loss: 0.0824 - accuracy: 0.973 - ETA: 9s - loss: 0.0826 - accuracy: 0.973 - ETA: 7s - loss: 0.0822 - accuracy: 0.97 - ETA: 6s - loss: 0.0823 - accuracy: 0.97 - ETA: 4s - loss: 0.0822 - accuracy: 0.97 - ETA: 2s - loss: 0.0820 - accuracy: 0.97 - ETA: 1s - loss: 0.0821 - accuracy: 0.97 - 266s 14ms/step - loss: 0.0820 - accuracy: 0.9736 - val_loss: 1.4986 - val_accuracy: 0.8051\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:44 - loss: 0.0678 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0481 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0533 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0697 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0690 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0669 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0656 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0688 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0638 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0605 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0588 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0610 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0600 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0589 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0576 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0614 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0658 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0657 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0647 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0654 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0643 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0631 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0675 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0673 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0710 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0687 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0668 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0666 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0670 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0663 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0670 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0675 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0692 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0697 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0689 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0705 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0726 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0752 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0756 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0747 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0753 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0758 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0748 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0751 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0753 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0758 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0764 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0768 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0765 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0792 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0779 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0771 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0771 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0762 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0753 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0751 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0758 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0766 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0768 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0772 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0767 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0762 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0754 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0748 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0738 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0729 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0727 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0733 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0734 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0732 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0727 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0720 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0728 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0722 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0719 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0718 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0726 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0721 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0715 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0718 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0716 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0715 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0712 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0711 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0714 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0721 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0731 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0743 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0739 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0743 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0744 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0746 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0750 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0762 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0770 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0766 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0761 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0763 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0765 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0765 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0773 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0769 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0766 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0770 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0766 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0762 - accuracy: 0.97 - ETA: 58s - loss: 0.0762 - accuracy: 0.9768 - ETA: 57s - loss: 0.0764 - accuracy: 0.976 - ETA: 55s - loss: 0.0761 - accuracy: 0.977 - ETA: 54s - loss: 0.0763 - accuracy: 0.976 - ETA: 52s - loss: 0.0770 - accuracy: 0.976 - ETA: 51s - loss: 0.0765 - accuracy: 0.976 - ETA: 49s - loss: 0.0765 - accuracy: 0.976 - ETA: 47s - loss: 0.0768 - accuracy: 0.976 - ETA: 46s - loss: 0.0762 - accuracy: 0.976 - ETA: 44s - loss: 0.0757 - accuracy: 0.977 - ETA: 43s - loss: 0.0756 - accuracy: 0.977 - ETA: 41s - loss: 0.0761 - accuracy: 0.977 - ETA: 40s - loss: 0.0765 - accuracy: 0.977 - ETA: 38s - loss: 0.0763 - accuracy: 0.976 - ETA: 36s - loss: 0.0762 - accuracy: 0.976 - ETA: 35s - loss: 0.0760 - accuracy: 0.977 - ETA: 33s - loss: 0.0762 - accuracy: 0.976 - ETA: 32s - loss: 0.0758 - accuracy: 0.976 - ETA: 30s - loss: 0.0757 - accuracy: 0.976 - ETA: 29s - loss: 0.0756 - accuracy: 0.976 - ETA: 27s - loss: 0.0758 - accuracy: 0.976 - ETA: 26s - loss: 0.0760 - accuracy: 0.976 - ETA: 24s - loss: 0.0755 - accuracy: 0.977 - ETA: 23s - loss: 0.0754 - accuracy: 0.977 - ETA: 21s - loss: 0.0754 - accuracy: 0.976 - ETA: 20s - loss: 0.0750 - accuracy: 0.977 - ETA: 18s - loss: 0.0746 - accuracy: 0.977 - ETA: 17s - loss: 0.0744 - accuracy: 0.977 - ETA: 15s - loss: 0.0744 - accuracy: 0.977 - ETA: 14s - loss: 0.0741 - accuracy: 0.977 - ETA: 12s - loss: 0.0739 - accuracy: 0.977 - ETA: 11s - loss: 0.0744 - accuracy: 0.977 - ETA: 9s - loss: 0.0743 - accuracy: 0.977 - ETA: 7s - loss: 0.0743 - accuracy: 0.97 - ETA: 6s - loss: 0.0750 - accuracy: 0.97 - ETA: 4s - loss: 0.0752 - accuracy: 0.97 - ETA: 3s - loss: 0.0753 - accuracy: 0.97 - ETA: 1s - loss: 0.0753 - accuracy: 0.97 - 279s 14ms/step - loss: 0.0757 - accuracy: 0.9770 - val_loss: 1.5453 - val_accuracy: 0.7991\n",
      "Epoch 44/100\n",
      "19312/19312 [==============================] - ETA: 3:36 - loss: 0.0411 - accuracy: 0.99 - ETA: 3:41 - loss: 0.0571 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0605 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0578 - accuracy: 0.97 - ETA: 3:41 - loss: 0.0550 - accuracy: 0.97 - ETA: 3:42 - loss: 0.0599 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0579 - accuracy: 0.97 - ETA: 3:33 - loss: 0.0605 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0614 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0587 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0546 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0535 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0557 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0572 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0566 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0601 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0596 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0598 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0580 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0617 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0642 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0646 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0644 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0630 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0662 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0664 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0655 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0654 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0646 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0643 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0644 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0635 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0639 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0643 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0643 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0644 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0663 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0673 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0672 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0678 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0685 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0685 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0692 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0694 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0691 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0686 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0679 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0670 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0668 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0678 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0709 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0709 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0700 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0717 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0734 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0730 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0724 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0714 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0713 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0710 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0707 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0713 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0707 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0701 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0706 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0704 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0704 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0709 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0708 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0721 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0715 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0712 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0718 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0725 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0733 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0738 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0742 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0745 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0753 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0751 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0749 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0749 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0754 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0757 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0752 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0751 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0756 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0753 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0757 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0761 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0758 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0763 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0767 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0769 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0767 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0767 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0763 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0761 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0757 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0754 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0751 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0756 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0753 - accuracy: 0.97 - ETA: 59s - loss: 0.0757 - accuracy: 0.9737 - ETA: 57s - loss: 0.0756 - accuracy: 0.973 - ETA: 56s - loss: 0.0755 - accuracy: 0.973 - ETA: 54s - loss: 0.0757 - accuracy: 0.973 - ETA: 52s - loss: 0.0760 - accuracy: 0.973 - ETA: 51s - loss: 0.0758 - accuracy: 0.973 - ETA: 49s - loss: 0.0756 - accuracy: 0.973 - ETA: 48s - loss: 0.0760 - accuracy: 0.973 - ETA: 46s - loss: 0.0759 - accuracy: 0.973 - ETA: 45s - loss: 0.0763 - accuracy: 0.973 - ETA: 43s - loss: 0.0777 - accuracy: 0.973 - ETA: 42s - loss: 0.0774 - accuracy: 0.973 - ETA: 40s - loss: 0.0774 - accuracy: 0.973 - ETA: 39s - loss: 0.0778 - accuracy: 0.973 - ETA: 37s - loss: 0.0775 - accuracy: 0.973 - ETA: 36s - loss: 0.0779 - accuracy: 0.973 - ETA: 34s - loss: 0.0777 - accuracy: 0.973 - ETA: 33s - loss: 0.0773 - accuracy: 0.973 - ETA: 31s - loss: 0.0770 - accuracy: 0.973 - ETA: 30s - loss: 0.0769 - accuracy: 0.973 - ETA: 28s - loss: 0.0766 - accuracy: 0.973 - ETA: 27s - loss: 0.0768 - accuracy: 0.973 - ETA: 25s - loss: 0.0766 - accuracy: 0.973 - ETA: 24s - loss: 0.0765 - accuracy: 0.974 - ETA: 22s - loss: 0.0768 - accuracy: 0.974 - ETA: 21s - loss: 0.0776 - accuracy: 0.973 - ETA: 19s - loss: 0.0776 - accuracy: 0.974 - ETA: 18s - loss: 0.0778 - accuracy: 0.974 - ETA: 16s - loss: 0.0775 - accuracy: 0.974 - ETA: 15s - loss: 0.0772 - accuracy: 0.974 - ETA: 13s - loss: 0.0772 - accuracy: 0.974 - ETA: 12s - loss: 0.0770 - accuracy: 0.974 - ETA: 10s - loss: 0.0769 - accuracy: 0.974 - ETA: 8s - loss: 0.0765 - accuracy: 0.974 - ETA: 7s - loss: 0.0766 - accuracy: 0.97 - ETA: 5s - loss: 0.0764 - accuracy: 0.97 - ETA: 4s - loss: 0.0767 - accuracy: 0.97 - ETA: 2s - loss: 0.0777 - accuracy: 0.97 - ETA: 1s - loss: 0.0774 - accuracy: 0.97 - 269s 14ms/step - loss: 0.0771 - accuracy: 0.9743 - val_loss: 1.6738 - val_accuracy: 0.7952\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:49 - loss: 0.1898 - accuracy: 0.96 - ETA: 3:46 - loss: 0.1042 - accuracy: 0.97 - ETA: 3:35 - loss: 0.0917 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0822 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0846 - accuracy: 0.97 - ETA: 3:49 - loss: 0.0885 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0897 - accuracy: 0.97 - ETA: 3:42 - loss: 0.0943 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0952 - accuracy: 0.96 - ETA: 3:38 - loss: 0.0953 - accuracy: 0.96 - ETA: 3:34 - loss: 0.0912 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0981 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0928 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0939 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0944 - accuracy: 0.96 - ETA: 3:22 - loss: 0.0926 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0902 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0887 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0882 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0906 - accuracy: 0.96 - ETA: 3:15 - loss: 0.0903 - accuracy: 0.96 - ETA: 3:14 - loss: 0.0897 - accuracy: 0.96 - ETA: 3:12 - loss: 0.0890 - accuracy: 0.96 - ETA: 3:11 - loss: 0.0944 - accuracy: 0.96 - ETA: 3:09 - loss: 0.0919 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0900 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0884 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0871 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0864 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0918 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0936 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0956 - accuracy: 0.96 - ETA: 2:58 - loss: 0.0988 - accuracy: 0.96 - ETA: 2:57 - loss: 0.0972 - accuracy: 0.96 - ETA: 2:55 - loss: 0.0968 - accuracy: 0.96 - ETA: 2:54 - loss: 0.0943 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0947 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0953 - accuracy: 0.96 - ETA: 2:49 - loss: 0.0972 - accuracy: 0.96 - ETA: 2:49 - loss: 0.0976 - accuracy: 0.96 - ETA: 2:47 - loss: 0.0981 - accuracy: 0.96 - ETA: 2:45 - loss: 0.0971 - accuracy: 0.96 - ETA: 2:43 - loss: 0.0967 - accuracy: 0.96 - ETA: 2:42 - loss: 0.0996 - accuracy: 0.96 - ETA: 2:40 - loss: 0.0991 - accuracy: 0.96 - ETA: 2:38 - loss: 0.0977 - accuracy: 0.96 - ETA: 2:37 - loss: 0.0980 - accuracy: 0.96 - ETA: 2:36 - loss: 0.0965 - accuracy: 0.96 - ETA: 2:34 - loss: 0.0954 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0944 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0943 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0945 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0942 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0937 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0929 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0921 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0916 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0925 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0924 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0926 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0924 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0925 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0917 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0907 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0903 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0902 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0893 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0895 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0894 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0894 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0888 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0885 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0894 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0890 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0895 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0883 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0901 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0910 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0901 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0895 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0890 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0884 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0885 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0890 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0894 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0887 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0886 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0882 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0889 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0883 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0872 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0867 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0864 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0860 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0859 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0858 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0856 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0863 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0865 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0869 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0871 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0872 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0875 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0870 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0870 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0866 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0866 - accuracy: 0.97 - ETA: 59s - loss: 0.0865 - accuracy: 0.9729 - ETA: 58s - loss: 0.0858 - accuracy: 0.973 - ETA: 56s - loss: 0.0855 - accuracy: 0.973 - ETA: 55s - loss: 0.0852 - accuracy: 0.973 - ETA: 53s - loss: 0.0848 - accuracy: 0.973 - ETA: 52s - loss: 0.0850 - accuracy: 0.973 - ETA: 50s - loss: 0.0846 - accuracy: 0.973 - ETA: 48s - loss: 0.0842 - accuracy: 0.973 - ETA: 47s - loss: 0.0837 - accuracy: 0.973 - ETA: 45s - loss: 0.0833 - accuracy: 0.973 - ETA: 44s - loss: 0.0829 - accuracy: 0.973 - ETA: 42s - loss: 0.0842 - accuracy: 0.973 - ETA: 41s - loss: 0.0838 - accuracy: 0.973 - ETA: 39s - loss: 0.0837 - accuracy: 0.973 - ETA: 38s - loss: 0.0839 - accuracy: 0.973 - ETA: 36s - loss: 0.0836 - accuracy: 0.973 - ETA: 35s - loss: 0.0835 - accuracy: 0.973 - ETA: 33s - loss: 0.0832 - accuracy: 0.974 - ETA: 32s - loss: 0.0830 - accuracy: 0.974 - ETA: 30s - loss: 0.0828 - accuracy: 0.974 - ETA: 29s - loss: 0.0828 - accuracy: 0.974 - ETA: 27s - loss: 0.0832 - accuracy: 0.973 - ETA: 26s - loss: 0.0831 - accuracy: 0.973 - ETA: 24s - loss: 0.0829 - accuracy: 0.974 - ETA: 23s - loss: 0.0829 - accuracy: 0.973 - ETA: 21s - loss: 0.0828 - accuracy: 0.973 - ETA: 19s - loss: 0.0829 - accuracy: 0.973 - ETA: 18s - loss: 0.0826 - accuracy: 0.973 - ETA: 16s - loss: 0.0826 - accuracy: 0.973 - ETA: 15s - loss: 0.0827 - accuracy: 0.973 - ETA: 13s - loss: 0.0823 - accuracy: 0.974 - ETA: 12s - loss: 0.0825 - accuracy: 0.973 - ETA: 10s - loss: 0.0829 - accuracy: 0.973 - ETA: 9s - loss: 0.0825 - accuracy: 0.973 - ETA: 7s - loss: 0.0825 - accuracy: 0.97 - ETA: 6s - loss: 0.0825 - accuracy: 0.97 - ETA: 4s - loss: 0.0823 - accuracy: 0.97 - ETA: 2s - loss: 0.0822 - accuracy: 0.97 - ETA: 1s - loss: 0.0826 - accuracy: 0.97 - 270s 14ms/step - loss: 0.0826 - accuracy: 0.9739 - val_loss: 1.5806 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "19312/19312 [==============================] - ETA: 3:49 - loss: 0.1099 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0892 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0987 - accuracy: 0.97 - ETA: 3:47 - loss: 0.0875 - accuracy: 0.97 - ETA: 3:42 - loss: 0.0818 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0763 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0698 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0669 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0633 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0635 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0631 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0591 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0610 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0604 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0604 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0601 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0662 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0664 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0654 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0665 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0643 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0666 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0643 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0654 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0643 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0626 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0633 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0637 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0655 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0630 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0624 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0611 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0599 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0598 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0587 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0590 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0599 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0619 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0622 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0611 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0605 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0603 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0603 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0599 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0602 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0603 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0601 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0613 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0617 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0635 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0632 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0644 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0638 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0641 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0642 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0642 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0647 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0648 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0641 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0643 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0646 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0657 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0657 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0659 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0659 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0655 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0651 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0651 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0655 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0655 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0653 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0661 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0666 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0669 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0670 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0681 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0695 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0697 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0696 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0688 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0685 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0681 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0678 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0685 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0682 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0691 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0702 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0711 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0719 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0734 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0730 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0731 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0728 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0729 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0727 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0725 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0722 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0737 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0736 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0734 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0741 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0745 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0746 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0745 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0745 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0752 - accuracy: 0.97 - ETA: 59s - loss: 0.0762 - accuracy: 0.9765 - ETA: 58s - loss: 0.0760 - accuracy: 0.976 - ETA: 56s - loss: 0.0761 - accuracy: 0.976 - ETA: 55s - loss: 0.0763 - accuracy: 0.976 - ETA: 53s - loss: 0.0765 - accuracy: 0.976 - ETA: 52s - loss: 0.0767 - accuracy: 0.976 - ETA: 50s - loss: 0.0761 - accuracy: 0.976 - ETA: 49s - loss: 0.0761 - accuracy: 0.976 - ETA: 47s - loss: 0.0759 - accuracy: 0.976 - ETA: 46s - loss: 0.0757 - accuracy: 0.976 - ETA: 45s - loss: 0.0759 - accuracy: 0.976 - ETA: 43s - loss: 0.0756 - accuracy: 0.976 - ETA: 42s - loss: 0.0756 - accuracy: 0.976 - ETA: 40s - loss: 0.0767 - accuracy: 0.976 - ETA: 39s - loss: 0.0769 - accuracy: 0.976 - ETA: 37s - loss: 0.0778 - accuracy: 0.976 - ETA: 36s - loss: 0.0789 - accuracy: 0.975 - ETA: 34s - loss: 0.0789 - accuracy: 0.975 - ETA: 33s - loss: 0.0793 - accuracy: 0.975 - ETA: 31s - loss: 0.0794 - accuracy: 0.975 - ETA: 30s - loss: 0.0797 - accuracy: 0.975 - ETA: 29s - loss: 0.0795 - accuracy: 0.975 - ETA: 27s - loss: 0.0792 - accuracy: 0.975 - ETA: 26s - loss: 0.0793 - accuracy: 0.975 - ETA: 24s - loss: 0.0797 - accuracy: 0.975 - ETA: 23s - loss: 0.0799 - accuracy: 0.975 - ETA: 21s - loss: 0.0807 - accuracy: 0.975 - ETA: 20s - loss: 0.0807 - accuracy: 0.975 - ETA: 18s - loss: 0.0805 - accuracy: 0.975 - ETA: 17s - loss: 0.0800 - accuracy: 0.975 - ETA: 15s - loss: 0.0803 - accuracy: 0.975 - ETA: 14s - loss: 0.0801 - accuracy: 0.975 - ETA: 13s - loss: 0.0802 - accuracy: 0.975 - ETA: 11s - loss: 0.0798 - accuracy: 0.975 - ETA: 10s - loss: 0.0800 - accuracy: 0.975 - ETA: 8s - loss: 0.0800 - accuracy: 0.975 - ETA: 7s - loss: 0.0796 - accuracy: 0.97 - ETA: 5s - loss: 0.0792 - accuracy: 0.97 - ETA: 4s - loss: 0.0790 - accuracy: 0.97 - ETA: 2s - loss: 0.0789 - accuracy: 0.97 - ETA: 1s - loss: 0.0791 - accuracy: 0.97 - 255s 13ms/step - loss: 0.0790 - accuracy: 0.9758 - val_loss: 1.6092 - val_accuracy: 0.7995\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:09 - loss: 0.2437 - accuracy: 0.94 - ETA: 3:54 - loss: 0.1474 - accuracy: 0.96 - ETA: 3:52 - loss: 0.1179 - accuracy: 0.96 - ETA: 3:46 - loss: 0.0999 - accuracy: 0.97 - ETA: 3:42 - loss: 0.0937 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0865 - accuracy: 0.97 - ETA: 3:53 - loss: 0.0867 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0849 - accuracy: 0.97 - ETA: 3:42 - loss: 0.1005 - accuracy: 0.97 - ETA: 3:44 - loss: 0.0934 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0940 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0947 - accuracy: 0.97 - ETA: 3:36 - loss: 0.0901 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0890 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0864 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0877 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0851 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0824 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0847 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0829 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0807 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0789 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0784 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0793 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0802 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0801 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0802 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0828 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0833 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0845 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0871 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0863 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0843 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0836 - accuracy: 0.97 - ETA: 3:00 - loss: 0.0823 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0828 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0816 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0801 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0793 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0817 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0806 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0814 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0810 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0796 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0786 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0800 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0793 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0793 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0804 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0802 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0800 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0789 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0788 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0779 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0781 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0803 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0804 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0805 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0814 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0813 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0806 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0832 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0824 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0827 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0832 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0847 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0849 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0852 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0856 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0852 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0863 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0858 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0869 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0864 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0871 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0861 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0859 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0858 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0851 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0850 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0849 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0859 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0855 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0856 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0865 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0861 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0859 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0872 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0875 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0878 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0877 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0876 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0873 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0870 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0882 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0878 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0881 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0886 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0885 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0879 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0878 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0874 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0867 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0869 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0863 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0863 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0863 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0865 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0862 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0871 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0866 - accuracy: 0.97 - ETA: 59s - loss: 0.0867 - accuracy: 0.9731 - ETA: 57s - loss: 0.0873 - accuracy: 0.973 - ETA: 56s - loss: 0.0876 - accuracy: 0.973 - ETA: 54s - loss: 0.0871 - accuracy: 0.973 - ETA: 53s - loss: 0.0876 - accuracy: 0.972 - ETA: 51s - loss: 0.0886 - accuracy: 0.972 - ETA: 49s - loss: 0.0882 - accuracy: 0.972 - ETA: 48s - loss: 0.0883 - accuracy: 0.972 - ETA: 46s - loss: 0.0885 - accuracy: 0.972 - ETA: 45s - loss: 0.0880 - accuracy: 0.972 - ETA: 43s - loss: 0.0879 - accuracy: 0.972 - ETA: 42s - loss: 0.0878 - accuracy: 0.972 - ETA: 40s - loss: 0.0881 - accuracy: 0.972 - ETA: 39s - loss: 0.0877 - accuracy: 0.972 - ETA: 37s - loss: 0.0871 - accuracy: 0.973 - ETA: 36s - loss: 0.0866 - accuracy: 0.973 - ETA: 34s - loss: 0.0866 - accuracy: 0.973 - ETA: 33s - loss: 0.0865 - accuracy: 0.973 - ETA: 31s - loss: 0.0865 - accuracy: 0.973 - ETA: 30s - loss: 0.0861 - accuracy: 0.973 - ETA: 28s - loss: 0.0858 - accuracy: 0.973 - ETA: 27s - loss: 0.0855 - accuracy: 0.973 - ETA: 25s - loss: 0.0852 - accuracy: 0.973 - ETA: 24s - loss: 0.0849 - accuracy: 0.973 - ETA: 22s - loss: 0.0847 - accuracy: 0.973 - ETA: 21s - loss: 0.0843 - accuracy: 0.973 - ETA: 19s - loss: 0.0838 - accuracy: 0.973 - ETA: 18s - loss: 0.0834 - accuracy: 0.973 - ETA: 16s - loss: 0.0836 - accuracy: 0.973 - ETA: 14s - loss: 0.0838 - accuracy: 0.973 - ETA: 13s - loss: 0.0844 - accuracy: 0.973 - ETA: 11s - loss: 0.0844 - accuracy: 0.973 - ETA: 10s - loss: 0.0844 - accuracy: 0.973 - ETA: 8s - loss: 0.0850 - accuracy: 0.973 - ETA: 7s - loss: 0.0851 - accuracy: 0.97 - ETA: 5s - loss: 0.0848 - accuracy: 0.97 - ETA: 4s - loss: 0.0848 - accuracy: 0.97 - ETA: 2s - loss: 0.0850 - accuracy: 0.97 - ETA: 1s - loss: 0.0849 - accuracy: 0.97 - 269s 14ms/step - loss: 0.0845 - accuracy: 0.9734 - val_loss: 1.7783 - val_accuracy: 0.7983\n",
      "Epoch 48/100\n",
      "19312/19312 [==============================] - ETA: 4:38 - loss: 0.0880 - accuracy: 0.96 - ETA: 4:12 - loss: 0.1128 - accuracy: 0.96 - ETA: 3:56 - loss: 0.0978 - accuracy: 0.96 - ETA: 3:48 - loss: 0.1224 - accuracy: 0.96 - ETA: 3:41 - loss: 0.1185 - accuracy: 0.96 - ETA: 3:34 - loss: 0.1081 - accuracy: 0.96 - ETA: 3:34 - loss: 0.0990 - accuracy: 0.97 - ETA: 3:33 - loss: 0.1146 - accuracy: 0.96 - ETA: 3:31 - loss: 0.1039 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0966 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0959 - accuracy: 0.97 - ETA: 3:35 - loss: 0.0938 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0925 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0890 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0885 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0849 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0821 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0813 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0802 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0776 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0766 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0758 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0753 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0765 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0771 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0766 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0780 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0776 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0782 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0765 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0768 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0772 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0760 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0761 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0789 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0788 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0771 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0767 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0780 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0770 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0752 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0781 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0789 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0777 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0779 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0771 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0763 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0769 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0781 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0769 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0765 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0754 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0747 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0747 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0738 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0736 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0731 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0725 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0719 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0735 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0743 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0745 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0756 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0760 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0760 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0751 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0755 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0761 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0757 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0753 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0749 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0745 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0745 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0748 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0741 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0741 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0747 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0750 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0752 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0756 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0756 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0764 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0761 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0761 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0759 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0760 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0765 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0761 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0763 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0761 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0760 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0760 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0762 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0759 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0761 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0756 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0753 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0747 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0743 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0741 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0738 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0738 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0737 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0738 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0736 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0732 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0730 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0730 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0734 - accuracy: 0.97 - ETA: 59s - loss: 0.0736 - accuracy: 0.9771 - ETA: 57s - loss: 0.0737 - accuracy: 0.976 - ETA: 56s - loss: 0.0734 - accuracy: 0.976 - ETA: 54s - loss: 0.0731 - accuracy: 0.977 - ETA: 53s - loss: 0.0728 - accuracy: 0.977 - ETA: 51s - loss: 0.0728 - accuracy: 0.976 - ETA: 50s - loss: 0.0733 - accuracy: 0.976 - ETA: 48s - loss: 0.0733 - accuracy: 0.976 - ETA: 47s - loss: 0.0732 - accuracy: 0.976 - ETA: 45s - loss: 0.0731 - accuracy: 0.976 - ETA: 44s - loss: 0.0729 - accuracy: 0.976 - ETA: 42s - loss: 0.0730 - accuracy: 0.976 - ETA: 41s - loss: 0.0733 - accuracy: 0.976 - ETA: 39s - loss: 0.0734 - accuracy: 0.976 - ETA: 38s - loss: 0.0730 - accuracy: 0.976 - ETA: 36s - loss: 0.0727 - accuracy: 0.976 - ETA: 35s - loss: 0.0728 - accuracy: 0.976 - ETA: 33s - loss: 0.0728 - accuracy: 0.976 - ETA: 32s - loss: 0.0733 - accuracy: 0.976 - ETA: 30s - loss: 0.0734 - accuracy: 0.976 - ETA: 29s - loss: 0.0737 - accuracy: 0.976 - ETA: 27s - loss: 0.0740 - accuracy: 0.976 - ETA: 26s - loss: 0.0742 - accuracy: 0.976 - ETA: 24s - loss: 0.0748 - accuracy: 0.976 - ETA: 23s - loss: 0.0746 - accuracy: 0.976 - ETA: 22s - loss: 0.0744 - accuracy: 0.976 - ETA: 20s - loss: 0.0750 - accuracy: 0.976 - ETA: 19s - loss: 0.0753 - accuracy: 0.976 - ETA: 17s - loss: 0.0753 - accuracy: 0.976 - ETA: 16s - loss: 0.0751 - accuracy: 0.976 - ETA: 14s - loss: 0.0752 - accuracy: 0.976 - ETA: 13s - loss: 0.0754 - accuracy: 0.976 - ETA: 11s - loss: 0.0751 - accuracy: 0.976 - ETA: 10s - loss: 0.0750 - accuracy: 0.976 - ETA: 8s - loss: 0.0751 - accuracy: 0.976 - ETA: 7s - loss: 0.0752 - accuracy: 0.97 - ETA: 5s - loss: 0.0754 - accuracy: 0.97 - ETA: 4s - loss: 0.0750 - accuracy: 0.97 - ETA: 2s - loss: 0.0748 - accuracy: 0.97 - ETA: 1s - loss: 0.0746 - accuracy: 0.97 - 262s 14ms/step - loss: 0.0748 - accuracy: 0.9765 - val_loss: 1.6763 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:50 - loss: 0.0556 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0978 - accuracy: 0.97 - ETA: 3:46 - loss: 0.0668 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0621 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0806 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0872 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0846 - accuracy: 0.97 - ETA: 3:35 - loss: 0.0832 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0782 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0744 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0693 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0670 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0641 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0676 - accuracy: 0.97 - ETA: 3:23 - loss: 0.0668 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0681 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0748 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0776 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0763 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0738 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0728 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0763 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0775 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0753 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0747 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0732 - accuracy: 0.97 - ETA: 3:11 - loss: 0.0745 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0758 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0741 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0734 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0720 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0703 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0706 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0701 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0694 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0692 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0710 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0716 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0746 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0742 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0749 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0757 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0742 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0737 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0726 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0724 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0721 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0731 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0728 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0727 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0716 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0720 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0718 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0712 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0713 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0730 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0727 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0730 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0733 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0727 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0725 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0721 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0714 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0716 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0720 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0733 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0742 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0739 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0739 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0738 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0737 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0734 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0741 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0738 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0739 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0736 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0742 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0738 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0741 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0732 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0727 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0727 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0727 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0726 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0719 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0712 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0708 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0713 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0706 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0706 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0703 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0707 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0707 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0708 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0706 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0712 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0707 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0709 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0707 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0707 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0717 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0723 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0723 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0722 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0727 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0727 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0733 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0729 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0730 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0727 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0732 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0732 - accuracy: 0.97 - ETA: 59s - loss: 0.0740 - accuracy: 0.9772 - ETA: 58s - loss: 0.0736 - accuracy: 0.977 - ETA: 56s - loss: 0.0734 - accuracy: 0.977 - ETA: 54s - loss: 0.0735 - accuracy: 0.977 - ETA: 53s - loss: 0.0733 - accuracy: 0.977 - ETA: 51s - loss: 0.0736 - accuracy: 0.977 - ETA: 50s - loss: 0.0732 - accuracy: 0.977 - ETA: 48s - loss: 0.0728 - accuracy: 0.977 - ETA: 47s - loss: 0.0732 - accuracy: 0.977 - ETA: 45s - loss: 0.0738 - accuracy: 0.977 - ETA: 43s - loss: 0.0734 - accuracy: 0.977 - ETA: 42s - loss: 0.0733 - accuracy: 0.977 - ETA: 40s - loss: 0.0729 - accuracy: 0.977 - ETA: 39s - loss: 0.0725 - accuracy: 0.977 - ETA: 37s - loss: 0.0729 - accuracy: 0.977 - ETA: 36s - loss: 0.0728 - accuracy: 0.977 - ETA: 34s - loss: 0.0726 - accuracy: 0.977 - ETA: 32s - loss: 0.0727 - accuracy: 0.977 - ETA: 31s - loss: 0.0728 - accuracy: 0.977 - ETA: 29s - loss: 0.0730 - accuracy: 0.977 - ETA: 28s - loss: 0.0730 - accuracy: 0.977 - ETA: 26s - loss: 0.0734 - accuracy: 0.977 - ETA: 24s - loss: 0.0735 - accuracy: 0.977 - ETA: 23s - loss: 0.0730 - accuracy: 0.977 - ETA: 21s - loss: 0.0728 - accuracy: 0.977 - ETA: 20s - loss: 0.0725 - accuracy: 0.977 - ETA: 18s - loss: 0.0723 - accuracy: 0.977 - ETA: 17s - loss: 0.0723 - accuracy: 0.977 - ETA: 15s - loss: 0.0718 - accuracy: 0.977 - ETA: 13s - loss: 0.0728 - accuracy: 0.977 - ETA: 12s - loss: 0.0730 - accuracy: 0.977 - ETA: 10s - loss: 0.0728 - accuracy: 0.977 - ETA: 9s - loss: 0.0731 - accuracy: 0.977 - ETA: 7s - loss: 0.0731 - accuracy: 0.97 - ETA: 6s - loss: 0.0729 - accuracy: 0.97 - ETA: 4s - loss: 0.0727 - accuracy: 0.97 - ETA: 2s - loss: 0.0726 - accuracy: 0.97 - ETA: 1s - loss: 0.0727 - accuracy: 0.97 - 271s 14ms/step - loss: 0.0726 - accuracy: 0.9775 - val_loss: 1.6417 - val_accuracy: 0.8002\n",
      "Epoch 50/100\n",
      "19312/19312 [==============================] - ETA: 2:54 - loss: 0.1596 - accuracy: 0.94 - ETA: 2:49 - loss: 0.0954 - accuracy: 0.96 - ETA: 2:44 - loss: 0.0858 - accuracy: 0.96 - ETA: 2:39 - loss: 0.0820 - accuracy: 0.96 - ETA: 2:38 - loss: 0.0767 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0746 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0816 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0829 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0809 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0870 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0926 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0944 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0959 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0975 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0916 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0869 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0874 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0848 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0805 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0806 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0851 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0856 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0839 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0810 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0807 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0783 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0785 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0792 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0796 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0791 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0773 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0762 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0764 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0759 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0759 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0747 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0740 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0740 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0731 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0734 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0729 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0726 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0732 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0727 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0728 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0730 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0736 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0741 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0731 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0730 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0729 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0726 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0722 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0712 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0721 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0713 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0711 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0713 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0709 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0738 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0736 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0739 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0748 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0754 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0750 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0749 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0753 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0749 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0742 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0743 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0739 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0757 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0754 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0757 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0749 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0753 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0758 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0758 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0754 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0758 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0758 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0751 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0765 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0759 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0760 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0755 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0754 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0748 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0751 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0745 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0743 - accuracy: 0.97 - ETA: 59s - loss: 0.0738 - accuracy: 0.9764 - ETA: 58s - loss: 0.0733 - accuracy: 0.976 - ETA: 57s - loss: 0.0732 - accuracy: 0.976 - ETA: 56s - loss: 0.0730 - accuracy: 0.976 - ETA: 55s - loss: 0.0729 - accuracy: 0.976 - ETA: 54s - loss: 0.0735 - accuracy: 0.976 - ETA: 53s - loss: 0.0728 - accuracy: 0.976 - ETA: 52s - loss: 0.0728 - accuracy: 0.976 - ETA: 51s - loss: 0.0729 - accuracy: 0.976 - ETA: 50s - loss: 0.0725 - accuracy: 0.976 - ETA: 48s - loss: 0.0722 - accuracy: 0.976 - ETA: 48s - loss: 0.0718 - accuracy: 0.976 - ETA: 47s - loss: 0.0719 - accuracy: 0.976 - ETA: 46s - loss: 0.0713 - accuracy: 0.977 - ETA: 44s - loss: 0.0709 - accuracy: 0.977 - ETA: 43s - loss: 0.0710 - accuracy: 0.977 - ETA: 42s - loss: 0.0708 - accuracy: 0.977 - ETA: 41s - loss: 0.0717 - accuracy: 0.977 - ETA: 40s - loss: 0.0715 - accuracy: 0.977 - ETA: 39s - loss: 0.0711 - accuracy: 0.977 - ETA: 38s - loss: 0.0719 - accuracy: 0.977 - ETA: 37s - loss: 0.0715 - accuracy: 0.977 - ETA: 36s - loss: 0.0712 - accuracy: 0.977 - ETA: 35s - loss: 0.0715 - accuracy: 0.977 - ETA: 34s - loss: 0.0713 - accuracy: 0.977 - ETA: 33s - loss: 0.0708 - accuracy: 0.977 - ETA: 32s - loss: 0.0712 - accuracy: 0.977 - ETA: 31s - loss: 0.0723 - accuracy: 0.977 - ETA: 30s - loss: 0.0724 - accuracy: 0.977 - ETA: 29s - loss: 0.0720 - accuracy: 0.977 - ETA: 28s - loss: 0.0721 - accuracy: 0.977 - ETA: 27s - loss: 0.0731 - accuracy: 0.976 - ETA: 26s - loss: 0.0726 - accuracy: 0.977 - ETA: 25s - loss: 0.0723 - accuracy: 0.977 - ETA: 24s - loss: 0.0721 - accuracy: 0.977 - ETA: 23s - loss: 0.0722 - accuracy: 0.977 - ETA: 22s - loss: 0.0718 - accuracy: 0.977 - ETA: 21s - loss: 0.0720 - accuracy: 0.977 - ETA: 20s - loss: 0.0716 - accuracy: 0.977 - ETA: 19s - loss: 0.0716 - accuracy: 0.977 - ETA: 18s - loss: 0.0715 - accuracy: 0.977 - ETA: 17s - loss: 0.0712 - accuracy: 0.977 - ETA: 16s - loss: 0.0710 - accuracy: 0.977 - ETA: 15s - loss: 0.0715 - accuracy: 0.977 - ETA: 14s - loss: 0.0715 - accuracy: 0.977 - ETA: 13s - loss: 0.0718 - accuracy: 0.977 - ETA: 12s - loss: 0.0724 - accuracy: 0.976 - ETA: 11s - loss: 0.0728 - accuracy: 0.976 - ETA: 10s - loss: 0.0733 - accuracy: 0.976 - ETA: 9s - loss: 0.0737 - accuracy: 0.976 - ETA: 8s - loss: 0.0736 - accuracy: 0.97 - ETA: 7s - loss: 0.0734 - accuracy: 0.97 - ETA: 6s - loss: 0.0733 - accuracy: 0.97 - ETA: 5s - loss: 0.0734 - accuracy: 0.97 - ETA: 3s - loss: 0.0731 - accuracy: 0.97 - ETA: 2s - loss: 0.0734 - accuracy: 0.97 - ETA: 1s - loss: 0.0731 - accuracy: 0.97 - ETA: 0s - loss: 0.0728 - accuracy: 0.97 - 181s 9ms/step - loss: 0.0728 - accuracy: 0.9766 - val_loss: 1.6414 - val_accuracy: 0.8002\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:43 - loss: 0.1170 - accuracy: 0.96 - ETA: 2:36 - loss: 0.0942 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0802 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0710 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0757 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0704 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0629 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0666 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0705 - accuracy: 0.97 - ETA: 2:24 - loss: 0.0692 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0745 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0745 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0739 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0695 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0674 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0664 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0681 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0692 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0684 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0684 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0693 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0717 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0705 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0698 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0687 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0685 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0700 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0690 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0680 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0683 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0683 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0681 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0677 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0667 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0680 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0675 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0676 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0691 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0696 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0689 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0680 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0678 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0673 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0681 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0714 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0707 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0736 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0730 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0721 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0712 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0701 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0690 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0691 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0707 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0710 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0704 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0712 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0715 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0712 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0702 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0693 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0693 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0685 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0691 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0690 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0692 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0689 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0683 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0681 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0678 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0696 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0713 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0716 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0711 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0705 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0703 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0707 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0698 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0703 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0698 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0695 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0688 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0682 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0681 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0685 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0686 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0683 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0682 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0680 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0688 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0685 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0700 - accuracy: 0.97 - ETA: 59s - loss: 0.0706 - accuracy: 0.9784 - ETA: 58s - loss: 0.0709 - accuracy: 0.978 - ETA: 57s - loss: 0.0711 - accuracy: 0.978 - ETA: 55s - loss: 0.0712 - accuracy: 0.978 - ETA: 54s - loss: 0.0712 - accuracy: 0.978 - ETA: 53s - loss: 0.0720 - accuracy: 0.977 - ETA: 52s - loss: 0.0718 - accuracy: 0.977 - ETA: 51s - loss: 0.0720 - accuracy: 0.977 - ETA: 50s - loss: 0.0715 - accuracy: 0.977 - ETA: 49s - loss: 0.0720 - accuracy: 0.977 - ETA: 48s - loss: 0.0733 - accuracy: 0.977 - ETA: 47s - loss: 0.0729 - accuracy: 0.977 - ETA: 46s - loss: 0.0731 - accuracy: 0.977 - ETA: 45s - loss: 0.0728 - accuracy: 0.977 - ETA: 44s - loss: 0.0731 - accuracy: 0.977 - ETA: 43s - loss: 0.0734 - accuracy: 0.976 - ETA: 42s - loss: 0.0738 - accuracy: 0.976 - ETA: 41s - loss: 0.0750 - accuracy: 0.976 - ETA: 40s - loss: 0.0747 - accuracy: 0.976 - ETA: 39s - loss: 0.0744 - accuracy: 0.976 - ETA: 38s - loss: 0.0740 - accuracy: 0.977 - ETA: 37s - loss: 0.0737 - accuracy: 0.977 - ETA: 36s - loss: 0.0737 - accuracy: 0.977 - ETA: 35s - loss: 0.0741 - accuracy: 0.977 - ETA: 34s - loss: 0.0739 - accuracy: 0.977 - ETA: 33s - loss: 0.0742 - accuracy: 0.976 - ETA: 32s - loss: 0.0743 - accuracy: 0.976 - ETA: 31s - loss: 0.0740 - accuracy: 0.976 - ETA: 30s - loss: 0.0738 - accuracy: 0.976 - ETA: 29s - loss: 0.0736 - accuracy: 0.977 - ETA: 28s - loss: 0.0738 - accuracy: 0.977 - ETA: 27s - loss: 0.0737 - accuracy: 0.977 - ETA: 26s - loss: 0.0736 - accuracy: 0.977 - ETA: 25s - loss: 0.0733 - accuracy: 0.977 - ETA: 24s - loss: 0.0733 - accuracy: 0.977 - ETA: 23s - loss: 0.0736 - accuracy: 0.977 - ETA: 22s - loss: 0.0737 - accuracy: 0.977 - ETA: 21s - loss: 0.0740 - accuracy: 0.977 - ETA: 20s - loss: 0.0736 - accuracy: 0.977 - ETA: 19s - loss: 0.0735 - accuracy: 0.977 - ETA: 18s - loss: 0.0734 - accuracy: 0.977 - ETA: 17s - loss: 0.0732 - accuracy: 0.977 - ETA: 16s - loss: 0.0730 - accuracy: 0.977 - ETA: 15s - loss: 0.0737 - accuracy: 0.977 - ETA: 14s - loss: 0.0735 - accuracy: 0.977 - ETA: 13s - loss: 0.0735 - accuracy: 0.977 - ETA: 12s - loss: 0.0737 - accuracy: 0.977 - ETA: 11s - loss: 0.0735 - accuracy: 0.977 - ETA: 10s - loss: 0.0738 - accuracy: 0.977 - ETA: 9s - loss: 0.0735 - accuracy: 0.977 - ETA: 8s - loss: 0.0730 - accuracy: 0.97 - ETA: 7s - loss: 0.0727 - accuracy: 0.97 - ETA: 5s - loss: 0.0729 - accuracy: 0.97 - ETA: 4s - loss: 0.0730 - accuracy: 0.97 - ETA: 3s - loss: 0.0729 - accuracy: 0.97 - ETA: 2s - loss: 0.0731 - accuracy: 0.97 - ETA: 1s - loss: 0.0735 - accuracy: 0.97 - ETA: 0s - loss: 0.0732 - accuracy: 0.97 - 189s 10ms/step - loss: 0.0729 - accuracy: 0.9773 - val_loss: 1.6597 - val_accuracy: 0.7991\n",
      "Epoch 52/100\n",
      "19312/19312 [==============================] - ETA: 2:34 - loss: 0.0429 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0689 - accuracy: 0.97 - ETA: 2:28 - loss: 0.0531 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0622 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0564 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0590 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0668 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0668 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0694 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0661 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0701 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0689 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0660 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0620 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0618 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0603 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0604 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0608 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0622 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0614 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0603 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0609 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0622 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0631 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0625 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0609 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0600 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0609 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0605 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0622 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0618 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0620 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0646 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0626 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0626 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0636 - accuracy: 0.98 - ETA: 59s - loss: 0.0638 - accuracy: 0.9814 - ETA: 58s - loss: 0.0634 - accuracy: 0.981 - ETA: 57s - loss: 0.0635 - accuracy: 0.981 - ETA: 56s - loss: 0.0636 - accuracy: 0.981 - ETA: 55s - loss: 0.0634 - accuracy: 0.981 - ETA: 53s - loss: 0.0638 - accuracy: 0.981 - ETA: 52s - loss: 0.0634 - accuracy: 0.981 - ETA: 51s - loss: 0.0633 - accuracy: 0.981 - ETA: 50s - loss: 0.0636 - accuracy: 0.981 - ETA: 49s - loss: 0.0641 - accuracy: 0.981 - ETA: 48s - loss: 0.0656 - accuracy: 0.981 - ETA: 47s - loss: 0.0658 - accuracy: 0.981 - ETA: 46s - loss: 0.0653 - accuracy: 0.981 - ETA: 44s - loss: 0.0652 - accuracy: 0.981 - ETA: 43s - loss: 0.0657 - accuracy: 0.981 - ETA: 42s - loss: 0.0660 - accuracy: 0.981 - ETA: 41s - loss: 0.0663 - accuracy: 0.980 - ETA: 40s - loss: 0.0667 - accuracy: 0.980 - ETA: 39s - loss: 0.0666 - accuracy: 0.980 - ETA: 38s - loss: 0.0667 - accuracy: 0.980 - ETA: 37s - loss: 0.0664 - accuracy: 0.980 - ETA: 36s - loss: 0.0663 - accuracy: 0.980 - ETA: 35s - loss: 0.0662 - accuracy: 0.980 - ETA: 34s - loss: 0.0665 - accuracy: 0.980 - ETA: 32s - loss: 0.0665 - accuracy: 0.980 - ETA: 31s - loss: 0.0665 - accuracy: 0.980 - ETA: 30s - loss: 0.0665 - accuracy: 0.980 - ETA: 29s - loss: 0.0664 - accuracy: 0.980 - ETA: 28s - loss: 0.0665 - accuracy: 0.980 - ETA: 27s - loss: 0.0664 - accuracy: 0.980 - ETA: 26s - loss: 0.0660 - accuracy: 0.980 - ETA: 25s - loss: 0.0658 - accuracy: 0.980 - ETA: 24s - loss: 0.0656 - accuracy: 0.980 - ETA: 23s - loss: 0.0655 - accuracy: 0.980 - ETA: 22s - loss: 0.0652 - accuracy: 0.980 - ETA: 21s - loss: 0.0653 - accuracy: 0.980 - ETA: 19s - loss: 0.0656 - accuracy: 0.980 - ETA: 18s - loss: 0.0658 - accuracy: 0.980 - ETA: 17s - loss: 0.0660 - accuracy: 0.980 - ETA: 16s - loss: 0.0667 - accuracy: 0.980 - ETA: 15s - loss: 0.0666 - accuracy: 0.980 - ETA: 13s - loss: 0.0677 - accuracy: 0.979 - ETA: 12s - loss: 0.0676 - accuracy: 0.979 - ETA: 11s - loss: 0.0674 - accuracy: 0.979 - ETA: 10s - loss: 0.0674 - accuracy: 0.979 - ETA: 8s - loss: 0.0672 - accuracy: 0.979 - ETA: 7s - loss: 0.0671 - accuracy: 0.97 - ETA: 6s - loss: 0.0672 - accuracy: 0.97 - ETA: 5s - loss: 0.0673 - accuracy: 0.97 - ETA: 3s - loss: 0.0673 - accuracy: 0.97 - ETA: 2s - loss: 0.0670 - accuracy: 0.97 - ETA: 1s - loss: 0.0669 - accuracy: 0.97 - 234s 12ms/step - loss: 0.0672 - accuracy: 0.9796 - val_loss: 1.6568 - val_accuracy: 0.8016\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:49 - loss: 0.1003 - accuracy: 0.95 - ETA: 4:19 - loss: 0.0750 - accuracy: 0.96 - ETA: 4:06 - loss: 0.0608 - accuracy: 0.97 - ETA: 3:57 - loss: 0.0616 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0616 - accuracy: 0.97 - ETA: 3:56 - loss: 0.0615 - accuracy: 0.97 - ETA: 3:56 - loss: 0.0742 - accuracy: 0.96 - ETA: 3:52 - loss: 0.0708 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0774 - accuracy: 0.96 - ETA: 3:46 - loss: 0.0733 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0703 - accuracy: 0.97 - ETA: 3:39 - loss: 0.0669 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0641 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0633 - accuracy: 0.97 - ETA: 3:35 - loss: 0.0622 - accuracy: 0.97 - ETA: 3:32 - loss: 0.0717 - accuracy: 0.97 - ETA: 3:30 - loss: 0.0752 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0727 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0718 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0695 - accuracy: 0.97 - ETA: 3:26 - loss: 0.0683 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0686 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0685 - accuracy: 0.97 - ETA: 3:20 - loss: 0.0684 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0668 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0669 - accuracy: 0.97 - ETA: 3:13 - loss: 0.0657 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0648 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0643 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0646 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0635 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0642 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0633 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0617 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0600 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0593 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0615 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0606 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0602 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0608 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0598 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0603 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0601 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0599 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0602 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0600 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0599 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0592 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0588 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0592 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0588 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0583 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0578 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0578 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0577 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0581 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0575 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0584 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0578 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0589 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0578 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0578 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0572 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0579 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0587 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0583 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0589 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0585 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0612 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0609 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0607 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0603 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0602 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0604 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0602 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0603 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0603 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0602 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0598 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0604 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0600 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0595 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0592 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0602 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0602 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0599 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0597 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0601 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0602 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0616 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0623 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0621 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0626 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0627 - accuracy: 0.97 - ETA: 58s - loss: 0.0625 - accuracy: 0.9794 - ETA: 57s - loss: 0.0633 - accuracy: 0.979 - ETA: 55s - loss: 0.0635 - accuracy: 0.979 - ETA: 53s - loss: 0.0633 - accuracy: 0.979 - ETA: 52s - loss: 0.0633 - accuracy: 0.979 - ETA: 50s - loss: 0.0634 - accuracy: 0.979 - ETA: 49s - loss: 0.0631 - accuracy: 0.979 - ETA: 47s - loss: 0.0635 - accuracy: 0.979 - ETA: 46s - loss: 0.0640 - accuracy: 0.979 - ETA: 44s - loss: 0.0642 - accuracy: 0.979 - ETA: 42s - loss: 0.0639 - accuracy: 0.979 - ETA: 41s - loss: 0.0637 - accuracy: 0.979 - ETA: 39s - loss: 0.0636 - accuracy: 0.979 - ETA: 37s - loss: 0.0632 - accuracy: 0.979 - ETA: 36s - loss: 0.0636 - accuracy: 0.979 - ETA: 34s - loss: 0.0633 - accuracy: 0.979 - ETA: 33s - loss: 0.0634 - accuracy: 0.979 - ETA: 31s - loss: 0.0639 - accuracy: 0.979 - ETA: 30s - loss: 0.0635 - accuracy: 0.979 - ETA: 28s - loss: 0.0632 - accuracy: 0.979 - ETA: 26s - loss: 0.0632 - accuracy: 0.979 - ETA: 25s - loss: 0.0628 - accuracy: 0.979 - ETA: 23s - loss: 0.0624 - accuracy: 0.979 - ETA: 22s - loss: 0.0625 - accuracy: 0.979 - ETA: 20s - loss: 0.0621 - accuracy: 0.979 - ETA: 18s - loss: 0.0623 - accuracy: 0.979 - ETA: 17s - loss: 0.0630 - accuracy: 0.979 - ETA: 15s - loss: 0.0630 - accuracy: 0.979 - ETA: 14s - loss: 0.0628 - accuracy: 0.979 - ETA: 12s - loss: 0.0634 - accuracy: 0.979 - ETA: 11s - loss: 0.0635 - accuracy: 0.979 - ETA: 9s - loss: 0.0638 - accuracy: 0.979 - ETA: 7s - loss: 0.0640 - accuracy: 0.97 - ETA: 6s - loss: 0.0637 - accuracy: 0.97 - ETA: 4s - loss: 0.0638 - accuracy: 0.97 - ETA: 3s - loss: 0.0637 - accuracy: 0.97 - ETA: 1s - loss: 0.0635 - accuracy: 0.97 - 271s 14ms/step - loss: 0.0632 - accuracy: 0.9793 - val_loss: 1.6515 - val_accuracy: 0.8058\n",
      "Epoch 54/100\n",
      "19312/19312 [==============================] - ETA: 3:42 - loss: 0.0401 - accuracy: 0.99 - ETA: 3:44 - loss: 0.0646 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0510 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0562 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0646 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0565 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0708 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0816 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0776 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0804 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0807 - accuracy: 0.97 - ETA: 3:21 - loss: 0.0778 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0724 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0697 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0711 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0678 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0662 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0631 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0638 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0628 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0613 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0620 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0635 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0661 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0656 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0655 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0641 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0646 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0643 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0666 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0663 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0659 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0672 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0658 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0647 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0644 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0642 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0653 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0664 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0669 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0708 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0697 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0690 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0693 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0681 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0670 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0674 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0664 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0658 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0653 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0650 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0643 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0641 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0637 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0630 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0639 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0621 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0622 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0624 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0625 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0624 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0617 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0614 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0610 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0608 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0584 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0605 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0598 - accuracy: 0.98 - ETA: 59s - loss: 0.0601 - accuracy: 0.9815 - ETA: 57s - loss: 0.0603 - accuracy: 0.981 - ETA: 55s - loss: 0.0600 - accuracy: 0.981 - ETA: 54s - loss: 0.0599 - accuracy: 0.981 - ETA: 52s - loss: 0.0599 - accuracy: 0.981 - ETA: 51s - loss: 0.0602 - accuracy: 0.981 - ETA: 49s - loss: 0.0599 - accuracy: 0.981 - ETA: 48s - loss: 0.0603 - accuracy: 0.981 - ETA: 46s - loss: 0.0606 - accuracy: 0.981 - ETA: 45s - loss: 0.0602 - accuracy: 0.981 - ETA: 43s - loss: 0.0598 - accuracy: 0.981 - ETA: 42s - loss: 0.0600 - accuracy: 0.981 - ETA: 40s - loss: 0.0599 - accuracy: 0.981 - ETA: 39s - loss: 0.0595 - accuracy: 0.981 - ETA: 37s - loss: 0.0592 - accuracy: 0.981 - ETA: 36s - loss: 0.0589 - accuracy: 0.981 - ETA: 34s - loss: 0.0588 - accuracy: 0.981 - ETA: 33s - loss: 0.0590 - accuracy: 0.981 - ETA: 31s - loss: 0.0590 - accuracy: 0.981 - ETA: 30s - loss: 0.0588 - accuracy: 0.981 - ETA: 28s - loss: 0.0586 - accuracy: 0.981 - ETA: 27s - loss: 0.0585 - accuracy: 0.981 - ETA: 25s - loss: 0.0582 - accuracy: 0.981 - ETA: 23s - loss: 0.0586 - accuracy: 0.981 - ETA: 22s - loss: 0.0588 - accuracy: 0.981 - ETA: 20s - loss: 0.0590 - accuracy: 0.981 - ETA: 19s - loss: 0.0589 - accuracy: 0.981 - ETA: 17s - loss: 0.0590 - accuracy: 0.981 - ETA: 16s - loss: 0.0590 - accuracy: 0.981 - ETA: 14s - loss: 0.0586 - accuracy: 0.981 - ETA: 13s - loss: 0.0583 - accuracy: 0.981 - ETA: 11s - loss: 0.0582 - accuracy: 0.981 - ETA: 10s - loss: 0.0585 - accuracy: 0.981 - ETA: 8s - loss: 0.0587 - accuracy: 0.981 - ETA: 7s - loss: 0.0588 - accuracy: 0.98 - ETA: 5s - loss: 0.0588 - accuracy: 0.98 - ETA: 4s - loss: 0.0587 - accuracy: 0.98 - ETA: 2s - loss: 0.0586 - accuracy: 0.98 - ETA: 1s - loss: 0.0582 - accuracy: 0.98 - 257s 13ms/step - loss: 0.0581 - accuracy: 0.9812 - val_loss: 1.6584 - val_accuracy: 0.8020\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:51 - loss: 0.0397 - accuracy: 0.99 - ETA: 3:48 - loss: 0.0552 - accuracy: 0.99 - ETA: 3:41 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0570 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0622 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0651 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0620 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0583 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0574 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0579 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0626 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0610 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0586 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0611 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0592 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0588 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0603 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0632 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0619 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0640 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0671 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0692 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0697 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0701 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0693 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0695 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0704 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0701 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0701 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0713 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0705 - accuracy: 0.97 - ETA: 2:56 - loss: 0.0692 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0678 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0669 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0657 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0674 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0670 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0668 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0665 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0672 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0671 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0676 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0673 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0673 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0674 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0667 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0653 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0639 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0619 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0621 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0609 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0613 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0616 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0607 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0621 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0639 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0638 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0647 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0639 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0658 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0671 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0673 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0666 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0662 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0659 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0673 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0674 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0675 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0691 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0695 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0689 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0688 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0695 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0694 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0693 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0687 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0682 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0683 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0682 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0675 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0675 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0674 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0679 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0673 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0674 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0659 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0660 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0662 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0659 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0653 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0655 - accuracy: 0.98 - ETA: 59s - loss: 0.0653 - accuracy: 0.9806 - ETA: 57s - loss: 0.0650 - accuracy: 0.980 - ETA: 56s - loss: 0.0647 - accuracy: 0.980 - ETA: 54s - loss: 0.0643 - accuracy: 0.980 - ETA: 53s - loss: 0.0643 - accuracy: 0.980 - ETA: 51s - loss: 0.0658 - accuracy: 0.980 - ETA: 50s - loss: 0.0655 - accuracy: 0.980 - ETA: 48s - loss: 0.0653 - accuracy: 0.980 - ETA: 47s - loss: 0.0658 - accuracy: 0.980 - ETA: 45s - loss: 0.0657 - accuracy: 0.980 - ETA: 44s - loss: 0.0656 - accuracy: 0.980 - ETA: 42s - loss: 0.0653 - accuracy: 0.980 - ETA: 41s - loss: 0.0653 - accuracy: 0.980 - ETA: 39s - loss: 0.0652 - accuracy: 0.980 - ETA: 38s - loss: 0.0651 - accuracy: 0.980 - ETA: 36s - loss: 0.0650 - accuracy: 0.980 - ETA: 35s - loss: 0.0648 - accuracy: 0.980 - ETA: 33s - loss: 0.0647 - accuracy: 0.980 - ETA: 32s - loss: 0.0644 - accuracy: 0.980 - ETA: 30s - loss: 0.0645 - accuracy: 0.980 - ETA: 29s - loss: 0.0645 - accuracy: 0.980 - ETA: 27s - loss: 0.0642 - accuracy: 0.980 - ETA: 26s - loss: 0.0645 - accuracy: 0.980 - ETA: 24s - loss: 0.0650 - accuracy: 0.980 - ETA: 23s - loss: 0.0651 - accuracy: 0.980 - ETA: 22s - loss: 0.0648 - accuracy: 0.980 - ETA: 20s - loss: 0.0647 - accuracy: 0.980 - ETA: 19s - loss: 0.0649 - accuracy: 0.980 - ETA: 17s - loss: 0.0652 - accuracy: 0.980 - ETA: 16s - loss: 0.0649 - accuracy: 0.980 - ETA: 14s - loss: 0.0647 - accuracy: 0.980 - ETA: 13s - loss: 0.0647 - accuracy: 0.980 - ETA: 11s - loss: 0.0648 - accuracy: 0.980 - ETA: 10s - loss: 0.0649 - accuracy: 0.980 - ETA: 8s - loss: 0.0649 - accuracy: 0.980 - ETA: 7s - loss: 0.0652 - accuracy: 0.98 - ETA: 5s - loss: 0.0655 - accuracy: 0.98 - ETA: 4s - loss: 0.0652 - accuracy: 0.98 - ETA: 2s - loss: 0.0649 - accuracy: 0.98 - ETA: 1s - loss: 0.0648 - accuracy: 0.98 - 259s 13ms/step - loss: 0.0649 - accuracy: 0.9802 - val_loss: 1.7074 - val_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "19312/19312 [==============================] - ETA: 3:52 - loss: 0.0821 - accuracy: 0.96 - ETA: 4:37 - loss: 0.0472 - accuracy: 0.97 - ETA: 4:15 - loss: 0.0739 - accuracy: 0.97 - ETA: 4:04 - loss: 0.0614 - accuracy: 0.97 - ETA: 3:52 - loss: 0.0695 - accuracy: 0.97 - ETA: 4:01 - loss: 0.0605 - accuracy: 0.97 - ETA: 3:52 - loss: 0.0675 - accuracy: 0.97 - ETA: 3:50 - loss: 0.0645 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0591 - accuracy: 0.97 - ETA: 3:47 - loss: 0.0594 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0558 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0517 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0577 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0541 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0577 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0612 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0605 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0599 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0588 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0572 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0608 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0634 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0620 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0598 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0624 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0650 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0663 - accuracy: 0.97 - ETA: 3:08 - loss: 0.0665 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0672 - accuracy: 0.97 - ETA: 3:04 - loss: 0.0686 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0681 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0666 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0661 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0671 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0671 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0654 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0658 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0672 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0694 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0680 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0680 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0685 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0670 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0674 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0675 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0664 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0657 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0654 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0650 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0658 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0650 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0644 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0644 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0658 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0658 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0662 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0652 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0652 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0649 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0654 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0653 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0647 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0640 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0632 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0642 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0640 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0646 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0637 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0635 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0632 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0635 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0622 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0622 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0619 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0654 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0658 - accuracy: 0.98 - ETA: 58s - loss: 0.0657 - accuracy: 0.9804 - ETA: 57s - loss: 0.0655 - accuracy: 0.980 - ETA: 55s - loss: 0.0653 - accuracy: 0.980 - ETA: 54s - loss: 0.0655 - accuracy: 0.980 - ETA: 52s - loss: 0.0653 - accuracy: 0.980 - ETA: 51s - loss: 0.0652 - accuracy: 0.980 - ETA: 49s - loss: 0.0652 - accuracy: 0.980 - ETA: 48s - loss: 0.0651 - accuracy: 0.980 - ETA: 46s - loss: 0.0651 - accuracy: 0.980 - ETA: 46s - loss: 0.0655 - accuracy: 0.980 - ETA: 44s - loss: 0.0656 - accuracy: 0.980 - ETA: 43s - loss: 0.0656 - accuracy: 0.980 - ETA: 41s - loss: 0.0652 - accuracy: 0.980 - ETA: 40s - loss: 0.0656 - accuracy: 0.980 - ETA: 38s - loss: 0.0656 - accuracy: 0.980 - ETA: 37s - loss: 0.0660 - accuracy: 0.980 - ETA: 36s - loss: 0.0656 - accuracy: 0.980 - ETA: 34s - loss: 0.0653 - accuracy: 0.980 - ETA: 33s - loss: 0.0657 - accuracy: 0.980 - ETA: 31s - loss: 0.0660 - accuracy: 0.980 - ETA: 30s - loss: 0.0658 - accuracy: 0.980 - ETA: 28s - loss: 0.0657 - accuracy: 0.980 - ETA: 27s - loss: 0.0653 - accuracy: 0.980 - ETA: 25s - loss: 0.0652 - accuracy: 0.980 - ETA: 24s - loss: 0.0651 - accuracy: 0.980 - ETA: 23s - loss: 0.0653 - accuracy: 0.980 - ETA: 21s - loss: 0.0653 - accuracy: 0.980 - ETA: 20s - loss: 0.0656 - accuracy: 0.980 - ETA: 18s - loss: 0.0652 - accuracy: 0.980 - ETA: 17s - loss: 0.0650 - accuracy: 0.980 - ETA: 15s - loss: 0.0651 - accuracy: 0.980 - ETA: 14s - loss: 0.0652 - accuracy: 0.980 - ETA: 12s - loss: 0.0649 - accuracy: 0.980 - ETA: 11s - loss: 0.0647 - accuracy: 0.980 - ETA: 10s - loss: 0.0645 - accuracy: 0.980 - ETA: 8s - loss: 0.0642 - accuracy: 0.980 - ETA: 7s - loss: 0.0645 - accuracy: 0.98 - ETA: 5s - loss: 0.0649 - accuracy: 0.98 - ETA: 4s - loss: 0.0651 - accuracy: 0.98 - ETA: 2s - loss: 0.0647 - accuracy: 0.98 - ETA: 1s - loss: 0.0650 - accuracy: 0.98 - 245s 13ms/step - loss: 0.0648 - accuracy: 0.9806 - val_loss: 1.6547 - val_accuracy: 0.8029\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:46 - loss: 0.0165 - accuracy: 0.99 - ETA: 3:46 - loss: 0.0264 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0286 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0273 - accuracy: 0.99 - ETA: 3:35 - loss: 0.0393 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0387 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0384 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0365 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0344 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0359 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0345 - accuracy: 0.99 - ETA: 3:21 - loss: 0.0359 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0385 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0369 - accuracy: 0.99 - ETA: 3:18 - loss: 0.0404 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0399 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0391 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0416 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0557 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0542 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0522 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0550 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0553 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0597 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0585 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0577 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0579 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0581 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0580 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0571 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0555 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0586 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0609 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0638 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0643 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0630 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0659 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0646 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0642 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0631 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0635 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0638 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0640 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0628 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0620 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0617 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0624 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0642 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0641 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0643 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0660 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0661 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0651 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0651 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0651 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0659 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0656 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0652 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0656 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0656 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0655 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0647 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0647 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0661 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0661 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0675 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0681 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0681 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0679 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0674 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0662 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0661 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0660 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0658 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0660 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0660 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0657 - accuracy: 0.98 - ETA: 58s - loss: 0.0655 - accuracy: 0.9812 - ETA: 57s - loss: 0.0660 - accuracy: 0.980 - ETA: 55s - loss: 0.0655 - accuracy: 0.981 - ETA: 54s - loss: 0.0658 - accuracy: 0.980 - ETA: 52s - loss: 0.0658 - accuracy: 0.980 - ETA: 51s - loss: 0.0662 - accuracy: 0.980 - ETA: 49s - loss: 0.0661 - accuracy: 0.980 - ETA: 48s - loss: 0.0661 - accuracy: 0.980 - ETA: 46s - loss: 0.0656 - accuracy: 0.980 - ETA: 45s - loss: 0.0656 - accuracy: 0.980 - ETA: 43s - loss: 0.0655 - accuracy: 0.980 - ETA: 42s - loss: 0.0651 - accuracy: 0.980 - ETA: 40s - loss: 0.0650 - accuracy: 0.980 - ETA: 39s - loss: 0.0652 - accuracy: 0.980 - ETA: 37s - loss: 0.0652 - accuracy: 0.980 - ETA: 36s - loss: 0.0647 - accuracy: 0.980 - ETA: 34s - loss: 0.0651 - accuracy: 0.980 - ETA: 33s - loss: 0.0653 - accuracy: 0.980 - ETA: 31s - loss: 0.0649 - accuracy: 0.980 - ETA: 30s - loss: 0.0647 - accuracy: 0.980 - ETA: 28s - loss: 0.0646 - accuracy: 0.980 - ETA: 27s - loss: 0.0660 - accuracy: 0.980 - ETA: 25s - loss: 0.0667 - accuracy: 0.980 - ETA: 24s - loss: 0.0665 - accuracy: 0.980 - ETA: 22s - loss: 0.0664 - accuracy: 0.980 - ETA: 21s - loss: 0.0662 - accuracy: 0.980 - ETA: 19s - loss: 0.0658 - accuracy: 0.980 - ETA: 18s - loss: 0.0656 - accuracy: 0.980 - ETA: 16s - loss: 0.0654 - accuracy: 0.980 - ETA: 14s - loss: 0.0651 - accuracy: 0.980 - ETA: 13s - loss: 0.0652 - accuracy: 0.980 - ETA: 12s - loss: 0.0653 - accuracy: 0.980 - ETA: 10s - loss: 0.0651 - accuracy: 0.980 - ETA: 8s - loss: 0.0650 - accuracy: 0.980 - ETA: 7s - loss: 0.0660 - accuracy: 0.97 - ETA: 5s - loss: 0.0664 - accuracy: 0.97 - ETA: 4s - loss: 0.0660 - accuracy: 0.98 - ETA: 2s - loss: 0.0662 - accuracy: 0.98 - ETA: 1s - loss: 0.0665 - accuracy: 0.97 - 266s 14ms/step - loss: 0.0665 - accuracy: 0.9799 - val_loss: 1.6613 - val_accuracy: 0.8064\n",
      "Epoch 58/100\n",
      "19312/19312 [==============================] - ETA: 3:22 - loss: 0.1032 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0690 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0552 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0569 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0671 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0706 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0640 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0628 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0614 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0619 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0603 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0609 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0590 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0561 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0568 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0553 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0558 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0542 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0539 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0525 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0519 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0513 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0534 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0521 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0515 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0501 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0494 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0505 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0538 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0563 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0572 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0567 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0566 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0560 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0571 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0562 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0587 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0584 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0586 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0585 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0586 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0576 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0565 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0570 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0566 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0562 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0568 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0566 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0583 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0579 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0573 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0573 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0578 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0567 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0571 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0565 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0564 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0560 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0555 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0566 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0558 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0571 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0577 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0584 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0576 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0573 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0569 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0576 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0584 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0573 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0576 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0577 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0580 - accuracy: 0.98 - ETA: 59s - loss: 0.0584 - accuracy: 0.9824 - ETA: 57s - loss: 0.0586 - accuracy: 0.982 - ETA: 56s - loss: 0.0583 - accuracy: 0.982 - ETA: 54s - loss: 0.0584 - accuracy: 0.982 - ETA: 53s - loss: 0.0583 - accuracy: 0.982 - ETA: 52s - loss: 0.0588 - accuracy: 0.982 - ETA: 50s - loss: 0.0588 - accuracy: 0.982 - ETA: 49s - loss: 0.0584 - accuracy: 0.982 - ETA: 47s - loss: 0.0582 - accuracy: 0.982 - ETA: 46s - loss: 0.0588 - accuracy: 0.982 - ETA: 44s - loss: 0.0595 - accuracy: 0.982 - ETA: 43s - loss: 0.0596 - accuracy: 0.982 - ETA: 41s - loss: 0.0597 - accuracy: 0.982 - ETA: 40s - loss: 0.0594 - accuracy: 0.982 - ETA: 38s - loss: 0.0594 - accuracy: 0.982 - ETA: 37s - loss: 0.0599 - accuracy: 0.982 - ETA: 35s - loss: 0.0594 - accuracy: 0.982 - ETA: 34s - loss: 0.0592 - accuracy: 0.982 - ETA: 32s - loss: 0.0599 - accuracy: 0.982 - ETA: 31s - loss: 0.0602 - accuracy: 0.982 - ETA: 29s - loss: 0.0605 - accuracy: 0.982 - ETA: 28s - loss: 0.0603 - accuracy: 0.982 - ETA: 26s - loss: 0.0600 - accuracy: 0.982 - ETA: 25s - loss: 0.0599 - accuracy: 0.982 - ETA: 23s - loss: 0.0602 - accuracy: 0.982 - ETA: 22s - loss: 0.0602 - accuracy: 0.982 - ETA: 20s - loss: 0.0603 - accuracy: 0.982 - ETA: 19s - loss: 0.0605 - accuracy: 0.981 - ETA: 17s - loss: 0.0602 - accuracy: 0.982 - ETA: 16s - loss: 0.0600 - accuracy: 0.982 - ETA: 14s - loss: 0.0605 - accuracy: 0.981 - ETA: 13s - loss: 0.0605 - accuracy: 0.981 - ETA: 11s - loss: 0.0605 - accuracy: 0.981 - ETA: 10s - loss: 0.0604 - accuracy: 0.981 - ETA: 8s - loss: 0.0601 - accuracy: 0.981 - ETA: 7s - loss: 0.0600 - accuracy: 0.98 - ETA: 5s - loss: 0.0598 - accuracy: 0.98 - ETA: 4s - loss: 0.0599 - accuracy: 0.98 - ETA: 2s - loss: 0.0599 - accuracy: 0.98 - ETA: 1s - loss: 0.0603 - accuracy: 0.98 - 266s 14ms/step - loss: 0.0601 - accuracy: 0.9817 - val_loss: 1.7870 - val_accuracy: 0.8080\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:53 - loss: 0.0298 - accuracy: 0.99 - ETA: 3:45 - loss: 0.0478 - accuracy: 0.97 - ETA: 3:53 - loss: 0.0455 - accuracy: 0.97 - ETA: 3:48 - loss: 0.0439 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0430 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0422 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0394 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0386 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0530 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0522 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0536 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0530 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0530 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0533 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0559 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0569 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0581 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0582 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0590 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0569 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0558 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0542 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0535 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0569 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0571 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0565 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0554 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0547 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0535 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0525 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0525 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0527 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0531 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0548 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0594 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0586 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0600 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0630 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0622 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0625 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0621 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0610 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0626 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0624 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0621 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0639 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0631 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0622 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0621 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0625 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0638 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0632 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0631 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0639 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0637 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0622 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0626 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0618 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0653 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0665 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0662 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0665 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0662 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0662 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0661 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0661 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0658 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0654 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0654 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0654 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0654 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0656 - accuracy: 0.97 - ETA: 58s - loss: 0.0656 - accuracy: 0.9798 - ETA: 57s - loss: 0.0658 - accuracy: 0.979 - ETA: 55s - loss: 0.0660 - accuracy: 0.979 - ETA: 54s - loss: 0.0657 - accuracy: 0.979 - ETA: 52s - loss: 0.0660 - accuracy: 0.979 - ETA: 51s - loss: 0.0662 - accuracy: 0.979 - ETA: 49s - loss: 0.0658 - accuracy: 0.979 - ETA: 48s - loss: 0.0656 - accuracy: 0.979 - ETA: 46s - loss: 0.0662 - accuracy: 0.979 - ETA: 45s - loss: 0.0669 - accuracy: 0.979 - ETA: 43s - loss: 0.0667 - accuracy: 0.979 - ETA: 42s - loss: 0.0669 - accuracy: 0.979 - ETA: 40s - loss: 0.0667 - accuracy: 0.979 - ETA: 39s - loss: 0.0664 - accuracy: 0.979 - ETA: 37s - loss: 0.0664 - accuracy: 0.979 - ETA: 36s - loss: 0.0661 - accuracy: 0.979 - ETA: 34s - loss: 0.0660 - accuracy: 0.979 - ETA: 32s - loss: 0.0663 - accuracy: 0.979 - ETA: 31s - loss: 0.0665 - accuracy: 0.979 - ETA: 29s - loss: 0.0661 - accuracy: 0.979 - ETA: 28s - loss: 0.0657 - accuracy: 0.979 - ETA: 26s - loss: 0.0658 - accuracy: 0.979 - ETA: 25s - loss: 0.0664 - accuracy: 0.979 - ETA: 23s - loss: 0.0661 - accuracy: 0.979 - ETA: 22s - loss: 0.0659 - accuracy: 0.979 - ETA: 20s - loss: 0.0662 - accuracy: 0.979 - ETA: 19s - loss: 0.0661 - accuracy: 0.979 - ETA: 17s - loss: 0.0662 - accuracy: 0.979 - ETA: 16s - loss: 0.0660 - accuracy: 0.979 - ETA: 14s - loss: 0.0661 - accuracy: 0.979 - ETA: 13s - loss: 0.0660 - accuracy: 0.979 - ETA: 11s - loss: 0.0661 - accuracy: 0.979 - ETA: 10s - loss: 0.0664 - accuracy: 0.979 - ETA: 8s - loss: 0.0662 - accuracy: 0.979 - ETA: 7s - loss: 0.0662 - accuracy: 0.97 - ETA: 5s - loss: 0.0665 - accuracy: 0.97 - ETA: 4s - loss: 0.0663 - accuracy: 0.97 - ETA: 2s - loss: 0.0662 - accuracy: 0.97 - ETA: 1s - loss: 0.0664 - accuracy: 0.97 - 257s 13ms/step - loss: 0.0664 - accuracy: 0.9792 - val_loss: 1.7057 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "19312/19312 [==============================] - ETA: 3:21 - loss: 0.0469 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0417 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0472 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0490 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0427 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0453 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0445 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0430 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0436 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0486 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0608 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0578 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0598 - accuracy: 0.97 - ETA: 3:10 - loss: 0.0583 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0566 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0605 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0590 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0580 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0612 - accuracy: 0.97 - ETA: 3:01 - loss: 0.0598 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0603 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0602 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0618 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0612 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0607 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0596 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0601 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0599 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0597 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0597 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0593 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0589 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0594 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0589 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0603 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0593 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0595 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0596 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0595 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0587 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0573 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0569 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0565 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0560 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0560 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0555 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0554 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0558 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0553 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0553 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0553 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0548 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0544 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0544 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0536 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0525 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0534 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0543 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0539 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0539 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0542 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0545 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0542 - accuracy: 0.98 - ETA: 59s - loss: 0.0543 - accuracy: 0.9819 - ETA: 57s - loss: 0.0538 - accuracy: 0.982 - ETA: 56s - loss: 0.0544 - accuracy: 0.981 - ETA: 55s - loss: 0.0539 - accuracy: 0.982 - ETA: 53s - loss: 0.0542 - accuracy: 0.981 - ETA: 52s - loss: 0.0552 - accuracy: 0.981 - ETA: 50s - loss: 0.0550 - accuracy: 0.981 - ETA: 49s - loss: 0.0546 - accuracy: 0.982 - ETA: 47s - loss: 0.0546 - accuracy: 0.982 - ETA: 46s - loss: 0.0550 - accuracy: 0.981 - ETA: 44s - loss: 0.0551 - accuracy: 0.981 - ETA: 43s - loss: 0.0558 - accuracy: 0.981 - ETA: 41s - loss: 0.0555 - accuracy: 0.981 - ETA: 40s - loss: 0.0561 - accuracy: 0.981 - ETA: 38s - loss: 0.0560 - accuracy: 0.981 - ETA: 37s - loss: 0.0564 - accuracy: 0.981 - ETA: 36s - loss: 0.0569 - accuracy: 0.981 - ETA: 34s - loss: 0.0565 - accuracy: 0.981 - ETA: 33s - loss: 0.0570 - accuracy: 0.981 - ETA: 31s - loss: 0.0567 - accuracy: 0.981 - ETA: 30s - loss: 0.0571 - accuracy: 0.981 - ETA: 28s - loss: 0.0568 - accuracy: 0.981 - ETA: 27s - loss: 0.0570 - accuracy: 0.981 - ETA: 25s - loss: 0.0567 - accuracy: 0.981 - ETA: 24s - loss: 0.0569 - accuracy: 0.981 - ETA: 22s - loss: 0.0566 - accuracy: 0.981 - ETA: 21s - loss: 0.0565 - accuracy: 0.981 - ETA: 20s - loss: 0.0572 - accuracy: 0.981 - ETA: 18s - loss: 0.0571 - accuracy: 0.981 - ETA: 17s - loss: 0.0572 - accuracy: 0.981 - ETA: 15s - loss: 0.0571 - accuracy: 0.981 - ETA: 14s - loss: 0.0568 - accuracy: 0.981 - ETA: 12s - loss: 0.0565 - accuracy: 0.981 - ETA: 11s - loss: 0.0564 - accuracy: 0.981 - ETA: 9s - loss: 0.0565 - accuracy: 0.981 - ETA: 8s - loss: 0.0566 - accuracy: 0.98 - ETA: 7s - loss: 0.0572 - accuracy: 0.98 - ETA: 5s - loss: 0.0569 - accuracy: 0.98 - ETA: 4s - loss: 0.0571 - accuracy: 0.98 - ETA: 2s - loss: 0.0569 - accuracy: 0.98 - ETA: 1s - loss: 0.0569 - accuracy: 0.98 - 248s 13ms/step - loss: 0.0569 - accuracy: 0.9814 - val_loss: 1.7558 - val_accuracy: 0.7998\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:50 - loss: 0.0310 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0542 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0623 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0650 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0608 - accuracy: 0.97 - ETA: 3:31 - loss: 0.0540 - accuracy: 0.97 - ETA: 3:35 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0539 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0571 - accuracy: 0.97 - ETA: 3:28 - loss: 0.0582 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0572 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0593 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0577 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0595 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0571 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0568 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0548 - accuracy: 0.97 - ETA: 3:14 - loss: 0.0532 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0545 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0534 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0579 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0568 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0559 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0539 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0566 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0577 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0585 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0569 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0590 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0589 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0578 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0573 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0591 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0604 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0588 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0581 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0590 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0575 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0585 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0585 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0578 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0571 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0562 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0556 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0567 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0564 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0567 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0564 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0558 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0542 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0538 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0533 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0533 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0528 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0532 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0548 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0511 - accuracy: 0.98 - ETA: 59s - loss: 0.0510 - accuracy: 0.9828 - ETA: 57s - loss: 0.0509 - accuracy: 0.982 - ETA: 56s - loss: 0.0511 - accuracy: 0.982 - ETA: 54s - loss: 0.0509 - accuracy: 0.982 - ETA: 53s - loss: 0.0505 - accuracy: 0.982 - ETA: 51s - loss: 0.0509 - accuracy: 0.982 - ETA: 50s - loss: 0.0517 - accuracy: 0.982 - ETA: 48s - loss: 0.0523 - accuracy: 0.982 - ETA: 47s - loss: 0.0524 - accuracy: 0.982 - ETA: 45s - loss: 0.0528 - accuracy: 0.982 - ETA: 44s - loss: 0.0539 - accuracy: 0.982 - ETA: 42s - loss: 0.0540 - accuracy: 0.982 - ETA: 41s - loss: 0.0537 - accuracy: 0.982 - ETA: 39s - loss: 0.0535 - accuracy: 0.982 - ETA: 38s - loss: 0.0534 - accuracy: 0.982 - ETA: 36s - loss: 0.0537 - accuracy: 0.982 - ETA: 35s - loss: 0.0536 - accuracy: 0.982 - ETA: 33s - loss: 0.0537 - accuracy: 0.982 - ETA: 32s - loss: 0.0538 - accuracy: 0.982 - ETA: 30s - loss: 0.0543 - accuracy: 0.982 - ETA: 29s - loss: 0.0543 - accuracy: 0.981 - ETA: 27s - loss: 0.0543 - accuracy: 0.981 - ETA: 26s - loss: 0.0544 - accuracy: 0.981 - ETA: 24s - loss: 0.0541 - accuracy: 0.982 - ETA: 23s - loss: 0.0542 - accuracy: 0.982 - ETA: 21s - loss: 0.0540 - accuracy: 0.982 - ETA: 20s - loss: 0.0539 - accuracy: 0.982 - ETA: 19s - loss: 0.0536 - accuracy: 0.982 - ETA: 17s - loss: 0.0534 - accuracy: 0.982 - ETA: 16s - loss: 0.0534 - accuracy: 0.982 - ETA: 14s - loss: 0.0535 - accuracy: 0.982 - ETA: 13s - loss: 0.0537 - accuracy: 0.982 - ETA: 11s - loss: 0.0538 - accuracy: 0.982 - ETA: 10s - loss: 0.0539 - accuracy: 0.982 - ETA: 8s - loss: 0.0546 - accuracy: 0.981 - ETA: 7s - loss: 0.0549 - accuracy: 0.98 - ETA: 5s - loss: 0.0548 - accuracy: 0.98 - ETA: 4s - loss: 0.0547 - accuracy: 0.98 - ETA: 2s - loss: 0.0549 - accuracy: 0.98 - ETA: 1s - loss: 0.0552 - accuracy: 0.98 - 250s 13ms/step - loss: 0.0553 - accuracy: 0.9817 - val_loss: 1.7566 - val_accuracy: 0.8043\n",
      "Epoch 62/100\n",
      "19312/19312 [==============================] - ETA: 4:16 - loss: 0.0831 - accuracy: 0.96 - ETA: 3:55 - loss: 0.0963 - accuracy: 0.96 - ETA: 3:45 - loss: 0.0958 - accuracy: 0.97 - ETA: 3:43 - loss: 0.0788 - accuracy: 0.97 - ETA: 3:38 - loss: 0.0747 - accuracy: 0.97 - ETA: 3:34 - loss: 0.0750 - accuracy: 0.97 - ETA: 3:29 - loss: 0.0764 - accuracy: 0.97 - ETA: 3:27 - loss: 0.0755 - accuracy: 0.97 - ETA: 3:25 - loss: 0.0765 - accuracy: 0.97 - ETA: 3:24 - loss: 0.0725 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0777 - accuracy: 0.97 - ETA: 3:22 - loss: 0.0748 - accuracy: 0.97 - ETA: 3:19 - loss: 0.0742 - accuracy: 0.97 - ETA: 3:18 - loss: 0.0712 - accuracy: 0.97 - ETA: 3:17 - loss: 0.0680 - accuracy: 0.97 - ETA: 3:16 - loss: 0.0762 - accuracy: 0.97 - ETA: 3:15 - loss: 0.0743 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0753 - accuracy: 0.97 - ETA: 3:12 - loss: 0.0792 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0764 - accuracy: 0.97 - ETA: 3:09 - loss: 0.0773 - accuracy: 0.97 - ETA: 3:07 - loss: 0.0740 - accuracy: 0.97 - ETA: 3:06 - loss: 0.0721 - accuracy: 0.97 - ETA: 3:05 - loss: 0.0708 - accuracy: 0.97 - ETA: 3:03 - loss: 0.0734 - accuracy: 0.97 - ETA: 3:02 - loss: 0.0754 - accuracy: 0.97 - ETA: 2:59 - loss: 0.0751 - accuracy: 0.97 - ETA: 2:58 - loss: 0.0764 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0743 - accuracy: 0.97 - ETA: 2:55 - loss: 0.0731 - accuracy: 0.97 - ETA: 2:54 - loss: 0.0714 - accuracy: 0.97 - ETA: 2:53 - loss: 0.0693 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0693 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0684 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0680 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0688 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0687 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0684 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0675 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0669 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0659 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0631 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0629 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0623 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0611 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0600 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0596 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0603 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0598 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0608 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0598 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0589 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0581 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0572 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0575 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0570 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0563 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0556 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0553 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0556 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0552 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0554 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0552 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0545 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0548 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0566 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0566 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0564 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0564 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0547 - accuracy: 0.98 - ETA: 59s - loss: 0.0545 - accuracy: 0.9820 - ETA: 57s - loss: 0.0551 - accuracy: 0.982 - ETA: 56s - loss: 0.0552 - accuracy: 0.982 - ETA: 55s - loss: 0.0548 - accuracy: 0.982 - ETA: 53s - loss: 0.0556 - accuracy: 0.982 - ETA: 52s - loss: 0.0559 - accuracy: 0.981 - ETA: 50s - loss: 0.0559 - accuracy: 0.981 - ETA: 49s - loss: 0.0556 - accuracy: 0.981 - ETA: 47s - loss: 0.0554 - accuracy: 0.981 - ETA: 46s - loss: 0.0551 - accuracy: 0.982 - ETA: 45s - loss: 0.0547 - accuracy: 0.982 - ETA: 43s - loss: 0.0548 - accuracy: 0.982 - ETA: 42s - loss: 0.0545 - accuracy: 0.982 - ETA: 40s - loss: 0.0548 - accuracy: 0.981 - ETA: 39s - loss: 0.0544 - accuracy: 0.982 - ETA: 37s - loss: 0.0540 - accuracy: 0.982 - ETA: 35s - loss: 0.0540 - accuracy: 0.982 - ETA: 34s - loss: 0.0544 - accuracy: 0.982 - ETA: 32s - loss: 0.0554 - accuracy: 0.981 - ETA: 31s - loss: 0.0554 - accuracy: 0.981 - ETA: 29s - loss: 0.0558 - accuracy: 0.981 - ETA: 28s - loss: 0.0558 - accuracy: 0.981 - ETA: 26s - loss: 0.0555 - accuracy: 0.981 - ETA: 24s - loss: 0.0554 - accuracy: 0.981 - ETA: 23s - loss: 0.0551 - accuracy: 0.981 - ETA: 21s - loss: 0.0547 - accuracy: 0.981 - ETA: 20s - loss: 0.0554 - accuracy: 0.981 - ETA: 18s - loss: 0.0553 - accuracy: 0.981 - ETA: 17s - loss: 0.0554 - accuracy: 0.981 - ETA: 15s - loss: 0.0553 - accuracy: 0.981 - ETA: 13s - loss: 0.0556 - accuracy: 0.981 - ETA: 12s - loss: 0.0553 - accuracy: 0.981 - ETA: 10s - loss: 0.0554 - accuracy: 0.981 - ETA: 9s - loss: 0.0555 - accuracy: 0.981 - ETA: 7s - loss: 0.0553 - accuracy: 0.98 - ETA: 6s - loss: 0.0552 - accuracy: 0.98 - ETA: 4s - loss: 0.0549 - accuracy: 0.98 - ETA: 2s - loss: 0.0548 - accuracy: 0.98 - ETA: 1s - loss: 0.0550 - accuracy: 0.98 - 263s 14ms/step - loss: 0.0547 - accuracy: 0.9821 - val_loss: 1.8364 - val_accuracy: 0.8000\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:02 - loss: 0.0235 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0301 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0225 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0296 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0304 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0263 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0423 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0496 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0450 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0495 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0445 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0422 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0407 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0388 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0416 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0410 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0427 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0427 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0421 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0452 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0507 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0499 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0515 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0519 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0531 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0510 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0501 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0495 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0528 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0520 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0534 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0536 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0528 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0528 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0536 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0570 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0576 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0569 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0569 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0571 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0566 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0543 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0529 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0524 - accuracy: 0.98 - ETA: 59s - loss: 0.0526 - accuracy: 0.9840 - ETA: 58s - loss: 0.0524 - accuracy: 0.984 - ETA: 56s - loss: 0.0525 - accuracy: 0.984 - ETA: 55s - loss: 0.0523 - accuracy: 0.984 - ETA: 53s - loss: 0.0526 - accuracy: 0.984 - ETA: 52s - loss: 0.0527 - accuracy: 0.983 - ETA: 50s - loss: 0.0534 - accuracy: 0.983 - ETA: 49s - loss: 0.0535 - accuracy: 0.983 - ETA: 47s - loss: 0.0533 - accuracy: 0.983 - ETA: 46s - loss: 0.0533 - accuracy: 0.983 - ETA: 44s - loss: 0.0531 - accuracy: 0.983 - ETA: 43s - loss: 0.0532 - accuracy: 0.983 - ETA: 41s - loss: 0.0538 - accuracy: 0.983 - ETA: 40s - loss: 0.0548 - accuracy: 0.983 - ETA: 38s - loss: 0.0555 - accuracy: 0.982 - ETA: 37s - loss: 0.0559 - accuracy: 0.982 - ETA: 35s - loss: 0.0561 - accuracy: 0.982 - ETA: 34s - loss: 0.0567 - accuracy: 0.982 - ETA: 32s - loss: 0.0564 - accuracy: 0.982 - ETA: 31s - loss: 0.0560 - accuracy: 0.982 - ETA: 29s - loss: 0.0564 - accuracy: 0.982 - ETA: 28s - loss: 0.0566 - accuracy: 0.982 - ETA: 26s - loss: 0.0579 - accuracy: 0.982 - ETA: 25s - loss: 0.0578 - accuracy: 0.982 - ETA: 23s - loss: 0.0578 - accuracy: 0.982 - ETA: 22s - loss: 0.0575 - accuracy: 0.982 - ETA: 20s - loss: 0.0577 - accuracy: 0.982 - ETA: 19s - loss: 0.0581 - accuracy: 0.982 - ETA: 17s - loss: 0.0580 - accuracy: 0.982 - ETA: 16s - loss: 0.0578 - accuracy: 0.982 - ETA: 14s - loss: 0.0576 - accuracy: 0.982 - ETA: 13s - loss: 0.0574 - accuracy: 0.982 - ETA: 11s - loss: 0.0571 - accuracy: 0.982 - ETA: 10s - loss: 0.0569 - accuracy: 0.982 - ETA: 8s - loss: 0.0569 - accuracy: 0.982 - ETA: 7s - loss: 0.0571 - accuracy: 0.98 - ETA: 5s - loss: 0.0570 - accuracy: 0.98 - ETA: 4s - loss: 0.0570 - accuracy: 0.98 - ETA: 2s - loss: 0.0569 - accuracy: 0.98 - ETA: 1s - loss: 0.0571 - accuracy: 0.98 - 261s 14ms/step - loss: 0.0568 - accuracy: 0.9821 - val_loss: 1.7789 - val_accuracy: 0.8004\n",
      "Epoch 64/100\n",
      "19312/19312 [==============================] - ETA: 3:48 - loss: 0.0555 - accuracy: 0.98 - ETA: 3:37 - loss: 0.1079 - accuracy: 0.97 - ETA: 3:33 - loss: 0.1001 - accuracy: 0.97 - ETA: 3:37 - loss: 0.0797 - accuracy: 0.97 - ETA: 3:35 - loss: 0.0705 - accuracy: 0.97 - ETA: 3:40 - loss: 0.0661 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0626 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0610 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0582 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0546 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0498 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0498 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0517 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0559 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0546 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0530 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0510 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0499 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0500 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0489 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0495 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0494 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0436 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0422 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0419 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0417 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0413 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0411 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0435 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0434 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0426 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0431 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0434 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0493 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0493 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0492 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0498 - accuracy: 0.98 - ETA: 59s - loss: 0.0496 - accuracy: 0.9841 - ETA: 58s - loss: 0.0494 - accuracy: 0.984 - ETA: 56s - loss: 0.0496 - accuracy: 0.984 - ETA: 55s - loss: 0.0497 - accuracy: 0.984 - ETA: 53s - loss: 0.0493 - accuracy: 0.984 - ETA: 52s - loss: 0.0493 - accuracy: 0.984 - ETA: 50s - loss: 0.0491 - accuracy: 0.984 - ETA: 49s - loss: 0.0489 - accuracy: 0.984 - ETA: 47s - loss: 0.0492 - accuracy: 0.984 - ETA: 46s - loss: 0.0491 - accuracy: 0.984 - ETA: 44s - loss: 0.0496 - accuracy: 0.983 - ETA: 43s - loss: 0.0500 - accuracy: 0.983 - ETA: 41s - loss: 0.0502 - accuracy: 0.983 - ETA: 40s - loss: 0.0504 - accuracy: 0.983 - ETA: 38s - loss: 0.0505 - accuracy: 0.983 - ETA: 37s - loss: 0.0508 - accuracy: 0.983 - ETA: 35s - loss: 0.0509 - accuracy: 0.983 - ETA: 34s - loss: 0.0509 - accuracy: 0.983 - ETA: 32s - loss: 0.0505 - accuracy: 0.983 - ETA: 31s - loss: 0.0505 - accuracy: 0.983 - ETA: 29s - loss: 0.0509 - accuracy: 0.983 - ETA: 28s - loss: 0.0509 - accuracy: 0.983 - ETA: 26s - loss: 0.0507 - accuracy: 0.983 - ETA: 25s - loss: 0.0506 - accuracy: 0.983 - ETA: 23s - loss: 0.0504 - accuracy: 0.983 - ETA: 22s - loss: 0.0502 - accuracy: 0.983 - ETA: 20s - loss: 0.0503 - accuracy: 0.983 - ETA: 19s - loss: 0.0501 - accuracy: 0.983 - ETA: 17s - loss: 0.0501 - accuracy: 0.983 - ETA: 16s - loss: 0.0502 - accuracy: 0.983 - ETA: 14s - loss: 0.0498 - accuracy: 0.983 - ETA: 13s - loss: 0.0499 - accuracy: 0.983 - ETA: 11s - loss: 0.0501 - accuracy: 0.983 - ETA: 10s - loss: 0.0507 - accuracy: 0.983 - ETA: 8s - loss: 0.0511 - accuracy: 0.983 - ETA: 7s - loss: 0.0511 - accuracy: 0.98 - ETA: 5s - loss: 0.0510 - accuracy: 0.98 - ETA: 4s - loss: 0.0511 - accuracy: 0.98 - ETA: 2s - loss: 0.0512 - accuracy: 0.98 - ETA: 1s - loss: 0.0512 - accuracy: 0.98 - 253s 13ms/step - loss: 0.0510 - accuracy: 0.9834 - val_loss: 1.8265 - val_accuracy: 0.8018\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:03 - loss: 0.0481 - accuracy: 0.97 - ETA: 3:46 - loss: 0.0255 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0381 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0343 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0409 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0356 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0385 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0375 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0427 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0441 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0480 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0526 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0524 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0523 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0506 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0532 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0530 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0531 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0543 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0522 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0536 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0516 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0509 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0522 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0527 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0500 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0530 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0510 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0493 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0486 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0493 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0487 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0491 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0491 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0489 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0491 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0494 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0487 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0483 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0505 - accuracy: 0.98 - ETA: 59s - loss: 0.0506 - accuracy: 0.9840 - ETA: 57s - loss: 0.0509 - accuracy: 0.984 - ETA: 56s - loss: 0.0518 - accuracy: 0.984 - ETA: 54s - loss: 0.0517 - accuracy: 0.984 - ETA: 53s - loss: 0.0515 - accuracy: 0.984 - ETA: 51s - loss: 0.0520 - accuracy: 0.984 - ETA: 49s - loss: 0.0523 - accuracy: 0.984 - ETA: 47s - loss: 0.0529 - accuracy: 0.983 - ETA: 46s - loss: 0.0531 - accuracy: 0.983 - ETA: 44s - loss: 0.0530 - accuracy: 0.983 - ETA: 42s - loss: 0.0530 - accuracy: 0.983 - ETA: 40s - loss: 0.0529 - accuracy: 0.983 - ETA: 39s - loss: 0.0530 - accuracy: 0.983 - ETA: 37s - loss: 0.0529 - accuracy: 0.983 - ETA: 35s - loss: 0.0525 - accuracy: 0.984 - ETA: 33s - loss: 0.0523 - accuracy: 0.984 - ETA: 31s - loss: 0.0523 - accuracy: 0.984 - ETA: 30s - loss: 0.0522 - accuracy: 0.984 - ETA: 28s - loss: 0.0520 - accuracy: 0.984 - ETA: 26s - loss: 0.0525 - accuracy: 0.984 - ETA: 24s - loss: 0.0531 - accuracy: 0.983 - ETA: 22s - loss: 0.0535 - accuracy: 0.983 - ETA: 20s - loss: 0.0539 - accuracy: 0.983 - ETA: 18s - loss: 0.0537 - accuracy: 0.983 - ETA: 17s - loss: 0.0536 - accuracy: 0.983 - ETA: 15s - loss: 0.0538 - accuracy: 0.983 - ETA: 13s - loss: 0.0544 - accuracy: 0.983 - ETA: 11s - loss: 0.0541 - accuracy: 0.983 - ETA: 9s - loss: 0.0542 - accuracy: 0.983 - ETA: 7s - loss: 0.0545 - accuracy: 0.98 - ETA: 5s - loss: 0.0549 - accuracy: 0.98 - ETA: 3s - loss: 0.0547 - accuracy: 0.98 - ETA: 1s - loss: 0.0546 - accuracy: 0.98 - 346s 18ms/step - loss: 0.0550 - accuracy: 0.9832 - val_loss: 1.7591 - val_accuracy: 0.8064\n",
      "Epoch 66/100\n",
      "19312/19312 [==============================] - ETA: 9:42 - loss: 0.0535 - accuracy: 0.98 - ETA: 7:50 - loss: 0.0424 - accuracy: 0.98 - ETA: 7:12 - loss: 0.0378 - accuracy: 0.98 - ETA: 7:23 - loss: 0.0441 - accuracy: 0.98 - ETA: 7:04 - loss: 0.0358 - accuracy: 0.98 - ETA: 7:10 - loss: 0.0325 - accuracy: 0.98 - ETA: 7:00 - loss: 0.0295 - accuracy: 0.98 - ETA: 6:46 - loss: 0.0367 - accuracy: 0.98 - ETA: 6:39 - loss: 0.0355 - accuracy: 0.98 - ETA: 6:28 - loss: 0.0427 - accuracy: 0.98 - ETA: 6:23 - loss: 0.0415 - accuracy: 0.98 - ETA: 6:15 - loss: 0.0394 - accuracy: 0.98 - ETA: 6:13 - loss: 0.0412 - accuracy: 0.98 - ETA: 6:09 - loss: 0.0526 - accuracy: 0.98 - ETA: 6:01 - loss: 0.0532 - accuracy: 0.98 - ETA: 5:58 - loss: 0.0579 - accuracy: 0.98 - ETA: 5:53 - loss: 0.0576 - accuracy: 0.98 - ETA: 5:50 - loss: 0.0566 - accuracy: 0.98 - ETA: 5:45 - loss: 0.0548 - accuracy: 0.98 - ETA: 5:42 - loss: 0.0564 - accuracy: 0.98 - ETA: 5:38 - loss: 0.0559 - accuracy: 0.98 - ETA: 5:36 - loss: 0.0574 - accuracy: 0.98 - ETA: 5:32 - loss: 0.0557 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0541 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0530 - accuracy: 0.98 - ETA: 5:27 - loss: 0.0522 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0533 - accuracy: 0.98 - ETA: 5:20 - loss: 0.0519 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0506 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0497 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0494 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0487 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0482 - accuracy: 0.98 - ETA: 5:01 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0461 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0500 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0507 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0511 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0518 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0510 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0505 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0500 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0505 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0502 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0500 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0492 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0491 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0491 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0495 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0493 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0489 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0506 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0499 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0491 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0495 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0494 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0484 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0480 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0486 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0479 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0486 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0484 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0482 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0479 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0473 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0497 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0497 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0500 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0499 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0493 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0499 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0499 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0507 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0507 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0520 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0519 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0489 - accuracy: 0.98 - ETA: 59s - loss: 0.0487 - accuracy: 0.9837 - ETA: 57s - loss: 0.0487 - accuracy: 0.983 - ETA: 54s - loss: 0.0490 - accuracy: 0.983 - ETA: 52s - loss: 0.0488 - accuracy: 0.983 - ETA: 49s - loss: 0.0488 - accuracy: 0.983 - ETA: 46s - loss: 0.0488 - accuracy: 0.983 - ETA: 44s - loss: 0.0487 - accuracy: 0.983 - ETA: 42s - loss: 0.0487 - accuracy: 0.983 - ETA: 39s - loss: 0.0484 - accuracy: 0.983 - ETA: 37s - loss: 0.0482 - accuracy: 0.983 - ETA: 34s - loss: 0.0479 - accuracy: 0.983 - ETA: 32s - loss: 0.0476 - accuracy: 0.983 - ETA: 29s - loss: 0.0478 - accuracy: 0.983 - ETA: 27s - loss: 0.0477 - accuracy: 0.983 - ETA: 24s - loss: 0.0480 - accuracy: 0.983 - ETA: 22s - loss: 0.0478 - accuracy: 0.983 - ETA: 19s - loss: 0.0477 - accuracy: 0.983 - ETA: 17s - loss: 0.0477 - accuracy: 0.983 - ETA: 14s - loss: 0.0475 - accuracy: 0.983 - ETA: 12s - loss: 0.0475 - accuracy: 0.983 - ETA: 9s - loss: 0.0475 - accuracy: 0.983 - ETA: 7s - loss: 0.0475 - accuracy: 0.98 - ETA: 4s - loss: 0.0473 - accuracy: 0.98 - ETA: 2s - loss: 0.0472 - accuracy: 0.98 - 426s 22ms/step - loss: 0.0469 - accuracy: 0.9839 - val_loss: 1.9331 - val_accuracy: 0.8016\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:42 - loss: 0.0609 - accuracy: 0.96 - ETA: 6:26 - loss: 0.0382 - accuracy: 0.97 - ETA: 6:21 - loss: 0.0637 - accuracy: 0.97 - ETA: 6:20 - loss: 0.0533 - accuracy: 0.98 - ETA: 6:17 - loss: 0.0580 - accuracy: 0.97 - ETA: 6:08 - loss: 0.0593 - accuracy: 0.97 - ETA: 6:05 - loss: 0.0593 - accuracy: 0.98 - ETA: 6:01 - loss: 0.0720 - accuracy: 0.97 - ETA: 5:57 - loss: 0.0698 - accuracy: 0.98 - ETA: 5:57 - loss: 0.0699 - accuracy: 0.98 - ETA: 5:51 - loss: 0.0673 - accuracy: 0.98 - ETA: 5:46 - loss: 0.0712 - accuracy: 0.97 - ETA: 5:43 - loss: 0.0664 - accuracy: 0.98 - ETA: 5:40 - loss: 0.0662 - accuracy: 0.97 - ETA: 5:39 - loss: 0.0624 - accuracy: 0.98 - ETA: 5:37 - loss: 0.0603 - accuracy: 0.98 - ETA: 5:34 - loss: 0.0610 - accuracy: 0.98 - ETA: 5:31 - loss: 0.0593 - accuracy: 0.98 - ETA: 5:30 - loss: 0.0567 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0558 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0562 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0542 - accuracy: 0.98 - ETA: 5:18 - loss: 0.0532 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0516 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0507 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0499 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0518 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0530 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0516 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0510 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0551 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0552 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0550 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0542 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0538 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0526 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0515 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0525 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0520 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0523 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0515 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0508 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0505 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0501 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0507 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0500 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0510 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0501 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0500 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0511 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0505 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0490 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0495 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0496 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0491 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0511 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0507 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0510 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0511 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0507 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0500 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0500 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0515 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0520 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0512 - accuracy: 0.98 - ETA: 59s - loss: 0.0509 - accuracy: 0.9839 - ETA: 57s - loss: 0.0507 - accuracy: 0.983 - ETA: 55s - loss: 0.0507 - accuracy: 0.983 - ETA: 53s - loss: 0.0510 - accuracy: 0.983 - ETA: 51s - loss: 0.0508 - accuracy: 0.983 - ETA: 49s - loss: 0.0509 - accuracy: 0.983 - ETA: 47s - loss: 0.0506 - accuracy: 0.983 - ETA: 45s - loss: 0.0509 - accuracy: 0.983 - ETA: 43s - loss: 0.0511 - accuracy: 0.983 - ETA: 41s - loss: 0.0511 - accuracy: 0.983 - ETA: 39s - loss: 0.0511 - accuracy: 0.983 - ETA: 37s - loss: 0.0510 - accuracy: 0.983 - ETA: 35s - loss: 0.0513 - accuracy: 0.983 - ETA: 33s - loss: 0.0513 - accuracy: 0.983 - ETA: 31s - loss: 0.0514 - accuracy: 0.983 - ETA: 29s - loss: 0.0512 - accuracy: 0.983 - ETA: 27s - loss: 0.0513 - accuracy: 0.983 - ETA: 25s - loss: 0.0510 - accuracy: 0.983 - ETA: 23s - loss: 0.0513 - accuracy: 0.983 - ETA: 21s - loss: 0.0515 - accuracy: 0.983 - ETA: 19s - loss: 0.0513 - accuracy: 0.983 - ETA: 17s - loss: 0.0510 - accuracy: 0.983 - ETA: 15s - loss: 0.0511 - accuracy: 0.983 - ETA: 13s - loss: 0.0515 - accuracy: 0.983 - ETA: 11s - loss: 0.0517 - accuracy: 0.983 - ETA: 9s - loss: 0.0515 - accuracy: 0.983 - ETA: 7s - loss: 0.0517 - accuracy: 0.98 - ETA: 5s - loss: 0.0514 - accuracy: 0.98 - ETA: 3s - loss: 0.0514 - accuracy: 0.98 - ETA: 1s - loss: 0.0513 - accuracy: 0.98 - 348s 18ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 1.8342 - val_accuracy: 0.8031\n",
      "Epoch 68/100\n",
      "19312/19312 [==============================] - ETA: 6:59 - loss: 0.0340 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0255 - accuracy: 0.99 - ETA: 5:12 - loss: 0.0293 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0310 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0273 - accuracy: 0.99 - ETA: 4:36 - loss: 0.0239 - accuracy: 0.99 - ETA: 4:45 - loss: 0.0279 - accuracy: 0.99 - ETA: 4:43 - loss: 0.0281 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0325 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0317 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0344 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0321 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0381 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0406 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0397 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0379 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0402 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0401 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0385 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0385 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0373 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0409 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0423 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0441 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0452 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0471 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0481 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0474 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0471 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0469 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0438 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0489 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0492 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0491 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0489 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0486 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0491 - accuracy: 0.98 - ETA: 58s - loss: 0.0490 - accuracy: 0.9844 - ETA: 56s - loss: 0.0489 - accuracy: 0.984 - ETA: 55s - loss: 0.0491 - accuracy: 0.984 - ETA: 53s - loss: 0.0489 - accuracy: 0.984 - ETA: 51s - loss: 0.0487 - accuracy: 0.984 - ETA: 49s - loss: 0.0489 - accuracy: 0.984 - ETA: 48s - loss: 0.0487 - accuracy: 0.984 - ETA: 46s - loss: 0.0502 - accuracy: 0.983 - ETA: 44s - loss: 0.0501 - accuracy: 0.983 - ETA: 42s - loss: 0.0505 - accuracy: 0.983 - ETA: 40s - loss: 0.0508 - accuracy: 0.983 - ETA: 39s - loss: 0.0516 - accuracy: 0.983 - ETA: 37s - loss: 0.0515 - accuracy: 0.983 - ETA: 35s - loss: 0.0515 - accuracy: 0.983 - ETA: 33s - loss: 0.0516 - accuracy: 0.983 - ETA: 32s - loss: 0.0514 - accuracy: 0.983 - ETA: 30s - loss: 0.0519 - accuracy: 0.983 - ETA: 28s - loss: 0.0522 - accuracy: 0.983 - ETA: 26s - loss: 0.0525 - accuracy: 0.983 - ETA: 25s - loss: 0.0522 - accuracy: 0.983 - ETA: 23s - loss: 0.0520 - accuracy: 0.983 - ETA: 21s - loss: 0.0518 - accuracy: 0.983 - ETA: 19s - loss: 0.0519 - accuracy: 0.983 - ETA: 17s - loss: 0.0522 - accuracy: 0.983 - ETA: 16s - loss: 0.0524 - accuracy: 0.983 - ETA: 14s - loss: 0.0521 - accuracy: 0.983 - ETA: 12s - loss: 0.0524 - accuracy: 0.983 - ETA: 10s - loss: 0.0521 - accuracy: 0.983 - ETA: 8s - loss: 0.0522 - accuracy: 0.983 - ETA: 7s - loss: 0.0521 - accuracy: 0.98 - ETA: 5s - loss: 0.0519 - accuracy: 0.98 - ETA: 3s - loss: 0.0522 - accuracy: 0.98 - ETA: 1s - loss: 0.0520 - accuracy: 0.98 - 317s 16ms/step - loss: 0.0522 - accuracy: 0.9834 - val_loss: 1.8236 - val_accuracy: 0.8014\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:31 - loss: 0.0206 - accuracy: 0.99 - ETA: 4:37 - loss: 0.0800 - accuracy: 0.96 - ETA: 4:33 - loss: 0.0574 - accuracy: 0.97 - ETA: 4:23 - loss: 0.0748 - accuracy: 0.97 - ETA: 4:19 - loss: 0.0862 - accuracy: 0.97 - ETA: 4:18 - loss: 0.0801 - accuracy: 0.97 - ETA: 4:14 - loss: 0.0807 - accuracy: 0.97 - ETA: 4:13 - loss: 0.0724 - accuracy: 0.97 - ETA: 4:12 - loss: 0.0724 - accuracy: 0.97 - ETA: 4:13 - loss: 0.0662 - accuracy: 0.97 - ETA: 4:11 - loss: 0.0625 - accuracy: 0.97 - ETA: 4:09 - loss: 0.0577 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0570 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0583 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0571 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0549 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0538 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0531 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0533 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0557 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0536 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0554 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0537 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0536 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0541 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0525 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0525 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0509 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0508 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0494 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0483 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0469 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0457 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0479 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0483 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0480 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0470 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0474 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0470 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0492 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0483 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0490 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0462 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0545 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0549 - accuracy: 0.98 - ETA: 59s - loss: 0.0549 - accuracy: 0.9832 - ETA: 57s - loss: 0.0551 - accuracy: 0.983 - ETA: 55s - loss: 0.0561 - accuracy: 0.982 - ETA: 53s - loss: 0.0557 - accuracy: 0.982 - ETA: 52s - loss: 0.0555 - accuracy: 0.983 - ETA: 50s - loss: 0.0551 - accuracy: 0.983 - ETA: 48s - loss: 0.0548 - accuracy: 0.983 - ETA: 46s - loss: 0.0552 - accuracy: 0.983 - ETA: 45s - loss: 0.0552 - accuracy: 0.982 - ETA: 43s - loss: 0.0551 - accuracy: 0.982 - ETA: 41s - loss: 0.0549 - accuracy: 0.983 - ETA: 40s - loss: 0.0550 - accuracy: 0.983 - ETA: 38s - loss: 0.0550 - accuracy: 0.983 - ETA: 36s - loss: 0.0550 - accuracy: 0.983 - ETA: 34s - loss: 0.0550 - accuracy: 0.983 - ETA: 33s - loss: 0.0555 - accuracy: 0.982 - ETA: 31s - loss: 0.0555 - accuracy: 0.982 - ETA: 29s - loss: 0.0553 - accuracy: 0.982 - ETA: 27s - loss: 0.0549 - accuracy: 0.983 - ETA: 26s - loss: 0.0546 - accuracy: 0.983 - ETA: 24s - loss: 0.0554 - accuracy: 0.983 - ETA: 22s - loss: 0.0553 - accuracy: 0.983 - ETA: 20s - loss: 0.0555 - accuracy: 0.982 - ETA: 19s - loss: 0.0563 - accuracy: 0.982 - ETA: 17s - loss: 0.0565 - accuracy: 0.982 - ETA: 15s - loss: 0.0562 - accuracy: 0.982 - ETA: 14s - loss: 0.0559 - accuracy: 0.982 - ETA: 12s - loss: 0.0560 - accuracy: 0.982 - ETA: 10s - loss: 0.0560 - accuracy: 0.982 - ETA: 8s - loss: 0.0560 - accuracy: 0.982 - ETA: 6s - loss: 0.0564 - accuracy: 0.98 - ETA: 5s - loss: 0.0562 - accuracy: 0.98 - ETA: 3s - loss: 0.0560 - accuracy: 0.98 - ETA: 1s - loss: 0.0558 - accuracy: 0.98 - 314s 16ms/step - loss: 0.0556 - accuracy: 0.9829 - val_loss: 1.8073 - val_accuracy: 0.8049\n",
      "Epoch 70/100\n",
      "19312/19312 [==============================] - ETA: 4:00 - loss: 0.0248 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0340 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0319 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0441 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0407 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0358 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0350 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0332 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0430 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0461 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0440 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0464 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0461 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0484 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0450 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0460 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0435 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0438 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0515 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0493 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0500 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0490 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0501 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0482 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0473 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0469 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0500 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0522 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0524 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0538 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0567 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0571 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0568 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0558 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0543 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0538 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0548 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0555 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0550 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0548 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0559 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0556 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0548 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0541 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0535 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0542 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0543 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0537 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0534 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0540 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0541 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0538 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0533 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0527 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0519 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0515 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0490 - accuracy: 0.98 - ETA: 59s - loss: 0.0491 - accuracy: 0.9845 - ETA: 57s - loss: 0.0490 - accuracy: 0.984 - ETA: 56s - loss: 0.0489 - accuracy: 0.984 - ETA: 54s - loss: 0.0488 - accuracy: 0.984 - ETA: 52s - loss: 0.0485 - accuracy: 0.984 - ETA: 50s - loss: 0.0487 - accuracy: 0.984 - ETA: 48s - loss: 0.0494 - accuracy: 0.984 - ETA: 46s - loss: 0.0492 - accuracy: 0.984 - ETA: 45s - loss: 0.0501 - accuracy: 0.984 - ETA: 43s - loss: 0.0507 - accuracy: 0.984 - ETA: 41s - loss: 0.0516 - accuracy: 0.984 - ETA: 39s - loss: 0.0518 - accuracy: 0.984 - ETA: 37s - loss: 0.0527 - accuracy: 0.984 - ETA: 35s - loss: 0.0525 - accuracy: 0.984 - ETA: 34s - loss: 0.0523 - accuracy: 0.984 - ETA: 32s - loss: 0.0521 - accuracy: 0.984 - ETA: 30s - loss: 0.0517 - accuracy: 0.984 - ETA: 28s - loss: 0.0519 - accuracy: 0.984 - ETA: 26s - loss: 0.0518 - accuracy: 0.984 - ETA: 25s - loss: 0.0517 - accuracy: 0.984 - ETA: 23s - loss: 0.0514 - accuracy: 0.984 - ETA: 21s - loss: 0.0517 - accuracy: 0.984 - ETA: 19s - loss: 0.0518 - accuracy: 0.984 - ETA: 17s - loss: 0.0517 - accuracy: 0.984 - ETA: 16s - loss: 0.0517 - accuracy: 0.984 - ETA: 14s - loss: 0.0520 - accuracy: 0.984 - ETA: 12s - loss: 0.0519 - accuracy: 0.984 - ETA: 10s - loss: 0.0522 - accuracy: 0.984 - ETA: 8s - loss: 0.0519 - accuracy: 0.984 - ETA: 6s - loss: 0.0517 - accuracy: 0.98 - ETA: 5s - loss: 0.0514 - accuracy: 0.98 - ETA: 3s - loss: 0.0513 - accuracy: 0.98 - ETA: 1s - loss: 0.0513 - accuracy: 0.98 - 307s 16ms/step - loss: 0.0522 - accuracy: 0.9841 - val_loss: 1.8263 - val_accuracy: 0.8058\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:39 - loss: 0.0534 - accuracy: 0.97 - ETA: 4:27 - loss: 0.0273 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0279 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0259 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0354 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0469 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0506 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0479 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0469 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0447 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0457 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0458 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0471 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0439 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0494 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0474 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0472 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0483 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0471 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0477 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0481 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0471 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0444 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0441 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0435 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0440 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0436 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0440 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0442 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0442 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0453 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0457 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0460 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0453 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0435 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0437 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0433 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0426 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0424 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0419 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0420 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0417 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0414 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0427 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0421 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0421 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0417 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0413 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0411 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0410 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0409 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0409 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0411 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0409 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0405 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0403 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0404 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0404 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0406 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0408 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0414 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0411 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0420 - accuracy: 0.98 - ETA: 59s - loss: 0.0418 - accuracy: 0.9855 - ETA: 57s - loss: 0.0418 - accuracy: 0.985 - ETA: 55s - loss: 0.0415 - accuracy: 0.985 - ETA: 53s - loss: 0.0415 - accuracy: 0.985 - ETA: 52s - loss: 0.0414 - accuracy: 0.985 - ETA: 50s - loss: 0.0414 - accuracy: 0.985 - ETA: 48s - loss: 0.0418 - accuracy: 0.985 - ETA: 47s - loss: 0.0419 - accuracy: 0.985 - ETA: 45s - loss: 0.0422 - accuracy: 0.985 - ETA: 43s - loss: 0.0421 - accuracy: 0.985 - ETA: 42s - loss: 0.0419 - accuracy: 0.985 - ETA: 40s - loss: 0.0424 - accuracy: 0.985 - ETA: 38s - loss: 0.0422 - accuracy: 0.985 - ETA: 37s - loss: 0.0421 - accuracy: 0.985 - ETA: 35s - loss: 0.0419 - accuracy: 0.985 - ETA: 33s - loss: 0.0418 - accuracy: 0.985 - ETA: 32s - loss: 0.0425 - accuracy: 0.985 - ETA: 30s - loss: 0.0422 - accuracy: 0.985 - ETA: 28s - loss: 0.0421 - accuracy: 0.985 - ETA: 27s - loss: 0.0425 - accuracy: 0.985 - ETA: 25s - loss: 0.0424 - accuracy: 0.985 - ETA: 23s - loss: 0.0438 - accuracy: 0.985 - ETA: 21s - loss: 0.0439 - accuracy: 0.985 - ETA: 20s - loss: 0.0437 - accuracy: 0.985 - ETA: 18s - loss: 0.0435 - accuracy: 0.985 - ETA: 16s - loss: 0.0442 - accuracy: 0.984 - ETA: 15s - loss: 0.0442 - accuracy: 0.984 - ETA: 13s - loss: 0.0450 - accuracy: 0.984 - ETA: 11s - loss: 0.0449 - accuracy: 0.984 - ETA: 10s - loss: 0.0448 - accuracy: 0.984 - ETA: 8s - loss: 0.0446 - accuracy: 0.985 - ETA: 6s - loss: 0.0448 - accuracy: 0.98 - ETA: 4s - loss: 0.0445 - accuracy: 0.98 - ETA: 3s - loss: 0.0444 - accuracy: 0.98 - ETA: 1s - loss: 0.0441 - accuracy: 0.98 - 299s 15ms/step - loss: 0.0439 - accuracy: 0.9852 - val_loss: 1.8741 - val_accuracy: 0.8062\n",
      "Epoch 72/100\n",
      "19312/19312 [==============================] - ETA: 5:56 - loss: 0.0557 - accuracy: 0.97 - ETA: 5:47 - loss: 0.0758 - accuracy: 0.97 - ETA: 5:36 - loss: 0.0550 - accuracy: 0.98 - ETA: 6:02 - loss: 0.0712 - accuracy: 0.97 - ETA: 5:54 - loss: 0.0864 - accuracy: 0.97 - ETA: 5:51 - loss: 0.0753 - accuracy: 0.98 - ETA: 5:51 - loss: 0.0686 - accuracy: 0.98 - ETA: 5:48 - loss: 0.0635 - accuracy: 0.98 - ETA: 5:57 - loss: 0.0636 - accuracy: 0.98 - ETA: 5:56 - loss: 0.0655 - accuracy: 0.98 - ETA: 5:53 - loss: 0.0651 - accuracy: 0.98 - ETA: 5:48 - loss: 0.0640 - accuracy: 0.98 - ETA: 5:44 - loss: 0.0600 - accuracy: 0.98 - ETA: 5:38 - loss: 0.0566 - accuracy: 0.98 - ETA: 5:44 - loss: 0.0578 - accuracy: 0.98 - ETA: 5:39 - loss: 0.0570 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0542 - accuracy: 0.98 - ETA: 5:32 - loss: 0.0570 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0557 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0582 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0557 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0570 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0572 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0580 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0583 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0564 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0569 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0551 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0534 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0552 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0551 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0557 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0564 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0565 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0553 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0540 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0558 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0546 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0549 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0539 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0548 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0542 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0546 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0541 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0533 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0548 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0546 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0538 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0548 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0539 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0540 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0533 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0546 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0546 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0550 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0546 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0550 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0559 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0553 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0546 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0541 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0543 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0543 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0540 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0535 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0529 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0522 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0528 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0528 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0524 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0518 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0524 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0523 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0527 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0520 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0519 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0509 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0525 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0528 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0528 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0510 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0507 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0528 - accuracy: 0.98 - ETA: 58s - loss: 0.0528 - accuracy: 0.9838 - ETA: 56s - loss: 0.0526 - accuracy: 0.983 - ETA: 54s - loss: 0.0525 - accuracy: 0.983 - ETA: 51s - loss: 0.0523 - accuracy: 0.983 - ETA: 49s - loss: 0.0524 - accuracy: 0.983 - ETA: 46s - loss: 0.0523 - accuracy: 0.983 - ETA: 44s - loss: 0.0520 - accuracy: 0.983 - ETA: 41s - loss: 0.0522 - accuracy: 0.983 - ETA: 39s - loss: 0.0523 - accuracy: 0.983 - ETA: 36s - loss: 0.0521 - accuracy: 0.983 - ETA: 34s - loss: 0.0522 - accuracy: 0.983 - ETA: 31s - loss: 0.0518 - accuracy: 0.983 - ETA: 29s - loss: 0.0519 - accuracy: 0.983 - ETA: 27s - loss: 0.0523 - accuracy: 0.983 - ETA: 24s - loss: 0.0521 - accuracy: 0.983 - ETA: 22s - loss: 0.0519 - accuracy: 0.984 - ETA: 19s - loss: 0.0517 - accuracy: 0.984 - ETA: 17s - loss: 0.0521 - accuracy: 0.983 - ETA: 14s - loss: 0.0524 - accuracy: 0.983 - ETA: 12s - loss: 0.0527 - accuracy: 0.983 - ETA: 9s - loss: 0.0525 - accuracy: 0.983 - ETA: 7s - loss: 0.0533 - accuracy: 0.98 - ETA: 4s - loss: 0.0533 - accuracy: 0.98 - ETA: 2s - loss: 0.0535 - accuracy: 0.98 - 423s 22ms/step - loss: 0.0533 - accuracy: 0.9836 - val_loss: 1.7998 - val_accuracy: 0.8068\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:14 - loss: 0.0639 - accuracy: 0.98 - ETA: 6:01 - loss: 0.0438 - accuracy: 0.98 - ETA: 5:59 - loss: 0.0403 - accuracy: 0.98 - ETA: 5:32 - loss: 0.0305 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0301 - accuracy: 0.98 - ETA: 5:36 - loss: 0.0258 - accuracy: 0.99 - ETA: 5:35 - loss: 0.0377 - accuracy: 0.98 - ETA: 5:34 - loss: 0.0434 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0423 - accuracy: 0.98 - ETA: 5:31 - loss: 0.0400 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0402 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0407 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0397 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0389 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0393 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0398 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0386 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0386 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0374 - accuracy: 0.98 - ETA: 5:13 - loss: 0.0372 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0391 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0389 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0401 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0426 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0420 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0417 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0409 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0401 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0400 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0393 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0385 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0373 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0365 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0380 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0376 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0380 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0373 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0374 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0379 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0392 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0391 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0415 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0452 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0465 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0461 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0461 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0470 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0475 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0481 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0482 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0473 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0473 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0482 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0481 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0478 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0480 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0477 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0473 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0460 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0454 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0457 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0451 - accuracy: 0.98 - ETA: 57s - loss: 0.0451 - accuracy: 0.9854 - ETA: 55s - loss: 0.0451 - accuracy: 0.985 - ETA: 52s - loss: 0.0451 - accuracy: 0.985 - ETA: 50s - loss: 0.0449 - accuracy: 0.985 - ETA: 47s - loss: 0.0449 - accuracy: 0.985 - ETA: 44s - loss: 0.0446 - accuracy: 0.985 - ETA: 42s - loss: 0.0448 - accuracy: 0.985 - ETA: 39s - loss: 0.0449 - accuracy: 0.985 - ETA: 37s - loss: 0.0448 - accuracy: 0.985 - ETA: 34s - loss: 0.0450 - accuracy: 0.985 - ETA: 32s - loss: 0.0450 - accuracy: 0.985 - ETA: 29s - loss: 0.0449 - accuracy: 0.985 - ETA: 27s - loss: 0.0447 - accuracy: 0.985 - ETA: 24s - loss: 0.0444 - accuracy: 0.985 - ETA: 22s - loss: 0.0441 - accuracy: 0.985 - ETA: 19s - loss: 0.0442 - accuracy: 0.985 - ETA: 17s - loss: 0.0444 - accuracy: 0.985 - ETA: 14s - loss: 0.0443 - accuracy: 0.985 - ETA: 12s - loss: 0.0446 - accuracy: 0.985 - ETA: 9s - loss: 0.0445 - accuracy: 0.985 - ETA: 7s - loss: 0.0444 - accuracy: 0.98 - ETA: 4s - loss: 0.0442 - accuracy: 0.98 - ETA: 2s - loss: 0.0440 - accuracy: 0.98 - 430s 22ms/step - loss: 0.0440 - accuracy: 0.9855 - val_loss: 1.8432 - val_accuracy: 0.8070\n",
      "Epoch 74/100\n",
      "19312/19312 [==============================] - ETA: 7:35 - loss: 0.0822 - accuracy: 0.96 - ETA: 6:46 - loss: 0.0418 - accuracy: 0.98 - ETA: 6:26 - loss: 0.0410 - accuracy: 0.98 - ETA: 6:18 - loss: 0.0313 - accuracy: 0.98 - ETA: 6:08 - loss: 0.0252 - accuracy: 0.99 - ETA: 6:14 - loss: 0.0225 - accuracy: 0.99 - ETA: 6:13 - loss: 0.0222 - accuracy: 0.99 - ETA: 6:05 - loss: 0.0211 - accuracy: 0.99 - ETA: 6:05 - loss: 0.0216 - accuracy: 0.99 - ETA: 6:00 - loss: 0.0303 - accuracy: 0.99 - ETA: 6:01 - loss: 0.0291 - accuracy: 0.99 - ETA: 6:02 - loss: 0.0300 - accuracy: 0.99 - ETA: 6:03 - loss: 0.0309 - accuracy: 0.99 - ETA: 6:03 - loss: 0.0319 - accuracy: 0.99 - ETA: 6:02 - loss: 0.0384 - accuracy: 0.98 - ETA: 5:58 - loss: 0.0378 - accuracy: 0.98 - ETA: 5:53 - loss: 0.0371 - accuracy: 0.98 - ETA: 5:55 - loss: 0.0390 - accuracy: 0.98 - ETA: 5:51 - loss: 0.0378 - accuracy: 0.98 - ETA: 5:49 - loss: 0.0408 - accuracy: 0.98 - ETA: 5:45 - loss: 0.0411 - accuracy: 0.98 - ETA: 5:38 - loss: 0.0418 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0405 - accuracy: 0.98 - ETA: 5:32 - loss: 0.0402 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0390 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0406 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0448 - accuracy: 0.98 - ETA: 5:18 - loss: 0.0448 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0434 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0430 - accuracy: 0.98 - ETA: 5:08 - loss: 0.0418 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0412 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0410 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0401 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0392 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0414 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0434 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0436 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0426 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0435 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0426 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0427 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0423 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0421 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0420 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0411 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0405 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0408 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0411 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0424 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0422 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0443 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0439 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0441 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0439 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0440 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0436 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0432 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0445 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0442 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0440 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0436 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0440 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0452 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0457 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0450 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0450 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0469 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0476 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0476 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0486 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0483 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0478 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0461 - accuracy: 0.98 - ETA: 58s - loss: 0.0458 - accuracy: 0.9860 - ETA: 55s - loss: 0.0457 - accuracy: 0.986 - ETA: 53s - loss: 0.0457 - accuracy: 0.986 - ETA: 50s - loss: 0.0455 - accuracy: 0.986 - ETA: 48s - loss: 0.0456 - accuracy: 0.986 - ETA: 45s - loss: 0.0455 - accuracy: 0.986 - ETA: 42s - loss: 0.0453 - accuracy: 0.986 - ETA: 40s - loss: 0.0451 - accuracy: 0.986 - ETA: 37s - loss: 0.0448 - accuracy: 0.986 - ETA: 35s - loss: 0.0445 - accuracy: 0.986 - ETA: 32s - loss: 0.0442 - accuracy: 0.986 - ETA: 30s - loss: 0.0440 - accuracy: 0.986 - ETA: 27s - loss: 0.0440 - accuracy: 0.986 - ETA: 25s - loss: 0.0440 - accuracy: 0.986 - ETA: 22s - loss: 0.0438 - accuracy: 0.986 - ETA: 20s - loss: 0.0441 - accuracy: 0.986 - ETA: 17s - loss: 0.0445 - accuracy: 0.986 - ETA: 15s - loss: 0.0442 - accuracy: 0.986 - ETA: 12s - loss: 0.0440 - accuracy: 0.986 - ETA: 9s - loss: 0.0438 - accuracy: 0.986 - ETA: 7s - loss: 0.0436 - accuracy: 0.98 - ETA: 4s - loss: 0.0436 - accuracy: 0.98 - ETA: 2s - loss: 0.0435 - accuracy: 0.98 - 439s 23ms/step - loss: 0.0436 - accuracy: 0.9864 - val_loss: 1.7990 - val_accuracy: 0.8107\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:05 - loss: 0.0110 - accuracy: 0.99 - ETA: 5:52 - loss: 0.0312 - accuracy: 0.98 - ETA: 5:54 - loss: 0.0391 - accuracy: 0.98 - ETA: 6:06 - loss: 0.0487 - accuracy: 0.98 - ETA: 6:09 - loss: 0.0436 - accuracy: 0.98 - ETA: 5:46 - loss: 0.0513 - accuracy: 0.98 - ETA: 5:31 - loss: 0.0444 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0442 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0427 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0434 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0436 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0420 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0422 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0399 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0394 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0409 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0404 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0409 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0414 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0418 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0428 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0415 - accuracy: 0.98 - ETA: 4:49 - loss: 0.0404 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0398 - accuracy: 0.98 - ETA: 4:52 - loss: 0.0408 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0446 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0453 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0470 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0456 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0456 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0458 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0455 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0442 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0444 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0464 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0458 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0459 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0452 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0444 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0463 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0482 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0476 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0465 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0455 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0446 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0438 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0430 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0427 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0441 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0433 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0428 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0426 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0426 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0454 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0457 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0453 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0460 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0438 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0435 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0433 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0434 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0436 - accuracy: 0.98 - ETA: 57s - loss: 0.0438 - accuracy: 0.9864 - ETA: 55s - loss: 0.0441 - accuracy: 0.986 - ETA: 53s - loss: 0.0442 - accuracy: 0.986 - ETA: 51s - loss: 0.0446 - accuracy: 0.986 - ETA: 48s - loss: 0.0443 - accuracy: 0.986 - ETA: 46s - loss: 0.0442 - accuracy: 0.986 - ETA: 44s - loss: 0.0441 - accuracy: 0.986 - ETA: 42s - loss: 0.0438 - accuracy: 0.986 - ETA: 39s - loss: 0.0440 - accuracy: 0.986 - ETA: 37s - loss: 0.0438 - accuracy: 0.986 - ETA: 35s - loss: 0.0437 - accuracy: 0.986 - ETA: 32s - loss: 0.0436 - accuracy: 0.986 - ETA: 30s - loss: 0.0434 - accuracy: 0.986 - ETA: 28s - loss: 0.0434 - accuracy: 0.986 - ETA: 25s - loss: 0.0437 - accuracy: 0.986 - ETA: 23s - loss: 0.0436 - accuracy: 0.986 - ETA: 21s - loss: 0.0437 - accuracy: 0.986 - ETA: 18s - loss: 0.0435 - accuracy: 0.986 - ETA: 16s - loss: 0.0432 - accuracy: 0.986 - ETA: 13s - loss: 0.0432 - accuracy: 0.986 - ETA: 11s - loss: 0.0433 - accuracy: 0.986 - ETA: 9s - loss: 0.0430 - accuracy: 0.986 - ETA: 6s - loss: 0.0431 - accuracy: 0.98 - ETA: 4s - loss: 0.0434 - accuracy: 0.98 - ETA: 2s - loss: 0.0433 - accuracy: 0.98 - 418s 22ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 1.9480 - val_accuracy: 0.8064\n",
      "Epoch 76/100\n",
      "19312/19312 [==============================] - ETA: 6:26 - loss: 0.0315 - accuracy: 0.98 - ETA: 6:15 - loss: 0.0523 - accuracy: 0.98 - ETA: 6:10 - loss: 0.0809 - accuracy: 0.98 - ETA: 6:06 - loss: 0.0675 - accuracy: 0.98 - ETA: 6:01 - loss: 0.0662 - accuracy: 0.98 - ETA: 5:54 - loss: 0.0605 - accuracy: 0.98 - ETA: 5:55 - loss: 0.0596 - accuracy: 0.98 - ETA: 5:52 - loss: 0.0527 - accuracy: 0.98 - ETA: 5:45 - loss: 0.0491 - accuracy: 0.98 - ETA: 5:41 - loss: 0.0454 - accuracy: 0.98 - ETA: 5:37 - loss: 0.0472 - accuracy: 0.98 - ETA: 5:38 - loss: 0.0471 - accuracy: 0.98 - ETA: 5:38 - loss: 0.0448 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0437 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0434 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0417 - accuracy: 0.98 - ETA: 5:23 - loss: 0.0427 - accuracy: 0.98 - ETA: 5:21 - loss: 0.0429 - accuracy: 0.98 - ETA: 5:18 - loss: 0.0411 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0402 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0383 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0380 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0381 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0385 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0374 - accuracy: 0.98 - ETA: 5:05 - loss: 0.0389 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0388 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0397 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0397 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0389 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0406 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0394 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0388 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0385 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0376 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0391 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0384 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0385 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0411 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0425 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0432 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0424 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0428 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0422 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0419 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0411 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0403 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0399 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0398 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0395 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0398 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0392 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0395 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0392 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0414 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0427 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0424 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0426 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0429 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0432 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0427 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0431 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0425 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0431 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0428 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0423 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0420 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0417 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0422 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0421 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0418 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0419 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0421 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0417 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0417 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0425 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0430 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0442 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0468 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0468 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0442 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0442 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0458 - accuracy: 0.98 - ETA: 59s - loss: 0.0457 - accuracy: 0.9857 - ETA: 56s - loss: 0.0454 - accuracy: 0.985 - ETA: 54s - loss: 0.0452 - accuracy: 0.985 - ETA: 51s - loss: 0.0452 - accuracy: 0.985 - ETA: 49s - loss: 0.0456 - accuracy: 0.985 - ETA: 46s - loss: 0.0459 - accuracy: 0.985 - ETA: 43s - loss: 0.0460 - accuracy: 0.985 - ETA: 41s - loss: 0.0460 - accuracy: 0.985 - ETA: 38s - loss: 0.0461 - accuracy: 0.985 - ETA: 36s - loss: 0.0459 - accuracy: 0.985 - ETA: 33s - loss: 0.0460 - accuracy: 0.985 - ETA: 31s - loss: 0.0458 - accuracy: 0.985 - ETA: 28s - loss: 0.0460 - accuracy: 0.985 - ETA: 25s - loss: 0.0458 - accuracy: 0.985 - ETA: 23s - loss: 0.0458 - accuracy: 0.985 - ETA: 20s - loss: 0.0462 - accuracy: 0.985 - ETA: 18s - loss: 0.0462 - accuracy: 0.985 - ETA: 15s - loss: 0.0462 - accuracy: 0.985 - ETA: 12s - loss: 0.0460 - accuracy: 0.985 - ETA: 10s - loss: 0.0459 - accuracy: 0.985 - ETA: 7s - loss: 0.0459 - accuracy: 0.985 - ETA: 4s - loss: 0.0460 - accuracy: 0.98 - ETA: 2s - loss: 0.0457 - accuracy: 0.98 - 448s 23ms/step - loss: 0.0461 - accuracy: 0.9854 - val_loss: 1.9251 - val_accuracy: 0.8053\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:10 - loss: 0.0387 - accuracy: 0.99 - ETA: 6:02 - loss: 0.0452 - accuracy: 0.98 - ETA: 6:32 - loss: 0.0412 - accuracy: 0.98 - ETA: 6:33 - loss: 0.0389 - accuracy: 0.98 - ETA: 6:29 - loss: 0.0671 - accuracy: 0.97 - ETA: 6:29 - loss: 0.0602 - accuracy: 0.98 - ETA: 6:29 - loss: 0.0529 - accuracy: 0.98 - ETA: 6:21 - loss: 0.0499 - accuracy: 0.98 - ETA: 6:26 - loss: 0.0570 - accuracy: 0.98 - ETA: 6:23 - loss: 0.0562 - accuracy: 0.98 - ETA: 6:18 - loss: 0.0578 - accuracy: 0.98 - ETA: 6:15 - loss: 0.0535 - accuracy: 0.98 - ETA: 6:07 - loss: 0.0505 - accuracy: 0.98 - ETA: 5:56 - loss: 0.0507 - accuracy: 0.98 - ETA: 6:01 - loss: 0.0497 - accuracy: 0.98 - ETA: 6:03 - loss: 0.0483 - accuracy: 0.98 - ETA: 5:59 - loss: 0.0469 - accuracy: 0.98 - ETA: 6:00 - loss: 0.0447 - accuracy: 0.98 - ETA: 5:57 - loss: 0.0429 - accuracy: 0.98 - ETA: 5:52 - loss: 0.0421 - accuracy: 0.98 - ETA: 5:53 - loss: 0.0420 - accuracy: 0.98 - ETA: 5:51 - loss: 0.0405 - accuracy: 0.98 - ETA: 5:47 - loss: 0.0405 - accuracy: 0.98 - ETA: 5:44 - loss: 0.0416 - accuracy: 0.98 - ETA: 5:43 - loss: 0.0402 - accuracy: 0.98 - ETA: 5:39 - loss: 0.0419 - accuracy: 0.98 - ETA: 5:35 - loss: 0.0404 - accuracy: 0.98 - ETA: 5:34 - loss: 0.0399 - accuracy: 0.98 - ETA: 5:31 - loss: 0.0406 - accuracy: 0.98 - ETA: 5:27 - loss: 0.0408 - accuracy: 0.98 - ETA: 5:25 - loss: 0.0405 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0394 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0387 - accuracy: 0.98 - ETA: 5:17 - loss: 0.0389 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0381 - accuracy: 0.98 - ETA: 5:11 - loss: 0.0373 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0364 - accuracy: 0.98 - ETA: 5:07 - loss: 0.0356 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0364 - accuracy: 0.98 - ETA: 5:02 - loss: 0.0359 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0358 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0369 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0370 - accuracy: 0.98 - ETA: 4:51 - loss: 0.0366 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0372 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0369 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0375 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0368 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0366 - accuracy: 0.98 - ETA: 4:36 - loss: 0.0365 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0368 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0367 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0382 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0379 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0377 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0371 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0368 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0372 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0366 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0369 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0364 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0360 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0358 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0366 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0363 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0371 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0380 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0374 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0370 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0369 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0370 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0368 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0365 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0361 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0363 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0359 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0355 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0353 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0353 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0351 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0351 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0347 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0346 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0344 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0348 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0354 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0360 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0360 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0360 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0359 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0357 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0355 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0356 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0357 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0356 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0355 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0357 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0360 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0360 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0357 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0356 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0355 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0363 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0363 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0362 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0359 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0357 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0355 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0353 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0351 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0363 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0360 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0357 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0358 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0353 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0352 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0352 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0355 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0354 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0355 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0355 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0357 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0364 - accuracy: 0.98 - ETA: 58s - loss: 0.0365 - accuracy: 0.9876 - ETA: 56s - loss: 0.0375 - accuracy: 0.987 - ETA: 53s - loss: 0.0377 - accuracy: 0.987 - ETA: 50s - loss: 0.0380 - accuracy: 0.987 - ETA: 47s - loss: 0.0379 - accuracy: 0.987 - ETA: 44s - loss: 0.0378 - accuracy: 0.987 - ETA: 41s - loss: 0.0380 - accuracy: 0.987 - ETA: 39s - loss: 0.0381 - accuracy: 0.987 - ETA: 36s - loss: 0.0389 - accuracy: 0.987 - ETA: 33s - loss: 0.0387 - accuracy: 0.987 - ETA: 30s - loss: 0.0386 - accuracy: 0.987 - ETA: 27s - loss: 0.0385 - accuracy: 0.987 - ETA: 24s - loss: 0.0386 - accuracy: 0.987 - ETA: 22s - loss: 0.0385 - accuracy: 0.987 - ETA: 19s - loss: 0.0386 - accuracy: 0.987 - ETA: 16s - loss: 0.0390 - accuracy: 0.987 - ETA: 13s - loss: 0.0388 - accuracy: 0.987 - ETA: 10s - loss: 0.0399 - accuracy: 0.986 - ETA: 8s - loss: 0.0403 - accuracy: 0.986 - ETA: 5s - loss: 0.0403 - accuracy: 0.98 - ETA: 2s - loss: 0.0402 - accuracy: 0.98 - 478s 25ms/step - loss: 0.0402 - accuracy: 0.9866 - val_loss: 2.0248 - val_accuracy: 0.8082\n",
      "Epoch 78/100\n",
      "19312/19312 [==============================] - ETA: 6:28 - loss: 0.0971 - accuracy: 0.96 - ETA: 5:53 - loss: 0.0938 - accuracy: 0.96 - ETA: 5:57 - loss: 0.0635 - accuracy: 0.97 - ETA: 5:46 - loss: 0.0527 - accuracy: 0.98 - ETA: 6:02 - loss: 0.0524 - accuracy: 0.98 - ETA: 5:58 - loss: 0.0468 - accuracy: 0.98 - ETA: 5:48 - loss: 0.0412 - accuracy: 0.98 - ETA: 5:47 - loss: 0.0384 - accuracy: 0.98 - ETA: 5:37 - loss: 0.0442 - accuracy: 0.98 - ETA: 5:29 - loss: 0.0423 - accuracy: 0.98 - ETA: 5:16 - loss: 0.0456 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0465 - accuracy: 0.98 - ETA: 4:55 - loss: 0.0436 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0435 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0459 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0470 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0467 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0475 - accuracy: 0.98 - ETA: 4:48 - loss: 0.0493 - accuracy: 0.98 - ETA: 4:44 - loss: 0.0514 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0521 - accuracy: 0.98 - ETA: 4:37 - loss: 0.0499 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0495 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0483 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0469 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0472 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0480 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0468 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0454 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0452 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0457 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0486 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0484 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0520 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0518 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0505 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0508 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0509 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0509 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0499 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0500 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0490 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0490 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0481 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0473 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0472 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0453 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0471 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0470 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0462 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0478 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0465 - accuracy: 0.98 - ETA: 59s - loss: 0.0467 - accuracy: 0.9842 - ETA: 57s - loss: 0.0473 - accuracy: 0.984 - ETA: 54s - loss: 0.0471 - accuracy: 0.984 - ETA: 52s - loss: 0.0468 - accuracy: 0.984 - ETA: 50s - loss: 0.0466 - accuracy: 0.984 - ETA: 48s - loss: 0.0463 - accuracy: 0.984 - ETA: 46s - loss: 0.0460 - accuracy: 0.984 - ETA: 43s - loss: 0.0459 - accuracy: 0.984 - ETA: 41s - loss: 0.0461 - accuracy: 0.984 - ETA: 39s - loss: 0.0463 - accuracy: 0.984 - ETA: 37s - loss: 0.0466 - accuracy: 0.984 - ETA: 34s - loss: 0.0463 - accuracy: 0.984 - ETA: 32s - loss: 0.0462 - accuracy: 0.984 - ETA: 30s - loss: 0.0462 - accuracy: 0.984 - ETA: 28s - loss: 0.0460 - accuracy: 0.984 - ETA: 25s - loss: 0.0459 - accuracy: 0.984 - ETA: 23s - loss: 0.0458 - accuracy: 0.984 - ETA: 21s - loss: 0.0457 - accuracy: 0.984 - ETA: 18s - loss: 0.0459 - accuracy: 0.984 - ETA: 16s - loss: 0.0457 - accuracy: 0.984 - ETA: 14s - loss: 0.0470 - accuracy: 0.984 - ETA: 11s - loss: 0.0468 - accuracy: 0.984 - ETA: 9s - loss: 0.0466 - accuracy: 0.984 - ETA: 6s - loss: 0.0467 - accuracy: 0.98 - ETA: 4s - loss: 0.0465 - accuracy: 0.98 - ETA: 2s - loss: 0.0469 - accuracy: 0.98 - 427s 22ms/step - loss: 0.0470 - accuracy: 0.9844 - val_loss: 1.9283 - val_accuracy: 0.8055\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:21 - loss: 0.0033 - accuracy: 1.00 - ETA: 6:23 - loss: 0.0109 - accuracy: 0.99 - ETA: 6:20 - loss: 0.0157 - accuracy: 0.99 - ETA: 6:11 - loss: 0.0146 - accuracy: 0.99 - ETA: 6:11 - loss: 0.0268 - accuracy: 0.99 - ETA: 6:08 - loss: 0.0278 - accuracy: 0.99 - ETA: 6:02 - loss: 0.0439 - accuracy: 0.98 - ETA: 6:01 - loss: 0.0446 - accuracy: 0.98 - ETA: 5:59 - loss: 0.0468 - accuracy: 0.98 - ETA: 5:59 - loss: 0.0452 - accuracy: 0.98 - ETA: 5:59 - loss: 0.0427 - accuracy: 0.98 - ETA: 5:59 - loss: 0.0429 - accuracy: 0.98 - ETA: 5:57 - loss: 0.0474 - accuracy: 0.98 - ETA: 5:57 - loss: 0.0482 - accuracy: 0.98 - ETA: 5:56 - loss: 0.0469 - accuracy: 0.98 - ETA: 5:53 - loss: 0.0467 - accuracy: 0.98 - ETA: 5:52 - loss: 0.0449 - accuracy: 0.98 - ETA: 5:53 - loss: 0.0473 - accuracy: 0.98 - ETA: 5:50 - loss: 0.0454 - accuracy: 0.98 - ETA: 5:48 - loss: 0.0437 - accuracy: 0.98 - ETA: 5:43 - loss: 0.0429 - accuracy: 0.98 - ETA: 5:41 - loss: 0.0423 - accuracy: 0.98 - ETA: 5:39 - loss: 0.0435 - accuracy: 0.98 - ETA: 5:36 - loss: 0.0455 - accuracy: 0.98 - ETA: 5:34 - loss: 0.0452 - accuracy: 0.98 - ETA: 5:31 - loss: 0.0444 - accuracy: 0.98 - ETA: 5:26 - loss: 0.0448 - accuracy: 0.98 - ETA: 5:22 - loss: 0.0452 - accuracy: 0.98 - ETA: 5:19 - loss: 0.0480 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0464 - accuracy: 0.98 - ETA: 5:15 - loss: 0.0451 - accuracy: 0.98 - ETA: 5:12 - loss: 0.0465 - accuracy: 0.98 - ETA: 5:09 - loss: 0.0454 - accuracy: 0.98 - ETA: 5:06 - loss: 0.0445 - accuracy: 0.98 - ETA: 5:04 - loss: 0.0465 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0475 - accuracy: 0.98 - ETA: 5:00 - loss: 0.0470 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0469 - accuracy: 0.98 - ETA: 4:58 - loss: 0.0457 - accuracy: 0.98 - ETA: 4:53 - loss: 0.0447 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0439 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0434 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0430 - accuracy: 0.98 - ETA: 4:42 - loss: 0.0439 - accuracy: 0.98 - ETA: 4:39 - loss: 0.0433 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0447 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0455 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0448 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0441 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0440 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0440 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0434 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0427 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0425 - accuracy: 0.98 - ETA: 4:10 - loss: 0.0427 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0440 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0434 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0437 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0432 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0436 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0436 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0434 - accuracy: 0.98 - ETA: 3:50 - loss: 0.0436 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0434 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0438 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0469 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0460 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0455 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0460 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0476 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0478 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0461 - accuracy: 0.98 - ETA: 57s - loss: 0.0461 - accuracy: 0.9853 - ETA: 55s - loss: 0.0463 - accuracy: 0.985 - ETA: 52s - loss: 0.0460 - accuracy: 0.985 - ETA: 50s - loss: 0.0457 - accuracy: 0.985 - ETA: 47s - loss: 0.0458 - accuracy: 0.985 - ETA: 44s - loss: 0.0457 - accuracy: 0.985 - ETA: 42s - loss: 0.0455 - accuracy: 0.985 - ETA: 39s - loss: 0.0458 - accuracy: 0.985 - ETA: 36s - loss: 0.0458 - accuracy: 0.985 - ETA: 34s - loss: 0.0455 - accuracy: 0.985 - ETA: 31s - loss: 0.0453 - accuracy: 0.985 - ETA: 28s - loss: 0.0452 - accuracy: 0.985 - ETA: 26s - loss: 0.0449 - accuracy: 0.985 - ETA: 23s - loss: 0.0447 - accuracy: 0.985 - ETA: 20s - loss: 0.0449 - accuracy: 0.985 - ETA: 18s - loss: 0.0449 - accuracy: 0.985 - ETA: 15s - loss: 0.0447 - accuracy: 0.985 - ETA: 12s - loss: 0.0454 - accuracy: 0.985 - ETA: 10s - loss: 0.0454 - accuracy: 0.985 - ETA: 7s - loss: 0.0459 - accuracy: 0.985 - ETA: 4s - loss: 0.0457 - accuracy: 0.98 - ETA: 2s - loss: 0.0455 - accuracy: 0.98 - 441s 23ms/step - loss: 0.0457 - accuracy: 0.9853 - val_loss: 2.0362 - val_accuracy: 0.8041\n",
      "Epoch 80/100\n",
      "19312/19312 [==============================] - ETA: 6:05 - loss: 0.0101 - accuracy: 0.99 - ETA: 5:29 - loss: 0.0237 - accuracy: 0.99 - ETA: 5:25 - loss: 0.0756 - accuracy: 0.98 - ETA: 5:28 - loss: 0.0843 - accuracy: 0.98 - ETA: 5:14 - loss: 0.0820 - accuracy: 0.97 - ETA: 5:08 - loss: 0.0893 - accuracy: 0.97 - ETA: 4:59 - loss: 0.0814 - accuracy: 0.97 - ETA: 4:55 - loss: 0.0737 - accuracy: 0.97 - ETA: 4:53 - loss: 0.0696 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0660 - accuracy: 0.98 - ETA: 4:46 - loss: 0.0666 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0636 - accuracy: 0.98 - ETA: 4:56 - loss: 0.0630 - accuracy: 0.98 - ETA: 4:59 - loss: 0.0611 - accuracy: 0.98 - ETA: 4:57 - loss: 0.0601 - accuracy: 0.98 - ETA: 4:54 - loss: 0.0565 - accuracy: 0.98 - ETA: 4:50 - loss: 0.0563 - accuracy: 0.98 - ETA: 4:45 - loss: 0.0547 - accuracy: 0.98 - ETA: 4:41 - loss: 0.0524 - accuracy: 0.98 - ETA: 4:38 - loss: 0.0520 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0562 - accuracy: 0.98 - ETA: 4:35 - loss: 0.0566 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0548 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0546 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0535 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0521 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0507 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0493 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0512 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0519 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0510 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0508 - accuracy: 0.98 - ETA: 4:30 - loss: 0.0514 - accuracy: 0.98 - ETA: 4:29 - loss: 0.0527 - accuracy: 0.98 - ETA: 4:28 - loss: 0.0539 - accuracy: 0.98 - ETA: 4:25 - loss: 0.0526 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0556 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0564 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0569 - accuracy: 0.98 - ETA: 4:15 - loss: 0.0561 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0568 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0563 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0558 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0572 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0581 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0570 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0566 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0555 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0558 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0556 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0552 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0555 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0547 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0545 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0538 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0539 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0532 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0526 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0534 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0540 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0540 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0539 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0531 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0537 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0532 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0527 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0523 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0525 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0525 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0524 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0528 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0527 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0524 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0529 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0527 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0527 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0517 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0515 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0519 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0523 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0519 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0520 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0519 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0513 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0505 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0499 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0504 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0501 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0533 - accuracy: 0.98 - ETA: 59s - loss: 0.0530 - accuracy: 0.9844 - ETA: 56s - loss: 0.0528 - accuracy: 0.984 - ETA: 54s - loss: 0.0526 - accuracy: 0.984 - ETA: 51s - loss: 0.0523 - accuracy: 0.984 - ETA: 49s - loss: 0.0524 - accuracy: 0.984 - ETA: 46s - loss: 0.0523 - accuracy: 0.984 - ETA: 44s - loss: 0.0521 - accuracy: 0.984 - ETA: 42s - loss: 0.0519 - accuracy: 0.984 - ETA: 39s - loss: 0.0520 - accuracy: 0.984 - ETA: 37s - loss: 0.0519 - accuracy: 0.984 - ETA: 34s - loss: 0.0516 - accuracy: 0.984 - ETA: 32s - loss: 0.0514 - accuracy: 0.984 - ETA: 30s - loss: 0.0511 - accuracy: 0.985 - ETA: 27s - loss: 0.0514 - accuracy: 0.985 - ETA: 25s - loss: 0.0514 - accuracy: 0.985 - ETA: 23s - loss: 0.0516 - accuracy: 0.985 - ETA: 20s - loss: 0.0515 - accuracy: 0.985 - ETA: 18s - loss: 0.0512 - accuracy: 0.985 - ETA: 15s - loss: 0.0511 - accuracy: 0.985 - ETA: 13s - loss: 0.0517 - accuracy: 0.985 - ETA: 11s - loss: 0.0521 - accuracy: 0.985 - ETA: 8s - loss: 0.0519 - accuracy: 0.985 - ETA: 6s - loss: 0.0520 - accuracy: 0.98 - ETA: 4s - loss: 0.0517 - accuracy: 0.98 - ETA: 2s - loss: 0.0516 - accuracy: 0.98 - 386s 20ms/step - loss: 0.0519 - accuracy: 0.9851 - val_loss: 1.9645 - val_accuracy: 0.8043\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:01 - loss: 0.0891 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0705 - accuracy: 0.98 - ETA: 4:40 - loss: 0.0497 - accuracy: 0.99 - ETA: 4:33 - loss: 0.0417 - accuracy: 0.99 - ETA: 4:30 - loss: 0.0515 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0506 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0436 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0477 - accuracy: 0.98 - ETA: 4:21 - loss: 0.0475 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0470 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0565 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0519 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0501 - accuracy: 0.98 - ETA: 4:09 - loss: 0.0556 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0559 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0531 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0486 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0457 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0494 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0483 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0482 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0469 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0454 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0440 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0435 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0439 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0430 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0423 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0463 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0477 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0477 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0476 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0488 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0491 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0438 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0432 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0427 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0468 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0448 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0442 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0458 - accuracy: 0.98 - ETA: 59s - loss: 0.0458 - accuracy: 0.9864 - ETA: 57s - loss: 0.0455 - accuracy: 0.986 - ETA: 56s - loss: 0.0454 - accuracy: 0.986 - ETA: 54s - loss: 0.0454 - accuracy: 0.986 - ETA: 52s - loss: 0.0454 - accuracy: 0.986 - ETA: 50s - loss: 0.0451 - accuracy: 0.986 - ETA: 49s - loss: 0.0448 - accuracy: 0.986 - ETA: 47s - loss: 0.0447 - accuracy: 0.986 - ETA: 45s - loss: 0.0444 - accuracy: 0.986 - ETA: 43s - loss: 0.0443 - accuracy: 0.986 - ETA: 42s - loss: 0.0441 - accuracy: 0.986 - ETA: 40s - loss: 0.0445 - accuracy: 0.986 - ETA: 38s - loss: 0.0446 - accuracy: 0.986 - ETA: 36s - loss: 0.0443 - accuracy: 0.986 - ETA: 35s - loss: 0.0440 - accuracy: 0.986 - ETA: 33s - loss: 0.0441 - accuracy: 0.986 - ETA: 31s - loss: 0.0441 - accuracy: 0.986 - ETA: 29s - loss: 0.0439 - accuracy: 0.986 - ETA: 28s - loss: 0.0439 - accuracy: 0.986 - ETA: 26s - loss: 0.0443 - accuracy: 0.986 - ETA: 24s - loss: 0.0446 - accuracy: 0.986 - ETA: 22s - loss: 0.0444 - accuracy: 0.986 - ETA: 20s - loss: 0.0441 - accuracy: 0.986 - ETA: 19s - loss: 0.0443 - accuracy: 0.986 - ETA: 17s - loss: 0.0442 - accuracy: 0.986 - ETA: 15s - loss: 0.0441 - accuracy: 0.986 - ETA: 13s - loss: 0.0438 - accuracy: 0.986 - ETA: 12s - loss: 0.0446 - accuracy: 0.986 - ETA: 10s - loss: 0.0443 - accuracy: 0.986 - ETA: 8s - loss: 0.0440 - accuracy: 0.986 - ETA: 6s - loss: 0.0442 - accuracy: 0.98 - ETA: 5s - loss: 0.0439 - accuracy: 0.98 - ETA: 3s - loss: 0.0439 - accuracy: 0.98 - ETA: 1s - loss: 0.0438 - accuracy: 0.98 - 299s 15ms/step - loss: 0.0437 - accuracy: 0.9870 - val_loss: 1.9240 - val_accuracy: 0.8089\n",
      "Epoch 82/100\n",
      "19312/19312 [==============================] - ETA: 4:24 - loss: 0.0399 - accuracy: 0.96 - ETA: 4:26 - loss: 0.0399 - accuracy: 0.97 - ETA: 4:23 - loss: 0.0535 - accuracy: 0.97 - ETA: 4:21 - loss: 0.0420 - accuracy: 0.97 - ETA: 4:15 - loss: 0.0405 - accuracy: 0.97 - ETA: 4:11 - loss: 0.0511 - accuracy: 0.97 - ETA: 4:08 - loss: 0.0499 - accuracy: 0.97 - ETA: 4:07 - loss: 0.0499 - accuracy: 0.97 - ETA: 4:06 - loss: 0.0466 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0426 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0487 - accuracy: 0.98 - ETA: 4:03 - loss: 0.0456 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0482 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0459 - accuracy: 0.98 - ETA: 4:01 - loss: 0.0469 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0499 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0540 - accuracy: 0.98 - ETA: 3:54 - loss: 0.0527 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0517 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0514 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0498 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0505 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0503 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0485 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0494 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0490 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0479 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0475 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0498 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0501 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0520 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0511 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0510 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0512 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0513 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0510 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0502 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0495 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0507 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0497 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0458 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0421 - accuracy: 0.98 - ETA: 59s - loss: 0.0425 - accuracy: 0.9861 - ETA: 57s - loss: 0.0424 - accuracy: 0.986 - ETA: 55s - loss: 0.0427 - accuracy: 0.986 - ETA: 54s - loss: 0.0424 - accuracy: 0.986 - ETA: 52s - loss: 0.0426 - accuracy: 0.986 - ETA: 50s - loss: 0.0437 - accuracy: 0.986 - ETA: 48s - loss: 0.0436 - accuracy: 0.986 - ETA: 47s - loss: 0.0436 - accuracy: 0.986 - ETA: 45s - loss: 0.0435 - accuracy: 0.986 - ETA: 43s - loss: 0.0434 - accuracy: 0.986 - ETA: 41s - loss: 0.0435 - accuracy: 0.986 - ETA: 40s - loss: 0.0434 - accuracy: 0.986 - ETA: 38s - loss: 0.0432 - accuracy: 0.986 - ETA: 36s - loss: 0.0434 - accuracy: 0.986 - ETA: 34s - loss: 0.0432 - accuracy: 0.986 - ETA: 33s - loss: 0.0436 - accuracy: 0.986 - ETA: 31s - loss: 0.0439 - accuracy: 0.986 - ETA: 29s - loss: 0.0438 - accuracy: 0.986 - ETA: 27s - loss: 0.0438 - accuracy: 0.986 - ETA: 26s - loss: 0.0437 - accuracy: 0.986 - ETA: 24s - loss: 0.0438 - accuracy: 0.986 - ETA: 22s - loss: 0.0436 - accuracy: 0.986 - ETA: 20s - loss: 0.0442 - accuracy: 0.986 - ETA: 19s - loss: 0.0440 - accuracy: 0.986 - ETA: 17s - loss: 0.0438 - accuracy: 0.986 - ETA: 15s - loss: 0.0436 - accuracy: 0.986 - ETA: 13s - loss: 0.0433 - accuracy: 0.986 - ETA: 12s - loss: 0.0431 - accuracy: 0.986 - ETA: 10s - loss: 0.0428 - accuracy: 0.986 - ETA: 8s - loss: 0.0429 - accuracy: 0.986 - ETA: 6s - loss: 0.0427 - accuracy: 0.98 - ETA: 5s - loss: 0.0425 - accuracy: 0.98 - ETA: 3s - loss: 0.0423 - accuracy: 0.98 - ETA: 1s - loss: 0.0421 - accuracy: 0.98 - 288s 15ms/step - loss: 0.0420 - accuracy: 0.9868 - val_loss: 2.0193 - val_accuracy: 0.8082\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:29 - loss: 0.0523 - accuracy: 0.98 - ETA: 4:23 - loss: 0.0374 - accuracy: 0.98 - ETA: 4:26 - loss: 0.0267 - accuracy: 0.98 - ETA: 4:24 - loss: 0.0339 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0362 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0359 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0353 - accuracy: 0.99 - ETA: 4:14 - loss: 0.0462 - accuracy: 0.98 - ETA: 4:12 - loss: 0.0435 - accuracy: 0.98 - ETA: 4:11 - loss: 0.0398 - accuracy: 0.98 - ETA: 4:08 - loss: 0.0363 - accuracy: 0.98 - ETA: 4:06 - loss: 0.0369 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0397 - accuracy: 0.98 - ETA: 4:00 - loss: 0.0386 - accuracy: 0.98 - ETA: 3:58 - loss: 0.0389 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0429 - accuracy: 0.98 - ETA: 3:55 - loss: 0.0425 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0414 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0416 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0412 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0395 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0425 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0417 - accuracy: 0.98 - ETA: 3:40 - loss: 0.0425 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0423 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0445 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0444 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0452 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0435 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0425 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0432 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0441 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0460 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0440 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0451 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0492 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0476 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0490 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0486 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0493 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0489 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0436 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0459 - accuracy: 0.98 - ETA: 58s - loss: 0.0459 - accuracy: 0.9866 - ETA: 57s - loss: 0.0456 - accuracy: 0.986 - ETA: 55s - loss: 0.0453 - accuracy: 0.986 - ETA: 54s - loss: 0.0450 - accuracy: 0.986 - ETA: 52s - loss: 0.0451 - accuracy: 0.986 - ETA: 51s - loss: 0.0451 - accuracy: 0.986 - ETA: 49s - loss: 0.0452 - accuracy: 0.986 - ETA: 48s - loss: 0.0450 - accuracy: 0.986 - ETA: 46s - loss: 0.0454 - accuracy: 0.986 - ETA: 45s - loss: 0.0452 - accuracy: 0.986 - ETA: 43s - loss: 0.0449 - accuracy: 0.986 - ETA: 42s - loss: 0.0453 - accuracy: 0.986 - ETA: 40s - loss: 0.0452 - accuracy: 0.986 - ETA: 39s - loss: 0.0451 - accuracy: 0.986 - ETA: 38s - loss: 0.0453 - accuracy: 0.986 - ETA: 36s - loss: 0.0452 - accuracy: 0.986 - ETA: 35s - loss: 0.0449 - accuracy: 0.986 - ETA: 33s - loss: 0.0456 - accuracy: 0.986 - ETA: 32s - loss: 0.0457 - accuracy: 0.986 - ETA: 30s - loss: 0.0462 - accuracy: 0.986 - ETA: 29s - loss: 0.0463 - accuracy: 0.986 - ETA: 27s - loss: 0.0463 - accuracy: 0.986 - ETA: 26s - loss: 0.0461 - accuracy: 0.986 - ETA: 24s - loss: 0.0460 - accuracy: 0.986 - ETA: 23s - loss: 0.0465 - accuracy: 0.986 - ETA: 21s - loss: 0.0462 - accuracy: 0.986 - ETA: 20s - loss: 0.0461 - accuracy: 0.986 - ETA: 18s - loss: 0.0460 - accuracy: 0.986 - ETA: 16s - loss: 0.0457 - accuracy: 0.986 - ETA: 15s - loss: 0.0457 - accuracy: 0.986 - ETA: 13s - loss: 0.0454 - accuracy: 0.986 - ETA: 12s - loss: 0.0456 - accuracy: 0.986 - ETA: 10s - loss: 0.0460 - accuracy: 0.986 - ETA: 9s - loss: 0.0461 - accuracy: 0.986 - ETA: 7s - loss: 0.0472 - accuracy: 0.98 - ETA: 6s - loss: 0.0474 - accuracy: 0.98 - ETA: 4s - loss: 0.0484 - accuracy: 0.98 - ETA: 2s - loss: 0.0484 - accuracy: 0.98 - ETA: 1s - loss: 0.0481 - accuracy: 0.98 - 270s 14ms/step - loss: 0.0479 - accuracy: 0.9863 - val_loss: 2.0796 - val_accuracy: 0.8024\n",
      "Epoch 84/100\n",
      "19312/19312 [==============================] - ETA: 4:41 - loss: 0.0127 - accuracy: 0.99 - ETA: 4:38 - loss: 0.0241 - accuracy: 0.99 - ETA: 4:34 - loss: 0.0251 - accuracy: 0.99 - ETA: 4:32 - loss: 0.0311 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0283 - accuracy: 0.98 - ETA: 4:02 - loss: 0.0270 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0424 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0384 - accuracy: 0.98 - ETA: 3:18 - loss: 0.0405 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0416 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0400 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0403 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0422 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0420 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0414 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0400 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0425 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0423 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0436 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0437 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0433 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0422 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0438 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0435 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0436 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0448 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0448 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0448 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0418 - accuracy: 0.98 - ETA: 59s - loss: 0.0414 - accuracy: 0.9872 - ETA: 58s - loss: 0.0418 - accuracy: 0.987 - ETA: 57s - loss: 0.0422 - accuracy: 0.986 - ETA: 55s - loss: 0.0419 - accuracy: 0.987 - ETA: 54s - loss: 0.0417 - accuracy: 0.987 - ETA: 53s - loss: 0.0415 - accuracy: 0.987 - ETA: 51s - loss: 0.0411 - accuracy: 0.987 - ETA: 50s - loss: 0.0409 - accuracy: 0.987 - ETA: 49s - loss: 0.0414 - accuracy: 0.987 - ETA: 48s - loss: 0.0411 - accuracy: 0.987 - ETA: 46s - loss: 0.0413 - accuracy: 0.987 - ETA: 45s - loss: 0.0411 - accuracy: 0.987 - ETA: 44s - loss: 0.0411 - accuracy: 0.987 - ETA: 42s - loss: 0.0411 - accuracy: 0.987 - ETA: 41s - loss: 0.0409 - accuracy: 0.987 - ETA: 40s - loss: 0.0409 - accuracy: 0.987 - ETA: 38s - loss: 0.0407 - accuracy: 0.987 - ETA: 37s - loss: 0.0406 - accuracy: 0.987 - ETA: 36s - loss: 0.0406 - accuracy: 0.987 - ETA: 35s - loss: 0.0410 - accuracy: 0.987 - ETA: 33s - loss: 0.0411 - accuracy: 0.987 - ETA: 32s - loss: 0.0412 - accuracy: 0.987 - ETA: 31s - loss: 0.0410 - accuracy: 0.987 - ETA: 29s - loss: 0.0409 - accuracy: 0.987 - ETA: 28s - loss: 0.0407 - accuracy: 0.987 - ETA: 27s - loss: 0.0409 - accuracy: 0.987 - ETA: 25s - loss: 0.0412 - accuracy: 0.987 - ETA: 24s - loss: 0.0409 - accuracy: 0.987 - ETA: 23s - loss: 0.0409 - accuracy: 0.987 - ETA: 21s - loss: 0.0411 - accuracy: 0.987 - ETA: 20s - loss: 0.0408 - accuracy: 0.987 - ETA: 19s - loss: 0.0407 - accuracy: 0.987 - ETA: 17s - loss: 0.0406 - accuracy: 0.987 - ETA: 16s - loss: 0.0403 - accuracy: 0.987 - ETA: 14s - loss: 0.0402 - accuracy: 0.987 - ETA: 13s - loss: 0.0404 - accuracy: 0.987 - ETA: 12s - loss: 0.0401 - accuracy: 0.987 - ETA: 10s - loss: 0.0401 - accuracy: 0.987 - ETA: 9s - loss: 0.0401 - accuracy: 0.987 - ETA: 8s - loss: 0.0401 - accuracy: 0.98 - ETA: 6s - loss: 0.0399 - accuracy: 0.98 - ETA: 5s - loss: 0.0400 - accuracy: 0.98 - ETA: 3s - loss: 0.0405 - accuracy: 0.98 - ETA: 2s - loss: 0.0403 - accuracy: 0.98 - ETA: 1s - loss: 0.0401 - accuracy: 0.98 - 222s 11ms/step - loss: 0.0400 - accuracy: 0.9876 - val_loss: 2.0825 - val_accuracy: 0.8022\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:07 - loss: 0.0188 - accuracy: 0.99 - ETA: 3:41 - loss: 0.0824 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0575 - accuracy: 0.99 - ETA: 4:11 - loss: 0.0535 - accuracy: 0.99 - ETA: 4:13 - loss: 0.0461 - accuracy: 0.99 - ETA: 4:13 - loss: 0.0463 - accuracy: 0.99 - ETA: 4:13 - loss: 0.0484 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0445 - accuracy: 0.99 - ETA: 4:12 - loss: 0.0400 - accuracy: 0.99 - ETA: 4:02 - loss: 0.0389 - accuracy: 0.99 - ETA: 3:53 - loss: 0.0484 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0468 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0497 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0470 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0454 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0444 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0443 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0436 - accuracy: 0.98 - ETA: 3:31 - loss: 0.0441 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0471 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0448 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0450 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:15 - loss: 0.0432 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0430 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0435 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0470 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0466 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0438 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0433 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0446 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0437 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0421 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0419 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0433 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0443 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0436 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0476 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0497 - accuracy: 0.98 - ETA: 58s - loss: 0.0504 - accuracy: 0.9861 - ETA: 57s - loss: 0.0502 - accuracy: 0.986 - ETA: 55s - loss: 0.0499 - accuracy: 0.986 - ETA: 54s - loss: 0.0498 - accuracy: 0.986 - ETA: 52s - loss: 0.0500 - accuracy: 0.986 - ETA: 50s - loss: 0.0497 - accuracy: 0.986 - ETA: 49s - loss: 0.0495 - accuracy: 0.986 - ETA: 47s - loss: 0.0493 - accuracy: 0.986 - ETA: 46s - loss: 0.0494 - accuracy: 0.986 - ETA: 44s - loss: 0.0491 - accuracy: 0.986 - ETA: 42s - loss: 0.0494 - accuracy: 0.986 - ETA: 41s - loss: 0.0490 - accuracy: 0.986 - ETA: 39s - loss: 0.0493 - accuracy: 0.986 - ETA: 37s - loss: 0.0492 - accuracy: 0.986 - ETA: 36s - loss: 0.0491 - accuracy: 0.986 - ETA: 34s - loss: 0.0496 - accuracy: 0.986 - ETA: 32s - loss: 0.0499 - accuracy: 0.986 - ETA: 31s - loss: 0.0503 - accuracy: 0.986 - ETA: 29s - loss: 0.0500 - accuracy: 0.986 - ETA: 27s - loss: 0.0498 - accuracy: 0.986 - ETA: 26s - loss: 0.0520 - accuracy: 0.986 - ETA: 24s - loss: 0.0516 - accuracy: 0.986 - ETA: 22s - loss: 0.0521 - accuracy: 0.986 - ETA: 21s - loss: 0.0522 - accuracy: 0.986 - ETA: 19s - loss: 0.0521 - accuracy: 0.986 - ETA: 17s - loss: 0.0522 - accuracy: 0.986 - ETA: 16s - loss: 0.0518 - accuracy: 0.986 - ETA: 14s - loss: 0.0518 - accuracy: 0.986 - ETA: 13s - loss: 0.0520 - accuracy: 0.986 - ETA: 11s - loss: 0.0517 - accuracy: 0.986 - ETA: 9s - loss: 0.0515 - accuracy: 0.986 - ETA: 8s - loss: 0.0514 - accuracy: 0.98 - ETA: 6s - loss: 0.0512 - accuracy: 0.98 - ETA: 4s - loss: 0.0509 - accuracy: 0.98 - ETA: 3s - loss: 0.0508 - accuracy: 0.98 - ETA: 1s - loss: 0.0505 - accuracy: 0.98 - 275s 14ms/step - loss: 0.0503 - accuracy: 0.9865 - val_loss: 2.0883 - val_accuracy: 0.8041\n",
      "Epoch 86/100\n",
      "19312/19312 [==============================] - ETA: 4:15 - loss: 0.0327 - accuracy: 0.98 - ETA: 4:47 - loss: 0.0168 - accuracy: 0.99 - ETA: 4:41 - loss: 0.0194 - accuracy: 0.98 - ETA: 4:31 - loss: 0.0265 - accuracy: 0.98 - ETA: 4:27 - loss: 0.0276 - accuracy: 0.98 - ETA: 4:19 - loss: 0.0284 - accuracy: 0.98 - ETA: 4:13 - loss: 0.0278 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0251 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0247 - accuracy: 0.98 - ETA: 3:56 - loss: 0.0371 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0381 - accuracy: 0.98 - ETA: 3:48 - loss: 0.0391 - accuracy: 0.98 - ETA: 3:44 - loss: 0.0467 - accuracy: 0.98 - ETA: 3:41 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:38 - loss: 0.0444 - accuracy: 0.98 - ETA: 3:37 - loss: 0.0426 - accuracy: 0.98 - ETA: 3:35 - loss: 0.0452 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0461 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0449 - accuracy: 0.98 - ETA: 3:30 - loss: 0.0434 - accuracy: 0.98 - ETA: 3:29 - loss: 0.0421 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0415 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0412 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0410 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0418 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0405 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0404 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0401 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0399 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0393 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0410 - accuracy: 0.98 - ETA: 3:08 - loss: 0.0413 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0409 - accuracy: 0.98 - ETA: 3:05 - loss: 0.0411 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0401 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0390 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0412 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0414 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0418 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0425 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0432 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0457 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0478 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0468 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0468 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0483 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0487 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0487 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0494 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0475 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0475 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0476 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0476 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0475 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0483 - accuracy: 0.98 - ETA: 58s - loss: 0.0488 - accuracy: 0.9862 - ETA: 56s - loss: 0.0491 - accuracy: 0.986 - ETA: 54s - loss: 0.0489 - accuracy: 0.986 - ETA: 53s - loss: 0.0486 - accuracy: 0.986 - ETA: 51s - loss: 0.0483 - accuracy: 0.986 - ETA: 49s - loss: 0.0480 - accuracy: 0.986 - ETA: 47s - loss: 0.0478 - accuracy: 0.986 - ETA: 46s - loss: 0.0482 - accuracy: 0.986 - ETA: 44s - loss: 0.0484 - accuracy: 0.986 - ETA: 42s - loss: 0.0485 - accuracy: 0.986 - ETA: 40s - loss: 0.0483 - accuracy: 0.986 - ETA: 39s - loss: 0.0481 - accuracy: 0.986 - ETA: 37s - loss: 0.0491 - accuracy: 0.985 - ETA: 35s - loss: 0.0498 - accuracy: 0.985 - ETA: 33s - loss: 0.0496 - accuracy: 0.985 - ETA: 32s - loss: 0.0493 - accuracy: 0.985 - ETA: 30s - loss: 0.0498 - accuracy: 0.985 - ETA: 28s - loss: 0.0495 - accuracy: 0.985 - ETA: 26s - loss: 0.0492 - accuracy: 0.985 - ETA: 24s - loss: 0.0488 - accuracy: 0.986 - ETA: 23s - loss: 0.0486 - accuracy: 0.986 - ETA: 21s - loss: 0.0483 - accuracy: 0.986 - ETA: 19s - loss: 0.0482 - accuracy: 0.986 - ETA: 17s - loss: 0.0480 - accuracy: 0.986 - ETA: 15s - loss: 0.0479 - accuracy: 0.986 - ETA: 14s - loss: 0.0491 - accuracy: 0.986 - ETA: 12s - loss: 0.0488 - accuracy: 0.986 - ETA: 10s - loss: 0.0492 - accuracy: 0.986 - ETA: 8s - loss: 0.0495 - accuracy: 0.986 - ETA: 6s - loss: 0.0498 - accuracy: 0.98 - ETA: 5s - loss: 0.0499 - accuracy: 0.98 - ETA: 3s - loss: 0.0498 - accuracy: 0.98 - ETA: 1s - loss: 0.0498 - accuracy: 0.98 - 299s 15ms/step - loss: 0.0496 - accuracy: 0.9859 - val_loss: 2.1165 - val_accuracy: 0.8033\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:20 - loss: 0.0753 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0442 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0639 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0495 - accuracy: 0.99 - ETA: 3:17 - loss: 0.0409 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0460 - accuracy: 0.99 - ETA: 3:12 - loss: 0.0534 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0498 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0462 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0422 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0460 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0440 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0433 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0446 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0434 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:00 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0476 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:54 - loss: 0.0433 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0421 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0412 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0418 - accuracy: 0.98 - ETA: 2:49 - loss: 0.0411 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0418 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0413 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0408 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0406 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0399 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0394 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0398 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0389 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0383 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0391 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0387 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0386 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0388 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0382 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0373 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0370 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0365 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0374 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0370 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0382 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0374 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0385 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0379 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0381 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0385 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0387 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0393 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0393 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0394 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0387 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0394 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0406 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0391 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0394 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0394 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0393 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0393 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0393 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0400 - accuracy: 0.98 - ETA: 59s - loss: 0.0397 - accuracy: 0.9871 - ETA: 57s - loss: 0.0399 - accuracy: 0.987 - ETA: 56s - loss: 0.0400 - accuracy: 0.987 - ETA: 54s - loss: 0.0406 - accuracy: 0.986 - ETA: 53s - loss: 0.0403 - accuracy: 0.987 - ETA: 52s - loss: 0.0410 - accuracy: 0.986 - ETA: 50s - loss: 0.0415 - accuracy: 0.986 - ETA: 49s - loss: 0.0413 - accuracy: 0.986 - ETA: 48s - loss: 0.0414 - accuracy: 0.986 - ETA: 46s - loss: 0.0414 - accuracy: 0.986 - ETA: 44s - loss: 0.0412 - accuracy: 0.986 - ETA: 43s - loss: 0.0411 - accuracy: 0.986 - ETA: 41s - loss: 0.0411 - accuracy: 0.986 - ETA: 40s - loss: 0.0410 - accuracy: 0.986 - ETA: 38s - loss: 0.0409 - accuracy: 0.986 - ETA: 37s - loss: 0.0408 - accuracy: 0.986 - ETA: 35s - loss: 0.0405 - accuracy: 0.986 - ETA: 33s - loss: 0.0403 - accuracy: 0.986 - ETA: 32s - loss: 0.0400 - accuracy: 0.986 - ETA: 30s - loss: 0.0400 - accuracy: 0.986 - ETA: 28s - loss: 0.0402 - accuracy: 0.986 - ETA: 27s - loss: 0.0403 - accuracy: 0.986 - ETA: 25s - loss: 0.0403 - accuracy: 0.986 - ETA: 24s - loss: 0.0404 - accuracy: 0.986 - ETA: 22s - loss: 0.0403 - accuracy: 0.986 - ETA: 20s - loss: 0.0403 - accuracy: 0.986 - ETA: 19s - loss: 0.0404 - accuracy: 0.986 - ETA: 17s - loss: 0.0404 - accuracy: 0.986 - ETA: 15s - loss: 0.0403 - accuracy: 0.986 - ETA: 14s - loss: 0.0403 - accuracy: 0.986 - ETA: 12s - loss: 0.0402 - accuracy: 0.986 - ETA: 11s - loss: 0.0402 - accuracy: 0.986 - ETA: 9s - loss: 0.0408 - accuracy: 0.986 - ETA: 8s - loss: 0.0408 - accuracy: 0.98 - ETA: 6s - loss: 0.0406 - accuracy: 0.98 - ETA: 5s - loss: 0.0404 - accuracy: 0.98 - ETA: 3s - loss: 0.0401 - accuracy: 0.98 - ETA: 1s - loss: 0.0399 - accuracy: 0.98 - 303s 16ms/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 2.0018 - val_accuracy: 0.8091\n",
      "Epoch 88/100\n",
      "19312/19312 [==============================] - ETA: 4:30 - loss: 0.0576 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0346 - accuracy: 0.98 - ETA: 4:04 - loss: 0.0235 - accuracy: 0.99 - ETA: 4:10 - loss: 0.0189 - accuracy: 0.99 - ETA: 4:09 - loss: 0.0195 - accuracy: 0.99 - ETA: 4:13 - loss: 0.0172 - accuracy: 0.99 - ETA: 4:14 - loss: 0.0210 - accuracy: 0.99 - ETA: 4:14 - loss: 0.0204 - accuracy: 0.99 - ETA: 4:10 - loss: 0.0195 - accuracy: 0.99 - ETA: 4:07 - loss: 0.0185 - accuracy: 0.99 - ETA: 4:08 - loss: 0.0185 - accuracy: 0.99 - ETA: 4:03 - loss: 0.0207 - accuracy: 0.99 - ETA: 3:56 - loss: 0.0195 - accuracy: 0.99 - ETA: 3:51 - loss: 0.0182 - accuracy: 0.99 - ETA: 3:47 - loss: 0.0180 - accuracy: 0.99 - ETA: 3:44 - loss: 0.0171 - accuracy: 0.99 - ETA: 3:42 - loss: 0.0194 - accuracy: 0.99 - ETA: 3:40 - loss: 0.0201 - accuracy: 0.99 - ETA: 3:38 - loss: 0.0217 - accuracy: 0.99 - ETA: 3:35 - loss: 0.0223 - accuracy: 0.99 - ETA: 3:32 - loss: 0.0218 - accuracy: 0.99 - ETA: 3:29 - loss: 0.0248 - accuracy: 0.99 - ETA: 3:26 - loss: 0.0247 - accuracy: 0.99 - ETA: 3:24 - loss: 0.0260 - accuracy: 0.99 - ETA: 3:21 - loss: 0.0267 - accuracy: 0.99 - ETA: 3:19 - loss: 0.0260 - accuracy: 0.99 - ETA: 3:16 - loss: 0.0278 - accuracy: 0.99 - ETA: 3:13 - loss: 0.0282 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0276 - accuracy: 0.99 - ETA: 3:09 - loss: 0.0279 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0272 - accuracy: 0.99 - ETA: 3:05 - loss: 0.0277 - accuracy: 0.99 - ETA: 3:02 - loss: 0.0268 - accuracy: 0.99 - ETA: 2:59 - loss: 0.0265 - accuracy: 0.99 - ETA: 2:56 - loss: 0.0258 - accuracy: 0.99 - ETA: 2:54 - loss: 0.0253 - accuracy: 0.99 - ETA: 2:52 - loss: 0.0247 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0250 - accuracy: 0.99 - ETA: 2:48 - loss: 0.0247 - accuracy: 0.99 - ETA: 2:46 - loss: 0.0251 - accuracy: 0.99 - ETA: 2:44 - loss: 0.0245 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0251 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0261 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0265 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0259 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0259 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0254 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0257 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0260 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0256 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0251 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0248 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0244 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0256 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0256 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0271 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0274 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0272 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0282 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0278 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0284 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0309 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0306 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0335 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0333 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0342 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0343 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0343 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0350 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0345 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0344 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0351 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0347 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0345 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0342 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0342 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0340 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0345 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0343 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0345 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0343 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0342 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0338 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0335 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0338 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0338 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0340 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0339 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0336 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0347 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0347 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0351 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0350 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0348 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0348 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0346 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0371 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0374 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0372 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0371 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0382 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0382 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0383 - accuracy: 0.98 - ETA: 59s - loss: 0.0382 - accuracy: 0.9891 - ETA: 58s - loss: 0.0385 - accuracy: 0.989 - ETA: 56s - loss: 0.0386 - accuracy: 0.989 - ETA: 55s - loss: 0.0393 - accuracy: 0.988 - ETA: 53s - loss: 0.0390 - accuracy: 0.989 - ETA: 52s - loss: 0.0389 - accuracy: 0.989 - ETA: 50s - loss: 0.0389 - accuracy: 0.988 - ETA: 49s - loss: 0.0388 - accuracy: 0.988 - ETA: 47s - loss: 0.0392 - accuracy: 0.988 - ETA: 46s - loss: 0.0391 - accuracy: 0.988 - ETA: 44s - loss: 0.0389 - accuracy: 0.988 - ETA: 43s - loss: 0.0386 - accuracy: 0.988 - ETA: 41s - loss: 0.0383 - accuracy: 0.988 - ETA: 40s - loss: 0.0382 - accuracy: 0.988 - ETA: 38s - loss: 0.0379 - accuracy: 0.988 - ETA: 37s - loss: 0.0381 - accuracy: 0.988 - ETA: 35s - loss: 0.0378 - accuracy: 0.988 - ETA: 34s - loss: 0.0385 - accuracy: 0.988 - ETA: 32s - loss: 0.0382 - accuracy: 0.988 - ETA: 31s - loss: 0.0380 - accuracy: 0.988 - ETA: 29s - loss: 0.0379 - accuracy: 0.988 - ETA: 28s - loss: 0.0378 - accuracy: 0.988 - ETA: 26s - loss: 0.0378 - accuracy: 0.988 - ETA: 25s - loss: 0.0377 - accuracy: 0.988 - ETA: 24s - loss: 0.0375 - accuracy: 0.988 - ETA: 22s - loss: 0.0375 - accuracy: 0.988 - ETA: 21s - loss: 0.0378 - accuracy: 0.988 - ETA: 19s - loss: 0.0381 - accuracy: 0.988 - ETA: 18s - loss: 0.0379 - accuracy: 0.988 - ETA: 16s - loss: 0.0376 - accuracy: 0.988 - ETA: 15s - loss: 0.0377 - accuracy: 0.988 - ETA: 14s - loss: 0.0375 - accuracy: 0.989 - ETA: 12s - loss: 0.0374 - accuracy: 0.988 - ETA: 11s - loss: 0.0376 - accuracy: 0.988 - ETA: 9s - loss: 0.0376 - accuracy: 0.988 - ETA: 8s - loss: 0.0375 - accuracy: 0.98 - ETA: 6s - loss: 0.0373 - accuracy: 0.98 - ETA: 5s - loss: 0.0372 - accuracy: 0.98 - ETA: 4s - loss: 0.0377 - accuracy: 0.98 - ETA: 2s - loss: 0.0375 - accuracy: 0.98 - ETA: 1s - loss: 0.0372 - accuracy: 0.98 - 245s 13ms/step - loss: 0.0371 - accuracy: 0.9890 - val_loss: 2.0278 - val_accuracy: 0.8037\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:50 - loss: 0.0427 - accuracy: 0.98 - ETA: 4:22 - loss: 0.0295 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0244 - accuracy: 0.98 - ETA: 4:18 - loss: 0.0331 - accuracy: 0.98 - ETA: 4:20 - loss: 0.0290 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0256 - accuracy: 0.98 - ETA: 4:14 - loss: 0.0424 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0504 - accuracy: 0.98 - ETA: 3:59 - loss: 0.0458 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0418 - accuracy: 0.98 - ETA: 3:42 - loss: 0.0409 - accuracy: 0.99 - ETA: 3:34 - loss: 0.0421 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0400 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0379 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0361 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0355 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0354 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0375 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0397 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0402 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0404 - accuracy: 0.98 - ETA: 3:11 - loss: 0.0395 - accuracy: 0.98 - ETA: 3:07 - loss: 0.0401 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0405 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0437 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0434 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0426 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0421 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0407 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0407 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0400 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0387 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0389 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0396 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0390 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0389 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0393 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0388 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0383 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0389 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0375 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0374 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0381 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0381 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0388 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0383 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0379 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0375 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0378 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0380 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0377 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0388 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0393 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0383 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0381 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0370 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0371 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0370 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0374 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0383 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0387 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0386 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0391 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0394 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0391 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0397 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0388 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0386 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0386 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0387 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0383 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0385 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0382 - accuracy: 0.98 - ETA: 58s - loss: 0.0380 - accuracy: 0.9879 - ETA: 57s - loss: 0.0381 - accuracy: 0.987 - ETA: 55s - loss: 0.0380 - accuracy: 0.987 - ETA: 54s - loss: 0.0379 - accuracy: 0.987 - ETA: 52s - loss: 0.0376 - accuracy: 0.988 - ETA: 51s - loss: 0.0377 - accuracy: 0.987 - ETA: 49s - loss: 0.0374 - accuracy: 0.988 - ETA: 48s - loss: 0.0378 - accuracy: 0.988 - ETA: 46s - loss: 0.0375 - accuracy: 0.988 - ETA: 45s - loss: 0.0378 - accuracy: 0.988 - ETA: 43s - loss: 0.0379 - accuracy: 0.988 - ETA: 41s - loss: 0.0379 - accuracy: 0.988 - ETA: 40s - loss: 0.0379 - accuracy: 0.988 - ETA: 38s - loss: 0.0378 - accuracy: 0.988 - ETA: 37s - loss: 0.0377 - accuracy: 0.988 - ETA: 35s - loss: 0.0374 - accuracy: 0.988 - ETA: 34s - loss: 0.0374 - accuracy: 0.988 - ETA: 32s - loss: 0.0374 - accuracy: 0.988 - ETA: 31s - loss: 0.0376 - accuracy: 0.988 - ETA: 29s - loss: 0.0373 - accuracy: 0.988 - ETA: 27s - loss: 0.0376 - accuracy: 0.988 - ETA: 26s - loss: 0.0373 - accuracy: 0.988 - ETA: 24s - loss: 0.0374 - accuracy: 0.988 - ETA: 22s - loss: 0.0371 - accuracy: 0.988 - ETA: 21s - loss: 0.0371 - accuracy: 0.988 - ETA: 19s - loss: 0.0371 - accuracy: 0.988 - ETA: 17s - loss: 0.0370 - accuracy: 0.988 - ETA: 16s - loss: 0.0371 - accuracy: 0.988 - ETA: 14s - loss: 0.0368 - accuracy: 0.988 - ETA: 12s - loss: 0.0370 - accuracy: 0.988 - ETA: 11s - loss: 0.0368 - accuracy: 0.988 - ETA: 9s - loss: 0.0369 - accuracy: 0.988 - ETA: 7s - loss: 0.0367 - accuracy: 0.98 - ETA: 6s - loss: 0.0365 - accuracy: 0.98 - ETA: 4s - loss: 0.0364 - accuracy: 0.98 - ETA: 3s - loss: 0.0366 - accuracy: 0.98 - ETA: 1s - loss: 0.0368 - accuracy: 0.98 - 276s 14ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 2.0872 - val_accuracy: 0.8070\n",
      "Epoch 90/100\n",
      "19312/19312 [==============================] - ETA: 4:49 - loss: 0.0571 - accuracy: 0.98 - ETA: 4:34 - loss: 0.0524 - accuracy: 0.98 - ETA: 4:32 - loss: 0.0418 - accuracy: 0.98 - ETA: 4:16 - loss: 0.0420 - accuracy: 0.98 - ETA: 4:07 - loss: 0.0375 - accuracy: 0.98 - ETA: 3:57 - loss: 0.0474 - accuracy: 0.98 - ETA: 3:53 - loss: 0.0425 - accuracy: 0.98 - ETA: 3:45 - loss: 0.0507 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0492 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0464 - accuracy: 0.98 - ETA: 3:33 - loss: 0.0487 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0465 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0436 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0456 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0452 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0459 - accuracy: 0.98 - ETA: 3:27 - loss: 0.0441 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0447 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0428 - accuracy: 0.98 - ETA: 3:26 - loss: 0.0427 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0438 - accuracy: 0.98 - ETA: 3:25 - loss: 0.0421 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0413 - accuracy: 0.98 - ETA: 3:23 - loss: 0.0406 - accuracy: 0.98 - ETA: 3:21 - loss: 0.0390 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0437 - accuracy: 0.98 - ETA: 3:17 - loss: 0.0428 - accuracy: 0.98 - ETA: 3:14 - loss: 0.0430 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0415 - accuracy: 0.98 - ETA: 3:12 - loss: 0.0405 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0393 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0387 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0376 - accuracy: 0.98 - ETA: 3:04 - loss: 0.0373 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0366 - accuracy: 0.98 - ETA: 3:03 - loss: 0.0364 - accuracy: 0.98 - ETA: 3:01 - loss: 0.0364 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0355 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0350 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0349 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0354 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0349 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0341 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0336 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0329 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0325 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0337 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0332 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0339 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0339 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0333 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0345 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0353 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0352 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0350 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0354 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0350 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0372 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0385 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0385 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0383 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0375 - accuracy: 0.98 - ETA: 3:51 - loss: 0.0372 - accuracy: 0.98 - ETA: 3:52 - loss: 0.0368 - accuracy: 0.98 - ETA: 3:49 - loss: 0.0369 - accuracy: 0.98 - ETA: 3:46 - loss: 0.0366 - accuracy: 0.98 - ETA: 3:43 - loss: 0.0385 - accuracy: 0.98 - ETA: 3:39 - loss: 0.0388 - accuracy: 0.98 - ETA: 3:36 - loss: 0.0389 - accuracy: 0.98 - ETA: 3:32 - loss: 0.0384 - accuracy: 0.98 - ETA: 3:28 - loss: 0.0383 - accuracy: 0.98 - ETA: 3:24 - loss: 0.0384 - accuracy: 0.98 - ETA: 3:20 - loss: 0.0381 - accuracy: 0.98 - ETA: 3:16 - loss: 0.0377 - accuracy: 0.98 - ETA: 3:13 - loss: 0.0380 - accuracy: 0.98 - ETA: 3:09 - loss: 0.0377 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0386 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0382 - accuracy: 0.98 - ETA: 2:59 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:52 - loss: 0.0382 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0383 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0383 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0399 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0398 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0396 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0394 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0391 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0392 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0389 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0393 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0400 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0402 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0416 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0414 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0417 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0411 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0411 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0408 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0418 - accuracy: 0.98 - ETA: 57s - loss: 0.0418 - accuracy: 0.9885 - ETA: 53s - loss: 0.0416 - accuracy: 0.988 - ETA: 50s - loss: 0.0413 - accuracy: 0.988 - ETA: 47s - loss: 0.0413 - accuracy: 0.988 - ETA: 44s - loss: 0.0415 - accuracy: 0.988 - ETA: 41s - loss: 0.0412 - accuracy: 0.988 - ETA: 38s - loss: 0.0414 - accuracy: 0.988 - ETA: 35s - loss: 0.0414 - accuracy: 0.988 - ETA: 32s - loss: 0.0415 - accuracy: 0.988 - ETA: 30s - loss: 0.0412 - accuracy: 0.988 - ETA: 27s - loss: 0.0410 - accuracy: 0.988 - ETA: 24s - loss: 0.0415 - accuracy: 0.988 - ETA: 21s - loss: 0.0416 - accuracy: 0.988 - ETA: 18s - loss: 0.0413 - accuracy: 0.988 - ETA: 15s - loss: 0.0418 - accuracy: 0.988 - ETA: 13s - loss: 0.0423 - accuracy: 0.988 - ETA: 10s - loss: 0.0422 - accuracy: 0.988 - ETA: 7s - loss: 0.0422 - accuracy: 0.988 - ETA: 5s - loss: 0.0420 - accuracy: 0.98 - ETA: 2s - loss: 0.0421 - accuracy: 0.98 - 418s 22ms/step - loss: 0.0418 - accuracy: 0.9885 - val_loss: 2.0460 - val_accuracy: 0.8055\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:58 - loss: 0.0830 - accuracy: 0.97 - ETA: 2:57 - loss: 0.0526 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0562 - accuracy: 0.98 - ETA: 2:45 - loss: 0.0431 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0390 - accuracy: 0.99 - ETA: 2:36 - loss: 0.0371 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0339 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0329 - accuracy: 0.99 - ETA: 2:31 - loss: 0.0336 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0348 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0346 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0354 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0336 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0355 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0338 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0341 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0330 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0331 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0354 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0345 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0360 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0383 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0407 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0396 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0396 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0387 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0386 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0370 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0379 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0373 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0363 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0400 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0397 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0386 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0386 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0408 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0442 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0448 - accuracy: 0.98 - ETA: 59s - loss: 0.0446 - accuracy: 0.9867 - ETA: 58s - loss: 0.0448 - accuracy: 0.986 - ETA: 57s - loss: 0.0447 - accuracy: 0.986 - ETA: 56s - loss: 0.0443 - accuracy: 0.986 - ETA: 55s - loss: 0.0454 - accuracy: 0.986 - ETA: 54s - loss: 0.0451 - accuracy: 0.986 - ETA: 53s - loss: 0.0451 - accuracy: 0.986 - ETA: 52s - loss: 0.0448 - accuracy: 0.986 - ETA: 51s - loss: 0.0446 - accuracy: 0.986 - ETA: 50s - loss: 0.0444 - accuracy: 0.986 - ETA: 49s - loss: 0.0447 - accuracy: 0.986 - ETA: 48s - loss: 0.0443 - accuracy: 0.986 - ETA: 47s - loss: 0.0438 - accuracy: 0.987 - ETA: 46s - loss: 0.0440 - accuracy: 0.987 - ETA: 45s - loss: 0.0441 - accuracy: 0.987 - ETA: 44s - loss: 0.0453 - accuracy: 0.986 - ETA: 43s - loss: 0.0451 - accuracy: 0.986 - ETA: 42s - loss: 0.0447 - accuracy: 0.986 - ETA: 41s - loss: 0.0448 - accuracy: 0.986 - ETA: 40s - loss: 0.0444 - accuracy: 0.987 - ETA: 39s - loss: 0.0447 - accuracy: 0.987 - ETA: 38s - loss: 0.0445 - accuracy: 0.986 - ETA: 37s - loss: 0.0447 - accuracy: 0.986 - ETA: 36s - loss: 0.0444 - accuracy: 0.986 - ETA: 35s - loss: 0.0440 - accuracy: 0.987 - ETA: 34s - loss: 0.0438 - accuracy: 0.987 - ETA: 33s - loss: 0.0437 - accuracy: 0.987 - ETA: 32s - loss: 0.0439 - accuracy: 0.986 - ETA: 31s - loss: 0.0441 - accuracy: 0.986 - ETA: 30s - loss: 0.0440 - accuracy: 0.987 - ETA: 29s - loss: 0.0440 - accuracy: 0.986 - ETA: 28s - loss: 0.0440 - accuracy: 0.987 - ETA: 27s - loss: 0.0438 - accuracy: 0.987 - ETA: 26s - loss: 0.0436 - accuracy: 0.987 - ETA: 25s - loss: 0.0434 - accuracy: 0.987 - ETA: 24s - loss: 0.0435 - accuracy: 0.987 - ETA: 23s - loss: 0.0432 - accuracy: 0.987 - ETA: 22s - loss: 0.0433 - accuracy: 0.987 - ETA: 21s - loss: 0.0430 - accuracy: 0.987 - ETA: 20s - loss: 0.0430 - accuracy: 0.987 - ETA: 19s - loss: 0.0429 - accuracy: 0.987 - ETA: 18s - loss: 0.0434 - accuracy: 0.986 - ETA: 17s - loss: 0.0440 - accuracy: 0.986 - ETA: 16s - loss: 0.0440 - accuracy: 0.986 - ETA: 15s - loss: 0.0440 - accuracy: 0.986 - ETA: 14s - loss: 0.0437 - accuracy: 0.986 - ETA: 13s - loss: 0.0435 - accuracy: 0.986 - ETA: 12s - loss: 0.0432 - accuracy: 0.986 - ETA: 11s - loss: 0.0430 - accuracy: 0.986 - ETA: 10s - loss: 0.0427 - accuracy: 0.986 - ETA: 9s - loss: 0.0424 - accuracy: 0.987 - ETA: 8s - loss: 0.0425 - accuracy: 0.98 - ETA: 6s - loss: 0.0425 - accuracy: 0.98 - ETA: 5s - loss: 0.0434 - accuracy: 0.98 - ETA: 4s - loss: 0.0434 - accuracy: 0.98 - ETA: 3s - loss: 0.0432 - accuracy: 0.98 - ETA: 2s - loss: 0.0430 - accuracy: 0.98 - ETA: 1s - loss: 0.0429 - accuracy: 0.98 - ETA: 0s - loss: 0.0428 - accuracy: 0.98 - 169s 9ms/step - loss: 0.0431 - accuracy: 0.9872 - val_loss: 2.1288 - val_accuracy: 0.8027\n",
      "Epoch 92/100\n",
      "19312/19312 [==============================] - ETA: 2:34 - loss: 0.0417 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0897 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0693 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0580 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0586 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0525 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0436 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0393 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0438 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0488 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0489 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0496 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0435 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0462 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0462 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0494 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0484 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0475 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0448 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0442 - accuracy: 0.98 - ETA: 59s - loss: 0.0441 - accuracy: 0.9875 - ETA: 58s - loss: 0.0437 - accuracy: 0.987 - ETA: 57s - loss: 0.0435 - accuracy: 0.987 - ETA: 56s - loss: 0.0433 - accuracy: 0.987 - ETA: 54s - loss: 0.0433 - accuracy: 0.987 - ETA: 53s - loss: 0.0433 - accuracy: 0.987 - ETA: 52s - loss: 0.0431 - accuracy: 0.987 - ETA: 51s - loss: 0.0435 - accuracy: 0.987 - ETA: 50s - loss: 0.0435 - accuracy: 0.987 - ETA: 49s - loss: 0.0434 - accuracy: 0.987 - ETA: 48s - loss: 0.0437 - accuracy: 0.987 - ETA: 47s - loss: 0.0436 - accuracy: 0.987 - ETA: 46s - loss: 0.0436 - accuracy: 0.987 - ETA: 45s - loss: 0.0435 - accuracy: 0.987 - ETA: 44s - loss: 0.0432 - accuracy: 0.987 - ETA: 43s - loss: 0.0432 - accuracy: 0.987 - ETA: 42s - loss: 0.0433 - accuracy: 0.987 - ETA: 41s - loss: 0.0432 - accuracy: 0.987 - ETA: 40s - loss: 0.0431 - accuracy: 0.987 - ETA: 39s - loss: 0.0437 - accuracy: 0.987 - ETA: 38s - loss: 0.0440 - accuracy: 0.986 - ETA: 37s - loss: 0.0440 - accuracy: 0.986 - ETA: 36s - loss: 0.0439 - accuracy: 0.986 - ETA: 35s - loss: 0.0438 - accuracy: 0.986 - ETA: 34s - loss: 0.0443 - accuracy: 0.986 - ETA: 33s - loss: 0.0443 - accuracy: 0.986 - ETA: 31s - loss: 0.0443 - accuracy: 0.986 - ETA: 30s - loss: 0.0440 - accuracy: 0.986 - ETA: 29s - loss: 0.0443 - accuracy: 0.986 - ETA: 28s - loss: 0.0442 - accuracy: 0.986 - ETA: 27s - loss: 0.0442 - accuracy: 0.986 - ETA: 26s - loss: 0.0443 - accuracy: 0.986 - ETA: 25s - loss: 0.0444 - accuracy: 0.986 - ETA: 24s - loss: 0.0444 - accuracy: 0.986 - ETA: 23s - loss: 0.0442 - accuracy: 0.986 - ETA: 22s - loss: 0.0447 - accuracy: 0.986 - ETA: 21s - loss: 0.0447 - accuracy: 0.986 - ETA: 20s - loss: 0.0444 - accuracy: 0.986 - ETA: 19s - loss: 0.0441 - accuracy: 0.986 - ETA: 18s - loss: 0.0440 - accuracy: 0.986 - ETA: 17s - loss: 0.0437 - accuracy: 0.986 - ETA: 16s - loss: 0.0436 - accuracy: 0.986 - ETA: 15s - loss: 0.0435 - accuracy: 0.986 - ETA: 14s - loss: 0.0447 - accuracy: 0.986 - ETA: 13s - loss: 0.0446 - accuracy: 0.986 - ETA: 12s - loss: 0.0444 - accuracy: 0.986 - ETA: 11s - loss: 0.0444 - accuracy: 0.986 - ETA: 10s - loss: 0.0453 - accuracy: 0.986 - ETA: 9s - loss: 0.0458 - accuracy: 0.986 - ETA: 8s - loss: 0.0461 - accuracy: 0.98 - ETA: 7s - loss: 0.0461 - accuracy: 0.98 - ETA: 6s - loss: 0.0469 - accuracy: 0.98 - ETA: 5s - loss: 0.0470 - accuracy: 0.98 - ETA: 3s - loss: 0.0467 - accuracy: 0.98 - ETA: 2s - loss: 0.0464 - accuracy: 0.98 - ETA: 1s - loss: 0.0463 - accuracy: 0.98 - ETA: 0s - loss: 0.0460 - accuracy: 0.98 - 172s 9ms/step - loss: 0.0461 - accuracy: 0.9866 - val_loss: 2.0908 - val_accuracy: 0.8043\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:53 - loss: 0.0234 - accuracy: 0.99 - ETA: 2:45 - loss: 0.0179 - accuracy: 0.99 - ETA: 2:38 - loss: 0.0143 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0144 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0303 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0273 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0245 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0262 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0280 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0292 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0298 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0326 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0308 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0348 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0337 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0326 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0353 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0334 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0325 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0337 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0336 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0335 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0346 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0353 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0340 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0348 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0356 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0353 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0354 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0350 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0340 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0349 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0345 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0337 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0367 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0362 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0352 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0346 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0339 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0339 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0349 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0350 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0342 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0336 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0333 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0337 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0341 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0338 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0335 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0337 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0341 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0335 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0333 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0342 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0337 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0336 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0331 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0326 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0333 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0330 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0329 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0332 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0328 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0324 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0320 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0322 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0318 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0314 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0312 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0313 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0310 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0311 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0312 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0316 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0315 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0311 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0310 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0306 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0305 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0304 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0306 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0305 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0305 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0316 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0314 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0312 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0310 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0311 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0309 - accuracy: 0.98 - ETA: 59s - loss: 0.0307 - accuracy: 0.9899 - ETA: 58s - loss: 0.0311 - accuracy: 0.989 - ETA: 57s - loss: 0.0311 - accuracy: 0.989 - ETA: 56s - loss: 0.0330 - accuracy: 0.989 - ETA: 55s - loss: 0.0333 - accuracy: 0.989 - ETA: 54s - loss: 0.0330 - accuracy: 0.989 - ETA: 53s - loss: 0.0329 - accuracy: 0.989 - ETA: 52s - loss: 0.0328 - accuracy: 0.989 - ETA: 51s - loss: 0.0329 - accuracy: 0.989 - ETA: 49s - loss: 0.0328 - accuracy: 0.989 - ETA: 48s - loss: 0.0325 - accuracy: 0.989 - ETA: 47s - loss: 0.0324 - accuracy: 0.989 - ETA: 46s - loss: 0.0324 - accuracy: 0.989 - ETA: 45s - loss: 0.0326 - accuracy: 0.989 - ETA: 44s - loss: 0.0324 - accuracy: 0.989 - ETA: 43s - loss: 0.0323 - accuracy: 0.989 - ETA: 42s - loss: 0.0330 - accuracy: 0.989 - ETA: 41s - loss: 0.0333 - accuracy: 0.989 - ETA: 40s - loss: 0.0337 - accuracy: 0.989 - ETA: 39s - loss: 0.0334 - accuracy: 0.989 - ETA: 38s - loss: 0.0332 - accuracy: 0.989 - ETA: 37s - loss: 0.0338 - accuracy: 0.989 - ETA: 36s - loss: 0.0338 - accuracy: 0.989 - ETA: 35s - loss: 0.0335 - accuracy: 0.989 - ETA: 34s - loss: 0.0333 - accuracy: 0.989 - ETA: 33s - loss: 0.0337 - accuracy: 0.989 - ETA: 32s - loss: 0.0340 - accuracy: 0.989 - ETA: 31s - loss: 0.0340 - accuracy: 0.989 - ETA: 30s - loss: 0.0337 - accuracy: 0.989 - ETA: 29s - loss: 0.0340 - accuracy: 0.989 - ETA: 28s - loss: 0.0338 - accuracy: 0.989 - ETA: 27s - loss: 0.0346 - accuracy: 0.989 - ETA: 26s - loss: 0.0344 - accuracy: 0.989 - ETA: 25s - loss: 0.0343 - accuracy: 0.989 - ETA: 24s - loss: 0.0342 - accuracy: 0.989 - ETA: 23s - loss: 0.0347 - accuracy: 0.989 - ETA: 22s - loss: 0.0361 - accuracy: 0.989 - ETA: 21s - loss: 0.0362 - accuracy: 0.989 - ETA: 20s - loss: 0.0362 - accuracy: 0.989 - ETA: 19s - loss: 0.0365 - accuracy: 0.989 - ETA: 18s - loss: 0.0368 - accuracy: 0.989 - ETA: 17s - loss: 0.0371 - accuracy: 0.988 - ETA: 16s - loss: 0.0368 - accuracy: 0.988 - ETA: 15s - loss: 0.0373 - accuracy: 0.988 - ETA: 14s - loss: 0.0374 - accuracy: 0.988 - ETA: 13s - loss: 0.0374 - accuracy: 0.988 - ETA: 12s - loss: 0.0378 - accuracy: 0.988 - ETA: 11s - loss: 0.0378 - accuracy: 0.988 - ETA: 10s - loss: 0.0378 - accuracy: 0.988 - ETA: 9s - loss: 0.0378 - accuracy: 0.988 - ETA: 8s - loss: 0.0376 - accuracy: 0.98 - ETA: 7s - loss: 0.0379 - accuracy: 0.98 - ETA: 6s - loss: 0.0376 - accuracy: 0.98 - ETA: 4s - loss: 0.0376 - accuracy: 0.98 - ETA: 3s - loss: 0.0374 - accuracy: 0.98 - ETA: 2s - loss: 0.0374 - accuracy: 0.98 - ETA: 1s - loss: 0.0372 - accuracy: 0.98 - ETA: 0s - loss: 0.0371 - accuracy: 0.98 - 167s 9ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 2.1063 - val_accuracy: 0.8064\n",
      "Epoch 94/100\n",
      "19312/19312 [==============================] - ETA: 2:30 - loss: 0.0134 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0204 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0194 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0210 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0228 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0205 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0180 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0209 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0190 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0177 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0182 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0251 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0240 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0263 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0265 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0273 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0262 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0253 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0247 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0254 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0280 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0279 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0274 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0315 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0318 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0307 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0338 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0343 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0334 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0323 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0322 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0320 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0314 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0306 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0304 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0307 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0321 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0315 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0312 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0305 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0332 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0326 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0348 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0345 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0359 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0354 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0350 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0347 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0340 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0343 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0337 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0357 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0355 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0363 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0360 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0361 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0364 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0359 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0357 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0366 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0364 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0358 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0350 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0348 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0347 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0347 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0344 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0341 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0342 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0339 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0335 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0332 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0328 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0340 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0337 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0333 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0337 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0343 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0340 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0340 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0346 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0344 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0340 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0344 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0342 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0339 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0338 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0351 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0354 - accuracy: 0.99 - ETA: 59s - loss: 0.0353 - accuracy: 0.9899 - ETA: 58s - loss: 0.0352 - accuracy: 0.989 - ETA: 57s - loss: 0.0348 - accuracy: 0.990 - ETA: 56s - loss: 0.0345 - accuracy: 0.990 - ETA: 55s - loss: 0.0344 - accuracy: 0.990 - ETA: 54s - loss: 0.0342 - accuracy: 0.990 - ETA: 53s - loss: 0.0349 - accuracy: 0.990 - ETA: 52s - loss: 0.0345 - accuracy: 0.990 - ETA: 51s - loss: 0.0343 - accuracy: 0.990 - ETA: 50s - loss: 0.0342 - accuracy: 0.990 - ETA: 49s - loss: 0.0348 - accuracy: 0.990 - ETA: 48s - loss: 0.0351 - accuracy: 0.989 - ETA: 47s - loss: 0.0358 - accuracy: 0.989 - ETA: 46s - loss: 0.0368 - accuracy: 0.989 - ETA: 45s - loss: 0.0374 - accuracy: 0.989 - ETA: 44s - loss: 0.0373 - accuracy: 0.989 - ETA: 43s - loss: 0.0370 - accuracy: 0.989 - ETA: 42s - loss: 0.0369 - accuracy: 0.989 - ETA: 41s - loss: 0.0366 - accuracy: 0.989 - ETA: 40s - loss: 0.0365 - accuracy: 0.989 - ETA: 39s - loss: 0.0362 - accuracy: 0.989 - ETA: 38s - loss: 0.0362 - accuracy: 0.989 - ETA: 37s - loss: 0.0359 - accuracy: 0.989 - ETA: 36s - loss: 0.0362 - accuracy: 0.989 - ETA: 35s - loss: 0.0362 - accuracy: 0.989 - ETA: 34s - loss: 0.0359 - accuracy: 0.989 - ETA: 33s - loss: 0.0356 - accuracy: 0.989 - ETA: 32s - loss: 0.0353 - accuracy: 0.989 - ETA: 31s - loss: 0.0351 - accuracy: 0.989 - ETA: 30s - loss: 0.0349 - accuracy: 0.989 - ETA: 29s - loss: 0.0347 - accuracy: 0.990 - ETA: 28s - loss: 0.0347 - accuracy: 0.990 - ETA: 27s - loss: 0.0347 - accuracy: 0.989 - ETA: 26s - loss: 0.0351 - accuracy: 0.989 - ETA: 25s - loss: 0.0351 - accuracy: 0.989 - ETA: 24s - loss: 0.0353 - accuracy: 0.989 - ETA: 23s - loss: 0.0353 - accuracy: 0.989 - ETA: 22s - loss: 0.0353 - accuracy: 0.989 - ETA: 21s - loss: 0.0351 - accuracy: 0.989 - ETA: 20s - loss: 0.0350 - accuracy: 0.989 - ETA: 19s - loss: 0.0349 - accuracy: 0.989 - ETA: 18s - loss: 0.0357 - accuracy: 0.989 - ETA: 17s - loss: 0.0358 - accuracy: 0.989 - ETA: 16s - loss: 0.0359 - accuracy: 0.989 - ETA: 15s - loss: 0.0358 - accuracy: 0.989 - ETA: 14s - loss: 0.0361 - accuracy: 0.989 - ETA: 13s - loss: 0.0359 - accuracy: 0.989 - ETA: 12s - loss: 0.0362 - accuracy: 0.989 - ETA: 11s - loss: 0.0364 - accuracy: 0.989 - ETA: 10s - loss: 0.0364 - accuracy: 0.989 - ETA: 9s - loss: 0.0361 - accuracy: 0.989 - ETA: 8s - loss: 0.0360 - accuracy: 0.98 - ETA: 6s - loss: 0.0359 - accuracy: 0.98 - ETA: 5s - loss: 0.0358 - accuracy: 0.98 - ETA: 4s - loss: 0.0358 - accuracy: 0.98 - ETA: 3s - loss: 0.0358 - accuracy: 0.98 - ETA: 2s - loss: 0.0357 - accuracy: 0.98 - ETA: 1s - loss: 0.0355 - accuracy: 0.98 - ETA: 0s - loss: 0.0357 - accuracy: 0.98 - 165s 9ms/step - loss: 0.0356 - accuracy: 0.9896 - val_loss: 2.3163 - val_accuracy: 0.8033\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:39 - loss: 0.0437 - accuracy: 0.97 - ETA: 2:34 - loss: 0.0235 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0179 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0373 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0333 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0386 - accuracy: 0.99 - ETA: 2:26 - loss: 0.0352 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0356 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0477 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0432 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0477 - accuracy: 0.99 - ETA: 2:19 - loss: 0.0457 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0474 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0455 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0485 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0471 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0461 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0441 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0418 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0489 - accuracy: 0.99 - ETA: 2:11 - loss: 0.0497 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0469 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0489 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0495 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0481 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0481 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0456 - accuracy: 0.98 - ETA: 59s - loss: 0.0452 - accuracy: 0.9873 - ETA: 58s - loss: 0.0449 - accuracy: 0.987 - ETA: 57s - loss: 0.0449 - accuracy: 0.987 - ETA: 56s - loss: 0.0448 - accuracy: 0.987 - ETA: 55s - loss: 0.0448 - accuracy: 0.987 - ETA: 54s - loss: 0.0443 - accuracy: 0.987 - ETA: 53s - loss: 0.0439 - accuracy: 0.987 - ETA: 52s - loss: 0.0437 - accuracy: 0.987 - ETA: 51s - loss: 0.0434 - accuracy: 0.987 - ETA: 50s - loss: 0.0431 - accuracy: 0.987 - ETA: 49s - loss: 0.0427 - accuracy: 0.987 - ETA: 48s - loss: 0.0431 - accuracy: 0.987 - ETA: 47s - loss: 0.0428 - accuracy: 0.987 - ETA: 46s - loss: 0.0426 - accuracy: 0.987 - ETA: 45s - loss: 0.0424 - accuracy: 0.987 - ETA: 44s - loss: 0.0424 - accuracy: 0.987 - ETA: 43s - loss: 0.0422 - accuracy: 0.987 - ETA: 42s - loss: 0.0423 - accuracy: 0.987 - ETA: 41s - loss: 0.0425 - accuracy: 0.987 - ETA: 40s - loss: 0.0422 - accuracy: 0.987 - ETA: 39s - loss: 0.0419 - accuracy: 0.987 - ETA: 38s - loss: 0.0416 - accuracy: 0.987 - ETA: 37s - loss: 0.0422 - accuracy: 0.987 - ETA: 36s - loss: 0.0419 - accuracy: 0.987 - ETA: 35s - loss: 0.0419 - accuracy: 0.987 - ETA: 34s - loss: 0.0418 - accuracy: 0.987 - ETA: 33s - loss: 0.0418 - accuracy: 0.987 - ETA: 32s - loss: 0.0417 - accuracy: 0.987 - ETA: 31s - loss: 0.0416 - accuracy: 0.987 - ETA: 30s - loss: 0.0415 - accuracy: 0.987 - ETA: 29s - loss: 0.0419 - accuracy: 0.987 - ETA: 28s - loss: 0.0416 - accuracy: 0.987 - ETA: 27s - loss: 0.0412 - accuracy: 0.988 - ETA: 26s - loss: 0.0412 - accuracy: 0.988 - ETA: 25s - loss: 0.0410 - accuracy: 0.988 - ETA: 24s - loss: 0.0418 - accuracy: 0.987 - ETA: 23s - loss: 0.0416 - accuracy: 0.988 - ETA: 22s - loss: 0.0413 - accuracy: 0.988 - ETA: 21s - loss: 0.0421 - accuracy: 0.988 - ETA: 20s - loss: 0.0420 - accuracy: 0.988 - ETA: 19s - loss: 0.0422 - accuracy: 0.988 - ETA: 18s - loss: 0.0420 - accuracy: 0.988 - ETA: 17s - loss: 0.0424 - accuracy: 0.987 - ETA: 16s - loss: 0.0424 - accuracy: 0.988 - ETA: 15s - loss: 0.0421 - accuracy: 0.988 - ETA: 14s - loss: 0.0419 - accuracy: 0.988 - ETA: 13s - loss: 0.0422 - accuracy: 0.987 - ETA: 12s - loss: 0.0421 - accuracy: 0.987 - ETA: 11s - loss: 0.0419 - accuracy: 0.987 - ETA: 10s - loss: 0.0417 - accuracy: 0.988 - ETA: 9s - loss: 0.0416 - accuracy: 0.988 - ETA: 7s - loss: 0.0415 - accuracy: 0.98 - ETA: 6s - loss: 0.0414 - accuracy: 0.98 - ETA: 5s - loss: 0.0414 - accuracy: 0.98 - ETA: 4s - loss: 0.0413 - accuracy: 0.98 - ETA: 3s - loss: 0.0416 - accuracy: 0.98 - ETA: 2s - loss: 0.0414 - accuracy: 0.98 - ETA: 1s - loss: 0.0416 - accuracy: 0.98 - ETA: 0s - loss: 0.0415 - accuracy: 0.98 - 165s 9ms/step - loss: 0.0413 - accuracy: 0.9880 - val_loss: 2.1763 - val_accuracy: 0.7998\n",
      "Epoch 96/100\n",
      "19312/19312 [==============================] - ETA: 2:42 - loss: 0.0558 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0546 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0322 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0266 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0250 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0225 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0207 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0194 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0310 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0307 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0320 - accuracy: 0.99 - ETA: 2:21 - loss: 0.0324 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0319 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0299 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0295 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0297 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0289 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0279 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0290 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0283 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0270 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0295 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0299 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0290 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0346 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0334 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0328 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0328 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0338 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0331 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0337 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0333 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0330 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0328 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0341 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0347 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0341 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0349 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0368 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0367 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0372 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0364 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0364 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0358 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0381 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0375 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0377 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0370 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0374 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0381 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0383 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0418 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0400 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0394 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0414 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0436 - accuracy: 0.98 - ETA: 59s - loss: 0.0440 - accuracy: 0.9878 - ETA: 58s - loss: 0.0439 - accuracy: 0.987 - ETA: 57s - loss: 0.0446 - accuracy: 0.987 - ETA: 56s - loss: 0.0450 - accuracy: 0.987 - ETA: 55s - loss: 0.0447 - accuracy: 0.987 - ETA: 54s - loss: 0.0443 - accuracy: 0.987 - ETA: 53s - loss: 0.0441 - accuracy: 0.987 - ETA: 52s - loss: 0.0446 - accuracy: 0.987 - ETA: 50s - loss: 0.0444 - accuracy: 0.987 - ETA: 49s - loss: 0.0450 - accuracy: 0.987 - ETA: 48s - loss: 0.0456 - accuracy: 0.987 - ETA: 47s - loss: 0.0457 - accuracy: 0.987 - ETA: 46s - loss: 0.0459 - accuracy: 0.987 - ETA: 45s - loss: 0.0455 - accuracy: 0.987 - ETA: 44s - loss: 0.0452 - accuracy: 0.987 - ETA: 43s - loss: 0.0451 - accuracy: 0.987 - ETA: 42s - loss: 0.0455 - accuracy: 0.987 - ETA: 41s - loss: 0.0453 - accuracy: 0.987 - ETA: 40s - loss: 0.0450 - accuracy: 0.987 - ETA: 39s - loss: 0.0448 - accuracy: 0.987 - ETA: 38s - loss: 0.0449 - accuracy: 0.987 - ETA: 37s - loss: 0.0452 - accuracy: 0.987 - ETA: 36s - loss: 0.0451 - accuracy: 0.987 - ETA: 35s - loss: 0.0451 - accuracy: 0.987 - ETA: 34s - loss: 0.0448 - accuracy: 0.987 - ETA: 33s - loss: 0.0445 - accuracy: 0.987 - ETA: 32s - loss: 0.0445 - accuracy: 0.987 - ETA: 31s - loss: 0.0443 - accuracy: 0.987 - ETA: 30s - loss: 0.0441 - accuracy: 0.987 - ETA: 29s - loss: 0.0442 - accuracy: 0.987 - ETA: 28s - loss: 0.0446 - accuracy: 0.987 - ETA: 27s - loss: 0.0450 - accuracy: 0.987 - ETA: 26s - loss: 0.0447 - accuracy: 0.987 - ETA: 25s - loss: 0.0450 - accuracy: 0.987 - ETA: 24s - loss: 0.0449 - accuracy: 0.987 - ETA: 23s - loss: 0.0448 - accuracy: 0.987 - ETA: 22s - loss: 0.0450 - accuracy: 0.987 - ETA: 21s - loss: 0.0464 - accuracy: 0.987 - ETA: 20s - loss: 0.0463 - accuracy: 0.987 - ETA: 19s - loss: 0.0465 - accuracy: 0.987 - ETA: 18s - loss: 0.0472 - accuracy: 0.987 - ETA: 17s - loss: 0.0468 - accuracy: 0.987 - ETA: 16s - loss: 0.0465 - accuracy: 0.987 - ETA: 15s - loss: 0.0466 - accuracy: 0.987 - ETA: 14s - loss: 0.0463 - accuracy: 0.987 - ETA: 13s - loss: 0.0461 - accuracy: 0.987 - ETA: 12s - loss: 0.0461 - accuracy: 0.987 - ETA: 11s - loss: 0.0458 - accuracy: 0.987 - ETA: 10s - loss: 0.0466 - accuracy: 0.987 - ETA: 9s - loss: 0.0463 - accuracy: 0.987 - ETA: 8s - loss: 0.0461 - accuracy: 0.98 - ETA: 7s - loss: 0.0462 - accuracy: 0.98 - ETA: 6s - loss: 0.0472 - accuracy: 0.98 - ETA: 4s - loss: 0.0470 - accuracy: 0.98 - ETA: 3s - loss: 0.0473 - accuracy: 0.98 - ETA: 2s - loss: 0.0478 - accuracy: 0.98 - ETA: 1s - loss: 0.0482 - accuracy: 0.98 - ETA: 0s - loss: 0.0480 - accuracy: 0.98 - 166s 9ms/step - loss: 0.0479 - accuracy: 0.9873 - val_loss: 2.2074 - val_accuracy: 0.8091\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:35 - loss: 0.0294 - accuracy: 0.98 - ETA: 2:34 - loss: 0.0153 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0152 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0290 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0344 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:32 - loss: 0.0432 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0493 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0462 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0432 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0405 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0380 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0362 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0368 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0391 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0374 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0394 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0365 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0360 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0357 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0349 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0365 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0400 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0444 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0408 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0406 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0400 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0391 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0388 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0391 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0387 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0386 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0394 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0385 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0382 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0380 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0377 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0377 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0377 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0372 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0367 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0363 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0359 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0355 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0359 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0362 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0360 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0360 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0361 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0362 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0359 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0359 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0358 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0359 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0357 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0354 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0355 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0353 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0351 - accuracy: 0.98 - ETA: 59s - loss: 0.0350 - accuracy: 0.9883 - ETA: 58s - loss: 0.0354 - accuracy: 0.988 - ETA: 57s - loss: 0.0353 - accuracy: 0.988 - ETA: 56s - loss: 0.0352 - accuracy: 0.988 - ETA: 55s - loss: 0.0350 - accuracy: 0.988 - ETA: 54s - loss: 0.0361 - accuracy: 0.988 - ETA: 53s - loss: 0.0357 - accuracy: 0.988 - ETA: 52s - loss: 0.0355 - accuracy: 0.988 - ETA: 51s - loss: 0.0353 - accuracy: 0.988 - ETA: 50s - loss: 0.0351 - accuracy: 0.988 - ETA: 49s - loss: 0.0354 - accuracy: 0.988 - ETA: 48s - loss: 0.0354 - accuracy: 0.988 - ETA: 47s - loss: 0.0351 - accuracy: 0.988 - ETA: 46s - loss: 0.0348 - accuracy: 0.988 - ETA: 45s - loss: 0.0345 - accuracy: 0.988 - ETA: 44s - loss: 0.0348 - accuracy: 0.988 - ETA: 43s - loss: 0.0347 - accuracy: 0.988 - ETA: 42s - loss: 0.0345 - accuracy: 0.988 - ETA: 41s - loss: 0.0343 - accuracy: 0.988 - ETA: 40s - loss: 0.0348 - accuracy: 0.988 - ETA: 39s - loss: 0.0346 - accuracy: 0.988 - ETA: 38s - loss: 0.0347 - accuracy: 0.988 - ETA: 37s - loss: 0.0347 - accuracy: 0.988 - ETA: 36s - loss: 0.0346 - accuracy: 0.988 - ETA: 35s - loss: 0.0346 - accuracy: 0.988 - ETA: 34s - loss: 0.0346 - accuracy: 0.988 - ETA: 33s - loss: 0.0350 - accuracy: 0.988 - ETA: 32s - loss: 0.0350 - accuracy: 0.988 - ETA: 31s - loss: 0.0351 - accuracy: 0.988 - ETA: 29s - loss: 0.0350 - accuracy: 0.988 - ETA: 28s - loss: 0.0348 - accuracy: 0.988 - ETA: 27s - loss: 0.0347 - accuracy: 0.988 - ETA: 26s - loss: 0.0346 - accuracy: 0.988 - ETA: 26s - loss: 0.0355 - accuracy: 0.988 - ETA: 25s - loss: 0.0353 - accuracy: 0.988 - ETA: 24s - loss: 0.0354 - accuracy: 0.988 - ETA: 23s - loss: 0.0357 - accuracy: 0.988 - ETA: 22s - loss: 0.0356 - accuracy: 0.988 - ETA: 21s - loss: 0.0356 - accuracy: 0.988 - ETA: 20s - loss: 0.0357 - accuracy: 0.988 - ETA: 19s - loss: 0.0355 - accuracy: 0.988 - ETA: 18s - loss: 0.0360 - accuracy: 0.988 - ETA: 17s - loss: 0.0358 - accuracy: 0.988 - ETA: 16s - loss: 0.0357 - accuracy: 0.988 - ETA: 15s - loss: 0.0357 - accuracy: 0.988 - ETA: 14s - loss: 0.0358 - accuracy: 0.988 - ETA: 12s - loss: 0.0357 - accuracy: 0.988 - ETA: 11s - loss: 0.0356 - accuracy: 0.988 - ETA: 10s - loss: 0.0360 - accuracy: 0.988 - ETA: 9s - loss: 0.0363 - accuracy: 0.988 - ETA: 8s - loss: 0.0362 - accuracy: 0.98 - ETA: 7s - loss: 0.0367 - accuracy: 0.98 - ETA: 6s - loss: 0.0365 - accuracy: 0.98 - ETA: 5s - loss: 0.0363 - accuracy: 0.98 - ETA: 4s - loss: 0.0362 - accuracy: 0.98 - ETA: 3s - loss: 0.0366 - accuracy: 0.98 - ETA: 2s - loss: 0.0369 - accuracy: 0.98 - ETA: 0s - loss: 0.0367 - accuracy: 0.98 - 185s 10ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 2.1265 - val_accuracy: 0.8053\n",
      "Epoch 98/100\n",
      "19312/19312 [==============================] - ETA: 2:50 - loss: 0.0455 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0333 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0538 - accuracy: 0.97 - ETA: 2:38 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:36 - loss: 0.0434 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0366 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0326 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0329 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0319 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0293 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0372 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0345 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0329 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0345 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0356 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0356 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0348 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0374 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0375 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0406 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0389 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0401 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0410 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0406 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0391 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0398 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0367 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0368 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0362 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0375 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0380 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0406 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0381 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0376 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0394 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0394 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0391 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0380 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0383 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0383 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0378 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0378 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0377 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0375 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0370 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0360 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0355 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0362 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0357 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0362 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0369 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0364 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0382 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0377 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0381 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0383 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0382 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0377 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0372 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0370 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0366 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0364 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0369 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0361 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0360 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0357 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0354 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0352 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0352 - accuracy: 0.98 - ETA: 59s - loss: 0.0349 - accuracy: 0.9900 - ETA: 58s - loss: 0.0350 - accuracy: 0.990 - ETA: 57s - loss: 0.0350 - accuracy: 0.989 - ETA: 56s - loss: 0.0348 - accuracy: 0.989 - ETA: 55s - loss: 0.0352 - accuracy: 0.989 - ETA: 54s - loss: 0.0355 - accuracy: 0.989 - ETA: 53s - loss: 0.0354 - accuracy: 0.989 - ETA: 52s - loss: 0.0352 - accuracy: 0.989 - ETA: 51s - loss: 0.0350 - accuracy: 0.989 - ETA: 50s - loss: 0.0354 - accuracy: 0.989 - ETA: 49s - loss: 0.0352 - accuracy: 0.989 - ETA: 48s - loss: 0.0349 - accuracy: 0.989 - ETA: 47s - loss: 0.0349 - accuracy: 0.989 - ETA: 46s - loss: 0.0350 - accuracy: 0.989 - ETA: 45s - loss: 0.0352 - accuracy: 0.989 - ETA: 44s - loss: 0.0351 - accuracy: 0.989 - ETA: 43s - loss: 0.0348 - accuracy: 0.989 - ETA: 42s - loss: 0.0347 - accuracy: 0.989 - ETA: 41s - loss: 0.0351 - accuracy: 0.989 - ETA: 39s - loss: 0.0352 - accuracy: 0.989 - ETA: 38s - loss: 0.0350 - accuracy: 0.989 - ETA: 37s - loss: 0.0348 - accuracy: 0.989 - ETA: 36s - loss: 0.0346 - accuracy: 0.989 - ETA: 35s - loss: 0.0344 - accuracy: 0.989 - ETA: 34s - loss: 0.0347 - accuracy: 0.989 - ETA: 33s - loss: 0.0345 - accuracy: 0.989 - ETA: 32s - loss: 0.0348 - accuracy: 0.989 - ETA: 31s - loss: 0.0349 - accuracy: 0.989 - ETA: 30s - loss: 0.0350 - accuracy: 0.989 - ETA: 29s - loss: 0.0354 - accuracy: 0.989 - ETA: 28s - loss: 0.0353 - accuracy: 0.989 - ETA: 27s - loss: 0.0351 - accuracy: 0.989 - ETA: 26s - loss: 0.0354 - accuracy: 0.989 - ETA: 25s - loss: 0.0353 - accuracy: 0.989 - ETA: 24s - loss: 0.0357 - accuracy: 0.989 - ETA: 23s - loss: 0.0355 - accuracy: 0.989 - ETA: 22s - loss: 0.0353 - accuracy: 0.989 - ETA: 21s - loss: 0.0351 - accuracy: 0.989 - ETA: 20s - loss: 0.0360 - accuracy: 0.989 - ETA: 19s - loss: 0.0357 - accuracy: 0.989 - ETA: 18s - loss: 0.0355 - accuracy: 0.989 - ETA: 17s - loss: 0.0366 - accuracy: 0.989 - ETA: 16s - loss: 0.0369 - accuracy: 0.989 - ETA: 15s - loss: 0.0372 - accuracy: 0.989 - ETA: 14s - loss: 0.0375 - accuracy: 0.989 - ETA: 13s - loss: 0.0379 - accuracy: 0.989 - ETA: 12s - loss: 0.0378 - accuracy: 0.989 - ETA: 11s - loss: 0.0377 - accuracy: 0.989 - ETA: 10s - loss: 0.0378 - accuracy: 0.989 - ETA: 9s - loss: 0.0390 - accuracy: 0.989 - ETA: 8s - loss: 0.0388 - accuracy: 0.98 - ETA: 7s - loss: 0.0388 - accuracy: 0.98 - ETA: 6s - loss: 0.0385 - accuracy: 0.98 - ETA: 5s - loss: 0.0388 - accuracy: 0.98 - ETA: 4s - loss: 0.0388 - accuracy: 0.98 - ETA: 2s - loss: 0.0386 - accuracy: 0.98 - ETA: 1s - loss: 0.0388 - accuracy: 0.98 - ETA: 0s - loss: 0.0386 - accuracy: 0.98 - 171s 9ms/step - loss: 0.0384 - accuracy: 0.9893 - val_loss: 2.1395 - val_accuracy: 0.8105\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:26 - loss: 0.0126 - accuracy: 0.99 - ETA: 2:35 - loss: 0.0098 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0328 - accuracy: 0.99 - ETA: 2:34 - loss: 0.0327 - accuracy: 0.99 - ETA: 2:33 - loss: 0.0278 - accuracy: 0.99 - ETA: 2:32 - loss: 0.0321 - accuracy: 0.99 - ETA: 2:29 - loss: 0.0282 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0262 - accuracy: 0.99 - ETA: 2:25 - loss: 0.0240 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0325 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0366 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0363 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0373 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0437 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0412 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0390 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0415 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0473 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0462 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0448 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0481 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0475 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0442 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0447 - accuracy: 0.98 - ETA: 59s - loss: 0.0443 - accuracy: 0.9878 - ETA: 58s - loss: 0.0440 - accuracy: 0.987 - ETA: 57s - loss: 0.0436 - accuracy: 0.987 - ETA: 56s - loss: 0.0442 - accuracy: 0.987 - ETA: 55s - loss: 0.0443 - accuracy: 0.987 - ETA: 54s - loss: 0.0439 - accuracy: 0.987 - ETA: 53s - loss: 0.0444 - accuracy: 0.987 - ETA: 52s - loss: 0.0441 - accuracy: 0.987 - ETA: 51s - loss: 0.0440 - accuracy: 0.987 - ETA: 50s - loss: 0.0437 - accuracy: 0.987 - ETA: 49s - loss: 0.0433 - accuracy: 0.987 - ETA: 48s - loss: 0.0430 - accuracy: 0.987 - ETA: 47s - loss: 0.0426 - accuracy: 0.988 - ETA: 46s - loss: 0.0424 - accuracy: 0.988 - ETA: 45s - loss: 0.0421 - accuracy: 0.988 - ETA: 44s - loss: 0.0424 - accuracy: 0.988 - ETA: 43s - loss: 0.0422 - accuracy: 0.988 - ETA: 42s - loss: 0.0423 - accuracy: 0.988 - ETA: 41s - loss: 0.0421 - accuracy: 0.988 - ETA: 40s - loss: 0.0419 - accuracy: 0.988 - ETA: 39s - loss: 0.0418 - accuracy: 0.988 - ETA: 38s - loss: 0.0419 - accuracy: 0.988 - ETA: 37s - loss: 0.0420 - accuracy: 0.988 - ETA: 36s - loss: 0.0419 - accuracy: 0.988 - ETA: 35s - loss: 0.0422 - accuracy: 0.987 - ETA: 34s - loss: 0.0421 - accuracy: 0.988 - ETA: 33s - loss: 0.0420 - accuracy: 0.988 - ETA: 32s - loss: 0.0421 - accuracy: 0.987 - ETA: 31s - loss: 0.0423 - accuracy: 0.987 - ETA: 30s - loss: 0.0423 - accuracy: 0.987 - ETA: 29s - loss: 0.0419 - accuracy: 0.987 - ETA: 28s - loss: 0.0417 - accuracy: 0.987 - ETA: 27s - loss: 0.0414 - accuracy: 0.988 - ETA: 26s - loss: 0.0412 - accuracy: 0.988 - ETA: 25s - loss: 0.0414 - accuracy: 0.988 - ETA: 24s - loss: 0.0416 - accuracy: 0.987 - ETA: 23s - loss: 0.0420 - accuracy: 0.987 - ETA: 22s - loss: 0.0420 - accuracy: 0.987 - ETA: 21s - loss: 0.0424 - accuracy: 0.987 - ETA: 20s - loss: 0.0426 - accuracy: 0.987 - ETA: 19s - loss: 0.0424 - accuracy: 0.987 - ETA: 18s - loss: 0.0428 - accuracy: 0.987 - ETA: 17s - loss: 0.0427 - accuracy: 0.987 - ETA: 16s - loss: 0.0426 - accuracy: 0.987 - ETA: 15s - loss: 0.0423 - accuracy: 0.987 - ETA: 14s - loss: 0.0420 - accuracy: 0.987 - ETA: 13s - loss: 0.0421 - accuracy: 0.987 - ETA: 12s - loss: 0.0420 - accuracy: 0.987 - ETA: 11s - loss: 0.0426 - accuracy: 0.987 - ETA: 10s - loss: 0.0424 - accuracy: 0.987 - ETA: 9s - loss: 0.0421 - accuracy: 0.988 - ETA: 7s - loss: 0.0418 - accuracy: 0.98 - ETA: 6s - loss: 0.0425 - accuracy: 0.98 - ETA: 5s - loss: 0.0425 - accuracy: 0.98 - ETA: 4s - loss: 0.0422 - accuracy: 0.98 - ETA: 3s - loss: 0.0425 - accuracy: 0.98 - ETA: 2s - loss: 0.0423 - accuracy: 0.98 - ETA: 1s - loss: 0.0420 - accuracy: 0.98 - ETA: 0s - loss: 0.0418 - accuracy: 0.98 - 165s 9ms/step - loss: 0.0417 - accuracy: 0.9880 - val_loss: 2.1632 - val_accuracy: 0.8072\n",
      "Epoch 100/100\n",
      "19312/19312 [==============================] - ETA: 2:21 - loss: 0.0813 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0566 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0414 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0385 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0358 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0365 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0385 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0414 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0381 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0360 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0345 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0334 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0338 - accuracy: 0.99 - ETA: 3:20 - loss: 0.0345 - accuracy: 0.98 - ETA: 3:19 - loss: 0.0326 - accuracy: 0.99 - ETA: 3:17 - loss: 0.0314 - accuracy: 0.99 - ETA: 3:14 - loss: 0.0358 - accuracy: 0.98 - ETA: 3:10 - loss: 0.0369 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0355 - accuracy: 0.98 - ETA: 3:02 - loss: 0.0350 - accuracy: 0.98 - ETA: 2:58 - loss: 0.0362 - accuracy: 0.98 - ETA: 2:55 - loss: 0.0364 - accuracy: 0.98 - ETA: 2:51 - loss: 0.0357 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0360 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0350 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0350 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0339 - accuracy: 0.98 - ETA: 2:38 - loss: 0.0334 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0348 - accuracy: 0.98 - ETA: 2:33 - loss: 0.0343 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0367 - accuracy: 0.98 - ETA: 2:29 - loss: 0.0358 - accuracy: 0.98 - ETA: 2:27 - loss: 0.0349 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0342 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0348 - accuracy: 0.98 - ETA: 2:21 - loss: 0.0343 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0383 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0381 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0392 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0387 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0377 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0370 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0383 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0378 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0377 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0370 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0367 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0363 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0371 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0414 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0400 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0398 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0395 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0395 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0390 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0387 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0387 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0391 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0395 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0392 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0388 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0386 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0386 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0387 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0388 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0391 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0393 - accuracy: 0.98 - ETA: 59s - loss: 0.0389 - accuracy: 0.9896 - ETA: 58s - loss: 0.0395 - accuracy: 0.989 - ETA: 56s - loss: 0.0396 - accuracy: 0.989 - ETA: 55s - loss: 0.0393 - accuracy: 0.989 - ETA: 54s - loss: 0.0392 - accuracy: 0.989 - ETA: 53s - loss: 0.0393 - accuracy: 0.989 - ETA: 52s - loss: 0.0393 - accuracy: 0.989 - ETA: 51s - loss: 0.0391 - accuracy: 0.989 - ETA: 49s - loss: 0.0397 - accuracy: 0.989 - ETA: 48s - loss: 0.0396 - accuracy: 0.989 - ETA: 47s - loss: 0.0396 - accuracy: 0.989 - ETA: 46s - loss: 0.0397 - accuracy: 0.989 - ETA: 45s - loss: 0.0402 - accuracy: 0.989 - ETA: 44s - loss: 0.0400 - accuracy: 0.989 - ETA: 43s - loss: 0.0398 - accuracy: 0.989 - ETA: 41s - loss: 0.0400 - accuracy: 0.989 - ETA: 40s - loss: 0.0402 - accuracy: 0.989 - ETA: 39s - loss: 0.0400 - accuracy: 0.989 - ETA: 38s - loss: 0.0408 - accuracy: 0.989 - ETA: 37s - loss: 0.0408 - accuracy: 0.989 - ETA: 36s - loss: 0.0405 - accuracy: 0.989 - ETA: 35s - loss: 0.0407 - accuracy: 0.989 - ETA: 33s - loss: 0.0404 - accuracy: 0.989 - ETA: 32s - loss: 0.0411 - accuracy: 0.988 - ETA: 31s - loss: 0.0410 - accuracy: 0.988 - ETA: 30s - loss: 0.0411 - accuracy: 0.988 - ETA: 29s - loss: 0.0408 - accuracy: 0.988 - ETA: 28s - loss: 0.0406 - accuracy: 0.989 - ETA: 27s - loss: 0.0404 - accuracy: 0.989 - ETA: 26s - loss: 0.0403 - accuracy: 0.989 - ETA: 25s - loss: 0.0409 - accuracy: 0.988 - ETA: 23s - loss: 0.0407 - accuracy: 0.988 - ETA: 22s - loss: 0.0409 - accuracy: 0.988 - ETA: 21s - loss: 0.0408 - accuracy: 0.988 - ETA: 20s - loss: 0.0409 - accuracy: 0.988 - ETA: 19s - loss: 0.0410 - accuracy: 0.988 - ETA: 18s - loss: 0.0407 - accuracy: 0.988 - ETA: 17s - loss: 0.0410 - accuracy: 0.988 - ETA: 16s - loss: 0.0409 - accuracy: 0.988 - ETA: 15s - loss: 0.0406 - accuracy: 0.988 - ETA: 13s - loss: 0.0405 - accuracy: 0.988 - ETA: 12s - loss: 0.0402 - accuracy: 0.989 - ETA: 11s - loss: 0.0404 - accuracy: 0.989 - ETA: 10s - loss: 0.0403 - accuracy: 0.988 - ETA: 9s - loss: 0.0401 - accuracy: 0.989 - ETA: 8s - loss: 0.0398 - accuracy: 0.98 - ETA: 7s - loss: 0.0397 - accuracy: 0.98 - ETA: 6s - loss: 0.0396 - accuracy: 0.98 - ETA: 5s - loss: 0.0400 - accuracy: 0.98 - ETA: 4s - loss: 0.0399 - accuracy: 0.98 - ETA: 3s - loss: 0.0399 - accuracy: 0.98 - ETA: 2s - loss: 0.0397 - accuracy: 0.98 - ETA: 0s - loss: 0.0400 - accuracy: 0.98 - 177s 9ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 2.1611 - val_accuracy: 0.8074\n",
      "2020-12-08 15:33:06.469493\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "t5=datetime.datetime.now()\n",
    "print(t5)\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n",
    "t6=datetime.datetime.now()\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [1.9313042054242489, 1.5107594638365498, 1.3323813416889227, 1.1925139284252404, 1.1586254871047095, 1.1013782492926165, 1.0931236914631546, 1.0733269334431883, 1.1165517826681677, 1.0829584609896876, 1.1303176642525736, 1.137678468898849, 1.1349271485019998, 1.1793841455239, 1.2162076150390964, 1.1674222913087586, 1.2093698155018429, 1.1863212078149383, 1.2345162059091144, 1.2210838975657536, 1.2125853634591575, 1.287691205647402, 1.2642381200264097, 1.3700309588712154, 1.2668901045121472, 1.333614746244039, 1.3243376441588435, 1.3490307463279396, 1.3852447086694843, 1.4147055836463474, 1.4144634262304372, 1.4383062611556394, 1.3835599626362212, 1.4888283580844015, 1.5019204567174385, 1.4332907143081535, 1.4367359115065785, 1.4679338436339997, 1.5000372447195347, 1.5367076805003757, 1.5000014522352632, 1.4986292645659203, 1.5453489152608537, 1.6737641315327887, 1.5806119668357834, 1.609217529441042, 1.7783478418475822, 1.6762875048214172, 1.641731335821051, 1.6414003833082305, 1.6597208852574405, 1.6568260103013606, 1.6515055000473435, 1.6583696609205971, 1.7074270232613966, 1.6547320322803791, 1.6612912699607965, 1.7869731256200996, 1.7056561562555328, 1.7557704366988882, 1.7565554531002223, 1.8363538127331587, 1.778895203581901, 1.8264704368010296, 1.7591187674008335, 1.9331323327571863, 1.8341580568867752, 1.8236089122050987, 1.8073447482090703, 1.8262719097382338, 1.8741088326018305, 1.7998187165004567, 1.8431662044606116, 1.7990340157852678, 1.9480377491474843, 1.9251480095626947, 2.0247867095048298, 1.9282550294593295, 2.036180263129444, 1.9645319966011892, 1.9240003815840727, 2.01928960417931, 2.0795966254971145, 2.082476432241004, 2.08828392407, 2.1165302641324115, 2.001836670360893, 2.0278331084043053, 2.0871904704802327, 2.0460297878446676, 2.1288137533916998, 2.09084882588583, 2.1062527790304593, 2.3163042635027975, 2.176343843442704, 2.207449724398234, 2.126503342129622, 2.1395325882880676, 2.1631564076185277, 2.161136475747899], 'val_accuracy': [0.5483536720275879, 0.6415407061576843, 0.6844066977500916, 0.7090494632720947, 0.7278939485549927, 0.7392835021018982, 0.7537792325019836, 0.7597846388816833, 0.7686891555786133, 0.7682750225067139, 0.7742803692817688, 0.7738662362098694, 0.7767653465270996, 0.7798715829849243, 0.7782149314880371, 0.7848415970802307, 0.7846344709396362, 0.7873265743255615, 0.7891902923583984, 0.7893974184989929, 0.7904328107833862, 0.7877407073974609, 0.7916752696037292, 0.7902257442474365, 0.7966452836990356, 0.7918823957443237, 0.7972665429115295, 0.7927107214927673, 0.792917788028717, 0.7920894622802734, 0.794781506061554, 0.795816957950592, 0.7999585866928101, 0.7997515201568604, 0.7945744395256042, 0.7999585866928101, 0.7995443940162659, 0.7966452836990356, 0.7997515201568604, 0.7987160682678223, 0.8036860823631287, 0.8051356673240662, 0.7991302609443665, 0.7951956987380981, 0.7999585866928101, 0.7995443940162659, 0.7983019351959229, 0.7999585866928101, 0.8001656532287598, 0.8001656532287598, 0.7991302609443665, 0.8016152381896973, 0.8057568669319153, 0.8020294308662415, 0.8045144081115723, 0.8028577566146851, 0.8063781261444092, 0.8080347776412964, 0.8045144081115723, 0.7997515201568604, 0.8043072819709778, 0.7999585866928101, 0.8003727197647095, 0.801822304725647, 0.8063781261444092, 0.8016152381896973, 0.8030648231506348, 0.8014081716537476, 0.8049285411834717, 0.8057568669319153, 0.8061710596084595, 0.8067923188209534, 0.8069993853569031, 0.8107268810272217, 0.8063781261444092, 0.8053427338600159, 0.8082418441772461, 0.8055498003959656, 0.8041002154350281, 0.8043072819709778, 0.80886310338974, 0.8082418441772461, 0.8024435639381409, 0.8022364974021912, 0.8041002154350281, 0.8032718896865845, 0.8090702295303345, 0.8036860823631287, 0.8069993853569031, 0.8055498003959656, 0.8026506304740906, 0.8043072819709778, 0.8063781261444092, 0.8032718896865845, 0.7997515201568604, 0.8090702295303345, 0.8053427338600159, 0.8105197548866272, 0.8072064518928528, 0.8074135184288025], 'loss': [5.491647000735519, 1.8869267837410637, 1.4167160040698175, 1.1243191555500425, 0.8866832273601004, 0.7420765169909302, 0.629266490497763, 0.549645380852335, 0.490690420112436, 0.4416396879863423, 0.38103146696742546, 0.3531687543870204, 0.31111739454875825, 0.28663608324409223, 0.27029276562062987, 0.2477830655829612, 0.23551578281482785, 0.22141749323550194, 0.20102609358203244, 0.20142035562832097, 0.16867687185885202, 0.17239060057844124, 0.17230149038142178, 0.1530057850487487, 0.15073983945329028, 0.14197234316808485, 0.13714745806803263, 0.13081701427031472, 0.11627174058949147, 0.12221908419336676, 0.12519419248823105, 0.1133749440201275, 0.11199772728309221, 0.10646185684446076, 0.09992384215525191, 0.09130144097194903, 0.0981085386710564, 0.09172071819598752, 0.08642804851661365, 0.08864781168515562, 0.08799289334210464, 0.08203664155369864, 0.07570527054758337, 0.07709286359926591, 0.08261319886285012, 0.07897739220709966, 0.08452187150611844, 0.07476100491324336, 0.07257514792188151, 0.0728411525626788, 0.0728864250627486, 0.06723322702514652, 0.06318694607230473, 0.0581345124619256, 0.06494828544606478, 0.06477861256549303, 0.0664598266651982, 0.060097132584152634, 0.06643737156897808, 0.056907125480948346, 0.055300968575701055, 0.054703801856071446, 0.056796862586002486, 0.051029858719511226, 0.055004967512391575, 0.04690999709599819, 0.05124679020302742, 0.052171396957316866, 0.05564387124988567, 0.052171472360494964, 0.04385570354125823, 0.05331155525322914, 0.044016877828935944, 0.04355390158608439, 0.04335100349353652, 0.04611281819013507, 0.04023899910905936, 0.04697090769749885, 0.04566160404349445, 0.05193842330510792, 0.04370050809354627, 0.04202244447369835, 0.047932562029587955, 0.03997247005475634, 0.050322375163843344, 0.04958132317315944, 0.03998023490386752, 0.03709722614508391, 0.03725801122914182, 0.04184506531162828, 0.04305836106646673, 0.04614774914371203, 0.03729930163385052, 0.03555530920466941, 0.041320768670104105, 0.047902677355464565, 0.036579011578742465, 0.03840802982835332, 0.04168202420607882, 0.03990575715138669], 'accuracy': [0.31700498, 0.5238712, 0.620495, 0.6803024, 0.7361226, 0.7718517, 0.8071665, 0.8273094, 0.8443455, 0.8589996, 0.87701946, 0.88706505, 0.89845693, 0.90705264, 0.91078085, 0.9183927, 0.9228977, 0.92626345, 0.9335646, 0.93558407, 0.9441798, 0.94231564, 0.9428853, 0.9496686, 0.9514292, 0.9535522, 0.95489854, 0.95707333, 0.96111226, 0.96023196, 0.9592999, 0.96282107, 0.9630282, 0.96644574, 0.9674296, 0.9700186, 0.96670467, 0.97027755, 0.97198635, 0.9712614, 0.97198635, 0.9736433, 0.9769573, 0.9742647, 0.9738504, 0.97581816, 0.9734362, 0.9764913, 0.9775269, 0.97659487, 0.97726804, 0.97959816, 0.9792875, 0.9812034, 0.98021954, 0.9806338, 0.9799089, 0.9816694, 0.9792357, 0.98135877, 0.9816694, 0.9821355, 0.9821355, 0.98342997, 0.98322284, 0.9839478, 0.98358536, 0.98337823, 0.9829122, 0.98405135, 0.9851906, 0.9836371, 0.9855012, 0.9864333, 0.98632973, 0.98544943, 0.98658866, 0.98441386, 0.9853459, 0.985087, 0.9870029, 0.9867958, 0.98632973, 0.9875725, 0.98653686, 0.9859155, 0.9866922, 0.9890224, 0.9883492, 0.9884528, 0.98715824, 0.98664045, 0.988401, 0.98964375, 0.98803854, 0.98731357, 0.9882974, 0.9892813, 0.98803854, 0.9889188]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFlCAYAAADRdSCHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdd3wUZf7A8c+UbHpPaAFCB6WJCIhUAUE9kSIqIlhPsZ1n+yl6nKBSFLDCYTv9+RO9QwVEAUFPigoCgvTQESKkQBopm2Q3uzO/PzZZyBFgMbsku/m+Xy80mZ155jtPkv3uM/MUxTRNEyGEEELUGmpNByCEEEKIyiQ5CyGEELWMJGchhBCilpHkLIQQQtQykpyFEEKIWkaSsxBCCFHLSHIWAWvKlCkMGzaMYcOG0aFDB4YMGeL+vrS01ONyVq5cyZQpU865z/Hjxxk9enR1Q3YbN24cK1as8Fp5F0Nubi5t27Y95z5/+ctf6NGjByUlJRcpKiH8k17TAQjhKxMnTnR/PWDAAGbNmkXHjh0vuJyBAwcycODAc+5Tv3595s+ff8Fl1yXHjx9n06ZNXHbZZSxevJjbbrutpkMSotaS5CzqrA4dOjBw4ED27t3LrFmz2LdvH5999hllZWXk5+dz3333MWbMGBYtWsS3337Lu+++y7hx47jsssvYsmULGRkZ9OzZk5deeon09HSGDh3K1q1bmT17NmlpaWRlZZGWlkb9+vWZOXMm9erVY8eOHUyePJmysjKaNm1Keno6EyZMoEePHh7H/dlnnzFv3jxUVSUhIYG///3vNG/enM2bN/Pyyy9jGAYA48ePZ8iQIWfdfjrDMJg2bRrbt2/HarVimiZTpkyha9euTJgwgYiICPbt20dmZiZt27bllVdeITw8nO+++47XX3+d0NBQOnTocM64P//8c3r27MmQIUN48803GT16NIqiALB9+3amTJlCSUkJQUFBPP300/Ts2fOs29u2bcv69euJi4sDcH9/4MABpk6dSlhYGFarlYULFzJjxowqr8tqtTJlyhS2bNmCpmkMGjSIBx54gH79+vH555/TvHlzAO666y7Gjh3LoEGDPP4ZCVFtphB1wNVXX23u2LGj0rY2bdqYX375pWmapllUVGTecsstZm5urmmaprl161bzsssuM03TNBcuXGjef//9pmma5tixY81HH33UdDqdZmFhodm7d29z/fr15tGjR937v/XWW+bAgQPNwsJC0zRNc/z48eabb75plpWVmX379jXXrFljmqZprl+/3mzbtq25YcOGM+IdO3asuXz58jO2//zzz+agQYPMnJwcd2zXXXedaRiGeccdd5hLly41TdM09+zZY06ePNk0TfOs20+3ZcsW8y9/+YvpdDpN0zTNd9991xw/frxpmqb5zDPPmLfeeqtps9lMu91uDh8+3FywYIGZlZVldu3a1Txw4IBpmqb5zjvvmG3atKmy/svKyszevXubq1atMm02m9mtWzd3PdjtdrNXr17m6tWrTdM0zZ07d5o33HCDabPZqtzudDrNNm3auOug4meZk5NjbtiwwWzXrp157Nix817XtGnTzMcff9x0OBymzWYzb7/9dnPDhg3mlClTzFdeecU0TdNMTU01+/XrZzocjiqvSwhfkZazqNOuuOIKAMLDw3nnnXf44YcfOHLkCHv37qW4uLjKY66++mpUVSUiIoLk5GTy8/Np3LhxpX26d+9OREQEAJdeein5+fns378fgH79+gFw5ZVX0rp16wuK96effuL66693txhHjhzJ1KlTOXbsGNdddx0vvvgiq1at4qqrruKJJ54AOOv203Xp0oXo6Gjmz5/P0aNH2bhxI+Hh4e7X+/Tpg8ViAaBNmzbk5+fz66+/0qZNG1q1agXArbfeymuvvVZl3CtXrsQwDPr06YOu61x//fV8/PHH9OvXj/3796OqKv379wdcdzSWLFlCSkpKldvPp2HDhiQlJZ33un7++WeeffZZNE1D0zQ++eQTAOrVq8fYsWN5/PHH+eyzzxg1ahSapp33vEJ4k3QIE3VaWFgYAJmZmQwfPpy0tDS6du3KY489dtZjQkJC3F8rioJZxfT0Ve2jadoZ+17om37FrenTmaaJw+Fg9OjRfP311/Tq1Yu1a9dy4403YrPZzrr9dGvWrGH8+PGA6xn7fz8PPts1n349un72z/r/+te/KC0tZfDgwQwYMIDvv/+etWvXcuDAATRNc9/errB///6zbnc4HJW22e32St9X/EzPd126rlcqPyMjg7y8PJo3b07btm1ZuXIlS5cu5eabbz7rdQnhK5KchQB27dpFXFwcDz30EL1792b16tUAOJ1Or52jZcuWWCwWfvzxRwB27NjB/v37z0hA59KnTx+++eYbcnNzAVi4cCExMTEkJyczevRo9uzZw8iRI3nppZcoKCggKyvrrNtPt27dOq6++mrGjBlDhw4d+P7778977d26dePgwYPs3bsXgEWLFlW53+HDh9m0aROLFi1i1apVrFq1irVr19KtWzc+/vhjWrRogaIorFu3DoCUlBTuvPPOs243DIO4uDh27twJwNKlS88a47muq2fPnnz55ZcYhoHdbufRRx9l06ZNAIwZM4YZM2bQqVMn6tevf856EMIX5La2EECvXr1YsGAB1157LYqi0L17d+Li4khNTfXaOXRdZ/bs2UyaNInXXnuNZs2akZCQUKlVerqnn36aZ5991v39mDFj+J//+R/uuuuuSknq3XffRVVVnnrqKaZNm8Ybb7yBoig88sgjNG7c+KzbTzd69GiefPJJhg4disPhoFevXnz33XdVttQrxMXFMWvWLJ566imCgoLo1q1blfv9+9//ZtCgQSQnJ1fa/vDDDzN+/Hgef/xxZs+ezbRp05gxYwZBQUHMnj0bi8Vy1u0TJ07kxRdfJCoqiquuuorExMQqz32u63rkkUeYOnUqw4YNw+l0cv311zN48GDA9ehi4sSJXh0eJ8SFUMyq7skJIXzilVde4d577yUhIYGMjAyGDRvG999/T1RUVE2HJk6zdetWJk6cyNKlSy/ozoYQ3iItZyEuoqSkJO666y50XXcP65HEXLs888wz/PLLL7z++uuSmEWNkZazEEIIUctIhzAhhBCilpHkLIQQQtQykpyFEEKIWqbWdAjLyir0anmxsWHk5VU9w5PwnNSjd0g9eofUo3dIPXpHdesxMTHyrK8FbMtZ12W6PW+QevQOqUfvkHr0DqlH7/BlPQZschZCCCH8lSRnIYQQopaR5CyEEELUMpKchRBCiFpGkrMQQghRy0hyFkIIIWoZSc5CCCFELSPJWQghhKhlJDkLIYTwCzabjSVLFnu07zffLGHt2h8u+Bw33jjkgo/xhVozfacQQgj/8fmqg2zae8KrZXZrV49bBrQ66+u5uTksWbKYoUOHn7es668f6s3QLrqATM5pWUUcyy2hcVxoTYcihBDCSz7++EOOHDlMnz7duOKK7pSUlDBhwt9ZsWIZe/fupri4mGbNmvPcc5P44IN3iY+Pp2nTZnz66ccEBelkZKQzYMA13Hnnvec91/79e3n99ZlomobFYuHppycSGxvL889PwGq1YrOV8uyzE2jR4lKmTp1MWtox7HY7t902loEDB1f7WgMyOc9fdZADR0/y9pP9UBSlpsMRQoiAc8uAVuds5frCHXfcw6FDB+nRoyeFhYU89thTWK1FREZG8sYbczEMg3HjbiErq3KL/vjxDD766N+UlZUxfPi1HiXnV16ZyoQJE2ndui0//bSGOXNe4557xpObm8Mbb8wlLy+PgoIsioutbNmymX/+cx6KovDLLxu8cq0BmZwNw8TuMDBME02SsxBCBJymTZMBCA4OIS8vj0mTniMsLIySkhIcDkelfVu0aIWu6+i6TnBwiEflZ2dn0bp1WwA6d76cd96ZQ4sWLRk58hYmT/4bDoeDe++9m7CwcB5//GlmzJhKcbGVwYOv88r1BWRy1jVXPzeH00STLm9CCBEQFEXFNA0AVNXV8NqwYR0nThznxRenk5eXx48/rsY0zf867sLPlZCQyMGDB2jVqjXbtm2hSZOmHDp0kOJiKzNnvkl2djYPP3wv//jHB+zbt4fp02dhs9m46aY/MWTI9eh69dJrQCZnrfyH5nQaECRLowkhRCCIjY2lrMyBzWZzb7vkkvZ89NEH3H//XVgsFho1SiI7O6va53rmmb/x+uszME0TTdOYMOHvJCQk8r//+x4rVixD14N49NFHiY+PJzc3h7vvHkNoaBijR4+tdmIGUMz//ohRQ7KyCr1W1twvd7J5XxZv/KU3UeEWr5VbFyUmRnr1Z1NXST16h9Sjd0g9ekd16zExMfKsrwVky7nitrbTqBWfO4QQQtQia9f+wPz5n56x/eabb6Nfv6trIKIzBWRy1jTXbW2H06jhSIQQQtQ2vXv3o3fvfjUdxjkFZHepUx3CJDkLIYTwP4GZnNXy29pOua0thBDC/wRkcnbf1jak5SyEEML/BHZylpazEEIIPxSQyfnUbW1pOQshRKC4GKtS1RYB2Vtbd9/WlpazEEL4wqKDS9l6YqdXy+xSryMjW91w1tdlVSo/5x7nLC1nIYQIGBdjVaqFCz/jhx9W43A4iIiIYOrUmRiGk2nTXiAzMxOHw8Hjj/8PrVu34fHHnyc19ah7W4cOnbx2rQGZnLXT5tYWQgjhfSNb3XDOVq4v+HpVKsMwyM/P54035qKqKk888Qh79qSwZ08KDRo04oUXpvPbbwfZvPkXUlJ2kpSUxHPPvejeJsn5PCrm1pZxzkIIEZh8sSqVqqoEBQUxefLfCA0N5cSJEzgcDn7/PZUrr7zKXVaLFq2YOXMagwcPrLTNmwKzQ5hWsfCFtJyFECJQnGtVqhdemMb99z+MzVb6h1elOnjwAD/+uIYXX5zO448/7T5XcnJz9uzZDUBa2jEmT/4bycnN2blzZ6Vt3hSQLWeZIUwIIQKPr1elaty4CaGhodx77zgsliDi4xPIzs5i2LCRTJ/+Io88cj9Op5O//vVJmjdvyeuvT6+0zZsCclWqDbszee/r3dwxpC39uyR5rdy6SFav8Q6pR++QevQOqUfvkFWpLlDFOGdpOQshhPhvsipVDdGlt7YQQoizkFWpaoi7Q5jMrS2EEMIP+bTlPHz4cCIjXffUGzduzPTp0315OrdTQ6mk5SyEEML/+Cw5V/Smmzdvnq9OcVaa9NYWQgjhx3x2W3vv3r2UlJRwzz33cMcdd7Bt2zZfneoM7uk7ZW5tIYQQfshnLeeQkBDuvfdebr75Zo4cOcJ9993HihUr0PWqTxkbG4aua145d6Hd1WK2WPRzdlUXnpE69A6pR++QevSOQK7HcePGMXnyZFq2bFnl6wMGDGD58uUEBwdX+1y+qkefJefmzZuTnJyMoig0b96cmJgYsrKyaNiwYZX75+UVe+3cBQUlABQW2WQsXzXJeEjvkHr0DqlH7/BGPWZ9MZ/CzZu8FJFL5BXdSLx5dLXLsdsd5OUVn/UanU6DrKxCgoPt1TqPX45zXrBgAfv372fy5MkcP36coqIiEhMTfXW6StxLRsozZyGECBjPPfc/3HzzaLp06cqePSnMnfsWMTGxFBUVkp9/kqFDRzBixCiPy8vISOfll1/C4XCgKAp//etTtG7dhqlTJ5OWdgy73c5tt41l4MDBvPvuP9iyZTOGYXDNNUO45ZYxPrxSHybnUaNG8eyzz3LbbbehKArTpk076y1tb5Pe2kII4VuJN4/2Siv3QgwdOpzly5fSpUtXvvlmKZdffgUtWrSkX78BZGdn8cgj919Qcv7HP95g1Khb6dOnPwcO7OPll19i9ux32LJlM//85zwUReGXXzYA8O233zBnznskJCTyzTdLfHWJbj7LlhaLhVdffdVXxZ/TqQ5h0nIWQohA0aNHT+bOfZOCgnx27NjKrFlv8c47c/jhh9WEhYWfsRrV+Rw5coTOnS8HoHXrtpw4cZywsHAef/xpZsyYSnGxlcGDrwNg8uSpvPvuHHJyctwrVPmSzBAmhBDCL6iqytVXD2LWrJfp06c/8+d/QocOnRgxYhRbtmxm/fq1F1Res2bN2LFjK7179+PAgX3ExcWTnZ3Nvn17mD59FjabjZtu+hPXXHMtq1evZPLkaZimybhxtzBo0BCfdqoLyORccVvbKc+chRAioPzpTzdyyy3DmD//SzIy0pk1azrffbec6OhoNE3Dbve8k9fDDz/GK69M4d///gSHw8Gzz/6d+Ph4cnNzuPvuMYSGhjF69FgsFgtRUVHcddcYIiMj6dbtSurXb+DDqwzQVanKHAbjZ62hffM4nrz1Mq+VWxdJ71jvkHr0DqlH75B69A6/7K1dkzRNWs5CCFGX7d69i7lz3zpj+8CBgy+o01hNCcjkrCoKqqrIM2chhKijLr20A3PmvFfTYfxhAbkqFbg6hck4ZyGEEP4oYJNzkCYtZyGEEP4pYJOzrqsyzlkIIYRfCtzkrKk4peUshBDCDwV0cnZIy1kIIeqcRx65n9TUIzUdRrUEZG9tcC1+UWKTlrMQQvjCz6sO8dveE14ts0W7elw1oOplHuuaAE7OqoxzFkKIAOKtValWr/6eRYu+oGIOrilTZhAVFcUbb8xkz54Uysoc3Hvv/fTq1feMbX369PfxVboEbnLWVemtLYQQPnLVgJYXvZXrrVWpjh79nZkz3yQkJIQZM6byyy/rCQ4OIT//JO+//zE5OdksXPg5hmGesU2SczXJOGchhAgs3lqVKjY2jilTJhEWFkZq6hE6dOjE8eOptG/fCYD4+ATuv/8h5s376IxtF0tAdwhzGia1ZOpwIYQQ1XS2Vamef/4lBgwY5NH7fVFRER988C4vvDCNZ56ZSHBwMKZp0qxZM/bu3e3e54knHqly28USsC3nIPeaziZ6+VzbQggh/Ft1V6UKDw+nY8fO3HPPWEJDQ4mMjCQ7O4vrrx/K5s2/8OCD9+J0Orn77vu48sqrzth2sQTkqlQAc79KYfOe47z9RD+CLZpXy65LZPUa75B69A6pR++QevQOWZXqD6hY09lhGAQjyVkIIeoSWZWqltJ1121t6bEthBB1j6xKVUu5nzlLj20hhBB+JmCTs16enB2GtJyFEEL4l8BNzrq0nIUQQvinwE3O5cOn5JmzEEIIfxPAybmiQ5i0nIUQQviXgE/OsqazEEIIfxPwyVlazkIIIfxN4CZn3fXM2Sm9tYUQQviZgE3OQdJyFkII4acCNjmfuq0tLWchhBD+JWCTs+ZelUpazkIIIfxLwCZn6RAmhBDCXwVscg7SZRISIYQQ/ilgk7MuC18IIYTwUwGfnGXhCyGEEP4mcJOzLjOECSGE8E+Bm5ylQ5gQQgg/FcDJuaJDmCRnIYQQ/iWAk3PFOGe5rS2EEMK/BHxylpazEEIIfxOwyTlIOoQJIYTwUwGbnGUolRBCCH8V+MlZbmsLIYTwMz5Nzjk5OfTr149Dhw758jRV0sp7a8sMYUIIIfyNz5JzWVkZzz//PCEhIb46xTkFyZKRQggh/JTPkvMrr7zC6NGjqVevnq9OcU4VM4TJbW0hhBD+RvdFoYsWLSIuLo4+ffrw3nvveXRMbGwYuq55LYYSmwMATddITIz0Wrl1kdSfd0g9eofUo3dIPXqHr+rRJ8l54cKFKIrC+vXr2bNnD8888wxvv/02iYmJZz0mL6/YqzHExIYDUFJiJyur0Ktl1yWJiZFSf14g9egdUo/eIfXoHdWtx3Mldp8k508//dT99bhx45g8efI5E7MvnJq+U545CyGE8C8BO5RKURQ0VcFhyDNnIYQQ/sUnLefTzZs3z9enOCtNU6TlLIQQwu8EbMsZQFdVGecshBDC7wR2cpaWsxBCCD8U0MlZ01Sc8sxZCCGEnwno5CwtZyGEEP4owJOzPHMWQgjhfwI6OWuqtJyFEEL4n8BOzpoq45yFEEL4nYBOzrqm4JSWsxBCCD8T2MlZVXEaJqYpCVoIIYT/COzkXD6/ttOQ5CyEEMJ/BHRy1jRZ01kIIYT/CezkrMrKVEIIIfxPQCdnvbzlLGOdhRBC+JMAT87SchZCCOF/Ajo5u585y1hnIYQQfiSgk/Op29rSchZCCOE/Ajs5uzuESctZCCGE/wjo5KzJOGchhBB+KKCTsy7jnIUQQvihgE7OMs5ZCCGEPwro5CzjnIUQQvijOpGcHfLMWQghhB/xKDnb7XZfx+ET7g5h0nIWQgjhRzxKzoMHD+aFF15gx44dvo7Hq051CJOWsxBCCP/hUXJevnw5nTt35rXXXmPo0KF88MEHZGVl+Tq2atNknLMQQgg/5FFyDg0NZfjw4Xz00Uc8+uijfPzxxwwePJiHHnqI1NRUX8f4h8l6zkIIIfyR7slOqampfPXVVyxbtoxGjRrx1FNPMXjwYDZs2MB9993Hd9995+s4/xAZ5yyEEMIfeZSc7777bkaOHMmHH35IUlKSe3u/fv1Yt26dz4KrLk2VZ85CCCH8j0e3tVesWMEll1xCUlISubm5LFiwANN0JbznnnvOpwFWx6nb2tJyFkII4T88Ss6TJk2qdOt648aNTJo0yWdBeYv01hZCCOGPPLqtvWvXLpYsWQJAXFwcM2fOZOjQoT4NzBsqemvLOGchhBD+xKOWs2EYnDhxwv19Tk4Oqlr7JxeTlrMQQgh/5FHL+YEHHmDEiBF07doVgO3bt9fqZ80VKmYIk97aQggh/IlHyXno0KF0796dbdu2oes6EydOpF69er6OrdpOLXwhLWchhBD+w6PknJuby/Lly7FarZimSUpKCseOHWPGjBm+jq9apLe2EEIIf+TRg+PHHnuMPXv28PXXX1NSUsK3337rF8+cNXnmLIQQwg95lGFPnDjBK6+8woABAxg8eDCffPIJu3fv9nVs1aZXzK0tLWchhBB+xKPkHB0dDUDz5s3Zu3cvsbGxPg3KW6TlLIQQwh959Mz5yiuv5NFHH+WZZ57hnnvuISUlhZCQEF/HVm26rOcshBDCD3mUnO+8806KiopISkritddeY9OmTTz88MO+jq3adJlbWwghhB/yKDnffvvtLF++HID27dvTvn17nwblLZr01hZCCOGHPErO7dq1Y/HixXTq1KnS7exGjRqd9Rin08nEiRM5fPgwmqYxffp0mjZtWv2IL0DF9J3SchZCCOFPPErO27dvZ/v27ZW2KYrCypUrz3rM6tWrAZg/fz4bN25k+vTpvP3229UI9cIpioKuKfLMWQghhF/xKDmvWrXqggseNGgQ/fv3ByA9PZ2EhIQLLsMbNFWVlrMQQgi/4lFyfvbZZ6vcPn369HMXrus888wz/Oc//+Gtt9668Oi8QNcUGecshBDCryimaZ63Wfnll1+6v3Y4HKxcuZIWLVrw9NNPe3SSrKwsbrnlFpYtW0ZYWFiV+zgcTnRd8zBsz42bvILwEJ13JgzyetlCCCGEL3jUch4xYkSl70eNGsVtt912zmMWL17M8ePHGT9+PKGhoSiKgqadPfnm5RV7EorHEhMjycoqRFXAZneSlVXo1fLriop6FNUj9egdUo/eIfXoHdWtx8TEyLO+5lFy/m+HDh2qtL5zVQYPHsyzzz7L7bffjsPh4LnnniM4OPiPnK5adFWlTDqECSGE8CMeD6VSFNewJNM0iYuL44knnjjnMWFhYbz55pvVj7CaNE2hxC7JWQghhP/wKDnv3bvX/bVpmu5E7Q+kt7YQQgh/49HCFxs3bmT06NEAHD58mIEDB7JlyxafBuYtMs5ZCCGEv/EoOb/88su8+OKLALRo0YL33nuPqVOn+jQwb9E1aTkLIYTwLx4lZ5vNRps2bdzft2zZEofD4bOgvEnXFAzTxDj/iDEhhBCiVvDomXOLFi2YOXMmw4YNQ1EUli5dSrNmzXwcmndUrOnsdJqouv88KxdCCFF3edRynjp1KiUlJTz55JM888wzlJSUMGXKFF/H5hW6e/ELee4shBDCP3jUco6IiKBXr148//zz5ObmsmrVKiIiInwdm1e4W86G3NYWQgjhHzxqOU+cOJHvvvvO/f3GjRuZNGmSz4LyJl2TlrMQQgj/4lHLedeuXSxZsgSAuLg4Zs6cydChQ30amLdoquvzhyRnIYQQ/sKjlrNhGJWm68zJyUFVPTq0xlW0nJ0ynEoIIYSf8Kjl/MADDzBixAi6du0KwPbt2/nb3/7m08C8Rdek5SyEEMK/eJSchw4dSvfu3dm2bRu6rjNx4kRCQ0N9HZtXaBUtZ+kQJoQQwk94fG+6fv36DBkyhMTERF5//XX69u3ry7i8Rnc/c5bkLIQQwj94lJytVivz589n2LBh7nWc58+f79PAvEWT3tpCCCH8zDlva+/evZv58+ezfPlyOnbsyNixY5k7dy7Tp0+/WPFVm+6eIUySsxBCCP9wzpbzyJEjKSws5KuvvuLDDz/k5ptv9pte2hXc45zlmbMQQgg/cc5MO3fuXBwOB8OHD+eJJ57g+++/x/SzBSRknLMQQgh/c87kPGDAAGbPns2KFSvo3Lkzc+bMITMzkxdeeIEDBw5crBirRcY5CyGE8Dce3aOOi4vjzjvvZPHixSxYsABVVbnjjjt8HZtXuMc5G9JyFkII4R/O2SHsjjvuoHv37vTt25dOnToBcOmll3LppZcyYcKEixJgdWmqtJyFEEL4l3Mm53/+859s2rSJZcuWMX36dJKSkujbty+9e/cmLi7uYsVYLTJDmBBCCH9zzuRssVjo1asXvXr1AiAtLY0ffviBiRMnUlRUxMcff3xRgqyOU+OcpeUshBDCP3g0fSfAiRMnSEpKonXr1pimybBhw3wZl9fIOGchhBD+xqMOYZMmTeKNN97g4MGDPPXUU6SkpDB58mQfh+YdusytLYQQws94lJx37tzJ1KlTWb58OaNGjWLatGkcPnzY17F5hSbPnIUQQvgZj5Kz0+nEMAxWrlxJ3759KSkpoaSkxNexeYWuyjNnIYQQ/sWj5Dx8+HB69+5NUlISnTt35qabbuLWW2/1dWxeock4ZyGEEH7Gow5hd999N3feead7Xu1PP/2U2NhYnwbmLTJDmBBCCH/jUct59erVvPrqq1itVkmURwEAACAASURBVK677jquvfZaFi1a5OvYvEKXubWFECKgGWVl2NKO1XQYXuVRcp4zZw5Dhw7lm2++oVOnTqxatYpPPvnE17F5hYxzFkKIwJbz5UJSJ02kaPu2mg7Fazxe/7Fdu3asWbOGAQMGEB4eTllZmS/j8hr3OGd55iyEEAHHKLOTv/YnALLmf4pRZq/hiLzDo+SckJDASy+9xM6dO+nTpw8vv/wyjRo18nVsXiFzawshROAq2vIrRrEVLSKSsqws8r77tqZD8gqPkvOrr75Kx44d+eSTTwgLC6NJkya8+uqrvo7NK2RubSGECFz5P/0IQNJjT6JFRpG7bAllubk1HFX1eZScw8PDsVqtzJo1i4ceegiHw0FYWJivY/MKXZ45CyFEQLIfP07J3j2Etm1HSLNmJNw0CtNuJ3vBZzUdWrV5lJxnzJjBunXrGDZsGCNHjmTjxo1MmzbN17F5hYxzFkKIwJS/1tVqju7TF4Coq3oT3Kw5hb9spHjfXgDsGelkLfic1JcmU7Rje43FeqE8Gue8bt06Fi9e7B7n3L9/f4YOHerTwLxFxjkLIUTgMR0OCn5eixoWTkTXKwBQVJV6Y8ZydNpLHP/4f9HCIyj97ZD7mPR/vEWjBx8h4rIuNRW2xzxKzk6nE4fDgcVicX+vaZpPA/MWVVFQkFWphBAikFh37sCZn0/MgEGoQRb39tAWLYnq1YeCdT9RppwgrH0Honv1QQ0LI33ubNLfnkPD+x8ksjyh/zejtJTiPbux7t6FUVyCEqSjaDqKrhNxeVfC2ra7KNfnUXIeOnQod9xxB3/6058AWLZsGTfccINPA/MWRVHQNBWHrEolhBABI/+nHwCI7tPvjNfq3XY7YW3bEdruEoLi4tzbkx57krQ3Xyfj3blw/wNEXH4FZdnZ2DPTsaelUbw7heL9+8DprPKcZTnZtSs5P/DAA1x66aWsX78e0zR54IEHWLNmjY9D8x5NU6S3thBC+ICzuBhb6hFCW7dB0T1KKedk2O1kvv8uZbk5xA4aTGS37meUW5abi3XnDoKbNSe4SZMzylBDQoi6qtcZ28PatKXx40+S9sarZLz7NoqmYToclfYJbppMeMdOhHfohB4fh+lwuvZxOgiq36Da1+cpj2uyb9++9O3b1/39E0884T9rOquKPHMWQggvMWw2rNu3UbjpF6w7t2M6HET360/9cXdVr1y7nfQ5b1K8OwWAzA/eI/vLBcReM4TwDh2xpadjO5rqet00ie57Zqv5fEJbtSbpif/hxLyPQNOxNGiApWEjLA0aEtqqFXp0TLWuwVv+8Mcc0/SfZKdrqrSchRDCA7a0YxT9uhnDZsMss2PYyzDtNpxWK06rFcNahOPkSczyWSItSY0x7Xbyf1hDeIeORHTpes7y7ZkZnPh0Hlp0NPF/GoqloWtCK6PMTvo/3qJ4dwrhnS8j8eZbOblqJflrfyTrs3+T9dm/K5VjadSIqO49/tA1hrZoSfKkl/7QsRfLH07OiqJ4Mw6f0jVFxjkLIcQ5mKbJydUryf58/hm3eisouo4aEYGlYSPCO3UislsPgpMaY0tL4/cpk8n86EOSm7UgqIpVC03TpGDtj5z496eYdtcUm4UbNxDZvQexQ64je9ECilN2Ed6pMw0feBg1KIh6Y8YSf+NwTq5Zhf14JsFJjQlu0pTgJk3Ro6J8WR017pzJedy4cVUmYdM0sdlsZz2urKyM5557jrS0NOx2Ow8++CADBw6sfrR/kKap2MqqfsAvhBCBxJaehhYReUHJy1lUROZHH2DdthUtIpLE0bcRVK8+apAFxRKEYglGCw9HtViqPD44KYnEW0Zz4tN5HP/wfZIefwpFPTWNhtNq5fi8jyjavAk1NJQG9z+IEqST8/ViCjduoHDjBgBXYn7wEdSgIPexWkQE8Tfc+Adrw3+dMzn/5S9/+UOFfv3118TExDBz5kzy8vIYMWJEjSZnXVMpLq36k6AQQvgLR/5Jsr74jOhefQi75NIzXi85sJ+jM19GCw+n0SN/JbRlq/OWWXLoIBnvzMWRl0tou0to+Of70WPObPmeT3T/AVh37cS6fRt5360g9pohlBzYT9G2LRRu+gVnfj4hrVrT8L7xBMUnABDeuQvW7VvJXb6MoPgE6t9zX6XEXJedMzl37979DxV67bXXMmTIEPf3NT0mWlMVWZVKCOHXXM9kZ1P62yGKtm6l6YTnCG7S1P26o6CA9HfnAq6W8LFZr9DgvgeIvPzsz4BtaWmkvfEqhs1G/PCRxF1/Q6UW74VQFIX6d91D6uS/k/3lQnJXfINRVASAGhpK/LARrvJPyweKqhLRpet5n1PXRdXv916F8PBwAIqKinj00Ud57LHHzntMbGwYuu7dJJ6YGAlASLCO02m6vxcXRurNO6QevaMu1qNpmhx4cw6lvx0ism0bCvftJ2POm3Sa+TLB8XGYTicpb72K8+RJku8cR1jTJuyb+RoZb88h5J67aHTjmfNSROsOdsx5HaOkhDZPPkZi3z7VDzQxktAn/sruF6eiBenUu3YwcVf2ILpD+4BtEfvq91ExfdTtOiMjg4cffpgxY8YwatSo8+6flVXo1fMnJka6y5z2ya8cSsvng2cGePUcdcHp9Sj+OKlH76ir9Zj77XKyv/iM4GbNafL0s5xc+R+yF35BcHIzmjz9LLkrviF3yVeEd76MRg8/iqKqlKYeIe2t13Hm5xN1VS/ih41w306Oiwxi69N/w5Z6hPjhI73+TNdZbEUNCf3DrXB/Ud3fx3Mldp+0nLOzs7nnnnt4/vnn6dmzpy9OcU6mYWCeNsOLriqYJhiGiar6Ty9zIYRvOYuK0CIiajoMt+I9u8n86APXRBjtOxDeviO2jDSyF3yOFhND0iOPolosxF57PfbjmRSs/Yljs16h9Mhh9IQEGtxznzshhiQ3o+lzz5M2+w0Kfl5HwcYNRF3Vi7hr/8T+9xZgSz1CVO8+xP3J++skaGHhXi+zrvFJcn7nnXcoKChg7ty5zJ3regby/vvvExIS4ovTneHEJ//H0f37aPLiNBRVrbSms0X1jznBhRC+VbR9G+lz3iR28LUk3nxrTYeD6XBw/NOPceTk4MjJwbp1i+sFRUHRdZIe+au7o5aiKNQfeydl2dmU7N2Dous0euBhtPDKSTEoPp7kv0+m8JcN5CxdQsFPP1JQvv5x2CWXUn/snX41LLYu8UlynjhxIhMnTvRF0R4x7HZKMzMpO3ECS4MG7uTslPm1hRC4nuHmfPUlmCZ53y7H0qBBlXM0X0z5P/1IWWYm0f2uJnbIdRSn7MSasovSI4epN3oMIc2aV9pf0XUaPfgIJz6dR0SXy8943b2fphHVsxeRPXpSuOkXcr9ZiiUshPoPPuyV6TaFbwTkTyYkuRmFG9ZT+vsRLA0aoJXfyi5zGoTWcGxCiJpXvDsF2++phLZpi+3YMY5/8jFB9RsQ1qZttcp1FBRgOp1VTsJxLs6SEnK+/hIlOIT4G4ejR0djqTeQmKvPPQRVCw+n4f0PeHQORVWJ6nElUT2urLPP7v1JQD6tD05uBoAt9QgAUeGugfN5BWefOEUIUXfkLl8GQOKtt9HowYcByJg7h7KsrD9UnmG3k7PkKw5PeIojEydg3bXzgo7PW/ENzsJC4q69Dj06+g/FIAJLYCbn8rF/pampACQlup7DHMsqqrGYhBDeVZabQ8mB/Rd8XMlvhyjZu4ew9h0ISW5G2CWXUu+223EWFZI2501sx45inGMGxNOZpknh5k0c+fuz5Hz1JWpwCBiGqxPW+p8r7WuUlZG38j8c//RjbMeOnnYdueT951u0mBhiB197wdcjAlNA3tbWQkMJadQQ2++pmKZJ40RXb0xJzkIEBtvR3zn26kycRYVEXtmTemPGoYWFuV83SkvJ/WYp1t0p1Lv1NkJbt3G/lvvNUgDirvuTe1tM/wHY09M4uWolqZP/DoAWGUVQYgKWRkmEJDcjuGkywU2aYhRbKTl4gJKDByjeuxf7saOgacQOuY64G27EdvR30ue8SeYH7+EoyCd20GAK1v9MzteLceTmAJC/ZjWRV/YkYdgIcr7+CtNuJ2HMWNTg4ItRfcIPBGRyBoho0YLstetwZGeTlOhaAiwty1rDUQkhqqv0yGGOvTYLo9hKUIMGFG5YT8n+/TS49z5CW7ehcON6shZ8gTP/JABHZ71CvdvHEdO3P7a0NKzbthLSoiWhbdtVKjfx1jFYGiZhO5pKWVY2ZTnZlKamUvrbbxSs/cm1k6LA6VNDaBrhl3UhcdStWBq41voNa9OWJs88R9obr5L9xWfkffctzvyTKLpO7DVDCGnVmpwlX1G4/meKNv2C6XRiSWpM1FW9L0r9Cf8QsMk5vKUrOZf+foTIrt2IjQyWlrMISKZpUrRlM6GtWteatWjPx1lURPrc2YS2bUf8jcM9Hs5TsHcfx16dgVFaSv277yWqR09yli0hd9kSjs16BUv9BtgzM1CCgogbOoyQ5s3J/OB9Tnz8EfZjR3EWuT6gx11/wxnnVDSNmKsrT1RkOp3YMzMoPXIEW+oRbEd/Rw0NJbRVa0JatSakWfMqF4MITmpMkwkTSXt9FvYTx4nq05f4ocMIiosHIKLL5RRu3ED2V4tw5OSQeMvogJ+wQ1yYgE3OES1cwwpsqalEdu1G48QIdv6WQ1FJGRGhgTmNnKibCn/ZQOb772Jp2Igmz/0dLbT2j0k4Mf9TSvbvo2T/PoySEhJvve2MZFn6eyr2Y8cwTQMMA6O0lJyvvsSw22nw5/FE9bgSgIRhIwjv2InMf76HPTODyG7dSRh1i3s2rKYTJ5E++01OrloJgKVREuGdOnsUp6JprmUKkxpDrwtr2QbFx9N00gsYxcVnfGhSVJWonlcRcUU3nCdPEpSYeEFli8AXsMk5vEULwPUHDq5OYTt/yyEtq4i2TS98xRUhaiPTMMhdtgQAe0Y6mR+8R6OH/lKrW2FFO7ZRuGE9wU2TMR1lnPz+OzBNEkePQVEUHIUFZC/4goJ1P51xrKLrNBz/EJFdr6i0PbRFS5Inv4QjLxdL/QaVXrMk1qPpcxPJ+Od7WLdtJf7GYRetftQgC2p01cssul4PQpXELKoQsMk5KCoSPT4eW+qR8k5hFT22rZKcRcAo2vor9vR0Inv0xFmQj3XbVnKWfEXCsBE1HVqVnMXFnJj3f6BpNLjnz2hR0Rx7dQYnV/4H0zAIbtyE7IVfYBRbCW7SlOj+A1B0zZVMFYUGnS6hOKzqv1/VYjkjMbtfCwml0cOP4sjLIyguzpeXKIRXBGxyBghp2oyirb/iOHnS3WM7TZ47iwBhmia5S5eAohA/dBhaRAS/T3mB3CVfEdyk6TmXCvQmw2Yjd9kSCjasJ2bAQGKvGVJpWcDTZS/4HEdeHvE3Die4cRMAGj/1NMdenUn+atdtZzUkhMTRtxNz9YAzyglPjKT4D06eoSiKJGbhN2rvvS8vCE5OBlyTkTSMD0dVFI5Jj21Ry5mGgT0z87z7WXdsx3b0dyK7dXfNhBcR4VqRyGIh84P3KfntkG/jPG2Mb+43S3Hk5pC94HN+n/oipeUTAJ2ueM9u8n9cgyWpMXHXn1rCUI+MosmTTxPWvgORPa+i2ZTpxA665qwJXoi6IKBbzsFNy5Pz76lEXNaF+nGhpGUXYZqmTPYuaq0T//qE/DWrSBh1C3HXXl/lPq5W89cAlVYVCm7ShAb3/JmMd+ZydNpLhLZpS8yAgURcdnmV8ygbNhulh3+j9LdDOAryUYIsqBYLSlAQanAwalgYWlg4algYiq7jLCrCWVCAs7AQ687tFO/ZjaLrxF1/A9H9ryZn8SIKfl7H71NfJGbgNVjq18dZWIizqIiiLb+6bk3ffe8ZsWiRkTR+/Ckv1qIQ/i2gk3NIecu5olNY48QIMnKKySkoJSG69vdoFXVP8b695K9ZBbhuAeuxce5eyZX2251C6eHfiOjS1dWT+DSRV3RHfSyUvO9WULw7hZL9+9BiYght3hIqlkxVFMpOnHDNVGUYfzjesA4dqXfb7e5nvQ3uuY/IHj05Me//OPmfb8/YP37YiLMu0CCEOCWgk7MeHYMWHeOeYzspMZxNe12TkUhyFrWNUWbn+Mf/C4pC/TvuIuvz+WR++D56dDRh7S6ptK+71XxD1WvxhnfoSHiHjtgzMzi5ehUFP6+laOuvlfZRdJ2Q5i0IbdmKkJYtCUpIxCwrwywrw7DbMWylGMXFGMXFOIuLMR1laBGRaJGRrtmz4uMJbpp8xl2o8PYdSH5hCkVbNoOquo/Ro6LcSx4KIc4toJMzuFrP1h3bceTnV5rGs3OrhBqOTIjKcpd8Tdnx48QMuoboPv0ISqzHsddnkf6Pt2gy4W/oMbEU/bqZgl82UHJgP+EdOxFSvsjL2VgaNKTebbeTePOtGKWlYJqYmGCYaOHhPlsyUA0OJqpnL5+ULURdEPDJOTi5WXnHmVQaJ7UCZBpPUfvYjv5O7rfL0ePiSRh+EwBh7S6hwT1/JvP9dzn6yjTXYgxOJwAhrVqTOHqMx+Uruo4WEeGT2IUQ3hfwyTmkvFNYaWoqCe07EhykyTSeolYxDYPM//tfcDqpf8edqCEh7teievTEcfIk2V98RnCTJkR2v5LIbt0JSpCJK4QIZAGfnN3DqX5PRVUUGiWE8/vxQhxOA10L6JFkogaYhkFxyi5QFMIubX/emaicRUVkLfgM25HDRF7Zk/AOnc7YJ27IdUT37e8X03IKIbwj4JOzHhuHFhGJLbWix3Y4hzMKOJ5bTFKi3OYT3mGUlpK/7idOfv8dZVlZAATVb0DsoMFEXdULiKy0v+lwcHL1SnKWfO1eXSnx1tvOWr4kZiHqloBPzoqiEJycTHHKLspyc90J+ViWVZJzHeUoKMCenoY9IwN7RjrOYitxQ64juEnTCy7LnplJ/k9ryP/pR4ziYhRdJ6pPXzBNCjes58SnH5O9eCH53bthdwKaaypK666dlB3PRA0NJfGW0cQMGOSzzllCCP9TJ94NIrt2ozhlFydXfU/jKwYBrh7bPahfw5GJiy332+Vkf/HZGduLtm6h4Z/HE9Hl8vOWYdhsFG3ZTP5PP1Kyfx8AWmQU8cNGEN3/avTIKAASRtzEydWrOLlmFVmr11QuRFWJvnoACTeOQIuMRAghTlc3knPPnmR/tYj8H1bTqP9gQHps10XWlF1kL/gcLSaG6Kt6Y2nYEEuDhpRlZZH50Qekz51NwshRxF57/Rljd03TpPS3QxSsW0vhpo0YJSUAhF3Snqg+fYjocjlqUOXVh/ToGBKGjyTuT0OJUmzkZhVgGgam0+kaJxwrY36FEFWrE8lZDbIQO/AashctwNj0M1FhkdJjOwA5Tp7EumsnptNJ1FW9UINOrdtdlp1Fxntvo2gajR56lNDyJUUBQpq3IKhBA9Jnv0n2wi+wpR0jonMXDJsNw27DWVhI0aZfsGdmAKDHxhIzYBBRvftgSax33rjUoCBCE+Ow6PIYRQjhmTqRnAHXvL/LlpL3/Xc0ufx2Uo4WUmJzEBpcZ6rA75mGQcnBAziys10bFNd/7MczsO7Yga18mlaAk6u+p8Hd9xLSrDlGmZ30t/+BYbVSb9xdlRJzhZCmyTT92/Okz32Lwg3rKdywvtLriq4T2a07Ub36eNQLWwghqqPOZCYtLJyYfv3J+24FnaxHSCGeI5mFXJIstxZrO9uxoxRsWE/hxg048nKr3knTCLukPeEdO2E/nkH+D2v4fdpLxF17PY78fGypR4jq1Yfovv3Oeh49JobGT02gcON6TIcDxWJxLf4QHEJIi5Zo4eE+ukIhhKisziRngJhBg8lb+R+aHNoEMUNIOZwrydnLDJsNNTi4+uWUlVH4y0ZOrvyPu0WshoYS1bsPoS1dM71huv6nRUUR1q4dasip4UaRV3Qn86MPyP1mKeBaoaze7ePOuxqZarEQ3efsCVwIIS6GOpWcg+JcK/wU/LyOtiFp7PwtklH9W9Z0WAEje/FCcpd/Q8P7xhN5Rfc/VIajoID8H1ZzcvVKnAUFoCiEX9aFqCuvIrxz5zM6XZ1N2CWX0uyFKWQvWkDJgQM0evARVItnxwohRE2rU8kZIHbI9RT8vI5+RXt470Rj8gptxEZWv6VX1xVu+ZXcpUsAyPzwn1gaNCS4cZNK+5iG4Rp6pKoExcWhx8Si6Dr2zAyKtm/Dun0bJQcPgGGghoYSO+RaYgYMIij+jy1SooaEUm/MuGpfmxBCXGx1LjkHJyUR3qkz7NhOs/B0Ug7n0rtTw5oOy6/ZMzM5/uH7KBYL8TfcSPaiBaT/YzZNJ05yP6d1lpSQ+cF7WLdtPXWgoqCGhmEUW93fhzRvTuSVVxF9Ve9Kc0wLIURdUueSM0D88JFYd+5gUNYmdh7qKMnZQ6ZpgmlW6qls2Gykvz0Ho7SUBveNJ6pHTwybjdxlS8h4/x2SHn2csqwTpM95C3tGOqFt2xHSoiWO3Fwcebk48k8S1rYd4Z0vI7xjJ/To6Bq8QiGEqB3qZHIOaZpMdN/+8MNq9F/XYQzrhKqeu6NQXWfYbGS8/w7Fu1MIa9uOsI6dCO/QiZyvFmFPO0bMgIFE9egJQPywEZSmplK8awcZ771D8e5dGMXFxAwaTOLNt6JoWg1fjRBC1G51MjmDa2rF7J/X0+3EVn47cIxWbZuc/6A6ymm1kjb7DUoPHkCLiMS6cwfWnTvIKn89pGUrEm85tWiDoqo0vH88v095kaLNv6DoOvXv/jPRvXrXzAUIIYSfqbPJWYuIwNnvWkK+X0zOlwtpNeGxmg7pojJNk5ID+zGsViyNGhGUWK/KiTVsOTkcnTEde9oxIrtfSYN7/owjPx/rrp1Yd+3AWVBAw/EPnbFogxYWTtJf/krO0q+JGXgNoS2kV7wQQniqziZngJY3Xs+WH3+g/sFtlPx2yK8SSFlWFsX79hLesSN6dEyV+ziLi1GDg8+4jWzPzODE/H9RvGune5ui6wQ1aIglsR56bAx6TCxaRCSpK5ZiP5FFzIBBJI4eg6KqBMXHE9OvPzH9+p8zRkvDRjS874FqX6sQQtQ1dTo5h4dZ2Hvp1dTftojMT+bR7LmJtX7ZvpJDB8n7bgVFW34F00QNCSH+xhHEDBjojt1+/Dg5SxZTuHEDakgIYZe2J7x9R0JbtyZ/7Y/kff8fcDoJu6Q9YZdcgj0jA1tGOvaMdOzHjp5xzvjyxRvON4GHEEII76jdmegiaHh5J1IObqH970f47ekniO7Tj+i+/QmKj6/p0NxM06Q4ZRc5S76i9NBBwDXjVXjHTpxcvYqsz/9N/tofiL9xBNadOyhYvw4MA0vDRhhldop+3UzRr5vd5ekJCdS79TbCL7u8UsI1DQOntQjnyZOU5eXhPHmShNbJlDVsdrEvWQgh6jTFNE2zpoMAyMoq9Gp5iYmRHpWZmlnIyx+s42b1IE0zdmMUF7tmpep8GYk33YylYSOvxnWhSo8cJmvB55Ts3QNAeOfLiL1mCKFt26EoCs7CQrIXLyT/xx+g/EdpadSI+BuHE3H5FaAolB0/jjVlJyX79xGS3IyYQYM9ni3L03oU5yb16B1Sj94h9egd1a3HxMSzr+Ve51vOTepHEBwVwddcxqwZf8a6eRMn16zCum0rxSm7SLj5VmKuHuj1W7rOkhJsv6fiLCjAUZCPs6AAw2ZDCQpCtVhQ9CBKU49QtPkXAMI6dCLxplEEN2laqRwtMpL64+4iuk9/8tf+SGjr1kR261Gpc5elQQMsDRoQO/Aar16DEEII36jzyVlVFDo0j+PnXZmknSwjuXcfonv3ofDXTRyf939k/esTrNu3Uf+uewmK9WyRDNPhoLB8CFF45y6V1hU2nU7yf1xD9uJFGFbrecsKbtacxFG3ENbuknPuF9KsGSHNmnkUnxBCiNqtzidngM6tEvh5Vyab950guYHrNkNk126EtmxN5kcfUrxrB6mTJhLWth1aTAx6+b+QpslYkhq7W6mmYVC4cT05Xy2mLNs1CliLjCSqd19i+vbHnnWCrM/+jT3tGGpICLHXDEFPSECPikaLjEQNDcV0ODDtdoyyMtTgYELbtJWOWEIIUcdIcgY6tYwn2KKxcfdxRvZt4U6GekwMSX99nPwfVpO98AuKtv56xrFqaCihrdsQnNyMol83YU9PR9F1YgZeg6Jp5K/7ibzly8hbvsx1gKIQ1acvCcNvkqkqhRBCVEmSMxAcpNGldQIbUo7zW0YBLRudSpqKohDTfwDRffu7ezI78k9SlpNL6eFDlOzfj3XHdqw7trsSb+8+xA8d7u7tHT9iJEWbN5G/9ieUIAsJI0YSktyshq5UCCGEP/Bpct6+fTuzZs1i3rx5vjyNV/S4pD4bUo6zcffxSsm5gqKq6JFR6JFRpzpllU/C4Th5ktLDv2Fp2AhLgwaVjlODLET17EVUz16+vgQhhBAB4sz5Gr3k/fffZ+LEidhsNl+dwqvaN48jPERn094TGMaFjS7TY2KI6HL5GYlZCCGE+CN81nJu2rQps2fP5umnn/bVKbxK11S6tq3Hj9vT2Xf0JJcke9YzWwghLpRhGpimiYHJ6VNNKOBa5xwFRVFQyv9vmiaGaZTvb6AqKpqiXVBnUcM0cJoGTsOB1a5RXFaC63DFdV4UVEWpiMJ1vop/GKioqIqCoqioioqKUinWihhNXP93mE4chsP9r+JMiqKgKme2CxVc20//p7jrAUzAaTpxGk4chhOn6awUo4nprhdN0dDU/y5DwTBNTCqOKY+3vF4N00BBQVNUVEUrj9F0X49pmsSHxqGrF+dpsM/OMmTIEI4dO+bx/rGxYei6d5cSPNcA76oMuaoZP25PZ8fhXPpe0fT8B9QRF1qPtZlhGtidZaf9UZsYhpMyw0GZswy70/VGEqTpBGsWLLoFixaEw3Bic9goddiwOeyUGY5KbxJQ8eaiuN8wE6Ee3gAAIABJREFUXW9Wrj/uQ0ed5W8shvvNqtRhx+60U+qw4zScBGk6Fi0IixaEruqV3lTA9cbkOtZ1Xl3V0FW9fH8Nh+HE7rRjc9ixO8twGk73G3LFG4/rTe/Um2NFcjBN0/Vm6nRgN8pwOB2Vrqv8XRyn+83WwDCc7jfain9mRXmY7mNd+7j2O3X9rjdZVVUJUnWCtCCCVB0T0/162WkxYFa8TVaUD1XNn2SW/0ydptN93RUq6tGVFA33dbteVMqTzempSqk4sFIiqngjNwyjUv06TVedAGiqhqZq6IoGilL+u1Lxs3Nc0O9sReKriq7qBJUni9MTVcU1Vfz2VMQnqqd748t4qtf4Stt89f5YazqE5eUVe7W8PzJzS/3IYKIjLKzdlsZNfZqjaz676+83PKlH0zQpddooslspdhS7E5az/P8Ow+H+FO3aZlT61Hv66w7D4UpYThs2p51Shw0TA+X0T+2nffpWFdenYbvTjs3pSnYVb34Vb2eGaWA3XK+VXeAbozg7VVErJeILPVZTNMzyFtbZ96n4G3QlGUVVUUzKPwC506fbma2vipZgRWp3JVpd0VHUUx98TFf2x6i4lvJkaJZ/7SxvsZqY7nPoio6qnjqXpqgoFR96Tvs9NzHRNd2drP+7dVgRd0U9VtTp6R8i1PKyXedQMAzD9QHRPJXsT/19VNRZ+YcYTLTy+tZVHU3RCAmxYLOVVVzhqQ88p7XkT29Buj4gnGpt/veHGwOzUmtfVRS08g8OuqKjq64PKa5jXOX89w/PfXegUmsYzPJzgYKuVrSKtdNayadayBV1XvFBuOLYiuuqeN+oeD+p+B2pqLeKVrJRXo77wyWufbrEd6z0figzhF0kqqrQrV09vt98jJTDuXRulVDTIXmNabpaJFZHMQX2QgrtVorsRZQ6ba7WUPkfeXFZyf+3d+9BdpR1wse/3U9fzplzmZlcJveETEIIEEIEAqIQZV9xQVcCqCVaL+prre+6xfuu7LqWgooBosutYNV9y3J5i3JFUGClFl2F1w23GJRBAgETQwK5z+Q2yVzPre/vH31OzwyZhEwyw1zy+1Sdmsvp0/2c3+nz/J7n6e6n6XK66XZ76HJ68EK3OpylMHSFrql+Ozz4oU/BKw65NzAUx5sETN3AUham3jfpS+3LlbNy2HrcCzZ1c0DlrWnV3pse995UtRfqBS5u6OEGHkpX1ddb2MpKKjmlV4cXGdgLrfXAal/sXC5NpeQnQ26GrrCUhVUtk9IUfuTjBh5+6OOFfr/KOu7xKN3AqFZMqtYLjeJl/dBPelGWbmEqs1/lqg2IYa3y6d8z17R4OM/QjfihGf2GHvviXnvftQo7Ll/fkKte63X2n7O933DnYMOxYRQSVEcvNA0MzUgq37eTaSeHh8Rx7JPk/DYXnTWNNS+38tLmA2MqOYdRSNEr4VR7lE7g4vhOnGi9Aj1OLz1ugUpQpuI7VPwK5cDBCZx4uDb0BgzxvRNd08lbOepTeVzPw4+C6nCwkxwDqrXkZ2VmkLUyZM0MGbMuqcBrrdy+v43q//Skgtf7JYTaMrYysZWNrWwsZSaV9MBjWrXf4yRjKWvQynysmMiVYZzYFUc9KKXBMZ6N9wOlYyrzqMsIcaoZ0eQ8e/ZsHn300ZHcxLBrnpFnSn2KV948hOMF2ObwHgc/miAM6Kh00V4+xKHyYdrLhzlc6Yx7sU4PPW7vkJJrqprc0kaKBiuPqSws3SRj1pGzsuSsHHkrS8pIDUikaSNFg11Pzsqia/qYSiq1JCCEEBOd9JzfRtM0LjprGr/+wy5efuMg7z9nxrCuv+I77O7dw47u3ewrHuBwpZOOSifdTs+gw7ZKU9TbeU7LzyFv5eOka8TDobayyVtZ8naOvJUja2apM9PYY7wXKYQQ4tgkOQ9ixbkz+X8v7eY/fred5YubsE6w91xwi7QV9rG3uJ+9hX3s6m1lb2H/gCSsodFg19NcfxqT041MSU9mavUxOT2JrJmRRCuEEKcYSc6DmNqQ5vIL5vBky25++8c9/NX7TnvH15S8Ert6WtnVuyf+2bOHbrdnwDKmbtJcfxrz6+cyPz+X2blZNNr1KF2GaoUQQvSR5HwUf/W+03jhT/v49R92ccnSGTRk7QHP97oF3urawZtd23mra/sRPeJ6K8+SyYuZmZ3BrOwMZmamM61uqiRikVx+Mp7uNhZFEWEYoevaCZU7CEJ8L742OAgiwiAkDCOU0jFMHdNUKEMf0ZiEYVwGw1To+olvJz4jv/ozjKpXXdV+MuDv2rL9niAMIzwvwPdCPDcgCEJMU2HaCssyMK24fJpenRREg8AP8f0w+amUhjJ0DENHqfiEOk07+j4VRRGeG+C6AZ7jE7ghXV2l+KoCTUMpnVTawLKNE/4MattwKj5OxccwdexUvE6l+k7q9L0Q3w+IIlCqekWDrh3X51/bDwM/JIrAMPVk3cd6TbnkUSq4KKVhWgrDVBimju+FOBUf14nLrOsahqljmArTVLXL+5PPMJOzT2rfGQpJzkeRtg2uWdHMvz21hcef384XPnomURSxrXsnz7W+wGvtG5MTtEzd4PSGZubXz2Nefjbz8nNosMfGHadqO3IQxF/qMIh/D4N4J69NVVpLGFFEtcKJH4Uuh0KhklQEaOC5QfzwAgI/7KtIqjttpexTKXtUSh6u42OYCstWWHZc8fhe3xfYdXyU0uOKyTawLANd15LrToG+y5J0DV2DMILAD5LKKgjiSjKsVpZhEOG6flJO3x94Ip2ua1i2kVQcpqXwXH9AmaIomXcjqbwMU0/iUItr/4pG00gq1CAIcRwf1wlwHT8upx8mMdd1DTtlYKdNUmkD2zYx7bhCMC2FUjqeG7/eceL3EpelrwLuH/dkhqZq0guCCKJjX3wWXzdcvZxK1+Lref0QP+hLAslnXd1+XHkpTCuuFMMwSj6HMAiT8uhKR9e1OD5ecFxT4moamFZ1P7ANLDtuyNZi6DpxGUxLx7QMLEthGHp1QhJIEmJ1Hwir7ydOSj6+17cfGKaOXf3sI6qvqT7iz7vvfcSfc5Ak1KFO7/tuisvcL3lUv0aBf3wnk2oaSfz7/y+K4rqktn/FcQLQqN4xF9c5+udsmDpEHPFdPKL8SsMwdAxDoekQBvG+HIbV7QZHrl/TSJKtaaq+xKprlAoOhV5n0NediAWLp/Lhq88elnW9E0nOx3Dp0pk8vb6NFza20rTgMBt7XmZPYS8As7IzOK9pKQsbmpmXn5PM0gNx8urqKOF7AaBRmwch8MM4aZV9nLLXt6Nq1WkSqjtv4AfVSj+u9GpJMAjiRBg/4kTpVHzKJZdKycOp+P2+NLGjTCwk3gX9GwG5XIowCtF1HU3XiMKISsWjUnLp7iiNqc+pVkEqQ8eyDOrqrLg3pzR8P8Tv3zBTOum0iTLiZBxFtco0biil0ma1wox7I3EvT0v24zCo9SLjdXrVRFzocfDc+Nr5uNGmyOZtTFMl+3tvVzluhFTVGi79Gy260rAsg0zOwrINDEPH88JqsvepVOJrq3U9Lr9p6knjxvMCwqCvd59KmxiWQlXXr2laX2NJq82pEf9S6/HWlnl7GU1LJYlEKS0uk+vjOXFDqNbQrPUU489DJZ9L0uj248ZhLXHFibN/Aoy3r5SOZSvMWixzKcolN+nZ+36IU/aoVHycipc0xvrvl0ppmKaRNLyIiMtZXah+kkEqZWCnTCzbwPeDI3ulhp4kUtD6NYriRrbvBwTVui+KIkxL76vzVNxIjh9xper7QdJI9vx4P6qU/aRBWJexmNKUJZOzyWStZNTCc+M61jQVVqraULdUHAsvwKvu5/1nuoM4Ob9bJDkfQ4/Xw/z37OVQ+8s8uddFQ+Pc+nNZlnoP6Uqe8m6PfVs9dpS3Uil7lIouhR4H13l3Z6GyUwapOpN8QzruAQG1JrOu9OQL3TcEFif3WiVZ09cS1pJeYF3aoqe3En9hghCiKK5ULIVV7eGF1Qqk1jpNpQ1SaZNUuvYl7asMPTfAMFXca0wZ2LZBUO3p1npHybBvrVBRRNivR69p1aGn6vuqVaya3lcRmdXymZZRrQiqUYni4c1ab8ypxGUyrb4yWbaRJJoonqIoGXnwq0lJq/Ugq71pTdP6VaZ9Ca7Wyz3WJWlRFOE6Qb9KI+7tW0kvMn4fcSj6ypSMFPTrjdcqsVpMjqU2OhKF8bo0GPGh5aEYbPj/7XGs7Q9iaMbSJZIjZbzvG5KcB9Fe7OBXf1rDm3v3YFbSzCqfgdHTSCN5AidkPQeBg0e8zrIVmZzNtJk5Mrm4lQ99U+MZSk+GMVNpE8NUyZzBVKckTJKooVcTUP9ehzaghRxF0YDjOSNhon2J416SwjAUdRnrHZbt+2IrQ8eyj7EwcIx5Nt5xO7WGwfEse5KbG7AuTdNAP/l1jYTjqVjHc+UrRtZ43zckOQO+H7C/tYd9rV1s2b6HrgMuKmhiLk0DlqsQMmduA9Nn5Jg8NUMmZ5NKm3HCTRlxsh1huo58akIIMcGdstV8qeCwa1sHu946zJ6dHQNOFglSDlPmpVg0Zw71jWnyDWk2tnbx4Jo3KYQBV31gPkqXa4+FEEKMjFMuOXe0F3npdzvYsfVQ8r9Uvc6hut10Zw8ya/Ykrj/3GialBt7P+YPTsrzR2s0f3zjIL9ft5JoVze920YUQQpwiTpnk3N1Z5uV1O9m66QAAU6fnmL94MpvUK7T0voilm1yz8KNcMuu9g98IXNP43BVnsGNfD//5+52cOa+RxfMaj1hOCCGEOFmnxNjsqy27+fn9L7F10wEmN2W48hNLuOja6fyaf6el90VmZWfwteVfZsXs9x1zqsy6lMn/vOpsNE3jX3+1id6S+y6+CyGEEKeKCZ+cN7+2jxef3U46Y3H5yrP45P+4gMO5Nu555f9woHSQy2ZfwlfP/19MzzS988qAhbPquWbFfLoKLt//99cpVbwRfgdCCCFONRM6Oe/efpjnn9qCnTL42HXnsvDMJrZ17+Qnf/45hmbwpaWf5xOLrhryfWSvfO883nv2NLbt7eHun2+gUJYELYQQYvhM2OS8r7WL3/7Hn9GVzkc+cQ6Nk+toLx3mX//0b4REfPGc6zlnylkntG5d0/jrj57FJUtnsGt/L3c9/Co9RRniFkIIMTwmZHLu6Srzs//7Ep4b8KGPncn02fWUvBI/fP0Bil6J6xZdw+JJp5/UNnRd4/NXLuay98yitb3AnQ+/QmevM0zvQAghxKlsQibnlrU7KPQ6XPKhhTSfMRU/9Ln/Tw9yoNTOf5u7gvfPumhYtqNrGv/9w4v48PI57Dtc4rYf/5GNOw4Py7qFEEKcuibkpVRLL5jNOe+ZxfQ58Z2h/nP7b9natY1zp5zN1Qs+Mqzb0jSNT/3FQhqyNr94fhv3PvIaH14+h49/YAGmMSHbPkIIIUbYhMwe02bmOee82QC4gcu6vS9Sb+X43NmfPualUidK0zSuuGgu3/js+UybVMdv/7iH7/zkZdoOFYd9W0IIISa+CZmc+3vl4OuU/QoXz7wQWx37Rgcn67TpeVZ9fjkrzp3B7oMFVj3wEo89+xYV9929S5UQQojxbcIn5xf2tqCh8b4Zy9+V7dmW4vNXnsn//vg5NGRtnmzZzTfub6HlzweSW+AJIYQQxzKhk/Pewn62d+9i8aTTmZye9K5u+z2nT2X1Fy/iqvefRm/J40e/3MS9j2ygqyBndAshhDi2CZ2cf7/3JQAumTk8Z2cPlW0qrr60mdV/fSHnNE9m085Ovv3AS2zcLmd0CyGEOLoJm5xd36Vl/3pyVvaEJxsZLk2Nddz4yaV8+kOnU3Z87n30NR579i38IHznFwshhDjlTMhLqQBebH2Vkl/mw/MuQ+lqtIuDpmlcfsEcFs1u4IdPbOTJlt28vu0w7ztnOssXNzGlPj3aRRRCCDFGTNjk/PT2dQC8f+aFo1ySgeZNz/Htzy/nZ2ve5Pcb9/PYs9t47NltLJiZ571nT+fSpTOwzNFvTAghhBg9EzI57y8eZHP7WyxuPJ0p6cmjXZwjpG2DL3z0TD552QJe2drOH984yOZdnWzbG98r+qMXz+MDy2bJJCZCCHGKmpDJuXYi2HBN0zlScnUWH1g2iw8sm0V30WXNy3tY83IrD695kydbdvOR985j+eIm8pmRvT5bCCHE2DIhk7MXeszMTWPpKJ8INhT1GYuPf2ABly+fw1Mv7uaZV1p56L+28vB/baV5Zp6lC6ewtHkys5syKF161EIIMZFp0RiZGaO9vXfY1hVFEU1N+WFd57utu+Dwh00HeO2tQ7zZ2k1Y/ZgsQ2dOU5Z503OcNj3P4nkNI3oy2dSpuXEdx7FC4jg8JI7DQ+I4PE42jlOn5o763ITsOWuaNtpFOGn1WZsrLprLFRfNpVjx2Li9gz/v7GDX/l527u9l294eoA2AaZPqWHLaJM6eP4m507I05Gz0CRADIYQ4VU3I5DzRZFImF501jYvOmgaA5we0thfZ1tbNn3d2snl3J0+/0srTr7QCce+6qbGO6ZPSzJySYeaUDLOmZpnWmMZQMiQuhBBjnSTnccg0FPNn5Jk/I8+HLpiDH4Rsa+vmjd1d7DtcZH9HiQMdZVrbC7ClPXmdoTTmTstxxtwGzpjTyOmz60nbsgsIIcRYIzXzBGAonTPmNnLG3Mbkf1EU0VVwaTtUoK29SNuhIq0HC+zc18v2vT08+eJuNA2yaZPaWQdRFNHUmObSpTO56KxpkriFEGKUSO07QWmaRmPOpjFns2R+37XeFdfnrbZutuzuYsueLoplL1keYNf+Ajv2beGRZ97iorOauPjcWRzuKOK4AY4X4r1tytGUqWiemWfe9JwMmQshxDCR5HyKSVkGS+ZPHpCw++vsdVj3+l7WvrYveRwP09Bprg61p2yFqXQMpWOaOvUZK24oZG1yGUtOVhNCiHcgyVkM0Jiz+dj75/PRi0/jzzs76HECfNfHMnVSpoFhaGj0Jdfekstbbd282drN1j1xb/xYlK6Rtg3qbIO0bZC2Fdm0SbbOin+mTaY2pJgzNcvk+tSgZ96HUYTnh3h+iOsFGIZOLm1OiLP0hRACJDmLo9B1jSXNk4/rOr73nj0dgFLFp+1QAdcP8f0QP4hwvYCuokNnb/zoKjiUKj4lx6er6OB6R78zV8pSzJqawTIUxbJHseJRqPg4bnDEsmnboKkxzbTGNJNyKZTSULqGrmuYSiedMsikTDLVn7m6uCEg85gLIcYiSc5i2NSlDE6f3TCk1/hBSLHiUyh7FEouvSWP/R0lWtsLtLYX2bG3lzCKsC1FNmUyrTFN2jKwTIVlxMPmjhtwsLNMW3uRXfuHNiGAbcY994acRWPWpiFnU5+xqLgBvdXyFMoelqnIVXv22bRJJm1Sl4pHADIpE02L34sXhPh+RBRFaJqGpsXH85u6HTzHi1+bMobcKKitbzCeH1B2AupShhz3F2KCkOQsRpWh4mPS9RkLyBzxvB+ERBHHdROQMIro7HHoLroEYUgYRgRhhOuHlCs+hYpHqeJTLMcJt7fsUSh59JRcduztZVvUM+h6NWC4p9GzDJ1sXV+yT1sGYRSXNwgjfD9utJQcj2J1tMBQOilLYZs6pqGouD6lio/rh0k581mLKfkUk/Ip0raBqXSU0jANHU2DY80HqHSNTLpvdKEuZWCbipRtkLIUaUthGkc2KqIoouIGFMteEqdaMyIII/wwIghCwigibRlJw6Z27oHnhxTKHsWyh2nqTMrZg25HiFOJJGcxpg2lJ6hrGpPrU0yuTw15O2EY0Vty6Sw49BRdUpZBrs4kV2dRlzLw/LAvqZfiIfaSEyfHYsWDKC6rYeiYqi8RRkREEShTcehwiUIlTkK91WR0oLPM7gOFQcuUthV1tsm0hjQpS+EFEY4X4LgBpYpHyjJomGKTSRmkbINi2eNQd6XfDHLDz1A6dbYinTIxlU6x4tFbcvGDoTVfNC2eXMcLwkEPU+QzFpPzNnUpE6XHhyiU0qlLm7iuj4aGrsWNJj+ID6H41SsJ6vodwkhZRhKzihfg+yHZOpOGjEV91iZfZ+IFERXXp+IGVNwgadiFEUTVxp3jBThegOsF6JqGZSpsU2GZejzykrVpyFo05Gw0oKPH4XBPhY5eB88PaMylmJSzmZRPka8z0fT4zI1kdKUvMkC/cyr8ED8ISdsG2bRJylJomkYURZSdgELZpbfsEYWglIauxbGqeAGF6qhPoeyhdC0ZFWrI2aQzNhXXx1A6StcIwigZwSqWPYIgJF+NUSZloGkajhtwqKfCoa4yXQWn+jn2bbM+azE5n2JS/sQbV1G1gRqGUXxYzA9wq+eW6NUrUIZyiafjBvSW4xGwsuPTkLWZ2pAaF42/EUvOYRiyatUqtmzZgmVZrF69mnnz5o3U5oQ4KbquUZ+1qc/agz5vVyvjSfmhJ3449hy8nh9Scf3kGHmcjHR0/cROcAvDiO6iS8X1k6Tl+X3H9uNkcOS6PT+gWG1s1M4LiBNW9afjU3ICyk78XI8fkEmZzGnKkaszyaRMdJ1kmCGCJKkqPa7Ey64/oHFiqr4RhEzaxHWDJKntOVhMEq6I6ZpG2lY4XjDkBtGJMpSGbSqKFf+4X5Ori0eDTFOPDz8ZKm5M9ds3aodjyo5P2fXx/PCYIzs1KUvRmLPJ1VmYqm//ApLGcrE6Qub6R+4/GtCQs5nakEbpWtK4C6qHpVwvvmzU9eNGo9Lj9RtK44PLZnHVJfOPOw4nY8SS85o1a3Bdl0ceeYQNGzZwxx138MMf/nCkNifEuGUaOqYxfLcF1fW4hwGDNzTGiyiK+irO6nB/Y2Mdhw4V4lGJak1uGPFle4bSiCIoO9UeYPVwgG3q2FY8NK+URm/Jo7vg0FVw6S25mIZOqvp8yjKSHqiux8nQMuIectxTVkRRVO1Fxz3qQtmjqxCf7NjZ60AEjfkUk/NxT9lUOp29Dh29caOjt+TFZY9IbmgTv9++924ataSmo5ROxfGTnm3J8bFNVR3ZMcmlLXRdSw7jBGEYn0tRZ5JNxQ2fIIzoLDh0F1w6ex1CoFT2CMKQIIiSCYky1cMsStfoKbp0F126CnFD77TpOSbXp5lSn6KxOn9/GMUjQ34Q0lWojhb0OHT0OjhunChdf2DjsP97TNsGaUvRkLOxDD1poOqahqF0LFPHMhSmqRMEURLjzl6HfYdLg+43dbZBJm0wY0qmGp94BCxlKTp6Hdo7yxzsKrO1emWJBnGCVxq2oWOZinzGig8FQXX/q8bpBBvMJ2LEkvP69eu59NJLAVi2bBkbN24cqU0JISYgTdMwDYXZr5aaXJ8mdI/dg0vbxjFHOKY1HvWpU8a7fVeq/jc/HK5LHmtD4H4QEoRxI6HONo57xMkPQjQtboCNxcswRyw5FwoFstls8rdSCt/3MYzBN9nYWIcxzMcBjnU7LnH8JI7DQ+I4PCSOw0PiODxGKo4jlpyz2SzFYjH5OwzDoyZmgM7OwYcoTpTcr3R4SByHh8RxeEgch4fEcXiM5P2cR+yiyPPOO4+1a9cCsGHDBhYtWjRSmxJCCCEmlBHrOV9++eW88MILXHfddURRxHe/+92R2pQQQggxoYxYctZ1ndtuu22kVi+EEEJMWDLXnxBCCDHGSHIWQgghxhhJzkIIIcQYI8lZCCGEGGMkOQshhBBjjCRnIYQQYoyR5CyEEEKMMVoUHc9NuoQQQgjxbpGesxBCCDHGSHIWQgghxhhJzkIIIcQYI8lZCCGEGGMkOQshhBBjjCRnIYQQYowZsVtGjpYwDFm1ahVbtmzBsixWr17NvHnzRrtY44Lnedx88820tbXhui5/+7d/y8KFC/n617+OpmmcfvrpfPvb30bXpU13PA4fPsy1117LAw88gGEYEscT8KMf/YhnnnkGz/P49Kc/zYUXXihxHCLP8/j6179OW1sbuq5z++23y/44RK+99hr33HMPDz74ILt27Ro0dv/yL//Cc889h2EY3HzzzSxduvSktjnhPo01a9bgui6PPPIIX/nKV7jjjjtGu0jjxi9/+UsaGhp4+OGHuf/++7n99tv5p3/6J2688UYefvhhoiji6aefHu1ijgue53HLLbeQSqUAJI4noKWlhVdffZWf/exnPPjgg+zfv1/ieAKef/55fN/n5z//OTfccAP//M//LHEcgvvvv59vfvObOI4DDP5d3rRpEy+99BKPPfYY9957L7feeutJb3fCJef169dz6aWXArBs2TI2btw4yiUaP6644gq+/OUvJ38rpdi0aRMXXnghACtWrOD3v//9aBVvXLnzzju57rrraGpqApA4noB169axaNEibrjhBr70pS/xwQ9+UOJ4AubPn08QBIRhSKFQwDAMieMQzJ07lx/84AfJ34PFbv369VxyySVomsbMmTMJgoCOjo6T2u6ES86FQoFsNpv8rZTC9/1RLNH4kclkyGazFAoF/u7v/o4bb7yRKIrQNC15vre3d5RLOfY9/vjjTJo0KWkkAhLHE9DZ2cnGjRv53ve+x6233so//uM/ShxPQF1dHW1tbVx55ZV861vf4vrrr5c4DsFf/uVfYhh9R4AHi93b885wxHTCHXPOZrMUi8Xk7zAMBwRWHNu+ffu44YYb+MxnPsPHPvYx7r777uS5YrFIPp8fxdKND7/4xS/QNI0//OEPbN68ma997WsDWtESx+PT0NBAc3MzlmXR3NyMbdvs378/eV7ieHx+/OMfc8kll/CVr3yFffv28bnPfQ7P85LnJY5D0//YfC12b887xWKRXC53cts5qVePQeeddx5r164FYMOGDSxatGiUSzR+HDp0iC984Qt89atf5ROf+AQAZ511Fi0tLQCsXbuWCy64YDSLOC489NBD/PSnP+XBBx/kzDPP5M4772TFihUSxyE6//zz+d3vfkcURRw4cIByuczFF18scRyifD6fJIr6+noZbfFRAAAEJElEQVR835fv9UkYLHbnnXce69atIwxD9u7dSxiGTJo06aS2M+FufFE7W3vr1q1EUcR3v/tdFixYMNrFGhdWr17Nk08+SXNzc/K/b3zjG6xevRrP82hubmb16tUopUaxlOPL9ddfz6pVq9B1nW9961sSxyG66667aGlpIYoi/v7v/57Zs2dLHIeoWCxy8803097ejud5fPazn2XJkiUSxyFobW3lH/7hH3j00UfZsWPHoLH7wQ9+wNq1awnDkJtuuumkGzwTLjkLIYQQ492EG9YWQgghxjtJzkIIIcQYI8lZCCGEGGMkOQshhBBjjCRnIYQQYoyR5CzEONPa2sqSJUtYuXLlgMdDDz00bNtoaWnh+uuvP65lr7vuOsrlMs899xz33XffsJVBiFOZTJ0lxDjU1NTEE088MdrFoFwuo2ka6XSaV155hfPPP3+0iyTEhCDJWYgJ5uKLL+byyy/n1VdfJZPJcM899zB79mw2bNjAd77zHRzHobGxkdtuu4158+axefNmbrnlFiqVCvX19dxzzz0AdHR08MUvfpHdu3czf/58vv/972NZVrKdm266iZaWFlzXZeXKlezcuZPnn3+eJUuWMHny5NF6+0JMDJEQYlzZs2dPdPbZZ0dXXXXVgMcbb7wRRVEULVq0KHr88cejKIqin/zkJ9Hf/M3fRI7jRJdddln02muvRVEURb/5zW+ia6+9NoqiKPrIRz4SPfPMM1EURdFDDz0U3XHHHdGLL74YLVu2LNq9e3cUBEH08Y9/PHr22WePKMtPf/rT6NFHH42iKIpWrlw50m9diFOG9JyFGIeONaxt2zZXX301ANdccw333nsvO3fuJJ/PJzeAv/LKK7nllltoa2ujvb2dyy67DIDPfOYzQHzMefHixcyZMweABQsW0NnZecS23nzzTa699loOHjzI1KlTh/19CnGqkuQsxASj63pyS7swDFFKEYbhEctF1Zl7a8sCOI7DwYMHAQbczU3TtGT5mptuuomnnnqK9evXUy6XKZVKrFy5kgceeECGtYU4SXK2thATTLlc5plnngHie0uvWLGC5uZmurq6eP311wH4zW9+w8yZM5k1axbTpk1j3bp1ADzxxBN873vfO67t3HrrrSxcuJBf/epXXH311dx666088cQTkpiFGAbScxZiHDp48CArV64c8L/ly5fzzW9+E4CnnnqK++67j6amJu68804sy+K+++7j9ttvp1wuU19fn1z2dPfdd7Nq1SruvvtuGhsbueuuu9ixY8c7lmHz5s2ceeaZQHx71k996lPD/C6FOHXJXamEmGDOOOMMtmzZMtrFEEKcBBnWFkIIIcYY6TkLIYQQY4z0nIUQQogxRpKzEEIIMcZIchZCCCHGGEnOQgghxBgjyVkIIYQYYyQ5CyGEEGPM/wdECJ0L7Me6RQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = np.arange(0, len(history.history['loss']))\n",
    "\n",
    "# You can chose the style of your preference\n",
    "# print(plt.style.available) to see the available options\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "plt.figure()\n",
    "plt.plot(N, history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(N, history.history['accuracy'], label = \"train_acc\")\n",
    "plt.plot(N, history.history['val_loss'], label = \"val_loss\")\n",
    "plt.plot(N, history.history['val_accuracy'], label = \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# Make sure there exists a folder called output in the current directory\n",
    "# or replace 'output' with whatever direcory you want to put in the plots\n",
    "plt.show()\n",
    "plt.savefig('../Output/EpochResNet101V2.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
