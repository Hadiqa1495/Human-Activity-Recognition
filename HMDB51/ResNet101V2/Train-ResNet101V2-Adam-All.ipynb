{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet_v2 import ResNet101V2\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24136</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24137</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24138</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24139</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24140</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image class\n",
       "24136  winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg  wave\n",
       "24137  winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg  wave\n",
       "24138  winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg  wave\n",
       "24139  winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg  wave\n",
       "24140  winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg  wave"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_2.csv')\n",
    "train.sort_values(by=['class', 'image'])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24141/24141 [01:28<00:00, 272.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/train_frame/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24141, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X = np.array(train_image,np.float16)\n",
    "train_image=[]\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 224, 224, 3)\n",
      "(4829, 224, 224, 3)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained ResNet101V2 model\n",
    "base_model = ResNet101V2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet101v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, None, None, 6 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, None, None, 6 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, None, None, 2 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, None, None, 2 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, None, None, 2 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, None, None, 2 0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, None, None, 2 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, None, None, 5 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, None, None, 5 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, None, None, 5 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, None, None, 5 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, None, None, 5 0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, None, None, 5 0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, None, None, 1 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, None, None, 1 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, None, None, 1 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, None, None, 1 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, None, None, 1 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, None, None, 1 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, None, None, 1 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block7_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, None, None, 2 0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, None, None, 2 0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, None, None, 1 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, None, None, 1 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, None, None, 2 0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, None, None, 2 0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, None, None, 1 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, None, None, 1 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, None, None, 2 0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, None, None, 2 0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, None, None, 1 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, None, None, 1 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, None, None, 1 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, None, None, 2 0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, None, None, 2 0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, None, None, 1 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, None, None, 1 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, None, None, 1 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, None, None, 2 0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, None, None, 2 0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, None, None, 1 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, None, None, 1 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, None, None, 1 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, None, None, 2 0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, None, None, 2 0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, None, None, 1 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, None, None, 1 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, None, None, 1 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, None, None, 2 0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, None, None, 2 0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, None, None, 1 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, None, None, 1 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, None, None, 1 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, None, None, 2 0           conv4_block14_1_bn[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, None, None, 2 0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, None, None, 1 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, None, None, 1 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, None, None, 1 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, None, None, 2 0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, None, None, 2 0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, None, None, 1 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, None, None, 1 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, None, None, 1 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, None, None, 2 0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, None, None, 2 0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, None, None, 1 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, None, None, 1 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, None, None, 1 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, None, None, 2 0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, None, None, 2 0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, None, None, 1 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, None, None, 1 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, None, None, 1 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, None, None, 2 0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, None, None, 2 0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, None, None, 1 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, None, None, 1 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, None, None, 1 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, None, None, 2 0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, None, None, 2 0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, None, None, 1 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, None, None, 1 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, None, None, 1 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, None, None, 2 0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, None, None, 2 0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, None, None, 1 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, None, None, 1 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, None, None, 1 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, None, None, 2 0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block21_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, None, None, 2 0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, None, None, 1 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, None, None, 1 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, None, None, 1 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, None, None, 2 0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, None, None, 2 0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, None, None, 1 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, None, None, 1 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, None, None, 1 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, None, None, 2 0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, None, None, 2 0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, None, None, 1 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, None, None, 1 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, None, None, 2 0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, None, None, 2 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, None, None, 2 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, None, None, 2 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, None, None, 2 0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 42,626,560\n",
      "Trainable params: 42,528,896\n",
      "Non-trainable params: 97,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'resnet101v2',\n",
       " 'layers': [{'name': 'input_1',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_1'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'conv1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((3, 3), (3, 3)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (7, 7),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'pool1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pool',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'pool1_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool1_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_0_conv', 0, 0, {}],\n",
       "     ['conv2_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}],\n",
       "     ['conv2_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_1',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_1', 0, 0, {}],\n",
       "     ['conv2_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_0_conv', 0, 0, {}],\n",
       "     ['conv3_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}],\n",
       "     ['conv3_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}],\n",
       "     ['conv3_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_2',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}],\n",
       "     ['conv3_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_0_conv', 0, 0, {}],\n",
       "     ['conv4_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}],\n",
       "     ['conv4_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}],\n",
       "     ['conv4_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}],\n",
       "     ['conv4_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block5_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block5_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}],\n",
       "     ['conv4_block5_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block6_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block6_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}],\n",
       "     ['conv4_block6_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block7_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block7_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}],\n",
       "     ['conv4_block7_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block8_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block8_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}],\n",
       "     ['conv4_block8_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block9_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block9_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}],\n",
       "     ['conv4_block9_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block10_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block10_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}],\n",
       "     ['conv4_block10_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block11_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block11_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}],\n",
       "     ['conv4_block11_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block12_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block12_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}],\n",
       "     ['conv4_block12_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block13_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block13_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}],\n",
       "     ['conv4_block13_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block14_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block14_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}],\n",
       "     ['conv4_block14_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block15_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block15_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}],\n",
       "     ['conv4_block15_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block16_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block16_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}],\n",
       "     ['conv4_block16_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block17_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block17_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}],\n",
       "     ['conv4_block17_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block18_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block18_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}],\n",
       "     ['conv4_block18_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block19_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block19_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}],\n",
       "     ['conv4_block19_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block20_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block20_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}],\n",
       "     ['conv4_block20_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block21_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block21_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}],\n",
       "     ['conv4_block21_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block22_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block22_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}],\n",
       "     ['conv4_block22_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block23_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_3',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block23_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_3', 0, 0, {}],\n",
       "     ['conv4_block23_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_0_conv', 0, 0, {}],\n",
       "     ['conv5_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}],\n",
       "     ['conv5_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}],\n",
       "     ['conv5_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'post_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'post_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'post_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'post_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['post_bn', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['post_relu', 0, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-05 12:39:04.085352\n",
      "(19312, 7, 7, 2048)\n",
      "2020-12-05 14:55:09.005110\n"
     ]
    }
   ],
   "source": [
    "t1=datetime.datetime.now()\n",
    "print(t1)\n",
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "print(X_train.shape)\n",
    "t2=datetime.datetime.now()\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(19312, 7*7*2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Pickle/ResNet101V2_X_train_2.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(X_train, '../Pickle/ResNet101V2_X_train_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-05 14:59:10.773945\n",
      "(4829, 7, 7, 2048)\n",
      "2020-12-05 15:26:38.191673\n"
     ]
    }
   ],
   "source": [
    "t3=datetime.datetime.now()\n",
    "print(t3)\n",
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "print(X_test.shape)\n",
    "t4=datetime.datetime.now()\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(4829, 7*7*2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Pickle/ResNet101V2_X_test_2.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_test, '../Pickle/ResNet101V2_X_test_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "X_train = joblib.load('../Pickle/ResNet101V2_X_train_2.pkl') \n",
    "X_test = joblib.load('../Pickle/ResNet101V2_X_test_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 100352)\n",
      "(4829, 100352)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "# shape of images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 51)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 51)                52275     \n",
      "=================================================================\n",
      "Total params: 102,813,747\n",
      "Trainable params: 102,813,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('../Models/weightResNet101V2_2.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-05 15:27:18.623719\n",
      "Train on 19312 samples, validate on 4829 samples\n",
      "Epoch 1/100\n",
      "19312/19312 [==============================] - ETA: 16:21 - loss: 9.8939 - accuracy: 0.0000e+0 - ETA: 10:51 - loss: 33.3630 - accuracy: 0.0312  - ETA: 8:26 - loss: 44.8409 - accuracy: 0.0573 - ETA: 7:07 - loss: 49.0334 - accuracy: 0.064 - ETA: 6:16 - loss: 50.9918 - accuracy: 0.075 - ETA: 5:41 - loss: 53.4734 - accuracy: 0.076 - ETA: 5:17 - loss: 52.3094 - accuracy: 0.080 - ETA: 5:00 - loss: 51.0517 - accuracy: 0.084 - ETA: 4:47 - loss: 48.9830 - accuracy: 0.101 - ETA: 4:35 - loss: 46.5813 - accuracy: 0.113 - ETA: 4:27 - loss: 44.1164 - accuracy: 0.124 - ETA: 4:19 - loss: 41.5062 - accuracy: 0.142 - ETA: 4:12 - loss: 39.3829 - accuracy: 0.145 - ETA: 4:05 - loss: 37.1912 - accuracy: 0.153 - ETA: 3:59 - loss: 35.1382 - accuracy: 0.167 - ETA: 3:53 - loss: 33.2913 - accuracy: 0.170 - ETA: 3:48 - loss: 31.6173 - accuracy: 0.172 - ETA: 3:43 - loss: 30.0674 - accuracy: 0.175 - ETA: 3:40 - loss: 28.6948 - accuracy: 0.176 - ETA: 3:36 - loss: 27.4737 - accuracy: 0.174 - ETA: 3:32 - loss: 26.3304 - accuracy: 0.176 - ETA: 3:32 - loss: 25.2976 - accuracy: 0.174 - ETA: 3:29 - loss: 24.3484 - accuracy: 0.175 - ETA: 3:26 - loss: 23.4828 - accuracy: 0.176 - ETA: 3:22 - loss: 22.6892 - accuracy: 0.175 - ETA: 3:19 - loss: 21.9553 - accuracy: 0.174 - ETA: 3:16 - loss: 21.2731 - accuracy: 0.174 - ETA: 3:14 - loss: 20.6309 - accuracy: 0.177 - ETA: 3:11 - loss: 20.0352 - accuracy: 0.176 - ETA: 3:09 - loss: 19.4723 - accuracy: 0.179 - ETA: 3:07 - loss: 18.9501 - accuracy: 0.180 - ETA: 3:04 - loss: 18.4667 - accuracy: 0.180 - ETA: 3:01 - loss: 18.0034 - accuracy: 0.181 - ETA: 2:59 - loss: 17.5780 - accuracy: 0.180 - ETA: 2:56 - loss: 17.1757 - accuracy: 0.178 - ETA: 2:54 - loss: 16.7907 - accuracy: 0.178 - ETA: 2:51 - loss: 16.4244 - accuracy: 0.179 - ETA: 2:49 - loss: 16.0770 - accuracy: 0.180 - ETA: 2:47 - loss: 15.7534 - accuracy: 0.180 - ETA: 2:44 - loss: 15.4381 - accuracy: 0.181 - ETA: 2:42 - loss: 15.1435 - accuracy: 0.181 - ETA: 2:40 - loss: 14.8589 - accuracy: 0.181 - ETA: 2:38 - loss: 14.5893 - accuracy: 0.182 - ETA: 2:36 - loss: 14.3356 - accuracy: 0.182 - ETA: 2:34 - loss: 14.0909 - accuracy: 0.182 - ETA: 2:32 - loss: 13.8516 - accuracy: 0.183 - ETA: 2:30 - loss: 13.6191 - accuracy: 0.186 - ETA: 2:28 - loss: 13.4002 - accuracy: 0.186 - ETA: 2:27 - loss: 13.1954 - accuracy: 0.187 - ETA: 2:25 - loss: 12.9918 - accuracy: 0.188 - ETA: 2:23 - loss: 12.7987 - accuracy: 0.189 - ETA: 2:21 - loss: 12.6104 - accuracy: 0.191 - ETA: 2:19 - loss: 12.4319 - accuracy: 0.191 - ETA: 2:17 - loss: 12.2603 - accuracy: 0.194 - ETA: 2:16 - loss: 12.0889 - accuracy: 0.196 - ETA: 2:14 - loss: 11.9225 - accuracy: 0.197 - ETA: 2:12 - loss: 11.7671 - accuracy: 0.198 - ETA: 2:11 - loss: 11.6114 - accuracy: 0.202 - ETA: 2:09 - loss: 11.4629 - accuracy: 0.203 - ETA: 2:07 - loss: 11.3193 - accuracy: 0.205 - ETA: 2:06 - loss: 11.1786 - accuracy: 0.207 - ETA: 2:04 - loss: 11.0479 - accuracy: 0.208 - ETA: 2:02 - loss: 10.9176 - accuracy: 0.210 - ETA: 2:01 - loss: 10.7948 - accuracy: 0.211 - ETA: 1:59 - loss: 10.6768 - accuracy: 0.212 - ETA: 1:57 - loss: 10.5579 - accuracy: 0.213 - ETA: 1:56 - loss: 10.4467 - accuracy: 0.213 - ETA: 1:54 - loss: 10.3367 - accuracy: 0.214 - ETA: 1:52 - loss: 10.2312 - accuracy: 0.215 - ETA: 1:51 - loss: 10.1284 - accuracy: 0.217 - ETA: 1:49 - loss: 10.0264 - accuracy: 0.218 - ETA: 1:48 - loss: 9.9255 - accuracy: 0.219 - ETA: 1:46 - loss: 9.8283 - accuracy: 0.22 - ETA: 1:45 - loss: 9.7356 - accuracy: 0.22 - ETA: 1:43 - loss: 9.6432 - accuracy: 0.22 - ETA: 1:42 - loss: 9.5578 - accuracy: 0.22 - ETA: 1:40 - loss: 9.4717 - accuracy: 0.22 - ETA: 1:38 - loss: 9.3889 - accuracy: 0.22 - ETA: 1:37 - loss: 9.3034 - accuracy: 0.22 - ETA: 1:35 - loss: 9.2232 - accuracy: 0.23 - ETA: 1:34 - loss: 9.1438 - accuracy: 0.23 - ETA: 1:32 - loss: 9.0671 - accuracy: 0.23 - ETA: 1:31 - loss: 8.9916 - accuracy: 0.23 - ETA: 1:29 - loss: 8.9175 - accuracy: 0.23 - ETA: 1:28 - loss: 8.8447 - accuracy: 0.23 - ETA: 1:26 - loss: 8.7759 - accuracy: 0.23 - ETA: 1:25 - loss: 8.7067 - accuracy: 0.23 - ETA: 1:24 - loss: 8.6427 - accuracy: 0.24 - ETA: 1:22 - loss: 8.5780 - accuracy: 0.24 - ETA: 1:21 - loss: 8.5109 - accuracy: 0.24 - ETA: 1:19 - loss: 8.4492 - accuracy: 0.24 - ETA: 1:18 - loss: 8.3883 - accuracy: 0.24 - ETA: 1:16 - loss: 8.3300 - accuracy: 0.24 - ETA: 1:15 - loss: 8.2713 - accuracy: 0.24 - ETA: 1:14 - loss: 8.2122 - accuracy: 0.24 - ETA: 1:12 - loss: 8.1587 - accuracy: 0.24 - ETA: 1:11 - loss: 8.1026 - accuracy: 0.24 - ETA: 1:09 - loss: 8.0521 - accuracy: 0.24 - ETA: 1:08 - loss: 7.9962 - accuracy: 0.25 - ETA: 1:07 - loss: 7.9427 - accuracy: 0.25 - ETA: 1:05 - loss: 7.8889 - accuracy: 0.25 - ETA: 1:04 - loss: 7.8393 - accuracy: 0.25 - ETA: 1:02 - loss: 7.7896 - accuracy: 0.25 - ETA: 1:01 - loss: 7.7400 - accuracy: 0.25 - ETA: 1:00 - loss: 7.6903 - accuracy: 0.25 - ETA: 58s - loss: 7.6450 - accuracy: 0.2588 - ETA: 57s - loss: 7.5985 - accuracy: 0.260 - ETA: 56s - loss: 7.5567 - accuracy: 0.260 - ETA: 54s - loss: 7.5122 - accuracy: 0.261 - ETA: 53s - loss: 7.4726 - accuracy: 0.262 - ETA: 51s - loss: 7.4280 - accuracy: 0.263 - ETA: 50s - loss: 7.3857 - accuracy: 0.264 - ETA: 49s - loss: 7.3443 - accuracy: 0.265 - ETA: 48s - loss: 7.3063 - accuracy: 0.266 - ETA: 46s - loss: 7.2674 - accuracy: 0.266 - ETA: 45s - loss: 7.2311 - accuracy: 0.267 - ETA: 43s - loss: 7.1971 - accuracy: 0.267 - ETA: 42s - loss: 7.1601 - accuracy: 0.268 - ETA: 41s - loss: 7.1233 - accuracy: 0.269 - ETA: 39s - loss: 7.0844 - accuracy: 0.270 - ETA: 38s - loss: 7.0490 - accuracy: 0.271 - ETA: 37s - loss: 7.0126 - accuracy: 0.272 - ETA: 36s - loss: 6.9776 - accuracy: 0.272 - ETA: 34s - loss: 6.9426 - accuracy: 0.273 - ETA: 33s - loss: 6.9095 - accuracy: 0.273 - ETA: 32s - loss: 6.8752 - accuracy: 0.274 - ETA: 30s - loss: 6.8411 - accuracy: 0.275 - ETA: 29s - loss: 6.8080 - accuracy: 0.275 - ETA: 28s - loss: 6.7755 - accuracy: 0.276 - ETA: 26s - loss: 6.7431 - accuracy: 0.277 - ETA: 25s - loss: 6.7108 - accuracy: 0.278 - ETA: 24s - loss: 6.6786 - accuracy: 0.279 - ETA: 22s - loss: 6.6467 - accuracy: 0.280 - ETA: 21s - loss: 6.6134 - accuracy: 0.281 - ETA: 20s - loss: 6.5845 - accuracy: 0.282 - ETA: 19s - loss: 6.5534 - accuracy: 0.283 - ETA: 17s - loss: 6.5227 - accuracy: 0.284 - ETA: 16s - loss: 6.4954 - accuracy: 0.285 - ETA: 15s - loss: 6.4670 - accuracy: 0.285 - ETA: 13s - loss: 6.4386 - accuracy: 0.286 - ETA: 12s - loss: 6.4108 - accuracy: 0.287 - ETA: 11s - loss: 6.3845 - accuracy: 0.287 - ETA: 10s - loss: 6.3572 - accuracy: 0.288 - ETA: 8s - loss: 6.3317 - accuracy: 0.288 - ETA: 7s - loss: 6.3064 - accuracy: 0.28 - ETA: 6s - loss: 6.2799 - accuracy: 0.28 - ETA: 4s - loss: 6.2555 - accuracy: 0.29 - ETA: 3s - loss: 6.2312 - accuracy: 0.29 - ETA: 2s - loss: 6.2044 - accuracy: 0.29 - ETA: 1s - loss: 6.1814 - accuracy: 0.29 - 210s 11ms/step - loss: 6.1594 - accuracy: 0.2927 - val_loss: 1.9942 - val_accuracy: 0.5204\n",
      "Epoch 2/100\n",
      "19312/19312 [==============================] - ETA: 3:09 - loss: 2.4719 - accuracy: 0.39 - ETA: 2:56 - loss: 2.3577 - accuracy: 0.42 - ETA: 2:50 - loss: 2.3722 - accuracy: 0.42 - ETA: 2:46 - loss: 2.3641 - accuracy: 0.43 - ETA: 2:47 - loss: 2.3499 - accuracy: 0.42 - ETA: 2:45 - loss: 2.3470 - accuracy: 0.42 - ETA: 2:43 - loss: 2.2799 - accuracy: 0.43 - ETA: 2:41 - loss: 2.3460 - accuracy: 0.43 - ETA: 2:39 - loss: 2.3297 - accuracy: 0.43 - ETA: 2:37 - loss: 2.3142 - accuracy: 0.43 - ETA: 2:35 - loss: 2.3006 - accuracy: 0.43 - ETA: 2:33 - loss: 2.3112 - accuracy: 0.43 - ETA: 2:32 - loss: 2.2867 - accuracy: 0.43 - ETA: 2:31 - loss: 2.2500 - accuracy: 0.44 - ETA: 2:30 - loss: 2.2493 - accuracy: 0.44 - ETA: 2:28 - loss: 2.2644 - accuracy: 0.44 - ETA: 2:27 - loss: 2.2695 - accuracy: 0.44 - ETA: 2:26 - loss: 2.2700 - accuracy: 0.44 - ETA: 2:26 - loss: 2.2676 - accuracy: 0.44 - ETA: 2:25 - loss: 2.2714 - accuracy: 0.44 - ETA: 2:24 - loss: 2.2456 - accuracy: 0.44 - ETA: 2:23 - loss: 2.2363 - accuracy: 0.44 - ETA: 2:21 - loss: 2.2343 - accuracy: 0.45 - ETA: 2:20 - loss: 2.2255 - accuracy: 0.44 - ETA: 2:19 - loss: 2.2208 - accuracy: 0.45 - ETA: 2:18 - loss: 2.2247 - accuracy: 0.45 - ETA: 2:17 - loss: 2.2293 - accuracy: 0.44 - ETA: 2:16 - loss: 2.2189 - accuracy: 0.45 - ETA: 2:15 - loss: 2.2209 - accuracy: 0.45 - ETA: 2:14 - loss: 2.2220 - accuracy: 0.45 - ETA: 2:13 - loss: 2.2226 - accuracy: 0.45 - ETA: 2:11 - loss: 2.2327 - accuracy: 0.45 - ETA: 2:10 - loss: 2.2384 - accuracy: 0.44 - ETA: 2:10 - loss: 2.2336 - accuracy: 0.45 - ETA: 2:09 - loss: 2.2175 - accuracy: 0.45 - ETA: 2:07 - loss: 2.2144 - accuracy: 0.45 - ETA: 2:06 - loss: 2.2187 - accuracy: 0.45 - ETA: 2:05 - loss: 2.2174 - accuracy: 0.45 - ETA: 2:04 - loss: 2.2133 - accuracy: 0.45 - ETA: 2:03 - loss: 2.2021 - accuracy: 0.45 - ETA: 2:02 - loss: 2.2014 - accuracy: 0.46 - ETA: 2:01 - loss: 2.2024 - accuracy: 0.46 - ETA: 1:59 - loss: 2.2067 - accuracy: 0.46 - ETA: 1:58 - loss: 2.2024 - accuracy: 0.46 - ETA: 1:57 - loss: 2.1946 - accuracy: 0.46 - ETA: 1:56 - loss: 2.1943 - accuracy: 0.46 - ETA: 1:55 - loss: 2.1973 - accuracy: 0.46 - ETA: 1:54 - loss: 2.1934 - accuracy: 0.46 - ETA: 1:53 - loss: 2.1944 - accuracy: 0.46 - ETA: 1:52 - loss: 2.1942 - accuracy: 0.46 - ETA: 1:51 - loss: 2.1966 - accuracy: 0.46 - ETA: 1:50 - loss: 2.1989 - accuracy: 0.46 - ETA: 1:49 - loss: 2.2009 - accuracy: 0.46 - ETA: 1:48 - loss: 2.2027 - accuracy: 0.46 - ETA: 1:47 - loss: 2.2056 - accuracy: 0.46 - ETA: 1:45 - loss: 2.2029 - accuracy: 0.46 - ETA: 1:44 - loss: 2.2036 - accuracy: 0.46 - ETA: 1:43 - loss: 2.1985 - accuracy: 0.46 - ETA: 1:42 - loss: 2.1947 - accuracy: 0.46 - ETA: 1:41 - loss: 2.1857 - accuracy: 0.46 - ETA: 1:40 - loss: 2.1844 - accuracy: 0.46 - ETA: 1:39 - loss: 2.1773 - accuracy: 0.46 - ETA: 1:38 - loss: 2.1809 - accuracy: 0.46 - ETA: 1:37 - loss: 2.1821 - accuracy: 0.46 - ETA: 1:36 - loss: 2.1859 - accuracy: 0.46 - ETA: 1:34 - loss: 2.1846 - accuracy: 0.46 - ETA: 1:33 - loss: 2.1823 - accuracy: 0.46 - ETA: 1:32 - loss: 2.1799 - accuracy: 0.46 - ETA: 1:31 - loss: 2.1825 - accuracy: 0.46 - ETA: 1:30 - loss: 2.1777 - accuracy: 0.46 - ETA: 1:29 - loss: 2.1794 - accuracy: 0.46 - ETA: 1:28 - loss: 2.1807 - accuracy: 0.46 - ETA: 1:27 - loss: 2.1807 - accuracy: 0.46 - ETA: 1:26 - loss: 2.1776 - accuracy: 0.46 - ETA: 1:24 - loss: 2.1754 - accuracy: 0.46 - ETA: 1:24 - loss: 2.1749 - accuracy: 0.46 - ETA: 1:22 - loss: 2.1772 - accuracy: 0.46 - ETA: 1:21 - loss: 2.1765 - accuracy: 0.46 - ETA: 1:20 - loss: 2.1775 - accuracy: 0.46 - ETA: 1:19 - loss: 2.1779 - accuracy: 0.46 - ETA: 1:18 - loss: 2.1799 - accuracy: 0.46 - ETA: 1:17 - loss: 2.1823 - accuracy: 0.46 - ETA: 1:16 - loss: 2.1845 - accuracy: 0.46 - ETA: 1:15 - loss: 2.1815 - accuracy: 0.46 - ETA: 1:14 - loss: 2.1813 - accuracy: 0.46 - ETA: 1:13 - loss: 2.1789 - accuracy: 0.46 - ETA: 1:11 - loss: 2.1781 - accuracy: 0.46 - ETA: 1:10 - loss: 2.1780 - accuracy: 0.46 - ETA: 1:09 - loss: 2.1776 - accuracy: 0.46 - ETA: 1:08 - loss: 2.1797 - accuracy: 0.46 - ETA: 1:07 - loss: 2.1777 - accuracy: 0.46 - ETA: 1:06 - loss: 2.1770 - accuracy: 0.46 - ETA: 1:05 - loss: 2.1827 - accuracy: 0.46 - ETA: 1:04 - loss: 2.1802 - accuracy: 0.46 - ETA: 1:03 - loss: 2.1831 - accuracy: 0.46 - ETA: 1:01 - loss: 2.1860 - accuracy: 0.46 - ETA: 1:00 - loss: 2.1882 - accuracy: 0.46 - ETA: 59s - loss: 2.1875 - accuracy: 0.4681 - ETA: 58s - loss: 2.1846 - accuracy: 0.468 - ETA: 57s - loss: 2.1891 - accuracy: 0.467 - ETA: 56s - loss: 2.1876 - accuracy: 0.467 - ETA: 55s - loss: 2.1877 - accuracy: 0.467 - ETA: 54s - loss: 2.1887 - accuracy: 0.467 - ETA: 52s - loss: 2.1855 - accuracy: 0.468 - ETA: 51s - loss: 2.1854 - accuracy: 0.468 - ETA: 50s - loss: 2.1860 - accuracy: 0.467 - ETA: 49s - loss: 2.1824 - accuracy: 0.468 - ETA: 48s - loss: 2.1829 - accuracy: 0.467 - ETA: 47s - loss: 2.1830 - accuracy: 0.467 - ETA: 46s - loss: 2.1837 - accuracy: 0.467 - ETA: 45s - loss: 2.1839 - accuracy: 0.466 - ETA: 44s - loss: 2.1838 - accuracy: 0.466 - ETA: 42s - loss: 2.1830 - accuracy: 0.467 - ETA: 41s - loss: 2.1828 - accuracy: 0.466 - ETA: 40s - loss: 2.1808 - accuracy: 0.467 - ETA: 39s - loss: 2.1801 - accuracy: 0.466 - ETA: 38s - loss: 2.1800 - accuracy: 0.467 - ETA: 37s - loss: 2.1813 - accuracy: 0.467 - ETA: 36s - loss: 2.1876 - accuracy: 0.466 - ETA: 35s - loss: 2.1865 - accuracy: 0.466 - ETA: 34s - loss: 2.1854 - accuracy: 0.466 - ETA: 32s - loss: 2.1820 - accuracy: 0.466 - ETA: 31s - loss: 2.1810 - accuracy: 0.466 - ETA: 30s - loss: 2.1784 - accuracy: 0.467 - ETA: 29s - loss: 2.1742 - accuracy: 0.468 - ETA: 28s - loss: 2.1733 - accuracy: 0.468 - ETA: 27s - loss: 2.1730 - accuracy: 0.468 - ETA: 26s - loss: 2.1708 - accuracy: 0.468 - ETA: 25s - loss: 2.1696 - accuracy: 0.468 - ETA: 24s - loss: 2.1703 - accuracy: 0.468 - ETA: 22s - loss: 2.1709 - accuracy: 0.468 - ETA: 21s - loss: 2.1688 - accuracy: 0.469 - ETA: 20s - loss: 2.1700 - accuracy: 0.468 - ETA: 19s - loss: 2.1697 - accuracy: 0.468 - ETA: 18s - loss: 2.1658 - accuracy: 0.469 - ETA: 17s - loss: 2.1679 - accuracy: 0.469 - ETA: 15s - loss: 2.1676 - accuracy: 0.469 - ETA: 14s - loss: 2.1673 - accuracy: 0.469 - ETA: 13s - loss: 2.1679 - accuracy: 0.470 - ETA: 12s - loss: 2.1659 - accuracy: 0.470 - ETA: 11s - loss: 2.1672 - accuracy: 0.470 - ETA: 10s - loss: 2.1648 - accuracy: 0.471 - ETA: 9s - loss: 2.1637 - accuracy: 0.471 - ETA: 7s - loss: 2.1643 - accuracy: 0.47 - ETA: 6s - loss: 2.1621 - accuracy: 0.47 - ETA: 5s - loss: 2.1611 - accuracy: 0.47 - ETA: 4s - loss: 2.1598 - accuracy: 0.47 - ETA: 3s - loss: 2.1574 - accuracy: 0.47 - ETA: 2s - loss: 2.1571 - accuracy: 0.47 - ETA: 1s - loss: 2.1553 - accuracy: 0.47 - 185s 10ms/step - loss: 2.1519 - accuracy: 0.4725 - val_loss: 1.6556 - val_accuracy: 0.5999\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:32 - loss: 1.9148 - accuracy: 0.50 - ETA: 5:20 - loss: 1.8302 - accuracy: 0.52 - ETA: 4:27 - loss: 1.8640 - accuracy: 0.52 - ETA: 4:00 - loss: 1.9360 - accuracy: 0.51 - ETA: 3:46 - loss: 1.8530 - accuracy: 0.53 - ETA: 3:36 - loss: 1.8733 - accuracy: 0.53 - ETA: 3:29 - loss: 1.8738 - accuracy: 0.53 - ETA: 3:22 - loss: 1.8585 - accuracy: 0.53 - ETA: 3:20 - loss: 1.8987 - accuracy: 0.53 - ETA: 3:16 - loss: 1.9126 - accuracy: 0.52 - ETA: 3:12 - loss: 1.9138 - accuracy: 0.52 - ETA: 3:07 - loss: 1.9066 - accuracy: 0.52 - ETA: 3:04 - loss: 1.8821 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8621 - accuracy: 0.53 - ETA: 2:57 - loss: 1.8714 - accuracy: 0.53 - ETA: 2:54 - loss: 1.8690 - accuracy: 0.53 - ETA: 3:04 - loss: 1.8576 - accuracy: 0.53 - ETA: 3:06 - loss: 1.8516 - accuracy: 0.53 - ETA: 3:07 - loss: 1.8506 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8423 - accuracy: 0.54 - ETA: 3:09 - loss: 1.8482 - accuracy: 0.53 - ETA: 3:11 - loss: 1.8451 - accuracy: 0.53 - ETA: 3:11 - loss: 1.8410 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8423 - accuracy: 0.53 - ETA: 3:13 - loss: 1.8523 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8420 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8448 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8429 - accuracy: 0.53 - ETA: 3:12 - loss: 1.8428 - accuracy: 0.53 - ETA: 3:11 - loss: 1.8317 - accuracy: 0.53 - ETA: 3:09 - loss: 1.8271 - accuracy: 0.53 - ETA: 3:07 - loss: 1.8187 - accuracy: 0.53 - ETA: 3:05 - loss: 1.8195 - accuracy: 0.53 - ETA: 3:03 - loss: 1.8171 - accuracy: 0.53 - ETA: 3:02 - loss: 1.8172 - accuracy: 0.53 - ETA: 3:01 - loss: 1.8229 - accuracy: 0.53 - ETA: 3:01 - loss: 1.8188 - accuracy: 0.53 - ETA: 3:00 - loss: 1.8143 - accuracy: 0.53 - ETA: 2:59 - loss: 1.8133 - accuracy: 0.54 - ETA: 2:59 - loss: 1.8125 - accuracy: 0.54 - ETA: 2:58 - loss: 1.8039 - accuracy: 0.54 - ETA: 2:58 - loss: 1.8101 - accuracy: 0.54 - ETA: 2:57 - loss: 1.8063 - accuracy: 0.54 - ETA: 2:56 - loss: 1.8013 - accuracy: 0.54 - ETA: 2:55 - loss: 1.8028 - accuracy: 0.54 - ETA: 2:54 - loss: 1.8055 - accuracy: 0.54 - ETA: 2:53 - loss: 1.8013 - accuracy: 0.53 - ETA: 2:52 - loss: 1.8016 - accuracy: 0.53 - ETA: 2:50 - loss: 1.7970 - accuracy: 0.53 - ETA: 2:49 - loss: 1.7991 - accuracy: 0.53 - ETA: 2:48 - loss: 1.7965 - accuracy: 0.53 - ETA: 2:46 - loss: 1.7985 - accuracy: 0.53 - ETA: 2:45 - loss: 1.8004 - accuracy: 0.53 - ETA: 2:43 - loss: 1.8029 - accuracy: 0.53 - ETA: 2:42 - loss: 1.8030 - accuracy: 0.53 - ETA: 2:40 - loss: 1.8060 - accuracy: 0.53 - ETA: 2:39 - loss: 1.8038 - accuracy: 0.53 - ETA: 2:38 - loss: 1.8031 - accuracy: 0.53 - ETA: 2:36 - loss: 1.8014 - accuracy: 0.53 - ETA: 2:35 - loss: 1.8015 - accuracy: 0.53 - ETA: 2:33 - loss: 1.7998 - accuracy: 0.54 - ETA: 2:32 - loss: 1.7976 - accuracy: 0.53 - ETA: 2:30 - loss: 1.8043 - accuracy: 0.53 - ETA: 2:29 - loss: 1.8014 - accuracy: 0.54 - ETA: 2:27 - loss: 1.8016 - accuracy: 0.54 - ETA: 2:26 - loss: 1.7996 - accuracy: 0.54 - ETA: 2:24 - loss: 1.8000 - accuracy: 0.54 - ETA: 2:23 - loss: 1.7983 - accuracy: 0.54 - ETA: 2:21 - loss: 1.7991 - accuracy: 0.54 - ETA: 2:20 - loss: 1.8003 - accuracy: 0.54 - ETA: 2:18 - loss: 1.8006 - accuracy: 0.53 - ETA: 2:16 - loss: 1.8003 - accuracy: 0.53 - ETA: 2:15 - loss: 1.7978 - accuracy: 0.53 - ETA: 2:13 - loss: 1.8036 - accuracy: 0.53 - ETA: 2:11 - loss: 1.7993 - accuracy: 0.53 - ETA: 2:10 - loss: 1.8005 - accuracy: 0.53 - ETA: 2:08 - loss: 1.8023 - accuracy: 0.53 - ETA: 2:06 - loss: 1.8020 - accuracy: 0.53 - ETA: 2:05 - loss: 1.7982 - accuracy: 0.54 - ETA: 2:03 - loss: 1.7957 - accuracy: 0.54 - ETA: 2:01 - loss: 1.7975 - accuracy: 0.54 - ETA: 2:00 - loss: 1.8010 - accuracy: 0.54 - ETA: 1:58 - loss: 1.8004 - accuracy: 0.54 - ETA: 1:57 - loss: 1.7993 - accuracy: 0.54 - ETA: 1:55 - loss: 1.7993 - accuracy: 0.54 - ETA: 1:53 - loss: 1.7969 - accuracy: 0.54 - ETA: 1:52 - loss: 1.7961 - accuracy: 0.54 - ETA: 1:50 - loss: 1.7947 - accuracy: 0.54 - ETA: 1:48 - loss: 1.7931 - accuracy: 0.54 - ETA: 1:47 - loss: 1.7991 - accuracy: 0.54 - ETA: 1:45 - loss: 1.8018 - accuracy: 0.54 - ETA: 1:43 - loss: 1.8063 - accuracy: 0.53 - ETA: 1:41 - loss: 1.8099 - accuracy: 0.53 - ETA: 1:40 - loss: 1.8065 - accuracy: 0.53 - ETA: 1:38 - loss: 1.8057 - accuracy: 0.54 - ETA: 1:36 - loss: 1.8039 - accuracy: 0.54 - ETA: 1:35 - loss: 1.8026 - accuracy: 0.54 - ETA: 1:33 - loss: 1.8009 - accuracy: 0.54 - ETA: 1:31 - loss: 1.8001 - accuracy: 0.54 - ETA: 1:29 - loss: 1.7952 - accuracy: 0.54 - ETA: 1:28 - loss: 1.7953 - accuracy: 0.54 - ETA: 1:26 - loss: 1.7965 - accuracy: 0.54 - ETA: 1:24 - loss: 1.7936 - accuracy: 0.54 - ETA: 1:22 - loss: 1.7928 - accuracy: 0.54 - ETA: 1:21 - loss: 1.7941 - accuracy: 0.54 - ETA: 1:19 - loss: 1.7939 - accuracy: 0.54 - ETA: 1:17 - loss: 1.7980 - accuracy: 0.54 - ETA: 1:16 - loss: 1.7994 - accuracy: 0.54 - ETA: 1:14 - loss: 1.8003 - accuracy: 0.54 - ETA: 1:12 - loss: 1.8012 - accuracy: 0.54 - ETA: 1:10 - loss: 1.8032 - accuracy: 0.54 - ETA: 1:09 - loss: 1.8029 - accuracy: 0.54 - ETA: 1:07 - loss: 1.7996 - accuracy: 0.54 - ETA: 1:05 - loss: 1.7975 - accuracy: 0.54 - ETA: 1:04 - loss: 1.8010 - accuracy: 0.54 - ETA: 1:02 - loss: 1.7995 - accuracy: 0.54 - ETA: 1:00 - loss: 1.7978 - accuracy: 0.54 - ETA: 58s - loss: 1.7959 - accuracy: 0.5420 - ETA: 56s - loss: 1.7965 - accuracy: 0.541 - ETA: 55s - loss: 1.7959 - accuracy: 0.541 - ETA: 53s - loss: 1.7954 - accuracy: 0.541 - ETA: 51s - loss: 1.7953 - accuracy: 0.541 - ETA: 49s - loss: 1.7969 - accuracy: 0.541 - ETA: 48s - loss: 1.7977 - accuracy: 0.541 - ETA: 46s - loss: 1.8011 - accuracy: 0.540 - ETA: 44s - loss: 1.8010 - accuracy: 0.540 - ETA: 42s - loss: 1.8031 - accuracy: 0.539 - ETA: 41s - loss: 1.8051 - accuracy: 0.539 - ETA: 39s - loss: 1.8032 - accuracy: 0.540 - ETA: 37s - loss: 1.8053 - accuracy: 0.539 - ETA: 35s - loss: 1.8066 - accuracy: 0.539 - ETA: 33s - loss: 1.8074 - accuracy: 0.538 - ETA: 32s - loss: 1.8063 - accuracy: 0.539 - ETA: 30s - loss: 1.8079 - accuracy: 0.539 - ETA: 28s - loss: 1.8095 - accuracy: 0.539 - ETA: 26s - loss: 1.8086 - accuracy: 0.539 - ETA: 24s - loss: 1.8102 - accuracy: 0.538 - ETA: 23s - loss: 1.8135 - accuracy: 0.538 - ETA: 21s - loss: 1.8135 - accuracy: 0.537 - ETA: 19s - loss: 1.8133 - accuracy: 0.537 - ETA: 17s - loss: 1.8154 - accuracy: 0.537 - ETA: 16s - loss: 1.8164 - accuracy: 0.537 - ETA: 14s - loss: 1.8163 - accuracy: 0.537 - ETA: 12s - loss: 1.8155 - accuracy: 0.537 - ETA: 10s - loss: 1.8158 - accuracy: 0.536 - ETA: 8s - loss: 1.8146 - accuracy: 0.537 - ETA: 7s - loss: 1.8139 - accuracy: 0.53 - ETA: 5s - loss: 1.8134 - accuracy: 0.53 - ETA: 3s - loss: 1.8134 - accuracy: 0.53 - ETA: 1s - loss: 1.8131 - accuracy: 0.53 - 300s 16ms/step - loss: 1.8133 - accuracy: 0.5372 - val_loss: 1.4994 - val_accuracy: 0.6198\n",
      "Epoch 4/100\n",
      "19312/19312 [==============================] - ETA: 5:35 - loss: 1.6297 - accuracy: 0.50 - ETA: 4:47 - loss: 1.7275 - accuracy: 0.53 - ETA: 4:38 - loss: 1.7551 - accuracy: 0.53 - ETA: 4:41 - loss: 1.6989 - accuracy: 0.53 - ETA: 4:34 - loss: 1.7041 - accuracy: 0.53 - ETA: 4:31 - loss: 1.7030 - accuracy: 0.54 - ETA: 4:27 - loss: 1.6608 - accuracy: 0.55 - ETA: 4:23 - loss: 1.6467 - accuracy: 0.55 - ETA: 4:22 - loss: 1.6429 - accuracy: 0.55 - ETA: 4:21 - loss: 1.6206 - accuracy: 0.56 - ETA: 4:19 - loss: 1.6182 - accuracy: 0.56 - ETA: 4:18 - loss: 1.6222 - accuracy: 0.56 - ETA: 4:16 - loss: 1.6093 - accuracy: 0.56 - ETA: 4:15 - loss: 1.6277 - accuracy: 0.56 - ETA: 4:13 - loss: 1.6226 - accuracy: 0.56 - ETA: 4:11 - loss: 1.6104 - accuracy: 0.57 - ETA: 4:11 - loss: 1.6101 - accuracy: 0.57 - ETA: 4:09 - loss: 1.6190 - accuracy: 0.57 - ETA: 4:08 - loss: 1.6155 - accuracy: 0.57 - ETA: 4:03 - loss: 1.6123 - accuracy: 0.57 - ETA: 4:02 - loss: 1.6246 - accuracy: 0.56 - ETA: 3:59 - loss: 1.6121 - accuracy: 0.57 - ETA: 3:57 - loss: 1.6077 - accuracy: 0.57 - ETA: 3:55 - loss: 1.6108 - accuracy: 0.57 - ETA: 3:53 - loss: 1.6108 - accuracy: 0.57 - ETA: 3:52 - loss: 1.6033 - accuracy: 0.57 - ETA: 3:50 - loss: 1.6044 - accuracy: 0.57 - ETA: 3:47 - loss: 1.5957 - accuracy: 0.57 - ETA: 3:45 - loss: 1.5946 - accuracy: 0.57 - ETA: 3:43 - loss: 1.5972 - accuracy: 0.57 - ETA: 3:41 - loss: 1.5969 - accuracy: 0.57 - ETA: 3:38 - loss: 1.5909 - accuracy: 0.57 - ETA: 3:37 - loss: 1.6036 - accuracy: 0.57 - ETA: 3:34 - loss: 1.6042 - accuracy: 0.57 - ETA: 3:32 - loss: 1.6077 - accuracy: 0.57 - ETA: 3:30 - loss: 1.6082 - accuracy: 0.57 - ETA: 3:29 - loss: 1.6053 - accuracy: 0.57 - ETA: 3:27 - loss: 1.6068 - accuracy: 0.57 - ETA: 3:25 - loss: 1.6059 - accuracy: 0.57 - ETA: 3:23 - loss: 1.6082 - accuracy: 0.57 - ETA: 3:22 - loss: 1.6167 - accuracy: 0.57 - ETA: 3:20 - loss: 1.6197 - accuracy: 0.57 - ETA: 3:18 - loss: 1.6272 - accuracy: 0.57 - ETA: 3:16 - loss: 1.6243 - accuracy: 0.57 - ETA: 3:14 - loss: 1.6216 - accuracy: 0.57 - ETA: 3:12 - loss: 1.6158 - accuracy: 0.57 - ETA: 3:10 - loss: 1.6183 - accuracy: 0.57 - ETA: 3:09 - loss: 1.6201 - accuracy: 0.57 - ETA: 3:07 - loss: 1.6260 - accuracy: 0.57 - ETA: 3:04 - loss: 1.6266 - accuracy: 0.57 - ETA: 3:03 - loss: 1.6242 - accuracy: 0.57 - ETA: 3:01 - loss: 1.6310 - accuracy: 0.57 - ETA: 2:59 - loss: 1.6351 - accuracy: 0.57 - ETA: 2:57 - loss: 1.6382 - accuracy: 0.57 - ETA: 2:55 - loss: 1.6350 - accuracy: 0.57 - ETA: 2:53 - loss: 1.6333 - accuracy: 0.57 - ETA: 2:51 - loss: 1.6360 - accuracy: 0.56 - ETA: 2:50 - loss: 1.6319 - accuracy: 0.57 - ETA: 2:48 - loss: 1.6333 - accuracy: 0.57 - ETA: 2:46 - loss: 1.6286 - accuracy: 0.57 - ETA: 2:44 - loss: 1.6300 - accuracy: 0.56 - ETA: 2:42 - loss: 1.6276 - accuracy: 0.57 - ETA: 2:40 - loss: 1.6276 - accuracy: 0.57 - ETA: 2:38 - loss: 1.6300 - accuracy: 0.57 - ETA: 2:37 - loss: 1.6312 - accuracy: 0.57 - ETA: 2:35 - loss: 1.6278 - accuracy: 0.57 - ETA: 2:33 - loss: 1.6289 - accuracy: 0.57 - ETA: 2:31 - loss: 1.6279 - accuracy: 0.57 - ETA: 2:29 - loss: 1.6229 - accuracy: 0.57 - ETA: 2:27 - loss: 1.6219 - accuracy: 0.57 - ETA: 2:25 - loss: 1.6183 - accuracy: 0.57 - ETA: 2:23 - loss: 1.6173 - accuracy: 0.57 - ETA: 2:21 - loss: 1.6192 - accuracy: 0.57 - ETA: 2:20 - loss: 1.6206 - accuracy: 0.57 - ETA: 2:18 - loss: 1.6196 - accuracy: 0.57 - ETA: 2:16 - loss: 1.6170 - accuracy: 0.57 - ETA: 2:15 - loss: 1.6184 - accuracy: 0.57 - ETA: 2:13 - loss: 1.6183 - accuracy: 0.57 - ETA: 2:11 - loss: 1.6134 - accuracy: 0.57 - ETA: 2:09 - loss: 1.6186 - accuracy: 0.57 - ETA: 2:07 - loss: 1.6193 - accuracy: 0.57 - ETA: 2:05 - loss: 1.6179 - accuracy: 0.57 - ETA: 2:04 - loss: 1.6181 - accuracy: 0.57 - ETA: 2:02 - loss: 1.6181 - accuracy: 0.57 - ETA: 2:00 - loss: 1.6201 - accuracy: 0.57 - ETA: 1:58 - loss: 1.6192 - accuracy: 0.57 - ETA: 1:56 - loss: 1.6176 - accuracy: 0.57 - ETA: 1:54 - loss: 1.6224 - accuracy: 0.57 - ETA: 1:52 - loss: 1.6209 - accuracy: 0.57 - ETA: 1:50 - loss: 1.6215 - accuracy: 0.57 - ETA: 1:49 - loss: 1.6230 - accuracy: 0.57 - ETA: 1:47 - loss: 1.6237 - accuracy: 0.57 - ETA: 1:45 - loss: 1.6257 - accuracy: 0.57 - ETA: 1:43 - loss: 1.6223 - accuracy: 0.57 - ETA: 1:41 - loss: 1.6231 - accuracy: 0.57 - ETA: 1:39 - loss: 1.6235 - accuracy: 0.57 - ETA: 1:38 - loss: 1.6204 - accuracy: 0.57 - ETA: 1:36 - loss: 1.6214 - accuracy: 0.57 - ETA: 1:34 - loss: 1.6223 - accuracy: 0.57 - ETA: 1:32 - loss: 1.6203 - accuracy: 0.57 - ETA: 1:30 - loss: 1.6208 - accuracy: 0.57 - ETA: 1:29 - loss: 1.6216 - accuracy: 0.57 - ETA: 1:27 - loss: 1.6231 - accuracy: 0.57 - ETA: 1:25 - loss: 1.6235 - accuracy: 0.57 - ETA: 1:23 - loss: 1.6243 - accuracy: 0.57 - ETA: 1:21 - loss: 1.6281 - accuracy: 0.57 - ETA: 1:19 - loss: 1.6315 - accuracy: 0.57 - ETA: 1:18 - loss: 1.6304 - accuracy: 0.57 - ETA: 1:16 - loss: 1.6309 - accuracy: 0.56 - ETA: 1:14 - loss: 1.6304 - accuracy: 0.56 - ETA: 1:12 - loss: 1.6291 - accuracy: 0.57 - ETA: 1:10 - loss: 1.6289 - accuracy: 0.56 - ETA: 1:09 - loss: 1.6318 - accuracy: 0.56 - ETA: 1:07 - loss: 1.6295 - accuracy: 0.56 - ETA: 1:05 - loss: 1.6313 - accuracy: 0.56 - ETA: 1:03 - loss: 1.6318 - accuracy: 0.56 - ETA: 1:01 - loss: 1.6317 - accuracy: 0.56 - ETA: 1:00 - loss: 1.6313 - accuracy: 0.56 - ETA: 58s - loss: 1.6300 - accuracy: 0.5695 - ETA: 56s - loss: 1.6310 - accuracy: 0.569 - ETA: 54s - loss: 1.6290 - accuracy: 0.570 - ETA: 52s - loss: 1.6280 - accuracy: 0.570 - ETA: 51s - loss: 1.6296 - accuracy: 0.569 - ETA: 49s - loss: 1.6291 - accuracy: 0.569 - ETA: 47s - loss: 1.6310 - accuracy: 0.570 - ETA: 45s - loss: 1.6307 - accuracy: 0.570 - ETA: 43s - loss: 1.6336 - accuracy: 0.570 - ETA: 41s - loss: 1.6345 - accuracy: 0.570 - ETA: 40s - loss: 1.6348 - accuracy: 0.570 - ETA: 38s - loss: 1.6346 - accuracy: 0.570 - ETA: 36s - loss: 1.6348 - accuracy: 0.570 - ETA: 34s - loss: 1.6366 - accuracy: 0.569 - ETA: 32s - loss: 1.6368 - accuracy: 0.569 - ETA: 30s - loss: 1.6363 - accuracy: 0.569 - ETA: 29s - loss: 1.6335 - accuracy: 0.570 - ETA: 27s - loss: 1.6351 - accuracy: 0.570 - ETA: 25s - loss: 1.6350 - accuracy: 0.570 - ETA: 23s - loss: 1.6357 - accuracy: 0.570 - ETA: 21s - loss: 1.6323 - accuracy: 0.570 - ETA: 20s - loss: 1.6327 - accuracy: 0.570 - ETA: 18s - loss: 1.6325 - accuracy: 0.570 - ETA: 16s - loss: 1.6345 - accuracy: 0.569 - ETA: 14s - loss: 1.6382 - accuracy: 0.569 - ETA: 12s - loss: 1.6382 - accuracy: 0.568 - ETA: 10s - loss: 1.6376 - accuracy: 0.569 - ETA: 8s - loss: 1.6380 - accuracy: 0.569 - ETA: 7s - loss: 1.6368 - accuracy: 0.56 - ETA: 5s - loss: 1.6365 - accuracy: 0.56 - ETA: 3s - loss: 1.6342 - accuracy: 0.57 - ETA: 1s - loss: 1.6328 - accuracy: 0.57 - 304s 16ms/step - loss: 1.6333 - accuracy: 0.5707 - val_loss: 1.4044 - val_accuracy: 0.6478\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:29 - loss: 1.0919 - accuracy: 0.67 - ETA: 5:08 - loss: 1.2854 - accuracy: 0.64 - ETA: 4:56 - loss: 1.3099 - accuracy: 0.64 - ETA: 4:47 - loss: 1.4151 - accuracy: 0.60 - ETA: 4:43 - loss: 1.4021 - accuracy: 0.60 - ETA: 4:37 - loss: 1.3921 - accuracy: 0.60 - ETA: 4:35 - loss: 1.3932 - accuracy: 0.60 - ETA: 4:33 - loss: 1.3835 - accuracy: 0.60 - ETA: 4:32 - loss: 1.3767 - accuracy: 0.61 - ETA: 4:30 - loss: 1.3804 - accuracy: 0.60 - ETA: 4:28 - loss: 1.3694 - accuracy: 0.61 - ETA: 4:25 - loss: 1.3967 - accuracy: 0.61 - ETA: 4:21 - loss: 1.4056 - accuracy: 0.61 - ETA: 4:21 - loss: 1.4076 - accuracy: 0.61 - ETA: 4:18 - loss: 1.4128 - accuracy: 0.61 - ETA: 4:15 - loss: 1.4239 - accuracy: 0.61 - ETA: 4:12 - loss: 1.4314 - accuracy: 0.61 - ETA: 4:10 - loss: 1.4473 - accuracy: 0.61 - ETA: 4:08 - loss: 1.4476 - accuracy: 0.60 - ETA: 4:05 - loss: 1.4593 - accuracy: 0.60 - ETA: 4:03 - loss: 1.4614 - accuracy: 0.60 - ETA: 4:01 - loss: 1.4528 - accuracy: 0.60 - ETA: 3:59 - loss: 1.4494 - accuracy: 0.60 - ETA: 3:57 - loss: 1.4528 - accuracy: 0.60 - ETA: 3:55 - loss: 1.4568 - accuracy: 0.60 - ETA: 3:53 - loss: 1.4613 - accuracy: 0.60 - ETA: 3:52 - loss: 1.4619 - accuracy: 0.60 - ETA: 3:49 - loss: 1.4588 - accuracy: 0.60 - ETA: 3:47 - loss: 1.4540 - accuracy: 0.60 - ETA: 3:45 - loss: 1.4551 - accuracy: 0.60 - ETA: 3:42 - loss: 1.4530 - accuracy: 0.60 - ETA: 3:40 - loss: 1.4525 - accuracy: 0.60 - ETA: 3:39 - loss: 1.4662 - accuracy: 0.60 - ETA: 3:37 - loss: 1.4717 - accuracy: 0.60 - ETA: 3:35 - loss: 1.4600 - accuracy: 0.60 - ETA: 3:34 - loss: 1.4593 - accuracy: 0.60 - ETA: 3:32 - loss: 1.4578 - accuracy: 0.60 - ETA: 3:31 - loss: 1.4661 - accuracy: 0.60 - ETA: 3:29 - loss: 1.4697 - accuracy: 0.60 - ETA: 3:27 - loss: 1.4669 - accuracy: 0.60 - ETA: 3:26 - loss: 1.4639 - accuracy: 0.60 - ETA: 3:24 - loss: 1.4658 - accuracy: 0.60 - ETA: 3:22 - loss: 1.4681 - accuracy: 0.60 - ETA: 3:20 - loss: 1.4654 - accuracy: 0.60 - ETA: 3:18 - loss: 1.4647 - accuracy: 0.60 - ETA: 3:17 - loss: 1.4664 - accuracy: 0.60 - ETA: 3:15 - loss: 1.4627 - accuracy: 0.60 - ETA: 3:13 - loss: 1.4740 - accuracy: 0.60 - ETA: 3:10 - loss: 1.4772 - accuracy: 0.60 - ETA: 3:09 - loss: 1.4828 - accuracy: 0.60 - ETA: 3:07 - loss: 1.4845 - accuracy: 0.59 - ETA: 3:05 - loss: 1.4886 - accuracy: 0.59 - ETA: 3:03 - loss: 1.4820 - accuracy: 0.60 - ETA: 3:01 - loss: 1.4819 - accuracy: 0.60 - ETA: 2:59 - loss: 1.4911 - accuracy: 0.59 - ETA: 2:57 - loss: 1.4904 - accuracy: 0.59 - ETA: 2:55 - loss: 1.4935 - accuracy: 0.59 - ETA: 2:53 - loss: 1.4899 - accuracy: 0.59 - ETA: 2:52 - loss: 1.4896 - accuracy: 0.60 - ETA: 2:50 - loss: 1.4859 - accuracy: 0.59 - ETA: 2:48 - loss: 1.4864 - accuracy: 0.59 - ETA: 2:46 - loss: 1.4847 - accuracy: 0.59 - ETA: 2:44 - loss: 1.4873 - accuracy: 0.59 - ETA: 2:42 - loss: 1.4862 - accuracy: 0.59 - ETA: 2:40 - loss: 1.4839 - accuracy: 0.59 - ETA: 2:38 - loss: 1.4836 - accuracy: 0.59 - ETA: 2:36 - loss: 1.4860 - accuracy: 0.59 - ETA: 2:35 - loss: 1.4856 - accuracy: 0.59 - ETA: 2:33 - loss: 1.4831 - accuracy: 0.59 - ETA: 2:31 - loss: 1.4840 - accuracy: 0.59 - ETA: 2:29 - loss: 1.4846 - accuracy: 0.59 - ETA: 2:27 - loss: 1.4877 - accuracy: 0.59 - ETA: 2:25 - loss: 1.4880 - accuracy: 0.59 - ETA: 2:23 - loss: 1.4871 - accuracy: 0.59 - ETA: 2:21 - loss: 1.4892 - accuracy: 0.59 - ETA: 2:19 - loss: 1.4883 - accuracy: 0.59 - ETA: 2:17 - loss: 1.4874 - accuracy: 0.59 - ETA: 2:16 - loss: 1.4882 - accuracy: 0.59 - ETA: 2:14 - loss: 1.4897 - accuracy: 0.59 - ETA: 2:12 - loss: 1.4931 - accuracy: 0.59 - ETA: 2:10 - loss: 1.4986 - accuracy: 0.59 - ETA: 2:08 - loss: 1.4957 - accuracy: 0.59 - ETA: 2:07 - loss: 1.4987 - accuracy: 0.59 - ETA: 2:05 - loss: 1.4985 - accuracy: 0.59 - ETA: 2:03 - loss: 1.5011 - accuracy: 0.59 - ETA: 2:01 - loss: 1.5047 - accuracy: 0.59 - ETA: 1:59 - loss: 1.5016 - accuracy: 0.59 - ETA: 1:57 - loss: 1.5022 - accuracy: 0.59 - ETA: 1:55 - loss: 1.4976 - accuracy: 0.59 - ETA: 1:53 - loss: 1.4931 - accuracy: 0.59 - ETA: 1:52 - loss: 1.4901 - accuracy: 0.59 - ETA: 1:50 - loss: 1.4885 - accuracy: 0.59 - ETA: 1:48 - loss: 1.4892 - accuracy: 0.59 - ETA: 1:46 - loss: 1.4923 - accuracy: 0.59 - ETA: 1:44 - loss: 1.4916 - accuracy: 0.59 - ETA: 1:43 - loss: 1.4946 - accuracy: 0.59 - ETA: 1:41 - loss: 1.4942 - accuracy: 0.59 - ETA: 1:39 - loss: 1.4973 - accuracy: 0.59 - ETA: 1:37 - loss: 1.4934 - accuracy: 0.59 - ETA: 1:35 - loss: 1.4977 - accuracy: 0.59 - ETA: 1:33 - loss: 1.4970 - accuracy: 0.59 - ETA: 1:31 - loss: 1.4954 - accuracy: 0.60 - ETA: 1:30 - loss: 1.4929 - accuracy: 0.60 - ETA: 1:28 - loss: 1.4920 - accuracy: 0.60 - ETA: 1:26 - loss: 1.4929 - accuracy: 0.60 - ETA: 1:24 - loss: 1.4918 - accuracy: 0.60 - ETA: 1:22 - loss: 1.4891 - accuracy: 0.60 - ETA: 1:20 - loss: 1.4885 - accuracy: 0.60 - ETA: 1:18 - loss: 1.4888 - accuracy: 0.60 - ETA: 1:16 - loss: 1.4880 - accuracy: 0.60 - ETA: 1:15 - loss: 1.4882 - accuracy: 0.60 - ETA: 1:13 - loss: 1.4913 - accuracy: 0.60 - ETA: 1:11 - loss: 1.4918 - accuracy: 0.59 - ETA: 1:09 - loss: 1.4897 - accuracy: 0.60 - ETA: 1:07 - loss: 1.4883 - accuracy: 0.60 - ETA: 1:05 - loss: 1.4872 - accuracy: 0.60 - ETA: 1:03 - loss: 1.4861 - accuracy: 0.60 - ETA: 1:02 - loss: 1.4854 - accuracy: 0.60 - ETA: 1:00 - loss: 1.4867 - accuracy: 0.60 - ETA: 58s - loss: 1.4850 - accuracy: 0.6009 - ETA: 56s - loss: 1.4835 - accuracy: 0.601 - ETA: 54s - loss: 1.4843 - accuracy: 0.601 - ETA: 52s - loss: 1.4837 - accuracy: 0.601 - ETA: 50s - loss: 1.4828 - accuracy: 0.601 - ETA: 48s - loss: 1.4861 - accuracy: 0.600 - ETA: 46s - loss: 1.4874 - accuracy: 0.600 - ETA: 45s - loss: 1.4875 - accuracy: 0.600 - ETA: 43s - loss: 1.4898 - accuracy: 0.600 - ETA: 41s - loss: 1.4888 - accuracy: 0.600 - ETA: 39s - loss: 1.4885 - accuracy: 0.600 - ETA: 37s - loss: 1.4890 - accuracy: 0.600 - ETA: 35s - loss: 1.4875 - accuracy: 0.600 - ETA: 33s - loss: 1.4903 - accuracy: 0.600 - ETA: 31s - loss: 1.4902 - accuracy: 0.600 - ETA: 30s - loss: 1.4912 - accuracy: 0.599 - ETA: 28s - loss: 1.4911 - accuracy: 0.599 - ETA: 26s - loss: 1.4907 - accuracy: 0.599 - ETA: 24s - loss: 1.4894 - accuracy: 0.599 - ETA: 22s - loss: 1.4899 - accuracy: 0.599 - ETA: 20s - loss: 1.4936 - accuracy: 0.598 - ETA: 18s - loss: 1.4933 - accuracy: 0.598 - ETA: 16s - loss: 1.4931 - accuracy: 0.598 - ETA: 14s - loss: 1.4951 - accuracy: 0.598 - ETA: 13s - loss: 1.4939 - accuracy: 0.597 - ETA: 11s - loss: 1.4931 - accuracy: 0.597 - ETA: 9s - loss: 1.4934 - accuracy: 0.598 - ETA: 7s - loss: 1.4940 - accuracy: 0.59 - ETA: 5s - loss: 1.4934 - accuracy: 0.59 - ETA: 3s - loss: 1.4925 - accuracy: 0.59 - ETA: 1s - loss: 1.4908 - accuracy: 0.59 - 310s 16ms/step - loss: 1.4914 - accuracy: 0.5985 - val_loss: 1.3846 - val_accuracy: 0.6544\n",
      "Epoch 6/100\n",
      "19312/19312 [==============================] - ETA: 7:23 - loss: 1.3049 - accuracy: 0.67 - ETA: 5:40 - loss: 1.3244 - accuracy: 0.62 - ETA: 5:13 - loss: 1.2449 - accuracy: 0.63 - ETA: 4:59 - loss: 1.2403 - accuracy: 0.62 - ETA: 4:52 - loss: 1.3886 - accuracy: 0.60 - ETA: 4:45 - loss: 1.3837 - accuracy: 0.60 - ETA: 4:42 - loss: 1.3816 - accuracy: 0.60 - ETA: 4:36 - loss: 1.3761 - accuracy: 0.61 - ETA: 4:34 - loss: 1.3819 - accuracy: 0.60 - ETA: 4:32 - loss: 1.4255 - accuracy: 0.60 - ETA: 4:29 - loss: 1.4107 - accuracy: 0.61 - ETA: 4:27 - loss: 1.4064 - accuracy: 0.60 - ETA: 4:25 - loss: 1.4069 - accuracy: 0.60 - ETA: 4:24 - loss: 1.4140 - accuracy: 0.60 - ETA: 4:20 - loss: 1.4129 - accuracy: 0.60 - ETA: 4:19 - loss: 1.4113 - accuracy: 0.60 - ETA: 4:15 - loss: 1.4095 - accuracy: 0.60 - ETA: 4:13 - loss: 1.4103 - accuracy: 0.60 - ETA: 4:11 - loss: 1.3939 - accuracy: 0.60 - ETA: 4:08 - loss: 1.3956 - accuracy: 0.60 - ETA: 4:06 - loss: 1.3982 - accuracy: 0.60 - ETA: 4:03 - loss: 1.4283 - accuracy: 0.60 - ETA: 4:01 - loss: 1.4332 - accuracy: 0.60 - ETA: 3:59 - loss: 1.4196 - accuracy: 0.60 - ETA: 3:58 - loss: 1.4329 - accuracy: 0.60 - ETA: 3:56 - loss: 1.4311 - accuracy: 0.60 - ETA: 3:54 - loss: 1.4303 - accuracy: 0.60 - ETA: 3:52 - loss: 1.4352 - accuracy: 0.60 - ETA: 3:50 - loss: 1.4334 - accuracy: 0.60 - ETA: 3:48 - loss: 1.4365 - accuracy: 0.60 - ETA: 3:46 - loss: 1.4327 - accuracy: 0.60 - ETA: 3:44 - loss: 1.4235 - accuracy: 0.60 - ETA: 3:42 - loss: 1.4172 - accuracy: 0.60 - ETA: 3:41 - loss: 1.4060 - accuracy: 0.61 - ETA: 3:38 - loss: 1.4039 - accuracy: 0.61 - ETA: 3:36 - loss: 1.3948 - accuracy: 0.61 - ETA: 3:34 - loss: 1.3994 - accuracy: 0.61 - ETA: 3:33 - loss: 1.3948 - accuracy: 0.61 - ETA: 3:31 - loss: 1.3894 - accuracy: 0.61 - ETA: 3:29 - loss: 1.3903 - accuracy: 0.61 - ETA: 3:27 - loss: 1.3844 - accuracy: 0.61 - ETA: 3:25 - loss: 1.3804 - accuracy: 0.61 - ETA: 3:23 - loss: 1.3812 - accuracy: 0.61 - ETA: 3:21 - loss: 1.3794 - accuracy: 0.61 - ETA: 3:20 - loss: 1.3825 - accuracy: 0.61 - ETA: 3:18 - loss: 1.3834 - accuracy: 0.61 - ETA: 3:16 - loss: 1.3805 - accuracy: 0.61 - ETA: 3:14 - loss: 1.3759 - accuracy: 0.61 - ETA: 3:12 - loss: 1.3781 - accuracy: 0.61 - ETA: 3:10 - loss: 1.3785 - accuracy: 0.61 - ETA: 3:08 - loss: 1.3782 - accuracy: 0.61 - ETA: 3:06 - loss: 1.3796 - accuracy: 0.61 - ETA: 3:04 - loss: 1.3857 - accuracy: 0.61 - ETA: 3:02 - loss: 1.3871 - accuracy: 0.61 - ETA: 3:00 - loss: 1.3867 - accuracy: 0.61 - ETA: 2:58 - loss: 1.3892 - accuracy: 0.61 - ETA: 2:56 - loss: 1.3857 - accuracy: 0.61 - ETA: 2:54 - loss: 1.3842 - accuracy: 0.61 - ETA: 2:52 - loss: 1.3853 - accuracy: 0.61 - ETA: 2:51 - loss: 1.3850 - accuracy: 0.61 - ETA: 2:49 - loss: 1.3845 - accuracy: 0.61 - ETA: 2:47 - loss: 1.3812 - accuracy: 0.61 - ETA: 2:45 - loss: 1.3804 - accuracy: 0.61 - ETA: 2:43 - loss: 1.3759 - accuracy: 0.61 - ETA: 2:41 - loss: 1.3791 - accuracy: 0.61 - ETA: 2:39 - loss: 1.3748 - accuracy: 0.61 - ETA: 2:37 - loss: 1.3741 - accuracy: 0.61 - ETA: 2:35 - loss: 1.3744 - accuracy: 0.61 - ETA: 2:33 - loss: 1.3739 - accuracy: 0.62 - ETA: 2:31 - loss: 1.3806 - accuracy: 0.62 - ETA: 2:30 - loss: 1.3807 - accuracy: 0.61 - ETA: 2:28 - loss: 1.3787 - accuracy: 0.62 - ETA: 2:26 - loss: 1.3790 - accuracy: 0.62 - ETA: 2:24 - loss: 1.3796 - accuracy: 0.61 - ETA: 2:22 - loss: 1.3795 - accuracy: 0.61 - ETA: 2:20 - loss: 1.3801 - accuracy: 0.61 - ETA: 2:18 - loss: 1.3795 - accuracy: 0.61 - ETA: 2:16 - loss: 1.3819 - accuracy: 0.61 - ETA: 2:15 - loss: 1.3804 - accuracy: 0.61 - ETA: 2:13 - loss: 1.3822 - accuracy: 0.61 - ETA: 2:11 - loss: 1.3795 - accuracy: 0.62 - ETA: 2:09 - loss: 1.3799 - accuracy: 0.61 - ETA: 2:07 - loss: 1.3829 - accuracy: 0.61 - ETA: 2:05 - loss: 1.3874 - accuracy: 0.61 - ETA: 2:03 - loss: 1.3840 - accuracy: 0.62 - ETA: 2:01 - loss: 1.3897 - accuracy: 0.61 - ETA: 1:59 - loss: 1.3882 - accuracy: 0.61 - ETA: 1:58 - loss: 1.3890 - accuracy: 0.61 - ETA: 1:56 - loss: 1.3918 - accuracy: 0.61 - ETA: 1:54 - loss: 1.3938 - accuracy: 0.61 - ETA: 1:52 - loss: 1.3956 - accuracy: 0.61 - ETA: 1:50 - loss: 1.3956 - accuracy: 0.61 - ETA: 1:48 - loss: 1.3976 - accuracy: 0.61 - ETA: 1:46 - loss: 1.3964 - accuracy: 0.61 - ETA: 1:44 - loss: 1.3963 - accuracy: 0.61 - ETA: 1:43 - loss: 1.3947 - accuracy: 0.61 - ETA: 1:41 - loss: 1.3941 - accuracy: 0.61 - ETA: 1:39 - loss: 1.3930 - accuracy: 0.61 - ETA: 1:37 - loss: 1.3944 - accuracy: 0.61 - ETA: 1:35 - loss: 1.3935 - accuracy: 0.61 - ETA: 1:33 - loss: 1.3969 - accuracy: 0.61 - ETA: 1:31 - loss: 1.3986 - accuracy: 0.61 - ETA: 1:29 - loss: 1.3981 - accuracy: 0.61 - ETA: 1:28 - loss: 1.3973 - accuracy: 0.61 - ETA: 1:26 - loss: 1.3977 - accuracy: 0.61 - ETA: 1:24 - loss: 1.3977 - accuracy: 0.61 - ETA: 1:22 - loss: 1.3968 - accuracy: 0.61 - ETA: 1:20 - loss: 1.3939 - accuracy: 0.61 - ETA: 1:18 - loss: 1.3941 - accuracy: 0.61 - ETA: 1:16 - loss: 1.3936 - accuracy: 0.61 - ETA: 1:14 - loss: 1.3933 - accuracy: 0.61 - ETA: 1:12 - loss: 1.3927 - accuracy: 0.61 - ETA: 1:11 - loss: 1.3923 - accuracy: 0.61 - ETA: 1:09 - loss: 1.3919 - accuracy: 0.61 - ETA: 1:07 - loss: 1.3916 - accuracy: 0.61 - ETA: 1:05 - loss: 1.3904 - accuracy: 0.61 - ETA: 1:03 - loss: 1.3907 - accuracy: 0.61 - ETA: 1:01 - loss: 1.3921 - accuracy: 0.61 - ETA: 59s - loss: 1.3903 - accuracy: 0.6180 - ETA: 57s - loss: 1.3936 - accuracy: 0.618 - ETA: 56s - loss: 1.3916 - accuracy: 0.619 - ETA: 54s - loss: 1.3917 - accuracy: 0.619 - ETA: 52s - loss: 1.3942 - accuracy: 0.619 - ETA: 50s - loss: 1.3921 - accuracy: 0.619 - ETA: 48s - loss: 1.3890 - accuracy: 0.619 - ETA: 46s - loss: 1.3902 - accuracy: 0.620 - ETA: 44s - loss: 1.3917 - accuracy: 0.620 - ETA: 42s - loss: 1.3943 - accuracy: 0.620 - ETA: 41s - loss: 1.3946 - accuracy: 0.620 - ETA: 39s - loss: 1.3946 - accuracy: 0.620 - ETA: 37s - loss: 1.3942 - accuracy: 0.620 - ETA: 35s - loss: 1.3968 - accuracy: 0.620 - ETA: 33s - loss: 1.3981 - accuracy: 0.620 - ETA: 31s - loss: 1.3984 - accuracy: 0.620 - ETA: 29s - loss: 1.3979 - accuracy: 0.620 - ETA: 27s - loss: 1.3974 - accuracy: 0.620 - ETA: 26s - loss: 1.3971 - accuracy: 0.620 - ETA: 24s - loss: 1.3990 - accuracy: 0.620 - ETA: 22s - loss: 1.4001 - accuracy: 0.620 - ETA: 20s - loss: 1.4008 - accuracy: 0.620 - ETA: 18s - loss: 1.3991 - accuracy: 0.621 - ETA: 16s - loss: 1.4007 - accuracy: 0.621 - ETA: 14s - loss: 1.4000 - accuracy: 0.621 - ETA: 12s - loss: 1.4012 - accuracy: 0.621 - ETA: 11s - loss: 1.3990 - accuracy: 0.621 - ETA: 9s - loss: 1.3985 - accuracy: 0.621 - ETA: 7s - loss: 1.3976 - accuracy: 0.62 - ETA: 5s - loss: 1.3953 - accuracy: 0.62 - ETA: 3s - loss: 1.3950 - accuracy: 0.62 - ETA: 1s - loss: 1.3965 - accuracy: 0.62 - 308s 16ms/step - loss: 1.3967 - accuracy: 0.6219 - val_loss: 1.3219 - val_accuracy: 0.6647\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:56 - loss: 1.1694 - accuracy: 0.67 - ETA: 6:02 - loss: 1.3146 - accuracy: 0.64 - ETA: 5:11 - loss: 1.2833 - accuracy: 0.66 - ETA: 5:04 - loss: 1.3260 - accuracy: 0.64 - ETA: 4:54 - loss: 1.2501 - accuracy: 0.65 - ETA: 4:46 - loss: 1.2128 - accuracy: 0.66 - ETA: 4:42 - loss: 1.2755 - accuracy: 0.65 - ETA: 4:37 - loss: 1.2669 - accuracy: 0.65 - ETA: 4:37 - loss: 1.2952 - accuracy: 0.64 - ETA: 4:33 - loss: 1.2895 - accuracy: 0.64 - ETA: 4:28 - loss: 1.2955 - accuracy: 0.64 - ETA: 4:25 - loss: 1.3123 - accuracy: 0.63 - ETA: 4:24 - loss: 1.3264 - accuracy: 0.64 - ETA: 4:22 - loss: 1.3277 - accuracy: 0.63 - ETA: 4:20 - loss: 1.3400 - accuracy: 0.63 - ETA: 4:19 - loss: 1.3353 - accuracy: 0.63 - ETA: 4:17 - loss: 1.3496 - accuracy: 0.63 - ETA: 4:14 - loss: 1.3517 - accuracy: 0.63 - ETA: 4:11 - loss: 1.3524 - accuracy: 0.63 - ETA: 4:09 - loss: 1.3668 - accuracy: 0.63 - ETA: 4:07 - loss: 1.3547 - accuracy: 0.63 - ETA: 4:05 - loss: 1.3530 - accuracy: 0.63 - ETA: 4:02 - loss: 1.3597 - accuracy: 0.63 - ETA: 3:59 - loss: 1.3608 - accuracy: 0.63 - ETA: 3:57 - loss: 1.3562 - accuracy: 0.63 - ETA: 3:56 - loss: 1.3509 - accuracy: 0.63 - ETA: 3:53 - loss: 1.3435 - accuracy: 0.63 - ETA: 3:51 - loss: 1.3390 - accuracy: 0.63 - ETA: 3:49 - loss: 1.3344 - accuracy: 0.63 - ETA: 3:46 - loss: 1.3374 - accuracy: 0.63 - ETA: 3:44 - loss: 1.3313 - accuracy: 0.63 - ETA: 3:42 - loss: 1.3330 - accuracy: 0.63 - ETA: 3:40 - loss: 1.3324 - accuracy: 0.64 - ETA: 3:38 - loss: 1.3329 - accuracy: 0.63 - ETA: 3:36 - loss: 1.3281 - accuracy: 0.63 - ETA: 3:34 - loss: 1.3268 - accuracy: 0.63 - ETA: 3:32 - loss: 1.3251 - accuracy: 0.63 - ETA: 3:31 - loss: 1.3235 - accuracy: 0.63 - ETA: 3:29 - loss: 1.3193 - accuracy: 0.63 - ETA: 3:27 - loss: 1.3215 - accuracy: 0.63 - ETA: 3:25 - loss: 1.3207 - accuracy: 0.63 - ETA: 3:23 - loss: 1.3195 - accuracy: 0.63 - ETA: 3:21 - loss: 1.3148 - accuracy: 0.63 - ETA: 3:19 - loss: 1.3161 - accuracy: 0.63 - ETA: 3:17 - loss: 1.3206 - accuracy: 0.63 - ETA: 3:16 - loss: 1.3152 - accuracy: 0.63 - ETA: 3:14 - loss: 1.3268 - accuracy: 0.63 - ETA: 3:12 - loss: 1.3245 - accuracy: 0.63 - ETA: 3:10 - loss: 1.3230 - accuracy: 0.63 - ETA: 3:08 - loss: 1.3254 - accuracy: 0.63 - ETA: 3:06 - loss: 1.3205 - accuracy: 0.63 - ETA: 3:04 - loss: 1.3208 - accuracy: 0.63 - ETA: 3:02 - loss: 1.3206 - accuracy: 0.63 - ETA: 3:00 - loss: 1.3199 - accuracy: 0.63 - ETA: 2:59 - loss: 1.3204 - accuracy: 0.63 - ETA: 2:57 - loss: 1.3196 - accuracy: 0.63 - ETA: 2:55 - loss: 1.3206 - accuracy: 0.63 - ETA: 2:53 - loss: 1.3185 - accuracy: 0.63 - ETA: 2:51 - loss: 1.3172 - accuracy: 0.63 - ETA: 2:49 - loss: 1.3191 - accuracy: 0.63 - ETA: 2:47 - loss: 1.3187 - accuracy: 0.63 - ETA: 2:45 - loss: 1.3161 - accuracy: 0.63 - ETA: 2:43 - loss: 1.3120 - accuracy: 0.63 - ETA: 2:41 - loss: 1.3147 - accuracy: 0.63 - ETA: 2:39 - loss: 1.3153 - accuracy: 0.63 - ETA: 2:37 - loss: 1.3150 - accuracy: 0.63 - ETA: 2:35 - loss: 1.3178 - accuracy: 0.63 - ETA: 2:33 - loss: 1.3147 - accuracy: 0.63 - ETA: 2:31 - loss: 1.3147 - accuracy: 0.63 - ETA: 2:29 - loss: 1.3152 - accuracy: 0.63 - ETA: 2:27 - loss: 1.3121 - accuracy: 0.63 - ETA: 2:26 - loss: 1.3178 - accuracy: 0.63 - ETA: 2:24 - loss: 1.3196 - accuracy: 0.63 - ETA: 2:22 - loss: 1.3239 - accuracy: 0.63 - ETA: 2:20 - loss: 1.3229 - accuracy: 0.63 - ETA: 2:18 - loss: 1.3224 - accuracy: 0.63 - ETA: 2:16 - loss: 1.3217 - accuracy: 0.63 - ETA: 2:14 - loss: 1.3196 - accuracy: 0.63 - ETA: 2:13 - loss: 1.3189 - accuracy: 0.63 - ETA: 2:11 - loss: 1.3150 - accuracy: 0.63 - ETA: 2:09 - loss: 1.3126 - accuracy: 0.63 - ETA: 2:07 - loss: 1.3102 - accuracy: 0.63 - ETA: 2:05 - loss: 1.3160 - accuracy: 0.63 - ETA: 2:03 - loss: 1.3181 - accuracy: 0.63 - ETA: 2:02 - loss: 1.3181 - accuracy: 0.63 - ETA: 2:00 - loss: 1.3157 - accuracy: 0.63 - ETA: 1:58 - loss: 1.3154 - accuracy: 0.63 - ETA: 1:56 - loss: 1.3190 - accuracy: 0.63 - ETA: 1:54 - loss: 1.3248 - accuracy: 0.63 - ETA: 1:53 - loss: 1.3263 - accuracy: 0.63 - ETA: 1:51 - loss: 1.3251 - accuracy: 0.63 - ETA: 1:49 - loss: 1.3238 - accuracy: 0.63 - ETA: 1:47 - loss: 1.3206 - accuracy: 0.63 - ETA: 1:45 - loss: 1.3225 - accuracy: 0.63 - ETA: 1:43 - loss: 1.3261 - accuracy: 0.63 - ETA: 1:41 - loss: 1.3265 - accuracy: 0.63 - ETA: 1:40 - loss: 1.3277 - accuracy: 0.63 - ETA: 1:38 - loss: 1.3282 - accuracy: 0.63 - ETA: 1:36 - loss: 1.3265 - accuracy: 0.63 - ETA: 1:34 - loss: 1.3287 - accuracy: 0.63 - ETA: 1:32 - loss: 1.3312 - accuracy: 0.63 - ETA: 1:31 - loss: 1.3324 - accuracy: 0.63 - ETA: 1:29 - loss: 1.3303 - accuracy: 0.63 - ETA: 1:27 - loss: 1.3293 - accuracy: 0.63 - ETA: 1:25 - loss: 1.3325 - accuracy: 0.63 - ETA: 1:23 - loss: 1.3295 - accuracy: 0.63 - ETA: 1:21 - loss: 1.3281 - accuracy: 0.63 - ETA: 1:19 - loss: 1.3296 - accuracy: 0.63 - ETA: 1:18 - loss: 1.3287 - accuracy: 0.63 - ETA: 1:16 - loss: 1.3245 - accuracy: 0.63 - ETA: 1:14 - loss: 1.3257 - accuracy: 0.63 - ETA: 1:12 - loss: 1.3283 - accuracy: 0.63 - ETA: 1:10 - loss: 1.3260 - accuracy: 0.63 - ETA: 1:08 - loss: 1.3275 - accuracy: 0.63 - ETA: 1:06 - loss: 1.3263 - accuracy: 0.63 - ETA: 1:05 - loss: 1.3270 - accuracy: 0.63 - ETA: 1:03 - loss: 1.3248 - accuracy: 0.63 - ETA: 1:01 - loss: 1.3239 - accuracy: 0.63 - ETA: 59s - loss: 1.3245 - accuracy: 0.6375 - ETA: 57s - loss: 1.3248 - accuracy: 0.637 - ETA: 55s - loss: 1.3274 - accuracy: 0.636 - ETA: 53s - loss: 1.3254 - accuracy: 0.637 - ETA: 52s - loss: 1.3239 - accuracy: 0.637 - ETA: 50s - loss: 1.3232 - accuracy: 0.637 - ETA: 48s - loss: 1.3252 - accuracy: 0.636 - ETA: 46s - loss: 1.3281 - accuracy: 0.636 - ETA: 44s - loss: 1.3292 - accuracy: 0.636 - ETA: 42s - loss: 1.3279 - accuracy: 0.636 - ETA: 40s - loss: 1.3255 - accuracy: 0.636 - ETA: 39s - loss: 1.3247 - accuracy: 0.636 - ETA: 37s - loss: 1.3237 - accuracy: 0.636 - ETA: 35s - loss: 1.3239 - accuracy: 0.637 - ETA: 33s - loss: 1.3234 - accuracy: 0.636 - ETA: 31s - loss: 1.3266 - accuracy: 0.635 - ETA: 29s - loss: 1.3265 - accuracy: 0.635 - ETA: 27s - loss: 1.3256 - accuracy: 0.636 - ETA: 26s - loss: 1.3276 - accuracy: 0.636 - ETA: 24s - loss: 1.3316 - accuracy: 0.636 - ETA: 22s - loss: 1.3346 - accuracy: 0.636 - ETA: 20s - loss: 1.3343 - accuracy: 0.636 - ETA: 18s - loss: 1.3346 - accuracy: 0.636 - ETA: 16s - loss: 1.3347 - accuracy: 0.636 - ETA: 14s - loss: 1.3352 - accuracy: 0.636 - ETA: 12s - loss: 1.3356 - accuracy: 0.635 - ETA: 11s - loss: 1.3359 - accuracy: 0.636 - ETA: 9s - loss: 1.3357 - accuracy: 0.635 - ETA: 7s - loss: 1.3362 - accuracy: 0.63 - ETA: 5s - loss: 1.3368 - accuracy: 0.63 - ETA: 3s - loss: 1.3343 - accuracy: 0.63 - ETA: 1s - loss: 1.3348 - accuracy: 0.63 - 308s 16ms/step - loss: 1.3338 - accuracy: 0.6359 - val_loss: 1.3204 - val_accuracy: 0.6747\n",
      "Epoch 8/100\n",
      "19312/19312 [==============================] - ETA: 5:07 - loss: 1.2021 - accuracy: 0.66 - ETA: 4:57 - loss: 1.2935 - accuracy: 0.62 - ETA: 4:44 - loss: 1.2074 - accuracy: 0.64 - ETA: 4:39 - loss: 1.1785 - accuracy: 0.66 - ETA: 4:40 - loss: 1.1679 - accuracy: 0.66 - ETA: 4:39 - loss: 1.1466 - accuracy: 0.66 - ETA: 4:36 - loss: 1.1336 - accuracy: 0.67 - ETA: 4:31 - loss: 1.1693 - accuracy: 0.66 - ETA: 4:28 - loss: 1.1745 - accuracy: 0.67 - ETA: 4:26 - loss: 1.1757 - accuracy: 0.66 - ETA: 4:24 - loss: 1.1747 - accuracy: 0.66 - ETA: 4:23 - loss: 1.1725 - accuracy: 0.66 - ETA: 4:21 - loss: 1.1493 - accuracy: 0.66 - ETA: 4:19 - loss: 1.1467 - accuracy: 0.67 - ETA: 4:17 - loss: 1.1540 - accuracy: 0.66 - ETA: 4:16 - loss: 1.1590 - accuracy: 0.66 - ETA: 4:13 - loss: 1.1547 - accuracy: 0.67 - ETA: 4:12 - loss: 1.1693 - accuracy: 0.67 - ETA: 4:10 - loss: 1.1699 - accuracy: 0.67 - ETA: 4:07 - loss: 1.1697 - accuracy: 0.67 - ETA: 4:04 - loss: 1.1756 - accuracy: 0.66 - ETA: 4:02 - loss: 1.1839 - accuracy: 0.66 - ETA: 4:00 - loss: 1.1844 - accuracy: 0.66 - ETA: 3:57 - loss: 1.1841 - accuracy: 0.66 - ETA: 3:55 - loss: 1.1722 - accuracy: 0.66 - ETA: 3:53 - loss: 1.1758 - accuracy: 0.66 - ETA: 3:51 - loss: 1.1747 - accuracy: 0.66 - ETA: 3:49 - loss: 1.1798 - accuracy: 0.66 - ETA: 3:46 - loss: 1.1882 - accuracy: 0.66 - ETA: 3:44 - loss: 1.1886 - accuracy: 0.66 - ETA: 3:42 - loss: 1.1957 - accuracy: 0.66 - ETA: 3:40 - loss: 1.1961 - accuracy: 0.66 - ETA: 3:39 - loss: 1.2067 - accuracy: 0.66 - ETA: 3:37 - loss: 1.2131 - accuracy: 0.65 - ETA: 3:35 - loss: 1.2180 - accuracy: 0.65 - ETA: 3:33 - loss: 1.2174 - accuracy: 0.65 - ETA: 3:31 - loss: 1.2179 - accuracy: 0.65 - ETA: 3:29 - loss: 1.2134 - accuracy: 0.66 - ETA: 3:27 - loss: 1.2088 - accuracy: 0.66 - ETA: 3:26 - loss: 1.2084 - accuracy: 0.66 - ETA: 3:24 - loss: 1.2132 - accuracy: 0.66 - ETA: 3:22 - loss: 1.2174 - accuracy: 0.65 - ETA: 3:20 - loss: 1.2161 - accuracy: 0.65 - ETA: 3:18 - loss: 1.2197 - accuracy: 0.65 - ETA: 3:16 - loss: 1.2215 - accuracy: 0.65 - ETA: 3:14 - loss: 1.2189 - accuracy: 0.65 - ETA: 3:12 - loss: 1.2212 - accuracy: 0.65 - ETA: 3:11 - loss: 1.2271 - accuracy: 0.65 - ETA: 3:08 - loss: 1.2242 - accuracy: 0.65 - ETA: 3:07 - loss: 1.2239 - accuracy: 0.65 - ETA: 3:05 - loss: 1.2259 - accuracy: 0.65 - ETA: 3:03 - loss: 1.2295 - accuracy: 0.65 - ETA: 3:01 - loss: 1.2276 - accuracy: 0.65 - ETA: 2:59 - loss: 1.2249 - accuracy: 0.65 - ETA: 2:58 - loss: 1.2266 - accuracy: 0.65 - ETA: 2:56 - loss: 1.2266 - accuracy: 0.65 - ETA: 2:54 - loss: 1.2262 - accuracy: 0.65 - ETA: 2:52 - loss: 1.2274 - accuracy: 0.65 - ETA: 2:50 - loss: 1.2310 - accuracy: 0.65 - ETA: 2:48 - loss: 1.2313 - accuracy: 0.65 - ETA: 2:46 - loss: 1.2311 - accuracy: 0.65 - ETA: 2:45 - loss: 1.2304 - accuracy: 0.65 - ETA: 2:43 - loss: 1.2363 - accuracy: 0.65 - ETA: 2:41 - loss: 1.2365 - accuracy: 0.65 - ETA: 2:39 - loss: 1.2365 - accuracy: 0.65 - ETA: 2:37 - loss: 1.2359 - accuracy: 0.65 - ETA: 2:36 - loss: 1.2397 - accuracy: 0.65 - ETA: 2:34 - loss: 1.2428 - accuracy: 0.65 - ETA: 2:32 - loss: 1.2412 - accuracy: 0.65 - ETA: 2:30 - loss: 1.2401 - accuracy: 0.65 - ETA: 2:28 - loss: 1.2425 - accuracy: 0.65 - ETA: 2:26 - loss: 1.2408 - accuracy: 0.65 - ETA: 2:24 - loss: 1.2426 - accuracy: 0.65 - ETA: 2:22 - loss: 1.2426 - accuracy: 0.65 - ETA: 2:21 - loss: 1.2404 - accuracy: 0.65 - ETA: 2:19 - loss: 1.2381 - accuracy: 0.65 - ETA: 2:17 - loss: 1.2393 - accuracy: 0.65 - ETA: 2:15 - loss: 1.2410 - accuracy: 0.65 - ETA: 2:13 - loss: 1.2410 - accuracy: 0.65 - ETA: 2:11 - loss: 1.2431 - accuracy: 0.65 - ETA: 2:10 - loss: 1.2412 - accuracy: 0.65 - ETA: 2:08 - loss: 1.2413 - accuracy: 0.65 - ETA: 2:06 - loss: 1.2436 - accuracy: 0.65 - ETA: 2:04 - loss: 1.2448 - accuracy: 0.65 - ETA: 2:02 - loss: 1.2438 - accuracy: 0.65 - ETA: 2:00 - loss: 1.2442 - accuracy: 0.65 - ETA: 1:59 - loss: 1.2413 - accuracy: 0.65 - ETA: 1:57 - loss: 1.2453 - accuracy: 0.65 - ETA: 1:55 - loss: 1.2499 - accuracy: 0.65 - ETA: 1:53 - loss: 1.2509 - accuracy: 0.65 - ETA: 1:51 - loss: 1.2499 - accuracy: 0.65 - ETA: 1:49 - loss: 1.2499 - accuracy: 0.65 - ETA: 1:47 - loss: 1.2484 - accuracy: 0.65 - ETA: 1:45 - loss: 1.2492 - accuracy: 0.65 - ETA: 1:44 - loss: 1.2501 - accuracy: 0.65 - ETA: 1:42 - loss: 1.2482 - accuracy: 0.65 - ETA: 1:40 - loss: 1.2490 - accuracy: 0.65 - ETA: 1:38 - loss: 1.2477 - accuracy: 0.65 - ETA: 1:36 - loss: 1.2476 - accuracy: 0.65 - ETA: 1:34 - loss: 1.2486 - accuracy: 0.65 - ETA: 1:33 - loss: 1.2482 - accuracy: 0.65 - ETA: 1:31 - loss: 1.2499 - accuracy: 0.65 - ETA: 1:29 - loss: 1.2489 - accuracy: 0.65 - ETA: 1:27 - loss: 1.2478 - accuracy: 0.65 - ETA: 1:25 - loss: 1.2478 - accuracy: 0.65 - ETA: 1:23 - loss: 1.2513 - accuracy: 0.64 - ETA: 1:21 - loss: 1.2528 - accuracy: 0.64 - ETA: 1:20 - loss: 1.2513 - accuracy: 0.65 - ETA: 1:18 - loss: 1.2507 - accuracy: 0.65 - ETA: 1:16 - loss: 1.2500 - accuracy: 0.65 - ETA: 1:14 - loss: 1.2519 - accuracy: 0.65 - ETA: 1:12 - loss: 1.2544 - accuracy: 0.65 - ETA: 1:10 - loss: 1.2558 - accuracy: 0.64 - ETA: 1:08 - loss: 1.2550 - accuracy: 0.65 - ETA: 1:06 - loss: 1.2543 - accuracy: 0.65 - ETA: 1:05 - loss: 1.2545 - accuracy: 0.65 - ETA: 1:03 - loss: 1.2541 - accuracy: 0.65 - ETA: 1:01 - loss: 1.2516 - accuracy: 0.65 - ETA: 59s - loss: 1.2502 - accuracy: 0.6513 - ETA: 57s - loss: 1.2476 - accuracy: 0.651 - ETA: 55s - loss: 1.2481 - accuracy: 0.651 - ETA: 53s - loss: 1.2473 - accuracy: 0.651 - ETA: 51s - loss: 1.2463 - accuracy: 0.652 - ETA: 50s - loss: 1.2468 - accuracy: 0.651 - ETA: 48s - loss: 1.2454 - accuracy: 0.652 - ETA: 46s - loss: 1.2473 - accuracy: 0.651 - ETA: 44s - loss: 1.2496 - accuracy: 0.651 - ETA: 42s - loss: 1.2508 - accuracy: 0.651 - ETA: 40s - loss: 1.2511 - accuracy: 0.651 - ETA: 38s - loss: 1.2526 - accuracy: 0.651 - ETA: 37s - loss: 1.2535 - accuracy: 0.651 - ETA: 35s - loss: 1.2527 - accuracy: 0.651 - ETA: 33s - loss: 1.2508 - accuracy: 0.652 - ETA: 31s - loss: 1.2518 - accuracy: 0.652 - ETA: 29s - loss: 1.2530 - accuracy: 0.651 - ETA: 27s - loss: 1.2514 - accuracy: 0.651 - ETA: 25s - loss: 1.2521 - accuracy: 0.651 - ETA: 24s - loss: 1.2558 - accuracy: 0.651 - ETA: 22s - loss: 1.2540 - accuracy: 0.651 - ETA: 20s - loss: 1.2525 - accuracy: 0.652 - ETA: 18s - loss: 1.2512 - accuracy: 0.652 - ETA: 16s - loss: 1.2509 - accuracy: 0.652 - ETA: 14s - loss: 1.2521 - accuracy: 0.652 - ETA: 12s - loss: 1.2495 - accuracy: 0.653 - ETA: 10s - loss: 1.2488 - accuracy: 0.653 - ETA: 9s - loss: 1.2492 - accuracy: 0.653 - ETA: 7s - loss: 1.2511 - accuracy: 0.65 - ETA: 5s - loss: 1.2523 - accuracy: 0.65 - ETA: 3s - loss: 1.2525 - accuracy: 0.65 - ETA: 1s - loss: 1.2530 - accuracy: 0.65 - 306s 16ms/step - loss: 1.2528 - accuracy: 0.6530 - val_loss: 1.2917 - val_accuracy: 0.6840\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:55 - loss: 1.1730 - accuracy: 0.67 - ETA: 4:39 - loss: 1.1501 - accuracy: 0.68 - ETA: 4:36 - loss: 1.1294 - accuracy: 0.68 - ETA: 4:32 - loss: 1.1576 - accuracy: 0.68 - ETA: 4:28 - loss: 1.2284 - accuracy: 0.66 - ETA: 4:21 - loss: 1.2480 - accuracy: 0.66 - ETA: 4:20 - loss: 1.2552 - accuracy: 0.65 - ETA: 4:18 - loss: 1.2541 - accuracy: 0.65 - ETA: 4:18 - loss: 1.2177 - accuracy: 0.65 - ETA: 4:17 - loss: 1.1964 - accuracy: 0.66 - ETA: 4:16 - loss: 1.2244 - accuracy: 0.66 - ETA: 4:14 - loss: 1.2170 - accuracy: 0.66 - ETA: 4:12 - loss: 1.2325 - accuracy: 0.65 - ETA: 4:10 - loss: 1.2362 - accuracy: 0.65 - ETA: 4:09 - loss: 1.2380 - accuracy: 0.65 - ETA: 4:08 - loss: 1.2235 - accuracy: 0.66 - ETA: 4:07 - loss: 1.2166 - accuracy: 0.66 - ETA: 4:05 - loss: 1.2128 - accuracy: 0.66 - ETA: 4:04 - loss: 1.2017 - accuracy: 0.66 - ETA: 4:03 - loss: 1.2012 - accuracy: 0.66 - ETA: 4:01 - loss: 1.1995 - accuracy: 0.66 - ETA: 3:59 - loss: 1.1920 - accuracy: 0.66 - ETA: 3:57 - loss: 1.1858 - accuracy: 0.66 - ETA: 3:55 - loss: 1.1909 - accuracy: 0.66 - ETA: 3:54 - loss: 1.1844 - accuracy: 0.66 - ETA: 3:52 - loss: 1.1869 - accuracy: 0.66 - ETA: 3:50 - loss: 1.1860 - accuracy: 0.66 - ETA: 3:48 - loss: 1.1881 - accuracy: 0.67 - ETA: 3:46 - loss: 1.1909 - accuracy: 0.66 - ETA: 3:44 - loss: 1.1988 - accuracy: 0.66 - ETA: 3:43 - loss: 1.2005 - accuracy: 0.66 - ETA: 3:41 - loss: 1.2071 - accuracy: 0.66 - ETA: 3:40 - loss: 1.2120 - accuracy: 0.66 - ETA: 3:37 - loss: 1.2120 - accuracy: 0.66 - ETA: 3:36 - loss: 1.2016 - accuracy: 0.66 - ETA: 3:34 - loss: 1.1989 - accuracy: 0.66 - ETA: 3:32 - loss: 1.1967 - accuracy: 0.66 - ETA: 3:30 - loss: 1.1852 - accuracy: 0.67 - ETA: 3:28 - loss: 1.1856 - accuracy: 0.67 - ETA: 3:27 - loss: 1.1855 - accuracy: 0.67 - ETA: 3:25 - loss: 1.1879 - accuracy: 0.67 - ETA: 3:23 - loss: 1.1854 - accuracy: 0.67 - ETA: 3:21 - loss: 1.1818 - accuracy: 0.67 - ETA: 3:20 - loss: 1.1850 - accuracy: 0.67 - ETA: 3:18 - loss: 1.1805 - accuracy: 0.67 - ETA: 3:16 - loss: 1.1901 - accuracy: 0.67 - ETA: 3:14 - loss: 1.1907 - accuracy: 0.67 - ETA: 3:12 - loss: 1.1907 - accuracy: 0.67 - ETA: 3:10 - loss: 1.1896 - accuracy: 0.67 - ETA: 3:08 - loss: 1.1930 - accuracy: 0.67 - ETA: 3:06 - loss: 1.1893 - accuracy: 0.67 - ETA: 3:04 - loss: 1.1837 - accuracy: 0.67 - ETA: 3:02 - loss: 1.1785 - accuracy: 0.67 - ETA: 3:00 - loss: 1.1716 - accuracy: 0.67 - ETA: 2:58 - loss: 1.1757 - accuracy: 0.67 - ETA: 2:56 - loss: 1.1753 - accuracy: 0.67 - ETA: 2:54 - loss: 1.1822 - accuracy: 0.67 - ETA: 2:52 - loss: 1.1858 - accuracy: 0.67 - ETA: 2:51 - loss: 1.1867 - accuracy: 0.67 - ETA: 2:49 - loss: 1.1841 - accuracy: 0.67 - ETA: 2:47 - loss: 1.1808 - accuracy: 0.67 - ETA: 2:45 - loss: 1.1794 - accuracy: 0.67 - ETA: 2:43 - loss: 1.1758 - accuracy: 0.67 - ETA: 2:41 - loss: 1.1745 - accuracy: 0.67 - ETA: 2:40 - loss: 1.1735 - accuracy: 0.67 - ETA: 2:38 - loss: 1.1722 - accuracy: 0.67 - ETA: 2:36 - loss: 1.1720 - accuracy: 0.67 - ETA: 2:34 - loss: 1.1778 - accuracy: 0.67 - ETA: 2:32 - loss: 1.1767 - accuracy: 0.67 - ETA: 2:30 - loss: 1.1758 - accuracy: 0.67 - ETA: 2:28 - loss: 1.1783 - accuracy: 0.67 - ETA: 2:27 - loss: 1.1842 - accuracy: 0.67 - ETA: 2:25 - loss: 1.1835 - accuracy: 0.67 - ETA: 2:23 - loss: 1.1926 - accuracy: 0.67 - ETA: 2:21 - loss: 1.1935 - accuracy: 0.67 - ETA: 2:19 - loss: 1.1882 - accuracy: 0.67 - ETA: 2:17 - loss: 1.1926 - accuracy: 0.67 - ETA: 2:16 - loss: 1.1928 - accuracy: 0.67 - ETA: 2:14 - loss: 1.1917 - accuracy: 0.67 - ETA: 2:12 - loss: 1.1920 - accuracy: 0.67 - ETA: 2:10 - loss: 1.1942 - accuracy: 0.67 - ETA: 2:08 - loss: 1.1968 - accuracy: 0.67 - ETA: 2:07 - loss: 1.1969 - accuracy: 0.67 - ETA: 2:05 - loss: 1.1974 - accuracy: 0.67 - ETA: 2:03 - loss: 1.1964 - accuracy: 0.67 - ETA: 2:01 - loss: 1.1953 - accuracy: 0.67 - ETA: 1:59 - loss: 1.1925 - accuracy: 0.67 - ETA: 1:57 - loss: 1.1944 - accuracy: 0.67 - ETA: 1:55 - loss: 1.1915 - accuracy: 0.67 - ETA: 1:54 - loss: 1.1904 - accuracy: 0.67 - ETA: 1:52 - loss: 1.1918 - accuracy: 0.67 - ETA: 1:50 - loss: 1.1904 - accuracy: 0.67 - ETA: 1:48 - loss: 1.1904 - accuracy: 0.67 - ETA: 1:46 - loss: 1.1882 - accuracy: 0.67 - ETA: 1:44 - loss: 1.1910 - accuracy: 0.67 - ETA: 1:42 - loss: 1.1900 - accuracy: 0.67 - ETA: 1:40 - loss: 1.1888 - accuracy: 0.67 - ETA: 1:38 - loss: 1.1870 - accuracy: 0.67 - ETA: 1:37 - loss: 1.1884 - accuracy: 0.67 - ETA: 1:35 - loss: 1.1883 - accuracy: 0.67 - ETA: 1:33 - loss: 1.1888 - accuracy: 0.67 - ETA: 1:31 - loss: 1.1883 - accuracy: 0.67 - ETA: 1:29 - loss: 1.1864 - accuracy: 0.67 - ETA: 1:27 - loss: 1.1858 - accuracy: 0.67 - ETA: 1:25 - loss: 1.1870 - accuracy: 0.67 - ETA: 1:24 - loss: 1.1853 - accuracy: 0.67 - ETA: 1:22 - loss: 1.1854 - accuracy: 0.67 - ETA: 1:20 - loss: 1.1901 - accuracy: 0.66 - ETA: 1:18 - loss: 1.1909 - accuracy: 0.66 - ETA: 1:16 - loss: 1.1915 - accuracy: 0.66 - ETA: 1:14 - loss: 1.1920 - accuracy: 0.66 - ETA: 1:12 - loss: 1.1948 - accuracy: 0.66 - ETA: 1:10 - loss: 1.1937 - accuracy: 0.66 - ETA: 1:09 - loss: 1.1941 - accuracy: 0.66 - ETA: 1:07 - loss: 1.1947 - accuracy: 0.66 - ETA: 1:05 - loss: 1.1934 - accuracy: 0.66 - ETA: 1:03 - loss: 1.1943 - accuracy: 0.66 - ETA: 1:01 - loss: 1.1957 - accuracy: 0.66 - ETA: 59s - loss: 1.1960 - accuracy: 0.6694 - ETA: 57s - loss: 1.1952 - accuracy: 0.669 - ETA: 55s - loss: 1.1938 - accuracy: 0.669 - ETA: 54s - loss: 1.1943 - accuracy: 0.669 - ETA: 52s - loss: 1.1919 - accuracy: 0.670 - ETA: 50s - loss: 1.1925 - accuracy: 0.669 - ETA: 48s - loss: 1.1899 - accuracy: 0.670 - ETA: 46s - loss: 1.1873 - accuracy: 0.671 - ETA: 44s - loss: 1.1881 - accuracy: 0.670 - ETA: 42s - loss: 1.1872 - accuracy: 0.670 - ETA: 40s - loss: 1.1865 - accuracy: 0.670 - ETA: 39s - loss: 1.1881 - accuracy: 0.670 - ETA: 37s - loss: 1.1867 - accuracy: 0.670 - ETA: 35s - loss: 1.1875 - accuracy: 0.670 - ETA: 33s - loss: 1.1878 - accuracy: 0.670 - ETA: 31s - loss: 1.1877 - accuracy: 0.670 - ETA: 29s - loss: 1.1872 - accuracy: 0.670 - ETA: 27s - loss: 1.1868 - accuracy: 0.670 - ETA: 25s - loss: 1.1887 - accuracy: 0.670 - ETA: 24s - loss: 1.1892 - accuracy: 0.670 - ETA: 22s - loss: 1.1904 - accuracy: 0.670 - ETA: 20s - loss: 1.1891 - accuracy: 0.670 - ETA: 18s - loss: 1.1879 - accuracy: 0.670 - ETA: 16s - loss: 1.1872 - accuracy: 0.670 - ETA: 14s - loss: 1.1870 - accuracy: 0.670 - ETA: 12s - loss: 1.1882 - accuracy: 0.670 - ETA: 10s - loss: 1.1887 - accuracy: 0.670 - ETA: 9s - loss: 1.1886 - accuracy: 0.670 - ETA: 7s - loss: 1.1873 - accuracy: 0.67 - ETA: 5s - loss: 1.1893 - accuracy: 0.66 - ETA: 3s - loss: 1.1925 - accuracy: 0.66 - ETA: 1s - loss: 1.1924 - accuracy: 0.66 - 307s 16ms/step - loss: 1.1925 - accuracy: 0.6693 - val_loss: 1.2852 - val_accuracy: 0.6939\n",
      "Epoch 10/100\n",
      "19312/19312 [==============================] - ETA: 5:38 - loss: 1.6993 - accuracy: 0.57 - ETA: 5:01 - loss: 1.5528 - accuracy: 0.60 - ETA: 4:51 - loss: 1.4055 - accuracy: 0.62 - ETA: 4:43 - loss: 1.3497 - accuracy: 0.63 - ETA: 4:38 - loss: 1.2836 - accuracy: 0.64 - ETA: 4:34 - loss: 1.2879 - accuracy: 0.64 - ETA: 4:30 - loss: 1.2666 - accuracy: 0.64 - ETA: 4:27 - loss: 1.2298 - accuracy: 0.66 - ETA: 4:24 - loss: 1.2036 - accuracy: 0.66 - ETA: 4:21 - loss: 1.2102 - accuracy: 0.65 - ETA: 4:18 - loss: 1.2005 - accuracy: 0.66 - ETA: 4:14 - loss: 1.2227 - accuracy: 0.66 - ETA: 4:13 - loss: 1.2055 - accuracy: 0.67 - ETA: 4:12 - loss: 1.1912 - accuracy: 0.67 - ETA: 4:10 - loss: 1.1587 - accuracy: 0.68 - ETA: 4:08 - loss: 1.1524 - accuracy: 0.68 - ETA: 4:07 - loss: 1.1414 - accuracy: 0.68 - ETA: 4:05 - loss: 1.1431 - accuracy: 0.68 - ETA: 4:03 - loss: 1.1351 - accuracy: 0.68 - ETA: 4:01 - loss: 1.1291 - accuracy: 0.68 - ETA: 4:00 - loss: 1.1307 - accuracy: 0.68 - ETA: 3:57 - loss: 1.1137 - accuracy: 0.68 - ETA: 3:55 - loss: 1.1242 - accuracy: 0.68 - ETA: 3:54 - loss: 1.1198 - accuracy: 0.68 - ETA: 3:52 - loss: 1.1180 - accuracy: 0.68 - ETA: 3:50 - loss: 1.1236 - accuracy: 0.68 - ETA: 3:48 - loss: 1.1262 - accuracy: 0.68 - ETA: 3:46 - loss: 1.1277 - accuracy: 0.68 - ETA: 3:45 - loss: 1.1281 - accuracy: 0.68 - ETA: 3:42 - loss: 1.1348 - accuracy: 0.68 - ETA: 3:41 - loss: 1.1288 - accuracy: 0.68 - ETA: 3:39 - loss: 1.1251 - accuracy: 0.68 - ETA: 3:37 - loss: 1.1231 - accuracy: 0.68 - ETA: 3:36 - loss: 1.1432 - accuracy: 0.68 - ETA: 3:34 - loss: 1.1388 - accuracy: 0.68 - ETA: 3:32 - loss: 1.1418 - accuracy: 0.68 - ETA: 3:30 - loss: 1.1522 - accuracy: 0.68 - ETA: 3:28 - loss: 1.1482 - accuracy: 0.68 - ETA: 3:26 - loss: 1.1435 - accuracy: 0.68 - ETA: 3:24 - loss: 1.1509 - accuracy: 0.68 - ETA: 3:22 - loss: 1.1548 - accuracy: 0.68 - ETA: 3:21 - loss: 1.1564 - accuracy: 0.67 - ETA: 3:19 - loss: 1.1573 - accuracy: 0.67 - ETA: 3:17 - loss: 1.1531 - accuracy: 0.67 - ETA: 3:15 - loss: 1.1565 - accuracy: 0.67 - ETA: 3:14 - loss: 1.1603 - accuracy: 0.67 - ETA: 3:12 - loss: 1.1579 - accuracy: 0.67 - ETA: 3:09 - loss: 1.1583 - accuracy: 0.67 - ETA: 3:08 - loss: 1.1590 - accuracy: 0.67 - ETA: 3:06 - loss: 1.1571 - accuracy: 0.67 - ETA: 3:04 - loss: 1.1593 - accuracy: 0.67 - ETA: 3:02 - loss: 1.1644 - accuracy: 0.67 - ETA: 3:00 - loss: 1.1618 - accuracy: 0.67 - ETA: 2:58 - loss: 1.1563 - accuracy: 0.67 - ETA: 2:56 - loss: 1.1558 - accuracy: 0.67 - ETA: 2:55 - loss: 1.1526 - accuracy: 0.67 - ETA: 2:53 - loss: 1.1562 - accuracy: 0.67 - ETA: 2:51 - loss: 1.1542 - accuracy: 0.67 - ETA: 2:49 - loss: 1.1576 - accuracy: 0.67 - ETA: 2:47 - loss: 1.1585 - accuracy: 0.67 - ETA: 2:45 - loss: 1.1567 - accuracy: 0.67 - ETA: 2:43 - loss: 1.1585 - accuracy: 0.67 - ETA: 2:42 - loss: 1.1561 - accuracy: 0.67 - ETA: 2:40 - loss: 1.1552 - accuracy: 0.67 - ETA: 2:38 - loss: 1.1571 - accuracy: 0.67 - ETA: 2:36 - loss: 1.1561 - accuracy: 0.67 - ETA: 2:34 - loss: 1.1603 - accuracy: 0.67 - ETA: 2:33 - loss: 1.1585 - accuracy: 0.67 - ETA: 2:31 - loss: 1.1571 - accuracy: 0.67 - ETA: 2:29 - loss: 1.1575 - accuracy: 0.67 - ETA: 2:27 - loss: 1.1535 - accuracy: 0.67 - ETA: 2:25 - loss: 1.1507 - accuracy: 0.67 - ETA: 2:23 - loss: 1.1509 - accuracy: 0.67 - ETA: 2:21 - loss: 1.1525 - accuracy: 0.67 - ETA: 2:20 - loss: 1.1520 - accuracy: 0.67 - ETA: 2:18 - loss: 1.1510 - accuracy: 0.67 - ETA: 2:16 - loss: 1.1514 - accuracy: 0.67 - ETA: 2:14 - loss: 1.1518 - accuracy: 0.67 - ETA: 2:12 - loss: 1.1520 - accuracy: 0.67 - ETA: 2:10 - loss: 1.1529 - accuracy: 0.67 - ETA: 2:08 - loss: 1.1491 - accuracy: 0.67 - ETA: 2:06 - loss: 1.1525 - accuracy: 0.67 - ETA: 2:04 - loss: 1.1529 - accuracy: 0.67 - ETA: 2:03 - loss: 1.1516 - accuracy: 0.67 - ETA: 2:01 - loss: 1.1532 - accuracy: 0.67 - ETA: 1:59 - loss: 1.1539 - accuracy: 0.67 - ETA: 1:57 - loss: 1.1502 - accuracy: 0.67 - ETA: 1:55 - loss: 1.1498 - accuracy: 0.67 - ETA: 1:53 - loss: 1.1528 - accuracy: 0.67 - ETA: 1:51 - loss: 1.1497 - accuracy: 0.67 - ETA: 1:50 - loss: 1.1531 - accuracy: 0.67 - ETA: 1:48 - loss: 1.1507 - accuracy: 0.67 - ETA: 1:46 - loss: 1.1505 - accuracy: 0.67 - ETA: 1:44 - loss: 1.1473 - accuracy: 0.67 - ETA: 1:42 - loss: 1.1451 - accuracy: 0.67 - ETA: 1:40 - loss: 1.1451 - accuracy: 0.67 - ETA: 1:39 - loss: 1.1440 - accuracy: 0.67 - ETA: 1:37 - loss: 1.1449 - accuracy: 0.67 - ETA: 1:35 - loss: 1.1474 - accuracy: 0.67 - ETA: 1:33 - loss: 1.1471 - accuracy: 0.67 - ETA: 1:31 - loss: 1.1449 - accuracy: 0.67 - ETA: 1:29 - loss: 1.1434 - accuracy: 0.67 - ETA: 1:28 - loss: 1.1441 - accuracy: 0.67 - ETA: 1:26 - loss: 1.1457 - accuracy: 0.67 - ETA: 1:24 - loss: 1.1505 - accuracy: 0.67 - ETA: 1:22 - loss: 1.1501 - accuracy: 0.67 - ETA: 1:20 - loss: 1.1484 - accuracy: 0.67 - ETA: 1:18 - loss: 1.1496 - accuracy: 0.67 - ETA: 1:17 - loss: 1.1496 - accuracy: 0.67 - ETA: 1:15 - loss: 1.1496 - accuracy: 0.67 - ETA: 1:13 - loss: 1.1520 - accuracy: 0.67 - ETA: 1:11 - loss: 1.1538 - accuracy: 0.67 - ETA: 1:09 - loss: 1.1545 - accuracy: 0.67 - ETA: 1:07 - loss: 1.1559 - accuracy: 0.67 - ETA: 1:06 - loss: 1.1593 - accuracy: 0.67 - ETA: 1:04 - loss: 1.1601 - accuracy: 0.67 - ETA: 1:02 - loss: 1.1615 - accuracy: 0.67 - ETA: 1:00 - loss: 1.1622 - accuracy: 0.67 - ETA: 58s - loss: 1.1605 - accuracy: 0.6738 - ETA: 56s - loss: 1.1590 - accuracy: 0.674 - ETA: 55s - loss: 1.1598 - accuracy: 0.673 - ETA: 53s - loss: 1.1600 - accuracy: 0.673 - ETA: 51s - loss: 1.1600 - accuracy: 0.673 - ETA: 49s - loss: 1.1588 - accuracy: 0.673 - ETA: 47s - loss: 1.1598 - accuracy: 0.673 - ETA: 45s - loss: 1.1592 - accuracy: 0.673 - ETA: 44s - loss: 1.1579 - accuracy: 0.673 - ETA: 42s - loss: 1.1585 - accuracy: 0.673 - ETA: 40s - loss: 1.1590 - accuracy: 0.673 - ETA: 38s - loss: 1.1582 - accuracy: 0.674 - ETA: 36s - loss: 1.1587 - accuracy: 0.673 - ETA: 34s - loss: 1.1560 - accuracy: 0.674 - ETA: 32s - loss: 1.1558 - accuracy: 0.673 - ETA: 31s - loss: 1.1561 - accuracy: 0.673 - ETA: 29s - loss: 1.1554 - accuracy: 0.673 - ETA: 27s - loss: 1.1590 - accuracy: 0.673 - ETA: 25s - loss: 1.1597 - accuracy: 0.673 - ETA: 23s - loss: 1.1586 - accuracy: 0.673 - ETA: 21s - loss: 1.1600 - accuracy: 0.673 - ETA: 20s - loss: 1.1600 - accuracy: 0.673 - ETA: 18s - loss: 1.1595 - accuracy: 0.673 - ETA: 16s - loss: 1.1595 - accuracy: 0.673 - ETA: 14s - loss: 1.1582 - accuracy: 0.674 - ETA: 12s - loss: 1.1562 - accuracy: 0.674 - ETA: 10s - loss: 1.1564 - accuracy: 0.674 - ETA: 9s - loss: 1.1581 - accuracy: 0.674 - ETA: 7s - loss: 1.1584 - accuracy: 0.67 - ETA: 5s - loss: 1.1595 - accuracy: 0.67 - ETA: 3s - loss: 1.1585 - accuracy: 0.67 - ETA: 1s - loss: 1.1588 - accuracy: 0.67 - 305s 16ms/step - loss: 1.1556 - accuracy: 0.6753 - val_loss: 1.2767 - val_accuracy: 0.6929\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:08 - loss: 0.7362 - accuracy: 0.75 - ETA: 6:00 - loss: 0.8250 - accuracy: 0.73 - ETA: 5:40 - loss: 0.9231 - accuracy: 0.71 - ETA: 5:20 - loss: 0.9377 - accuracy: 0.71 - ETA: 5:08 - loss: 0.9301 - accuracy: 0.71 - ETA: 5:01 - loss: 0.9396 - accuracy: 0.70 - ETA: 4:55 - loss: 0.9289 - accuracy: 0.71 - ETA: 4:47 - loss: 0.9379 - accuracy: 0.71 - ETA: 4:42 - loss: 0.9840 - accuracy: 0.71 - ETA: 4:37 - loss: 0.9882 - accuracy: 0.71 - ETA: 4:35 - loss: 1.0328 - accuracy: 0.70 - ETA: 4:31 - loss: 1.0720 - accuracy: 0.69 - ETA: 4:26 - loss: 1.0895 - accuracy: 0.69 - ETA: 4:23 - loss: 1.0850 - accuracy: 0.69 - ETA: 4:19 - loss: 1.0824 - accuracy: 0.69 - ETA: 4:16 - loss: 1.0870 - accuracy: 0.68 - ETA: 4:13 - loss: 1.0893 - accuracy: 0.68 - ETA: 4:11 - loss: 1.1115 - accuracy: 0.68 - ETA: 4:07 - loss: 1.1309 - accuracy: 0.68 - ETA: 4:05 - loss: 1.1287 - accuracy: 0.67 - ETA: 4:03 - loss: 1.1213 - accuracy: 0.68 - ETA: 4:00 - loss: 1.1161 - accuracy: 0.68 - ETA: 3:58 - loss: 1.1283 - accuracy: 0.67 - ETA: 3:56 - loss: 1.1259 - accuracy: 0.67 - ETA: 3:54 - loss: 1.1338 - accuracy: 0.67 - ETA: 3:51 - loss: 1.1386 - accuracy: 0.67 - ETA: 3:49 - loss: 1.1331 - accuracy: 0.68 - ETA: 3:47 - loss: 1.1209 - accuracy: 0.68 - ETA: 3:45 - loss: 1.1175 - accuracy: 0.68 - ETA: 3:43 - loss: 1.1231 - accuracy: 0.68 - ETA: 3:40 - loss: 1.1188 - accuracy: 0.68 - ETA: 3:38 - loss: 1.1088 - accuracy: 0.68 - ETA: 3:36 - loss: 1.1137 - accuracy: 0.68 - ETA: 3:34 - loss: 1.1124 - accuracy: 0.68 - ETA: 3:32 - loss: 1.1168 - accuracy: 0.68 - ETA: 3:30 - loss: 1.1210 - accuracy: 0.68 - ETA: 3:28 - loss: 1.1206 - accuracy: 0.68 - ETA: 3:26 - loss: 1.1178 - accuracy: 0.68 - ETA: 3:24 - loss: 1.1110 - accuracy: 0.68 - ETA: 3:22 - loss: 1.1056 - accuracy: 0.68 - ETA: 3:21 - loss: 1.0981 - accuracy: 0.68 - ETA: 3:19 - loss: 1.0966 - accuracy: 0.68 - ETA: 3:17 - loss: 1.1078 - accuracy: 0.68 - ETA: 3:15 - loss: 1.1068 - accuracy: 0.68 - ETA: 3:13 - loss: 1.1058 - accuracy: 0.68 - ETA: 3:11 - loss: 1.1079 - accuracy: 0.68 - ETA: 3:10 - loss: 1.1085 - accuracy: 0.68 - ETA: 3:08 - loss: 1.1077 - accuracy: 0.68 - ETA: 3:06 - loss: 1.1100 - accuracy: 0.68 - ETA: 3:04 - loss: 1.1106 - accuracy: 0.68 - ETA: 3:02 - loss: 1.1086 - accuracy: 0.68 - ETA: 3:00 - loss: 1.1039 - accuracy: 0.68 - ETA: 2:58 - loss: 1.1008 - accuracy: 0.68 - ETA: 2:57 - loss: 1.1054 - accuracy: 0.68 - ETA: 2:55 - loss: 1.1061 - accuracy: 0.68 - ETA: 2:53 - loss: 1.1056 - accuracy: 0.68 - ETA: 2:51 - loss: 1.1001 - accuracy: 0.68 - ETA: 2:50 - loss: 1.0999 - accuracy: 0.68 - ETA: 2:48 - loss: 1.0982 - accuracy: 0.68 - ETA: 2:46 - loss: 1.0993 - accuracy: 0.68 - ETA: 2:44 - loss: 1.1005 - accuracy: 0.68 - ETA: 2:43 - loss: 1.0982 - accuracy: 0.68 - ETA: 2:41 - loss: 1.0978 - accuracy: 0.68 - ETA: 2:39 - loss: 1.0956 - accuracy: 0.68 - ETA: 2:37 - loss: 1.1001 - accuracy: 0.68 - ETA: 2:35 - loss: 1.0956 - accuracy: 0.68 - ETA: 2:33 - loss: 1.0961 - accuracy: 0.68 - ETA: 2:32 - loss: 1.0987 - accuracy: 0.68 - ETA: 2:30 - loss: 1.1020 - accuracy: 0.68 - ETA: 2:28 - loss: 1.1012 - accuracy: 0.68 - ETA: 2:26 - loss: 1.0987 - accuracy: 0.68 - ETA: 2:24 - loss: 1.1003 - accuracy: 0.68 - ETA: 2:23 - loss: 1.0968 - accuracy: 0.68 - ETA: 2:21 - loss: 1.0960 - accuracy: 0.68 - ETA: 2:19 - loss: 1.0982 - accuracy: 0.68 - ETA: 2:17 - loss: 1.0992 - accuracy: 0.68 - ETA: 2:16 - loss: 1.0977 - accuracy: 0.68 - ETA: 2:14 - loss: 1.0972 - accuracy: 0.68 - ETA: 2:12 - loss: 1.0989 - accuracy: 0.68 - ETA: 2:10 - loss: 1.0978 - accuracy: 0.68 - ETA: 2:08 - loss: 1.0979 - accuracy: 0.68 - ETA: 2:06 - loss: 1.1025 - accuracy: 0.68 - ETA: 2:04 - loss: 1.1033 - accuracy: 0.68 - ETA: 2:02 - loss: 1.1014 - accuracy: 0.68 - ETA: 2:01 - loss: 1.1023 - accuracy: 0.68 - ETA: 1:59 - loss: 1.1040 - accuracy: 0.68 - ETA: 1:57 - loss: 1.1034 - accuracy: 0.68 - ETA: 1:55 - loss: 1.1036 - accuracy: 0.68 - ETA: 1:53 - loss: 1.1031 - accuracy: 0.68 - ETA: 1:51 - loss: 1.1063 - accuracy: 0.68 - ETA: 1:49 - loss: 1.1071 - accuracy: 0.68 - ETA: 1:48 - loss: 1.1114 - accuracy: 0.68 - ETA: 1:46 - loss: 1.1104 - accuracy: 0.68 - ETA: 1:44 - loss: 1.1111 - accuracy: 0.68 - ETA: 1:42 - loss: 1.1143 - accuracy: 0.68 - ETA: 1:40 - loss: 1.1126 - accuracy: 0.68 - ETA: 1:38 - loss: 1.1124 - accuracy: 0.68 - ETA: 1:37 - loss: 1.1105 - accuracy: 0.68 - ETA: 1:35 - loss: 1.1123 - accuracy: 0.68 - ETA: 1:33 - loss: 1.1116 - accuracy: 0.68 - ETA: 1:31 - loss: 1.1149 - accuracy: 0.68 - ETA: 1:29 - loss: 1.1154 - accuracy: 0.68 - ETA: 1:27 - loss: 1.1171 - accuracy: 0.68 - ETA: 1:26 - loss: 1.1168 - accuracy: 0.68 - ETA: 1:24 - loss: 1.1172 - accuracy: 0.68 - ETA: 1:22 - loss: 1.1133 - accuracy: 0.68 - ETA: 1:20 - loss: 1.1135 - accuracy: 0.68 - ETA: 1:18 - loss: 1.1123 - accuracy: 0.68 - ETA: 1:16 - loss: 1.1118 - accuracy: 0.68 - ETA: 1:15 - loss: 1.1113 - accuracy: 0.68 - ETA: 1:13 - loss: 1.1121 - accuracy: 0.68 - ETA: 1:11 - loss: 1.1118 - accuracy: 0.68 - ETA: 1:09 - loss: 1.1135 - accuracy: 0.68 - ETA: 1:07 - loss: 1.1128 - accuracy: 0.68 - ETA: 1:06 - loss: 1.1135 - accuracy: 0.68 - ETA: 1:04 - loss: 1.1105 - accuracy: 0.68 - ETA: 1:02 - loss: 1.1097 - accuracy: 0.68 - ETA: 1:00 - loss: 1.1085 - accuracy: 0.68 - ETA: 58s - loss: 1.1073 - accuracy: 0.6859 - ETA: 56s - loss: 1.1078 - accuracy: 0.685 - ETA: 54s - loss: 1.1109 - accuracy: 0.685 - ETA: 53s - loss: 1.1119 - accuracy: 0.685 - ETA: 51s - loss: 1.1147 - accuracy: 0.685 - ETA: 49s - loss: 1.1124 - accuracy: 0.685 - ETA: 47s - loss: 1.1132 - accuracy: 0.685 - ETA: 45s - loss: 1.1124 - accuracy: 0.685 - ETA: 43s - loss: 1.1127 - accuracy: 0.685 - ETA: 42s - loss: 1.1140 - accuracy: 0.684 - ETA: 40s - loss: 1.1114 - accuracy: 0.685 - ETA: 38s - loss: 1.1098 - accuracy: 0.685 - ETA: 36s - loss: 1.1104 - accuracy: 0.684 - ETA: 34s - loss: 1.1110 - accuracy: 0.684 - ETA: 32s - loss: 1.1098 - accuracy: 0.685 - ETA: 31s - loss: 1.1089 - accuracy: 0.685 - ETA: 29s - loss: 1.1090 - accuracy: 0.685 - ETA: 27s - loss: 1.1059 - accuracy: 0.686 - ETA: 25s - loss: 1.1084 - accuracy: 0.686 - ETA: 23s - loss: 1.1078 - accuracy: 0.686 - ETA: 21s - loss: 1.1079 - accuracy: 0.686 - ETA: 20s - loss: 1.1091 - accuracy: 0.685 - ETA: 18s - loss: 1.1098 - accuracy: 0.685 - ETA: 16s - loss: 1.1121 - accuracy: 0.685 - ETA: 14s - loss: 1.1125 - accuracy: 0.685 - ETA: 12s - loss: 1.1118 - accuracy: 0.685 - ETA: 10s - loss: 1.1113 - accuracy: 0.685 - ETA: 8s - loss: 1.1099 - accuracy: 0.685 - ETA: 7s - loss: 1.1114 - accuracy: 0.68 - ETA: 5s - loss: 1.1129 - accuracy: 0.68 - ETA: 3s - loss: 1.1136 - accuracy: 0.68 - ETA: 1s - loss: 1.1124 - accuracy: 0.68 - 303s 16ms/step - loss: 1.1120 - accuracy: 0.6855 - val_loss: 1.2795 - val_accuracy: 0.6989\n",
      "Epoch 12/100\n",
      "19312/19312 [==============================] - ETA: 5:20 - loss: 1.0107 - accuracy: 0.70 - ETA: 5:08 - loss: 1.0049 - accuracy: 0.69 - ETA: 4:54 - loss: 1.1259 - accuracy: 0.66 - ETA: 4:46 - loss: 1.1568 - accuracy: 0.66 - ETA: 4:41 - loss: 1.1273 - accuracy: 0.66 - ETA: 4:39 - loss: 1.1693 - accuracy: 0.67 - ETA: 4:37 - loss: 1.1523 - accuracy: 0.67 - ETA: 4:33 - loss: 1.1773 - accuracy: 0.68 - ETA: 4:33 - loss: 1.1658 - accuracy: 0.68 - ETA: 4:31 - loss: 1.1432 - accuracy: 0.68 - ETA: 4:30 - loss: 1.1500 - accuracy: 0.67 - ETA: 4:29 - loss: 1.1544 - accuracy: 0.67 - ETA: 4:26 - loss: 1.1419 - accuracy: 0.68 - ETA: 4:23 - loss: 1.1354 - accuracy: 0.68 - ETA: 4:22 - loss: 1.1169 - accuracy: 0.68 - ETA: 4:19 - loss: 1.1160 - accuracy: 0.68 - ETA: 4:18 - loss: 1.1279 - accuracy: 0.68 - ETA: 4:15 - loss: 1.1216 - accuracy: 0.68 - ETA: 4:13 - loss: 1.1167 - accuracy: 0.68 - ETA: 4:10 - loss: 1.1054 - accuracy: 0.68 - ETA: 4:08 - loss: 1.1002 - accuracy: 0.68 - ETA: 4:05 - loss: 1.1098 - accuracy: 0.68 - ETA: 4:04 - loss: 1.1021 - accuracy: 0.68 - ETA: 4:02 - loss: 1.1097 - accuracy: 0.68 - ETA: 3:59 - loss: 1.1089 - accuracy: 0.68 - ETA: 3:57 - loss: 1.1145 - accuracy: 0.68 - ETA: 3:55 - loss: 1.1258 - accuracy: 0.68 - ETA: 3:53 - loss: 1.1249 - accuracy: 0.68 - ETA: 3:51 - loss: 1.1366 - accuracy: 0.68 - ETA: 3:48 - loss: 1.1285 - accuracy: 0.68 - ETA: 3:46 - loss: 1.1283 - accuracy: 0.68 - ETA: 3:45 - loss: 1.1372 - accuracy: 0.68 - ETA: 3:42 - loss: 1.1342 - accuracy: 0.68 - ETA: 3:41 - loss: 1.1305 - accuracy: 0.68 - ETA: 3:39 - loss: 1.1202 - accuracy: 0.68 - ETA: 3:37 - loss: 1.1209 - accuracy: 0.68 - ETA: 3:36 - loss: 1.1224 - accuracy: 0.68 - ETA: 3:33 - loss: 1.1185 - accuracy: 0.68 - ETA: 3:32 - loss: 1.1185 - accuracy: 0.68 - ETA: 3:30 - loss: 1.1237 - accuracy: 0.68 - ETA: 3:27 - loss: 1.1202 - accuracy: 0.68 - ETA: 3:25 - loss: 1.1150 - accuracy: 0.68 - ETA: 3:24 - loss: 1.1148 - accuracy: 0.68 - ETA: 3:22 - loss: 1.1210 - accuracy: 0.68 - ETA: 3:20 - loss: 1.1181 - accuracy: 0.68 - ETA: 3:18 - loss: 1.1220 - accuracy: 0.68 - ETA: 3:16 - loss: 1.1208 - accuracy: 0.68 - ETA: 3:14 - loss: 1.1190 - accuracy: 0.68 - ETA: 3:12 - loss: 1.1162 - accuracy: 0.68 - ETA: 3:10 - loss: 1.1216 - accuracy: 0.68 - ETA: 3:08 - loss: 1.1174 - accuracy: 0.69 - ETA: 3:06 - loss: 1.1194 - accuracy: 0.68 - ETA: 3:05 - loss: 1.1163 - accuracy: 0.68 - ETA: 3:03 - loss: 1.1177 - accuracy: 0.68 - ETA: 3:01 - loss: 1.1163 - accuracy: 0.69 - ETA: 2:59 - loss: 1.1155 - accuracy: 0.69 - ETA: 2:57 - loss: 1.1165 - accuracy: 0.69 - ETA: 2:55 - loss: 1.1196 - accuracy: 0.68 - ETA: 2:53 - loss: 1.1138 - accuracy: 0.69 - ETA: 2:51 - loss: 1.1120 - accuracy: 0.69 - ETA: 2:49 - loss: 1.1162 - accuracy: 0.68 - ETA: 2:47 - loss: 1.1210 - accuracy: 0.68 - ETA: 2:45 - loss: 1.1169 - accuracy: 0.68 - ETA: 2:43 - loss: 1.1162 - accuracy: 0.68 - ETA: 2:41 - loss: 1.1197 - accuracy: 0.68 - ETA: 2:39 - loss: 1.1203 - accuracy: 0.68 - ETA: 2:37 - loss: 1.1164 - accuracy: 0.68 - ETA: 2:35 - loss: 1.1108 - accuracy: 0.69 - ETA: 2:33 - loss: 1.1125 - accuracy: 0.69 - ETA: 2:31 - loss: 1.1127 - accuracy: 0.69 - ETA: 2:29 - loss: 1.1137 - accuracy: 0.69 - ETA: 2:27 - loss: 1.1104 - accuracy: 0.69 - ETA: 2:25 - loss: 1.1093 - accuracy: 0.69 - ETA: 2:24 - loss: 1.1083 - accuracy: 0.69 - ETA: 2:22 - loss: 1.1066 - accuracy: 0.69 - ETA: 2:20 - loss: 1.1087 - accuracy: 0.69 - ETA: 2:18 - loss: 1.1071 - accuracy: 0.69 - ETA: 2:16 - loss: 1.1057 - accuracy: 0.69 - ETA: 2:14 - loss: 1.1070 - accuracy: 0.69 - ETA: 2:12 - loss: 1.1092 - accuracy: 0.69 - ETA: 2:10 - loss: 1.1043 - accuracy: 0.69 - ETA: 2:08 - loss: 1.1098 - accuracy: 0.69 - ETA: 2:07 - loss: 1.1109 - accuracy: 0.69 - ETA: 2:05 - loss: 1.1105 - accuracy: 0.69 - ETA: 2:03 - loss: 1.1087 - accuracy: 0.69 - ETA: 2:01 - loss: 1.1073 - accuracy: 0.69 - ETA: 1:59 - loss: 1.1063 - accuracy: 0.69 - ETA: 1:57 - loss: 1.1061 - accuracy: 0.69 - ETA: 1:55 - loss: 1.1048 - accuracy: 0.69 - ETA: 1:53 - loss: 1.1029 - accuracy: 0.69 - ETA: 1:52 - loss: 1.1007 - accuracy: 0.69 - ETA: 1:50 - loss: 1.1017 - accuracy: 0.69 - ETA: 1:48 - loss: 1.0992 - accuracy: 0.69 - ETA: 1:46 - loss: 1.1009 - accuracy: 0.69 - ETA: 1:44 - loss: 1.0986 - accuracy: 0.69 - ETA: 1:42 - loss: 1.0967 - accuracy: 0.69 - ETA: 1:40 - loss: 1.0986 - accuracy: 0.69 - ETA: 1:38 - loss: 1.0984 - accuracy: 0.69 - ETA: 1:37 - loss: 1.0982 - accuracy: 0.69 - ETA: 1:35 - loss: 1.1001 - accuracy: 0.69 - ETA: 1:33 - loss: 1.0998 - accuracy: 0.69 - ETA: 1:31 - loss: 1.0979 - accuracy: 0.69 - ETA: 1:29 - loss: 1.0971 - accuracy: 0.69 - ETA: 1:27 - loss: 1.0978 - accuracy: 0.69 - ETA: 1:25 - loss: 1.0999 - accuracy: 0.68 - ETA: 1:23 - loss: 1.0977 - accuracy: 0.69 - ETA: 1:22 - loss: 1.0996 - accuracy: 0.69 - ETA: 1:20 - loss: 1.1017 - accuracy: 0.68 - ETA: 1:18 - loss: 1.1025 - accuracy: 0.68 - ETA: 1:16 - loss: 1.1025 - accuracy: 0.68 - ETA: 1:14 - loss: 1.1009 - accuracy: 0.69 - ETA: 1:12 - loss: 1.1000 - accuracy: 0.69 - ETA: 1:10 - loss: 1.1004 - accuracy: 0.68 - ETA: 1:09 - loss: 1.1008 - accuracy: 0.68 - ETA: 1:07 - loss: 1.1082 - accuracy: 0.68 - ETA: 1:05 - loss: 1.1084 - accuracy: 0.68 - ETA: 1:03 - loss: 1.1070 - accuracy: 0.68 - ETA: 1:01 - loss: 1.1100 - accuracy: 0.68 - ETA: 59s - loss: 1.1112 - accuracy: 0.6891 - ETA: 57s - loss: 1.1133 - accuracy: 0.689 - ETA: 55s - loss: 1.1129 - accuracy: 0.689 - ETA: 54s - loss: 1.1148 - accuracy: 0.689 - ETA: 52s - loss: 1.1152 - accuracy: 0.689 - ETA: 50s - loss: 1.1158 - accuracy: 0.689 - ETA: 48s - loss: 1.1140 - accuracy: 0.689 - ETA: 46s - loss: 1.1132 - accuracy: 0.689 - ETA: 44s - loss: 1.1118 - accuracy: 0.690 - ETA: 42s - loss: 1.1120 - accuracy: 0.689 - ETA: 40s - loss: 1.1152 - accuracy: 0.689 - ETA: 39s - loss: 1.1137 - accuracy: 0.689 - ETA: 37s - loss: 1.1145 - accuracy: 0.689 - ETA: 35s - loss: 1.1119 - accuracy: 0.690 - ETA: 33s - loss: 1.1130 - accuracy: 0.690 - ETA: 31s - loss: 1.1150 - accuracy: 0.689 - ETA: 29s - loss: 1.1166 - accuracy: 0.689 - ETA: 27s - loss: 1.1156 - accuracy: 0.690 - ETA: 26s - loss: 1.1149 - accuracy: 0.690 - ETA: 24s - loss: 1.1154 - accuracy: 0.689 - ETA: 22s - loss: 1.1162 - accuracy: 0.689 - ETA: 20s - loss: 1.1156 - accuracy: 0.689 - ETA: 18s - loss: 1.1156 - accuracy: 0.689 - ETA: 16s - loss: 1.1152 - accuracy: 0.689 - ETA: 14s - loss: 1.1140 - accuracy: 0.690 - ETA: 12s - loss: 1.1149 - accuracy: 0.689 - ETA: 11s - loss: 1.1158 - accuracy: 0.689 - ETA: 9s - loss: 1.1159 - accuracy: 0.689 - ETA: 7s - loss: 1.1163 - accuracy: 0.68 - ETA: 5s - loss: 1.1190 - accuracy: 0.68 - ETA: 3s - loss: 1.1169 - accuracy: 0.68 - ETA: 1s - loss: 1.1159 - accuracy: 0.68 - 308s 16ms/step - loss: 1.1161 - accuracy: 0.6894 - val_loss: 1.2902 - val_accuracy: 0.6997\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:49 - loss: 1.1085 - accuracy: 0.66 - ETA: 4:37 - loss: 1.0679 - accuracy: 0.68 - ETA: 4:36 - loss: 0.9883 - accuracy: 0.70 - ETA: 4:34 - loss: 1.0288 - accuracy: 0.70 - ETA: 4:32 - loss: 1.0182 - accuracy: 0.70 - ETA: 4:31 - loss: 1.0743 - accuracy: 0.68 - ETA: 4:28 - loss: 1.0882 - accuracy: 0.68 - ETA: 4:26 - loss: 1.0537 - accuracy: 0.69 - ETA: 4:24 - loss: 1.0668 - accuracy: 0.69 - ETA: 4:23 - loss: 1.0590 - accuracy: 0.69 - ETA: 4:21 - loss: 1.0767 - accuracy: 0.69 - ETA: 4:19 - loss: 1.0826 - accuracy: 0.69 - ETA: 4:18 - loss: 1.0650 - accuracy: 0.69 - ETA: 4:16 - loss: 1.0575 - accuracy: 0.69 - ETA: 4:13 - loss: 1.0352 - accuracy: 0.69 - ETA: 4:11 - loss: 1.0348 - accuracy: 0.69 - ETA: 4:09 - loss: 1.0300 - accuracy: 0.70 - ETA: 4:07 - loss: 1.0359 - accuracy: 0.69 - ETA: 4:06 - loss: 1.0333 - accuracy: 0.70 - ETA: 4:04 - loss: 1.0358 - accuracy: 0.70 - ETA: 4:02 - loss: 1.0495 - accuracy: 0.70 - ETA: 4:01 - loss: 1.0717 - accuracy: 0.69 - ETA: 3:58 - loss: 1.0630 - accuracy: 0.70 - ETA: 3:57 - loss: 1.0662 - accuracy: 0.70 - ETA: 3:55 - loss: 1.0615 - accuracy: 0.70 - ETA: 3:53 - loss: 1.0763 - accuracy: 0.70 - ETA: 3:52 - loss: 1.0901 - accuracy: 0.70 - ETA: 3:50 - loss: 1.0869 - accuracy: 0.70 - ETA: 3:48 - loss: 1.0867 - accuracy: 0.70 - ETA: 3:45 - loss: 1.0873 - accuracy: 0.70 - ETA: 3:43 - loss: 1.0829 - accuracy: 0.70 - ETA: 3:41 - loss: 1.0766 - accuracy: 0.70 - ETA: 3:39 - loss: 1.0806 - accuracy: 0.70 - ETA: 3:37 - loss: 1.0723 - accuracy: 0.70 - ETA: 3:35 - loss: 1.0716 - accuracy: 0.70 - ETA: 3:34 - loss: 1.0710 - accuracy: 0.70 - ETA: 3:31 - loss: 1.0783 - accuracy: 0.70 - ETA: 3:30 - loss: 1.0712 - accuracy: 0.70 - ETA: 3:28 - loss: 1.0817 - accuracy: 0.70 - ETA: 3:26 - loss: 1.0766 - accuracy: 0.71 - ETA: 3:24 - loss: 1.0802 - accuracy: 0.70 - ETA: 3:22 - loss: 1.0796 - accuracy: 0.70 - ETA: 3:21 - loss: 1.0821 - accuracy: 0.70 - ETA: 3:19 - loss: 1.0809 - accuracy: 0.70 - ETA: 3:17 - loss: 1.0772 - accuracy: 0.70 - ETA: 3:15 - loss: 1.0729 - accuracy: 0.71 - ETA: 3:13 - loss: 1.0701 - accuracy: 0.71 - ETA: 3:11 - loss: 1.0681 - accuracy: 0.71 - ETA: 3:09 - loss: 1.0671 - accuracy: 0.71 - ETA: 3:08 - loss: 1.0654 - accuracy: 0.71 - ETA: 3:06 - loss: 1.0684 - accuracy: 0.70 - ETA: 3:04 - loss: 1.0736 - accuracy: 0.70 - ETA: 3:02 - loss: 1.0709 - accuracy: 0.70 - ETA: 3:00 - loss: 1.0703 - accuracy: 0.70 - ETA: 2:58 - loss: 1.0725 - accuracy: 0.70 - ETA: 2:56 - loss: 1.0703 - accuracy: 0.70 - ETA: 2:54 - loss: 1.0679 - accuracy: 0.70 - ETA: 2:52 - loss: 1.0710 - accuracy: 0.70 - ETA: 2:51 - loss: 1.0711 - accuracy: 0.70 - ETA: 2:49 - loss: 1.0707 - accuracy: 0.70 - ETA: 2:47 - loss: 1.0709 - accuracy: 0.70 - ETA: 2:45 - loss: 1.0672 - accuracy: 0.70 - ETA: 2:43 - loss: 1.0614 - accuracy: 0.70 - ETA: 2:41 - loss: 1.0621 - accuracy: 0.70 - ETA: 2:39 - loss: 1.0637 - accuracy: 0.70 - ETA: 2:37 - loss: 1.0702 - accuracy: 0.70 - ETA: 2:36 - loss: 1.0732 - accuracy: 0.70 - ETA: 2:34 - loss: 1.0754 - accuracy: 0.70 - ETA: 2:32 - loss: 1.0716 - accuracy: 0.70 - ETA: 2:30 - loss: 1.0732 - accuracy: 0.70 - ETA: 2:28 - loss: 1.0738 - accuracy: 0.70 - ETA: 2:26 - loss: 1.0722 - accuracy: 0.70 - ETA: 2:25 - loss: 1.0755 - accuracy: 0.70 - ETA: 2:23 - loss: 1.0734 - accuracy: 0.70 - ETA: 2:21 - loss: 1.0737 - accuracy: 0.70 - ETA: 2:19 - loss: 1.0721 - accuracy: 0.70 - ETA: 2:17 - loss: 1.0710 - accuracy: 0.70 - ETA: 2:15 - loss: 1.0722 - accuracy: 0.70 - ETA: 2:13 - loss: 1.0705 - accuracy: 0.70 - ETA: 2:11 - loss: 1.0697 - accuracy: 0.70 - ETA: 2:09 - loss: 1.0683 - accuracy: 0.70 - ETA: 2:08 - loss: 1.0687 - accuracy: 0.70 - ETA: 2:06 - loss: 1.0715 - accuracy: 0.70 - ETA: 2:04 - loss: 1.0692 - accuracy: 0.70 - ETA: 2:02 - loss: 1.0669 - accuracy: 0.70 - ETA: 2:00 - loss: 1.0673 - accuracy: 0.70 - ETA: 1:58 - loss: 1.0643 - accuracy: 0.70 - ETA: 1:56 - loss: 1.0639 - accuracy: 0.70 - ETA: 1:55 - loss: 1.0652 - accuracy: 0.70 - ETA: 1:53 - loss: 1.0684 - accuracy: 0.70 - ETA: 1:51 - loss: 1.0711 - accuracy: 0.70 - ETA: 1:49 - loss: 1.0724 - accuracy: 0.70 - ETA: 1:47 - loss: 1.0743 - accuracy: 0.70 - ETA: 1:45 - loss: 1.0764 - accuracy: 0.70 - ETA: 1:44 - loss: 1.0790 - accuracy: 0.70 - ETA: 1:42 - loss: 1.0787 - accuracy: 0.70 - ETA: 1:40 - loss: 1.0781 - accuracy: 0.70 - ETA: 1:38 - loss: 1.0782 - accuracy: 0.70 - ETA: 1:36 - loss: 1.0820 - accuracy: 0.70 - ETA: 1:34 - loss: 1.0796 - accuracy: 0.70 - ETA: 1:33 - loss: 1.0801 - accuracy: 0.70 - ETA: 1:31 - loss: 1.0789 - accuracy: 0.70 - ETA: 1:29 - loss: 1.0798 - accuracy: 0.70 - ETA: 1:27 - loss: 1.0796 - accuracy: 0.70 - ETA: 1:25 - loss: 1.0799 - accuracy: 0.70 - ETA: 1:23 - loss: 1.0790 - accuracy: 0.70 - ETA: 1:21 - loss: 1.0797 - accuracy: 0.70 - ETA: 1:19 - loss: 1.0786 - accuracy: 0.70 - ETA: 1:18 - loss: 1.0788 - accuracy: 0.70 - ETA: 1:16 - loss: 1.0795 - accuracy: 0.70 - ETA: 1:14 - loss: 1.0786 - accuracy: 0.70 - ETA: 1:12 - loss: 1.0790 - accuracy: 0.70 - ETA: 1:10 - loss: 1.0785 - accuracy: 0.70 - ETA: 1:08 - loss: 1.0779 - accuracy: 0.70 - ETA: 1:06 - loss: 1.0813 - accuracy: 0.70 - ETA: 1:04 - loss: 1.0818 - accuracy: 0.70 - ETA: 1:03 - loss: 1.0809 - accuracy: 0.70 - ETA: 1:01 - loss: 1.0815 - accuracy: 0.70 - ETA: 59s - loss: 1.0809 - accuracy: 0.7037 - ETA: 57s - loss: 1.0829 - accuracy: 0.703 - ETA: 55s - loss: 1.0819 - accuracy: 0.703 - ETA: 53s - loss: 1.0833 - accuracy: 0.703 - ETA: 51s - loss: 1.0823 - accuracy: 0.703 - ETA: 49s - loss: 1.0803 - accuracy: 0.704 - ETA: 48s - loss: 1.0805 - accuracy: 0.703 - ETA: 46s - loss: 1.0805 - accuracy: 0.703 - ETA: 44s - loss: 1.0836 - accuracy: 0.703 - ETA: 42s - loss: 1.0820 - accuracy: 0.703 - ETA: 40s - loss: 1.0822 - accuracy: 0.703 - ETA: 38s - loss: 1.0813 - accuracy: 0.703 - ETA: 36s - loss: 1.0804 - accuracy: 0.703 - ETA: 35s - loss: 1.0801 - accuracy: 0.703 - ETA: 33s - loss: 1.0788 - accuracy: 0.703 - ETA: 31s - loss: 1.0786 - accuracy: 0.703 - ETA: 29s - loss: 1.0789 - accuracy: 0.703 - ETA: 27s - loss: 1.0787 - accuracy: 0.703 - ETA: 25s - loss: 1.0762 - accuracy: 0.703 - ETA: 23s - loss: 1.0780 - accuracy: 0.703 - ETA: 22s - loss: 1.0781 - accuracy: 0.702 - ETA: 20s - loss: 1.0768 - accuracy: 0.702 - ETA: 18s - loss: 1.0754 - accuracy: 0.702 - ETA: 16s - loss: 1.0762 - accuracy: 0.702 - ETA: 14s - loss: 1.0769 - accuracy: 0.702 - ETA: 12s - loss: 1.0767 - accuracy: 0.702 - ETA: 10s - loss: 1.0764 - accuracy: 0.702 - ETA: 9s - loss: 1.0746 - accuracy: 0.702 - ETA: 7s - loss: 1.0749 - accuracy: 0.70 - ETA: 5s - loss: 1.0730 - accuracy: 0.70 - ETA: 3s - loss: 1.0734 - accuracy: 0.70 - ETA: 1s - loss: 1.0735 - accuracy: 0.70 - 306s 16ms/step - loss: 1.0727 - accuracy: 0.7027 - val_loss: 1.2812 - val_accuracy: 0.7080\n",
      "Epoch 14/100\n",
      "19312/19312 [==============================] - ETA: 4:45 - loss: 1.2057 - accuracy: 0.64 - ETA: 4:44 - loss: 1.1166 - accuracy: 0.67 - ETA: 4:46 - loss: 1.0485 - accuracy: 0.67 - ETA: 4:36 - loss: 1.0427 - accuracy: 0.66 - ETA: 4:33 - loss: 1.0262 - accuracy: 0.67 - ETA: 4:32 - loss: 1.1414 - accuracy: 0.68 - ETA: 4:28 - loss: 1.1248 - accuracy: 0.68 - ETA: 4:25 - loss: 1.0838 - accuracy: 0.69 - ETA: 4:23 - loss: 1.0672 - accuracy: 0.69 - ETA: 4:20 - loss: 1.0508 - accuracy: 0.70 - ETA: 4:17 - loss: 1.0591 - accuracy: 0.69 - ETA: 4:15 - loss: 1.0510 - accuracy: 0.70 - ETA: 4:14 - loss: 1.0420 - accuracy: 0.70 - ETA: 4:12 - loss: 1.0318 - accuracy: 0.70 - ETA: 4:10 - loss: 1.0281 - accuracy: 0.70 - ETA: 4:08 - loss: 1.0251 - accuracy: 0.71 - ETA: 4:07 - loss: 1.0268 - accuracy: 0.71 - ETA: 4:04 - loss: 1.0361 - accuracy: 0.71 - ETA: 4:02 - loss: 1.0475 - accuracy: 0.70 - ETA: 4:00 - loss: 1.0537 - accuracy: 0.70 - ETA: 3:58 - loss: 1.0482 - accuracy: 0.70 - ETA: 3:56 - loss: 1.0427 - accuracy: 0.70 - ETA: 3:54 - loss: 1.0318 - accuracy: 0.71 - ETA: 3:53 - loss: 1.0351 - accuracy: 0.71 - ETA: 3:51 - loss: 1.0344 - accuracy: 0.71 - ETA: 3:49 - loss: 1.0322 - accuracy: 0.70 - ETA: 3:47 - loss: 1.0318 - accuracy: 0.71 - ETA: 3:45 - loss: 1.0298 - accuracy: 0.71 - ETA: 3:43 - loss: 1.0368 - accuracy: 0.71 - ETA: 3:42 - loss: 1.0375 - accuracy: 0.71 - ETA: 3:40 - loss: 1.0346 - accuracy: 0.71 - ETA: 3:38 - loss: 1.0405 - accuracy: 0.71 - ETA: 3:36 - loss: 1.0389 - accuracy: 0.71 - ETA: 3:35 - loss: 1.0500 - accuracy: 0.71 - ETA: 3:33 - loss: 1.0523 - accuracy: 0.70 - ETA: 3:31 - loss: 1.0510 - accuracy: 0.70 - ETA: 3:29 - loss: 1.0510 - accuracy: 0.70 - ETA: 3:27 - loss: 1.0600 - accuracy: 0.70 - ETA: 3:25 - loss: 1.0557 - accuracy: 0.70 - ETA: 3:23 - loss: 1.0546 - accuracy: 0.70 - ETA: 3:21 - loss: 1.0530 - accuracy: 0.70 - ETA: 3:19 - loss: 1.0504 - accuracy: 0.70 - ETA: 3:17 - loss: 1.0448 - accuracy: 0.70 - ETA: 3:16 - loss: 1.0457 - accuracy: 0.70 - ETA: 3:14 - loss: 1.0482 - accuracy: 0.70 - ETA: 3:12 - loss: 1.0515 - accuracy: 0.70 - ETA: 3:10 - loss: 1.0568 - accuracy: 0.70 - ETA: 3:08 - loss: 1.0577 - accuracy: 0.70 - ETA: 3:07 - loss: 1.0559 - accuracy: 0.70 - ETA: 3:05 - loss: 1.0520 - accuracy: 0.70 - ETA: 3:03 - loss: 1.0474 - accuracy: 0.70 - ETA: 3:01 - loss: 1.0503 - accuracy: 0.70 - ETA: 2:59 - loss: 1.0467 - accuracy: 0.70 - ETA: 2:57 - loss: 1.0505 - accuracy: 0.70 - ETA: 2:55 - loss: 1.0526 - accuracy: 0.70 - ETA: 2:54 - loss: 1.0562 - accuracy: 0.70 - ETA: 2:52 - loss: 1.0572 - accuracy: 0.70 - ETA: 2:50 - loss: 1.0643 - accuracy: 0.70 - ETA: 2:48 - loss: 1.0696 - accuracy: 0.70 - ETA: 2:47 - loss: 1.0661 - accuracy: 0.70 - ETA: 2:45 - loss: 1.0654 - accuracy: 0.70 - ETA: 2:43 - loss: 1.0686 - accuracy: 0.70 - ETA: 2:41 - loss: 1.0658 - accuracy: 0.70 - ETA: 2:39 - loss: 1.0665 - accuracy: 0.70 - ETA: 2:37 - loss: 1.0695 - accuracy: 0.70 - ETA: 2:36 - loss: 1.0675 - accuracy: 0.70 - ETA: 2:34 - loss: 1.0691 - accuracy: 0.70 - ETA: 2:32 - loss: 1.0696 - accuracy: 0.70 - ETA: 2:30 - loss: 1.0727 - accuracy: 0.70 - ETA: 2:28 - loss: 1.0748 - accuracy: 0.70 - ETA: 2:27 - loss: 1.0870 - accuracy: 0.70 - ETA: 2:25 - loss: 1.0855 - accuracy: 0.70 - ETA: 2:23 - loss: 1.0904 - accuracy: 0.70 - ETA: 2:21 - loss: 1.0877 - accuracy: 0.70 - ETA: 2:19 - loss: 1.0870 - accuracy: 0.70 - ETA: 2:18 - loss: 1.0865 - accuracy: 0.70 - ETA: 2:16 - loss: 1.0847 - accuracy: 0.70 - ETA: 2:14 - loss: 1.0875 - accuracy: 0.70 - ETA: 2:12 - loss: 1.0877 - accuracy: 0.70 - ETA: 2:10 - loss: 1.0840 - accuracy: 0.70 - ETA: 2:08 - loss: 1.0872 - accuracy: 0.70 - ETA: 2:07 - loss: 1.0879 - accuracy: 0.70 - ETA: 2:05 - loss: 1.0857 - accuracy: 0.70 - ETA: 2:03 - loss: 1.0850 - accuracy: 0.70 - ETA: 2:01 - loss: 1.0838 - accuracy: 0.70 - ETA: 1:59 - loss: 1.0897 - accuracy: 0.70 - ETA: 1:57 - loss: 1.0903 - accuracy: 0.70 - ETA: 1:55 - loss: 1.0898 - accuracy: 0.70 - ETA: 1:54 - loss: 1.0887 - accuracy: 0.70 - ETA: 1:52 - loss: 1.0928 - accuracy: 0.70 - ETA: 1:50 - loss: 1.0955 - accuracy: 0.70 - ETA: 1:48 - loss: 1.0960 - accuracy: 0.70 - ETA: 1:46 - loss: 1.0945 - accuracy: 0.70 - ETA: 1:44 - loss: 1.0957 - accuracy: 0.70 - ETA: 1:43 - loss: 1.0944 - accuracy: 0.70 - ETA: 1:41 - loss: 1.0962 - accuracy: 0.70 - ETA: 1:39 - loss: 1.0959 - accuracy: 0.70 - ETA: 1:37 - loss: 1.0957 - accuracy: 0.70 - ETA: 1:35 - loss: 1.0932 - accuracy: 0.70 - ETA: 1:33 - loss: 1.0904 - accuracy: 0.70 - ETA: 1:32 - loss: 1.0873 - accuracy: 0.70 - ETA: 1:30 - loss: 1.0883 - accuracy: 0.70 - ETA: 1:28 - loss: 1.0898 - accuracy: 0.70 - ETA: 1:26 - loss: 1.0876 - accuracy: 0.70 - ETA: 1:24 - loss: 1.0874 - accuracy: 0.70 - ETA: 1:22 - loss: 1.0869 - accuracy: 0.70 - ETA: 1:20 - loss: 1.0875 - accuracy: 0.70 - ETA: 1:19 - loss: 1.0871 - accuracy: 0.70 - ETA: 1:17 - loss: 1.0868 - accuracy: 0.70 - ETA: 1:15 - loss: 1.0866 - accuracy: 0.70 - ETA: 1:13 - loss: 1.0881 - accuracy: 0.70 - ETA: 1:11 - loss: 1.0872 - accuracy: 0.70 - ETA: 1:09 - loss: 1.0881 - accuracy: 0.70 - ETA: 1:08 - loss: 1.0873 - accuracy: 0.70 - ETA: 1:06 - loss: 1.0886 - accuracy: 0.70 - ETA: 1:04 - loss: 1.0887 - accuracy: 0.70 - ETA: 1:02 - loss: 1.0876 - accuracy: 0.70 - ETA: 1:00 - loss: 1.0883 - accuracy: 0.70 - ETA: 58s - loss: 1.0897 - accuracy: 0.7043 - ETA: 56s - loss: 1.0877 - accuracy: 0.704 - ETA: 55s - loss: 1.0862 - accuracy: 0.704 - ETA: 53s - loss: 1.0871 - accuracy: 0.704 - ETA: 51s - loss: 1.0861 - accuracy: 0.704 - ETA: 49s - loss: 1.0869 - accuracy: 0.704 - ETA: 47s - loss: 1.0866 - accuracy: 0.703 - ETA: 45s - loss: 1.0835 - accuracy: 0.704 - ETA: 44s - loss: 1.0839 - accuracy: 0.703 - ETA: 42s - loss: 1.0820 - accuracy: 0.704 - ETA: 40s - loss: 1.0815 - accuracy: 0.704 - ETA: 38s - loss: 1.0810 - accuracy: 0.704 - ETA: 36s - loss: 1.0779 - accuracy: 0.705 - ETA: 34s - loss: 1.0765 - accuracy: 0.705 - ETA: 33s - loss: 1.0753 - accuracy: 0.705 - ETA: 31s - loss: 1.0747 - accuracy: 0.705 - ETA: 29s - loss: 1.0760 - accuracy: 0.705 - ETA: 27s - loss: 1.0765 - accuracy: 0.705 - ETA: 25s - loss: 1.0766 - accuracy: 0.705 - ETA: 23s - loss: 1.0770 - accuracy: 0.705 - ETA: 21s - loss: 1.0770 - accuracy: 0.705 - ETA: 20s - loss: 1.0753 - accuracy: 0.705 - ETA: 18s - loss: 1.0770 - accuracy: 0.705 - ETA: 16s - loss: 1.0772 - accuracy: 0.705 - ETA: 14s - loss: 1.0757 - accuracy: 0.705 - ETA: 12s - loss: 1.0749 - accuracy: 0.705 - ETA: 10s - loss: 1.0744 - accuracy: 0.705 - ETA: 9s - loss: 1.0750 - accuracy: 0.706 - ETA: 7s - loss: 1.0735 - accuracy: 0.70 - ETA: 5s - loss: 1.0741 - accuracy: 0.70 - ETA: 3s - loss: 1.0719 - accuracy: 0.70 - ETA: 1s - loss: 1.0706 - accuracy: 0.70 - 304s 16ms/step - loss: 1.0720 - accuracy: 0.7060 - val_loss: 1.3084 - val_accuracy: 0.7068\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:31 - loss: 0.8368 - accuracy: 0.71 - ETA: 4:24 - loss: 0.9873 - accuracy: 0.70 - ETA: 4:30 - loss: 1.1003 - accuracy: 0.69 - ETA: 4:30 - loss: 1.0907 - accuracy: 0.69 - ETA: 4:31 - loss: 1.0719 - accuracy: 0.70 - ETA: 4:31 - loss: 1.0437 - accuracy: 0.70 - ETA: 4:31 - loss: 1.0240 - accuracy: 0.71 - ETA: 4:33 - loss: 0.9851 - accuracy: 0.72 - ETA: 4:31 - loss: 0.9932 - accuracy: 0.72 - ETA: 4:27 - loss: 0.9811 - accuracy: 0.72 - ETA: 4:25 - loss: 0.9740 - accuracy: 0.72 - ETA: 4:23 - loss: 0.9951 - accuracy: 0.72 - ETA: 4:21 - loss: 0.9998 - accuracy: 0.71 - ETA: 4:20 - loss: 0.9995 - accuracy: 0.71 - ETA: 4:18 - loss: 1.0156 - accuracy: 0.71 - ETA: 4:16 - loss: 1.0274 - accuracy: 0.70 - ETA: 4:15 - loss: 0.9999 - accuracy: 0.71 - ETA: 4:12 - loss: 0.9977 - accuracy: 0.71 - ETA: 4:10 - loss: 1.0003 - accuracy: 0.71 - ETA: 4:08 - loss: 0.9944 - accuracy: 0.71 - ETA: 4:05 - loss: 0.9986 - accuracy: 0.71 - ETA: 4:04 - loss: 0.9936 - accuracy: 0.71 - ETA: 4:02 - loss: 0.9845 - accuracy: 0.71 - ETA: 4:00 - loss: 0.9911 - accuracy: 0.71 - ETA: 3:58 - loss: 0.9813 - accuracy: 0.72 - ETA: 3:56 - loss: 0.9875 - accuracy: 0.71 - ETA: 3:54 - loss: 0.9776 - accuracy: 0.71 - ETA: 3:52 - loss: 0.9752 - accuracy: 0.72 - ETA: 3:50 - loss: 0.9678 - accuracy: 0.72 - ETA: 3:48 - loss: 0.9694 - accuracy: 0.72 - ETA: 3:47 - loss: 0.9676 - accuracy: 0.72 - ETA: 3:45 - loss: 0.9621 - accuracy: 0.72 - ETA: 3:43 - loss: 0.9628 - accuracy: 0.72 - ETA: 3:41 - loss: 0.9663 - accuracy: 0.72 - ETA: 3:39 - loss: 0.9665 - accuracy: 0.72 - ETA: 3:37 - loss: 0.9696 - accuracy: 0.72 - ETA: 3:35 - loss: 0.9660 - accuracy: 0.72 - ETA: 3:32 - loss: 0.9740 - accuracy: 0.71 - ETA: 3:31 - loss: 0.9796 - accuracy: 0.71 - ETA: 3:29 - loss: 0.9748 - accuracy: 0.71 - ETA: 3:27 - loss: 0.9739 - accuracy: 0.72 - ETA: 3:25 - loss: 0.9727 - accuracy: 0.72 - ETA: 3:23 - loss: 0.9699 - accuracy: 0.72 - ETA: 3:21 - loss: 0.9777 - accuracy: 0.71 - ETA: 3:19 - loss: 0.9828 - accuracy: 0.71 - ETA: 3:17 - loss: 0.9846 - accuracy: 0.71 - ETA: 3:15 - loss: 0.9860 - accuracy: 0.71 - ETA: 3:13 - loss: 0.9834 - accuracy: 0.71 - ETA: 3:12 - loss: 0.9866 - accuracy: 0.71 - ETA: 3:10 - loss: 0.9869 - accuracy: 0.71 - ETA: 3:08 - loss: 0.9938 - accuracy: 0.71 - ETA: 3:06 - loss: 0.9969 - accuracy: 0.71 - ETA: 3:04 - loss: 0.9967 - accuracy: 0.71 - ETA: 3:02 - loss: 0.9992 - accuracy: 0.71 - ETA: 3:00 - loss: 1.0037 - accuracy: 0.71 - ETA: 2:59 - loss: 1.0033 - accuracy: 0.71 - ETA: 2:56 - loss: 1.0034 - accuracy: 0.71 - ETA: 2:55 - loss: 1.0013 - accuracy: 0.71 - ETA: 2:53 - loss: 1.0014 - accuracy: 0.71 - ETA: 2:51 - loss: 1.0020 - accuracy: 0.71 - ETA: 2:49 - loss: 1.0011 - accuracy: 0.71 - ETA: 2:47 - loss: 1.0056 - accuracy: 0.71 - ETA: 2:45 - loss: 1.0062 - accuracy: 0.71 - ETA: 2:43 - loss: 1.0026 - accuracy: 0.71 - ETA: 2:42 - loss: 1.0013 - accuracy: 0.71 - ETA: 2:40 - loss: 0.9972 - accuracy: 0.71 - ETA: 2:38 - loss: 0.9954 - accuracy: 0.71 - ETA: 2:36 - loss: 0.9963 - accuracy: 0.71 - ETA: 2:34 - loss: 0.9926 - accuracy: 0.71 - ETA: 2:32 - loss: 0.9925 - accuracy: 0.71 - ETA: 2:30 - loss: 0.9913 - accuracy: 0.71 - ETA: 2:28 - loss: 0.9887 - accuracy: 0.71 - ETA: 2:26 - loss: 0.9901 - accuracy: 0.71 - ETA: 2:24 - loss: 0.9902 - accuracy: 0.71 - ETA: 2:23 - loss: 0.9881 - accuracy: 0.71 - ETA: 2:21 - loss: 0.9906 - accuracy: 0.71 - ETA: 2:19 - loss: 0.9905 - accuracy: 0.71 - ETA: 2:17 - loss: 0.9887 - accuracy: 0.71 - ETA: 2:15 - loss: 0.9894 - accuracy: 0.71 - ETA: 2:13 - loss: 0.9906 - accuracy: 0.71 - ETA: 2:11 - loss: 0.9933 - accuracy: 0.71 - ETA: 2:09 - loss: 0.9929 - accuracy: 0.71 - ETA: 2:07 - loss: 0.9922 - accuracy: 0.71 - ETA: 2:06 - loss: 0.9948 - accuracy: 0.71 - ETA: 2:03 - loss: 0.9947 - accuracy: 0.71 - ETA: 2:02 - loss: 0.9935 - accuracy: 0.71 - ETA: 2:00 - loss: 0.9921 - accuracy: 0.71 - ETA: 1:58 - loss: 0.9925 - accuracy: 0.71 - ETA: 1:56 - loss: 0.9934 - accuracy: 0.71 - ETA: 1:54 - loss: 0.9920 - accuracy: 0.71 - ETA: 1:52 - loss: 0.9909 - accuracy: 0.71 - ETA: 1:50 - loss: 0.9912 - accuracy: 0.71 - ETA: 1:48 - loss: 0.9908 - accuracy: 0.71 - ETA: 1:46 - loss: 0.9902 - accuracy: 0.71 - ETA: 1:44 - loss: 0.9897 - accuracy: 0.71 - ETA: 1:43 - loss: 0.9908 - accuracy: 0.71 - ETA: 1:41 - loss: 0.9894 - accuracy: 0.71 - ETA: 1:39 - loss: 0.9896 - accuracy: 0.71 - ETA: 1:37 - loss: 0.9902 - accuracy: 0.71 - ETA: 1:35 - loss: 0.9914 - accuracy: 0.71 - ETA: 1:33 - loss: 0.9889 - accuracy: 0.72 - ETA: 1:31 - loss: 0.9901 - accuracy: 0.71 - ETA: 1:29 - loss: 0.9914 - accuracy: 0.71 - ETA: 1:28 - loss: 0.9919 - accuracy: 0.71 - ETA: 1:26 - loss: 0.9936 - accuracy: 0.71 - ETA: 1:24 - loss: 0.9955 - accuracy: 0.71 - ETA: 1:22 - loss: 0.9968 - accuracy: 0.71 - ETA: 1:20 - loss: 0.9961 - accuracy: 0.71 - ETA: 1:18 - loss: 0.9965 - accuracy: 0.71 - ETA: 1:16 - loss: 0.9964 - accuracy: 0.71 - ETA: 1:15 - loss: 0.9975 - accuracy: 0.71 - ETA: 1:13 - loss: 0.9980 - accuracy: 0.71 - ETA: 1:11 - loss: 1.0071 - accuracy: 0.71 - ETA: 1:09 - loss: 1.0076 - accuracy: 0.71 - ETA: 1:07 - loss: 1.0064 - accuracy: 0.71 - ETA: 1:05 - loss: 1.0059 - accuracy: 0.71 - ETA: 1:03 - loss: 1.0064 - accuracy: 0.71 - ETA: 1:01 - loss: 1.0033 - accuracy: 0.71 - ETA: 1:00 - loss: 1.0062 - accuracy: 0.71 - ETA: 58s - loss: 1.0072 - accuracy: 0.7169 - ETA: 56s - loss: 1.0061 - accuracy: 0.717 - ETA: 54s - loss: 1.0065 - accuracy: 0.717 - ETA: 52s - loss: 1.0067 - accuracy: 0.717 - ETA: 50s - loss: 1.0053 - accuracy: 0.717 - ETA: 48s - loss: 1.0038 - accuracy: 0.717 - ETA: 46s - loss: 1.0063 - accuracy: 0.717 - ETA: 44s - loss: 1.0053 - accuracy: 0.717 - ETA: 43s - loss: 1.0052 - accuracy: 0.717 - ETA: 41s - loss: 1.0069 - accuracy: 0.717 - ETA: 39s - loss: 1.0118 - accuracy: 0.716 - ETA: 37s - loss: 1.0136 - accuracy: 0.716 - ETA: 35s - loss: 1.0113 - accuracy: 0.716 - ETA: 33s - loss: 1.0133 - accuracy: 0.716 - ETA: 31s - loss: 1.0148 - accuracy: 0.716 - ETA: 29s - loss: 1.0169 - accuracy: 0.716 - ETA: 27s - loss: 1.0162 - accuracy: 0.716 - ETA: 26s - loss: 1.0147 - accuracy: 0.716 - ETA: 24s - loss: 1.0141 - accuracy: 0.716 - ETA: 22s - loss: 1.0141 - accuracy: 0.716 - ETA: 20s - loss: 1.0147 - accuracy: 0.716 - ETA: 18s - loss: 1.0186 - accuracy: 0.716 - ETA: 16s - loss: 1.0219 - accuracy: 0.716 - ETA: 14s - loss: 1.0208 - accuracy: 0.716 - ETA: 12s - loss: 1.0203 - accuracy: 0.716 - ETA: 11s - loss: 1.0203 - accuracy: 0.716 - ETA: 9s - loss: 1.0215 - accuracy: 0.716 - ETA: 7s - loss: 1.0216 - accuracy: 0.71 - ETA: 5s - loss: 1.0213 - accuracy: 0.71 - ETA: 3s - loss: 1.0204 - accuracy: 0.71 - ETA: 1s - loss: 1.0202 - accuracy: 0.71 - 308s 16ms/step - loss: 1.0214 - accuracy: 0.7167 - val_loss: 1.3250 - val_accuracy: 0.7062\n",
      "Epoch 16/100\n",
      "19312/19312 [==============================] - ETA: 4:54 - loss: 1.1783 - accuracy: 0.68 - ETA: 4:38 - loss: 1.1952 - accuracy: 0.68 - ETA: 4:40 - loss: 1.1448 - accuracy: 0.67 - ETA: 4:36 - loss: 1.1093 - accuracy: 0.68 - ETA: 4:36 - loss: 1.0862 - accuracy: 0.68 - ETA: 4:31 - loss: 1.0179 - accuracy: 0.70 - ETA: 4:30 - loss: 1.0420 - accuracy: 0.70 - ETA: 4:26 - loss: 1.0508 - accuracy: 0.70 - ETA: 4:25 - loss: 1.0472 - accuracy: 0.69 - ETA: 4:23 - loss: 1.0381 - accuracy: 0.70 - ETA: 4:22 - loss: 1.0019 - accuracy: 0.71 - ETA: 4:21 - loss: 1.0213 - accuracy: 0.71 - ETA: 4:19 - loss: 1.0134 - accuracy: 0.71 - ETA: 4:17 - loss: 1.0086 - accuracy: 0.71 - ETA: 4:14 - loss: 1.0127 - accuracy: 0.71 - ETA: 4:11 - loss: 1.0229 - accuracy: 0.71 - ETA: 4:09 - loss: 1.0266 - accuracy: 0.71 - ETA: 4:07 - loss: 1.0180 - accuracy: 0.71 - ETA: 4:05 - loss: 1.0174 - accuracy: 0.71 - ETA: 4:03 - loss: 1.0171 - accuracy: 0.71 - ETA: 4:01 - loss: 1.0104 - accuracy: 0.71 - ETA: 4:00 - loss: 1.0071 - accuracy: 0.71 - ETA: 3:57 - loss: 1.0096 - accuracy: 0.71 - ETA: 3:55 - loss: 1.0077 - accuracy: 0.71 - ETA: 3:53 - loss: 1.0056 - accuracy: 0.71 - ETA: 3:50 - loss: 1.0063 - accuracy: 0.71 - ETA: 3:49 - loss: 1.0067 - accuracy: 0.72 - ETA: 3:47 - loss: 1.0093 - accuracy: 0.71 - ETA: 3:46 - loss: 0.9969 - accuracy: 0.72 - ETA: 3:44 - loss: 0.9902 - accuracy: 0.72 - ETA: 3:42 - loss: 0.9853 - accuracy: 0.72 - ETA: 3:40 - loss: 0.9869 - accuracy: 0.72 - ETA: 3:38 - loss: 0.9973 - accuracy: 0.72 - ETA: 3:36 - loss: 1.0013 - accuracy: 0.72 - ETA: 3:34 - loss: 1.0050 - accuracy: 0.72 - ETA: 3:32 - loss: 1.0037 - accuracy: 0.72 - ETA: 3:30 - loss: 1.0056 - accuracy: 0.71 - ETA: 3:28 - loss: 1.0050 - accuracy: 0.71 - ETA: 3:27 - loss: 1.0056 - accuracy: 0.71 - ETA: 3:25 - loss: 1.0010 - accuracy: 0.72 - ETA: 3:23 - loss: 0.9945 - accuracy: 0.72 - ETA: 3:22 - loss: 0.9973 - accuracy: 0.72 - ETA: 3:20 - loss: 1.0068 - accuracy: 0.72 - ETA: 3:18 - loss: 1.0066 - accuracy: 0.72 - ETA: 3:17 - loss: 1.0026 - accuracy: 0.72 - ETA: 3:15 - loss: 0.9994 - accuracy: 0.72 - ETA: 3:13 - loss: 1.0043 - accuracy: 0.72 - ETA: 3:11 - loss: 1.0028 - accuracy: 0.72 - ETA: 3:09 - loss: 1.0035 - accuracy: 0.72 - ETA: 3:08 - loss: 1.0083 - accuracy: 0.72 - ETA: 3:06 - loss: 1.0095 - accuracy: 0.72 - ETA: 3:04 - loss: 1.0101 - accuracy: 0.72 - ETA: 3:02 - loss: 1.0112 - accuracy: 0.71 - ETA: 3:00 - loss: 1.0071 - accuracy: 0.72 - ETA: 2:58 - loss: 1.0077 - accuracy: 0.71 - ETA: 2:57 - loss: 1.0100 - accuracy: 0.71 - ETA: 2:55 - loss: 1.0070 - accuracy: 0.71 - ETA: 2:53 - loss: 1.0047 - accuracy: 0.72 - ETA: 2:51 - loss: 1.0045 - accuracy: 0.71 - ETA: 2:49 - loss: 1.0031 - accuracy: 0.71 - ETA: 2:47 - loss: 1.0094 - accuracy: 0.71 - ETA: 2:45 - loss: 1.0107 - accuracy: 0.71 - ETA: 2:43 - loss: 1.0124 - accuracy: 0.71 - ETA: 2:41 - loss: 1.0126 - accuracy: 0.71 - ETA: 2:39 - loss: 1.0152 - accuracy: 0.71 - ETA: 2:37 - loss: 1.0165 - accuracy: 0.71 - ETA: 2:35 - loss: 1.0224 - accuracy: 0.71 - ETA: 2:33 - loss: 1.0207 - accuracy: 0.71 - ETA: 2:32 - loss: 1.0199 - accuracy: 0.71 - ETA: 2:30 - loss: 1.0217 - accuracy: 0.71 - ETA: 2:28 - loss: 1.0217 - accuracy: 0.71 - ETA: 2:26 - loss: 1.0204 - accuracy: 0.71 - ETA: 2:24 - loss: 1.0216 - accuracy: 0.71 - ETA: 2:22 - loss: 1.0186 - accuracy: 0.71 - ETA: 2:21 - loss: 1.0281 - accuracy: 0.71 - ETA: 2:19 - loss: 1.0285 - accuracy: 0.71 - ETA: 2:17 - loss: 1.0276 - accuracy: 0.71 - ETA: 2:15 - loss: 1.0254 - accuracy: 0.71 - ETA: 2:13 - loss: 1.0230 - accuracy: 0.71 - ETA: 2:11 - loss: 1.0207 - accuracy: 0.71 - ETA: 2:09 - loss: 1.0219 - accuracy: 0.71 - ETA: 2:07 - loss: 1.0252 - accuracy: 0.71 - ETA: 2:05 - loss: 1.0240 - accuracy: 0.71 - ETA: 2:04 - loss: 1.0236 - accuracy: 0.71 - ETA: 2:02 - loss: 1.0183 - accuracy: 0.71 - ETA: 2:00 - loss: 1.0162 - accuracy: 0.71 - ETA: 1:58 - loss: 1.0159 - accuracy: 0.71 - ETA: 1:56 - loss: 1.0141 - accuracy: 0.71 - ETA: 1:54 - loss: 1.0146 - accuracy: 0.71 - ETA: 1:53 - loss: 1.0114 - accuracy: 0.71 - ETA: 1:51 - loss: 1.0117 - accuracy: 0.71 - ETA: 1:49 - loss: 1.0109 - accuracy: 0.71 - ETA: 1:47 - loss: 1.0132 - accuracy: 0.71 - ETA: 1:45 - loss: 1.0106 - accuracy: 0.71 - ETA: 1:43 - loss: 1.0109 - accuracy: 0.71 - ETA: 1:41 - loss: 1.0101 - accuracy: 0.71 - ETA: 1:40 - loss: 1.0127 - accuracy: 0.71 - ETA: 1:38 - loss: 1.0169 - accuracy: 0.71 - ETA: 1:36 - loss: 1.0221 - accuracy: 0.71 - ETA: 1:34 - loss: 1.0216 - accuracy: 0.71 - ETA: 1:32 - loss: 1.0240 - accuracy: 0.71 - ETA: 1:30 - loss: 1.0236 - accuracy: 0.71 - ETA: 1:29 - loss: 1.0296 - accuracy: 0.71 - ETA: 1:27 - loss: 1.0280 - accuracy: 0.71 - ETA: 1:25 - loss: 1.0326 - accuracy: 0.71 - ETA: 1:23 - loss: 1.0367 - accuracy: 0.71 - ETA: 1:21 - loss: 1.0337 - accuracy: 0.71 - ETA: 1:19 - loss: 1.0321 - accuracy: 0.71 - ETA: 1:17 - loss: 1.0327 - accuracy: 0.71 - ETA: 1:16 - loss: 1.0341 - accuracy: 0.71 - ETA: 1:14 - loss: 1.0339 - accuracy: 0.71 - ETA: 1:12 - loss: 1.0334 - accuracy: 0.71 - ETA: 1:10 - loss: 1.0324 - accuracy: 0.71 - ETA: 1:08 - loss: 1.0314 - accuracy: 0.71 - ETA: 1:06 - loss: 1.0281 - accuracy: 0.71 - ETA: 1:04 - loss: 1.0261 - accuracy: 0.71 - ETA: 1:03 - loss: 1.0245 - accuracy: 0.71 - ETA: 1:01 - loss: 1.0262 - accuracy: 0.71 - ETA: 59s - loss: 1.0238 - accuracy: 0.7174 - ETA: 57s - loss: 1.0233 - accuracy: 0.717 - ETA: 55s - loss: 1.0252 - accuracy: 0.717 - ETA: 53s - loss: 1.0243 - accuracy: 0.717 - ETA: 51s - loss: 1.0219 - accuracy: 0.717 - ETA: 50s - loss: 1.0219 - accuracy: 0.717 - ETA: 48s - loss: 1.0216 - accuracy: 0.717 - ETA: 46s - loss: 1.0225 - accuracy: 0.717 - ETA: 44s - loss: 1.0212 - accuracy: 0.717 - ETA: 42s - loss: 1.0208 - accuracy: 0.717 - ETA: 40s - loss: 1.0216 - accuracy: 0.717 - ETA: 38s - loss: 1.0228 - accuracy: 0.717 - ETA: 37s - loss: 1.0229 - accuracy: 0.717 - ETA: 35s - loss: 1.0229 - accuracy: 0.717 - ETA: 33s - loss: 1.0230 - accuracy: 0.717 - ETA: 31s - loss: 1.0208 - accuracy: 0.717 - ETA: 29s - loss: 1.0211 - accuracy: 0.717 - ETA: 27s - loss: 1.0221 - accuracy: 0.717 - ETA: 25s - loss: 1.0207 - accuracy: 0.717 - ETA: 23s - loss: 1.0212 - accuracy: 0.717 - ETA: 22s - loss: 1.0220 - accuracy: 0.717 - ETA: 20s - loss: 1.0210 - accuracy: 0.717 - ETA: 18s - loss: 1.0247 - accuracy: 0.717 - ETA: 16s - loss: 1.0259 - accuracy: 0.717 - ETA: 14s - loss: 1.0261 - accuracy: 0.717 - ETA: 12s - loss: 1.0273 - accuracy: 0.717 - ETA: 10s - loss: 1.0283 - accuracy: 0.716 - ETA: 9s - loss: 1.0287 - accuracy: 0.716 - ETA: 7s - loss: 1.0293 - accuracy: 0.71 - ETA: 5s - loss: 1.0305 - accuracy: 0.71 - ETA: 3s - loss: 1.0306 - accuracy: 0.71 - ETA: 1s - loss: 1.0296 - accuracy: 0.71 - 309s 16ms/step - loss: 1.0296 - accuracy: 0.7162 - val_loss: 1.3422 - val_accuracy: 0.6989\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:46 - loss: 1.2098 - accuracy: 0.65 - ETA: 4:41 - loss: 1.2266 - accuracy: 0.66 - ETA: 4:37 - loss: 1.2331 - accuracy: 0.66 - ETA: 4:33 - loss: 1.1940 - accuracy: 0.68 - ETA: 4:31 - loss: 1.1482 - accuracy: 0.71 - ETA: 4:27 - loss: 1.1441 - accuracy: 0.70 - ETA: 4:26 - loss: 1.1374 - accuracy: 0.71 - ETA: 4:24 - loss: 1.1279 - accuracy: 0.71 - ETA: 4:23 - loss: 1.1153 - accuracy: 0.71 - ETA: 4:21 - loss: 1.0907 - accuracy: 0.72 - ETA: 4:20 - loss: 1.0848 - accuracy: 0.72 - ETA: 4:17 - loss: 1.0732 - accuracy: 0.72 - ETA: 4:17 - loss: 1.0672 - accuracy: 0.71 - ETA: 4:14 - loss: 1.0554 - accuracy: 0.71 - ETA: 4:11 - loss: 1.0324 - accuracy: 0.72 - ETA: 4:09 - loss: 1.0632 - accuracy: 0.72 - ETA: 4:08 - loss: 1.0538 - accuracy: 0.71 - ETA: 4:07 - loss: 1.0358 - accuracy: 0.72 - ETA: 4:05 - loss: 1.0288 - accuracy: 0.71 - ETA: 4:03 - loss: 1.0318 - accuracy: 0.71 - ETA: 4:01 - loss: 1.0212 - accuracy: 0.71 - ETA: 3:59 - loss: 1.0094 - accuracy: 0.72 - ETA: 3:57 - loss: 1.0122 - accuracy: 0.72 - ETA: 3:55 - loss: 1.0010 - accuracy: 0.72 - ETA: 3:54 - loss: 0.9979 - accuracy: 0.72 - ETA: 3:53 - loss: 0.9901 - accuracy: 0.72 - ETA: 3:56 - loss: 0.9933 - accuracy: 0.72 - ETA: 3:55 - loss: 0.9885 - accuracy: 0.72 - ETA: 3:53 - loss: 0.9911 - accuracy: 0.72 - ETA: 3:50 - loss: 0.9867 - accuracy: 0.72 - ETA: 3:48 - loss: 1.0037 - accuracy: 0.72 - ETA: 3:47 - loss: 1.0137 - accuracy: 0.72 - ETA: 3:45 - loss: 1.0090 - accuracy: 0.72 - ETA: 3:43 - loss: 1.0041 - accuracy: 0.72 - ETA: 3:42 - loss: 0.9956 - accuracy: 0.72 - ETA: 3:40 - loss: 0.9986 - accuracy: 0.72 - ETA: 3:39 - loss: 1.0030 - accuracy: 0.72 - ETA: 3:37 - loss: 1.0004 - accuracy: 0.72 - ETA: 3:35 - loss: 0.9984 - accuracy: 0.72 - ETA: 3:33 - loss: 1.0002 - accuracy: 0.72 - ETA: 3:32 - loss: 0.9925 - accuracy: 0.72 - ETA: 3:30 - loss: 0.9861 - accuracy: 0.72 - ETA: 3:28 - loss: 0.9827 - accuracy: 0.72 - ETA: 3:26 - loss: 0.9805 - accuracy: 0.72 - ETA: 3:24 - loss: 0.9834 - accuracy: 0.72 - ETA: 3:22 - loss: 0.9849 - accuracy: 0.72 - ETA: 3:20 - loss: 0.9786 - accuracy: 0.72 - ETA: 3:18 - loss: 0.9818 - accuracy: 0.72 - ETA: 3:16 - loss: 0.9763 - accuracy: 0.72 - ETA: 3:14 - loss: 0.9789 - accuracy: 0.72 - ETA: 3:13 - loss: 0.9791 - accuracy: 0.72 - ETA: 3:11 - loss: 0.9814 - accuracy: 0.72 - ETA: 3:09 - loss: 0.9855 - accuracy: 0.72 - ETA: 3:07 - loss: 0.9799 - accuracy: 0.72 - ETA: 3:05 - loss: 0.9790 - accuracy: 0.72 - ETA: 3:04 - loss: 0.9797 - accuracy: 0.72 - ETA: 3:02 - loss: 0.9808 - accuracy: 0.72 - ETA: 2:59 - loss: 0.9785 - accuracy: 0.72 - ETA: 2:57 - loss: 0.9806 - accuracy: 0.72 - ETA: 2:55 - loss: 0.9818 - accuracy: 0.72 - ETA: 2:54 - loss: 0.9852 - accuracy: 0.72 - ETA: 2:52 - loss: 0.9849 - accuracy: 0.72 - ETA: 2:49 - loss: 0.9823 - accuracy: 0.72 - ETA: 2:48 - loss: 0.9813 - accuracy: 0.72 - ETA: 2:46 - loss: 0.9821 - accuracy: 0.72 - ETA: 2:44 - loss: 0.9852 - accuracy: 0.72 - ETA: 2:42 - loss: 0.9894 - accuracy: 0.72 - ETA: 2:40 - loss: 0.9900 - accuracy: 0.72 - ETA: 2:38 - loss: 0.9890 - accuracy: 0.72 - ETA: 2:36 - loss: 0.9856 - accuracy: 0.72 - ETA: 2:34 - loss: 0.9826 - accuracy: 0.72 - ETA: 2:32 - loss: 0.9836 - accuracy: 0.72 - ETA: 2:30 - loss: 0.9869 - accuracy: 0.72 - ETA: 2:29 - loss: 0.9896 - accuracy: 0.72 - ETA: 2:27 - loss: 0.9889 - accuracy: 0.72 - ETA: 2:25 - loss: 0.9870 - accuracy: 0.72 - ETA: 2:23 - loss: 0.9857 - accuracy: 0.72 - ETA: 2:21 - loss: 0.9843 - accuracy: 0.72 - ETA: 2:19 - loss: 0.9821 - accuracy: 0.72 - ETA: 2:17 - loss: 0.9815 - accuracy: 0.72 - ETA: 2:15 - loss: 0.9788 - accuracy: 0.72 - ETA: 2:13 - loss: 0.9799 - accuracy: 0.72 - ETA: 2:11 - loss: 0.9796 - accuracy: 0.72 - ETA: 2:09 - loss: 0.9791 - accuracy: 0.72 - ETA: 2:07 - loss: 0.9797 - accuracy: 0.72 - ETA: 2:05 - loss: 0.9795 - accuracy: 0.72 - ETA: 2:03 - loss: 0.9817 - accuracy: 0.72 - ETA: 2:01 - loss: 0.9790 - accuracy: 0.72 - ETA: 1:59 - loss: 0.9818 - accuracy: 0.72 - ETA: 1:57 - loss: 0.9831 - accuracy: 0.72 - ETA: 1:55 - loss: 0.9844 - accuracy: 0.72 - ETA: 1:53 - loss: 0.9842 - accuracy: 0.72 - ETA: 1:51 - loss: 0.9837 - accuracy: 0.72 - ETA: 1:49 - loss: 0.9869 - accuracy: 0.72 - ETA: 1:47 - loss: 0.9841 - accuracy: 0.72 - ETA: 1:45 - loss: 0.9820 - accuracy: 0.72 - ETA: 1:43 - loss: 0.9832 - accuracy: 0.72 - ETA: 1:41 - loss: 0.9863 - accuracy: 0.72 - ETA: 1:39 - loss: 0.9866 - accuracy: 0.72 - ETA: 1:37 - loss: 0.9861 - accuracy: 0.72 - ETA: 1:35 - loss: 0.9848 - accuracy: 0.72 - ETA: 1:33 - loss: 0.9898 - accuracy: 0.72 - ETA: 1:32 - loss: 0.9882 - accuracy: 0.72 - ETA: 1:29 - loss: 0.9867 - accuracy: 0.72 - ETA: 1:28 - loss: 0.9865 - accuracy: 0.72 - ETA: 1:26 - loss: 0.9869 - accuracy: 0.72 - ETA: 1:24 - loss: 0.9880 - accuracy: 0.72 - ETA: 1:22 - loss: 0.9923 - accuracy: 0.72 - ETA: 1:20 - loss: 0.9916 - accuracy: 0.72 - ETA: 1:18 - loss: 0.9903 - accuracy: 0.72 - ETA: 1:16 - loss: 0.9888 - accuracy: 0.72 - ETA: 1:14 - loss: 0.9883 - accuracy: 0.72 - ETA: 1:12 - loss: 0.9918 - accuracy: 0.72 - ETA: 1:10 - loss: 0.9903 - accuracy: 0.72 - ETA: 1:08 - loss: 0.9908 - accuracy: 0.72 - ETA: 1:06 - loss: 0.9890 - accuracy: 0.72 - ETA: 1:04 - loss: 0.9894 - accuracy: 0.72 - ETA: 1:02 - loss: 0.9903 - accuracy: 0.72 - ETA: 1:00 - loss: 0.9903 - accuracy: 0.72 - ETA: 58s - loss: 0.9896 - accuracy: 0.7244 - ETA: 57s - loss: 0.9910 - accuracy: 0.724 - ETA: 55s - loss: 0.9896 - accuracy: 0.724 - ETA: 53s - loss: 0.9923 - accuracy: 0.724 - ETA: 51s - loss: 0.9918 - accuracy: 0.724 - ETA: 49s - loss: 0.9910 - accuracy: 0.724 - ETA: 47s - loss: 0.9914 - accuracy: 0.724 - ETA: 45s - loss: 0.9944 - accuracy: 0.724 - ETA: 43s - loss: 0.9934 - accuracy: 0.724 - ETA: 41s - loss: 0.9947 - accuracy: 0.724 - ETA: 39s - loss: 0.9971 - accuracy: 0.724 - ETA: 37s - loss: 0.9949 - accuracy: 0.724 - ETA: 36s - loss: 0.9954 - accuracy: 0.724 - ETA: 34s - loss: 0.9978 - accuracy: 0.723 - ETA: 32s - loss: 0.9976 - accuracy: 0.723 - ETA: 30s - loss: 0.9987 - accuracy: 0.723 - ETA: 28s - loss: 0.9999 - accuracy: 0.723 - ETA: 26s - loss: 0.9986 - accuracy: 0.723 - ETA: 24s - loss: 0.9979 - accuracy: 0.723 - ETA: 22s - loss: 0.9970 - accuracy: 0.723 - ETA: 20s - loss: 0.9986 - accuracy: 0.722 - ETA: 18s - loss: 1.0007 - accuracy: 0.722 - ETA: 16s - loss: 0.9993 - accuracy: 0.723 - ETA: 15s - loss: 0.9992 - accuracy: 0.722 - ETA: 13s - loss: 1.0000 - accuracy: 0.722 - ETA: 11s - loss: 0.9985 - accuracy: 0.722 - ETA: 9s - loss: 0.9962 - accuracy: 0.723 - ETA: 7s - loss: 0.9976 - accuracy: 0.72 - ETA: 5s - loss: 0.9971 - accuracy: 0.72 - ETA: 3s - loss: 0.9988 - accuracy: 0.72 - ETA: 1s - loss: 0.9995 - accuracy: 0.72 - 314s 16ms/step - loss: 1.0002 - accuracy: 0.7227 - val_loss: 1.3857 - val_accuracy: 0.7151\n",
      "Epoch 18/100\n",
      "19312/19312 [==============================] - ETA: 4:29 - loss: 0.6966 - accuracy: 0.81 - ETA: 4:36 - loss: 0.8616 - accuracy: 0.73 - ETA: 4:39 - loss: 0.8770 - accuracy: 0.73 - ETA: 4:36 - loss: 0.8588 - accuracy: 0.72 - ETA: 4:36 - loss: 0.8759 - accuracy: 0.72 - ETA: 4:37 - loss: 0.8757 - accuracy: 0.73 - ETA: 4:36 - loss: 0.8540 - accuracy: 0.74 - ETA: 4:33 - loss: 0.8513 - accuracy: 0.74 - ETA: 4:30 - loss: 0.8631 - accuracy: 0.73 - ETA: 4:28 - loss: 0.8796 - accuracy: 0.73 - ETA: 4:25 - loss: 0.9176 - accuracy: 0.73 - ETA: 4:23 - loss: 0.8954 - accuracy: 0.74 - ETA: 4:21 - loss: 0.9002 - accuracy: 0.73 - ETA: 4:19 - loss: 0.9016 - accuracy: 0.73 - ETA: 4:16 - loss: 0.9106 - accuracy: 0.73 - ETA: 4:15 - loss: 0.9015 - accuracy: 0.73 - ETA: 4:12 - loss: 0.9104 - accuracy: 0.73 - ETA: 4:10 - loss: 0.9037 - accuracy: 0.74 - ETA: 4:08 - loss: 0.9055 - accuracy: 0.73 - ETA: 4:06 - loss: 0.9073 - accuracy: 0.74 - ETA: 4:04 - loss: 0.8961 - accuracy: 0.74 - ETA: 4:02 - loss: 0.9054 - accuracy: 0.74 - ETA: 4:00 - loss: 0.9009 - accuracy: 0.74 - ETA: 3:58 - loss: 0.9088 - accuracy: 0.73 - ETA: 3:56 - loss: 0.9176 - accuracy: 0.73 - ETA: 3:54 - loss: 0.9146 - accuracy: 0.74 - ETA: 3:52 - loss: 0.9335 - accuracy: 0.73 - ETA: 3:51 - loss: 0.9393 - accuracy: 0.73 - ETA: 3:49 - loss: 0.9354 - accuracy: 0.73 - ETA: 3:47 - loss: 0.9440 - accuracy: 0.73 - ETA: 3:45 - loss: 0.9517 - accuracy: 0.73 - ETA: 3:44 - loss: 0.9502 - accuracy: 0.73 - ETA: 3:42 - loss: 0.9539 - accuracy: 0.73 - ETA: 3:40 - loss: 0.9595 - accuracy: 0.73 - ETA: 3:38 - loss: 0.9570 - accuracy: 0.73 - ETA: 3:36 - loss: 0.9542 - accuracy: 0.73 - ETA: 3:34 - loss: 0.9501 - accuracy: 0.73 - ETA: 3:32 - loss: 0.9518 - accuracy: 0.73 - ETA: 3:31 - loss: 0.9513 - accuracy: 0.73 - ETA: 3:29 - loss: 0.9457 - accuracy: 0.73 - ETA: 3:27 - loss: 0.9441 - accuracy: 0.73 - ETA: 3:25 - loss: 0.9391 - accuracy: 0.73 - ETA: 3:23 - loss: 0.9374 - accuracy: 0.74 - ETA: 3:22 - loss: 0.9362 - accuracy: 0.74 - ETA: 3:20 - loss: 0.9343 - accuracy: 0.74 - ETA: 3:18 - loss: 0.9343 - accuracy: 0.74 - ETA: 3:16 - loss: 0.9342 - accuracy: 0.74 - ETA: 3:14 - loss: 0.9320 - accuracy: 0.74 - ETA: 3:12 - loss: 0.9345 - accuracy: 0.74 - ETA: 3:11 - loss: 0.9330 - accuracy: 0.74 - ETA: 3:09 - loss: 0.9302 - accuracy: 0.74 - ETA: 3:07 - loss: 0.9246 - accuracy: 0.74 - ETA: 3:05 - loss: 0.9259 - accuracy: 0.74 - ETA: 3:03 - loss: 0.9261 - accuracy: 0.74 - ETA: 3:01 - loss: 0.9246 - accuracy: 0.74 - ETA: 2:59 - loss: 0.9301 - accuracy: 0.74 - ETA: 2:57 - loss: 0.9343 - accuracy: 0.74 - ETA: 2:55 - loss: 0.9362 - accuracy: 0.74 - ETA: 2:53 - loss: 0.9386 - accuracy: 0.73 - ETA: 2:51 - loss: 0.9430 - accuracy: 0.74 - ETA: 2:50 - loss: 0.9429 - accuracy: 0.74 - ETA: 2:48 - loss: 0.9384 - accuracy: 0.74 - ETA: 2:45 - loss: 0.9413 - accuracy: 0.74 - ETA: 2:43 - loss: 0.9494 - accuracy: 0.73 - ETA: 2:40 - loss: 0.9499 - accuracy: 0.73 - ETA: 2:37 - loss: 0.9473 - accuracy: 0.73 - ETA: 2:34 - loss: 0.9491 - accuracy: 0.73 - ETA: 2:31 - loss: 0.9489 - accuracy: 0.73 - ETA: 2:29 - loss: 0.9526 - accuracy: 0.73 - ETA: 2:26 - loss: 0.9586 - accuracy: 0.73 - ETA: 2:24 - loss: 0.9584 - accuracy: 0.73 - ETA: 2:21 - loss: 0.9626 - accuracy: 0.73 - ETA: 2:19 - loss: 0.9619 - accuracy: 0.73 - ETA: 2:16 - loss: 0.9621 - accuracy: 0.73 - ETA: 2:14 - loss: 0.9667 - accuracy: 0.73 - ETA: 2:11 - loss: 0.9664 - accuracy: 0.73 - ETA: 2:09 - loss: 0.9690 - accuracy: 0.73 - ETA: 2:06 - loss: 0.9687 - accuracy: 0.73 - ETA: 2:04 - loss: 0.9705 - accuracy: 0.73 - ETA: 2:02 - loss: 0.9709 - accuracy: 0.73 - ETA: 1:59 - loss: 0.9764 - accuracy: 0.73 - ETA: 1:57 - loss: 0.9756 - accuracy: 0.73 - ETA: 1:55 - loss: 0.9764 - accuracy: 0.73 - ETA: 1:53 - loss: 0.9782 - accuracy: 0.73 - ETA: 1:51 - loss: 0.9746 - accuracy: 0.73 - ETA: 1:49 - loss: 0.9732 - accuracy: 0.73 - ETA: 1:47 - loss: 0.9712 - accuracy: 0.73 - ETA: 1:45 - loss: 0.9707 - accuracy: 0.73 - ETA: 1:43 - loss: 0.9697 - accuracy: 0.73 - ETA: 1:41 - loss: 0.9694 - accuracy: 0.73 - ETA: 1:39 - loss: 0.9666 - accuracy: 0.73 - ETA: 1:37 - loss: 0.9671 - accuracy: 0.73 - ETA: 1:35 - loss: 0.9653 - accuracy: 0.73 - ETA: 1:33 - loss: 0.9639 - accuracy: 0.73 - ETA: 1:31 - loss: 0.9618 - accuracy: 0.73 - ETA: 1:29 - loss: 0.9612 - accuracy: 0.73 - ETA: 1:27 - loss: 0.9607 - accuracy: 0.73 - ETA: 1:25 - loss: 0.9610 - accuracy: 0.73 - ETA: 1:23 - loss: 0.9638 - accuracy: 0.73 - ETA: 1:21 - loss: 0.9652 - accuracy: 0.73 - ETA: 1:19 - loss: 0.9648 - accuracy: 0.73 - ETA: 1:18 - loss: 0.9651 - accuracy: 0.73 - ETA: 1:16 - loss: 0.9678 - accuracy: 0.73 - ETA: 1:14 - loss: 0.9722 - accuracy: 0.73 - ETA: 1:12 - loss: 0.9736 - accuracy: 0.73 - ETA: 1:10 - loss: 0.9737 - accuracy: 0.73 - ETA: 1:09 - loss: 0.9757 - accuracy: 0.73 - ETA: 1:07 - loss: 0.9789 - accuracy: 0.73 - ETA: 1:05 - loss: 0.9798 - accuracy: 0.73 - ETA: 1:03 - loss: 0.9800 - accuracy: 0.73 - ETA: 1:02 - loss: 0.9821 - accuracy: 0.73 - ETA: 1:00 - loss: 0.9831 - accuracy: 0.73 - ETA: 58s - loss: 0.9837 - accuracy: 0.7308 - ETA: 57s - loss: 0.9854 - accuracy: 0.730 - ETA: 55s - loss: 0.9863 - accuracy: 0.730 - ETA: 53s - loss: 0.9864 - accuracy: 0.730 - ETA: 52s - loss: 0.9862 - accuracy: 0.729 - ETA: 50s - loss: 0.9871 - accuracy: 0.729 - ETA: 48s - loss: 0.9851 - accuracy: 0.729 - ETA: 47s - loss: 0.9852 - accuracy: 0.729 - ETA: 45s - loss: 0.9846 - accuracy: 0.729 - ETA: 44s - loss: 0.9858 - accuracy: 0.729 - ETA: 42s - loss: 0.9861 - accuracy: 0.729 - ETA: 40s - loss: 0.9870 - accuracy: 0.729 - ETA: 39s - loss: 0.9863 - accuracy: 0.729 - ETA: 37s - loss: 0.9852 - accuracy: 0.729 - ETA: 36s - loss: 0.9913 - accuracy: 0.729 - ETA: 34s - loss: 0.9918 - accuracy: 0.729 - ETA: 32s - loss: 0.9950 - accuracy: 0.728 - ETA: 31s - loss: 0.9964 - accuracy: 0.728 - ETA: 29s - loss: 0.9959 - accuracy: 0.728 - ETA: 28s - loss: 0.9964 - accuracy: 0.728 - ETA: 26s - loss: 0.9963 - accuracy: 0.728 - ETA: 25s - loss: 0.9958 - accuracy: 0.728 - ETA: 23s - loss: 0.9944 - accuracy: 0.728 - ETA: 22s - loss: 0.9949 - accuracy: 0.729 - ETA: 20s - loss: 0.9963 - accuracy: 0.728 - ETA: 19s - loss: 0.9951 - accuracy: 0.728 - ETA: 17s - loss: 0.9952 - accuracy: 0.728 - ETA: 16s - loss: 0.9955 - accuracy: 0.728 - ETA: 14s - loss: 0.9967 - accuracy: 0.728 - ETA: 13s - loss: 0.9977 - accuracy: 0.728 - ETA: 11s - loss: 0.9977 - accuracy: 0.727 - ETA: 10s - loss: 0.9996 - accuracy: 0.727 - ETA: 8s - loss: 0.9972 - accuracy: 0.728 - ETA: 7s - loss: 0.9980 - accuracy: 0.72 - ETA: 5s - loss: 0.9962 - accuracy: 0.72 - ETA: 4s - loss: 0.9956 - accuracy: 0.72 - ETA: 2s - loss: 0.9942 - accuracy: 0.72 - ETA: 1s - loss: 0.9944 - accuracy: 0.72 - 232s 12ms/step - loss: 0.9941 - accuracy: 0.7276 - val_loss: 1.3672 - val_accuracy: 0.7155\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:51 - loss: 0.8123 - accuracy: 0.71 - ETA: 2:46 - loss: 0.8336 - accuracy: 0.71 - ETA: 2:45 - loss: 0.9612 - accuracy: 0.70 - ETA: 2:46 - loss: 0.9336 - accuracy: 0.72 - ETA: 2:43 - loss: 0.9394 - accuracy: 0.72 - ETA: 2:44 - loss: 0.9170 - accuracy: 0.72 - ETA: 2:43 - loss: 0.9611 - accuracy: 0.72 - ETA: 2:42 - loss: 0.9722 - accuracy: 0.72 - ETA: 2:40 - loss: 0.9655 - accuracy: 0.72 - ETA: 2:39 - loss: 0.9780 - accuracy: 0.72 - ETA: 2:38 - loss: 0.9883 - accuracy: 0.71 - ETA: 2:36 - loss: 1.0017 - accuracy: 0.71 - ETA: 2:35 - loss: 0.9880 - accuracy: 0.71 - ETA: 2:34 - loss: 0.9849 - accuracy: 0.71 - ETA: 2:33 - loss: 0.9806 - accuracy: 0.71 - ETA: 2:31 - loss: 0.9696 - accuracy: 0.72 - ETA: 2:31 - loss: 0.9565 - accuracy: 0.72 - ETA: 2:30 - loss: 0.9871 - accuracy: 0.72 - ETA: 2:29 - loss: 0.9889 - accuracy: 0.72 - ETA: 2:28 - loss: 0.9731 - accuracy: 0.72 - ETA: 2:28 - loss: 0.9595 - accuracy: 0.72 - ETA: 2:26 - loss: 0.9578 - accuracy: 0.73 - ETA: 2:25 - loss: 0.9569 - accuracy: 0.73 - ETA: 2:24 - loss: 0.9754 - accuracy: 0.73 - ETA: 2:23 - loss: 0.9788 - accuracy: 0.73 - ETA: 2:21 - loss: 0.9950 - accuracy: 0.72 - ETA: 2:20 - loss: 0.9997 - accuracy: 0.72 - ETA: 2:19 - loss: 0.9872 - accuracy: 0.73 - ETA: 2:18 - loss: 0.9885 - accuracy: 0.72 - ETA: 2:17 - loss: 0.9813 - accuracy: 0.73 - ETA: 2:15 - loss: 0.9823 - accuracy: 0.73 - ETA: 2:14 - loss: 0.9764 - accuracy: 0.73 - ETA: 2:13 - loss: 0.9830 - accuracy: 0.73 - ETA: 2:12 - loss: 0.9872 - accuracy: 0.73 - ETA: 2:11 - loss: 0.9878 - accuracy: 0.72 - ETA: 2:10 - loss: 0.9824 - accuracy: 0.73 - ETA: 2:09 - loss: 0.9805 - accuracy: 0.73 - ETA: 2:07 - loss: 0.9764 - accuracy: 0.73 - ETA: 2:06 - loss: 0.9709 - accuracy: 0.73 - ETA: 2:05 - loss: 0.9787 - accuracy: 0.73 - ETA: 2:04 - loss: 0.9750 - accuracy: 0.73 - ETA: 2:03 - loss: 0.9764 - accuracy: 0.73 - ETA: 2:02 - loss: 0.9744 - accuracy: 0.73 - ETA: 2:01 - loss: 0.9755 - accuracy: 0.73 - ETA: 2:00 - loss: 0.9746 - accuracy: 0.73 - ETA: 1:59 - loss: 0.9786 - accuracy: 0.73 - ETA: 1:57 - loss: 0.9790 - accuracy: 0.73 - ETA: 1:56 - loss: 0.9762 - accuracy: 0.73 - ETA: 1:55 - loss: 0.9798 - accuracy: 0.73 - ETA: 1:54 - loss: 0.9817 - accuracy: 0.73 - ETA: 1:53 - loss: 0.9773 - accuracy: 0.73 - ETA: 1:52 - loss: 0.9781 - accuracy: 0.73 - ETA: 1:51 - loss: 0.9781 - accuracy: 0.73 - ETA: 1:50 - loss: 0.9786 - accuracy: 0.73 - ETA: 1:49 - loss: 0.9827 - accuracy: 0.73 - ETA: 1:47 - loss: 0.9802 - accuracy: 0.73 - ETA: 1:46 - loss: 0.9773 - accuracy: 0.73 - ETA: 1:45 - loss: 0.9767 - accuracy: 0.73 - ETA: 1:44 - loss: 0.9814 - accuracy: 0.73 - ETA: 1:43 - loss: 0.9813 - accuracy: 0.73 - ETA: 1:42 - loss: 0.9778 - accuracy: 0.73 - ETA: 1:41 - loss: 0.9785 - accuracy: 0.73 - ETA: 1:39 - loss: 0.9846 - accuracy: 0.73 - ETA: 1:38 - loss: 0.9863 - accuracy: 0.73 - ETA: 1:37 - loss: 0.9889 - accuracy: 0.73 - ETA: 1:36 - loss: 0.9906 - accuracy: 0.73 - ETA: 1:35 - loss: 0.9923 - accuracy: 0.73 - ETA: 1:34 - loss: 0.9907 - accuracy: 0.73 - ETA: 1:33 - loss: 0.9897 - accuracy: 0.73 - ETA: 1:31 - loss: 0.9906 - accuracy: 0.73 - ETA: 1:30 - loss: 0.9951 - accuracy: 0.73 - ETA: 1:29 - loss: 0.9924 - accuracy: 0.73 - ETA: 1:28 - loss: 0.9920 - accuracy: 0.73 - ETA: 1:27 - loss: 0.9897 - accuracy: 0.73 - ETA: 1:26 - loss: 0.9894 - accuracy: 0.73 - ETA: 1:24 - loss: 0.9849 - accuracy: 0.73 - ETA: 1:23 - loss: 0.9853 - accuracy: 0.73 - ETA: 1:22 - loss: 0.9808 - accuracy: 0.73 - ETA: 1:21 - loss: 0.9790 - accuracy: 0.73 - ETA: 1:20 - loss: 0.9781 - accuracy: 0.73 - ETA: 1:19 - loss: 0.9767 - accuracy: 0.73 - ETA: 1:18 - loss: 0.9765 - accuracy: 0.73 - ETA: 1:17 - loss: 0.9738 - accuracy: 0.73 - ETA: 1:16 - loss: 0.9787 - accuracy: 0.73 - ETA: 1:15 - loss: 0.9771 - accuracy: 0.73 - ETA: 1:13 - loss: 0.9761 - accuracy: 0.73 - ETA: 1:12 - loss: 0.9746 - accuracy: 0.73 - ETA: 1:11 - loss: 0.9715 - accuracy: 0.73 - ETA: 1:10 - loss: 0.9762 - accuracy: 0.73 - ETA: 1:09 - loss: 0.9773 - accuracy: 0.73 - ETA: 1:08 - loss: 0.9786 - accuracy: 0.73 - ETA: 1:07 - loss: 0.9805 - accuracy: 0.73 - ETA: 1:05 - loss: 0.9849 - accuracy: 0.73 - ETA: 1:04 - loss: 0.9840 - accuracy: 0.73 - ETA: 1:03 - loss: 0.9818 - accuracy: 0.73 - ETA: 1:02 - loss: 0.9802 - accuracy: 0.73 - ETA: 1:01 - loss: 0.9775 - accuracy: 0.73 - ETA: 1:00 - loss: 0.9802 - accuracy: 0.73 - ETA: 59s - loss: 0.9823 - accuracy: 0.7336 - ETA: 58s - loss: 0.9834 - accuracy: 0.733 - ETA: 56s - loss: 0.9824 - accuracy: 0.733 - ETA: 55s - loss: 0.9810 - accuracy: 0.733 - ETA: 54s - loss: 0.9806 - accuracy: 0.733 - ETA: 53s - loss: 0.9807 - accuracy: 0.733 - ETA: 52s - loss: 0.9814 - accuracy: 0.733 - ETA: 51s - loss: 0.9815 - accuracy: 0.733 - ETA: 50s - loss: 0.9848 - accuracy: 0.733 - ETA: 48s - loss: 0.9856 - accuracy: 0.733 - ETA: 47s - loss: 0.9922 - accuracy: 0.732 - ETA: 46s - loss: 0.9891 - accuracy: 0.733 - ETA: 45s - loss: 0.9869 - accuracy: 0.733 - ETA: 44s - loss: 0.9878 - accuracy: 0.733 - ETA: 43s - loss: 0.9943 - accuracy: 0.733 - ETA: 42s - loss: 0.9936 - accuracy: 0.733 - ETA: 40s - loss: 0.9961 - accuracy: 0.733 - ETA: 39s - loss: 0.9958 - accuracy: 0.733 - ETA: 38s - loss: 0.9948 - accuracy: 0.733 - ETA: 37s - loss: 0.9932 - accuracy: 0.733 - ETA: 36s - loss: 0.9934 - accuracy: 0.733 - ETA: 35s - loss: 0.9925 - accuracy: 0.734 - ETA: 34s - loss: 0.9911 - accuracy: 0.734 - ETA: 32s - loss: 0.9918 - accuracy: 0.734 - ETA: 31s - loss: 0.9893 - accuracy: 0.734 - ETA: 30s - loss: 0.9907 - accuracy: 0.733 - ETA: 29s - loss: 0.9897 - accuracy: 0.733 - ETA: 28s - loss: 0.9889 - accuracy: 0.733 - ETA: 27s - loss: 0.9881 - accuracy: 0.733 - ETA: 26s - loss: 0.9879 - accuracy: 0.734 - ETA: 24s - loss: 0.9896 - accuracy: 0.733 - ETA: 23s - loss: 0.9980 - accuracy: 0.733 - ETA: 22s - loss: 0.9952 - accuracy: 0.733 - ETA: 21s - loss: 0.9954 - accuracy: 0.733 - ETA: 20s - loss: 0.9970 - accuracy: 0.733 - ETA: 19s - loss: 0.9973 - accuracy: 0.733 - ETA: 18s - loss: 0.9999 - accuracy: 0.733 - ETA: 16s - loss: 0.9991 - accuracy: 0.733 - ETA: 15s - loss: 0.9987 - accuracy: 0.733 - ETA: 14s - loss: 0.9978 - accuracy: 0.733 - ETA: 13s - loss: 0.9973 - accuracy: 0.733 - ETA: 12s - loss: 0.9973 - accuracy: 0.733 - ETA: 11s - loss: 0.9998 - accuracy: 0.732 - ETA: 10s - loss: 0.9990 - accuracy: 0.733 - ETA: 8s - loss: 0.9984 - accuracy: 0.732 - ETA: 7s - loss: 0.9994 - accuracy: 0.73 - ETA: 6s - loss: 0.9985 - accuracy: 0.73 - ETA: 5s - loss: 1.0005 - accuracy: 0.73 - ETA: 4s - loss: 1.0015 - accuracy: 0.73 - ETA: 3s - loss: 1.0032 - accuracy: 0.73 - ETA: 2s - loss: 1.0048 - accuracy: 0.73 - ETA: 0s - loss: 1.0096 - accuracy: 0.73 - 183s 9ms/step - loss: 1.0081 - accuracy: 0.7309 - val_loss: 1.3393 - val_accuracy: 0.7062\n",
      "Epoch 20/100\n",
      "19312/19312 [==============================] - ETA: 3:00 - loss: 1.2299 - accuracy: 0.65 - ETA: 2:54 - loss: 1.0179 - accuracy: 0.70 - ETA: 2:49 - loss: 1.0465 - accuracy: 0.69 - ETA: 2:46 - loss: 0.9976 - accuracy: 0.70 - ETA: 2:44 - loss: 0.9881 - accuracy: 0.71 - ETA: 2:45 - loss: 0.9604 - accuracy: 0.72 - ETA: 2:43 - loss: 0.9830 - accuracy: 0.72 - ETA: 2:41 - loss: 0.9635 - accuracy: 0.72 - ETA: 2:39 - loss: 1.0058 - accuracy: 0.71 - ETA: 2:38 - loss: 1.0042 - accuracy: 0.71 - ETA: 2:37 - loss: 1.0213 - accuracy: 0.71 - ETA: 2:35 - loss: 1.0009 - accuracy: 0.71 - ETA: 2:34 - loss: 1.0067 - accuracy: 0.71 - ETA: 2:34 - loss: 1.0173 - accuracy: 0.71 - ETA: 2:34 - loss: 1.0050 - accuracy: 0.71 - ETA: 2:32 - loss: 0.9987 - accuracy: 0.72 - ETA: 2:31 - loss: 1.0058 - accuracy: 0.72 - ETA: 2:29 - loss: 1.0102 - accuracy: 0.71 - ETA: 2:28 - loss: 1.0073 - accuracy: 0.71 - ETA: 2:27 - loss: 1.0055 - accuracy: 0.71 - ETA: 2:25 - loss: 1.0000 - accuracy: 0.71 - ETA: 2:24 - loss: 1.0134 - accuracy: 0.71 - ETA: 2:23 - loss: 1.0027 - accuracy: 0.71 - ETA: 2:22 - loss: 1.0014 - accuracy: 0.71 - ETA: 2:21 - loss: 1.0015 - accuracy: 0.71 - ETA: 2:20 - loss: 1.0059 - accuracy: 0.71 - ETA: 2:19 - loss: 1.0015 - accuracy: 0.72 - ETA: 2:18 - loss: 0.9886 - accuracy: 0.72 - ETA: 2:17 - loss: 0.9934 - accuracy: 0.72 - ETA: 2:16 - loss: 0.9887 - accuracy: 0.72 - ETA: 2:15 - loss: 0.9904 - accuracy: 0.72 - ETA: 2:14 - loss: 0.9804 - accuracy: 0.72 - ETA: 2:13 - loss: 0.9855 - accuracy: 0.72 - ETA: 2:11 - loss: 0.9799 - accuracy: 0.72 - ETA: 2:10 - loss: 0.9790 - accuracy: 0.72 - ETA: 2:09 - loss: 0.9852 - accuracy: 0.72 - ETA: 2:08 - loss: 0.9893 - accuracy: 0.72 - ETA: 2:06 - loss: 0.9910 - accuracy: 0.72 - ETA: 2:05 - loss: 0.9895 - accuracy: 0.72 - ETA: 2:04 - loss: 0.9967 - accuracy: 0.72 - ETA: 2:03 - loss: 0.9967 - accuracy: 0.72 - ETA: 2:02 - loss: 0.9997 - accuracy: 0.72 - ETA: 2:01 - loss: 1.0092 - accuracy: 0.72 - ETA: 2:00 - loss: 1.0053 - accuracy: 0.72 - ETA: 1:59 - loss: 1.0028 - accuracy: 0.72 - ETA: 1:57 - loss: 0.9956 - accuracy: 0.72 - ETA: 1:56 - loss: 0.9954 - accuracy: 0.72 - ETA: 1:55 - loss: 0.9900 - accuracy: 0.72 - ETA: 1:54 - loss: 0.9907 - accuracy: 0.72 - ETA: 1:53 - loss: 0.9882 - accuracy: 0.72 - ETA: 1:52 - loss: 0.9886 - accuracy: 0.72 - ETA: 1:50 - loss: 0.9926 - accuracy: 0.72 - ETA: 1:49 - loss: 0.9823 - accuracy: 0.72 - ETA: 1:48 - loss: 0.9792 - accuracy: 0.72 - ETA: 1:47 - loss: 0.9781 - accuracy: 0.72 - ETA: 1:46 - loss: 0.9782 - accuracy: 0.72 - ETA: 1:45 - loss: 0.9827 - accuracy: 0.72 - ETA: 1:44 - loss: 0.9825 - accuracy: 0.72 - ETA: 1:43 - loss: 0.9816 - accuracy: 0.72 - ETA: 1:42 - loss: 0.9840 - accuracy: 0.72 - ETA: 1:41 - loss: 0.9876 - accuracy: 0.72 - ETA: 1:40 - loss: 0.9838 - accuracy: 0.72 - ETA: 1:38 - loss: 0.9863 - accuracy: 0.72 - ETA: 1:37 - loss: 0.9817 - accuracy: 0.72 - ETA: 1:36 - loss: 0.9786 - accuracy: 0.72 - ETA: 1:35 - loss: 0.9798 - accuracy: 0.72 - ETA: 1:34 - loss: 0.9828 - accuracy: 0.72 - ETA: 1:33 - loss: 0.9863 - accuracy: 0.72 - ETA: 1:32 - loss: 0.9840 - accuracy: 0.72 - ETA: 1:31 - loss: 0.9840 - accuracy: 0.72 - ETA: 1:29 - loss: 0.9861 - accuracy: 0.72 - ETA: 1:28 - loss: 0.9843 - accuracy: 0.72 - ETA: 1:27 - loss: 0.9823 - accuracy: 0.72 - ETA: 1:26 - loss: 0.9848 - accuracy: 0.72 - ETA: 1:25 - loss: 0.9866 - accuracy: 0.72 - ETA: 1:24 - loss: 0.9877 - accuracy: 0.72 - ETA: 1:23 - loss: 0.9872 - accuracy: 0.72 - ETA: 1:22 - loss: 0.9928 - accuracy: 0.72 - ETA: 1:20 - loss: 0.9912 - accuracy: 0.72 - ETA: 1:19 - loss: 0.9944 - accuracy: 0.72 - ETA: 1:18 - loss: 0.9927 - accuracy: 0.72 - ETA: 1:17 - loss: 0.9932 - accuracy: 0.72 - ETA: 1:16 - loss: 0.9925 - accuracy: 0.72 - ETA: 1:15 - loss: 0.9926 - accuracy: 0.72 - ETA: 1:14 - loss: 0.9925 - accuracy: 0.72 - ETA: 1:13 - loss: 0.9937 - accuracy: 0.72 - ETA: 1:11 - loss: 0.9938 - accuracy: 0.72 - ETA: 1:10 - loss: 0.9917 - accuracy: 0.72 - ETA: 1:09 - loss: 0.9880 - accuracy: 0.72 - ETA: 1:08 - loss: 0.9892 - accuracy: 0.72 - ETA: 1:07 - loss: 0.9875 - accuracy: 0.72 - ETA: 1:06 - loss: 0.9848 - accuracy: 0.73 - ETA: 1:05 - loss: 0.9838 - accuracy: 0.73 - ETA: 1:03 - loss: 0.9867 - accuracy: 0.72 - ETA: 1:02 - loss: 0.9871 - accuracy: 0.72 - ETA: 1:01 - loss: 0.9857 - accuracy: 0.72 - ETA: 1:00 - loss: 0.9858 - accuracy: 0.72 - ETA: 59s - loss: 0.9863 - accuracy: 0.7287 - ETA: 58s - loss: 0.9862 - accuracy: 0.729 - ETA: 57s - loss: 0.9903 - accuracy: 0.728 - ETA: 56s - loss: 0.9911 - accuracy: 0.728 - ETA: 55s - loss: 0.9905 - accuracy: 0.728 - ETA: 53s - loss: 0.9914 - accuracy: 0.728 - ETA: 52s - loss: 0.9932 - accuracy: 0.728 - ETA: 51s - loss: 0.9910 - accuracy: 0.729 - ETA: 50s - loss: 0.9909 - accuracy: 0.728 - ETA: 49s - loss: 0.9889 - accuracy: 0.729 - ETA: 48s - loss: 0.9884 - accuracy: 0.728 - ETA: 47s - loss: 0.9893 - accuracy: 0.728 - ETA: 46s - loss: 0.9885 - accuracy: 0.728 - ETA: 44s - loss: 0.9882 - accuracy: 0.728 - ETA: 43s - loss: 0.9935 - accuracy: 0.727 - ETA: 42s - loss: 0.9956 - accuracy: 0.727 - ETA: 41s - loss: 0.9972 - accuracy: 0.727 - ETA: 40s - loss: 0.9970 - accuracy: 0.727 - ETA: 39s - loss: 0.9977 - accuracy: 0.727 - ETA: 38s - loss: 0.9960 - accuracy: 0.727 - ETA: 37s - loss: 0.9936 - accuracy: 0.727 - ETA: 35s - loss: 0.9937 - accuracy: 0.727 - ETA: 34s - loss: 0.9927 - accuracy: 0.727 - ETA: 33s - loss: 0.9916 - accuracy: 0.727 - ETA: 32s - loss: 0.9912 - accuracy: 0.727 - ETA: 31s - loss: 0.9903 - accuracy: 0.728 - ETA: 30s - loss: 0.9927 - accuracy: 0.727 - ETA: 29s - loss: 0.9932 - accuracy: 0.727 - ETA: 28s - loss: 0.9952 - accuracy: 0.726 - ETA: 26s - loss: 0.9942 - accuracy: 0.727 - ETA: 25s - loss: 0.9950 - accuracy: 0.727 - ETA: 24s - loss: 0.9969 - accuracy: 0.726 - ETA: 23s - loss: 0.9950 - accuracy: 0.726 - ETA: 22s - loss: 0.9938 - accuracy: 0.727 - ETA: 21s - loss: 0.9953 - accuracy: 0.727 - ETA: 20s - loss: 0.9943 - accuracy: 0.727 - ETA: 19s - loss: 0.9953 - accuracy: 0.727 - ETA: 17s - loss: 0.9942 - accuracy: 0.727 - ETA: 16s - loss: 0.9937 - accuracy: 0.727 - ETA: 15s - loss: 0.9924 - accuracy: 0.727 - ETA: 14s - loss: 0.9905 - accuracy: 0.728 - ETA: 13s - loss: 0.9907 - accuracy: 0.728 - ETA: 12s - loss: 0.9906 - accuracy: 0.728 - ETA: 11s - loss: 0.9896 - accuracy: 0.728 - ETA: 10s - loss: 0.9904 - accuracy: 0.727 - ETA: 8s - loss: 0.9891 - accuracy: 0.727 - ETA: 7s - loss: 0.9911 - accuracy: 0.72 - ETA: 6s - loss: 0.9911 - accuracy: 0.72 - ETA: 5s - loss: 0.9895 - accuracy: 0.72 - ETA: 4s - loss: 0.9887 - accuracy: 0.72 - ETA: 3s - loss: 0.9894 - accuracy: 0.72 - ETA: 2s - loss: 0.9902 - accuracy: 0.72 - ETA: 0s - loss: 0.9914 - accuracy: 0.72 - 182s 9ms/step - loss: 0.9918 - accuracy: 0.7275 - val_loss: 1.4161 - val_accuracy: 0.7169\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:54 - loss: 0.9204 - accuracy: 0.74 - ETA: 2:51 - loss: 0.9602 - accuracy: 0.74 - ETA: 2:48 - loss: 0.9973 - accuracy: 0.72 - ETA: 2:46 - loss: 0.9996 - accuracy: 0.73 - ETA: 2:44 - loss: 0.9297 - accuracy: 0.74 - ETA: 2:43 - loss: 0.9346 - accuracy: 0.73 - ETA: 2:41 - loss: 0.9715 - accuracy: 0.71 - ETA: 2:41 - loss: 0.9865 - accuracy: 0.71 - ETA: 2:42 - loss: 0.9873 - accuracy: 0.71 - ETA: 2:41 - loss: 0.9721 - accuracy: 0.71 - ETA: 2:39 - loss: 0.9809 - accuracy: 0.71 - ETA: 2:37 - loss: 1.0024 - accuracy: 0.71 - ETA: 2:36 - loss: 1.0104 - accuracy: 0.71 - ETA: 2:34 - loss: 1.0048 - accuracy: 0.71 - ETA: 2:34 - loss: 0.9994 - accuracy: 0.71 - ETA: 2:32 - loss: 0.9932 - accuracy: 0.71 - ETA: 2:31 - loss: 0.9962 - accuracy: 0.71 - ETA: 2:30 - loss: 0.9836 - accuracy: 0.71 - ETA: 2:29 - loss: 0.9925 - accuracy: 0.72 - ETA: 2:27 - loss: 0.9925 - accuracy: 0.72 - ETA: 2:26 - loss: 0.9994 - accuracy: 0.71 - ETA: 2:25 - loss: 0.9985 - accuracy: 0.71 - ETA: 2:24 - loss: 1.0166 - accuracy: 0.71 - ETA: 2:23 - loss: 1.0150 - accuracy: 0.71 - ETA: 2:23 - loss: 1.0116 - accuracy: 0.72 - ETA: 2:21 - loss: 1.0155 - accuracy: 0.72 - ETA: 2:20 - loss: 1.0117 - accuracy: 0.72 - ETA: 2:19 - loss: 1.0044 - accuracy: 0.72 - ETA: 2:18 - loss: 0.9945 - accuracy: 0.72 - ETA: 2:17 - loss: 0.9914 - accuracy: 0.72 - ETA: 2:15 - loss: 0.9868 - accuracy: 0.72 - ETA: 2:14 - loss: 0.9919 - accuracy: 0.72 - ETA: 2:13 - loss: 0.9896 - accuracy: 0.72 - ETA: 2:11 - loss: 0.9918 - accuracy: 0.72 - ETA: 2:10 - loss: 0.9942 - accuracy: 0.72 - ETA: 2:09 - loss: 0.9899 - accuracy: 0.72 - ETA: 2:08 - loss: 0.9861 - accuracy: 0.72 - ETA: 2:08 - loss: 0.9814 - accuracy: 0.72 - ETA: 2:06 - loss: 0.9821 - accuracy: 0.72 - ETA: 2:05 - loss: 0.9780 - accuracy: 0.72 - ETA: 2:04 - loss: 0.9732 - accuracy: 0.72 - ETA: 2:03 - loss: 0.9648 - accuracy: 0.73 - ETA: 2:01 - loss: 0.9593 - accuracy: 0.73 - ETA: 2:00 - loss: 0.9696 - accuracy: 0.72 - ETA: 1:59 - loss: 0.9783 - accuracy: 0.72 - ETA: 1:58 - loss: 0.9797 - accuracy: 0.72 - ETA: 1:57 - loss: 0.9886 - accuracy: 0.72 - ETA: 1:56 - loss: 0.9877 - accuracy: 0.72 - ETA: 1:55 - loss: 0.9812 - accuracy: 0.72 - ETA: 1:54 - loss: 0.9874 - accuracy: 0.72 - ETA: 1:53 - loss: 0.9899 - accuracy: 0.72 - ETA: 1:52 - loss: 0.9934 - accuracy: 0.72 - ETA: 1:51 - loss: 0.9981 - accuracy: 0.72 - ETA: 1:50 - loss: 0.9950 - accuracy: 0.72 - ETA: 1:48 - loss: 0.9948 - accuracy: 0.72 - ETA: 1:47 - loss: 0.9905 - accuracy: 0.72 - ETA: 1:46 - loss: 0.9988 - accuracy: 0.72 - ETA: 1:45 - loss: 0.9991 - accuracy: 0.72 - ETA: 1:44 - loss: 1.0069 - accuracy: 0.72 - ETA: 1:43 - loss: 1.0051 - accuracy: 0.72 - ETA: 1:42 - loss: 1.0021 - accuracy: 0.72 - ETA: 1:41 - loss: 0.9999 - accuracy: 0.72 - ETA: 1:39 - loss: 1.0019 - accuracy: 0.72 - ETA: 1:38 - loss: 0.9997 - accuracy: 0.72 - ETA: 1:37 - loss: 0.9992 - accuracy: 0.72 - ETA: 1:36 - loss: 0.9967 - accuracy: 0.72 - ETA: 1:35 - loss: 0.9955 - accuracy: 0.72 - ETA: 1:34 - loss: 0.9945 - accuracy: 0.72 - ETA: 1:33 - loss: 0.9939 - accuracy: 0.72 - ETA: 1:31 - loss: 0.9940 - accuracy: 0.72 - ETA: 1:30 - loss: 0.9941 - accuracy: 0.72 - ETA: 1:29 - loss: 0.9952 - accuracy: 0.72 - ETA: 1:28 - loss: 0.9934 - accuracy: 0.72 - ETA: 1:27 - loss: 0.9954 - accuracy: 0.72 - ETA: 1:26 - loss: 0.9917 - accuracy: 0.72 - ETA: 1:24 - loss: 0.9936 - accuracy: 0.72 - ETA: 1:23 - loss: 0.9957 - accuracy: 0.72 - ETA: 1:22 - loss: 0.9961 - accuracy: 0.72 - ETA: 1:21 - loss: 0.9996 - accuracy: 0.72 - ETA: 1:20 - loss: 0.9995 - accuracy: 0.72 - ETA: 1:19 - loss: 1.0064 - accuracy: 0.72 - ETA: 1:18 - loss: 1.0062 - accuracy: 0.72 - ETA: 1:17 - loss: 1.0055 - accuracy: 0.72 - ETA: 1:16 - loss: 1.0060 - accuracy: 0.72 - ETA: 1:14 - loss: 1.0038 - accuracy: 0.72 - ETA: 1:13 - loss: 1.0032 - accuracy: 0.72 - ETA: 1:12 - loss: 1.0054 - accuracy: 0.72 - ETA: 1:11 - loss: 1.0079 - accuracy: 0.72 - ETA: 1:10 - loss: 1.0109 - accuracy: 0.72 - ETA: 1:09 - loss: 1.0104 - accuracy: 0.72 - ETA: 1:08 - loss: 1.0237 - accuracy: 0.72 - ETA: 1:07 - loss: 1.0208 - accuracy: 0.72 - ETA: 1:06 - loss: 1.0222 - accuracy: 0.72 - ETA: 1:05 - loss: 1.0205 - accuracy: 0.72 - ETA: 1:04 - loss: 1.0218 - accuracy: 0.72 - ETA: 1:03 - loss: 1.0197 - accuracy: 0.72 - ETA: 1:01 - loss: 1.0175 - accuracy: 0.72 - ETA: 1:00 - loss: 1.0188 - accuracy: 0.72 - ETA: 59s - loss: 1.0175 - accuracy: 0.7254 - ETA: 58s - loss: 1.0150 - accuracy: 0.725 - ETA: 57s - loss: 1.0131 - accuracy: 0.725 - ETA: 56s - loss: 1.0137 - accuracy: 0.725 - ETA: 55s - loss: 1.0136 - accuracy: 0.725 - ETA: 53s - loss: 1.0144 - accuracy: 0.724 - ETA: 52s - loss: 1.0148 - accuracy: 0.724 - ETA: 51s - loss: 1.0156 - accuracy: 0.724 - ETA: 50s - loss: 1.0156 - accuracy: 0.724 - ETA: 49s - loss: 1.0142 - accuracy: 0.724 - ETA: 48s - loss: 1.0169 - accuracy: 0.724 - ETA: 46s - loss: 1.0202 - accuracy: 0.723 - ETA: 45s - loss: 1.0197 - accuracy: 0.723 - ETA: 44s - loss: 1.0194 - accuracy: 0.723 - ETA: 43s - loss: 1.0185 - accuracy: 0.723 - ETA: 42s - loss: 1.0169 - accuracy: 0.723 - ETA: 41s - loss: 1.0149 - accuracy: 0.724 - ETA: 40s - loss: 1.0145 - accuracy: 0.724 - ETA: 38s - loss: 1.0144 - accuracy: 0.723 - ETA: 37s - loss: 1.0143 - accuracy: 0.724 - ETA: 36s - loss: 1.0132 - accuracy: 0.724 - ETA: 35s - loss: 1.0146 - accuracy: 0.724 - ETA: 34s - loss: 1.0136 - accuracy: 0.724 - ETA: 33s - loss: 1.0170 - accuracy: 0.724 - ETA: 31s - loss: 1.0168 - accuracy: 0.724 - ETA: 30s - loss: 1.0162 - accuracy: 0.724 - ETA: 29s - loss: 1.0162 - accuracy: 0.724 - ETA: 28s - loss: 1.0143 - accuracy: 0.724 - ETA: 27s - loss: 1.0143 - accuracy: 0.725 - ETA: 26s - loss: 1.0165 - accuracy: 0.724 - ETA: 25s - loss: 1.0160 - accuracy: 0.724 - ETA: 23s - loss: 1.0144 - accuracy: 0.725 - ETA: 22s - loss: 1.0128 - accuracy: 0.725 - ETA: 21s - loss: 1.0120 - accuracy: 0.725 - ETA: 20s - loss: 1.0120 - accuracy: 0.725 - ETA: 19s - loss: 1.0109 - accuracy: 0.725 - ETA: 18s - loss: 1.0121 - accuracy: 0.725 - ETA: 17s - loss: 1.0106 - accuracy: 0.726 - ETA: 15s - loss: 1.0126 - accuracy: 0.726 - ETA: 14s - loss: 1.0121 - accuracy: 0.726 - ETA: 13s - loss: 1.0111 - accuracy: 0.726 - ETA: 12s - loss: 1.0110 - accuracy: 0.726 - ETA: 11s - loss: 1.0100 - accuracy: 0.726 - ETA: 10s - loss: 1.0131 - accuracy: 0.725 - ETA: 9s - loss: 1.0137 - accuracy: 0.725 - ETA: 7s - loss: 1.0137 - accuracy: 0.72 - ETA: 6s - loss: 1.0135 - accuracy: 0.72 - ETA: 5s - loss: 1.0144 - accuracy: 0.72 - ETA: 4s - loss: 1.0125 - accuracy: 0.72 - ETA: 3s - loss: 1.0116 - accuracy: 0.72 - ETA: 2s - loss: 1.0128 - accuracy: 0.72 - ETA: 1s - loss: 1.0113 - accuracy: 0.72 - 185s 10ms/step - loss: 1.0096 - accuracy: 0.7266 - val_loss: 1.3968 - val_accuracy: 0.7109\n",
      "Epoch 22/100\n",
      "19312/19312 [==============================] - ETA: 3:09 - loss: 0.8506 - accuracy: 0.73 - ETA: 3:01 - loss: 0.9478 - accuracy: 0.73 - ETA: 2:54 - loss: 1.0446 - accuracy: 0.73 - ETA: 2:52 - loss: 1.0339 - accuracy: 0.73 - ETA: 2:49 - loss: 1.0558 - accuracy: 0.72 - ETA: 2:46 - loss: 1.0848 - accuracy: 0.71 - ETA: 2:45 - loss: 1.0730 - accuracy: 0.71 - ETA: 2:43 - loss: 1.0649 - accuracy: 0.71 - ETA: 2:41 - loss: 1.0940 - accuracy: 0.70 - ETA: 2:40 - loss: 1.0833 - accuracy: 0.71 - ETA: 2:38 - loss: 1.0531 - accuracy: 0.71 - ETA: 2:36 - loss: 1.0214 - accuracy: 0.72 - ETA: 2:36 - loss: 1.0378 - accuracy: 0.71 - ETA: 2:35 - loss: 1.0291 - accuracy: 0.71 - ETA: 2:34 - loss: 1.0089 - accuracy: 0.72 - ETA: 2:34 - loss: 0.9846 - accuracy: 0.72 - ETA: 2:33 - loss: 0.9971 - accuracy: 0.72 - ETA: 2:31 - loss: 1.0731 - accuracy: 0.72 - ETA: 2:31 - loss: 1.0777 - accuracy: 0.72 - ETA: 2:29 - loss: 1.0771 - accuracy: 0.72 - ETA: 2:28 - loss: 1.0630 - accuracy: 0.72 - ETA: 2:27 - loss: 1.0975 - accuracy: 0.72 - ETA: 2:26 - loss: 1.0920 - accuracy: 0.72 - ETA: 2:25 - loss: 1.0886 - accuracy: 0.72 - ETA: 2:23 - loss: 1.0934 - accuracy: 0.71 - ETA: 2:22 - loss: 1.1048 - accuracy: 0.71 - ETA: 2:21 - loss: 1.0966 - accuracy: 0.71 - ETA: 2:19 - loss: 1.0908 - accuracy: 0.71 - ETA: 2:18 - loss: 1.0862 - accuracy: 0.72 - ETA: 2:18 - loss: 1.0778 - accuracy: 0.72 - ETA: 2:17 - loss: 1.0720 - accuracy: 0.72 - ETA: 2:15 - loss: 1.0619 - accuracy: 0.72 - ETA: 2:14 - loss: 1.0662 - accuracy: 0.72 - ETA: 2:13 - loss: 1.0630 - accuracy: 0.72 - ETA: 2:12 - loss: 1.0607 - accuracy: 0.72 - ETA: 2:10 - loss: 1.0642 - accuracy: 0.72 - ETA: 2:09 - loss: 1.0553 - accuracy: 0.72 - ETA: 2:08 - loss: 1.0518 - accuracy: 0.72 - ETA: 2:07 - loss: 1.0573 - accuracy: 0.72 - ETA: 2:05 - loss: 1.0548 - accuracy: 0.72 - ETA: 2:04 - loss: 1.0528 - accuracy: 0.72 - ETA: 2:03 - loss: 1.0494 - accuracy: 0.72 - ETA: 2:02 - loss: 1.0494 - accuracy: 0.72 - ETA: 2:01 - loss: 1.0472 - accuracy: 0.72 - ETA: 2:00 - loss: 1.0416 - accuracy: 0.72 - ETA: 1:59 - loss: 1.0429 - accuracy: 0.72 - ETA: 1:58 - loss: 1.0497 - accuracy: 0.72 - ETA: 1:56 - loss: 1.0497 - accuracy: 0.72 - ETA: 1:55 - loss: 1.0458 - accuracy: 0.72 - ETA: 1:54 - loss: 1.0558 - accuracy: 0.72 - ETA: 1:53 - loss: 1.0569 - accuracy: 0.72 - ETA: 1:52 - loss: 1.0589 - accuracy: 0.72 - ETA: 1:51 - loss: 1.0535 - accuracy: 0.72 - ETA: 1:49 - loss: 1.0491 - accuracy: 0.72 - ETA: 1:48 - loss: 1.0500 - accuracy: 0.72 - ETA: 1:47 - loss: 1.0504 - accuracy: 0.72 - ETA: 1:46 - loss: 1.0548 - accuracy: 0.72 - ETA: 1:45 - loss: 1.0527 - accuracy: 0.72 - ETA: 1:44 - loss: 1.0511 - accuracy: 0.72 - ETA: 1:43 - loss: 1.0487 - accuracy: 0.72 - ETA: 1:42 - loss: 1.0463 - accuracy: 0.72 - ETA: 1:40 - loss: 1.0525 - accuracy: 0.72 - ETA: 1:39 - loss: 1.0535 - accuracy: 0.72 - ETA: 1:38 - loss: 1.0541 - accuracy: 0.72 - ETA: 1:37 - loss: 1.0510 - accuracy: 0.72 - ETA: 1:36 - loss: 1.0470 - accuracy: 0.72 - ETA: 1:35 - loss: 1.0433 - accuracy: 0.72 - ETA: 1:34 - loss: 1.0480 - accuracy: 0.72 - ETA: 1:32 - loss: 1.0492 - accuracy: 0.72 - ETA: 1:31 - loss: 1.0454 - accuracy: 0.72 - ETA: 1:30 - loss: 1.0432 - accuracy: 0.72 - ETA: 1:29 - loss: 1.0437 - accuracy: 0.72 - ETA: 1:28 - loss: 1.0455 - accuracy: 0.72 - ETA: 1:27 - loss: 1.0426 - accuracy: 0.72 - ETA: 1:26 - loss: 1.0425 - accuracy: 0.72 - ETA: 1:25 - loss: 1.0409 - accuracy: 0.72 - ETA: 1:23 - loss: 1.0402 - accuracy: 0.72 - ETA: 1:22 - loss: 1.0378 - accuracy: 0.72 - ETA: 1:21 - loss: 1.0374 - accuracy: 0.72 - ETA: 1:20 - loss: 1.0395 - accuracy: 0.72 - ETA: 1:19 - loss: 1.0367 - accuracy: 0.72 - ETA: 1:18 - loss: 1.0345 - accuracy: 0.72 - ETA: 1:17 - loss: 1.0312 - accuracy: 0.72 - ETA: 1:15 - loss: 1.0303 - accuracy: 0.72 - ETA: 1:14 - loss: 1.0277 - accuracy: 0.72 - ETA: 1:13 - loss: 1.0252 - accuracy: 0.72 - ETA: 1:12 - loss: 1.0267 - accuracy: 0.72 - ETA: 1:11 - loss: 1.0276 - accuracy: 0.72 - ETA: 1:10 - loss: 1.0319 - accuracy: 0.72 - ETA: 1:09 - loss: 1.0304 - accuracy: 0.72 - ETA: 1:08 - loss: 1.0270 - accuracy: 0.72 - ETA: 1:07 - loss: 1.0251 - accuracy: 0.72 - ETA: 1:05 - loss: 1.0250 - accuracy: 0.72 - ETA: 1:04 - loss: 1.0280 - accuracy: 0.72 - ETA: 1:03 - loss: 1.0291 - accuracy: 0.72 - ETA: 1:02 - loss: 1.0289 - accuracy: 0.72 - ETA: 1:01 - loss: 1.0259 - accuracy: 0.72 - ETA: 1:00 - loss: 1.0245 - accuracy: 0.72 - ETA: 59s - loss: 1.0238 - accuracy: 0.7244 - ETA: 57s - loss: 1.0246 - accuracy: 0.723 - ETA: 56s - loss: 1.0212 - accuracy: 0.724 - ETA: 55s - loss: 1.0206 - accuracy: 0.725 - ETA: 54s - loss: 1.0196 - accuracy: 0.725 - ETA: 53s - loss: 1.0197 - accuracy: 0.725 - ETA: 52s - loss: 1.0184 - accuracy: 0.725 - ETA: 51s - loss: 1.0178 - accuracy: 0.725 - ETA: 49s - loss: 1.0194 - accuracy: 0.725 - ETA: 48s - loss: 1.0195 - accuracy: 0.725 - ETA: 47s - loss: 1.0196 - accuracy: 0.725 - ETA: 46s - loss: 1.0222 - accuracy: 0.725 - ETA: 45s - loss: 1.0232 - accuracy: 0.725 - ETA: 44s - loss: 1.0210 - accuracy: 0.725 - ETA: 43s - loss: 1.0188 - accuracy: 0.726 - ETA: 42s - loss: 1.0196 - accuracy: 0.726 - ETA: 40s - loss: 1.0185 - accuracy: 0.726 - ETA: 39s - loss: 1.0198 - accuracy: 0.725 - ETA: 38s - loss: 1.0187 - accuracy: 0.725 - ETA: 37s - loss: 1.0209 - accuracy: 0.726 - ETA: 36s - loss: 1.0190 - accuracy: 0.726 - ETA: 35s - loss: 1.0171 - accuracy: 0.726 - ETA: 34s - loss: 1.0166 - accuracy: 0.726 - ETA: 32s - loss: 1.0154 - accuracy: 0.726 - ETA: 31s - loss: 1.0166 - accuracy: 0.726 - ETA: 30s - loss: 1.0173 - accuracy: 0.725 - ETA: 29s - loss: 1.0177 - accuracy: 0.725 - ETA: 28s - loss: 1.0185 - accuracy: 0.725 - ETA: 27s - loss: 1.0181 - accuracy: 0.725 - ETA: 26s - loss: 1.0195 - accuracy: 0.725 - ETA: 24s - loss: 1.0184 - accuracy: 0.726 - ETA: 23s - loss: 1.0150 - accuracy: 0.726 - ETA: 22s - loss: 1.0127 - accuracy: 0.727 - ETA: 21s - loss: 1.0115 - accuracy: 0.727 - ETA: 20s - loss: 1.0120 - accuracy: 0.727 - ETA: 19s - loss: 1.0107 - accuracy: 0.728 - ETA: 18s - loss: 1.0093 - accuracy: 0.728 - ETA: 16s - loss: 1.0109 - accuracy: 0.727 - ETA: 15s - loss: 1.0104 - accuracy: 0.728 - ETA: 14s - loss: 1.0091 - accuracy: 0.728 - ETA: 13s - loss: 1.0072 - accuracy: 0.728 - ETA: 12s - loss: 1.0070 - accuracy: 0.728 - ETA: 11s - loss: 1.0085 - accuracy: 0.728 - ETA: 10s - loss: 1.0091 - accuracy: 0.728 - ETA: 8s - loss: 1.0084 - accuracy: 0.728 - ETA: 7s - loss: 1.0106 - accuracy: 0.72 - ETA: 6s - loss: 1.0102 - accuracy: 0.72 - ETA: 5s - loss: 1.0107 - accuracy: 0.72 - ETA: 4s - loss: 1.0093 - accuracy: 0.72 - ETA: 3s - loss: 1.0097 - accuracy: 0.72 - ETA: 2s - loss: 1.0073 - accuracy: 0.72 - ETA: 0s - loss: 1.0062 - accuracy: 0.72 - 184s 10ms/step - loss: 1.0075 - accuracy: 0.7280 - val_loss: 1.4964 - val_accuracy: 0.7124\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:49 - loss: 0.8611 - accuracy: 0.78 - ETA: 2:46 - loss: 0.8532 - accuracy: 0.78 - ETA: 2:46 - loss: 0.9201 - accuracy: 0.76 - ETA: 2:47 - loss: 0.9324 - accuracy: 0.75 - ETA: 2:45 - loss: 0.9775 - accuracy: 0.74 - ETA: 2:44 - loss: 0.9774 - accuracy: 0.74 - ETA: 2:43 - loss: 0.9865 - accuracy: 0.74 - ETA: 2:44 - loss: 0.9664 - accuracy: 0.74 - ETA: 2:43 - loss: 1.0019 - accuracy: 0.74 - ETA: 2:41 - loss: 0.9581 - accuracy: 0.75 - ETA: 2:40 - loss: 0.9716 - accuracy: 0.75 - ETA: 2:38 - loss: 0.9754 - accuracy: 0.74 - ETA: 2:38 - loss: 0.9722 - accuracy: 0.74 - ETA: 2:36 - loss: 0.9785 - accuracy: 0.74 - ETA: 2:35 - loss: 0.9667 - accuracy: 0.74 - ETA: 2:34 - loss: 0.9618 - accuracy: 0.73 - ETA: 2:32 - loss: 0.9776 - accuracy: 0.73 - ETA: 2:32 - loss: 0.9691 - accuracy: 0.74 - ETA: 2:30 - loss: 0.9747 - accuracy: 0.74 - ETA: 2:29 - loss: 0.9799 - accuracy: 0.73 - ETA: 2:28 - loss: 0.9660 - accuracy: 0.74 - ETA: 2:28 - loss: 0.9627 - accuracy: 0.74 - ETA: 2:27 - loss: 0.9632 - accuracy: 0.74 - ETA: 2:26 - loss: 0.9652 - accuracy: 0.73 - ETA: 2:25 - loss: 0.9496 - accuracy: 0.74 - ETA: 2:24 - loss: 0.9519 - accuracy: 0.74 - ETA: 2:22 - loss: 0.9494 - accuracy: 0.74 - ETA: 2:21 - loss: 0.9454 - accuracy: 0.74 - ETA: 2:19 - loss: 0.9392 - accuracy: 0.74 - ETA: 2:18 - loss: 0.9294 - accuracy: 0.74 - ETA: 2:17 - loss: 0.9317 - accuracy: 0.74 - ETA: 2:16 - loss: 0.9283 - accuracy: 0.74 - ETA: 2:15 - loss: 0.9239 - accuracy: 0.74 - ETA: 2:14 - loss: 0.9266 - accuracy: 0.74 - ETA: 2:12 - loss: 0.9294 - accuracy: 0.74 - ETA: 2:12 - loss: 0.9290 - accuracy: 0.74 - ETA: 2:11 - loss: 0.9420 - accuracy: 0.74 - ETA: 2:10 - loss: 0.9487 - accuracy: 0.74 - ETA: 2:08 - loss: 0.9469 - accuracy: 0.74 - ETA: 2:07 - loss: 0.9455 - accuracy: 0.74 - ETA: 2:06 - loss: 0.9426 - accuracy: 0.74 - ETA: 2:05 - loss: 0.9452 - accuracy: 0.74 - ETA: 2:04 - loss: 0.9400 - accuracy: 0.74 - ETA: 2:03 - loss: 0.9434 - accuracy: 0.74 - ETA: 2:01 - loss: 0.9498 - accuracy: 0.73 - ETA: 2:00 - loss: 0.9539 - accuracy: 0.73 - ETA: 1:59 - loss: 0.9552 - accuracy: 0.73 - ETA: 1:58 - loss: 0.9557 - accuracy: 0.73 - ETA: 1:57 - loss: 0.9577 - accuracy: 0.73 - ETA: 1:56 - loss: 0.9547 - accuracy: 0.73 - ETA: 1:55 - loss: 0.9594 - accuracy: 0.73 - ETA: 1:53 - loss: 0.9751 - accuracy: 0.73 - ETA: 1:52 - loss: 0.9679 - accuracy: 0.73 - ETA: 1:51 - loss: 0.9644 - accuracy: 0.73 - ETA: 1:50 - loss: 0.9629 - accuracy: 0.73 - ETA: 1:49 - loss: 0.9619 - accuracy: 0.73 - ETA: 1:47 - loss: 0.9594 - accuracy: 0.73 - ETA: 1:46 - loss: 0.9637 - accuracy: 0.73 - ETA: 1:45 - loss: 0.9618 - accuracy: 0.73 - ETA: 1:44 - loss: 0.9626 - accuracy: 0.73 - ETA: 1:42 - loss: 0.9609 - accuracy: 0.73 - ETA: 1:41 - loss: 0.9646 - accuracy: 0.73 - ETA: 1:40 - loss: 0.9648 - accuracy: 0.73 - ETA: 1:39 - loss: 0.9608 - accuracy: 0.73 - ETA: 1:38 - loss: 0.9562 - accuracy: 0.73 - ETA: 1:37 - loss: 0.9548 - accuracy: 0.73 - ETA: 1:36 - loss: 0.9589 - accuracy: 0.73 - ETA: 1:35 - loss: 0.9633 - accuracy: 0.73 - ETA: 1:33 - loss: 0.9609 - accuracy: 0.73 - ETA: 1:32 - loss: 0.9594 - accuracy: 0.73 - ETA: 1:31 - loss: 0.9586 - accuracy: 0.73 - ETA: 1:30 - loss: 0.9582 - accuracy: 0.73 - ETA: 1:29 - loss: 0.9577 - accuracy: 0.73 - ETA: 1:28 - loss: 0.9578 - accuracy: 0.73 - ETA: 1:27 - loss: 0.9552 - accuracy: 0.73 - ETA: 1:26 - loss: 0.9566 - accuracy: 0.73 - ETA: 1:24 - loss: 0.9583 - accuracy: 0.73 - ETA: 1:23 - loss: 0.9640 - accuracy: 0.73 - ETA: 1:22 - loss: 0.9641 - accuracy: 0.73 - ETA: 1:21 - loss: 0.9622 - accuracy: 0.73 - ETA: 1:20 - loss: 0.9611 - accuracy: 0.73 - ETA: 1:19 - loss: 0.9600 - accuracy: 0.73 - ETA: 1:18 - loss: 0.9578 - accuracy: 0.73 - ETA: 1:17 - loss: 0.9603 - accuracy: 0.73 - ETA: 1:15 - loss: 0.9582 - accuracy: 0.73 - ETA: 1:14 - loss: 0.9565 - accuracy: 0.73 - ETA: 1:13 - loss: 0.9555 - accuracy: 0.73 - ETA: 1:12 - loss: 0.9544 - accuracy: 0.73 - ETA: 1:11 - loss: 0.9565 - accuracy: 0.73 - ETA: 1:09 - loss: 0.9545 - accuracy: 0.73 - ETA: 1:08 - loss: 0.9534 - accuracy: 0.73 - ETA: 1:07 - loss: 0.9531 - accuracy: 0.73 - ETA: 1:06 - loss: 0.9531 - accuracy: 0.73 - ETA: 1:05 - loss: 0.9524 - accuracy: 0.73 - ETA: 1:04 - loss: 0.9519 - accuracy: 0.73 - ETA: 1:03 - loss: 0.9498 - accuracy: 0.73 - ETA: 1:01 - loss: 0.9507 - accuracy: 0.73 - ETA: 1:00 - loss: 0.9513 - accuracy: 0.73 - ETA: 59s - loss: 0.9515 - accuracy: 0.7362 - ETA: 58s - loss: 0.9501 - accuracy: 0.736 - ETA: 57s - loss: 0.9494 - accuracy: 0.736 - ETA: 56s - loss: 0.9502 - accuracy: 0.736 - ETA: 54s - loss: 0.9529 - accuracy: 0.735 - ETA: 53s - loss: 0.9543 - accuracy: 0.735 - ETA: 52s - loss: 0.9528 - accuracy: 0.735 - ETA: 51s - loss: 0.9537 - accuracy: 0.735 - ETA: 50s - loss: 0.9551 - accuracy: 0.735 - ETA: 49s - loss: 0.9556 - accuracy: 0.734 - ETA: 48s - loss: 0.9550 - accuracy: 0.734 - ETA: 47s - loss: 0.9548 - accuracy: 0.734 - ETA: 45s - loss: 0.9566 - accuracy: 0.734 - ETA: 44s - loss: 0.9561 - accuracy: 0.734 - ETA: 43s - loss: 0.9566 - accuracy: 0.734 - ETA: 42s - loss: 0.9581 - accuracy: 0.733 - ETA: 41s - loss: 0.9562 - accuracy: 0.733 - ETA: 40s - loss: 0.9533 - accuracy: 0.734 - ETA: 38s - loss: 0.9541 - accuracy: 0.734 - ETA: 37s - loss: 0.9578 - accuracy: 0.733 - ETA: 36s - loss: 0.9573 - accuracy: 0.733 - ETA: 35s - loss: 0.9584 - accuracy: 0.733 - ETA: 34s - loss: 0.9575 - accuracy: 0.734 - ETA: 33s - loss: 0.9561 - accuracy: 0.734 - ETA: 32s - loss: 0.9558 - accuracy: 0.734 - ETA: 30s - loss: 0.9560 - accuracy: 0.734 - ETA: 29s - loss: 0.9539 - accuracy: 0.735 - ETA: 28s - loss: 0.9523 - accuracy: 0.735 - ETA: 27s - loss: 0.9547 - accuracy: 0.735 - ETA: 26s - loss: 0.9564 - accuracy: 0.735 - ETA: 25s - loss: 0.9553 - accuracy: 0.735 - ETA: 23s - loss: 0.9552 - accuracy: 0.735 - ETA: 22s - loss: 0.9552 - accuracy: 0.735 - ETA: 21s - loss: 0.9571 - accuracy: 0.734 - ETA: 20s - loss: 0.9567 - accuracy: 0.734 - ETA: 19s - loss: 0.9607 - accuracy: 0.734 - ETA: 18s - loss: 0.9604 - accuracy: 0.734 - ETA: 17s - loss: 0.9607 - accuracy: 0.734 - ETA: 15s - loss: 0.9620 - accuracy: 0.734 - ETA: 14s - loss: 0.9636 - accuracy: 0.734 - ETA: 13s - loss: 0.9669 - accuracy: 0.733 - ETA: 12s - loss: 0.9671 - accuracy: 0.734 - ETA: 11s - loss: 0.9666 - accuracy: 0.734 - ETA: 10s - loss: 0.9654 - accuracy: 0.734 - ETA: 9s - loss: 0.9653 - accuracy: 0.734 - ETA: 7s - loss: 0.9659 - accuracy: 0.73 - ETA: 6s - loss: 0.9676 - accuracy: 0.73 - ETA: 5s - loss: 0.9689 - accuracy: 0.73 - ETA: 4s - loss: 0.9692 - accuracy: 0.73 - ETA: 3s - loss: 0.9701 - accuracy: 0.73 - ETA: 2s - loss: 0.9695 - accuracy: 0.73 - ETA: 1s - loss: 0.9701 - accuracy: 0.73 - 185s 10ms/step - loss: 0.9715 - accuracy: 0.7334 - val_loss: 1.4816 - val_accuracy: 0.7146\n",
      "Epoch 24/100\n",
      "19312/19312 [==============================] - ETA: 3:11 - loss: 1.5967 - accuracy: 0.64 - ETA: 3:03 - loss: 1.3794 - accuracy: 0.67 - ETA: 2:56 - loss: 1.2096 - accuracy: 0.70 - ETA: 2:52 - loss: 1.1219 - accuracy: 0.70 - ETA: 2:50 - loss: 1.1295 - accuracy: 0.70 - ETA: 2:46 - loss: 1.0986 - accuracy: 0.70 - ETA: 2:45 - loss: 1.0979 - accuracy: 0.70 - ETA: 2:43 - loss: 1.0577 - accuracy: 0.70 - ETA: 2:43 - loss: 1.0755 - accuracy: 0.70 - ETA: 2:42 - loss: 1.0829 - accuracy: 0.70 - ETA: 2:40 - loss: 1.0636 - accuracy: 0.70 - ETA: 2:38 - loss: 1.0902 - accuracy: 0.70 - ETA: 2:37 - loss: 1.0629 - accuracy: 0.71 - ETA: 2:37 - loss: 1.0593 - accuracy: 0.71 - ETA: 2:36 - loss: 1.0608 - accuracy: 0.71 - ETA: 2:34 - loss: 1.0501 - accuracy: 0.71 - ETA: 2:33 - loss: 1.0518 - accuracy: 0.71 - ETA: 2:32 - loss: 1.0414 - accuracy: 0.71 - ETA: 2:30 - loss: 1.0388 - accuracy: 0.72 - ETA: 2:29 - loss: 1.0301 - accuracy: 0.72 - ETA: 2:28 - loss: 1.0176 - accuracy: 0.72 - ETA: 2:27 - loss: 1.0204 - accuracy: 0.72 - ETA: 2:25 - loss: 1.0135 - accuracy: 0.72 - ETA: 2:24 - loss: 1.0087 - accuracy: 0.72 - ETA: 2:23 - loss: 1.0199 - accuracy: 0.72 - ETA: 2:22 - loss: 1.0174 - accuracy: 0.72 - ETA: 2:20 - loss: 1.0270 - accuracy: 0.72 - ETA: 2:19 - loss: 1.0328 - accuracy: 0.72 - ETA: 2:19 - loss: 1.0355 - accuracy: 0.72 - ETA: 2:17 - loss: 1.0337 - accuracy: 0.71 - ETA: 2:16 - loss: 1.0208 - accuracy: 0.72 - ETA: 2:15 - loss: 1.0149 - accuracy: 0.72 - ETA: 2:14 - loss: 1.0058 - accuracy: 0.72 - ETA: 2:12 - loss: 1.0109 - accuracy: 0.72 - ETA: 2:11 - loss: 1.0149 - accuracy: 0.72 - ETA: 2:10 - loss: 1.0090 - accuracy: 0.72 - ETA: 2:09 - loss: 1.0046 - accuracy: 0.72 - ETA: 2:08 - loss: 1.0109 - accuracy: 0.72 - ETA: 2:07 - loss: 1.0120 - accuracy: 0.72 - ETA: 2:06 - loss: 1.0180 - accuracy: 0.72 - ETA: 2:05 - loss: 1.0208 - accuracy: 0.72 - ETA: 2:03 - loss: 1.0244 - accuracy: 0.72 - ETA: 2:03 - loss: 1.0205 - accuracy: 0.72 - ETA: 2:01 - loss: 1.0185 - accuracy: 0.72 - ETA: 2:00 - loss: 1.0136 - accuracy: 0.72 - ETA: 1:59 - loss: 1.0149 - accuracy: 0.72 - ETA: 1:58 - loss: 1.0153 - accuracy: 0.72 - ETA: 1:57 - loss: 1.0159 - accuracy: 0.72 - ETA: 1:55 - loss: 1.0117 - accuracy: 0.72 - ETA: 1:54 - loss: 1.0099 - accuracy: 0.72 - ETA: 1:53 - loss: 1.0080 - accuracy: 0.72 - ETA: 1:52 - loss: 1.0129 - accuracy: 0.72 - ETA: 1:51 - loss: 1.0082 - accuracy: 0.72 - ETA: 1:49 - loss: 1.0065 - accuracy: 0.72 - ETA: 1:48 - loss: 0.9987 - accuracy: 0.72 - ETA: 1:47 - loss: 0.9966 - accuracy: 0.72 - ETA: 1:46 - loss: 0.9975 - accuracy: 0.72 - ETA: 1:45 - loss: 0.9949 - accuracy: 0.72 - ETA: 1:44 - loss: 0.9987 - accuracy: 0.72 - ETA: 1:43 - loss: 0.9977 - accuracy: 0.72 - ETA: 1:42 - loss: 0.9958 - accuracy: 0.72 - ETA: 1:41 - loss: 0.9949 - accuracy: 0.72 - ETA: 1:40 - loss: 0.9953 - accuracy: 0.72 - ETA: 1:38 - loss: 0.9941 - accuracy: 0.72 - ETA: 1:37 - loss: 0.9885 - accuracy: 0.73 - ETA: 1:36 - loss: 0.9886 - accuracy: 0.73 - ETA: 1:35 - loss: 0.9869 - accuracy: 0.73 - ETA: 1:34 - loss: 0.9823 - accuracy: 0.73 - ETA: 1:33 - loss: 0.9832 - accuracy: 0.73 - ETA: 1:31 - loss: 0.9824 - accuracy: 0.73 - ETA: 1:30 - loss: 0.9803 - accuracy: 0.73 - ETA: 1:29 - loss: 0.9833 - accuracy: 0.73 - ETA: 1:28 - loss: 0.9840 - accuracy: 0.73 - ETA: 1:27 - loss: 0.9872 - accuracy: 0.73 - ETA: 1:26 - loss: 0.9864 - accuracy: 0.73 - ETA: 1:25 - loss: 0.9851 - accuracy: 0.73 - ETA: 1:24 - loss: 0.9849 - accuracy: 0.73 - ETA: 1:22 - loss: 0.9838 - accuracy: 0.73 - ETA: 1:21 - loss: 0.9825 - accuracy: 0.73 - ETA: 1:20 - loss: 0.9844 - accuracy: 0.73 - ETA: 1:19 - loss: 0.9832 - accuracy: 0.73 - ETA: 1:18 - loss: 0.9817 - accuracy: 0.73 - ETA: 1:17 - loss: 0.9832 - accuracy: 0.73 - ETA: 1:15 - loss: 0.9815 - accuracy: 0.73 - ETA: 1:14 - loss: 0.9779 - accuracy: 0.73 - ETA: 1:13 - loss: 0.9781 - accuracy: 0.73 - ETA: 1:12 - loss: 0.9765 - accuracy: 0.73 - ETA: 1:11 - loss: 0.9724 - accuracy: 0.73 - ETA: 1:10 - loss: 0.9706 - accuracy: 0.73 - ETA: 1:09 - loss: 0.9715 - accuracy: 0.73 - ETA: 1:08 - loss: 0.9688 - accuracy: 0.73 - ETA: 1:06 - loss: 0.9697 - accuracy: 0.73 - ETA: 1:05 - loss: 0.9689 - accuracy: 0.73 - ETA: 1:04 - loss: 0.9686 - accuracy: 0.73 - ETA: 1:03 - loss: 0.9697 - accuracy: 0.73 - ETA: 1:02 - loss: 0.9707 - accuracy: 0.73 - ETA: 1:01 - loss: 0.9735 - accuracy: 0.73 - ETA: 1:00 - loss: 0.9724 - accuracy: 0.73 - ETA: 58s - loss: 0.9756 - accuracy: 0.7314 - ETA: 57s - loss: 0.9726 - accuracy: 0.732 - ETA: 56s - loss: 0.9730 - accuracy: 0.732 - ETA: 55s - loss: 0.9727 - accuracy: 0.731 - ETA: 54s - loss: 0.9707 - accuracy: 0.732 - ETA: 53s - loss: 0.9699 - accuracy: 0.732 - ETA: 52s - loss: 0.9693 - accuracy: 0.732 - ETA: 51s - loss: 0.9684 - accuracy: 0.732 - ETA: 49s - loss: 0.9679 - accuracy: 0.733 - ETA: 48s - loss: 0.9699 - accuracy: 0.733 - ETA: 47s - loss: 0.9682 - accuracy: 0.733 - ETA: 46s - loss: 0.9710 - accuracy: 0.732 - ETA: 45s - loss: 0.9719 - accuracy: 0.732 - ETA: 44s - loss: 0.9714 - accuracy: 0.733 - ETA: 43s - loss: 0.9700 - accuracy: 0.733 - ETA: 42s - loss: 0.9672 - accuracy: 0.733 - ETA: 40s - loss: 0.9683 - accuracy: 0.733 - ETA: 39s - loss: 0.9682 - accuracy: 0.733 - ETA: 38s - loss: 0.9699 - accuracy: 0.733 - ETA: 37s - loss: 0.9706 - accuracy: 0.733 - ETA: 36s - loss: 0.9692 - accuracy: 0.733 - ETA: 35s - loss: 0.9721 - accuracy: 0.732 - ETA: 34s - loss: 0.9743 - accuracy: 0.732 - ETA: 32s - loss: 0.9725 - accuracy: 0.732 - ETA: 31s - loss: 0.9749 - accuracy: 0.732 - ETA: 30s - loss: 0.9748 - accuracy: 0.732 - ETA: 29s - loss: 0.9748 - accuracy: 0.732 - ETA: 28s - loss: 0.9751 - accuracy: 0.732 - ETA: 27s - loss: 0.9773 - accuracy: 0.732 - ETA: 26s - loss: 0.9778 - accuracy: 0.732 - ETA: 24s - loss: 0.9764 - accuracy: 0.732 - ETA: 23s - loss: 0.9767 - accuracy: 0.732 - ETA: 22s - loss: 0.9775 - accuracy: 0.732 - ETA: 21s - loss: 0.9775 - accuracy: 0.731 - ETA: 20s - loss: 0.9769 - accuracy: 0.732 - ETA: 19s - loss: 0.9780 - accuracy: 0.732 - ETA: 18s - loss: 0.9804 - accuracy: 0.732 - ETA: 16s - loss: 0.9794 - accuracy: 0.732 - ETA: 15s - loss: 0.9768 - accuracy: 0.732 - ETA: 14s - loss: 0.9802 - accuracy: 0.732 - ETA: 13s - loss: 0.9793 - accuracy: 0.732 - ETA: 12s - loss: 0.9807 - accuracy: 0.731 - ETA: 11s - loss: 0.9780 - accuracy: 0.732 - ETA: 10s - loss: 0.9782 - accuracy: 0.731 - ETA: 8s - loss: 0.9777 - accuracy: 0.732 - ETA: 7s - loss: 0.9767 - accuracy: 0.73 - ETA: 6s - loss: 0.9746 - accuracy: 0.73 - ETA: 5s - loss: 0.9735 - accuracy: 0.73 - ETA: 4s - loss: 0.9733 - accuracy: 0.73 - ETA: 3s - loss: 0.9736 - accuracy: 0.73 - ETA: 2s - loss: 0.9718 - accuracy: 0.73 - ETA: 0s - loss: 0.9714 - accuracy: 0.73 - 184s 10ms/step - loss: 0.9722 - accuracy: 0.7335 - val_loss: 1.4498 - val_accuracy: 0.7122\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:52 - loss: 0.8436 - accuracy: 0.71 - ETA: 2:48 - loss: 0.9414 - accuracy: 0.69 - ETA: 2:45 - loss: 0.8669 - accuracy: 0.72 - ETA: 2:42 - loss: 0.9367 - accuracy: 0.72 - ETA: 2:41 - loss: 0.9223 - accuracy: 0.72 - ETA: 2:42 - loss: 0.8858 - accuracy: 0.73 - ETA: 2:43 - loss: 0.9065 - accuracy: 0.72 - ETA: 2:44 - loss: 0.9259 - accuracy: 0.72 - ETA: 2:43 - loss: 0.9641 - accuracy: 0.72 - ETA: 2:41 - loss: 0.9502 - accuracy: 0.72 - ETA: 2:40 - loss: 0.9392 - accuracy: 0.72 - ETA: 2:38 - loss: 0.9383 - accuracy: 0.72 - ETA: 2:38 - loss: 0.9312 - accuracy: 0.72 - ETA: 2:37 - loss: 0.9404 - accuracy: 0.72 - ETA: 2:36 - loss: 0.9276 - accuracy: 0.72 - ETA: 2:35 - loss: 0.9389 - accuracy: 0.72 - ETA: 2:33 - loss: 0.9236 - accuracy: 0.72 - ETA: 2:32 - loss: 0.9303 - accuracy: 0.72 - ETA: 2:30 - loss: 0.9400 - accuracy: 0.72 - ETA: 2:29 - loss: 0.9416 - accuracy: 0.72 - ETA: 2:28 - loss: 0.9502 - accuracy: 0.72 - ETA: 2:27 - loss: 0.9538 - accuracy: 0.72 - ETA: 2:26 - loss: 0.9628 - accuracy: 0.72 - ETA: 2:24 - loss: 0.9779 - accuracy: 0.72 - ETA: 2:23 - loss: 0.9744 - accuracy: 0.72 - ETA: 2:22 - loss: 0.9688 - accuracy: 0.72 - ETA: 2:21 - loss: 0.9681 - accuracy: 0.72 - ETA: 2:20 - loss: 0.9649 - accuracy: 0.72 - ETA: 2:19 - loss: 0.9645 - accuracy: 0.72 - ETA: 2:18 - loss: 0.9630 - accuracy: 0.72 - ETA: 2:16 - loss: 0.9572 - accuracy: 0.73 - ETA: 2:15 - loss: 0.9544 - accuracy: 0.73 - ETA: 2:14 - loss: 0.9538 - accuracy: 0.73 - ETA: 2:13 - loss: 0.9591 - accuracy: 0.73 - ETA: 2:12 - loss: 0.9601 - accuracy: 0.73 - ETA: 2:11 - loss: 0.9498 - accuracy: 0.73 - ETA: 2:10 - loss: 0.9515 - accuracy: 0.73 - ETA: 2:09 - loss: 0.9524 - accuracy: 0.73 - ETA: 2:07 - loss: 0.9550 - accuracy: 0.73 - ETA: 2:06 - loss: 0.9555 - accuracy: 0.73 - ETA: 2:05 - loss: 0.9620 - accuracy: 0.73 - ETA: 2:04 - loss: 0.9733 - accuracy: 0.73 - ETA: 2:03 - loss: 0.9687 - accuracy: 0.73 - ETA: 2:01 - loss: 0.9784 - accuracy: 0.73 - ETA: 2:00 - loss: 0.9796 - accuracy: 0.73 - ETA: 1:59 - loss: 0.9793 - accuracy: 0.73 - ETA: 1:58 - loss: 0.9791 - accuracy: 0.72 - ETA: 1:57 - loss: 0.9799 - accuracy: 0.72 - ETA: 1:55 - loss: 0.9748 - accuracy: 0.72 - ETA: 1:54 - loss: 0.9765 - accuracy: 0.72 - ETA: 1:53 - loss: 0.9770 - accuracy: 0.72 - ETA: 1:52 - loss: 0.9804 - accuracy: 0.73 - ETA: 1:51 - loss: 0.9869 - accuracy: 0.72 - ETA: 1:50 - loss: 0.9926 - accuracy: 0.72 - ETA: 1:49 - loss: 0.9963 - accuracy: 0.72 - ETA: 1:47 - loss: 0.9962 - accuracy: 0.72 - ETA: 1:46 - loss: 0.9974 - accuracy: 0.72 - ETA: 1:45 - loss: 0.9967 - accuracy: 0.72 - ETA: 1:44 - loss: 0.9946 - accuracy: 0.72 - ETA: 1:43 - loss: 0.9928 - accuracy: 0.72 - ETA: 1:42 - loss: 0.9945 - accuracy: 0.72 - ETA: 1:41 - loss: 0.9986 - accuracy: 0.72 - ETA: 1:39 - loss: 0.9955 - accuracy: 0.72 - ETA: 1:38 - loss: 0.9946 - accuracy: 0.72 - ETA: 1:37 - loss: 0.9947 - accuracy: 0.72 - ETA: 1:36 - loss: 0.9950 - accuracy: 0.72 - ETA: 1:35 - loss: 0.9927 - accuracy: 0.72 - ETA: 1:34 - loss: 0.9869 - accuracy: 0.73 - ETA: 1:33 - loss: 0.9876 - accuracy: 0.73 - ETA: 1:32 - loss: 0.9864 - accuracy: 0.73 - ETA: 1:31 - loss: 0.9827 - accuracy: 0.73 - ETA: 1:29 - loss: 0.9838 - accuracy: 0.73 - ETA: 1:28 - loss: 0.9827 - accuracy: 0.73 - ETA: 1:27 - loss: 0.9818 - accuracy: 0.73 - ETA: 1:26 - loss: 0.9807 - accuracy: 0.73 - ETA: 1:25 - loss: 0.9839 - accuracy: 0.73 - ETA: 1:24 - loss: 0.9835 - accuracy: 0.73 - ETA: 1:23 - loss: 0.9831 - accuracy: 0.73 - ETA: 1:21 - loss: 0.9815 - accuracy: 0.73 - ETA: 1:20 - loss: 0.9802 - accuracy: 0.73 - ETA: 1:19 - loss: 0.9784 - accuracy: 0.73 - ETA: 1:18 - loss: 0.9753 - accuracy: 0.73 - ETA: 1:17 - loss: 0.9740 - accuracy: 0.73 - ETA: 1:16 - loss: 0.9707 - accuracy: 0.73 - ETA: 1:15 - loss: 0.9711 - accuracy: 0.73 - ETA: 1:14 - loss: 0.9771 - accuracy: 0.73 - ETA: 1:12 - loss: 0.9736 - accuracy: 0.73 - ETA: 1:11 - loss: 0.9716 - accuracy: 0.73 - ETA: 1:10 - loss: 0.9713 - accuracy: 0.73 - ETA: 1:09 - loss: 0.9679 - accuracy: 0.73 - ETA: 1:08 - loss: 0.9711 - accuracy: 0.73 - ETA: 1:07 - loss: 0.9706 - accuracy: 0.73 - ETA: 1:06 - loss: 0.9678 - accuracy: 0.73 - ETA: 1:05 - loss: 0.9686 - accuracy: 0.73 - ETA: 1:03 - loss: 0.9702 - accuracy: 0.73 - ETA: 1:02 - loss: 0.9708 - accuracy: 0.73 - ETA: 1:01 - loss: 0.9718 - accuracy: 0.73 - ETA: 1:00 - loss: 0.9740 - accuracy: 0.73 - ETA: 59s - loss: 0.9720 - accuracy: 0.7322 - ETA: 58s - loss: 0.9681 - accuracy: 0.733 - ETA: 56s - loss: 0.9657 - accuracy: 0.733 - ETA: 55s - loss: 0.9622 - accuracy: 0.734 - ETA: 54s - loss: 0.9601 - accuracy: 0.734 - ETA: 53s - loss: 0.9599 - accuracy: 0.733 - ETA: 52s - loss: 0.9597 - accuracy: 0.734 - ETA: 51s - loss: 0.9598 - accuracy: 0.734 - ETA: 50s - loss: 0.9605 - accuracy: 0.734 - ETA: 48s - loss: 0.9590 - accuracy: 0.734 - ETA: 47s - loss: 0.9585 - accuracy: 0.734 - ETA: 46s - loss: 0.9584 - accuracy: 0.734 - ETA: 45s - loss: 0.9571 - accuracy: 0.734 - ETA: 44s - loss: 0.9580 - accuracy: 0.734 - ETA: 43s - loss: 0.9559 - accuracy: 0.735 - ETA: 42s - loss: 0.9552 - accuracy: 0.734 - ETA: 40s - loss: 0.9560 - accuracy: 0.734 - ETA: 39s - loss: 0.9530 - accuracy: 0.735 - ETA: 38s - loss: 0.9525 - accuracy: 0.735 - ETA: 37s - loss: 0.9548 - accuracy: 0.735 - ETA: 36s - loss: 0.9560 - accuracy: 0.734 - ETA: 35s - loss: 0.9549 - accuracy: 0.734 - ETA: 34s - loss: 0.9527 - accuracy: 0.735 - ETA: 32s - loss: 0.9512 - accuracy: 0.735 - ETA: 31s - loss: 0.9499 - accuracy: 0.735 - ETA: 30s - loss: 0.9522 - accuracy: 0.735 - ETA: 29s - loss: 0.9523 - accuracy: 0.734 - ETA: 28s - loss: 0.9529 - accuracy: 0.734 - ETA: 27s - loss: 0.9541 - accuracy: 0.734 - ETA: 26s - loss: 0.9530 - accuracy: 0.734 - ETA: 24s - loss: 0.9590 - accuracy: 0.734 - ETA: 23s - loss: 0.9583 - accuracy: 0.734 - ETA: 22s - loss: 0.9585 - accuracy: 0.734 - ETA: 21s - loss: 0.9571 - accuracy: 0.734 - ETA: 20s - loss: 0.9561 - accuracy: 0.734 - ETA: 19s - loss: 0.9580 - accuracy: 0.734 - ETA: 18s - loss: 0.9550 - accuracy: 0.735 - ETA: 16s - loss: 0.9547 - accuracy: 0.735 - ETA: 15s - loss: 0.9558 - accuracy: 0.735 - ETA: 14s - loss: 0.9549 - accuracy: 0.735 - ETA: 13s - loss: 0.9563 - accuracy: 0.734 - ETA: 12s - loss: 0.9553 - accuracy: 0.735 - ETA: 11s - loss: 0.9551 - accuracy: 0.735 - ETA: 10s - loss: 0.9530 - accuracy: 0.735 - ETA: 8s - loss: 0.9543 - accuracy: 0.735 - ETA: 7s - loss: 0.9528 - accuracy: 0.73 - ETA: 6s - loss: 0.9543 - accuracy: 0.73 - ETA: 5s - loss: 0.9514 - accuracy: 0.73 - ETA: 4s - loss: 0.9523 - accuracy: 0.73 - ETA: 3s - loss: 0.9511 - accuracy: 0.73 - ETA: 2s - loss: 0.9511 - accuracy: 0.73 - ETA: 0s - loss: 0.9512 - accuracy: 0.73 - 184s 10ms/step - loss: 0.9503 - accuracy: 0.7371 - val_loss: 1.4799 - val_accuracy: 0.7167\n",
      "Epoch 26/100\n",
      "19312/19312 [==============================] - ETA: 2:48 - loss: 0.7712 - accuracy: 0.80 - ETA: 2:49 - loss: 0.8939 - accuracy: 0.77 - ETA: 2:46 - loss: 0.9316 - accuracy: 0.75 - ETA: 2:46 - loss: 0.8967 - accuracy: 0.76 - ETA: 2:45 - loss: 0.8866 - accuracy: 0.76 - ETA: 2:42 - loss: 0.9776 - accuracy: 0.75 - ETA: 2:42 - loss: 0.9859 - accuracy: 0.74 - ETA: 2:42 - loss: 0.9791 - accuracy: 0.74 - ETA: 2:39 - loss: 0.9723 - accuracy: 0.74 - ETA: 2:38 - loss: 0.9375 - accuracy: 0.75 - ETA: 2:38 - loss: 0.9623 - accuracy: 0.74 - ETA: 2:37 - loss: 0.9512 - accuracy: 0.74 - ETA: 2:36 - loss: 0.9581 - accuracy: 0.74 - ETA: 2:36 - loss: 0.9520 - accuracy: 0.74 - ETA: 2:35 - loss: 0.9774 - accuracy: 0.74 - ETA: 2:34 - loss: 0.9785 - accuracy: 0.73 - ETA: 2:34 - loss: 0.9694 - accuracy: 0.74 - ETA: 2:32 - loss: 0.9539 - accuracy: 0.74 - ETA: 2:31 - loss: 0.9553 - accuracy: 0.74 - ETA: 2:31 - loss: 0.9640 - accuracy: 0.74 - ETA: 2:30 - loss: 0.9673 - accuracy: 0.73 - ETA: 2:29 - loss: 0.9760 - accuracy: 0.73 - ETA: 2:28 - loss: 0.9656 - accuracy: 0.73 - ETA: 2:27 - loss: 0.9494 - accuracy: 0.74 - ETA: 2:26 - loss: 0.9566 - accuracy: 0.73 - ETA: 2:25 - loss: 0.9596 - accuracy: 0.73 - ETA: 2:24 - loss: 0.9539 - accuracy: 0.73 - ETA: 2:23 - loss: 0.9582 - accuracy: 0.74 - ETA: 2:22 - loss: 0.9477 - accuracy: 0.74 - ETA: 2:21 - loss: 0.9580 - accuracy: 0.73 - ETA: 2:19 - loss: 0.9643 - accuracy: 0.73 - ETA: 2:18 - loss: 0.9692 - accuracy: 0.73 - ETA: 2:17 - loss: 0.9659 - accuracy: 0.73 - ETA: 2:15 - loss: 0.9613 - accuracy: 0.73 - ETA: 2:14 - loss: 0.9624 - accuracy: 0.73 - ETA: 2:13 - loss: 0.9641 - accuracy: 0.73 - ETA: 2:12 - loss: 0.9633 - accuracy: 0.73 - ETA: 2:11 - loss: 0.9601 - accuracy: 0.73 - ETA: 2:09 - loss: 0.9657 - accuracy: 0.73 - ETA: 2:08 - loss: 0.9660 - accuracy: 0.73 - ETA: 2:08 - loss: 0.9686 - accuracy: 0.73 - ETA: 2:06 - loss: 0.9635 - accuracy: 0.73 - ETA: 2:05 - loss: 0.9617 - accuracy: 0.73 - ETA: 2:04 - loss: 0.9601 - accuracy: 0.73 - ETA: 2:03 - loss: 0.9544 - accuracy: 0.73 - ETA: 2:02 - loss: 0.9557 - accuracy: 0.73 - ETA: 2:00 - loss: 0.9524 - accuracy: 0.73 - ETA: 1:59 - loss: 0.9443 - accuracy: 0.73 - ETA: 1:58 - loss: 0.9368 - accuracy: 0.73 - ETA: 1:57 - loss: 0.9359 - accuracy: 0.74 - ETA: 1:56 - loss: 0.9295 - accuracy: 0.74 - ETA: 1:55 - loss: 0.9317 - accuracy: 0.74 - ETA: 1:53 - loss: 0.9339 - accuracy: 0.73 - ETA: 1:52 - loss: 0.9306 - accuracy: 0.74 - ETA: 1:51 - loss: 0.9347 - accuracy: 0.74 - ETA: 1:50 - loss: 0.9328 - accuracy: 0.74 - ETA: 1:49 - loss: 0.9354 - accuracy: 0.73 - ETA: 1:48 - loss: 0.9380 - accuracy: 0.73 - ETA: 1:47 - loss: 0.9402 - accuracy: 0.73 - ETA: 1:45 - loss: 0.9369 - accuracy: 0.73 - ETA: 1:44 - loss: 0.9395 - accuracy: 0.73 - ETA: 1:43 - loss: 0.9356 - accuracy: 0.73 - ETA: 1:42 - loss: 0.9402 - accuracy: 0.73 - ETA: 1:41 - loss: 0.9484 - accuracy: 0.73 - ETA: 1:39 - loss: 0.9484 - accuracy: 0.73 - ETA: 1:38 - loss: 0.9530 - accuracy: 0.73 - ETA: 1:37 - loss: 0.9507 - accuracy: 0.73 - ETA: 1:36 - loss: 0.9499 - accuracy: 0.73 - ETA: 1:35 - loss: 0.9529 - accuracy: 0.73 - ETA: 1:34 - loss: 0.9531 - accuracy: 0.73 - ETA: 1:32 - loss: 0.9553 - accuracy: 0.73 - ETA: 1:31 - loss: 0.9517 - accuracy: 0.73 - ETA: 1:30 - loss: 0.9519 - accuracy: 0.74 - ETA: 1:29 - loss: 0.9557 - accuracy: 0.73 - ETA: 1:28 - loss: 0.9552 - accuracy: 0.73 - ETA: 1:27 - loss: 0.9536 - accuracy: 0.73 - ETA: 1:25 - loss: 0.9496 - accuracy: 0.74 - ETA: 1:24 - loss: 0.9540 - accuracy: 0.74 - ETA: 1:23 - loss: 0.9529 - accuracy: 0.74 - ETA: 1:22 - loss: 0.9541 - accuracy: 0.74 - ETA: 1:21 - loss: 0.9522 - accuracy: 0.74 - ETA: 1:20 - loss: 0.9512 - accuracy: 0.74 - ETA: 1:19 - loss: 0.9498 - accuracy: 0.74 - ETA: 1:17 - loss: 0.9478 - accuracy: 0.74 - ETA: 1:16 - loss: 0.9449 - accuracy: 0.74 - ETA: 1:15 - loss: 0.9444 - accuracy: 0.74 - ETA: 1:14 - loss: 0.9438 - accuracy: 0.74 - ETA: 1:13 - loss: 0.9446 - accuracy: 0.74 - ETA: 1:12 - loss: 0.9422 - accuracy: 0.74 - ETA: 1:11 - loss: 0.9427 - accuracy: 0.74 - ETA: 1:09 - loss: 0.9414 - accuracy: 0.74 - ETA: 1:08 - loss: 0.9403 - accuracy: 0.74 - ETA: 1:07 - loss: 0.9393 - accuracy: 0.74 - ETA: 1:06 - loss: 0.9393 - accuracy: 0.74 - ETA: 1:05 - loss: 0.9388 - accuracy: 0.74 - ETA: 1:04 - loss: 0.9402 - accuracy: 0.74 - ETA: 1:02 - loss: 0.9389 - accuracy: 0.74 - ETA: 1:01 - loss: 0.9385 - accuracy: 0.74 - ETA: 1:00 - loss: 0.9396 - accuracy: 0.74 - ETA: 59s - loss: 0.9396 - accuracy: 0.7409 - ETA: 58s - loss: 0.9367 - accuracy: 0.741 - ETA: 56s - loss: 0.9437 - accuracy: 0.740 - ETA: 55s - loss: 0.9440 - accuracy: 0.740 - ETA: 54s - loss: 0.9413 - accuracy: 0.740 - ETA: 53s - loss: 0.9453 - accuracy: 0.740 - ETA: 52s - loss: 0.9445 - accuracy: 0.740 - ETA: 51s - loss: 0.9448 - accuracy: 0.739 - ETA: 49s - loss: 0.9484 - accuracy: 0.739 - ETA: 48s - loss: 0.9507 - accuracy: 0.739 - ETA: 47s - loss: 0.9532 - accuracy: 0.738 - ETA: 46s - loss: 0.9560 - accuracy: 0.738 - ETA: 45s - loss: 0.9579 - accuracy: 0.737 - ETA: 44s - loss: 0.9558 - accuracy: 0.738 - ETA: 42s - loss: 0.9572 - accuracy: 0.737 - ETA: 41s - loss: 0.9562 - accuracy: 0.738 - ETA: 40s - loss: 0.9548 - accuracy: 0.738 - ETA: 39s - loss: 0.9540 - accuracy: 0.738 - ETA: 38s - loss: 0.9515 - accuracy: 0.739 - ETA: 37s - loss: 0.9520 - accuracy: 0.739 - ETA: 35s - loss: 0.9517 - accuracy: 0.739 - ETA: 34s - loss: 0.9530 - accuracy: 0.739 - ETA: 33s - loss: 0.9529 - accuracy: 0.739 - ETA: 32s - loss: 0.9525 - accuracy: 0.739 - ETA: 31s - loss: 0.9519 - accuracy: 0.739 - ETA: 30s - loss: 0.9521 - accuracy: 0.739 - ETA: 28s - loss: 0.9531 - accuracy: 0.739 - ETA: 27s - loss: 0.9532 - accuracy: 0.739 - ETA: 26s - loss: 0.9505 - accuracy: 0.740 - ETA: 25s - loss: 0.9509 - accuracy: 0.740 - ETA: 24s - loss: 0.9520 - accuracy: 0.740 - ETA: 23s - loss: 0.9500 - accuracy: 0.740 - ETA: 21s - loss: 0.9508 - accuracy: 0.740 - ETA: 20s - loss: 0.9522 - accuracy: 0.740 - ETA: 19s - loss: 0.9522 - accuracy: 0.739 - ETA: 18s - loss: 0.9521 - accuracy: 0.739 - ETA: 17s - loss: 0.9539 - accuracy: 0.739 - ETA: 16s - loss: 0.9526 - accuracy: 0.739 - ETA: 14s - loss: 0.9516 - accuracy: 0.739 - ETA: 13s - loss: 0.9530 - accuracy: 0.739 - ETA: 12s - loss: 0.9521 - accuracy: 0.739 - ETA: 11s - loss: 0.9508 - accuracy: 0.739 - ETA: 10s - loss: 0.9506 - accuracy: 0.739 - ETA: 9s - loss: 0.9502 - accuracy: 0.739 - ETA: 7s - loss: 0.9515 - accuracy: 0.73 - ETA: 6s - loss: 0.9501 - accuracy: 0.74 - ETA: 5s - loss: 0.9508 - accuracy: 0.73 - ETA: 4s - loss: 0.9500 - accuracy: 0.73 - ETA: 3s - loss: 0.9479 - accuracy: 0.74 - ETA: 2s - loss: 0.9470 - accuracy: 0.74 - ETA: 1s - loss: 0.9439 - accuracy: 0.74 - 187s 10ms/step - loss: 0.9451 - accuracy: 0.7404 - val_loss: 1.4939 - val_accuracy: 0.7180\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:00 - loss: 0.8489 - accuracy: 0.76 - ETA: 2:53 - loss: 0.8100 - accuracy: 0.76 - ETA: 2:48 - loss: 0.8124 - accuracy: 0.78 - ETA: 2:49 - loss: 0.8748 - accuracy: 0.75 - ETA: 2:51 - loss: 0.8656 - accuracy: 0.76 - ETA: 2:50 - loss: 0.8316 - accuracy: 0.77 - ETA: 2:47 - loss: 0.8252 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8449 - accuracy: 0.76 - ETA: 2:43 - loss: 0.8327 - accuracy: 0.76 - ETA: 2:42 - loss: 0.8457 - accuracy: 0.76 - ETA: 2:40 - loss: 0.8768 - accuracy: 0.76 - ETA: 2:38 - loss: 0.8760 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8803 - accuracy: 0.76 - ETA: 2:36 - loss: 0.9106 - accuracy: 0.75 - ETA: 2:35 - loss: 0.9036 - accuracy: 0.76 - ETA: 2:33 - loss: 0.9189 - accuracy: 0.76 - ETA: 2:32 - loss: 0.9047 - accuracy: 0.76 - ETA: 2:31 - loss: 0.9206 - accuracy: 0.75 - ETA: 2:31 - loss: 0.9061 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8988 - accuracy: 0.76 - ETA: 2:29 - loss: 0.8943 - accuracy: 0.76 - ETA: 2:28 - loss: 0.9065 - accuracy: 0.76 - ETA: 2:27 - loss: 0.9098 - accuracy: 0.76 - ETA: 2:25 - loss: 0.9070 - accuracy: 0.76 - ETA: 2:24 - loss: 0.9173 - accuracy: 0.75 - ETA: 2:22 - loss: 0.9219 - accuracy: 0.75 - ETA: 2:21 - loss: 0.9294 - accuracy: 0.75 - ETA: 2:20 - loss: 0.9378 - accuracy: 0.75 - ETA: 2:19 - loss: 0.9241 - accuracy: 0.75 - ETA: 2:18 - loss: 0.9194 - accuracy: 0.75 - ETA: 2:16 - loss: 0.9174 - accuracy: 0.75 - ETA: 2:15 - loss: 0.9182 - accuracy: 0.75 - ETA: 2:14 - loss: 0.9243 - accuracy: 0.75 - ETA: 2:13 - loss: 0.9237 - accuracy: 0.75 - ETA: 2:12 - loss: 0.9212 - accuracy: 0.75 - ETA: 2:11 - loss: 0.9267 - accuracy: 0.75 - ETA: 2:09 - loss: 0.9211 - accuracy: 0.75 - ETA: 2:08 - loss: 0.9203 - accuracy: 0.75 - ETA: 2:07 - loss: 0.9164 - accuracy: 0.75 - ETA: 2:06 - loss: 0.9230 - accuracy: 0.75 - ETA: 2:04 - loss: 0.9191 - accuracy: 0.75 - ETA: 2:03 - loss: 0.9249 - accuracy: 0.75 - ETA: 2:02 - loss: 0.9242 - accuracy: 0.75 - ETA: 2:01 - loss: 0.9219 - accuracy: 0.75 - ETA: 2:00 - loss: 0.9244 - accuracy: 0.75 - ETA: 1:59 - loss: 0.9254 - accuracy: 0.75 - ETA: 1:58 - loss: 0.9269 - accuracy: 0.75 - ETA: 1:57 - loss: 0.9289 - accuracy: 0.75 - ETA: 1:56 - loss: 0.9306 - accuracy: 0.75 - ETA: 1:54 - loss: 0.9372 - accuracy: 0.74 - ETA: 1:53 - loss: 0.9348 - accuracy: 0.74 - ETA: 1:52 - loss: 0.9335 - accuracy: 0.74 - ETA: 1:51 - loss: 0.9356 - accuracy: 0.74 - ETA: 1:50 - loss: 0.9351 - accuracy: 0.74 - ETA: 1:48 - loss: 0.9339 - accuracy: 0.75 - ETA: 1:47 - loss: 0.9426 - accuracy: 0.75 - ETA: 1:46 - loss: 0.9480 - accuracy: 0.74 - ETA: 1:45 - loss: 0.9494 - accuracy: 0.74 - ETA: 1:44 - loss: 0.9602 - accuracy: 0.74 - ETA: 1:43 - loss: 0.9675 - accuracy: 0.74 - ETA: 1:42 - loss: 0.9682 - accuracy: 0.74 - ETA: 1:41 - loss: 0.9700 - accuracy: 0.74 - ETA: 1:40 - loss: 0.9684 - accuracy: 0.74 - ETA: 1:38 - loss: 0.9673 - accuracy: 0.74 - ETA: 1:37 - loss: 0.9696 - accuracy: 0.74 - ETA: 1:36 - loss: 0.9753 - accuracy: 0.74 - ETA: 1:35 - loss: 0.9739 - accuracy: 0.74 - ETA: 1:34 - loss: 0.9701 - accuracy: 0.74 - ETA: 1:32 - loss: 0.9736 - accuracy: 0.74 - ETA: 1:31 - loss: 0.9754 - accuracy: 0.74 - ETA: 1:30 - loss: 0.9740 - accuracy: 0.74 - ETA: 1:29 - loss: 0.9725 - accuracy: 0.74 - ETA: 1:28 - loss: 0.9747 - accuracy: 0.74 - ETA: 1:27 - loss: 0.9711 - accuracy: 0.74 - ETA: 1:26 - loss: 0.9705 - accuracy: 0.74 - ETA: 1:25 - loss: 0.9700 - accuracy: 0.74 - ETA: 1:23 - loss: 0.9723 - accuracy: 0.74 - ETA: 1:22 - loss: 0.9707 - accuracy: 0.74 - ETA: 1:21 - loss: 0.9676 - accuracy: 0.74 - ETA: 1:20 - loss: 0.9667 - accuracy: 0.74 - ETA: 1:19 - loss: 0.9658 - accuracy: 0.74 - ETA: 1:18 - loss: 0.9708 - accuracy: 0.74 - ETA: 1:17 - loss: 0.9748 - accuracy: 0.74 - ETA: 1:15 - loss: 0.9746 - accuracy: 0.74 - ETA: 1:14 - loss: 0.9783 - accuracy: 0.74 - ETA: 1:13 - loss: 0.9799 - accuracy: 0.73 - ETA: 1:12 - loss: 0.9781 - accuracy: 0.73 - ETA: 1:11 - loss: 0.9765 - accuracy: 0.73 - ETA: 1:10 - loss: 0.9763 - accuracy: 0.73 - ETA: 1:09 - loss: 0.9780 - accuracy: 0.73 - ETA: 1:08 - loss: 0.9764 - accuracy: 0.73 - ETA: 1:06 - loss: 0.9761 - accuracy: 0.73 - ETA: 1:05 - loss: 0.9769 - accuracy: 0.73 - ETA: 1:04 - loss: 0.9771 - accuracy: 0.73 - ETA: 1:03 - loss: 0.9784 - accuracy: 0.73 - ETA: 1:02 - loss: 0.9782 - accuracy: 0.73 - ETA: 1:01 - loss: 0.9783 - accuracy: 0.73 - ETA: 1:00 - loss: 0.9775 - accuracy: 0.73 - ETA: 58s - loss: 0.9781 - accuracy: 0.7387 - ETA: 57s - loss: 0.9763 - accuracy: 0.739 - ETA: 56s - loss: 0.9812 - accuracy: 0.738 - ETA: 55s - loss: 0.9815 - accuracy: 0.738 - ETA: 54s - loss: 0.9820 - accuracy: 0.738 - ETA: 53s - loss: 0.9818 - accuracy: 0.738 - ETA: 52s - loss: 0.9789 - accuracy: 0.739 - ETA: 51s - loss: 0.9764 - accuracy: 0.739 - ETA: 49s - loss: 0.9759 - accuracy: 0.739 - ETA: 48s - loss: 0.9759 - accuracy: 0.739 - ETA: 47s - loss: 0.9759 - accuracy: 0.739 - ETA: 46s - loss: 0.9778 - accuracy: 0.739 - ETA: 45s - loss: 0.9782 - accuracy: 0.739 - ETA: 44s - loss: 0.9789 - accuracy: 0.739 - ETA: 42s - loss: 0.9789 - accuracy: 0.739 - ETA: 41s - loss: 0.9756 - accuracy: 0.739 - ETA: 40s - loss: 0.9743 - accuracy: 0.740 - ETA: 39s - loss: 0.9755 - accuracy: 0.739 - ETA: 38s - loss: 0.9772 - accuracy: 0.739 - ETA: 37s - loss: 0.9768 - accuracy: 0.739 - ETA: 36s - loss: 0.9792 - accuracy: 0.738 - ETA: 35s - loss: 0.9781 - accuracy: 0.739 - ETA: 33s - loss: 0.9800 - accuracy: 0.738 - ETA: 32s - loss: 0.9776 - accuracy: 0.739 - ETA: 31s - loss: 0.9804 - accuracy: 0.738 - ETA: 30s - loss: 0.9790 - accuracy: 0.738 - ETA: 29s - loss: 0.9789 - accuracy: 0.738 - ETA: 28s - loss: 0.9788 - accuracy: 0.738 - ETA: 27s - loss: 0.9783 - accuracy: 0.738 - ETA: 25s - loss: 0.9782 - accuracy: 0.738 - ETA: 24s - loss: 0.9780 - accuracy: 0.738 - ETA: 23s - loss: 0.9757 - accuracy: 0.738 - ETA: 22s - loss: 0.9771 - accuracy: 0.738 - ETA: 21s - loss: 0.9757 - accuracy: 0.738 - ETA: 20s - loss: 0.9757 - accuracy: 0.739 - ETA: 19s - loss: 0.9740 - accuracy: 0.739 - ETA: 18s - loss: 0.9746 - accuracy: 0.739 - ETA: 16s - loss: 0.9747 - accuracy: 0.738 - ETA: 15s - loss: 0.9724 - accuracy: 0.739 - ETA: 14s - loss: 0.9703 - accuracy: 0.739 - ETA: 13s - loss: 0.9691 - accuracy: 0.739 - ETA: 12s - loss: 0.9691 - accuracy: 0.739 - ETA: 11s - loss: 0.9681 - accuracy: 0.739 - ETA: 10s - loss: 0.9680 - accuracy: 0.739 - ETA: 8s - loss: 0.9667 - accuracy: 0.739 - ETA: 7s - loss: 0.9681 - accuracy: 0.73 - ETA: 6s - loss: 0.9683 - accuracy: 0.73 - ETA: 5s - loss: 0.9672 - accuracy: 0.73 - ETA: 4s - loss: 0.9669 - accuracy: 0.73 - ETA: 3s - loss: 0.9659 - accuracy: 0.73 - ETA: 2s - loss: 0.9665 - accuracy: 0.73 - ETA: 0s - loss: 0.9662 - accuracy: 0.73 - 183s 9ms/step - loss: 0.9671 - accuracy: 0.7397 - val_loss: 1.4646 - val_accuracy: 0.7186\n",
      "Epoch 28/100\n",
      "19312/19312 [==============================] - ETA: 2:51 - loss: 0.9393 - accuracy: 0.73 - ETA: 2:46 - loss: 0.9000 - accuracy: 0.75 - ETA: 2:49 - loss: 0.8454 - accuracy: 0.76 - ETA: 2:48 - loss: 0.8962 - accuracy: 0.75 - ETA: 2:46 - loss: 0.8823 - accuracy: 0.74 - ETA: 2:44 - loss: 0.8672 - accuracy: 0.75 - ETA: 2:44 - loss: 0.8529 - accuracy: 0.75 - ETA: 2:42 - loss: 0.8831 - accuracy: 0.74 - ETA: 2:40 - loss: 0.8955 - accuracy: 0.73 - ETA: 2:39 - loss: 0.8842 - accuracy: 0.74 - ETA: 2:37 - loss: 0.8699 - accuracy: 0.74 - ETA: 2:37 - loss: 0.8792 - accuracy: 0.74 - ETA: 2:37 - loss: 0.8812 - accuracy: 0.74 - ETA: 2:36 - loss: 0.8951 - accuracy: 0.74 - ETA: 2:34 - loss: 0.8997 - accuracy: 0.74 - ETA: 2:34 - loss: 0.9088 - accuracy: 0.74 - ETA: 2:32 - loss: 0.9167 - accuracy: 0.74 - ETA: 2:31 - loss: 0.9070 - accuracy: 0.74 - ETA: 2:29 - loss: 0.9059 - accuracy: 0.74 - ETA: 2:28 - loss: 0.9047 - accuracy: 0.74 - ETA: 2:27 - loss: 0.8983 - accuracy: 0.74 - ETA: 2:26 - loss: 0.9061 - accuracy: 0.74 - ETA: 2:25 - loss: 0.8920 - accuracy: 0.74 - ETA: 2:24 - loss: 0.9138 - accuracy: 0.74 - ETA: 2:23 - loss: 0.9071 - accuracy: 0.74 - ETA: 2:22 - loss: 0.9066 - accuracy: 0.74 - ETA: 2:21 - loss: 0.9054 - accuracy: 0.74 - ETA: 2:20 - loss: 0.9084 - accuracy: 0.74 - ETA: 2:19 - loss: 0.9060 - accuracy: 0.74 - ETA: 2:19 - loss: 0.9071 - accuracy: 0.74 - ETA: 2:17 - loss: 0.9096 - accuracy: 0.74 - ETA: 2:16 - loss: 0.9088 - accuracy: 0.74 - ETA: 2:15 - loss: 0.9075 - accuracy: 0.75 - ETA: 2:14 - loss: 0.9040 - accuracy: 0.74 - ETA: 2:12 - loss: 0.9116 - accuracy: 0.74 - ETA: 2:11 - loss: 0.9122 - accuracy: 0.74 - ETA: 2:10 - loss: 0.9032 - accuracy: 0.74 - ETA: 2:08 - loss: 0.9005 - accuracy: 0.75 - ETA: 2:07 - loss: 0.9024 - accuracy: 0.74 - ETA: 2:06 - loss: 0.9056 - accuracy: 0.74 - ETA: 2:05 - loss: 0.9093 - accuracy: 0.74 - ETA: 2:04 - loss: 0.9071 - accuracy: 0.74 - ETA: 2:03 - loss: 0.9020 - accuracy: 0.74 - ETA: 2:01 - loss: 0.9067 - accuracy: 0.74 - ETA: 2:00 - loss: 0.9063 - accuracy: 0.74 - ETA: 1:59 - loss: 0.9054 - accuracy: 0.74 - ETA: 1:58 - loss: 0.9057 - accuracy: 0.74 - ETA: 1:57 - loss: 0.9049 - accuracy: 0.74 - ETA: 1:56 - loss: 0.9055 - accuracy: 0.74 - ETA: 1:55 - loss: 0.9055 - accuracy: 0.74 - ETA: 1:54 - loss: 0.9073 - accuracy: 0.74 - ETA: 1:52 - loss: 0.9103 - accuracy: 0.74 - ETA: 1:51 - loss: 0.9089 - accuracy: 0.74 - ETA: 1:50 - loss: 0.9126 - accuracy: 0.74 - ETA: 1:49 - loss: 0.9113 - accuracy: 0.74 - ETA: 1:48 - loss: 0.9094 - accuracy: 0.74 - ETA: 1:47 - loss: 0.9140 - accuracy: 0.74 - ETA: 1:46 - loss: 0.9114 - accuracy: 0.74 - ETA: 1:44 - loss: 0.9136 - accuracy: 0.74 - ETA: 1:43 - loss: 0.9112 - accuracy: 0.74 - ETA: 1:42 - loss: 0.9107 - accuracy: 0.74 - ETA: 1:41 - loss: 0.9169 - accuracy: 0.74 - ETA: 1:40 - loss: 0.9204 - accuracy: 0.74 - ETA: 1:38 - loss: 0.9231 - accuracy: 0.74 - ETA: 1:37 - loss: 0.9208 - accuracy: 0.74 - ETA: 1:36 - loss: 0.9282 - accuracy: 0.74 - ETA: 1:35 - loss: 0.9302 - accuracy: 0.74 - ETA: 1:34 - loss: 0.9309 - accuracy: 0.74 - ETA: 1:33 - loss: 0.9321 - accuracy: 0.74 - ETA: 1:32 - loss: 0.9317 - accuracy: 0.74 - ETA: 1:31 - loss: 0.9301 - accuracy: 0.74 - ETA: 1:29 - loss: 0.9269 - accuracy: 0.74 - ETA: 1:28 - loss: 0.9295 - accuracy: 0.74 - ETA: 1:27 - loss: 0.9296 - accuracy: 0.74 - ETA: 1:26 - loss: 0.9367 - accuracy: 0.74 - ETA: 1:25 - loss: 0.9383 - accuracy: 0.73 - ETA: 1:24 - loss: 0.9361 - accuracy: 0.73 - ETA: 1:23 - loss: 0.9345 - accuracy: 0.73 - ETA: 1:21 - loss: 0.9341 - accuracy: 0.73 - ETA: 1:20 - loss: 0.9376 - accuracy: 0.73 - ETA: 1:19 - loss: 0.9384 - accuracy: 0.73 - ETA: 1:18 - loss: 0.9361 - accuracy: 0.73 - ETA: 1:17 - loss: 0.9333 - accuracy: 0.74 - ETA: 1:16 - loss: 0.9354 - accuracy: 0.74 - ETA: 1:15 - loss: 0.9344 - accuracy: 0.74 - ETA: 1:14 - loss: 0.9377 - accuracy: 0.74 - ETA: 1:12 - loss: 0.9379 - accuracy: 0.73 - ETA: 1:11 - loss: 0.9442 - accuracy: 0.73 - ETA: 1:10 - loss: 0.9441 - accuracy: 0.73 - ETA: 1:09 - loss: 0.9438 - accuracy: 0.73 - ETA: 1:08 - loss: 0.9431 - accuracy: 0.73 - ETA: 1:07 - loss: 0.9450 - accuracy: 0.73 - ETA: 1:05 - loss: 0.9459 - accuracy: 0.73 - ETA: 1:04 - loss: 0.9435 - accuracy: 0.74 - ETA: 1:03 - loss: 0.9458 - accuracy: 0.74 - ETA: 1:02 - loss: 0.9450 - accuracy: 0.74 - ETA: 1:01 - loss: 0.9477 - accuracy: 0.74 - ETA: 1:00 - loss: 0.9482 - accuracy: 0.73 - ETA: 59s - loss: 0.9472 - accuracy: 0.7399 - ETA: 58s - loss: 0.9475 - accuracy: 0.739 - ETA: 56s - loss: 0.9452 - accuracy: 0.740 - ETA: 55s - loss: 0.9453 - accuracy: 0.740 - ETA: 54s - loss: 0.9448 - accuracy: 0.740 - ETA: 53s - loss: 0.9448 - accuracy: 0.740 - ETA: 52s - loss: 0.9448 - accuracy: 0.741 - ETA: 51s - loss: 0.9439 - accuracy: 0.741 - ETA: 50s - loss: 0.9430 - accuracy: 0.741 - ETA: 48s - loss: 0.9439 - accuracy: 0.740 - ETA: 47s - loss: 0.9434 - accuracy: 0.741 - ETA: 46s - loss: 0.9455 - accuracy: 0.740 - ETA: 45s - loss: 0.9442 - accuracy: 0.741 - ETA: 44s - loss: 0.9459 - accuracy: 0.741 - ETA: 43s - loss: 0.9444 - accuracy: 0.740 - ETA: 42s - loss: 0.9424 - accuracy: 0.740 - ETA: 40s - loss: 0.9430 - accuracy: 0.740 - ETA: 39s - loss: 0.9438 - accuracy: 0.740 - ETA: 38s - loss: 0.9447 - accuracy: 0.740 - ETA: 37s - loss: 0.9438 - accuracy: 0.740 - ETA: 36s - loss: 0.9423 - accuracy: 0.741 - ETA: 35s - loss: 0.9408 - accuracy: 0.741 - ETA: 34s - loss: 0.9399 - accuracy: 0.741 - ETA: 33s - loss: 0.9373 - accuracy: 0.741 - ETA: 32s - loss: 0.9398 - accuracy: 0.741 - ETA: 31s - loss: 0.9401 - accuracy: 0.741 - ETA: 30s - loss: 0.9381 - accuracy: 0.741 - ETA: 29s - loss: 0.9364 - accuracy: 0.741 - ETA: 27s - loss: 0.9369 - accuracy: 0.741 - ETA: 26s - loss: 0.9361 - accuracy: 0.741 - ETA: 25s - loss: 0.9373 - accuracy: 0.741 - ETA: 24s - loss: 0.9358 - accuracy: 0.741 - ETA: 23s - loss: 0.9358 - accuracy: 0.741 - ETA: 22s - loss: 0.9350 - accuracy: 0.741 - ETA: 20s - loss: 0.9330 - accuracy: 0.741 - ETA: 19s - loss: 0.9319 - accuracy: 0.741 - ETA: 18s - loss: 0.9347 - accuracy: 0.741 - ETA: 17s - loss: 0.9352 - accuracy: 0.740 - ETA: 16s - loss: 0.9353 - accuracy: 0.740 - ETA: 15s - loss: 0.9336 - accuracy: 0.740 - ETA: 13s - loss: 0.9327 - accuracy: 0.740 - ETA: 12s - loss: 0.9321 - accuracy: 0.740 - ETA: 11s - loss: 0.9317 - accuracy: 0.740 - ETA: 10s - loss: 0.9299 - accuracy: 0.740 - ETA: 9s - loss: 0.9304 - accuracy: 0.741 - ETA: 8s - loss: 0.9322 - accuracy: 0.74 - ETA: 6s - loss: 0.9317 - accuracy: 0.74 - ETA: 5s - loss: 0.9313 - accuracy: 0.74 - ETA: 4s - loss: 0.9311 - accuracy: 0.74 - ETA: 3s - loss: 0.9300 - accuracy: 0.74 - ETA: 2s - loss: 0.9299 - accuracy: 0.74 - ETA: 1s - loss: 0.9275 - accuracy: 0.74 - 189s 10ms/step - loss: 0.9269 - accuracy: 0.7422 - val_loss: 1.5099 - val_accuracy: 0.7155\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:18 - loss: 0.9692 - accuracy: 0.71 - ETA: 3:10 - loss: 0.8131 - accuracy: 0.75 - ETA: 3:01 - loss: 0.8443 - accuracy: 0.76 - ETA: 2:55 - loss: 0.8438 - accuracy: 0.75 - ETA: 2:53 - loss: 0.8490 - accuracy: 0.75 - ETA: 2:50 - loss: 0.8713 - accuracy: 0.75 - ETA: 2:48 - loss: 0.8689 - accuracy: 0.75 - ETA: 2:45 - loss: 0.8670 - accuracy: 0.75 - ETA: 2:43 - loss: 0.8666 - accuracy: 0.75 - ETA: 2:41 - loss: 0.8609 - accuracy: 0.76 - ETA: 2:40 - loss: 0.9232 - accuracy: 0.75 - ETA: 2:40 - loss: 0.9115 - accuracy: 0.75 - ETA: 2:38 - loss: 0.9134 - accuracy: 0.75 - ETA: 2:36 - loss: 0.9020 - accuracy: 0.76 - ETA: 2:36 - loss: 0.9110 - accuracy: 0.75 - ETA: 2:35 - loss: 0.9174 - accuracy: 0.75 - ETA: 2:34 - loss: 0.9221 - accuracy: 0.75 - ETA: 2:33 - loss: 0.9337 - accuracy: 0.75 - ETA: 2:31 - loss: 0.9453 - accuracy: 0.75 - ETA: 2:30 - loss: 0.9460 - accuracy: 0.74 - ETA: 2:29 - loss: 0.9520 - accuracy: 0.74 - ETA: 2:27 - loss: 0.9514 - accuracy: 0.74 - ETA: 2:26 - loss: 0.9530 - accuracy: 0.74 - ETA: 2:25 - loss: 0.9516 - accuracy: 0.74 - ETA: 2:23 - loss: 0.9534 - accuracy: 0.75 - ETA: 2:22 - loss: 0.9550 - accuracy: 0.75 - ETA: 2:21 - loss: 0.9424 - accuracy: 0.75 - ETA: 2:20 - loss: 0.9424 - accuracy: 0.75 - ETA: 2:19 - loss: 0.9439 - accuracy: 0.75 - ETA: 2:18 - loss: 0.9510 - accuracy: 0.75 - ETA: 2:17 - loss: 0.9456 - accuracy: 0.75 - ETA: 2:16 - loss: 0.9379 - accuracy: 0.75 - ETA: 2:14 - loss: 0.9376 - accuracy: 0.75 - ETA: 2:13 - loss: 0.9342 - accuracy: 0.75 - ETA: 2:12 - loss: 0.9301 - accuracy: 0.75 - ETA: 2:10 - loss: 0.9362 - accuracy: 0.75 - ETA: 2:09 - loss: 0.9337 - accuracy: 0.75 - ETA: 2:08 - loss: 0.9331 - accuracy: 0.75 - ETA: 2:07 - loss: 0.9315 - accuracy: 0.75 - ETA: 2:06 - loss: 0.9282 - accuracy: 0.75 - ETA: 2:05 - loss: 0.9327 - accuracy: 0.74 - ETA: 2:03 - loss: 0.9337 - accuracy: 0.74 - ETA: 2:03 - loss: 0.9356 - accuracy: 0.74 - ETA: 2:02 - loss: 0.9308 - accuracy: 0.74 - ETA: 2:00 - loss: 0.9259 - accuracy: 0.75 - ETA: 1:59 - loss: 0.9257 - accuracy: 0.74 - ETA: 1:58 - loss: 0.9202 - accuracy: 0.75 - ETA: 1:57 - loss: 0.9195 - accuracy: 0.75 - ETA: 1:56 - loss: 0.9233 - accuracy: 0.75 - ETA: 1:55 - loss: 0.9268 - accuracy: 0.75 - ETA: 1:54 - loss: 0.9238 - accuracy: 0.75 - ETA: 1:52 - loss: 0.9221 - accuracy: 0.75 - ETA: 1:51 - loss: 0.9259 - accuracy: 0.75 - ETA: 1:50 - loss: 0.9289 - accuracy: 0.75 - ETA: 1:49 - loss: 0.9273 - accuracy: 0.75 - ETA: 1:48 - loss: 0.9250 - accuracy: 0.75 - ETA: 1:47 - loss: 0.9290 - accuracy: 0.75 - ETA: 1:46 - loss: 0.9256 - accuracy: 0.75 - ETA: 1:45 - loss: 0.9228 - accuracy: 0.75 - ETA: 1:43 - loss: 0.9225 - accuracy: 0.75 - ETA: 1:42 - loss: 0.9228 - accuracy: 0.75 - ETA: 1:41 - loss: 0.9223 - accuracy: 0.75 - ETA: 1:40 - loss: 0.9202 - accuracy: 0.75 - ETA: 1:39 - loss: 0.9173 - accuracy: 0.75 - ETA: 1:38 - loss: 0.9163 - accuracy: 0.75 - ETA: 1:37 - loss: 0.9219 - accuracy: 0.75 - ETA: 1:35 - loss: 0.9185 - accuracy: 0.75 - ETA: 1:34 - loss: 0.9186 - accuracy: 0.75 - ETA: 1:33 - loss: 0.9191 - accuracy: 0.75 - ETA: 1:32 - loss: 0.9172 - accuracy: 0.75 - ETA: 1:31 - loss: 0.9187 - accuracy: 0.75 - ETA: 1:30 - loss: 0.9190 - accuracy: 0.75 - ETA: 1:29 - loss: 0.9178 - accuracy: 0.75 - ETA: 1:27 - loss: 0.9169 - accuracy: 0.75 - ETA: 1:26 - loss: 0.9208 - accuracy: 0.75 - ETA: 1:25 - loss: 0.9203 - accuracy: 0.75 - ETA: 1:24 - loss: 0.9189 - accuracy: 0.75 - ETA: 1:23 - loss: 0.9214 - accuracy: 0.75 - ETA: 1:22 - loss: 0.9238 - accuracy: 0.75 - ETA: 1:21 - loss: 0.9268 - accuracy: 0.75 - ETA: 1:19 - loss: 0.9275 - accuracy: 0.75 - ETA: 1:18 - loss: 0.9287 - accuracy: 0.75 - ETA: 1:17 - loss: 0.9273 - accuracy: 0.75 - ETA: 1:16 - loss: 0.9283 - accuracy: 0.75 - ETA: 1:15 - loss: 0.9275 - accuracy: 0.75 - ETA: 1:14 - loss: 0.9265 - accuracy: 0.75 - ETA: 1:13 - loss: 0.9270 - accuracy: 0.75 - ETA: 1:12 - loss: 0.9269 - accuracy: 0.75 - ETA: 1:11 - loss: 0.9281 - accuracy: 0.75 - ETA: 1:09 - loss: 0.9281 - accuracy: 0.75 - ETA: 1:08 - loss: 0.9295 - accuracy: 0.75 - ETA: 1:07 - loss: 0.9386 - accuracy: 0.75 - ETA: 1:06 - loss: 0.9351 - accuracy: 0.75 - ETA: 1:05 - loss: 0.9380 - accuracy: 0.75 - ETA: 1:04 - loss: 0.9371 - accuracy: 0.75 - ETA: 1:02 - loss: 0.9359 - accuracy: 0.75 - ETA: 1:01 - loss: 0.9374 - accuracy: 0.74 - ETA: 1:00 - loss: 0.9349 - accuracy: 0.74 - ETA: 59s - loss: 0.9389 - accuracy: 0.7496 - ETA: 58s - loss: 0.9390 - accuracy: 0.749 - ETA: 57s - loss: 0.9373 - accuracy: 0.749 - ETA: 56s - loss: 0.9367 - accuracy: 0.749 - ETA: 54s - loss: 0.9352 - accuracy: 0.749 - ETA: 53s - loss: 0.9390 - accuracy: 0.748 - ETA: 52s - loss: 0.9360 - accuracy: 0.749 - ETA: 51s - loss: 0.9343 - accuracy: 0.749 - ETA: 50s - loss: 0.9355 - accuracy: 0.749 - ETA: 49s - loss: 0.9346 - accuracy: 0.749 - ETA: 47s - loss: 0.9357 - accuracy: 0.748 - ETA: 46s - loss: 0.9349 - accuracy: 0.748 - ETA: 45s - loss: 0.9363 - accuracy: 0.748 - ETA: 44s - loss: 0.9373 - accuracy: 0.747 - ETA: 43s - loss: 0.9374 - accuracy: 0.748 - ETA: 42s - loss: 0.9388 - accuracy: 0.747 - ETA: 41s - loss: 0.9416 - accuracy: 0.747 - ETA: 39s - loss: 0.9402 - accuracy: 0.747 - ETA: 38s - loss: 0.9395 - accuracy: 0.747 - ETA: 37s - loss: 0.9371 - accuracy: 0.748 - ETA: 36s - loss: 0.9377 - accuracy: 0.748 - ETA: 35s - loss: 0.9372 - accuracy: 0.748 - ETA: 34s - loss: 0.9381 - accuracy: 0.748 - ETA: 33s - loss: 0.9368 - accuracy: 0.748 - ETA: 31s - loss: 0.9363 - accuracy: 0.748 - ETA: 30s - loss: 0.9350 - accuracy: 0.748 - ETA: 29s - loss: 0.9342 - accuracy: 0.748 - ETA: 28s - loss: 0.9341 - accuracy: 0.748 - ETA: 27s - loss: 0.9324 - accuracy: 0.748 - ETA: 26s - loss: 0.9327 - accuracy: 0.748 - ETA: 25s - loss: 0.9338 - accuracy: 0.748 - ETA: 23s - loss: 0.9337 - accuracy: 0.748 - ETA: 22s - loss: 0.9313 - accuracy: 0.749 - ETA: 21s - loss: 0.9311 - accuracy: 0.749 - ETA: 20s - loss: 0.9330 - accuracy: 0.749 - ETA: 19s - loss: 0.9316 - accuracy: 0.749 - ETA: 18s - loss: 0.9329 - accuracy: 0.749 - ETA: 17s - loss: 0.9340 - accuracy: 0.748 - ETA: 15s - loss: 0.9344 - accuracy: 0.748 - ETA: 14s - loss: 0.9323 - accuracy: 0.748 - ETA: 13s - loss: 0.9309 - accuracy: 0.748 - ETA: 12s - loss: 0.9300 - accuracy: 0.748 - ETA: 11s - loss: 0.9299 - accuracy: 0.748 - ETA: 10s - loss: 0.9318 - accuracy: 0.748 - ETA: 9s - loss: 0.9305 - accuracy: 0.748 - ETA: 7s - loss: 0.9303 - accuracy: 0.74 - ETA: 6s - loss: 0.9314 - accuracy: 0.74 - ETA: 5s - loss: 0.9358 - accuracy: 0.74 - ETA: 4s - loss: 0.9342 - accuracy: 0.74 - ETA: 3s - loss: 0.9336 - accuracy: 0.74 - ETA: 2s - loss: 0.9340 - accuracy: 0.74 - ETA: 1s - loss: 0.9339 - accuracy: 0.74 - 185s 10ms/step - loss: 0.9344 - accuracy: 0.7473 - val_loss: 1.4839 - val_accuracy: 0.7217\n",
      "Epoch 30/100\n",
      "19312/19312 [==============================] - ETA: 2:47 - loss: 0.5648 - accuracy: 0.81 - ETA: 2:49 - loss: 0.6723 - accuracy: 0.79 - ETA: 2:48 - loss: 0.6627 - accuracy: 0.79 - ETA: 2:46 - loss: 0.6818 - accuracy: 0.79 - ETA: 2:46 - loss: 0.7361 - accuracy: 0.77 - ETA: 2:43 - loss: 0.6963 - accuracy: 0.78 - ETA: 2:43 - loss: 0.7001 - accuracy: 0.78 - ETA: 2:45 - loss: 0.6983 - accuracy: 0.78 - ETA: 2:43 - loss: 0.6936 - accuracy: 0.78 - ETA: 2:42 - loss: 0.7464 - accuracy: 0.77 - ETA: 2:41 - loss: 0.7608 - accuracy: 0.77 - ETA: 2:40 - loss: 0.7664 - accuracy: 0.77 - ETA: 2:38 - loss: 0.7701 - accuracy: 0.78 - ETA: 2:37 - loss: 0.7893 - accuracy: 0.77 - ETA: 2:35 - loss: 0.7808 - accuracy: 0.77 - ETA: 2:34 - loss: 0.7848 - accuracy: 0.77 - ETA: 2:33 - loss: 0.7890 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8142 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8049 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8162 - accuracy: 0.76 - ETA: 2:29 - loss: 0.8021 - accuracy: 0.77 - ETA: 2:28 - loss: 0.7915 - accuracy: 0.77 - ETA: 2:26 - loss: 0.7882 - accuracy: 0.77 - ETA: 2:25 - loss: 0.7879 - accuracy: 0.77 - ETA: 2:24 - loss: 0.7928 - accuracy: 0.77 - ETA: 2:23 - loss: 0.7981 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8035 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8068 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8075 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8011 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8109 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8158 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8147 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8168 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8185 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8188 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8202 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8219 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8253 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8325 - accuracy: 0.76 - ETA: 2:05 - loss: 0.8408 - accuracy: 0.76 - ETA: 2:04 - loss: 0.8448 - accuracy: 0.76 - ETA: 2:03 - loss: 0.8499 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8444 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8478 - accuracy: 0.76 - ETA: 1:59 - loss: 0.8527 - accuracy: 0.76 - ETA: 1:58 - loss: 0.8613 - accuracy: 0.76 - ETA: 1:57 - loss: 0.8604 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8610 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8646 - accuracy: 0.76 - ETA: 1:54 - loss: 0.8685 - accuracy: 0.76 - ETA: 1:52 - loss: 0.8720 - accuracy: 0.75 - ETA: 1:51 - loss: 0.8765 - accuracy: 0.75 - ETA: 1:50 - loss: 0.8727 - accuracy: 0.75 - ETA: 1:49 - loss: 0.8757 - accuracy: 0.75 - ETA: 1:48 - loss: 0.8809 - accuracy: 0.75 - ETA: 1:47 - loss: 0.8793 - accuracy: 0.75 - ETA: 1:45 - loss: 0.8759 - accuracy: 0.75 - ETA: 1:44 - loss: 0.8707 - accuracy: 0.75 - ETA: 1:43 - loss: 0.8763 - accuracy: 0.75 - ETA: 1:42 - loss: 0.8763 - accuracy: 0.75 - ETA: 1:41 - loss: 0.8744 - accuracy: 0.75 - ETA: 1:40 - loss: 0.8734 - accuracy: 0.75 - ETA: 1:39 - loss: 0.8739 - accuracy: 0.75 - ETA: 1:38 - loss: 0.8752 - accuracy: 0.75 - ETA: 1:37 - loss: 0.8803 - accuracy: 0.75 - ETA: 1:35 - loss: 0.8790 - accuracy: 0.75 - ETA: 1:34 - loss: 0.8785 - accuracy: 0.75 - ETA: 1:33 - loss: 0.8792 - accuracy: 0.75 - ETA: 1:32 - loss: 0.8808 - accuracy: 0.75 - ETA: 1:31 - loss: 0.8846 - accuracy: 0.75 - ETA: 1:30 - loss: 0.8844 - accuracy: 0.75 - ETA: 1:28 - loss: 0.8867 - accuracy: 0.75 - ETA: 1:27 - loss: 0.8933 - accuracy: 0.75 - ETA: 1:26 - loss: 0.8923 - accuracy: 0.75 - ETA: 1:25 - loss: 0.8913 - accuracy: 0.75 - ETA: 1:24 - loss: 0.8939 - accuracy: 0.75 - ETA: 1:23 - loss: 0.8935 - accuracy: 0.75 - ETA: 1:22 - loss: 0.8944 - accuracy: 0.75 - ETA: 1:20 - loss: 0.8931 - accuracy: 0.75 - ETA: 1:19 - loss: 0.8908 - accuracy: 0.75 - ETA: 1:18 - loss: 0.8895 - accuracy: 0.75 - ETA: 1:17 - loss: 0.8876 - accuracy: 0.75 - ETA: 1:16 - loss: 0.8879 - accuracy: 0.75 - ETA: 1:15 - loss: 0.8879 - accuracy: 0.75 - ETA: 1:13 - loss: 0.8860 - accuracy: 0.75 - ETA: 1:12 - loss: 0.8871 - accuracy: 0.75 - ETA: 1:11 - loss: 0.8883 - accuracy: 0.75 - ETA: 1:10 - loss: 0.8863 - accuracy: 0.75 - ETA: 1:09 - loss: 0.8852 - accuracy: 0.75 - ETA: 1:08 - loss: 0.8854 - accuracy: 0.75 - ETA: 1:07 - loss: 0.8859 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8862 - accuracy: 0.75 - ETA: 1:04 - loss: 0.8855 - accuracy: 0.75 - ETA: 1:03 - loss: 0.8852 - accuracy: 0.75 - ETA: 1:02 - loss: 0.8863 - accuracy: 0.75 - ETA: 1:01 - loss: 0.8871 - accuracy: 0.75 - ETA: 1:00 - loss: 0.8905 - accuracy: 0.75 - ETA: 59s - loss: 0.8924 - accuracy: 0.7501 - ETA: 58s - loss: 0.8920 - accuracy: 0.750 - ETA: 56s - loss: 0.8910 - accuracy: 0.750 - ETA: 55s - loss: 0.8913 - accuracy: 0.750 - ETA: 54s - loss: 0.8920 - accuracy: 0.750 - ETA: 53s - loss: 0.8915 - accuracy: 0.750 - ETA: 52s - loss: 0.8920 - accuracy: 0.749 - ETA: 51s - loss: 0.8924 - accuracy: 0.749 - ETA: 50s - loss: 0.8932 - accuracy: 0.748 - ETA: 49s - loss: 0.8933 - accuracy: 0.748 - ETA: 47s - loss: 0.8925 - accuracy: 0.748 - ETA: 46s - loss: 0.8938 - accuracy: 0.748 - ETA: 45s - loss: 0.8928 - accuracy: 0.748 - ETA: 44s - loss: 0.8960 - accuracy: 0.748 - ETA: 43s - loss: 0.8948 - accuracy: 0.748 - ETA: 42s - loss: 0.8941 - accuracy: 0.748 - ETA: 41s - loss: 0.8946 - accuracy: 0.748 - ETA: 39s - loss: 0.8941 - accuracy: 0.748 - ETA: 38s - loss: 0.8946 - accuracy: 0.748 - ETA: 37s - loss: 0.8951 - accuracy: 0.748 - ETA: 36s - loss: 0.8938 - accuracy: 0.748 - ETA: 35s - loss: 0.8933 - accuracy: 0.748 - ETA: 34s - loss: 0.8945 - accuracy: 0.747 - ETA: 33s - loss: 0.8957 - accuracy: 0.747 - ETA: 31s - loss: 0.8985 - accuracy: 0.746 - ETA: 30s - loss: 0.9001 - accuracy: 0.746 - ETA: 29s - loss: 0.9010 - accuracy: 0.747 - ETA: 28s - loss: 0.9008 - accuracy: 0.747 - ETA: 27s - loss: 0.9004 - accuracy: 0.747 - ETA: 26s - loss: 0.9005 - accuracy: 0.747 - ETA: 24s - loss: 0.9018 - accuracy: 0.747 - ETA: 23s - loss: 0.9012 - accuracy: 0.747 - ETA: 22s - loss: 0.9010 - accuracy: 0.747 - ETA: 21s - loss: 0.9011 - accuracy: 0.747 - ETA: 20s - loss: 0.8996 - accuracy: 0.747 - ETA: 19s - loss: 0.9000 - accuracy: 0.747 - ETA: 18s - loss: 0.9005 - accuracy: 0.746 - ETA: 17s - loss: 0.9023 - accuracy: 0.746 - ETA: 15s - loss: 0.9021 - accuracy: 0.746 - ETA: 14s - loss: 0.9020 - accuracy: 0.746 - ETA: 13s - loss: 0.9023 - accuracy: 0.745 - ETA: 12s - loss: 0.9023 - accuracy: 0.745 - ETA: 11s - loss: 0.9022 - accuracy: 0.745 - ETA: 10s - loss: 0.9018 - accuracy: 0.745 - ETA: 9s - loss: 0.9024 - accuracy: 0.746 - ETA: 7s - loss: 0.9031 - accuracy: 0.74 - ETA: 6s - loss: 0.9039 - accuracy: 0.74 - ETA: 5s - loss: 0.9040 - accuracy: 0.74 - ETA: 4s - loss: 0.9038 - accuracy: 0.74 - ETA: 3s - loss: 0.9032 - accuracy: 0.74 - ETA: 2s - loss: 0.9029 - accuracy: 0.74 - ETA: 1s - loss: 0.9028 - accuracy: 0.74 - 187s 10ms/step - loss: 0.9023 - accuracy: 0.7460 - val_loss: 1.4692 - val_accuracy: 0.7130\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:56 - loss: 1.0831 - accuracy: 0.67 - ETA: 2:49 - loss: 1.0551 - accuracy: 0.67 - ETA: 2:46 - loss: 0.9187 - accuracy: 0.71 - ETA: 2:45 - loss: 0.9252 - accuracy: 0.71 - ETA: 2:47 - loss: 0.9313 - accuracy: 0.72 - ETA: 2:45 - loss: 0.9355 - accuracy: 0.72 - ETA: 2:44 - loss: 0.9283 - accuracy: 0.72 - ETA: 2:42 - loss: 0.9233 - accuracy: 0.73 - ETA: 2:41 - loss: 0.8925 - accuracy: 0.73 - ETA: 2:40 - loss: 0.8887 - accuracy: 0.73 - ETA: 2:38 - loss: 0.8962 - accuracy: 0.74 - ETA: 2:38 - loss: 0.8981 - accuracy: 0.74 - ETA: 2:38 - loss: 0.8730 - accuracy: 0.75 - ETA: 2:38 - loss: 0.8762 - accuracy: 0.75 - ETA: 2:37 - loss: 0.8818 - accuracy: 0.74 - ETA: 2:35 - loss: 0.8748 - accuracy: 0.75 - ETA: 2:34 - loss: 0.8815 - accuracy: 0.75 - ETA: 2:33 - loss: 0.8824 - accuracy: 0.75 - ETA: 2:32 - loss: 0.8882 - accuracy: 0.75 - ETA: 2:31 - loss: 0.9089 - accuracy: 0.74 - ETA: 2:29 - loss: 0.8995 - accuracy: 0.74 - ETA: 2:28 - loss: 0.8910 - accuracy: 0.75 - ETA: 2:26 - loss: 0.8868 - accuracy: 0.75 - ETA: 2:25 - loss: 0.8902 - accuracy: 0.75 - ETA: 2:24 - loss: 0.8862 - accuracy: 0.75 - ETA: 2:23 - loss: 0.8874 - accuracy: 0.75 - ETA: 2:23 - loss: 0.8863 - accuracy: 0.75 - ETA: 2:22 - loss: 0.8886 - accuracy: 0.74 - ETA: 2:20 - loss: 0.8903 - accuracy: 0.74 - ETA: 2:19 - loss: 0.8841 - accuracy: 0.75 - ETA: 2:18 - loss: 0.8799 - accuracy: 0.75 - ETA: 2:16 - loss: 0.8767 - accuracy: 0.75 - ETA: 2:15 - loss: 0.8716 - accuracy: 0.75 - ETA: 2:14 - loss: 0.8740 - accuracy: 0.75 - ETA: 2:13 - loss: 0.8690 - accuracy: 0.75 - ETA: 2:12 - loss: 0.8660 - accuracy: 0.75 - ETA: 2:11 - loss: 0.8689 - accuracy: 0.75 - ETA: 2:09 - loss: 0.8745 - accuracy: 0.75 - ETA: 2:08 - loss: 0.8814 - accuracy: 0.75 - ETA: 2:07 - loss: 0.8860 - accuracy: 0.74 - ETA: 2:07 - loss: 0.8805 - accuracy: 0.75 - ETA: 2:05 - loss: 0.8838 - accuracy: 0.75 - ETA: 2:04 - loss: 0.8806 - accuracy: 0.75 - ETA: 2:03 - loss: 0.8814 - accuracy: 0.75 - ETA: 2:02 - loss: 0.8806 - accuracy: 0.75 - ETA: 2:00 - loss: 0.8800 - accuracy: 0.75 - ETA: 1:59 - loss: 0.8804 - accuracy: 0.75 - ETA: 1:58 - loss: 0.8805 - accuracy: 0.75 - ETA: 1:57 - loss: 0.8822 - accuracy: 0.75 - ETA: 1:56 - loss: 0.8776 - accuracy: 0.75 - ETA: 1:55 - loss: 0.8834 - accuracy: 0.74 - ETA: 1:53 - loss: 0.8826 - accuracy: 0.75 - ETA: 1:52 - loss: 0.8857 - accuracy: 0.75 - ETA: 1:51 - loss: 0.8837 - accuracy: 0.75 - ETA: 1:50 - loss: 0.8872 - accuracy: 0.75 - ETA: 1:49 - loss: 0.8906 - accuracy: 0.75 - ETA: 1:48 - loss: 0.8899 - accuracy: 0.75 - ETA: 1:47 - loss: 0.8898 - accuracy: 0.75 - ETA: 1:46 - loss: 0.8891 - accuracy: 0.75 - ETA: 1:44 - loss: 0.8893 - accuracy: 0.75 - ETA: 1:43 - loss: 0.8854 - accuracy: 0.75 - ETA: 1:42 - loss: 0.8909 - accuracy: 0.75 - ETA: 1:41 - loss: 0.8916 - accuracy: 0.75 - ETA: 1:39 - loss: 0.8930 - accuracy: 0.75 - ETA: 1:38 - loss: 0.8918 - accuracy: 0.75 - ETA: 1:37 - loss: 0.8908 - accuracy: 0.75 - ETA: 1:36 - loss: 0.8936 - accuracy: 0.75 - ETA: 1:35 - loss: 0.8930 - accuracy: 0.75 - ETA: 1:34 - loss: 0.8904 - accuracy: 0.75 - ETA: 1:33 - loss: 0.8882 - accuracy: 0.75 - ETA: 1:32 - loss: 0.8887 - accuracy: 0.75 - ETA: 1:31 - loss: 0.8849 - accuracy: 0.75 - ETA: 1:30 - loss: 0.8844 - accuracy: 0.75 - ETA: 1:29 - loss: 0.8856 - accuracy: 0.75 - ETA: 1:27 - loss: 0.8885 - accuracy: 0.75 - ETA: 1:26 - loss: 0.8912 - accuracy: 0.75 - ETA: 1:25 - loss: 0.8942 - accuracy: 0.75 - ETA: 1:24 - loss: 0.8920 - accuracy: 0.75 - ETA: 1:23 - loss: 0.8916 - accuracy: 0.75 - ETA: 1:22 - loss: 0.8944 - accuracy: 0.75 - ETA: 1:20 - loss: 0.8927 - accuracy: 0.75 - ETA: 1:19 - loss: 0.8918 - accuracy: 0.75 - ETA: 1:18 - loss: 0.8923 - accuracy: 0.75 - ETA: 1:17 - loss: 0.8935 - accuracy: 0.75 - ETA: 1:16 - loss: 0.8946 - accuracy: 0.75 - ETA: 1:15 - loss: 0.8963 - accuracy: 0.75 - ETA: 1:13 - loss: 0.8989 - accuracy: 0.75 - ETA: 1:12 - loss: 0.8966 - accuracy: 0.75 - ETA: 1:11 - loss: 0.8976 - accuracy: 0.75 - ETA: 1:10 - loss: 0.8985 - accuracy: 0.75 - ETA: 1:09 - loss: 0.9014 - accuracy: 0.75 - ETA: 1:07 - loss: 0.9009 - accuracy: 0.75 - ETA: 1:06 - loss: 0.9006 - accuracy: 0.75 - ETA: 1:05 - loss: 0.9006 - accuracy: 0.75 - ETA: 1:04 - loss: 0.9006 - accuracy: 0.75 - ETA: 1:03 - loss: 0.9032 - accuracy: 0.75 - ETA: 1:02 - loss: 0.9052 - accuracy: 0.75 - ETA: 1:01 - loss: 0.9088 - accuracy: 0.75 - ETA: 59s - loss: 0.9065 - accuracy: 0.7508 - ETA: 58s - loss: 0.9120 - accuracy: 0.749 - ETA: 57s - loss: 0.9113 - accuracy: 0.749 - ETA: 56s - loss: 0.9109 - accuracy: 0.749 - ETA: 55s - loss: 0.9133 - accuracy: 0.749 - ETA: 54s - loss: 0.9142 - accuracy: 0.749 - ETA: 52s - loss: 0.9126 - accuracy: 0.749 - ETA: 51s - loss: 0.9129 - accuracy: 0.749 - ETA: 50s - loss: 0.9143 - accuracy: 0.750 - ETA: 49s - loss: 0.9146 - accuracy: 0.750 - ETA: 48s - loss: 0.9161 - accuracy: 0.749 - ETA: 47s - loss: 0.9174 - accuracy: 0.749 - ETA: 46s - loss: 0.9144 - accuracy: 0.750 - ETA: 44s - loss: 0.9139 - accuracy: 0.750 - ETA: 43s - loss: 0.9132 - accuracy: 0.750 - ETA: 42s - loss: 0.9133 - accuracy: 0.750 - ETA: 41s - loss: 0.9127 - accuracy: 0.750 - ETA: 40s - loss: 0.9127 - accuracy: 0.750 - ETA: 39s - loss: 0.9121 - accuracy: 0.750 - ETA: 37s - loss: 0.9127 - accuracy: 0.750 - ETA: 36s - loss: 0.9112 - accuracy: 0.751 - ETA: 35s - loss: 0.9117 - accuracy: 0.750 - ETA: 34s - loss: 0.9144 - accuracy: 0.750 - ETA: 33s - loss: 0.9128 - accuracy: 0.750 - ETA: 32s - loss: 0.9114 - accuracy: 0.751 - ETA: 30s - loss: 0.9119 - accuracy: 0.750 - ETA: 29s - loss: 0.9129 - accuracy: 0.750 - ETA: 28s - loss: 0.9107 - accuracy: 0.750 - ETA: 27s - loss: 0.9123 - accuracy: 0.749 - ETA: 26s - loss: 0.9142 - accuracy: 0.749 - ETA: 25s - loss: 0.9123 - accuracy: 0.749 - ETA: 24s - loss: 0.9115 - accuracy: 0.749 - ETA: 22s - loss: 0.9104 - accuracy: 0.750 - ETA: 21s - loss: 0.9105 - accuracy: 0.749 - ETA: 20s - loss: 0.9085 - accuracy: 0.750 - ETA: 19s - loss: 0.9067 - accuracy: 0.750 - ETA: 18s - loss: 0.9074 - accuracy: 0.750 - ETA: 17s - loss: 0.9088 - accuracy: 0.750 - ETA: 16s - loss: 0.9116 - accuracy: 0.749 - ETA: 14s - loss: 0.9127 - accuracy: 0.749 - ETA: 13s - loss: 0.9108 - accuracy: 0.749 - ETA: 12s - loss: 0.9113 - accuracy: 0.749 - ETA: 11s - loss: 0.9098 - accuracy: 0.749 - ETA: 10s - loss: 0.9088 - accuracy: 0.749 - ETA: 9s - loss: 0.9082 - accuracy: 0.749 - ETA: 7s - loss: 0.9089 - accuracy: 0.74 - ETA: 6s - loss: 0.9069 - accuracy: 0.74 - ETA: 5s - loss: 0.9062 - accuracy: 0.74 - ETA: 4s - loss: 0.9065 - accuracy: 0.74 - ETA: 3s - loss: 0.9080 - accuracy: 0.74 - ETA: 2s - loss: 0.9078 - accuracy: 0.74 - ETA: 1s - loss: 0.9066 - accuracy: 0.74 - 187s 10ms/step - loss: 0.9059 - accuracy: 0.7500 - val_loss: 1.5590 - val_accuracy: 0.7200\n",
      "Epoch 32/100\n",
      "19312/19312 [==============================] - ETA: 3:00 - loss: 0.9426 - accuracy: 0.75 - ETA: 3:02 - loss: 0.9129 - accuracy: 0.78 - ETA: 3:00 - loss: 0.8425 - accuracy: 0.79 - ETA: 2:54 - loss: 0.8839 - accuracy: 0.78 - ETA: 2:50 - loss: 0.8265 - accuracy: 0.78 - ETA: 2:46 - loss: 0.8611 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8498 - accuracy: 0.76 - ETA: 2:43 - loss: 0.8756 - accuracy: 0.76 - ETA: 2:41 - loss: 0.8759 - accuracy: 0.75 - ETA: 2:40 - loss: 0.8964 - accuracy: 0.75 - ETA: 2:39 - loss: 0.8734 - accuracy: 0.75 - ETA: 2:37 - loss: 0.8888 - accuracy: 0.75 - ETA: 2:36 - loss: 0.8831 - accuracy: 0.75 - ETA: 2:34 - loss: 0.8797 - accuracy: 0.75 - ETA: 2:34 - loss: 0.8536 - accuracy: 0.76 - ETA: 2:33 - loss: 0.8459 - accuracy: 0.76 - ETA: 2:33 - loss: 0.8462 - accuracy: 0.76 - ETA: 2:31 - loss: 0.8484 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8814 - accuracy: 0.76 - ETA: 2:29 - loss: 0.8955 - accuracy: 0.76 - ETA: 2:27 - loss: 0.9031 - accuracy: 0.76 - ETA: 2:26 - loss: 0.9085 - accuracy: 0.75 - ETA: 2:25 - loss: 0.9086 - accuracy: 0.76 - ETA: 2:24 - loss: 0.9150 - accuracy: 0.76 - ETA: 2:22 - loss: 0.9184 - accuracy: 0.76 - ETA: 2:21 - loss: 0.9253 - accuracy: 0.75 - ETA: 2:20 - loss: 0.9162 - accuracy: 0.75 - ETA: 2:19 - loss: 0.9048 - accuracy: 0.76 - ETA: 2:17 - loss: 0.9006 - accuracy: 0.76 - ETA: 2:16 - loss: 0.8986 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8941 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8954 - accuracy: 0.75 - ETA: 2:13 - loss: 0.8898 - accuracy: 0.75 - ETA: 2:12 - loss: 0.8871 - accuracy: 0.75 - ETA: 2:11 - loss: 0.8856 - accuracy: 0.75 - ETA: 2:10 - loss: 0.8945 - accuracy: 0.75 - ETA: 2:09 - loss: 0.8971 - accuracy: 0.75 - ETA: 2:08 - loss: 0.8978 - accuracy: 0.75 - ETA: 2:07 - loss: 0.8994 - accuracy: 0.75 - ETA: 2:05 - loss: 0.8919 - accuracy: 0.75 - ETA: 2:04 - loss: 0.8881 - accuracy: 0.75 - ETA: 2:03 - loss: 0.8807 - accuracy: 0.75 - ETA: 2:02 - loss: 0.8747 - accuracy: 0.75 - ETA: 2:01 - loss: 0.8835 - accuracy: 0.75 - ETA: 2:00 - loss: 0.8850 - accuracy: 0.75 - ETA: 1:59 - loss: 0.8841 - accuracy: 0.75 - ETA: 1:58 - loss: 0.8838 - accuracy: 0.75 - ETA: 1:57 - loss: 0.8849 - accuracy: 0.75 - ETA: 1:56 - loss: 0.8784 - accuracy: 0.75 - ETA: 1:55 - loss: 0.8809 - accuracy: 0.75 - ETA: 1:54 - loss: 0.8821 - accuracy: 0.75 - ETA: 1:53 - loss: 0.8834 - accuracy: 0.75 - ETA: 1:51 - loss: 0.8875 - accuracy: 0.75 - ETA: 1:50 - loss: 0.8908 - accuracy: 0.75 - ETA: 1:49 - loss: 0.8887 - accuracy: 0.75 - ETA: 1:48 - loss: 0.8887 - accuracy: 0.75 - ETA: 1:47 - loss: 0.8883 - accuracy: 0.75 - ETA: 1:46 - loss: 0.8907 - accuracy: 0.75 - ETA: 1:45 - loss: 0.8888 - accuracy: 0.75 - ETA: 1:43 - loss: 0.8918 - accuracy: 0.75 - ETA: 1:42 - loss: 0.8923 - accuracy: 0.75 - ETA: 1:41 - loss: 0.8941 - accuracy: 0.75 - ETA: 1:40 - loss: 0.8971 - accuracy: 0.75 - ETA: 1:39 - loss: 0.8965 - accuracy: 0.75 - ETA: 1:37 - loss: 0.9025 - accuracy: 0.75 - ETA: 1:36 - loss: 0.9035 - accuracy: 0.75 - ETA: 1:35 - loss: 0.9037 - accuracy: 0.75 - ETA: 1:34 - loss: 0.9101 - accuracy: 0.75 - ETA: 1:33 - loss: 0.9072 - accuracy: 0.75 - ETA: 1:32 - loss: 0.9092 - accuracy: 0.75 - ETA: 1:31 - loss: 0.9077 - accuracy: 0.75 - ETA: 1:30 - loss: 0.9075 - accuracy: 0.75 - ETA: 1:29 - loss: 0.9056 - accuracy: 0.75 - ETA: 1:27 - loss: 0.9047 - accuracy: 0.75 - ETA: 1:26 - loss: 0.9068 - accuracy: 0.75 - ETA: 1:25 - loss: 0.9046 - accuracy: 0.75 - ETA: 1:24 - loss: 0.9073 - accuracy: 0.75 - ETA: 1:23 - loss: 0.9105 - accuracy: 0.75 - ETA: 1:22 - loss: 0.9081 - accuracy: 0.75 - ETA: 1:20 - loss: 0.9067 - accuracy: 0.75 - ETA: 1:19 - loss: 0.9076 - accuracy: 0.75 - ETA: 1:18 - loss: 0.9100 - accuracy: 0.75 - ETA: 1:17 - loss: 0.9104 - accuracy: 0.75 - ETA: 1:16 - loss: 0.9116 - accuracy: 0.75 - ETA: 1:15 - loss: 0.9105 - accuracy: 0.75 - ETA: 1:13 - loss: 0.9091 - accuracy: 0.75 - ETA: 1:12 - loss: 0.9079 - accuracy: 0.75 - ETA: 1:11 - loss: 0.9091 - accuracy: 0.75 - ETA: 1:10 - loss: 0.9106 - accuracy: 0.75 - ETA: 1:09 - loss: 0.9165 - accuracy: 0.75 - ETA: 1:08 - loss: 0.9178 - accuracy: 0.75 - ETA: 1:07 - loss: 0.9169 - accuracy: 0.75 - ETA: 1:05 - loss: 0.9163 - accuracy: 0.75 - ETA: 1:04 - loss: 0.9158 - accuracy: 0.75 - ETA: 1:03 - loss: 0.9171 - accuracy: 0.75 - ETA: 1:02 - loss: 0.9157 - accuracy: 0.75 - ETA: 1:01 - loss: 0.9181 - accuracy: 0.75 - ETA: 1:00 - loss: 0.9174 - accuracy: 0.75 - ETA: 59s - loss: 0.9190 - accuracy: 0.7505 - ETA: 58s - loss: 0.9192 - accuracy: 0.750 - ETA: 56s - loss: 0.9183 - accuracy: 0.751 - ETA: 55s - loss: 0.9188 - accuracy: 0.750 - ETA: 54s - loss: 0.9214 - accuracy: 0.750 - ETA: 53s - loss: 0.9201 - accuracy: 0.750 - ETA: 52s - loss: 0.9195 - accuracy: 0.750 - ETA: 51s - loss: 0.9208 - accuracy: 0.750 - ETA: 50s - loss: 0.9231 - accuracy: 0.750 - ETA: 48s - loss: 0.9224 - accuracy: 0.750 - ETA: 47s - loss: 0.9253 - accuracy: 0.750 - ETA: 46s - loss: 0.9249 - accuracy: 0.749 - ETA: 45s - loss: 0.9237 - accuracy: 0.749 - ETA: 44s - loss: 0.9271 - accuracy: 0.749 - ETA: 43s - loss: 0.9262 - accuracy: 0.750 - ETA: 42s - loss: 0.9249 - accuracy: 0.749 - ETA: 41s - loss: 0.9221 - accuracy: 0.750 - ETA: 39s - loss: 0.9214 - accuracy: 0.751 - ETA: 38s - loss: 0.9203 - accuracy: 0.751 - ETA: 37s - loss: 0.9205 - accuracy: 0.751 - ETA: 36s - loss: 0.9204 - accuracy: 0.751 - ETA: 35s - loss: 0.9201 - accuracy: 0.751 - ETA: 34s - loss: 0.9200 - accuracy: 0.752 - ETA: 33s - loss: 0.9216 - accuracy: 0.752 - ETA: 31s - loss: 0.9196 - accuracy: 0.752 - ETA: 30s - loss: 0.9194 - accuracy: 0.752 - ETA: 29s - loss: 0.9210 - accuracy: 0.751 - ETA: 28s - loss: 0.9214 - accuracy: 0.752 - ETA: 27s - loss: 0.9198 - accuracy: 0.752 - ETA: 26s - loss: 0.9203 - accuracy: 0.752 - ETA: 25s - loss: 0.9214 - accuracy: 0.752 - ETA: 23s - loss: 0.9207 - accuracy: 0.752 - ETA: 22s - loss: 0.9212 - accuracy: 0.752 - ETA: 21s - loss: 0.9233 - accuracy: 0.751 - ETA: 20s - loss: 0.9222 - accuracy: 0.751 - ETA: 19s - loss: 0.9200 - accuracy: 0.751 - ETA: 18s - loss: 0.9205 - accuracy: 0.751 - ETA: 17s - loss: 0.9184 - accuracy: 0.752 - ETA: 15s - loss: 0.9169 - accuracy: 0.752 - ETA: 14s - loss: 0.9174 - accuracy: 0.752 - ETA: 13s - loss: 0.9180 - accuracy: 0.752 - ETA: 12s - loss: 0.9176 - accuracy: 0.752 - ETA: 11s - loss: 0.9195 - accuracy: 0.751 - ETA: 10s - loss: 0.9186 - accuracy: 0.751 - ETA: 9s - loss: 0.9183 - accuracy: 0.752 - ETA: 7s - loss: 0.9185 - accuracy: 0.75 - ETA: 6s - loss: 0.9186 - accuracy: 0.75 - ETA: 5s - loss: 0.9179 - accuracy: 0.75 - ETA: 4s - loss: 0.9156 - accuracy: 0.75 - ETA: 3s - loss: 0.9149 - accuracy: 0.75 - ETA: 2s - loss: 0.9182 - accuracy: 0.75 - ETA: 1s - loss: 0.9176 - accuracy: 0.75 - 185s 10ms/step - loss: 0.9175 - accuracy: 0.7521 - val_loss: 1.5731 - val_accuracy: 0.7213\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:53 - loss: 1.0162 - accuracy: 0.72 - ETA: 2:47 - loss: 1.1282 - accuracy: 0.73 - ETA: 2:47 - loss: 1.0641 - accuracy: 0.71 - ETA: 2:46 - loss: 1.0397 - accuracy: 0.73 - ETA: 2:45 - loss: 1.0254 - accuracy: 0.73 - ETA: 2:43 - loss: 1.0060 - accuracy: 0.74 - ETA: 2:41 - loss: 1.0439 - accuracy: 0.73 - ETA: 2:42 - loss: 1.0433 - accuracy: 0.74 - ETA: 2:41 - loss: 1.0155 - accuracy: 0.74 - ETA: 2:40 - loss: 1.0193 - accuracy: 0.73 - ETA: 2:38 - loss: 1.0402 - accuracy: 0.73 - ETA: 2:36 - loss: 1.0331 - accuracy: 0.73 - ETA: 2:35 - loss: 1.0268 - accuracy: 0.73 - ETA: 2:33 - loss: 1.0313 - accuracy: 0.72 - ETA: 2:31 - loss: 1.0143 - accuracy: 0.73 - ETA: 2:30 - loss: 0.9956 - accuracy: 0.73 - ETA: 2:30 - loss: 1.0052 - accuracy: 0.73 - ETA: 2:28 - loss: 1.0046 - accuracy: 0.73 - ETA: 2:28 - loss: 1.0101 - accuracy: 0.74 - ETA: 2:27 - loss: 0.9954 - accuracy: 0.74 - ETA: 2:27 - loss: 0.9902 - accuracy: 0.74 - ETA: 2:26 - loss: 0.9902 - accuracy: 0.74 - ETA: 2:25 - loss: 0.9936 - accuracy: 0.74 - ETA: 2:24 - loss: 0.9911 - accuracy: 0.74 - ETA: 2:22 - loss: 0.9768 - accuracy: 0.74 - ETA: 2:21 - loss: 0.9745 - accuracy: 0.74 - ETA: 2:20 - loss: 0.9699 - accuracy: 0.74 - ETA: 2:19 - loss: 0.9561 - accuracy: 0.74 - ETA: 2:18 - loss: 0.9511 - accuracy: 0.74 - ETA: 2:17 - loss: 0.9492 - accuracy: 0.74 - ETA: 2:16 - loss: 0.9485 - accuracy: 0.74 - ETA: 2:15 - loss: 0.9478 - accuracy: 0.74 - ETA: 2:13 - loss: 0.9456 - accuracy: 0.74 - ETA: 2:12 - loss: 0.9476 - accuracy: 0.74 - ETA: 2:11 - loss: 0.9454 - accuracy: 0.74 - ETA: 2:10 - loss: 0.9415 - accuracy: 0.74 - ETA: 2:09 - loss: 0.9373 - accuracy: 0.74 - ETA: 2:08 - loss: 0.9416 - accuracy: 0.74 - ETA: 2:07 - loss: 0.9399 - accuracy: 0.74 - ETA: 2:06 - loss: 0.9398 - accuracy: 0.74 - ETA: 2:05 - loss: 0.9343 - accuracy: 0.74 - ETA: 2:04 - loss: 0.9305 - accuracy: 0.74 - ETA: 2:02 - loss: 0.9275 - accuracy: 0.74 - ETA: 2:01 - loss: 0.9209 - accuracy: 0.74 - ETA: 2:00 - loss: 0.9198 - accuracy: 0.74 - ETA: 1:58 - loss: 0.9187 - accuracy: 0.74 - ETA: 1:57 - loss: 0.9273 - accuracy: 0.74 - ETA: 1:56 - loss: 0.9308 - accuracy: 0.74 - ETA: 1:55 - loss: 0.9267 - accuracy: 0.74 - ETA: 1:54 - loss: 0.9270 - accuracy: 0.74 - ETA: 1:53 - loss: 0.9266 - accuracy: 0.74 - ETA: 1:52 - loss: 0.9216 - accuracy: 0.74 - ETA: 1:51 - loss: 0.9244 - accuracy: 0.74 - ETA: 1:50 - loss: 0.9235 - accuracy: 0.74 - ETA: 1:48 - loss: 0.9272 - accuracy: 0.74 - ETA: 1:47 - loss: 0.9289 - accuracy: 0.74 - ETA: 1:46 - loss: 0.9260 - accuracy: 0.74 - ETA: 1:45 - loss: 0.9217 - accuracy: 0.74 - ETA: 1:44 - loss: 0.9210 - accuracy: 0.74 - ETA: 1:42 - loss: 0.9244 - accuracy: 0.74 - ETA: 1:41 - loss: 0.9284 - accuracy: 0.74 - ETA: 1:40 - loss: 0.9285 - accuracy: 0.74 - ETA: 1:39 - loss: 0.9270 - accuracy: 0.74 - ETA: 1:38 - loss: 0.9250 - accuracy: 0.74 - ETA: 1:37 - loss: 0.9270 - accuracy: 0.74 - ETA: 1:36 - loss: 0.9261 - accuracy: 0.74 - ETA: 1:35 - loss: 0.9281 - accuracy: 0.74 - ETA: 1:34 - loss: 0.9301 - accuracy: 0.74 - ETA: 1:34 - loss: 0.9267 - accuracy: 0.74 - ETA: 1:33 - loss: 0.9265 - accuracy: 0.74 - ETA: 1:31 - loss: 0.9283 - accuracy: 0.74 - ETA: 1:30 - loss: 0.9305 - accuracy: 0.74 - ETA: 1:29 - loss: 0.9285 - accuracy: 0.74 - ETA: 1:28 - loss: 0.9282 - accuracy: 0.74 - ETA: 1:27 - loss: 0.9278 - accuracy: 0.74 - ETA: 1:26 - loss: 0.9244 - accuracy: 0.74 - ETA: 1:25 - loss: 0.9242 - accuracy: 0.74 - ETA: 1:23 - loss: 0.9231 - accuracy: 0.74 - ETA: 1:22 - loss: 0.9248 - accuracy: 0.74 - ETA: 1:21 - loss: 0.9239 - accuracy: 0.74 - ETA: 1:20 - loss: 0.9218 - accuracy: 0.74 - ETA: 1:19 - loss: 0.9232 - accuracy: 0.74 - ETA: 1:18 - loss: 0.9253 - accuracy: 0.74 - ETA: 1:17 - loss: 0.9265 - accuracy: 0.74 - ETA: 1:15 - loss: 0.9250 - accuracy: 0.74 - ETA: 1:14 - loss: 0.9241 - accuracy: 0.74 - ETA: 1:13 - loss: 0.9256 - accuracy: 0.74 - ETA: 1:12 - loss: 0.9250 - accuracy: 0.74 - ETA: 1:11 - loss: 0.9230 - accuracy: 0.74 - ETA: 1:10 - loss: 0.9234 - accuracy: 0.74 - ETA: 1:08 - loss: 0.9235 - accuracy: 0.74 - ETA: 1:07 - loss: 0.9211 - accuracy: 0.74 - ETA: 1:06 - loss: 0.9217 - accuracy: 0.74 - ETA: 1:05 - loss: 0.9223 - accuracy: 0.74 - ETA: 1:04 - loss: 0.9200 - accuracy: 0.74 - ETA: 1:03 - loss: 0.9218 - accuracy: 0.74 - ETA: 1:01 - loss: 0.9229 - accuracy: 0.74 - ETA: 1:00 - loss: 0.9226 - accuracy: 0.74 - ETA: 59s - loss: 0.9205 - accuracy: 0.7485 - ETA: 58s - loss: 0.9219 - accuracy: 0.747 - ETA: 57s - loss: 0.9225 - accuracy: 0.747 - ETA: 56s - loss: 0.9225 - accuracy: 0.747 - ETA: 55s - loss: 0.9217 - accuracy: 0.747 - ETA: 53s - loss: 0.9240 - accuracy: 0.746 - ETA: 52s - loss: 0.9219 - accuracy: 0.746 - ETA: 51s - loss: 0.9257 - accuracy: 0.746 - ETA: 50s - loss: 0.9297 - accuracy: 0.746 - ETA: 49s - loss: 0.9301 - accuracy: 0.745 - ETA: 48s - loss: 0.9301 - accuracy: 0.745 - ETA: 47s - loss: 0.9315 - accuracy: 0.745 - ETA: 46s - loss: 0.9358 - accuracy: 0.744 - ETA: 44s - loss: 0.9383 - accuracy: 0.744 - ETA: 43s - loss: 0.9401 - accuracy: 0.744 - ETA: 42s - loss: 0.9386 - accuracy: 0.743 - ETA: 41s - loss: 0.9412 - accuracy: 0.743 - ETA: 40s - loss: 0.9419 - accuracy: 0.743 - ETA: 39s - loss: 0.9469 - accuracy: 0.742 - ETA: 37s - loss: 0.9454 - accuracy: 0.743 - ETA: 36s - loss: 0.9447 - accuracy: 0.743 - ETA: 35s - loss: 0.9466 - accuracy: 0.742 - ETA: 34s - loss: 0.9449 - accuracy: 0.742 - ETA: 33s - loss: 0.9444 - accuracy: 0.742 - ETA: 32s - loss: 0.9476 - accuracy: 0.742 - ETA: 31s - loss: 0.9515 - accuracy: 0.741 - ETA: 29s - loss: 0.9509 - accuracy: 0.741 - ETA: 28s - loss: 0.9505 - accuracy: 0.741 - ETA: 27s - loss: 0.9539 - accuracy: 0.741 - ETA: 26s - loss: 0.9528 - accuracy: 0.741 - ETA: 25s - loss: 0.9516 - accuracy: 0.741 - ETA: 24s - loss: 0.9513 - accuracy: 0.741 - ETA: 22s - loss: 0.9511 - accuracy: 0.741 - ETA: 21s - loss: 0.9503 - accuracy: 0.741 - ETA: 20s - loss: 0.9502 - accuracy: 0.741 - ETA: 19s - loss: 0.9509 - accuracy: 0.740 - ETA: 18s - loss: 0.9497 - accuracy: 0.741 - ETA: 17s - loss: 0.9504 - accuracy: 0.741 - ETA: 16s - loss: 0.9499 - accuracy: 0.741 - ETA: 14s - loss: 0.9493 - accuracy: 0.741 - ETA: 13s - loss: 0.9510 - accuracy: 0.741 - ETA: 12s - loss: 0.9536 - accuracy: 0.740 - ETA: 11s - loss: 0.9540 - accuracy: 0.741 - ETA: 10s - loss: 0.9543 - accuracy: 0.740 - ETA: 9s - loss: 0.9545 - accuracy: 0.740 - ETA: 7s - loss: 0.9541 - accuracy: 0.74 - ETA: 6s - loss: 0.9530 - accuracy: 0.74 - ETA: 5s - loss: 0.9530 - accuracy: 0.74 - ETA: 4s - loss: 0.9537 - accuracy: 0.74 - ETA: 3s - loss: 0.9553 - accuracy: 0.73 - ETA: 2s - loss: 0.9572 - accuracy: 0.74 - ETA: 1s - loss: 0.9569 - accuracy: 0.73 - 187s 10ms/step - loss: 0.9554 - accuracy: 0.7400 - val_loss: 1.5703 - val_accuracy: 0.7078\n",
      "Epoch 34/100\n",
      "19312/19312 [==============================] - ETA: 2:55 - loss: 0.7440 - accuracy: 0.80 - ETA: 2:48 - loss: 0.8207 - accuracy: 0.78 - ETA: 2:45 - loss: 0.8600 - accuracy: 0.78 - ETA: 2:44 - loss: 0.9284 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8670 - accuracy: 0.78 - ETA: 2:43 - loss: 0.8961 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8931 - accuracy: 0.76 - ETA: 2:43 - loss: 0.9160 - accuracy: 0.76 - ETA: 2:42 - loss: 0.9149 - accuracy: 0.76 - ETA: 2:41 - loss: 0.9463 - accuracy: 0.75 - ETA: 2:39 - loss: 0.9238 - accuracy: 0.75 - ETA: 2:39 - loss: 0.9230 - accuracy: 0.76 - ETA: 2:39 - loss: 0.9180 - accuracy: 0.76 - ETA: 2:38 - loss: 0.9170 - accuracy: 0.76 - ETA: 2:37 - loss: 0.9115 - accuracy: 0.76 - ETA: 2:35 - loss: 0.9033 - accuracy: 0.75 - ETA: 2:34 - loss: 0.9045 - accuracy: 0.76 - ETA: 2:32 - loss: 0.9039 - accuracy: 0.76 - ETA: 2:31 - loss: 0.8989 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8972 - accuracy: 0.75 - ETA: 2:29 - loss: 0.9052 - accuracy: 0.75 - ETA: 2:27 - loss: 0.9147 - accuracy: 0.75 - ETA: 2:27 - loss: 0.9154 - accuracy: 0.75 - ETA: 2:25 - loss: 0.9149 - accuracy: 0.75 - ETA: 2:24 - loss: 0.9093 - accuracy: 0.75 - ETA: 2:23 - loss: 0.9135 - accuracy: 0.75 - ETA: 2:22 - loss: 0.9029 - accuracy: 0.75 - ETA: 2:21 - loss: 0.8961 - accuracy: 0.75 - ETA: 2:19 - loss: 0.8922 - accuracy: 0.75 - ETA: 2:18 - loss: 0.8920 - accuracy: 0.75 - ETA: 2:17 - loss: 0.8858 - accuracy: 0.75 - ETA: 2:16 - loss: 0.8932 - accuracy: 0.75 - ETA: 2:15 - loss: 0.8845 - accuracy: 0.75 - ETA: 2:13 - loss: 0.8766 - accuracy: 0.75 - ETA: 2:12 - loss: 0.8720 - accuracy: 0.75 - ETA: 2:11 - loss: 0.8736 - accuracy: 0.75 - ETA: 2:10 - loss: 0.8688 - accuracy: 0.75 - ETA: 2:08 - loss: 0.8737 - accuracy: 0.75 - ETA: 2:07 - loss: 0.8732 - accuracy: 0.75 - ETA: 2:06 - loss: 0.8697 - accuracy: 0.75 - ETA: 2:05 - loss: 0.8783 - accuracy: 0.75 - ETA: 2:04 - loss: 0.8944 - accuracy: 0.74 - ETA: 2:03 - loss: 0.8980 - accuracy: 0.75 - ETA: 2:02 - loss: 0.9006 - accuracy: 0.74 - ETA: 2:01 - loss: 0.9123 - accuracy: 0.74 - ETA: 1:59 - loss: 0.9145 - accuracy: 0.74 - ETA: 1:58 - loss: 0.9165 - accuracy: 0.74 - ETA: 1:57 - loss: 0.9291 - accuracy: 0.74 - ETA: 1:56 - loss: 0.9267 - accuracy: 0.74 - ETA: 1:55 - loss: 0.9310 - accuracy: 0.74 - ETA: 1:53 - loss: 0.9271 - accuracy: 0.74 - ETA: 1:52 - loss: 0.9275 - accuracy: 0.74 - ETA: 1:51 - loss: 0.9270 - accuracy: 0.74 - ETA: 1:50 - loss: 0.9234 - accuracy: 0.74 - ETA: 1:49 - loss: 0.9237 - accuracy: 0.74 - ETA: 1:48 - loss: 0.9215 - accuracy: 0.74 - ETA: 1:47 - loss: 0.9204 - accuracy: 0.74 - ETA: 1:46 - loss: 0.9206 - accuracy: 0.74 - ETA: 1:45 - loss: 0.9190 - accuracy: 0.74 - ETA: 1:43 - loss: 0.9174 - accuracy: 0.74 - ETA: 1:42 - loss: 0.9182 - accuracy: 0.74 - ETA: 1:41 - loss: 0.9201 - accuracy: 0.74 - ETA: 1:40 - loss: 0.9227 - accuracy: 0.74 - ETA: 1:39 - loss: 0.9217 - accuracy: 0.74 - ETA: 1:37 - loss: 0.9213 - accuracy: 0.74 - ETA: 1:36 - loss: 0.9196 - accuracy: 0.74 - ETA: 1:35 - loss: 0.9242 - accuracy: 0.74 - ETA: 1:34 - loss: 0.9260 - accuracy: 0.74 - ETA: 1:33 - loss: 0.9236 - accuracy: 0.74 - ETA: 1:32 - loss: 0.9267 - accuracy: 0.74 - ETA: 1:31 - loss: 0.9288 - accuracy: 0.74 - ETA: 1:29 - loss: 0.9297 - accuracy: 0.74 - ETA: 1:28 - loss: 0.9283 - accuracy: 0.74 - ETA: 1:27 - loss: 0.9267 - accuracy: 0.74 - ETA: 1:26 - loss: 0.9276 - accuracy: 0.74 - ETA: 1:25 - loss: 0.9258 - accuracy: 0.74 - ETA: 1:24 - loss: 0.9260 - accuracy: 0.74 - ETA: 1:23 - loss: 0.9239 - accuracy: 0.74 - ETA: 1:21 - loss: 0.9226 - accuracy: 0.74 - ETA: 1:20 - loss: 0.9244 - accuracy: 0.74 - ETA: 1:19 - loss: 0.9265 - accuracy: 0.74 - ETA: 1:18 - loss: 0.9238 - accuracy: 0.74 - ETA: 1:17 - loss: 0.9272 - accuracy: 0.74 - ETA: 1:16 - loss: 0.9263 - accuracy: 0.74 - ETA: 1:15 - loss: 0.9267 - accuracy: 0.74 - ETA: 1:14 - loss: 0.9272 - accuracy: 0.74 - ETA: 1:13 - loss: 0.9274 - accuracy: 0.74 - ETA: 1:11 - loss: 0.9263 - accuracy: 0.74 - ETA: 1:10 - loss: 0.9270 - accuracy: 0.74 - ETA: 1:09 - loss: 0.9266 - accuracy: 0.74 - ETA: 1:08 - loss: 0.9251 - accuracy: 0.74 - ETA: 1:07 - loss: 0.9215 - accuracy: 0.74 - ETA: 1:06 - loss: 0.9235 - accuracy: 0.74 - ETA: 1:04 - loss: 0.9259 - accuracy: 0.74 - ETA: 1:03 - loss: 0.9283 - accuracy: 0.74 - ETA: 1:02 - loss: 0.9278 - accuracy: 0.74 - ETA: 1:01 - loss: 0.9239 - accuracy: 0.74 - ETA: 1:00 - loss: 0.9254 - accuracy: 0.74 - ETA: 59s - loss: 0.9263 - accuracy: 0.7438 - ETA: 58s - loss: 0.9283 - accuracy: 0.743 - ETA: 56s - loss: 0.9273 - accuracy: 0.743 - ETA: 55s - loss: 0.9284 - accuracy: 0.742 - ETA: 54s - loss: 0.9320 - accuracy: 0.742 - ETA: 53s - loss: 0.9325 - accuracy: 0.742 - ETA: 52s - loss: 0.9314 - accuracy: 0.741 - ETA: 51s - loss: 0.9306 - accuracy: 0.742 - ETA: 50s - loss: 0.9289 - accuracy: 0.742 - ETA: 48s - loss: 0.9283 - accuracy: 0.742 - ETA: 47s - loss: 0.9286 - accuracy: 0.742 - ETA: 46s - loss: 0.9291 - accuracy: 0.742 - ETA: 45s - loss: 0.9298 - accuracy: 0.741 - ETA: 44s - loss: 0.9309 - accuracy: 0.741 - ETA: 43s - loss: 0.9307 - accuracy: 0.741 - ETA: 42s - loss: 0.9277 - accuracy: 0.742 - ETA: 40s - loss: 0.9266 - accuracy: 0.742 - ETA: 39s - loss: 0.9265 - accuracy: 0.742 - ETA: 38s - loss: 0.9267 - accuracy: 0.742 - ETA: 37s - loss: 0.9291 - accuracy: 0.742 - ETA: 36s - loss: 0.9270 - accuracy: 0.742 - ETA: 35s - loss: 0.9265 - accuracy: 0.742 - ETA: 34s - loss: 0.9231 - accuracy: 0.742 - ETA: 32s - loss: 0.9243 - accuracy: 0.742 - ETA: 31s - loss: 0.9250 - accuracy: 0.743 - ETA: 30s - loss: 0.9295 - accuracy: 0.742 - ETA: 29s - loss: 0.9284 - accuracy: 0.742 - ETA: 28s - loss: 0.9301 - accuracy: 0.742 - ETA: 27s - loss: 0.9315 - accuracy: 0.742 - ETA: 26s - loss: 0.9325 - accuracy: 0.742 - ETA: 25s - loss: 0.9354 - accuracy: 0.741 - ETA: 23s - loss: 0.9355 - accuracy: 0.741 - ETA: 22s - loss: 0.9369 - accuracy: 0.741 - ETA: 21s - loss: 0.9380 - accuracy: 0.741 - ETA: 20s - loss: 0.9375 - accuracy: 0.741 - ETA: 19s - loss: 0.9385 - accuracy: 0.741 - ETA: 18s - loss: 0.9371 - accuracy: 0.741 - ETA: 16s - loss: 0.9387 - accuracy: 0.741 - ETA: 15s - loss: 0.9379 - accuracy: 0.741 - ETA: 14s - loss: 0.9377 - accuracy: 0.741 - ETA: 13s - loss: 0.9361 - accuracy: 0.741 - ETA: 12s - loss: 0.9364 - accuracy: 0.741 - ETA: 11s - loss: 0.9347 - accuracy: 0.742 - ETA: 10s - loss: 0.9358 - accuracy: 0.741 - ETA: 9s - loss: 0.9372 - accuracy: 0.741 - ETA: 7s - loss: 0.9411 - accuracy: 0.74 - ETA: 6s - loss: 0.9412 - accuracy: 0.74 - ETA: 5s - loss: 0.9411 - accuracy: 0.74 - ETA: 4s - loss: 0.9422 - accuracy: 0.74 - ETA: 3s - loss: 0.9412 - accuracy: 0.74 - ETA: 2s - loss: 0.9396 - accuracy: 0.74 - ETA: 0s - loss: 0.9387 - accuracy: 0.74 - 185s 10ms/step - loss: 0.9378 - accuracy: 0.7415 - val_loss: 1.5712 - val_accuracy: 0.7209\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:58 - loss: 0.7503 - accuracy: 0.78 - ETA: 2:49 - loss: 0.9606 - accuracy: 0.74 - ETA: 2:47 - loss: 1.0028 - accuracy: 0.73 - ETA: 2:47 - loss: 0.9998 - accuracy: 0.73 - ETA: 2:52 - loss: 0.9358 - accuracy: 0.75 - ETA: 2:49 - loss: 0.9427 - accuracy: 0.75 - ETA: 2:47 - loss: 0.9226 - accuracy: 0.75 - ETA: 2:45 - loss: 0.8809 - accuracy: 0.75 - ETA: 2:45 - loss: 0.9393 - accuracy: 0.74 - ETA: 2:43 - loss: 0.9565 - accuracy: 0.74 - ETA: 2:41 - loss: 0.9454 - accuracy: 0.74 - ETA: 2:39 - loss: 0.9901 - accuracy: 0.74 - ETA: 2:38 - loss: 0.9928 - accuracy: 0.74 - ETA: 2:36 - loss: 0.9888 - accuracy: 0.74 - ETA: 2:34 - loss: 0.9759 - accuracy: 0.75 - ETA: 2:33 - loss: 0.9894 - accuracy: 0.74 - ETA: 2:31 - loss: 0.9792 - accuracy: 0.74 - ETA: 2:31 - loss: 0.9658 - accuracy: 0.74 - ETA: 2:31 - loss: 0.9623 - accuracy: 0.74 - ETA: 2:29 - loss: 0.9612 - accuracy: 0.74 - ETA: 2:28 - loss: 0.9740 - accuracy: 0.74 - ETA: 2:27 - loss: 0.9639 - accuracy: 0.74 - ETA: 2:26 - loss: 0.9497 - accuracy: 0.74 - ETA: 2:24 - loss: 0.9562 - accuracy: 0.74 - ETA: 2:23 - loss: 0.9662 - accuracy: 0.74 - ETA: 2:21 - loss: 0.9878 - accuracy: 0.74 - ETA: 2:20 - loss: 0.9872 - accuracy: 0.74 - ETA: 2:19 - loss: 0.9866 - accuracy: 0.74 - ETA: 2:18 - loss: 0.9853 - accuracy: 0.74 - ETA: 2:17 - loss: 0.9862 - accuracy: 0.74 - ETA: 2:15 - loss: 1.0008 - accuracy: 0.74 - ETA: 2:15 - loss: 1.0012 - accuracy: 0.73 - ETA: 2:14 - loss: 0.9989 - accuracy: 0.73 - ETA: 2:12 - loss: 0.9941 - accuracy: 0.73 - ETA: 2:11 - loss: 0.9905 - accuracy: 0.73 - ETA: 2:10 - loss: 0.9962 - accuracy: 0.73 - ETA: 2:09 - loss: 0.9926 - accuracy: 0.73 - ETA: 2:08 - loss: 0.9977 - accuracy: 0.73 - ETA: 2:07 - loss: 0.9981 - accuracy: 0.73 - ETA: 2:05 - loss: 0.9936 - accuracy: 0.74 - ETA: 2:04 - loss: 0.9911 - accuracy: 0.74 - ETA: 2:03 - loss: 0.9840 - accuracy: 0.74 - ETA: 2:02 - loss: 0.9840 - accuracy: 0.74 - ETA: 2:01 - loss: 0.9772 - accuracy: 0.74 - ETA: 2:00 - loss: 0.9746 - accuracy: 0.74 - ETA: 1:58 - loss: 0.9793 - accuracy: 0.74 - ETA: 1:57 - loss: 0.9789 - accuracy: 0.74 - ETA: 1:57 - loss: 0.9834 - accuracy: 0.74 - ETA: 1:56 - loss: 0.9811 - accuracy: 0.74 - ETA: 1:54 - loss: 0.9812 - accuracy: 0.74 - ETA: 1:53 - loss: 0.9800 - accuracy: 0.74 - ETA: 1:52 - loss: 0.9794 - accuracy: 0.74 - ETA: 1:51 - loss: 0.9778 - accuracy: 0.74 - ETA: 1:50 - loss: 0.9757 - accuracy: 0.74 - ETA: 1:48 - loss: 0.9757 - accuracy: 0.74 - ETA: 1:47 - loss: 0.9778 - accuracy: 0.74 - ETA: 1:46 - loss: 0.9748 - accuracy: 0.74 - ETA: 1:45 - loss: 0.9719 - accuracy: 0.74 - ETA: 1:44 - loss: 0.9729 - accuracy: 0.74 - ETA: 1:43 - loss: 0.9691 - accuracy: 0.74 - ETA: 1:42 - loss: 0.9670 - accuracy: 0.74 - ETA: 1:41 - loss: 0.9645 - accuracy: 0.74 - ETA: 1:40 - loss: 0.9695 - accuracy: 0.74 - ETA: 1:39 - loss: 0.9689 - accuracy: 0.74 - ETA: 1:37 - loss: 0.9694 - accuracy: 0.74 - ETA: 1:36 - loss: 0.9654 - accuracy: 0.74 - ETA: 1:35 - loss: 0.9629 - accuracy: 0.74 - ETA: 1:34 - loss: 0.9645 - accuracy: 0.74 - ETA: 1:33 - loss: 0.9622 - accuracy: 0.74 - ETA: 1:32 - loss: 0.9713 - accuracy: 0.74 - ETA: 1:30 - loss: 0.9731 - accuracy: 0.74 - ETA: 1:29 - loss: 0.9740 - accuracy: 0.74 - ETA: 1:28 - loss: 0.9779 - accuracy: 0.74 - ETA: 1:27 - loss: 0.9760 - accuracy: 0.74 - ETA: 1:26 - loss: 0.9718 - accuracy: 0.74 - ETA: 1:25 - loss: 0.9689 - accuracy: 0.74 - ETA: 1:24 - loss: 0.9695 - accuracy: 0.74 - ETA: 1:23 - loss: 0.9704 - accuracy: 0.74 - ETA: 1:21 - loss: 0.9691 - accuracy: 0.74 - ETA: 1:20 - loss: 0.9691 - accuracy: 0.74 - ETA: 1:19 - loss: 0.9669 - accuracy: 0.75 - ETA: 1:18 - loss: 0.9643 - accuracy: 0.75 - ETA: 1:17 - loss: 0.9621 - accuracy: 0.75 - ETA: 1:16 - loss: 0.9599 - accuracy: 0.75 - ETA: 1:14 - loss: 0.9615 - accuracy: 0.75 - ETA: 1:13 - loss: 0.9578 - accuracy: 0.75 - ETA: 1:12 - loss: 0.9546 - accuracy: 0.75 - ETA: 1:11 - loss: 0.9541 - accuracy: 0.75 - ETA: 1:10 - loss: 0.9526 - accuracy: 0.75 - ETA: 1:09 - loss: 0.9524 - accuracy: 0.75 - ETA: 1:08 - loss: 0.9555 - accuracy: 0.75 - ETA: 1:07 - loss: 0.9537 - accuracy: 0.75 - ETA: 1:05 - loss: 0.9552 - accuracy: 0.75 - ETA: 1:04 - loss: 0.9531 - accuracy: 0.75 - ETA: 1:03 - loss: 0.9507 - accuracy: 0.75 - ETA: 1:02 - loss: 0.9491 - accuracy: 0.75 - ETA: 1:01 - loss: 0.9499 - accuracy: 0.75 - ETA: 1:00 - loss: 0.9474 - accuracy: 0.75 - ETA: 59s - loss: 0.9497 - accuracy: 0.7511 - ETA: 57s - loss: 0.9501 - accuracy: 0.751 - ETA: 56s - loss: 0.9514 - accuracy: 0.751 - ETA: 55s - loss: 0.9508 - accuracy: 0.751 - ETA: 54s - loss: 0.9512 - accuracy: 0.751 - ETA: 53s - loss: 0.9490 - accuracy: 0.751 - ETA: 52s - loss: 0.9471 - accuracy: 0.751 - ETA: 51s - loss: 0.9480 - accuracy: 0.751 - ETA: 49s - loss: 0.9501 - accuracy: 0.751 - ETA: 48s - loss: 0.9507 - accuracy: 0.751 - ETA: 47s - loss: 0.9486 - accuracy: 0.751 - ETA: 46s - loss: 0.9474 - accuracy: 0.751 - ETA: 45s - loss: 0.9447 - accuracy: 0.751 - ETA: 44s - loss: 0.9436 - accuracy: 0.751 - ETA: 43s - loss: 0.9443 - accuracy: 0.751 - ETA: 42s - loss: 0.9438 - accuracy: 0.751 - ETA: 40s - loss: 0.9440 - accuracy: 0.751 - ETA: 39s - loss: 0.9453 - accuracy: 0.750 - ETA: 38s - loss: 0.9446 - accuracy: 0.750 - ETA: 37s - loss: 0.9451 - accuracy: 0.750 - ETA: 36s - loss: 0.9434 - accuracy: 0.750 - ETA: 35s - loss: 0.9431 - accuracy: 0.750 - ETA: 34s - loss: 0.9399 - accuracy: 0.751 - ETA: 32s - loss: 0.9385 - accuracy: 0.751 - ETA: 31s - loss: 0.9390 - accuracy: 0.751 - ETA: 30s - loss: 0.9374 - accuracy: 0.751 - ETA: 29s - loss: 0.9394 - accuracy: 0.751 - ETA: 28s - loss: 0.9396 - accuracy: 0.750 - ETA: 27s - loss: 0.9387 - accuracy: 0.751 - ETA: 26s - loss: 0.9391 - accuracy: 0.751 - ETA: 24s - loss: 0.9386 - accuracy: 0.751 - ETA: 23s - loss: 0.9360 - accuracy: 0.751 - ETA: 22s - loss: 0.9365 - accuracy: 0.751 - ETA: 21s - loss: 0.9357 - accuracy: 0.751 - ETA: 20s - loss: 0.9355 - accuracy: 0.751 - ETA: 19s - loss: 0.9353 - accuracy: 0.750 - ETA: 18s - loss: 0.9361 - accuracy: 0.750 - ETA: 16s - loss: 0.9381 - accuracy: 0.750 - ETA: 15s - loss: 0.9374 - accuracy: 0.751 - ETA: 14s - loss: 0.9401 - accuracy: 0.751 - ETA: 13s - loss: 0.9392 - accuracy: 0.751 - ETA: 12s - loss: 0.9404 - accuracy: 0.750 - ETA: 11s - loss: 0.9402 - accuracy: 0.750 - ETA: 10s - loss: 0.9404 - accuracy: 0.750 - ETA: 8s - loss: 0.9403 - accuracy: 0.750 - ETA: 7s - loss: 0.9391 - accuracy: 0.75 - ETA: 6s - loss: 0.9407 - accuracy: 0.75 - ETA: 5s - loss: 0.9407 - accuracy: 0.75 - ETA: 4s - loss: 0.9407 - accuracy: 0.75 - ETA: 3s - loss: 0.9397 - accuracy: 0.75 - ETA: 2s - loss: 0.9395 - accuracy: 0.75 - ETA: 0s - loss: 0.9385 - accuracy: 0.75 - 184s 10ms/step - loss: 0.9379 - accuracy: 0.7514 - val_loss: 1.6088 - val_accuracy: 0.7200\n",
      "Epoch 36/100\n",
      "19312/19312 [==============================] - ETA: 2:45 - loss: 1.0634 - accuracy: 0.75 - ETA: 2:45 - loss: 0.9581 - accuracy: 0.77 - ETA: 2:42 - loss: 0.8811 - accuracy: 0.78 - ETA: 2:42 - loss: 0.8368 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8189 - accuracy: 0.77 - ETA: 2:42 - loss: 0.8217 - accuracy: 0.76 - ETA: 2:41 - loss: 0.8328 - accuracy: 0.76 - ETA: 2:39 - loss: 0.7890 - accuracy: 0.76 - ETA: 2:38 - loss: 0.7851 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8161 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8459 - accuracy: 0.75 - ETA: 2:36 - loss: 0.8590 - accuracy: 0.75 - ETA: 2:35 - loss: 0.8576 - accuracy: 0.75 - ETA: 2:34 - loss: 0.8513 - accuracy: 0.76 - ETA: 2:34 - loss: 0.8420 - accuracy: 0.76 - ETA: 2:32 - loss: 0.8371 - accuracy: 0.76 - ETA: 2:31 - loss: 0.8391 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8553 - accuracy: 0.76 - ETA: 2:29 - loss: 0.8627 - accuracy: 0.76 - ETA: 2:27 - loss: 0.8692 - accuracy: 0.76 - ETA: 2:26 - loss: 0.8621 - accuracy: 0.76 - ETA: 2:25 - loss: 0.8615 - accuracy: 0.76 - ETA: 2:24 - loss: 0.8605 - accuracy: 0.76 - ETA: 2:23 - loss: 0.8638 - accuracy: 0.76 - ETA: 2:22 - loss: 0.8599 - accuracy: 0.76 - ETA: 2:21 - loss: 0.8577 - accuracy: 0.76 - ETA: 2:19 - loss: 0.8509 - accuracy: 0.76 - ETA: 2:18 - loss: 0.8546 - accuracy: 0.76 - ETA: 2:17 - loss: 0.8596 - accuracy: 0.76 - ETA: 2:16 - loss: 0.8609 - accuracy: 0.76 - ETA: 2:14 - loss: 0.8535 - accuracy: 0.76 - ETA: 2:14 - loss: 0.8641 - accuracy: 0.75 - ETA: 2:13 - loss: 0.8678 - accuracy: 0.75 - ETA: 2:11 - loss: 0.8662 - accuracy: 0.75 - ETA: 2:10 - loss: 0.8653 - accuracy: 0.75 - ETA: 2:09 - loss: 0.8712 - accuracy: 0.75 - ETA: 2:08 - loss: 0.8774 - accuracy: 0.75 - ETA: 2:07 - loss: 0.8707 - accuracy: 0.76 - ETA: 2:06 - loss: 0.8641 - accuracy: 0.76 - ETA: 2:05 - loss: 0.8801 - accuracy: 0.76 - ETA: 2:04 - loss: 0.8817 - accuracy: 0.76 - ETA: 2:03 - loss: 0.8861 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8839 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8745 - accuracy: 0.76 - ETA: 1:59 - loss: 0.8761 - accuracy: 0.76 - ETA: 1:58 - loss: 0.8689 - accuracy: 0.76 - ETA: 1:57 - loss: 0.8661 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8627 - accuracy: 0.76 - ETA: 1:54 - loss: 0.8645 - accuracy: 0.76 - ETA: 1:53 - loss: 0.8628 - accuracy: 0.76 - ETA: 1:52 - loss: 0.8626 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8617 - accuracy: 0.76 - ETA: 1:52 - loss: 0.8646 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8649 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8591 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8615 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8629 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8593 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8669 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8660 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8683 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8700 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8715 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8707 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8754 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8747 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8781 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8771 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8736 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8700 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8696 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8706 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8702 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8696 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8687 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8679 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8710 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8717 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8723 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8720 - accuracy: 0.76 - ETA: 1:21 - loss: 0.8736 - accuracy: 0.76 - ETA: 1:19 - loss: 0.8750 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8783 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8799 - accuracy: 0.75 - ETA: 1:16 - loss: 0.8792 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8770 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8780 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8756 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8792 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8764 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8797 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8800 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8799 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8794 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8827 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8870 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8845 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8873 - accuracy: 0.76 - ETA: 59s - loss: 0.8874 - accuracy: 0.7622 - ETA: 58s - loss: 0.8885 - accuracy: 0.762 - ETA: 57s - loss: 0.8890 - accuracy: 0.762 - ETA: 56s - loss: 0.8882 - accuracy: 0.762 - ETA: 55s - loss: 0.8881 - accuracy: 0.762 - ETA: 54s - loss: 0.8900 - accuracy: 0.762 - ETA: 52s - loss: 0.8865 - accuracy: 0.762 - ETA: 51s - loss: 0.8845 - accuracy: 0.763 - ETA: 50s - loss: 0.8829 - accuracy: 0.762 - ETA: 49s - loss: 0.8842 - accuracy: 0.762 - ETA: 48s - loss: 0.8834 - accuracy: 0.762 - ETA: 47s - loss: 0.8832 - accuracy: 0.762 - ETA: 46s - loss: 0.8846 - accuracy: 0.762 - ETA: 44s - loss: 0.8838 - accuracy: 0.762 - ETA: 43s - loss: 0.8846 - accuracy: 0.761 - ETA: 42s - loss: 0.8866 - accuracy: 0.761 - ETA: 41s - loss: 0.8841 - accuracy: 0.761 - ETA: 40s - loss: 0.8843 - accuracy: 0.761 - ETA: 39s - loss: 0.8872 - accuracy: 0.761 - ETA: 37s - loss: 0.8858 - accuracy: 0.762 - ETA: 36s - loss: 0.8870 - accuracy: 0.761 - ETA: 35s - loss: 0.8866 - accuracy: 0.761 - ETA: 34s - loss: 0.8865 - accuracy: 0.761 - ETA: 33s - loss: 0.8855 - accuracy: 0.761 - ETA: 32s - loss: 0.8881 - accuracy: 0.761 - ETA: 31s - loss: 0.8886 - accuracy: 0.761 - ETA: 29s - loss: 0.8919 - accuracy: 0.761 - ETA: 28s - loss: 0.8940 - accuracy: 0.761 - ETA: 27s - loss: 0.8939 - accuracy: 0.761 - ETA: 26s - loss: 0.8943 - accuracy: 0.761 - ETA: 25s - loss: 0.8934 - accuracy: 0.761 - ETA: 24s - loss: 0.8906 - accuracy: 0.761 - ETA: 22s - loss: 0.8893 - accuracy: 0.761 - ETA: 21s - loss: 0.8885 - accuracy: 0.761 - ETA: 20s - loss: 0.8866 - accuracy: 0.762 - ETA: 19s - loss: 0.8859 - accuracy: 0.761 - ETA: 18s - loss: 0.8852 - accuracy: 0.761 - ETA: 17s - loss: 0.8854 - accuracy: 0.762 - ETA: 16s - loss: 0.8849 - accuracy: 0.762 - ETA: 14s - loss: 0.8837 - accuracy: 0.762 - ETA: 13s - loss: 0.8828 - accuracy: 0.762 - ETA: 12s - loss: 0.8831 - accuracy: 0.762 - ETA: 11s - loss: 0.8827 - accuracy: 0.762 - ETA: 10s - loss: 0.8817 - accuracy: 0.762 - ETA: 9s - loss: 0.8842 - accuracy: 0.761 - ETA: 7s - loss: 0.8860 - accuracy: 0.76 - ETA: 6s - loss: 0.8871 - accuracy: 0.76 - ETA: 5s - loss: 0.8874 - accuracy: 0.76 - ETA: 4s - loss: 0.8874 - accuracy: 0.76 - ETA: 3s - loss: 0.8871 - accuracy: 0.76 - ETA: 2s - loss: 0.8866 - accuracy: 0.76 - ETA: 1s - loss: 0.8881 - accuracy: 0.76 - 186s 10ms/step - loss: 0.8875 - accuracy: 0.7604 - val_loss: 1.6383 - val_accuracy: 0.7095\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:00 - loss: 1.7500 - accuracy: 0.64 - ETA: 2:52 - loss: 1.3807 - accuracy: 0.67 - ETA: 2:58 - loss: 1.1590 - accuracy: 0.71 - ETA: 2:53 - loss: 1.0829 - accuracy: 0.72 - ETA: 2:51 - loss: 1.1003 - accuracy: 0.72 - ETA: 2:47 - loss: 1.0406 - accuracy: 0.73 - ETA: 2:44 - loss: 1.0185 - accuracy: 0.73 - ETA: 2:42 - loss: 0.9910 - accuracy: 0.73 - ETA: 2:41 - loss: 1.0129 - accuracy: 0.73 - ETA: 2:40 - loss: 1.0028 - accuracy: 0.73 - ETA: 2:39 - loss: 1.0052 - accuracy: 0.73 - ETA: 2:37 - loss: 0.9719 - accuracy: 0.74 - ETA: 2:36 - loss: 0.9696 - accuracy: 0.74 - ETA: 2:35 - loss: 0.9457 - accuracy: 0.74 - ETA: 2:34 - loss: 0.9426 - accuracy: 0.74 - ETA: 2:33 - loss: 0.9496 - accuracy: 0.74 - ETA: 2:32 - loss: 0.9533 - accuracy: 0.74 - ETA: 2:32 - loss: 0.9460 - accuracy: 0.74 - ETA: 2:30 - loss: 0.9552 - accuracy: 0.74 - ETA: 2:29 - loss: 0.9512 - accuracy: 0.74 - ETA: 2:28 - loss: 0.9592 - accuracy: 0.74 - ETA: 2:27 - loss: 0.9515 - accuracy: 0.74 - ETA: 2:26 - loss: 0.9462 - accuracy: 0.74 - ETA: 2:24 - loss: 0.9480 - accuracy: 0.73 - ETA: 2:23 - loss: 0.9346 - accuracy: 0.74 - ETA: 2:22 - loss: 0.9375 - accuracy: 0.74 - ETA: 2:21 - loss: 0.9363 - accuracy: 0.74 - ETA: 2:20 - loss: 0.9271 - accuracy: 0.74 - ETA: 2:19 - loss: 0.9250 - accuracy: 0.74 - ETA: 2:18 - loss: 0.9243 - accuracy: 0.74 - ETA: 2:17 - loss: 0.9220 - accuracy: 0.74 - ETA: 2:16 - loss: 0.9113 - accuracy: 0.75 - ETA: 2:15 - loss: 0.9107 - accuracy: 0.75 - ETA: 2:14 - loss: 0.9153 - accuracy: 0.75 - ETA: 2:12 - loss: 0.9241 - accuracy: 0.74 - ETA: 2:11 - loss: 0.9231 - accuracy: 0.74 - ETA: 2:10 - loss: 0.9168 - accuracy: 0.75 - ETA: 2:09 - loss: 0.9114 - accuracy: 0.75 - ETA: 2:07 - loss: 0.9118 - accuracy: 0.75 - ETA: 2:06 - loss: 0.9133 - accuracy: 0.75 - ETA: 2:05 - loss: 0.9069 - accuracy: 0.75 - ETA: 2:04 - loss: 0.9041 - accuracy: 0.75 - ETA: 2:02 - loss: 0.8990 - accuracy: 0.75 - ETA: 2:01 - loss: 0.8943 - accuracy: 0.75 - ETA: 2:00 - loss: 0.8883 - accuracy: 0.75 - ETA: 1:59 - loss: 0.8992 - accuracy: 0.75 - ETA: 1:58 - loss: 0.8965 - accuracy: 0.75 - ETA: 1:57 - loss: 0.9015 - accuracy: 0.75 - ETA: 1:56 - loss: 0.9031 - accuracy: 0.75 - ETA: 1:55 - loss: 0.9076 - accuracy: 0.75 - ETA: 1:54 - loss: 0.9137 - accuracy: 0.75 - ETA: 1:52 - loss: 0.9137 - accuracy: 0.75 - ETA: 1:51 - loss: 0.9104 - accuracy: 0.75 - ETA: 1:50 - loss: 0.9136 - accuracy: 0.75 - ETA: 1:49 - loss: 0.9171 - accuracy: 0.75 - ETA: 1:48 - loss: 0.9187 - accuracy: 0.75 - ETA: 1:46 - loss: 0.9181 - accuracy: 0.75 - ETA: 1:45 - loss: 0.9128 - accuracy: 0.75 - ETA: 1:44 - loss: 0.9173 - accuracy: 0.75 - ETA: 1:43 - loss: 0.9171 - accuracy: 0.75 - ETA: 1:42 - loss: 0.9222 - accuracy: 0.75 - ETA: 1:41 - loss: 0.9194 - accuracy: 0.75 - ETA: 1:40 - loss: 0.9201 - accuracy: 0.75 - ETA: 1:39 - loss: 0.9169 - accuracy: 0.75 - ETA: 1:38 - loss: 0.9164 - accuracy: 0.75 - ETA: 1:36 - loss: 0.9171 - accuracy: 0.75 - ETA: 1:35 - loss: 0.9171 - accuracy: 0.75 - ETA: 1:34 - loss: 0.9205 - accuracy: 0.75 - ETA: 1:33 - loss: 0.9171 - accuracy: 0.75 - ETA: 1:32 - loss: 0.9126 - accuracy: 0.75 - ETA: 1:31 - loss: 0.9111 - accuracy: 0.75 - ETA: 1:29 - loss: 0.9103 - accuracy: 0.75 - ETA: 1:28 - loss: 0.9092 - accuracy: 0.75 - ETA: 1:27 - loss: 0.9070 - accuracy: 0.75 - ETA: 1:26 - loss: 0.9074 - accuracy: 0.75 - ETA: 1:25 - loss: 0.9052 - accuracy: 0.75 - ETA: 1:24 - loss: 0.9074 - accuracy: 0.75 - ETA: 1:23 - loss: 0.9057 - accuracy: 0.75 - ETA: 1:21 - loss: 0.9062 - accuracy: 0.75 - ETA: 1:20 - loss: 0.9051 - accuracy: 0.75 - ETA: 1:19 - loss: 0.9047 - accuracy: 0.75 - ETA: 1:18 - loss: 0.9023 - accuracy: 0.75 - ETA: 1:17 - loss: 0.9034 - accuracy: 0.75 - ETA: 1:16 - loss: 0.9022 - accuracy: 0.75 - ETA: 1:15 - loss: 0.9003 - accuracy: 0.75 - ETA: 1:13 - loss: 0.9034 - accuracy: 0.75 - ETA: 1:12 - loss: 0.9038 - accuracy: 0.75 - ETA: 1:11 - loss: 0.9026 - accuracy: 0.75 - ETA: 1:10 - loss: 0.9030 - accuracy: 0.75 - ETA: 1:09 - loss: 0.9079 - accuracy: 0.75 - ETA: 1:08 - loss: 0.9156 - accuracy: 0.75 - ETA: 1:07 - loss: 0.9172 - accuracy: 0.75 - ETA: 1:06 - loss: 0.9143 - accuracy: 0.75 - ETA: 1:04 - loss: 0.9147 - accuracy: 0.75 - ETA: 1:03 - loss: 0.9135 - accuracy: 0.75 - ETA: 1:02 - loss: 0.9109 - accuracy: 0.75 - ETA: 1:01 - loss: 0.9109 - accuracy: 0.75 - ETA: 1:00 - loss: 0.9118 - accuracy: 0.75 - ETA: 59s - loss: 0.9116 - accuracy: 0.7573 - ETA: 57s - loss: 0.9137 - accuracy: 0.757 - ETA: 56s - loss: 0.9131 - accuracy: 0.756 - ETA: 56s - loss: 0.9126 - accuracy: 0.756 - ETA: 55s - loss: 0.9099 - accuracy: 0.756 - ETA: 53s - loss: 0.9077 - accuracy: 0.757 - ETA: 52s - loss: 0.9052 - accuracy: 0.757 - ETA: 51s - loss: 0.9038 - accuracy: 0.758 - ETA: 50s - loss: 0.9019 - accuracy: 0.758 - ETA: 49s - loss: 0.8989 - accuracy: 0.759 - ETA: 48s - loss: 0.8970 - accuracy: 0.759 - ETA: 47s - loss: 0.8986 - accuracy: 0.758 - ETA: 45s - loss: 0.8962 - accuracy: 0.759 - ETA: 44s - loss: 0.8962 - accuracy: 0.759 - ETA: 43s - loss: 0.8953 - accuracy: 0.759 - ETA: 42s - loss: 0.8961 - accuracy: 0.759 - ETA: 41s - loss: 0.8937 - accuracy: 0.759 - ETA: 40s - loss: 0.8946 - accuracy: 0.759 - ETA: 39s - loss: 0.8974 - accuracy: 0.759 - ETA: 37s - loss: 0.8974 - accuracy: 0.759 - ETA: 36s - loss: 0.8977 - accuracy: 0.758 - ETA: 35s - loss: 0.8979 - accuracy: 0.758 - ETA: 34s - loss: 0.8968 - accuracy: 0.759 - ETA: 33s - loss: 0.8994 - accuracy: 0.759 - ETA: 32s - loss: 0.8987 - accuracy: 0.759 - ETA: 30s - loss: 0.8983 - accuracy: 0.758 - ETA: 29s - loss: 0.8973 - accuracy: 0.759 - ETA: 28s - loss: 0.8967 - accuracy: 0.759 - ETA: 27s - loss: 0.8981 - accuracy: 0.759 - ETA: 26s - loss: 0.8980 - accuracy: 0.758 - ETA: 25s - loss: 0.8983 - accuracy: 0.758 - ETA: 24s - loss: 0.8986 - accuracy: 0.758 - ETA: 22s - loss: 0.8988 - accuracy: 0.758 - ETA: 21s - loss: 0.9000 - accuracy: 0.758 - ETA: 20s - loss: 0.9001 - accuracy: 0.758 - ETA: 19s - loss: 0.9000 - accuracy: 0.758 - ETA: 18s - loss: 0.9000 - accuracy: 0.758 - ETA: 17s - loss: 0.8991 - accuracy: 0.758 - ETA: 15s - loss: 0.8997 - accuracy: 0.758 - ETA: 14s - loss: 0.9001 - accuracy: 0.758 - ETA: 13s - loss: 0.9027 - accuracy: 0.758 - ETA: 12s - loss: 0.9018 - accuracy: 0.758 - ETA: 11s - loss: 0.9039 - accuracy: 0.757 - ETA: 10s - loss: 0.9024 - accuracy: 0.758 - ETA: 9s - loss: 0.9038 - accuracy: 0.757 - ETA: 7s - loss: 0.9048 - accuracy: 0.75 - ETA: 6s - loss: 0.9062 - accuracy: 0.75 - ETA: 5s - loss: 0.9056 - accuracy: 0.75 - ETA: 4s - loss: 0.9090 - accuracy: 0.75 - ETA: 3s - loss: 0.9099 - accuracy: 0.75 - ETA: 2s - loss: 0.9079 - accuracy: 0.75 - ETA: 1s - loss: 0.9089 - accuracy: 0.75 - 186s 10ms/step - loss: 0.9091 - accuracy: 0.7563 - val_loss: 1.5321 - val_accuracy: 0.7171\n",
      "Epoch 38/100\n",
      "19312/19312 [==============================] - ETA: 2:55 - loss: 1.0729 - accuracy: 0.72 - ETA: 2:54 - loss: 1.2702 - accuracy: 0.71 - ETA: 2:49 - loss: 1.1143 - accuracy: 0.72 - ETA: 2:49 - loss: 1.0328 - accuracy: 0.73 - ETA: 2:48 - loss: 0.9817 - accuracy: 0.74 - ETA: 2:46 - loss: 1.0082 - accuracy: 0.73 - ETA: 2:45 - loss: 0.9657 - accuracy: 0.74 - ETA: 2:45 - loss: 0.9436 - accuracy: 0.75 - ETA: 2:45 - loss: 0.9461 - accuracy: 0.74 - ETA: 2:43 - loss: 0.9496 - accuracy: 0.75 - ETA: 2:41 - loss: 0.9711 - accuracy: 0.75 - ETA: 2:40 - loss: 0.9625 - accuracy: 0.75 - ETA: 2:38 - loss: 0.9471 - accuracy: 0.76 - ETA: 2:36 - loss: 0.9557 - accuracy: 0.75 - ETA: 2:35 - loss: 0.9506 - accuracy: 0.75 - ETA: 2:34 - loss: 0.9754 - accuracy: 0.75 - ETA: 2:32 - loss: 1.0006 - accuracy: 0.74 - ETA: 2:31 - loss: 0.9865 - accuracy: 0.75 - ETA: 2:29 - loss: 0.9744 - accuracy: 0.75 - ETA: 2:28 - loss: 0.9637 - accuracy: 0.75 - ETA: 2:27 - loss: 0.9523 - accuracy: 0.75 - ETA: 2:26 - loss: 0.9707 - accuracy: 0.75 - ETA: 2:25 - loss: 0.9595 - accuracy: 0.75 - ETA: 2:24 - loss: 0.9519 - accuracy: 0.75 - ETA: 2:23 - loss: 0.9525 - accuracy: 0.75 - ETA: 2:22 - loss: 0.9500 - accuracy: 0.75 - ETA: 2:21 - loss: 0.9535 - accuracy: 0.74 - ETA: 2:20 - loss: 0.9516 - accuracy: 0.74 - ETA: 2:18 - loss: 0.9472 - accuracy: 0.74 - ETA: 2:17 - loss: 0.9458 - accuracy: 0.74 - ETA: 2:16 - loss: 0.9391 - accuracy: 0.75 - ETA: 2:15 - loss: 0.9335 - accuracy: 0.75 - ETA: 2:14 - loss: 0.9331 - accuracy: 0.75 - ETA: 2:12 - loss: 0.9382 - accuracy: 0.75 - ETA: 2:11 - loss: 0.9374 - accuracy: 0.75 - ETA: 2:10 - loss: 0.9344 - accuracy: 0.75 - ETA: 2:09 - loss: 0.9346 - accuracy: 0.75 - ETA: 2:08 - loss: 0.9311 - accuracy: 0.75 - ETA: 2:07 - loss: 0.9286 - accuracy: 0.75 - ETA: 2:06 - loss: 0.9212 - accuracy: 0.75 - ETA: 2:05 - loss: 0.9161 - accuracy: 0.75 - ETA: 2:05 - loss: 0.9133 - accuracy: 0.75 - ETA: 2:04 - loss: 0.9179 - accuracy: 0.75 - ETA: 2:03 - loss: 0.9115 - accuracy: 0.75 - ETA: 2:01 - loss: 0.9107 - accuracy: 0.75 - ETA: 2:00 - loss: 0.9118 - accuracy: 0.75 - ETA: 1:59 - loss: 0.9115 - accuracy: 0.75 - ETA: 1:58 - loss: 0.9144 - accuracy: 0.75 - ETA: 1:57 - loss: 0.9139 - accuracy: 0.75 - ETA: 1:56 - loss: 0.9126 - accuracy: 0.75 - ETA: 1:55 - loss: 0.9134 - accuracy: 0.75 - ETA: 1:54 - loss: 0.9156 - accuracy: 0.75 - ETA: 1:52 - loss: 0.9114 - accuracy: 0.75 - ETA: 1:51 - loss: 0.9102 - accuracy: 0.75 - ETA: 1:50 - loss: 0.9099 - accuracy: 0.75 - ETA: 1:49 - loss: 0.9154 - accuracy: 0.75 - ETA: 1:48 - loss: 0.9134 - accuracy: 0.75 - ETA: 1:48 - loss: 0.9101 - accuracy: 0.75 - ETA: 1:47 - loss: 0.9083 - accuracy: 0.75 - ETA: 1:45 - loss: 0.9037 - accuracy: 0.75 - ETA: 1:44 - loss: 0.9034 - accuracy: 0.75 - ETA: 1:43 - loss: 0.9005 - accuracy: 0.75 - ETA: 1:42 - loss: 0.8998 - accuracy: 0.75 - ETA: 1:41 - loss: 0.8960 - accuracy: 0.75 - ETA: 1:40 - loss: 0.8996 - accuracy: 0.75 - ETA: 1:39 - loss: 0.9009 - accuracy: 0.75 - ETA: 1:38 - loss: 0.8991 - accuracy: 0.75 - ETA: 1:37 - loss: 0.8987 - accuracy: 0.75 - ETA: 1:35 - loss: 0.8982 - accuracy: 0.75 - ETA: 1:34 - loss: 0.8977 - accuracy: 0.75 - ETA: 1:33 - loss: 0.8959 - accuracy: 0.75 - ETA: 1:32 - loss: 0.8984 - accuracy: 0.75 - ETA: 1:31 - loss: 0.9010 - accuracy: 0.75 - ETA: 1:29 - loss: 0.8972 - accuracy: 0.75 - ETA: 1:28 - loss: 0.9029 - accuracy: 0.75 - ETA: 1:27 - loss: 0.9019 - accuracy: 0.75 - ETA: 1:26 - loss: 0.9013 - accuracy: 0.75 - ETA: 1:25 - loss: 0.9032 - accuracy: 0.75 - ETA: 1:24 - loss: 0.9032 - accuracy: 0.75 - ETA: 1:22 - loss: 0.9026 - accuracy: 0.75 - ETA: 1:21 - loss: 0.9010 - accuracy: 0.75 - ETA: 1:20 - loss: 0.9024 - accuracy: 0.75 - ETA: 1:19 - loss: 0.9014 - accuracy: 0.75 - ETA: 1:18 - loss: 0.9034 - accuracy: 0.75 - ETA: 1:16 - loss: 0.9052 - accuracy: 0.75 - ETA: 1:15 - loss: 0.9036 - accuracy: 0.75 - ETA: 1:14 - loss: 0.9045 - accuracy: 0.75 - ETA: 1:13 - loss: 0.9042 - accuracy: 0.75 - ETA: 1:11 - loss: 0.9030 - accuracy: 0.75 - ETA: 1:10 - loss: 0.9004 - accuracy: 0.75 - ETA: 1:09 - loss: 0.9009 - accuracy: 0.75 - ETA: 1:08 - loss: 0.8989 - accuracy: 0.75 - ETA: 1:07 - loss: 0.8990 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8989 - accuracy: 0.75 - ETA: 1:05 - loss: 0.8989 - accuracy: 0.75 - ETA: 1:03 - loss: 0.9013 - accuracy: 0.75 - ETA: 1:02 - loss: 0.9058 - accuracy: 0.75 - ETA: 1:01 - loss: 0.9049 - accuracy: 0.75 - ETA: 1:00 - loss: 0.9016 - accuracy: 0.75 - ETA: 59s - loss: 0.9005 - accuracy: 0.7567 - ETA: 57s - loss: 0.9033 - accuracy: 0.756 - ETA: 56s - loss: 0.9029 - accuracy: 0.755 - ETA: 55s - loss: 0.9016 - accuracy: 0.756 - ETA: 54s - loss: 0.9021 - accuracy: 0.756 - ETA: 53s - loss: 0.9025 - accuracy: 0.756 - ETA: 52s - loss: 0.9046 - accuracy: 0.756 - ETA: 51s - loss: 0.9034 - accuracy: 0.756 - ETA: 49s - loss: 0.9080 - accuracy: 0.755 - ETA: 48s - loss: 0.9072 - accuracy: 0.755 - ETA: 47s - loss: 0.9062 - accuracy: 0.755 - ETA: 46s - loss: 0.9074 - accuracy: 0.755 - ETA: 45s - loss: 0.9062 - accuracy: 0.755 - ETA: 43s - loss: 0.9054 - accuracy: 0.756 - ETA: 42s - loss: 0.9036 - accuracy: 0.756 - ETA: 41s - loss: 0.9043 - accuracy: 0.755 - ETA: 40s - loss: 0.9047 - accuracy: 0.755 - ETA: 39s - loss: 0.9048 - accuracy: 0.755 - ETA: 38s - loss: 0.9040 - accuracy: 0.755 - ETA: 37s - loss: 0.9009 - accuracy: 0.756 - ETA: 35s - loss: 0.9018 - accuracy: 0.756 - ETA: 34s - loss: 0.9053 - accuracy: 0.756 - ETA: 33s - loss: 0.9058 - accuracy: 0.756 - ETA: 32s - loss: 0.9053 - accuracy: 0.756 - ETA: 31s - loss: 0.9064 - accuracy: 0.756 - ETA: 30s - loss: 0.9062 - accuracy: 0.755 - ETA: 28s - loss: 0.9099 - accuracy: 0.755 - ETA: 27s - loss: 0.9104 - accuracy: 0.755 - ETA: 26s - loss: 0.9095 - accuracy: 0.755 - ETA: 25s - loss: 0.9096 - accuracy: 0.754 - ETA: 24s - loss: 0.9132 - accuracy: 0.754 - ETA: 23s - loss: 0.9117 - accuracy: 0.754 - ETA: 21s - loss: 0.9115 - accuracy: 0.754 - ETA: 20s - loss: 0.9107 - accuracy: 0.754 - ETA: 19s - loss: 0.9110 - accuracy: 0.754 - ETA: 18s - loss: 0.9101 - accuracy: 0.755 - ETA: 17s - loss: 0.9110 - accuracy: 0.754 - ETA: 16s - loss: 0.9115 - accuracy: 0.754 - ETA: 14s - loss: 0.9107 - accuracy: 0.754 - ETA: 13s - loss: 0.9106 - accuracy: 0.754 - ETA: 12s - loss: 0.9101 - accuracy: 0.754 - ETA: 11s - loss: 0.9084 - accuracy: 0.755 - ETA: 10s - loss: 0.9083 - accuracy: 0.755 - ETA: 9s - loss: 0.9055 - accuracy: 0.756 - ETA: 7s - loss: 0.9043 - accuracy: 0.75 - ETA: 6s - loss: 0.9072 - accuracy: 0.75 - ETA: 5s - loss: 0.9065 - accuracy: 0.75 - ETA: 4s - loss: 0.9070 - accuracy: 0.75 - ETA: 3s - loss: 0.9106 - accuracy: 0.75 - ETA: 2s - loss: 0.9090 - accuracy: 0.75 - ETA: 1s - loss: 0.9090 - accuracy: 0.75 - 188s 10ms/step - loss: 0.9084 - accuracy: 0.7566 - val_loss: 1.6402 - val_accuracy: 0.7119\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:50 - loss: 1.8929 - accuracy: 0.68 - ETA: 2:43 - loss: 1.1522 - accuracy: 0.77 - ETA: 2:42 - loss: 1.0109 - accuracy: 0.77 - ETA: 2:42 - loss: 0.9814 - accuracy: 0.76 - ETA: 2:41 - loss: 1.0237 - accuracy: 0.73 - ETA: 2:40 - loss: 0.9788 - accuracy: 0.74 - ETA: 2:40 - loss: 0.9677 - accuracy: 0.74 - ETA: 2:40 - loss: 0.9778 - accuracy: 0.75 - ETA: 2:39 - loss: 0.9802 - accuracy: 0.75 - ETA: 2:39 - loss: 0.9528 - accuracy: 0.76 - ETA: 2:39 - loss: 0.9681 - accuracy: 0.75 - ETA: 2:40 - loss: 0.9927 - accuracy: 0.75 - ETA: 2:39 - loss: 0.9809 - accuracy: 0.75 - ETA: 2:38 - loss: 0.9846 - accuracy: 0.75 - ETA: 2:36 - loss: 0.9951 - accuracy: 0.75 - ETA: 2:35 - loss: 0.9860 - accuracy: 0.74 - ETA: 2:34 - loss: 0.9857 - accuracy: 0.74 - ETA: 2:32 - loss: 0.9701 - accuracy: 0.74 - ETA: 2:31 - loss: 0.9562 - accuracy: 0.74 - ETA: 2:29 - loss: 0.9492 - accuracy: 0.74 - ETA: 2:28 - loss: 0.9445 - accuracy: 0.74 - ETA: 2:27 - loss: 0.9871 - accuracy: 0.74 - ETA: 2:25 - loss: 0.9734 - accuracy: 0.74 - ETA: 2:24 - loss: 0.9561 - accuracy: 0.74 - ETA: 2:24 - loss: 0.9584 - accuracy: 0.74 - ETA: 2:23 - loss: 0.9791 - accuracy: 0.74 - ETA: 2:22 - loss: 0.9715 - accuracy: 0.74 - ETA: 2:21 - loss: 0.9632 - accuracy: 0.74 - ETA: 2:19 - loss: 0.9576 - accuracy: 0.74 - ETA: 2:18 - loss: 0.9525 - accuracy: 0.75 - ETA: 2:17 - loss: 0.9432 - accuracy: 0.75 - ETA: 2:16 - loss: 0.9447 - accuracy: 0.75 - ETA: 2:14 - loss: 0.9449 - accuracy: 0.75 - ETA: 2:13 - loss: 0.9349 - accuracy: 0.75 - ETA: 2:12 - loss: 0.9344 - accuracy: 0.75 - ETA: 2:11 - loss: 0.9287 - accuracy: 0.75 - ETA: 2:10 - loss: 0.9394 - accuracy: 0.75 - ETA: 2:09 - loss: 0.9348 - accuracy: 0.75 - ETA: 2:08 - loss: 0.9316 - accuracy: 0.75 - ETA: 2:07 - loss: 0.9302 - accuracy: 0.75 - ETA: 2:06 - loss: 0.9278 - accuracy: 0.75 - ETA: 2:04 - loss: 0.9334 - accuracy: 0.75 - ETA: 2:03 - loss: 0.9424 - accuracy: 0.75 - ETA: 2:02 - loss: 0.9439 - accuracy: 0.75 - ETA: 2:01 - loss: 0.9410 - accuracy: 0.75 - ETA: 2:00 - loss: 0.9371 - accuracy: 0.75 - ETA: 1:58 - loss: 0.9429 - accuracy: 0.75 - ETA: 1:57 - loss: 0.9448 - accuracy: 0.75 - ETA: 1:56 - loss: 0.9491 - accuracy: 0.75 - ETA: 1:55 - loss: 0.9514 - accuracy: 0.75 - ETA: 1:53 - loss: 0.9464 - accuracy: 0.75 - ETA: 1:52 - loss: 0.9465 - accuracy: 0.75 - ETA: 1:51 - loss: 0.9443 - accuracy: 0.75 - ETA: 1:50 - loss: 0.9478 - accuracy: 0.75 - ETA: 1:49 - loss: 0.9500 - accuracy: 0.75 - ETA: 1:48 - loss: 0.9436 - accuracy: 0.75 - ETA: 1:47 - loss: 0.9399 - accuracy: 0.75 - ETA: 1:45 - loss: 0.9400 - accuracy: 0.75 - ETA: 1:44 - loss: 0.9397 - accuracy: 0.75 - ETA: 1:43 - loss: 0.9372 - accuracy: 0.75 - ETA: 1:42 - loss: 0.9388 - accuracy: 0.75 - ETA: 1:41 - loss: 0.9451 - accuracy: 0.75 - ETA: 1:40 - loss: 0.9419 - accuracy: 0.75 - ETA: 1:39 - loss: 0.9404 - accuracy: 0.75 - ETA: 1:37 - loss: 0.9429 - accuracy: 0.74 - ETA: 1:36 - loss: 0.9433 - accuracy: 0.74 - ETA: 1:35 - loss: 0.9413 - accuracy: 0.74 - ETA: 1:34 - loss: 0.9398 - accuracy: 0.74 - ETA: 1:33 - loss: 0.9378 - accuracy: 0.74 - ETA: 1:32 - loss: 0.9392 - accuracy: 0.74 - ETA: 1:31 - loss: 0.9390 - accuracy: 0.74 - ETA: 1:30 - loss: 0.9485 - accuracy: 0.74 - ETA: 1:28 - loss: 0.9496 - accuracy: 0.75 - ETA: 1:27 - loss: 0.9481 - accuracy: 0.75 - ETA: 1:26 - loss: 0.9466 - accuracy: 0.75 - ETA: 1:25 - loss: 0.9435 - accuracy: 0.75 - ETA: 1:24 - loss: 0.9414 - accuracy: 0.75 - ETA: 1:22 - loss: 0.9400 - accuracy: 0.75 - ETA: 1:21 - loss: 0.9394 - accuracy: 0.75 - ETA: 1:20 - loss: 0.9375 - accuracy: 0.75 - ETA: 1:19 - loss: 0.9375 - accuracy: 0.75 - ETA: 1:18 - loss: 0.9348 - accuracy: 0.75 - ETA: 1:17 - loss: 0.9325 - accuracy: 0.75 - ETA: 1:16 - loss: 0.9268 - accuracy: 0.75 - ETA: 1:14 - loss: 0.9279 - accuracy: 0.75 - ETA: 1:13 - loss: 0.9270 - accuracy: 0.75 - ETA: 1:12 - loss: 0.9330 - accuracy: 0.75 - ETA: 1:11 - loss: 0.9317 - accuracy: 0.75 - ETA: 1:10 - loss: 0.9348 - accuracy: 0.75 - ETA: 1:09 - loss: 0.9397 - accuracy: 0.75 - ETA: 1:08 - loss: 0.9386 - accuracy: 0.75 - ETA: 1:07 - loss: 0.9345 - accuracy: 0.75 - ETA: 1:05 - loss: 0.9335 - accuracy: 0.75 - ETA: 1:04 - loss: 0.9360 - accuracy: 0.75 - ETA: 1:03 - loss: 0.9361 - accuracy: 0.75 - ETA: 1:02 - loss: 0.9370 - accuracy: 0.75 - ETA: 1:01 - loss: 0.9385 - accuracy: 0.75 - ETA: 1:00 - loss: 0.9404 - accuracy: 0.75 - ETA: 59s - loss: 0.9365 - accuracy: 0.7525 - ETA: 58s - loss: 0.9359 - accuracy: 0.752 - ETA: 56s - loss: 0.9353 - accuracy: 0.752 - ETA: 55s - loss: 0.9397 - accuracy: 0.750 - ETA: 54s - loss: 0.9373 - accuracy: 0.750 - ETA: 53s - loss: 0.9350 - accuracy: 0.751 - ETA: 52s - loss: 0.9359 - accuracy: 0.751 - ETA: 51s - loss: 0.9351 - accuracy: 0.751 - ETA: 50s - loss: 0.9374 - accuracy: 0.751 - ETA: 48s - loss: 0.9362 - accuracy: 0.751 - ETA: 47s - loss: 0.9344 - accuracy: 0.751 - ETA: 46s - loss: 0.9332 - accuracy: 0.751 - ETA: 45s - loss: 0.9363 - accuracy: 0.751 - ETA: 44s - loss: 0.9395 - accuracy: 0.750 - ETA: 43s - loss: 0.9378 - accuracy: 0.750 - ETA: 42s - loss: 0.9395 - accuracy: 0.750 - ETA: 40s - loss: 0.9390 - accuracy: 0.751 - ETA: 39s - loss: 0.9373 - accuracy: 0.751 - ETA: 38s - loss: 0.9365 - accuracy: 0.751 - ETA: 37s - loss: 0.9366 - accuracy: 0.751 - ETA: 36s - loss: 0.9365 - accuracy: 0.751 - ETA: 35s - loss: 0.9358 - accuracy: 0.751 - ETA: 34s - loss: 0.9337 - accuracy: 0.751 - ETA: 32s - loss: 0.9335 - accuracy: 0.751 - ETA: 31s - loss: 0.9309 - accuracy: 0.752 - ETA: 30s - loss: 0.9313 - accuracy: 0.752 - ETA: 29s - loss: 0.9319 - accuracy: 0.752 - ETA: 28s - loss: 0.9309 - accuracy: 0.752 - ETA: 27s - loss: 0.9324 - accuracy: 0.752 - ETA: 26s - loss: 0.9337 - accuracy: 0.752 - ETA: 24s - loss: 0.9335 - accuracy: 0.751 - ETA: 23s - loss: 0.9321 - accuracy: 0.752 - ETA: 22s - loss: 0.9314 - accuracy: 0.752 - ETA: 21s - loss: 0.9333 - accuracy: 0.751 - ETA: 20s - loss: 0.9305 - accuracy: 0.752 - ETA: 19s - loss: 0.9290 - accuracy: 0.752 - ETA: 18s - loss: 0.9279 - accuracy: 0.752 - ETA: 16s - loss: 0.9260 - accuracy: 0.752 - ETA: 15s - loss: 0.9258 - accuracy: 0.752 - ETA: 14s - loss: 0.9239 - accuracy: 0.752 - ETA: 13s - loss: 0.9226 - accuracy: 0.753 - ETA: 12s - loss: 0.9243 - accuracy: 0.753 - ETA: 11s - loss: 0.9254 - accuracy: 0.752 - ETA: 10s - loss: 0.9274 - accuracy: 0.753 - ETA: 8s - loss: 0.9282 - accuracy: 0.752 - ETA: 7s - loss: 0.9258 - accuracy: 0.75 - ETA: 6s - loss: 0.9251 - accuracy: 0.75 - ETA: 5s - loss: 0.9261 - accuracy: 0.75 - ETA: 4s - loss: 0.9255 - accuracy: 0.75 - ETA: 3s - loss: 0.9263 - accuracy: 0.75 - ETA: 2s - loss: 0.9254 - accuracy: 0.75 - ETA: 0s - loss: 0.9246 - accuracy: 0.75 - 184s 10ms/step - loss: 0.9248 - accuracy: 0.7533 - val_loss: 1.5845 - val_accuracy: 0.7229\n",
      "Epoch 40/100\n",
      "19312/19312 [==============================] - ETA: 2:45 - loss: 1.0520 - accuracy: 0.72 - ETA: 2:51 - loss: 0.9704 - accuracy: 0.72 - ETA: 2:52 - loss: 0.8966 - accuracy: 0.73 - ETA: 2:53 - loss: 0.8643 - accuracy: 0.74 - ETA: 2:53 - loss: 0.7958 - accuracy: 0.76 - ETA: 2:53 - loss: 0.8342 - accuracy: 0.76 - ETA: 2:51 - loss: 0.8319 - accuracy: 0.76 - ETA: 2:49 - loss: 0.8371 - accuracy: 0.76 - ETA: 2:46 - loss: 0.8109 - accuracy: 0.76 - ETA: 2:45 - loss: 0.7849 - accuracy: 0.76 - ETA: 2:44 - loss: 0.7783 - accuracy: 0.76 - ETA: 2:42 - loss: 0.7806 - accuracy: 0.76 - ETA: 2:40 - loss: 0.8005 - accuracy: 0.76 - ETA: 2:39 - loss: 0.8337 - accuracy: 0.75 - ETA: 2:38 - loss: 0.8358 - accuracy: 0.75 - ETA: 2:37 - loss: 0.8625 - accuracy: 0.75 - ETA: 2:36 - loss: 0.8775 - accuracy: 0.75 - ETA: 2:35 - loss: 0.8707 - accuracy: 0.75 - ETA: 2:34 - loss: 0.8693 - accuracy: 0.75 - ETA: 2:33 - loss: 0.8764 - accuracy: 0.75 - ETA: 2:31 - loss: 0.8820 - accuracy: 0.75 - ETA: 2:30 - loss: 0.8881 - accuracy: 0.75 - ETA: 2:28 - loss: 0.8788 - accuracy: 0.76 - ETA: 2:27 - loss: 0.8736 - accuracy: 0.76 - ETA: 2:25 - loss: 0.8813 - accuracy: 0.76 - ETA: 2:24 - loss: 0.8896 - accuracy: 0.76 - ETA: 2:22 - loss: 0.8911 - accuracy: 0.76 - ETA: 2:21 - loss: 0.8811 - accuracy: 0.76 - ETA: 2:20 - loss: 0.8823 - accuracy: 0.76 - ETA: 2:18 - loss: 0.8780 - accuracy: 0.76 - ETA: 2:17 - loss: 0.8891 - accuracy: 0.76 - ETA: 2:16 - loss: 0.8900 - accuracy: 0.76 - ETA: 2:16 - loss: 0.8891 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8896 - accuracy: 0.76 - ETA: 2:13 - loss: 0.8838 - accuracy: 0.76 - ETA: 2:12 - loss: 0.8904 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8937 - accuracy: 0.76 - ETA: 2:10 - loss: 0.8995 - accuracy: 0.75 - ETA: 2:09 - loss: 0.9056 - accuracy: 0.75 - ETA: 2:07 - loss: 0.9042 - accuracy: 0.75 - ETA: 2:06 - loss: 0.9065 - accuracy: 0.75 - ETA: 2:05 - loss: 0.8963 - accuracy: 0.75 - ETA: 2:04 - loss: 0.8948 - accuracy: 0.75 - ETA: 2:02 - loss: 0.8933 - accuracy: 0.75 - ETA: 2:01 - loss: 0.8934 - accuracy: 0.75 - ETA: 2:00 - loss: 0.8982 - accuracy: 0.75 - ETA: 1:59 - loss: 0.9006 - accuracy: 0.75 - ETA: 1:58 - loss: 0.9141 - accuracy: 0.75 - ETA: 1:57 - loss: 0.9104 - accuracy: 0.75 - ETA: 1:56 - loss: 0.9108 - accuracy: 0.75 - ETA: 1:55 - loss: 0.9083 - accuracy: 0.75 - ETA: 1:53 - loss: 0.9099 - accuracy: 0.75 - ETA: 1:52 - loss: 0.9046 - accuracy: 0.75 - ETA: 1:51 - loss: 0.8995 - accuracy: 0.75 - ETA: 1:50 - loss: 0.9028 - accuracy: 0.75 - ETA: 1:48 - loss: 0.8974 - accuracy: 0.75 - ETA: 1:47 - loss: 0.8937 - accuracy: 0.75 - ETA: 1:46 - loss: 0.8986 - accuracy: 0.75 - ETA: 1:45 - loss: 0.9024 - accuracy: 0.75 - ETA: 1:44 - loss: 0.9037 - accuracy: 0.75 - ETA: 1:43 - loss: 0.9015 - accuracy: 0.75 - ETA: 1:41 - loss: 0.8966 - accuracy: 0.75 - ETA: 1:40 - loss: 0.8956 - accuracy: 0.75 - ETA: 1:39 - loss: 0.8959 - accuracy: 0.75 - ETA: 1:38 - loss: 0.8933 - accuracy: 0.75 - ETA: 1:37 - loss: 0.8924 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8960 - accuracy: 0.75 - ETA: 1:35 - loss: 0.8956 - accuracy: 0.75 - ETA: 1:33 - loss: 0.8942 - accuracy: 0.75 - ETA: 1:32 - loss: 0.8918 - accuracy: 0.75 - ETA: 1:31 - loss: 0.8878 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8905 - accuracy: 0.75 - ETA: 1:29 - loss: 0.8882 - accuracy: 0.76 - ETA: 1:28 - loss: 0.8866 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8829 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8795 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8828 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8804 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8812 - accuracy: 0.76 - ETA: 1:21 - loss: 0.8783 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8794 - accuracy: 0.76 - ETA: 1:19 - loss: 0.8855 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8902 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8911 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8881 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8851 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8856 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8837 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8815 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8799 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8789 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8793 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8784 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8787 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8815 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8814 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8842 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8840 - accuracy: 0.76 - ETA: 59s - loss: 0.8830 - accuracy: 0.7627 - ETA: 58s - loss: 0.8805 - accuracy: 0.763 - ETA: 57s - loss: 0.8821 - accuracy: 0.762 - ETA: 56s - loss: 0.8832 - accuracy: 0.762 - ETA: 54s - loss: 0.8871 - accuracy: 0.762 - ETA: 53s - loss: 0.8876 - accuracy: 0.762 - ETA: 52s - loss: 0.8870 - accuracy: 0.762 - ETA: 51s - loss: 0.8853 - accuracy: 0.763 - ETA: 50s - loss: 0.8845 - accuracy: 0.763 - ETA: 49s - loss: 0.8852 - accuracy: 0.763 - ETA: 47s - loss: 0.8858 - accuracy: 0.763 - ETA: 46s - loss: 0.8860 - accuracy: 0.763 - ETA: 45s - loss: 0.8849 - accuracy: 0.763 - ETA: 44s - loss: 0.8824 - accuracy: 0.763 - ETA: 43s - loss: 0.8837 - accuracy: 0.763 - ETA: 42s - loss: 0.8851 - accuracy: 0.763 - ETA: 41s - loss: 0.8869 - accuracy: 0.763 - ETA: 40s - loss: 0.8861 - accuracy: 0.762 - ETA: 39s - loss: 0.8855 - accuracy: 0.762 - ETA: 38s - loss: 0.8880 - accuracy: 0.762 - ETA: 37s - loss: 0.8918 - accuracy: 0.761 - ETA: 35s - loss: 0.8914 - accuracy: 0.761 - ETA: 34s - loss: 0.8898 - accuracy: 0.761 - ETA: 33s - loss: 0.8919 - accuracy: 0.761 - ETA: 32s - loss: 0.8941 - accuracy: 0.761 - ETA: 31s - loss: 0.8932 - accuracy: 0.761 - ETA: 30s - loss: 0.8942 - accuracy: 0.761 - ETA: 29s - loss: 0.8953 - accuracy: 0.761 - ETA: 27s - loss: 0.8955 - accuracy: 0.760 - ETA: 26s - loss: 0.8940 - accuracy: 0.760 - ETA: 25s - loss: 0.8938 - accuracy: 0.760 - ETA: 24s - loss: 0.8925 - accuracy: 0.760 - ETA: 23s - loss: 0.8930 - accuracy: 0.760 - ETA: 22s - loss: 0.8940 - accuracy: 0.760 - ETA: 20s - loss: 0.8947 - accuracy: 0.760 - ETA: 19s - loss: 0.8935 - accuracy: 0.760 - ETA: 18s - loss: 0.8932 - accuracy: 0.760 - ETA: 17s - loss: 0.8909 - accuracy: 0.761 - ETA: 16s - loss: 0.8912 - accuracy: 0.760 - ETA: 15s - loss: 0.8911 - accuracy: 0.760 - ETA: 13s - loss: 0.8924 - accuracy: 0.760 - ETA: 12s - loss: 0.8935 - accuracy: 0.760 - ETA: 11s - loss: 0.8929 - accuracy: 0.760 - ETA: 10s - loss: 0.8934 - accuracy: 0.761 - ETA: 9s - loss: 0.8928 - accuracy: 0.761 - ETA: 8s - loss: 0.8927 - accuracy: 0.76 - ETA: 6s - loss: 0.8942 - accuracy: 0.76 - ETA: 5s - loss: 0.8929 - accuracy: 0.76 - ETA: 4s - loss: 0.8949 - accuracy: 0.76 - ETA: 3s - loss: 0.8951 - accuracy: 0.76 - ETA: 2s - loss: 0.8953 - accuracy: 0.76 - ETA: 1s - loss: 0.8953 - accuracy: 0.76 - 189s 10ms/step - loss: 0.8944 - accuracy: 0.7607 - val_loss: 1.6402 - val_accuracy: 0.7204\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:02 - loss: 0.8992 - accuracy: 0.75 - ETA: 2:53 - loss: 0.7848 - accuracy: 0.76 - ETA: 2:53 - loss: 0.8089 - accuracy: 0.76 - ETA: 2:53 - loss: 0.8143 - accuracy: 0.76 - ETA: 2:50 - loss: 0.8146 - accuracy: 0.76 - ETA: 2:48 - loss: 0.8367 - accuracy: 0.76 - ETA: 2:48 - loss: 0.8495 - accuracy: 0.76 - ETA: 2:48 - loss: 0.8711 - accuracy: 0.76 - ETA: 2:46 - loss: 0.8705 - accuracy: 0.76 - ETA: 2:44 - loss: 0.8855 - accuracy: 0.76 - ETA: 2:42 - loss: 0.9088 - accuracy: 0.75 - ETA: 2:41 - loss: 0.9239 - accuracy: 0.75 - ETA: 2:39 - loss: 0.9021 - accuracy: 0.75 - ETA: 2:38 - loss: 0.9068 - accuracy: 0.75 - ETA: 2:36 - loss: 0.8873 - accuracy: 0.76 - ETA: 2:35 - loss: 0.8906 - accuracy: 0.75 - ETA: 2:33 - loss: 0.8977 - accuracy: 0.75 - ETA: 2:32 - loss: 0.8953 - accuracy: 0.75 - ETA: 2:31 - loss: 0.8953 - accuracy: 0.75 - ETA: 2:30 - loss: 0.8816 - accuracy: 0.75 - ETA: 2:29 - loss: 0.8793 - accuracy: 0.75 - ETA: 2:28 - loss: 0.8743 - accuracy: 0.75 - ETA: 2:27 - loss: 0.8769 - accuracy: 0.75 - ETA: 2:26 - loss: 0.8763 - accuracy: 0.75 - ETA: 2:25 - loss: 0.8670 - accuracy: 0.75 - ETA: 2:23 - loss: 0.8722 - accuracy: 0.75 - ETA: 2:22 - loss: 0.8701 - accuracy: 0.75 - ETA: 2:21 - loss: 0.8689 - accuracy: 0.75 - ETA: 2:20 - loss: 0.8645 - accuracy: 0.75 - ETA: 2:18 - loss: 0.8673 - accuracy: 0.75 - ETA: 2:17 - loss: 0.8681 - accuracy: 0.75 - ETA: 2:16 - loss: 0.8754 - accuracy: 0.75 - ETA: 2:15 - loss: 0.8801 - accuracy: 0.75 - ETA: 2:21 - loss: 0.8692 - accuracy: 0.75 - ETA: 2:20 - loss: 0.8606 - accuracy: 0.75 - ETA: 2:19 - loss: 0.8589 - accuracy: 0.75 - ETA: 2:18 - loss: 0.8616 - accuracy: 0.75 - ETA: 2:16 - loss: 0.8651 - accuracy: 0.75 - ETA: 2:15 - loss: 0.8613 - accuracy: 0.75 - ETA: 2:14 - loss: 0.8625 - accuracy: 0.75 - ETA: 2:13 - loss: 0.8646 - accuracy: 0.75 - ETA: 2:11 - loss: 0.8710 - accuracy: 0.75 - ETA: 2:10 - loss: 0.8697 - accuracy: 0.75 - ETA: 2:08 - loss: 0.8670 - accuracy: 0.75 - ETA: 2:07 - loss: 0.8695 - accuracy: 0.75 - ETA: 2:05 - loss: 0.8695 - accuracy: 0.75 - ETA: 2:04 - loss: 0.8651 - accuracy: 0.75 - ETA: 2:03 - loss: 0.8693 - accuracy: 0.75 - ETA: 2:01 - loss: 0.8734 - accuracy: 0.75 - ETA: 2:00 - loss: 0.8777 - accuracy: 0.75 - ETA: 1:59 - loss: 0.8788 - accuracy: 0.75 - ETA: 1:57 - loss: 0.8737 - accuracy: 0.75 - ETA: 1:56 - loss: 0.8766 - accuracy: 0.75 - ETA: 1:55 - loss: 0.8723 - accuracy: 0.75 - ETA: 1:53 - loss: 0.8702 - accuracy: 0.75 - ETA: 1:52 - loss: 0.8696 - accuracy: 0.75 - ETA: 1:51 - loss: 0.8683 - accuracy: 0.75 - ETA: 1:49 - loss: 0.8685 - accuracy: 0.75 - ETA: 1:48 - loss: 0.8632 - accuracy: 0.75 - ETA: 1:47 - loss: 0.8612 - accuracy: 0.75 - ETA: 1:46 - loss: 0.8637 - accuracy: 0.75 - ETA: 1:45 - loss: 0.8715 - accuracy: 0.75 - ETA: 1:43 - loss: 0.8718 - accuracy: 0.75 - ETA: 1:42 - loss: 0.8733 - accuracy: 0.75 - ETA: 1:41 - loss: 0.8716 - accuracy: 0.75 - ETA: 1:40 - loss: 0.8713 - accuracy: 0.75 - ETA: 1:38 - loss: 0.8721 - accuracy: 0.75 - ETA: 1:37 - loss: 0.8694 - accuracy: 0.75 - ETA: 1:36 - loss: 0.8671 - accuracy: 0.75 - ETA: 1:34 - loss: 0.8653 - accuracy: 0.75 - ETA: 1:33 - loss: 0.8621 - accuracy: 0.75 - ETA: 1:32 - loss: 0.8607 - accuracy: 0.75 - ETA: 1:31 - loss: 0.8653 - accuracy: 0.75 - ETA: 1:30 - loss: 0.8742 - accuracy: 0.75 - ETA: 1:29 - loss: 0.8713 - accuracy: 0.75 - ETA: 1:27 - loss: 0.8754 - accuracy: 0.75 - ETA: 1:26 - loss: 0.8744 - accuracy: 0.75 - ETA: 1:25 - loss: 0.8760 - accuracy: 0.75 - ETA: 1:24 - loss: 0.8872 - accuracy: 0.75 - ETA: 1:23 - loss: 0.8876 - accuracy: 0.75 - ETA: 1:21 - loss: 0.8858 - accuracy: 0.75 - ETA: 1:20 - loss: 0.8841 - accuracy: 0.75 - ETA: 1:19 - loss: 0.8838 - accuracy: 0.75 - ETA: 1:18 - loss: 0.8827 - accuracy: 0.75 - ETA: 1:17 - loss: 0.8865 - accuracy: 0.75 - ETA: 1:15 - loss: 0.8857 - accuracy: 0.75 - ETA: 1:14 - loss: 0.8876 - accuracy: 0.75 - ETA: 1:13 - loss: 0.8907 - accuracy: 0.75 - ETA: 1:12 - loss: 0.8956 - accuracy: 0.75 - ETA: 1:11 - loss: 0.8939 - accuracy: 0.75 - ETA: 1:09 - loss: 0.8927 - accuracy: 0.75 - ETA: 1:08 - loss: 0.8937 - accuracy: 0.75 - ETA: 1:07 - loss: 0.8937 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8940 - accuracy: 0.75 - ETA: 1:05 - loss: 0.8910 - accuracy: 0.75 - ETA: 1:03 - loss: 0.8929 - accuracy: 0.75 - ETA: 1:02 - loss: 0.8915 - accuracy: 0.75 - ETA: 1:01 - loss: 0.8908 - accuracy: 0.75 - ETA: 1:00 - loss: 0.8879 - accuracy: 0.75 - ETA: 59s - loss: 0.8890 - accuracy: 0.7581 - ETA: 57s - loss: 0.8941 - accuracy: 0.757 - ETA: 56s - loss: 0.8938 - accuracy: 0.757 - ETA: 55s - loss: 0.8926 - accuracy: 0.757 - ETA: 54s - loss: 0.8925 - accuracy: 0.756 - ETA: 53s - loss: 0.8917 - accuracy: 0.756 - ETA: 52s - loss: 0.8905 - accuracy: 0.757 - ETA: 50s - loss: 0.8909 - accuracy: 0.757 - ETA: 49s - loss: 0.8901 - accuracy: 0.757 - ETA: 48s - loss: 0.8902 - accuracy: 0.757 - ETA: 47s - loss: 0.8920 - accuracy: 0.757 - ETA: 46s - loss: 0.8936 - accuracy: 0.757 - ETA: 45s - loss: 0.8951 - accuracy: 0.757 - ETA: 43s - loss: 0.8958 - accuracy: 0.756 - ETA: 42s - loss: 0.8948 - accuracy: 0.757 - ETA: 41s - loss: 0.8952 - accuracy: 0.757 - ETA: 40s - loss: 0.8927 - accuracy: 0.757 - ETA: 39s - loss: 0.8916 - accuracy: 0.757 - ETA: 38s - loss: 0.8957 - accuracy: 0.757 - ETA: 36s - loss: 0.8939 - accuracy: 0.757 - ETA: 35s - loss: 0.8957 - accuracy: 0.757 - ETA: 34s - loss: 0.8946 - accuracy: 0.757 - ETA: 33s - loss: 0.8965 - accuracy: 0.757 - ETA: 32s - loss: 0.8982 - accuracy: 0.757 - ETA: 31s - loss: 0.8944 - accuracy: 0.757 - ETA: 29s - loss: 0.8932 - accuracy: 0.758 - ETA: 28s - loss: 0.8948 - accuracy: 0.757 - ETA: 27s - loss: 0.8949 - accuracy: 0.757 - ETA: 26s - loss: 0.8954 - accuracy: 0.757 - ETA: 25s - loss: 0.8957 - accuracy: 0.757 - ETA: 24s - loss: 0.8952 - accuracy: 0.756 - ETA: 23s - loss: 0.8950 - accuracy: 0.756 - ETA: 21s - loss: 0.8948 - accuracy: 0.756 - ETA: 20s - loss: 0.8937 - accuracy: 0.757 - ETA: 19s - loss: 0.8945 - accuracy: 0.757 - ETA: 18s - loss: 0.8957 - accuracy: 0.757 - ETA: 17s - loss: 0.8971 - accuracy: 0.757 - ETA: 16s - loss: 0.8969 - accuracy: 0.757 - ETA: 14s - loss: 0.8969 - accuracy: 0.756 - ETA: 13s - loss: 0.8992 - accuracy: 0.756 - ETA: 12s - loss: 0.8982 - accuracy: 0.756 - ETA: 11s - loss: 0.8967 - accuracy: 0.756 - ETA: 10s - loss: 0.8969 - accuracy: 0.756 - ETA: 9s - loss: 0.8992 - accuracy: 0.756 - ETA: 7s - loss: 0.8979 - accuracy: 0.75 - ETA: 6s - loss: 0.8974 - accuracy: 0.75 - ETA: 5s - loss: 0.8957 - accuracy: 0.75 - ETA: 4s - loss: 0.8977 - accuracy: 0.75 - ETA: 3s - loss: 0.9000 - accuracy: 0.75 - ETA: 2s - loss: 0.9014 - accuracy: 0.75 - ETA: 1s - loss: 0.9033 - accuracy: 0.75 - 186s 10ms/step - loss: 0.9038 - accuracy: 0.7569 - val_loss: 1.7513 - val_accuracy: 0.7177\n",
      "Epoch 42/100\n",
      "19312/19312 [==============================] - ETA: 2:53 - loss: 0.7609 - accuracy: 0.75 - ETA: 2:50 - loss: 0.8372 - accuracy: 0.77 - ETA: 2:50 - loss: 0.8785 - accuracy: 0.76 - ETA: 2:48 - loss: 0.8604 - accuracy: 0.75 - ETA: 2:47 - loss: 0.8749 - accuracy: 0.75 - ETA: 2:45 - loss: 0.8714 - accuracy: 0.75 - ETA: 2:45 - loss: 0.8611 - accuracy: 0.75 - ETA: 2:43 - loss: 0.8241 - accuracy: 0.76 - ETA: 2:41 - loss: 0.8376 - accuracy: 0.76 - ETA: 2:39 - loss: 0.8115 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8514 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8535 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8660 - accuracy: 0.76 - ETA: 2:35 - loss: 0.8926 - accuracy: 0.76 - ETA: 2:34 - loss: 0.9010 - accuracy: 0.76 - ETA: 2:33 - loss: 0.9230 - accuracy: 0.76 - ETA: 2:31 - loss: 0.9168 - accuracy: 0.75 - ETA: 2:30 - loss: 0.9330 - accuracy: 0.75 - ETA: 2:29 - loss: 0.9260 - accuracy: 0.75 - ETA: 2:28 - loss: 0.9339 - accuracy: 0.75 - ETA: 2:27 - loss: 0.9307 - accuracy: 0.75 - ETA: 2:26 - loss: 0.9371 - accuracy: 0.75 - ETA: 2:25 - loss: 0.9342 - accuracy: 0.75 - ETA: 2:24 - loss: 0.9414 - accuracy: 0.75 - ETA: 2:23 - loss: 0.9307 - accuracy: 0.75 - ETA: 2:23 - loss: 0.9245 - accuracy: 0.75 - ETA: 2:22 - loss: 0.9207 - accuracy: 0.75 - ETA: 2:22 - loss: 0.9363 - accuracy: 0.75 - ETA: 2:21 - loss: 0.9376 - accuracy: 0.75 - ETA: 2:20 - loss: 0.9476 - accuracy: 0.75 - ETA: 2:19 - loss: 0.9380 - accuracy: 0.75 - ETA: 2:18 - loss: 0.9421 - accuracy: 0.75 - ETA: 2:17 - loss: 0.9348 - accuracy: 0.75 - ETA: 2:15 - loss: 0.9286 - accuracy: 0.75 - ETA: 2:14 - loss: 0.9273 - accuracy: 0.75 - ETA: 2:13 - loss: 0.9365 - accuracy: 0.75 - ETA: 2:11 - loss: 0.9298 - accuracy: 0.75 - ETA: 2:10 - loss: 0.9279 - accuracy: 0.75 - ETA: 2:09 - loss: 0.9326 - accuracy: 0.75 - ETA: 2:08 - loss: 0.9346 - accuracy: 0.75 - ETA: 2:07 - loss: 0.9327 - accuracy: 0.75 - ETA: 2:06 - loss: 0.9302 - accuracy: 0.75 - ETA: 2:05 - loss: 0.9262 - accuracy: 0.75 - ETA: 2:04 - loss: 0.9232 - accuracy: 0.75 - ETA: 2:03 - loss: 0.9252 - accuracy: 0.75 - ETA: 2:02 - loss: 0.9232 - accuracy: 0.75 - ETA: 2:01 - loss: 0.9273 - accuracy: 0.75 - ETA: 1:59 - loss: 0.9211 - accuracy: 0.75 - ETA: 1:58 - loss: 0.9167 - accuracy: 0.75 - ETA: 1:57 - loss: 0.9150 - accuracy: 0.75 - ETA: 1:56 - loss: 0.9144 - accuracy: 0.75 - ETA: 1:55 - loss: 0.9139 - accuracy: 0.75 - ETA: 1:54 - loss: 0.9178 - accuracy: 0.75 - ETA: 1:53 - loss: 0.9178 - accuracy: 0.75 - ETA: 1:52 - loss: 0.9164 - accuracy: 0.75 - ETA: 1:51 - loss: 0.9145 - accuracy: 0.75 - ETA: 1:49 - loss: 0.9154 - accuracy: 0.75 - ETA: 1:48 - loss: 0.9126 - accuracy: 0.75 - ETA: 1:47 - loss: 0.9112 - accuracy: 0.75 - ETA: 1:46 - loss: 0.9082 - accuracy: 0.75 - ETA: 1:44 - loss: 0.9105 - accuracy: 0.75 - ETA: 1:43 - loss: 0.9084 - accuracy: 0.75 - ETA: 1:42 - loss: 0.9055 - accuracy: 0.75 - ETA: 1:41 - loss: 0.9075 - accuracy: 0.75 - ETA: 1:40 - loss: 0.9025 - accuracy: 0.75 - ETA: 1:38 - loss: 0.8989 - accuracy: 0.75 - ETA: 1:37 - loss: 0.8975 - accuracy: 0.75 - ETA: 1:36 - loss: 0.8961 - accuracy: 0.75 - ETA: 1:35 - loss: 0.8979 - accuracy: 0.75 - ETA: 1:34 - loss: 0.8954 - accuracy: 0.75 - ETA: 1:33 - loss: 0.9005 - accuracy: 0.75 - ETA: 1:31 - loss: 0.9022 - accuracy: 0.75 - ETA: 1:30 - loss: 0.8998 - accuracy: 0.75 - ETA: 1:29 - loss: 0.8994 - accuracy: 0.75 - ETA: 1:28 - loss: 0.9006 - accuracy: 0.75 - ETA: 1:27 - loss: 0.8980 - accuracy: 0.75 - ETA: 1:25 - loss: 0.8974 - accuracy: 0.75 - ETA: 1:24 - loss: 0.8977 - accuracy: 0.75 - ETA: 1:23 - loss: 0.9035 - accuracy: 0.75 - ETA: 1:22 - loss: 0.8996 - accuracy: 0.75 - ETA: 1:21 - loss: 0.9033 - accuracy: 0.75 - ETA: 1:20 - loss: 0.9047 - accuracy: 0.75 - ETA: 1:19 - loss: 0.9034 - accuracy: 0.75 - ETA: 1:17 - loss: 0.9007 - accuracy: 0.75 - ETA: 1:16 - loss: 0.9022 - accuracy: 0.75 - ETA: 1:15 - loss: 0.9007 - accuracy: 0.75 - ETA: 1:14 - loss: 0.8984 - accuracy: 0.75 - ETA: 1:13 - loss: 0.8997 - accuracy: 0.75 - ETA: 1:11 - loss: 0.8988 - accuracy: 0.75 - ETA: 1:10 - loss: 0.8996 - accuracy: 0.75 - ETA: 1:09 - loss: 0.8964 - accuracy: 0.75 - ETA: 1:08 - loss: 0.8953 - accuracy: 0.75 - ETA: 1:07 - loss: 0.8976 - accuracy: 0.75 - ETA: 1:05 - loss: 0.8982 - accuracy: 0.75 - ETA: 1:04 - loss: 0.9003 - accuracy: 0.75 - ETA: 1:03 - loss: 0.9017 - accuracy: 0.75 - ETA: 1:02 - loss: 0.9023 - accuracy: 0.75 - ETA: 1:01 - loss: 0.8996 - accuracy: 0.75 - ETA: 1:00 - loss: 0.8969 - accuracy: 0.75 - ETA: 59s - loss: 0.8940 - accuracy: 0.7573 - ETA: 57s - loss: 0.8956 - accuracy: 0.757 - ETA: 56s - loss: 0.8973 - accuracy: 0.756 - ETA: 55s - loss: 0.8967 - accuracy: 0.756 - ETA: 54s - loss: 0.9045 - accuracy: 0.756 - ETA: 53s - loss: 0.9056 - accuracy: 0.756 - ETA: 52s - loss: 0.9049 - accuracy: 0.756 - ETA: 50s - loss: 0.9042 - accuracy: 0.756 - ETA: 49s - loss: 0.9050 - accuracy: 0.756 - ETA: 48s - loss: 0.9053 - accuracy: 0.756 - ETA: 47s - loss: 0.9068 - accuracy: 0.755 - ETA: 46s - loss: 0.9080 - accuracy: 0.755 - ETA: 45s - loss: 0.9091 - accuracy: 0.755 - ETA: 43s - loss: 0.9088 - accuracy: 0.755 - ETA: 42s - loss: 0.9082 - accuracy: 0.755 - ETA: 41s - loss: 0.9083 - accuracy: 0.755 - ETA: 40s - loss: 0.9093 - accuracy: 0.755 - ETA: 39s - loss: 0.9122 - accuracy: 0.754 - ETA: 38s - loss: 0.9140 - accuracy: 0.754 - ETA: 36s - loss: 0.9135 - accuracy: 0.755 - ETA: 35s - loss: 0.9143 - accuracy: 0.754 - ETA: 34s - loss: 0.9167 - accuracy: 0.754 - ETA: 33s - loss: 0.9176 - accuracy: 0.753 - ETA: 32s - loss: 0.9168 - accuracy: 0.753 - ETA: 31s - loss: 0.9162 - accuracy: 0.754 - ETA: 29s - loss: 0.9148 - accuracy: 0.754 - ETA: 28s - loss: 0.9163 - accuracy: 0.753 - ETA: 27s - loss: 0.9152 - accuracy: 0.754 - ETA: 26s - loss: 0.9165 - accuracy: 0.753 - ETA: 25s - loss: 0.9147 - accuracy: 0.753 - ETA: 24s - loss: 0.9157 - accuracy: 0.753 - ETA: 22s - loss: 0.9144 - accuracy: 0.753 - ETA: 21s - loss: 0.9148 - accuracy: 0.753 - ETA: 20s - loss: 0.9143 - accuracy: 0.753 - ETA: 19s - loss: 0.9137 - accuracy: 0.753 - ETA: 18s - loss: 0.9144 - accuracy: 0.753 - ETA: 17s - loss: 0.9139 - accuracy: 0.753 - ETA: 16s - loss: 0.9170 - accuracy: 0.753 - ETA: 14s - loss: 0.9170 - accuracy: 0.753 - ETA: 13s - loss: 0.9148 - accuracy: 0.753 - ETA: 12s - loss: 0.9140 - accuracy: 0.753 - ETA: 11s - loss: 0.9129 - accuracy: 0.753 - ETA: 10s - loss: 0.9126 - accuracy: 0.753 - ETA: 9s - loss: 0.9122 - accuracy: 0.753 - ETA: 7s - loss: 0.9113 - accuracy: 0.75 - ETA: 6s - loss: 0.9101 - accuracy: 0.75 - ETA: 5s - loss: 0.9089 - accuracy: 0.75 - ETA: 4s - loss: 0.9077 - accuracy: 0.75 - ETA: 3s - loss: 0.9078 - accuracy: 0.75 - ETA: 2s - loss: 0.9071 - accuracy: 0.75 - ETA: 1s - loss: 0.9083 - accuracy: 0.75 - 186s 10ms/step - loss: 0.9097 - accuracy: 0.7549 - val_loss: 1.7969 - val_accuracy: 0.7204\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:47 - loss: 1.0917 - accuracy: 0.75 - ETA: 2:46 - loss: 0.8387 - accuracy: 0.80 - ETA: 2:46 - loss: 0.7800 - accuracy: 0.79 - ETA: 2:50 - loss: 0.7669 - accuracy: 0.78 - ETA: 2:47 - loss: 0.7552 - accuracy: 0.78 - ETA: 2:44 - loss: 0.7955 - accuracy: 0.78 - ETA: 2:41 - loss: 0.8174 - accuracy: 0.78 - ETA: 2:40 - loss: 0.8322 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8391 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8800 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8928 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8893 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8901 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8823 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8917 - accuracy: 0.76 - ETA: 2:33 - loss: 0.8847 - accuracy: 0.76 - ETA: 2:32 - loss: 0.8877 - accuracy: 0.76 - ETA: 2:32 - loss: 0.8778 - accuracy: 0.76 - ETA: 2:31 - loss: 0.8773 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8677 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8624 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8650 - accuracy: 0.76 - ETA: 2:26 - loss: 0.8692 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8630 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8714 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8752 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8690 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8800 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8761 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8762 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8780 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8725 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8707 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8771 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8785 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8812 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8808 - accuracy: 0.76 - ETA: 2:08 - loss: 0.8869 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8822 - accuracy: 0.76 - ETA: 2:06 - loss: 0.8849 - accuracy: 0.76 - ETA: 2:05 - loss: 0.8894 - accuracy: 0.76 - ETA: 2:04 - loss: 0.8876 - accuracy: 0.76 - ETA: 2:03 - loss: 0.8820 - accuracy: 0.76 - ETA: 2:01 - loss: 0.8806 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8890 - accuracy: 0.76 - ETA: 1:59 - loss: 0.8918 - accuracy: 0.76 - ETA: 1:58 - loss: 0.8991 - accuracy: 0.76 - ETA: 1:57 - loss: 0.8926 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8951 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8965 - accuracy: 0.76 - ETA: 1:53 - loss: 0.8915 - accuracy: 0.76 - ETA: 1:52 - loss: 0.8863 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8852 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8839 - accuracy: 0.76 - ETA: 1:48 - loss: 0.8878 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8864 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8901 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8934 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8885 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8851 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8843 - accuracy: 0.76 - ETA: 1:41 - loss: 0.8838 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8835 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8824 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8929 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8952 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8938 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8894 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8919 - accuracy: 0.76 - ETA: 1:32 - loss: 0.9002 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8995 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8998 - accuracy: 0.76 - ETA: 1:28 - loss: 0.8993 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8977 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8979 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8957 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8912 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8917 - accuracy: 0.76 - ETA: 1:21 - loss: 0.8927 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8895 - accuracy: 0.76 - ETA: 1:19 - loss: 0.8878 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8868 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8849 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8830 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8824 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8806 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8811 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8860 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8838 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8842 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8823 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8824 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8830 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8849 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8848 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8817 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8820 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8817 - accuracy: 0.76 - ETA: 59s - loss: 0.8831 - accuracy: 0.7628 - ETA: 57s - loss: 0.8807 - accuracy: 0.763 - ETA: 56s - loss: 0.8800 - accuracy: 0.763 - ETA: 55s - loss: 0.8798 - accuracy: 0.763 - ETA: 54s - loss: 0.8792 - accuracy: 0.763 - ETA: 53s - loss: 0.8787 - accuracy: 0.762 - ETA: 52s - loss: 0.8774 - accuracy: 0.762 - ETA: 51s - loss: 0.8791 - accuracy: 0.762 - ETA: 49s - loss: 0.8795 - accuracy: 0.762 - ETA: 48s - loss: 0.8779 - accuracy: 0.762 - ETA: 47s - loss: 0.8779 - accuracy: 0.762 - ETA: 46s - loss: 0.8769 - accuracy: 0.762 - ETA: 45s - loss: 0.8772 - accuracy: 0.762 - ETA: 44s - loss: 0.8781 - accuracy: 0.762 - ETA: 43s - loss: 0.8804 - accuracy: 0.762 - ETA: 42s - loss: 0.8803 - accuracy: 0.761 - ETA: 40s - loss: 0.8801 - accuracy: 0.762 - ETA: 39s - loss: 0.8797 - accuracy: 0.761 - ETA: 38s - loss: 0.8798 - accuracy: 0.762 - ETA: 37s - loss: 0.8796 - accuracy: 0.761 - ETA: 36s - loss: 0.8792 - accuracy: 0.762 - ETA: 35s - loss: 0.8778 - accuracy: 0.762 - ETA: 34s - loss: 0.8838 - accuracy: 0.762 - ETA: 32s - loss: 0.8837 - accuracy: 0.763 - ETA: 31s - loss: 0.8856 - accuracy: 0.763 - ETA: 30s - loss: 0.8857 - accuracy: 0.762 - ETA: 29s - loss: 0.8881 - accuracy: 0.762 - ETA: 28s - loss: 0.8864 - accuracy: 0.762 - ETA: 27s - loss: 0.8848 - accuracy: 0.762 - ETA: 26s - loss: 0.8859 - accuracy: 0.762 - ETA: 24s - loss: 0.8858 - accuracy: 0.762 - ETA: 23s - loss: 0.8890 - accuracy: 0.761 - ETA: 22s - loss: 0.8886 - accuracy: 0.762 - ETA: 21s - loss: 0.8885 - accuracy: 0.761 - ETA: 20s - loss: 0.8872 - accuracy: 0.762 - ETA: 19s - loss: 0.8866 - accuracy: 0.761 - ETA: 18s - loss: 0.8857 - accuracy: 0.761 - ETA: 16s - loss: 0.8872 - accuracy: 0.761 - ETA: 15s - loss: 0.8869 - accuracy: 0.761 - ETA: 14s - loss: 0.8860 - accuracy: 0.761 - ETA: 13s - loss: 0.8872 - accuracy: 0.761 - ETA: 12s - loss: 0.8887 - accuracy: 0.761 - ETA: 11s - loss: 0.8867 - accuracy: 0.761 - ETA: 10s - loss: 0.8852 - accuracy: 0.761 - ETA: 8s - loss: 0.8843 - accuracy: 0.761 - ETA: 7s - loss: 0.8857 - accuracy: 0.76 - ETA: 6s - loss: 0.8858 - accuracy: 0.76 - ETA: 5s - loss: 0.8845 - accuracy: 0.76 - ETA: 4s - loss: 0.8837 - accuracy: 0.76 - ETA: 3s - loss: 0.8844 - accuracy: 0.76 - ETA: 2s - loss: 0.8865 - accuracy: 0.76 - ETA: 0s - loss: 0.8871 - accuracy: 0.76 - 184s 10ms/step - loss: 0.8878 - accuracy: 0.7608 - val_loss: 1.6932 - val_accuracy: 0.7192\n",
      "Epoch 44/100\n",
      "19312/19312 [==============================] - ETA: 2:50 - loss: 1.5266 - accuracy: 0.73 - ETA: 2:46 - loss: 1.1057 - accuracy: 0.75 - ETA: 2:47 - loss: 1.0087 - accuracy: 0.76 - ETA: 2:42 - loss: 1.0234 - accuracy: 0.75 - ETA: 2:42 - loss: 0.9517 - accuracy: 0.76 - ETA: 2:42 - loss: 1.0040 - accuracy: 0.74 - ETA: 2:41 - loss: 1.0152 - accuracy: 0.75 - ETA: 2:41 - loss: 0.9915 - accuracy: 0.75 - ETA: 2:41 - loss: 0.9674 - accuracy: 0.75 - ETA: 2:39 - loss: 0.9496 - accuracy: 0.75 - ETA: 2:39 - loss: 0.9210 - accuracy: 0.76 - ETA: 2:38 - loss: 0.9190 - accuracy: 0.75 - ETA: 2:37 - loss: 0.8911 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8784 - accuracy: 0.76 - ETA: 2:34 - loss: 0.8847 - accuracy: 0.76 - ETA: 2:34 - loss: 0.9127 - accuracy: 0.75 - ETA: 2:32 - loss: 0.8999 - accuracy: 0.76 - ETA: 2:31 - loss: 0.9042 - accuracy: 0.75 - ETA: 2:29 - loss: 0.8957 - accuracy: 0.75 - ETA: 2:28 - loss: 0.9083 - accuracy: 0.75 - ETA: 2:27 - loss: 0.9102 - accuracy: 0.75 - ETA: 2:25 - loss: 0.9115 - accuracy: 0.75 - ETA: 2:24 - loss: 0.9026 - accuracy: 0.75 - ETA: 2:24 - loss: 0.8951 - accuracy: 0.75 - ETA: 2:23 - loss: 0.8907 - accuracy: 0.75 - ETA: 2:22 - loss: 0.8780 - accuracy: 0.75 - ETA: 2:21 - loss: 0.8843 - accuracy: 0.75 - ETA: 2:19 - loss: 0.8884 - accuracy: 0.75 - ETA: 2:18 - loss: 0.8869 - accuracy: 0.75 - ETA: 2:17 - loss: 0.8887 - accuracy: 0.75 - ETA: 2:16 - loss: 0.8887 - accuracy: 0.75 - ETA: 2:14 - loss: 0.8871 - accuracy: 0.75 - ETA: 2:13 - loss: 0.8813 - accuracy: 0.75 - ETA: 2:12 - loss: 0.8812 - accuracy: 0.75 - ETA: 2:11 - loss: 0.8818 - accuracy: 0.75 - ETA: 2:10 - loss: 0.8879 - accuracy: 0.75 - ETA: 2:08 - loss: 0.8850 - accuracy: 0.75 - ETA: 2:07 - loss: 0.8781 - accuracy: 0.75 - ETA: 2:06 - loss: 0.8757 - accuracy: 0.75 - ETA: 2:06 - loss: 0.8806 - accuracy: 0.75 - ETA: 2:04 - loss: 0.8798 - accuracy: 0.75 - ETA: 2:03 - loss: 0.8788 - accuracy: 0.75 - ETA: 2:02 - loss: 0.8792 - accuracy: 0.75 - ETA: 2:00 - loss: 0.8800 - accuracy: 0.75 - ETA: 1:59 - loss: 0.8744 - accuracy: 0.75 - ETA: 1:58 - loss: 0.8725 - accuracy: 0.75 - ETA: 1:57 - loss: 0.8713 - accuracy: 0.75 - ETA: 1:56 - loss: 0.8661 - accuracy: 0.75 - ETA: 1:55 - loss: 0.8655 - accuracy: 0.75 - ETA: 1:54 - loss: 0.8653 - accuracy: 0.75 - ETA: 1:53 - loss: 0.8708 - accuracy: 0.75 - ETA: 1:51 - loss: 0.8746 - accuracy: 0.75 - ETA: 1:50 - loss: 0.8746 - accuracy: 0.75 - ETA: 1:49 - loss: 0.8729 - accuracy: 0.75 - ETA: 1:48 - loss: 0.8704 - accuracy: 0.75 - ETA: 1:47 - loss: 0.8709 - accuracy: 0.75 - ETA: 1:46 - loss: 0.8767 - accuracy: 0.75 - ETA: 1:45 - loss: 0.8751 - accuracy: 0.75 - ETA: 1:43 - loss: 0.8709 - accuracy: 0.75 - ETA: 1:42 - loss: 0.8684 - accuracy: 0.75 - ETA: 1:41 - loss: 0.8643 - accuracy: 0.75 - ETA: 1:40 - loss: 0.8635 - accuracy: 0.75 - ETA: 1:39 - loss: 0.8624 - accuracy: 0.75 - ETA: 1:37 - loss: 0.8619 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8605 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8562 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8588 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8606 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8591 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8610 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8619 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8625 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8647 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8714 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8731 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8710 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8707 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8716 - accuracy: 0.76 - ETA: 1:21 - loss: 0.8721 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8721 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8724 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8728 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8720 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8729 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8726 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8710 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8694 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8692 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8744 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8734 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8713 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8729 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8712 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8723 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8692 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8674 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8650 - accuracy: 0.76 - ETA: 59s - loss: 0.8650 - accuracy: 0.7631 - ETA: 58s - loss: 0.8628 - accuracy: 0.763 - ETA: 57s - loss: 0.8640 - accuracy: 0.763 - ETA: 56s - loss: 0.8674 - accuracy: 0.762 - ETA: 55s - loss: 0.8642 - accuracy: 0.762 - ETA: 54s - loss: 0.8648 - accuracy: 0.762 - ETA: 52s - loss: 0.8645 - accuracy: 0.762 - ETA: 51s - loss: 0.8685 - accuracy: 0.761 - ETA: 50s - loss: 0.8678 - accuracy: 0.761 - ETA: 49s - loss: 0.8669 - accuracy: 0.761 - ETA: 48s - loss: 0.8659 - accuracy: 0.761 - ETA: 47s - loss: 0.8667 - accuracy: 0.761 - ETA: 46s - loss: 0.8668 - accuracy: 0.761 - ETA: 45s - loss: 0.8685 - accuracy: 0.761 - ETA: 43s - loss: 0.8731 - accuracy: 0.761 - ETA: 42s - loss: 0.8719 - accuracy: 0.762 - ETA: 41s - loss: 0.8719 - accuracy: 0.762 - ETA: 40s - loss: 0.8694 - accuracy: 0.762 - ETA: 39s - loss: 0.8679 - accuracy: 0.762 - ETA: 38s - loss: 0.8672 - accuracy: 0.762 - ETA: 37s - loss: 0.8669 - accuracy: 0.762 - ETA: 36s - loss: 0.8670 - accuracy: 0.762 - ETA: 34s - loss: 0.8656 - accuracy: 0.762 - ETA: 33s - loss: 0.8658 - accuracy: 0.762 - ETA: 32s - loss: 0.8646 - accuracy: 0.763 - ETA: 31s - loss: 0.8640 - accuracy: 0.763 - ETA: 30s - loss: 0.8677 - accuracy: 0.762 - ETA: 29s - loss: 0.8670 - accuracy: 0.762 - ETA: 28s - loss: 0.8651 - accuracy: 0.763 - ETA: 27s - loss: 0.8660 - accuracy: 0.762 - ETA: 25s - loss: 0.8661 - accuracy: 0.762 - ETA: 24s - loss: 0.8671 - accuracy: 0.762 - ETA: 23s - loss: 0.8646 - accuracy: 0.762 - ETA: 22s - loss: 0.8648 - accuracy: 0.762 - ETA: 21s - loss: 0.8635 - accuracy: 0.763 - ETA: 20s - loss: 0.8622 - accuracy: 0.763 - ETA: 19s - loss: 0.8607 - accuracy: 0.763 - ETA: 17s - loss: 0.8605 - accuracy: 0.764 - ETA: 16s - loss: 0.8605 - accuracy: 0.763 - ETA: 15s - loss: 0.8609 - accuracy: 0.763 - ETA: 14s - loss: 0.8597 - accuracy: 0.764 - ETA: 13s - loss: 0.8596 - accuracy: 0.764 - ETA: 12s - loss: 0.8605 - accuracy: 0.764 - ETA: 11s - loss: 0.8584 - accuracy: 0.764 - ETA: 10s - loss: 0.8604 - accuracy: 0.764 - ETA: 8s - loss: 0.8607 - accuracy: 0.764 - ETA: 7s - loss: 0.8694 - accuracy: 0.76 - ETA: 6s - loss: 0.8689 - accuracy: 0.76 - ETA: 5s - loss: 0.8672 - accuracy: 0.76 - ETA: 4s - loss: 0.8667 - accuracy: 0.76 - ETA: 3s - loss: 0.8663 - accuracy: 0.76 - ETA: 2s - loss: 0.8649 - accuracy: 0.76 - ETA: 0s - loss: 0.8654 - accuracy: 0.76 - 184s 10ms/step - loss: 0.8669 - accuracy: 0.7646 - val_loss: 1.7390 - val_accuracy: 0.7225\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:43 - loss: 0.8874 - accuracy: 0.76 - ETA: 2:46 - loss: 0.9541 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8744 - accuracy: 0.78 - ETA: 2:45 - loss: 0.7764 - accuracy: 0.79 - ETA: 2:45 - loss: 0.7933 - accuracy: 0.80 - ETA: 2:44 - loss: 0.7906 - accuracy: 0.79 - ETA: 2:42 - loss: 0.7991 - accuracy: 0.79 - ETA: 2:42 - loss: 0.8013 - accuracy: 0.78 - ETA: 2:40 - loss: 0.8223 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8147 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8025 - accuracy: 0.77 - ETA: 2:36 - loss: 0.7959 - accuracy: 0.77 - ETA: 2:35 - loss: 0.7946 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8102 - accuracy: 0.77 - ETA: 2:33 - loss: 0.7938 - accuracy: 0.77 - ETA: 2:32 - loss: 0.7910 - accuracy: 0.77 - ETA: 2:31 - loss: 0.7919 - accuracy: 0.77 - ETA: 2:30 - loss: 0.7919 - accuracy: 0.77 - ETA: 2:30 - loss: 0.7963 - accuracy: 0.77 - ETA: 2:28 - loss: 0.7947 - accuracy: 0.77 - ETA: 2:27 - loss: 0.7939 - accuracy: 0.77 - ETA: 2:26 - loss: 0.7868 - accuracy: 0.77 - ETA: 2:25 - loss: 0.7915 - accuracy: 0.77 - ETA: 2:24 - loss: 0.7851 - accuracy: 0.77 - ETA: 2:22 - loss: 0.7957 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8076 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8105 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8168 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8150 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8197 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8249 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8302 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8311 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8447 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8477 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8608 - accuracy: 0.76 - ETA: 2:08 - loss: 0.8598 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8569 - accuracy: 0.76 - ETA: 2:06 - loss: 0.8504 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8470 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8485 - accuracy: 0.76 - ETA: 2:04 - loss: 0.8492 - accuracy: 0.76 - ETA: 2:03 - loss: 0.8481 - accuracy: 0.76 - ETA: 2:01 - loss: 0.8459 - accuracy: 0.76 - ETA: 2:01 - loss: 0.8448 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8560 - accuracy: 0.76 - ETA: 1:59 - loss: 0.8566 - accuracy: 0.76 - ETA: 1:58 - loss: 0.8518 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8498 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8503 - accuracy: 0.76 - ETA: 1:54 - loss: 0.8479 - accuracy: 0.76 - ETA: 1:53 - loss: 0.8474 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8495 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8496 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8580 - accuracy: 0.76 - ETA: 1:48 - loss: 0.8573 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8554 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8532 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8516 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8512 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8495 - accuracy: 0.76 - ETA: 1:41 - loss: 0.8580 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8593 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8576 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8608 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8651 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8645 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8689 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8637 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8602 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8649 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8619 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8639 - accuracy: 0.76 - ETA: 1:28 - loss: 0.8647 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8638 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8623 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8648 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8607 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8581 - accuracy: 0.76 - ETA: 1:21 - loss: 0.8586 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8614 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8636 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8637 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8629 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8656 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8645 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8667 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8675 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8665 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8649 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8626 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8616 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8616 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8626 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8621 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8637 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8631 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8627 - accuracy: 0.76 - ETA: 59s - loss: 0.8613 - accuracy: 0.7618 - ETA: 58s - loss: 0.8620 - accuracy: 0.761 - ETA: 57s - loss: 0.8643 - accuracy: 0.761 - ETA: 56s - loss: 0.8626 - accuracy: 0.761 - ETA: 54s - loss: 0.8628 - accuracy: 0.761 - ETA: 53s - loss: 0.8634 - accuracy: 0.761 - ETA: 52s - loss: 0.8625 - accuracy: 0.761 - ETA: 51s - loss: 0.8616 - accuracy: 0.761 - ETA: 50s - loss: 0.8603 - accuracy: 0.761 - ETA: 49s - loss: 0.8589 - accuracy: 0.761 - ETA: 48s - loss: 0.8573 - accuracy: 0.761 - ETA: 46s - loss: 0.8551 - accuracy: 0.762 - ETA: 45s - loss: 0.8554 - accuracy: 0.761 - ETA: 44s - loss: 0.8553 - accuracy: 0.762 - ETA: 43s - loss: 0.8547 - accuracy: 0.762 - ETA: 42s - loss: 0.8524 - accuracy: 0.763 - ETA: 41s - loss: 0.8530 - accuracy: 0.762 - ETA: 40s - loss: 0.8508 - accuracy: 0.763 - ETA: 38s - loss: 0.8502 - accuracy: 0.763 - ETA: 37s - loss: 0.8513 - accuracy: 0.763 - ETA: 36s - loss: 0.8524 - accuracy: 0.763 - ETA: 35s - loss: 0.8519 - accuracy: 0.763 - ETA: 34s - loss: 0.8535 - accuracy: 0.762 - ETA: 33s - loss: 0.8557 - accuracy: 0.762 - ETA: 32s - loss: 0.8560 - accuracy: 0.762 - ETA: 30s - loss: 0.8547 - accuracy: 0.762 - ETA: 29s - loss: 0.8561 - accuracy: 0.762 - ETA: 28s - loss: 0.8546 - accuracy: 0.763 - ETA: 27s - loss: 0.8567 - accuracy: 0.762 - ETA: 26s - loss: 0.8590 - accuracy: 0.762 - ETA: 25s - loss: 0.8586 - accuracy: 0.763 - ETA: 23s - loss: 0.8584 - accuracy: 0.763 - ETA: 22s - loss: 0.8583 - accuracy: 0.763 - ETA: 21s - loss: 0.8599 - accuracy: 0.763 - ETA: 20s - loss: 0.8593 - accuracy: 0.763 - ETA: 19s - loss: 0.8568 - accuracy: 0.763 - ETA: 18s - loss: 0.8561 - accuracy: 0.763 - ETA: 17s - loss: 0.8550 - accuracy: 0.763 - ETA: 15s - loss: 0.8561 - accuracy: 0.763 - ETA: 14s - loss: 0.8543 - accuracy: 0.764 - ETA: 13s - loss: 0.8571 - accuracy: 0.764 - ETA: 12s - loss: 0.8580 - accuracy: 0.764 - ETA: 11s - loss: 0.8559 - accuracy: 0.764 - ETA: 10s - loss: 0.8536 - accuracy: 0.765 - ETA: 9s - loss: 0.8532 - accuracy: 0.764 - ETA: 7s - loss: 0.8525 - accuracy: 0.76 - ETA: 6s - loss: 0.8519 - accuracy: 0.76 - ETA: 5s - loss: 0.8555 - accuracy: 0.76 - ETA: 4s - loss: 0.8549 - accuracy: 0.76 - ETA: 3s - loss: 0.8562 - accuracy: 0.76 - ETA: 2s - loss: 0.8559 - accuracy: 0.76 - ETA: 1s - loss: 0.8547 - accuracy: 0.76 - 184s 10ms/step - loss: 0.8550 - accuracy: 0.7646 - val_loss: 1.7010 - val_accuracy: 0.7217\n",
      "Epoch 46/100\n",
      "19312/19312 [==============================] - ETA: 2:47 - loss: 0.6485 - accuracy: 0.81 - ETA: 2:50 - loss: 0.7650 - accuracy: 0.77 - ETA: 2:47 - loss: 0.8478 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8030 - accuracy: 0.76 - ETA: 2:42 - loss: 0.8124 - accuracy: 0.76 - ETA: 2:41 - loss: 0.8996 - accuracy: 0.75 - ETA: 2:41 - loss: 0.8740 - accuracy: 0.76 - ETA: 2:40 - loss: 0.9054 - accuracy: 0.76 - ETA: 2:40 - loss: 0.8693 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8637 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8476 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8378 - accuracy: 0.77 - ETA: 2:38 - loss: 0.8229 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8288 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8341 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8305 - accuracy: 0.76 - ETA: 2:32 - loss: 0.8333 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8363 - accuracy: 0.76 - ETA: 2:29 - loss: 0.8424 - accuracy: 0.76 - ETA: 2:28 - loss: 0.8543 - accuracy: 0.76 - ETA: 2:27 - loss: 0.8457 - accuracy: 0.76 - ETA: 2:26 - loss: 0.8438 - accuracy: 0.76 - ETA: 2:25 - loss: 0.8520 - accuracy: 0.76 - ETA: 2:25 - loss: 0.8521 - accuracy: 0.76 - ETA: 2:24 - loss: 0.8432 - accuracy: 0.76 - ETA: 2:23 - loss: 0.8401 - accuracy: 0.76 - ETA: 2:22 - loss: 0.8277 - accuracy: 0.76 - ETA: 2:21 - loss: 0.8274 - accuracy: 0.76 - ETA: 2:20 - loss: 0.8276 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8313 - accuracy: 0.76 - ETA: 2:18 - loss: 0.8302 - accuracy: 0.76 - ETA: 2:17 - loss: 0.8294 - accuracy: 0.76 - ETA: 2:16 - loss: 0.8199 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8168 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8146 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8138 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8223 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8248 - accuracy: 0.76 - ETA: 2:10 - loss: 0.8218 - accuracy: 0.76 - ETA: 2:08 - loss: 0.8227 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8278 - accuracy: 0.76 - ETA: 2:06 - loss: 0.8291 - accuracy: 0.76 - ETA: 2:05 - loss: 0.8265 - accuracy: 0.76 - ETA: 2:03 - loss: 0.8251 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8225 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8187 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8178 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8188 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8238 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8217 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8207 - accuracy: 0.76 - ETA: 1:54 - loss: 0.8220 - accuracy: 0.76 - ETA: 1:53 - loss: 0.8193 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8157 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8151 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8152 - accuracy: 0.76 - ETA: 1:48 - loss: 0.8202 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8197 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8179 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8132 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8110 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8144 - accuracy: 0.76 - ETA: 1:41 - loss: 0.8154 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8144 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8130 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8127 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8188 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8195 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8210 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8210 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8246 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8236 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8280 - accuracy: 0.76 - ETA: 1:28 - loss: 0.8253 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8301 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8298 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8301 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8345 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8358 - accuracy: 0.76 - ETA: 1:21 - loss: 0.8351 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8356 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8372 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8377 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8380 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8349 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8373 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8364 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8382 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8366 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8394 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8429 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8422 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8403 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8406 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8393 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8369 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8377 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8382 - accuracy: 0.76 - ETA: 59s - loss: 0.8408 - accuracy: 0.7648 - ETA: 58s - loss: 0.8423 - accuracy: 0.764 - ETA: 56s - loss: 0.8476 - accuracy: 0.764 - ETA: 55s - loss: 0.8475 - accuracy: 0.764 - ETA: 54s - loss: 0.8487 - accuracy: 0.764 - ETA: 53s - loss: 0.8490 - accuracy: 0.763 - ETA: 52s - loss: 0.8487 - accuracy: 0.764 - ETA: 51s - loss: 0.8475 - accuracy: 0.764 - ETA: 50s - loss: 0.8491 - accuracy: 0.764 - ETA: 48s - loss: 0.8497 - accuracy: 0.764 - ETA: 47s - loss: 0.8482 - accuracy: 0.764 - ETA: 46s - loss: 0.8485 - accuracy: 0.764 - ETA: 45s - loss: 0.8472 - accuracy: 0.764 - ETA: 44s - loss: 0.8493 - accuracy: 0.764 - ETA: 43s - loss: 0.8506 - accuracy: 0.764 - ETA: 42s - loss: 0.8525 - accuracy: 0.763 - ETA: 40s - loss: 0.8566 - accuracy: 0.763 - ETA: 39s - loss: 0.8565 - accuracy: 0.763 - ETA: 38s - loss: 0.8548 - accuracy: 0.764 - ETA: 37s - loss: 0.8542 - accuracy: 0.764 - ETA: 36s - loss: 0.8543 - accuracy: 0.764 - ETA: 35s - loss: 0.8528 - accuracy: 0.765 - ETA: 34s - loss: 0.8536 - accuracy: 0.765 - ETA: 32s - loss: 0.8530 - accuracy: 0.764 - ETA: 31s - loss: 0.8520 - accuracy: 0.764 - ETA: 30s - loss: 0.8516 - accuracy: 0.765 - ETA: 29s - loss: 0.8508 - accuracy: 0.765 - ETA: 28s - loss: 0.8489 - accuracy: 0.766 - ETA: 27s - loss: 0.8515 - accuracy: 0.765 - ETA: 26s - loss: 0.8500 - accuracy: 0.766 - ETA: 24s - loss: 0.8514 - accuracy: 0.766 - ETA: 23s - loss: 0.8527 - accuracy: 0.765 - ETA: 22s - loss: 0.8527 - accuracy: 0.765 - ETA: 21s - loss: 0.8554 - accuracy: 0.765 - ETA: 20s - loss: 0.8549 - accuracy: 0.765 - ETA: 19s - loss: 0.8543 - accuracy: 0.765 - ETA: 18s - loss: 0.8543 - accuracy: 0.765 - ETA: 16s - loss: 0.8561 - accuracy: 0.765 - ETA: 15s - loss: 0.8559 - accuracy: 0.765 - ETA: 14s - loss: 0.8556 - accuracy: 0.765 - ETA: 13s - loss: 0.8586 - accuracy: 0.765 - ETA: 12s - loss: 0.8604 - accuracy: 0.765 - ETA: 11s - loss: 0.8610 - accuracy: 0.765 - ETA: 10s - loss: 0.8620 - accuracy: 0.764 - ETA: 8s - loss: 0.8606 - accuracy: 0.765 - ETA: 7s - loss: 0.8605 - accuracy: 0.76 - ETA: 6s - loss: 0.8602 - accuracy: 0.76 - ETA: 5s - loss: 0.8601 - accuracy: 0.76 - ETA: 4s - loss: 0.8618 - accuracy: 0.76 - ETA: 3s - loss: 0.8613 - accuracy: 0.76 - ETA: 2s - loss: 0.8607 - accuracy: 0.76 - ETA: 0s - loss: 0.8594 - accuracy: 0.76 - 185s 10ms/step - loss: 0.8620 - accuracy: 0.7651 - val_loss: 1.7731 - val_accuracy: 0.7219\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:46 - loss: 0.7995 - accuracy: 0.80 - ETA: 2:51 - loss: 1.0814 - accuracy: 0.78 - ETA: 2:55 - loss: 1.0445 - accuracy: 0.76 - ETA: 2:58 - loss: 1.0420 - accuracy: 0.75 - ETA: 2:54 - loss: 1.0438 - accuracy: 0.75 - ETA: 2:51 - loss: 0.9999 - accuracy: 0.75 - ETA: 2:47 - loss: 0.9635 - accuracy: 0.75 - ETA: 2:46 - loss: 0.9276 - accuracy: 0.75 - ETA: 2:43 - loss: 0.8962 - accuracy: 0.76 - ETA: 2:41 - loss: 0.9125 - accuracy: 0.76 - ETA: 2:39 - loss: 0.9198 - accuracy: 0.76 - ETA: 2:38 - loss: 0.9302 - accuracy: 0.76 - ETA: 2:37 - loss: 0.9502 - accuracy: 0.75 - ETA: 2:36 - loss: 0.9371 - accuracy: 0.76 - ETA: 2:35 - loss: 0.9174 - accuracy: 0.76 - ETA: 2:33 - loss: 0.9067 - accuracy: 0.76 - ETA: 2:33 - loss: 0.9022 - accuracy: 0.76 - ETA: 2:33 - loss: 0.9057 - accuracy: 0.76 - ETA: 2:31 - loss: 0.8978 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8910 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8809 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8788 - accuracy: 0.76 - ETA: 2:26 - loss: 0.8811 - accuracy: 0.76 - ETA: 2:25 - loss: 0.8865 - accuracy: 0.76 - ETA: 2:23 - loss: 0.8829 - accuracy: 0.76 - ETA: 2:22 - loss: 0.8762 - accuracy: 0.76 - ETA: 2:21 - loss: 0.8832 - accuracy: 0.76 - ETA: 2:20 - loss: 0.8771 - accuracy: 0.76 - ETA: 2:19 - loss: 0.8760 - accuracy: 0.76 - ETA: 2:18 - loss: 0.8716 - accuracy: 0.76 - ETA: 2:17 - loss: 0.8677 - accuracy: 0.76 - ETA: 2:16 - loss: 0.8794 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8749 - accuracy: 0.76 - ETA: 2:14 - loss: 0.8722 - accuracy: 0.76 - ETA: 2:13 - loss: 0.8682 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8725 - accuracy: 0.76 - ETA: 2:10 - loss: 0.8638 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8596 - accuracy: 0.76 - ETA: 2:08 - loss: 0.8572 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8612 - accuracy: 0.76 - ETA: 2:06 - loss: 0.8601 - accuracy: 0.76 - ETA: 2:05 - loss: 0.8553 - accuracy: 0.76 - ETA: 2:04 - loss: 0.8530 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8496 - accuracy: 0.76 - ETA: 2:01 - loss: 0.8474 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8452 - accuracy: 0.76 - ETA: 1:59 - loss: 0.8478 - accuracy: 0.76 - ETA: 1:58 - loss: 0.8477 - accuracy: 0.76 - ETA: 1:57 - loss: 0.8521 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8499 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8475 - accuracy: 0.76 - ETA: 1:54 - loss: 0.8670 - accuracy: 0.76 - ETA: 1:52 - loss: 0.8652 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8608 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8572 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8582 - accuracy: 0.76 - ETA: 1:48 - loss: 0.8531 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8507 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8486 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8517 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8610 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8589 - accuracy: 0.76 - ETA: 1:41 - loss: 0.8549 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8526 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8498 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8517 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8522 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8528 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8562 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8565 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8562 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8628 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8614 - accuracy: 0.76 - ETA: 1:28 - loss: 0.8613 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8661 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8664 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8668 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8662 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8674 - accuracy: 0.76 - ETA: 1:21 - loss: 0.8685 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8717 - accuracy: 0.76 - ETA: 1:19 - loss: 0.8720 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8733 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8757 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8781 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8759 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8750 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8733 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8762 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8773 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8777 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8769 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8755 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8752 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8799 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8799 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8782 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8802 - accuracy: 0.76 - ETA: 59s - loss: 0.8835 - accuracy: 0.7642 - ETA: 58s - loss: 0.8809 - accuracy: 0.764 - ETA: 57s - loss: 0.8795 - accuracy: 0.765 - ETA: 56s - loss: 0.8787 - accuracy: 0.765 - ETA: 55s - loss: 0.8792 - accuracy: 0.765 - ETA: 53s - loss: 0.8796 - accuracy: 0.764 - ETA: 52s - loss: 0.8794 - accuracy: 0.764 - ETA: 51s - loss: 0.8820 - accuracy: 0.764 - ETA: 50s - loss: 0.8855 - accuracy: 0.764 - ETA: 49s - loss: 0.8863 - accuracy: 0.763 - ETA: 48s - loss: 0.8876 - accuracy: 0.763 - ETA: 46s - loss: 0.8864 - accuracy: 0.764 - ETA: 45s - loss: 0.8853 - accuracy: 0.764 - ETA: 44s - loss: 0.8868 - accuracy: 0.764 - ETA: 43s - loss: 0.8896 - accuracy: 0.764 - ETA: 42s - loss: 0.8896 - accuracy: 0.763 - ETA: 41s - loss: 0.8893 - accuracy: 0.763 - ETA: 40s - loss: 0.8866 - accuracy: 0.764 - ETA: 38s - loss: 0.8853 - accuracy: 0.764 - ETA: 37s - loss: 0.8889 - accuracy: 0.763 - ETA: 36s - loss: 0.8888 - accuracy: 0.763 - ETA: 35s - loss: 0.8884 - accuracy: 0.764 - ETA: 34s - loss: 0.8882 - accuracy: 0.764 - ETA: 33s - loss: 0.8889 - accuracy: 0.763 - ETA: 31s - loss: 0.8896 - accuracy: 0.763 - ETA: 30s - loss: 0.8907 - accuracy: 0.763 - ETA: 29s - loss: 0.8914 - accuracy: 0.762 - ETA: 28s - loss: 0.8934 - accuracy: 0.762 - ETA: 27s - loss: 0.8938 - accuracy: 0.762 - ETA: 26s - loss: 0.8943 - accuracy: 0.762 - ETA: 25s - loss: 0.8917 - accuracy: 0.762 - ETA: 23s - loss: 0.8919 - accuracy: 0.762 - ETA: 22s - loss: 0.8903 - accuracy: 0.763 - ETA: 21s - loss: 0.8908 - accuracy: 0.763 - ETA: 20s - loss: 0.8912 - accuracy: 0.763 - ETA: 19s - loss: 0.8889 - accuracy: 0.763 - ETA: 18s - loss: 0.8882 - accuracy: 0.763 - ETA: 17s - loss: 0.8876 - accuracy: 0.763 - ETA: 15s - loss: 0.8879 - accuracy: 0.763 - ETA: 14s - loss: 0.8888 - accuracy: 0.763 - ETA: 13s - loss: 0.8883 - accuracy: 0.763 - ETA: 12s - loss: 0.8878 - accuracy: 0.763 - ETA: 11s - loss: 0.8872 - accuracy: 0.763 - ETA: 10s - loss: 0.8893 - accuracy: 0.763 - ETA: 9s - loss: 0.8899 - accuracy: 0.763 - ETA: 7s - loss: 0.8905 - accuracy: 0.76 - ETA: 6s - loss: 0.8905 - accuracy: 0.76 - ETA: 5s - loss: 0.8927 - accuracy: 0.76 - ETA: 4s - loss: 0.8931 - accuracy: 0.76 - ETA: 3s - loss: 0.8932 - accuracy: 0.76 - ETA: 2s - loss: 0.8912 - accuracy: 0.76 - ETA: 1s - loss: 0.8926 - accuracy: 0.76 - 187s 10ms/step - loss: 0.8916 - accuracy: 0.7620 - val_loss: 1.6764 - val_accuracy: 0.7209\n",
      "Epoch 48/100\n",
      "19312/19312 [==============================] - ETA: 3:01 - loss: 0.7903 - accuracy: 0.77 - ETA: 2:57 - loss: 0.8041 - accuracy: 0.77 - ETA: 2:52 - loss: 0.7828 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8049 - accuracy: 0.77 - ETA: 2:45 - loss: 0.7827 - accuracy: 0.77 - ETA: 2:44 - loss: 0.7601 - accuracy: 0.77 - ETA: 2:44 - loss: 0.7694 - accuracy: 0.77 - ETA: 2:45 - loss: 0.7978 - accuracy: 0.76 - ETA: 2:43 - loss: 0.8453 - accuracy: 0.76 - ETA: 2:42 - loss: 0.8478 - accuracy: 0.76 - ETA: 2:40 - loss: 0.8489 - accuracy: 0.76 - ETA: 2:39 - loss: 0.8560 - accuracy: 0.76 - ETA: 2:38 - loss: 0.8423 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8327 - accuracy: 0.76 - ETA: 2:35 - loss: 0.8370 - accuracy: 0.76 - ETA: 2:34 - loss: 0.8465 - accuracy: 0.76 - ETA: 2:33 - loss: 0.8358 - accuracy: 0.76 - ETA: 2:33 - loss: 0.8363 - accuracy: 0.76 - ETA: 2:32 - loss: 0.8207 - accuracy: 0.76 - ETA: 2:32 - loss: 0.8004 - accuracy: 0.77 - ETA: 2:33 - loss: 0.7930 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8079 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8089 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8051 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8060 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8062 - accuracy: 0.77 - ETA: 2:27 - loss: 0.7965 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8053 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8226 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8180 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8209 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8199 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8176 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8126 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8118 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8127 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8137 - accuracy: 0.76 - ETA: 2:12 - loss: 0.8128 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8092 - accuracy: 0.76 - ETA: 2:10 - loss: 0.8079 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8125 - accuracy: 0.76 - ETA: 2:08 - loss: 0.8144 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8224 - accuracy: 0.76 - ETA: 2:06 - loss: 0.8192 - accuracy: 0.76 - ETA: 2:05 - loss: 0.8209 - accuracy: 0.76 - ETA: 2:04 - loss: 0.8255 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8280 - accuracy: 0.76 - ETA: 2:01 - loss: 0.8302 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8256 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8258 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8270 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8287 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8300 - accuracy: 0.76 - ETA: 1:54 - loss: 0.8340 - accuracy: 0.76 - ETA: 1:52 - loss: 0.8356 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8373 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8376 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8444 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8430 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8443 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8404 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8378 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8351 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8345 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8340 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8316 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8332 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8346 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8331 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8331 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8319 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8330 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8354 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8423 - accuracy: 0.76 - ETA: 1:28 - loss: 0.8426 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8455 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8480 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8456 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8534 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8514 - accuracy: 0.76 - ETA: 1:21 - loss: 0.8520 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8529 - accuracy: 0.76 - ETA: 1:19 - loss: 0.8511 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8508 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8519 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8541 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8546 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8510 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8503 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8503 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8499 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8474 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8482 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8463 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8505 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8480 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8492 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8486 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8489 - accuracy: 0.76 - ETA: 59s - loss: 0.8484 - accuracy: 0.7695 - ETA: 57s - loss: 0.8497 - accuracy: 0.769 - ETA: 56s - loss: 0.8482 - accuracy: 0.769 - ETA: 55s - loss: 0.8523 - accuracy: 0.769 - ETA: 54s - loss: 0.8545 - accuracy: 0.769 - ETA: 53s - loss: 0.8542 - accuracy: 0.769 - ETA: 52s - loss: 0.8529 - accuracy: 0.769 - ETA: 50s - loss: 0.8515 - accuracy: 0.769 - ETA: 49s - loss: 0.8512 - accuracy: 0.769 - ETA: 48s - loss: 0.8510 - accuracy: 0.770 - ETA: 47s - loss: 0.8525 - accuracy: 0.769 - ETA: 46s - loss: 0.8509 - accuracy: 0.770 - ETA: 45s - loss: 0.8508 - accuracy: 0.770 - ETA: 43s - loss: 0.8518 - accuracy: 0.769 - ETA: 42s - loss: 0.8499 - accuracy: 0.769 - ETA: 41s - loss: 0.8503 - accuracy: 0.769 - ETA: 40s - loss: 0.8505 - accuracy: 0.769 - ETA: 39s - loss: 0.8530 - accuracy: 0.769 - ETA: 38s - loss: 0.8520 - accuracy: 0.769 - ETA: 36s - loss: 0.8515 - accuracy: 0.769 - ETA: 35s - loss: 0.8507 - accuracy: 0.769 - ETA: 34s - loss: 0.8513 - accuracy: 0.769 - ETA: 33s - loss: 0.8489 - accuracy: 0.769 - ETA: 32s - loss: 0.8487 - accuracy: 0.769 - ETA: 31s - loss: 0.8504 - accuracy: 0.769 - ETA: 29s - loss: 0.8480 - accuracy: 0.769 - ETA: 28s - loss: 0.8481 - accuracy: 0.770 - ETA: 27s - loss: 0.8474 - accuracy: 0.770 - ETA: 26s - loss: 0.8456 - accuracy: 0.770 - ETA: 25s - loss: 0.8450 - accuracy: 0.770 - ETA: 24s - loss: 0.8462 - accuracy: 0.770 - ETA: 23s - loss: 0.8463 - accuracy: 0.770 - ETA: 21s - loss: 0.8486 - accuracy: 0.770 - ETA: 20s - loss: 0.8474 - accuracy: 0.770 - ETA: 19s - loss: 0.8508 - accuracy: 0.770 - ETA: 18s - loss: 0.8493 - accuracy: 0.769 - ETA: 17s - loss: 0.8489 - accuracy: 0.769 - ETA: 16s - loss: 0.8471 - accuracy: 0.770 - ETA: 14s - loss: 0.8471 - accuracy: 0.770 - ETA: 13s - loss: 0.8463 - accuracy: 0.770 - ETA: 12s - loss: 0.8479 - accuracy: 0.770 - ETA: 11s - loss: 0.8480 - accuracy: 0.769 - ETA: 10s - loss: 0.8473 - accuracy: 0.769 - ETA: 9s - loss: 0.8473 - accuracy: 0.769 - ETA: 7s - loss: 0.8472 - accuracy: 0.77 - ETA: 6s - loss: 0.8460 - accuracy: 0.77 - ETA: 5s - loss: 0.8451 - accuracy: 0.77 - ETA: 4s - loss: 0.8454 - accuracy: 0.76 - ETA: 3s - loss: 0.8466 - accuracy: 0.76 - ETA: 2s - loss: 0.8477 - accuracy: 0.76 - ETA: 1s - loss: 0.8469 - accuracy: 0.76 - 188s 10ms/step - loss: 0.8477 - accuracy: 0.7690 - val_loss: 1.6882 - val_accuracy: 0.7175\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:50 - loss: 0.8879 - accuracy: 0.77 - ETA: 2:50 - loss: 0.8320 - accuracy: 0.75 - ETA: 2:46 - loss: 0.8171 - accuracy: 0.77 - ETA: 2:46 - loss: 0.7939 - accuracy: 0.78 - ETA: 2:45 - loss: 0.7818 - accuracy: 0.78 - ETA: 2:42 - loss: 0.7431 - accuracy: 0.79 - ETA: 2:41 - loss: 0.7524 - accuracy: 0.78 - ETA: 2:40 - loss: 0.7865 - accuracy: 0.77 - ETA: 2:38 - loss: 0.8038 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8099 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8088 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8099 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8024 - accuracy: 0.76 - ETA: 2:35 - loss: 0.8169 - accuracy: 0.75 - ETA: 2:33 - loss: 0.8310 - accuracy: 0.75 - ETA: 2:32 - loss: 0.8264 - accuracy: 0.75 - ETA: 2:31 - loss: 0.8312 - accuracy: 0.75 - ETA: 2:30 - loss: 0.8381 - accuracy: 0.75 - ETA: 2:29 - loss: 0.8404 - accuracy: 0.75 - ETA: 2:27 - loss: 0.8418 - accuracy: 0.75 - ETA: 2:26 - loss: 0.8360 - accuracy: 0.75 - ETA: 2:25 - loss: 0.8329 - accuracy: 0.75 - ETA: 2:24 - loss: 0.8670 - accuracy: 0.75 - ETA: 2:23 - loss: 0.8564 - accuracy: 0.75 - ETA: 2:22 - loss: 0.8561 - accuracy: 0.75 - ETA: 2:22 - loss: 0.8459 - accuracy: 0.75 - ETA: 2:21 - loss: 0.8493 - accuracy: 0.75 - ETA: 2:20 - loss: 0.8455 - accuracy: 0.75 - ETA: 2:19 - loss: 0.8448 - accuracy: 0.75 - ETA: 2:17 - loss: 0.8383 - accuracy: 0.75 - ETA: 2:16 - loss: 0.8387 - accuracy: 0.75 - ETA: 2:15 - loss: 0.8342 - accuracy: 0.75 - ETA: 2:13 - loss: 0.8344 - accuracy: 0.76 - ETA: 2:12 - loss: 0.8337 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8388 - accuracy: 0.76 - ETA: 2:10 - loss: 0.8363 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8411 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8472 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8464 - accuracy: 0.76 - ETA: 2:06 - loss: 0.8550 - accuracy: 0.76 - ETA: 2:04 - loss: 0.8512 - accuracy: 0.76 - ETA: 2:03 - loss: 0.8533 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8526 - accuracy: 0.76 - ETA: 2:01 - loss: 0.8625 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8662 - accuracy: 0.76 - ETA: 1:59 - loss: 0.8640 - accuracy: 0.76 - ETA: 1:57 - loss: 0.8645 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8592 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8661 - accuracy: 0.75 - ETA: 1:54 - loss: 0.8617 - accuracy: 0.76 - ETA: 1:53 - loss: 0.8620 - accuracy: 0.76 - ETA: 1:52 - loss: 0.8592 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8566 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8555 - accuracy: 0.76 - ETA: 1:48 - loss: 0.8559 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8507 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8533 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8509 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8486 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8479 - accuracy: 0.76 - ETA: 1:41 - loss: 0.8457 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8472 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8462 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8480 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8448 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8467 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8491 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8489 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8480 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8445 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8445 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8486 - accuracy: 0.76 - ETA: 1:28 - loss: 0.8487 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8493 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8483 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8461 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8478 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8465 - accuracy: 0.76 - ETA: 1:21 - loss: 0.8492 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8477 - accuracy: 0.76 - ETA: 1:19 - loss: 0.8499 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8542 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8523 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8513 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8517 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8518 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8533 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8519 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8501 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8471 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8448 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8459 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8432 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8421 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8425 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8439 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8414 - accuracy: 0.76 - ETA: 59s - loss: 0.8455 - accuracy: 0.7647 - ETA: 58s - loss: 0.8468 - accuracy: 0.764 - ETA: 57s - loss: 0.8497 - accuracy: 0.763 - ETA: 56s - loss: 0.8494 - accuracy: 0.763 - ETA: 55s - loss: 0.8496 - accuracy: 0.763 - ETA: 54s - loss: 0.8536 - accuracy: 0.763 - ETA: 53s - loss: 0.8524 - accuracy: 0.763 - ETA: 51s - loss: 0.8516 - accuracy: 0.763 - ETA: 50s - loss: 0.8482 - accuracy: 0.764 - ETA: 49s - loss: 0.8488 - accuracy: 0.764 - ETA: 48s - loss: 0.8498 - accuracy: 0.764 - ETA: 47s - loss: 0.8487 - accuracy: 0.764 - ETA: 46s - loss: 0.8488 - accuracy: 0.764 - ETA: 45s - loss: 0.8501 - accuracy: 0.764 - ETA: 44s - loss: 0.8531 - accuracy: 0.764 - ETA: 42s - loss: 0.8524 - accuracy: 0.764 - ETA: 41s - loss: 0.8500 - accuracy: 0.765 - ETA: 40s - loss: 0.8499 - accuracy: 0.765 - ETA: 39s - loss: 0.8505 - accuracy: 0.764 - ETA: 38s - loss: 0.8503 - accuracy: 0.764 - ETA: 37s - loss: 0.8557 - accuracy: 0.764 - ETA: 36s - loss: 0.8571 - accuracy: 0.764 - ETA: 34s - loss: 0.8567 - accuracy: 0.764 - ETA: 33s - loss: 0.8533 - accuracy: 0.765 - ETA: 32s - loss: 0.8550 - accuracy: 0.764 - ETA: 31s - loss: 0.8564 - accuracy: 0.764 - ETA: 30s - loss: 0.8574 - accuracy: 0.764 - ETA: 29s - loss: 0.8571 - accuracy: 0.765 - ETA: 28s - loss: 0.8561 - accuracy: 0.765 - ETA: 27s - loss: 0.8534 - accuracy: 0.765 - ETA: 25s - loss: 0.8516 - accuracy: 0.766 - ETA: 24s - loss: 0.8516 - accuracy: 0.766 - ETA: 23s - loss: 0.8506 - accuracy: 0.766 - ETA: 22s - loss: 0.8524 - accuracy: 0.766 - ETA: 21s - loss: 0.8527 - accuracy: 0.765 - ETA: 20s - loss: 0.8544 - accuracy: 0.765 - ETA: 19s - loss: 0.8528 - accuracy: 0.765 - ETA: 17s - loss: 0.8518 - accuracy: 0.765 - ETA: 16s - loss: 0.8503 - accuracy: 0.766 - ETA: 15s - loss: 0.8497 - accuracy: 0.766 - ETA: 14s - loss: 0.8492 - accuracy: 0.766 - ETA: 13s - loss: 0.8486 - accuracy: 0.766 - ETA: 12s - loss: 0.8506 - accuracy: 0.765 - ETA: 11s - loss: 0.8507 - accuracy: 0.766 - ETA: 10s - loss: 0.8522 - accuracy: 0.766 - ETA: 8s - loss: 0.8550 - accuracy: 0.766 - ETA: 7s - loss: 0.8559 - accuracy: 0.76 - ETA: 6s - loss: 0.8552 - accuracy: 0.76 - ETA: 5s - loss: 0.8534 - accuracy: 0.76 - ETA: 4s - loss: 0.8558 - accuracy: 0.76 - ETA: 3s - loss: 0.8566 - accuracy: 0.76 - ETA: 2s - loss: 0.8584 - accuracy: 0.76 - ETA: 0s - loss: 0.8640 - accuracy: 0.76 - 183s 9ms/step - loss: 0.8649 - accuracy: 0.7645 - val_loss: 1.8773 - val_accuracy: 0.7159\n",
      "Epoch 50/100\n",
      "19312/19312 [==============================] - ETA: 2:51 - loss: 0.8238 - accuracy: 0.76 - ETA: 2:49 - loss: 0.7861 - accuracy: 0.76 - ETA: 2:45 - loss: 0.8363 - accuracy: 0.76 - ETA: 2:45 - loss: 0.8303 - accuracy: 0.76 - ETA: 2:48 - loss: 0.8046 - accuracy: 0.75 - ETA: 2:47 - loss: 0.8063 - accuracy: 0.76 - ETA: 2:46 - loss: 0.8499 - accuracy: 0.75 - ETA: 2:44 - loss: 0.8626 - accuracy: 0.76 - ETA: 2:44 - loss: 0.8958 - accuracy: 0.75 - ETA: 2:43 - loss: 0.9067 - accuracy: 0.75 - ETA: 2:41 - loss: 0.8848 - accuracy: 0.75 - ETA: 2:39 - loss: 0.8688 - accuracy: 0.75 - ETA: 2:38 - loss: 0.8583 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8608 - accuracy: 0.75 - ETA: 2:35 - loss: 0.8723 - accuracy: 0.75 - ETA: 2:33 - loss: 0.8860 - accuracy: 0.75 - ETA: 2:33 - loss: 0.9023 - accuracy: 0.75 - ETA: 2:32 - loss: 0.8926 - accuracy: 0.75 - ETA: 2:32 - loss: 0.8959 - accuracy: 0.75 - ETA: 2:31 - loss: 0.8861 - accuracy: 0.75 - ETA: 2:29 - loss: 0.8848 - accuracy: 0.75 - ETA: 2:28 - loss: 0.8755 - accuracy: 0.76 - ETA: 2:27 - loss: 0.8659 - accuracy: 0.76 - ETA: 2:25 - loss: 0.8690 - accuracy: 0.76 - ETA: 2:24 - loss: 0.8757 - accuracy: 0.76 - ETA: 2:23 - loss: 0.8692 - accuracy: 0.76 - ETA: 2:22 - loss: 0.8739 - accuracy: 0.76 - ETA: 2:21 - loss: 0.8708 - accuracy: 0.76 - ETA: 2:19 - loss: 0.8702 - accuracy: 0.76 - ETA: 2:18 - loss: 0.8763 - accuracy: 0.76 - ETA: 2:17 - loss: 0.8723 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8875 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8858 - accuracy: 0.76 - ETA: 2:13 - loss: 0.8889 - accuracy: 0.76 - ETA: 2:12 - loss: 0.8917 - accuracy: 0.76 - ETA: 2:11 - loss: 0.9042 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8958 - accuracy: 0.76 - ETA: 2:08 - loss: 0.8873 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8894 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8944 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8867 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8894 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8881 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8928 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8961 - accuracy: 0.76 - ETA: 1:59 - loss: 0.8921 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8866 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8870 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8886 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8884 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8956 - accuracy: 0.76 - ETA: 1:53 - loss: 0.8962 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8922 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8927 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8862 - accuracy: 0.76 - ETA: 1:48 - loss: 0.8837 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8813 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8850 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8855 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8813 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8758 - accuracy: 0.76 - ETA: 1:41 - loss: 0.8748 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8743 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8725 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8721 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8719 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8780 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8756 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8788 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8928 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8889 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8844 - accuracy: 0.76 - ETA: 1:28 - loss: 0.8847 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8824 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8853 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8855 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8817 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8853 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8854 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8848 - accuracy: 0.76 - ETA: 1:19 - loss: 0.8844 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8824 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8907 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8904 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8913 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8978 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8951 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8933 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8936 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8925 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8916 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8904 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8902 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8895 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8898 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8902 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8939 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8979 - accuracy: 0.76 - ETA: 59s - loss: 0.8964 - accuracy: 0.7648 - ETA: 58s - loss: 0.8955 - accuracy: 0.765 - ETA: 57s - loss: 0.8936 - accuracy: 0.764 - ETA: 56s - loss: 0.8932 - accuracy: 0.764 - ETA: 55s - loss: 0.8936 - accuracy: 0.764 - ETA: 53s - loss: 0.8921 - accuracy: 0.764 - ETA: 52s - loss: 0.8904 - accuracy: 0.764 - ETA: 51s - loss: 0.8907 - accuracy: 0.764 - ETA: 50s - loss: 0.8906 - accuracy: 0.765 - ETA: 49s - loss: 0.8893 - accuracy: 0.765 - ETA: 48s - loss: 0.8876 - accuracy: 0.765 - ETA: 46s - loss: 0.8881 - accuracy: 0.765 - ETA: 45s - loss: 0.8886 - accuracy: 0.764 - ETA: 44s - loss: 0.8912 - accuracy: 0.764 - ETA: 43s - loss: 0.8909 - accuracy: 0.764 - ETA: 42s - loss: 0.8899 - accuracy: 0.764 - ETA: 41s - loss: 0.8902 - accuracy: 0.764 - ETA: 40s - loss: 0.8900 - accuracy: 0.763 - ETA: 38s - loss: 0.8929 - accuracy: 0.763 - ETA: 37s - loss: 0.8912 - accuracy: 0.763 - ETA: 36s - loss: 0.8925 - accuracy: 0.762 - ETA: 35s - loss: 0.8916 - accuracy: 0.762 - ETA: 34s - loss: 0.8905 - accuracy: 0.762 - ETA: 33s - loss: 0.8903 - accuracy: 0.762 - ETA: 31s - loss: 0.8931 - accuracy: 0.762 - ETA: 30s - loss: 0.8910 - accuracy: 0.762 - ETA: 29s - loss: 0.8906 - accuracy: 0.762 - ETA: 28s - loss: 0.8925 - accuracy: 0.762 - ETA: 27s - loss: 0.8927 - accuracy: 0.761 - ETA: 26s - loss: 0.8916 - accuracy: 0.761 - ETA: 25s - loss: 0.8949 - accuracy: 0.761 - ETA: 23s - loss: 0.8943 - accuracy: 0.761 - ETA: 22s - loss: 0.8944 - accuracy: 0.761 - ETA: 21s - loss: 0.8949 - accuracy: 0.761 - ETA: 20s - loss: 0.8954 - accuracy: 0.761 - ETA: 19s - loss: 0.8940 - accuracy: 0.761 - ETA: 18s - loss: 0.8940 - accuracy: 0.761 - ETA: 17s - loss: 0.8931 - accuracy: 0.761 - ETA: 15s - loss: 0.8939 - accuracy: 0.761 - ETA: 14s - loss: 0.8919 - accuracy: 0.762 - ETA: 13s - loss: 0.8928 - accuracy: 0.762 - ETA: 12s - loss: 0.8924 - accuracy: 0.762 - ETA: 11s - loss: 0.8934 - accuracy: 0.762 - ETA: 10s - loss: 0.8949 - accuracy: 0.761 - ETA: 9s - loss: 0.8949 - accuracy: 0.761 - ETA: 7s - loss: 0.8936 - accuracy: 0.76 - ETA: 6s - loss: 0.8940 - accuracy: 0.76 - ETA: 5s - loss: 0.8951 - accuracy: 0.76 - ETA: 4s - loss: 0.8984 - accuracy: 0.76 - ETA: 3s - loss: 0.8982 - accuracy: 0.76 - ETA: 2s - loss: 0.8963 - accuracy: 0.76 - ETA: 1s - loss: 0.8950 - accuracy: 0.76 - 186s 10ms/step - loss: 0.8951 - accuracy: 0.7620 - val_loss: 1.6687 - val_accuracy: 0.7142\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:58 - loss: 0.5865 - accuracy: 0.81 - ETA: 2:52 - loss: 0.6970 - accuracy: 0.78 - ETA: 2:49 - loss: 1.0006 - accuracy: 0.77 - ETA: 2:46 - loss: 1.0996 - accuracy: 0.77 - ETA: 2:45 - loss: 1.0139 - accuracy: 0.77 - ETA: 2:44 - loss: 0.9994 - accuracy: 0.76 - ETA: 2:42 - loss: 0.9725 - accuracy: 0.76 - ETA: 2:41 - loss: 0.9247 - accuracy: 0.77 - ETA: 2:40 - loss: 0.9841 - accuracy: 0.76 - ETA: 2:47 - loss: 0.9472 - accuracy: 0.76 - ETA: 2:46 - loss: 0.9347 - accuracy: 0.76 - ETA: 2:45 - loss: 0.9134 - accuracy: 0.76 - ETA: 2:44 - loss: 0.9192 - accuracy: 0.76 - ETA: 2:43 - loss: 0.9143 - accuracy: 0.76 - ETA: 2:42 - loss: 0.8905 - accuracy: 0.76 - ETA: 2:40 - loss: 0.8956 - accuracy: 0.76 - ETA: 2:40 - loss: 0.9058 - accuracy: 0.76 - ETA: 2:39 - loss: 0.9088 - accuracy: 0.76 - ETA: 2:37 - loss: 0.9084 - accuracy: 0.76 - ETA: 2:35 - loss: 0.9040 - accuracy: 0.76 - ETA: 2:34 - loss: 0.9054 - accuracy: 0.76 - ETA: 2:33 - loss: 0.9013 - accuracy: 0.76 - ETA: 2:32 - loss: 0.9010 - accuracy: 0.76 - ETA: 2:31 - loss: 0.8888 - accuracy: 0.76 - ETA: 2:29 - loss: 0.8985 - accuracy: 0.76 - ETA: 2:28 - loss: 0.9446 - accuracy: 0.76 - ETA: 2:26 - loss: 0.9419 - accuracy: 0.76 - ETA: 2:24 - loss: 0.9401 - accuracy: 0.76 - ETA: 2:23 - loss: 0.9188 - accuracy: 0.76 - ETA: 2:21 - loss: 0.9127 - accuracy: 0.76 - ETA: 2:20 - loss: 0.9063 - accuracy: 0.76 - ETA: 2:18 - loss: 0.8994 - accuracy: 0.76 - ETA: 2:17 - loss: 0.9031 - accuracy: 0.76 - ETA: 2:16 - loss: 0.8987 - accuracy: 0.76 - ETA: 2:14 - loss: 0.8986 - accuracy: 0.76 - ETA: 2:13 - loss: 0.8996 - accuracy: 0.76 - ETA: 2:12 - loss: 0.8863 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8792 - accuracy: 0.76 - ETA: 2:10 - loss: 0.8786 - accuracy: 0.76 - ETA: 2:08 - loss: 0.8827 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8788 - accuracy: 0.76 - ETA: 2:06 - loss: 0.8722 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8696 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8707 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8659 - accuracy: 0.76 - ETA: 2:01 - loss: 0.8684 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8680 - accuracy: 0.76 - ETA: 1:59 - loss: 0.8709 - accuracy: 0.76 - ETA: 1:58 - loss: 0.8683 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8714 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8750 - accuracy: 0.76 - ETA: 1:54 - loss: 0.8691 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8687 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8701 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8768 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8795 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8786 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8831 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8824 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8822 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8839 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8814 - accuracy: 0.76 - ETA: 1:41 - loss: 0.8798 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8759 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8736 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8795 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8820 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8831 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8815 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8793 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8789 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8785 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8809 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8785 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8762 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8744 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8785 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8771 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8800 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8772 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8765 - accuracy: 0.76 - ETA: 1:19 - loss: 0.8750 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8737 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8746 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8787 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8769 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8767 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8774 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8762 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8786 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8780 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8791 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8788 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8775 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8787 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8765 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8757 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8746 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8737 - accuracy: 0.76 - ETA: 58s - loss: 0.8696 - accuracy: 0.7646 - ETA: 57s - loss: 0.8688 - accuracy: 0.764 - ETA: 56s - loss: 0.8701 - accuracy: 0.763 - ETA: 55s - loss: 0.8703 - accuracy: 0.764 - ETA: 54s - loss: 0.8701 - accuracy: 0.764 - ETA: 52s - loss: 0.8722 - accuracy: 0.764 - ETA: 51s - loss: 0.8725 - accuracy: 0.764 - ETA: 50s - loss: 0.8762 - accuracy: 0.763 - ETA: 49s - loss: 0.8768 - accuracy: 0.763 - ETA: 48s - loss: 0.8804 - accuracy: 0.763 - ETA: 47s - loss: 0.8794 - accuracy: 0.763 - ETA: 46s - loss: 0.8781 - accuracy: 0.763 - ETA: 44s - loss: 0.8808 - accuracy: 0.763 - ETA: 43s - loss: 0.8806 - accuracy: 0.762 - ETA: 42s - loss: 0.8802 - accuracy: 0.763 - ETA: 41s - loss: 0.8774 - accuracy: 0.763 - ETA: 40s - loss: 0.8778 - accuracy: 0.763 - ETA: 39s - loss: 0.8790 - accuracy: 0.763 - ETA: 37s - loss: 0.8801 - accuracy: 0.764 - ETA: 36s - loss: 0.8791 - accuracy: 0.764 - ETA: 35s - loss: 0.8775 - accuracy: 0.764 - ETA: 34s - loss: 0.8760 - accuracy: 0.764 - ETA: 33s - loss: 0.8758 - accuracy: 0.764 - ETA: 32s - loss: 0.8745 - accuracy: 0.764 - ETA: 31s - loss: 0.8762 - accuracy: 0.764 - ETA: 29s - loss: 0.8763 - accuracy: 0.764 - ETA: 28s - loss: 0.8757 - accuracy: 0.764 - ETA: 27s - loss: 0.8758 - accuracy: 0.764 - ETA: 26s - loss: 0.8739 - accuracy: 0.765 - ETA: 25s - loss: 0.8733 - accuracy: 0.765 - ETA: 24s - loss: 0.8735 - accuracy: 0.765 - ETA: 22s - loss: 0.8749 - accuracy: 0.765 - ETA: 21s - loss: 0.8779 - accuracy: 0.764 - ETA: 20s - loss: 0.8779 - accuracy: 0.764 - ETA: 19s - loss: 0.8790 - accuracy: 0.764 - ETA: 18s - loss: 0.8781 - accuracy: 0.765 - ETA: 17s - loss: 0.8788 - accuracy: 0.765 - ETA: 16s - loss: 0.8766 - accuracy: 0.765 - ETA: 14s - loss: 0.8764 - accuracy: 0.765 - ETA: 13s - loss: 0.8768 - accuracy: 0.765 - ETA: 12s - loss: 0.8765 - accuracy: 0.765 - ETA: 11s - loss: 0.8753 - accuracy: 0.766 - ETA: 10s - loss: 0.8746 - accuracy: 0.766 - ETA: 9s - loss: 0.8746 - accuracy: 0.766 - ETA: 7s - loss: 0.8733 - accuracy: 0.76 - ETA: 6s - loss: 0.8758 - accuracy: 0.76 - ETA: 5s - loss: 0.8746 - accuracy: 0.76 - ETA: 4s - loss: 0.8742 - accuracy: 0.76 - ETA: 3s - loss: 0.8723 - accuracy: 0.76 - ETA: 2s - loss: 0.8722 - accuracy: 0.76 - ETA: 1s - loss: 0.8727 - accuracy: 0.76 - 186s 10ms/step - loss: 0.8726 - accuracy: 0.7661 - val_loss: 1.8670 - val_accuracy: 0.7128\n",
      "Epoch 52/100\n",
      "19312/19312 [==============================] - ETA: 2:56 - loss: 1.2121 - accuracy: 0.71 - ETA: 2:56 - loss: 1.0866 - accuracy: 0.73 - ETA: 2:54 - loss: 0.9348 - accuracy: 0.75 - ETA: 2:51 - loss: 0.8611 - accuracy: 0.76 - ETA: 2:49 - loss: 0.8109 - accuracy: 0.77 - ETA: 2:46 - loss: 0.8093 - accuracy: 0.76 - ETA: 2:44 - loss: 0.7874 - accuracy: 0.77 - ETA: 2:43 - loss: 0.7963 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8435 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8426 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8267 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8223 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8771 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8668 - accuracy: 0.76 - ETA: 2:34 - loss: 0.8665 - accuracy: 0.76 - ETA: 2:34 - loss: 0.8492 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8436 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8500 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8584 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8553 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8501 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8394 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8345 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8351 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8364 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8310 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8266 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8378 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8381 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8445 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8414 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8442 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8517 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8551 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8571 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8581 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8565 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8658 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8673 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8707 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8702 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8670 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8664 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8713 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8647 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8637 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8658 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8574 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8625 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8642 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8690 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8695 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8650 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8629 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8644 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8777 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8741 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8699 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8741 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8699 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8677 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8703 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8712 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8666 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8712 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8677 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8656 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8662 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8632 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8681 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8638 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8606 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8644 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8645 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8627 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8604 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8577 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8604 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8607 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8588 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8582 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8572 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8554 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8566 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8579 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8588 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8575 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8558 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8549 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8557 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8565 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8577 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8576 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8560 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8570 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8562 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8558 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8566 - accuracy: 0.77 - ETA: 58s - loss: 0.8550 - accuracy: 0.7759 - ETA: 57s - loss: 0.8543 - accuracy: 0.775 - ETA: 56s - loss: 0.8581 - accuracy: 0.775 - ETA: 55s - loss: 0.8574 - accuracy: 0.775 - ETA: 54s - loss: 0.8551 - accuracy: 0.776 - ETA: 53s - loss: 0.8536 - accuracy: 0.776 - ETA: 52s - loss: 0.8509 - accuracy: 0.776 - ETA: 50s - loss: 0.8502 - accuracy: 0.777 - ETA: 49s - loss: 0.8491 - accuracy: 0.776 - ETA: 48s - loss: 0.8481 - accuracy: 0.776 - ETA: 47s - loss: 0.8471 - accuracy: 0.776 - ETA: 46s - loss: 0.8480 - accuracy: 0.776 - ETA: 45s - loss: 0.8492 - accuracy: 0.775 - ETA: 44s - loss: 0.8533 - accuracy: 0.776 - ETA: 42s - loss: 0.8522 - accuracy: 0.776 - ETA: 41s - loss: 0.8515 - accuracy: 0.776 - ETA: 40s - loss: 0.8519 - accuracy: 0.776 - ETA: 39s - loss: 0.8546 - accuracy: 0.775 - ETA: 38s - loss: 0.8531 - accuracy: 0.775 - ETA: 37s - loss: 0.8537 - accuracy: 0.775 - ETA: 36s - loss: 0.8536 - accuracy: 0.775 - ETA: 35s - loss: 0.8565 - accuracy: 0.774 - ETA: 33s - loss: 0.8578 - accuracy: 0.774 - ETA: 32s - loss: 0.8577 - accuracy: 0.773 - ETA: 31s - loss: 0.8601 - accuracy: 0.773 - ETA: 30s - loss: 0.8597 - accuracy: 0.773 - ETA: 29s - loss: 0.8597 - accuracy: 0.773 - ETA: 28s - loss: 0.8579 - accuracy: 0.773 - ETA: 27s - loss: 0.8590 - accuracy: 0.773 - ETA: 25s - loss: 0.8571 - accuracy: 0.774 - ETA: 24s - loss: 0.8579 - accuracy: 0.773 - ETA: 23s - loss: 0.8576 - accuracy: 0.773 - ETA: 22s - loss: 0.8559 - accuracy: 0.774 - ETA: 21s - loss: 0.8562 - accuracy: 0.773 - ETA: 20s - loss: 0.8554 - accuracy: 0.773 - ETA: 19s - loss: 0.8556 - accuracy: 0.773 - ETA: 18s - loss: 0.8548 - accuracy: 0.773 - ETA: 16s - loss: 0.8545 - accuracy: 0.773 - ETA: 15s - loss: 0.8565 - accuracy: 0.772 - ETA: 14s - loss: 0.8590 - accuracy: 0.772 - ETA: 13s - loss: 0.8603 - accuracy: 0.772 - ETA: 12s - loss: 0.8612 - accuracy: 0.772 - ETA: 11s - loss: 0.8605 - accuracy: 0.772 - ETA: 10s - loss: 0.8599 - accuracy: 0.771 - ETA: 8s - loss: 0.8611 - accuracy: 0.771 - ETA: 7s - loss: 0.8628 - accuracy: 0.77 - ETA: 6s - loss: 0.8624 - accuracy: 0.77 - ETA: 5s - loss: 0.8604 - accuracy: 0.77 - ETA: 4s - loss: 0.8615 - accuracy: 0.77 - ETA: 3s - loss: 0.8613 - accuracy: 0.77 - ETA: 2s - loss: 0.8620 - accuracy: 0.77 - ETA: 0s - loss: 0.8602 - accuracy: 0.77 - 183s 9ms/step - loss: 0.8600 - accuracy: 0.7716 - val_loss: 1.9037 - val_accuracy: 0.7186\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:47 - loss: 0.3946 - accuracy: 0.83 - ETA: 2:48 - loss: 0.6140 - accuracy: 0.83 - ETA: 2:47 - loss: 0.7188 - accuracy: 0.80 - ETA: 2:45 - loss: 0.6577 - accuracy: 0.81 - ETA: 2:43 - loss: 0.6920 - accuracy: 0.79 - ETA: 2:43 - loss: 0.7035 - accuracy: 0.79 - ETA: 2:41 - loss: 0.7303 - accuracy: 0.79 - ETA: 2:41 - loss: 0.7484 - accuracy: 0.78 - ETA: 2:40 - loss: 0.7629 - accuracy: 0.78 - ETA: 2:40 - loss: 0.7915 - accuracy: 0.78 - ETA: 2:39 - loss: 0.8106 - accuracy: 0.78 - ETA: 2:38 - loss: 0.8252 - accuracy: 0.78 - ETA: 2:37 - loss: 0.8456 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8482 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8322 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8310 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8389 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8301 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8359 - accuracy: 0.78 - ETA: 2:29 - loss: 0.8454 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8412 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8490 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8511 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8609 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8536 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8609 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8510 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8615 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8584 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8536 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8475 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8584 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8655 - accuracy: 0.76 - ETA: 2:13 - loss: 0.8694 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8733 - accuracy: 0.76 - ETA: 2:10 - loss: 0.8799 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8770 - accuracy: 0.76 - ETA: 2:08 - loss: 0.8686 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8647 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8634 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8751 - accuracy: 0.76 - ETA: 2:03 - loss: 0.8755 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8737 - accuracy: 0.76 - ETA: 2:01 - loss: 0.8703 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8699 - accuracy: 0.76 - ETA: 1:59 - loss: 0.8725 - accuracy: 0.76 - ETA: 1:57 - loss: 0.8653 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8612 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8579 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8570 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8558 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8533 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8556 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8553 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8531 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8528 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8512 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8529 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8540 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8586 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8559 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8537 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8511 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8524 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8537 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8519 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8533 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8548 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8537 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8529 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8522 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8505 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8520 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8518 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8534 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8525 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8575 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8591 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8634 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8591 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8651 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8691 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8700 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8696 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8696 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8694 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8718 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8726 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8702 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8720 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8724 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8727 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8748 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8735 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8725 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8724 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8702 - accuracy: 0.76 - ETA: 59s - loss: 0.8663 - accuracy: 0.7682 - ETA: 58s - loss: 0.8667 - accuracy: 0.768 - ETA: 57s - loss: 0.8672 - accuracy: 0.767 - ETA: 56s - loss: 0.8665 - accuracy: 0.768 - ETA: 55s - loss: 0.8667 - accuracy: 0.768 - ETA: 54s - loss: 0.8665 - accuracy: 0.768 - ETA: 53s - loss: 0.8675 - accuracy: 0.768 - ETA: 52s - loss: 0.8676 - accuracy: 0.768 - ETA: 50s - loss: 0.8668 - accuracy: 0.768 - ETA: 49s - loss: 0.8672 - accuracy: 0.769 - ETA: 48s - loss: 0.8678 - accuracy: 0.769 - ETA: 47s - loss: 0.8670 - accuracy: 0.769 - ETA: 46s - loss: 0.8643 - accuracy: 0.770 - ETA: 45s - loss: 0.8652 - accuracy: 0.769 - ETA: 44s - loss: 0.8632 - accuracy: 0.770 - ETA: 42s - loss: 0.8628 - accuracy: 0.770 - ETA: 41s - loss: 0.8630 - accuracy: 0.770 - ETA: 40s - loss: 0.8653 - accuracy: 0.770 - ETA: 39s - loss: 0.8685 - accuracy: 0.769 - ETA: 38s - loss: 0.8662 - accuracy: 0.770 - ETA: 37s - loss: 0.8642 - accuracy: 0.770 - ETA: 36s - loss: 0.8659 - accuracy: 0.769 - ETA: 34s - loss: 0.8660 - accuracy: 0.769 - ETA: 33s - loss: 0.8655 - accuracy: 0.769 - ETA: 32s - loss: 0.8672 - accuracy: 0.768 - ETA: 31s - loss: 0.8653 - accuracy: 0.769 - ETA: 30s - loss: 0.8626 - accuracy: 0.769 - ETA: 29s - loss: 0.8622 - accuracy: 0.769 - ETA: 28s - loss: 0.8615 - accuracy: 0.769 - ETA: 27s - loss: 0.8618 - accuracy: 0.769 - ETA: 25s - loss: 0.8607 - accuracy: 0.770 - ETA: 24s - loss: 0.8612 - accuracy: 0.769 - ETA: 23s - loss: 0.8637 - accuracy: 0.769 - ETA: 22s - loss: 0.8643 - accuracy: 0.769 - ETA: 21s - loss: 0.8639 - accuracy: 0.769 - ETA: 20s - loss: 0.8619 - accuracy: 0.769 - ETA: 19s - loss: 0.8620 - accuracy: 0.769 - ETA: 17s - loss: 0.8597 - accuracy: 0.770 - ETA: 16s - loss: 0.8586 - accuracy: 0.770 - ETA: 15s - loss: 0.8593 - accuracy: 0.769 - ETA: 14s - loss: 0.8618 - accuracy: 0.769 - ETA: 13s - loss: 0.8637 - accuracy: 0.769 - ETA: 12s - loss: 0.8638 - accuracy: 0.768 - ETA: 11s - loss: 0.8650 - accuracy: 0.768 - ETA: 10s - loss: 0.8647 - accuracy: 0.768 - ETA: 8s - loss: 0.8665 - accuracy: 0.768 - ETA: 7s - loss: 0.8666 - accuracy: 0.76 - ETA: 6s - loss: 0.8678 - accuracy: 0.76 - ETA: 5s - loss: 0.8675 - accuracy: 0.76 - ETA: 4s - loss: 0.8671 - accuracy: 0.76 - ETA: 3s - loss: 0.8673 - accuracy: 0.76 - ETA: 2s - loss: 0.8683 - accuracy: 0.76 - ETA: 0s - loss: 0.8678 - accuracy: 0.77 - 182s 9ms/step - loss: 0.8670 - accuracy: 0.7699 - val_loss: 1.8175 - val_accuracy: 0.7177\n",
      "Epoch 54/100\n",
      "19312/19312 [==============================] - ETA: 2:53 - loss: 0.7232 - accuracy: 0.79 - ETA: 2:47 - loss: 0.8338 - accuracy: 0.74 - ETA: 2:47 - loss: 0.7671 - accuracy: 0.76 - ETA: 2:48 - loss: 0.7776 - accuracy: 0.76 - ETA: 2:48 - loss: 0.8297 - accuracy: 0.76 - ETA: 2:48 - loss: 0.8014 - accuracy: 0.76 - ETA: 2:45 - loss: 0.8234 - accuracy: 0.75 - ETA: 2:43 - loss: 0.8841 - accuracy: 0.74 - ETA: 2:41 - loss: 0.9008 - accuracy: 0.74 - ETA: 2:40 - loss: 0.8733 - accuracy: 0.74 - ETA: 2:38 - loss: 0.8644 - accuracy: 0.75 - ETA: 2:36 - loss: 0.8783 - accuracy: 0.75 - ETA: 2:35 - loss: 0.8588 - accuracy: 0.75 - ETA: 2:34 - loss: 0.8672 - accuracy: 0.75 - ETA: 2:33 - loss: 0.8717 - accuracy: 0.75 - ETA: 2:31 - loss: 0.8588 - accuracy: 0.75 - ETA: 2:30 - loss: 0.8408 - accuracy: 0.76 - ETA: 2:29 - loss: 0.8316 - accuracy: 0.76 - ETA: 2:29 - loss: 0.8259 - accuracy: 0.76 - ETA: 2:28 - loss: 0.8183 - accuracy: 0.76 - ETA: 2:27 - loss: 0.8270 - accuracy: 0.76 - ETA: 2:26 - loss: 0.8216 - accuracy: 0.76 - ETA: 2:25 - loss: 0.8142 - accuracy: 0.76 - ETA: 2:23 - loss: 0.8139 - accuracy: 0.76 - ETA: 2:22 - loss: 0.8116 - accuracy: 0.76 - ETA: 2:20 - loss: 0.8059 - accuracy: 0.76 - ETA: 2:19 - loss: 0.8013 - accuracy: 0.77 - ETA: 2:18 - loss: 0.7894 - accuracy: 0.77 - ETA: 2:17 - loss: 0.7835 - accuracy: 0.77 - ETA: 2:16 - loss: 0.7987 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8194 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8137 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8133 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8147 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8209 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8221 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8239 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8247 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8314 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8322 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8306 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8336 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8340 - accuracy: 0.76 - ETA: 2:01 - loss: 0.8412 - accuracy: 0.76 - ETA: 1:59 - loss: 0.8409 - accuracy: 0.76 - ETA: 1:58 - loss: 0.8405 - accuracy: 0.76 - ETA: 1:57 - loss: 0.8359 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8365 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8348 - accuracy: 0.76 - ETA: 1:54 - loss: 0.8382 - accuracy: 0.76 - ETA: 1:53 - loss: 0.8412 - accuracy: 0.76 - ETA: 1:52 - loss: 0.8428 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8384 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8384 - accuracy: 0.76 - ETA: 1:48 - loss: 0.8377 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8399 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8394 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8400 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8363 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8388 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8371 - accuracy: 0.76 - ETA: 1:41 - loss: 0.8374 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8320 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8317 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8275 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8331 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8310 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8297 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8282 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8247 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8222 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8214 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8216 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8192 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8214 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8221 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8246 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8219 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8203 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8163 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8160 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8199 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8230 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8243 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8254 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8244 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8220 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8231 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8197 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8197 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8188 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8177 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8195 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8190 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8208 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8217 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8196 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8194 - accuracy: 0.77 - ETA: 59s - loss: 0.8183 - accuracy: 0.7741 - ETA: 58s - loss: 0.8178 - accuracy: 0.774 - ETA: 57s - loss: 0.8194 - accuracy: 0.773 - ETA: 55s - loss: 0.8184 - accuracy: 0.773 - ETA: 54s - loss: 0.8181 - accuracy: 0.774 - ETA: 53s - loss: 0.8217 - accuracy: 0.773 - ETA: 52s - loss: 0.8248 - accuracy: 0.772 - ETA: 51s - loss: 0.8263 - accuracy: 0.771 - ETA: 50s - loss: 0.8241 - accuracy: 0.772 - ETA: 49s - loss: 0.8234 - accuracy: 0.772 - ETA: 47s - loss: 0.8226 - accuracy: 0.772 - ETA: 46s - loss: 0.8209 - accuracy: 0.772 - ETA: 45s - loss: 0.8190 - accuracy: 0.773 - ETA: 44s - loss: 0.8203 - accuracy: 0.772 - ETA: 43s - loss: 0.8208 - accuracy: 0.772 - ETA: 42s - loss: 0.8201 - accuracy: 0.773 - ETA: 40s - loss: 0.8239 - accuracy: 0.773 - ETA: 39s - loss: 0.8237 - accuracy: 0.773 - ETA: 38s - loss: 0.8226 - accuracy: 0.773 - ETA: 37s - loss: 0.8238 - accuracy: 0.772 - ETA: 36s - loss: 0.8254 - accuracy: 0.772 - ETA: 35s - loss: 0.8280 - accuracy: 0.771 - ETA: 34s - loss: 0.8298 - accuracy: 0.770 - ETA: 32s - loss: 0.8337 - accuracy: 0.770 - ETA: 31s - loss: 0.8339 - accuracy: 0.770 - ETA: 30s - loss: 0.8331 - accuracy: 0.770 - ETA: 29s - loss: 0.8322 - accuracy: 0.770 - ETA: 28s - loss: 0.8355 - accuracy: 0.769 - ETA: 27s - loss: 0.8363 - accuracy: 0.769 - ETA: 26s - loss: 0.8342 - accuracy: 0.769 - ETA: 24s - loss: 0.8341 - accuracy: 0.770 - ETA: 23s - loss: 0.8339 - accuracy: 0.769 - ETA: 22s - loss: 0.8353 - accuracy: 0.769 - ETA: 21s - loss: 0.8364 - accuracy: 0.768 - ETA: 20s - loss: 0.8374 - accuracy: 0.768 - ETA: 19s - loss: 0.8380 - accuracy: 0.768 - ETA: 18s - loss: 0.8382 - accuracy: 0.768 - ETA: 16s - loss: 0.8368 - accuracy: 0.768 - ETA: 15s - loss: 0.8354 - accuracy: 0.768 - ETA: 14s - loss: 0.8359 - accuracy: 0.768 - ETA: 13s - loss: 0.8359 - accuracy: 0.768 - ETA: 12s - loss: 0.8362 - accuracy: 0.768 - ETA: 11s - loss: 0.8389 - accuracy: 0.767 - ETA: 10s - loss: 0.8382 - accuracy: 0.768 - ETA: 8s - loss: 0.8389 - accuracy: 0.768 - ETA: 7s - loss: 0.8394 - accuracy: 0.76 - ETA: 6s - loss: 0.8416 - accuracy: 0.76 - ETA: 5s - loss: 0.8419 - accuracy: 0.76 - ETA: 4s - loss: 0.8426 - accuracy: 0.76 - ETA: 3s - loss: 0.8409 - accuracy: 0.76 - ETA: 2s - loss: 0.8396 - accuracy: 0.76 - ETA: 0s - loss: 0.8394 - accuracy: 0.76 - 184s 10ms/step - loss: 0.8383 - accuracy: 0.7677 - val_loss: 1.8987 - val_accuracy: 0.7126\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:01 - loss: 0.6896 - accuracy: 0.78 - ETA: 2:52 - loss: 0.6277 - accuracy: 0.79 - ETA: 2:51 - loss: 0.7025 - accuracy: 0.78 - ETA: 2:46 - loss: 0.6732 - accuracy: 0.78 - ETA: 2:44 - loss: 0.7206 - accuracy: 0.77 - ETA: 2:43 - loss: 0.7408 - accuracy: 0.76 - ETA: 2:41 - loss: 0.7558 - accuracy: 0.76 - ETA: 2:39 - loss: 0.7559 - accuracy: 0.76 - ETA: 2:38 - loss: 0.7931 - accuracy: 0.76 - ETA: 2:36 - loss: 0.7922 - accuracy: 0.76 - ETA: 2:36 - loss: 0.7823 - accuracy: 0.76 - ETA: 2:36 - loss: 0.7807 - accuracy: 0.76 - ETA: 2:35 - loss: 0.7875 - accuracy: 0.76 - ETA: 2:34 - loss: 0.7899 - accuracy: 0.76 - ETA: 2:34 - loss: 0.7763 - accuracy: 0.77 - ETA: 2:33 - loss: 0.7928 - accuracy: 0.76 - ETA: 2:32 - loss: 0.7882 - accuracy: 0.76 - ETA: 2:31 - loss: 0.7869 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8009 - accuracy: 0.76 - ETA: 2:29 - loss: 0.7953 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8092 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8058 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8071 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8036 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8090 - accuracy: 0.77 - ETA: 2:23 - loss: 0.7990 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8087 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8134 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8159 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8129 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8111 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8192 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8144 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8168 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8180 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8197 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8191 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8242 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8229 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8411 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8418 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8441 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8477 - accuracy: 0.76 - ETA: 2:01 - loss: 0.8452 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8418 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8385 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8379 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8350 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8351 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8404 - accuracy: 0.76 - ETA: 1:53 - loss: 0.8468 - accuracy: 0.76 - ETA: 1:52 - loss: 0.8436 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8440 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8427 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8380 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8350 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8295 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8308 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8374 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8359 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8379 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8363 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8425 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8424 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8417 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8409 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8385 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8361 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8322 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8376 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8376 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8372 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8356 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8408 - accuracy: 0.76 - ETA: 1:28 - loss: 0.8379 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8385 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8364 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8345 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8339 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8318 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8304 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8292 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8319 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8306 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8294 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8295 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8287 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8291 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8309 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8316 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8319 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8335 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8379 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8397 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8393 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8389 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8392 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8390 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8396 - accuracy: 0.77 - ETA: 58s - loss: 0.8411 - accuracy: 0.7698 - ETA: 57s - loss: 0.8446 - accuracy: 0.770 - ETA: 56s - loss: 0.8442 - accuracy: 0.769 - ETA: 55s - loss: 0.8459 - accuracy: 0.769 - ETA: 54s - loss: 0.8453 - accuracy: 0.769 - ETA: 53s - loss: 0.8442 - accuracy: 0.769 - ETA: 51s - loss: 0.8463 - accuracy: 0.769 - ETA: 50s - loss: 0.8475 - accuracy: 0.768 - ETA: 49s - loss: 0.8486 - accuracy: 0.769 - ETA: 48s - loss: 0.8498 - accuracy: 0.769 - ETA: 47s - loss: 0.8547 - accuracy: 0.768 - ETA: 46s - loss: 0.8558 - accuracy: 0.768 - ETA: 44s - loss: 0.8567 - accuracy: 0.768 - ETA: 43s - loss: 0.8550 - accuracy: 0.768 - ETA: 42s - loss: 0.8561 - accuracy: 0.768 - ETA: 41s - loss: 0.8565 - accuracy: 0.768 - ETA: 40s - loss: 0.8543 - accuracy: 0.768 - ETA: 39s - loss: 0.8570 - accuracy: 0.768 - ETA: 37s - loss: 0.8579 - accuracy: 0.767 - ETA: 36s - loss: 0.8615 - accuracy: 0.767 - ETA: 35s - loss: 0.8646 - accuracy: 0.767 - ETA: 34s - loss: 0.8619 - accuracy: 0.767 - ETA: 33s - loss: 0.8621 - accuracy: 0.767 - ETA: 32s - loss: 0.8607 - accuracy: 0.767 - ETA: 31s - loss: 0.8606 - accuracy: 0.767 - ETA: 29s - loss: 0.8608 - accuracy: 0.767 - ETA: 28s - loss: 0.8593 - accuracy: 0.767 - ETA: 27s - loss: 0.8584 - accuracy: 0.767 - ETA: 26s - loss: 0.8573 - accuracy: 0.768 - ETA: 25s - loss: 0.8566 - accuracy: 0.768 - ETA: 24s - loss: 0.8553 - accuracy: 0.768 - ETA: 22s - loss: 0.8551 - accuracy: 0.768 - ETA: 21s - loss: 0.8556 - accuracy: 0.768 - ETA: 20s - loss: 0.8571 - accuracy: 0.767 - ETA: 19s - loss: 0.8588 - accuracy: 0.767 - ETA: 18s - loss: 0.8580 - accuracy: 0.767 - ETA: 17s - loss: 0.8564 - accuracy: 0.767 - ETA: 16s - loss: 0.8566 - accuracy: 0.767 - ETA: 14s - loss: 0.8568 - accuracy: 0.767 - ETA: 13s - loss: 0.8557 - accuracy: 0.767 - ETA: 12s - loss: 0.8558 - accuracy: 0.767 - ETA: 11s - loss: 0.8562 - accuracy: 0.767 - ETA: 10s - loss: 0.8573 - accuracy: 0.767 - ETA: 9s - loss: 0.8608 - accuracy: 0.767 - ETA: 7s - loss: 0.8618 - accuracy: 0.76 - ETA: 6s - loss: 0.8612 - accuracy: 0.76 - ETA: 5s - loss: 0.8617 - accuracy: 0.76 - ETA: 4s - loss: 0.8630 - accuracy: 0.76 - ETA: 3s - loss: 0.8630 - accuracy: 0.76 - ETA: 2s - loss: 0.8627 - accuracy: 0.76 - ETA: 1s - loss: 0.8653 - accuracy: 0.76 - 186s 10ms/step - loss: 0.8644 - accuracy: 0.7665 - val_loss: 1.9193 - val_accuracy: 0.7213\n",
      "Epoch 56/100\n",
      "19312/19312 [==============================] - ETA: 2:52 - loss: 1.0652 - accuracy: 0.79 - ETA: 2:54 - loss: 0.8401 - accuracy: 0.81 - ETA: 3:04 - loss: 0.9536 - accuracy: 0.81 - ETA: 3:02 - loss: 0.8785 - accuracy: 0.80 - ETA: 2:59 - loss: 0.8884 - accuracy: 0.79 - ETA: 2:57 - loss: 0.8465 - accuracy: 0.79 - ETA: 2:54 - loss: 0.8316 - accuracy: 0.79 - ETA: 2:53 - loss: 0.8295 - accuracy: 0.78 - ETA: 2:52 - loss: 0.8405 - accuracy: 0.78 - ETA: 2:51 - loss: 0.8247 - accuracy: 0.78 - ETA: 2:50 - loss: 0.8217 - accuracy: 0.78 - ETA: 2:49 - loss: 0.8228 - accuracy: 0.78 - ETA: 2:48 - loss: 0.8450 - accuracy: 0.78 - ETA: 2:45 - loss: 0.8600 - accuracy: 0.78 - ETA: 2:43 - loss: 0.8465 - accuracy: 0.78 - ETA: 2:43 - loss: 0.8642 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8535 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8649 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8535 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8550 - accuracy: 0.78 - ETA: 2:34 - loss: 0.8537 - accuracy: 0.78 - ETA: 2:33 - loss: 0.8738 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8719 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8720 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8806 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8783 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8724 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8746 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8665 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8664 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8704 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8669 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8670 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8635 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8639 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8714 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8831 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8779 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8735 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8695 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8619 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8563 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8496 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8537 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8534 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8545 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8613 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8588 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8602 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8625 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8667 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8640 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8567 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8543 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8640 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8665 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8664 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8689 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8671 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8667 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8671 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8618 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8611 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8576 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8629 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8605 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8622 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8590 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8632 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8612 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8620 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8634 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8628 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8618 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8617 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8632 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8629 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8621 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8609 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8658 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8671 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8643 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8639 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8623 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8651 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8642 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8599 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8594 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8636 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8633 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8622 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8651 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8690 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8676 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8704 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8680 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8673 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8642 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8619 - accuracy: 0.77 - ETA: 58s - loss: 0.8661 - accuracy: 0.7713 - ETA: 57s - loss: 0.8660 - accuracy: 0.771 - ETA: 56s - loss: 0.8651 - accuracy: 0.771 - ETA: 55s - loss: 0.8655 - accuracy: 0.771 - ETA: 54s - loss: 0.8626 - accuracy: 0.771 - ETA: 53s - loss: 0.8623 - accuracy: 0.772 - ETA: 51s - loss: 0.8654 - accuracy: 0.771 - ETA: 50s - loss: 0.8644 - accuracy: 0.771 - ETA: 49s - loss: 0.8627 - accuracy: 0.771 - ETA: 48s - loss: 0.8623 - accuracy: 0.770 - ETA: 47s - loss: 0.8615 - accuracy: 0.771 - ETA: 46s - loss: 0.8622 - accuracy: 0.771 - ETA: 44s - loss: 0.8609 - accuracy: 0.771 - ETA: 43s - loss: 0.8603 - accuracy: 0.771 - ETA: 42s - loss: 0.8634 - accuracy: 0.770 - ETA: 41s - loss: 0.8619 - accuracy: 0.770 - ETA: 40s - loss: 0.8611 - accuracy: 0.770 - ETA: 39s - loss: 0.8609 - accuracy: 0.771 - ETA: 37s - loss: 0.8627 - accuracy: 0.771 - ETA: 36s - loss: 0.8636 - accuracy: 0.770 - ETA: 35s - loss: 0.8637 - accuracy: 0.770 - ETA: 34s - loss: 0.8648 - accuracy: 0.770 - ETA: 33s - loss: 0.8654 - accuracy: 0.770 - ETA: 32s - loss: 0.8633 - accuracy: 0.770 - ETA: 30s - loss: 0.8629 - accuracy: 0.770 - ETA: 29s - loss: 0.8640 - accuracy: 0.770 - ETA: 28s - loss: 0.8638 - accuracy: 0.770 - ETA: 27s - loss: 0.8629 - accuracy: 0.769 - ETA: 26s - loss: 0.8635 - accuracy: 0.770 - ETA: 25s - loss: 0.8630 - accuracy: 0.770 - ETA: 24s - loss: 0.8632 - accuracy: 0.770 - ETA: 22s - loss: 0.8642 - accuracy: 0.769 - ETA: 21s - loss: 0.8618 - accuracy: 0.769 - ETA: 20s - loss: 0.8610 - accuracy: 0.770 - ETA: 19s - loss: 0.8609 - accuracy: 0.770 - ETA: 18s - loss: 0.8594 - accuracy: 0.770 - ETA: 17s - loss: 0.8617 - accuracy: 0.770 - ETA: 15s - loss: 0.8634 - accuracy: 0.770 - ETA: 14s - loss: 0.8647 - accuracy: 0.769 - ETA: 13s - loss: 0.8642 - accuracy: 0.769 - ETA: 12s - loss: 0.8651 - accuracy: 0.769 - ETA: 11s - loss: 0.8663 - accuracy: 0.769 - ETA: 10s - loss: 0.8658 - accuracy: 0.769 - ETA: 9s - loss: 0.8659 - accuracy: 0.769 - ETA: 7s - loss: 0.8671 - accuracy: 0.76 - ETA: 6s - loss: 0.8686 - accuracy: 0.76 - ETA: 5s - loss: 0.8675 - accuracy: 0.76 - ETA: 4s - loss: 0.8677 - accuracy: 0.76 - ETA: 3s - loss: 0.8672 - accuracy: 0.76 - ETA: 2s - loss: 0.8661 - accuracy: 0.76 - ETA: 1s - loss: 0.8695 - accuracy: 0.76 - 186s 10ms/step - loss: 0.8721 - accuracy: 0.7680 - val_loss: 1.7036 - val_accuracy: 0.7262\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:45 - loss: 0.7897 - accuracy: 0.74 - ETA: 2:44 - loss: 0.7902 - accuracy: 0.76 - ETA: 2:44 - loss: 0.8678 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8316 - accuracy: 0.78 - ETA: 2:42 - loss: 0.8110 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8248 - accuracy: 0.77 - ETA: 2:40 - loss: 0.8023 - accuracy: 0.77 - ETA: 2:42 - loss: 0.8065 - accuracy: 0.76 - ETA: 2:45 - loss: 0.7876 - accuracy: 0.77 - ETA: 2:43 - loss: 0.7607 - accuracy: 0.78 - ETA: 2:42 - loss: 0.7654 - accuracy: 0.78 - ETA: 2:40 - loss: 0.7834 - accuracy: 0.77 - ETA: 2:39 - loss: 0.7903 - accuracy: 0.77 - ETA: 2:37 - loss: 0.7818 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8150 - accuracy: 0.77 - ETA: 2:34 - loss: 0.7918 - accuracy: 0.77 - ETA: 2:33 - loss: 0.7848 - accuracy: 0.77 - ETA: 2:31 - loss: 0.7897 - accuracy: 0.77 - ETA: 2:30 - loss: 0.7917 - accuracy: 0.76 - ETA: 2:29 - loss: 0.7881 - accuracy: 0.76 - ETA: 2:29 - loss: 0.7809 - accuracy: 0.77 - ETA: 2:28 - loss: 0.7750 - accuracy: 0.76 - ETA: 2:27 - loss: 0.7852 - accuracy: 0.76 - ETA: 2:26 - loss: 0.7797 - accuracy: 0.76 - ETA: 2:25 - loss: 0.7729 - accuracy: 0.76 - ETA: 2:24 - loss: 0.7606 - accuracy: 0.77 - ETA: 2:23 - loss: 0.7748 - accuracy: 0.77 - ETA: 2:21 - loss: 0.7750 - accuracy: 0.77 - ETA: 2:20 - loss: 0.7805 - accuracy: 0.77 - ETA: 2:19 - loss: 0.7868 - accuracy: 0.77 - ETA: 2:17 - loss: 0.7917 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8108 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8164 - accuracy: 0.76 - ETA: 2:14 - loss: 0.8138 - accuracy: 0.76 - ETA: 2:12 - loss: 0.8109 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8112 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8061 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8031 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8084 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8103 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8041 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8047 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8041 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8095 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8078 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8038 - accuracy: 0.77 - ETA: 1:58 - loss: 0.7994 - accuracy: 0.77 - ETA: 1:57 - loss: 0.7959 - accuracy: 0.77 - ETA: 1:56 - loss: 0.7942 - accuracy: 0.77 - ETA: 1:55 - loss: 0.7954 - accuracy: 0.77 - ETA: 1:54 - loss: 0.7945 - accuracy: 0.77 - ETA: 1:53 - loss: 0.7929 - accuracy: 0.77 - ETA: 1:52 - loss: 0.7894 - accuracy: 0.77 - ETA: 1:50 - loss: 0.7905 - accuracy: 0.77 - ETA: 1:49 - loss: 0.7862 - accuracy: 0.77 - ETA: 1:48 - loss: 0.7879 - accuracy: 0.77 - ETA: 1:47 - loss: 0.7966 - accuracy: 0.77 - ETA: 1:46 - loss: 0.7937 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8021 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8034 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8127 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8112 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8137 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8172 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8200 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8188 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8203 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8224 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8241 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8275 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8319 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8322 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8363 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8383 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8386 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8412 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8446 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8424 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8404 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8381 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8391 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8404 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8395 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8398 - accuracy: 0.76 - ETA: 1:15 - loss: 0.8395 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8395 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8400 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8408 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8400 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8384 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8391 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8401 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8425 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8446 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8425 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8477 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8490 - accuracy: 0.76 - ETA: 1:00 - loss: 0.8475 - accuracy: 0.76 - ETA: 59s - loss: 0.8447 - accuracy: 0.7704 - ETA: 58s - loss: 0.8435 - accuracy: 0.770 - ETA: 56s - loss: 0.8480 - accuracy: 0.770 - ETA: 55s - loss: 0.8469 - accuracy: 0.771 - ETA: 54s - loss: 0.8474 - accuracy: 0.770 - ETA: 53s - loss: 0.8460 - accuracy: 0.771 - ETA: 52s - loss: 0.8463 - accuracy: 0.771 - ETA: 51s - loss: 0.8450 - accuracy: 0.771 - ETA: 50s - loss: 0.8427 - accuracy: 0.771 - ETA: 48s - loss: 0.8430 - accuracy: 0.770 - ETA: 47s - loss: 0.8441 - accuracy: 0.770 - ETA: 46s - loss: 0.8428 - accuracy: 0.770 - ETA: 45s - loss: 0.8422 - accuracy: 0.770 - ETA: 44s - loss: 0.8418 - accuracy: 0.770 - ETA: 43s - loss: 0.8402 - accuracy: 0.770 - ETA: 42s - loss: 0.8384 - accuracy: 0.771 - ETA: 40s - loss: 0.8371 - accuracy: 0.771 - ETA: 39s - loss: 0.8363 - accuracy: 0.771 - ETA: 38s - loss: 0.8365 - accuracy: 0.771 - ETA: 37s - loss: 0.8346 - accuracy: 0.772 - ETA: 36s - loss: 0.8347 - accuracy: 0.771 - ETA: 35s - loss: 0.8331 - accuracy: 0.772 - ETA: 34s - loss: 0.8322 - accuracy: 0.772 - ETA: 32s - loss: 0.8324 - accuracy: 0.772 - ETA: 31s - loss: 0.8300 - accuracy: 0.772 - ETA: 30s - loss: 0.8302 - accuracy: 0.772 - ETA: 29s - loss: 0.8309 - accuracy: 0.772 - ETA: 28s - loss: 0.8295 - accuracy: 0.772 - ETA: 27s - loss: 0.8296 - accuracy: 0.772 - ETA: 26s - loss: 0.8311 - accuracy: 0.772 - ETA: 24s - loss: 0.8305 - accuracy: 0.772 - ETA: 23s - loss: 0.8290 - accuracy: 0.773 - ETA: 22s - loss: 0.8324 - accuracy: 0.772 - ETA: 21s - loss: 0.8320 - accuracy: 0.772 - ETA: 20s - loss: 0.8329 - accuracy: 0.772 - ETA: 19s - loss: 0.8328 - accuracy: 0.772 - ETA: 18s - loss: 0.8330 - accuracy: 0.772 - ETA: 16s - loss: 0.8327 - accuracy: 0.771 - ETA: 15s - loss: 0.8309 - accuracy: 0.772 - ETA: 14s - loss: 0.8301 - accuracy: 0.772 - ETA: 13s - loss: 0.8280 - accuracy: 0.772 - ETA: 12s - loss: 0.8275 - accuracy: 0.772 - ETA: 11s - loss: 0.8272 - accuracy: 0.772 - ETA: 10s - loss: 0.8275 - accuracy: 0.772 - ETA: 8s - loss: 0.8306 - accuracy: 0.772 - ETA: 7s - loss: 0.8298 - accuracy: 0.77 - ETA: 6s - loss: 0.8325 - accuracy: 0.77 - ETA: 5s - loss: 0.8305 - accuracy: 0.77 - ETA: 4s - loss: 0.8308 - accuracy: 0.77 - ETA: 3s - loss: 0.8294 - accuracy: 0.77 - ETA: 2s - loss: 0.8299 - accuracy: 0.77 - ETA: 0s - loss: 0.8296 - accuracy: 0.77 - 184s 10ms/step - loss: 0.8286 - accuracy: 0.7727 - val_loss: 1.8527 - val_accuracy: 0.7206\n",
      "Epoch 58/100\n",
      "19312/19312 [==============================] - ETA: 3:10 - loss: 0.5821 - accuracy: 0.81 - ETA: 3:03 - loss: 0.7184 - accuracy: 0.78 - ETA: 2:56 - loss: 0.7200 - accuracy: 0.77 - ETA: 2:52 - loss: 0.7119 - accuracy: 0.77 - ETA: 2:51 - loss: 0.8871 - accuracy: 0.76 - ETA: 2:50 - loss: 0.8610 - accuracy: 0.76 - ETA: 2:47 - loss: 0.8261 - accuracy: 0.77 - ETA: 2:45 - loss: 0.8249 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8085 - accuracy: 0.77 - ETA: 2:42 - loss: 0.7958 - accuracy: 0.77 - ETA: 2:40 - loss: 0.7981 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8047 - accuracy: 0.76 - ETA: 2:38 - loss: 0.7884 - accuracy: 0.76 - ETA: 2:36 - loss: 0.7831 - accuracy: 0.77 - ETA: 2:36 - loss: 0.7869 - accuracy: 0.76 - ETA: 2:35 - loss: 0.7791 - accuracy: 0.77 - ETA: 2:34 - loss: 0.7766 - accuracy: 0.77 - ETA: 2:33 - loss: 0.7800 - accuracy: 0.77 - ETA: 2:32 - loss: 0.7884 - accuracy: 0.77 - ETA: 2:31 - loss: 0.7960 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8018 - accuracy: 0.77 - ETA: 2:28 - loss: 0.7989 - accuracy: 0.77 - ETA: 2:27 - loss: 0.7967 - accuracy: 0.77 - ETA: 2:26 - loss: 0.7944 - accuracy: 0.77 - ETA: 2:25 - loss: 0.7963 - accuracy: 0.77 - ETA: 2:23 - loss: 0.7975 - accuracy: 0.77 - ETA: 2:22 - loss: 0.7942 - accuracy: 0.77 - ETA: 2:22 - loss: 0.7929 - accuracy: 0.77 - ETA: 2:21 - loss: 0.7900 - accuracy: 0.77 - ETA: 2:19 - loss: 0.7866 - accuracy: 0.77 - ETA: 2:18 - loss: 0.7852 - accuracy: 0.77 - ETA: 2:17 - loss: 0.7849 - accuracy: 0.77 - ETA: 2:16 - loss: 0.7845 - accuracy: 0.77 - ETA: 2:14 - loss: 0.7855 - accuracy: 0.77 - ETA: 2:13 - loss: 0.7890 - accuracy: 0.77 - ETA: 2:12 - loss: 0.7881 - accuracy: 0.77 - ETA: 2:11 - loss: 0.7820 - accuracy: 0.77 - ETA: 2:10 - loss: 0.7746 - accuracy: 0.77 - ETA: 2:09 - loss: 0.7751 - accuracy: 0.77 - ETA: 2:07 - loss: 0.7799 - accuracy: 0.77 - ETA: 2:06 - loss: 0.7832 - accuracy: 0.77 - ETA: 2:05 - loss: 0.7798 - accuracy: 0.77 - ETA: 2:04 - loss: 0.7783 - accuracy: 0.77 - ETA: 2:03 - loss: 0.7799 - accuracy: 0.77 - ETA: 2:01 - loss: 0.7935 - accuracy: 0.77 - ETA: 2:00 - loss: 0.7975 - accuracy: 0.77 - ETA: 1:59 - loss: 0.7983 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8035 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8075 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8092 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8187 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8194 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8152 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8184 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8197 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8168 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8151 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8177 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8152 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8209 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8264 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8278 - accuracy: 0.78 - ETA: 1:41 - loss: 0.8330 - accuracy: 0.78 - ETA: 1:40 - loss: 0.8330 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8302 - accuracy: 0.78 - ETA: 1:37 - loss: 0.8271 - accuracy: 0.78 - ETA: 1:36 - loss: 0.8299 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8299 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8303 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8273 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8281 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8275 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8326 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8342 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8359 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8357 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8405 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8399 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8406 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8390 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8375 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8347 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8366 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8373 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8359 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8364 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8385 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8389 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8348 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8382 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8383 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8350 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8433 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8552 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8611 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8595 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8587 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8594 - accuracy: 0.77 - ETA: 59s - loss: 0.8593 - accuracy: 0.7756 - ETA: 58s - loss: 0.8617 - accuracy: 0.775 - ETA: 57s - loss: 0.8645 - accuracy: 0.775 - ETA: 56s - loss: 0.8626 - accuracy: 0.775 - ETA: 54s - loss: 0.8632 - accuracy: 0.775 - ETA: 53s - loss: 0.8628 - accuracy: 0.776 - ETA: 52s - loss: 0.8636 - accuracy: 0.776 - ETA: 51s - loss: 0.8631 - accuracy: 0.775 - ETA: 50s - loss: 0.8630 - accuracy: 0.774 - ETA: 49s - loss: 0.8650 - accuracy: 0.774 - ETA: 47s - loss: 0.8654 - accuracy: 0.774 - ETA: 46s - loss: 0.8660 - accuracy: 0.774 - ETA: 45s - loss: 0.8634 - accuracy: 0.774 - ETA: 44s - loss: 0.8659 - accuracy: 0.774 - ETA: 43s - loss: 0.8649 - accuracy: 0.774 - ETA: 42s - loss: 0.8653 - accuracy: 0.773 - ETA: 41s - loss: 0.8662 - accuracy: 0.773 - ETA: 39s - loss: 0.8650 - accuracy: 0.773 - ETA: 38s - loss: 0.8641 - accuracy: 0.773 - ETA: 37s - loss: 0.8636 - accuracy: 0.773 - ETA: 36s - loss: 0.8647 - accuracy: 0.772 - ETA: 35s - loss: 0.8625 - accuracy: 0.773 - ETA: 34s - loss: 0.8645 - accuracy: 0.773 - ETA: 33s - loss: 0.8642 - accuracy: 0.773 - ETA: 31s - loss: 0.8619 - accuracy: 0.773 - ETA: 30s - loss: 0.8614 - accuracy: 0.773 - ETA: 29s - loss: 0.8633 - accuracy: 0.773 - ETA: 28s - loss: 0.8617 - accuracy: 0.773 - ETA: 27s - loss: 0.8614 - accuracy: 0.773 - ETA: 26s - loss: 0.8619 - accuracy: 0.773 - ETA: 25s - loss: 0.8612 - accuracy: 0.773 - ETA: 23s - loss: 0.8639 - accuracy: 0.773 - ETA: 22s - loss: 0.8631 - accuracy: 0.773 - ETA: 21s - loss: 0.8621 - accuracy: 0.773 - ETA: 20s - loss: 0.8621 - accuracy: 0.773 - ETA: 19s - loss: 0.8630 - accuracy: 0.773 - ETA: 18s - loss: 0.8628 - accuracy: 0.772 - ETA: 17s - loss: 0.8610 - accuracy: 0.773 - ETA: 15s - loss: 0.8620 - accuracy: 0.772 - ETA: 14s - loss: 0.8641 - accuracy: 0.772 - ETA: 13s - loss: 0.8641 - accuracy: 0.771 - ETA: 12s - loss: 0.8641 - accuracy: 0.772 - ETA: 11s - loss: 0.8643 - accuracy: 0.772 - ETA: 10s - loss: 0.8634 - accuracy: 0.772 - ETA: 9s - loss: 0.8617 - accuracy: 0.772 - ETA: 7s - loss: 0.8605 - accuracy: 0.77 - ETA: 6s - loss: 0.8590 - accuracy: 0.77 - ETA: 5s - loss: 0.8606 - accuracy: 0.77 - ETA: 4s - loss: 0.8612 - accuracy: 0.77 - ETA: 3s - loss: 0.8607 - accuracy: 0.77 - ETA: 2s - loss: 0.8596 - accuracy: 0.77 - ETA: 0s - loss: 0.8582 - accuracy: 0.77 - 185s 10ms/step - loss: 0.8599 - accuracy: 0.7726 - val_loss: 1.8119 - val_accuracy: 0.7269\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:53 - loss: 0.9971 - accuracy: 0.82 - ETA: 2:53 - loss: 0.8768 - accuracy: 0.78 - ETA: 2:49 - loss: 0.8511 - accuracy: 0.78 - ETA: 2:47 - loss: 0.8531 - accuracy: 0.78 - ETA: 2:46 - loss: 0.8455 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8353 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8343 - accuracy: 0.78 - ETA: 2:44 - loss: 0.8409 - accuracy: 0.77 - ETA: 2:42 - loss: 0.9090 - accuracy: 0.76 - ETA: 2:41 - loss: 0.8654 - accuracy: 0.77 - ETA: 2:40 - loss: 0.8544 - accuracy: 0.77 - ETA: 2:38 - loss: 0.8773 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8478 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8415 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8381 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8266 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8224 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8164 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8222 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8237 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8168 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8060 - accuracy: 0.78 - ETA: 2:26 - loss: 0.8024 - accuracy: 0.78 - ETA: 2:25 - loss: 0.7958 - accuracy: 0.78 - ETA: 2:23 - loss: 0.7826 - accuracy: 0.78 - ETA: 2:22 - loss: 0.7787 - accuracy: 0.78 - ETA: 2:21 - loss: 0.7842 - accuracy: 0.78 - ETA: 2:19 - loss: 0.7845 - accuracy: 0.78 - ETA: 2:18 - loss: 0.7825 - accuracy: 0.78 - ETA: 2:17 - loss: 0.7839 - accuracy: 0.78 - ETA: 2:16 - loss: 0.7901 - accuracy: 0.78 - ETA: 2:15 - loss: 0.7962 - accuracy: 0.78 - ETA: 2:14 - loss: 0.8100 - accuracy: 0.78 - ETA: 2:12 - loss: 0.8119 - accuracy: 0.78 - ETA: 2:12 - loss: 0.8155 - accuracy: 0.78 - ETA: 2:11 - loss: 0.8136 - accuracy: 0.78 - ETA: 2:10 - loss: 0.8104 - accuracy: 0.78 - ETA: 2:09 - loss: 0.8162 - accuracy: 0.78 - ETA: 2:07 - loss: 0.8094 - accuracy: 0.78 - ETA: 2:06 - loss: 0.8145 - accuracy: 0.78 - ETA: 2:05 - loss: 0.8118 - accuracy: 0.78 - ETA: 2:04 - loss: 0.8057 - accuracy: 0.78 - ETA: 2:03 - loss: 0.8047 - accuracy: 0.78 - ETA: 2:01 - loss: 0.8060 - accuracy: 0.78 - ETA: 2:00 - loss: 0.8027 - accuracy: 0.78 - ETA: 1:59 - loss: 0.7983 - accuracy: 0.78 - ETA: 1:58 - loss: 0.8002 - accuracy: 0.78 - ETA: 1:57 - loss: 0.8054 - accuracy: 0.78 - ETA: 1:56 - loss: 0.8055 - accuracy: 0.78 - ETA: 1:55 - loss: 0.8056 - accuracy: 0.78 - ETA: 1:53 - loss: 0.8067 - accuracy: 0.78 - ETA: 1:52 - loss: 0.8044 - accuracy: 0.78 - ETA: 1:51 - loss: 0.8028 - accuracy: 0.78 - ETA: 1:50 - loss: 0.7996 - accuracy: 0.78 - ETA: 1:49 - loss: 0.7986 - accuracy: 0.78 - ETA: 1:48 - loss: 0.7991 - accuracy: 0.78 - ETA: 1:47 - loss: 0.7969 - accuracy: 0.78 - ETA: 1:45 - loss: 0.7993 - accuracy: 0.78 - ETA: 1:44 - loss: 0.7986 - accuracy: 0.78 - ETA: 1:43 - loss: 0.7979 - accuracy: 0.78 - ETA: 1:42 - loss: 0.7978 - accuracy: 0.78 - ETA: 1:41 - loss: 0.8014 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8109 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8088 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8069 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8097 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8215 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8172 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8246 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8231 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8256 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8227 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8235 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8239 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8217 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8238 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8202 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8195 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8213 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8189 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8226 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8246 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8270 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8283 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8285 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8292 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8336 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8329 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8310 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8333 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8316 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8298 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8309 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8301 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8322 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8328 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8355 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8345 - accuracy: 0.77 - ETA: 59s - loss: 0.8326 - accuracy: 0.7733 - ETA: 58s - loss: 0.8314 - accuracy: 0.773 - ETA: 56s - loss: 0.8299 - accuracy: 0.773 - ETA: 55s - loss: 0.8312 - accuracy: 0.772 - ETA: 54s - loss: 0.8309 - accuracy: 0.772 - ETA: 53s - loss: 0.8304 - accuracy: 0.772 - ETA: 52s - loss: 0.8310 - accuracy: 0.772 - ETA: 51s - loss: 0.8283 - accuracy: 0.773 - ETA: 50s - loss: 0.8305 - accuracy: 0.773 - ETA: 48s - loss: 0.8318 - accuracy: 0.773 - ETA: 47s - loss: 0.8320 - accuracy: 0.773 - ETA: 46s - loss: 0.8313 - accuracy: 0.774 - ETA: 45s - loss: 0.8355 - accuracy: 0.773 - ETA: 44s - loss: 0.8363 - accuracy: 0.772 - ETA: 43s - loss: 0.8365 - accuracy: 0.773 - ETA: 42s - loss: 0.8355 - accuracy: 0.773 - ETA: 40s - loss: 0.8402 - accuracy: 0.772 - ETA: 39s - loss: 0.8398 - accuracy: 0.772 - ETA: 38s - loss: 0.8399 - accuracy: 0.771 - ETA: 37s - loss: 0.8406 - accuracy: 0.771 - ETA: 36s - loss: 0.8416 - accuracy: 0.771 - ETA: 35s - loss: 0.8427 - accuracy: 0.771 - ETA: 34s - loss: 0.8416 - accuracy: 0.771 - ETA: 32s - loss: 0.8439 - accuracy: 0.770 - ETA: 31s - loss: 0.8441 - accuracy: 0.770 - ETA: 30s - loss: 0.8457 - accuracy: 0.771 - ETA: 29s - loss: 0.8460 - accuracy: 0.770 - ETA: 28s - loss: 0.8454 - accuracy: 0.770 - ETA: 27s - loss: 0.8449 - accuracy: 0.770 - ETA: 26s - loss: 0.8446 - accuracy: 0.771 - ETA: 24s - loss: 0.8443 - accuracy: 0.771 - ETA: 23s - loss: 0.8445 - accuracy: 0.770 - ETA: 22s - loss: 0.8446 - accuracy: 0.770 - ETA: 21s - loss: 0.8442 - accuracy: 0.770 - ETA: 20s - loss: 0.8436 - accuracy: 0.770 - ETA: 19s - loss: 0.8432 - accuracy: 0.770 - ETA: 18s - loss: 0.8426 - accuracy: 0.770 - ETA: 16s - loss: 0.8441 - accuracy: 0.770 - ETA: 15s - loss: 0.8431 - accuracy: 0.770 - ETA: 14s - loss: 0.8421 - accuracy: 0.770 - ETA: 13s - loss: 0.8415 - accuracy: 0.770 - ETA: 12s - loss: 0.8405 - accuracy: 0.770 - ETA: 11s - loss: 0.8403 - accuracy: 0.770 - ETA: 10s - loss: 0.8396 - accuracy: 0.770 - ETA: 8s - loss: 0.8398 - accuracy: 0.770 - ETA: 7s - loss: 0.8394 - accuracy: 0.77 - ETA: 6s - loss: 0.8399 - accuracy: 0.77 - ETA: 5s - loss: 0.8408 - accuracy: 0.77 - ETA: 4s - loss: 0.8425 - accuracy: 0.77 - ETA: 3s - loss: 0.8420 - accuracy: 0.77 - ETA: 2s - loss: 0.8420 - accuracy: 0.77 - ETA: 0s - loss: 0.8404 - accuracy: 0.77 - 186s 10ms/step - loss: 0.8393 - accuracy: 0.7707 - val_loss: 1.7665 - val_accuracy: 0.7217\n",
      "Epoch 60/100\n",
      "19312/19312 [==============================] - ETA: 2:50 - loss: 0.7633 - accuracy: 0.76 - ETA: 2:46 - loss: 0.6152 - accuracy: 0.81 - ETA: 2:43 - loss: 0.6469 - accuracy: 0.81 - ETA: 2:42 - loss: 0.6661 - accuracy: 0.81 - ETA: 2:41 - loss: 0.6664 - accuracy: 0.80 - ETA: 2:41 - loss: 0.7041 - accuracy: 0.79 - ETA: 2:39 - loss: 0.7703 - accuracy: 0.78 - ETA: 2:38 - loss: 0.7678 - accuracy: 0.78 - ETA: 2:38 - loss: 0.7515 - accuracy: 0.78 - ETA: 2:36 - loss: 0.7570 - accuracy: 0.78 - ETA: 2:34 - loss: 0.7895 - accuracy: 0.77 - ETA: 2:34 - loss: 0.7930 - accuracy: 0.77 - ETA: 2:34 - loss: 0.7781 - accuracy: 0.77 - ETA: 2:33 - loss: 0.7839 - accuracy: 0.77 - ETA: 2:32 - loss: 0.7723 - accuracy: 0.77 - ETA: 2:31 - loss: 0.7747 - accuracy: 0.77 - ETA: 2:30 - loss: 0.7831 - accuracy: 0.77 - ETA: 2:29 - loss: 0.7964 - accuracy: 0.76 - ETA: 2:28 - loss: 0.7911 - accuracy: 0.76 - ETA: 2:27 - loss: 0.7900 - accuracy: 0.76 - ETA: 2:26 - loss: 0.7969 - accuracy: 0.76 - ETA: 2:25 - loss: 0.7890 - accuracy: 0.76 - ETA: 2:24 - loss: 0.7896 - accuracy: 0.77 - ETA: 2:23 - loss: 0.7939 - accuracy: 0.77 - ETA: 2:21 - loss: 0.7944 - accuracy: 0.77 - ETA: 2:20 - loss: 0.7992 - accuracy: 0.77 - ETA: 2:19 - loss: 0.7931 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8132 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8186 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8126 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8106 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8074 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8078 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8112 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8112 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8123 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8097 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8122 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8106 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8064 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8093 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8026 - accuracy: 0.77 - ETA: 2:03 - loss: 0.7983 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8032 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8030 - accuracy: 0.77 - ETA: 1:59 - loss: 0.7960 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8035 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8052 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8045 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8030 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8033 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8072 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8108 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8092 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8118 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8129 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8090 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8064 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8023 - accuracy: 0.77 - ETA: 1:44 - loss: 0.7993 - accuracy: 0.78 - ETA: 1:42 - loss: 0.8030 - accuracy: 0.78 - ETA: 1:41 - loss: 0.8081 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8210 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8195 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8173 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8193 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8182 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8235 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8274 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8262 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8258 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8260 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8212 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8203 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8242 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8305 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8301 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8286 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8266 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8273 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8307 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8329 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8309 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8307 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8298 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8309 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8301 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8312 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8285 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8284 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8261 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8259 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8262 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8265 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8249 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8245 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8263 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8265 - accuracy: 0.77 - ETA: 59s - loss: 0.8261 - accuracy: 0.7763 - ETA: 58s - loss: 0.8274 - accuracy: 0.775 - ETA: 57s - loss: 0.8271 - accuracy: 0.775 - ETA: 56s - loss: 0.8274 - accuracy: 0.775 - ETA: 54s - loss: 0.8306 - accuracy: 0.774 - ETA: 53s - loss: 0.8310 - accuracy: 0.774 - ETA: 52s - loss: 0.8314 - accuracy: 0.774 - ETA: 51s - loss: 0.8356 - accuracy: 0.774 - ETA: 50s - loss: 0.8366 - accuracy: 0.774 - ETA: 49s - loss: 0.8448 - accuracy: 0.773 - ETA: 47s - loss: 0.8425 - accuracy: 0.773 - ETA: 46s - loss: 0.8409 - accuracy: 0.773 - ETA: 45s - loss: 0.8438 - accuracy: 0.773 - ETA: 44s - loss: 0.8446 - accuracy: 0.773 - ETA: 43s - loss: 0.8464 - accuracy: 0.773 - ETA: 42s - loss: 0.8478 - accuracy: 0.773 - ETA: 41s - loss: 0.8494 - accuracy: 0.772 - ETA: 39s - loss: 0.8502 - accuracy: 0.772 - ETA: 38s - loss: 0.8492 - accuracy: 0.772 - ETA: 37s - loss: 0.8521 - accuracy: 0.771 - ETA: 36s - loss: 0.8511 - accuracy: 0.772 - ETA: 35s - loss: 0.8487 - accuracy: 0.772 - ETA: 34s - loss: 0.8491 - accuracy: 0.772 - ETA: 33s - loss: 0.8465 - accuracy: 0.772 - ETA: 31s - loss: 0.8456 - accuracy: 0.772 - ETA: 30s - loss: 0.8464 - accuracy: 0.772 - ETA: 29s - loss: 0.8471 - accuracy: 0.771 - ETA: 28s - loss: 0.8452 - accuracy: 0.772 - ETA: 27s - loss: 0.8471 - accuracy: 0.772 - ETA: 26s - loss: 0.8476 - accuracy: 0.771 - ETA: 25s - loss: 0.8478 - accuracy: 0.771 - ETA: 23s - loss: 0.8468 - accuracy: 0.772 - ETA: 22s - loss: 0.8474 - accuracy: 0.772 - ETA: 21s - loss: 0.8492 - accuracy: 0.771 - ETA: 20s - loss: 0.8508 - accuracy: 0.771 - ETA: 19s - loss: 0.8519 - accuracy: 0.771 - ETA: 18s - loss: 0.8508 - accuracy: 0.771 - ETA: 17s - loss: 0.8488 - accuracy: 0.772 - ETA: 15s - loss: 0.8516 - accuracy: 0.771 - ETA: 14s - loss: 0.8503 - accuracy: 0.771 - ETA: 13s - loss: 0.8502 - accuracy: 0.771 - ETA: 12s - loss: 0.8495 - accuracy: 0.771 - ETA: 11s - loss: 0.8490 - accuracy: 0.771 - ETA: 10s - loss: 0.8476 - accuracy: 0.771 - ETA: 9s - loss: 0.8477 - accuracy: 0.771 - ETA: 7s - loss: 0.8481 - accuracy: 0.77 - ETA: 6s - loss: 0.8466 - accuracy: 0.77 - ETA: 5s - loss: 0.8479 - accuracy: 0.77 - ETA: 4s - loss: 0.8467 - accuracy: 0.77 - ETA: 3s - loss: 0.8468 - accuracy: 0.77 - ETA: 2s - loss: 0.8457 - accuracy: 0.77 - ETA: 1s - loss: 0.8453 - accuracy: 0.77 - 186s 10ms/step - loss: 0.8451 - accuracy: 0.7719 - val_loss: 2.0430 - val_accuracy: 0.7273\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:46 - loss: 0.5040 - accuracy: 0.85 - ETA: 2:43 - loss: 0.7531 - accuracy: 0.80 - ETA: 2:44 - loss: 0.8124 - accuracy: 0.79 - ETA: 2:46 - loss: 0.7923 - accuracy: 0.79 - ETA: 2:48 - loss: 0.7132 - accuracy: 0.81 - ETA: 2:47 - loss: 0.7910 - accuracy: 0.80 - ETA: 2:45 - loss: 0.7916 - accuracy: 0.79 - ETA: 2:44 - loss: 0.8115 - accuracy: 0.79 - ETA: 2:42 - loss: 0.8222 - accuracy: 0.79 - ETA: 2:40 - loss: 0.8249 - accuracy: 0.78 - ETA: 2:39 - loss: 0.8442 - accuracy: 0.78 - ETA: 2:37 - loss: 0.8377 - accuracy: 0.78 - ETA: 2:36 - loss: 0.8717 - accuracy: 0.78 - ETA: 2:36 - loss: 0.8674 - accuracy: 0.78 - ETA: 2:34 - loss: 0.8543 - accuracy: 0.78 - ETA: 2:33 - loss: 0.8328 - accuracy: 0.78 - ETA: 2:32 - loss: 0.8420 - accuracy: 0.78 - ETA: 2:31 - loss: 0.8515 - accuracy: 0.78 - ETA: 2:31 - loss: 0.8348 - accuracy: 0.78 - ETA: 2:29 - loss: 0.8473 - accuracy: 0.78 - ETA: 2:28 - loss: 0.8471 - accuracy: 0.78 - ETA: 2:27 - loss: 0.8454 - accuracy: 0.78 - ETA: 2:25 - loss: 0.8525 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8428 - accuracy: 0.78 - ETA: 2:23 - loss: 0.8406 - accuracy: 0.78 - ETA: 2:22 - loss: 0.8262 - accuracy: 0.78 - ETA: 2:21 - loss: 0.8378 - accuracy: 0.78 - ETA: 2:19 - loss: 0.8359 - accuracy: 0.78 - ETA: 2:18 - loss: 0.8312 - accuracy: 0.78 - ETA: 2:17 - loss: 0.8315 - accuracy: 0.78 - ETA: 2:16 - loss: 0.8295 - accuracy: 0.78 - ETA: 2:15 - loss: 0.8367 - accuracy: 0.78 - ETA: 2:14 - loss: 0.8473 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8482 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8393 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8389 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8381 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8365 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8425 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8396 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8413 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8503 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8507 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8466 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8490 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8476 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8503 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8450 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8473 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8463 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8409 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8411 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8397 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8374 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8412 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8405 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8403 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8388 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8389 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8385 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8372 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8390 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8356 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8339 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8348 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8413 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8433 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8437 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8425 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8455 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8448 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8509 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8488 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8484 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8480 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8476 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8443 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8424 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8408 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8408 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8374 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8381 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8407 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8384 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8395 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8384 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8362 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8385 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8404 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8397 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8393 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8339 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8308 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8313 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8312 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8311 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8295 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8273 - accuracy: 0.77 - ETA: 58s - loss: 0.8239 - accuracy: 0.7795 - ETA: 57s - loss: 0.8222 - accuracy: 0.780 - ETA: 56s - loss: 0.8221 - accuracy: 0.779 - ETA: 55s - loss: 0.8240 - accuracy: 0.779 - ETA: 54s - loss: 0.8242 - accuracy: 0.778 - ETA: 53s - loss: 0.8232 - accuracy: 0.778 - ETA: 52s - loss: 0.8212 - accuracy: 0.778 - ETA: 51s - loss: 0.8266 - accuracy: 0.778 - ETA: 49s - loss: 0.8283 - accuracy: 0.778 - ETA: 48s - loss: 0.8262 - accuracy: 0.779 - ETA: 47s - loss: 0.8244 - accuracy: 0.779 - ETA: 46s - loss: 0.8240 - accuracy: 0.780 - ETA: 45s - loss: 0.8220 - accuracy: 0.780 - ETA: 44s - loss: 0.8239 - accuracy: 0.779 - ETA: 43s - loss: 0.8226 - accuracy: 0.779 - ETA: 41s - loss: 0.8237 - accuracy: 0.779 - ETA: 40s - loss: 0.8248 - accuracy: 0.778 - ETA: 39s - loss: 0.8262 - accuracy: 0.778 - ETA: 38s - loss: 0.8275 - accuracy: 0.778 - ETA: 37s - loss: 0.8255 - accuracy: 0.779 - ETA: 36s - loss: 0.8247 - accuracy: 0.779 - ETA: 35s - loss: 0.8257 - accuracy: 0.778 - ETA: 34s - loss: 0.8247 - accuracy: 0.778 - ETA: 32s - loss: 0.8246 - accuracy: 0.778 - ETA: 31s - loss: 0.8239 - accuracy: 0.778 - ETA: 30s - loss: 0.8240 - accuracy: 0.778 - ETA: 29s - loss: 0.8243 - accuracy: 0.778 - ETA: 28s - loss: 0.8237 - accuracy: 0.778 - ETA: 27s - loss: 0.8255 - accuracy: 0.777 - ETA: 26s - loss: 0.8258 - accuracy: 0.777 - ETA: 24s - loss: 0.8258 - accuracy: 0.777 - ETA: 23s - loss: 0.8247 - accuracy: 0.777 - ETA: 22s - loss: 0.8227 - accuracy: 0.777 - ETA: 21s - loss: 0.8213 - accuracy: 0.777 - ETA: 20s - loss: 0.8204 - accuracy: 0.778 - ETA: 19s - loss: 0.8192 - accuracy: 0.777 - ETA: 18s - loss: 0.8202 - accuracy: 0.777 - ETA: 16s - loss: 0.8207 - accuracy: 0.777 - ETA: 15s - loss: 0.8200 - accuracy: 0.777 - ETA: 14s - loss: 0.8212 - accuracy: 0.777 - ETA: 13s - loss: 0.8220 - accuracy: 0.777 - ETA: 12s - loss: 0.8236 - accuracy: 0.777 - ETA: 11s - loss: 0.8222 - accuracy: 0.777 - ETA: 10s - loss: 0.8214 - accuracy: 0.777 - ETA: 8s - loss: 0.8213 - accuracy: 0.777 - ETA: 7s - loss: 0.8230 - accuracy: 0.77 - ETA: 6s - loss: 0.8213 - accuracy: 0.77 - ETA: 5s - loss: 0.8224 - accuracy: 0.77 - ETA: 4s - loss: 0.8236 - accuracy: 0.77 - ETA: 3s - loss: 0.8239 - accuracy: 0.77 - ETA: 2s - loss: 0.8226 - accuracy: 0.77 - ETA: 0s - loss: 0.8232 - accuracy: 0.77 - 185s 10ms/step - loss: 0.8233 - accuracy: 0.7779 - val_loss: 1.8853 - val_accuracy: 0.7240\n",
      "Epoch 62/100\n",
      "19312/19312 [==============================] - ETA: 2:51 - loss: 0.6034 - accuracy: 0.82 - ETA: 2:43 - loss: 0.5994 - accuracy: 0.82 - ETA: 2:46 - loss: 0.5992 - accuracy: 0.81 - ETA: 2:44 - loss: 0.6931 - accuracy: 0.79 - ETA: 2:42 - loss: 0.6814 - accuracy: 0.79 - ETA: 2:40 - loss: 0.6840 - accuracy: 0.79 - ETA: 2:40 - loss: 0.7263 - accuracy: 0.78 - ETA: 2:40 - loss: 0.7399 - accuracy: 0.78 - ETA: 2:38 - loss: 0.7408 - accuracy: 0.78 - ETA: 2:39 - loss: 0.7704 - accuracy: 0.78 - ETA: 2:38 - loss: 0.7567 - accuracy: 0.78 - ETA: 2:38 - loss: 0.7616 - accuracy: 0.78 - ETA: 2:37 - loss: 0.7575 - accuracy: 0.78 - ETA: 2:36 - loss: 0.7440 - accuracy: 0.79 - ETA: 2:34 - loss: 0.7390 - accuracy: 0.79 - ETA: 2:33 - loss: 0.7585 - accuracy: 0.79 - ETA: 2:32 - loss: 0.7749 - accuracy: 0.79 - ETA: 2:30 - loss: 0.7627 - accuracy: 0.79 - ETA: 2:29 - loss: 0.7711 - accuracy: 0.79 - ETA: 2:28 - loss: 0.7743 - accuracy: 0.78 - ETA: 2:27 - loss: 0.7847 - accuracy: 0.78 - ETA: 2:26 - loss: 0.7767 - accuracy: 0.78 - ETA: 2:25 - loss: 0.7679 - accuracy: 0.78 - ETA: 2:24 - loss: 0.7689 - accuracy: 0.78 - ETA: 2:24 - loss: 0.7778 - accuracy: 0.78 - ETA: 2:22 - loss: 0.7841 - accuracy: 0.78 - ETA: 2:21 - loss: 0.7949 - accuracy: 0.78 - ETA: 2:20 - loss: 0.8037 - accuracy: 0.78 - ETA: 2:18 - loss: 0.8126 - accuracy: 0.78 - ETA: 2:17 - loss: 0.8191 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8105 - accuracy: 0.78 - ETA: 2:14 - loss: 0.8039 - accuracy: 0.78 - ETA: 2:13 - loss: 0.8134 - accuracy: 0.78 - ETA: 2:12 - loss: 0.8160 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8184 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8166 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8255 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8331 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8406 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8347 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8284 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8341 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8294 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8313 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8331 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8300 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8328 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8303 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8334 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8318 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8367 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8392 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8373 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8418 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8436 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8410 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8363 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8366 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8379 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8399 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8369 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8420 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8416 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8411 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8431 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8429 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8410 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8445 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8448 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8453 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8441 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8450 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8461 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8508 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8500 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8517 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8557 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8524 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8555 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8559 - accuracy: 0.76 - ETA: 1:19 - loss: 0.8566 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8576 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8567 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8579 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8589 - accuracy: 0.76 - ETA: 1:13 - loss: 0.8587 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8612 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8604 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8699 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8689 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8705 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8700 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8679 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8690 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8671 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8624 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8637 - accuracy: 0.76 - ETA: 59s - loss: 0.8621 - accuracy: 0.7687 - ETA: 58s - loss: 0.8607 - accuracy: 0.768 - ETA: 57s - loss: 0.8583 - accuracy: 0.769 - ETA: 56s - loss: 0.8566 - accuracy: 0.769 - ETA: 55s - loss: 0.8583 - accuracy: 0.770 - ETA: 54s - loss: 0.8604 - accuracy: 0.769 - ETA: 53s - loss: 0.8602 - accuracy: 0.769 - ETA: 52s - loss: 0.8578 - accuracy: 0.770 - ETA: 50s - loss: 0.8558 - accuracy: 0.770 - ETA: 49s - loss: 0.8551 - accuracy: 0.770 - ETA: 48s - loss: 0.8539 - accuracy: 0.770 - ETA: 47s - loss: 0.8576 - accuracy: 0.770 - ETA: 46s - loss: 0.8558 - accuracy: 0.770 - ETA: 45s - loss: 0.8561 - accuracy: 0.770 - ETA: 44s - loss: 0.8543 - accuracy: 0.770 - ETA: 43s - loss: 0.8536 - accuracy: 0.770 - ETA: 42s - loss: 0.8517 - accuracy: 0.770 - ETA: 40s - loss: 0.8566 - accuracy: 0.770 - ETA: 39s - loss: 0.8577 - accuracy: 0.770 - ETA: 38s - loss: 0.8581 - accuracy: 0.770 - ETA: 37s - loss: 0.8551 - accuracy: 0.770 - ETA: 36s - loss: 0.8545 - accuracy: 0.771 - ETA: 35s - loss: 0.8557 - accuracy: 0.770 - ETA: 34s - loss: 0.8544 - accuracy: 0.771 - ETA: 32s - loss: 0.8527 - accuracy: 0.771 - ETA: 31s - loss: 0.8512 - accuracy: 0.771 - ETA: 30s - loss: 0.8494 - accuracy: 0.771 - ETA: 29s - loss: 0.8479 - accuracy: 0.772 - ETA: 28s - loss: 0.8481 - accuracy: 0.772 - ETA: 27s - loss: 0.8479 - accuracy: 0.771 - ETA: 26s - loss: 0.8483 - accuracy: 0.771 - ETA: 24s - loss: 0.8494 - accuracy: 0.771 - ETA: 23s - loss: 0.8498 - accuracy: 0.771 - ETA: 22s - loss: 0.8486 - accuracy: 0.771 - ETA: 21s - loss: 0.8457 - accuracy: 0.772 - ETA: 20s - loss: 0.8462 - accuracy: 0.772 - ETA: 19s - loss: 0.8453 - accuracy: 0.772 - ETA: 18s - loss: 0.8449 - accuracy: 0.772 - ETA: 16s - loss: 0.8444 - accuracy: 0.772 - ETA: 15s - loss: 0.8448 - accuracy: 0.772 - ETA: 14s - loss: 0.8447 - accuracy: 0.772 - ETA: 13s - loss: 0.8446 - accuracy: 0.772 - ETA: 12s - loss: 0.8462 - accuracy: 0.772 - ETA: 11s - loss: 0.8469 - accuracy: 0.771 - ETA: 10s - loss: 0.8456 - accuracy: 0.772 - ETA: 8s - loss: 0.8464 - accuracy: 0.771 - ETA: 7s - loss: 0.8455 - accuracy: 0.77 - ETA: 6s - loss: 0.8451 - accuracy: 0.77 - ETA: 5s - loss: 0.8460 - accuracy: 0.77 - ETA: 4s - loss: 0.8454 - accuracy: 0.77 - ETA: 3s - loss: 0.8460 - accuracy: 0.77 - ETA: 2s - loss: 0.8462 - accuracy: 0.77 - ETA: 0s - loss: 0.8456 - accuracy: 0.77 - 184s 10ms/step - loss: 0.8438 - accuracy: 0.7721 - val_loss: 1.7784 - val_accuracy: 0.7190\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:49 - loss: 0.9782 - accuracy: 0.71 - ETA: 2:46 - loss: 1.0240 - accuracy: 0.75 - ETA: 2:48 - loss: 1.0082 - accuracy: 0.76 - ETA: 2:53 - loss: 0.9568 - accuracy: 0.77 - ETA: 2:51 - loss: 0.9222 - accuracy: 0.76 - ETA: 2:48 - loss: 0.9057 - accuracy: 0.76 - ETA: 2:46 - loss: 0.8812 - accuracy: 0.76 - ETA: 2:43 - loss: 0.8896 - accuracy: 0.75 - ETA: 2:42 - loss: 0.9000 - accuracy: 0.75 - ETA: 2:40 - loss: 0.8806 - accuracy: 0.76 - ETA: 2:39 - loss: 0.8996 - accuracy: 0.75 - ETA: 2:37 - loss: 0.8715 - accuracy: 0.75 - ETA: 2:36 - loss: 0.8553 - accuracy: 0.76 - ETA: 2:35 - loss: 0.8651 - accuracy: 0.75 - ETA: 2:33 - loss: 0.8559 - accuracy: 0.75 - ETA: 2:32 - loss: 0.8492 - accuracy: 0.76 - ETA: 2:31 - loss: 0.8365 - accuracy: 0.76 - ETA: 2:31 - loss: 0.8416 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8477 - accuracy: 0.76 - ETA: 2:29 - loss: 0.8470 - accuracy: 0.76 - ETA: 2:28 - loss: 0.8399 - accuracy: 0.76 - ETA: 2:27 - loss: 0.8257 - accuracy: 0.76 - ETA: 2:25 - loss: 0.8308 - accuracy: 0.76 - ETA: 2:24 - loss: 0.8300 - accuracy: 0.76 - ETA: 2:23 - loss: 0.8215 - accuracy: 0.76 - ETA: 2:21 - loss: 0.8289 - accuracy: 0.76 - ETA: 2:20 - loss: 0.8320 - accuracy: 0.76 - ETA: 2:19 - loss: 0.8306 - accuracy: 0.76 - ETA: 2:17 - loss: 0.8269 - accuracy: 0.76 - ETA: 2:16 - loss: 0.8194 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8186 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8195 - accuracy: 0.76 - ETA: 2:14 - loss: 0.8143 - accuracy: 0.76 - ETA: 2:12 - loss: 0.8110 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8136 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8195 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8155 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8182 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8123 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8130 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8118 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8089 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8068 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8127 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8094 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8131 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8125 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8190 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8254 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8265 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8276 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8267 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8239 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8246 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8278 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8234 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8199 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8178 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8170 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8207 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8196 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8178 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8222 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8215 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8244 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8205 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8190 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8161 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8197 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8189 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8179 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8185 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8234 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8238 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8231 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8246 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8267 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8268 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8265 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8250 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8231 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8246 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8308 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8301 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8317 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8294 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8314 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8319 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8315 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8312 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8372 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8348 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8329 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8300 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8279 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8307 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8309 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8307 - accuracy: 0.77 - ETA: 59s - loss: 0.8307 - accuracy: 0.7729 - ETA: 58s - loss: 0.8277 - accuracy: 0.773 - ETA: 56s - loss: 0.8259 - accuracy: 0.773 - ETA: 55s - loss: 0.8274 - accuracy: 0.773 - ETA: 54s - loss: 0.8257 - accuracy: 0.774 - ETA: 53s - loss: 0.8256 - accuracy: 0.774 - ETA: 52s - loss: 0.8261 - accuracy: 0.773 - ETA: 51s - loss: 0.8279 - accuracy: 0.773 - ETA: 50s - loss: 0.8275 - accuracy: 0.773 - ETA: 48s - loss: 0.8269 - accuracy: 0.773 - ETA: 47s - loss: 0.8254 - accuracy: 0.773 - ETA: 46s - loss: 0.8289 - accuracy: 0.772 - ETA: 45s - loss: 0.8311 - accuracy: 0.773 - ETA: 44s - loss: 0.8321 - accuracy: 0.772 - ETA: 43s - loss: 0.8301 - accuracy: 0.773 - ETA: 42s - loss: 0.8307 - accuracy: 0.773 - ETA: 40s - loss: 0.8308 - accuracy: 0.772 - ETA: 39s - loss: 0.8307 - accuracy: 0.772 - ETA: 38s - loss: 0.8312 - accuracy: 0.772 - ETA: 37s - loss: 0.8327 - accuracy: 0.772 - ETA: 36s - loss: 0.8337 - accuracy: 0.772 - ETA: 35s - loss: 0.8343 - accuracy: 0.772 - ETA: 34s - loss: 0.8381 - accuracy: 0.772 - ETA: 32s - loss: 0.8395 - accuracy: 0.771 - ETA: 31s - loss: 0.8416 - accuracy: 0.771 - ETA: 30s - loss: 0.8410 - accuracy: 0.771 - ETA: 29s - loss: 0.8406 - accuracy: 0.770 - ETA: 28s - loss: 0.8399 - accuracy: 0.771 - ETA: 27s - loss: 0.8378 - accuracy: 0.771 - ETA: 26s - loss: 0.8372 - accuracy: 0.771 - ETA: 24s - loss: 0.8354 - accuracy: 0.772 - ETA: 23s - loss: 0.8347 - accuracy: 0.772 - ETA: 22s - loss: 0.8336 - accuracy: 0.772 - ETA: 21s - loss: 0.8344 - accuracy: 0.772 - ETA: 20s - loss: 0.8361 - accuracy: 0.772 - ETA: 19s - loss: 0.8341 - accuracy: 0.772 - ETA: 18s - loss: 0.8338 - accuracy: 0.772 - ETA: 17s - loss: 0.8325 - accuracy: 0.772 - ETA: 16s - loss: 0.8333 - accuracy: 0.773 - ETA: 15s - loss: 0.8336 - accuracy: 0.772 - ETA: 14s - loss: 0.8368 - accuracy: 0.772 - ETA: 13s - loss: 0.8371 - accuracy: 0.772 - ETA: 11s - loss: 0.8375 - accuracy: 0.772 - ETA: 10s - loss: 0.8407 - accuracy: 0.771 - ETA: 9s - loss: 0.8388 - accuracy: 0.772 - ETA: 8s - loss: 0.8379 - accuracy: 0.77 - ETA: 7s - loss: 0.8388 - accuracy: 0.77 - ETA: 5s - loss: 0.8403 - accuracy: 0.77 - ETA: 4s - loss: 0.8409 - accuracy: 0.77 - ETA: 3s - loss: 0.8412 - accuracy: 0.77 - ETA: 2s - loss: 0.8400 - accuracy: 0.77 - ETA: 1s - loss: 0.8376 - accuracy: 0.77 - 214s 11ms/step - loss: 0.8371 - accuracy: 0.7732 - val_loss: 1.9533 - val_accuracy: 0.7229\n",
      "Epoch 64/100\n",
      "19312/19312 [==============================] - ETA: 4:51 - loss: 0.8004 - accuracy: 0.78 - ETA: 4:50 - loss: 0.7950 - accuracy: 0.78 - ETA: 4:44 - loss: 0.7982 - accuracy: 0.79 - ETA: 4:46 - loss: 0.7906 - accuracy: 0.78 - ETA: 4:45 - loss: 0.7374 - accuracy: 0.80 - ETA: 4:39 - loss: 0.7350 - accuracy: 0.80 - ETA: 4:36 - loss: 0.7412 - accuracy: 0.79 - ETA: 4:33 - loss: 0.7123 - accuracy: 0.80 - ETA: 4:35 - loss: 0.7232 - accuracy: 0.79 - ETA: 4:31 - loss: 0.7330 - accuracy: 0.78 - ETA: 4:27 - loss: 0.7281 - accuracy: 0.78 - ETA: 4:24 - loss: 0.7154 - accuracy: 0.79 - ETA: 4:20 - loss: 0.7795 - accuracy: 0.78 - ETA: 4:17 - loss: 0.7786 - accuracy: 0.78 - ETA: 4:16 - loss: 0.7754 - accuracy: 0.78 - ETA: 4:13 - loss: 0.7877 - accuracy: 0.78 - ETA: 4:10 - loss: 0.7738 - accuracy: 0.78 - ETA: 4:08 - loss: 0.7736 - accuracy: 0.78 - ETA: 4:07 - loss: 0.7771 - accuracy: 0.78 - ETA: 4:04 - loss: 0.7720 - accuracy: 0.78 - ETA: 4:02 - loss: 0.7670 - accuracy: 0.78 - ETA: 3:57 - loss: 0.7643 - accuracy: 0.78 - ETA: 3:56 - loss: 0.7588 - accuracy: 0.78 - ETA: 3:54 - loss: 0.7764 - accuracy: 0.78 - ETA: 3:52 - loss: 0.7766 - accuracy: 0.78 - ETA: 3:48 - loss: 0.7839 - accuracy: 0.78 - ETA: 3:47 - loss: 0.7852 - accuracy: 0.77 - ETA: 3:45 - loss: 0.7960 - accuracy: 0.77 - ETA: 3:44 - loss: 0.8126 - accuracy: 0.77 - ETA: 3:42 - loss: 0.8169 - accuracy: 0.77 - ETA: 3:40 - loss: 0.8248 - accuracy: 0.77 - ETA: 3:38 - loss: 0.8255 - accuracy: 0.77 - ETA: 3:36 - loss: 0.8197 - accuracy: 0.77 - ETA: 3:34 - loss: 0.8140 - accuracy: 0.77 - ETA: 3:30 - loss: 0.8167 - accuracy: 0.77 - ETA: 3:28 - loss: 0.8151 - accuracy: 0.77 - ETA: 3:27 - loss: 0.8191 - accuracy: 0.77 - ETA: 3:25 - loss: 0.8166 - accuracy: 0.77 - ETA: 3:24 - loss: 0.8239 - accuracy: 0.77 - ETA: 3:22 - loss: 0.8250 - accuracy: 0.77 - ETA: 3:20 - loss: 0.8296 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8257 - accuracy: 0.77 - ETA: 3:17 - loss: 0.8239 - accuracy: 0.77 - ETA: 3:15 - loss: 0.8266 - accuracy: 0.77 - ETA: 3:13 - loss: 0.8256 - accuracy: 0.77 - ETA: 3:11 - loss: 0.8225 - accuracy: 0.77 - ETA: 3:10 - loss: 0.8229 - accuracy: 0.77 - ETA: 3:08 - loss: 0.8263 - accuracy: 0.77 - ETA: 3:06 - loss: 0.8268 - accuracy: 0.77 - ETA: 3:04 - loss: 0.8305 - accuracy: 0.77 - ETA: 3:02 - loss: 0.8336 - accuracy: 0.77 - ETA: 3:00 - loss: 0.8377 - accuracy: 0.77 - ETA: 2:59 - loss: 0.8379 - accuracy: 0.77 - ETA: 2:57 - loss: 0.8383 - accuracy: 0.77 - ETA: 2:55 - loss: 0.8370 - accuracy: 0.77 - ETA: 2:53 - loss: 0.8332 - accuracy: 0.77 - ETA: 2:51 - loss: 0.8266 - accuracy: 0.77 - ETA: 2:50 - loss: 0.8236 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8245 - accuracy: 0.77 - ETA: 2:46 - loss: 0.8254 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8241 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8233 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8224 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8195 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8200 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8195 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8198 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8184 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8171 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8143 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8143 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8111 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8113 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8145 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8131 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8127 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8150 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8132 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8105 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8092 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8087 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8103 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8104 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8122 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8125 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8112 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8102 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8087 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8068 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8049 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8036 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8069 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8070 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8090 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8074 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8060 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8090 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8078 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8091 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8080 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8078 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8087 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8096 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8070 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8058 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8056 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8077 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8091 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8089 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8077 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8086 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8093 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8093 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8106 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8100 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8119 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8132 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8131 - accuracy: 0.77 - ETA: 59s - loss: 0.8114 - accuracy: 0.7737 - ETA: 57s - loss: 0.8143 - accuracy: 0.774 - ETA: 55s - loss: 0.8136 - accuracy: 0.773 - ETA: 53s - loss: 0.8153 - accuracy: 0.773 - ETA: 51s - loss: 0.8159 - accuracy: 0.774 - ETA: 49s - loss: 0.8154 - accuracy: 0.774 - ETA: 48s - loss: 0.8146 - accuracy: 0.774 - ETA: 46s - loss: 0.8155 - accuracy: 0.774 - ETA: 44s - loss: 0.8173 - accuracy: 0.773 - ETA: 42s - loss: 0.8166 - accuracy: 0.774 - ETA: 40s - loss: 0.8208 - accuracy: 0.773 - ETA: 38s - loss: 0.8215 - accuracy: 0.773 - ETA: 37s - loss: 0.8211 - accuracy: 0.773 - ETA: 35s - loss: 0.8196 - accuracy: 0.773 - ETA: 33s - loss: 0.8186 - accuracy: 0.773 - ETA: 31s - loss: 0.8205 - accuracy: 0.774 - ETA: 29s - loss: 0.8204 - accuracy: 0.774 - ETA: 27s - loss: 0.8219 - accuracy: 0.774 - ETA: 25s - loss: 0.8270 - accuracy: 0.774 - ETA: 23s - loss: 0.8270 - accuracy: 0.773 - ETA: 22s - loss: 0.8262 - accuracy: 0.773 - ETA: 20s - loss: 0.8260 - accuracy: 0.773 - ETA: 18s - loss: 0.8260 - accuracy: 0.773 - ETA: 16s - loss: 0.8261 - accuracy: 0.773 - ETA: 14s - loss: 0.8252 - accuracy: 0.773 - ETA: 12s - loss: 0.8246 - accuracy: 0.773 - ETA: 10s - loss: 0.8239 - accuracy: 0.774 - ETA: 9s - loss: 0.8266 - accuracy: 0.773 - ETA: 7s - loss: 0.8262 - accuracy: 0.77 - ETA: 5s - loss: 0.8265 - accuracy: 0.77 - ETA: 3s - loss: 0.8265 - accuracy: 0.77 - ETA: 1s - loss: 0.8277 - accuracy: 0.77 - 306s 16ms/step - loss: 0.8292 - accuracy: 0.7735 - val_loss: 1.8495 - val_accuracy: 0.7213\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:21 - loss: 1.0315 - accuracy: 0.75 - ETA: 4:26 - loss: 0.9691 - accuracy: 0.74 - ETA: 4:26 - loss: 0.8996 - accuracy: 0.74 - ETA: 4:26 - loss: 0.8823 - accuracy: 0.75 - ETA: 4:26 - loss: 0.8654 - accuracy: 0.75 - ETA: 4:25 - loss: 0.8317 - accuracy: 0.77 - ETA: 4:25 - loss: 0.8210 - accuracy: 0.77 - ETA: 4:25 - loss: 0.7884 - accuracy: 0.77 - ETA: 4:23 - loss: 0.7648 - accuracy: 0.78 - ETA: 4:21 - loss: 0.7747 - accuracy: 0.78 - ETA: 4:19 - loss: 0.7725 - accuracy: 0.78 - ETA: 4:17 - loss: 0.7825 - accuracy: 0.78 - ETA: 4:17 - loss: 0.7945 - accuracy: 0.78 - ETA: 4:15 - loss: 0.8054 - accuracy: 0.78 - ETA: 4:13 - loss: 0.8108 - accuracy: 0.77 - ETA: 4:11 - loss: 0.8067 - accuracy: 0.77 - ETA: 4:09 - loss: 0.8051 - accuracy: 0.77 - ETA: 4:07 - loss: 0.8190 - accuracy: 0.77 - ETA: 4:04 - loss: 0.8111 - accuracy: 0.77 - ETA: 4:02 - loss: 0.8016 - accuracy: 0.77 - ETA: 4:01 - loss: 0.8183 - accuracy: 0.77 - ETA: 3:59 - loss: 0.8161 - accuracy: 0.77 - ETA: 3:56 - loss: 0.8066 - accuracy: 0.77 - ETA: 3:54 - loss: 0.8067 - accuracy: 0.77 - ETA: 3:51 - loss: 0.8157 - accuracy: 0.77 - ETA: 3:50 - loss: 0.8149 - accuracy: 0.77 - ETA: 3:48 - loss: 0.8240 - accuracy: 0.77 - ETA: 3:46 - loss: 0.8267 - accuracy: 0.77 - ETA: 3:44 - loss: 0.8178 - accuracy: 0.77 - ETA: 3:42 - loss: 0.8210 - accuracy: 0.77 - ETA: 3:40 - loss: 0.8147 - accuracy: 0.77 - ETA: 3:39 - loss: 0.8134 - accuracy: 0.77 - ETA: 3:37 - loss: 0.8124 - accuracy: 0.77 - ETA: 3:35 - loss: 0.8176 - accuracy: 0.77 - ETA: 3:33 - loss: 0.8193 - accuracy: 0.77 - ETA: 3:31 - loss: 0.8148 - accuracy: 0.77 - ETA: 3:29 - loss: 0.8194 - accuracy: 0.77 - ETA: 3:27 - loss: 0.8255 - accuracy: 0.77 - ETA: 3:26 - loss: 0.8227 - accuracy: 0.77 - ETA: 3:24 - loss: 0.8260 - accuracy: 0.77 - ETA: 3:21 - loss: 0.8206 - accuracy: 0.77 - ETA: 3:19 - loss: 0.8254 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8251 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8295 - accuracy: 0.77 - ETA: 3:14 - loss: 0.8413 - accuracy: 0.77 - ETA: 3:12 - loss: 0.8443 - accuracy: 0.77 - ETA: 3:10 - loss: 0.8452 - accuracy: 0.77 - ETA: 3:08 - loss: 0.8454 - accuracy: 0.77 - ETA: 3:07 - loss: 0.8496 - accuracy: 0.77 - ETA: 3:05 - loss: 0.8513 - accuracy: 0.77 - ETA: 3:03 - loss: 0.8519 - accuracy: 0.77 - ETA: 3:01 - loss: 0.8565 - accuracy: 0.77 - ETA: 3:00 - loss: 0.8533 - accuracy: 0.77 - ETA: 2:58 - loss: 0.8525 - accuracy: 0.77 - ETA: 2:56 - loss: 0.8564 - accuracy: 0.77 - ETA: 2:54 - loss: 0.8614 - accuracy: 0.77 - ETA: 2:53 - loss: 0.8629 - accuracy: 0.77 - ETA: 2:51 - loss: 0.8609 - accuracy: 0.77 - ETA: 2:49 - loss: 0.8616 - accuracy: 0.77 - ETA: 2:47 - loss: 0.8556 - accuracy: 0.77 - ETA: 2:45 - loss: 0.8561 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8625 - accuracy: 0.76 - ETA: 2:42 - loss: 0.8610 - accuracy: 0.76 - ETA: 2:40 - loss: 0.8617 - accuracy: 0.76 - ETA: 2:38 - loss: 0.8598 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8568 - accuracy: 0.76 - ETA: 2:34 - loss: 0.8506 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8555 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8510 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8474 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8494 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8519 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8510 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8509 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8507 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8487 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8494 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8488 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8462 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8502 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8508 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8491 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8503 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8524 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8532 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8541 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8536 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8526 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8539 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8577 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8561 - accuracy: 0.76 - ETA: 1:48 - loss: 0.8548 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8529 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8489 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8466 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8450 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8450 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8447 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8490 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8483 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8516 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8507 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8536 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8536 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8514 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8509 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8490 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8542 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8541 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8538 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8535 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8533 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8528 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8512 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8496 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8504 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8504 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8496 - accuracy: 0.77 - ETA: 59s - loss: 0.8491 - accuracy: 0.7707 - ETA: 57s - loss: 0.8494 - accuracy: 0.770 - ETA: 55s - loss: 0.8492 - accuracy: 0.770 - ETA: 53s - loss: 0.8460 - accuracy: 0.771 - ETA: 51s - loss: 0.8463 - accuracy: 0.770 - ETA: 50s - loss: 0.8470 - accuracy: 0.770 - ETA: 48s - loss: 0.8477 - accuracy: 0.770 - ETA: 46s - loss: 0.8470 - accuracy: 0.770 - ETA: 44s - loss: 0.8461 - accuracy: 0.770 - ETA: 42s - loss: 0.8456 - accuracy: 0.770 - ETA: 40s - loss: 0.8438 - accuracy: 0.770 - ETA: 38s - loss: 0.8449 - accuracy: 0.769 - ETA: 37s - loss: 0.8454 - accuracy: 0.769 - ETA: 35s - loss: 0.8462 - accuracy: 0.769 - ETA: 33s - loss: 0.8499 - accuracy: 0.769 - ETA: 31s - loss: 0.8539 - accuracy: 0.768 - ETA: 29s - loss: 0.8541 - accuracy: 0.768 - ETA: 27s - loss: 0.8535 - accuracy: 0.769 - ETA: 25s - loss: 0.8537 - accuracy: 0.769 - ETA: 24s - loss: 0.8560 - accuracy: 0.769 - ETA: 22s - loss: 0.8541 - accuracy: 0.769 - ETA: 20s - loss: 0.8544 - accuracy: 0.768 - ETA: 18s - loss: 0.8548 - accuracy: 0.768 - ETA: 16s - loss: 0.8538 - accuracy: 0.768 - ETA: 14s - loss: 0.8551 - accuracy: 0.768 - ETA: 12s - loss: 0.8538 - accuracy: 0.768 - ETA: 10s - loss: 0.8515 - accuracy: 0.768 - ETA: 9s - loss: 0.8502 - accuracy: 0.769 - ETA: 7s - loss: 0.8507 - accuracy: 0.76 - ETA: 5s - loss: 0.8509 - accuracy: 0.76 - ETA: 3s - loss: 0.8523 - accuracy: 0.76 - ETA: 1s - loss: 0.8519 - accuracy: 0.76 - 306s 16ms/step - loss: 0.8518 - accuracy: 0.7693 - val_loss: 1.8670 - val_accuracy: 0.7283\n",
      "Epoch 66/100\n",
      "19312/19312 [==============================] - ETA: 4:38 - loss: 0.7342 - accuracy: 0.81 - ETA: 4:36 - loss: 0.7182 - accuracy: 0.78 - ETA: 4:34 - loss: 0.6473 - accuracy: 0.80 - ETA: 4:31 - loss: 0.7026 - accuracy: 0.80 - ETA: 4:26 - loss: 0.6740 - accuracy: 0.81 - ETA: 4:24 - loss: 0.6977 - accuracy: 0.80 - ETA: 4:22 - loss: 0.7271 - accuracy: 0.80 - ETA: 4:23 - loss: 0.7588 - accuracy: 0.79 - ETA: 4:22 - loss: 0.7674 - accuracy: 0.78 - ETA: 4:22 - loss: 0.7939 - accuracy: 0.78 - ETA: 4:22 - loss: 0.7871 - accuracy: 0.78 - ETA: 4:21 - loss: 0.8055 - accuracy: 0.78 - ETA: 4:20 - loss: 0.8073 - accuracy: 0.78 - ETA: 4:21 - loss: 0.8081 - accuracy: 0.78 - ETA: 4:20 - loss: 0.8463 - accuracy: 0.77 - ETA: 4:16 - loss: 0.8428 - accuracy: 0.77 - ETA: 4:15 - loss: 0.8396 - accuracy: 0.77 - ETA: 4:14 - loss: 0.8231 - accuracy: 0.77 - ETA: 4:13 - loss: 0.8291 - accuracy: 0.77 - ETA: 4:20 - loss: 0.8194 - accuracy: 0.77 - ETA: 4:17 - loss: 0.8308 - accuracy: 0.77 - ETA: 4:14 - loss: 0.8409 - accuracy: 0.77 - ETA: 4:12 - loss: 0.8287 - accuracy: 0.77 - ETA: 4:10 - loss: 0.8237 - accuracy: 0.77 - ETA: 4:08 - loss: 0.8303 - accuracy: 0.77 - ETA: 4:05 - loss: 0.8272 - accuracy: 0.78 - ETA: 4:03 - loss: 0.8199 - accuracy: 0.78 - ETA: 4:00 - loss: 0.8120 - accuracy: 0.78 - ETA: 3:58 - loss: 0.8141 - accuracy: 0.78 - ETA: 3:55 - loss: 0.8243 - accuracy: 0.78 - ETA: 3:53 - loss: 0.8282 - accuracy: 0.78 - ETA: 3:50 - loss: 0.8193 - accuracy: 0.78 - ETA: 3:48 - loss: 0.8186 - accuracy: 0.78 - ETA: 3:45 - loss: 0.8135 - accuracy: 0.78 - ETA: 3:43 - loss: 0.8077 - accuracy: 0.78 - ETA: 3:41 - loss: 0.8108 - accuracy: 0.78 - ETA: 3:39 - loss: 0.8047 - accuracy: 0.78 - ETA: 3:37 - loss: 0.8081 - accuracy: 0.78 - ETA: 3:35 - loss: 0.8094 - accuracy: 0.77 - ETA: 3:33 - loss: 0.8041 - accuracy: 0.78 - ETA: 3:31 - loss: 0.8009 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8061 - accuracy: 0.77 - ETA: 3:26 - loss: 0.8008 - accuracy: 0.78 - ETA: 3:24 - loss: 0.7999 - accuracy: 0.78 - ETA: 3:23 - loss: 0.8050 - accuracy: 0.77 - ETA: 3:21 - loss: 0.8062 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8080 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8075 - accuracy: 0.77 - ETA: 3:14 - loss: 0.8104 - accuracy: 0.77 - ETA: 3:12 - loss: 0.8083 - accuracy: 0.77 - ETA: 3:10 - loss: 0.8068 - accuracy: 0.77 - ETA: 3:08 - loss: 0.8006 - accuracy: 0.77 - ETA: 3:06 - loss: 0.8022 - accuracy: 0.77 - ETA: 3:04 - loss: 0.8052 - accuracy: 0.77 - ETA: 3:02 - loss: 0.8068 - accuracy: 0.77 - ETA: 3:00 - loss: 0.8079 - accuracy: 0.77 - ETA: 2:58 - loss: 0.8077 - accuracy: 0.77 - ETA: 2:56 - loss: 0.8084 - accuracy: 0.77 - ETA: 2:54 - loss: 0.8088 - accuracy: 0.77 - ETA: 2:52 - loss: 0.8113 - accuracy: 0.77 - ETA: 2:50 - loss: 0.8095 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8090 - accuracy: 0.77 - ETA: 2:46 - loss: 0.8120 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8127 - accuracy: 0.77 - ETA: 2:42 - loss: 0.8181 - accuracy: 0.77 - ETA: 2:40 - loss: 0.8177 - accuracy: 0.77 - ETA: 2:38 - loss: 0.8172 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8162 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8193 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8205 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8169 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8207 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8226 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8218 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8220 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8207 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8201 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8205 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8204 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8188 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8239 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8237 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8247 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8262 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8255 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8230 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8227 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8227 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8209 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8196 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8186 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8215 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8219 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8196 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8185 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8180 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8191 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8200 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8196 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8209 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8244 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8239 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8238 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8265 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8273 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8292 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8283 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8297 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8311 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8305 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8318 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8326 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8315 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8315 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8321 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8295 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8289 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8307 - accuracy: 0.77 - ETA: 59s - loss: 0.8294 - accuracy: 0.7750 - ETA: 57s - loss: 0.8278 - accuracy: 0.775 - ETA: 55s - loss: 0.8283 - accuracy: 0.775 - ETA: 54s - loss: 0.8307 - accuracy: 0.775 - ETA: 52s - loss: 0.8302 - accuracy: 0.774 - ETA: 50s - loss: 0.8291 - accuracy: 0.774 - ETA: 48s - loss: 0.8288 - accuracy: 0.774 - ETA: 46s - loss: 0.8307 - accuracy: 0.774 - ETA: 44s - loss: 0.8314 - accuracy: 0.774 - ETA: 42s - loss: 0.8295 - accuracy: 0.775 - ETA: 41s - loss: 0.8294 - accuracy: 0.775 - ETA: 39s - loss: 0.8309 - accuracy: 0.774 - ETA: 37s - loss: 0.8341 - accuracy: 0.774 - ETA: 35s - loss: 0.8333 - accuracy: 0.774 - ETA: 33s - loss: 0.8325 - accuracy: 0.775 - ETA: 31s - loss: 0.8316 - accuracy: 0.775 - ETA: 29s - loss: 0.8312 - accuracy: 0.775 - ETA: 27s - loss: 0.8308 - accuracy: 0.775 - ETA: 26s - loss: 0.8305 - accuracy: 0.775 - ETA: 24s - loss: 0.8310 - accuracy: 0.775 - ETA: 22s - loss: 0.8315 - accuracy: 0.775 - ETA: 20s - loss: 0.8310 - accuracy: 0.775 - ETA: 18s - loss: 0.8331 - accuracy: 0.775 - ETA: 16s - loss: 0.8339 - accuracy: 0.775 - ETA: 14s - loss: 0.8327 - accuracy: 0.776 - ETA: 12s - loss: 0.8327 - accuracy: 0.775 - ETA: 11s - loss: 0.8337 - accuracy: 0.775 - ETA: 9s - loss: 0.8344 - accuracy: 0.774 - ETA: 7s - loss: 0.8364 - accuracy: 0.77 - ETA: 5s - loss: 0.8369 - accuracy: 0.77 - ETA: 3s - loss: 0.8357 - accuracy: 0.77 - ETA: 1s - loss: 0.8340 - accuracy: 0.77 - 309s 16ms/step - loss: 0.8345 - accuracy: 0.7749 - val_loss: 2.0979 - val_accuracy: 0.7221\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:35 - loss: 0.7962 - accuracy: 0.76 - ETA: 4:37 - loss: 0.9084 - accuracy: 0.76 - ETA: 4:35 - loss: 0.9194 - accuracy: 0.75 - ETA: 4:34 - loss: 0.8746 - accuracy: 0.76 - ETA: 4:28 - loss: 0.8033 - accuracy: 0.77 - ETA: 4:28 - loss: 0.7633 - accuracy: 0.77 - ETA: 4:25 - loss: 0.8128 - accuracy: 0.77 - ETA: 4:24 - loss: 0.7946 - accuracy: 0.77 - ETA: 4:22 - loss: 0.8175 - accuracy: 0.77 - ETA: 4:21 - loss: 0.8100 - accuracy: 0.77 - ETA: 4:19 - loss: 0.8290 - accuracy: 0.76 - ETA: 4:17 - loss: 0.8615 - accuracy: 0.76 - ETA: 4:15 - loss: 0.8428 - accuracy: 0.76 - ETA: 4:14 - loss: 0.8073 - accuracy: 0.77 - ETA: 4:12 - loss: 0.8344 - accuracy: 0.77 - ETA: 4:10 - loss: 0.8405 - accuracy: 0.77 - ETA: 4:08 - loss: 0.8493 - accuracy: 0.77 - ETA: 4:07 - loss: 0.8383 - accuracy: 0.77 - ETA: 4:06 - loss: 0.8343 - accuracy: 0.78 - ETA: 4:03 - loss: 0.8637 - accuracy: 0.77 - ETA: 4:01 - loss: 0.8649 - accuracy: 0.77 - ETA: 3:59 - loss: 0.8839 - accuracy: 0.77 - ETA: 3:57 - loss: 0.8816 - accuracy: 0.77 - ETA: 3:55 - loss: 0.8840 - accuracy: 0.77 - ETA: 3:53 - loss: 0.8934 - accuracy: 0.77 - ETA: 3:51 - loss: 0.8896 - accuracy: 0.77 - ETA: 3:50 - loss: 0.8968 - accuracy: 0.77 - ETA: 3:48 - loss: 0.8930 - accuracy: 0.77 - ETA: 3:46 - loss: 0.8930 - accuracy: 0.77 - ETA: 3:44 - loss: 0.8892 - accuracy: 0.77 - ETA: 3:42 - loss: 0.8770 - accuracy: 0.77 - ETA: 3:40 - loss: 0.8735 - accuracy: 0.77 - ETA: 3:38 - loss: 0.8652 - accuracy: 0.77 - ETA: 3:37 - loss: 0.8584 - accuracy: 0.77 - ETA: 3:35 - loss: 0.8638 - accuracy: 0.77 - ETA: 3:33 - loss: 0.8614 - accuracy: 0.77 - ETA: 3:31 - loss: 0.8505 - accuracy: 0.77 - ETA: 3:29 - loss: 0.8650 - accuracy: 0.77 - ETA: 3:27 - loss: 0.8623 - accuracy: 0.77 - ETA: 3:25 - loss: 0.8624 - accuracy: 0.77 - ETA: 3:23 - loss: 0.8732 - accuracy: 0.77 - ETA: 3:22 - loss: 0.8711 - accuracy: 0.77 - ETA: 3:20 - loss: 0.8713 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8679 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8623 - accuracy: 0.77 - ETA: 3:15 - loss: 0.8596 - accuracy: 0.77 - ETA: 3:13 - loss: 0.8584 - accuracy: 0.77 - ETA: 3:11 - loss: 0.8540 - accuracy: 0.77 - ETA: 3:09 - loss: 0.8489 - accuracy: 0.77 - ETA: 3:07 - loss: 0.8461 - accuracy: 0.77 - ETA: 3:05 - loss: 0.8428 - accuracy: 0.77 - ETA: 3:03 - loss: 0.8439 - accuracy: 0.77 - ETA: 3:01 - loss: 0.8465 - accuracy: 0.77 - ETA: 3:00 - loss: 0.8451 - accuracy: 0.77 - ETA: 2:58 - loss: 0.8470 - accuracy: 0.77 - ETA: 2:56 - loss: 0.8457 - accuracy: 0.77 - ETA: 2:54 - loss: 0.8506 - accuracy: 0.77 - ETA: 2:52 - loss: 0.8493 - accuracy: 0.77 - ETA: 2:51 - loss: 0.8450 - accuracy: 0.77 - ETA: 2:49 - loss: 0.8473 - accuracy: 0.77 - ETA: 2:47 - loss: 0.8465 - accuracy: 0.77 - ETA: 2:45 - loss: 0.8465 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8448 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8419 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8397 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8378 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8387 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8332 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8380 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8407 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8381 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8423 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8412 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8398 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8389 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8360 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8355 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8352 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8359 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8313 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8312 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8333 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8319 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8332 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8296 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8332 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8347 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8327 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8333 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8370 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8368 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8362 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8345 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8323 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8361 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8375 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8356 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8328 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8295 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8317 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8310 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8331 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8314 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8276 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8258 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8260 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8256 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8265 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8293 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8298 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8297 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8284 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8281 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8286 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8278 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8269 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8251 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8255 - accuracy: 0.77 - ETA: 59s - loss: 0.8262 - accuracy: 0.7740 - ETA: 57s - loss: 0.8250 - accuracy: 0.774 - ETA: 55s - loss: 0.8238 - accuracy: 0.774 - ETA: 54s - loss: 0.8221 - accuracy: 0.774 - ETA: 52s - loss: 0.8236 - accuracy: 0.773 - ETA: 50s - loss: 0.8244 - accuracy: 0.774 - ETA: 48s - loss: 0.8255 - accuracy: 0.773 - ETA: 46s - loss: 0.8246 - accuracy: 0.773 - ETA: 44s - loss: 0.8244 - accuracy: 0.773 - ETA: 42s - loss: 0.8251 - accuracy: 0.773 - ETA: 40s - loss: 0.8235 - accuracy: 0.773 - ETA: 39s - loss: 0.8252 - accuracy: 0.773 - ETA: 37s - loss: 0.8265 - accuracy: 0.772 - ETA: 35s - loss: 0.8259 - accuracy: 0.772 - ETA: 33s - loss: 0.8252 - accuracy: 0.773 - ETA: 31s - loss: 0.8270 - accuracy: 0.773 - ETA: 29s - loss: 0.8283 - accuracy: 0.773 - ETA: 27s - loss: 0.8277 - accuracy: 0.772 - ETA: 25s - loss: 0.8276 - accuracy: 0.772 - ETA: 24s - loss: 0.8268 - accuracy: 0.772 - ETA: 22s - loss: 0.8263 - accuracy: 0.772 - ETA: 20s - loss: 0.8274 - accuracy: 0.772 - ETA: 18s - loss: 0.8271 - accuracy: 0.773 - ETA: 16s - loss: 0.8277 - accuracy: 0.773 - ETA: 14s - loss: 0.8295 - accuracy: 0.773 - ETA: 12s - loss: 0.8297 - accuracy: 0.773 - ETA: 11s - loss: 0.8295 - accuracy: 0.773 - ETA: 9s - loss: 0.8281 - accuracy: 0.773 - ETA: 7s - loss: 0.8312 - accuracy: 0.77 - ETA: 5s - loss: 0.8314 - accuracy: 0.77 - ETA: 3s - loss: 0.8321 - accuracy: 0.77 - ETA: 1s - loss: 0.8308 - accuracy: 0.77 - 308s 16ms/step - loss: 0.8328 - accuracy: 0.7722 - val_loss: 1.9247 - val_accuracy: 0.7229\n",
      "Epoch 68/100\n",
      "19312/19312 [==============================] - ETA: 4:37 - loss: 0.8759 - accuracy: 0.75 - ETA: 5:34 - loss: 0.9825 - accuracy: 0.70 - ETA: 5:13 - loss: 0.8985 - accuracy: 0.73 - ETA: 5:03 - loss: 0.8763 - accuracy: 0.74 - ETA: 5:00 - loss: 0.9164 - accuracy: 0.76 - ETA: 4:54 - loss: 0.8973 - accuracy: 0.76 - ETA: 4:50 - loss: 0.8895 - accuracy: 0.76 - ETA: 4:48 - loss: 0.8423 - accuracy: 0.76 - ETA: 4:44 - loss: 0.8325 - accuracy: 0.77 - ETA: 4:41 - loss: 0.8434 - accuracy: 0.76 - ETA: 4:38 - loss: 0.8793 - accuracy: 0.77 - ETA: 4:36 - loss: 0.8784 - accuracy: 0.77 - ETA: 4:34 - loss: 0.8574 - accuracy: 0.78 - ETA: 4:33 - loss: 0.8519 - accuracy: 0.78 - ETA: 4:29 - loss: 0.8420 - accuracy: 0.78 - ETA: 4:26 - loss: 0.8346 - accuracy: 0.78 - ETA: 4:23 - loss: 0.8342 - accuracy: 0.78 - ETA: 4:20 - loss: 0.8295 - accuracy: 0.78 - ETA: 4:17 - loss: 0.8258 - accuracy: 0.78 - ETA: 4:14 - loss: 0.8245 - accuracy: 0.78 - ETA: 4:12 - loss: 0.8286 - accuracy: 0.78 - ETA: 4:09 - loss: 0.8292 - accuracy: 0.78 - ETA: 4:06 - loss: 0.8181 - accuracy: 0.78 - ETA: 4:04 - loss: 0.8137 - accuracy: 0.78 - ETA: 4:01 - loss: 0.8268 - accuracy: 0.77 - ETA: 3:58 - loss: 0.8264 - accuracy: 0.77 - ETA: 3:56 - loss: 0.8231 - accuracy: 0.77 - ETA: 3:54 - loss: 0.8229 - accuracy: 0.77 - ETA: 3:52 - loss: 0.8404 - accuracy: 0.77 - ETA: 3:50 - loss: 0.8373 - accuracy: 0.77 - ETA: 3:48 - loss: 0.8344 - accuracy: 0.77 - ETA: 3:47 - loss: 0.8301 - accuracy: 0.77 - ETA: 3:44 - loss: 0.8229 - accuracy: 0.77 - ETA: 3:43 - loss: 0.8247 - accuracy: 0.77 - ETA: 3:41 - loss: 0.8204 - accuracy: 0.77 - ETA: 3:39 - loss: 0.8129 - accuracy: 0.77 - ETA: 3:37 - loss: 0.8141 - accuracy: 0.77 - ETA: 3:35 - loss: 0.8131 - accuracy: 0.77 - ETA: 3:33 - loss: 0.8184 - accuracy: 0.77 - ETA: 3:31 - loss: 0.8217 - accuracy: 0.77 - ETA: 3:29 - loss: 0.8187 - accuracy: 0.77 - ETA: 3:27 - loss: 0.8207 - accuracy: 0.77 - ETA: 3:25 - loss: 0.8188 - accuracy: 0.77 - ETA: 3:23 - loss: 0.8176 - accuracy: 0.77 - ETA: 3:21 - loss: 0.8254 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8209 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8237 - accuracy: 0.77 - ETA: 3:14 - loss: 0.8268 - accuracy: 0.77 - ETA: 3:12 - loss: 0.8249 - accuracy: 0.77 - ETA: 3:10 - loss: 0.8196 - accuracy: 0.77 - ETA: 3:08 - loss: 0.8209 - accuracy: 0.77 - ETA: 3:06 - loss: 0.8196 - accuracy: 0.77 - ETA: 3:05 - loss: 0.8168 - accuracy: 0.77 - ETA: 3:03 - loss: 0.8169 - accuracy: 0.77 - ETA: 3:01 - loss: 0.8168 - accuracy: 0.77 - ETA: 2:59 - loss: 0.8152 - accuracy: 0.77 - ETA: 2:57 - loss: 0.8176 - accuracy: 0.77 - ETA: 2:55 - loss: 0.8150 - accuracy: 0.77 - ETA: 2:53 - loss: 0.8104 - accuracy: 0.77 - ETA: 2:51 - loss: 0.8093 - accuracy: 0.77 - ETA: 2:49 - loss: 0.8098 - accuracy: 0.77 - ETA: 2:47 - loss: 0.8103 - accuracy: 0.77 - ETA: 2:45 - loss: 0.8110 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8112 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8080 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8091 - accuracy: 0.77 - ETA: 2:38 - loss: 0.8094 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8079 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8108 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8101 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8130 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8124 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8109 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8125 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8129 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8147 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8209 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8200 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8183 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8229 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8225 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8240 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8225 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8206 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8205 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8193 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8213 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8213 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8204 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8200 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8230 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8201 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8224 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8242 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8272 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8279 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8280 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8269 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8271 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8286 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8262 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8248 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8252 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8267 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8265 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8277 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8289 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8293 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8289 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8320 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8327 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8327 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8330 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8330 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8315 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8320 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8315 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8302 - accuracy: 0.77 - ETA: 59s - loss: 0.8295 - accuracy: 0.7742 - ETA: 58s - loss: 0.8281 - accuracy: 0.774 - ETA: 56s - loss: 0.8274 - accuracy: 0.774 - ETA: 54s - loss: 0.8273 - accuracy: 0.774 - ETA: 52s - loss: 0.8291 - accuracy: 0.774 - ETA: 50s - loss: 0.8291 - accuracy: 0.774 - ETA: 48s - loss: 0.8302 - accuracy: 0.773 - ETA: 46s - loss: 0.8304 - accuracy: 0.774 - ETA: 44s - loss: 0.8312 - accuracy: 0.774 - ETA: 42s - loss: 0.8299 - accuracy: 0.774 - ETA: 41s - loss: 0.8361 - accuracy: 0.774 - ETA: 39s - loss: 0.8364 - accuracy: 0.774 - ETA: 37s - loss: 0.8375 - accuracy: 0.774 - ETA: 35s - loss: 0.8358 - accuracy: 0.774 - ETA: 33s - loss: 0.8367 - accuracy: 0.774 - ETA: 31s - loss: 0.8382 - accuracy: 0.774 - ETA: 29s - loss: 0.8377 - accuracy: 0.774 - ETA: 27s - loss: 0.8360 - accuracy: 0.774 - ETA: 26s - loss: 0.8376 - accuracy: 0.773 - ETA: 24s - loss: 0.8375 - accuracy: 0.773 - ETA: 22s - loss: 0.8362 - accuracy: 0.773 - ETA: 20s - loss: 0.8365 - accuracy: 0.774 - ETA: 18s - loss: 0.8349 - accuracy: 0.774 - ETA: 16s - loss: 0.8335 - accuracy: 0.774 - ETA: 14s - loss: 0.8342 - accuracy: 0.774 - ETA: 12s - loss: 0.8354 - accuracy: 0.774 - ETA: 11s - loss: 0.8366 - accuracy: 0.774 - ETA: 9s - loss: 0.8357 - accuracy: 0.775 - ETA: 7s - loss: 0.8336 - accuracy: 0.77 - ETA: 5s - loss: 0.8334 - accuracy: 0.77 - ETA: 3s - loss: 0.8327 - accuracy: 0.77 - ETA: 1s - loss: 0.8318 - accuracy: 0.77 - 309s 16ms/step - loss: 0.8303 - accuracy: 0.7766 - val_loss: 1.9474 - val_accuracy: 0.7252\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:30 - loss: 0.7417 - accuracy: 0.76 - ETA: 4:48 - loss: 0.7860 - accuracy: 0.74 - ETA: 4:36 - loss: 0.8824 - accuracy: 0.73 - ETA: 4:34 - loss: 0.8899 - accuracy: 0.74 - ETA: 4:32 - loss: 0.9435 - accuracy: 0.73 - ETA: 4:29 - loss: 0.9717 - accuracy: 0.73 - ETA: 4:28 - loss: 0.9824 - accuracy: 0.73 - ETA: 4:24 - loss: 0.9735 - accuracy: 0.74 - ETA: 4:23 - loss: 0.9528 - accuracy: 0.74 - ETA: 4:20 - loss: 0.9831 - accuracy: 0.74 - ETA: 4:18 - loss: 0.9745 - accuracy: 0.74 - ETA: 4:14 - loss: 0.9604 - accuracy: 0.74 - ETA: 4:12 - loss: 0.9520 - accuracy: 0.75 - ETA: 4:11 - loss: 0.9547 - accuracy: 0.75 - ETA: 4:09 - loss: 0.9632 - accuracy: 0.75 - ETA: 4:08 - loss: 0.9490 - accuracy: 0.75 - ETA: 4:08 - loss: 0.9445 - accuracy: 0.75 - ETA: 4:06 - loss: 0.9310 - accuracy: 0.75 - ETA: 4:04 - loss: 0.9390 - accuracy: 0.75 - ETA: 4:03 - loss: 0.9422 - accuracy: 0.75 - ETA: 4:01 - loss: 0.9234 - accuracy: 0.75 - ETA: 3:59 - loss: 0.9205 - accuracy: 0.75 - ETA: 3:57 - loss: 0.9137 - accuracy: 0.75 - ETA: 3:54 - loss: 0.9013 - accuracy: 0.75 - ETA: 3:53 - loss: 0.8910 - accuracy: 0.75 - ETA: 3:51 - loss: 0.8834 - accuracy: 0.75 - ETA: 3:49 - loss: 0.8750 - accuracy: 0.75 - ETA: 3:47 - loss: 0.8683 - accuracy: 0.76 - ETA: 3:46 - loss: 0.8585 - accuracy: 0.76 - ETA: 3:44 - loss: 0.8568 - accuracy: 0.76 - ETA: 3:43 - loss: 0.8535 - accuracy: 0.76 - ETA: 3:41 - loss: 0.8501 - accuracy: 0.76 - ETA: 3:39 - loss: 0.8567 - accuracy: 0.76 - ETA: 3:38 - loss: 0.8636 - accuracy: 0.76 - ETA: 3:36 - loss: 0.8648 - accuracy: 0.76 - ETA: 3:34 - loss: 0.8596 - accuracy: 0.76 - ETA: 3:32 - loss: 0.8576 - accuracy: 0.76 - ETA: 3:30 - loss: 0.8514 - accuracy: 0.76 - ETA: 3:29 - loss: 0.8487 - accuracy: 0.77 - ETA: 3:27 - loss: 0.8423 - accuracy: 0.77 - ETA: 3:25 - loss: 0.8494 - accuracy: 0.77 - ETA: 3:23 - loss: 0.8489 - accuracy: 0.77 - ETA: 3:21 - loss: 0.8460 - accuracy: 0.77 - ETA: 3:19 - loss: 0.8420 - accuracy: 0.77 - ETA: 3:17 - loss: 0.8454 - accuracy: 0.77 - ETA: 3:15 - loss: 0.8436 - accuracy: 0.77 - ETA: 3:13 - loss: 0.8463 - accuracy: 0.77 - ETA: 3:12 - loss: 0.8432 - accuracy: 0.77 - ETA: 3:10 - loss: 0.8466 - accuracy: 0.77 - ETA: 3:08 - loss: 0.8423 - accuracy: 0.77 - ETA: 3:06 - loss: 0.8441 - accuracy: 0.77 - ETA: 3:04 - loss: 0.8407 - accuracy: 0.77 - ETA: 3:02 - loss: 0.8467 - accuracy: 0.77 - ETA: 3:00 - loss: 0.8459 - accuracy: 0.77 - ETA: 2:58 - loss: 0.8515 - accuracy: 0.76 - ETA: 2:56 - loss: 0.8495 - accuracy: 0.77 - ETA: 2:55 - loss: 0.8478 - accuracy: 0.77 - ETA: 2:53 - loss: 0.8498 - accuracy: 0.76 - ETA: 2:51 - loss: 0.8477 - accuracy: 0.76 - ETA: 2:49 - loss: 0.8498 - accuracy: 0.76 - ETA: 2:47 - loss: 0.8511 - accuracy: 0.76 - ETA: 2:45 - loss: 0.8515 - accuracy: 0.76 - ETA: 2:43 - loss: 0.8510 - accuracy: 0.76 - ETA: 2:42 - loss: 0.8474 - accuracy: 0.76 - ETA: 2:40 - loss: 0.8454 - accuracy: 0.77 - ETA: 2:38 - loss: 0.8446 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8408 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8411 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8404 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8365 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8340 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8317 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8319 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8394 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8409 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8421 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8433 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8450 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8422 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8422 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8441 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8417 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8432 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8430 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8447 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8462 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8479 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8458 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8468 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8495 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8496 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8499 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8511 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8476 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8498 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8469 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8458 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8445 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8437 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8433 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8466 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8469 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8461 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8469 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8506 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8525 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8506 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8520 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8526 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8515 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8513 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8533 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8522 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8512 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8488 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8519 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8514 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8511 - accuracy: 0.77 - ETA: 59s - loss: 0.8486 - accuracy: 0.7709 - ETA: 57s - loss: 0.8509 - accuracy: 0.770 - ETA: 55s - loss: 0.8499 - accuracy: 0.770 - ETA: 53s - loss: 0.8500 - accuracy: 0.770 - ETA: 51s - loss: 0.8487 - accuracy: 0.770 - ETA: 50s - loss: 0.8491 - accuracy: 0.770 - ETA: 48s - loss: 0.8466 - accuracy: 0.771 - ETA: 46s - loss: 0.8491 - accuracy: 0.770 - ETA: 44s - loss: 0.8479 - accuracy: 0.770 - ETA: 42s - loss: 0.8493 - accuracy: 0.770 - ETA: 40s - loss: 0.8483 - accuracy: 0.771 - ETA: 38s - loss: 0.8462 - accuracy: 0.771 - ETA: 37s - loss: 0.8458 - accuracy: 0.770 - ETA: 35s - loss: 0.8446 - accuracy: 0.771 - ETA: 33s - loss: 0.8438 - accuracy: 0.771 - ETA: 31s - loss: 0.8443 - accuracy: 0.770 - ETA: 29s - loss: 0.8424 - accuracy: 0.771 - ETA: 27s - loss: 0.8420 - accuracy: 0.771 - ETA: 25s - loss: 0.8406 - accuracy: 0.771 - ETA: 23s - loss: 0.8423 - accuracy: 0.771 - ETA: 22s - loss: 0.8429 - accuracy: 0.771 - ETA: 20s - loss: 0.8416 - accuracy: 0.771 - ETA: 18s - loss: 0.8405 - accuracy: 0.771 - ETA: 16s - loss: 0.8395 - accuracy: 0.771 - ETA: 14s - loss: 0.8402 - accuracy: 0.771 - ETA: 12s - loss: 0.8398 - accuracy: 0.771 - ETA: 10s - loss: 0.8391 - accuracy: 0.771 - ETA: 9s - loss: 0.8389 - accuracy: 0.771 - ETA: 7s - loss: 0.8384 - accuracy: 0.77 - ETA: 5s - loss: 0.8381 - accuracy: 0.77 - ETA: 3s - loss: 0.8375 - accuracy: 0.77 - ETA: 1s - loss: 0.8376 - accuracy: 0.77 - 307s 16ms/step - loss: 0.8364 - accuracy: 0.7722 - val_loss: 2.0618 - val_accuracy: 0.7260\n",
      "Epoch 70/100\n",
      "19312/19312 [==============================] - ETA: 4:32 - loss: 0.8268 - accuracy: 0.78 - ETA: 4:32 - loss: 0.8566 - accuracy: 0.75 - ETA: 4:34 - loss: 0.8362 - accuracy: 0.76 - ETA: 4:35 - loss: 0.7788 - accuracy: 0.77 - ETA: 4:36 - loss: 0.8016 - accuracy: 0.77 - ETA: 4:32 - loss: 0.8480 - accuracy: 0.77 - ETA: 4:29 - loss: 0.8196 - accuracy: 0.77 - ETA: 4:24 - loss: 0.8052 - accuracy: 0.78 - ETA: 4:20 - loss: 0.7928 - accuracy: 0.78 - ETA: 4:18 - loss: 0.7865 - accuracy: 0.78 - ETA: 4:15 - loss: 0.7821 - accuracy: 0.78 - ETA: 4:14 - loss: 0.7952 - accuracy: 0.77 - ETA: 4:12 - loss: 0.7898 - accuracy: 0.77 - ETA: 4:11 - loss: 0.7948 - accuracy: 0.77 - ETA: 4:09 - loss: 0.8187 - accuracy: 0.77 - ETA: 4:08 - loss: 0.8209 - accuracy: 0.77 - ETA: 4:06 - loss: 0.8578 - accuracy: 0.77 - ETA: 4:05 - loss: 0.8541 - accuracy: 0.77 - ETA: 4:03 - loss: 0.8477 - accuracy: 0.77 - ETA: 4:01 - loss: 0.8433 - accuracy: 0.77 - ETA: 3:59 - loss: 0.8340 - accuracy: 0.77 - ETA: 3:57 - loss: 0.8301 - accuracy: 0.77 - ETA: 3:55 - loss: 0.8397 - accuracy: 0.77 - ETA: 3:53 - loss: 0.8386 - accuracy: 0.77 - ETA: 3:51 - loss: 0.8519 - accuracy: 0.77 - ETA: 3:49 - loss: 0.8542 - accuracy: 0.76 - ETA: 3:47 - loss: 0.8582 - accuracy: 0.76 - ETA: 3:46 - loss: 0.8556 - accuracy: 0.77 - ETA: 3:44 - loss: 0.8576 - accuracy: 0.76 - ETA: 3:42 - loss: 0.8483 - accuracy: 0.77 - ETA: 3:40 - loss: 0.8386 - accuracy: 0.77 - ETA: 3:39 - loss: 0.8327 - accuracy: 0.77 - ETA: 3:37 - loss: 0.8366 - accuracy: 0.77 - ETA: 3:35 - loss: 0.8357 - accuracy: 0.77 - ETA: 3:33 - loss: 0.8248 - accuracy: 0.77 - ETA: 3:31 - loss: 0.8190 - accuracy: 0.77 - ETA: 3:30 - loss: 0.8273 - accuracy: 0.77 - ETA: 3:28 - loss: 0.8193 - accuracy: 0.77 - ETA: 3:26 - loss: 0.8266 - accuracy: 0.77 - ETA: 3:25 - loss: 0.8298 - accuracy: 0.77 - ETA: 3:23 - loss: 0.8332 - accuracy: 0.77 - ETA: 3:21 - loss: 0.8277 - accuracy: 0.77 - ETA: 3:19 - loss: 0.8316 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8336 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8278 - accuracy: 0.77 - ETA: 3:14 - loss: 0.8276 - accuracy: 0.77 - ETA: 3:12 - loss: 0.8257 - accuracy: 0.77 - ETA: 3:10 - loss: 0.8228 - accuracy: 0.77 - ETA: 3:08 - loss: 0.8242 - accuracy: 0.77 - ETA: 3:06 - loss: 0.8214 - accuracy: 0.77 - ETA: 3:04 - loss: 0.8172 - accuracy: 0.77 - ETA: 3:02 - loss: 0.8117 - accuracy: 0.77 - ETA: 3:01 - loss: 0.8134 - accuracy: 0.77 - ETA: 2:59 - loss: 0.8128 - accuracy: 0.77 - ETA: 2:57 - loss: 0.8166 - accuracy: 0.77 - ETA: 2:55 - loss: 0.8191 - accuracy: 0.77 - ETA: 2:53 - loss: 0.8199 - accuracy: 0.77 - ETA: 2:51 - loss: 0.8172 - accuracy: 0.77 - ETA: 2:50 - loss: 0.8146 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8182 - accuracy: 0.77 - ETA: 2:46 - loss: 0.8204 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8203 - accuracy: 0.77 - ETA: 2:42 - loss: 0.8197 - accuracy: 0.76 - ETA: 2:41 - loss: 0.8201 - accuracy: 0.76 - ETA: 2:39 - loss: 0.8192 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8183 - accuracy: 0.76 - ETA: 2:35 - loss: 0.8257 - accuracy: 0.76 - ETA: 2:34 - loss: 0.8329 - accuracy: 0.76 - ETA: 2:32 - loss: 0.8324 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8317 - accuracy: 0.76 - ETA: 2:28 - loss: 0.8288 - accuracy: 0.76 - ETA: 2:26 - loss: 0.8293 - accuracy: 0.76 - ETA: 2:24 - loss: 0.8311 - accuracy: 0.76 - ETA: 2:22 - loss: 0.8286 - accuracy: 0.76 - ETA: 2:20 - loss: 0.8285 - accuracy: 0.76 - ETA: 2:18 - loss: 0.8304 - accuracy: 0.76 - ETA: 2:16 - loss: 0.8280 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8287 - accuracy: 0.76 - ETA: 2:13 - loss: 0.8296 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8297 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8275 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8271 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8275 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8285 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8282 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8280 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8294 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8283 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8315 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8369 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8355 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8358 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8378 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8390 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8412 - accuracy: 0.76 - ETA: 1:41 - loss: 0.8388 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8406 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8382 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8366 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8362 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8349 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8324 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8340 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8336 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8312 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8317 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8291 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8318 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8308 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8338 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8341 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8326 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8367 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8363 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8370 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8348 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8373 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8368 - accuracy: 0.77 - ETA: 59s - loss: 0.8400 - accuracy: 0.7719 - ETA: 57s - loss: 0.8382 - accuracy: 0.772 - ETA: 55s - loss: 0.8362 - accuracy: 0.772 - ETA: 53s - loss: 0.8353 - accuracy: 0.772 - ETA: 51s - loss: 0.8398 - accuracy: 0.772 - ETA: 49s - loss: 0.8393 - accuracy: 0.772 - ETA: 47s - loss: 0.8388 - accuracy: 0.772 - ETA: 46s - loss: 0.8377 - accuracy: 0.772 - ETA: 44s - loss: 0.8361 - accuracy: 0.772 - ETA: 42s - loss: 0.8339 - accuracy: 0.773 - ETA: 40s - loss: 0.8317 - accuracy: 0.773 - ETA: 38s - loss: 0.8312 - accuracy: 0.773 - ETA: 36s - loss: 0.8290 - accuracy: 0.774 - ETA: 35s - loss: 0.8302 - accuracy: 0.773 - ETA: 33s - loss: 0.8301 - accuracy: 0.773 - ETA: 31s - loss: 0.8288 - accuracy: 0.773 - ETA: 29s - loss: 0.8287 - accuracy: 0.773 - ETA: 27s - loss: 0.8287 - accuracy: 0.773 - ETA: 25s - loss: 0.8283 - accuracy: 0.773 - ETA: 23s - loss: 0.8268 - accuracy: 0.773 - ETA: 22s - loss: 0.8281 - accuracy: 0.773 - ETA: 20s - loss: 0.8289 - accuracy: 0.773 - ETA: 18s - loss: 0.8282 - accuracy: 0.773 - ETA: 16s - loss: 0.8303 - accuracy: 0.773 - ETA: 14s - loss: 0.8291 - accuracy: 0.774 - ETA: 12s - loss: 0.8299 - accuracy: 0.773 - ETA: 10s - loss: 0.8370 - accuracy: 0.773 - ETA: 9s - loss: 0.8381 - accuracy: 0.773 - ETA: 7s - loss: 0.8385 - accuracy: 0.77 - ETA: 5s - loss: 0.8372 - accuracy: 0.77 - ETA: 3s - loss: 0.8357 - accuracy: 0.77 - ETA: 1s - loss: 0.8341 - accuracy: 0.77 - 305s 16ms/step - loss: 0.8330 - accuracy: 0.7741 - val_loss: 1.7565 - val_accuracy: 0.7260\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:48 - loss: 0.6052 - accuracy: 0.82 - ETA: 4:40 - loss: 0.6105 - accuracy: 0.82 - ETA: 4:48 - loss: 0.5983 - accuracy: 0.81 - ETA: 4:47 - loss: 0.6366 - accuracy: 0.80 - ETA: 4:44 - loss: 0.6128 - accuracy: 0.81 - ETA: 4:43 - loss: 0.6317 - accuracy: 0.81 - ETA: 4:38 - loss: 0.6690 - accuracy: 0.80 - ETA: 4:38 - loss: 0.7120 - accuracy: 0.79 - ETA: 4:37 - loss: 0.7121 - accuracy: 0.79 - ETA: 4:35 - loss: 0.7186 - accuracy: 0.79 - ETA: 4:33 - loss: 0.7124 - accuracy: 0.79 - ETA: 4:30 - loss: 0.7150 - accuracy: 0.79 - ETA: 4:28 - loss: 0.6972 - accuracy: 0.79 - ETA: 4:25 - loss: 0.6881 - accuracy: 0.80 - ETA: 4:22 - loss: 0.6762 - accuracy: 0.80 - ETA: 4:19 - loss: 0.6805 - accuracy: 0.80 - ETA: 4:16 - loss: 0.6871 - accuracy: 0.80 - ETA: 4:14 - loss: 0.6843 - accuracy: 0.80 - ETA: 4:12 - loss: 0.6856 - accuracy: 0.80 - ETA: 4:11 - loss: 0.7068 - accuracy: 0.79 - ETA: 4:08 - loss: 0.7048 - accuracy: 0.80 - ETA: 4:06 - loss: 0.7145 - accuracy: 0.79 - ETA: 4:03 - loss: 0.7124 - accuracy: 0.79 - ETA: 4:01 - loss: 0.7283 - accuracy: 0.79 - ETA: 3:59 - loss: 0.7310 - accuracy: 0.79 - ETA: 3:56 - loss: 0.7323 - accuracy: 0.79 - ETA: 3:54 - loss: 0.7292 - accuracy: 0.79 - ETA: 3:52 - loss: 0.7344 - accuracy: 0.79 - ETA: 3:50 - loss: 0.7313 - accuracy: 0.79 - ETA: 3:48 - loss: 0.7291 - accuracy: 0.79 - ETA: 3:46 - loss: 0.7291 - accuracy: 0.79 - ETA: 3:45 - loss: 0.7306 - accuracy: 0.79 - ETA: 3:43 - loss: 0.7300 - accuracy: 0.79 - ETA: 3:41 - loss: 0.7254 - accuracy: 0.79 - ETA: 3:40 - loss: 0.7210 - accuracy: 0.79 - ETA: 3:38 - loss: 0.7225 - accuracy: 0.79 - ETA: 3:36 - loss: 0.7230 - accuracy: 0.79 - ETA: 3:34 - loss: 0.7236 - accuracy: 0.79 - ETA: 3:32 - loss: 0.7274 - accuracy: 0.79 - ETA: 3:30 - loss: 0.7240 - accuracy: 0.79 - ETA: 3:28 - loss: 0.7241 - accuracy: 0.79 - ETA: 3:26 - loss: 0.7281 - accuracy: 0.79 - ETA: 3:24 - loss: 0.7246 - accuracy: 0.79 - ETA: 3:22 - loss: 0.7255 - accuracy: 0.79 - ETA: 3:21 - loss: 0.7247 - accuracy: 0.79 - ETA: 3:19 - loss: 0.7224 - accuracy: 0.79 - ETA: 3:17 - loss: 0.7215 - accuracy: 0.79 - ETA: 3:15 - loss: 0.7255 - accuracy: 0.79 - ETA: 3:13 - loss: 0.7253 - accuracy: 0.79 - ETA: 3:11 - loss: 0.7314 - accuracy: 0.79 - ETA: 3:09 - loss: 0.7301 - accuracy: 0.79 - ETA: 3:07 - loss: 0.7336 - accuracy: 0.79 - ETA: 3:05 - loss: 0.7351 - accuracy: 0.79 - ETA: 3:03 - loss: 0.7346 - accuracy: 0.79 - ETA: 3:01 - loss: 0.7366 - accuracy: 0.79 - ETA: 2:59 - loss: 0.7312 - accuracy: 0.79 - ETA: 2:57 - loss: 0.7385 - accuracy: 0.79 - ETA: 2:56 - loss: 0.7368 - accuracy: 0.79 - ETA: 2:54 - loss: 0.7369 - accuracy: 0.79 - ETA: 2:52 - loss: 0.7361 - accuracy: 0.79 - ETA: 2:50 - loss: 0.7338 - accuracy: 0.79 - ETA: 2:48 - loss: 0.7376 - accuracy: 0.79 - ETA: 2:46 - loss: 0.7406 - accuracy: 0.79 - ETA: 2:44 - loss: 0.7468 - accuracy: 0.79 - ETA: 2:42 - loss: 0.7475 - accuracy: 0.79 - ETA: 2:40 - loss: 0.7461 - accuracy: 0.79 - ETA: 2:38 - loss: 0.7447 - accuracy: 0.79 - ETA: 2:36 - loss: 0.7501 - accuracy: 0.79 - ETA: 2:34 - loss: 0.7516 - accuracy: 0.79 - ETA: 2:32 - loss: 0.7489 - accuracy: 0.79 - ETA: 2:30 - loss: 0.7548 - accuracy: 0.79 - ETA: 2:28 - loss: 0.7558 - accuracy: 0.79 - ETA: 2:26 - loss: 0.7557 - accuracy: 0.79 - ETA: 2:24 - loss: 0.7556 - accuracy: 0.79 - ETA: 2:23 - loss: 0.7570 - accuracy: 0.79 - ETA: 2:21 - loss: 0.7576 - accuracy: 0.79 - ETA: 2:19 - loss: 0.7578 - accuracy: 0.79 - ETA: 2:17 - loss: 0.7578 - accuracy: 0.79 - ETA: 2:15 - loss: 0.7577 - accuracy: 0.79 - ETA: 2:13 - loss: 0.7551 - accuracy: 0.79 - ETA: 2:11 - loss: 0.7582 - accuracy: 0.79 - ETA: 2:10 - loss: 0.7584 - accuracy: 0.78 - ETA: 2:08 - loss: 0.7601 - accuracy: 0.78 - ETA: 2:06 - loss: 0.7606 - accuracy: 0.78 - ETA: 2:04 - loss: 0.7613 - accuracy: 0.78 - ETA: 2:02 - loss: 0.7616 - accuracy: 0.78 - ETA: 2:00 - loss: 0.7621 - accuracy: 0.78 - ETA: 1:58 - loss: 0.7611 - accuracy: 0.78 - ETA: 1:56 - loss: 0.7619 - accuracy: 0.78 - ETA: 1:54 - loss: 0.7591 - accuracy: 0.78 - ETA: 1:53 - loss: 0.7581 - accuracy: 0.78 - ETA: 1:51 - loss: 0.7593 - accuracy: 0.78 - ETA: 1:49 - loss: 0.7598 - accuracy: 0.78 - ETA: 1:47 - loss: 0.7611 - accuracy: 0.78 - ETA: 1:45 - loss: 0.7607 - accuracy: 0.78 - ETA: 1:43 - loss: 0.7637 - accuracy: 0.78 - ETA: 1:41 - loss: 0.7661 - accuracy: 0.78 - ETA: 1:39 - loss: 0.7705 - accuracy: 0.78 - ETA: 1:37 - loss: 0.7696 - accuracy: 0.78 - ETA: 1:35 - loss: 0.7688 - accuracy: 0.78 - ETA: 1:34 - loss: 0.7699 - accuracy: 0.78 - ETA: 1:32 - loss: 0.7698 - accuracy: 0.78 - ETA: 1:30 - loss: 0.7702 - accuracy: 0.78 - ETA: 1:28 - loss: 0.7689 - accuracy: 0.78 - ETA: 1:26 - loss: 0.7674 - accuracy: 0.78 - ETA: 1:24 - loss: 0.7732 - accuracy: 0.78 - ETA: 1:22 - loss: 0.7735 - accuracy: 0.78 - ETA: 1:20 - loss: 0.7751 - accuracy: 0.78 - ETA: 1:18 - loss: 0.7790 - accuracy: 0.78 - ETA: 1:16 - loss: 0.7768 - accuracy: 0.78 - ETA: 1:15 - loss: 0.7745 - accuracy: 0.78 - ETA: 1:13 - loss: 0.7765 - accuracy: 0.78 - ETA: 1:11 - loss: 0.7798 - accuracy: 0.78 - ETA: 1:09 - loss: 0.7798 - accuracy: 0.78 - ETA: 1:07 - loss: 0.7808 - accuracy: 0.78 - ETA: 1:05 - loss: 0.7802 - accuracy: 0.78 - ETA: 1:03 - loss: 0.7818 - accuracy: 0.78 - ETA: 1:01 - loss: 0.7844 - accuracy: 0.78 - ETA: 1:00 - loss: 0.7855 - accuracy: 0.78 - ETA: 58s - loss: 0.7875 - accuracy: 0.7827 - ETA: 56s - loss: 0.7897 - accuracy: 0.782 - ETA: 54s - loss: 0.7898 - accuracy: 0.783 - ETA: 52s - loss: 0.7915 - accuracy: 0.782 - ETA: 50s - loss: 0.7938 - accuracy: 0.782 - ETA: 48s - loss: 0.7935 - accuracy: 0.781 - ETA: 46s - loss: 0.7942 - accuracy: 0.781 - ETA: 44s - loss: 0.7959 - accuracy: 0.781 - ETA: 43s - loss: 0.7955 - accuracy: 0.781 - ETA: 41s - loss: 0.7961 - accuracy: 0.781 - ETA: 39s - loss: 0.7953 - accuracy: 0.781 - ETA: 37s - loss: 0.7944 - accuracy: 0.781 - ETA: 35s - loss: 0.7957 - accuracy: 0.781 - ETA: 33s - loss: 0.7941 - accuracy: 0.781 - ETA: 31s - loss: 0.7950 - accuracy: 0.781 - ETA: 29s - loss: 0.7966 - accuracy: 0.782 - ETA: 27s - loss: 0.7962 - accuracy: 0.782 - ETA: 26s - loss: 0.7977 - accuracy: 0.781 - ETA: 24s - loss: 0.7976 - accuracy: 0.782 - ETA: 22s - loss: 0.7988 - accuracy: 0.781 - ETA: 20s - loss: 0.7983 - accuracy: 0.781 - ETA: 18s - loss: 0.7986 - accuracy: 0.781 - ETA: 16s - loss: 0.7994 - accuracy: 0.781 - ETA: 14s - loss: 0.7973 - accuracy: 0.781 - ETA: 12s - loss: 0.7979 - accuracy: 0.781 - ETA: 11s - loss: 0.8006 - accuracy: 0.781 - ETA: 9s - loss: 0.8007 - accuracy: 0.781 - ETA: 7s - loss: 0.8012 - accuracy: 0.78 - ETA: 5s - loss: 0.8011 - accuracy: 0.78 - ETA: 3s - loss: 0.8003 - accuracy: 0.78 - ETA: 1s - loss: 0.8002 - accuracy: 0.78 - 308s 16ms/step - loss: 0.7997 - accuracy: 0.7816 - val_loss: 1.8069 - val_accuracy: 0.7281\n",
      "Epoch 72/100\n",
      "19312/19312 [==============================] - ETA: 4:54 - loss: 0.9927 - accuracy: 0.73 - ETA: 4:42 - loss: 0.7936 - accuracy: 0.76 - ETA: 4:36 - loss: 0.7296 - accuracy: 0.77 - ETA: 4:36 - loss: 0.7234 - accuracy: 0.77 - ETA: 4:33 - loss: 0.7059 - accuracy: 0.78 - ETA: 4:27 - loss: 0.7225 - accuracy: 0.77 - ETA: 4:25 - loss: 0.7120 - accuracy: 0.78 - ETA: 4:24 - loss: 0.7423 - accuracy: 0.77 - ETA: 4:21 - loss: 0.7367 - accuracy: 0.78 - ETA: 4:20 - loss: 0.7344 - accuracy: 0.78 - ETA: 4:18 - loss: 0.7321 - accuracy: 0.78 - ETA: 4:17 - loss: 0.7345 - accuracy: 0.78 - ETA: 4:15 - loss: 0.7536 - accuracy: 0.78 - ETA: 4:14 - loss: 0.7536 - accuracy: 0.78 - ETA: 4:13 - loss: 0.7459 - accuracy: 0.78 - ETA: 4:11 - loss: 0.7531 - accuracy: 0.78 - ETA: 4:10 - loss: 0.7416 - accuracy: 0.78 - ETA: 4:08 - loss: 0.7532 - accuracy: 0.78 - ETA: 4:07 - loss: 0.7605 - accuracy: 0.78 - ETA: 4:05 - loss: 0.7754 - accuracy: 0.78 - ETA: 4:03 - loss: 0.7769 - accuracy: 0.77 - ETA: 4:01 - loss: 0.7741 - accuracy: 0.77 - ETA: 3:58 - loss: 0.7612 - accuracy: 0.78 - ETA: 3:56 - loss: 0.7619 - accuracy: 0.78 - ETA: 3:55 - loss: 0.7563 - accuracy: 0.78 - ETA: 3:54 - loss: 0.7544 - accuracy: 0.78 - ETA: 3:52 - loss: 0.7477 - accuracy: 0.78 - ETA: 3:50 - loss: 0.7445 - accuracy: 0.78 - ETA: 3:48 - loss: 0.7507 - accuracy: 0.78 - ETA: 3:46 - loss: 0.7438 - accuracy: 0.78 - ETA: 3:44 - loss: 0.7500 - accuracy: 0.78 - ETA: 3:42 - loss: 0.7480 - accuracy: 0.78 - ETA: 3:40 - loss: 0.7551 - accuracy: 0.78 - ETA: 3:38 - loss: 0.7578 - accuracy: 0.78 - ETA: 3:36 - loss: 0.7528 - accuracy: 0.78 - ETA: 3:34 - loss: 0.7520 - accuracy: 0.78 - ETA: 3:32 - loss: 0.7551 - accuracy: 0.78 - ETA: 3:30 - loss: 0.7621 - accuracy: 0.78 - ETA: 3:28 - loss: 0.7717 - accuracy: 0.77 - ETA: 3:26 - loss: 0.7736 - accuracy: 0.77 - ETA: 3:24 - loss: 0.7784 - accuracy: 0.77 - ETA: 3:22 - loss: 0.7807 - accuracy: 0.77 - ETA: 3:20 - loss: 0.7753 - accuracy: 0.78 - ETA: 3:18 - loss: 0.7759 - accuracy: 0.78 - ETA: 3:16 - loss: 0.7758 - accuracy: 0.78 - ETA: 3:15 - loss: 0.7820 - accuracy: 0.78 - ETA: 3:13 - loss: 0.7879 - accuracy: 0.78 - ETA: 3:11 - loss: 0.7866 - accuracy: 0.77 - ETA: 3:09 - loss: 0.7874 - accuracy: 0.77 - ETA: 3:07 - loss: 0.7873 - accuracy: 0.77 - ETA: 3:06 - loss: 0.7912 - accuracy: 0.77 - ETA: 3:04 - loss: 0.7920 - accuracy: 0.77 - ETA: 3:02 - loss: 0.7875 - accuracy: 0.77 - ETA: 3:00 - loss: 0.7903 - accuracy: 0.77 - ETA: 2:58 - loss: 0.7908 - accuracy: 0.77 - ETA: 2:56 - loss: 0.7965 - accuracy: 0.77 - ETA: 2:55 - loss: 0.7954 - accuracy: 0.77 - ETA: 2:53 - loss: 0.7974 - accuracy: 0.77 - ETA: 2:51 - loss: 0.7988 - accuracy: 0.77 - ETA: 2:49 - loss: 0.7937 - accuracy: 0.77 - ETA: 2:47 - loss: 0.7966 - accuracy: 0.77 - ETA: 2:45 - loss: 0.7938 - accuracy: 0.77 - ETA: 2:43 - loss: 0.7956 - accuracy: 0.77 - ETA: 2:41 - loss: 0.7931 - accuracy: 0.77 - ETA: 2:39 - loss: 0.7893 - accuracy: 0.77 - ETA: 2:37 - loss: 0.7887 - accuracy: 0.77 - ETA: 2:36 - loss: 0.7896 - accuracy: 0.77 - ETA: 2:34 - loss: 0.7858 - accuracy: 0.77 - ETA: 2:32 - loss: 0.7868 - accuracy: 0.77 - ETA: 2:30 - loss: 0.7873 - accuracy: 0.77 - ETA: 2:28 - loss: 0.7860 - accuracy: 0.77 - ETA: 2:26 - loss: 0.7837 - accuracy: 0.77 - ETA: 2:24 - loss: 0.7825 - accuracy: 0.77 - ETA: 2:23 - loss: 0.7884 - accuracy: 0.77 - ETA: 2:21 - loss: 0.7879 - accuracy: 0.77 - ETA: 2:19 - loss: 0.7866 - accuracy: 0.77 - ETA: 2:17 - loss: 0.7845 - accuracy: 0.77 - ETA: 2:15 - loss: 0.7826 - accuracy: 0.77 - ETA: 2:14 - loss: 0.7818 - accuracy: 0.77 - ETA: 2:12 - loss: 0.7803 - accuracy: 0.77 - ETA: 2:10 - loss: 0.7831 - accuracy: 0.77 - ETA: 2:08 - loss: 0.7825 - accuracy: 0.77 - ETA: 2:06 - loss: 0.7831 - accuracy: 0.77 - ETA: 2:04 - loss: 0.7821 - accuracy: 0.77 - ETA: 2:02 - loss: 0.7856 - accuracy: 0.77 - ETA: 2:01 - loss: 0.7853 - accuracy: 0.77 - ETA: 1:59 - loss: 0.7857 - accuracy: 0.77 - ETA: 1:57 - loss: 0.7850 - accuracy: 0.77 - ETA: 1:55 - loss: 0.7845 - accuracy: 0.77 - ETA: 1:53 - loss: 0.7872 - accuracy: 0.77 - ETA: 1:51 - loss: 0.7863 - accuracy: 0.77 - ETA: 1:50 - loss: 0.7876 - accuracy: 0.77 - ETA: 1:48 - loss: 0.7873 - accuracy: 0.77 - ETA: 1:46 - loss: 0.7870 - accuracy: 0.77 - ETA: 1:44 - loss: 0.7850 - accuracy: 0.77 - ETA: 1:42 - loss: 0.7834 - accuracy: 0.77 - ETA: 1:40 - loss: 0.7833 - accuracy: 0.77 - ETA: 1:39 - loss: 0.7838 - accuracy: 0.77 - ETA: 1:37 - loss: 0.7832 - accuracy: 0.77 - ETA: 1:35 - loss: 0.7827 - accuracy: 0.77 - ETA: 1:33 - loss: 0.7844 - accuracy: 0.77 - ETA: 1:31 - loss: 0.7870 - accuracy: 0.77 - ETA: 1:29 - loss: 0.7865 - accuracy: 0.77 - ETA: 1:27 - loss: 0.7847 - accuracy: 0.77 - ETA: 1:25 - loss: 0.7813 - accuracy: 0.77 - ETA: 1:23 - loss: 0.7828 - accuracy: 0.77 - ETA: 1:21 - loss: 0.7835 - accuracy: 0.77 - ETA: 1:20 - loss: 0.7806 - accuracy: 0.77 - ETA: 1:18 - loss: 0.7812 - accuracy: 0.77 - ETA: 1:16 - loss: 0.7811 - accuracy: 0.77 - ETA: 1:14 - loss: 0.7804 - accuracy: 0.77 - ETA: 1:12 - loss: 0.7807 - accuracy: 0.77 - ETA: 1:10 - loss: 0.7797 - accuracy: 0.77 - ETA: 1:08 - loss: 0.7825 - accuracy: 0.77 - ETA: 1:06 - loss: 0.7839 - accuracy: 0.77 - ETA: 1:05 - loss: 0.7827 - accuracy: 0.77 - ETA: 1:03 - loss: 0.7806 - accuracy: 0.77 - ETA: 1:01 - loss: 0.7859 - accuracy: 0.77 - ETA: 59s - loss: 0.7844 - accuracy: 0.7785 - ETA: 57s - loss: 0.7833 - accuracy: 0.778 - ETA: 55s - loss: 0.7870 - accuracy: 0.778 - ETA: 53s - loss: 0.7851 - accuracy: 0.778 - ETA: 52s - loss: 0.7869 - accuracy: 0.778 - ETA: 50s - loss: 0.7880 - accuracy: 0.778 - ETA: 48s - loss: 0.7907 - accuracy: 0.778 - ETA: 46s - loss: 0.7908 - accuracy: 0.778 - ETA: 44s - loss: 0.7896 - accuracy: 0.778 - ETA: 42s - loss: 0.7888 - accuracy: 0.778 - ETA: 40s - loss: 0.7909 - accuracy: 0.778 - ETA: 38s - loss: 0.7918 - accuracy: 0.777 - ETA: 37s - loss: 0.7900 - accuracy: 0.778 - ETA: 35s - loss: 0.7897 - accuracy: 0.778 - ETA: 33s - loss: 0.7902 - accuracy: 0.778 - ETA: 31s - loss: 0.7920 - accuracy: 0.778 - ETA: 29s - loss: 0.7949 - accuracy: 0.777 - ETA: 27s - loss: 0.7953 - accuracy: 0.777 - ETA: 25s - loss: 0.7952 - accuracy: 0.777 - ETA: 24s - loss: 0.7963 - accuracy: 0.777 - ETA: 22s - loss: 0.7961 - accuracy: 0.777 - ETA: 20s - loss: 0.7990 - accuracy: 0.776 - ETA: 18s - loss: 0.7990 - accuracy: 0.776 - ETA: 16s - loss: 0.8003 - accuracy: 0.776 - ETA: 14s - loss: 0.7999 - accuracy: 0.776 - ETA: 12s - loss: 0.8008 - accuracy: 0.775 - ETA: 10s - loss: 0.7998 - accuracy: 0.776 - ETA: 9s - loss: 0.7981 - accuracy: 0.776 - ETA: 7s - loss: 0.7966 - accuracy: 0.77 - ETA: 5s - loss: 0.7982 - accuracy: 0.77 - ETA: 3s - loss: 0.7980 - accuracy: 0.77 - ETA: 1s - loss: 0.7990 - accuracy: 0.77 - 307s 16ms/step - loss: 0.8038 - accuracy: 0.7759 - val_loss: 1.8987 - val_accuracy: 0.7242\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:27 - loss: 0.6635 - accuracy: 0.82 - ETA: 4:32 - loss: 0.7225 - accuracy: 0.79 - ETA: 4:26 - loss: 0.6702 - accuracy: 0.79 - ETA: 4:29 - loss: 0.6922 - accuracy: 0.80 - ETA: 4:28 - loss: 0.8344 - accuracy: 0.80 - ETA: 4:29 - loss: 0.8713 - accuracy: 0.79 - ETA: 4:27 - loss: 0.8171 - accuracy: 0.80 - ETA: 4:24 - loss: 0.8298 - accuracy: 0.80 - ETA: 4:22 - loss: 0.8241 - accuracy: 0.80 - ETA: 4:21 - loss: 0.8118 - accuracy: 0.80 - ETA: 4:19 - loss: 0.8102 - accuracy: 0.80 - ETA: 4:18 - loss: 0.7986 - accuracy: 0.80 - ETA: 4:14 - loss: 0.7837 - accuracy: 0.79 - ETA: 4:13 - loss: 0.7935 - accuracy: 0.79 - ETA: 4:11 - loss: 0.8231 - accuracy: 0.79 - ETA: 4:09 - loss: 0.8135 - accuracy: 0.79 - ETA: 4:07 - loss: 0.8084 - accuracy: 0.79 - ETA: 4:07 - loss: 0.7986 - accuracy: 0.79 - ETA: 4:05 - loss: 0.8029 - accuracy: 0.78 - ETA: 4:03 - loss: 0.8029 - accuracy: 0.78 - ETA: 4:00 - loss: 0.7973 - accuracy: 0.78 - ETA: 3:58 - loss: 0.7953 - accuracy: 0.78 - ETA: 3:56 - loss: 0.8067 - accuracy: 0.78 - ETA: 3:54 - loss: 0.8039 - accuracy: 0.78 - ETA: 3:53 - loss: 0.8086 - accuracy: 0.78 - ETA: 3:51 - loss: 0.7991 - accuracy: 0.78 - ETA: 3:49 - loss: 0.7956 - accuracy: 0.78 - ETA: 3:47 - loss: 0.7967 - accuracy: 0.78 - ETA: 3:45 - loss: 0.7966 - accuracy: 0.78 - ETA: 3:43 - loss: 0.7879 - accuracy: 0.78 - ETA: 3:41 - loss: 0.7976 - accuracy: 0.78 - ETA: 3:39 - loss: 0.7969 - accuracy: 0.78 - ETA: 3:37 - loss: 0.8000 - accuracy: 0.78 - ETA: 3:35 - loss: 0.7946 - accuracy: 0.78 - ETA: 3:33 - loss: 0.7898 - accuracy: 0.78 - ETA: 3:31 - loss: 0.7934 - accuracy: 0.78 - ETA: 3:29 - loss: 0.7922 - accuracy: 0.78 - ETA: 3:28 - loss: 0.7960 - accuracy: 0.78 - ETA: 3:26 - loss: 0.7962 - accuracy: 0.78 - ETA: 3:24 - loss: 0.7949 - accuracy: 0.78 - ETA: 3:23 - loss: 0.8040 - accuracy: 0.78 - ETA: 3:21 - loss: 0.8016 - accuracy: 0.78 - ETA: 3:19 - loss: 0.8081 - accuracy: 0.78 - ETA: 3:18 - loss: 0.8112 - accuracy: 0.78 - ETA: 3:16 - loss: 0.8089 - accuracy: 0.78 - ETA: 3:14 - loss: 0.8110 - accuracy: 0.78 - ETA: 3:12 - loss: 0.8145 - accuracy: 0.78 - ETA: 3:10 - loss: 0.8156 - accuracy: 0.78 - ETA: 3:09 - loss: 0.8157 - accuracy: 0.78 - ETA: 3:07 - loss: 0.8181 - accuracy: 0.78 - ETA: 3:05 - loss: 0.8172 - accuracy: 0.78 - ETA: 3:03 - loss: 0.8133 - accuracy: 0.78 - ETA: 3:01 - loss: 0.8158 - accuracy: 0.78 - ETA: 2:59 - loss: 0.8172 - accuracy: 0.77 - ETA: 2:57 - loss: 0.8184 - accuracy: 0.77 - ETA: 2:56 - loss: 0.8115 - accuracy: 0.78 - ETA: 2:54 - loss: 0.8125 - accuracy: 0.78 - ETA: 2:52 - loss: 0.8125 - accuracy: 0.78 - ETA: 2:50 - loss: 0.8105 - accuracy: 0.78 - ETA: 2:48 - loss: 0.8131 - accuracy: 0.78 - ETA: 2:47 - loss: 0.8109 - accuracy: 0.78 - ETA: 2:45 - loss: 0.8101 - accuracy: 0.78 - ETA: 2:43 - loss: 0.8126 - accuracy: 0.78 - ETA: 2:41 - loss: 0.8144 - accuracy: 0.78 - ETA: 2:39 - loss: 0.8142 - accuracy: 0.78 - ETA: 2:38 - loss: 0.8174 - accuracy: 0.78 - ETA: 2:36 - loss: 0.8140 - accuracy: 0.78 - ETA: 2:34 - loss: 0.8123 - accuracy: 0.78 - ETA: 2:32 - loss: 0.8171 - accuracy: 0.78 - ETA: 2:30 - loss: 0.8180 - accuracy: 0.78 - ETA: 2:29 - loss: 0.8215 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8179 - accuracy: 0.78 - ETA: 2:25 - loss: 0.8195 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8186 - accuracy: 0.78 - ETA: 2:21 - loss: 0.8216 - accuracy: 0.78 - ETA: 2:20 - loss: 0.8204 - accuracy: 0.78 - ETA: 2:18 - loss: 0.8262 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8252 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8246 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8274 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8261 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8256 - accuracy: 0.78 - ETA: 2:06 - loss: 0.8232 - accuracy: 0.78 - ETA: 2:04 - loss: 0.8212 - accuracy: 0.78 - ETA: 2:03 - loss: 0.8224 - accuracy: 0.78 - ETA: 2:01 - loss: 0.8239 - accuracy: 0.78 - ETA: 1:59 - loss: 0.8239 - accuracy: 0.78 - ETA: 1:57 - loss: 0.8241 - accuracy: 0.78 - ETA: 1:55 - loss: 0.8255 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8240 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8244 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8225 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8238 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8230 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8227 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8236 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8217 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8216 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8214 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8221 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8234 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8239 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8249 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8276 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8271 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8263 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8312 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8288 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8288 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8289 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8280 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8273 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8281 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8273 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8264 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8273 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8268 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8256 - accuracy: 0.77 - ETA: 59s - loss: 0.8235 - accuracy: 0.7786 - ETA: 57s - loss: 0.8234 - accuracy: 0.778 - ETA: 55s - loss: 0.8204 - accuracy: 0.779 - ETA: 54s - loss: 0.8179 - accuracy: 0.779 - ETA: 52s - loss: 0.8189 - accuracy: 0.779 - ETA: 50s - loss: 0.8187 - accuracy: 0.779 - ETA: 48s - loss: 0.8197 - accuracy: 0.778 - ETA: 46s - loss: 0.8189 - accuracy: 0.778 - ETA: 44s - loss: 0.8169 - accuracy: 0.779 - ETA: 42s - loss: 0.8184 - accuracy: 0.779 - ETA: 40s - loss: 0.8188 - accuracy: 0.778 - ETA: 39s - loss: 0.8231 - accuracy: 0.778 - ETA: 37s - loss: 0.8231 - accuracy: 0.778 - ETA: 35s - loss: 0.8231 - accuracy: 0.777 - ETA: 33s - loss: 0.8234 - accuracy: 0.777 - ETA: 31s - loss: 0.8217 - accuracy: 0.777 - ETA: 29s - loss: 0.8215 - accuracy: 0.777 - ETA: 27s - loss: 0.8205 - accuracy: 0.778 - ETA: 25s - loss: 0.8211 - accuracy: 0.777 - ETA: 24s - loss: 0.8212 - accuracy: 0.777 - ETA: 22s - loss: 0.8199 - accuracy: 0.777 - ETA: 20s - loss: 0.8194 - accuracy: 0.777 - ETA: 18s - loss: 0.8191 - accuracy: 0.777 - ETA: 16s - loss: 0.8191 - accuracy: 0.777 - ETA: 14s - loss: 0.8171 - accuracy: 0.778 - ETA: 12s - loss: 0.8164 - accuracy: 0.777 - ETA: 10s - loss: 0.8163 - accuracy: 0.777 - ETA: 9s - loss: 0.8163 - accuracy: 0.777 - ETA: 7s - loss: 0.8174 - accuracy: 0.77 - ETA: 5s - loss: 0.8162 - accuracy: 0.77 - ETA: 3s - loss: 0.8172 - accuracy: 0.77 - ETA: 1s - loss: 0.8169 - accuracy: 0.77 - 308s 16ms/step - loss: 0.8165 - accuracy: 0.7776 - val_loss: 1.9873 - val_accuracy: 0.7318\n",
      "Epoch 74/100\n",
      "19312/19312 [==============================] - ETA: 4:36 - loss: 0.5028 - accuracy: 0.82 - ETA: 5:24 - loss: 0.5642 - accuracy: 0.82 - ETA: 5:09 - loss: 0.6100 - accuracy: 0.80 - ETA: 4:58 - loss: 0.6306 - accuracy: 0.79 - ETA: 4:53 - loss: 0.6535 - accuracy: 0.79 - ETA: 4:46 - loss: 0.6749 - accuracy: 0.79 - ETA: 4:46 - loss: 0.7120 - accuracy: 0.79 - ETA: 4:40 - loss: 0.7218 - accuracy: 0.79 - ETA: 4:34 - loss: 0.7762 - accuracy: 0.79 - ETA: 4:31 - loss: 0.7955 - accuracy: 0.78 - ETA: 4:29 - loss: 0.8190 - accuracy: 0.78 - ETA: 4:27 - loss: 0.8327 - accuracy: 0.78 - ETA: 4:24 - loss: 0.8258 - accuracy: 0.78 - ETA: 4:23 - loss: 0.8474 - accuracy: 0.78 - ETA: 4:21 - loss: 0.8365 - accuracy: 0.78 - ETA: 4:19 - loss: 0.8278 - accuracy: 0.78 - ETA: 4:16 - loss: 0.8245 - accuracy: 0.78 - ETA: 4:13 - loss: 0.8448 - accuracy: 0.78 - ETA: 4:12 - loss: 0.8524 - accuracy: 0.78 - ETA: 4:10 - loss: 0.8390 - accuracy: 0.78 - ETA: 4:07 - loss: 0.8273 - accuracy: 0.79 - ETA: 4:04 - loss: 0.8259 - accuracy: 0.78 - ETA: 4:01 - loss: 0.8189 - accuracy: 0.78 - ETA: 3:59 - loss: 0.8043 - accuracy: 0.79 - ETA: 3:56 - loss: 0.7960 - accuracy: 0.79 - ETA: 3:53 - loss: 0.7897 - accuracy: 0.79 - ETA: 3:49 - loss: 0.8067 - accuracy: 0.79 - ETA: 3:47 - loss: 0.8224 - accuracy: 0.78 - ETA: 3:46 - loss: 0.8120 - accuracy: 0.79 - ETA: 3:44 - loss: 0.8102 - accuracy: 0.79 - ETA: 3:41 - loss: 0.8049 - accuracy: 0.78 - ETA: 3:39 - loss: 0.8033 - accuracy: 0.78 - ETA: 3:37 - loss: 0.8002 - accuracy: 0.79 - ETA: 3:36 - loss: 0.8002 - accuracy: 0.78 - ETA: 3:33 - loss: 0.8007 - accuracy: 0.78 - ETA: 3:31 - loss: 0.7980 - accuracy: 0.78 - ETA: 3:29 - loss: 0.8087 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8033 - accuracy: 0.78 - ETA: 3:26 - loss: 0.8049 - accuracy: 0.78 - ETA: 3:24 - loss: 0.8018 - accuracy: 0.78 - ETA: 3:23 - loss: 0.8028 - accuracy: 0.78 - ETA: 3:21 - loss: 0.8067 - accuracy: 0.78 - ETA: 3:19 - loss: 0.8095 - accuracy: 0.78 - ETA: 3:17 - loss: 0.8112 - accuracy: 0.78 - ETA: 3:15 - loss: 0.8134 - accuracy: 0.78 - ETA: 3:14 - loss: 0.8195 - accuracy: 0.78 - ETA: 3:12 - loss: 0.8230 - accuracy: 0.78 - ETA: 3:10 - loss: 0.8188 - accuracy: 0.78 - ETA: 3:08 - loss: 0.8141 - accuracy: 0.78 - ETA: 3:06 - loss: 0.8098 - accuracy: 0.78 - ETA: 3:04 - loss: 0.8112 - accuracy: 0.78 - ETA: 3:02 - loss: 0.8062 - accuracy: 0.78 - ETA: 3:00 - loss: 0.8089 - accuracy: 0.78 - ETA: 2:58 - loss: 0.8069 - accuracy: 0.78 - ETA: 2:57 - loss: 0.8088 - accuracy: 0.78 - ETA: 2:55 - loss: 0.8101 - accuracy: 0.78 - ETA: 2:53 - loss: 0.8112 - accuracy: 0.78 - ETA: 2:51 - loss: 0.8069 - accuracy: 0.78 - ETA: 2:49 - loss: 0.8104 - accuracy: 0.78 - ETA: 2:47 - loss: 0.8092 - accuracy: 0.78 - ETA: 2:45 - loss: 0.8098 - accuracy: 0.78 - ETA: 2:43 - loss: 0.8103 - accuracy: 0.78 - ETA: 2:42 - loss: 0.8122 - accuracy: 0.78 - ETA: 2:40 - loss: 0.8070 - accuracy: 0.78 - ETA: 2:38 - loss: 0.8054 - accuracy: 0.78 - ETA: 2:36 - loss: 0.8066 - accuracy: 0.78 - ETA: 2:34 - loss: 0.8097 - accuracy: 0.78 - ETA: 2:33 - loss: 0.8088 - accuracy: 0.78 - ETA: 2:31 - loss: 0.8110 - accuracy: 0.78 - ETA: 2:29 - loss: 0.8071 - accuracy: 0.78 - ETA: 2:27 - loss: 0.8081 - accuracy: 0.78 - ETA: 2:25 - loss: 0.8093 - accuracy: 0.78 - ETA: 2:23 - loss: 0.8139 - accuracy: 0.78 - ETA: 2:22 - loss: 0.8100 - accuracy: 0.78 - ETA: 2:20 - loss: 0.8079 - accuracy: 0.78 - ETA: 2:18 - loss: 0.8084 - accuracy: 0.78 - ETA: 2:16 - loss: 0.8128 - accuracy: 0.78 - ETA: 2:14 - loss: 0.8128 - accuracy: 0.78 - ETA: 2:12 - loss: 0.8091 - accuracy: 0.78 - ETA: 2:11 - loss: 0.8098 - accuracy: 0.78 - ETA: 2:09 - loss: 0.8126 - accuracy: 0.78 - ETA: 2:07 - loss: 0.8115 - accuracy: 0.78 - ETA: 2:05 - loss: 0.8098 - accuracy: 0.78 - ETA: 2:03 - loss: 0.8168 - accuracy: 0.78 - ETA: 2:02 - loss: 0.8178 - accuracy: 0.78 - ETA: 2:00 - loss: 0.8196 - accuracy: 0.78 - ETA: 1:58 - loss: 0.8183 - accuracy: 0.78 - ETA: 1:56 - loss: 0.8163 - accuracy: 0.78 - ETA: 1:54 - loss: 0.8160 - accuracy: 0.78 - ETA: 1:53 - loss: 0.8205 - accuracy: 0.78 - ETA: 1:51 - loss: 0.8196 - accuracy: 0.78 - ETA: 1:49 - loss: 0.8209 - accuracy: 0.78 - ETA: 1:47 - loss: 0.8237 - accuracy: 0.78 - ETA: 1:45 - loss: 0.8237 - accuracy: 0.78 - ETA: 1:43 - loss: 0.8252 - accuracy: 0.78 - ETA: 1:41 - loss: 0.8247 - accuracy: 0.78 - ETA: 1:40 - loss: 0.8255 - accuracy: 0.78 - ETA: 1:38 - loss: 0.8259 - accuracy: 0.78 - ETA: 1:36 - loss: 0.8247 - accuracy: 0.78 - ETA: 1:34 - loss: 0.8254 - accuracy: 0.78 - ETA: 1:32 - loss: 0.8270 - accuracy: 0.78 - ETA: 1:30 - loss: 0.8259 - accuracy: 0.78 - ETA: 1:28 - loss: 0.8272 - accuracy: 0.78 - ETA: 1:27 - loss: 0.8289 - accuracy: 0.78 - ETA: 1:25 - loss: 0.8267 - accuracy: 0.78 - ETA: 1:23 - loss: 0.8260 - accuracy: 0.78 - ETA: 1:21 - loss: 0.8254 - accuracy: 0.78 - ETA: 1:19 - loss: 0.8232 - accuracy: 0.78 - ETA: 1:17 - loss: 0.8204 - accuracy: 0.78 - ETA: 1:15 - loss: 0.8185 - accuracy: 0.78 - ETA: 1:14 - loss: 0.8167 - accuracy: 0.78 - ETA: 1:12 - loss: 0.8184 - accuracy: 0.78 - ETA: 1:10 - loss: 0.8184 - accuracy: 0.78 - ETA: 1:08 - loss: 0.8181 - accuracy: 0.78 - ETA: 1:06 - loss: 0.8137 - accuracy: 0.78 - ETA: 1:04 - loss: 0.8171 - accuracy: 0.78 - ETA: 1:02 - loss: 0.8160 - accuracy: 0.78 - ETA: 1:01 - loss: 0.8150 - accuracy: 0.78 - ETA: 59s - loss: 0.8160 - accuracy: 0.7821 - ETA: 57s - loss: 0.8152 - accuracy: 0.781 - ETA: 55s - loss: 0.8161 - accuracy: 0.781 - ETA: 53s - loss: 0.8162 - accuracy: 0.782 - ETA: 51s - loss: 0.8160 - accuracy: 0.781 - ETA: 50s - loss: 0.8153 - accuracy: 0.782 - ETA: 48s - loss: 0.8151 - accuracy: 0.782 - ETA: 46s - loss: 0.8188 - accuracy: 0.782 - ETA: 44s - loss: 0.8183 - accuracy: 0.782 - ETA: 42s - loss: 0.8165 - accuracy: 0.782 - ETA: 40s - loss: 0.8170 - accuracy: 0.781 - ETA: 38s - loss: 0.8166 - accuracy: 0.781 - ETA: 36s - loss: 0.8148 - accuracy: 0.782 - ETA: 35s - loss: 0.8143 - accuracy: 0.782 - ETA: 33s - loss: 0.8138 - accuracy: 0.782 - ETA: 31s - loss: 0.8135 - accuracy: 0.782 - ETA: 29s - loss: 0.8135 - accuracy: 0.781 - ETA: 27s - loss: 0.8132 - accuracy: 0.782 - ETA: 25s - loss: 0.8123 - accuracy: 0.782 - ETA: 23s - loss: 0.8111 - accuracy: 0.782 - ETA: 22s - loss: 0.8119 - accuracy: 0.782 - ETA: 20s - loss: 0.8108 - accuracy: 0.782 - ETA: 18s - loss: 0.8119 - accuracy: 0.782 - ETA: 16s - loss: 0.8115 - accuracy: 0.782 - ETA: 14s - loss: 0.8112 - accuracy: 0.782 - ETA: 12s - loss: 0.8111 - accuracy: 0.782 - ETA: 10s - loss: 0.8109 - accuracy: 0.782 - ETA: 9s - loss: 0.8088 - accuracy: 0.782 - ETA: 7s - loss: 0.8083 - accuracy: 0.78 - ETA: 5s - loss: 0.8078 - accuracy: 0.78 - ETA: 3s - loss: 0.8085 - accuracy: 0.78 - ETA: 1s - loss: 0.8082 - accuracy: 0.78 - 306s 16ms/step - loss: 0.8083 - accuracy: 0.7829 - val_loss: 1.7742 - val_accuracy: 0.7180\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:27 - loss: 0.7658 - accuracy: 0.78 - ETA: 4:41 - loss: 0.9112 - accuracy: 0.73 - ETA: 4:41 - loss: 0.8103 - accuracy: 0.76 - ETA: 4:34 - loss: 0.8044 - accuracy: 0.76 - ETA: 4:33 - loss: 0.8163 - accuracy: 0.77 - ETA: 4:33 - loss: 0.8013 - accuracy: 0.77 - ETA: 4:31 - loss: 0.8194 - accuracy: 0.76 - ETA: 4:29 - loss: 0.8414 - accuracy: 0.76 - ETA: 4:27 - loss: 0.8411 - accuracy: 0.76 - ETA: 4:26 - loss: 0.8380 - accuracy: 0.76 - ETA: 4:24 - loss: 0.8505 - accuracy: 0.76 - ETA: 4:21 - loss: 0.8431 - accuracy: 0.76 - ETA: 4:19 - loss: 0.8268 - accuracy: 0.76 - ETA: 4:17 - loss: 0.8228 - accuracy: 0.76 - ETA: 4:15 - loss: 0.8190 - accuracy: 0.76 - ETA: 4:13 - loss: 0.8155 - accuracy: 0.76 - ETA: 4:11 - loss: 0.8036 - accuracy: 0.76 - ETA: 4:10 - loss: 0.8446 - accuracy: 0.76 - ETA: 4:08 - loss: 0.8592 - accuracy: 0.76 - ETA: 4:06 - loss: 0.8532 - accuracy: 0.76 - ETA: 4:04 - loss: 0.8384 - accuracy: 0.76 - ETA: 4:02 - loss: 0.8267 - accuracy: 0.76 - ETA: 4:00 - loss: 0.8169 - accuracy: 0.77 - ETA: 3:59 - loss: 0.8162 - accuracy: 0.77 - ETA: 3:57 - loss: 0.8028 - accuracy: 0.77 - ETA: 3:55 - loss: 0.8076 - accuracy: 0.77 - ETA: 3:52 - loss: 0.8061 - accuracy: 0.77 - ETA: 3:50 - loss: 0.8041 - accuracy: 0.77 - ETA: 3:48 - loss: 0.8111 - accuracy: 0.76 - ETA: 3:46 - loss: 0.8101 - accuracy: 0.77 - ETA: 3:45 - loss: 0.8026 - accuracy: 0.77 - ETA: 3:43 - loss: 0.7992 - accuracy: 0.77 - ETA: 3:41 - loss: 0.8014 - accuracy: 0.77 - ETA: 3:39 - loss: 0.8066 - accuracy: 0.77 - ETA: 3:37 - loss: 0.8116 - accuracy: 0.77 - ETA: 3:36 - loss: 0.8094 - accuracy: 0.77 - ETA: 3:34 - loss: 0.8120 - accuracy: 0.77 - ETA: 3:32 - loss: 0.8120 - accuracy: 0.77 - ETA: 3:30 - loss: 0.8143 - accuracy: 0.77 - ETA: 3:28 - loss: 0.8126 - accuracy: 0.77 - ETA: 3:26 - loss: 0.8068 - accuracy: 0.77 - ETA: 3:24 - loss: 0.8074 - accuracy: 0.77 - ETA: 3:22 - loss: 0.8102 - accuracy: 0.77 - ETA: 3:20 - loss: 0.8116 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8205 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8168 - accuracy: 0.77 - ETA: 3:14 - loss: 0.8146 - accuracy: 0.77 - ETA: 3:12 - loss: 0.8200 - accuracy: 0.77 - ETA: 3:11 - loss: 0.8168 - accuracy: 0.77 - ETA: 3:09 - loss: 0.8145 - accuracy: 0.77 - ETA: 3:07 - loss: 0.8126 - accuracy: 0.77 - ETA: 3:05 - loss: 0.8080 - accuracy: 0.77 - ETA: 3:03 - loss: 0.8154 - accuracy: 0.77 - ETA: 3:01 - loss: 0.8141 - accuracy: 0.77 - ETA: 2:59 - loss: 0.8141 - accuracy: 0.77 - ETA: 2:58 - loss: 0.8116 - accuracy: 0.77 - ETA: 2:56 - loss: 0.8103 - accuracy: 0.77 - ETA: 2:54 - loss: 0.8095 - accuracy: 0.77 - ETA: 2:52 - loss: 0.8063 - accuracy: 0.77 - ETA: 2:50 - loss: 0.8078 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8083 - accuracy: 0.77 - ETA: 2:46 - loss: 0.8063 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8076 - accuracy: 0.77 - ETA: 2:42 - loss: 0.8250 - accuracy: 0.77 - ETA: 2:40 - loss: 0.8204 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8196 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8201 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8219 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8246 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8211 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8222 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8195 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8162 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8108 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8152 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8127 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8136 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8113 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8090 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8092 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8081 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8089 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8102 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8093 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8067 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8072 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8057 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8058 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8056 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8080 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8106 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8112 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8164 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8163 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8153 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8146 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8134 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8118 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8114 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8109 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8081 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8063 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8092 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8107 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8086 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8095 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8069 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8044 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8046 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8084 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8093 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8082 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8060 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8070 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8081 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8108 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8109 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8106 - accuracy: 0.77 - ETA: 59s - loss: 0.8088 - accuracy: 0.7776 - ETA: 57s - loss: 0.8070 - accuracy: 0.777 - ETA: 56s - loss: 0.8076 - accuracy: 0.777 - ETA: 54s - loss: 0.8092 - accuracy: 0.777 - ETA: 52s - loss: 0.8088 - accuracy: 0.777 - ETA: 50s - loss: 0.8098 - accuracy: 0.777 - ETA: 48s - loss: 0.8105 - accuracy: 0.777 - ETA: 46s - loss: 0.8098 - accuracy: 0.777 - ETA: 44s - loss: 0.8088 - accuracy: 0.777 - ETA: 42s - loss: 0.8095 - accuracy: 0.777 - ETA: 41s - loss: 0.8100 - accuracy: 0.777 - ETA: 39s - loss: 0.8104 - accuracy: 0.777 - ETA: 37s - loss: 0.8085 - accuracy: 0.777 - ETA: 35s - loss: 0.8085 - accuracy: 0.777 - ETA: 33s - loss: 0.8068 - accuracy: 0.777 - ETA: 31s - loss: 0.8054 - accuracy: 0.777 - ETA: 29s - loss: 0.8067 - accuracy: 0.777 - ETA: 27s - loss: 0.8076 - accuracy: 0.777 - ETA: 26s - loss: 0.8088 - accuracy: 0.776 - ETA: 24s - loss: 0.8134 - accuracy: 0.776 - ETA: 22s - loss: 0.8143 - accuracy: 0.776 - ETA: 20s - loss: 0.8163 - accuracy: 0.776 - ETA: 18s - loss: 0.8174 - accuracy: 0.776 - ETA: 16s - loss: 0.8155 - accuracy: 0.776 - ETA: 14s - loss: 0.8167 - accuracy: 0.776 - ETA: 12s - loss: 0.8156 - accuracy: 0.777 - ETA: 11s - loss: 0.8166 - accuracy: 0.777 - ETA: 9s - loss: 0.8171 - accuracy: 0.777 - ETA: 7s - loss: 0.8185 - accuracy: 0.77 - ETA: 5s - loss: 0.8183 - accuracy: 0.77 - ETA: 3s - loss: 0.8212 - accuracy: 0.77 - ETA: 1s - loss: 0.8207 - accuracy: 0.77 - 311s 16ms/step - loss: 0.8209 - accuracy: 0.7764 - val_loss: 1.9644 - val_accuracy: 0.7258\n",
      "Epoch 76/100\n",
      "19312/19312 [==============================] - ETA: 4:29 - loss: 0.7119 - accuracy: 0.78 - ETA: 4:35 - loss: 0.7011 - accuracy: 0.79 - ETA: 4:27 - loss: 0.7715 - accuracy: 0.78 - ETA: 4:22 - loss: 0.7893 - accuracy: 0.78 - ETA: 4:22 - loss: 0.7518 - accuracy: 0.79 - ETA: 4:24 - loss: 0.7654 - accuracy: 0.79 - ETA: 4:22 - loss: 0.7726 - accuracy: 0.78 - ETA: 4:22 - loss: 0.7644 - accuracy: 0.79 - ETA: 4:20 - loss: 0.7847 - accuracy: 0.78 - ETA: 4:19 - loss: 0.7831 - accuracy: 0.78 - ETA: 4:17 - loss: 0.7629 - accuracy: 0.78 - ETA: 4:16 - loss: 0.7706 - accuracy: 0.78 - ETA: 4:14 - loss: 0.7886 - accuracy: 0.78 - ETA: 4:12 - loss: 0.7898 - accuracy: 0.78 - ETA: 4:11 - loss: 0.7887 - accuracy: 0.78 - ETA: 4:09 - loss: 0.7834 - accuracy: 0.78 - ETA: 4:07 - loss: 0.7857 - accuracy: 0.78 - ETA: 4:05 - loss: 0.7952 - accuracy: 0.78 - ETA: 4:03 - loss: 0.7989 - accuracy: 0.78 - ETA: 4:02 - loss: 0.7949 - accuracy: 0.78 - ETA: 4:00 - loss: 0.7878 - accuracy: 0.78 - ETA: 3:56 - loss: 0.7860 - accuracy: 0.78 - ETA: 3:55 - loss: 0.7883 - accuracy: 0.78 - ETA: 3:52 - loss: 0.7942 - accuracy: 0.78 - ETA: 3:50 - loss: 0.8074 - accuracy: 0.78 - ETA: 3:49 - loss: 0.8058 - accuracy: 0.78 - ETA: 3:48 - loss: 0.8139 - accuracy: 0.78 - ETA: 3:47 - loss: 0.8021 - accuracy: 0.78 - ETA: 3:45 - loss: 0.8125 - accuracy: 0.78 - ETA: 3:43 - loss: 0.8079 - accuracy: 0.78 - ETA: 3:41 - loss: 0.8094 - accuracy: 0.78 - ETA: 3:40 - loss: 0.8061 - accuracy: 0.78 - ETA: 3:37 - loss: 0.7950 - accuracy: 0.78 - ETA: 3:36 - loss: 0.7973 - accuracy: 0.78 - ETA: 3:34 - loss: 0.7961 - accuracy: 0.78 - ETA: 3:33 - loss: 0.7945 - accuracy: 0.78 - ETA: 3:31 - loss: 0.7885 - accuracy: 0.78 - ETA: 3:29 - loss: 0.7791 - accuracy: 0.78 - ETA: 3:27 - loss: 0.7846 - accuracy: 0.78 - ETA: 3:25 - loss: 0.7861 - accuracy: 0.78 - ETA: 3:24 - loss: 0.7873 - accuracy: 0.78 - ETA: 3:22 - loss: 0.7878 - accuracy: 0.78 - ETA: 3:20 - loss: 0.7826 - accuracy: 0.78 - ETA: 3:18 - loss: 0.7825 - accuracy: 0.78 - ETA: 3:16 - loss: 0.7863 - accuracy: 0.78 - ETA: 3:14 - loss: 0.7894 - accuracy: 0.78 - ETA: 3:12 - loss: 0.7994 - accuracy: 0.78 - ETA: 3:10 - loss: 0.8022 - accuracy: 0.77 - ETA: 3:09 - loss: 0.8011 - accuracy: 0.77 - ETA: 3:07 - loss: 0.7963 - accuracy: 0.78 - ETA: 3:05 - loss: 0.7974 - accuracy: 0.78 - ETA: 3:03 - loss: 0.7962 - accuracy: 0.78 - ETA: 3:02 - loss: 0.7984 - accuracy: 0.77 - ETA: 3:00 - loss: 0.7967 - accuracy: 0.78 - ETA: 2:58 - loss: 0.7968 - accuracy: 0.78 - ETA: 2:56 - loss: 0.7940 - accuracy: 0.78 - ETA: 2:54 - loss: 0.7955 - accuracy: 0.78 - ETA: 2:52 - loss: 0.7999 - accuracy: 0.77 - ETA: 2:50 - loss: 0.7955 - accuracy: 0.78 - ETA: 2:48 - loss: 0.7957 - accuracy: 0.78 - ETA: 2:46 - loss: 0.8002 - accuracy: 0.78 - ETA: 2:45 - loss: 0.8066 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8066 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8068 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8082 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8069 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8071 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8052 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8028 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8062 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8088 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8089 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8086 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8056 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8050 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8071 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8092 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8075 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8069 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8069 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8055 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8035 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8026 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8049 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8067 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8063 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8045 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8047 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8059 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8075 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8068 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8081 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8083 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8109 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8113 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8131 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8164 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8141 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8126 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8106 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8120 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8106 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8112 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8113 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8120 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8119 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8120 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8106 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8099 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8114 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8100 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8100 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8099 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8097 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8117 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8135 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8129 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8121 - accuracy: 0.77 - ETA: 59s - loss: 0.8125 - accuracy: 0.7765 - ETA: 57s - loss: 0.8125 - accuracy: 0.776 - ETA: 55s - loss: 0.8111 - accuracy: 0.777 - ETA: 53s - loss: 0.8118 - accuracy: 0.776 - ETA: 52s - loss: 0.8117 - accuracy: 0.777 - ETA: 50s - loss: 0.8114 - accuracy: 0.777 - ETA: 48s - loss: 0.8093 - accuracy: 0.777 - ETA: 46s - loss: 0.8120 - accuracy: 0.777 - ETA: 44s - loss: 0.8119 - accuracy: 0.777 - ETA: 42s - loss: 0.8094 - accuracy: 0.778 - ETA: 40s - loss: 0.8081 - accuracy: 0.777 - ETA: 39s - loss: 0.8083 - accuracy: 0.777 - ETA: 37s - loss: 0.8065 - accuracy: 0.778 - ETA: 35s - loss: 0.8056 - accuracy: 0.778 - ETA: 33s - loss: 0.8061 - accuracy: 0.778 - ETA: 31s - loss: 0.8056 - accuracy: 0.778 - ETA: 29s - loss: 0.8073 - accuracy: 0.778 - ETA: 27s - loss: 0.8050 - accuracy: 0.778 - ETA: 25s - loss: 0.8058 - accuracy: 0.778 - ETA: 24s - loss: 0.8050 - accuracy: 0.778 - ETA: 22s - loss: 0.8043 - accuracy: 0.778 - ETA: 20s - loss: 0.8023 - accuracy: 0.778 - ETA: 18s - loss: 0.8021 - accuracy: 0.778 - ETA: 16s - loss: 0.8040 - accuracy: 0.778 - ETA: 14s - loss: 0.8028 - accuracy: 0.778 - ETA: 12s - loss: 0.8039 - accuracy: 0.778 - ETA: 10s - loss: 0.8048 - accuracy: 0.778 - ETA: 9s - loss: 0.8053 - accuracy: 0.778 - ETA: 7s - loss: 0.8042 - accuracy: 0.77 - ETA: 5s - loss: 0.8050 - accuracy: 0.77 - ETA: 3s - loss: 0.8069 - accuracy: 0.77 - ETA: 1s - loss: 0.8058 - accuracy: 0.77 - 309s 16ms/step - loss: 0.8080 - accuracy: 0.7796 - val_loss: 1.9061 - val_accuracy: 0.7267\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:50 - loss: 1.0068 - accuracy: 0.78 - ETA: 4:48 - loss: 0.8053 - accuracy: 0.80 - ETA: 4:44 - loss: 0.8097 - accuracy: 0.79 - ETA: 4:42 - loss: 0.7627 - accuracy: 0.80 - ETA: 4:37 - loss: 0.7385 - accuracy: 0.80 - ETA: 4:37 - loss: 0.7656 - accuracy: 0.80 - ETA: 4:37 - loss: 0.7388 - accuracy: 0.79 - ETA: 4:32 - loss: 0.7453 - accuracy: 0.79 - ETA: 4:29 - loss: 0.7835 - accuracy: 0.78 - ETA: 4:26 - loss: 0.7663 - accuracy: 0.78 - ETA: 4:22 - loss: 0.7652 - accuracy: 0.78 - ETA: 4:21 - loss: 0.7723 - accuracy: 0.78 - ETA: 4:21 - loss: 0.7581 - accuracy: 0.78 - ETA: 4:17 - loss: 0.7536 - accuracy: 0.78 - ETA: 4:16 - loss: 0.7636 - accuracy: 0.78 - ETA: 4:15 - loss: 0.7504 - accuracy: 0.78 - ETA: 4:11 - loss: 0.7558 - accuracy: 0.78 - ETA: 4:10 - loss: 0.7600 - accuracy: 0.78 - ETA: 4:07 - loss: 0.7553 - accuracy: 0.78 - ETA: 4:05 - loss: 0.7442 - accuracy: 0.79 - ETA: 4:03 - loss: 0.7544 - accuracy: 0.79 - ETA: 4:00 - loss: 0.7574 - accuracy: 0.79 - ETA: 3:59 - loss: 0.7700 - accuracy: 0.78 - ETA: 3:58 - loss: 0.7804 - accuracy: 0.78 - ETA: 3:56 - loss: 0.7860 - accuracy: 0.78 - ETA: 3:54 - loss: 0.7821 - accuracy: 0.78 - ETA: 3:52 - loss: 0.7753 - accuracy: 0.78 - ETA: 3:50 - loss: 0.7734 - accuracy: 0.78 - ETA: 3:48 - loss: 0.7756 - accuracy: 0.78 - ETA: 3:46 - loss: 0.7904 - accuracy: 0.78 - ETA: 3:44 - loss: 0.7850 - accuracy: 0.78 - ETA: 3:42 - loss: 0.7991 - accuracy: 0.78 - ETA: 3:40 - loss: 0.8017 - accuracy: 0.78 - ETA: 3:38 - loss: 0.7985 - accuracy: 0.78 - ETA: 3:36 - loss: 0.7968 - accuracy: 0.78 - ETA: 3:35 - loss: 0.8048 - accuracy: 0.78 - ETA: 3:33 - loss: 0.8111 - accuracy: 0.78 - ETA: 3:31 - loss: 0.8121 - accuracy: 0.78 - ETA: 3:29 - loss: 0.8072 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8196 - accuracy: 0.78 - ETA: 3:26 - loss: 0.8226 - accuracy: 0.78 - ETA: 3:24 - loss: 0.8237 - accuracy: 0.77 - ETA: 3:22 - loss: 0.8202 - accuracy: 0.78 - ETA: 3:20 - loss: 0.8164 - accuracy: 0.78 - ETA: 3:18 - loss: 0.8185 - accuracy: 0.78 - ETA: 3:16 - loss: 0.8202 - accuracy: 0.78 - ETA: 3:14 - loss: 0.8292 - accuracy: 0.77 - ETA: 3:13 - loss: 0.8400 - accuracy: 0.77 - ETA: 3:11 - loss: 0.8400 - accuracy: 0.77 - ETA: 3:09 - loss: 0.8389 - accuracy: 0.77 - ETA: 3:07 - loss: 0.8343 - accuracy: 0.77 - ETA: 3:05 - loss: 0.8323 - accuracy: 0.77 - ETA: 3:03 - loss: 0.8263 - accuracy: 0.78 - ETA: 3:01 - loss: 0.8314 - accuracy: 0.77 - ETA: 2:59 - loss: 0.8277 - accuracy: 0.78 - ETA: 2:57 - loss: 0.8248 - accuracy: 0.77 - ETA: 2:55 - loss: 0.8322 - accuracy: 0.77 - ETA: 2:53 - loss: 0.8311 - accuracy: 0.77 - ETA: 2:51 - loss: 0.8349 - accuracy: 0.77 - ETA: 2:50 - loss: 0.8353 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8385 - accuracy: 0.77 - ETA: 2:46 - loss: 0.8406 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8393 - accuracy: 0.77 - ETA: 2:42 - loss: 0.8509 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8506 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8484 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8478 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8458 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8472 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8490 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8458 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8429 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8409 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8397 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8385 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8389 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8389 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8382 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8376 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8351 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8356 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8358 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8377 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8393 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8393 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8397 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8385 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8388 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8402 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8377 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8383 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8402 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8388 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8407 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8395 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8416 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8394 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8384 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8380 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8387 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8383 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8358 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8363 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8364 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8367 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8365 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8368 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8374 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8394 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8395 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8402 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8377 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8368 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8356 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8356 - accuracy: 0.77 - ETA: 1:05 - loss: 0.8369 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8389 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8377 - accuracy: 0.77 - ETA: 59s - loss: 0.8393 - accuracy: 0.7742 - ETA: 58s - loss: 0.8379 - accuracy: 0.774 - ETA: 56s - loss: 0.8370 - accuracy: 0.774 - ETA: 54s - loss: 0.8353 - accuracy: 0.774 - ETA: 52s - loss: 0.8354 - accuracy: 0.774 - ETA: 50s - loss: 0.8356 - accuracy: 0.774 - ETA: 48s - loss: 0.8336 - accuracy: 0.775 - ETA: 46s - loss: 0.8316 - accuracy: 0.775 - ETA: 45s - loss: 0.8335 - accuracy: 0.775 - ETA: 43s - loss: 0.8344 - accuracy: 0.775 - ETA: 41s - loss: 0.8334 - accuracy: 0.775 - ETA: 39s - loss: 0.8333 - accuracy: 0.775 - ETA: 37s - loss: 0.8329 - accuracy: 0.775 - ETA: 35s - loss: 0.8327 - accuracy: 0.775 - ETA: 33s - loss: 0.8335 - accuracy: 0.775 - ETA: 31s - loss: 0.8314 - accuracy: 0.776 - ETA: 30s - loss: 0.8314 - accuracy: 0.776 - ETA: 28s - loss: 0.8305 - accuracy: 0.776 - ETA: 26s - loss: 0.8322 - accuracy: 0.775 - ETA: 24s - loss: 0.8309 - accuracy: 0.775 - ETA: 22s - loss: 0.8328 - accuracy: 0.775 - ETA: 20s - loss: 0.8330 - accuracy: 0.775 - ETA: 18s - loss: 0.8318 - accuracy: 0.775 - ETA: 16s - loss: 0.8324 - accuracy: 0.774 - ETA: 14s - loss: 0.8310 - accuracy: 0.775 - ETA: 13s - loss: 0.8322 - accuracy: 0.774 - ETA: 11s - loss: 0.8318 - accuracy: 0.774 - ETA: 9s - loss: 0.8313 - accuracy: 0.775 - ETA: 7s - loss: 0.8345 - accuracy: 0.77 - ETA: 5s - loss: 0.8344 - accuracy: 0.77 - ETA: 3s - loss: 0.8322 - accuracy: 0.77 - ETA: 1s - loss: 0.8318 - accuracy: 0.77 - 311s 16ms/step - loss: 0.8309 - accuracy: 0.7758 - val_loss: 2.0839 - val_accuracy: 0.7267\n",
      "Epoch 78/100\n",
      "19312/19312 [==============================] - ETA: 4:59 - loss: 0.8439 - accuracy: 0.76 - ETA: 4:50 - loss: 0.8146 - accuracy: 0.77 - ETA: 4:45 - loss: 0.8217 - accuracy: 0.77 - ETA: 4:42 - loss: 0.8246 - accuracy: 0.77 - ETA: 4:40 - loss: 0.7663 - accuracy: 0.78 - ETA: 4:37 - loss: 0.7421 - accuracy: 0.79 - ETA: 4:35 - loss: 0.7137 - accuracy: 0.79 - ETA: 4:32 - loss: 0.7013 - accuracy: 0.79 - ETA: 4:29 - loss: 0.7273 - accuracy: 0.78 - ETA: 4:27 - loss: 0.7396 - accuracy: 0.78 - ETA: 4:27 - loss: 0.7353 - accuracy: 0.78 - ETA: 4:25 - loss: 0.7557 - accuracy: 0.78 - ETA: 4:23 - loss: 0.7684 - accuracy: 0.78 - ETA: 4:22 - loss: 0.7753 - accuracy: 0.78 - ETA: 4:19 - loss: 0.7585 - accuracy: 0.78 - ETA: 4:17 - loss: 0.7704 - accuracy: 0.78 - ETA: 4:15 - loss: 0.7719 - accuracy: 0.78 - ETA: 4:13 - loss: 0.7920 - accuracy: 0.77 - ETA: 4:10 - loss: 0.8128 - accuracy: 0.77 - ETA: 4:08 - loss: 0.8385 - accuracy: 0.77 - ETA: 4:06 - loss: 0.8509 - accuracy: 0.77 - ETA: 4:04 - loss: 0.8698 - accuracy: 0.77 - ETA: 4:02 - loss: 0.8724 - accuracy: 0.77 - ETA: 4:00 - loss: 0.8753 - accuracy: 0.77 - ETA: 3:58 - loss: 0.8728 - accuracy: 0.77 - ETA: 3:56 - loss: 0.8630 - accuracy: 0.77 - ETA: 3:54 - loss: 0.8629 - accuracy: 0.77 - ETA: 3:53 - loss: 0.8582 - accuracy: 0.77 - ETA: 3:51 - loss: 0.8648 - accuracy: 0.77 - ETA: 3:49 - loss: 0.8580 - accuracy: 0.77 - ETA: 3:47 - loss: 0.8501 - accuracy: 0.77 - ETA: 3:45 - loss: 0.8406 - accuracy: 0.77 - ETA: 3:44 - loss: 0.8605 - accuracy: 0.77 - ETA: 3:42 - loss: 0.8605 - accuracy: 0.77 - ETA: 3:40 - loss: 0.8660 - accuracy: 0.77 - ETA: 3:38 - loss: 0.8787 - accuracy: 0.77 - ETA: 3:36 - loss: 0.8802 - accuracy: 0.77 - ETA: 3:33 - loss: 0.8744 - accuracy: 0.77 - ETA: 3:31 - loss: 0.8729 - accuracy: 0.77 - ETA: 3:29 - loss: 0.8773 - accuracy: 0.77 - ETA: 3:27 - loss: 0.8749 - accuracy: 0.77 - ETA: 3:25 - loss: 0.8720 - accuracy: 0.77 - ETA: 3:23 - loss: 0.8717 - accuracy: 0.77 - ETA: 3:21 - loss: 0.8726 - accuracy: 0.77 - ETA: 3:19 - loss: 0.8707 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8759 - accuracy: 0.77 - ETA: 3:15 - loss: 0.8814 - accuracy: 0.76 - ETA: 3:14 - loss: 0.8793 - accuracy: 0.76 - ETA: 3:12 - loss: 0.8786 - accuracy: 0.76 - ETA: 3:10 - loss: 0.8781 - accuracy: 0.76 - ETA: 3:08 - loss: 0.8810 - accuracy: 0.76 - ETA: 3:06 - loss: 0.8770 - accuracy: 0.76 - ETA: 3:04 - loss: 0.8733 - accuracy: 0.76 - ETA: 3:02 - loss: 0.8741 - accuracy: 0.76 - ETA: 3:00 - loss: 0.8748 - accuracy: 0.76 - ETA: 2:59 - loss: 0.8749 - accuracy: 0.76 - ETA: 2:57 - loss: 0.8718 - accuracy: 0.76 - ETA: 2:55 - loss: 0.8721 - accuracy: 0.76 - ETA: 2:53 - loss: 0.8665 - accuracy: 0.76 - ETA: 2:51 - loss: 0.8668 - accuracy: 0.76 - ETA: 2:49 - loss: 0.8713 - accuracy: 0.76 - ETA: 2:47 - loss: 0.8718 - accuracy: 0.76 - ETA: 2:45 - loss: 0.8733 - accuracy: 0.76 - ETA: 2:43 - loss: 0.8769 - accuracy: 0.76 - ETA: 2:41 - loss: 0.8749 - accuracy: 0.76 - ETA: 2:39 - loss: 0.8782 - accuracy: 0.76 - ETA: 2:37 - loss: 0.8805 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8818 - accuracy: 0.76 - ETA: 2:34 - loss: 0.8786 - accuracy: 0.76 - ETA: 2:32 - loss: 0.8789 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8779 - accuracy: 0.76 - ETA: 2:28 - loss: 0.8802 - accuracy: 0.76 - ETA: 2:26 - loss: 0.8763 - accuracy: 0.76 - ETA: 2:24 - loss: 0.8739 - accuracy: 0.76 - ETA: 2:22 - loss: 0.8728 - accuracy: 0.76 - ETA: 2:20 - loss: 0.8703 - accuracy: 0.76 - ETA: 2:18 - loss: 0.8698 - accuracy: 0.76 - ETA: 2:17 - loss: 0.8715 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8759 - accuracy: 0.76 - ETA: 2:13 - loss: 0.8752 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8739 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8766 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8749 - accuracy: 0.76 - ETA: 2:05 - loss: 0.8756 - accuracy: 0.76 - ETA: 2:04 - loss: 0.8754 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8715 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8720 - accuracy: 0.76 - ETA: 1:58 - loss: 0.8756 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8748 - accuracy: 0.76 - ETA: 1:54 - loss: 0.8715 - accuracy: 0.76 - ETA: 1:52 - loss: 0.8702 - accuracy: 0.76 - ETA: 1:50 - loss: 0.8703 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8693 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8684 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8732 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8708 - accuracy: 0.76 - ETA: 1:41 - loss: 0.8707 - accuracy: 0.76 - ETA: 1:39 - loss: 0.8727 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8746 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8726 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8708 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8714 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8779 - accuracy: 0.76 - ETA: 1:28 - loss: 0.8805 - accuracy: 0.76 - ETA: 1:26 - loss: 0.8801 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8767 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8772 - accuracy: 0.76 - ETA: 1:20 - loss: 0.8752 - accuracy: 0.76 - ETA: 1:18 - loss: 0.8763 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8766 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8722 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8723 - accuracy: 0.76 - ETA: 1:11 - loss: 0.8710 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8726 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8722 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8709 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8702 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8696 - accuracy: 0.76 - ETA: 59s - loss: 0.8707 - accuracy: 0.7683 - ETA: 57s - loss: 0.8710 - accuracy: 0.768 - ETA: 56s - loss: 0.8692 - accuracy: 0.767 - ETA: 54s - loss: 0.8666 - accuracy: 0.768 - ETA: 52s - loss: 0.8667 - accuracy: 0.768 - ETA: 50s - loss: 0.8671 - accuracy: 0.768 - ETA: 48s - loss: 0.8664 - accuracy: 0.768 - ETA: 46s - loss: 0.8676 - accuracy: 0.768 - ETA: 44s - loss: 0.8697 - accuracy: 0.768 - ETA: 42s - loss: 0.8689 - accuracy: 0.768 - ETA: 41s - loss: 0.8678 - accuracy: 0.768 - ETA: 39s - loss: 0.8670 - accuracy: 0.769 - ETA: 37s - loss: 0.8703 - accuracy: 0.768 - ETA: 35s - loss: 0.8737 - accuracy: 0.768 - ETA: 33s - loss: 0.8722 - accuracy: 0.769 - ETA: 31s - loss: 0.8723 - accuracy: 0.769 - ETA: 29s - loss: 0.8712 - accuracy: 0.769 - ETA: 27s - loss: 0.8713 - accuracy: 0.769 - ETA: 26s - loss: 0.8712 - accuracy: 0.769 - ETA: 24s - loss: 0.8714 - accuracy: 0.769 - ETA: 22s - loss: 0.8706 - accuracy: 0.769 - ETA: 20s - loss: 0.8710 - accuracy: 0.769 - ETA: 18s - loss: 0.8710 - accuracy: 0.769 - ETA: 16s - loss: 0.8696 - accuracy: 0.770 - ETA: 14s - loss: 0.8688 - accuracy: 0.769 - ETA: 12s - loss: 0.8679 - accuracy: 0.770 - ETA: 11s - loss: 0.8670 - accuracy: 0.770 - ETA: 9s - loss: 0.8655 - accuracy: 0.770 - ETA: 7s - loss: 0.8671 - accuracy: 0.77 - ETA: 5s - loss: 0.8670 - accuracy: 0.77 - ETA: 3s - loss: 0.8664 - accuracy: 0.77 - ETA: 1s - loss: 0.8665 - accuracy: 0.77 - 306s 16ms/step - loss: 0.8668 - accuracy: 0.7703 - val_loss: 2.2926 - val_accuracy: 0.7252\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:28 - loss: 1.0819 - accuracy: 0.74 - ETA: 4:35 - loss: 0.8602 - accuracy: 0.76 - ETA: 4:31 - loss: 0.9273 - accuracy: 0.74 - ETA: 4:28 - loss: 0.8776 - accuracy: 0.75 - ETA: 4:23 - loss: 0.8718 - accuracy: 0.76 - ETA: 4:20 - loss: 0.8642 - accuracy: 0.76 - ETA: 4:20 - loss: 0.8828 - accuracy: 0.76 - ETA: 4:18 - loss: 0.8709 - accuracy: 0.77 - ETA: 4:17 - loss: 0.8590 - accuracy: 0.77 - ETA: 4:16 - loss: 0.8716 - accuracy: 0.77 - ETA: 4:12 - loss: 0.8695 - accuracy: 0.76 - ETA: 4:09 - loss: 0.9008 - accuracy: 0.76 - ETA: 4:07 - loss: 0.8929 - accuracy: 0.77 - ETA: 4:06 - loss: 0.8694 - accuracy: 0.77 - ETA: 4:04 - loss: 0.8807 - accuracy: 0.77 - ETA: 4:03 - loss: 0.8650 - accuracy: 0.77 - ETA: 4:02 - loss: 0.8849 - accuracy: 0.77 - ETA: 4:00 - loss: 0.8702 - accuracy: 0.77 - ETA: 3:58 - loss: 0.8802 - accuracy: 0.77 - ETA: 3:57 - loss: 0.8892 - accuracy: 0.77 - ETA: 3:56 - loss: 0.8854 - accuracy: 0.77 - ETA: 3:54 - loss: 0.8784 - accuracy: 0.77 - ETA: 3:52 - loss: 0.8734 - accuracy: 0.77 - ETA: 3:50 - loss: 0.8941 - accuracy: 0.77 - ETA: 3:49 - loss: 0.9003 - accuracy: 0.77 - ETA: 3:47 - loss: 0.8913 - accuracy: 0.77 - ETA: 3:45 - loss: 0.8819 - accuracy: 0.77 - ETA: 3:44 - loss: 0.8833 - accuracy: 0.77 - ETA: 3:42 - loss: 0.8757 - accuracy: 0.77 - ETA: 3:40 - loss: 0.8747 - accuracy: 0.77 - ETA: 3:39 - loss: 0.8749 - accuracy: 0.77 - ETA: 3:37 - loss: 0.8679 - accuracy: 0.77 - ETA: 3:35 - loss: 0.8603 - accuracy: 0.77 - ETA: 3:34 - loss: 0.8618 - accuracy: 0.77 - ETA: 3:32 - loss: 0.8646 - accuracy: 0.77 - ETA: 3:30 - loss: 0.8695 - accuracy: 0.77 - ETA: 3:28 - loss: 0.8723 - accuracy: 0.77 - ETA: 3:26 - loss: 0.8750 - accuracy: 0.77 - ETA: 3:25 - loss: 0.8675 - accuracy: 0.77 - ETA: 3:23 - loss: 0.8705 - accuracy: 0.77 - ETA: 3:21 - loss: 0.8647 - accuracy: 0.77 - ETA: 3:20 - loss: 0.8638 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8616 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8581 - accuracy: 0.77 - ETA: 3:14 - loss: 0.8641 - accuracy: 0.77 - ETA: 3:13 - loss: 0.8719 - accuracy: 0.77 - ETA: 3:11 - loss: 0.8812 - accuracy: 0.76 - ETA: 3:09 - loss: 0.8833 - accuracy: 0.77 - ETA: 3:07 - loss: 0.8847 - accuracy: 0.77 - ETA: 3:05 - loss: 0.8831 - accuracy: 0.77 - ETA: 3:04 - loss: 0.8796 - accuracy: 0.77 - ETA: 3:02 - loss: 0.8813 - accuracy: 0.77 - ETA: 3:00 - loss: 0.8840 - accuracy: 0.76 - ETA: 2:59 - loss: 0.8841 - accuracy: 0.76 - ETA: 2:57 - loss: 0.8867 - accuracy: 0.76 - ETA: 2:55 - loss: 0.8865 - accuracy: 0.76 - ETA: 2:53 - loss: 0.8866 - accuracy: 0.76 - ETA: 2:52 - loss: 0.8830 - accuracy: 0.77 - ETA: 2:50 - loss: 0.8812 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8759 - accuracy: 0.77 - ETA: 2:46 - loss: 0.8801 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8816 - accuracy: 0.76 - ETA: 2:42 - loss: 0.8790 - accuracy: 0.77 - ETA: 2:40 - loss: 0.8777 - accuracy: 0.76 - ETA: 2:39 - loss: 0.8752 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8733 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8727 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8715 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8692 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8726 - accuracy: 0.76 - ETA: 2:28 - loss: 0.8734 - accuracy: 0.76 - ETA: 2:26 - loss: 0.8777 - accuracy: 0.76 - ETA: 2:24 - loss: 0.8773 - accuracy: 0.76 - ETA: 2:22 - loss: 0.8738 - accuracy: 0.76 - ETA: 2:20 - loss: 0.8702 - accuracy: 0.76 - ETA: 2:18 - loss: 0.8687 - accuracy: 0.76 - ETA: 2:17 - loss: 0.8688 - accuracy: 0.76 - ETA: 2:15 - loss: 0.8700 - accuracy: 0.76 - ETA: 2:13 - loss: 0.8703 - accuracy: 0.76 - ETA: 2:11 - loss: 0.8702 - accuracy: 0.76 - ETA: 2:09 - loss: 0.8664 - accuracy: 0.76 - ETA: 2:07 - loss: 0.8665 - accuracy: 0.76 - ETA: 2:05 - loss: 0.8638 - accuracy: 0.76 - ETA: 2:04 - loss: 0.8652 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8669 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8686 - accuracy: 0.76 - ETA: 1:58 - loss: 0.8686 - accuracy: 0.76 - ETA: 1:56 - loss: 0.8683 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8676 - accuracy: 0.76 - ETA: 1:53 - loss: 0.8662 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8695 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8699 - accuracy: 0.76 - ETA: 1:47 - loss: 0.8715 - accuracy: 0.76 - ETA: 1:45 - loss: 0.8713 - accuracy: 0.76 - ETA: 1:43 - loss: 0.8699 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8684 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8654 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8652 - accuracy: 0.76 - ETA: 1:36 - loss: 0.8649 - accuracy: 0.76 - ETA: 1:34 - loss: 0.8649 - accuracy: 0.76 - ETA: 1:32 - loss: 0.8626 - accuracy: 0.76 - ETA: 1:30 - loss: 0.8619 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8625 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8640 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8635 - accuracy: 0.76 - ETA: 1:23 - loss: 0.8632 - accuracy: 0.76 - ETA: 1:21 - loss: 0.8613 - accuracy: 0.76 - ETA: 1:19 - loss: 0.8586 - accuracy: 0.76 - ETA: 1:17 - loss: 0.8627 - accuracy: 0.76 - ETA: 1:16 - loss: 0.8604 - accuracy: 0.76 - ETA: 1:14 - loss: 0.8591 - accuracy: 0.76 - ETA: 1:12 - loss: 0.8611 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8600 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8589 - accuracy: 0.76 - ETA: 1:06 - loss: 0.8571 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8542 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8548 - accuracy: 0.76 - ETA: 1:01 - loss: 0.8551 - accuracy: 0.76 - ETA: 59s - loss: 0.8537 - accuracy: 0.7692 - ETA: 57s - loss: 0.8535 - accuracy: 0.768 - ETA: 55s - loss: 0.8557 - accuracy: 0.768 - ETA: 53s - loss: 0.8543 - accuracy: 0.769 - ETA: 51s - loss: 0.8535 - accuracy: 0.769 - ETA: 49s - loss: 0.8528 - accuracy: 0.769 - ETA: 48s - loss: 0.8509 - accuracy: 0.769 - ETA: 46s - loss: 0.8546 - accuracy: 0.769 - ETA: 44s - loss: 0.8540 - accuracy: 0.769 - ETA: 42s - loss: 0.8528 - accuracy: 0.769 - ETA: 40s - loss: 0.8537 - accuracy: 0.769 - ETA: 38s - loss: 0.8516 - accuracy: 0.770 - ETA: 36s - loss: 0.8487 - accuracy: 0.770 - ETA: 35s - loss: 0.8494 - accuracy: 0.770 - ETA: 33s - loss: 0.8502 - accuracy: 0.770 - ETA: 31s - loss: 0.8487 - accuracy: 0.771 - ETA: 29s - loss: 0.8498 - accuracy: 0.770 - ETA: 27s - loss: 0.8511 - accuracy: 0.770 - ETA: 25s - loss: 0.8501 - accuracy: 0.771 - ETA: 23s - loss: 0.8527 - accuracy: 0.770 - ETA: 22s - loss: 0.8523 - accuracy: 0.770 - ETA: 20s - loss: 0.8527 - accuracy: 0.770 - ETA: 18s - loss: 0.8510 - accuracy: 0.771 - ETA: 16s - loss: 0.8493 - accuracy: 0.771 - ETA: 14s - loss: 0.8485 - accuracy: 0.771 - ETA: 12s - loss: 0.8487 - accuracy: 0.771 - ETA: 10s - loss: 0.8473 - accuracy: 0.772 - ETA: 9s - loss: 0.8462 - accuracy: 0.772 - ETA: 7s - loss: 0.8486 - accuracy: 0.77 - ETA: 5s - loss: 0.8488 - accuracy: 0.77 - ETA: 3s - loss: 0.8495 - accuracy: 0.77 - ETA: 1s - loss: 0.8488 - accuracy: 0.77 - 306s 16ms/step - loss: 0.8477 - accuracy: 0.7721 - val_loss: 1.9978 - val_accuracy: 0.7281\n",
      "Epoch 80/100\n",
      "19312/19312 [==============================] - ETA: 4:43 - loss: 0.7424 - accuracy: 0.75 - ETA: 4:10 - loss: 0.7782 - accuracy: 0.76 - ETA: 4:11 - loss: 0.8920 - accuracy: 0.75 - ETA: 4:10 - loss: 0.8815 - accuracy: 0.75 - ETA: 4:08 - loss: 0.9060 - accuracy: 0.75 - ETA: 4:10 - loss: 0.8492 - accuracy: 0.76 - ETA: 4:10 - loss: 0.8613 - accuracy: 0.75 - ETA: 4:08 - loss: 0.8833 - accuracy: 0.75 - ETA: 4:07 - loss: 0.8380 - accuracy: 0.76 - ETA: 4:05 - loss: 0.8342 - accuracy: 0.76 - ETA: 4:04 - loss: 0.8192 - accuracy: 0.76 - ETA: 4:04 - loss: 0.8158 - accuracy: 0.77 - ETA: 4:04 - loss: 0.8181 - accuracy: 0.77 - ETA: 4:02 - loss: 0.7980 - accuracy: 0.77 - ETA: 4:00 - loss: 0.7996 - accuracy: 0.77 - ETA: 4:00 - loss: 0.7860 - accuracy: 0.78 - ETA: 3:59 - loss: 0.7842 - accuracy: 0.78 - ETA: 3:58 - loss: 0.7905 - accuracy: 0.77 - ETA: 3:56 - loss: 0.7823 - accuracy: 0.78 - ETA: 3:55 - loss: 0.7767 - accuracy: 0.78 - ETA: 3:53 - loss: 0.7805 - accuracy: 0.78 - ETA: 3:52 - loss: 0.7867 - accuracy: 0.78 - ETA: 3:50 - loss: 0.7889 - accuracy: 0.78 - ETA: 3:49 - loss: 0.7853 - accuracy: 0.78 - ETA: 3:48 - loss: 0.7869 - accuracy: 0.78 - ETA: 3:46 - loss: 0.7862 - accuracy: 0.78 - ETA: 3:45 - loss: 0.7763 - accuracy: 0.78 - ETA: 3:43 - loss: 0.7699 - accuracy: 0.78 - ETA: 3:41 - loss: 0.7759 - accuracy: 0.78 - ETA: 3:40 - loss: 0.7830 - accuracy: 0.78 - ETA: 3:38 - loss: 0.7899 - accuracy: 0.78 - ETA: 3:36 - loss: 0.7806 - accuracy: 0.78 - ETA: 3:35 - loss: 0.7925 - accuracy: 0.78 - ETA: 3:33 - loss: 0.7945 - accuracy: 0.78 - ETA: 3:31 - loss: 0.8002 - accuracy: 0.77 - ETA: 3:30 - loss: 0.8010 - accuracy: 0.77 - ETA: 3:28 - loss: 0.7944 - accuracy: 0.78 - ETA: 3:27 - loss: 0.7883 - accuracy: 0.78 - ETA: 3:25 - loss: 0.7876 - accuracy: 0.78 - ETA: 3:23 - loss: 0.7845 - accuracy: 0.78 - ETA: 3:21 - loss: 0.7846 - accuracy: 0.78 - ETA: 3:19 - loss: 0.7843 - accuracy: 0.78 - ETA: 3:17 - loss: 0.7779 - accuracy: 0.78 - ETA: 3:16 - loss: 0.7820 - accuracy: 0.78 - ETA: 3:14 - loss: 0.7767 - accuracy: 0.78 - ETA: 3:12 - loss: 0.7744 - accuracy: 0.78 - ETA: 3:11 - loss: 0.7775 - accuracy: 0.78 - ETA: 3:09 - loss: 0.7763 - accuracy: 0.78 - ETA: 3:07 - loss: 0.7807 - accuracy: 0.78 - ETA: 3:05 - loss: 0.7787 - accuracy: 0.78 - ETA: 3:03 - loss: 0.7789 - accuracy: 0.78 - ETA: 3:02 - loss: 0.7775 - accuracy: 0.78 - ETA: 3:00 - loss: 0.7748 - accuracy: 0.78 - ETA: 2:58 - loss: 0.7793 - accuracy: 0.78 - ETA: 2:56 - loss: 0.7838 - accuracy: 0.78 - ETA: 2:54 - loss: 0.7863 - accuracy: 0.78 - ETA: 2:52 - loss: 0.7822 - accuracy: 0.78 - ETA: 2:50 - loss: 0.7883 - accuracy: 0.78 - ETA: 2:48 - loss: 0.7884 - accuracy: 0.78 - ETA: 2:47 - loss: 0.7862 - accuracy: 0.78 - ETA: 2:45 - loss: 0.7821 - accuracy: 0.78 - ETA: 2:43 - loss: 0.7818 - accuracy: 0.78 - ETA: 2:42 - loss: 0.7820 - accuracy: 0.78 - ETA: 2:40 - loss: 0.7800 - accuracy: 0.78 - ETA: 2:38 - loss: 0.7764 - accuracy: 0.78 - ETA: 2:36 - loss: 0.7774 - accuracy: 0.78 - ETA: 2:34 - loss: 0.7783 - accuracy: 0.78 - ETA: 2:32 - loss: 0.7789 - accuracy: 0.78 - ETA: 2:31 - loss: 0.7844 - accuracy: 0.78 - ETA: 2:29 - loss: 0.7826 - accuracy: 0.78 - ETA: 2:27 - loss: 0.7893 - accuracy: 0.78 - ETA: 2:25 - loss: 0.7967 - accuracy: 0.78 - ETA: 2:23 - loss: 0.7980 - accuracy: 0.78 - ETA: 2:21 - loss: 0.8030 - accuracy: 0.78 - ETA: 2:19 - loss: 0.8011 - accuracy: 0.78 - ETA: 2:18 - loss: 0.7988 - accuracy: 0.78 - ETA: 2:16 - loss: 0.8010 - accuracy: 0.78 - ETA: 2:14 - loss: 0.7971 - accuracy: 0.78 - ETA: 2:12 - loss: 0.7990 - accuracy: 0.78 - ETA: 2:10 - loss: 0.8016 - accuracy: 0.78 - ETA: 2:08 - loss: 0.8005 - accuracy: 0.78 - ETA: 2:06 - loss: 0.8032 - accuracy: 0.78 - ETA: 2:05 - loss: 0.8031 - accuracy: 0.78 - ETA: 2:03 - loss: 0.8040 - accuracy: 0.78 - ETA: 2:01 - loss: 0.8050 - accuracy: 0.78 - ETA: 1:59 - loss: 0.8033 - accuracy: 0.78 - ETA: 1:57 - loss: 0.8043 - accuracy: 0.78 - ETA: 1:56 - loss: 0.8033 - accuracy: 0.78 - ETA: 1:54 - loss: 0.8022 - accuracy: 0.78 - ETA: 1:52 - loss: 0.8040 - accuracy: 0.78 - ETA: 1:50 - loss: 0.8110 - accuracy: 0.78 - ETA: 1:48 - loss: 0.8102 - accuracy: 0.78 - ETA: 1:46 - loss: 0.8115 - accuracy: 0.78 - ETA: 1:44 - loss: 0.8119 - accuracy: 0.78 - ETA: 1:42 - loss: 0.8122 - accuracy: 0.78 - ETA: 1:41 - loss: 0.8111 - accuracy: 0.78 - ETA: 1:39 - loss: 0.8101 - accuracy: 0.78 - ETA: 1:37 - loss: 0.8153 - accuracy: 0.78 - ETA: 1:35 - loss: 0.8134 - accuracy: 0.78 - ETA: 1:33 - loss: 0.8105 - accuracy: 0.78 - ETA: 1:31 - loss: 0.8110 - accuracy: 0.78 - ETA: 1:30 - loss: 0.8100 - accuracy: 0.78 - ETA: 1:28 - loss: 0.8101 - accuracy: 0.78 - ETA: 1:26 - loss: 0.8101 - accuracy: 0.78 - ETA: 1:24 - loss: 0.8109 - accuracy: 0.78 - ETA: 1:22 - loss: 0.8099 - accuracy: 0.78 - ETA: 1:20 - loss: 0.8122 - accuracy: 0.78 - ETA: 1:19 - loss: 0.8095 - accuracy: 0.78 - ETA: 1:17 - loss: 0.8089 - accuracy: 0.78 - ETA: 1:15 - loss: 0.8128 - accuracy: 0.78 - ETA: 1:13 - loss: 0.8121 - accuracy: 0.78 - ETA: 1:11 - loss: 0.8120 - accuracy: 0.78 - ETA: 1:09 - loss: 0.8115 - accuracy: 0.78 - ETA: 1:07 - loss: 0.8134 - accuracy: 0.78 - ETA: 1:06 - loss: 0.8141 - accuracy: 0.78 - ETA: 1:04 - loss: 0.8187 - accuracy: 0.78 - ETA: 1:02 - loss: 0.8176 - accuracy: 0.78 - ETA: 1:00 - loss: 0.8175 - accuracy: 0.78 - ETA: 58s - loss: 0.8174 - accuracy: 0.7841 - ETA: 56s - loss: 0.8185 - accuracy: 0.784 - ETA: 55s - loss: 0.8184 - accuracy: 0.784 - ETA: 53s - loss: 0.8169 - accuracy: 0.784 - ETA: 51s - loss: 0.8164 - accuracy: 0.784 - ETA: 49s - loss: 0.8175 - accuracy: 0.784 - ETA: 47s - loss: 0.8193 - accuracy: 0.783 - ETA: 45s - loss: 0.8200 - accuracy: 0.783 - ETA: 44s - loss: 0.8192 - accuracy: 0.783 - ETA: 42s - loss: 0.8194 - accuracy: 0.783 - ETA: 40s - loss: 0.8197 - accuracy: 0.783 - ETA: 38s - loss: 0.8217 - accuracy: 0.783 - ETA: 36s - loss: 0.8206 - accuracy: 0.783 - ETA: 34s - loss: 0.8220 - accuracy: 0.783 - ETA: 32s - loss: 0.8217 - accuracy: 0.783 - ETA: 31s - loss: 0.8208 - accuracy: 0.783 - ETA: 29s - loss: 0.8205 - accuracy: 0.783 - ETA: 27s - loss: 0.8210 - accuracy: 0.783 - ETA: 25s - loss: 0.8202 - accuracy: 0.783 - ETA: 23s - loss: 0.8192 - accuracy: 0.782 - ETA: 21s - loss: 0.8185 - accuracy: 0.782 - ETA: 20s - loss: 0.8193 - accuracy: 0.782 - ETA: 18s - loss: 0.8190 - accuracy: 0.782 - ETA: 16s - loss: 0.8206 - accuracy: 0.782 - ETA: 14s - loss: 0.8225 - accuracy: 0.781 - ETA: 12s - loss: 0.8223 - accuracy: 0.781 - ETA: 10s - loss: 0.8230 - accuracy: 0.781 - ETA: 8s - loss: 0.8250 - accuracy: 0.781 - ETA: 7s - loss: 0.8231 - accuracy: 0.78 - ETA: 5s - loss: 0.8228 - accuracy: 0.78 - ETA: 3s - loss: 0.8226 - accuracy: 0.78 - ETA: 1s - loss: 0.8219 - accuracy: 0.78 - 303s 16ms/step - loss: 0.8223 - accuracy: 0.7816 - val_loss: 2.0254 - val_accuracy: 0.7231\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:26 - loss: 1.0452 - accuracy: 0.69 - ETA: 4:24 - loss: 1.0373 - accuracy: 0.73 - ETA: 4:25 - loss: 0.9844 - accuracy: 0.75 - ETA: 4:28 - loss: 0.9099 - accuracy: 0.75 - ETA: 4:27 - loss: 0.8699 - accuracy: 0.76 - ETA: 4:23 - loss: 0.8603 - accuracy: 0.76 - ETA: 4:21 - loss: 0.8584 - accuracy: 0.76 - ETA: 4:20 - loss: 0.8403 - accuracy: 0.76 - ETA: 4:20 - loss: 0.8165 - accuracy: 0.77 - ETA: 4:18 - loss: 0.8228 - accuracy: 0.76 - ETA: 4:15 - loss: 0.8403 - accuracy: 0.76 - ETA: 4:13 - loss: 0.8317 - accuracy: 0.76 - ETA: 4:12 - loss: 0.8322 - accuracy: 0.76 - ETA: 4:11 - loss: 0.8341 - accuracy: 0.76 - ETA: 4:10 - loss: 0.8247 - accuracy: 0.77 - ETA: 4:08 - loss: 0.8291 - accuracy: 0.76 - ETA: 4:07 - loss: 0.8189 - accuracy: 0.77 - ETA: 4:05 - loss: 0.8331 - accuracy: 0.77 - ETA: 4:03 - loss: 0.8311 - accuracy: 0.77 - ETA: 4:02 - loss: 0.8418 - accuracy: 0.76 - ETA: 4:00 - loss: 0.8265 - accuracy: 0.77 - ETA: 3:58 - loss: 0.8296 - accuracy: 0.77 - ETA: 3:57 - loss: 0.8388 - accuracy: 0.76 - ETA: 3:54 - loss: 0.8372 - accuracy: 0.77 - ETA: 3:52 - loss: 0.8568 - accuracy: 0.77 - ETA: 3:51 - loss: 0.8590 - accuracy: 0.77 - ETA: 3:49 - loss: 0.8523 - accuracy: 0.77 - ETA: 3:46 - loss: 0.8514 - accuracy: 0.77 - ETA: 3:45 - loss: 0.8549 - accuracy: 0.77 - ETA: 3:43 - loss: 0.8516 - accuracy: 0.77 - ETA: 3:41 - loss: 0.8519 - accuracy: 0.77 - ETA: 3:39 - loss: 0.8442 - accuracy: 0.77 - ETA: 3:37 - loss: 0.8505 - accuracy: 0.77 - ETA: 3:35 - loss: 0.8519 - accuracy: 0.77 - ETA: 3:33 - loss: 0.8445 - accuracy: 0.77 - ETA: 3:31 - loss: 0.8408 - accuracy: 0.77 - ETA: 3:29 - loss: 0.8370 - accuracy: 0.77 - ETA: 3:27 - loss: 0.8341 - accuracy: 0.77 - ETA: 3:26 - loss: 0.8297 - accuracy: 0.77 - ETA: 3:24 - loss: 0.8263 - accuracy: 0.77 - ETA: 3:22 - loss: 0.8289 - accuracy: 0.77 - ETA: 3:20 - loss: 0.8318 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8333 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8368 - accuracy: 0.77 - ETA: 3:15 - loss: 0.8363 - accuracy: 0.77 - ETA: 3:13 - loss: 0.8336 - accuracy: 0.77 - ETA: 3:11 - loss: 0.8371 - accuracy: 0.77 - ETA: 3:09 - loss: 0.8357 - accuracy: 0.77 - ETA: 3:07 - loss: 0.8340 - accuracy: 0.77 - ETA: 3:05 - loss: 0.8390 - accuracy: 0.77 - ETA: 3:03 - loss: 0.8385 - accuracy: 0.77 - ETA: 3:02 - loss: 0.8358 - accuracy: 0.77 - ETA: 3:00 - loss: 0.8341 - accuracy: 0.77 - ETA: 2:58 - loss: 0.8391 - accuracy: 0.77 - ETA: 2:57 - loss: 0.8406 - accuracy: 0.77 - ETA: 2:55 - loss: 0.8414 - accuracy: 0.77 - ETA: 2:53 - loss: 0.8426 - accuracy: 0.77 - ETA: 2:51 - loss: 0.8409 - accuracy: 0.77 - ETA: 2:50 - loss: 0.8374 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8373 - accuracy: 0.77 - ETA: 2:46 - loss: 0.8360 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8395 - accuracy: 0.77 - ETA: 2:42 - loss: 0.8386 - accuracy: 0.77 - ETA: 2:40 - loss: 0.8394 - accuracy: 0.77 - ETA: 2:38 - loss: 0.8390 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8355 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8347 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8333 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8342 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8350 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8366 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8408 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8440 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8456 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8445 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8417 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8403 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8420 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8413 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8448 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8474 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8495 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8507 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8521 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8539 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8547 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8575 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8566 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8553 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8599 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8575 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8545 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8565 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8554 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8583 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8562 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8584 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8576 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8569 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8548 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8534 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8524 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8511 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8492 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8526 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8490 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8511 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8535 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8515 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8488 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8482 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8528 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8532 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8535 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8543 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8563 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8565 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8585 - accuracy: 0.77 - ETA: 59s - loss: 0.8579 - accuracy: 0.7741 - ETA: 57s - loss: 0.8567 - accuracy: 0.774 - ETA: 55s - loss: 0.8592 - accuracy: 0.773 - ETA: 53s - loss: 0.8596 - accuracy: 0.773 - ETA: 51s - loss: 0.8610 - accuracy: 0.773 - ETA: 49s - loss: 0.8604 - accuracy: 0.773 - ETA: 47s - loss: 0.8625 - accuracy: 0.772 - ETA: 46s - loss: 0.8623 - accuracy: 0.773 - ETA: 44s - loss: 0.8613 - accuracy: 0.773 - ETA: 42s - loss: 0.8597 - accuracy: 0.773 - ETA: 40s - loss: 0.8614 - accuracy: 0.773 - ETA: 38s - loss: 0.8592 - accuracy: 0.773 - ETA: 36s - loss: 0.8582 - accuracy: 0.774 - ETA: 34s - loss: 0.8580 - accuracy: 0.774 - ETA: 33s - loss: 0.8553 - accuracy: 0.774 - ETA: 31s - loss: 0.8557 - accuracy: 0.774 - ETA: 29s - loss: 0.8538 - accuracy: 0.774 - ETA: 27s - loss: 0.8524 - accuracy: 0.774 - ETA: 25s - loss: 0.8534 - accuracy: 0.774 - ETA: 23s - loss: 0.8546 - accuracy: 0.774 - ETA: 21s - loss: 0.8539 - accuracy: 0.774 - ETA: 20s - loss: 0.8534 - accuracy: 0.774 - ETA: 18s - loss: 0.8539 - accuracy: 0.774 - ETA: 16s - loss: 0.8529 - accuracy: 0.774 - ETA: 14s - loss: 0.8524 - accuracy: 0.775 - ETA: 12s - loss: 0.8517 - accuracy: 0.774 - ETA: 10s - loss: 0.8525 - accuracy: 0.774 - ETA: 9s - loss: 0.8500 - accuracy: 0.775 - ETA: 7s - loss: 0.8506 - accuracy: 0.77 - ETA: 5s - loss: 0.8514 - accuracy: 0.77 - ETA: 3s - loss: 0.8538 - accuracy: 0.77 - ETA: 1s - loss: 0.8523 - accuracy: 0.77 - 305s 16ms/step - loss: 0.8515 - accuracy: 0.7751 - val_loss: 2.1230 - val_accuracy: 0.7194\n",
      "Epoch 82/100\n",
      "19312/19312 [==============================] - ETA: 4:31 - loss: 0.6634 - accuracy: 0.82 - ETA: 4:28 - loss: 0.7328 - accuracy: 0.80 - ETA: 4:21 - loss: 0.7794 - accuracy: 0.79 - ETA: 4:23 - loss: 0.7520 - accuracy: 0.79 - ETA: 4:19 - loss: 0.7378 - accuracy: 0.79 - ETA: 4:16 - loss: 0.7903 - accuracy: 0.78 - ETA: 4:16 - loss: 0.8032 - accuracy: 0.78 - ETA: 4:17 - loss: 0.8378 - accuracy: 0.78 - ETA: 4:14 - loss: 0.8209 - accuracy: 0.77 - ETA: 4:14 - loss: 0.7923 - accuracy: 0.78 - ETA: 4:13 - loss: 0.7772 - accuracy: 0.78 - ETA: 4:13 - loss: 0.7711 - accuracy: 0.78 - ETA: 4:12 - loss: 0.7696 - accuracy: 0.78 - ETA: 4:10 - loss: 0.7900 - accuracy: 0.78 - ETA: 4:07 - loss: 0.7769 - accuracy: 0.78 - ETA: 4:06 - loss: 0.7753 - accuracy: 0.78 - ETA: 4:04 - loss: 0.8004 - accuracy: 0.78 - ETA: 4:02 - loss: 0.7988 - accuracy: 0.78 - ETA: 4:00 - loss: 0.7902 - accuracy: 0.78 - ETA: 3:58 - loss: 0.7845 - accuracy: 0.78 - ETA: 3:57 - loss: 0.7924 - accuracy: 0.78 - ETA: 3:55 - loss: 0.7936 - accuracy: 0.78 - ETA: 3:54 - loss: 0.7891 - accuracy: 0.78 - ETA: 3:52 - loss: 0.7879 - accuracy: 0.78 - ETA: 3:50 - loss: 0.7843 - accuracy: 0.78 - ETA: 3:48 - loss: 0.7725 - accuracy: 0.78 - ETA: 3:47 - loss: 0.7729 - accuracy: 0.78 - ETA: 3:45 - loss: 0.7729 - accuracy: 0.78 - ETA: 3:44 - loss: 0.7755 - accuracy: 0.78 - ETA: 3:42 - loss: 0.7772 - accuracy: 0.78 - ETA: 3:40 - loss: 0.7771 - accuracy: 0.78 - ETA: 3:38 - loss: 0.7818 - accuracy: 0.78 - ETA: 3:37 - loss: 0.7808 - accuracy: 0.78 - ETA: 3:35 - loss: 0.7771 - accuracy: 0.78 - ETA: 3:33 - loss: 0.7820 - accuracy: 0.78 - ETA: 3:31 - loss: 0.7756 - accuracy: 0.78 - ETA: 3:29 - loss: 0.7776 - accuracy: 0.78 - ETA: 3:28 - loss: 0.7803 - accuracy: 0.78 - ETA: 3:26 - loss: 0.7830 - accuracy: 0.78 - ETA: 3:24 - loss: 0.7917 - accuracy: 0.78 - ETA: 3:22 - loss: 0.7899 - accuracy: 0.78 - ETA: 3:20 - loss: 0.7901 - accuracy: 0.78 - ETA: 3:19 - loss: 0.7893 - accuracy: 0.78 - ETA: 3:17 - loss: 0.7837 - accuracy: 0.78 - ETA: 3:15 - loss: 0.7800 - accuracy: 0.78 - ETA: 3:13 - loss: 0.7829 - accuracy: 0.78 - ETA: 3:11 - loss: 0.7862 - accuracy: 0.78 - ETA: 3:09 - loss: 0.7847 - accuracy: 0.78 - ETA: 3:08 - loss: 0.7901 - accuracy: 0.78 - ETA: 3:06 - loss: 0.7920 - accuracy: 0.78 - ETA: 3:04 - loss: 0.7921 - accuracy: 0.78 - ETA: 3:02 - loss: 0.7894 - accuracy: 0.78 - ETA: 3:01 - loss: 0.7877 - accuracy: 0.78 - ETA: 2:59 - loss: 0.7802 - accuracy: 0.78 - ETA: 2:57 - loss: 0.7861 - accuracy: 0.78 - ETA: 2:55 - loss: 0.7816 - accuracy: 0.78 - ETA: 2:53 - loss: 0.7829 - accuracy: 0.78 - ETA: 2:51 - loss: 0.7836 - accuracy: 0.78 - ETA: 2:50 - loss: 0.7867 - accuracy: 0.78 - ETA: 2:48 - loss: 0.7860 - accuracy: 0.78 - ETA: 2:46 - loss: 0.7856 - accuracy: 0.78 - ETA: 2:44 - loss: 0.7830 - accuracy: 0.78 - ETA: 2:42 - loss: 0.7876 - accuracy: 0.78 - ETA: 2:40 - loss: 0.7861 - accuracy: 0.78 - ETA: 2:38 - loss: 0.7886 - accuracy: 0.78 - ETA: 2:37 - loss: 0.7871 - accuracy: 0.78 - ETA: 2:35 - loss: 0.7844 - accuracy: 0.78 - ETA: 2:33 - loss: 0.7858 - accuracy: 0.78 - ETA: 2:31 - loss: 0.7849 - accuracy: 0.78 - ETA: 2:29 - loss: 0.7862 - accuracy: 0.78 - ETA: 2:27 - loss: 0.7864 - accuracy: 0.78 - ETA: 2:25 - loss: 0.7856 - accuracy: 0.78 - ETA: 2:23 - loss: 0.7847 - accuracy: 0.78 - ETA: 2:22 - loss: 0.7836 - accuracy: 0.78 - ETA: 2:20 - loss: 0.7802 - accuracy: 0.78 - ETA: 2:18 - loss: 0.7800 - accuracy: 0.78 - ETA: 2:16 - loss: 0.7796 - accuracy: 0.78 - ETA: 2:14 - loss: 0.7772 - accuracy: 0.78 - ETA: 2:12 - loss: 0.7812 - accuracy: 0.78 - ETA: 2:11 - loss: 0.7821 - accuracy: 0.78 - ETA: 2:09 - loss: 0.7828 - accuracy: 0.78 - ETA: 2:07 - loss: 0.7840 - accuracy: 0.78 - ETA: 2:05 - loss: 0.7839 - accuracy: 0.78 - ETA: 2:03 - loss: 0.7827 - accuracy: 0.78 - ETA: 2:01 - loss: 0.7855 - accuracy: 0.78 - ETA: 2:00 - loss: 0.7850 - accuracy: 0.78 - ETA: 1:58 - loss: 0.7863 - accuracy: 0.78 - ETA: 1:56 - loss: 0.7865 - accuracy: 0.78 - ETA: 1:54 - loss: 0.7874 - accuracy: 0.78 - ETA: 1:52 - loss: 0.7852 - accuracy: 0.78 - ETA: 1:50 - loss: 0.7856 - accuracy: 0.78 - ETA: 1:49 - loss: 0.7905 - accuracy: 0.78 - ETA: 1:47 - loss: 0.7886 - accuracy: 0.78 - ETA: 1:45 - loss: 0.7890 - accuracy: 0.78 - ETA: 1:43 - loss: 0.7895 - accuracy: 0.78 - ETA: 1:41 - loss: 0.7912 - accuracy: 0.78 - ETA: 1:39 - loss: 0.7897 - accuracy: 0.78 - ETA: 1:37 - loss: 0.7922 - accuracy: 0.78 - ETA: 1:35 - loss: 0.7945 - accuracy: 0.78 - ETA: 1:34 - loss: 0.7953 - accuracy: 0.78 - ETA: 1:32 - loss: 0.7982 - accuracy: 0.78 - ETA: 1:30 - loss: 0.7957 - accuracy: 0.78 - ETA: 1:28 - loss: 0.7945 - accuracy: 0.78 - ETA: 1:26 - loss: 0.7950 - accuracy: 0.78 - ETA: 1:24 - loss: 0.7923 - accuracy: 0.78 - ETA: 1:23 - loss: 0.7929 - accuracy: 0.78 - ETA: 1:21 - loss: 0.7929 - accuracy: 0.78 - ETA: 1:19 - loss: 0.7921 - accuracy: 0.78 - ETA: 1:17 - loss: 0.7909 - accuracy: 0.78 - ETA: 1:15 - loss: 0.7914 - accuracy: 0.78 - ETA: 1:13 - loss: 0.7979 - accuracy: 0.78 - ETA: 1:11 - loss: 0.8039 - accuracy: 0.78 - ETA: 1:10 - loss: 0.8052 - accuracy: 0.78 - ETA: 1:08 - loss: 0.8065 - accuracy: 0.78 - ETA: 1:06 - loss: 0.8074 - accuracy: 0.78 - ETA: 1:04 - loss: 0.8075 - accuracy: 0.78 - ETA: 1:02 - loss: 0.8075 - accuracy: 0.78 - ETA: 1:00 - loss: 0.8042 - accuracy: 0.78 - ETA: 59s - loss: 0.8030 - accuracy: 0.7828 - ETA: 57s - loss: 0.8021 - accuracy: 0.783 - ETA: 55s - loss: 0.8032 - accuracy: 0.782 - ETA: 53s - loss: 0.8023 - accuracy: 0.782 - ETA: 51s - loss: 0.8021 - accuracy: 0.782 - ETA: 49s - loss: 0.8030 - accuracy: 0.782 - ETA: 47s - loss: 0.8038 - accuracy: 0.782 - ETA: 46s - loss: 0.8065 - accuracy: 0.782 - ETA: 44s - loss: 0.8060 - accuracy: 0.782 - ETA: 42s - loss: 0.8057 - accuracy: 0.782 - ETA: 40s - loss: 0.8053 - accuracy: 0.782 - ETA: 38s - loss: 0.8044 - accuracy: 0.782 - ETA: 36s - loss: 0.8032 - accuracy: 0.782 - ETA: 34s - loss: 0.8057 - accuracy: 0.781 - ETA: 33s - loss: 0.8060 - accuracy: 0.781 - ETA: 31s - loss: 0.8039 - accuracy: 0.782 - ETA: 29s - loss: 0.8025 - accuracy: 0.782 - ETA: 27s - loss: 0.8025 - accuracy: 0.782 - ETA: 25s - loss: 0.8019 - accuracy: 0.782 - ETA: 23s - loss: 0.8008 - accuracy: 0.782 - ETA: 22s - loss: 0.8007 - accuracy: 0.782 - ETA: 20s - loss: 0.8003 - accuracy: 0.782 - ETA: 18s - loss: 0.8028 - accuracy: 0.782 - ETA: 16s - loss: 0.8018 - accuracy: 0.782 - ETA: 14s - loss: 0.7992 - accuracy: 0.783 - ETA: 12s - loss: 0.7992 - accuracy: 0.783 - ETA: 10s - loss: 0.7985 - accuracy: 0.783 - ETA: 9s - loss: 0.7974 - accuracy: 0.783 - ETA: 7s - loss: 0.7984 - accuracy: 0.78 - ETA: 5s - loss: 0.7977 - accuracy: 0.78 - ETA: 3s - loss: 0.7988 - accuracy: 0.78 - ETA: 1s - loss: 0.7989 - accuracy: 0.78 - 307s 16ms/step - loss: 0.7984 - accuracy: 0.7828 - val_loss: 2.0713 - val_accuracy: 0.7248\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:44 - loss: 0.7500 - accuracy: 0.76 - ETA: 4:35 - loss: 1.1790 - accuracy: 0.76 - ETA: 4:26 - loss: 0.9895 - accuracy: 0.77 - ETA: 4:19 - loss: 0.9589 - accuracy: 0.78 - ETA: 4:23 - loss: 0.8902 - accuracy: 0.78 - ETA: 4:20 - loss: 0.8715 - accuracy: 0.78 - ETA: 4:20 - loss: 0.8185 - accuracy: 0.79 - ETA: 4:19 - loss: 0.8367 - accuracy: 0.78 - ETA: 4:17 - loss: 0.8360 - accuracy: 0.78 - ETA: 4:15 - loss: 0.8760 - accuracy: 0.78 - ETA: 4:14 - loss: 0.8777 - accuracy: 0.78 - ETA: 4:12 - loss: 0.8850 - accuracy: 0.78 - ETA: 4:11 - loss: 0.8715 - accuracy: 0.78 - ETA: 4:10 - loss: 0.8752 - accuracy: 0.78 - ETA: 4:09 - loss: 0.8618 - accuracy: 0.78 - ETA: 4:08 - loss: 0.8548 - accuracy: 0.78 - ETA: 4:07 - loss: 0.8453 - accuracy: 0.78 - ETA: 4:04 - loss: 0.8344 - accuracy: 0.78 - ETA: 4:04 - loss: 0.8326 - accuracy: 0.78 - ETA: 4:02 - loss: 0.8332 - accuracy: 0.78 - ETA: 3:59 - loss: 0.8380 - accuracy: 0.78 - ETA: 3:57 - loss: 0.8339 - accuracy: 0.78 - ETA: 3:56 - loss: 0.8346 - accuracy: 0.78 - ETA: 3:54 - loss: 0.8172 - accuracy: 0.78 - ETA: 3:53 - loss: 0.8119 - accuracy: 0.78 - ETA: 3:50 - loss: 0.8061 - accuracy: 0.78 - ETA: 3:49 - loss: 0.8008 - accuracy: 0.78 - ETA: 3:47 - loss: 0.7914 - accuracy: 0.78 - ETA: 3:45 - loss: 0.7867 - accuracy: 0.78 - ETA: 3:43 - loss: 0.7903 - accuracy: 0.78 - ETA: 3:41 - loss: 0.7869 - accuracy: 0.78 - ETA: 3:39 - loss: 0.7857 - accuracy: 0.79 - ETA: 3:37 - loss: 0.8181 - accuracy: 0.78 - ETA: 3:35 - loss: 0.8148 - accuracy: 0.78 - ETA: 3:33 - loss: 0.8130 - accuracy: 0.78 - ETA: 3:32 - loss: 0.8140 - accuracy: 0.78 - ETA: 3:30 - loss: 0.8057 - accuracy: 0.79 - ETA: 3:28 - loss: 0.8104 - accuracy: 0.78 - ETA: 3:26 - loss: 0.8084 - accuracy: 0.78 - ETA: 3:24 - loss: 0.8065 - accuracy: 0.79 - ETA: 3:22 - loss: 0.8158 - accuracy: 0.78 - ETA: 3:20 - loss: 0.8124 - accuracy: 0.78 - ETA: 3:19 - loss: 0.8089 - accuracy: 0.78 - ETA: 3:17 - loss: 0.8080 - accuracy: 0.78 - ETA: 3:15 - loss: 0.8062 - accuracy: 0.78 - ETA: 3:13 - loss: 0.8051 - accuracy: 0.78 - ETA: 3:11 - loss: 0.8031 - accuracy: 0.78 - ETA: 3:10 - loss: 0.8010 - accuracy: 0.78 - ETA: 3:08 - loss: 0.8005 - accuracy: 0.78 - ETA: 3:06 - loss: 0.7957 - accuracy: 0.78 - ETA: 3:04 - loss: 0.7945 - accuracy: 0.78 - ETA: 3:02 - loss: 0.7982 - accuracy: 0.78 - ETA: 3:01 - loss: 0.7976 - accuracy: 0.78 - ETA: 2:59 - loss: 0.7980 - accuracy: 0.78 - ETA: 2:57 - loss: 0.7985 - accuracy: 0.78 - ETA: 2:55 - loss: 0.8002 - accuracy: 0.78 - ETA: 2:54 - loss: 0.8077 - accuracy: 0.78 - ETA: 2:52 - loss: 0.8093 - accuracy: 0.78 - ETA: 2:50 - loss: 0.8074 - accuracy: 0.78 - ETA: 2:48 - loss: 0.8065 - accuracy: 0.78 - ETA: 2:46 - loss: 0.8051 - accuracy: 0.78 - ETA: 2:44 - loss: 0.8086 - accuracy: 0.78 - ETA: 2:42 - loss: 0.8041 - accuracy: 0.78 - ETA: 2:40 - loss: 0.8054 - accuracy: 0.78 - ETA: 2:38 - loss: 0.8021 - accuracy: 0.78 - ETA: 2:36 - loss: 0.8001 - accuracy: 0.78 - ETA: 2:34 - loss: 0.8023 - accuracy: 0.78 - ETA: 2:32 - loss: 0.8013 - accuracy: 0.78 - ETA: 2:30 - loss: 0.8009 - accuracy: 0.78 - ETA: 2:28 - loss: 0.7964 - accuracy: 0.78 - ETA: 2:26 - loss: 0.7946 - accuracy: 0.78 - ETA: 2:25 - loss: 0.7956 - accuracy: 0.78 - ETA: 2:23 - loss: 0.7951 - accuracy: 0.78 - ETA: 2:21 - loss: 0.7928 - accuracy: 0.78 - ETA: 2:19 - loss: 0.7945 - accuracy: 0.78 - ETA: 2:17 - loss: 0.7968 - accuracy: 0.78 - ETA: 2:16 - loss: 0.7980 - accuracy: 0.78 - ETA: 2:14 - loss: 0.7963 - accuracy: 0.78 - ETA: 2:12 - loss: 0.7948 - accuracy: 0.78 - ETA: 2:10 - loss: 0.7971 - accuracy: 0.78 - ETA: 2:08 - loss: 0.7974 - accuracy: 0.78 - ETA: 2:06 - loss: 0.8009 - accuracy: 0.78 - ETA: 2:04 - loss: 0.8073 - accuracy: 0.78 - ETA: 2:03 - loss: 0.8054 - accuracy: 0.78 - ETA: 2:01 - loss: 0.8050 - accuracy: 0.78 - ETA: 1:59 - loss: 0.8019 - accuracy: 0.78 - ETA: 1:57 - loss: 0.8013 - accuracy: 0.78 - ETA: 1:55 - loss: 0.8021 - accuracy: 0.78 - ETA: 1:53 - loss: 0.8034 - accuracy: 0.78 - ETA: 1:52 - loss: 0.8056 - accuracy: 0.78 - ETA: 1:50 - loss: 0.8066 - accuracy: 0.78 - ETA: 1:48 - loss: 0.8045 - accuracy: 0.78 - ETA: 1:46 - loss: 0.8043 - accuracy: 0.78 - ETA: 1:44 - loss: 0.8028 - accuracy: 0.78 - ETA: 1:42 - loss: 0.8037 - accuracy: 0.78 - ETA: 1:41 - loss: 0.8009 - accuracy: 0.78 - ETA: 1:39 - loss: 0.8014 - accuracy: 0.78 - ETA: 1:37 - loss: 0.8005 - accuracy: 0.78 - ETA: 1:35 - loss: 0.8001 - accuracy: 0.78 - ETA: 1:33 - loss: 0.7992 - accuracy: 0.78 - ETA: 1:31 - loss: 0.7991 - accuracy: 0.78 - ETA: 1:29 - loss: 0.8002 - accuracy: 0.78 - ETA: 1:28 - loss: 0.8009 - accuracy: 0.78 - ETA: 1:26 - loss: 0.8024 - accuracy: 0.78 - ETA: 1:24 - loss: 0.8014 - accuracy: 0.78 - ETA: 1:22 - loss: 0.8013 - accuracy: 0.78 - ETA: 1:20 - loss: 0.8027 - accuracy: 0.78 - ETA: 1:18 - loss: 0.8029 - accuracy: 0.78 - ETA: 1:17 - loss: 0.8035 - accuracy: 0.78 - ETA: 1:15 - loss: 0.8016 - accuracy: 0.78 - ETA: 1:13 - loss: 0.8023 - accuracy: 0.78 - ETA: 1:11 - loss: 0.8009 - accuracy: 0.78 - ETA: 1:09 - loss: 0.8013 - accuracy: 0.78 - ETA: 1:07 - loss: 0.8026 - accuracy: 0.78 - ETA: 1:06 - loss: 0.8059 - accuracy: 0.78 - ETA: 1:04 - loss: 0.8046 - accuracy: 0.78 - ETA: 1:02 - loss: 0.8042 - accuracy: 0.78 - ETA: 1:00 - loss: 0.8033 - accuracy: 0.78 - ETA: 58s - loss: 0.8020 - accuracy: 0.7812 - ETA: 56s - loss: 0.8023 - accuracy: 0.780 - ETA: 55s - loss: 0.8015 - accuracy: 0.781 - ETA: 53s - loss: 0.8051 - accuracy: 0.781 - ETA: 51s - loss: 0.8030 - accuracy: 0.781 - ETA: 49s - loss: 0.8021 - accuracy: 0.781 - ETA: 47s - loss: 0.8015 - accuracy: 0.781 - ETA: 45s - loss: 0.8016 - accuracy: 0.781 - ETA: 44s - loss: 0.8015 - accuracy: 0.781 - ETA: 42s - loss: 0.8037 - accuracy: 0.780 - ETA: 40s - loss: 0.8041 - accuracy: 0.780 - ETA: 38s - loss: 0.8055 - accuracy: 0.780 - ETA: 36s - loss: 0.8068 - accuracy: 0.779 - ETA: 34s - loss: 0.8070 - accuracy: 0.779 - ETA: 32s - loss: 0.8056 - accuracy: 0.780 - ETA: 31s - loss: 0.8050 - accuracy: 0.780 - ETA: 29s - loss: 0.8036 - accuracy: 0.780 - ETA: 27s - loss: 0.8033 - accuracy: 0.780 - ETA: 25s - loss: 0.8038 - accuracy: 0.779 - ETA: 23s - loss: 0.8056 - accuracy: 0.779 - ETA: 21s - loss: 0.8063 - accuracy: 0.779 - ETA: 20s - loss: 0.8103 - accuracy: 0.779 - ETA: 18s - loss: 0.8119 - accuracy: 0.778 - ETA: 16s - loss: 0.8120 - accuracy: 0.778 - ETA: 14s - loss: 0.8122 - accuracy: 0.778 - ETA: 12s - loss: 0.8098 - accuracy: 0.778 - ETA: 10s - loss: 0.8126 - accuracy: 0.778 - ETA: 8s - loss: 0.8124 - accuracy: 0.778 - ETA: 7s - loss: 0.8114 - accuracy: 0.77 - ETA: 5s - loss: 0.8109 - accuracy: 0.77 - ETA: 3s - loss: 0.8103 - accuracy: 0.77 - ETA: 1s - loss: 0.8092 - accuracy: 0.77 - 303s 16ms/step - loss: 0.8077 - accuracy: 0.7798 - val_loss: 2.0434 - val_accuracy: 0.7300\n",
      "Epoch 84/100\n",
      "19312/19312 [==============================] - ETA: 4:20 - loss: 0.7952 - accuracy: 0.80 - ETA: 4:28 - loss: 0.8565 - accuracy: 0.77 - ETA: 4:23 - loss: 0.8464 - accuracy: 0.76 - ETA: 4:25 - loss: 0.8690 - accuracy: 0.75 - ETA: 4:24 - loss: 0.8770 - accuracy: 0.75 - ETA: 4:24 - loss: 0.8471 - accuracy: 0.75 - ETA: 4:25 - loss: 0.8261 - accuracy: 0.76 - ETA: 4:20 - loss: 0.8448 - accuracy: 0.77 - ETA: 4:17 - loss: 0.8267 - accuracy: 0.77 - ETA: 4:18 - loss: 0.8003 - accuracy: 0.78 - ETA: 4:16 - loss: 0.8442 - accuracy: 0.78 - ETA: 4:14 - loss: 0.8313 - accuracy: 0.78 - ETA: 4:12 - loss: 0.8537 - accuracy: 0.78 - ETA: 4:10 - loss: 0.8486 - accuracy: 0.78 - ETA: 4:09 - loss: 0.8406 - accuracy: 0.78 - ETA: 4:06 - loss: 0.8252 - accuracy: 0.78 - ETA: 4:05 - loss: 0.8325 - accuracy: 0.78 - ETA: 4:04 - loss: 0.8418 - accuracy: 0.78 - ETA: 4:03 - loss: 0.8413 - accuracy: 0.78 - ETA: 4:01 - loss: 0.8299 - accuracy: 0.78 - ETA: 3:59 - loss: 0.8296 - accuracy: 0.78 - ETA: 3:58 - loss: 0.8208 - accuracy: 0.78 - ETA: 3:56 - loss: 0.8212 - accuracy: 0.79 - ETA: 3:55 - loss: 0.8353 - accuracy: 0.78 - ETA: 3:53 - loss: 0.8545 - accuracy: 0.78 - ETA: 3:51 - loss: 0.8514 - accuracy: 0.78 - ETA: 3:50 - loss: 0.8537 - accuracy: 0.78 - ETA: 3:48 - loss: 0.8550 - accuracy: 0.78 - ETA: 3:45 - loss: 0.8612 - accuracy: 0.78 - ETA: 3:43 - loss: 0.8541 - accuracy: 0.78 - ETA: 3:42 - loss: 0.8491 - accuracy: 0.78 - ETA: 3:40 - loss: 0.8412 - accuracy: 0.78 - ETA: 3:38 - loss: 0.8433 - accuracy: 0.78 - ETA: 3:36 - loss: 0.8408 - accuracy: 0.78 - ETA: 3:35 - loss: 0.8331 - accuracy: 0.78 - ETA: 3:33 - loss: 0.8300 - accuracy: 0.78 - ETA: 3:31 - loss: 0.8296 - accuracy: 0.78 - ETA: 3:30 - loss: 0.8274 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8229 - accuracy: 0.78 - ETA: 3:26 - loss: 0.8220 - accuracy: 0.78 - ETA: 3:25 - loss: 0.8240 - accuracy: 0.78 - ETA: 3:23 - loss: 0.8226 - accuracy: 0.78 - ETA: 3:21 - loss: 0.8298 - accuracy: 0.78 - ETA: 3:19 - loss: 0.8266 - accuracy: 0.78 - ETA: 3:18 - loss: 0.8275 - accuracy: 0.78 - ETA: 3:16 - loss: 0.8258 - accuracy: 0.78 - ETA: 3:14 - loss: 0.8298 - accuracy: 0.78 - ETA: 3:12 - loss: 0.8294 - accuracy: 0.78 - ETA: 3:11 - loss: 0.8253 - accuracy: 0.78 - ETA: 3:09 - loss: 0.8278 - accuracy: 0.78 - ETA: 3:07 - loss: 0.8285 - accuracy: 0.78 - ETA: 3:05 - loss: 0.8285 - accuracy: 0.78 - ETA: 3:03 - loss: 0.8304 - accuracy: 0.78 - ETA: 3:01 - loss: 0.8345 - accuracy: 0.78 - ETA: 2:59 - loss: 0.8388 - accuracy: 0.78 - ETA: 2:57 - loss: 0.8392 - accuracy: 0.78 - ETA: 2:56 - loss: 0.8393 - accuracy: 0.78 - ETA: 2:54 - loss: 0.8377 - accuracy: 0.78 - ETA: 2:52 - loss: 0.8365 - accuracy: 0.78 - ETA: 2:50 - loss: 0.8327 - accuracy: 0.78 - ETA: 2:48 - loss: 0.8281 - accuracy: 0.78 - ETA: 2:46 - loss: 0.8271 - accuracy: 0.78 - ETA: 2:44 - loss: 0.8233 - accuracy: 0.78 - ETA: 2:42 - loss: 0.8216 - accuracy: 0.78 - ETA: 2:40 - loss: 0.8229 - accuracy: 0.78 - ETA: 2:38 - loss: 0.8219 - accuracy: 0.78 - ETA: 2:36 - loss: 0.8222 - accuracy: 0.78 - ETA: 2:35 - loss: 0.8212 - accuracy: 0.78 - ETA: 2:33 - loss: 0.8215 - accuracy: 0.78 - ETA: 2:31 - loss: 0.8218 - accuracy: 0.78 - ETA: 2:29 - loss: 0.8201 - accuracy: 0.78 - ETA: 2:27 - loss: 0.8180 - accuracy: 0.78 - ETA: 2:25 - loss: 0.8179 - accuracy: 0.78 - ETA: 2:23 - loss: 0.8181 - accuracy: 0.78 - ETA: 2:21 - loss: 0.8209 - accuracy: 0.78 - ETA: 2:20 - loss: 0.8171 - accuracy: 0.78 - ETA: 2:18 - loss: 0.8155 - accuracy: 0.78 - ETA: 2:16 - loss: 0.8166 - accuracy: 0.78 - ETA: 2:14 - loss: 0.8184 - accuracy: 0.78 - ETA: 2:12 - loss: 0.8200 - accuracy: 0.78 - ETA: 2:10 - loss: 0.8208 - accuracy: 0.78 - ETA: 2:08 - loss: 0.8215 - accuracy: 0.78 - ETA: 2:07 - loss: 0.8217 - accuracy: 0.78 - ETA: 2:05 - loss: 0.8173 - accuracy: 0.78 - ETA: 2:03 - loss: 0.8150 - accuracy: 0.78 - ETA: 2:01 - loss: 0.8127 - accuracy: 0.78 - ETA: 1:59 - loss: 0.8108 - accuracy: 0.78 - ETA: 1:57 - loss: 0.8102 - accuracy: 0.78 - ETA: 1:55 - loss: 0.8085 - accuracy: 0.78 - ETA: 1:53 - loss: 0.8103 - accuracy: 0.78 - ETA: 1:52 - loss: 0.8140 - accuracy: 0.78 - ETA: 1:50 - loss: 0.8130 - accuracy: 0.78 - ETA: 1:48 - loss: 0.8173 - accuracy: 0.78 - ETA: 1:46 - loss: 0.8147 - accuracy: 0.78 - ETA: 1:44 - loss: 0.8131 - accuracy: 0.78 - ETA: 1:42 - loss: 0.8148 - accuracy: 0.78 - ETA: 1:40 - loss: 0.8122 - accuracy: 0.78 - ETA: 1:38 - loss: 0.8145 - accuracy: 0.78 - ETA: 1:36 - loss: 0.8116 - accuracy: 0.78 - ETA: 1:34 - loss: 0.8097 - accuracy: 0.78 - ETA: 1:33 - loss: 0.8086 - accuracy: 0.78 - ETA: 1:31 - loss: 0.8063 - accuracy: 0.78 - ETA: 1:29 - loss: 0.8052 - accuracy: 0.78 - ETA: 1:27 - loss: 0.8065 - accuracy: 0.78 - ETA: 1:25 - loss: 0.8045 - accuracy: 0.78 - ETA: 1:23 - loss: 0.8045 - accuracy: 0.78 - ETA: 1:21 - loss: 0.8041 - accuracy: 0.78 - ETA: 1:19 - loss: 0.8026 - accuracy: 0.78 - ETA: 1:18 - loss: 0.8029 - accuracy: 0.78 - ETA: 1:16 - loss: 0.8023 - accuracy: 0.78 - ETA: 1:14 - loss: 0.8013 - accuracy: 0.78 - ETA: 1:12 - loss: 0.8016 - accuracy: 0.78 - ETA: 1:10 - loss: 0.8018 - accuracy: 0.78 - ETA: 1:08 - loss: 0.8099 - accuracy: 0.78 - ETA: 1:06 - loss: 0.8173 - accuracy: 0.78 - ETA: 1:05 - loss: 0.8170 - accuracy: 0.78 - ETA: 1:03 - loss: 0.8171 - accuracy: 0.78 - ETA: 1:01 - loss: 0.8193 - accuracy: 0.78 - ETA: 59s - loss: 0.8177 - accuracy: 0.7828 - ETA: 57s - loss: 0.8209 - accuracy: 0.782 - ETA: 55s - loss: 0.8194 - accuracy: 0.782 - ETA: 53s - loss: 0.8175 - accuracy: 0.782 - ETA: 52s - loss: 0.8181 - accuracy: 0.783 - ETA: 50s - loss: 0.8161 - accuracy: 0.783 - ETA: 48s - loss: 0.8155 - accuracy: 0.783 - ETA: 46s - loss: 0.8154 - accuracy: 0.783 - ETA: 44s - loss: 0.8153 - accuracy: 0.783 - ETA: 42s - loss: 0.8147 - accuracy: 0.783 - ETA: 40s - loss: 0.8142 - accuracy: 0.783 - ETA: 38s - loss: 0.8174 - accuracy: 0.783 - ETA: 37s - loss: 0.8177 - accuracy: 0.783 - ETA: 35s - loss: 0.8157 - accuracy: 0.783 - ETA: 33s - loss: 0.8152 - accuracy: 0.783 - ETA: 31s - loss: 0.8143 - accuracy: 0.783 - ETA: 29s - loss: 0.8177 - accuracy: 0.783 - ETA: 27s - loss: 0.8178 - accuracy: 0.783 - ETA: 25s - loss: 0.8180 - accuracy: 0.782 - ETA: 24s - loss: 0.8169 - accuracy: 0.782 - ETA: 22s - loss: 0.8163 - accuracy: 0.782 - ETA: 20s - loss: 0.8151 - accuracy: 0.782 - ETA: 18s - loss: 0.8151 - accuracy: 0.782 - ETA: 16s - loss: 0.8146 - accuracy: 0.782 - ETA: 14s - loss: 0.8148 - accuracy: 0.782 - ETA: 12s - loss: 0.8137 - accuracy: 0.782 - ETA: 10s - loss: 0.8138 - accuracy: 0.783 - ETA: 9s - loss: 0.8151 - accuracy: 0.782 - ETA: 7s - loss: 0.8161 - accuracy: 0.78 - ETA: 5s - loss: 0.8163 - accuracy: 0.78 - ETA: 3s - loss: 0.8180 - accuracy: 0.78 - ETA: 1s - loss: 0.8212 - accuracy: 0.78 - 305s 16ms/step - loss: 0.8206 - accuracy: 0.7815 - val_loss: 2.0673 - val_accuracy: 0.7211\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:31 - loss: 0.4206 - accuracy: 0.82 - ETA: 4:32 - loss: 0.5051 - accuracy: 0.81 - ETA: 4:35 - loss: 0.5797 - accuracy: 0.81 - ETA: 4:32 - loss: 0.7024 - accuracy: 0.79 - ETA: 4:32 - loss: 0.7321 - accuracy: 0.80 - ETA: 4:31 - loss: 0.7063 - accuracy: 0.81 - ETA: 4:27 - loss: 0.6947 - accuracy: 0.81 - ETA: 4:26 - loss: 0.7101 - accuracy: 0.81 - ETA: 4:24 - loss: 0.6963 - accuracy: 0.81 - ETA: 4:23 - loss: 0.7092 - accuracy: 0.80 - ETA: 4:22 - loss: 0.6972 - accuracy: 0.81 - ETA: 4:20 - loss: 0.7025 - accuracy: 0.80 - ETA: 4:18 - loss: 0.7068 - accuracy: 0.80 - ETA: 4:15 - loss: 0.7385 - accuracy: 0.79 - ETA: 4:15 - loss: 0.7362 - accuracy: 0.79 - ETA: 4:13 - loss: 0.7676 - accuracy: 0.79 - ETA: 4:11 - loss: 0.7656 - accuracy: 0.79 - ETA: 4:09 - loss: 0.7716 - accuracy: 0.79 - ETA: 4:07 - loss: 0.7778 - accuracy: 0.78 - ETA: 4:05 - loss: 0.7763 - accuracy: 0.78 - ETA: 4:03 - loss: 0.7755 - accuracy: 0.79 - ETA: 4:02 - loss: 0.7737 - accuracy: 0.79 - ETA: 4:00 - loss: 0.7694 - accuracy: 0.79 - ETA: 3:58 - loss: 0.7548 - accuracy: 0.79 - ETA: 3:56 - loss: 0.7595 - accuracy: 0.79 - ETA: 3:54 - loss: 0.7720 - accuracy: 0.78 - ETA: 3:52 - loss: 0.7771 - accuracy: 0.78 - ETA: 3:50 - loss: 0.7760 - accuracy: 0.78 - ETA: 3:48 - loss: 0.7742 - accuracy: 0.78 - ETA: 3:46 - loss: 0.7797 - accuracy: 0.78 - ETA: 3:44 - loss: 0.7772 - accuracy: 0.78 - ETA: 3:42 - loss: 0.7733 - accuracy: 0.78 - ETA: 3:39 - loss: 0.7820 - accuracy: 0.78 - ETA: 3:37 - loss: 0.7860 - accuracy: 0.78 - ETA: 3:35 - loss: 0.7920 - accuracy: 0.78 - ETA: 3:33 - loss: 0.8153 - accuracy: 0.77 - ETA: 3:31 - loss: 0.8144 - accuracy: 0.77 - ETA: 3:29 - loss: 0.8103 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8141 - accuracy: 0.78 - ETA: 3:26 - loss: 0.8096 - accuracy: 0.78 - ETA: 3:24 - loss: 0.8141 - accuracy: 0.78 - ETA: 3:22 - loss: 0.8145 - accuracy: 0.78 - ETA: 3:20 - loss: 0.8185 - accuracy: 0.78 - ETA: 3:18 - loss: 0.8192 - accuracy: 0.77 - ETA: 3:17 - loss: 0.8216 - accuracy: 0.77 - ETA: 3:15 - loss: 0.8237 - accuracy: 0.77 - ETA: 3:13 - loss: 0.8206 - accuracy: 0.77 - ETA: 3:11 - loss: 0.8190 - accuracy: 0.77 - ETA: 3:09 - loss: 0.8195 - accuracy: 0.77 - ETA: 3:08 - loss: 0.8156 - accuracy: 0.77 - ETA: 3:06 - loss: 0.8183 - accuracy: 0.77 - ETA: 3:04 - loss: 0.8163 - accuracy: 0.77 - ETA: 3:02 - loss: 0.8224 - accuracy: 0.77 - ETA: 3:00 - loss: 0.8206 - accuracy: 0.77 - ETA: 2:59 - loss: 0.8272 - accuracy: 0.77 - ETA: 2:57 - loss: 0.8230 - accuracy: 0.77 - ETA: 2:55 - loss: 0.8250 - accuracy: 0.77 - ETA: 2:53 - loss: 0.8250 - accuracy: 0.77 - ETA: 2:51 - loss: 0.8270 - accuracy: 0.77 - ETA: 2:49 - loss: 0.8290 - accuracy: 0.77 - ETA: 2:47 - loss: 0.8276 - accuracy: 0.77 - ETA: 2:45 - loss: 0.8256 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8221 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8263 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8218 - accuracy: 0.77 - ETA: 2:38 - loss: 0.8181 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8221 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8259 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8230 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8231 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8208 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8209 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8220 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8242 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8232 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8316 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8327 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8298 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8325 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8310 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8339 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8342 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8320 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8294 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8246 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8218 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8190 - accuracy: 0.78 - ETA: 1:57 - loss: 0.8170 - accuracy: 0.78 - ETA: 1:55 - loss: 0.8162 - accuracy: 0.78 - ETA: 1:53 - loss: 0.8163 - accuracy: 0.78 - ETA: 1:51 - loss: 0.8176 - accuracy: 0.78 - ETA: 1:49 - loss: 0.8186 - accuracy: 0.78 - ETA: 1:47 - loss: 0.8206 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8211 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8211 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8220 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8199 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8183 - accuracy: 0.78 - ETA: 1:36 - loss: 0.8193 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8177 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8170 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8200 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8201 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8205 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8232 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8225 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8209 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8199 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8187 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8188 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8219 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8215 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8204 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8207 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8176 - accuracy: 0.78 - ETA: 1:05 - loss: 0.8205 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8213 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8220 - accuracy: 0.77 - ETA: 59s - loss: 0.8200 - accuracy: 0.7799 - ETA: 57s - loss: 0.8198 - accuracy: 0.779 - ETA: 55s - loss: 0.8222 - accuracy: 0.779 - ETA: 53s - loss: 0.8217 - accuracy: 0.779 - ETA: 52s - loss: 0.8224 - accuracy: 0.779 - ETA: 50s - loss: 0.8233 - accuracy: 0.778 - ETA: 48s - loss: 0.8240 - accuracy: 0.778 - ETA: 46s - loss: 0.8250 - accuracy: 0.778 - ETA: 44s - loss: 0.8316 - accuracy: 0.778 - ETA: 42s - loss: 0.8322 - accuracy: 0.777 - ETA: 40s - loss: 0.8325 - accuracy: 0.777 - ETA: 38s - loss: 0.8313 - accuracy: 0.777 - ETA: 37s - loss: 0.8292 - accuracy: 0.777 - ETA: 35s - loss: 0.8287 - accuracy: 0.777 - ETA: 33s - loss: 0.8313 - accuracy: 0.777 - ETA: 31s - loss: 0.8323 - accuracy: 0.777 - ETA: 29s - loss: 0.8323 - accuracy: 0.777 - ETA: 27s - loss: 0.8301 - accuracy: 0.777 - ETA: 25s - loss: 0.8282 - accuracy: 0.778 - ETA: 24s - loss: 0.8265 - accuracy: 0.778 - ETA: 22s - loss: 0.8258 - accuracy: 0.778 - ETA: 20s - loss: 0.8260 - accuracy: 0.778 - ETA: 18s - loss: 0.8240 - accuracy: 0.778 - ETA: 16s - loss: 0.8232 - accuracy: 0.778 - ETA: 14s - loss: 0.8241 - accuracy: 0.778 - ETA: 12s - loss: 0.8232 - accuracy: 0.778 - ETA: 10s - loss: 0.8225 - accuracy: 0.778 - ETA: 9s - loss: 0.8213 - accuracy: 0.778 - ETA: 7s - loss: 0.8215 - accuracy: 0.77 - ETA: 5s - loss: 0.8227 - accuracy: 0.77 - ETA: 3s - loss: 0.8247 - accuracy: 0.77 - ETA: 1s - loss: 0.8241 - accuracy: 0.77 - 307s 16ms/step - loss: 0.8226 - accuracy: 0.7782 - val_loss: 2.1698 - val_accuracy: 0.7291\n",
      "Epoch 86/100\n",
      "19312/19312 [==============================] - ETA: 4:40 - loss: 0.8139 - accuracy: 0.78 - ETA: 3:58 - loss: 0.8198 - accuracy: 0.78 - ETA: 3:43 - loss: 0.8736 - accuracy: 0.78 - ETA: 3:49 - loss: 0.8322 - accuracy: 0.79 - ETA: 3:58 - loss: 0.8479 - accuracy: 0.79 - ETA: 4:02 - loss: 0.7892 - accuracy: 0.80 - ETA: 4:06 - loss: 0.7921 - accuracy: 0.80 - ETA: 4:08 - loss: 0.7984 - accuracy: 0.80 - ETA: 4:10 - loss: 0.8070 - accuracy: 0.80 - ETA: 4:10 - loss: 0.7996 - accuracy: 0.79 - ETA: 4:07 - loss: 0.8063 - accuracy: 0.79 - ETA: 4:07 - loss: 0.7965 - accuracy: 0.79 - ETA: 4:07 - loss: 0.8161 - accuracy: 0.78 - ETA: 4:06 - loss: 0.8363 - accuracy: 0.78 - ETA: 4:04 - loss: 0.8203 - accuracy: 0.78 - ETA: 4:03 - loss: 0.8435 - accuracy: 0.78 - ETA: 4:02 - loss: 0.8382 - accuracy: 0.78 - ETA: 4:00 - loss: 0.8317 - accuracy: 0.78 - ETA: 3:58 - loss: 0.8477 - accuracy: 0.77 - ETA: 3:56 - loss: 0.8463 - accuracy: 0.77 - ETA: 3:54 - loss: 0.8361 - accuracy: 0.77 - ETA: 3:52 - loss: 0.8343 - accuracy: 0.78 - ETA: 3:50 - loss: 0.8298 - accuracy: 0.78 - ETA: 3:49 - loss: 0.8313 - accuracy: 0.77 - ETA: 3:48 - loss: 0.8275 - accuracy: 0.77 - ETA: 3:46 - loss: 0.8307 - accuracy: 0.78 - ETA: 3:45 - loss: 0.8502 - accuracy: 0.77 - ETA: 3:42 - loss: 0.8465 - accuracy: 0.77 - ETA: 3:41 - loss: 0.8433 - accuracy: 0.78 - ETA: 3:39 - loss: 0.8309 - accuracy: 0.78 - ETA: 3:37 - loss: 0.8304 - accuracy: 0.78 - ETA: 3:36 - loss: 0.8302 - accuracy: 0.78 - ETA: 3:35 - loss: 0.8273 - accuracy: 0.78 - ETA: 3:33 - loss: 0.8223 - accuracy: 0.78 - ETA: 3:31 - loss: 0.8131 - accuracy: 0.78 - ETA: 3:29 - loss: 0.8096 - accuracy: 0.78 - ETA: 3:27 - loss: 0.8133 - accuracy: 0.78 - ETA: 3:25 - loss: 0.8110 - accuracy: 0.78 - ETA: 3:23 - loss: 0.8102 - accuracy: 0.78 - ETA: 3:21 - loss: 0.8064 - accuracy: 0.78 - ETA: 3:20 - loss: 0.8094 - accuracy: 0.78 - ETA: 3:18 - loss: 0.8070 - accuracy: 0.78 - ETA: 3:17 - loss: 0.8055 - accuracy: 0.78 - ETA: 3:15 - loss: 0.8056 - accuracy: 0.78 - ETA: 3:13 - loss: 0.8076 - accuracy: 0.78 - ETA: 3:12 - loss: 0.8101 - accuracy: 0.77 - ETA: 3:10 - loss: 0.8101 - accuracy: 0.77 - ETA: 3:08 - loss: 0.8099 - accuracy: 0.77 - ETA: 3:07 - loss: 0.8068 - accuracy: 0.78 - ETA: 3:05 - loss: 0.8069 - accuracy: 0.78 - ETA: 3:03 - loss: 0.8013 - accuracy: 0.78 - ETA: 3:02 - loss: 0.8025 - accuracy: 0.78 - ETA: 3:00 - loss: 0.8008 - accuracy: 0.78 - ETA: 2:58 - loss: 0.8017 - accuracy: 0.78 - ETA: 2:56 - loss: 0.7966 - accuracy: 0.78 - ETA: 2:54 - loss: 0.7960 - accuracy: 0.78 - ETA: 2:52 - loss: 0.7933 - accuracy: 0.78 - ETA: 2:51 - loss: 0.7921 - accuracy: 0.78 - ETA: 2:49 - loss: 0.7875 - accuracy: 0.78 - ETA: 2:47 - loss: 0.7928 - accuracy: 0.78 - ETA: 2:45 - loss: 0.7921 - accuracy: 0.78 - ETA: 2:43 - loss: 0.7954 - accuracy: 0.78 - ETA: 2:41 - loss: 0.7903 - accuracy: 0.78 - ETA: 2:39 - loss: 0.7960 - accuracy: 0.78 - ETA: 2:37 - loss: 0.7964 - accuracy: 0.78 - ETA: 2:36 - loss: 0.7983 - accuracy: 0.78 - ETA: 2:34 - loss: 0.8028 - accuracy: 0.78 - ETA: 2:32 - loss: 0.7979 - accuracy: 0.78 - ETA: 2:30 - loss: 0.7949 - accuracy: 0.78 - ETA: 2:28 - loss: 0.7936 - accuracy: 0.78 - ETA: 2:26 - loss: 0.7932 - accuracy: 0.78 - ETA: 2:24 - loss: 0.7945 - accuracy: 0.78 - ETA: 2:23 - loss: 0.7990 - accuracy: 0.78 - ETA: 2:21 - loss: 0.8006 - accuracy: 0.78 - ETA: 2:19 - loss: 0.7979 - accuracy: 0.78 - ETA: 2:17 - loss: 0.8029 - accuracy: 0.78 - ETA: 2:16 - loss: 0.8045 - accuracy: 0.78 - ETA: 2:14 - loss: 0.8031 - accuracy: 0.78 - ETA: 2:12 - loss: 0.8037 - accuracy: 0.78 - ETA: 2:10 - loss: 0.8043 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8026 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8031 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8016 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8010 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8002 - accuracy: 0.77 - ETA: 1:59 - loss: 0.7994 - accuracy: 0.77 - ETA: 1:57 - loss: 0.7951 - accuracy: 0.77 - ETA: 1:56 - loss: 0.7961 - accuracy: 0.77 - ETA: 1:54 - loss: 0.7972 - accuracy: 0.77 - ETA: 1:52 - loss: 0.7947 - accuracy: 0.77 - ETA: 1:50 - loss: 0.7948 - accuracy: 0.78 - ETA: 1:48 - loss: 0.7959 - accuracy: 0.78 - ETA: 1:46 - loss: 0.7933 - accuracy: 0.78 - ETA: 1:45 - loss: 0.7982 - accuracy: 0.77 - ETA: 1:43 - loss: 0.7952 - accuracy: 0.78 - ETA: 1:41 - loss: 0.7946 - accuracy: 0.78 - ETA: 1:39 - loss: 0.7966 - accuracy: 0.78 - ETA: 1:37 - loss: 0.7990 - accuracy: 0.78 - ETA: 1:35 - loss: 0.7993 - accuracy: 0.78 - ETA: 1:34 - loss: 0.7989 - accuracy: 0.78 - ETA: 1:32 - loss: 0.7987 - accuracy: 0.78 - ETA: 1:30 - loss: 0.8004 - accuracy: 0.77 - ETA: 1:28 - loss: 0.7985 - accuracy: 0.78 - ETA: 1:26 - loss: 0.7966 - accuracy: 0.78 - ETA: 1:24 - loss: 0.7974 - accuracy: 0.78 - ETA: 1:22 - loss: 0.7997 - accuracy: 0.77 - ETA: 1:21 - loss: 0.7988 - accuracy: 0.77 - ETA: 1:19 - loss: 0.7994 - accuracy: 0.78 - ETA: 1:17 - loss: 0.7978 - accuracy: 0.78 - ETA: 1:15 - loss: 0.7974 - accuracy: 0.78 - ETA: 1:13 - loss: 0.7994 - accuracy: 0.78 - ETA: 1:11 - loss: 0.7998 - accuracy: 0.78 - ETA: 1:10 - loss: 0.8021 - accuracy: 0.78 - ETA: 1:08 - loss: 0.8032 - accuracy: 0.78 - ETA: 1:06 - loss: 0.8042 - accuracy: 0.78 - ETA: 1:04 - loss: 0.8014 - accuracy: 0.78 - ETA: 1:02 - loss: 0.8015 - accuracy: 0.78 - ETA: 1:00 - loss: 0.8010 - accuracy: 0.78 - ETA: 59s - loss: 0.7970 - accuracy: 0.7827 - ETA: 57s - loss: 0.7964 - accuracy: 0.782 - ETA: 55s - loss: 0.7966 - accuracy: 0.782 - ETA: 53s - loss: 0.7953 - accuracy: 0.782 - ETA: 51s - loss: 0.7931 - accuracy: 0.782 - ETA: 49s - loss: 0.7947 - accuracy: 0.782 - ETA: 47s - loss: 0.7939 - accuracy: 0.782 - ETA: 46s - loss: 0.7939 - accuracy: 0.782 - ETA: 44s - loss: 0.7926 - accuracy: 0.783 - ETA: 42s - loss: 0.7902 - accuracy: 0.783 - ETA: 40s - loss: 0.7899 - accuracy: 0.783 - ETA: 38s - loss: 0.7937 - accuracy: 0.783 - ETA: 36s - loss: 0.7964 - accuracy: 0.783 - ETA: 34s - loss: 0.7949 - accuracy: 0.783 - ETA: 33s - loss: 0.7959 - accuracy: 0.783 - ETA: 31s - loss: 0.7963 - accuracy: 0.782 - ETA: 29s - loss: 0.7962 - accuracy: 0.782 - ETA: 27s - loss: 0.7951 - accuracy: 0.783 - ETA: 25s - loss: 0.7955 - accuracy: 0.783 - ETA: 23s - loss: 0.7969 - accuracy: 0.783 - ETA: 21s - loss: 0.7959 - accuracy: 0.783 - ETA: 20s - loss: 0.7948 - accuracy: 0.783 - ETA: 18s - loss: 0.7948 - accuracy: 0.783 - ETA: 16s - loss: 0.7963 - accuracy: 0.783 - ETA: 14s - loss: 0.7984 - accuracy: 0.783 - ETA: 12s - loss: 0.8008 - accuracy: 0.782 - ETA: 10s - loss: 0.8022 - accuracy: 0.782 - ETA: 9s - loss: 0.8018 - accuracy: 0.782 - ETA: 7s - loss: 0.8041 - accuracy: 0.78 - ETA: 5s - loss: 0.8028 - accuracy: 0.78 - ETA: 3s - loss: 0.8081 - accuracy: 0.78 - ETA: 1s - loss: 0.8107 - accuracy: 0.78 - 304s 16ms/step - loss: 0.8110 - accuracy: 0.7807 - val_loss: 2.1373 - val_accuracy: 0.7260\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:43 - loss: 0.6269 - accuracy: 0.80 - ETA: 4:35 - loss: 0.7420 - accuracy: 0.76 - ETA: 4:37 - loss: 0.7598 - accuracy: 0.76 - ETA: 4:31 - loss: 0.8128 - accuracy: 0.76 - ETA: 4:35 - loss: 0.7434 - accuracy: 0.78 - ETA: 4:32 - loss: 0.6867 - accuracy: 0.80 - ETA: 4:29 - loss: 0.7106 - accuracy: 0.79 - ETA: 4:27 - loss: 0.7246 - accuracy: 0.78 - ETA: 4:27 - loss: 0.7099 - accuracy: 0.79 - ETA: 4:24 - loss: 0.7483 - accuracy: 0.78 - ETA: 4:23 - loss: 0.7848 - accuracy: 0.78 - ETA: 4:20 - loss: 0.7819 - accuracy: 0.78 - ETA: 4:18 - loss: 0.7920 - accuracy: 0.77 - ETA: 4:17 - loss: 0.7880 - accuracy: 0.78 - ETA: 4:14 - loss: 0.7766 - accuracy: 0.78 - ETA: 4:11 - loss: 0.7788 - accuracy: 0.78 - ETA: 4:10 - loss: 0.7865 - accuracy: 0.78 - ETA: 4:07 - loss: 0.7977 - accuracy: 0.77 - ETA: 4:05 - loss: 0.7928 - accuracy: 0.78 - ETA: 4:03 - loss: 0.8044 - accuracy: 0.77 - ETA: 4:01 - loss: 0.8059 - accuracy: 0.77 - ETA: 3:59 - loss: 0.7997 - accuracy: 0.77 - ETA: 3:56 - loss: 0.8083 - accuracy: 0.77 - ETA: 3:54 - loss: 0.8035 - accuracy: 0.77 - ETA: 3:52 - loss: 0.7994 - accuracy: 0.77 - ETA: 3:50 - loss: 0.8038 - accuracy: 0.77 - ETA: 3:48 - loss: 0.8015 - accuracy: 0.77 - ETA: 3:46 - loss: 0.8008 - accuracy: 0.77 - ETA: 3:44 - loss: 0.7924 - accuracy: 0.77 - ETA: 3:42 - loss: 0.7891 - accuracy: 0.77 - ETA: 3:40 - loss: 0.7818 - accuracy: 0.77 - ETA: 3:39 - loss: 0.7763 - accuracy: 0.78 - ETA: 3:37 - loss: 0.7717 - accuracy: 0.78 - ETA: 3:35 - loss: 0.7732 - accuracy: 0.78 - ETA: 3:33 - loss: 0.7784 - accuracy: 0.78 - ETA: 3:31 - loss: 0.7748 - accuracy: 0.78 - ETA: 3:29 - loss: 0.7775 - accuracy: 0.78 - ETA: 3:27 - loss: 0.7683 - accuracy: 0.78 - ETA: 3:26 - loss: 0.7710 - accuracy: 0.78 - ETA: 3:24 - loss: 0.7713 - accuracy: 0.78 - ETA: 3:22 - loss: 0.7702 - accuracy: 0.78 - ETA: 3:21 - loss: 0.7654 - accuracy: 0.78 - ETA: 3:19 - loss: 0.7683 - accuracy: 0.78 - ETA: 3:17 - loss: 0.7664 - accuracy: 0.78 - ETA: 3:15 - loss: 0.7705 - accuracy: 0.78 - ETA: 3:13 - loss: 0.7679 - accuracy: 0.78 - ETA: 3:12 - loss: 0.7722 - accuracy: 0.78 - ETA: 3:10 - loss: 0.7762 - accuracy: 0.78 - ETA: 3:08 - loss: 0.7763 - accuracy: 0.78 - ETA: 3:07 - loss: 0.7871 - accuracy: 0.78 - ETA: 3:05 - loss: 0.7852 - accuracy: 0.78 - ETA: 3:03 - loss: 0.7817 - accuracy: 0.78 - ETA: 3:01 - loss: 0.7856 - accuracy: 0.78 - ETA: 2:59 - loss: 0.7862 - accuracy: 0.78 - ETA: 2:58 - loss: 0.7834 - accuracy: 0.78 - ETA: 2:56 - loss: 0.7825 - accuracy: 0.78 - ETA: 2:54 - loss: 0.7801 - accuracy: 0.78 - ETA: 2:52 - loss: 0.7873 - accuracy: 0.78 - ETA: 2:50 - loss: 0.7888 - accuracy: 0.78 - ETA: 2:48 - loss: 0.7868 - accuracy: 0.78 - ETA: 2:46 - loss: 0.7863 - accuracy: 0.78 - ETA: 2:44 - loss: 0.7899 - accuracy: 0.77 - ETA: 2:43 - loss: 0.7881 - accuracy: 0.78 - ETA: 2:41 - loss: 0.7884 - accuracy: 0.77 - ETA: 2:39 - loss: 0.7875 - accuracy: 0.77 - ETA: 2:37 - loss: 0.7889 - accuracy: 0.77 - ETA: 2:35 - loss: 0.7884 - accuracy: 0.77 - ETA: 2:34 - loss: 0.7867 - accuracy: 0.78 - ETA: 2:32 - loss: 0.7849 - accuracy: 0.78 - ETA: 2:30 - loss: 0.7868 - accuracy: 0.78 - ETA: 2:28 - loss: 0.7871 - accuracy: 0.77 - ETA: 2:26 - loss: 0.7865 - accuracy: 0.77 - ETA: 2:25 - loss: 0.7860 - accuracy: 0.77 - ETA: 2:23 - loss: 0.7823 - accuracy: 0.78 - ETA: 2:21 - loss: 0.7803 - accuracy: 0.78 - ETA: 2:19 - loss: 0.7817 - accuracy: 0.78 - ETA: 2:17 - loss: 0.7807 - accuracy: 0.78 - ETA: 2:15 - loss: 0.7801 - accuracy: 0.78 - ETA: 2:13 - loss: 0.7822 - accuracy: 0.78 - ETA: 2:11 - loss: 0.7797 - accuracy: 0.78 - ETA: 2:10 - loss: 0.7771 - accuracy: 0.78 - ETA: 2:08 - loss: 0.7741 - accuracy: 0.78 - ETA: 2:06 - loss: 0.7751 - accuracy: 0.78 - ETA: 2:04 - loss: 0.7750 - accuracy: 0.78 - ETA: 2:02 - loss: 0.7781 - accuracy: 0.78 - ETA: 2:00 - loss: 0.7769 - accuracy: 0.78 - ETA: 1:58 - loss: 0.7772 - accuracy: 0.78 - ETA: 1:57 - loss: 0.7802 - accuracy: 0.78 - ETA: 1:55 - loss: 0.7807 - accuracy: 0.78 - ETA: 1:53 - loss: 0.7807 - accuracy: 0.78 - ETA: 1:51 - loss: 0.7783 - accuracy: 0.78 - ETA: 1:49 - loss: 0.7793 - accuracy: 0.78 - ETA: 1:47 - loss: 0.7801 - accuracy: 0.78 - ETA: 1:45 - loss: 0.7784 - accuracy: 0.78 - ETA: 1:44 - loss: 0.7791 - accuracy: 0.78 - ETA: 1:42 - loss: 0.7774 - accuracy: 0.78 - ETA: 1:40 - loss: 0.7785 - accuracy: 0.78 - ETA: 1:38 - loss: 0.7816 - accuracy: 0.78 - ETA: 1:36 - loss: 0.7820 - accuracy: 0.78 - ETA: 1:34 - loss: 0.7818 - accuracy: 0.78 - ETA: 1:32 - loss: 0.7828 - accuracy: 0.78 - ETA: 1:31 - loss: 0.7828 - accuracy: 0.78 - ETA: 1:29 - loss: 0.7816 - accuracy: 0.78 - ETA: 1:27 - loss: 0.7849 - accuracy: 0.78 - ETA: 1:25 - loss: 0.7872 - accuracy: 0.78 - ETA: 1:23 - loss: 0.7866 - accuracy: 0.78 - ETA: 1:21 - loss: 0.7861 - accuracy: 0.77 - ETA: 1:19 - loss: 0.7853 - accuracy: 0.77 - ETA: 1:18 - loss: 0.7840 - accuracy: 0.78 - ETA: 1:16 - loss: 0.7821 - accuracy: 0.78 - ETA: 1:14 - loss: 0.7826 - accuracy: 0.78 - ETA: 1:12 - loss: 0.7820 - accuracy: 0.78 - ETA: 1:10 - loss: 0.7821 - accuracy: 0.78 - ETA: 1:08 - loss: 0.7837 - accuracy: 0.78 - ETA: 1:06 - loss: 0.7825 - accuracy: 0.78 - ETA: 1:05 - loss: 0.7805 - accuracy: 0.78 - ETA: 1:03 - loss: 0.7826 - accuracy: 0.78 - ETA: 1:01 - loss: 0.7822 - accuracy: 0.78 - ETA: 59s - loss: 0.7840 - accuracy: 0.7807 - ETA: 57s - loss: 0.7837 - accuracy: 0.780 - ETA: 55s - loss: 0.7817 - accuracy: 0.781 - ETA: 53s - loss: 0.7802 - accuracy: 0.781 - ETA: 52s - loss: 0.7788 - accuracy: 0.781 - ETA: 50s - loss: 0.7793 - accuracy: 0.781 - ETA: 48s - loss: 0.7798 - accuracy: 0.781 - ETA: 46s - loss: 0.7805 - accuracy: 0.782 - ETA: 44s - loss: 0.7806 - accuracy: 0.781 - ETA: 42s - loss: 0.7817 - accuracy: 0.781 - ETA: 40s - loss: 0.7806 - accuracy: 0.781 - ETA: 38s - loss: 0.7796 - accuracy: 0.781 - ETA: 37s - loss: 0.7808 - accuracy: 0.781 - ETA: 35s - loss: 0.7843 - accuracy: 0.780 - ETA: 33s - loss: 0.7837 - accuracy: 0.780 - ETA: 31s - loss: 0.7840 - accuracy: 0.780 - ETA: 29s - loss: 0.7836 - accuracy: 0.781 - ETA: 27s - loss: 0.7826 - accuracy: 0.781 - ETA: 25s - loss: 0.7850 - accuracy: 0.781 - ETA: 24s - loss: 0.7857 - accuracy: 0.781 - ETA: 22s - loss: 0.7874 - accuracy: 0.781 - ETA: 20s - loss: 0.7860 - accuracy: 0.781 - ETA: 18s - loss: 0.7865 - accuracy: 0.781 - ETA: 16s - loss: 0.7861 - accuracy: 0.781 - ETA: 14s - loss: 0.7871 - accuracy: 0.780 - ETA: 12s - loss: 0.7865 - accuracy: 0.780 - ETA: 10s - loss: 0.7850 - accuracy: 0.781 - ETA: 9s - loss: 0.7841 - accuracy: 0.781 - ETA: 7s - loss: 0.7850 - accuracy: 0.78 - ETA: 5s - loss: 0.7832 - accuracy: 0.78 - ETA: 3s - loss: 0.7819 - accuracy: 0.78 - ETA: 1s - loss: 0.7845 - accuracy: 0.78 - 307s 16ms/step - loss: 0.7839 - accuracy: 0.7818 - val_loss: 2.3285 - val_accuracy: 0.7258\n",
      "Epoch 88/100\n",
      "19312/19312 [==============================] - ETA: 4:42 - loss: 0.9602 - accuracy: 0.78 - ETA: 4:29 - loss: 1.3212 - accuracy: 0.73 - ETA: 4:34 - loss: 1.1425 - accuracy: 0.75 - ETA: 4:32 - loss: 1.0681 - accuracy: 0.75 - ETA: 4:31 - loss: 1.0371 - accuracy: 0.76 - ETA: 4:28 - loss: 0.9896 - accuracy: 0.76 - ETA: 4:27 - loss: 0.9671 - accuracy: 0.76 - ETA: 4:24 - loss: 0.9547 - accuracy: 0.75 - ETA: 4:21 - loss: 0.9118 - accuracy: 0.76 - ETA: 4:21 - loss: 0.8846 - accuracy: 0.77 - ETA: 4:19 - loss: 0.8841 - accuracy: 0.77 - ETA: 4:17 - loss: 0.8524 - accuracy: 0.77 - ETA: 4:17 - loss: 0.8394 - accuracy: 0.77 - ETA: 4:15 - loss: 0.8367 - accuracy: 0.78 - ETA: 4:12 - loss: 0.8448 - accuracy: 0.77 - ETA: 4:11 - loss: 0.8556 - accuracy: 0.77 - ETA: 4:09 - loss: 0.8382 - accuracy: 0.77 - ETA: 4:06 - loss: 0.8474 - accuracy: 0.77 - ETA: 4:04 - loss: 0.8302 - accuracy: 0.77 - ETA: 4:02 - loss: 0.8217 - accuracy: 0.77 - ETA: 4:00 - loss: 0.8443 - accuracy: 0.78 - ETA: 3:58 - loss: 0.8605 - accuracy: 0.77 - ETA: 3:56 - loss: 0.8567 - accuracy: 0.77 - ETA: 3:54 - loss: 0.8643 - accuracy: 0.77 - ETA: 3:52 - loss: 0.8648 - accuracy: 0.77 - ETA: 3:50 - loss: 0.8567 - accuracy: 0.77 - ETA: 3:46 - loss: 0.8423 - accuracy: 0.77 - ETA: 3:45 - loss: 0.8413 - accuracy: 0.77 - ETA: 3:43 - loss: 0.8439 - accuracy: 0.77 - ETA: 3:42 - loss: 0.8403 - accuracy: 0.77 - ETA: 3:40 - loss: 0.8400 - accuracy: 0.77 - ETA: 3:38 - loss: 0.8421 - accuracy: 0.77 - ETA: 3:37 - loss: 0.8407 - accuracy: 0.77 - ETA: 3:35 - loss: 0.8409 - accuracy: 0.77 - ETA: 3:33 - loss: 0.8295 - accuracy: 0.78 - ETA: 3:32 - loss: 0.8264 - accuracy: 0.78 - ETA: 3:30 - loss: 0.8272 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8308 - accuracy: 0.78 - ETA: 3:26 - loss: 0.8260 - accuracy: 0.78 - ETA: 3:24 - loss: 0.8294 - accuracy: 0.78 - ETA: 3:23 - loss: 0.8266 - accuracy: 0.78 - ETA: 3:21 - loss: 0.8274 - accuracy: 0.78 - ETA: 3:19 - loss: 0.8287 - accuracy: 0.78 - ETA: 3:17 - loss: 0.8246 - accuracy: 0.78 - ETA: 3:15 - loss: 0.8249 - accuracy: 0.78 - ETA: 3:13 - loss: 0.8271 - accuracy: 0.78 - ETA: 3:11 - loss: 0.8227 - accuracy: 0.78 - ETA: 3:09 - loss: 0.8191 - accuracy: 0.78 - ETA: 3:07 - loss: 0.8325 - accuracy: 0.78 - ETA: 3:06 - loss: 0.8277 - accuracy: 0.78 - ETA: 3:04 - loss: 0.8271 - accuracy: 0.78 - ETA: 3:02 - loss: 0.8348 - accuracy: 0.78 - ETA: 3:00 - loss: 0.8336 - accuracy: 0.78 - ETA: 2:59 - loss: 0.8351 - accuracy: 0.78 - ETA: 2:57 - loss: 0.8319 - accuracy: 0.78 - ETA: 2:55 - loss: 0.8308 - accuracy: 0.78 - ETA: 2:53 - loss: 0.8249 - accuracy: 0.78 - ETA: 2:51 - loss: 0.8296 - accuracy: 0.78 - ETA: 2:49 - loss: 0.8339 - accuracy: 0.78 - ETA: 2:47 - loss: 0.8358 - accuracy: 0.78 - ETA: 2:45 - loss: 0.8341 - accuracy: 0.78 - ETA: 2:44 - loss: 0.8310 - accuracy: 0.78 - ETA: 2:42 - loss: 0.8279 - accuracy: 0.78 - ETA: 2:40 - loss: 0.8288 - accuracy: 0.78 - ETA: 2:38 - loss: 0.8322 - accuracy: 0.78 - ETA: 2:36 - loss: 0.8317 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8505 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8482 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8445 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8458 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8438 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8447 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8428 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8418 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8419 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8384 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8416 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8392 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8372 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8409 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8385 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8428 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8411 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8442 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8435 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8449 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8438 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8434 - accuracy: 0.77 - ETA: 1:54 - loss: 0.8413 - accuracy: 0.77 - ETA: 1:52 - loss: 0.8400 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8375 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8385 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8347 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8356 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8358 - accuracy: 0.77 - ETA: 1:41 - loss: 0.8357 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8356 - accuracy: 0.77 - ETA: 1:37 - loss: 0.8365 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8358 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8329 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8313 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8317 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8317 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8319 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8343 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8344 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8351 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8375 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8386 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8383 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8372 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8378 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8375 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8371 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8374 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8361 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8381 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8366 - accuracy: 0.77 - ETA: 59s - loss: 0.8347 - accuracy: 0.7779 - ETA: 57s - loss: 0.8355 - accuracy: 0.777 - ETA: 55s - loss: 0.8351 - accuracy: 0.777 - ETA: 53s - loss: 0.8343 - accuracy: 0.777 - ETA: 51s - loss: 0.8344 - accuracy: 0.777 - ETA: 49s - loss: 0.8344 - accuracy: 0.777 - ETA: 47s - loss: 0.8322 - accuracy: 0.778 - ETA: 46s - loss: 0.8309 - accuracy: 0.778 - ETA: 44s - loss: 0.8292 - accuracy: 0.778 - ETA: 42s - loss: 0.8278 - accuracy: 0.778 - ETA: 40s - loss: 0.8272 - accuracy: 0.778 - ETA: 38s - loss: 0.8270 - accuracy: 0.778 - ETA: 36s - loss: 0.8274 - accuracy: 0.778 - ETA: 34s - loss: 0.8266 - accuracy: 0.778 - ETA: 33s - loss: 0.8262 - accuracy: 0.778 - ETA: 31s - loss: 0.8277 - accuracy: 0.777 - ETA: 29s - loss: 0.8285 - accuracy: 0.777 - ETA: 27s - loss: 0.8266 - accuracy: 0.778 - ETA: 25s - loss: 0.8274 - accuracy: 0.778 - ETA: 23s - loss: 0.8257 - accuracy: 0.778 - ETA: 22s - loss: 0.8247 - accuracy: 0.778 - ETA: 20s - loss: 0.8233 - accuracy: 0.778 - ETA: 18s - loss: 0.8226 - accuracy: 0.778 - ETA: 16s - loss: 0.8236 - accuracy: 0.777 - ETA: 14s - loss: 0.8237 - accuracy: 0.777 - ETA: 12s - loss: 0.8253 - accuracy: 0.777 - ETA: 10s - loss: 0.8250 - accuracy: 0.777 - ETA: 9s - loss: 0.8263 - accuracy: 0.777 - ETA: 7s - loss: 0.8275 - accuracy: 0.77 - ETA: 5s - loss: 0.8284 - accuracy: 0.77 - ETA: 3s - loss: 0.8269 - accuracy: 0.77 - ETA: 1s - loss: 0.8294 - accuracy: 0.77 - 306s 16ms/step - loss: 0.8313 - accuracy: 0.7766 - val_loss: 2.3651 - val_accuracy: 0.7194\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:16 - loss: 0.5079 - accuracy: 0.82 - ETA: 4:40 - loss: 0.6381 - accuracy: 0.80 - ETA: 4:35 - loss: 0.7597 - accuracy: 0.77 - ETA: 4:35 - loss: 0.7745 - accuracy: 0.77 - ETA: 4:32 - loss: 0.7954 - accuracy: 0.75 - ETA: 4:29 - loss: 0.7740 - accuracy: 0.76 - ETA: 4:26 - loss: 0.7988 - accuracy: 0.76 - ETA: 4:23 - loss: 0.8226 - accuracy: 0.76 - ETA: 4:21 - loss: 0.7886 - accuracy: 0.77 - ETA: 4:18 - loss: 0.7899 - accuracy: 0.77 - ETA: 4:17 - loss: 0.8111 - accuracy: 0.76 - ETA: 4:16 - loss: 0.7914 - accuracy: 0.77 - ETA: 4:16 - loss: 0.8006 - accuracy: 0.77 - ETA: 4:13 - loss: 0.7956 - accuracy: 0.77 - ETA: 4:12 - loss: 0.7943 - accuracy: 0.77 - ETA: 4:10 - loss: 0.8087 - accuracy: 0.76 - ETA: 4:09 - loss: 0.7972 - accuracy: 0.76 - ETA: 4:07 - loss: 0.8039 - accuracy: 0.77 - ETA: 4:06 - loss: 0.8015 - accuracy: 0.77 - ETA: 4:04 - loss: 0.7957 - accuracy: 0.77 - ETA: 4:02 - loss: 0.8068 - accuracy: 0.77 - ETA: 4:00 - loss: 0.8025 - accuracy: 0.77 - ETA: 3:58 - loss: 0.7916 - accuracy: 0.77 - ETA: 3:56 - loss: 0.7848 - accuracy: 0.77 - ETA: 3:54 - loss: 0.7964 - accuracy: 0.77 - ETA: 3:52 - loss: 0.7927 - accuracy: 0.77 - ETA: 3:50 - loss: 0.7967 - accuracy: 0.77 - ETA: 3:48 - loss: 0.7966 - accuracy: 0.77 - ETA: 3:47 - loss: 0.8039 - accuracy: 0.77 - ETA: 3:45 - loss: 0.8100 - accuracy: 0.77 - ETA: 3:43 - loss: 0.8118 - accuracy: 0.77 - ETA: 3:41 - loss: 0.8248 - accuracy: 0.77 - ETA: 3:39 - loss: 0.8206 - accuracy: 0.77 - ETA: 3:38 - loss: 0.8241 - accuracy: 0.77 - ETA: 3:36 - loss: 0.8222 - accuracy: 0.77 - ETA: 3:34 - loss: 0.8210 - accuracy: 0.77 - ETA: 3:32 - loss: 0.8194 - accuracy: 0.77 - ETA: 3:31 - loss: 0.8168 - accuracy: 0.77 - ETA: 3:29 - loss: 0.8102 - accuracy: 0.77 - ETA: 3:27 - loss: 0.8105 - accuracy: 0.77 - ETA: 3:25 - loss: 0.8249 - accuracy: 0.77 - ETA: 3:23 - loss: 0.8289 - accuracy: 0.77 - ETA: 3:21 - loss: 0.8262 - accuracy: 0.77 - ETA: 3:19 - loss: 0.8290 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8309 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8337 - accuracy: 0.77 - ETA: 3:14 - loss: 0.8345 - accuracy: 0.76 - ETA: 3:12 - loss: 0.8332 - accuracy: 0.76 - ETA: 3:10 - loss: 0.8377 - accuracy: 0.76 - ETA: 3:08 - loss: 0.8379 - accuracy: 0.76 - ETA: 3:06 - loss: 0.8358 - accuracy: 0.76 - ETA: 3:04 - loss: 0.8389 - accuracy: 0.76 - ETA: 3:02 - loss: 0.8387 - accuracy: 0.76 - ETA: 3:00 - loss: 0.8390 - accuracy: 0.76 - ETA: 2:58 - loss: 0.8398 - accuracy: 0.76 - ETA: 2:56 - loss: 0.8401 - accuracy: 0.76 - ETA: 2:54 - loss: 0.8399 - accuracy: 0.76 - ETA: 2:53 - loss: 0.8465 - accuracy: 0.76 - ETA: 2:51 - loss: 0.8432 - accuracy: 0.76 - ETA: 2:49 - loss: 0.8426 - accuracy: 0.76 - ETA: 2:47 - loss: 0.8422 - accuracy: 0.76 - ETA: 2:45 - loss: 0.8440 - accuracy: 0.76 - ETA: 2:43 - loss: 0.8428 - accuracy: 0.76 - ETA: 2:41 - loss: 0.8391 - accuracy: 0.76 - ETA: 2:39 - loss: 0.8432 - accuracy: 0.76 - ETA: 2:38 - loss: 0.8412 - accuracy: 0.76 - ETA: 2:36 - loss: 0.8398 - accuracy: 0.76 - ETA: 2:34 - loss: 0.8436 - accuracy: 0.76 - ETA: 2:32 - loss: 0.8439 - accuracy: 0.76 - ETA: 2:30 - loss: 0.8431 - accuracy: 0.76 - ETA: 2:28 - loss: 0.8419 - accuracy: 0.76 - ETA: 2:27 - loss: 0.8426 - accuracy: 0.76 - ETA: 2:25 - loss: 0.8441 - accuracy: 0.76 - ETA: 2:23 - loss: 0.8454 - accuracy: 0.76 - ETA: 2:21 - loss: 0.8436 - accuracy: 0.76 - ETA: 2:19 - loss: 0.8446 - accuracy: 0.76 - ETA: 2:17 - loss: 0.8447 - accuracy: 0.76 - ETA: 2:16 - loss: 0.8514 - accuracy: 0.76 - ETA: 2:14 - loss: 0.8500 - accuracy: 0.76 - ETA: 2:12 - loss: 0.8490 - accuracy: 0.76 - ETA: 2:10 - loss: 0.8513 - accuracy: 0.76 - ETA: 2:08 - loss: 0.8505 - accuracy: 0.76 - ETA: 2:06 - loss: 0.8545 - accuracy: 0.76 - ETA: 2:04 - loss: 0.8538 - accuracy: 0.76 - ETA: 2:02 - loss: 0.8562 - accuracy: 0.76 - ETA: 2:00 - loss: 0.8522 - accuracy: 0.76 - ETA: 1:58 - loss: 0.8508 - accuracy: 0.76 - ETA: 1:57 - loss: 0.8505 - accuracy: 0.76 - ETA: 1:55 - loss: 0.8519 - accuracy: 0.76 - ETA: 1:53 - loss: 0.8529 - accuracy: 0.76 - ETA: 1:51 - loss: 0.8519 - accuracy: 0.76 - ETA: 1:49 - loss: 0.8513 - accuracy: 0.76 - ETA: 1:48 - loss: 0.8500 - accuracy: 0.76 - ETA: 1:46 - loss: 0.8500 - accuracy: 0.76 - ETA: 1:44 - loss: 0.8481 - accuracy: 0.76 - ETA: 1:42 - loss: 0.8484 - accuracy: 0.76 - ETA: 1:40 - loss: 0.8464 - accuracy: 0.76 - ETA: 1:38 - loss: 0.8480 - accuracy: 0.76 - ETA: 1:37 - loss: 0.8501 - accuracy: 0.76 - ETA: 1:35 - loss: 0.8478 - accuracy: 0.76 - ETA: 1:33 - loss: 0.8475 - accuracy: 0.76 - ETA: 1:31 - loss: 0.8455 - accuracy: 0.76 - ETA: 1:29 - loss: 0.8461 - accuracy: 0.76 - ETA: 1:27 - loss: 0.8426 - accuracy: 0.76 - ETA: 1:25 - loss: 0.8414 - accuracy: 0.76 - ETA: 1:24 - loss: 0.8415 - accuracy: 0.76 - ETA: 1:22 - loss: 0.8425 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8418 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8412 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8402 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8413 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8390 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8402 - accuracy: 0.76 - ETA: 1:09 - loss: 0.8393 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8399 - accuracy: 0.76 - ETA: 1:05 - loss: 0.8380 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8372 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8368 - accuracy: 0.77 - ETA: 59s - loss: 0.8368 - accuracy: 0.7707 - ETA: 57s - loss: 0.8366 - accuracy: 0.770 - ETA: 55s - loss: 0.8372 - accuracy: 0.770 - ETA: 54s - loss: 0.8367 - accuracy: 0.770 - ETA: 52s - loss: 0.8352 - accuracy: 0.770 - ETA: 50s - loss: 0.8362 - accuracy: 0.770 - ETA: 48s - loss: 0.8366 - accuracy: 0.769 - ETA: 46s - loss: 0.8398 - accuracy: 0.769 - ETA: 44s - loss: 0.8371 - accuracy: 0.770 - ETA: 42s - loss: 0.8347 - accuracy: 0.770 - ETA: 40s - loss: 0.8330 - accuracy: 0.771 - ETA: 39s - loss: 0.8337 - accuracy: 0.771 - ETA: 37s - loss: 0.8335 - accuracy: 0.771 - ETA: 35s - loss: 0.8316 - accuracy: 0.771 - ETA: 33s - loss: 0.8300 - accuracy: 0.771 - ETA: 31s - loss: 0.8284 - accuracy: 0.772 - ETA: 29s - loss: 0.8286 - accuracy: 0.772 - ETA: 27s - loss: 0.8302 - accuracy: 0.772 - ETA: 25s - loss: 0.8294 - accuracy: 0.772 - ETA: 24s - loss: 0.8283 - accuracy: 0.772 - ETA: 22s - loss: 0.8279 - accuracy: 0.773 - ETA: 20s - loss: 0.8277 - accuracy: 0.773 - ETA: 18s - loss: 0.8264 - accuracy: 0.773 - ETA: 16s - loss: 0.8246 - accuracy: 0.773 - ETA: 14s - loss: 0.8263 - accuracy: 0.773 - ETA: 12s - loss: 0.8266 - accuracy: 0.773 - ETA: 10s - loss: 0.8278 - accuracy: 0.773 - ETA: 9s - loss: 0.8289 - accuracy: 0.773 - ETA: 7s - loss: 0.8287 - accuracy: 0.77 - ETA: 5s - loss: 0.8286 - accuracy: 0.77 - ETA: 3s - loss: 0.8288 - accuracy: 0.77 - ETA: 1s - loss: 0.8271 - accuracy: 0.77 - 308s 16ms/step - loss: 0.8261 - accuracy: 0.7735 - val_loss: 2.1362 - val_accuracy: 0.7300\n",
      "Epoch 90/100\n",
      "19312/19312 [==============================] - ETA: 4:51 - loss: 0.7894 - accuracy: 0.78 - ETA: 4:41 - loss: 0.6768 - accuracy: 0.79 - ETA: 4:41 - loss: 0.7606 - accuracy: 0.80 - ETA: 4:41 - loss: 0.7453 - accuracy: 0.81 - ETA: 4:38 - loss: 0.7660 - accuracy: 0.80 - ETA: 4:32 - loss: 0.7655 - accuracy: 0.79 - ETA: 4:31 - loss: 0.7883 - accuracy: 0.79 - ETA: 4:30 - loss: 0.7515 - accuracy: 0.79 - ETA: 4:27 - loss: 0.8202 - accuracy: 0.78 - ETA: 4:25 - loss: 0.8173 - accuracy: 0.78 - ETA: 4:24 - loss: 0.7944 - accuracy: 0.78 - ETA: 4:19 - loss: 0.8095 - accuracy: 0.78 - ETA: 4:17 - loss: 0.7978 - accuracy: 0.78 - ETA: 4:15 - loss: 0.7849 - accuracy: 0.78 - ETA: 4:14 - loss: 0.7685 - accuracy: 0.78 - ETA: 4:12 - loss: 0.7667 - accuracy: 0.78 - ETA: 4:11 - loss: 0.7551 - accuracy: 0.79 - ETA: 4:08 - loss: 0.7625 - accuracy: 0.78 - ETA: 4:06 - loss: 0.7694 - accuracy: 0.78 - ETA: 4:05 - loss: 0.7532 - accuracy: 0.79 - ETA: 4:03 - loss: 0.7532 - accuracy: 0.79 - ETA: 4:01 - loss: 0.7507 - accuracy: 0.79 - ETA: 4:00 - loss: 0.7464 - accuracy: 0.79 - ETA: 3:58 - loss: 0.7463 - accuracy: 0.79 - ETA: 3:56 - loss: 0.7421 - accuracy: 0.79 - ETA: 3:53 - loss: 0.7526 - accuracy: 0.79 - ETA: 3:51 - loss: 0.7533 - accuracy: 0.79 - ETA: 3:50 - loss: 0.7427 - accuracy: 0.79 - ETA: 3:48 - loss: 0.7467 - accuracy: 0.79 - ETA: 3:47 - loss: 0.7560 - accuracy: 0.79 - ETA: 3:45 - loss: 0.7510 - accuracy: 0.79 - ETA: 3:44 - loss: 0.7452 - accuracy: 0.79 - ETA: 3:42 - loss: 0.7460 - accuracy: 0.79 - ETA: 3:40 - loss: 0.7518 - accuracy: 0.78 - ETA: 3:38 - loss: 0.7540 - accuracy: 0.78 - ETA: 3:37 - loss: 0.7518 - accuracy: 0.78 - ETA: 3:34 - loss: 0.7538 - accuracy: 0.78 - ETA: 3:32 - loss: 0.7512 - accuracy: 0.78 - ETA: 3:30 - loss: 0.7508 - accuracy: 0.78 - ETA: 3:28 - loss: 0.7603 - accuracy: 0.78 - ETA: 3:27 - loss: 0.7703 - accuracy: 0.78 - ETA: 3:25 - loss: 0.7676 - accuracy: 0.78 - ETA: 3:23 - loss: 0.7641 - accuracy: 0.78 - ETA: 3:21 - loss: 0.7693 - accuracy: 0.78 - ETA: 3:19 - loss: 0.7628 - accuracy: 0.78 - ETA: 3:17 - loss: 0.7638 - accuracy: 0.78 - ETA: 3:15 - loss: 0.7664 - accuracy: 0.78 - ETA: 3:13 - loss: 0.7713 - accuracy: 0.78 - ETA: 3:12 - loss: 0.7676 - accuracy: 0.78 - ETA: 3:10 - loss: 0.7686 - accuracy: 0.78 - ETA: 3:08 - loss: 0.7700 - accuracy: 0.78 - ETA: 3:06 - loss: 0.7794 - accuracy: 0.78 - ETA: 3:04 - loss: 0.7769 - accuracy: 0.78 - ETA: 3:02 - loss: 0.7705 - accuracy: 0.78 - ETA: 3:00 - loss: 0.7663 - accuracy: 0.78 - ETA: 2:58 - loss: 0.7640 - accuracy: 0.78 - ETA: 2:56 - loss: 0.7627 - accuracy: 0.78 - ETA: 2:54 - loss: 0.7680 - accuracy: 0.78 - ETA: 2:52 - loss: 0.7646 - accuracy: 0.78 - ETA: 2:51 - loss: 0.7626 - accuracy: 0.78 - ETA: 2:48 - loss: 0.7661 - accuracy: 0.78 - ETA: 2:47 - loss: 0.7621 - accuracy: 0.79 - ETA: 2:45 - loss: 0.7622 - accuracy: 0.79 - ETA: 2:43 - loss: 0.7617 - accuracy: 0.79 - ETA: 2:41 - loss: 0.7604 - accuracy: 0.79 - ETA: 2:39 - loss: 0.7609 - accuracy: 0.79 - ETA: 2:37 - loss: 0.7652 - accuracy: 0.78 - ETA: 2:35 - loss: 0.7601 - accuracy: 0.78 - ETA: 2:33 - loss: 0.7606 - accuracy: 0.78 - ETA: 2:32 - loss: 0.7581 - accuracy: 0.78 - ETA: 2:30 - loss: 0.7593 - accuracy: 0.78 - ETA: 2:28 - loss: 0.7609 - accuracy: 0.78 - ETA: 2:26 - loss: 0.7615 - accuracy: 0.78 - ETA: 2:24 - loss: 0.7610 - accuracy: 0.78 - ETA: 2:22 - loss: 0.7614 - accuracy: 0.78 - ETA: 2:20 - loss: 0.7608 - accuracy: 0.78 - ETA: 2:18 - loss: 0.7651 - accuracy: 0.78 - ETA: 2:16 - loss: 0.7689 - accuracy: 0.78 - ETA: 2:14 - loss: 0.7669 - accuracy: 0.78 - ETA: 2:13 - loss: 0.7666 - accuracy: 0.78 - ETA: 2:11 - loss: 0.7716 - accuracy: 0.78 - ETA: 2:09 - loss: 0.7750 - accuracy: 0.78 - ETA: 2:07 - loss: 0.7752 - accuracy: 0.78 - ETA: 2:05 - loss: 0.7764 - accuracy: 0.78 - ETA: 2:03 - loss: 0.7756 - accuracy: 0.78 - ETA: 2:01 - loss: 0.7747 - accuracy: 0.78 - ETA: 1:59 - loss: 0.7745 - accuracy: 0.78 - ETA: 1:57 - loss: 0.7775 - accuracy: 0.78 - ETA: 1:55 - loss: 0.7783 - accuracy: 0.78 - ETA: 1:54 - loss: 0.7762 - accuracy: 0.78 - ETA: 1:52 - loss: 0.7770 - accuracy: 0.78 - ETA: 1:50 - loss: 0.7778 - accuracy: 0.78 - ETA: 1:48 - loss: 0.7768 - accuracy: 0.78 - ETA: 1:46 - loss: 0.7823 - accuracy: 0.78 - ETA: 1:44 - loss: 0.7821 - accuracy: 0.78 - ETA: 1:42 - loss: 0.7815 - accuracy: 0.78 - ETA: 1:40 - loss: 0.7819 - accuracy: 0.78 - ETA: 1:39 - loss: 0.7843 - accuracy: 0.78 - ETA: 1:37 - loss: 0.7828 - accuracy: 0.78 - ETA: 1:35 - loss: 0.7821 - accuracy: 0.78 - ETA: 1:33 - loss: 0.7826 - accuracy: 0.78 - ETA: 1:31 - loss: 0.7840 - accuracy: 0.78 - ETA: 1:29 - loss: 0.7831 - accuracy: 0.78 - ETA: 1:27 - loss: 0.7821 - accuracy: 0.78 - ETA: 1:25 - loss: 0.7826 - accuracy: 0.78 - ETA: 1:23 - loss: 0.7850 - accuracy: 0.78 - ETA: 1:22 - loss: 0.7843 - accuracy: 0.78 - ETA: 1:20 - loss: 0.7834 - accuracy: 0.78 - ETA: 1:18 - loss: 0.7831 - accuracy: 0.78 - ETA: 1:16 - loss: 0.7830 - accuracy: 0.78 - ETA: 1:14 - loss: 0.7833 - accuracy: 0.78 - ETA: 1:12 - loss: 0.7878 - accuracy: 0.78 - ETA: 1:10 - loss: 0.7883 - accuracy: 0.78 - ETA: 1:09 - loss: 0.7865 - accuracy: 0.78 - ETA: 1:07 - loss: 0.7868 - accuracy: 0.78 - ETA: 1:05 - loss: 0.7884 - accuracy: 0.78 - ETA: 1:03 - loss: 0.7894 - accuracy: 0.78 - ETA: 1:01 - loss: 0.7873 - accuracy: 0.78 - ETA: 59s - loss: 0.7853 - accuracy: 0.7861 - ETA: 57s - loss: 0.7875 - accuracy: 0.785 - ETA: 55s - loss: 0.7900 - accuracy: 0.785 - ETA: 54s - loss: 0.7890 - accuracy: 0.785 - ETA: 52s - loss: 0.7883 - accuracy: 0.785 - ETA: 50s - loss: 0.7884 - accuracy: 0.785 - ETA: 48s - loss: 0.7912 - accuracy: 0.785 - ETA: 46s - loss: 0.7902 - accuracy: 0.785 - ETA: 44s - loss: 0.7931 - accuracy: 0.784 - ETA: 42s - loss: 0.7922 - accuracy: 0.784 - ETA: 40s - loss: 0.7916 - accuracy: 0.784 - ETA: 39s - loss: 0.7910 - accuracy: 0.784 - ETA: 37s - loss: 0.7929 - accuracy: 0.783 - ETA: 35s - loss: 0.7906 - accuracy: 0.784 - ETA: 33s - loss: 0.7906 - accuracy: 0.784 - ETA: 31s - loss: 0.7913 - accuracy: 0.783 - ETA: 29s - loss: 0.7926 - accuracy: 0.783 - ETA: 27s - loss: 0.7933 - accuracy: 0.783 - ETA: 25s - loss: 0.7912 - accuracy: 0.784 - ETA: 24s - loss: 0.7915 - accuracy: 0.784 - ETA: 22s - loss: 0.7902 - accuracy: 0.784 - ETA: 20s - loss: 0.7908 - accuracy: 0.784 - ETA: 18s - loss: 0.7911 - accuracy: 0.784 - ETA: 16s - loss: 0.7926 - accuracy: 0.783 - ETA: 14s - loss: 0.7909 - accuracy: 0.784 - ETA: 12s - loss: 0.7884 - accuracy: 0.784 - ETA: 10s - loss: 0.7893 - accuracy: 0.784 - ETA: 9s - loss: 0.7889 - accuracy: 0.784 - ETA: 7s - loss: 0.7882 - accuracy: 0.78 - ETA: 5s - loss: 0.7909 - accuracy: 0.78 - ETA: 3s - loss: 0.7900 - accuracy: 0.78 - ETA: 1s - loss: 0.7883 - accuracy: 0.78 - 308s 16ms/step - loss: 0.7868 - accuracy: 0.7847 - val_loss: 2.0196 - val_accuracy: 0.7291\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:46 - loss: 0.7008 - accuracy: 0.79 - ETA: 4:39 - loss: 0.6464 - accuracy: 0.80 - ETA: 4:41 - loss: 0.6289 - accuracy: 0.80 - ETA: 4:36 - loss: 0.6371 - accuracy: 0.79 - ETA: 4:38 - loss: 0.6305 - accuracy: 0.79 - ETA: 4:33 - loss: 0.6697 - accuracy: 0.79 - ETA: 4:31 - loss: 0.6614 - accuracy: 0.79 - ETA: 4:30 - loss: 0.7843 - accuracy: 0.79 - ETA: 4:25 - loss: 0.7757 - accuracy: 0.79 - ETA: 4:22 - loss: 0.7822 - accuracy: 0.78 - ETA: 4:22 - loss: 0.7561 - accuracy: 0.79 - ETA: 4:20 - loss: 0.7834 - accuracy: 0.79 - ETA: 4:17 - loss: 0.7748 - accuracy: 0.79 - ETA: 4:14 - loss: 0.7716 - accuracy: 0.79 - ETA: 4:13 - loss: 0.7769 - accuracy: 0.78 - ETA: 4:12 - loss: 0.7667 - accuracy: 0.79 - ETA: 4:09 - loss: 0.7596 - accuracy: 0.79 - ETA: 4:08 - loss: 0.7676 - accuracy: 0.79 - ETA: 4:06 - loss: 0.7708 - accuracy: 0.79 - ETA: 4:04 - loss: 0.7653 - accuracy: 0.79 - ETA: 4:02 - loss: 0.7828 - accuracy: 0.78 - ETA: 3:59 - loss: 0.7724 - accuracy: 0.79 - ETA: 3:57 - loss: 0.7676 - accuracy: 0.79 - ETA: 3:55 - loss: 0.7656 - accuracy: 0.79 - ETA: 3:53 - loss: 0.7580 - accuracy: 0.79 - ETA: 3:51 - loss: 0.7576 - accuracy: 0.79 - ETA: 3:50 - loss: 0.7618 - accuracy: 0.79 - ETA: 3:49 - loss: 0.7668 - accuracy: 0.78 - ETA: 3:47 - loss: 0.7667 - accuracy: 0.78 - ETA: 3:45 - loss: 0.7607 - accuracy: 0.79 - ETA: 3:43 - loss: 0.7553 - accuracy: 0.79 - ETA: 3:41 - loss: 0.7635 - accuracy: 0.79 - ETA: 3:40 - loss: 0.7598 - accuracy: 0.79 - ETA: 3:38 - loss: 0.7488 - accuracy: 0.79 - ETA: 3:36 - loss: 0.7456 - accuracy: 0.79 - ETA: 3:34 - loss: 0.7466 - accuracy: 0.79 - ETA: 3:32 - loss: 0.7432 - accuracy: 0.79 - ETA: 3:30 - loss: 0.7468 - accuracy: 0.79 - ETA: 3:28 - loss: 0.7621 - accuracy: 0.78 - ETA: 3:26 - loss: 0.7594 - accuracy: 0.79 - ETA: 3:24 - loss: 0.7538 - accuracy: 0.79 - ETA: 3:22 - loss: 0.7579 - accuracy: 0.79 - ETA: 3:21 - loss: 0.7549 - accuracy: 0.79 - ETA: 3:19 - loss: 0.7560 - accuracy: 0.79 - ETA: 3:17 - loss: 0.7549 - accuracy: 0.79 - ETA: 3:16 - loss: 0.7586 - accuracy: 0.79 - ETA: 3:14 - loss: 0.7582 - accuracy: 0.79 - ETA: 3:12 - loss: 0.7606 - accuracy: 0.78 - ETA: 3:10 - loss: 0.7571 - accuracy: 0.78 - ETA: 3:08 - loss: 0.7511 - accuracy: 0.79 - ETA: 3:06 - loss: 0.7473 - accuracy: 0.79 - ETA: 3:04 - loss: 0.7450 - accuracy: 0.79 - ETA: 3:02 - loss: 0.7454 - accuracy: 0.79 - ETA: 3:00 - loss: 0.7439 - accuracy: 0.79 - ETA: 2:58 - loss: 0.7455 - accuracy: 0.79 - ETA: 2:57 - loss: 0.7504 - accuracy: 0.79 - ETA: 2:55 - loss: 0.7534 - accuracy: 0.79 - ETA: 2:53 - loss: 0.7506 - accuracy: 0.79 - ETA: 2:51 - loss: 0.7523 - accuracy: 0.79 - ETA: 2:49 - loss: 0.7554 - accuracy: 0.79 - ETA: 2:47 - loss: 0.7530 - accuracy: 0.79 - ETA: 2:45 - loss: 0.7560 - accuracy: 0.79 - ETA: 2:44 - loss: 0.7558 - accuracy: 0.79 - ETA: 2:42 - loss: 0.7582 - accuracy: 0.79 - ETA: 2:40 - loss: 0.7579 - accuracy: 0.79 - ETA: 2:38 - loss: 0.7625 - accuracy: 0.79 - ETA: 2:36 - loss: 0.7624 - accuracy: 0.78 - ETA: 2:34 - loss: 0.7611 - accuracy: 0.78 - ETA: 2:32 - loss: 0.7620 - accuracy: 0.78 - ETA: 2:30 - loss: 0.7587 - accuracy: 0.79 - ETA: 2:29 - loss: 0.7577 - accuracy: 0.79 - ETA: 2:27 - loss: 0.7646 - accuracy: 0.79 - ETA: 2:25 - loss: 0.7648 - accuracy: 0.79 - ETA: 2:23 - loss: 0.7650 - accuracy: 0.79 - ETA: 2:21 - loss: 0.7689 - accuracy: 0.78 - ETA: 2:19 - loss: 0.7711 - accuracy: 0.78 - ETA: 2:17 - loss: 0.7750 - accuracy: 0.78 - ETA: 2:15 - loss: 0.7770 - accuracy: 0.78 - ETA: 2:13 - loss: 0.7785 - accuracy: 0.78 - ETA: 2:11 - loss: 0.7769 - accuracy: 0.78 - ETA: 2:10 - loss: 0.7785 - accuracy: 0.78 - ETA: 2:08 - loss: 0.7767 - accuracy: 0.78 - ETA: 2:06 - loss: 0.7786 - accuracy: 0.78 - ETA: 2:04 - loss: 0.7780 - accuracy: 0.78 - ETA: 2:02 - loss: 0.7821 - accuracy: 0.78 - ETA: 2:00 - loss: 0.7812 - accuracy: 0.78 - ETA: 1:59 - loss: 0.7821 - accuracy: 0.78 - ETA: 1:57 - loss: 0.7811 - accuracy: 0.78 - ETA: 1:55 - loss: 0.7796 - accuracy: 0.78 - ETA: 1:53 - loss: 0.7781 - accuracy: 0.78 - ETA: 1:51 - loss: 0.7785 - accuracy: 0.78 - ETA: 1:49 - loss: 0.7801 - accuracy: 0.78 - ETA: 1:47 - loss: 0.7847 - accuracy: 0.78 - ETA: 1:46 - loss: 0.7856 - accuracy: 0.78 - ETA: 1:44 - loss: 0.7836 - accuracy: 0.78 - ETA: 1:42 - loss: 0.7826 - accuracy: 0.78 - ETA: 1:40 - loss: 0.7825 - accuracy: 0.78 - ETA: 1:38 - loss: 0.7817 - accuracy: 0.78 - ETA: 1:36 - loss: 0.7839 - accuracy: 0.78 - ETA: 1:35 - loss: 0.7841 - accuracy: 0.78 - ETA: 1:33 - loss: 0.7828 - accuracy: 0.78 - ETA: 1:31 - loss: 0.7849 - accuracy: 0.78 - ETA: 1:29 - loss: 0.7828 - accuracy: 0.78 - ETA: 1:27 - loss: 0.7839 - accuracy: 0.78 - ETA: 1:25 - loss: 0.7850 - accuracy: 0.78 - ETA: 1:23 - loss: 0.7856 - accuracy: 0.78 - ETA: 1:21 - loss: 0.7862 - accuracy: 0.78 - ETA: 1:20 - loss: 0.7846 - accuracy: 0.78 - ETA: 1:18 - loss: 0.7835 - accuracy: 0.78 - ETA: 1:16 - loss: 0.7863 - accuracy: 0.78 - ETA: 1:14 - loss: 0.7857 - accuracy: 0.78 - ETA: 1:12 - loss: 0.7847 - accuracy: 0.78 - ETA: 1:10 - loss: 0.7861 - accuracy: 0.78 - ETA: 1:08 - loss: 0.7931 - accuracy: 0.78 - ETA: 1:07 - loss: 0.7952 - accuracy: 0.78 - ETA: 1:05 - loss: 0.7941 - accuracy: 0.78 - ETA: 1:03 - loss: 0.7945 - accuracy: 0.78 - ETA: 1:01 - loss: 0.7950 - accuracy: 0.78 - ETA: 59s - loss: 0.7967 - accuracy: 0.7841 - ETA: 57s - loss: 0.7964 - accuracy: 0.784 - ETA: 55s - loss: 0.7944 - accuracy: 0.784 - ETA: 54s - loss: 0.7914 - accuracy: 0.784 - ETA: 52s - loss: 0.7910 - accuracy: 0.784 - ETA: 50s - loss: 0.7892 - accuracy: 0.785 - ETA: 48s - loss: 0.7871 - accuracy: 0.785 - ETA: 46s - loss: 0.7879 - accuracy: 0.785 - ETA: 44s - loss: 0.7889 - accuracy: 0.784 - ETA: 42s - loss: 0.7874 - accuracy: 0.784 - ETA: 40s - loss: 0.7874 - accuracy: 0.784 - ETA: 39s - loss: 0.7886 - accuracy: 0.783 - ETA: 37s - loss: 0.7888 - accuracy: 0.783 - ETA: 35s - loss: 0.7891 - accuracy: 0.783 - ETA: 33s - loss: 0.7891 - accuracy: 0.783 - ETA: 31s - loss: 0.7917 - accuracy: 0.783 - ETA: 29s - loss: 0.7899 - accuracy: 0.783 - ETA: 27s - loss: 0.7898 - accuracy: 0.783 - ETA: 25s - loss: 0.7914 - accuracy: 0.783 - ETA: 24s - loss: 0.7907 - accuracy: 0.783 - ETA: 22s - loss: 0.7903 - accuracy: 0.783 - ETA: 20s - loss: 0.7913 - accuracy: 0.783 - ETA: 18s - loss: 0.7902 - accuracy: 0.784 - ETA: 16s - loss: 0.7938 - accuracy: 0.783 - ETA: 14s - loss: 0.7935 - accuracy: 0.783 - ETA: 12s - loss: 0.7939 - accuracy: 0.783 - ETA: 10s - loss: 0.7918 - accuracy: 0.784 - ETA: 9s - loss: 0.7911 - accuracy: 0.783 - ETA: 7s - loss: 0.7915 - accuracy: 0.78 - ETA: 5s - loss: 0.7900 - accuracy: 0.78 - ETA: 3s - loss: 0.7899 - accuracy: 0.78 - ETA: 1s - loss: 0.7900 - accuracy: 0.78 - 308s 16ms/step - loss: 0.7896 - accuracy: 0.7843 - val_loss: 1.9751 - val_accuracy: 0.7264\n",
      "Epoch 92/100\n",
      "19312/19312 [==============================] - ETA: 4:38 - loss: 0.7656 - accuracy: 0.77 - ETA: 4:29 - loss: 0.6482 - accuracy: 0.79 - ETA: 4:23 - loss: 0.7503 - accuracy: 0.77 - ETA: 4:21 - loss: 0.7220 - accuracy: 0.78 - ETA: 4:21 - loss: 0.7290 - accuracy: 0.77 - ETA: 4:20 - loss: 0.7252 - accuracy: 0.77 - ETA: 4:19 - loss: 0.7213 - accuracy: 0.77 - ETA: 4:19 - loss: 0.7192 - accuracy: 0.77 - ETA: 4:18 - loss: 0.7257 - accuracy: 0.77 - ETA: 4:17 - loss: 0.7365 - accuracy: 0.77 - ETA: 4:15 - loss: 0.7665 - accuracy: 0.77 - ETA: 4:13 - loss: 0.7711 - accuracy: 0.77 - ETA: 4:12 - loss: 0.7918 - accuracy: 0.77 - ETA: 4:11 - loss: 0.7770 - accuracy: 0.77 - ETA: 4:10 - loss: 0.7789 - accuracy: 0.77 - ETA: 4:08 - loss: 0.7805 - accuracy: 0.77 - ETA: 4:06 - loss: 0.7916 - accuracy: 0.77 - ETA: 4:04 - loss: 0.8114 - accuracy: 0.77 - ETA: 4:02 - loss: 0.8090 - accuracy: 0.77 - ETA: 4:00 - loss: 0.8013 - accuracy: 0.77 - ETA: 3:58 - loss: 0.8103 - accuracy: 0.77 - ETA: 3:57 - loss: 0.8125 - accuracy: 0.77 - ETA: 3:55 - loss: 0.8060 - accuracy: 0.77 - ETA: 3:53 - loss: 0.8025 - accuracy: 0.77 - ETA: 3:51 - loss: 0.7972 - accuracy: 0.77 - ETA: 3:50 - loss: 0.7839 - accuracy: 0.77 - ETA: 3:48 - loss: 0.7800 - accuracy: 0.77 - ETA: 3:47 - loss: 0.7904 - accuracy: 0.77 - ETA: 3:45 - loss: 0.7897 - accuracy: 0.77 - ETA: 3:43 - loss: 0.7922 - accuracy: 0.77 - ETA: 3:41 - loss: 0.7870 - accuracy: 0.77 - ETA: 3:39 - loss: 0.7885 - accuracy: 0.77 - ETA: 3:37 - loss: 0.7881 - accuracy: 0.77 - ETA: 3:35 - loss: 0.7869 - accuracy: 0.77 - ETA: 3:34 - loss: 0.8002 - accuracy: 0.77 - ETA: 3:31 - loss: 0.8007 - accuracy: 0.77 - ETA: 3:30 - loss: 0.7952 - accuracy: 0.77 - ETA: 3:28 - loss: 0.7974 - accuracy: 0.77 - ETA: 3:26 - loss: 0.8056 - accuracy: 0.77 - ETA: 3:24 - loss: 0.8048 - accuracy: 0.77 - ETA: 3:22 - loss: 0.8086 - accuracy: 0.77 - ETA: 3:20 - loss: 0.8180 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8179 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8136 - accuracy: 0.77 - ETA: 3:14 - loss: 0.8105 - accuracy: 0.77 - ETA: 3:13 - loss: 0.8074 - accuracy: 0.77 - ETA: 3:11 - loss: 0.8020 - accuracy: 0.77 - ETA: 3:09 - loss: 0.8026 - accuracy: 0.77 - ETA: 3:07 - loss: 0.8052 - accuracy: 0.77 - ETA: 3:05 - loss: 0.8027 - accuracy: 0.77 - ETA: 3:03 - loss: 0.8000 - accuracy: 0.77 - ETA: 3:01 - loss: 0.7991 - accuracy: 0.77 - ETA: 3:00 - loss: 0.7984 - accuracy: 0.77 - ETA: 2:58 - loss: 0.8032 - accuracy: 0.77 - ETA: 2:56 - loss: 0.8002 - accuracy: 0.77 - ETA: 2:54 - loss: 0.7969 - accuracy: 0.77 - ETA: 2:52 - loss: 0.7969 - accuracy: 0.77 - ETA: 2:50 - loss: 0.7977 - accuracy: 0.77 - ETA: 2:48 - loss: 0.7943 - accuracy: 0.77 - ETA: 2:46 - loss: 0.7902 - accuracy: 0.77 - ETA: 2:45 - loss: 0.7971 - accuracy: 0.78 - ETA: 2:43 - loss: 0.7960 - accuracy: 0.78 - ETA: 2:41 - loss: 0.7924 - accuracy: 0.78 - ETA: 2:39 - loss: 0.7905 - accuracy: 0.78 - ETA: 2:37 - loss: 0.7966 - accuracy: 0.78 - ETA: 2:36 - loss: 0.7981 - accuracy: 0.78 - ETA: 2:34 - loss: 0.8039 - accuracy: 0.78 - ETA: 2:32 - loss: 0.8011 - accuracy: 0.78 - ETA: 2:30 - loss: 0.8025 - accuracy: 0.78 - ETA: 2:28 - loss: 0.8062 - accuracy: 0.78 - ETA: 2:26 - loss: 0.8066 - accuracy: 0.78 - ETA: 2:24 - loss: 0.8085 - accuracy: 0.78 - ETA: 2:22 - loss: 0.8085 - accuracy: 0.78 - ETA: 2:21 - loss: 0.8070 - accuracy: 0.78 - ETA: 2:19 - loss: 0.8119 - accuracy: 0.78 - ETA: 2:17 - loss: 0.8155 - accuracy: 0.78 - ETA: 2:15 - loss: 0.8153 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8150 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8155 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8161 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8156 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8153 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8142 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8100 - accuracy: 0.78 - ETA: 2:01 - loss: 0.8097 - accuracy: 0.78 - ETA: 1:59 - loss: 0.8151 - accuracy: 0.78 - ETA: 1:57 - loss: 0.8120 - accuracy: 0.78 - ETA: 1:55 - loss: 0.8134 - accuracy: 0.78 - ETA: 1:53 - loss: 0.8122 - accuracy: 0.78 - ETA: 1:52 - loss: 0.8155 - accuracy: 0.78 - ETA: 1:50 - loss: 0.8173 - accuracy: 0.78 - ETA: 1:48 - loss: 0.8206 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8232 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8230 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8220 - accuracy: 0.78 - ETA: 1:41 - loss: 0.8248 - accuracy: 0.77 - ETA: 1:39 - loss: 0.8259 - accuracy: 0.78 - ETA: 1:37 - loss: 0.8270 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8325 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8319 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8281 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8304 - accuracy: 0.77 - ETA: 1:28 - loss: 0.8363 - accuracy: 0.77 - ETA: 1:26 - loss: 0.8345 - accuracy: 0.77 - ETA: 1:24 - loss: 0.8333 - accuracy: 0.77 - ETA: 1:22 - loss: 0.8326 - accuracy: 0.77 - ETA: 1:20 - loss: 0.8331 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8340 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8353 - accuracy: 0.77 - ETA: 1:15 - loss: 0.8349 - accuracy: 0.77 - ETA: 1:13 - loss: 0.8359 - accuracy: 0.77 - ETA: 1:11 - loss: 0.8358 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8375 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8377 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8378 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8385 - accuracy: 0.77 - ETA: 1:02 - loss: 0.8377 - accuracy: 0.77 - ETA: 1:00 - loss: 0.8385 - accuracy: 0.77 - ETA: 58s - loss: 0.8393 - accuracy: 0.7783 - ETA: 56s - loss: 0.8381 - accuracy: 0.778 - ETA: 55s - loss: 0.8400 - accuracy: 0.778 - ETA: 53s - loss: 0.8404 - accuracy: 0.777 - ETA: 51s - loss: 0.8410 - accuracy: 0.777 - ETA: 49s - loss: 0.8417 - accuracy: 0.777 - ETA: 47s - loss: 0.8429 - accuracy: 0.776 - ETA: 45s - loss: 0.8444 - accuracy: 0.776 - ETA: 44s - loss: 0.8444 - accuracy: 0.776 - ETA: 42s - loss: 0.8445 - accuracy: 0.775 - ETA: 40s - loss: 0.8476 - accuracy: 0.775 - ETA: 38s - loss: 0.8481 - accuracy: 0.774 - ETA: 36s - loss: 0.8472 - accuracy: 0.775 - ETA: 34s - loss: 0.8456 - accuracy: 0.775 - ETA: 33s - loss: 0.8432 - accuracy: 0.775 - ETA: 31s - loss: 0.8486 - accuracy: 0.775 - ETA: 29s - loss: 0.8482 - accuracy: 0.775 - ETA: 27s - loss: 0.8476 - accuracy: 0.775 - ETA: 25s - loss: 0.8480 - accuracy: 0.775 - ETA: 23s - loss: 0.8485 - accuracy: 0.775 - ETA: 21s - loss: 0.8486 - accuracy: 0.775 - ETA: 20s - loss: 0.8492 - accuracy: 0.775 - ETA: 18s - loss: 0.8489 - accuracy: 0.775 - ETA: 16s - loss: 0.8481 - accuracy: 0.775 - ETA: 14s - loss: 0.8472 - accuracy: 0.775 - ETA: 12s - loss: 0.8469 - accuracy: 0.775 - ETA: 10s - loss: 0.8480 - accuracy: 0.775 - ETA: 9s - loss: 0.8465 - accuracy: 0.775 - ETA: 7s - loss: 0.8446 - accuracy: 0.77 - ETA: 5s - loss: 0.8474 - accuracy: 0.77 - ETA: 3s - loss: 0.8469 - accuracy: 0.77 - ETA: 1s - loss: 0.8470 - accuracy: 0.77 - 305s 16ms/step - loss: 0.8467 - accuracy: 0.7754 - val_loss: 2.1895 - val_accuracy: 0.7275\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:32 - loss: 0.6906 - accuracy: 0.79 - ETA: 4:34 - loss: 0.7123 - accuracy: 0.79 - ETA: 4:33 - loss: 0.7525 - accuracy: 0.78 - ETA: 4:25 - loss: 0.8104 - accuracy: 0.78 - ETA: 4:24 - loss: 0.7993 - accuracy: 0.77 - ETA: 4:26 - loss: 0.8127 - accuracy: 0.76 - ETA: 4:25 - loss: 0.8084 - accuracy: 0.76 - ETA: 4:25 - loss: 0.8041 - accuracy: 0.76 - ETA: 4:25 - loss: 0.7982 - accuracy: 0.77 - ETA: 4:22 - loss: 0.8214 - accuracy: 0.76 - ETA: 4:21 - loss: 0.8103 - accuracy: 0.77 - ETA: 4:20 - loss: 0.8236 - accuracy: 0.77 - ETA: 4:19 - loss: 0.8261 - accuracy: 0.77 - ETA: 4:16 - loss: 0.7992 - accuracy: 0.77 - ETA: 4:14 - loss: 0.8169 - accuracy: 0.77 - ETA: 4:12 - loss: 0.8111 - accuracy: 0.77 - ETA: 4:09 - loss: 0.8139 - accuracy: 0.77 - ETA: 4:08 - loss: 0.8595 - accuracy: 0.77 - ETA: 4:05 - loss: 0.8597 - accuracy: 0.76 - ETA: 4:03 - loss: 0.8438 - accuracy: 0.77 - ETA: 4:02 - loss: 0.8438 - accuracy: 0.77 - ETA: 4:01 - loss: 0.8359 - accuracy: 0.77 - ETA: 3:58 - loss: 0.8424 - accuracy: 0.77 - ETA: 3:57 - loss: 0.8336 - accuracy: 0.77 - ETA: 3:55 - loss: 0.8242 - accuracy: 0.77 - ETA: 3:54 - loss: 0.8230 - accuracy: 0.77 - ETA: 3:51 - loss: 0.8207 - accuracy: 0.77 - ETA: 3:50 - loss: 0.8206 - accuracy: 0.77 - ETA: 3:48 - loss: 0.8136 - accuracy: 0.77 - ETA: 3:47 - loss: 0.8064 - accuracy: 0.77 - ETA: 3:45 - loss: 0.8000 - accuracy: 0.77 - ETA: 3:44 - loss: 0.7908 - accuracy: 0.78 - ETA: 3:41 - loss: 0.7899 - accuracy: 0.78 - ETA: 3:40 - loss: 0.7996 - accuracy: 0.78 - ETA: 3:37 - loss: 0.7951 - accuracy: 0.78 - ETA: 3:36 - loss: 0.7944 - accuracy: 0.78 - ETA: 3:34 - loss: 0.7884 - accuracy: 0.78 - ETA: 3:32 - loss: 0.7888 - accuracy: 0.78 - ETA: 3:30 - loss: 0.8000 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8022 - accuracy: 0.78 - ETA: 3:26 - loss: 0.8029 - accuracy: 0.78 - ETA: 3:24 - loss: 0.8047 - accuracy: 0.78 - ETA: 3:22 - loss: 0.8031 - accuracy: 0.78 - ETA: 3:20 - loss: 0.7983 - accuracy: 0.78 - ETA: 3:18 - loss: 0.7963 - accuracy: 0.78 - ETA: 3:16 - loss: 0.7944 - accuracy: 0.78 - ETA: 3:14 - loss: 0.7949 - accuracy: 0.78 - ETA: 3:13 - loss: 0.8002 - accuracy: 0.78 - ETA: 3:11 - loss: 0.7985 - accuracy: 0.78 - ETA: 3:09 - loss: 0.7999 - accuracy: 0.78 - ETA: 3:07 - loss: 0.7990 - accuracy: 0.78 - ETA: 3:05 - loss: 0.8043 - accuracy: 0.78 - ETA: 3:03 - loss: 0.8070 - accuracy: 0.78 - ETA: 3:01 - loss: 0.8047 - accuracy: 0.78 - ETA: 2:59 - loss: 0.8047 - accuracy: 0.78 - ETA: 2:57 - loss: 0.8044 - accuracy: 0.78 - ETA: 2:55 - loss: 0.8019 - accuracy: 0.78 - ETA: 2:54 - loss: 0.7999 - accuracy: 0.78 - ETA: 2:52 - loss: 0.7964 - accuracy: 0.78 - ETA: 2:50 - loss: 0.7928 - accuracy: 0.78 - ETA: 2:48 - loss: 0.7934 - accuracy: 0.78 - ETA: 2:46 - loss: 0.7989 - accuracy: 0.78 - ETA: 2:44 - loss: 0.7995 - accuracy: 0.78 - ETA: 2:42 - loss: 0.7982 - accuracy: 0.78 - ETA: 2:40 - loss: 0.8016 - accuracy: 0.78 - ETA: 2:38 - loss: 0.7995 - accuracy: 0.78 - ETA: 2:36 - loss: 0.7982 - accuracy: 0.78 - ETA: 2:34 - loss: 0.7983 - accuracy: 0.78 - ETA: 2:32 - loss: 0.7957 - accuracy: 0.78 - ETA: 2:31 - loss: 0.7938 - accuracy: 0.78 - ETA: 2:29 - loss: 0.7975 - accuracy: 0.78 - ETA: 2:27 - loss: 0.7952 - accuracy: 0.78 - ETA: 2:25 - loss: 0.7947 - accuracy: 0.78 - ETA: 2:23 - loss: 0.7924 - accuracy: 0.78 - ETA: 2:21 - loss: 0.7965 - accuracy: 0.78 - ETA: 2:19 - loss: 0.7973 - accuracy: 0.78 - ETA: 2:18 - loss: 0.7981 - accuracy: 0.78 - ETA: 2:16 - loss: 0.8006 - accuracy: 0.78 - ETA: 2:14 - loss: 0.7981 - accuracy: 0.78 - ETA: 2:12 - loss: 0.7968 - accuracy: 0.78 - ETA: 2:10 - loss: 0.8003 - accuracy: 0.78 - ETA: 2:08 - loss: 0.7985 - accuracy: 0.78 - ETA: 2:06 - loss: 0.7976 - accuracy: 0.78 - ETA: 2:04 - loss: 0.8035 - accuracy: 0.78 - ETA: 2:03 - loss: 0.8040 - accuracy: 0.78 - ETA: 2:01 - loss: 0.8045 - accuracy: 0.78 - ETA: 1:59 - loss: 0.8063 - accuracy: 0.78 - ETA: 1:57 - loss: 0.8025 - accuracy: 0.78 - ETA: 1:55 - loss: 0.8007 - accuracy: 0.78 - ETA: 1:53 - loss: 0.8005 - accuracy: 0.78 - ETA: 1:51 - loss: 0.7981 - accuracy: 0.78 - ETA: 1:50 - loss: 0.7977 - accuracy: 0.78 - ETA: 1:48 - loss: 0.8017 - accuracy: 0.78 - ETA: 1:46 - loss: 0.7996 - accuracy: 0.78 - ETA: 1:44 - loss: 0.8005 - accuracy: 0.78 - ETA: 1:42 - loss: 0.8009 - accuracy: 0.78 - ETA: 1:40 - loss: 0.7990 - accuracy: 0.78 - ETA: 1:38 - loss: 0.7993 - accuracy: 0.78 - ETA: 1:36 - loss: 0.7977 - accuracy: 0.78 - ETA: 1:35 - loss: 0.8008 - accuracy: 0.78 - ETA: 1:33 - loss: 0.8014 - accuracy: 0.78 - ETA: 1:31 - loss: 0.8032 - accuracy: 0.78 - ETA: 1:29 - loss: 0.8015 - accuracy: 0.78 - ETA: 1:27 - loss: 0.8031 - accuracy: 0.78 - ETA: 1:25 - loss: 0.8017 - accuracy: 0.78 - ETA: 1:23 - loss: 0.8017 - accuracy: 0.78 - ETA: 1:21 - loss: 0.8025 - accuracy: 0.78 - ETA: 1:19 - loss: 0.8017 - accuracy: 0.78 - ETA: 1:18 - loss: 0.8058 - accuracy: 0.78 - ETA: 1:16 - loss: 0.8053 - accuracy: 0.78 - ETA: 1:14 - loss: 0.8035 - accuracy: 0.78 - ETA: 1:12 - loss: 0.8049 - accuracy: 0.78 - ETA: 1:10 - loss: 0.8046 - accuracy: 0.78 - ETA: 1:08 - loss: 0.8045 - accuracy: 0.78 - ETA: 1:06 - loss: 0.8053 - accuracy: 0.78 - ETA: 1:04 - loss: 0.8037 - accuracy: 0.78 - ETA: 1:03 - loss: 0.8045 - accuracy: 0.78 - ETA: 1:01 - loss: 0.8068 - accuracy: 0.78 - ETA: 59s - loss: 0.8082 - accuracy: 0.7840 - ETA: 57s - loss: 0.8080 - accuracy: 0.783 - ETA: 55s - loss: 0.8060 - accuracy: 0.784 - ETA: 53s - loss: 0.8060 - accuracy: 0.784 - ETA: 51s - loss: 0.8046 - accuracy: 0.784 - ETA: 50s - loss: 0.8038 - accuracy: 0.784 - ETA: 48s - loss: 0.8017 - accuracy: 0.784 - ETA: 46s - loss: 0.8003 - accuracy: 0.784 - ETA: 44s - loss: 0.7993 - accuracy: 0.784 - ETA: 42s - loss: 0.7980 - accuracy: 0.785 - ETA: 40s - loss: 0.7980 - accuracy: 0.785 - ETA: 38s - loss: 0.7978 - accuracy: 0.785 - ETA: 37s - loss: 0.7977 - accuracy: 0.785 - ETA: 35s - loss: 0.7998 - accuracy: 0.785 - ETA: 33s - loss: 0.7985 - accuracy: 0.785 - ETA: 31s - loss: 0.7980 - accuracy: 0.785 - ETA: 29s - loss: 0.7995 - accuracy: 0.785 - ETA: 27s - loss: 0.8001 - accuracy: 0.785 - ETA: 25s - loss: 0.8013 - accuracy: 0.786 - ETA: 24s - loss: 0.8044 - accuracy: 0.786 - ETA: 22s - loss: 0.8091 - accuracy: 0.785 - ETA: 20s - loss: 0.8090 - accuracy: 0.785 - ETA: 18s - loss: 0.8118 - accuracy: 0.784 - ETA: 16s - loss: 0.8131 - accuracy: 0.784 - ETA: 14s - loss: 0.8127 - accuracy: 0.784 - ETA: 12s - loss: 0.8125 - accuracy: 0.784 - ETA: 10s - loss: 0.8108 - accuracy: 0.784 - ETA: 9s - loss: 0.8132 - accuracy: 0.784 - ETA: 7s - loss: 0.8132 - accuracy: 0.78 - ETA: 5s - loss: 0.8145 - accuracy: 0.78 - ETA: 3s - loss: 0.8136 - accuracy: 0.78 - ETA: 1s - loss: 0.8134 - accuracy: 0.78 - 307s 16ms/step - loss: 0.8138 - accuracy: 0.7834 - val_loss: 2.2777 - val_accuracy: 0.7238\n",
      "Epoch 94/100\n",
      "19312/19312 [==============================] - ETA: 4:34 - loss: 1.2669 - accuracy: 0.75 - ETA: 4:29 - loss: 1.0655 - accuracy: 0.76 - ETA: 4:28 - loss: 1.0232 - accuracy: 0.76 - ETA: 4:24 - loss: 0.9571 - accuracy: 0.76 - ETA: 4:23 - loss: 0.8832 - accuracy: 0.77 - ETA: 4:21 - loss: 0.9100 - accuracy: 0.76 - ETA: 4:21 - loss: 0.8674 - accuracy: 0.76 - ETA: 4:21 - loss: 0.8717 - accuracy: 0.76 - ETA: 4:19 - loss: 0.8438 - accuracy: 0.77 - ETA: 4:18 - loss: 0.8399 - accuracy: 0.77 - ETA: 4:17 - loss: 0.8235 - accuracy: 0.77 - ETA: 4:16 - loss: 0.8185 - accuracy: 0.77 - ETA: 4:16 - loss: 0.8199 - accuracy: 0.77 - ETA: 4:13 - loss: 0.8770 - accuracy: 0.77 - ETA: 4:12 - loss: 0.8787 - accuracy: 0.77 - ETA: 4:10 - loss: 0.8687 - accuracy: 0.77 - ETA: 4:09 - loss: 0.8748 - accuracy: 0.77 - ETA: 4:07 - loss: 0.8857 - accuracy: 0.77 - ETA: 4:04 - loss: 0.9553 - accuracy: 0.77 - ETA: 4:02 - loss: 0.9599 - accuracy: 0.77 - ETA: 4:01 - loss: 0.9367 - accuracy: 0.77 - ETA: 4:00 - loss: 0.9311 - accuracy: 0.77 - ETA: 3:58 - loss: 0.9281 - accuracy: 0.77 - ETA: 3:56 - loss: 0.9200 - accuracy: 0.77 - ETA: 3:54 - loss: 0.9122 - accuracy: 0.77 - ETA: 3:52 - loss: 0.9110 - accuracy: 0.77 - ETA: 3:50 - loss: 0.9083 - accuracy: 0.77 - ETA: 3:48 - loss: 0.9051 - accuracy: 0.77 - ETA: 3:46 - loss: 0.8986 - accuracy: 0.77 - ETA: 3:44 - loss: 0.8980 - accuracy: 0.77 - ETA: 3:42 - loss: 0.9030 - accuracy: 0.77 - ETA: 3:40 - loss: 0.8899 - accuracy: 0.77 - ETA: 3:38 - loss: 0.8940 - accuracy: 0.78 - ETA: 3:36 - loss: 0.8940 - accuracy: 0.77 - ETA: 3:34 - loss: 0.8926 - accuracy: 0.77 - ETA: 3:32 - loss: 0.8872 - accuracy: 0.77 - ETA: 3:30 - loss: 0.8790 - accuracy: 0.77 - ETA: 3:28 - loss: 0.8794 - accuracy: 0.77 - ETA: 3:26 - loss: 0.8788 - accuracy: 0.77 - ETA: 3:24 - loss: 0.8772 - accuracy: 0.77 - ETA: 3:22 - loss: 0.8770 - accuracy: 0.78 - ETA: 3:20 - loss: 0.8709 - accuracy: 0.78 - ETA: 3:18 - loss: 0.8687 - accuracy: 0.78 - ETA: 3:16 - loss: 0.8643 - accuracy: 0.78 - ETA: 3:15 - loss: 0.8856 - accuracy: 0.78 - ETA: 3:13 - loss: 0.8808 - accuracy: 0.78 - ETA: 3:11 - loss: 0.8796 - accuracy: 0.77 - ETA: 3:09 - loss: 0.8927 - accuracy: 0.77 - ETA: 3:08 - loss: 0.8983 - accuracy: 0.77 - ETA: 3:06 - loss: 0.8932 - accuracy: 0.77 - ETA: 3:04 - loss: 0.8892 - accuracy: 0.78 - ETA: 3:02 - loss: 0.8849 - accuracy: 0.78 - ETA: 3:00 - loss: 0.8786 - accuracy: 0.78 - ETA: 2:59 - loss: 0.8784 - accuracy: 0.78 - ETA: 2:57 - loss: 0.8772 - accuracy: 0.78 - ETA: 2:55 - loss: 0.8767 - accuracy: 0.77 - ETA: 2:53 - loss: 0.8796 - accuracy: 0.77 - ETA: 2:52 - loss: 0.8745 - accuracy: 0.78 - ETA: 2:50 - loss: 0.8767 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8761 - accuracy: 0.78 - ETA: 2:46 - loss: 0.8732 - accuracy: 0.78 - ETA: 2:44 - loss: 0.8698 - accuracy: 0.78 - ETA: 2:42 - loss: 0.8670 - accuracy: 0.78 - ETA: 2:40 - loss: 0.8674 - accuracy: 0.78 - ETA: 2:38 - loss: 0.8693 - accuracy: 0.78 - ETA: 2:36 - loss: 0.8665 - accuracy: 0.78 - ETA: 2:35 - loss: 0.8687 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8707 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8687 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8700 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8702 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8735 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8745 - accuracy: 0.77 - ETA: 2:22 - loss: 0.8776 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8825 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8799 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8774 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8742 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8727 - accuracy: 0.77 - ETA: 2:11 - loss: 0.8718 - accuracy: 0.77 - ETA: 2:09 - loss: 0.8714 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8703 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8721 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8711 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8688 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8667 - accuracy: 0.77 - ETA: 1:58 - loss: 0.8666 - accuracy: 0.77 - ETA: 1:56 - loss: 0.8637 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8632 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8603 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8620 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8593 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8585 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8573 - accuracy: 0.77 - ETA: 1:43 - loss: 0.8593 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8597 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8574 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8572 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8558 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8540 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8530 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8523 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8515 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8529 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8517 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8526 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8522 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8539 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8532 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8556 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8555 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8552 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8553 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8563 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8538 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8528 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8520 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8525 - accuracy: 0.77 - ETA: 59s - loss: 0.8506 - accuracy: 0.7746 - ETA: 57s - loss: 0.8518 - accuracy: 0.774 - ETA: 55s - loss: 0.8502 - accuracy: 0.774 - ETA: 53s - loss: 0.8504 - accuracy: 0.774 - ETA: 51s - loss: 0.8493 - accuracy: 0.774 - ETA: 49s - loss: 0.8496 - accuracy: 0.774 - ETA: 48s - loss: 0.8487 - accuracy: 0.774 - ETA: 46s - loss: 0.8502 - accuracy: 0.773 - ETA: 44s - loss: 0.8511 - accuracy: 0.773 - ETA: 42s - loss: 0.8521 - accuracy: 0.773 - ETA: 40s - loss: 0.8528 - accuracy: 0.772 - ETA: 38s - loss: 0.8519 - accuracy: 0.772 - ETA: 36s - loss: 0.8521 - accuracy: 0.772 - ETA: 35s - loss: 0.8501 - accuracy: 0.773 - ETA: 33s - loss: 0.8503 - accuracy: 0.772 - ETA: 31s - loss: 0.8508 - accuracy: 0.772 - ETA: 29s - loss: 0.8505 - accuracy: 0.772 - ETA: 27s - loss: 0.8503 - accuracy: 0.772 - ETA: 25s - loss: 0.8492 - accuracy: 0.772 - ETA: 23s - loss: 0.8485 - accuracy: 0.772 - ETA: 22s - loss: 0.8486 - accuracy: 0.772 - ETA: 20s - loss: 0.8485 - accuracy: 0.772 - ETA: 18s - loss: 0.8493 - accuracy: 0.772 - ETA: 16s - loss: 0.8515 - accuracy: 0.772 - ETA: 14s - loss: 0.8512 - accuracy: 0.772 - ETA: 12s - loss: 0.8498 - accuracy: 0.772 - ETA: 10s - loss: 0.8529 - accuracy: 0.772 - ETA: 9s - loss: 0.8531 - accuracy: 0.771 - ETA: 7s - loss: 0.8524 - accuracy: 0.77 - ETA: 5s - loss: 0.8506 - accuracy: 0.77 - ETA: 3s - loss: 0.8499 - accuracy: 0.77 - ETA: 1s - loss: 0.8476 - accuracy: 0.77 - 308s 16ms/step - loss: 0.8470 - accuracy: 0.7727 - val_loss: 2.1779 - val_accuracy: 0.7235\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:36 - loss: 0.7967 - accuracy: 0.75 - ETA: 4:32 - loss: 0.7057 - accuracy: 0.78 - ETA: 4:36 - loss: 0.6685 - accuracy: 0.79 - ETA: 4:37 - loss: 0.6939 - accuracy: 0.79 - ETA: 4:34 - loss: 0.8772 - accuracy: 0.77 - ETA: 4:31 - loss: 0.9090 - accuracy: 0.76 - ETA: 4:30 - loss: 0.9023 - accuracy: 0.75 - ETA: 4:31 - loss: 0.8853 - accuracy: 0.75 - ETA: 4:27 - loss: 0.8695 - accuracy: 0.76 - ETA: 4:26 - loss: 0.8510 - accuracy: 0.76 - ETA: 4:25 - loss: 0.8443 - accuracy: 0.75 - ETA: 4:23 - loss: 0.8259 - accuracy: 0.76 - ETA: 4:20 - loss: 0.8591 - accuracy: 0.76 - ETA: 4:19 - loss: 0.8513 - accuracy: 0.77 - ETA: 4:16 - loss: 0.8420 - accuracy: 0.77 - ETA: 4:15 - loss: 0.8282 - accuracy: 0.77 - ETA: 4:13 - loss: 0.8540 - accuracy: 0.77 - ETA: 4:12 - loss: 0.8469 - accuracy: 0.77 - ETA: 4:10 - loss: 0.8428 - accuracy: 0.77 - ETA: 4:08 - loss: 0.8568 - accuracy: 0.77 - ETA: 4:05 - loss: 0.8589 - accuracy: 0.77 - ETA: 4:03 - loss: 0.8586 - accuracy: 0.77 - ETA: 4:01 - loss: 0.8642 - accuracy: 0.77 - ETA: 3:59 - loss: 0.8672 - accuracy: 0.77 - ETA: 3:57 - loss: 0.8798 - accuracy: 0.77 - ETA: 3:56 - loss: 0.8828 - accuracy: 0.77 - ETA: 3:54 - loss: 0.8815 - accuracy: 0.77 - ETA: 3:52 - loss: 0.8739 - accuracy: 0.77 - ETA: 3:49 - loss: 0.8654 - accuracy: 0.77 - ETA: 3:47 - loss: 0.8599 - accuracy: 0.77 - ETA: 3:45 - loss: 0.8620 - accuracy: 0.77 - ETA: 3:43 - loss: 0.8600 - accuracy: 0.77 - ETA: 3:40 - loss: 0.8559 - accuracy: 0.77 - ETA: 3:39 - loss: 0.8547 - accuracy: 0.77 - ETA: 3:37 - loss: 0.8541 - accuracy: 0.77 - ETA: 3:34 - loss: 0.8587 - accuracy: 0.77 - ETA: 3:32 - loss: 0.8534 - accuracy: 0.77 - ETA: 3:31 - loss: 0.8509 - accuracy: 0.77 - ETA: 3:29 - loss: 0.8515 - accuracy: 0.77 - ETA: 3:27 - loss: 0.8464 - accuracy: 0.77 - ETA: 3:25 - loss: 0.8484 - accuracy: 0.77 - ETA: 3:23 - loss: 0.8523 - accuracy: 0.77 - ETA: 3:21 - loss: 0.8455 - accuracy: 0.77 - ETA: 3:19 - loss: 0.8447 - accuracy: 0.77 - ETA: 3:18 - loss: 0.8477 - accuracy: 0.77 - ETA: 3:16 - loss: 0.8521 - accuracy: 0.77 - ETA: 3:13 - loss: 0.8486 - accuracy: 0.77 - ETA: 3:12 - loss: 0.8542 - accuracy: 0.77 - ETA: 3:10 - loss: 0.8566 - accuracy: 0.77 - ETA: 3:08 - loss: 0.8532 - accuracy: 0.77 - ETA: 3:06 - loss: 0.8486 - accuracy: 0.77 - ETA: 3:04 - loss: 0.8456 - accuracy: 0.77 - ETA: 3:03 - loss: 0.8425 - accuracy: 0.77 - ETA: 3:01 - loss: 0.8400 - accuracy: 0.77 - ETA: 2:59 - loss: 0.8439 - accuracy: 0.77 - ETA: 2:57 - loss: 0.8400 - accuracy: 0.77 - ETA: 2:56 - loss: 0.8394 - accuracy: 0.77 - ETA: 2:54 - loss: 0.8362 - accuracy: 0.77 - ETA: 2:52 - loss: 0.8345 - accuracy: 0.77 - ETA: 2:50 - loss: 0.8336 - accuracy: 0.77 - ETA: 2:48 - loss: 0.8349 - accuracy: 0.77 - ETA: 2:46 - loss: 0.8352 - accuracy: 0.77 - ETA: 2:44 - loss: 0.8348 - accuracy: 0.77 - ETA: 2:42 - loss: 0.8302 - accuracy: 0.77 - ETA: 2:40 - loss: 0.8273 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8253 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8245 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8243 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8272 - accuracy: 0.77 - ETA: 2:31 - loss: 0.8234 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8204 - accuracy: 0.78 - ETA: 2:27 - loss: 0.8209 - accuracy: 0.77 - ETA: 2:25 - loss: 0.8216 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8198 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8163 - accuracy: 0.77 - ETA: 2:20 - loss: 0.8165 - accuracy: 0.77 - ETA: 2:18 - loss: 0.8128 - accuracy: 0.77 - ETA: 2:16 - loss: 0.8155 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8156 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8123 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8118 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8089 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8066 - accuracy: 0.78 - ETA: 2:05 - loss: 0.8041 - accuracy: 0.78 - ETA: 2:03 - loss: 0.8062 - accuracy: 0.78 - ETA: 2:01 - loss: 0.8067 - accuracy: 0.78 - ETA: 1:59 - loss: 0.8045 - accuracy: 0.78 - ETA: 1:57 - loss: 0.8093 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8083 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8143 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8123 - accuracy: 0.77 - ETA: 1:50 - loss: 0.8178 - accuracy: 0.77 - ETA: 1:48 - loss: 0.8202 - accuracy: 0.77 - ETA: 1:46 - loss: 0.8207 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8202 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8187 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8197 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8178 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8173 - accuracy: 0.77 - ETA: 1:35 - loss: 0.8149 - accuracy: 0.77 - ETA: 1:33 - loss: 0.8153 - accuracy: 0.77 - ETA: 1:31 - loss: 0.8153 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8135 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8136 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8155 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8129 - accuracy: 0.78 - ETA: 1:21 - loss: 0.8101 - accuracy: 0.78 - ETA: 1:19 - loss: 0.8089 - accuracy: 0.78 - ETA: 1:18 - loss: 0.8110 - accuracy: 0.78 - ETA: 1:16 - loss: 0.8128 - accuracy: 0.78 - ETA: 1:14 - loss: 0.8104 - accuracy: 0.78 - ETA: 1:12 - loss: 0.8098 - accuracy: 0.78 - ETA: 1:10 - loss: 0.8114 - accuracy: 0.78 - ETA: 1:08 - loss: 0.8126 - accuracy: 0.78 - ETA: 1:06 - loss: 0.8102 - accuracy: 0.78 - ETA: 1:04 - loss: 0.8158 - accuracy: 0.78 - ETA: 1:03 - loss: 0.8168 - accuracy: 0.78 - ETA: 1:01 - loss: 0.8155 - accuracy: 0.78 - ETA: 59s - loss: 0.8153 - accuracy: 0.7810 - ETA: 57s - loss: 0.8159 - accuracy: 0.780 - ETA: 55s - loss: 0.8161 - accuracy: 0.780 - ETA: 53s - loss: 0.8157 - accuracy: 0.781 - ETA: 51s - loss: 0.8169 - accuracy: 0.780 - ETA: 49s - loss: 0.8161 - accuracy: 0.781 - ETA: 48s - loss: 0.8168 - accuracy: 0.781 - ETA: 46s - loss: 0.8163 - accuracy: 0.781 - ETA: 44s - loss: 0.8154 - accuracy: 0.781 - ETA: 42s - loss: 0.8146 - accuracy: 0.781 - ETA: 40s - loss: 0.8130 - accuracy: 0.782 - ETA: 38s - loss: 0.8126 - accuracy: 0.782 - ETA: 36s - loss: 0.8162 - accuracy: 0.781 - ETA: 35s - loss: 0.8146 - accuracy: 0.782 - ETA: 33s - loss: 0.8148 - accuracy: 0.782 - ETA: 31s - loss: 0.8154 - accuracy: 0.781 - ETA: 29s - loss: 0.8164 - accuracy: 0.781 - ETA: 27s - loss: 0.8167 - accuracy: 0.782 - ETA: 25s - loss: 0.8162 - accuracy: 0.782 - ETA: 23s - loss: 0.8152 - accuracy: 0.781 - ETA: 22s - loss: 0.8171 - accuracy: 0.781 - ETA: 20s - loss: 0.8175 - accuracy: 0.781 - ETA: 18s - loss: 0.8161 - accuracy: 0.781 - ETA: 16s - loss: 0.8149 - accuracy: 0.781 - ETA: 14s - loss: 0.8153 - accuracy: 0.781 - ETA: 12s - loss: 0.8140 - accuracy: 0.781 - ETA: 10s - loss: 0.8145 - accuracy: 0.781 - ETA: 9s - loss: 0.8164 - accuracy: 0.781 - ETA: 7s - loss: 0.8154 - accuracy: 0.78 - ETA: 5s - loss: 0.8160 - accuracy: 0.78 - ETA: 3s - loss: 0.8150 - accuracy: 0.78 - ETA: 1s - loss: 0.8155 - accuracy: 0.78 - 305s 16ms/step - loss: 0.8149 - accuracy: 0.7815 - val_loss: 2.1181 - val_accuracy: 0.7186\n",
      "Epoch 96/100\n",
      "19312/19312 [==============================] - ETA: 4:24 - loss: 0.6481 - accuracy: 0.78 - ETA: 4:37 - loss: 0.7894 - accuracy: 0.78 - ETA: 4:33 - loss: 0.7203 - accuracy: 0.80 - ETA: 4:35 - loss: 0.7553 - accuracy: 0.79 - ETA: 4:30 - loss: 0.7145 - accuracy: 0.79 - ETA: 4:26 - loss: 0.7974 - accuracy: 0.79 - ETA: 4:25 - loss: 0.8053 - accuracy: 0.79 - ETA: 4:24 - loss: 0.7915 - accuracy: 0.79 - ETA: 4:21 - loss: 0.8513 - accuracy: 0.79 - ETA: 4:19 - loss: 0.8450 - accuracy: 0.79 - ETA: 4:18 - loss: 0.8611 - accuracy: 0.78 - ETA: 4:15 - loss: 0.8691 - accuracy: 0.78 - ETA: 4:12 - loss: 0.8648 - accuracy: 0.78 - ETA: 4:12 - loss: 0.8514 - accuracy: 0.78 - ETA: 4:10 - loss: 0.8439 - accuracy: 0.78 - ETA: 4:09 - loss: 0.8489 - accuracy: 0.78 - ETA: 4:08 - loss: 0.8418 - accuracy: 0.78 - ETA: 4:06 - loss: 0.8433 - accuracy: 0.78 - ETA: 4:05 - loss: 0.8329 - accuracy: 0.78 - ETA: 4:03 - loss: 0.8314 - accuracy: 0.78 - ETA: 4:01 - loss: 0.8375 - accuracy: 0.78 - ETA: 3:59 - loss: 0.8355 - accuracy: 0.78 - ETA: 3:57 - loss: 0.8314 - accuracy: 0.78 - ETA: 3:55 - loss: 0.8451 - accuracy: 0.78 - ETA: 3:54 - loss: 0.8410 - accuracy: 0.78 - ETA: 3:52 - loss: 0.8357 - accuracy: 0.78 - ETA: 3:50 - loss: 0.8301 - accuracy: 0.78 - ETA: 3:48 - loss: 0.8331 - accuracy: 0.78 - ETA: 3:46 - loss: 0.8282 - accuracy: 0.78 - ETA: 3:44 - loss: 0.8376 - accuracy: 0.78 - ETA: 3:42 - loss: 0.8361 - accuracy: 0.78 - ETA: 3:40 - loss: 0.8470 - accuracy: 0.78 - ETA: 3:39 - loss: 0.8360 - accuracy: 0.78 - ETA: 3:36 - loss: 0.8327 - accuracy: 0.78 - ETA: 3:34 - loss: 0.8353 - accuracy: 0.78 - ETA: 3:33 - loss: 0.8381 - accuracy: 0.78 - ETA: 3:31 - loss: 0.8371 - accuracy: 0.78 - ETA: 3:30 - loss: 0.8381 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8355 - accuracy: 0.78 - ETA: 3:26 - loss: 0.8320 - accuracy: 0.78 - ETA: 3:25 - loss: 0.8310 - accuracy: 0.78 - ETA: 3:23 - loss: 0.8349 - accuracy: 0.77 - ETA: 3:21 - loss: 0.8262 - accuracy: 0.78 - ETA: 3:19 - loss: 0.8205 - accuracy: 0.78 - ETA: 3:17 - loss: 0.8209 - accuracy: 0.78 - ETA: 3:15 - loss: 0.8143 - accuracy: 0.78 - ETA: 3:13 - loss: 0.8142 - accuracy: 0.78 - ETA: 3:11 - loss: 0.8115 - accuracy: 0.78 - ETA: 3:09 - loss: 0.8135 - accuracy: 0.78 - ETA: 3:08 - loss: 0.8161 - accuracy: 0.78 - ETA: 3:06 - loss: 0.8170 - accuracy: 0.78 - ETA: 3:04 - loss: 0.8184 - accuracy: 0.77 - ETA: 3:02 - loss: 0.8145 - accuracy: 0.78 - ETA: 3:00 - loss: 0.8220 - accuracy: 0.77 - ETA: 2:58 - loss: 0.8172 - accuracy: 0.78 - ETA: 2:56 - loss: 0.8153 - accuracy: 0.78 - ETA: 2:54 - loss: 0.8202 - accuracy: 0.77 - ETA: 2:52 - loss: 0.8232 - accuracy: 0.78 - ETA: 2:51 - loss: 0.8258 - accuracy: 0.77 - ETA: 2:49 - loss: 0.8246 - accuracy: 0.77 - ETA: 2:47 - loss: 0.8286 - accuracy: 0.77 - ETA: 2:45 - loss: 0.8310 - accuracy: 0.77 - ETA: 2:43 - loss: 0.8276 - accuracy: 0.77 - ETA: 2:41 - loss: 0.8260 - accuracy: 0.77 - ETA: 2:39 - loss: 0.8279 - accuracy: 0.77 - ETA: 2:38 - loss: 0.8311 - accuracy: 0.77 - ETA: 2:36 - loss: 0.8303 - accuracy: 0.77 - ETA: 2:34 - loss: 0.8317 - accuracy: 0.77 - ETA: 2:32 - loss: 0.8291 - accuracy: 0.77 - ETA: 2:30 - loss: 0.8327 - accuracy: 0.77 - ETA: 2:28 - loss: 0.8386 - accuracy: 0.77 - ETA: 2:26 - loss: 0.8367 - accuracy: 0.77 - ETA: 2:24 - loss: 0.8378 - accuracy: 0.77 - ETA: 2:23 - loss: 0.8357 - accuracy: 0.77 - ETA: 2:21 - loss: 0.8409 - accuracy: 0.77 - ETA: 2:19 - loss: 0.8400 - accuracy: 0.77 - ETA: 2:17 - loss: 0.8433 - accuracy: 0.77 - ETA: 2:15 - loss: 0.8463 - accuracy: 0.77 - ETA: 2:13 - loss: 0.8519 - accuracy: 0.77 - ETA: 2:12 - loss: 0.8512 - accuracy: 0.77 - ETA: 2:10 - loss: 0.8525 - accuracy: 0.77 - ETA: 2:08 - loss: 0.8475 - accuracy: 0.77 - ETA: 2:06 - loss: 0.8469 - accuracy: 0.77 - ETA: 2:04 - loss: 0.8481 - accuracy: 0.77 - ETA: 2:02 - loss: 0.8463 - accuracy: 0.77 - ETA: 2:00 - loss: 0.8477 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8505 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8480 - accuracy: 0.77 - ETA: 1:55 - loss: 0.8478 - accuracy: 0.77 - ETA: 1:53 - loss: 0.8478 - accuracy: 0.77 - ETA: 1:51 - loss: 0.8488 - accuracy: 0.77 - ETA: 1:49 - loss: 0.8473 - accuracy: 0.77 - ETA: 1:47 - loss: 0.8470 - accuracy: 0.77 - ETA: 1:45 - loss: 0.8597 - accuracy: 0.77 - ETA: 1:44 - loss: 0.8570 - accuracy: 0.77 - ETA: 1:42 - loss: 0.8556 - accuracy: 0.77 - ETA: 1:40 - loss: 0.8540 - accuracy: 0.77 - ETA: 1:38 - loss: 0.8537 - accuracy: 0.77 - ETA: 1:36 - loss: 0.8519 - accuracy: 0.77 - ETA: 1:34 - loss: 0.8523 - accuracy: 0.77 - ETA: 1:32 - loss: 0.8542 - accuracy: 0.77 - ETA: 1:30 - loss: 0.8528 - accuracy: 0.77 - ETA: 1:29 - loss: 0.8524 - accuracy: 0.77 - ETA: 1:27 - loss: 0.8504 - accuracy: 0.77 - ETA: 1:25 - loss: 0.8489 - accuracy: 0.77 - ETA: 1:23 - loss: 0.8478 - accuracy: 0.77 - ETA: 1:21 - loss: 0.8464 - accuracy: 0.77 - ETA: 1:19 - loss: 0.8482 - accuracy: 0.77 - ETA: 1:17 - loss: 0.8460 - accuracy: 0.77 - ETA: 1:16 - loss: 0.8458 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8456 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8489 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8486 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8487 - accuracy: 0.77 - ETA: 1:06 - loss: 0.8477 - accuracy: 0.77 - ETA: 1:04 - loss: 0.8463 - accuracy: 0.77 - ETA: 1:03 - loss: 0.8498 - accuracy: 0.77 - ETA: 1:01 - loss: 0.8510 - accuracy: 0.77 - ETA: 59s - loss: 0.8523 - accuracy: 0.7784 - ETA: 57s - loss: 0.8506 - accuracy: 0.778 - ETA: 55s - loss: 0.8519 - accuracy: 0.778 - ETA: 53s - loss: 0.8525 - accuracy: 0.778 - ETA: 51s - loss: 0.8535 - accuracy: 0.777 - ETA: 50s - loss: 0.8531 - accuracy: 0.777 - ETA: 48s - loss: 0.8515 - accuracy: 0.778 - ETA: 46s - loss: 0.8506 - accuracy: 0.778 - ETA: 44s - loss: 0.8500 - accuracy: 0.778 - ETA: 42s - loss: 0.8493 - accuracy: 0.778 - ETA: 40s - loss: 0.8493 - accuracy: 0.778 - ETA: 38s - loss: 0.8500 - accuracy: 0.778 - ETA: 37s - loss: 0.8495 - accuracy: 0.777 - ETA: 35s - loss: 0.8484 - accuracy: 0.778 - ETA: 33s - loss: 0.8468 - accuracy: 0.778 - ETA: 31s - loss: 0.8466 - accuracy: 0.778 - ETA: 29s - loss: 0.8454 - accuracy: 0.778 - ETA: 27s - loss: 0.8438 - accuracy: 0.778 - ETA: 25s - loss: 0.8421 - accuracy: 0.779 - ETA: 23s - loss: 0.8408 - accuracy: 0.779 - ETA: 22s - loss: 0.8399 - accuracy: 0.779 - ETA: 20s - loss: 0.8414 - accuracy: 0.779 - ETA: 18s - loss: 0.8402 - accuracy: 0.779 - ETA: 16s - loss: 0.8394 - accuracy: 0.779 - ETA: 14s - loss: 0.8394 - accuracy: 0.779 - ETA: 12s - loss: 0.8377 - accuracy: 0.780 - ETA: 10s - loss: 0.8368 - accuracy: 0.780 - ETA: 9s - loss: 0.8374 - accuracy: 0.780 - ETA: 7s - loss: 0.8355 - accuracy: 0.78 - ETA: 5s - loss: 0.8366 - accuracy: 0.78 - ETA: 3s - loss: 0.8361 - accuracy: 0.78 - ETA: 1s - loss: 0.8357 - accuracy: 0.78 - 306s 16ms/step - loss: 0.8371 - accuracy: 0.7798 - val_loss: 2.0466 - val_accuracy: 0.7256\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:28 - loss: 0.6823 - accuracy: 0.76 - ETA: 4:27 - loss: 0.7156 - accuracy: 0.79 - ETA: 4:29 - loss: 0.7992 - accuracy: 0.77 - ETA: 4:29 - loss: 0.8650 - accuracy: 0.76 - ETA: 4:28 - loss: 0.9214 - accuracy: 0.76 - ETA: 4:28 - loss: 0.9044 - accuracy: 0.76 - ETA: 4:27 - loss: 0.8949 - accuracy: 0.76 - ETA: 4:25 - loss: 0.8579 - accuracy: 0.76 - ETA: 4:22 - loss: 0.8345 - accuracy: 0.77 - ETA: 4:17 - loss: 0.8603 - accuracy: 0.77 - ETA: 4:17 - loss: 0.8410 - accuracy: 0.77 - ETA: 4:15 - loss: 0.8267 - accuracy: 0.78 - ETA: 4:15 - loss: 0.8279 - accuracy: 0.78 - ETA: 4:14 - loss: 0.8338 - accuracy: 0.78 - ETA: 4:13 - loss: 0.8193 - accuracy: 0.78 - ETA: 4:12 - loss: 0.8303 - accuracy: 0.77 - ETA: 4:09 - loss: 0.8184 - accuracy: 0.77 - ETA: 4:07 - loss: 0.8277 - accuracy: 0.77 - ETA: 4:05 - loss: 0.8232 - accuracy: 0.78 - ETA: 4:04 - loss: 0.8216 - accuracy: 0.78 - ETA: 4:02 - loss: 0.8223 - accuracy: 0.78 - ETA: 4:00 - loss: 0.8172 - accuracy: 0.78 - ETA: 3:59 - loss: 0.8146 - accuracy: 0.78 - ETA: 3:57 - loss: 0.8227 - accuracy: 0.78 - ETA: 3:55 - loss: 0.8209 - accuracy: 0.78 - ETA: 3:53 - loss: 0.8247 - accuracy: 0.78 - ETA: 3:51 - loss: 0.8153 - accuracy: 0.78 - ETA: 3:49 - loss: 0.8141 - accuracy: 0.78 - ETA: 3:47 - loss: 0.8283 - accuracy: 0.78 - ETA: 3:45 - loss: 0.8221 - accuracy: 0.78 - ETA: 3:43 - loss: 0.8195 - accuracy: 0.78 - ETA: 3:42 - loss: 0.8160 - accuracy: 0.78 - ETA: 3:40 - loss: 0.8070 - accuracy: 0.78 - ETA: 3:38 - loss: 0.8088 - accuracy: 0.78 - ETA: 3:37 - loss: 0.8107 - accuracy: 0.78 - ETA: 3:35 - loss: 0.8080 - accuracy: 0.78 - ETA: 3:34 - loss: 0.7989 - accuracy: 0.78 - ETA: 3:32 - loss: 0.7941 - accuracy: 0.78 - ETA: 3:30 - loss: 0.7976 - accuracy: 0.78 - ETA: 3:28 - loss: 0.7962 - accuracy: 0.78 - ETA: 3:26 - loss: 0.7983 - accuracy: 0.78 - ETA: 3:24 - loss: 0.8070 - accuracy: 0.78 - ETA: 3:22 - loss: 0.8069 - accuracy: 0.78 - ETA: 3:20 - loss: 0.8021 - accuracy: 0.78 - ETA: 3:18 - loss: 0.7989 - accuracy: 0.78 - ETA: 3:16 - loss: 0.7942 - accuracy: 0.78 - ETA: 3:14 - loss: 0.7928 - accuracy: 0.78 - ETA: 3:12 - loss: 0.7929 - accuracy: 0.78 - ETA: 3:10 - loss: 0.7948 - accuracy: 0.78 - ETA: 3:08 - loss: 0.7979 - accuracy: 0.78 - ETA: 3:07 - loss: 0.7982 - accuracy: 0.78 - ETA: 3:05 - loss: 0.8019 - accuracy: 0.78 - ETA: 3:03 - loss: 0.8049 - accuracy: 0.78 - ETA: 3:01 - loss: 0.8004 - accuracy: 0.78 - ETA: 2:59 - loss: 0.7983 - accuracy: 0.78 - ETA: 2:57 - loss: 0.7930 - accuracy: 0.78 - ETA: 2:55 - loss: 0.7939 - accuracy: 0.78 - ETA: 2:53 - loss: 0.7952 - accuracy: 0.78 - ETA: 2:51 - loss: 0.7929 - accuracy: 0.78 - ETA: 2:50 - loss: 0.7913 - accuracy: 0.78 - ETA: 2:48 - loss: 0.7914 - accuracy: 0.78 - ETA: 2:46 - loss: 0.7933 - accuracy: 0.78 - ETA: 2:44 - loss: 0.7918 - accuracy: 0.78 - ETA: 2:42 - loss: 0.7920 - accuracy: 0.78 - ETA: 2:40 - loss: 0.7931 - accuracy: 0.78 - ETA: 2:38 - loss: 0.8007 - accuracy: 0.78 - ETA: 2:36 - loss: 0.7992 - accuracy: 0.78 - ETA: 2:34 - loss: 0.8014 - accuracy: 0.78 - ETA: 2:33 - loss: 0.8013 - accuracy: 0.78 - ETA: 2:31 - loss: 0.8014 - accuracy: 0.78 - ETA: 2:29 - loss: 0.7995 - accuracy: 0.78 - ETA: 2:27 - loss: 0.7997 - accuracy: 0.78 - ETA: 2:25 - loss: 0.8025 - accuracy: 0.78 - ETA: 2:23 - loss: 0.8002 - accuracy: 0.78 - ETA: 2:22 - loss: 0.8039 - accuracy: 0.78 - ETA: 2:20 - loss: 0.8016 - accuracy: 0.78 - ETA: 2:18 - loss: 0.8024 - accuracy: 0.78 - ETA: 2:16 - loss: 0.8068 - accuracy: 0.78 - ETA: 2:14 - loss: 0.8057 - accuracy: 0.78 - ETA: 2:12 - loss: 0.8067 - accuracy: 0.78 - ETA: 2:10 - loss: 0.8055 - accuracy: 0.78 - ETA: 2:08 - loss: 0.8078 - accuracy: 0.78 - ETA: 2:06 - loss: 0.8074 - accuracy: 0.78 - ETA: 2:05 - loss: 0.8096 - accuracy: 0.78 - ETA: 2:03 - loss: 0.8119 - accuracy: 0.78 - ETA: 2:01 - loss: 0.8090 - accuracy: 0.78 - ETA: 1:59 - loss: 0.8134 - accuracy: 0.78 - ETA: 1:57 - loss: 0.8154 - accuracy: 0.78 - ETA: 1:55 - loss: 0.8166 - accuracy: 0.78 - ETA: 1:53 - loss: 0.8124 - accuracy: 0.78 - ETA: 1:51 - loss: 0.8101 - accuracy: 0.78 - ETA: 1:49 - loss: 0.8100 - accuracy: 0.78 - ETA: 1:47 - loss: 0.8100 - accuracy: 0.78 - ETA: 1:46 - loss: 0.8096 - accuracy: 0.78 - ETA: 1:44 - loss: 0.8103 - accuracy: 0.78 - ETA: 1:42 - loss: 0.8099 - accuracy: 0.78 - ETA: 1:40 - loss: 0.8095 - accuracy: 0.78 - ETA: 1:38 - loss: 0.8093 - accuracy: 0.78 - ETA: 1:36 - loss: 0.8082 - accuracy: 0.78 - ETA: 1:34 - loss: 0.8080 - accuracy: 0.78 - ETA: 1:33 - loss: 0.8078 - accuracy: 0.78 - ETA: 1:31 - loss: 0.8098 - accuracy: 0.78 - ETA: 1:29 - loss: 0.8114 - accuracy: 0.78 - ETA: 1:27 - loss: 0.8118 - accuracy: 0.78 - ETA: 1:25 - loss: 0.8145 - accuracy: 0.78 - ETA: 1:23 - loss: 0.8146 - accuracy: 0.78 - ETA: 1:21 - loss: 0.8127 - accuracy: 0.78 - ETA: 1:20 - loss: 0.8141 - accuracy: 0.78 - ETA: 1:18 - loss: 0.8137 - accuracy: 0.78 - ETA: 1:16 - loss: 0.8133 - accuracy: 0.78 - ETA: 1:14 - loss: 0.8113 - accuracy: 0.78 - ETA: 1:12 - loss: 0.8093 - accuracy: 0.78 - ETA: 1:10 - loss: 0.8081 - accuracy: 0.78 - ETA: 1:08 - loss: 0.8084 - accuracy: 0.78 - ETA: 1:07 - loss: 0.8079 - accuracy: 0.78 - ETA: 1:05 - loss: 0.8118 - accuracy: 0.78 - ETA: 1:03 - loss: 0.8135 - accuracy: 0.78 - ETA: 1:01 - loss: 0.8146 - accuracy: 0.78 - ETA: 59s - loss: 0.8120 - accuracy: 0.7816 - ETA: 57s - loss: 0.8130 - accuracy: 0.781 - ETA: 55s - loss: 0.8137 - accuracy: 0.781 - ETA: 53s - loss: 0.8149 - accuracy: 0.780 - ETA: 51s - loss: 0.8157 - accuracy: 0.780 - ETA: 50s - loss: 0.8176 - accuracy: 0.780 - ETA: 48s - loss: 0.8185 - accuracy: 0.780 - ETA: 46s - loss: 0.8186 - accuracy: 0.779 - ETA: 44s - loss: 0.8196 - accuracy: 0.779 - ETA: 42s - loss: 0.8195 - accuracy: 0.779 - ETA: 40s - loss: 0.8173 - accuracy: 0.779 - ETA: 38s - loss: 0.8166 - accuracy: 0.779 - ETA: 37s - loss: 0.8179 - accuracy: 0.779 - ETA: 35s - loss: 0.8160 - accuracy: 0.780 - ETA: 33s - loss: 0.8148 - accuracy: 0.780 - ETA: 31s - loss: 0.8162 - accuracy: 0.779 - ETA: 29s - loss: 0.8148 - accuracy: 0.780 - ETA: 27s - loss: 0.8147 - accuracy: 0.779 - ETA: 25s - loss: 0.8156 - accuracy: 0.779 - ETA: 23s - loss: 0.8148 - accuracy: 0.779 - ETA: 22s - loss: 0.8140 - accuracy: 0.780 - ETA: 20s - loss: 0.8154 - accuracy: 0.780 - ETA: 18s - loss: 0.8136 - accuracy: 0.780 - ETA: 16s - loss: 0.8113 - accuracy: 0.780 - ETA: 14s - loss: 0.8100 - accuracy: 0.781 - ETA: 12s - loss: 0.8094 - accuracy: 0.781 - ETA: 11s - loss: 0.8105 - accuracy: 0.780 - ETA: 9s - loss: 0.8106 - accuracy: 0.780 - ETA: 7s - loss: 0.8107 - accuracy: 0.78 - ETA: 5s - loss: 0.8106 - accuracy: 0.78 - ETA: 3s - loss: 0.8105 - accuracy: 0.78 - ETA: 1s - loss: 0.8127 - accuracy: 0.78 - 308s 16ms/step - loss: 0.8131 - accuracy: 0.7803 - val_loss: 2.0463 - val_accuracy: 0.7209\n",
      "Epoch 98/100\n",
      "19312/19312 [==============================] - ETA: 4:37 - loss: 0.8962 - accuracy: 0.75 - ETA: 4:38 - loss: 1.1283 - accuracy: 0.77 - ETA: 4:37 - loss: 0.9451 - accuracy: 0.80 - ETA: 4:35 - loss: 0.9052 - accuracy: 0.78 - ETA: 4:31 - loss: 0.9773 - accuracy: 0.78 - ETA: 4:32 - loss: 0.9177 - accuracy: 0.78 - ETA: 4:32 - loss: 0.8902 - accuracy: 0.78 - ETA: 4:30 - loss: 0.9172 - accuracy: 0.78 - ETA: 4:27 - loss: 0.8954 - accuracy: 0.78 - ETA: 4:25 - loss: 0.8792 - accuracy: 0.78 - ETA: 4:25 - loss: 0.8909 - accuracy: 0.78 - ETA: 4:23 - loss: 0.8561 - accuracy: 0.78 - ETA: 4:22 - loss: 0.8585 - accuracy: 0.79 - ETA: 4:20 - loss: 0.8873 - accuracy: 0.78 - ETA: 4:19 - loss: 0.8687 - accuracy: 0.79 - ETA: 4:17 - loss: 0.8516 - accuracy: 0.79 - ETA: 4:14 - loss: 0.8543 - accuracy: 0.79 - ETA: 4:12 - loss: 0.8567 - accuracy: 0.78 - ETA: 4:10 - loss: 0.8671 - accuracy: 0.78 - ETA: 4:07 - loss: 0.8604 - accuracy: 0.78 - ETA: 4:04 - loss: 0.8684 - accuracy: 0.78 - ETA: 4:02 - loss: 0.8750 - accuracy: 0.78 - ETA: 3:59 - loss: 0.8745 - accuracy: 0.78 - ETA: 3:57 - loss: 0.8859 - accuracy: 0.78 - ETA: 3:55 - loss: 0.8792 - accuracy: 0.77 - ETA: 3:53 - loss: 0.8737 - accuracy: 0.78 - ETA: 3:51 - loss: 0.8829 - accuracy: 0.78 - ETA: 3:50 - loss: 0.8768 - accuracy: 0.78 - ETA: 3:48 - loss: 0.8885 - accuracy: 0.78 - ETA: 3:46 - loss: 0.8792 - accuracy: 0.78 - ETA: 3:45 - loss: 0.8753 - accuracy: 0.78 - ETA: 3:43 - loss: 0.8768 - accuracy: 0.78 - ETA: 3:41 - loss: 0.8693 - accuracy: 0.78 - ETA: 3:39 - loss: 0.8610 - accuracy: 0.78 - ETA: 3:37 - loss: 0.8625 - accuracy: 0.78 - ETA: 3:35 - loss: 0.8617 - accuracy: 0.78 - ETA: 3:33 - loss: 0.8651 - accuracy: 0.78 - ETA: 3:32 - loss: 0.8655 - accuracy: 0.78 - ETA: 3:29 - loss: 0.8596 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8561 - accuracy: 0.78 - ETA: 3:26 - loss: 0.8482 - accuracy: 0.78 - ETA: 3:24 - loss: 0.8456 - accuracy: 0.78 - ETA: 3:22 - loss: 0.8528 - accuracy: 0.78 - ETA: 3:20 - loss: 0.8502 - accuracy: 0.78 - ETA: 3:18 - loss: 0.8453 - accuracy: 0.78 - ETA: 3:16 - loss: 0.8482 - accuracy: 0.78 - ETA: 3:14 - loss: 0.8434 - accuracy: 0.78 - ETA: 3:12 - loss: 0.8381 - accuracy: 0.78 - ETA: 3:10 - loss: 0.8335 - accuracy: 0.78 - ETA: 3:08 - loss: 0.8337 - accuracy: 0.78 - ETA: 3:06 - loss: 0.8323 - accuracy: 0.78 - ETA: 3:04 - loss: 0.8324 - accuracy: 0.78 - ETA: 3:03 - loss: 0.8331 - accuracy: 0.78 - ETA: 3:01 - loss: 0.8321 - accuracy: 0.78 - ETA: 2:59 - loss: 0.8331 - accuracy: 0.78 - ETA: 2:57 - loss: 0.8386 - accuracy: 0.78 - ETA: 2:55 - loss: 0.8411 - accuracy: 0.78 - ETA: 2:53 - loss: 0.8367 - accuracy: 0.78 - ETA: 2:52 - loss: 0.8362 - accuracy: 0.78 - ETA: 2:50 - loss: 0.8341 - accuracy: 0.78 - ETA: 2:48 - loss: 0.8366 - accuracy: 0.78 - ETA: 2:46 - loss: 0.8352 - accuracy: 0.78 - ETA: 2:44 - loss: 0.8316 - accuracy: 0.78 - ETA: 2:42 - loss: 0.8315 - accuracy: 0.78 - ETA: 2:40 - loss: 0.8351 - accuracy: 0.77 - ETA: 2:38 - loss: 0.8369 - accuracy: 0.77 - ETA: 2:37 - loss: 0.8378 - accuracy: 0.77 - ETA: 2:35 - loss: 0.8393 - accuracy: 0.77 - ETA: 2:33 - loss: 0.8351 - accuracy: 0.78 - ETA: 2:31 - loss: 0.8392 - accuracy: 0.77 - ETA: 2:29 - loss: 0.8393 - accuracy: 0.77 - ETA: 2:27 - loss: 0.8436 - accuracy: 0.78 - ETA: 2:25 - loss: 0.8445 - accuracy: 0.78 - ETA: 2:23 - loss: 0.8460 - accuracy: 0.78 - ETA: 2:22 - loss: 0.8433 - accuracy: 0.78 - ETA: 2:20 - loss: 0.8459 - accuracy: 0.78 - ETA: 2:18 - loss: 0.8441 - accuracy: 0.78 - ETA: 2:16 - loss: 0.8444 - accuracy: 0.77 - ETA: 2:14 - loss: 0.8418 - accuracy: 0.78 - ETA: 2:12 - loss: 0.8392 - accuracy: 0.78 - ETA: 2:10 - loss: 0.8403 - accuracy: 0.78 - ETA: 2:08 - loss: 0.8382 - accuracy: 0.77 - ETA: 2:07 - loss: 0.8388 - accuracy: 0.77 - ETA: 2:05 - loss: 0.8370 - accuracy: 0.77 - ETA: 2:03 - loss: 0.8364 - accuracy: 0.77 - ETA: 2:01 - loss: 0.8351 - accuracy: 0.77 - ETA: 1:59 - loss: 0.8361 - accuracy: 0.77 - ETA: 1:57 - loss: 0.8329 - accuracy: 0.78 - ETA: 1:55 - loss: 0.8317 - accuracy: 0.78 - ETA: 1:53 - loss: 0.8309 - accuracy: 0.78 - ETA: 1:51 - loss: 0.8266 - accuracy: 0.78 - ETA: 1:50 - loss: 0.8257 - accuracy: 0.78 - ETA: 1:48 - loss: 0.8311 - accuracy: 0.78 - ETA: 1:46 - loss: 0.8271 - accuracy: 0.78 - ETA: 1:44 - loss: 0.8263 - accuracy: 0.78 - ETA: 1:42 - loss: 0.8298 - accuracy: 0.78 - ETA: 1:40 - loss: 0.8292 - accuracy: 0.78 - ETA: 1:38 - loss: 0.8292 - accuracy: 0.78 - ETA: 1:37 - loss: 0.8266 - accuracy: 0.78 - ETA: 1:35 - loss: 0.8253 - accuracy: 0.78 - ETA: 1:33 - loss: 0.8252 - accuracy: 0.78 - ETA: 1:31 - loss: 0.8297 - accuracy: 0.78 - ETA: 1:29 - loss: 0.8284 - accuracy: 0.78 - ETA: 1:27 - loss: 0.8270 - accuracy: 0.78 - ETA: 1:25 - loss: 0.8260 - accuracy: 0.78 - ETA: 1:23 - loss: 0.8276 - accuracy: 0.78 - ETA: 1:22 - loss: 0.8264 - accuracy: 0.78 - ETA: 1:20 - loss: 0.8274 - accuracy: 0.77 - ETA: 1:18 - loss: 0.8262 - accuracy: 0.78 - ETA: 1:16 - loss: 0.8267 - accuracy: 0.77 - ETA: 1:14 - loss: 0.8271 - accuracy: 0.77 - ETA: 1:12 - loss: 0.8248 - accuracy: 0.77 - ETA: 1:10 - loss: 0.8254 - accuracy: 0.77 - ETA: 1:08 - loss: 0.8238 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8250 - accuracy: 0.78 - ETA: 1:05 - loss: 0.8242 - accuracy: 0.78 - ETA: 1:03 - loss: 0.8258 - accuracy: 0.78 - ETA: 1:01 - loss: 0.8294 - accuracy: 0.78 - ETA: 59s - loss: 0.8305 - accuracy: 0.7799 - ETA: 57s - loss: 0.8332 - accuracy: 0.779 - ETA: 55s - loss: 0.8336 - accuracy: 0.779 - ETA: 53s - loss: 0.8329 - accuracy: 0.779 - ETA: 52s - loss: 0.8320 - accuracy: 0.779 - ETA: 50s - loss: 0.8305 - accuracy: 0.779 - ETA: 48s - loss: 0.8294 - accuracy: 0.779 - ETA: 46s - loss: 0.8281 - accuracy: 0.779 - ETA: 44s - loss: 0.8275 - accuracy: 0.779 - ETA: 42s - loss: 0.8292 - accuracy: 0.779 - ETA: 40s - loss: 0.8285 - accuracy: 0.779 - ETA: 39s - loss: 0.8260 - accuracy: 0.780 - ETA: 37s - loss: 0.8228 - accuracy: 0.780 - ETA: 35s - loss: 0.8226 - accuracy: 0.780 - ETA: 33s - loss: 0.8250 - accuracy: 0.779 - ETA: 31s - loss: 0.8242 - accuracy: 0.779 - ETA: 29s - loss: 0.8254 - accuracy: 0.779 - ETA: 27s - loss: 0.8258 - accuracy: 0.779 - ETA: 25s - loss: 0.8247 - accuracy: 0.779 - ETA: 24s - loss: 0.8234 - accuracy: 0.779 - ETA: 22s - loss: 0.8235 - accuracy: 0.780 - ETA: 20s - loss: 0.8235 - accuracy: 0.779 - ETA: 18s - loss: 0.8229 - accuracy: 0.780 - ETA: 16s - loss: 0.8222 - accuracy: 0.779 - ETA: 14s - loss: 0.8220 - accuracy: 0.779 - ETA: 12s - loss: 0.8237 - accuracy: 0.779 - ETA: 10s - loss: 0.8224 - accuracy: 0.779 - ETA: 9s - loss: 0.8247 - accuracy: 0.779 - ETA: 7s - loss: 0.8254 - accuracy: 0.77 - ETA: 5s - loss: 0.8247 - accuracy: 0.77 - ETA: 3s - loss: 0.8244 - accuracy: 0.77 - ETA: 1s - loss: 0.8237 - accuracy: 0.78 - 306s 16ms/step - loss: 0.8239 - accuracy: 0.7798 - val_loss: 2.1096 - val_accuracy: 0.7271\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:33 - loss: 1.1932 - accuracy: 0.68 - ETA: 4:43 - loss: 1.0391 - accuracy: 0.73 - ETA: 4:40 - loss: 0.9202 - accuracy: 0.75 - ETA: 4:41 - loss: 0.8569 - accuracy: 0.77 - ETA: 4:37 - loss: 0.8631 - accuracy: 0.76 - ETA: 4:36 - loss: 0.8364 - accuracy: 0.77 - ETA: 4:32 - loss: 0.8178 - accuracy: 0.77 - ETA: 4:29 - loss: 0.9049 - accuracy: 0.78 - ETA: 4:29 - loss: 0.8616 - accuracy: 0.78 - ETA: 4:26 - loss: 0.8651 - accuracy: 0.78 - ETA: 4:23 - loss: 0.8475 - accuracy: 0.78 - ETA: 4:22 - loss: 0.8257 - accuracy: 0.78 - ETA: 4:19 - loss: 0.8174 - accuracy: 0.78 - ETA: 4:19 - loss: 0.8096 - accuracy: 0.78 - ETA: 4:17 - loss: 0.8200 - accuracy: 0.78 - ETA: 4:14 - loss: 0.8157 - accuracy: 0.78 - ETA: 4:11 - loss: 0.8034 - accuracy: 0.79 - ETA: 4:09 - loss: 0.8009 - accuracy: 0.78 - ETA: 4:06 - loss: 0.7998 - accuracy: 0.78 - ETA: 4:04 - loss: 0.8020 - accuracy: 0.78 - ETA: 4:02 - loss: 0.8052 - accuracy: 0.78 - ETA: 4:00 - loss: 0.7995 - accuracy: 0.78 - ETA: 3:58 - loss: 0.7893 - accuracy: 0.79 - ETA: 3:56 - loss: 0.7881 - accuracy: 0.79 - ETA: 3:54 - loss: 0.7795 - accuracy: 0.79 - ETA: 3:53 - loss: 0.7813 - accuracy: 0.79 - ETA: 3:51 - loss: 0.8015 - accuracy: 0.79 - ETA: 3:49 - loss: 0.7985 - accuracy: 0.79 - ETA: 3:47 - loss: 0.7972 - accuracy: 0.79 - ETA: 3:45 - loss: 0.7983 - accuracy: 0.79 - ETA: 3:43 - loss: 0.8064 - accuracy: 0.78 - ETA: 3:41 - loss: 0.8107 - accuracy: 0.78 - ETA: 3:39 - loss: 0.8156 - accuracy: 0.78 - ETA: 3:37 - loss: 0.8114 - accuracy: 0.78 - ETA: 3:36 - loss: 0.8231 - accuracy: 0.78 - ETA: 3:34 - loss: 0.8191 - accuracy: 0.78 - ETA: 3:32 - loss: 0.8177 - accuracy: 0.78 - ETA: 3:30 - loss: 0.8324 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8267 - accuracy: 0.78 - ETA: 3:26 - loss: 0.8329 - accuracy: 0.78 - ETA: 3:24 - loss: 0.8309 - accuracy: 0.78 - ETA: 3:23 - loss: 0.8236 - accuracy: 0.78 - ETA: 3:21 - loss: 0.8354 - accuracy: 0.78 - ETA: 3:19 - loss: 0.8381 - accuracy: 0.78 - ETA: 3:17 - loss: 0.8418 - accuracy: 0.78 - ETA: 3:15 - loss: 0.8353 - accuracy: 0.78 - ETA: 3:13 - loss: 0.8297 - accuracy: 0.78 - ETA: 3:11 - loss: 0.8278 - accuracy: 0.78 - ETA: 3:09 - loss: 0.8247 - accuracy: 0.79 - ETA: 3:08 - loss: 0.8364 - accuracy: 0.78 - ETA: 3:06 - loss: 0.8372 - accuracy: 0.78 - ETA: 3:04 - loss: 0.8398 - accuracy: 0.78 - ETA: 3:02 - loss: 0.8358 - accuracy: 0.78 - ETA: 3:00 - loss: 0.8306 - accuracy: 0.78 - ETA: 2:58 - loss: 0.8300 - accuracy: 0.78 - ETA: 2:56 - loss: 0.8324 - accuracy: 0.78 - ETA: 2:54 - loss: 0.8332 - accuracy: 0.78 - ETA: 2:52 - loss: 0.8324 - accuracy: 0.78 - ETA: 2:50 - loss: 0.8353 - accuracy: 0.78 - ETA: 2:48 - loss: 0.8310 - accuracy: 0.78 - ETA: 2:47 - loss: 0.8299 - accuracy: 0.78 - ETA: 2:45 - loss: 0.8289 - accuracy: 0.78 - ETA: 2:43 - loss: 0.8253 - accuracy: 0.78 - ETA: 2:41 - loss: 0.8257 - accuracy: 0.78 - ETA: 2:40 - loss: 0.8275 - accuracy: 0.78 - ETA: 2:38 - loss: 0.8229 - accuracy: 0.78 - ETA: 2:36 - loss: 0.8197 - accuracy: 0.78 - ETA: 2:34 - loss: 0.8195 - accuracy: 0.78 - ETA: 2:32 - loss: 0.8180 - accuracy: 0.78 - ETA: 2:30 - loss: 0.8193 - accuracy: 0.78 - ETA: 2:28 - loss: 0.8223 - accuracy: 0.78 - ETA: 2:26 - loss: 0.8224 - accuracy: 0.78 - ETA: 2:24 - loss: 0.8197 - accuracy: 0.78 - ETA: 2:22 - loss: 0.8156 - accuracy: 0.78 - ETA: 2:21 - loss: 0.8155 - accuracy: 0.78 - ETA: 2:19 - loss: 0.8152 - accuracy: 0.78 - ETA: 2:17 - loss: 0.8131 - accuracy: 0.78 - ETA: 2:15 - loss: 0.8104 - accuracy: 0.78 - ETA: 2:13 - loss: 0.8110 - accuracy: 0.78 - ETA: 2:11 - loss: 0.8095 - accuracy: 0.78 - ETA: 2:09 - loss: 0.8157 - accuracy: 0.78 - ETA: 2:08 - loss: 0.8162 - accuracy: 0.78 - ETA: 2:06 - loss: 0.8187 - accuracy: 0.78 - ETA: 2:04 - loss: 0.8179 - accuracy: 0.78 - ETA: 2:02 - loss: 0.8170 - accuracy: 0.78 - ETA: 2:00 - loss: 0.8138 - accuracy: 0.78 - ETA: 1:58 - loss: 0.8172 - accuracy: 0.78 - ETA: 1:56 - loss: 0.8168 - accuracy: 0.78 - ETA: 1:55 - loss: 0.8150 - accuracy: 0.78 - ETA: 1:53 - loss: 0.8125 - accuracy: 0.78 - ETA: 1:51 - loss: 0.8109 - accuracy: 0.78 - ETA: 1:49 - loss: 0.8102 - accuracy: 0.78 - ETA: 1:47 - loss: 0.8115 - accuracy: 0.78 - ETA: 1:45 - loss: 0.8116 - accuracy: 0.78 - ETA: 1:43 - loss: 0.8103 - accuracy: 0.78 - ETA: 1:42 - loss: 0.8069 - accuracy: 0.78 - ETA: 1:40 - loss: 0.8088 - accuracy: 0.78 - ETA: 1:38 - loss: 0.8113 - accuracy: 0.78 - ETA: 1:36 - loss: 0.8090 - accuracy: 0.78 - ETA: 1:34 - loss: 0.8118 - accuracy: 0.78 - ETA: 1:32 - loss: 0.8121 - accuracy: 0.78 - ETA: 1:31 - loss: 0.8148 - accuracy: 0.78 - ETA: 1:29 - loss: 0.8127 - accuracy: 0.78 - ETA: 1:27 - loss: 0.8172 - accuracy: 0.78 - ETA: 1:25 - loss: 0.8165 - accuracy: 0.78 - ETA: 1:23 - loss: 0.8178 - accuracy: 0.78 - ETA: 1:21 - loss: 0.8190 - accuracy: 0.78 - ETA: 1:19 - loss: 0.8187 - accuracy: 0.78 - ETA: 1:17 - loss: 0.8178 - accuracy: 0.78 - ETA: 1:16 - loss: 0.8172 - accuracy: 0.78 - ETA: 1:14 - loss: 0.8156 - accuracy: 0.78 - ETA: 1:12 - loss: 0.8190 - accuracy: 0.78 - ETA: 1:10 - loss: 0.8176 - accuracy: 0.78 - ETA: 1:08 - loss: 0.8177 - accuracy: 0.78 - ETA: 1:06 - loss: 0.8177 - accuracy: 0.78 - ETA: 1:04 - loss: 0.8188 - accuracy: 0.78 - ETA: 1:02 - loss: 0.8190 - accuracy: 0.78 - ETA: 1:01 - loss: 0.8177 - accuracy: 0.78 - ETA: 59s - loss: 0.8159 - accuracy: 0.7878 - ETA: 57s - loss: 0.8144 - accuracy: 0.788 - ETA: 55s - loss: 0.8138 - accuracy: 0.788 - ETA: 53s - loss: 0.8155 - accuracy: 0.787 - ETA: 51s - loss: 0.8163 - accuracy: 0.787 - ETA: 49s - loss: 0.8183 - accuracy: 0.787 - ETA: 48s - loss: 0.8176 - accuracy: 0.786 - ETA: 46s - loss: 0.8172 - accuracy: 0.787 - ETA: 44s - loss: 0.8168 - accuracy: 0.786 - ETA: 42s - loss: 0.8190 - accuracy: 0.786 - ETA: 40s - loss: 0.8178 - accuracy: 0.786 - ETA: 38s - loss: 0.8180 - accuracy: 0.786 - ETA: 37s - loss: 0.8179 - accuracy: 0.786 - ETA: 35s - loss: 0.8168 - accuracy: 0.785 - ETA: 33s - loss: 0.8151 - accuracy: 0.786 - ETA: 31s - loss: 0.8167 - accuracy: 0.785 - ETA: 29s - loss: 0.8190 - accuracy: 0.785 - ETA: 27s - loss: 0.8213 - accuracy: 0.785 - ETA: 25s - loss: 0.8227 - accuracy: 0.785 - ETA: 23s - loss: 0.8231 - accuracy: 0.785 - ETA: 22s - loss: 0.8217 - accuracy: 0.785 - ETA: 20s - loss: 0.8240 - accuracy: 0.785 - ETA: 18s - loss: 0.8248 - accuracy: 0.785 - ETA: 16s - loss: 0.8258 - accuracy: 0.784 - ETA: 14s - loss: 0.8247 - accuracy: 0.784 - ETA: 12s - loss: 0.8269 - accuracy: 0.784 - ETA: 10s - loss: 0.8260 - accuracy: 0.784 - ETA: 9s - loss: 0.8272 - accuracy: 0.784 - ETA: 7s - loss: 0.8264 - accuracy: 0.78 - ETA: 5s - loss: 0.8262 - accuracy: 0.78 - ETA: 3s - loss: 0.8265 - accuracy: 0.78 - ETA: 1s - loss: 0.8270 - accuracy: 0.78 - 306s 16ms/step - loss: 0.8270 - accuracy: 0.7841 - val_loss: 2.2264 - val_accuracy: 0.7225\n",
      "Epoch 100/100\n",
      "19312/19312 [==============================] - ETA: 4:39 - loss: 0.8523 - accuracy: 0.73 - ETA: 4:32 - loss: 0.9149 - accuracy: 0.74 - ETA: 4:28 - loss: 0.8459 - accuracy: 0.76 - ETA: 4:28 - loss: 0.8297 - accuracy: 0.76 - ETA: 4:29 - loss: 0.8092 - accuracy: 0.76 - ETA: 4:26 - loss: 0.7818 - accuracy: 0.77 - ETA: 4:27 - loss: 0.7851 - accuracy: 0.77 - ETA: 4:26 - loss: 0.8005 - accuracy: 0.76 - ETA: 4:24 - loss: 0.8450 - accuracy: 0.76 - ETA: 4:23 - loss: 0.8158 - accuracy: 0.77 - ETA: 4:21 - loss: 0.8049 - accuracy: 0.77 - ETA: 4:19 - loss: 0.8064 - accuracy: 0.77 - ETA: 4:16 - loss: 0.8230 - accuracy: 0.77 - ETA: 4:13 - loss: 0.8196 - accuracy: 0.77 - ETA: 4:11 - loss: 0.8104 - accuracy: 0.77 - ETA: 4:09 - loss: 0.7996 - accuracy: 0.78 - ETA: 4:07 - loss: 0.7977 - accuracy: 0.78 - ETA: 4:06 - loss: 0.8176 - accuracy: 0.77 - ETA: 4:03 - loss: 0.8145 - accuracy: 0.77 - ETA: 4:01 - loss: 0.8091 - accuracy: 0.78 - ETA: 3:59 - loss: 0.7987 - accuracy: 0.78 - ETA: 3:57 - loss: 0.7919 - accuracy: 0.78 - ETA: 3:55 - loss: 0.7864 - accuracy: 0.78 - ETA: 3:54 - loss: 0.7802 - accuracy: 0.78 - ETA: 3:52 - loss: 0.7745 - accuracy: 0.78 - ETA: 3:51 - loss: 0.7851 - accuracy: 0.78 - ETA: 3:49 - loss: 0.7919 - accuracy: 0.78 - ETA: 3:47 - loss: 0.7801 - accuracy: 0.78 - ETA: 3:45 - loss: 0.7793 - accuracy: 0.78 - ETA: 3:44 - loss: 0.7839 - accuracy: 0.78 - ETA: 3:42 - loss: 0.7815 - accuracy: 0.78 - ETA: 3:40 - loss: 0.7762 - accuracy: 0.78 - ETA: 3:38 - loss: 0.7754 - accuracy: 0.78 - ETA: 3:37 - loss: 0.7778 - accuracy: 0.78 - ETA: 3:35 - loss: 0.7755 - accuracy: 0.78 - ETA: 3:33 - loss: 0.7735 - accuracy: 0.78 - ETA: 3:31 - loss: 0.7795 - accuracy: 0.77 - ETA: 3:30 - loss: 0.7771 - accuracy: 0.77 - ETA: 3:28 - loss: 0.7757 - accuracy: 0.77 - ETA: 3:26 - loss: 0.7825 - accuracy: 0.77 - ETA: 3:24 - loss: 0.7801 - accuracy: 0.77 - ETA: 3:22 - loss: 0.7798 - accuracy: 0.77 - ETA: 3:20 - loss: 0.7765 - accuracy: 0.77 - ETA: 3:18 - loss: 0.7770 - accuracy: 0.77 - ETA: 3:16 - loss: 0.7713 - accuracy: 0.78 - ETA: 3:15 - loss: 0.7710 - accuracy: 0.77 - ETA: 3:12 - loss: 0.7731 - accuracy: 0.77 - ETA: 3:11 - loss: 0.7699 - accuracy: 0.77 - ETA: 3:09 - loss: 0.7639 - accuracy: 0.78 - ETA: 3:07 - loss: 0.7622 - accuracy: 0.78 - ETA: 3:05 - loss: 0.7582 - accuracy: 0.78 - ETA: 3:03 - loss: 0.7611 - accuracy: 0.78 - ETA: 3:01 - loss: 0.7704 - accuracy: 0.78 - ETA: 2:59 - loss: 0.7729 - accuracy: 0.78 - ETA: 2:57 - loss: 0.7737 - accuracy: 0.78 - ETA: 2:55 - loss: 0.7766 - accuracy: 0.78 - ETA: 2:53 - loss: 0.7761 - accuracy: 0.78 - ETA: 2:52 - loss: 0.7774 - accuracy: 0.78 - ETA: 2:50 - loss: 0.7800 - accuracy: 0.78 - ETA: 2:48 - loss: 0.7782 - accuracy: 0.78 - ETA: 2:46 - loss: 0.7775 - accuracy: 0.78 - ETA: 2:44 - loss: 0.7737 - accuracy: 0.78 - ETA: 2:43 - loss: 0.7753 - accuracy: 0.78 - ETA: 2:41 - loss: 0.7734 - accuracy: 0.78 - ETA: 2:39 - loss: 0.7764 - accuracy: 0.77 - ETA: 2:37 - loss: 0.7748 - accuracy: 0.78 - ETA: 2:35 - loss: 0.7791 - accuracy: 0.78 - ETA: 2:33 - loss: 0.7745 - accuracy: 0.78 - ETA: 2:31 - loss: 0.7786 - accuracy: 0.78 - ETA: 2:29 - loss: 0.7769 - accuracy: 0.78 - ETA: 2:28 - loss: 0.7789 - accuracy: 0.78 - ETA: 2:26 - loss: 0.7797 - accuracy: 0.78 - ETA: 2:24 - loss: 0.7774 - accuracy: 0.78 - ETA: 2:22 - loss: 0.7744 - accuracy: 0.78 - ETA: 2:20 - loss: 0.7752 - accuracy: 0.78 - ETA: 2:19 - loss: 0.7728 - accuracy: 0.78 - ETA: 2:17 - loss: 0.7780 - accuracy: 0.78 - ETA: 2:15 - loss: 0.7788 - accuracy: 0.78 - ETA: 2:13 - loss: 0.7780 - accuracy: 0.78 - ETA: 2:11 - loss: 0.7783 - accuracy: 0.78 - ETA: 2:09 - loss: 0.7755 - accuracy: 0.78 - ETA: 2:08 - loss: 0.7749 - accuracy: 0.78 - ETA: 2:06 - loss: 0.7738 - accuracy: 0.78 - ETA: 2:04 - loss: 0.7718 - accuracy: 0.78 - ETA: 2:02 - loss: 0.7691 - accuracy: 0.78 - ETA: 2:00 - loss: 0.7671 - accuracy: 0.78 - ETA: 1:58 - loss: 0.7683 - accuracy: 0.78 - ETA: 1:56 - loss: 0.7685 - accuracy: 0.78 - ETA: 1:55 - loss: 0.7701 - accuracy: 0.78 - ETA: 1:53 - loss: 0.7712 - accuracy: 0.78 - ETA: 1:51 - loss: 0.7736 - accuracy: 0.78 - ETA: 1:49 - loss: 0.7763 - accuracy: 0.78 - ETA: 1:47 - loss: 0.7752 - accuracy: 0.78 - ETA: 1:45 - loss: 0.7746 - accuracy: 0.78 - ETA: 1:43 - loss: 0.7758 - accuracy: 0.78 - ETA: 1:42 - loss: 0.7770 - accuracy: 0.78 - ETA: 1:40 - loss: 0.7785 - accuracy: 0.78 - ETA: 1:38 - loss: 0.7781 - accuracy: 0.78 - ETA: 1:36 - loss: 0.7758 - accuracy: 0.78 - ETA: 1:34 - loss: 0.7773 - accuracy: 0.78 - ETA: 1:32 - loss: 0.7770 - accuracy: 0.78 - ETA: 1:30 - loss: 0.7764 - accuracy: 0.78 - ETA: 1:28 - loss: 0.7787 - accuracy: 0.78 - ETA: 1:27 - loss: 0.7799 - accuracy: 0.78 - ETA: 1:25 - loss: 0.7810 - accuracy: 0.78 - ETA: 1:23 - loss: 0.7852 - accuracy: 0.78 - ETA: 1:21 - loss: 0.7895 - accuracy: 0.78 - ETA: 1:19 - loss: 0.7894 - accuracy: 0.78 - ETA: 1:17 - loss: 0.7894 - accuracy: 0.78 - ETA: 1:15 - loss: 0.7881 - accuracy: 0.78 - ETA: 1:14 - loss: 0.7894 - accuracy: 0.78 - ETA: 1:12 - loss: 0.7925 - accuracy: 0.78 - ETA: 1:10 - loss: 0.7944 - accuracy: 0.78 - ETA: 1:08 - loss: 0.7954 - accuracy: 0.78 - ETA: 1:06 - loss: 0.7950 - accuracy: 0.78 - ETA: 1:04 - loss: 0.7965 - accuracy: 0.78 - ETA: 1:02 - loss: 0.7940 - accuracy: 0.78 - ETA: 1:00 - loss: 0.7942 - accuracy: 0.78 - ETA: 58s - loss: 0.7954 - accuracy: 0.7815 - ETA: 57s - loss: 0.7965 - accuracy: 0.781 - ETA: 55s - loss: 0.7950 - accuracy: 0.782 - ETA: 53s - loss: 0.7988 - accuracy: 0.781 - ETA: 51s - loss: 0.8003 - accuracy: 0.781 - ETA: 49s - loss: 0.8010 - accuracy: 0.781 - ETA: 47s - loss: 0.8004 - accuracy: 0.781 - ETA: 46s - loss: 0.7996 - accuracy: 0.781 - ETA: 44s - loss: 0.8011 - accuracy: 0.781 - ETA: 42s - loss: 0.7999 - accuracy: 0.781 - ETA: 40s - loss: 0.8004 - accuracy: 0.781 - ETA: 38s - loss: 0.8021 - accuracy: 0.781 - ETA: 36s - loss: 0.8003 - accuracy: 0.781 - ETA: 34s - loss: 0.7993 - accuracy: 0.781 - ETA: 33s - loss: 0.7994 - accuracy: 0.781 - ETA: 31s - loss: 0.7999 - accuracy: 0.781 - ETA: 29s - loss: 0.8019 - accuracy: 0.781 - ETA: 27s - loss: 0.8015 - accuracy: 0.781 - ETA: 25s - loss: 0.8021 - accuracy: 0.781 - ETA: 23s - loss: 0.8046 - accuracy: 0.781 - ETA: 21s - loss: 0.8069 - accuracy: 0.781 - ETA: 20s - loss: 0.8091 - accuracy: 0.780 - ETA: 18s - loss: 0.8087 - accuracy: 0.780 - ETA: 16s - loss: 0.8084 - accuracy: 0.780 - ETA: 14s - loss: 0.8074 - accuracy: 0.780 - ETA: 12s - loss: 0.8085 - accuracy: 0.780 - ETA: 10s - loss: 0.8110 - accuracy: 0.780 - ETA: 9s - loss: 0.8113 - accuracy: 0.780 - ETA: 7s - loss: 0.8109 - accuracy: 0.78 - ETA: 5s - loss: 0.8113 - accuracy: 0.78 - ETA: 3s - loss: 0.8110 - accuracy: 0.78 - ETA: 1s - loss: 0.8117 - accuracy: 0.78 - 305s 16ms/step - loss: 0.8112 - accuracy: 0.7801 - val_loss: 2.2380 - val_accuracy: 0.7217\n",
      "2020-12-05 22:25:08.132118\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "t5=datetime.datetime.now()\n",
    "print(t5)\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n",
    "t6=datetime.datetime.now()\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [1.9941744076635408, 1.6555630186127934, 1.4993723716319138, 1.404351697819256, 1.3845813303019447, 1.3218510019332386, 1.320363012819612, 1.2917453257236255, 1.2852074443047328, 1.2766851898453255, 1.2795445241279348, 1.2902251590135108, 1.2812172504754065, 1.3083874939835376, 1.3250302196808004, 1.3421667557272217, 1.3857181914649066, 1.3671940166922083, 1.3392790984875371, 1.416131678094625, 1.3968325734237232, 1.4964405785166814, 1.4816215889477093, 1.4498402487789777, 1.479912767822043, 1.4938821664234698, 1.4646212926536002, 1.5099088665762164, 1.483924268935625, 1.4692295702576612, 1.5590405114616857, 1.5731336315810298, 1.5702813540489486, 1.5711605022056772, 1.6087628417835642, 1.6382934940999327, 1.532078767988, 1.6401925727333138, 1.584530860228824, 1.64018712383937, 1.7513275039840321, 1.7969376559730494, 1.6931957924778256, 1.73903087778204, 1.7010283486199789, 1.7730557546528705, 1.6763921158978796, 1.6881912280422582, 1.8773317071907167, 1.6686773835859774, 1.866996452733828, 1.9037254972718571, 1.8174975794475996, 1.898711940619634, 1.9192623903500068, 1.7035733739098893, 1.8527039348474321, 1.811926237271424, 1.7664974866186913, 2.042981478510794, 1.8852693864242165, 1.7784029521120583, 1.9533093116574218, 1.8494897979736131, 1.8669942297484223, 2.097863211916159, 1.9247175457561996, 1.947390594944546, 2.06181416809744, 1.7564723686442214, 1.806925731678882, 1.8987269392663289, 1.9873358430416102, 1.774245865598281, 1.9644381381088372, 1.9061206487375995, 2.083934698891852, 2.292563101869608, 1.9977918908472114, 2.025372314388941, 2.123030178096137, 2.071289608803909, 2.043428746729219, 2.067295602400324, 2.169753345502141, 2.137262928310599, 2.3285038842007495, 2.3650820774181853, 2.136232013854459, 2.019621519673115, 1.975125512836833, 2.189494868963, 2.2777210096563456, 2.177850090610633, 2.118099514434342, 2.046634337723835, 2.0462605338778945, 2.1095912587595764, 2.2263682775059013, 2.238004866631832], 'val_accuracy': [0.5203976035118103, 0.5999171733856201, 0.6197970509529114, 0.6477531790733337, 0.6543797850608826, 0.66473388671875, 0.674673855304718, 0.6839925646781921, 0.6939324736595154, 0.6928970813751221, 0.6989024877548218, 0.6997308135032654, 0.7080140709877014, 0.7067716121673584, 0.7061503529548645, 0.6989024877548218, 0.7150548696517944, 0.7154690623283386, 0.7061503529548645, 0.7169185876846313, 0.7109132409095764, 0.7123628258705139, 0.714640736579895, 0.7121556997299194, 0.7167115211486816, 0.7179540395736694, 0.7185752987861633, 0.7154690623283386, 0.721681535243988, 0.712984025478363, 0.720024824142456, 0.7212673425674438, 0.7078070044517517, 0.7208531498908997, 0.720024824142456, 0.7094636559486389, 0.7171257138252258, 0.7119486331939697, 0.722923994064331, 0.7204390168190002, 0.7177469730377197, 0.7204390168190002, 0.7191964983940125, 0.7225098609924316, 0.721681535243988, 0.7218886017799377, 0.7208531498908997, 0.7175398468971252, 0.715883195400238, 0.7142265439033508, 0.7127769589424133, 0.7185752987861633, 0.7177469730377197, 0.7125698924064636, 0.7212673425674438, 0.7262372970581055, 0.72064608335495, 0.7268585562705994, 0.721681535243988, 0.7272727489471436, 0.7239593863487244, 0.7189894318580627, 0.722923994064331, 0.7212673425674438, 0.7283081412315369, 0.7220956683158875, 0.722923994064331, 0.7252019047737122, 0.7260302305221558, 0.7260302305221558, 0.7281010746955872, 0.7241665124893188, 0.731828510761261, 0.7179540395736694, 0.725823163986206, 0.7266514897346497, 0.7266514897346497, 0.7252019047737122, 0.7281010746955872, 0.7231310606002808, 0.7194036245346069, 0.724787712097168, 0.7299647927284241, 0.7210602760314941, 0.7291364669799805, 0.7260302305221558, 0.725823163986206, 0.7194036245346069, 0.7299647927284241, 0.7291364669799805, 0.7264444231987, 0.7274798154830933, 0.7237523198127747, 0.723545253276825, 0.7185752987861633, 0.7256160974502563, 0.7208531498908997, 0.7270656228065491, 0.7225098609924316, 0.721681535243988], 'loss': [6.159444176271719, 2.151947087064299, 1.8132528775767442, 1.633255716286717, 1.49144137221718, 1.3967385501434908, 1.3338264702960492, 1.2528427714835344, 1.1924627471187437, 1.1555530600243595, 1.1119622983711261, 1.1161030331424375, 1.0726578293403715, 1.0720466811892013, 1.0214240586550254, 1.0296074775199606, 1.000206044121231, 0.9940820946215398, 1.0080897514743061, 0.9917571016254757, 1.0095536161673988, 1.0074825995009895, 0.9715303463094375, 0.9721746300505327, 0.9503030600682111, 0.945107275331524, 0.9671064557965965, 0.9269297082955519, 0.9344145702545368, 0.9023333475327038, 0.9059193789613277, 0.9175247975687597, 0.9554330303635395, 0.9378236397890978, 0.9378833290260492, 0.8875263924922643, 0.9090743701420446, 0.9084176334746139, 0.9247955235945062, 0.89438456341365, 0.9038364475387725, 0.9097082287986711, 0.8877831230305796, 0.8668965429141685, 0.8550396766066057, 0.8619809005511331, 0.891636798425262, 0.8476895627248554, 0.8649016938727062, 0.8951441065378197, 0.8725588175019846, 0.8599861369413488, 0.86696220644269, 0.8382923454416618, 0.864357319269283, 0.8720698703293378, 0.8285693205281932, 0.8599198128234876, 0.839299745715741, 0.8450759146563159, 0.8232612959985014, 0.8437925604324057, 0.8371432000383822, 0.8291555870241041, 0.851799685646901, 0.8344973916343745, 0.8327968963039939, 0.830270604200371, 0.8364434381013284, 0.8330134002749546, 0.7997082016541134, 0.8038493446209456, 0.816467782437752, 0.8083447214484512, 0.8209106060425506, 0.808013595424611, 0.8308720044983056, 0.8668041858874577, 0.8476852654620647, 0.8223142947356564, 0.851476384917862, 0.7983844117774584, 0.8076983105079537, 0.8206376089176661, 0.822556816158753, 0.8109783063570922, 0.7838869455340685, 0.8313246014301897, 0.8261464024834526, 0.7867594661056847, 0.7895982645223628, 0.8467065307752298, 0.8138306409046486, 0.8470441880261691, 0.8148977995511413, 0.837075513359329, 0.8131344844807054, 0.8238783913796464, 0.8269749613171683, 0.8111918990831288], 'accuracy': [0.29266778, 0.47245237, 0.53717893, 0.57068145, 0.59853977, 0.6218931, 0.6358741, 0.65301365, 0.669273, 0.6752796, 0.68553233, 0.68941593, 0.7026719, 0.7059859, 0.71670467, 0.7161868, 0.72265947, 0.7276305, 0.7308927, 0.72747517, 0.72659487, 0.72804475, 0.73342997, 0.73353356, 0.73710644, 0.74042046, 0.7397473, 0.7422328, 0.74725556, 0.74596107, 0.75, 0.75212306, 0.7399544, 0.7415079, 0.7514499, 0.76035625, 0.7563173, 0.756628, 0.753314, 0.7607187, 0.7569387, 0.75486743, 0.7608223, 0.76455057, 0.76455057, 0.76506835, 0.76196146, 0.76900375, 0.7644988, 0.76196146, 0.7660522, 0.7715928, 0.7699358, 0.7677092, 0.76646644, 0.76801986, 0.7726802, 0.7726284, 0.77066076, 0.7718517, 0.7779101, 0.7721106, 0.773198, 0.77345693, 0.7693144, 0.7749068, 0.7721624, 0.7765638, 0.7721624, 0.77413005, 0.7815866, 0.77589065, 0.7775994, 0.7828811, 0.77640843, 0.7795671, 0.77578706, 0.77029824, 0.77205884, 0.7815866, 0.77511394, 0.78277755, 0.779826, 0.7815348, 0.77816904, 0.7807063, 0.7818455, 0.7765638, 0.7735087, 0.7847452, 0.78433096, 0.7754246, 0.7833989, 0.7726802, 0.781483, 0.779826, 0.78029203, 0.779826, 0.7840721, 0.7801367]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = np.arange(0, len(history.history['loss']))\n",
    "\n",
    "# You can chose the style of your preference\n",
    "# print(plt.style.available) to see the available options\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "plt.figure()\n",
    "plt.plot(N, history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(N, history.history['accuracy'], label = \"train_acc\")\n",
    "plt.plot(N, history.history['val_loss'], label = \"val_loss\")\n",
    "plt.plot(N, history.history['val_accuracy'], label = \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# Make sure there exists a folder called output in the current directory\n",
    "# or replace 'output' with whatever direcory you want to put in the plots\n",
    "plt.show()\n",
    "plt.savefig('../Output/EpochResNet101V2.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
