{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet_v2 import ResNet101V2\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24136</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24137</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24138</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24139</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24140</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image class\n",
       "24136  winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg  wave\n",
       "24137  winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg  wave\n",
       "24138  winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg  wave\n",
       "24139  winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg  wave\n",
       "24140  winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg  wave"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_2.csv')\n",
    "train.sort_values(by=['class', 'image'])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24141/24141 [03:13<00:00, 124.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/train_frame/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24141, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X = np.array(train_image,np.float16)\n",
    "train_image=[]\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 224, 224, 3)\n",
      "(4829, 224, 224, 3)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained ResNet101V2 model\n",
    "base_model = ResNet101V2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet101v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, None, None, 6 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, None, None, 6 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, None, None, 2 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, None, None, 2 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, None, None, 2 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, None, None, 2 0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, None, None, 2 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, None, None, 5 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, None, None, 5 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, None, None, 5 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, None, None, 5 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, None, None, 5 0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, None, None, 5 0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, None, None, 1 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, None, None, 1 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, None, None, 1 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, None, None, 1 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, None, None, 1 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, None, None, 1 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, None, None, 1 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block7_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, None, None, 2 0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, None, None, 2 0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, None, None, 1 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, None, None, 1 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, None, None, 2 0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, None, None, 2 0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, None, None, 1 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, None, None, 1 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, None, None, 2 0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, None, None, 2 0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, None, None, 1 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, None, None, 1 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, None, None, 1 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, None, None, 2 0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, None, None, 2 0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block10_2_relu[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, None, None, 1 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, None, None, 1 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, None, None, 1 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, None, None, 2 0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, None, None, 2 0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, None, None, 1 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, None, None, 1 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, None, None, 1 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, None, None, 2 0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, None, None, 2 0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, None, None, 1 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, None, None, 1 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, None, None, 1 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, None, None, 2 0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, None, None, 2 0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, None, None, 1 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, None, None, 1 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, None, None, 1 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, None, None, 2 0           conv4_block14_1_bn[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, None, None, 2 0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, None, None, 1 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, None, None, 1 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, None, None, 1 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, None, None, 2 0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, None, None, 2 0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, None, None, 1 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, None, None, 1 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, None, None, 1 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, None, None, 2 0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, None, None, 2 0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, None, None, 1 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, None, None, 1 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, None, None, 1 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, None, None, 2 0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, None, None, 2 0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, None, None, 1 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, None, None, 1 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, None, None, 1 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, None, None, 2 0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, None, None, 2 0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, None, None, 1 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, None, None, 1 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, None, None, 1 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, None, None, 2 0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, None, None, 2 0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, None, None, 1 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, None, None, 1 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, None, None, 1 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, None, None, 2 0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, None, None, 2 0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, None, None, 1 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, None, None, 1 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, None, None, 1 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, None, None, 2 0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block21_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, None, None, 2 0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, None, None, 1 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, None, None, 1 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, None, None, 1 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, None, None, 2 0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, None, None, 2 0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, None, None, 1 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, None, None, 1 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, None, None, 1 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, None, None, 2 0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, None, None, 2 0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, None, None, 1 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, None, None, 1 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, None, None, 2 0           conv5_block1_0_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, None, None, 2 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, None, None, 2 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, None, None, 2 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, None, None, 2 0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 42,626,560\n",
      "Trainable params: 42,528,896\n",
      "Non-trainable params: 97,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'resnet101v2',\n",
       " 'layers': [{'name': 'input_1',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_1'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'conv1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((3, 3), (3, 3)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (7, 7),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'pool1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pool',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'pool1_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool1_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_0_conv', 0, 0, {}],\n",
       "     ['conv2_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}],\n",
       "     ['conv2_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_1',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_1', 0, 0, {}],\n",
       "     ['conv2_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_0_conv', 0, 0, {}],\n",
       "     ['conv3_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}],\n",
       "     ['conv3_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}],\n",
       "     ['conv3_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_2',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}],\n",
       "     ['conv3_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_0_conv', 0, 0, {}],\n",
       "     ['conv4_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}],\n",
       "     ['conv4_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}],\n",
       "     ['conv4_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}],\n",
       "     ['conv4_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block5_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block5_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}],\n",
       "     ['conv4_block5_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block6_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block6_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}],\n",
       "     ['conv4_block6_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block7_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block7_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}],\n",
       "     ['conv4_block7_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block8_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block8_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}],\n",
       "     ['conv4_block8_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block9_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block9_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}],\n",
       "     ['conv4_block9_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block10_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block10_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}],\n",
       "     ['conv4_block10_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block11_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block11_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}],\n",
       "     ['conv4_block11_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block12_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block12_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}],\n",
       "     ['conv4_block12_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block13_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block13_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}],\n",
       "     ['conv4_block13_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block14_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block14_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}],\n",
       "     ['conv4_block14_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block15_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block15_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}],\n",
       "     ['conv4_block15_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block16_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block16_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}],\n",
       "     ['conv4_block16_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block17_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block17_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}],\n",
       "     ['conv4_block17_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block18_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block18_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}],\n",
       "     ['conv4_block18_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block19_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block19_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}],\n",
       "     ['conv4_block19_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block20_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block20_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}],\n",
       "     ['conv4_block20_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block21_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block21_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}],\n",
       "     ['conv4_block21_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block22_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block22_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}],\n",
       "     ['conv4_block22_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block23_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_3',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block23_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_3', 0, 0, {}],\n",
       "     ['conv4_block23_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_0_conv', 0, 0, {}],\n",
       "     ['conv5_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}],\n",
       "     ['conv5_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}],\n",
       "     ['conv5_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'post_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'post_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'post_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'post_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['post_bn', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['post_relu', 0, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t1=datetime.datetime.now()\n",
    "print(t1)\n",
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "print(X_train.shape)\n",
    "t2=datetime.datetime.now()\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(19312, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(X_train, '../Pickle/ResNet101V2_X_train_2.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t3=datetime.datetime.now()\n",
    "print(t3)\n",
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "print(X_test.shape)\n",
    "t4=datetime.datetime.now()\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test = X_test.reshape(4829, 7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib.dump(X_test, '../Pickle/ResNet101V2_X_test_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "X_train = joblib.load('../Pickle/ResNet101V2_X_train_2.pkl') \n",
    "X_test = joblib.load('../Pickle/ResNet101V2_X_test_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19312, 100352)\n",
      "(4829, 100352)\n",
      "(19312, 51)\n",
      "(4829, 51)\n"
     ]
    }
   ],
   "source": [
    "# shape of images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 51)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 51)                52275     \n",
      "=================================================================\n",
      "Total params: 102,813,747\n",
      "Trainable params: 102,813,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('../Models/weightResNet101V2_6.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adagrad',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-07 13:07:08.603226\n",
      "Train on 19312 samples, validate on 4829 samples\n",
      "Epoch 1/100\n",
      "19312/19312 [==============================] - ETA: 14:07 - loss: 9.3637 - accuracy: 0.062 - ETA: 12:13 - loss: 307.2236 - accuracy: 0.113 - ETA: 10:06 - loss: 463.0573 - accuracy: 0.104 - ETA: 9:38 - loss: 443.7920 - accuracy: 0.089 - ETA: 9:11 - loss: 400.0244 - accuracy: 0.08 - ETA: 8:52 - loss: 364.7016 - accuracy: 0.08 - ETA: 8:27 - loss: 329.4693 - accuracy: 0.09 - ETA: 8:16 - loss: 298.8581 - accuracy: 0.09 - ETA: 8:07 - loss: 270.2870 - accuracy: 0.10 - ETA: 8:13 - loss: 245.7946 - accuracy: 0.12 - ETA: 8:11 - loss: 224.7878 - accuracy: 0.13 - ETA: 8:07 - loss: 207.2462 - accuracy: 0.14 - ETA: 8:10 - loss: 192.3790 - accuracy: 0.14 - ETA: 8:07 - loss: 179.2438 - accuracy: 0.15 - ETA: 8:06 - loss: 167.6413 - accuracy: 0.16 - ETA: 8:08 - loss: 157.4951 - accuracy: 0.16 - ETA: 8:01 - loss: 148.5511 - accuracy: 0.16 - ETA: 7:56 - loss: 140.5368 - accuracy: 0.17 - ETA: 7:52 - loss: 133.3350 - accuracy: 0.17 - ETA: 7:45 - loss: 126.9194 - accuracy: 0.17 - ETA: 7:36 - loss: 121.0915 - accuracy: 0.17 - ETA: 7:25 - loss: 115.7622 - accuracy: 0.17 - ETA: 7:12 - loss: 110.8982 - accuracy: 0.17 - ETA: 7:12 - loss: 106.4333 - accuracy: 0.17 - ETA: 7:06 - loss: 102.3350 - accuracy: 0.18 - ETA: 7:01 - loss: 98.5485 - accuracy: 0.1815 - ETA: 6:54 - loss: 95.0439 - accuracy: 0.182 - ETA: 6:44 - loss: 91.7861 - accuracy: 0.182 - ETA: 6:41 - loss: 88.7456 - accuracy: 0.183 - ETA: 6:36 - loss: 85.9291 - accuracy: 0.182 - ETA: 6:34 - loss: 83.2734 - accuracy: 0.182 - ETA: 6:30 - loss: 80.7801 - accuracy: 0.183 - ETA: 6:25 - loss: 78.4352 - accuracy: 0.184 - ETA: 6:20 - loss: 76.2510 - accuracy: 0.184 - ETA: 6:17 - loss: 74.1772 - accuracy: 0.184 - ETA: 6:12 - loss: 72.2163 - accuracy: 0.184 - ETA: 6:07 - loss: 70.3539 - accuracy: 0.185 - ETA: 6:04 - loss: 68.6818 - accuracy: 0.184 - ETA: 5:59 - loss: 67.0050 - accuracy: 0.185 - ETA: 5:55 - loss: 65.4102 - accuracy: 0.185 - ETA: 5:52 - loss: 63.8996 - accuracy: 0.187 - ETA: 5:51 - loss: 62.4595 - accuracy: 0.187 - ETA: 5:49 - loss: 61.0962 - accuracy: 0.186 - ETA: 5:46 - loss: 59.7929 - accuracy: 0.185 - ETA: 5:43 - loss: 58.5349 - accuracy: 0.186 - ETA: 5:40 - loss: 57.3414 - accuracy: 0.186 - ETA: 5:35 - loss: 56.1931 - accuracy: 0.187 - ETA: 5:30 - loss: 55.0989 - accuracy: 0.188 - ETA: 5:24 - loss: 54.0567 - accuracy: 0.188 - ETA: 5:20 - loss: 53.0513 - accuracy: 0.188 - ETA: 5:17 - loss: 52.0821 - accuracy: 0.187 - ETA: 5:15 - loss: 51.1482 - accuracy: 0.187 - ETA: 5:12 - loss: 50.2497 - accuracy: 0.188 - ETA: 5:08 - loss: 49.3751 - accuracy: 0.190 - ETA: 5:04 - loss: 48.5434 - accuracy: 0.191 - ETA: 5:00 - loss: 47.7403 - accuracy: 0.190 - ETA: 4:57 - loss: 46.9587 - accuracy: 0.191 - ETA: 4:55 - loss: 46.2042 - accuracy: 0.192 - ETA: 4:51 - loss: 45.4754 - accuracy: 0.194 - ETA: 4:47 - loss: 44.7726 - accuracy: 0.195 - ETA: 4:43 - loss: 44.0956 - accuracy: 0.195 - ETA: 4:40 - loss: 43.4386 - accuracy: 0.196 - ETA: 4:37 - loss: 42.8004 - accuracy: 0.197 - ETA: 4:34 - loss: 42.1835 - accuracy: 0.198 - ETA: 4:30 - loss: 41.5843 - accuracy: 0.199 - ETA: 4:26 - loss: 41.0026 - accuracy: 0.200 - ETA: 4:23 - loss: 40.4420 - accuracy: 0.201 - ETA: 4:19 - loss: 39.9036 - accuracy: 0.202 - ETA: 4:15 - loss: 39.3734 - accuracy: 0.202 - ETA: 4:10 - loss: 38.8556 - accuracy: 0.203 - ETA: 4:06 - loss: 38.3539 - accuracy: 0.204 - ETA: 4:04 - loss: 37.8680 - accuracy: 0.205 - ETA: 4:00 - loss: 37.3954 - accuracy: 0.205 - ETA: 3:57 - loss: 36.9340 - accuracy: 0.206 - ETA: 3:54 - loss: 36.4838 - accuracy: 0.207 - ETA: 3:51 - loss: 36.0486 - accuracy: 0.208 - ETA: 3:47 - loss: 35.6214 - accuracy: 0.209 - ETA: 3:43 - loss: 35.2095 - accuracy: 0.210 - ETA: 3:40 - loss: 34.8033 - accuracy: 0.211 - ETA: 3:37 - loss: 34.4112 - accuracy: 0.212 - ETA: 3:34 - loss: 34.0271 - accuracy: 0.213 - ETA: 3:31 - loss: 33.6486 - accuracy: 0.214 - ETA: 3:27 - loss: 33.2813 - accuracy: 0.215 - ETA: 3:23 - loss: 32.9229 - accuracy: 0.216 - ETA: 3:20 - loss: 32.5769 - accuracy: 0.217 - ETA: 3:17 - loss: 32.2347 - accuracy: 0.217 - ETA: 3:14 - loss: 31.9017 - accuracy: 0.217 - ETA: 3:11 - loss: 31.5735 - accuracy: 0.218 - ETA: 3:08 - loss: 31.2557 - accuracy: 0.219 - ETA: 3:05 - loss: 30.9432 - accuracy: 0.220 - ETA: 3:01 - loss: 30.6383 - accuracy: 0.220 - ETA: 2:59 - loss: 30.3384 - accuracy: 0.221 - ETA: 2:56 - loss: 30.0454 - accuracy: 0.222 - ETA: 2:52 - loss: 29.7587 - accuracy: 0.222 - ETA: 2:49 - loss: 29.4770 - accuracy: 0.223 - ETA: 2:46 - loss: 29.2003 - accuracy: 0.225 - ETA: 2:43 - loss: 28.9326 - accuracy: 0.225 - ETA: 2:40 - loss: 28.6678 - accuracy: 0.226 - ETA: 2:36 - loss: 28.4101 - accuracy: 0.227 - ETA: 2:33 - loss: 28.1527 - accuracy: 0.228 - ETA: 2:30 - loss: 27.9047 - accuracy: 0.228 - ETA: 2:27 - loss: 27.6620 - accuracy: 0.229 - ETA: 2:25 - loss: 27.4261 - accuracy: 0.230 - ETA: 2:22 - loss: 27.1967 - accuracy: 0.230 - ETA: 2:19 - loss: 26.9708 - accuracy: 0.231 - ETA: 2:16 - loss: 26.7455 - accuracy: 0.232 - ETA: 2:13 - loss: 26.5221 - accuracy: 0.233 - ETA: 2:09 - loss: 26.3062 - accuracy: 0.233 - ETA: 2:06 - loss: 26.0924 - accuracy: 0.234 - ETA: 2:03 - loss: 25.8801 - accuracy: 0.235 - ETA: 2:00 - loss: 25.6741 - accuracy: 0.236 - ETA: 1:57 - loss: 25.4728 - accuracy: 0.236 - ETA: 1:54 - loss: 25.2784 - accuracy: 0.236 - ETA: 1:51 - loss: 25.0838 - accuracy: 0.237 - ETA: 1:48 - loss: 24.8921 - accuracy: 0.238 - ETA: 1:45 - loss: 24.7031 - accuracy: 0.239 - ETA: 1:42 - loss: 24.5202 - accuracy: 0.240 - ETA: 1:39 - loss: 24.3388 - accuracy: 0.240 - ETA: 1:36 - loss: 24.1575 - accuracy: 0.240 - ETA: 1:33 - loss: 23.9812 - accuracy: 0.241 - ETA: 1:30 - loss: 23.8104 - accuracy: 0.241 - ETA: 1:26 - loss: 23.6412 - accuracy: 0.242 - ETA: 1:23 - loss: 23.4759 - accuracy: 0.242 - ETA: 1:20 - loss: 23.3216 - accuracy: 0.243 - ETA: 1:17 - loss: 23.1605 - accuracy: 0.244 - ETA: 1:14 - loss: 23.0048 - accuracy: 0.244 - ETA: 1:11 - loss: 22.8471 - accuracy: 0.245 - ETA: 1:08 - loss: 22.6910 - accuracy: 0.246 - ETA: 1:05 - loss: 22.5382 - accuracy: 0.246 - ETA: 1:02 - loss: 22.3912 - accuracy: 0.246 - ETA: 59s - loss: 22.2463 - accuracy: 0.247 - ETA: 56s - loss: 22.0978 - accuracy: 0.24 - ETA: 53s - loss: 21.9544 - accuracy: 0.24 - ETA: 50s - loss: 21.8135 - accuracy: 0.24 - ETA: 47s - loss: 21.6751 - accuracy: 0.24 - ETA: 44s - loss: 21.5415 - accuracy: 0.25 - ETA: 41s - loss: 21.4045 - accuracy: 0.25 - ETA: 38s - loss: 21.2695 - accuracy: 0.25 - ETA: 35s - loss: 21.1397 - accuracy: 0.25 - ETA: 32s - loss: 21.0120 - accuracy: 0.25 - ETA: 29s - loss: 20.8844 - accuracy: 0.25 - ETA: 26s - loss: 20.7598 - accuracy: 0.25 - ETA: 23s - loss: 20.6362 - accuracy: 0.25 - ETA: 20s - loss: 20.5122 - accuracy: 0.25 - ETA: 17s - loss: 20.3906 - accuracy: 0.25 - ETA: 14s - loss: 20.2714 - accuracy: 0.25 - ETA: 11s - loss: 20.1553 - accuracy: 0.25 - ETA: 8s - loss: 20.0372 - accuracy: 0.2569 - ETA: 5s - loss: 19.9241 - accuracy: 0.256 - ETA: 2s - loss: 19.8113 - accuracy: 0.257 - 503s 26ms/step - loss: 19.7140 - accuracy: 0.2579 - val_loss: 2.5431 - val_accuracy: 0.4245\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:14 - loss: 2.8324 - accuracy: 0.32 - ETA: 6:52 - loss: 3.0006 - accuracy: 0.30 - ETA: 6:54 - loss: 2.8586 - accuracy: 0.34 - ETA: 6:49 - loss: 2.8033 - accuracy: 0.34 - ETA: 6:44 - loss: 2.8396 - accuracy: 0.34 - ETA: 6:39 - loss: 2.8129 - accuracy: 0.34 - ETA: 6:33 - loss: 2.8646 - accuracy: 0.34 - ETA: 6:31 - loss: 2.8449 - accuracy: 0.35 - ETA: 6:20 - loss: 2.8137 - accuracy: 0.36 - ETA: 6:22 - loss: 2.7796 - accuracy: 0.36 - ETA: 6:19 - loss: 2.7661 - accuracy: 0.36 - ETA: 6:09 - loss: 2.7599 - accuracy: 0.36 - ETA: 6:08 - loss: 2.7576 - accuracy: 0.36 - ETA: 6:03 - loss: 2.7520 - accuracy: 0.36 - ETA: 6:01 - loss: 2.7368 - accuracy: 0.36 - ETA: 6:00 - loss: 2.7214 - accuracy: 0.36 - ETA: 5:57 - loss: 2.7156 - accuracy: 0.36 - ETA: 5:55 - loss: 2.7298 - accuracy: 0.36 - ETA: 5:53 - loss: 2.7269 - accuracy: 0.36 - ETA: 5:48 - loss: 2.7334 - accuracy: 0.36 - ETA: 5:47 - loss: 2.7256 - accuracy: 0.36 - ETA: 5:46 - loss: 2.7361 - accuracy: 0.36 - ETA: 5:43 - loss: 2.7462 - accuracy: 0.35 - ETA: 5:41 - loss: 2.7481 - accuracy: 0.35 - ETA: 5:35 - loss: 2.7515 - accuracy: 0.35 - ETA: 5:33 - loss: 2.7550 - accuracy: 0.35 - ETA: 5:31 - loss: 2.7603 - accuracy: 0.35 - ETA: 5:29 - loss: 2.7776 - accuracy: 0.35 - ETA: 5:27 - loss: 2.7770 - accuracy: 0.35 - ETA: 5:24 - loss: 2.7901 - accuracy: 0.35 - ETA: 5:17 - loss: 2.7908 - accuracy: 0.35 - ETA: 5:15 - loss: 2.7756 - accuracy: 0.36 - ETA: 5:12 - loss: 2.7628 - accuracy: 0.36 - ETA: 5:11 - loss: 2.7569 - accuracy: 0.36 - ETA: 5:08 - loss: 2.7487 - accuracy: 0.36 - ETA: 5:06 - loss: 2.7497 - accuracy: 0.36 - ETA: 5:03 - loss: 2.7544 - accuracy: 0.36 - ETA: 5:02 - loss: 2.7472 - accuracy: 0.36 - ETA: 4:59 - loss: 2.7529 - accuracy: 0.36 - ETA: 4:58 - loss: 2.7487 - accuracy: 0.36 - ETA: 4:56 - loss: 2.7425 - accuracy: 0.36 - ETA: 4:53 - loss: 2.7385 - accuracy: 0.36 - ETA: 4:51 - loss: 2.7377 - accuracy: 0.36 - ETA: 4:49 - loss: 2.7380 - accuracy: 0.36 - ETA: 4:47 - loss: 2.7410 - accuracy: 0.36 - ETA: 4:44 - loss: 2.7386 - accuracy: 0.36 - ETA: 4:42 - loss: 2.7313 - accuracy: 0.36 - ETA: 4:39 - loss: 2.7297 - accuracy: 0.36 - ETA: 4:36 - loss: 2.7262 - accuracy: 0.36 - ETA: 4:31 - loss: 2.7190 - accuracy: 0.36 - ETA: 4:27 - loss: 2.7172 - accuracy: 0.36 - ETA: 4:23 - loss: 2.7093 - accuracy: 0.36 - ETA: 4:18 - loss: 2.7119 - accuracy: 0.36 - ETA: 4:14 - loss: 2.7006 - accuracy: 0.36 - ETA: 4:11 - loss: 2.6977 - accuracy: 0.37 - ETA: 4:08 - loss: 2.6985 - accuracy: 0.37 - ETA: 4:05 - loss: 2.6975 - accuracy: 0.37 - ETA: 4:03 - loss: 2.6973 - accuracy: 0.37 - ETA: 3:59 - loss: 2.7012 - accuracy: 0.37 - ETA: 3:57 - loss: 2.6988 - accuracy: 0.37 - ETA: 3:54 - loss: 2.6947 - accuracy: 0.37 - ETA: 3:52 - loss: 2.6892 - accuracy: 0.37 - ETA: 3:49 - loss: 2.6876 - accuracy: 0.37 - ETA: 3:47 - loss: 2.6867 - accuracy: 0.37 - ETA: 3:44 - loss: 2.6849 - accuracy: 0.37 - ETA: 3:42 - loss: 2.6825 - accuracy: 0.37 - ETA: 3:39 - loss: 2.6765 - accuracy: 0.37 - ETA: 3:37 - loss: 2.6702 - accuracy: 0.37 - ETA: 3:34 - loss: 2.6643 - accuracy: 0.37 - ETA: 3:31 - loss: 2.6608 - accuracy: 0.37 - ETA: 3:29 - loss: 2.6584 - accuracy: 0.37 - ETA: 3:27 - loss: 2.6579 - accuracy: 0.37 - ETA: 3:25 - loss: 2.6628 - accuracy: 0.37 - ETA: 3:23 - loss: 2.6605 - accuracy: 0.37 - ETA: 3:20 - loss: 2.6573 - accuracy: 0.37 - ETA: 3:17 - loss: 2.6572 - accuracy: 0.37 - ETA: 3:15 - loss: 2.6595 - accuracy: 0.37 - ETA: 3:12 - loss: 2.6572 - accuracy: 0.37 - ETA: 3:10 - loss: 2.6575 - accuracy: 0.37 - ETA: 3:07 - loss: 2.6585 - accuracy: 0.37 - ETA: 3:05 - loss: 2.6570 - accuracy: 0.37 - ETA: 3:02 - loss: 2.6576 - accuracy: 0.37 - ETA: 3:00 - loss: 2.6544 - accuracy: 0.37 - ETA: 2:57 - loss: 2.6574 - accuracy: 0.37 - ETA: 2:54 - loss: 2.6572 - accuracy: 0.37 - ETA: 2:52 - loss: 2.6543 - accuracy: 0.37 - ETA: 2:49 - loss: 2.6571 - accuracy: 0.37 - ETA: 2:47 - loss: 2.6554 - accuracy: 0.37 - ETA: 2:44 - loss: 2.6508 - accuracy: 0.37 - ETA: 2:41 - loss: 2.6496 - accuracy: 0.37 - ETA: 2:39 - loss: 2.6474 - accuracy: 0.37 - ETA: 2:36 - loss: 2.6489 - accuracy: 0.37 - ETA: 2:33 - loss: 2.6472 - accuracy: 0.37 - ETA: 2:31 - loss: 2.6464 - accuracy: 0.38 - ETA: 2:28 - loss: 2.6434 - accuracy: 0.38 - ETA: 2:26 - loss: 2.6408 - accuracy: 0.38 - ETA: 2:23 - loss: 2.6429 - accuracy: 0.38 - ETA: 2:20 - loss: 2.6385 - accuracy: 0.38 - ETA: 2:18 - loss: 2.6354 - accuracy: 0.38 - ETA: 2:15 - loss: 2.6319 - accuracy: 0.38 - ETA: 2:13 - loss: 2.6288 - accuracy: 0.38 - ETA: 2:10 - loss: 2.6264 - accuracy: 0.38 - ETA: 2:07 - loss: 2.6296 - accuracy: 0.38 - ETA: 2:04 - loss: 2.6347 - accuracy: 0.38 - ETA: 2:02 - loss: 2.6325 - accuracy: 0.38 - ETA: 1:59 - loss: 2.6319 - accuracy: 0.38 - ETA: 1:57 - loss: 2.6299 - accuracy: 0.38 - ETA: 1:54 - loss: 2.6280 - accuracy: 0.38 - ETA: 1:52 - loss: 2.6246 - accuracy: 0.38 - ETA: 1:49 - loss: 2.6202 - accuracy: 0.38 - ETA: 1:47 - loss: 2.6221 - accuracy: 0.38 - ETA: 1:44 - loss: 2.6233 - accuracy: 0.38 - ETA: 1:41 - loss: 2.6237 - accuracy: 0.38 - ETA: 1:39 - loss: 2.6219 - accuracy: 0.38 - ETA: 1:36 - loss: 2.6197 - accuracy: 0.38 - ETA: 1:33 - loss: 2.6203 - accuracy: 0.38 - ETA: 1:31 - loss: 2.6197 - accuracy: 0.38 - ETA: 1:28 - loss: 2.6163 - accuracy: 0.38 - ETA: 1:25 - loss: 2.6168 - accuracy: 0.38 - ETA: 1:23 - loss: 2.6148 - accuracy: 0.38 - ETA: 1:20 - loss: 2.6139 - accuracy: 0.38 - ETA: 1:17 - loss: 2.6118 - accuracy: 0.38 - ETA: 1:15 - loss: 2.6132 - accuracy: 0.38 - ETA: 1:12 - loss: 2.6120 - accuracy: 0.38 - ETA: 1:09 - loss: 2.6127 - accuracy: 0.38 - ETA: 1:07 - loss: 2.6101 - accuracy: 0.38 - ETA: 1:04 - loss: 2.6077 - accuracy: 0.38 - ETA: 1:01 - loss: 2.6050 - accuracy: 0.39 - ETA: 59s - loss: 2.6031 - accuracy: 0.3904 - ETA: 56s - loss: 2.6010 - accuracy: 0.391 - ETA: 53s - loss: 2.5980 - accuracy: 0.391 - ETA: 51s - loss: 2.6000 - accuracy: 0.391 - ETA: 48s - loss: 2.5981 - accuracy: 0.391 - ETA: 45s - loss: 2.5993 - accuracy: 0.391 - ETA: 43s - loss: 2.5964 - accuracy: 0.392 - ETA: 40s - loss: 2.5975 - accuracy: 0.391 - ETA: 37s - loss: 2.5959 - accuracy: 0.391 - ETA: 34s - loss: 2.5938 - accuracy: 0.392 - ETA: 32s - loss: 2.5918 - accuracy: 0.392 - ETA: 29s - loss: 2.5911 - accuracy: 0.393 - ETA: 26s - loss: 2.5892 - accuracy: 0.393 - ETA: 24s - loss: 2.5892 - accuracy: 0.393 - ETA: 21s - loss: 2.5897 - accuracy: 0.393 - ETA: 18s - loss: 2.5909 - accuracy: 0.393 - ETA: 16s - loss: 2.5892 - accuracy: 0.393 - ETA: 13s - loss: 2.5926 - accuracy: 0.393 - ETA: 10s - loss: 2.5920 - accuracy: 0.393 - ETA: 7s - loss: 2.5907 - accuracy: 0.392 - ETA: 5s - loss: 2.5903 - accuracy: 0.39 - ETA: 2s - loss: 2.5899 - accuracy: 0.39 - 457s 24ms/step - loss: 2.5898 - accuracy: 0.3935 - val_loss: 2.1281 - val_accuracy: 0.5115\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:01 - loss: 2.1908 - accuracy: 0.45 - ETA: 5:47 - loss: 2.1999 - accuracy: 0.45 - ETA: 6:13 - loss: 2.1473 - accuracy: 0.44 - ETA: 6:10 - loss: 2.1476 - accuracy: 0.44 - ETA: 6:05 - loss: 2.1237 - accuracy: 0.45 - ETA: 5:44 - loss: 2.1562 - accuracy: 0.45 - ETA: 5:26 - loss: 2.1585 - accuracy: 0.45 - ETA: 5:14 - loss: 2.1848 - accuracy: 0.44 - ETA: 5:21 - loss: 2.2169 - accuracy: 0.44 - ETA: 5:23 - loss: 2.2152 - accuracy: 0.44 - ETA: 5:23 - loss: 2.2032 - accuracy: 0.44 - ETA: 5:22 - loss: 2.2165 - accuracy: 0.44 - ETA: 5:24 - loss: 2.2371 - accuracy: 0.43 - ETA: 5:26 - loss: 2.2294 - accuracy: 0.44 - ETA: 5:26 - loss: 2.2448 - accuracy: 0.43 - ETA: 5:25 - loss: 2.2477 - accuracy: 0.43 - ETA: 5:25 - loss: 2.2763 - accuracy: 0.43 - ETA: 5:23 - loss: 2.2927 - accuracy: 0.43 - ETA: 5:22 - loss: 2.2921 - accuracy: 0.43 - ETA: 5:23 - loss: 2.2793 - accuracy: 0.43 - ETA: 5:17 - loss: 2.2643 - accuracy: 0.43 - ETA: 5:10 - loss: 2.2553 - accuracy: 0.44 - ETA: 5:07 - loss: 2.2622 - accuracy: 0.43 - ETA: 5:06 - loss: 2.2793 - accuracy: 0.43 - ETA: 5:03 - loss: 2.2947 - accuracy: 0.43 - ETA: 5:03 - loss: 2.2978 - accuracy: 0.43 - ETA: 5:01 - loss: 2.3038 - accuracy: 0.43 - ETA: 5:01 - loss: 2.3039 - accuracy: 0.43 - ETA: 4:59 - loss: 2.3070 - accuracy: 0.43 - ETA: 4:58 - loss: 2.3010 - accuracy: 0.43 - ETA: 4:56 - loss: 2.3003 - accuracy: 0.43 - ETA: 4:54 - loss: 2.2989 - accuracy: 0.43 - ETA: 4:53 - loss: 2.3047 - accuracy: 0.43 - ETA: 4:51 - loss: 2.3007 - accuracy: 0.43 - ETA: 4:50 - loss: 2.2937 - accuracy: 0.44 - ETA: 4:47 - loss: 2.2846 - accuracy: 0.44 - ETA: 4:45 - loss: 2.2771 - accuracy: 0.44 - ETA: 4:40 - loss: 2.2722 - accuracy: 0.44 - ETA: 4:35 - loss: 2.2670 - accuracy: 0.44 - ETA: 4:30 - loss: 2.2613 - accuracy: 0.44 - ETA: 4:28 - loss: 2.2598 - accuracy: 0.44 - ETA: 4:26 - loss: 2.2641 - accuracy: 0.44 - ETA: 4:24 - loss: 2.2567 - accuracy: 0.44 - ETA: 4:21 - loss: 2.2523 - accuracy: 0.44 - ETA: 4:18 - loss: 2.2573 - accuracy: 0.44 - ETA: 4:14 - loss: 2.2578 - accuracy: 0.44 - ETA: 4:10 - loss: 2.2583 - accuracy: 0.44 - ETA: 4:07 - loss: 2.2639 - accuracy: 0.44 - ETA: 4:05 - loss: 2.2657 - accuracy: 0.44 - ETA: 4:04 - loss: 2.2673 - accuracy: 0.44 - ETA: 4:02 - loss: 2.2619 - accuracy: 0.44 - ETA: 4:00 - loss: 2.2601 - accuracy: 0.44 - ETA: 3:58 - loss: 2.2595 - accuracy: 0.44 - ETA: 3:56 - loss: 2.2632 - accuracy: 0.44 - ETA: 3:54 - loss: 2.2607 - accuracy: 0.44 - ETA: 3:52 - loss: 2.2599 - accuracy: 0.44 - ETA: 3:49 - loss: 2.2544 - accuracy: 0.44 - ETA: 3:47 - loss: 2.2529 - accuracy: 0.44 - ETA: 3:43 - loss: 2.2529 - accuracy: 0.44 - ETA: 3:40 - loss: 2.2559 - accuracy: 0.44 - ETA: 3:36 - loss: 2.2508 - accuracy: 0.44 - ETA: 3:34 - loss: 2.2510 - accuracy: 0.44 - ETA: 3:32 - loss: 2.2499 - accuracy: 0.44 - ETA: 3:30 - loss: 2.2528 - accuracy: 0.44 - ETA: 3:28 - loss: 2.2535 - accuracy: 0.44 - ETA: 3:26 - loss: 2.2523 - accuracy: 0.44 - ETA: 3:24 - loss: 2.2456 - accuracy: 0.44 - ETA: 3:21 - loss: 2.2476 - accuracy: 0.44 - ETA: 3:18 - loss: 2.2466 - accuracy: 0.44 - ETA: 3:17 - loss: 2.2434 - accuracy: 0.44 - ETA: 3:14 - loss: 2.2403 - accuracy: 0.44 - ETA: 3:12 - loss: 2.2417 - accuracy: 0.44 - ETA: 3:10 - loss: 2.2445 - accuracy: 0.44 - ETA: 3:08 - loss: 2.2439 - accuracy: 0.44 - ETA: 3:06 - loss: 2.2410 - accuracy: 0.44 - ETA: 3:04 - loss: 2.2420 - accuracy: 0.44 - ETA: 3:01 - loss: 2.2458 - accuracy: 0.44 - ETA: 2:59 - loss: 2.2464 - accuracy: 0.44 - ETA: 2:57 - loss: 2.2434 - accuracy: 0.44 - ETA: 2:55 - loss: 2.2478 - accuracy: 0.44 - ETA: 2:53 - loss: 2.2495 - accuracy: 0.44 - ETA: 2:50 - loss: 2.2510 - accuracy: 0.44 - ETA: 2:48 - loss: 2.2518 - accuracy: 0.44 - ETA: 2:45 - loss: 2.2529 - accuracy: 0.44 - ETA: 2:42 - loss: 2.2534 - accuracy: 0.44 - ETA: 2:39 - loss: 2.2503 - accuracy: 0.44 - ETA: 2:37 - loss: 2.2494 - accuracy: 0.44 - ETA: 2:34 - loss: 2.2475 - accuracy: 0.44 - ETA: 2:32 - loss: 2.2483 - accuracy: 0.44 - ETA: 2:30 - loss: 2.2447 - accuracy: 0.44 - ETA: 2:28 - loss: 2.2450 - accuracy: 0.44 - ETA: 2:25 - loss: 2.2444 - accuracy: 0.44 - ETA: 2:22 - loss: 2.2475 - accuracy: 0.44 - ETA: 2:19 - loss: 2.2503 - accuracy: 0.44 - ETA: 2:17 - loss: 2.2498 - accuracy: 0.44 - ETA: 2:15 - loss: 2.2484 - accuracy: 0.44 - ETA: 2:12 - loss: 2.2489 - accuracy: 0.44 - ETA: 2:10 - loss: 2.2432 - accuracy: 0.44 - ETA: 2:08 - loss: 2.2414 - accuracy: 0.44 - ETA: 2:05 - loss: 2.2429 - accuracy: 0.45 - ETA: 2:03 - loss: 2.2474 - accuracy: 0.44 - ETA: 2:01 - loss: 2.2481 - accuracy: 0.44 - ETA: 1:58 - loss: 2.2492 - accuracy: 0.44 - ETA: 1:56 - loss: 2.2446 - accuracy: 0.44 - ETA: 1:54 - loss: 2.2455 - accuracy: 0.44 - ETA: 1:51 - loss: 2.2436 - accuracy: 0.45 - ETA: 1:49 - loss: 2.2423 - accuracy: 0.45 - ETA: 1:46 - loss: 2.2429 - accuracy: 0.44 - ETA: 1:44 - loss: 2.2385 - accuracy: 0.45 - ETA: 1:42 - loss: 2.2370 - accuracy: 0.45 - ETA: 1:39 - loss: 2.2369 - accuracy: 0.45 - ETA: 1:37 - loss: 2.2355 - accuracy: 0.45 - ETA: 1:34 - loss: 2.2365 - accuracy: 0.45 - ETA: 1:32 - loss: 2.2360 - accuracy: 0.45 - ETA: 1:29 - loss: 2.2348 - accuracy: 0.45 - ETA: 1:27 - loss: 2.2358 - accuracy: 0.45 - ETA: 1:24 - loss: 2.2366 - accuracy: 0.45 - ETA: 1:21 - loss: 2.2367 - accuracy: 0.45 - ETA: 1:19 - loss: 2.2344 - accuracy: 0.45 - ETA: 1:16 - loss: 2.2337 - accuracy: 0.45 - ETA: 1:14 - loss: 2.2346 - accuracy: 0.45 - ETA: 1:12 - loss: 2.2319 - accuracy: 0.45 - ETA: 1:09 - loss: 2.2325 - accuracy: 0.45 - ETA: 1:07 - loss: 2.2309 - accuracy: 0.45 - ETA: 1:04 - loss: 2.2299 - accuracy: 0.45 - ETA: 1:02 - loss: 2.2301 - accuracy: 0.45 - ETA: 59s - loss: 2.2286 - accuracy: 0.4532 - ETA: 57s - loss: 2.2288 - accuracy: 0.453 - ETA: 55s - loss: 2.2277 - accuracy: 0.453 - ETA: 52s - loss: 2.2264 - accuracy: 0.454 - ETA: 50s - loss: 2.2281 - accuracy: 0.454 - ETA: 47s - loss: 2.2274 - accuracy: 0.453 - ETA: 45s - loss: 2.2273 - accuracy: 0.453 - ETA: 42s - loss: 2.2291 - accuracy: 0.453 - ETA: 40s - loss: 2.2292 - accuracy: 0.453 - ETA: 37s - loss: 2.2279 - accuracy: 0.453 - ETA: 35s - loss: 2.2244 - accuracy: 0.454 - ETA: 32s - loss: 2.2232 - accuracy: 0.455 - ETA: 30s - loss: 2.2237 - accuracy: 0.455 - ETA: 27s - loss: 2.2226 - accuracy: 0.455 - ETA: 25s - loss: 2.2231 - accuracy: 0.454 - ETA: 22s - loss: 2.2227 - accuracy: 0.454 - ETA: 20s - loss: 2.2248 - accuracy: 0.454 - ETA: 17s - loss: 2.2223 - accuracy: 0.454 - ETA: 14s - loss: 2.2234 - accuracy: 0.454 - ETA: 12s - loss: 2.2227 - accuracy: 0.454 - ETA: 9s - loss: 2.2208 - accuracy: 0.455 - ETA: 7s - loss: 2.2188 - accuracy: 0.45 - ETA: 4s - loss: 2.2185 - accuracy: 0.45 - ETA: 2s - loss: 2.2169 - accuracy: 0.45 - 429s 22ms/step - loss: 2.2148 - accuracy: 0.4563 - val_loss: 1.9210 - val_accuracy: 0.5492\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:48 - loss: 2.2240 - accuracy: 0.43 - ETA: 7:04 - loss: 2.1698 - accuracy: 0.47 - ETA: 7:11 - loss: 2.1106 - accuracy: 0.47 - ETA: 6:55 - loss: 2.0720 - accuracy: 0.48 - ETA: 6:51 - loss: 2.0301 - accuracy: 0.48 - ETA: 6:46 - loss: 1.9744 - accuracy: 0.49 - ETA: 6:42 - loss: 1.9746 - accuracy: 0.49 - ETA: 6:36 - loss: 1.9842 - accuracy: 0.49 - ETA: 6:39 - loss: 2.0259 - accuracy: 0.48 - ETA: 6:39 - loss: 2.0183 - accuracy: 0.48 - ETA: 6:36 - loss: 2.0301 - accuracy: 0.48 - ETA: 6:33 - loss: 2.0388 - accuracy: 0.48 - ETA: 6:26 - loss: 2.0392 - accuracy: 0.48 - ETA: 6:28 - loss: 2.0466 - accuracy: 0.48 - ETA: 6:25 - loss: 2.0523 - accuracy: 0.48 - ETA: 6:22 - loss: 2.0419 - accuracy: 0.48 - ETA: 6:18 - loss: 2.0417 - accuracy: 0.48 - ETA: 6:18 - loss: 2.0376 - accuracy: 0.48 - ETA: 6:14 - loss: 2.0435 - accuracy: 0.48 - ETA: 6:09 - loss: 2.0260 - accuracy: 0.49 - ETA: 6:04 - loss: 2.0199 - accuracy: 0.49 - ETA: 6:01 - loss: 2.0182 - accuracy: 0.49 - ETA: 5:59 - loss: 2.0283 - accuracy: 0.48 - ETA: 5:56 - loss: 2.0359 - accuracy: 0.48 - ETA: 5:54 - loss: 2.0424 - accuracy: 0.48 - ETA: 5:51 - loss: 2.0355 - accuracy: 0.48 - ETA: 5:49 - loss: 2.0198 - accuracy: 0.49 - ETA: 5:46 - loss: 2.0091 - accuracy: 0.49 - ETA: 5:43 - loss: 2.0208 - accuracy: 0.49 - ETA: 5:37 - loss: 2.0197 - accuracy: 0.49 - ETA: 5:31 - loss: 2.0294 - accuracy: 0.48 - ETA: 5:25 - loss: 2.0311 - accuracy: 0.49 - ETA: 5:19 - loss: 2.0350 - accuracy: 0.48 - ETA: 5:16 - loss: 2.0422 - accuracy: 0.48 - ETA: 5:13 - loss: 2.0449 - accuracy: 0.48 - ETA: 5:10 - loss: 2.0503 - accuracy: 0.48 - ETA: 5:05 - loss: 2.0440 - accuracy: 0.48 - ETA: 5:04 - loss: 2.0460 - accuracy: 0.48 - ETA: 5:02 - loss: 2.0436 - accuracy: 0.48 - ETA: 5:00 - loss: 2.0423 - accuracy: 0.48 - ETA: 4:57 - loss: 2.0379 - accuracy: 0.48 - ETA: 4:53 - loss: 2.0326 - accuracy: 0.48 - ETA: 4:50 - loss: 2.0301 - accuracy: 0.48 - ETA: 4:48 - loss: 2.0274 - accuracy: 0.48 - ETA: 4:46 - loss: 2.0267 - accuracy: 0.48 - ETA: 4:43 - loss: 2.0363 - accuracy: 0.48 - ETA: 4:41 - loss: 2.0321 - accuracy: 0.48 - ETA: 4:38 - loss: 2.0299 - accuracy: 0.48 - ETA: 4:34 - loss: 2.0285 - accuracy: 0.48 - ETA: 4:30 - loss: 2.0367 - accuracy: 0.48 - ETA: 4:25 - loss: 2.0389 - accuracy: 0.48 - ETA: 4:21 - loss: 2.0355 - accuracy: 0.48 - ETA: 4:17 - loss: 2.0320 - accuracy: 0.48 - ETA: 4:15 - loss: 2.0322 - accuracy: 0.48 - ETA: 4:13 - loss: 2.0298 - accuracy: 0.48 - ETA: 4:10 - loss: 2.0269 - accuracy: 0.48 - ETA: 4:08 - loss: 2.0225 - accuracy: 0.48 - ETA: 4:06 - loss: 2.0157 - accuracy: 0.48 - ETA: 4:04 - loss: 2.0138 - accuracy: 0.48 - ETA: 4:01 - loss: 2.0171 - accuracy: 0.48 - ETA: 3:58 - loss: 2.0206 - accuracy: 0.48 - ETA: 3:56 - loss: 2.0199 - accuracy: 0.48 - ETA: 3:53 - loss: 2.0221 - accuracy: 0.48 - ETA: 3:49 - loss: 2.0248 - accuracy: 0.48 - ETA: 3:45 - loss: 2.0234 - accuracy: 0.48 - ETA: 3:43 - loss: 2.0193 - accuracy: 0.48 - ETA: 3:40 - loss: 2.0133 - accuracy: 0.48 - ETA: 3:38 - loss: 2.0142 - accuracy: 0.48 - ETA: 3:36 - loss: 2.0102 - accuracy: 0.48 - ETA: 3:33 - loss: 2.0083 - accuracy: 0.48 - ETA: 3:31 - loss: 2.0051 - accuracy: 0.48 - ETA: 3:27 - loss: 2.0055 - accuracy: 0.48 - ETA: 3:25 - loss: 2.0076 - accuracy: 0.48 - ETA: 3:22 - loss: 2.0096 - accuracy: 0.48 - ETA: 3:20 - loss: 2.0095 - accuracy: 0.48 - ETA: 3:18 - loss: 2.0109 - accuracy: 0.48 - ETA: 3:15 - loss: 2.0084 - accuracy: 0.48 - ETA: 3:13 - loss: 2.0073 - accuracy: 0.48 - ETA: 3:10 - loss: 2.0102 - accuracy: 0.48 - ETA: 3:07 - loss: 2.0166 - accuracy: 0.48 - ETA: 3:05 - loss: 2.0192 - accuracy: 0.48 - ETA: 3:03 - loss: 2.0165 - accuracy: 0.48 - ETA: 3:00 - loss: 2.0171 - accuracy: 0.48 - ETA: 2:58 - loss: 2.0134 - accuracy: 0.48 - ETA: 2:55 - loss: 2.0124 - accuracy: 0.48 - ETA: 2:52 - loss: 2.0137 - accuracy: 0.48 - ETA: 2:50 - loss: 2.0157 - accuracy: 0.48 - ETA: 2:48 - loss: 2.0111 - accuracy: 0.48 - ETA: 2:45 - loss: 2.0105 - accuracy: 0.48 - ETA: 2:42 - loss: 2.0112 - accuracy: 0.48 - ETA: 2:39 - loss: 2.0101 - accuracy: 0.48 - ETA: 2:36 - loss: 2.0095 - accuracy: 0.48 - ETA: 2:34 - loss: 2.0111 - accuracy: 0.48 - ETA: 2:31 - loss: 2.0113 - accuracy: 0.48 - ETA: 2:29 - loss: 2.0095 - accuracy: 0.48 - ETA: 2:26 - loss: 2.0104 - accuracy: 0.48 - ETA: 2:24 - loss: 2.0082 - accuracy: 0.48 - ETA: 2:21 - loss: 2.0051 - accuracy: 0.48 - ETA: 2:19 - loss: 2.0032 - accuracy: 0.48 - ETA: 2:16 - loss: 2.0004 - accuracy: 0.48 - ETA: 2:14 - loss: 1.9963 - accuracy: 0.49 - ETA: 2:11 - loss: 1.9966 - accuracy: 0.48 - ETA: 2:08 - loss: 1.9958 - accuracy: 0.49 - ETA: 2:06 - loss: 1.9946 - accuracy: 0.49 - ETA: 2:03 - loss: 1.9940 - accuracy: 0.49 - ETA: 2:00 - loss: 1.9934 - accuracy: 0.49 - ETA: 1:57 - loss: 1.9911 - accuracy: 0.49 - ETA: 1:54 - loss: 1.9944 - accuracy: 0.49 - ETA: 1:52 - loss: 1.9952 - accuracy: 0.49 - ETA: 1:49 - loss: 1.9946 - accuracy: 0.49 - ETA: 1:47 - loss: 1.9976 - accuracy: 0.49 - ETA: 1:44 - loss: 1.9971 - accuracy: 0.49 - ETA: 1:41 - loss: 1.9946 - accuracy: 0.49 - ETA: 1:38 - loss: 1.9951 - accuracy: 0.49 - ETA: 1:36 - loss: 1.9996 - accuracy: 0.49 - ETA: 1:33 - loss: 1.9991 - accuracy: 0.49 - ETA: 1:30 - loss: 2.0004 - accuracy: 0.49 - ETA: 1:28 - loss: 1.9993 - accuracy: 0.49 - ETA: 1:25 - loss: 1.9986 - accuracy: 0.49 - ETA: 1:22 - loss: 1.9967 - accuracy: 0.49 - ETA: 1:20 - loss: 1.9940 - accuracy: 0.49 - ETA: 1:17 - loss: 1.9933 - accuracy: 0.49 - ETA: 1:14 - loss: 1.9909 - accuracy: 0.49 - ETA: 1:11 - loss: 1.9925 - accuracy: 0.49 - ETA: 1:09 - loss: 1.9911 - accuracy: 0.49 - ETA: 1:06 - loss: 1.9921 - accuracy: 0.49 - ETA: 1:03 - loss: 1.9921 - accuracy: 0.49 - ETA: 1:00 - loss: 1.9920 - accuracy: 0.49 - ETA: 58s - loss: 1.9925 - accuracy: 0.4931 - ETA: 55s - loss: 1.9937 - accuracy: 0.492 - ETA: 52s - loss: 1.9912 - accuracy: 0.493 - ETA: 50s - loss: 1.9912 - accuracy: 0.492 - ETA: 47s - loss: 1.9908 - accuracy: 0.493 - ETA: 44s - loss: 1.9918 - accuracy: 0.493 - ETA: 42s - loss: 1.9899 - accuracy: 0.493 - ETA: 39s - loss: 1.9888 - accuracy: 0.493 - ETA: 36s - loss: 1.9900 - accuracy: 0.493 - ETA: 34s - loss: 1.9907 - accuracy: 0.493 - ETA: 31s - loss: 1.9891 - accuracy: 0.494 - ETA: 29s - loss: 1.9879 - accuracy: 0.495 - ETA: 26s - loss: 1.9867 - accuracy: 0.495 - ETA: 23s - loss: 1.9858 - accuracy: 0.495 - ETA: 21s - loss: 1.9859 - accuracy: 0.495 - ETA: 18s - loss: 1.9849 - accuracy: 0.495 - ETA: 15s - loss: 1.9857 - accuracy: 0.495 - ETA: 13s - loss: 1.9843 - accuracy: 0.495 - ETA: 10s - loss: 1.9818 - accuracy: 0.496 - ETA: 7s - loss: 1.9810 - accuracy: 0.496 - ETA: 5s - loss: 1.9807 - accuracy: 0.49 - ETA: 2s - loss: 1.9806 - accuracy: 0.49 - 447s 23ms/step - loss: 1.9803 - accuracy: 0.4968 - val_loss: 1.7587 - val_accuracy: 0.5838\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:30 - loss: 1.7848 - accuracy: 0.53 - ETA: 6:04 - loss: 1.8998 - accuracy: 0.50 - ETA: 6:11 - loss: 1.7995 - accuracy: 0.53 - ETA: 6:23 - loss: 1.7754 - accuracy: 0.53 - ETA: 6:27 - loss: 1.7992 - accuracy: 0.54 - ETA: 6:16 - loss: 1.7948 - accuracy: 0.53 - ETA: 5:57 - loss: 1.8271 - accuracy: 0.52 - ETA: 6:02 - loss: 1.8383 - accuracy: 0.51 - ETA: 6:03 - loss: 1.8324 - accuracy: 0.52 - ETA: 6:03 - loss: 1.8138 - accuracy: 0.52 - ETA: 6:04 - loss: 1.8017 - accuracy: 0.53 - ETA: 6:03 - loss: 1.8000 - accuracy: 0.53 - ETA: 6:03 - loss: 1.8126 - accuracy: 0.52 - ETA: 6:02 - loss: 1.8110 - accuracy: 0.52 - ETA: 5:55 - loss: 1.8063 - accuracy: 0.52 - ETA: 5:44 - loss: 1.8037 - accuracy: 0.52 - ETA: 5:35 - loss: 1.7889 - accuracy: 0.52 - ETA: 5:27 - loss: 1.7911 - accuracy: 0.52 - ETA: 5:19 - loss: 1.7861 - accuracy: 0.53 - ETA: 5:11 - loss: 1.8002 - accuracy: 0.52 - ETA: 5:05 - loss: 1.8133 - accuracy: 0.52 - ETA: 4:58 - loss: 1.8202 - accuracy: 0.52 - ETA: 4:53 - loss: 1.8147 - accuracy: 0.52 - ETA: 4:48 - loss: 1.8035 - accuracy: 0.52 - ETA: 4:48 - loss: 1.8102 - accuracy: 0.52 - ETA: 4:49 - loss: 1.7981 - accuracy: 0.52 - ETA: 4:49 - loss: 1.7981 - accuracy: 0.52 - ETA: 4:50 - loss: 1.7964 - accuracy: 0.52 - ETA: 4:49 - loss: 1.7980 - accuracy: 0.52 - ETA: 4:49 - loss: 1.7931 - accuracy: 0.52 - ETA: 4:49 - loss: 1.7865 - accuracy: 0.52 - ETA: 4:47 - loss: 1.7823 - accuracy: 0.52 - ETA: 4:47 - loss: 1.7800 - accuracy: 0.53 - ETA: 4:46 - loss: 1.7893 - accuracy: 0.52 - ETA: 4:45 - loss: 1.7979 - accuracy: 0.52 - ETA: 4:44 - loss: 1.7968 - accuracy: 0.52 - ETA: 4:43 - loss: 1.8046 - accuracy: 0.52 - ETA: 4:42 - loss: 1.8172 - accuracy: 0.52 - ETA: 4:38 - loss: 1.8230 - accuracy: 0.52 - ETA: 4:33 - loss: 1.8301 - accuracy: 0.52 - ETA: 4:28 - loss: 1.8321 - accuracy: 0.52 - ETA: 4:24 - loss: 1.8319 - accuracy: 0.52 - ETA: 4:19 - loss: 1.8317 - accuracy: 0.52 - ETA: 4:15 - loss: 1.8341 - accuracy: 0.52 - ETA: 4:14 - loss: 1.8343 - accuracy: 0.52 - ETA: 4:12 - loss: 1.8345 - accuracy: 0.52 - ETA: 4:10 - loss: 1.8316 - accuracy: 0.52 - ETA: 4:08 - loss: 1.8243 - accuracy: 0.52 - ETA: 4:05 - loss: 1.8247 - accuracy: 0.52 - ETA: 4:03 - loss: 1.8223 - accuracy: 0.52 - ETA: 4:01 - loss: 1.8211 - accuracy: 0.52 - ETA: 3:59 - loss: 1.8282 - accuracy: 0.52 - ETA: 3:58 - loss: 1.8264 - accuracy: 0.52 - ETA: 3:56 - loss: 1.8232 - accuracy: 0.52 - ETA: 3:54 - loss: 1.8221 - accuracy: 0.52 - ETA: 3:52 - loss: 1.8183 - accuracy: 0.52 - ETA: 3:51 - loss: 1.8152 - accuracy: 0.52 - ETA: 3:49 - loss: 1.8202 - accuracy: 0.52 - ETA: 3:46 - loss: 1.8239 - accuracy: 0.52 - ETA: 3:43 - loss: 1.8203 - accuracy: 0.52 - ETA: 3:41 - loss: 1.8205 - accuracy: 0.52 - ETA: 3:39 - loss: 1.8242 - accuracy: 0.52 - ETA: 3:36 - loss: 1.8186 - accuracy: 0.52 - ETA: 3:35 - loss: 1.8197 - accuracy: 0.52 - ETA: 3:32 - loss: 1.8204 - accuracy: 0.52 - ETA: 3:30 - loss: 1.8208 - accuracy: 0.52 - ETA: 3:28 - loss: 1.8192 - accuracy: 0.52 - ETA: 3:26 - loss: 1.8164 - accuracy: 0.52 - ETA: 3:23 - loss: 1.8132 - accuracy: 0.52 - ETA: 3:21 - loss: 1.8126 - accuracy: 0.52 - ETA: 3:19 - loss: 1.8105 - accuracy: 0.52 - ETA: 3:17 - loss: 1.8114 - accuracy: 0.52 - ETA: 3:15 - loss: 1.8096 - accuracy: 0.52 - ETA: 3:12 - loss: 1.8118 - accuracy: 0.52 - ETA: 3:10 - loss: 1.8097 - accuracy: 0.52 - ETA: 3:08 - loss: 1.8130 - accuracy: 0.52 - ETA: 3:06 - loss: 1.8152 - accuracy: 0.52 - ETA: 3:03 - loss: 1.8139 - accuracy: 0.52 - ETA: 3:01 - loss: 1.8124 - accuracy: 0.52 - ETA: 2:58 - loss: 1.8121 - accuracy: 0.52 - ETA: 2:56 - loss: 1.8092 - accuracy: 0.52 - ETA: 2:54 - loss: 1.8108 - accuracy: 0.52 - ETA: 2:52 - loss: 1.8081 - accuracy: 0.52 - ETA: 2:49 - loss: 1.8071 - accuracy: 0.52 - ETA: 2:47 - loss: 1.8081 - accuracy: 0.52 - ETA: 2:44 - loss: 1.8094 - accuracy: 0.52 - ETA: 2:42 - loss: 1.8090 - accuracy: 0.52 - ETA: 2:39 - loss: 1.8080 - accuracy: 0.52 - ETA: 2:37 - loss: 1.8040 - accuracy: 0.52 - ETA: 2:34 - loss: 1.8015 - accuracy: 0.52 - ETA: 2:32 - loss: 1.7991 - accuracy: 0.52 - ETA: 2:29 - loss: 1.8010 - accuracy: 0.52 - ETA: 2:26 - loss: 1.8015 - accuracy: 0.52 - ETA: 2:23 - loss: 1.8035 - accuracy: 0.52 - ETA: 2:20 - loss: 1.8023 - accuracy: 0.52 - ETA: 2:18 - loss: 1.8015 - accuracy: 0.52 - ETA: 2:15 - loss: 1.8008 - accuracy: 0.52 - ETA: 2:13 - loss: 1.8036 - accuracy: 0.52 - ETA: 2:10 - loss: 1.8015 - accuracy: 0.52 - ETA: 2:08 - loss: 1.8011 - accuracy: 0.52 - ETA: 2:06 - loss: 1.8016 - accuracy: 0.52 - ETA: 2:03 - loss: 1.8001 - accuracy: 0.52 - ETA: 2:01 - loss: 1.7986 - accuracy: 0.52 - ETA: 1:58 - loss: 1.7982 - accuracy: 0.52 - ETA: 1:56 - loss: 1.7983 - accuracy: 0.52 - ETA: 1:54 - loss: 1.7994 - accuracy: 0.52 - ETA: 1:51 - loss: 1.7943 - accuracy: 0.52 - ETA: 1:49 - loss: 1.7966 - accuracy: 0.52 - ETA: 1:46 - loss: 1.7961 - accuracy: 0.52 - ETA: 1:44 - loss: 1.7925 - accuracy: 0.52 - ETA: 1:41 - loss: 1.7929 - accuracy: 0.52 - ETA: 1:39 - loss: 1.7915 - accuracy: 0.53 - ETA: 1:36 - loss: 1.7923 - accuracy: 0.53 - ETA: 1:34 - loss: 1.7930 - accuracy: 0.52 - ETA: 1:31 - loss: 1.7906 - accuracy: 0.53 - ETA: 1:29 - loss: 1.7932 - accuracy: 0.53 - ETA: 1:26 - loss: 1.7936 - accuracy: 0.53 - ETA: 1:24 - loss: 1.7924 - accuracy: 0.53 - ETA: 1:21 - loss: 1.7927 - accuracy: 0.53 - ETA: 1:19 - loss: 1.7931 - accuracy: 0.53 - ETA: 1:16 - loss: 1.7942 - accuracy: 0.53 - ETA: 1:13 - loss: 1.7945 - accuracy: 0.53 - ETA: 1:11 - loss: 1.7960 - accuracy: 0.53 - ETA: 1:08 - loss: 1.7957 - accuracy: 0.53 - ETA: 1:06 - loss: 1.7960 - accuracy: 0.52 - ETA: 1:03 - loss: 1.7939 - accuracy: 0.53 - ETA: 1:01 - loss: 1.7933 - accuracy: 0.53 - ETA: 58s - loss: 1.7926 - accuracy: 0.5308 - ETA: 56s - loss: 1.7940 - accuracy: 0.530 - ETA: 53s - loss: 1.7949 - accuracy: 0.530 - ETA: 51s - loss: 1.7945 - accuracy: 0.530 - ETA: 48s - loss: 1.7956 - accuracy: 0.530 - ETA: 45s - loss: 1.7951 - accuracy: 0.530 - ETA: 43s - loss: 1.7975 - accuracy: 0.529 - ETA: 40s - loss: 1.7955 - accuracy: 0.530 - ETA: 38s - loss: 1.7951 - accuracy: 0.530 - ETA: 35s - loss: 1.7955 - accuracy: 0.530 - ETA: 33s - loss: 1.7942 - accuracy: 0.529 - ETA: 30s - loss: 1.7939 - accuracy: 0.530 - ETA: 28s - loss: 1.7946 - accuracy: 0.529 - ETA: 25s - loss: 1.7956 - accuracy: 0.529 - ETA: 22s - loss: 1.7957 - accuracy: 0.529 - ETA: 20s - loss: 1.7955 - accuracy: 0.529 - ETA: 17s - loss: 1.7929 - accuracy: 0.530 - ETA: 15s - loss: 1.7925 - accuracy: 0.530 - ETA: 12s - loss: 1.7935 - accuracy: 0.529 - ETA: 9s - loss: 1.7939 - accuracy: 0.530 - ETA: 7s - loss: 1.7948 - accuracy: 0.52 - ETA: 4s - loss: 1.7947 - accuracy: 0.52 - ETA: 2s - loss: 1.7925 - accuracy: 0.53 - 433s 22ms/step - loss: 1.7914 - accuracy: 0.5303 - val_loss: 1.6683 - val_accuracy: 0.5985\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:44 - loss: 1.8542 - accuracy: 0.52 - ETA: 6:46 - loss: 1.7225 - accuracy: 0.55 - ETA: 6:51 - loss: 1.6705 - accuracy: 0.55 - ETA: 6:45 - loss: 1.6629 - accuracy: 0.55 - ETA: 6:36 - loss: 1.6255 - accuracy: 0.56 - ETA: 6:34 - loss: 1.6041 - accuracy: 0.56 - ETA: 6:33 - loss: 1.6297 - accuracy: 0.55 - ETA: 6:26 - loss: 1.6064 - accuracy: 0.56 - ETA: 6:23 - loss: 1.5887 - accuracy: 0.56 - ETA: 6:07 - loss: 1.6059 - accuracy: 0.56 - ETA: 6:06 - loss: 1.6000 - accuracy: 0.56 - ETA: 6:05 - loss: 1.5998 - accuracy: 0.56 - ETA: 6:01 - loss: 1.5927 - accuracy: 0.56 - ETA: 5:49 - loss: 1.5900 - accuracy: 0.56 - ETA: 5:47 - loss: 1.6037 - accuracy: 0.56 - ETA: 5:45 - loss: 1.6217 - accuracy: 0.55 - ETA: 5:42 - loss: 1.6229 - accuracy: 0.55 - ETA: 5:39 - loss: 1.6308 - accuracy: 0.55 - ETA: 5:38 - loss: 1.6247 - accuracy: 0.55 - ETA: 5:36 - loss: 1.6225 - accuracy: 0.55 - ETA: 5:35 - loss: 1.6222 - accuracy: 0.55 - ETA: 5:34 - loss: 1.6297 - accuracy: 0.56 - ETA: 5:32 - loss: 1.6342 - accuracy: 0.55 - ETA: 5:28 - loss: 1.6426 - accuracy: 0.55 - ETA: 5:27 - loss: 1.6361 - accuracy: 0.55 - ETA: 5:21 - loss: 1.6392 - accuracy: 0.55 - ETA: 5:14 - loss: 1.6555 - accuracy: 0.54 - ETA: 5:09 - loss: 1.6519 - accuracy: 0.55 - ETA: 5:05 - loss: 1.6548 - accuracy: 0.54 - ETA: 5:03 - loss: 1.6525 - accuracy: 0.54 - ETA: 5:01 - loss: 1.6486 - accuracy: 0.54 - ETA: 4:59 - loss: 1.6418 - accuracy: 0.54 - ETA: 4:58 - loss: 1.6359 - accuracy: 0.54 - ETA: 4:56 - loss: 1.6397 - accuracy: 0.55 - ETA: 4:54 - loss: 1.6470 - accuracy: 0.54 - ETA: 4:51 - loss: 1.6377 - accuracy: 0.55 - ETA: 4:50 - loss: 1.6374 - accuracy: 0.55 - ETA: 4:49 - loss: 1.6405 - accuracy: 0.55 - ETA: 4:47 - loss: 1.6405 - accuracy: 0.55 - ETA: 4:44 - loss: 1.6360 - accuracy: 0.55 - ETA: 4:42 - loss: 1.6341 - accuracy: 0.55 - ETA: 4:40 - loss: 1.6348 - accuracy: 0.55 - ETA: 4:38 - loss: 1.6388 - accuracy: 0.55 - ETA: 4:35 - loss: 1.6389 - accuracy: 0.55 - ETA: 4:30 - loss: 1.6326 - accuracy: 0.55 - ETA: 4:25 - loss: 1.6310 - accuracy: 0.55 - ETA: 4:22 - loss: 1.6267 - accuracy: 0.55 - ETA: 4:20 - loss: 1.6227 - accuracy: 0.55 - ETA: 4:17 - loss: 1.6218 - accuracy: 0.55 - ETA: 4:15 - loss: 1.6277 - accuracy: 0.55 - ETA: 4:12 - loss: 1.6288 - accuracy: 0.55 - ETA: 4:10 - loss: 1.6299 - accuracy: 0.55 - ETA: 4:08 - loss: 1.6282 - accuracy: 0.55 - ETA: 4:05 - loss: 1.6265 - accuracy: 0.55 - ETA: 4:02 - loss: 1.6290 - accuracy: 0.55 - ETA: 3:59 - loss: 1.6298 - accuracy: 0.55 - ETA: 3:57 - loss: 1.6272 - accuracy: 0.55 - ETA: 3:55 - loss: 1.6284 - accuracy: 0.55 - ETA: 3:53 - loss: 1.6294 - accuracy: 0.55 - ETA: 3:49 - loss: 1.6273 - accuracy: 0.55 - ETA: 3:47 - loss: 1.6284 - accuracy: 0.55 - ETA: 3:44 - loss: 1.6319 - accuracy: 0.55 - ETA: 3:43 - loss: 1.6312 - accuracy: 0.55 - ETA: 3:40 - loss: 1.6285 - accuracy: 0.55 - ETA: 3:37 - loss: 1.6299 - accuracy: 0.55 - ETA: 3:33 - loss: 1.6289 - accuracy: 0.55 - ETA: 3:31 - loss: 1.6277 - accuracy: 0.55 - ETA: 3:29 - loss: 1.6252 - accuracy: 0.55 - ETA: 3:26 - loss: 1.6299 - accuracy: 0.55 - ETA: 3:24 - loss: 1.6306 - accuracy: 0.55 - ETA: 3:22 - loss: 1.6329 - accuracy: 0.55 - ETA: 3:20 - loss: 1.6341 - accuracy: 0.55 - ETA: 3:16 - loss: 1.6380 - accuracy: 0.55 - ETA: 3:14 - loss: 1.6383 - accuracy: 0.55 - ETA: 3:11 - loss: 1.6387 - accuracy: 0.55 - ETA: 3:09 - loss: 1.6362 - accuracy: 0.55 - ETA: 3:06 - loss: 1.6351 - accuracy: 0.55 - ETA: 3:04 - loss: 1.6380 - accuracy: 0.55 - ETA: 3:00 - loss: 1.6331 - accuracy: 0.55 - ETA: 2:58 - loss: 1.6314 - accuracy: 0.55 - ETA: 2:56 - loss: 1.6342 - accuracy: 0.55 - ETA: 2:53 - loss: 1.6376 - accuracy: 0.55 - ETA: 2:51 - loss: 1.6417 - accuracy: 0.55 - ETA: 2:48 - loss: 1.6399 - accuracy: 0.55 - ETA: 2:46 - loss: 1.6374 - accuracy: 0.55 - ETA: 2:44 - loss: 1.6374 - accuracy: 0.55 - ETA: 2:41 - loss: 1.6374 - accuracy: 0.55 - ETA: 2:39 - loss: 1.6373 - accuracy: 0.55 - ETA: 2:37 - loss: 1.6368 - accuracy: 0.55 - ETA: 2:34 - loss: 1.6389 - accuracy: 0.55 - ETA: 2:32 - loss: 1.6404 - accuracy: 0.55 - ETA: 2:29 - loss: 1.6405 - accuracy: 0.55 - ETA: 2:27 - loss: 1.6397 - accuracy: 0.55 - ETA: 2:24 - loss: 1.6414 - accuracy: 0.55 - ETA: 2:22 - loss: 1.6407 - accuracy: 0.55 - ETA: 2:20 - loss: 1.6397 - accuracy: 0.55 - ETA: 2:17 - loss: 1.6398 - accuracy: 0.55 - ETA: 2:15 - loss: 1.6403 - accuracy: 0.55 - ETA: 2:12 - loss: 1.6418 - accuracy: 0.55 - ETA: 2:10 - loss: 1.6396 - accuracy: 0.55 - ETA: 2:07 - loss: 1.6408 - accuracy: 0.55 - ETA: 2:05 - loss: 1.6424 - accuracy: 0.55 - ETA: 2:02 - loss: 1.6422 - accuracy: 0.55 - ETA: 2:00 - loss: 1.6416 - accuracy: 0.55 - ETA: 1:57 - loss: 1.6428 - accuracy: 0.55 - ETA: 1:54 - loss: 1.6389 - accuracy: 0.55 - ETA: 1:52 - loss: 1.6389 - accuracy: 0.55 - ETA: 1:49 - loss: 1.6374 - accuracy: 0.55 - ETA: 1:47 - loss: 1.6358 - accuracy: 0.55 - ETA: 1:44 - loss: 1.6363 - accuracy: 0.55 - ETA: 1:42 - loss: 1.6348 - accuracy: 0.55 - ETA: 1:39 - loss: 1.6349 - accuracy: 0.55 - ETA: 1:37 - loss: 1.6360 - accuracy: 0.55 - ETA: 1:34 - loss: 1.6373 - accuracy: 0.55 - ETA: 1:32 - loss: 1.6362 - accuracy: 0.55 - ETA: 1:29 - loss: 1.6366 - accuracy: 0.55 - ETA: 1:27 - loss: 1.6365 - accuracy: 0.55 - ETA: 1:24 - loss: 1.6395 - accuracy: 0.55 - ETA: 1:22 - loss: 1.6396 - accuracy: 0.55 - ETA: 1:19 - loss: 1.6404 - accuracy: 0.55 - ETA: 1:17 - loss: 1.6395 - accuracy: 0.55 - ETA: 1:14 - loss: 1.6399 - accuracy: 0.55 - ETA: 1:11 - loss: 1.6400 - accuracy: 0.55 - ETA: 1:09 - loss: 1.6408 - accuracy: 0.55 - ETA: 1:06 - loss: 1.6414 - accuracy: 0.55 - ETA: 1:04 - loss: 1.6410 - accuracy: 0.55 - ETA: 1:01 - loss: 1.6401 - accuracy: 0.55 - ETA: 58s - loss: 1.6400 - accuracy: 0.5540 - ETA: 56s - loss: 1.6407 - accuracy: 0.554 - ETA: 53s - loss: 1.6390 - accuracy: 0.554 - ETA: 51s - loss: 1.6389 - accuracy: 0.554 - ETA: 48s - loss: 1.6363 - accuracy: 0.554 - ETA: 45s - loss: 1.6361 - accuracy: 0.554 - ETA: 43s - loss: 1.6354 - accuracy: 0.554 - ETA: 40s - loss: 1.6336 - accuracy: 0.555 - ETA: 38s - loss: 1.6329 - accuracy: 0.555 - ETA: 35s - loss: 1.6315 - accuracy: 0.556 - ETA: 33s - loss: 1.6303 - accuracy: 0.556 - ETA: 30s - loss: 1.6308 - accuracy: 0.555 - ETA: 27s - loss: 1.6302 - accuracy: 0.556 - ETA: 25s - loss: 1.6320 - accuracy: 0.555 - ETA: 22s - loss: 1.6295 - accuracy: 0.555 - ETA: 20s - loss: 1.6295 - accuracy: 0.556 - ETA: 17s - loss: 1.6288 - accuracy: 0.556 - ETA: 14s - loss: 1.6293 - accuracy: 0.556 - ETA: 12s - loss: 1.6300 - accuracy: 0.556 - ETA: 9s - loss: 1.6312 - accuracy: 0.555 - ETA: 7s - loss: 1.6337 - accuracy: 0.55 - ETA: 4s - loss: 1.6339 - accuracy: 0.55 - ETA: 2s - loss: 1.6364 - accuracy: 0.55 - 426s 22ms/step - loss: 1.6360 - accuracy: 0.5557 - val_loss: 1.6041 - val_accuracy: 0.6088\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:59 - loss: 1.5161 - accuracy: 0.55 - ETA: 6:33 - loss: 1.3388 - accuracy: 0.62 - ETA: 6:37 - loss: 1.3907 - accuracy: 0.62 - ETA: 6:23 - loss: 1.4017 - accuracy: 0.60 - ETA: 6:23 - loss: 1.4211 - accuracy: 0.60 - ETA: 6:25 - loss: 1.4322 - accuracy: 0.59 - ETA: 6:25 - loss: 1.4442 - accuracy: 0.59 - ETA: 6:14 - loss: 1.4387 - accuracy: 0.59 - ETA: 6:11 - loss: 1.4291 - accuracy: 0.59 - ETA: 6:06 - loss: 1.4462 - accuracy: 0.59 - ETA: 6:00 - loss: 1.4533 - accuracy: 0.59 - ETA: 5:59 - loss: 1.4353 - accuracy: 0.59 - ETA: 5:57 - loss: 1.4359 - accuracy: 0.59 - ETA: 5:55 - loss: 1.4581 - accuracy: 0.59 - ETA: 5:54 - loss: 1.4475 - accuracy: 0.59 - ETA: 5:50 - loss: 1.4676 - accuracy: 0.58 - ETA: 5:48 - loss: 1.4648 - accuracy: 0.59 - ETA: 5:47 - loss: 1.4758 - accuracy: 0.58 - ETA: 5:45 - loss: 1.4866 - accuracy: 0.58 - ETA: 5:43 - loss: 1.5018 - accuracy: 0.58 - ETA: 5:41 - loss: 1.4936 - accuracy: 0.58 - ETA: 5:40 - loss: 1.4917 - accuracy: 0.58 - ETA: 5:38 - loss: 1.4905 - accuracy: 0.58 - ETA: 5:36 - loss: 1.4933 - accuracy: 0.58 - ETA: 5:32 - loss: 1.4890 - accuracy: 0.58 - ETA: 5:32 - loss: 1.4931 - accuracy: 0.58 - ETA: 5:28 - loss: 1.5038 - accuracy: 0.58 - ETA: 5:26 - loss: 1.5049 - accuracy: 0.58 - ETA: 5:23 - loss: 1.4975 - accuracy: 0.58 - ETA: 5:20 - loss: 1.4963 - accuracy: 0.58 - ETA: 5:18 - loss: 1.4986 - accuracy: 0.58 - ETA: 5:15 - loss: 1.4944 - accuracy: 0.58 - ETA: 5:13 - loss: 1.4981 - accuracy: 0.58 - ETA: 5:09 - loss: 1.5015 - accuracy: 0.57 - ETA: 5:06 - loss: 1.5014 - accuracy: 0.58 - ETA: 5:04 - loss: 1.5001 - accuracy: 0.57 - ETA: 5:01 - loss: 1.5014 - accuracy: 0.58 - ETA: 4:59 - loss: 1.4971 - accuracy: 0.58 - ETA: 4:56 - loss: 1.4978 - accuracy: 0.58 - ETA: 4:52 - loss: 1.4966 - accuracy: 0.58 - ETA: 4:49 - loss: 1.4981 - accuracy: 0.57 - ETA: 4:47 - loss: 1.4982 - accuracy: 0.57 - ETA: 4:45 - loss: 1.5018 - accuracy: 0.57 - ETA: 4:41 - loss: 1.4990 - accuracy: 0.57 - ETA: 4:39 - loss: 1.4940 - accuracy: 0.58 - ETA: 4:36 - loss: 1.4906 - accuracy: 0.58 - ETA: 4:33 - loss: 1.4890 - accuracy: 0.58 - ETA: 4:31 - loss: 1.4890 - accuracy: 0.58 - ETA: 4:28 - loss: 1.4904 - accuracy: 0.58 - ETA: 4:25 - loss: 1.4870 - accuracy: 0.58 - ETA: 4:21 - loss: 1.4890 - accuracy: 0.58 - ETA: 4:17 - loss: 1.4888 - accuracy: 0.58 - ETA: 4:13 - loss: 1.4859 - accuracy: 0.58 - ETA: 4:09 - loss: 1.4853 - accuracy: 0.58 - ETA: 4:06 - loss: 1.4861 - accuracy: 0.58 - ETA: 4:03 - loss: 1.4852 - accuracy: 0.58 - ETA: 3:59 - loss: 1.4845 - accuracy: 0.58 - ETA: 3:55 - loss: 1.4821 - accuracy: 0.58 - ETA: 3:52 - loss: 1.4766 - accuracy: 0.58 - ETA: 3:50 - loss: 1.4764 - accuracy: 0.58 - ETA: 3:48 - loss: 1.4782 - accuracy: 0.58 - ETA: 3:46 - loss: 1.4742 - accuracy: 0.58 - ETA: 3:44 - loss: 1.4748 - accuracy: 0.58 - ETA: 3:42 - loss: 1.4747 - accuracy: 0.58 - ETA: 3:40 - loss: 1.4708 - accuracy: 0.58 - ETA: 3:38 - loss: 1.4738 - accuracy: 0.58 - ETA: 3:37 - loss: 1.4705 - accuracy: 0.58 - ETA: 3:34 - loss: 1.4731 - accuracy: 0.58 - ETA: 3:31 - loss: 1.4712 - accuracy: 0.58 - ETA: 3:27 - loss: 1.4703 - accuracy: 0.58 - ETA: 3:25 - loss: 1.4692 - accuracy: 0.58 - ETA: 3:22 - loss: 1.4694 - accuracy: 0.58 - ETA: 3:20 - loss: 1.4670 - accuracy: 0.58 - ETA: 3:17 - loss: 1.4648 - accuracy: 0.59 - ETA: 3:16 - loss: 1.4665 - accuracy: 0.58 - ETA: 3:14 - loss: 1.4651 - accuracy: 0.59 - ETA: 3:11 - loss: 1.4706 - accuracy: 0.58 - ETA: 3:09 - loss: 1.4742 - accuracy: 0.58 - ETA: 3:07 - loss: 1.4746 - accuracy: 0.58 - ETA: 3:04 - loss: 1.4746 - accuracy: 0.58 - ETA: 3:02 - loss: 1.4801 - accuracy: 0.58 - ETA: 2:59 - loss: 1.4816 - accuracy: 0.58 - ETA: 2:56 - loss: 1.4823 - accuracy: 0.58 - ETA: 2:52 - loss: 1.4864 - accuracy: 0.58 - ETA: 2:49 - loss: 1.4880 - accuracy: 0.58 - ETA: 2:46 - loss: 1.4894 - accuracy: 0.58 - ETA: 2:42 - loss: 1.4894 - accuracy: 0.58 - ETA: 2:39 - loss: 1.4891 - accuracy: 0.58 - ETA: 2:36 - loss: 1.4902 - accuracy: 0.58 - ETA: 2:33 - loss: 1.4925 - accuracy: 0.58 - ETA: 2:30 - loss: 1.4917 - accuracy: 0.58 - ETA: 2:27 - loss: 1.4902 - accuracy: 0.58 - ETA: 2:25 - loss: 1.4930 - accuracy: 0.58 - ETA: 2:22 - loss: 1.4939 - accuracy: 0.58 - ETA: 2:20 - loss: 1.4911 - accuracy: 0.58 - ETA: 2:18 - loss: 1.4891 - accuracy: 0.58 - ETA: 2:15 - loss: 1.4900 - accuracy: 0.58 - ETA: 2:13 - loss: 1.4891 - accuracy: 0.58 - ETA: 2:10 - loss: 1.4886 - accuracy: 0.58 - ETA: 2:07 - loss: 1.4887 - accuracy: 0.58 - ETA: 2:04 - loss: 1.4895 - accuracy: 0.58 - ETA: 2:01 - loss: 1.4914 - accuracy: 0.58 - ETA: 1:58 - loss: 1.4928 - accuracy: 0.58 - ETA: 1:56 - loss: 1.4915 - accuracy: 0.58 - ETA: 1:53 - loss: 1.4909 - accuracy: 0.58 - ETA: 1:51 - loss: 1.4889 - accuracy: 0.58 - ETA: 1:48 - loss: 1.4895 - accuracy: 0.58 - ETA: 1:46 - loss: 1.4884 - accuracy: 0.58 - ETA: 1:44 - loss: 1.4896 - accuracy: 0.58 - ETA: 1:41 - loss: 1.4897 - accuracy: 0.58 - ETA: 1:39 - loss: 1.4900 - accuracy: 0.58 - ETA: 1:36 - loss: 1.4903 - accuracy: 0.58 - ETA: 1:33 - loss: 1.4898 - accuracy: 0.58 - ETA: 1:31 - loss: 1.4891 - accuracy: 0.58 - ETA: 1:29 - loss: 1.4889 - accuracy: 0.58 - ETA: 1:26 - loss: 1.4874 - accuracy: 0.58 - ETA: 1:24 - loss: 1.4905 - accuracy: 0.58 - ETA: 1:22 - loss: 1.4898 - accuracy: 0.58 - ETA: 1:19 - loss: 1.4876 - accuracy: 0.58 - ETA: 1:17 - loss: 1.4905 - accuracy: 0.58 - ETA: 1:14 - loss: 1.4928 - accuracy: 0.58 - ETA: 1:12 - loss: 1.4932 - accuracy: 0.58 - ETA: 1:09 - loss: 1.4935 - accuracy: 0.58 - ETA: 1:07 - loss: 1.4944 - accuracy: 0.58 - ETA: 1:04 - loss: 1.4940 - accuracy: 0.58 - ETA: 1:02 - loss: 1.4935 - accuracy: 0.58 - ETA: 1:00 - loss: 1.4936 - accuracy: 0.58 - ETA: 57s - loss: 1.4925 - accuracy: 0.5852 - ETA: 55s - loss: 1.4915 - accuracy: 0.585 - ETA: 52s - loss: 1.4938 - accuracy: 0.584 - ETA: 49s - loss: 1.4930 - accuracy: 0.584 - ETA: 47s - loss: 1.4935 - accuracy: 0.584 - ETA: 44s - loss: 1.4915 - accuracy: 0.585 - ETA: 42s - loss: 1.4896 - accuracy: 0.585 - ETA: 39s - loss: 1.4884 - accuracy: 0.585 - ETA: 37s - loss: 1.4889 - accuracy: 0.585 - ETA: 34s - loss: 1.4896 - accuracy: 0.585 - ETA: 32s - loss: 1.4902 - accuracy: 0.585 - ETA: 30s - loss: 1.4882 - accuracy: 0.585 - ETA: 27s - loss: 1.4888 - accuracy: 0.585 - ETA: 25s - loss: 1.4894 - accuracy: 0.585 - ETA: 22s - loss: 1.4877 - accuracy: 0.586 - ETA: 19s - loss: 1.4863 - accuracy: 0.586 - ETA: 17s - loss: 1.4849 - accuracy: 0.586 - ETA: 14s - loss: 1.4866 - accuracy: 0.586 - ETA: 12s - loss: 1.4876 - accuracy: 0.585 - ETA: 9s - loss: 1.4888 - accuracy: 0.585 - ETA: 7s - loss: 1.4873 - accuracy: 0.58 - ETA: 4s - loss: 1.4876 - accuracy: 0.58 - ETA: 2s - loss: 1.4870 - accuracy: 0.58 - 404s 21ms/step - loss: 1.4861 - accuracy: 0.5869 - val_loss: 1.5540 - val_accuracy: 0.6244\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:59 - loss: 1.2338 - accuracy: 0.64 - ETA: 3:53 - loss: 1.5171 - accuracy: 0.57 - ETA: 4:05 - loss: 1.4058 - accuracy: 0.61 - ETA: 3:58 - loss: 1.4393 - accuracy: 0.61 - ETA: 3:45 - loss: 1.3936 - accuracy: 0.62 - ETA: 3:46 - loss: 1.3782 - accuracy: 0.62 - ETA: 3:47 - loss: 1.4372 - accuracy: 0.61 - ETA: 3:41 - loss: 1.4204 - accuracy: 0.61 - ETA: 3:44 - loss: 1.4316 - accuracy: 0.60 - ETA: 3:50 - loss: 1.4297 - accuracy: 0.60 - ETA: 3:50 - loss: 1.4460 - accuracy: 0.60 - ETA: 3:52 - loss: 1.4250 - accuracy: 0.60 - ETA: 3:52 - loss: 1.4220 - accuracy: 0.60 - ETA: 3:48 - loss: 1.4181 - accuracy: 0.60 - ETA: 3:47 - loss: 1.4249 - accuracy: 0.60 - ETA: 3:45 - loss: 1.4308 - accuracy: 0.60 - ETA: 3:46 - loss: 1.4278 - accuracy: 0.60 - ETA: 3:46 - loss: 1.4316 - accuracy: 0.60 - ETA: 3:44 - loss: 1.4196 - accuracy: 0.60 - ETA: 3:42 - loss: 1.4164 - accuracy: 0.60 - ETA: 3:37 - loss: 1.4033 - accuracy: 0.61 - ETA: 3:36 - loss: 1.4030 - accuracy: 0.61 - ETA: 3:34 - loss: 1.4138 - accuracy: 0.60 - ETA: 3:33 - loss: 1.4198 - accuracy: 0.60 - ETA: 3:31 - loss: 1.4111 - accuracy: 0.60 - ETA: 3:28 - loss: 1.4081 - accuracy: 0.60 - ETA: 3:24 - loss: 1.4105 - accuracy: 0.60 - ETA: 3:20 - loss: 1.4092 - accuracy: 0.60 - ETA: 3:18 - loss: 1.4116 - accuracy: 0.60 - ETA: 3:21 - loss: 1.4042 - accuracy: 0.60 - ETA: 3:23 - loss: 1.4096 - accuracy: 0.60 - ETA: 3:25 - loss: 1.4004 - accuracy: 0.60 - ETA: 3:27 - loss: 1.4001 - accuracy: 0.61 - ETA: 3:30 - loss: 1.4026 - accuracy: 0.61 - ETA: 3:31 - loss: 1.4005 - accuracy: 0.61 - ETA: 3:31 - loss: 1.4042 - accuracy: 0.61 - ETA: 3:32 - loss: 1.4085 - accuracy: 0.61 - ETA: 3:33 - loss: 1.4072 - accuracy: 0.61 - ETA: 3:33 - loss: 1.4147 - accuracy: 0.60 - ETA: 3:34 - loss: 1.4108 - accuracy: 0.61 - ETA: 3:34 - loss: 1.4107 - accuracy: 0.61 - ETA: 3:35 - loss: 1.4185 - accuracy: 0.60 - ETA: 3:35 - loss: 1.4176 - accuracy: 0.60 - ETA: 3:35 - loss: 1.4096 - accuracy: 0.61 - ETA: 3:36 - loss: 1.4076 - accuracy: 0.60 - ETA: 3:36 - loss: 1.4015 - accuracy: 0.61 - ETA: 3:36 - loss: 1.4044 - accuracy: 0.61 - ETA: 3:36 - loss: 1.3978 - accuracy: 0.61 - ETA: 3:35 - loss: 1.4009 - accuracy: 0.61 - ETA: 3:34 - loss: 1.3972 - accuracy: 0.61 - ETA: 3:34 - loss: 1.3933 - accuracy: 0.61 - ETA: 3:32 - loss: 1.3999 - accuracy: 0.61 - ETA: 3:32 - loss: 1.4039 - accuracy: 0.61 - ETA: 3:30 - loss: 1.4042 - accuracy: 0.61 - ETA: 3:29 - loss: 1.4047 - accuracy: 0.61 - ETA: 3:28 - loss: 1.4074 - accuracy: 0.61 - ETA: 3:25 - loss: 1.4095 - accuracy: 0.61 - ETA: 3:22 - loss: 1.4087 - accuracy: 0.61 - ETA: 3:19 - loss: 1.4081 - accuracy: 0.61 - ETA: 3:15 - loss: 1.4116 - accuracy: 0.61 - ETA: 3:12 - loss: 1.4090 - accuracy: 0.61 - ETA: 3:11 - loss: 1.4087 - accuracy: 0.61 - ETA: 3:09 - loss: 1.4128 - accuracy: 0.61 - ETA: 3:07 - loss: 1.4097 - accuracy: 0.61 - ETA: 3:06 - loss: 1.4117 - accuracy: 0.60 - ETA: 3:05 - loss: 1.4114 - accuracy: 0.60 - ETA: 3:04 - loss: 1.4142 - accuracy: 0.60 - ETA: 3:02 - loss: 1.4145 - accuracy: 0.60 - ETA: 3:00 - loss: 1.4140 - accuracy: 0.60 - ETA: 2:57 - loss: 1.4153 - accuracy: 0.60 - ETA: 2:56 - loss: 1.4140 - accuracy: 0.60 - ETA: 2:55 - loss: 1.4088 - accuracy: 0.60 - ETA: 2:53 - loss: 1.4083 - accuracy: 0.60 - ETA: 2:51 - loss: 1.4086 - accuracy: 0.60 - ETA: 2:50 - loss: 1.4121 - accuracy: 0.60 - ETA: 2:48 - loss: 1.4139 - accuracy: 0.60 - ETA: 2:46 - loss: 1.4139 - accuracy: 0.60 - ETA: 2:44 - loss: 1.4118 - accuracy: 0.60 - ETA: 2:43 - loss: 1.4119 - accuracy: 0.60 - ETA: 2:41 - loss: 1.4123 - accuracy: 0.60 - ETA: 2:39 - loss: 1.4138 - accuracy: 0.60 - ETA: 2:37 - loss: 1.4102 - accuracy: 0.60 - ETA: 2:35 - loss: 1.4136 - accuracy: 0.60 - ETA: 2:33 - loss: 1.4154 - accuracy: 0.60 - ETA: 2:31 - loss: 1.4154 - accuracy: 0.60 - ETA: 2:29 - loss: 1.4110 - accuracy: 0.60 - ETA: 2:27 - loss: 1.4113 - accuracy: 0.60 - ETA: 2:25 - loss: 1.4119 - accuracy: 0.60 - ETA: 2:23 - loss: 1.4129 - accuracy: 0.60 - ETA: 2:22 - loss: 1.4098 - accuracy: 0.60 - ETA: 2:20 - loss: 1.4079 - accuracy: 0.60 - ETA: 2:18 - loss: 1.4067 - accuracy: 0.60 - ETA: 2:15 - loss: 1.4068 - accuracy: 0.60 - ETA: 2:13 - loss: 1.4065 - accuracy: 0.60 - ETA: 2:11 - loss: 1.4075 - accuracy: 0.60 - ETA: 2:09 - loss: 1.4094 - accuracy: 0.60 - ETA: 2:07 - loss: 1.4101 - accuracy: 0.60 - ETA: 2:05 - loss: 1.4109 - accuracy: 0.60 - ETA: 2:03 - loss: 1.4133 - accuracy: 0.60 - ETA: 2:01 - loss: 1.4127 - accuracy: 0.60 - ETA: 1:59 - loss: 1.4154 - accuracy: 0.60 - ETA: 1:57 - loss: 1.4155 - accuracy: 0.60 - ETA: 1:55 - loss: 1.4147 - accuracy: 0.60 - ETA: 1:52 - loss: 1.4135 - accuracy: 0.60 - ETA: 1:50 - loss: 1.4117 - accuracy: 0.60 - ETA: 1:48 - loss: 1.4142 - accuracy: 0.60 - ETA: 1:46 - loss: 1.4151 - accuracy: 0.60 - ETA: 1:44 - loss: 1.4157 - accuracy: 0.60 - ETA: 1:41 - loss: 1.4133 - accuracy: 0.60 - ETA: 1:39 - loss: 1.4122 - accuracy: 0.60 - ETA: 1:37 - loss: 1.4072 - accuracy: 0.60 - ETA: 1:34 - loss: 1.4088 - accuracy: 0.60 - ETA: 1:32 - loss: 1.4075 - accuracy: 0.60 - ETA: 1:30 - loss: 1.4072 - accuracy: 0.60 - ETA: 1:27 - loss: 1.4072 - accuracy: 0.60 - ETA: 1:25 - loss: 1.4048 - accuracy: 0.60 - ETA: 1:23 - loss: 1.4052 - accuracy: 0.60 - ETA: 1:20 - loss: 1.4078 - accuracy: 0.60 - ETA: 1:18 - loss: 1.4058 - accuracy: 0.60 - ETA: 1:16 - loss: 1.4054 - accuracy: 0.60 - ETA: 1:13 - loss: 1.4071 - accuracy: 0.60 - ETA: 1:11 - loss: 1.4059 - accuracy: 0.60 - ETA: 1:09 - loss: 1.4052 - accuracy: 0.60 - ETA: 1:06 - loss: 1.4042 - accuracy: 0.60 - ETA: 1:04 - loss: 1.4027 - accuracy: 0.60 - ETA: 1:01 - loss: 1.4038 - accuracy: 0.60 - ETA: 59s - loss: 1.4023 - accuracy: 0.6074 - ETA: 57s - loss: 1.4031 - accuracy: 0.606 - ETA: 54s - loss: 1.4047 - accuracy: 0.606 - ETA: 52s - loss: 1.4059 - accuracy: 0.606 - ETA: 49s - loss: 1.4035 - accuracy: 0.606 - ETA: 47s - loss: 1.4048 - accuracy: 0.606 - ETA: 44s - loss: 1.4032 - accuracy: 0.606 - ETA: 42s - loss: 1.4039 - accuracy: 0.606 - ETA: 40s - loss: 1.4032 - accuracy: 0.606 - ETA: 37s - loss: 1.4009 - accuracy: 0.607 - ETA: 34s - loss: 1.4011 - accuracy: 0.607 - ETA: 32s - loss: 1.4020 - accuracy: 0.607 - ETA: 29s - loss: 1.4037 - accuracy: 0.606 - ETA: 27s - loss: 1.4029 - accuracy: 0.607 - ETA: 25s - loss: 1.4038 - accuracy: 0.607 - ETA: 22s - loss: 1.4046 - accuracy: 0.606 - ETA: 20s - loss: 1.4057 - accuracy: 0.606 - ETA: 17s - loss: 1.4070 - accuracy: 0.606 - ETA: 14s - loss: 1.4084 - accuracy: 0.605 - ETA: 12s - loss: 1.4093 - accuracy: 0.605 - ETA: 9s - loss: 1.4110 - accuracy: 0.605 - ETA: 7s - loss: 1.4105 - accuracy: 0.60 - ETA: 4s - loss: 1.4088 - accuracy: 0.60 - ETA: 2s - loss: 1.4080 - accuracy: 0.60 - 431s 22ms/step - loss: 1.4071 - accuracy: 0.6061 - val_loss: 1.5060 - val_accuracy: 0.6413\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:58 - loss: 1.2372 - accuracy: 0.64 - ETA: 8:39 - loss: 1.3279 - accuracy: 0.61 - ETA: 8:39 - loss: 1.3440 - accuracy: 0.62 - ETA: 8:19 - loss: 1.4270 - accuracy: 0.60 - ETA: 8:16 - loss: 1.4176 - accuracy: 0.60 - ETA: 8:06 - loss: 1.4251 - accuracy: 0.59 - ETA: 8:07 - loss: 1.3621 - accuracy: 0.60 - ETA: 7:50 - loss: 1.3575 - accuracy: 0.60 - ETA: 7:29 - loss: 1.3415 - accuracy: 0.60 - ETA: 7:13 - loss: 1.3532 - accuracy: 0.60 - ETA: 7:09 - loss: 1.3813 - accuracy: 0.59 - ETA: 7:02 - loss: 1.3769 - accuracy: 0.59 - ETA: 6:59 - loss: 1.3584 - accuracy: 0.60 - ETA: 6:55 - loss: 1.3480 - accuracy: 0.60 - ETA: 6:50 - loss: 1.3674 - accuracy: 0.60 - ETA: 6:46 - loss: 1.3618 - accuracy: 0.60 - ETA: 6:40 - loss: 1.3613 - accuracy: 0.60 - ETA: 6:37 - loss: 1.3635 - accuracy: 0.60 - ETA: 6:35 - loss: 1.3579 - accuracy: 0.60 - ETA: 6:32 - loss: 1.3539 - accuracy: 0.60 - ETA: 6:28 - loss: 1.3492 - accuracy: 0.61 - ETA: 6:25 - loss: 1.3508 - accuracy: 0.61 - ETA: 6:22 - loss: 1.3482 - accuracy: 0.61 - ETA: 6:18 - loss: 1.3608 - accuracy: 0.60 - ETA: 6:14 - loss: 1.3621 - accuracy: 0.60 - ETA: 6:11 - loss: 1.3637 - accuracy: 0.60 - ETA: 6:07 - loss: 1.3666 - accuracy: 0.60 - ETA: 6:05 - loss: 1.3606 - accuracy: 0.60 - ETA: 6:01 - loss: 1.3615 - accuracy: 0.60 - ETA: 5:58 - loss: 1.3570 - accuracy: 0.60 - ETA: 5:55 - loss: 1.3596 - accuracy: 0.60 - ETA: 5:52 - loss: 1.3574 - accuracy: 0.61 - ETA: 5:48 - loss: 1.3518 - accuracy: 0.61 - ETA: 5:44 - loss: 1.3491 - accuracy: 0.61 - ETA: 5:41 - loss: 1.3439 - accuracy: 0.61 - ETA: 5:37 - loss: 1.3360 - accuracy: 0.61 - ETA: 5:34 - loss: 1.3308 - accuracy: 0.61 - ETA: 5:32 - loss: 1.3316 - accuracy: 0.61 - ETA: 5:28 - loss: 1.3307 - accuracy: 0.61 - ETA: 5:24 - loss: 1.3291 - accuracy: 0.61 - ETA: 5:21 - loss: 1.3263 - accuracy: 0.61 - ETA: 5:18 - loss: 1.3260 - accuracy: 0.61 - ETA: 5:15 - loss: 1.3232 - accuracy: 0.61 - ETA: 5:11 - loss: 1.3304 - accuracy: 0.61 - ETA: 5:08 - loss: 1.3264 - accuracy: 0.61 - ETA: 5:05 - loss: 1.3228 - accuracy: 0.61 - ETA: 5:03 - loss: 1.3246 - accuracy: 0.61 - ETA: 5:00 - loss: 1.3275 - accuracy: 0.61 - ETA: 4:58 - loss: 1.3235 - accuracy: 0.61 - ETA: 4:55 - loss: 1.3245 - accuracy: 0.61 - ETA: 4:53 - loss: 1.3209 - accuracy: 0.61 - ETA: 4:49 - loss: 1.3195 - accuracy: 0.61 - ETA: 4:46 - loss: 1.3169 - accuracy: 0.61 - ETA: 4:44 - loss: 1.3130 - accuracy: 0.61 - ETA: 4:41 - loss: 1.3107 - accuracy: 0.61 - ETA: 4:38 - loss: 1.3109 - accuracy: 0.61 - ETA: 4:35 - loss: 1.3121 - accuracy: 0.61 - ETA: 4:32 - loss: 1.3123 - accuracy: 0.61 - ETA: 4:29 - loss: 1.3152 - accuracy: 0.61 - ETA: 4:26 - loss: 1.3173 - accuracy: 0.61 - ETA: 4:23 - loss: 1.3212 - accuracy: 0.61 - ETA: 4:20 - loss: 1.3156 - accuracy: 0.61 - ETA: 4:17 - loss: 1.3119 - accuracy: 0.61 - ETA: 4:14 - loss: 1.3113 - accuracy: 0.61 - ETA: 4:11 - loss: 1.3093 - accuracy: 0.61 - ETA: 4:08 - loss: 1.3102 - accuracy: 0.61 - ETA: 4:05 - loss: 1.3126 - accuracy: 0.61 - ETA: 4:02 - loss: 1.3103 - accuracy: 0.61 - ETA: 3:59 - loss: 1.3109 - accuracy: 0.61 - ETA: 3:56 - loss: 1.3095 - accuracy: 0.61 - ETA: 3:53 - loss: 1.3093 - accuracy: 0.61 - ETA: 3:50 - loss: 1.3107 - accuracy: 0.61 - ETA: 3:47 - loss: 1.3117 - accuracy: 0.61 - ETA: 3:44 - loss: 1.3135 - accuracy: 0.61 - ETA: 3:42 - loss: 1.3117 - accuracy: 0.61 - ETA: 3:39 - loss: 1.3157 - accuracy: 0.61 - ETA: 3:36 - loss: 1.3154 - accuracy: 0.61 - ETA: 3:33 - loss: 1.3151 - accuracy: 0.61 - ETA: 3:29 - loss: 1.3179 - accuracy: 0.61 - ETA: 3:25 - loss: 1.3171 - accuracy: 0.61 - ETA: 3:23 - loss: 1.3204 - accuracy: 0.61 - ETA: 3:20 - loss: 1.3179 - accuracy: 0.61 - ETA: 3:17 - loss: 1.3179 - accuracy: 0.61 - ETA: 3:14 - loss: 1.3167 - accuracy: 0.61 - ETA: 3:11 - loss: 1.3180 - accuracy: 0.61 - ETA: 3:08 - loss: 1.3153 - accuracy: 0.61 - ETA: 3:05 - loss: 1.3179 - accuracy: 0.61 - ETA: 3:02 - loss: 1.3170 - accuracy: 0.61 - ETA: 2:59 - loss: 1.3200 - accuracy: 0.61 - ETA: 2:56 - loss: 1.3210 - accuracy: 0.61 - ETA: 2:54 - loss: 1.3206 - accuracy: 0.61 - ETA: 2:51 - loss: 1.3191 - accuracy: 0.61 - ETA: 2:48 - loss: 1.3166 - accuracy: 0.61 - ETA: 2:45 - loss: 1.3163 - accuracy: 0.61 - ETA: 2:42 - loss: 1.3153 - accuracy: 0.61 - ETA: 2:39 - loss: 1.3178 - accuracy: 0.61 - ETA: 2:37 - loss: 1.3178 - accuracy: 0.61 - ETA: 2:34 - loss: 1.3167 - accuracy: 0.61 - ETA: 2:31 - loss: 1.3160 - accuracy: 0.61 - ETA: 2:28 - loss: 1.3165 - accuracy: 0.61 - ETA: 2:25 - loss: 1.3165 - accuracy: 0.61 - ETA: 2:22 - loss: 1.3140 - accuracy: 0.61 - ETA: 2:19 - loss: 1.3137 - accuracy: 0.61 - ETA: 2:16 - loss: 1.3156 - accuracy: 0.61 - ETA: 2:13 - loss: 1.3166 - accuracy: 0.61 - ETA: 2:10 - loss: 1.3166 - accuracy: 0.61 - ETA: 2:08 - loss: 1.3164 - accuracy: 0.61 - ETA: 2:05 - loss: 1.3143 - accuracy: 0.61 - ETA: 2:02 - loss: 1.3132 - accuracy: 0.61 - ETA: 1:59 - loss: 1.3117 - accuracy: 0.61 - ETA: 1:56 - loss: 1.3116 - accuracy: 0.61 - ETA: 1:53 - loss: 1.3102 - accuracy: 0.61 - ETA: 1:50 - loss: 1.3097 - accuracy: 0.61 - ETA: 1:47 - loss: 1.3103 - accuracy: 0.61 - ETA: 1:44 - loss: 1.3081 - accuracy: 0.61 - ETA: 1:41 - loss: 1.3079 - accuracy: 0.61 - ETA: 1:38 - loss: 1.3078 - accuracy: 0.61 - ETA: 1:35 - loss: 1.3087 - accuracy: 0.61 - ETA: 1:32 - loss: 1.3094 - accuracy: 0.61 - ETA: 1:29 - loss: 1.3076 - accuracy: 0.61 - ETA: 1:26 - loss: 1.3085 - accuracy: 0.61 - ETA: 1:24 - loss: 1.3077 - accuracy: 0.61 - ETA: 1:21 - loss: 1.3097 - accuracy: 0.61 - ETA: 1:18 - loss: 1.3078 - accuracy: 0.61 - ETA: 1:15 - loss: 1.3064 - accuracy: 0.61 - ETA: 1:12 - loss: 1.3060 - accuracy: 0.61 - ETA: 1:09 - loss: 1.3065 - accuracy: 0.61 - ETA: 1:06 - loss: 1.3078 - accuracy: 0.61 - ETA: 1:02 - loss: 1.3088 - accuracy: 0.61 - ETA: 59s - loss: 1.3087 - accuracy: 0.6191 - ETA: 56s - loss: 1.3080 - accuracy: 0.619 - ETA: 53s - loss: 1.3069 - accuracy: 0.619 - ETA: 50s - loss: 1.3071 - accuracy: 0.619 - ETA: 48s - loss: 1.3056 - accuracy: 0.619 - ETA: 45s - loss: 1.3072 - accuracy: 0.619 - ETA: 42s - loss: 1.3061 - accuracy: 0.619 - ETA: 39s - loss: 1.3078 - accuracy: 0.619 - ETA: 36s - loss: 1.3068 - accuracy: 0.620 - ETA: 33s - loss: 1.3065 - accuracy: 0.620 - ETA: 30s - loss: 1.3067 - accuracy: 0.620 - ETA: 28s - loss: 1.3068 - accuracy: 0.620 - ETA: 25s - loss: 1.3075 - accuracy: 0.620 - ETA: 22s - loss: 1.3103 - accuracy: 0.619 - ETA: 19s - loss: 1.3102 - accuracy: 0.619 - ETA: 16s - loss: 1.3118 - accuracy: 0.619 - ETA: 13s - loss: 1.3134 - accuracy: 0.618 - ETA: 10s - loss: 1.3131 - accuracy: 0.618 - ETA: 8s - loss: 1.3120 - accuracy: 0.619 - ETA: 5s - loss: 1.3117 - accuracy: 0.61 - ETA: 2s - loss: 1.3117 - accuracy: 0.61 - 457s 24ms/step - loss: 1.3119 - accuracy: 0.6190 - val_loss: 1.4465 - val_accuracy: 0.6478\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:58 - loss: 1.3227 - accuracy: 0.64 - ETA: 6:58 - loss: 1.3020 - accuracy: 0.64 - ETA: 6:47 - loss: 1.2871 - accuracy: 0.63 - ETA: 6:47 - loss: 1.2201 - accuracy: 0.64 - ETA: 6:38 - loss: 1.2399 - accuracy: 0.64 - ETA: 6:44 - loss: 1.2461 - accuracy: 0.63 - ETA: 6:42 - loss: 1.2377 - accuracy: 0.63 - ETA: 6:37 - loss: 1.2130 - accuracy: 0.63 - ETA: 6:36 - loss: 1.2312 - accuracy: 0.63 - ETA: 6:32 - loss: 1.2153 - accuracy: 0.63 - ETA: 6:31 - loss: 1.2327 - accuracy: 0.63 - ETA: 6:29 - loss: 1.2280 - accuracy: 0.63 - ETA: 6:28 - loss: 1.2249 - accuracy: 0.64 - ETA: 6:28 - loss: 1.2152 - accuracy: 0.64 - ETA: 6:23 - loss: 1.2299 - accuracy: 0.64 - ETA: 6:19 - loss: 1.2201 - accuracy: 0.64 - ETA: 6:17 - loss: 1.2280 - accuracy: 0.64 - ETA: 6:15 - loss: 1.2160 - accuracy: 0.64 - ETA: 6:13 - loss: 1.2267 - accuracy: 0.64 - ETA: 6:12 - loss: 1.2265 - accuracy: 0.63 - ETA: 6:08 - loss: 1.2155 - accuracy: 0.64 - ETA: 6:04 - loss: 1.2120 - accuracy: 0.64 - ETA: 6:03 - loss: 1.2144 - accuracy: 0.64 - ETA: 6:00 - loss: 1.2184 - accuracy: 0.64 - ETA: 5:57 - loss: 1.2077 - accuracy: 0.64 - ETA: 5:54 - loss: 1.2075 - accuracy: 0.64 - ETA: 5:51 - loss: 1.2131 - accuracy: 0.64 - ETA: 5:48 - loss: 1.2165 - accuracy: 0.64 - ETA: 5:46 - loss: 1.2159 - accuracy: 0.63 - ETA: 5:43 - loss: 1.2135 - accuracy: 0.64 - ETA: 5:40 - loss: 1.2031 - accuracy: 0.64 - ETA: 5:37 - loss: 1.2088 - accuracy: 0.64 - ETA: 5:34 - loss: 1.2102 - accuracy: 0.64 - ETA: 5:31 - loss: 1.2114 - accuracy: 0.64 - ETA: 5:29 - loss: 1.2105 - accuracy: 0.64 - ETA: 5:25 - loss: 1.2072 - accuracy: 0.64 - ETA: 5:23 - loss: 1.2064 - accuracy: 0.64 - ETA: 5:20 - loss: 1.1964 - accuracy: 0.64 - ETA: 5:17 - loss: 1.1990 - accuracy: 0.64 - ETA: 5:14 - loss: 1.2011 - accuracy: 0.64 - ETA: 5:12 - loss: 1.2057 - accuracy: 0.64 - ETA: 5:09 - loss: 1.2037 - accuracy: 0.64 - ETA: 5:06 - loss: 1.2070 - accuracy: 0.64 - ETA: 5:03 - loss: 1.2169 - accuracy: 0.64 - ETA: 5:01 - loss: 1.2148 - accuracy: 0.64 - ETA: 4:58 - loss: 1.2122 - accuracy: 0.64 - ETA: 4:55 - loss: 1.2096 - accuracy: 0.64 - ETA: 4:53 - loss: 1.2143 - accuracy: 0.64 - ETA: 4:48 - loss: 1.2125 - accuracy: 0.64 - ETA: 4:43 - loss: 1.2084 - accuracy: 0.64 - ETA: 4:39 - loss: 1.2095 - accuracy: 0.64 - ETA: 4:34 - loss: 1.2135 - accuracy: 0.64 - ETA: 4:29 - loss: 1.2147 - accuracy: 0.64 - ETA: 4:26 - loss: 1.2157 - accuracy: 0.64 - ETA: 4:23 - loss: 1.2175 - accuracy: 0.63 - ETA: 4:21 - loss: 1.2167 - accuracy: 0.64 - ETA: 4:18 - loss: 1.2128 - accuracy: 0.64 - ETA: 4:16 - loss: 1.2103 - accuracy: 0.64 - ETA: 4:13 - loss: 1.2101 - accuracy: 0.64 - ETA: 4:11 - loss: 1.2116 - accuracy: 0.64 - ETA: 4:08 - loss: 1.2132 - accuracy: 0.64 - ETA: 4:05 - loss: 1.2121 - accuracy: 0.64 - ETA: 4:03 - loss: 1.2120 - accuracy: 0.64 - ETA: 4:00 - loss: 1.2119 - accuracy: 0.64 - ETA: 3:58 - loss: 1.2073 - accuracy: 0.64 - ETA: 3:55 - loss: 1.2060 - accuracy: 0.64 - ETA: 3:53 - loss: 1.2050 - accuracy: 0.64 - ETA: 3:50 - loss: 1.2018 - accuracy: 0.64 - ETA: 3:47 - loss: 1.2000 - accuracy: 0.64 - ETA: 3:43 - loss: 1.2032 - accuracy: 0.64 - ETA: 3:39 - loss: 1.2042 - accuracy: 0.64 - ETA: 3:37 - loss: 1.2043 - accuracy: 0.64 - ETA: 3:34 - loss: 1.2050 - accuracy: 0.64 - ETA: 3:32 - loss: 1.2072 - accuracy: 0.64 - ETA: 3:29 - loss: 1.2078 - accuracy: 0.64 - ETA: 3:27 - loss: 1.2105 - accuracy: 0.64 - ETA: 3:24 - loss: 1.2107 - accuracy: 0.64 - ETA: 3:22 - loss: 1.2092 - accuracy: 0.64 - ETA: 3:19 - loss: 1.2084 - accuracy: 0.64 - ETA: 3:16 - loss: 1.2056 - accuracy: 0.64 - ETA: 3:14 - loss: 1.2049 - accuracy: 0.64 - ETA: 3:10 - loss: 1.2036 - accuracy: 0.64 - ETA: 3:07 - loss: 1.2005 - accuracy: 0.64 - ETA: 3:04 - loss: 1.2018 - accuracy: 0.64 - ETA: 3:01 - loss: 1.2007 - accuracy: 0.64 - ETA: 2:58 - loss: 1.2027 - accuracy: 0.64 - ETA: 2:56 - loss: 1.2033 - accuracy: 0.64 - ETA: 2:53 - loss: 1.2051 - accuracy: 0.64 - ETA: 2:50 - loss: 1.2077 - accuracy: 0.64 - ETA: 2:47 - loss: 1.2085 - accuracy: 0.64 - ETA: 2:44 - loss: 1.2084 - accuracy: 0.64 - ETA: 2:41 - loss: 1.2061 - accuracy: 0.64 - ETA: 2:39 - loss: 1.2069 - accuracy: 0.64 - ETA: 2:36 - loss: 1.2056 - accuracy: 0.64 - ETA: 2:33 - loss: 1.2079 - accuracy: 0.64 - ETA: 2:31 - loss: 1.2083 - accuracy: 0.64 - ETA: 2:28 - loss: 1.2102 - accuracy: 0.64 - ETA: 2:25 - loss: 1.2095 - accuracy: 0.64 - ETA: 2:22 - loss: 1.2093 - accuracy: 0.64 - ETA: 2:20 - loss: 1.2085 - accuracy: 0.64 - ETA: 2:17 - loss: 1.2058 - accuracy: 0.64 - ETA: 2:14 - loss: 1.2059 - accuracy: 0.64 - ETA: 2:12 - loss: 1.2085 - accuracy: 0.64 - ETA: 2:09 - loss: 1.2091 - accuracy: 0.64 - ETA: 2:06 - loss: 1.2115 - accuracy: 0.64 - ETA: 2:04 - loss: 1.2115 - accuracy: 0.64 - ETA: 2:01 - loss: 1.2126 - accuracy: 0.64 - ETA: 1:58 - loss: 1.2174 - accuracy: 0.64 - ETA: 1:55 - loss: 1.2178 - accuracy: 0.64 - ETA: 1:53 - loss: 1.2188 - accuracy: 0.64 - ETA: 1:50 - loss: 1.2205 - accuracy: 0.64 - ETA: 1:47 - loss: 1.2223 - accuracy: 0.64 - ETA: 1:44 - loss: 1.2220 - accuracy: 0.64 - ETA: 1:41 - loss: 1.2212 - accuracy: 0.64 - ETA: 1:39 - loss: 1.2216 - accuracy: 0.64 - ETA: 1:36 - loss: 1.2211 - accuracy: 0.64 - ETA: 1:33 - loss: 1.2194 - accuracy: 0.64 - ETA: 1:30 - loss: 1.2173 - accuracy: 0.64 - ETA: 1:28 - loss: 1.2178 - accuracy: 0.64 - ETA: 1:25 - loss: 1.2170 - accuracy: 0.64 - ETA: 1:22 - loss: 1.2173 - accuracy: 0.64 - ETA: 1:19 - loss: 1.2169 - accuracy: 0.64 - ETA: 1:17 - loss: 1.2175 - accuracy: 0.64 - ETA: 1:14 - loss: 1.2158 - accuracy: 0.64 - ETA: 1:11 - loss: 1.2156 - accuracy: 0.64 - ETA: 1:08 - loss: 1.2152 - accuracy: 0.64 - ETA: 1:05 - loss: 1.2156 - accuracy: 0.64 - ETA: 1:03 - loss: 1.2162 - accuracy: 0.64 - ETA: 1:00 - loss: 1.2172 - accuracy: 0.64 - ETA: 57s - loss: 1.2187 - accuracy: 0.6417 - ETA: 54s - loss: 1.2202 - accuracy: 0.641 - ETA: 51s - loss: 1.2198 - accuracy: 0.641 - ETA: 49s - loss: 1.2187 - accuracy: 0.641 - ETA: 46s - loss: 1.2186 - accuracy: 0.641 - ETA: 43s - loss: 1.2209 - accuracy: 0.640 - ETA: 41s - loss: 1.2231 - accuracy: 0.640 - ETA: 38s - loss: 1.2239 - accuracy: 0.639 - ETA: 35s - loss: 1.2232 - accuracy: 0.640 - ETA: 32s - loss: 1.2229 - accuracy: 0.640 - ETA: 29s - loss: 1.2213 - accuracy: 0.640 - ETA: 27s - loss: 1.2205 - accuracy: 0.640 - ETA: 24s - loss: 1.2209 - accuracy: 0.640 - ETA: 21s - loss: 1.2189 - accuracy: 0.640 - ETA: 18s - loss: 1.2196 - accuracy: 0.640 - ETA: 16s - loss: 1.2199 - accuracy: 0.639 - ETA: 13s - loss: 1.2195 - accuracy: 0.640 - ETA: 10s - loss: 1.2204 - accuracy: 0.639 - ETA: 7s - loss: 1.2198 - accuracy: 0.639 - ETA: 5s - loss: 1.2189 - accuracy: 0.64 - ETA: 2s - loss: 1.2191 - accuracy: 0.63 - 459s 24ms/step - loss: 1.2190 - accuracy: 0.6397 - val_loss: 1.4384 - val_accuracy: 0.6591\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:39 - loss: 1.0012 - accuracy: 0.72 - ETA: 5:52 - loss: 1.1314 - accuracy: 0.67 - ETA: 6:02 - loss: 1.1501 - accuracy: 0.65 - ETA: 6:14 - loss: 1.1532 - accuracy: 0.65 - ETA: 5:52 - loss: 1.1226 - accuracy: 0.66 - ETA: 5:59 - loss: 1.1336 - accuracy: 0.66 - ETA: 6:10 - loss: 1.1454 - accuracy: 0.66 - ETA: 6:12 - loss: 1.1728 - accuracy: 0.66 - ETA: 6:12 - loss: 1.1953 - accuracy: 0.66 - ETA: 6:15 - loss: 1.1710 - accuracy: 0.66 - ETA: 6:11 - loss: 1.1587 - accuracy: 0.66 - ETA: 6:11 - loss: 1.1491 - accuracy: 0.66 - ETA: 6:11 - loss: 1.1573 - accuracy: 0.66 - ETA: 6:11 - loss: 1.1828 - accuracy: 0.65 - ETA: 6:10 - loss: 1.1768 - accuracy: 0.65 - ETA: 6:08 - loss: 1.1707 - accuracy: 0.66 - ETA: 6:05 - loss: 1.1576 - accuracy: 0.66 - ETA: 6:04 - loss: 1.1514 - accuracy: 0.66 - ETA: 6:04 - loss: 1.1472 - accuracy: 0.66 - ETA: 6:02 - loss: 1.1417 - accuracy: 0.66 - ETA: 5:59 - loss: 1.1375 - accuracy: 0.66 - ETA: 5:53 - loss: 1.1449 - accuracy: 0.66 - ETA: 5:52 - loss: 1.1459 - accuracy: 0.66 - ETA: 5:51 - loss: 1.1436 - accuracy: 0.66 - ETA: 5:50 - loss: 1.1423 - accuracy: 0.66 - ETA: 5:48 - loss: 1.1423 - accuracy: 0.66 - ETA: 5:45 - loss: 1.1455 - accuracy: 0.66 - ETA: 5:44 - loss: 1.1397 - accuracy: 0.66 - ETA: 5:41 - loss: 1.1363 - accuracy: 0.66 - ETA: 5:39 - loss: 1.1379 - accuracy: 0.66 - ETA: 5:37 - loss: 1.1353 - accuracy: 0.66 - ETA: 5:35 - loss: 1.1348 - accuracy: 0.66 - ETA: 5:34 - loss: 1.1333 - accuracy: 0.66 - ETA: 5:33 - loss: 1.1377 - accuracy: 0.66 - ETA: 5:32 - loss: 1.1366 - accuracy: 0.66 - ETA: 5:29 - loss: 1.1375 - accuracy: 0.66 - ETA: 5:26 - loss: 1.1397 - accuracy: 0.65 - ETA: 5:23 - loss: 1.1495 - accuracy: 0.65 - ETA: 5:18 - loss: 1.1384 - accuracy: 0.65 - ETA: 5:13 - loss: 1.1381 - accuracy: 0.65 - ETA: 5:07 - loss: 1.1343 - accuracy: 0.65 - ETA: 5:02 - loss: 1.1355 - accuracy: 0.65 - ETA: 4:56 - loss: 1.1332 - accuracy: 0.65 - ETA: 4:53 - loss: 1.1320 - accuracy: 0.66 - ETA: 4:50 - loss: 1.1330 - accuracy: 0.66 - ETA: 4:48 - loss: 1.1336 - accuracy: 0.66 - ETA: 4:46 - loss: 1.1330 - accuracy: 0.66 - ETA: 4:44 - loss: 1.1372 - accuracy: 0.65 - ETA: 4:42 - loss: 1.1349 - accuracy: 0.66 - ETA: 4:38 - loss: 1.1356 - accuracy: 0.66 - ETA: 4:33 - loss: 1.1369 - accuracy: 0.66 - ETA: 4:28 - loss: 1.1368 - accuracy: 0.66 - ETA: 4:23 - loss: 1.1364 - accuracy: 0.66 - ETA: 4:18 - loss: 1.1359 - accuracy: 0.66 - ETA: 4:14 - loss: 1.1333 - accuracy: 0.66 - ETA: 4:10 - loss: 1.1386 - accuracy: 0.66 - ETA: 4:06 - loss: 1.1408 - accuracy: 0.66 - ETA: 4:02 - loss: 1.1375 - accuracy: 0.66 - ETA: 3:57 - loss: 1.1395 - accuracy: 0.66 - ETA: 3:53 - loss: 1.1402 - accuracy: 0.66 - ETA: 3:50 - loss: 1.1420 - accuracy: 0.66 - ETA: 47:26 - loss: 1.1403 - accuracy: 0.661 - ETA: 46:16 - loss: 1.1396 - accuracy: 0.661 - ETA: 45:06 - loss: 1.1391 - accuracy: 0.662 - ETA: 43:57 - loss: 1.1406 - accuracy: 0.661 - ETA: 42:49 - loss: 1.1395 - accuracy: 0.661 - ETA: 41:44 - loss: 1.1423 - accuracy: 0.660 - ETA: 40:40 - loss: 1.1444 - accuracy: 0.660 - ETA: 39:38 - loss: 1.1463 - accuracy: 0.660 - ETA: 38:39 - loss: 1.1456 - accuracy: 0.660 - ETA: 37:41 - loss: 1.1447 - accuracy: 0.659 - ETA: 36:44 - loss: 1.1462 - accuracy: 0.659 - ETA: 35:48 - loss: 1.1485 - accuracy: 0.659 - ETA: 34:54 - loss: 1.1493 - accuracy: 0.658 - ETA: 34:01 - loss: 1.1468 - accuracy: 0.659 - ETA: 33:09 - loss: 1.1466 - accuracy: 0.658 - ETA: 32:19 - loss: 1.1478 - accuracy: 0.658 - ETA: 31:30 - loss: 1.1492 - accuracy: 0.658 - ETA: 30:42 - loss: 1.1497 - accuracy: 0.657 - ETA: 29:55 - loss: 1.1491 - accuracy: 0.657 - ETA: 29:10 - loss: 1.1506 - accuracy: 0.656 - ETA: 28:25 - loss: 1.1518 - accuracy: 0.656 - ETA: 27:41 - loss: 1.1543 - accuracy: 0.655 - ETA: 26:59 - loss: 1.1532 - accuracy: 0.655 - ETA: 26:17 - loss: 1.1544 - accuracy: 0.655 - ETA: 25:36 - loss: 1.1545 - accuracy: 0.655 - ETA: 24:56 - loss: 1.1540 - accuracy: 0.655 - ETA: 24:18 - loss: 1.1524 - accuracy: 0.655 - ETA: 23:40 - loss: 1.1515 - accuracy: 0.655 - ETA: 23:02 - loss: 1.1534 - accuracy: 0.655 - ETA: 22:26 - loss: 1.1543 - accuracy: 0.655 - ETA: 21:50 - loss: 1.1537 - accuracy: 0.655 - ETA: 21:15 - loss: 1.1524 - accuracy: 0.655 - ETA: 20:41 - loss: 1.1506 - accuracy: 0.656 - ETA: 20:08 - loss: 1.1537 - accuracy: 0.656 - ETA: 19:35 - loss: 1.1565 - accuracy: 0.654 - ETA: 19:02 - loss: 1.1570 - accuracy: 0.654 - ETA: 18:31 - loss: 1.1570 - accuracy: 0.655 - ETA: 18:00 - loss: 1.1550 - accuracy: 0.655 - ETA: 17:29 - loss: 1.1548 - accuracy: 0.655 - ETA: 16:59 - loss: 1.1545 - accuracy: 0.656 - ETA: 16:30 - loss: 1.1542 - accuracy: 0.656 - ETA: 16:01 - loss: 1.1545 - accuracy: 0.657 - ETA: 15:32 - loss: 1.1555 - accuracy: 0.656 - ETA: 15:05 - loss: 1.1549 - accuracy: 0.657 - ETA: 14:37 - loss: 1.1582 - accuracy: 0.656 - ETA: 14:10 - loss: 1.1603 - accuracy: 0.656 - ETA: 13:44 - loss: 1.1590 - accuracy: 0.656 - ETA: 13:18 - loss: 1.1586 - accuracy: 0.656 - ETA: 12:52 - loss: 1.1569 - accuracy: 0.656 - ETA: 12:28 - loss: 1.1544 - accuracy: 0.657 - ETA: 12:04 - loss: 1.1539 - accuracy: 0.657 - ETA: 11:40 - loss: 1.1526 - accuracy: 0.657 - ETA: 11:16 - loss: 1.1532 - accuracy: 0.657 - ETA: 10:52 - loss: 1.1538 - accuracy: 0.657 - ETA: 10:29 - loss: 1.1533 - accuracy: 0.657 - ETA: 10:07 - loss: 1.1513 - accuracy: 0.657 - ETA: 9:45 - loss: 1.1514 - accuracy: 0.658 - ETA: 9:23 - loss: 1.1523 - accuracy: 0.65 - ETA: 9:01 - loss: 1.1529 - accuracy: 0.65 - ETA: 8:40 - loss: 1.1538 - accuracy: 0.65 - ETA: 8:19 - loss: 1.1539 - accuracy: 0.65 - ETA: 7:59 - loss: 1.1544 - accuracy: 0.65 - ETA: 7:38 - loss: 1.1539 - accuracy: 0.65 - ETA: 7:18 - loss: 1.1542 - accuracy: 0.65 - ETA: 6:59 - loss: 1.1527 - accuracy: 0.65 - ETA: 6:39 - loss: 1.1531 - accuracy: 0.65 - ETA: 6:20 - loss: 1.1526 - accuracy: 0.65 - ETA: 6:01 - loss: 1.1539 - accuracy: 0.65 - ETA: 5:42 - loss: 1.1543 - accuracy: 0.65 - ETA: 5:24 - loss: 1.1541 - accuracy: 0.65 - ETA: 5:05 - loss: 1.1541 - accuracy: 0.65 - ETA: 4:47 - loss: 1.1534 - accuracy: 0.65 - ETA: 4:30 - loss: 1.1530 - accuracy: 0.65 - ETA: 4:12 - loss: 1.1539 - accuracy: 0.65 - ETA: 3:55 - loss: 1.1539 - accuracy: 0.65 - ETA: 3:37 - loss: 1.1539 - accuracy: 0.65 - ETA: 3:21 - loss: 1.1539 - accuracy: 0.65 - ETA: 3:04 - loss: 1.1528 - accuracy: 0.65 - ETA: 2:47 - loss: 1.1536 - accuracy: 0.65 - ETA: 2:31 - loss: 1.1522 - accuracy: 0.65 - ETA: 2:15 - loss: 1.1514 - accuracy: 0.65 - ETA: 1:59 - loss: 1.1520 - accuracy: 0.65 - ETA: 1:43 - loss: 1.1533 - accuracy: 0.65 - ETA: 1:28 - loss: 1.1528 - accuracy: 0.65 - ETA: 1:12 - loss: 1.1520 - accuracy: 0.65 - ETA: 57s - loss: 1.1520 - accuracy: 0.6576 - ETA: 42s - loss: 1.1516 - accuracy: 0.657 - ETA: 27s - loss: 1.1513 - accuracy: 0.657 - ETA: 12s - loss: 1.1505 - accuracy: 0.658 - 2244s 116ms/step - loss: 1.1509 - accuracy: 0.6581 - val_loss: 1.4035 - val_accuracy: 0.6695\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 7:26 - loss: 1.1004 - accuracy: 0.67 - ETA: 5:45 - loss: 1.0608 - accuracy: 0.66 - ETA: 5:11 - loss: 1.1427 - accuracy: 0.64 - ETA: 5:34 - loss: 1.2118 - accuracy: 0.63 - ETA: 5:43 - loss: 1.2208 - accuracy: 0.62 - ETA: 5:38 - loss: 1.1984 - accuracy: 0.63 - ETA: 5:52 - loss: 1.1537 - accuracy: 0.65 - ETA: 5:53 - loss: 1.1437 - accuracy: 0.65 - ETA: 5:54 - loss: 1.1270 - accuracy: 0.65 - ETA: 5:42 - loss: 1.1127 - accuracy: 0.65 - ETA: 5:31 - loss: 1.1041 - accuracy: 0.65 - ETA: 5:30 - loss: 1.1019 - accuracy: 0.66 - ETA: 5:33 - loss: 1.0919 - accuracy: 0.66 - ETA: 5:38 - loss: 1.0990 - accuracy: 0.66 - ETA: 5:31 - loss: 1.1119 - accuracy: 0.65 - ETA: 5:25 - loss: 1.1004 - accuracy: 0.66 - ETA: 5:17 - loss: 1.0993 - accuracy: 0.66 - ETA: 5:14 - loss: 1.0937 - accuracy: 0.66 - ETA: 5:15 - loss: 1.0841 - accuracy: 0.67 - ETA: 5:12 - loss: 1.0911 - accuracy: 0.67 - ETA: 5:11 - loss: 1.0941 - accuracy: 0.66 - ETA: 5:09 - loss: 1.0910 - accuracy: 0.66 - ETA: 5:07 - loss: 1.1015 - accuracy: 0.66 - ETA: 5:06 - loss: 1.1026 - accuracy: 0.66 - ETA: 5:06 - loss: 1.1027 - accuracy: 0.66 - ETA: 5:04 - loss: 1.1060 - accuracy: 0.66 - ETA: 5:00 - loss: 1.1051 - accuracy: 0.66 - ETA: 4:54 - loss: 1.1059 - accuracy: 0.66 - ETA: 4:49 - loss: 1.1012 - accuracy: 0.66 - ETA: 4:43 - loss: 1.1019 - accuracy: 0.66 - ETA: 4:42 - loss: 1.0996 - accuracy: 0.66 - ETA: 4:40 - loss: 1.1051 - accuracy: 0.66 - ETA: 4:37 - loss: 1.0988 - accuracy: 0.66 - ETA: 4:32 - loss: 1.1030 - accuracy: 0.66 - ETA: 4:28 - loss: 1.1062 - accuracy: 0.66 - ETA: 4:23 - loss: 1.1081 - accuracy: 0.66 - ETA: 4:19 - loss: 1.1148 - accuracy: 0.65 - ETA: 4:18 - loss: 1.1135 - accuracy: 0.65 - ETA: 4:17 - loss: 1.1154 - accuracy: 0.65 - ETA: 4:15 - loss: 1.1106 - accuracy: 0.65 - ETA: 4:12 - loss: 1.1095 - accuracy: 0.66 - ETA: 4:11 - loss: 1.1127 - accuracy: 0.65 - ETA: 4:07 - loss: 1.1168 - accuracy: 0.65 - ETA: 4:06 - loss: 1.1150 - accuracy: 0.65 - ETA: 4:04 - loss: 1.1179 - accuracy: 0.65 - ETA: 4:01 - loss: 1.1226 - accuracy: 0.65 - ETA: 3:57 - loss: 1.1310 - accuracy: 0.65 - ETA: 3:56 - loss: 1.1318 - accuracy: 0.65 - ETA: 3:54 - loss: 1.1276 - accuracy: 0.65 - ETA: 3:53 - loss: 1.1298 - accuracy: 0.65 - ETA: 3:51 - loss: 1.1309 - accuracy: 0.65 - ETA: 3:49 - loss: 1.1340 - accuracy: 0.65 - ETA: 3:48 - loss: 1.1308 - accuracy: 0.65 - ETA: 3:46 - loss: 1.1277 - accuracy: 0.65 - ETA: 3:44 - loss: 1.1279 - accuracy: 0.65 - ETA: 3:40 - loss: 1.1292 - accuracy: 0.65 - ETA: 3:37 - loss: 1.1293 - accuracy: 0.65 - ETA: 3:33 - loss: 1.1279 - accuracy: 0.65 - ETA: 3:32 - loss: 1.1245 - accuracy: 0.65 - ETA: 3:30 - loss: 1.1226 - accuracy: 0.65 - ETA: 3:28 - loss: 1.1235 - accuracy: 0.65 - ETA: 3:26 - loss: 1.1252 - accuracy: 0.65 - ETA: 3:24 - loss: 1.1261 - accuracy: 0.65 - ETA: 3:22 - loss: 1.1236 - accuracy: 0.65 - ETA: 3:21 - loss: 1.1204 - accuracy: 0.65 - ETA: 3:19 - loss: 1.1241 - accuracy: 0.65 - ETA: 3:17 - loss: 1.1228 - accuracy: 0.65 - ETA: 3:15 - loss: 1.1217 - accuracy: 0.65 - ETA: 3:13 - loss: 1.1214 - accuracy: 0.65 - ETA: 3:11 - loss: 1.1185 - accuracy: 0.65 - ETA: 3:08 - loss: 1.1198 - accuracy: 0.65 - ETA: 3:06 - loss: 1.1173 - accuracy: 0.65 - ETA: 3:04 - loss: 1.1171 - accuracy: 0.65 - ETA: 3:02 - loss: 1.1144 - accuracy: 0.65 - ETA: 2:59 - loss: 1.1111 - accuracy: 0.65 - ETA: 2:56 - loss: 1.1066 - accuracy: 0.65 - ETA: 2:53 - loss: 1.1048 - accuracy: 0.66 - ETA: 2:50 - loss: 1.1032 - accuracy: 0.66 - ETA: 2:48 - loss: 1.1031 - accuracy: 0.66 - ETA: 2:46 - loss: 1.1020 - accuracy: 0.66 - ETA: 2:45 - loss: 1.1025 - accuracy: 0.66 - ETA: 2:43 - loss: 1.1009 - accuracy: 0.66 - ETA: 2:41 - loss: 1.1017 - accuracy: 0.66 - ETA: 2:39 - loss: 1.0997 - accuracy: 0.66 - ETA: 2:37 - loss: 1.0993 - accuracy: 0.66 - ETA: 2:35 - loss: 1.0977 - accuracy: 0.66 - ETA: 2:32 - loss: 1.0967 - accuracy: 0.66 - ETA: 2:31 - loss: 1.0977 - accuracy: 0.66 - ETA: 2:29 - loss: 1.0956 - accuracy: 0.66 - ETA: 2:27 - loss: 1.0963 - accuracy: 0.66 - ETA: 2:24 - loss: 1.0959 - accuracy: 0.66 - ETA: 2:22 - loss: 1.0964 - accuracy: 0.66 - ETA: 2:20 - loss: 1.0961 - accuracy: 0.66 - ETA: 2:18 - loss: 1.0956 - accuracy: 0.66 - ETA: 2:16 - loss: 1.0969 - accuracy: 0.66 - ETA: 2:14 - loss: 1.0966 - accuracy: 0.66 - ETA: 2:12 - loss: 1.0967 - accuracy: 0.66 - ETA: 2:10 - loss: 1.0975 - accuracy: 0.66 - ETA: 2:07 - loss: 1.0973 - accuracy: 0.66 - ETA: 2:05 - loss: 1.0974 - accuracy: 0.66 - ETA: 2:03 - loss: 1.0962 - accuracy: 0.66 - ETA: 2:01 - loss: 1.0958 - accuracy: 0.66 - ETA: 1:58 - loss: 1.0980 - accuracy: 0.66 - ETA: 1:56 - loss: 1.0963 - accuracy: 0.66 - ETA: 1:54 - loss: 1.0941 - accuracy: 0.66 - ETA: 1:51 - loss: 1.0950 - accuracy: 0.66 - ETA: 1:49 - loss: 1.0948 - accuracy: 0.66 - ETA: 1:47 - loss: 1.0929 - accuracy: 0.66 - ETA: 1:44 - loss: 1.0916 - accuracy: 0.66 - ETA: 1:42 - loss: 1.0919 - accuracy: 0.66 - ETA: 1:40 - loss: 1.0918 - accuracy: 0.66 - ETA: 1:37 - loss: 1.0900 - accuracy: 0.66 - ETA: 1:35 - loss: 1.0889 - accuracy: 0.66 - ETA: 1:32 - loss: 1.0869 - accuracy: 0.66 - ETA: 1:29 - loss: 1.0856 - accuracy: 0.66 - ETA: 1:27 - loss: 1.0861 - accuracy: 0.66 - ETA: 1:25 - loss: 1.0880 - accuracy: 0.66 - ETA: 1:22 - loss: 1.0884 - accuracy: 0.66 - ETA: 1:20 - loss: 1.0888 - accuracy: 0.66 - ETA: 1:18 - loss: 1.0889 - accuracy: 0.66 - ETA: 1:15 - loss: 1.0887 - accuracy: 0.66 - ETA: 1:12 - loss: 1.0883 - accuracy: 0.66 - ETA: 1:10 - loss: 1.0879 - accuracy: 0.66 - ETA: 1:07 - loss: 1.0887 - accuracy: 0.66 - ETA: 1:05 - loss: 1.0888 - accuracy: 0.66 - ETA: 1:02 - loss: 1.0892 - accuracy: 0.66 - ETA: 1:00 - loss: 1.0890 - accuracy: 0.66 - ETA: 57s - loss: 1.0903 - accuracy: 0.6683 - ETA: 55s - loss: 1.0926 - accuracy: 0.668 - ETA: 52s - loss: 1.0934 - accuracy: 0.667 - ETA: 50s - loss: 1.0942 - accuracy: 0.667 - ETA: 47s - loss: 1.0934 - accuracy: 0.668 - ETA: 45s - loss: 1.0963 - accuracy: 0.667 - ETA: 42s - loss: 1.0959 - accuracy: 0.667 - ETA: 40s - loss: 1.0949 - accuracy: 0.667 - ETA: 37s - loss: 1.0941 - accuracy: 0.668 - ETA: 35s - loss: 1.0939 - accuracy: 0.667 - ETA: 32s - loss: 1.0952 - accuracy: 0.667 - ETA: 30s - loss: 1.0957 - accuracy: 0.667 - ETA: 27s - loss: 1.0950 - accuracy: 0.667 - ETA: 24s - loss: 1.0957 - accuracy: 0.667 - ETA: 22s - loss: 1.0968 - accuracy: 0.667 - ETA: 19s - loss: 1.0974 - accuracy: 0.667 - ETA: 17s - loss: 1.0973 - accuracy: 0.667 - ETA: 14s - loss: 1.0984 - accuracy: 0.666 - ETA: 12s - loss: 1.0983 - accuracy: 0.666 - ETA: 9s - loss: 1.0989 - accuracy: 0.666 - ETA: 7s - loss: 1.0983 - accuracy: 0.66 - ETA: 4s - loss: 1.0996 - accuracy: 0.66 - ETA: 2s - loss: 1.1004 - accuracy: 0.66 - 440s 23ms/step - loss: 1.1002 - accuracy: 0.6660 - val_loss: 1.3962 - val_accuracy: 0.6743\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:55 - loss: 0.9958 - accuracy: 0.68 - ETA: 6:59 - loss: 1.0786 - accuracy: 0.66 - ETA: 7:10 - loss: 1.0419 - accuracy: 0.66 - ETA: 7:14 - loss: 1.0524 - accuracy: 0.66 - ETA: 7:06 - loss: 1.0573 - accuracy: 0.66 - ETA: 6:43 - loss: 1.0323 - accuracy: 0.66 - ETA: 6:40 - loss: 1.0291 - accuracy: 0.66 - ETA: 6:29 - loss: 0.9891 - accuracy: 0.68 - ETA: 6:12 - loss: 1.0307 - accuracy: 0.67 - ETA: 5:56 - loss: 1.0171 - accuracy: 0.68 - ETA: 6:02 - loss: 1.0054 - accuracy: 0.68 - ETA: 6:02 - loss: 1.0046 - accuracy: 0.68 - ETA: 6:01 - loss: 0.9910 - accuracy: 0.68 - ETA: 6:01 - loss: 0.9876 - accuracy: 0.69 - ETA: 5:52 - loss: 0.9922 - accuracy: 0.69 - ETA: 5:42 - loss: 0.9949 - accuracy: 0.69 - ETA: 5:38 - loss: 1.0119 - accuracy: 0.68 - ETA: 5:37 - loss: 1.0202 - accuracy: 0.68 - ETA: 5:36 - loss: 1.0161 - accuracy: 0.69 - ETA: 5:36 - loss: 1.0121 - accuracy: 0.69 - ETA: 5:35 - loss: 1.0137 - accuracy: 0.69 - ETA: 5:36 - loss: 1.0029 - accuracy: 0.69 - ETA: 5:34 - loss: 0.9974 - accuracy: 0.69 - ETA: 5:34 - loss: 0.9964 - accuracy: 0.69 - ETA: 5:33 - loss: 1.0017 - accuracy: 0.69 - ETA: 5:32 - loss: 0.9981 - accuracy: 0.69 - ETA: 5:29 - loss: 0.9981 - accuracy: 0.69 - ETA: 5:29 - loss: 0.9972 - accuracy: 0.69 - ETA: 5:27 - loss: 1.0028 - accuracy: 0.69 - ETA: 5:25 - loss: 1.0021 - accuracy: 0.69 - ETA: 5:22 - loss: 1.0135 - accuracy: 0.68 - ETA: 5:21 - loss: 1.0117 - accuracy: 0.68 - ETA: 5:18 - loss: 1.0067 - accuracy: 0.69 - ETA: 5:17 - loss: 1.0073 - accuracy: 0.69 - ETA: 5:15 - loss: 1.0079 - accuracy: 0.69 - ETA: 5:12 - loss: 1.0103 - accuracy: 0.68 - ETA: 5:07 - loss: 1.0148 - accuracy: 0.68 - ETA: 5:04 - loss: 1.0134 - accuracy: 0.68 - ETA: 5:01 - loss: 1.0176 - accuracy: 0.68 - ETA: 4:59 - loss: 1.0201 - accuracy: 0.68 - ETA: 4:56 - loss: 1.0213 - accuracy: 0.68 - ETA: 4:50 - loss: 1.0232 - accuracy: 0.68 - ETA: 4:48 - loss: 1.0241 - accuracy: 0.68 - ETA: 4:45 - loss: 1.0285 - accuracy: 0.68 - ETA: 4:44 - loss: 1.0268 - accuracy: 0.68 - ETA: 4:40 - loss: 1.0320 - accuracy: 0.67 - ETA: 4:36 - loss: 1.0327 - accuracy: 0.67 - ETA: 4:33 - loss: 1.0328 - accuracy: 0.67 - ETA: 4:31 - loss: 1.0336 - accuracy: 0.67 - ETA: 4:29 - loss: 1.0327 - accuracy: 0.67 - ETA: 4:28 - loss: 1.0360 - accuracy: 0.67 - ETA: 4:25 - loss: 1.0311 - accuracy: 0.67 - ETA: 4:21 - loss: 1.0360 - accuracy: 0.67 - ETA: 4:19 - loss: 1.0365 - accuracy: 0.67 - ETA: 4:17 - loss: 1.0412 - accuracy: 0.67 - ETA: 4:15 - loss: 1.0403 - accuracy: 0.67 - ETA: 4:13 - loss: 1.0417 - accuracy: 0.67 - ETA: 4:11 - loss: 1.0430 - accuracy: 0.67 - ETA: 4:10 - loss: 1.0459 - accuracy: 0.67 - ETA: 4:09 - loss: 1.0493 - accuracy: 0.67 - ETA: 4:06 - loss: 1.0496 - accuracy: 0.67 - ETA: 4:02 - loss: 1.0503 - accuracy: 0.67 - ETA: 3:58 - loss: 1.0511 - accuracy: 0.67 - ETA: 3:54 - loss: 1.0507 - accuracy: 0.67 - ETA: 3:51 - loss: 1.0519 - accuracy: 0.67 - ETA: 3:49 - loss: 1.0547 - accuracy: 0.67 - ETA: 3:46 - loss: 1.0534 - accuracy: 0.67 - ETA: 3:44 - loss: 1.0549 - accuracy: 0.67 - ETA: 3:42 - loss: 1.0561 - accuracy: 0.67 - ETA: 3:39 - loss: 1.0595 - accuracy: 0.67 - ETA: 3:37 - loss: 1.0633 - accuracy: 0.67 - ETA: 3:34 - loss: 1.0624 - accuracy: 0.67 - ETA: 3:32 - loss: 1.0594 - accuracy: 0.67 - ETA: 3:29 - loss: 1.0624 - accuracy: 0.67 - ETA: 3:27 - loss: 1.0638 - accuracy: 0.67 - ETA: 3:24 - loss: 1.0623 - accuracy: 0.67 - ETA: 3:21 - loss: 1.0630 - accuracy: 0.67 - ETA: 3:19 - loss: 1.0612 - accuracy: 0.67 - ETA: 3:17 - loss: 1.0602 - accuracy: 0.67 - ETA: 3:13 - loss: 1.0617 - accuracy: 0.67 - ETA: 3:10 - loss: 1.0610 - accuracy: 0.67 - ETA: 3:07 - loss: 1.0616 - accuracy: 0.67 - ETA: 3:04 - loss: 1.0610 - accuracy: 0.67 - ETA: 3:01 - loss: 1.0637 - accuracy: 0.67 - ETA: 2:59 - loss: 1.0643 - accuracy: 0.67 - ETA: 2:56 - loss: 1.0631 - accuracy: 0.67 - ETA: 2:53 - loss: 1.0631 - accuracy: 0.67 - ETA: 2:50 - loss: 1.0616 - accuracy: 0.67 - ETA: 2:47 - loss: 1.0615 - accuracy: 0.67 - ETA: 2:44 - loss: 1.0632 - accuracy: 0.67 - ETA: 2:42 - loss: 1.0638 - accuracy: 0.67 - ETA: 2:39 - loss: 1.0602 - accuracy: 0.67 - ETA: 2:37 - loss: 1.0602 - accuracy: 0.67 - ETA: 2:34 - loss: 1.0589 - accuracy: 0.67 - ETA: 2:32 - loss: 1.0566 - accuracy: 0.67 - ETA: 2:29 - loss: 1.0562 - accuracy: 0.67 - ETA: 2:26 - loss: 1.0561 - accuracy: 0.67 - ETA: 2:24 - loss: 1.0564 - accuracy: 0.67 - ETA: 2:21 - loss: 1.0537 - accuracy: 0.67 - ETA: 2:18 - loss: 1.0542 - accuracy: 0.67 - ETA: 2:16 - loss: 1.0552 - accuracy: 0.67 - ETA: 2:13 - loss: 1.0556 - accuracy: 0.67 - ETA: 2:10 - loss: 1.0550 - accuracy: 0.67 - ETA: 2:07 - loss: 1.0535 - accuracy: 0.67 - ETA: 2:04 - loss: 1.0551 - accuracy: 0.67 - ETA: 2:01 - loss: 1.0545 - accuracy: 0.67 - ETA: 1:59 - loss: 1.0521 - accuracy: 0.67 - ETA: 1:56 - loss: 1.0510 - accuracy: 0.67 - ETA: 1:53 - loss: 1.0498 - accuracy: 0.67 - ETA: 1:51 - loss: 1.0507 - accuracy: 0.67 - ETA: 1:48 - loss: 1.0491 - accuracy: 0.67 - ETA: 1:46 - loss: 1.0470 - accuracy: 0.67 - ETA: 1:43 - loss: 1.0460 - accuracy: 0.67 - ETA: 1:40 - loss: 1.0456 - accuracy: 0.67 - ETA: 1:38 - loss: 1.0453 - accuracy: 0.67 - ETA: 1:35 - loss: 1.0453 - accuracy: 0.67 - ETA: 1:32 - loss: 1.0457 - accuracy: 0.67 - ETA: 1:29 - loss: 1.0454 - accuracy: 0.67 - ETA: 1:27 - loss: 1.0431 - accuracy: 0.67 - ETA: 1:24 - loss: 1.0428 - accuracy: 0.67 - ETA: 1:21 - loss: 1.0439 - accuracy: 0.67 - ETA: 1:19 - loss: 1.0432 - accuracy: 0.67 - ETA: 1:16 - loss: 1.0419 - accuracy: 0.67 - ETA: 1:13 - loss: 1.0443 - accuracy: 0.67 - ETA: 1:10 - loss: 1.0435 - accuracy: 0.67 - ETA: 1:08 - loss: 1.0438 - accuracy: 0.67 - ETA: 1:05 - loss: 1.0440 - accuracy: 0.67 - ETA: 1:02 - loss: 1.0435 - accuracy: 0.67 - ETA: 59s - loss: 1.0440 - accuracy: 0.6771 - ETA: 57s - loss: 1.0441 - accuracy: 0.677 - ETA: 54s - loss: 1.0444 - accuracy: 0.677 - ETA: 51s - loss: 1.0433 - accuracy: 0.677 - ETA: 48s - loss: 1.0416 - accuracy: 0.677 - ETA: 46s - loss: 1.0416 - accuracy: 0.677 - ETA: 43s - loss: 1.0406 - accuracy: 0.678 - ETA: 40s - loss: 1.0409 - accuracy: 0.678 - ETA: 37s - loss: 1.0411 - accuracy: 0.678 - ETA: 35s - loss: 1.0417 - accuracy: 0.678 - ETA: 32s - loss: 1.0422 - accuracy: 0.677 - ETA: 29s - loss: 1.0432 - accuracy: 0.677 - ETA: 26s - loss: 1.0424 - accuracy: 0.677 - ETA: 24s - loss: 1.0430 - accuracy: 0.677 - ETA: 21s - loss: 1.0417 - accuracy: 0.677 - ETA: 18s - loss: 1.0417 - accuracy: 0.677 - ETA: 16s - loss: 1.0421 - accuracy: 0.677 - ETA: 13s - loss: 1.0430 - accuracy: 0.677 - ETA: 10s - loss: 1.0427 - accuracy: 0.677 - ETA: 7s - loss: 1.0416 - accuracy: 0.677 - ETA: 5s - loss: 1.0413 - accuracy: 0.67 - ETA: 2s - loss: 1.0413 - accuracy: 0.67 - 456s 24ms/step - loss: 1.0409 - accuracy: 0.6783 - val_loss: 1.3860 - val_accuracy: 0.6805\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:21 - loss: 0.9007 - accuracy: 0.72 - ETA: 5:34 - loss: 0.9632 - accuracy: 0.71 - ETA: 5:58 - loss: 0.8723 - accuracy: 0.73 - ETA: 6:08 - loss: 0.9520 - accuracy: 0.70 - ETA: 6:18 - loss: 0.9695 - accuracy: 0.70 - ETA: 6:20 - loss: 0.9222 - accuracy: 0.71 - ETA: 6:10 - loss: 0.9305 - accuracy: 0.71 - ETA: 5:55 - loss: 0.9478 - accuracy: 0.71 - ETA: 5:43 - loss: 0.9470 - accuracy: 0.71 - ETA: 5:34 - loss: 0.9737 - accuracy: 0.70 - ETA: 5:32 - loss: 0.9702 - accuracy: 0.70 - ETA: 5:37 - loss: 0.9508 - accuracy: 0.70 - ETA: 5:38 - loss: 0.9502 - accuracy: 0.70 - ETA: 5:38 - loss: 0.9521 - accuracy: 0.70 - ETA: 5:31 - loss: 0.9379 - accuracy: 0.70 - ETA: 5:22 - loss: 0.9389 - accuracy: 0.71 - ETA: 5:16 - loss: 0.9464 - accuracy: 0.70 - ETA: 5:20 - loss: 0.9388 - accuracy: 0.70 - ETA: 5:18 - loss: 0.9397 - accuracy: 0.70 - ETA: 5:18 - loss: 0.9486 - accuracy: 0.70 - ETA: 5:17 - loss: 0.9446 - accuracy: 0.70 - ETA: 5:19 - loss: 0.9620 - accuracy: 0.69 - ETA: 5:20 - loss: 0.9590 - accuracy: 0.69 - ETA: 5:19 - loss: 0.9699 - accuracy: 0.69 - ETA: 5:17 - loss: 0.9614 - accuracy: 0.69 - ETA: 5:15 - loss: 0.9605 - accuracy: 0.69 - ETA: 5:11 - loss: 0.9638 - accuracy: 0.69 - ETA: 5:06 - loss: 0.9559 - accuracy: 0.70 - ETA: 5:01 - loss: 0.9557 - accuracy: 0.70 - ETA: 5:01 - loss: 0.9517 - accuracy: 0.70 - ETA: 4:59 - loss: 0.9558 - accuracy: 0.69 - ETA: 4:57 - loss: 0.9540 - accuracy: 0.70 - ETA: 4:54 - loss: 0.9511 - accuracy: 0.70 - ETA: 4:53 - loss: 0.9574 - accuracy: 0.69 - ETA: 4:51 - loss: 0.9539 - accuracy: 0.69 - ETA: 4:48 - loss: 0.9558 - accuracy: 0.69 - ETA: 4:45 - loss: 0.9549 - accuracy: 0.69 - ETA: 4:43 - loss: 0.9602 - accuracy: 0.69 - ETA: 4:41 - loss: 0.9611 - accuracy: 0.69 - ETA: 4:39 - loss: 0.9620 - accuracy: 0.69 - ETA: 4:38 - loss: 0.9626 - accuracy: 0.69 - ETA: 4:36 - loss: 0.9657 - accuracy: 0.69 - ETA: 4:34 - loss: 0.9644 - accuracy: 0.69 - ETA: 4:31 - loss: 0.9590 - accuracy: 0.69 - ETA: 4:30 - loss: 0.9566 - accuracy: 0.69 - ETA: 4:28 - loss: 0.9572 - accuracy: 0.69 - ETA: 4:27 - loss: 0.9541 - accuracy: 0.69 - ETA: 4:25 - loss: 0.9544 - accuracy: 0.69 - ETA: 4:23 - loss: 0.9554 - accuracy: 0.69 - ETA: 4:21 - loss: 0.9572 - accuracy: 0.69 - ETA: 4:19 - loss: 0.9582 - accuracy: 0.69 - ETA: 4:17 - loss: 0.9617 - accuracy: 0.69 - ETA: 4:15 - loss: 0.9660 - accuracy: 0.69 - ETA: 4:13 - loss: 0.9667 - accuracy: 0.69 - ETA: 4:10 - loss: 0.9660 - accuracy: 0.69 - ETA: 4:06 - loss: 0.9658 - accuracy: 0.69 - ETA: 4:03 - loss: 0.9674 - accuracy: 0.69 - ETA: 4:00 - loss: 0.9677 - accuracy: 0.69 - ETA: 3:56 - loss: 0.9695 - accuracy: 0.69 - ETA: 3:53 - loss: 0.9673 - accuracy: 0.69 - ETA: 3:51 - loss: 0.9665 - accuracy: 0.69 - ETA: 3:48 - loss: 0.9664 - accuracy: 0.69 - ETA: 3:45 - loss: 0.9668 - accuracy: 0.69 - ETA: 3:43 - loss: 0.9648 - accuracy: 0.69 - ETA: 3:41 - loss: 0.9657 - accuracy: 0.69 - ETA: 3:38 - loss: 0.9666 - accuracy: 0.69 - ETA: 3:35 - loss: 0.9673 - accuracy: 0.69 - ETA: 3:33 - loss: 0.9684 - accuracy: 0.69 - ETA: 3:30 - loss: 0.9707 - accuracy: 0.69 - ETA: 3:28 - loss: 0.9694 - accuracy: 0.69 - ETA: 3:26 - loss: 0.9745 - accuracy: 0.69 - ETA: 3:23 - loss: 0.9774 - accuracy: 0.69 - ETA: 3:21 - loss: 0.9799 - accuracy: 0.69 - ETA: 3:18 - loss: 0.9783 - accuracy: 0.69 - ETA: 3:16 - loss: 0.9785 - accuracy: 0.69 - ETA: 3:13 - loss: 0.9795 - accuracy: 0.69 - ETA: 3:11 - loss: 0.9775 - accuracy: 0.69 - ETA: 3:08 - loss: 0.9785 - accuracy: 0.69 - ETA: 3:05 - loss: 0.9790 - accuracy: 0.69 - ETA: 3:02 - loss: 0.9781 - accuracy: 0.69 - ETA: 3:00 - loss: 0.9763 - accuracy: 0.69 - ETA: 2:57 - loss: 0.9743 - accuracy: 0.69 - ETA: 2:55 - loss: 0.9742 - accuracy: 0.69 - ETA: 2:52 - loss: 0.9775 - accuracy: 0.69 - ETA: 2:50 - loss: 0.9770 - accuracy: 0.69 - ETA: 2:47 - loss: 0.9741 - accuracy: 0.69 - ETA: 2:45 - loss: 0.9737 - accuracy: 0.69 - ETA: 2:42 - loss: 0.9760 - accuracy: 0.69 - ETA: 2:40 - loss: 0.9756 - accuracy: 0.69 - ETA: 2:38 - loss: 0.9745 - accuracy: 0.69 - ETA: 2:35 - loss: 0.9753 - accuracy: 0.69 - ETA: 2:32 - loss: 0.9743 - accuracy: 0.69 - ETA: 2:30 - loss: 0.9745 - accuracy: 0.69 - ETA: 2:27 - loss: 0.9752 - accuracy: 0.69 - ETA: 2:25 - loss: 0.9759 - accuracy: 0.69 - ETA: 2:22 - loss: 0.9766 - accuracy: 0.69 - ETA: 2:20 - loss: 0.9767 - accuracy: 0.69 - ETA: 2:17 - loss: 0.9762 - accuracy: 0.69 - ETA: 2:15 - loss: 0.9767 - accuracy: 0.69 - ETA: 2:12 - loss: 0.9765 - accuracy: 0.69 - ETA: 2:10 - loss: 0.9778 - accuracy: 0.69 - ETA: 2:07 - loss: 0.9777 - accuracy: 0.69 - ETA: 2:04 - loss: 0.9778 - accuracy: 0.69 - ETA: 2:02 - loss: 0.9765 - accuracy: 0.69 - ETA: 1:59 - loss: 0.9756 - accuracy: 0.69 - ETA: 1:57 - loss: 0.9765 - accuracy: 0.69 - ETA: 1:54 - loss: 0.9783 - accuracy: 0.69 - ETA: 1:52 - loss: 0.9786 - accuracy: 0.69 - ETA: 1:49 - loss: 0.9787 - accuracy: 0.69 - ETA: 1:46 - loss: 0.9804 - accuracy: 0.69 - ETA: 1:44 - loss: 0.9821 - accuracy: 0.69 - ETA: 1:41 - loss: 0.9837 - accuracy: 0.69 - ETA: 1:38 - loss: 0.9826 - accuracy: 0.69 - ETA: 1:35 - loss: 0.9829 - accuracy: 0.69 - ETA: 1:33 - loss: 0.9833 - accuracy: 0.69 - ETA: 1:30 - loss: 0.9835 - accuracy: 0.69 - ETA: 1:28 - loss: 0.9820 - accuracy: 0.69 - ETA: 1:25 - loss: 0.9821 - accuracy: 0.69 - ETA: 1:23 - loss: 0.9828 - accuracy: 0.69 - ETA: 1:20 - loss: 0.9814 - accuracy: 0.69 - ETA: 1:18 - loss: 0.9829 - accuracy: 0.69 - ETA: 1:15 - loss: 0.9834 - accuracy: 0.69 - ETA: 1:13 - loss: 0.9833 - accuracy: 0.69 - ETA: 1:10 - loss: 0.9835 - accuracy: 0.69 - ETA: 1:07 - loss: 0.9839 - accuracy: 0.69 - ETA: 1:05 - loss: 0.9864 - accuracy: 0.69 - ETA: 1:02 - loss: 0.9874 - accuracy: 0.69 - ETA: 1:00 - loss: 0.9877 - accuracy: 0.69 - ETA: 57s - loss: 0.9887 - accuracy: 0.6905 - ETA: 54s - loss: 0.9892 - accuracy: 0.690 - ETA: 52s - loss: 0.9890 - accuracy: 0.690 - ETA: 49s - loss: 0.9889 - accuracy: 0.690 - ETA: 46s - loss: 0.9898 - accuracy: 0.690 - ETA: 44s - loss: 0.9907 - accuracy: 0.690 - ETA: 41s - loss: 0.9898 - accuracy: 0.690 - ETA: 39s - loss: 0.9900 - accuracy: 0.690 - ETA: 36s - loss: 0.9899 - accuracy: 0.690 - ETA: 33s - loss: 0.9884 - accuracy: 0.691 - ETA: 31s - loss: 0.9885 - accuracy: 0.691 - ETA: 28s - loss: 0.9895 - accuracy: 0.690 - ETA: 25s - loss: 0.9908 - accuracy: 0.690 - ETA: 23s - loss: 0.9909 - accuracy: 0.690 - ETA: 20s - loss: 0.9912 - accuracy: 0.689 - ETA: 18s - loss: 0.9897 - accuracy: 0.690 - ETA: 15s - loss: 0.9890 - accuracy: 0.690 - ETA: 12s - loss: 0.9879 - accuracy: 0.691 - ETA: 10s - loss: 0.9877 - accuracy: 0.690 - ETA: 7s - loss: 0.9864 - accuracy: 0.691 - ETA: 4s - loss: 0.9847 - accuracy: 0.69 - ETA: 2s - loss: 0.9842 - accuracy: 0.69 - 439s 23ms/step - loss: 0.9840 - accuracy: 0.6917 - val_loss: 1.3760 - val_accuracy: 0.6979\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 5:52 - loss: 0.8061 - accuracy: 0.74 - ETA: 6:06 - loss: 0.8382 - accuracy: 0.73 - ETA: 6:06 - loss: 0.9633 - accuracy: 0.69 - ETA: 6:10 - loss: 0.9846 - accuracy: 0.68 - ETA: 6:21 - loss: 1.0030 - accuracy: 0.68 - ETA: 6:27 - loss: 0.9591 - accuracy: 0.69 - ETA: 6:28 - loss: 0.9451 - accuracy: 0.70 - ETA: 6:27 - loss: 0.9314 - accuracy: 0.70 - ETA: 6:30 - loss: 0.9486 - accuracy: 0.70 - ETA: 6:29 - loss: 0.9391 - accuracy: 0.70 - ETA: 6:27 - loss: 0.9129 - accuracy: 0.71 - ETA: 6:25 - loss: 0.9079 - accuracy: 0.71 - ETA: 6:22 - loss: 0.9201 - accuracy: 0.70 - ETA: 6:21 - loss: 0.9108 - accuracy: 0.70 - ETA: 6:18 - loss: 0.9099 - accuracy: 0.71 - ETA: 6:16 - loss: 0.9137 - accuracy: 0.71 - ETA: 6:13 - loss: 0.9194 - accuracy: 0.70 - ETA: 6:07 - loss: 0.9091 - accuracy: 0.70 - ETA: 6:06 - loss: 0.8994 - accuracy: 0.71 - ETA: 6:01 - loss: 0.8900 - accuracy: 0.71 - ETA: 5:59 - loss: 0.8867 - accuracy: 0.71 - ETA: 5:57 - loss: 0.8847 - accuracy: 0.71 - ETA: 5:55 - loss: 0.8781 - accuracy: 0.71 - ETA: 5:52 - loss: 0.8879 - accuracy: 0.71 - ETA: 5:49 - loss: 0.8899 - accuracy: 0.71 - ETA: 5:46 - loss: 0.8991 - accuracy: 0.71 - ETA: 5:42 - loss: 0.8996 - accuracy: 0.71 - ETA: 5:40 - loss: 0.9021 - accuracy: 0.71 - ETA: 5:38 - loss: 0.9020 - accuracy: 0.71 - ETA: 5:31 - loss: 0.9034 - accuracy: 0.71 - ETA: 5:26 - loss: 0.9043 - accuracy: 0.71 - ETA: 5:23 - loss: 0.9027 - accuracy: 0.71 - ETA: 5:21 - loss: 0.9051 - accuracy: 0.71 - ETA: 5:18 - loss: 0.9052 - accuracy: 0.71 - ETA: 5:15 - loss: 0.9042 - accuracy: 0.71 - ETA: 5:10 - loss: 0.9080 - accuracy: 0.71 - ETA: 5:06 - loss: 0.9098 - accuracy: 0.70 - ETA: 5:03 - loss: 0.9124 - accuracy: 0.70 - ETA: 5:01 - loss: 0.9146 - accuracy: 0.70 - ETA: 4:58 - loss: 0.9212 - accuracy: 0.70 - ETA: 4:56 - loss: 0.9219 - accuracy: 0.70 - ETA: 4:51 - loss: 0.9211 - accuracy: 0.70 - ETA: 4:46 - loss: 0.9220 - accuracy: 0.70 - ETA: 4:43 - loss: 0.9222 - accuracy: 0.70 - ETA: 4:41 - loss: 0.9230 - accuracy: 0.70 - ETA: 4:38 - loss: 0.9243 - accuracy: 0.70 - ETA: 4:35 - loss: 0.9223 - accuracy: 0.70 - ETA: 4:33 - loss: 0.9229 - accuracy: 0.70 - ETA: 4:31 - loss: 0.9274 - accuracy: 0.70 - ETA: 4:29 - loss: 0.9300 - accuracy: 0.70 - ETA: 4:26 - loss: 0.9287 - accuracy: 0.70 - ETA: 4:22 - loss: 0.9299 - accuracy: 0.70 - ETA: 4:20 - loss: 0.9248 - accuracy: 0.70 - ETA: 4:17 - loss: 0.9288 - accuracy: 0.70 - ETA: 4:16 - loss: 0.9284 - accuracy: 0.70 - ETA: 4:13 - loss: 0.9267 - accuracy: 0.70 - ETA: 4:10 - loss: 0.9279 - accuracy: 0.70 - ETA: 4:07 - loss: 0.9266 - accuracy: 0.70 - ETA: 4:05 - loss: 0.9268 - accuracy: 0.70 - ETA: 4:01 - loss: 0.9282 - accuracy: 0.70 - ETA: 3:57 - loss: 0.9300 - accuracy: 0.70 - ETA: 3:55 - loss: 0.9307 - accuracy: 0.70 - ETA: 3:52 - loss: 0.9283 - accuracy: 0.70 - ETA: 3:50 - loss: 0.9276 - accuracy: 0.70 - ETA: 3:48 - loss: 0.9312 - accuracy: 0.70 - ETA: 3:45 - loss: 0.9342 - accuracy: 0.70 - ETA: 3:43 - loss: 0.9357 - accuracy: 0.70 - ETA: 3:40 - loss: 0.9345 - accuracy: 0.70 - ETA: 3:38 - loss: 0.9342 - accuracy: 0.70 - ETA: 3:35 - loss: 0.9340 - accuracy: 0.70 - ETA: 3:33 - loss: 0.9336 - accuracy: 0.70 - ETA: 3:31 - loss: 0.9325 - accuracy: 0.70 - ETA: 3:28 - loss: 0.9378 - accuracy: 0.70 - ETA: 3:25 - loss: 0.9375 - accuracy: 0.70 - ETA: 3:22 - loss: 0.9352 - accuracy: 0.70 - ETA: 3:20 - loss: 0.9371 - accuracy: 0.70 - ETA: 3:17 - loss: 0.9350 - accuracy: 0.70 - ETA: 3:15 - loss: 0.9332 - accuracy: 0.70 - ETA: 3:13 - loss: 0.9342 - accuracy: 0.70 - ETA: 3:10 - loss: 0.9343 - accuracy: 0.70 - ETA: 3:08 - loss: 0.9367 - accuracy: 0.70 - ETA: 3:05 - loss: 0.9367 - accuracy: 0.70 - ETA: 3:03 - loss: 0.9371 - accuracy: 0.70 - ETA: 3:00 - loss: 0.9368 - accuracy: 0.70 - ETA: 2:58 - loss: 0.9374 - accuracy: 0.70 - ETA: 2:55 - loss: 0.9386 - accuracy: 0.70 - ETA: 2:52 - loss: 0.9375 - accuracy: 0.70 - ETA: 2:50 - loss: 0.9372 - accuracy: 0.70 - ETA: 2:47 - loss: 0.9386 - accuracy: 0.70 - ETA: 2:44 - loss: 0.9387 - accuracy: 0.70 - ETA: 2:41 - loss: 0.9372 - accuracy: 0.70 - ETA: 2:39 - loss: 0.9367 - accuracy: 0.70 - ETA: 2:36 - loss: 0.9353 - accuracy: 0.70 - ETA: 2:33 - loss: 0.9358 - accuracy: 0.70 - ETA: 2:31 - loss: 0.9367 - accuracy: 0.70 - ETA: 2:28 - loss: 0.9358 - accuracy: 0.70 - ETA: 2:25 - loss: 0.9386 - accuracy: 0.70 - ETA: 2:23 - loss: 0.9406 - accuracy: 0.70 - ETA: 2:20 - loss: 0.9403 - accuracy: 0.70 - ETA: 2:17 - loss: 0.9403 - accuracy: 0.70 - ETA: 2:13 - loss: 0.9381 - accuracy: 0.70 - ETA: 2:10 - loss: 0.9382 - accuracy: 0.70 - ETA: 2:08 - loss: 0.9385 - accuracy: 0.70 - ETA: 2:05 - loss: 0.9378 - accuracy: 0.70 - ETA: 2:02 - loss: 0.9377 - accuracy: 0.70 - ETA: 2:00 - loss: 0.9382 - accuracy: 0.70 - ETA: 1:57 - loss: 0.9405 - accuracy: 0.70 - ETA: 1:54 - loss: 0.9420 - accuracy: 0.70 - ETA: 1:51 - loss: 0.9423 - accuracy: 0.70 - ETA: 1:48 - loss: 0.9432 - accuracy: 0.70 - ETA: 1:46 - loss: 0.9427 - accuracy: 0.70 - ETA: 1:43 - loss: 0.9417 - accuracy: 0.70 - ETA: 1:40 - loss: 0.9419 - accuracy: 0.70 - ETA: 1:38 - loss: 0.9422 - accuracy: 0.70 - ETA: 1:35 - loss: 0.9420 - accuracy: 0.70 - ETA: 1:32 - loss: 0.9412 - accuracy: 0.70 - ETA: 1:29 - loss: 0.9423 - accuracy: 0.70 - ETA: 1:27 - loss: 0.9405 - accuracy: 0.70 - ETA: 1:24 - loss: 0.9398 - accuracy: 0.70 - ETA: 1:21 - loss: 0.9389 - accuracy: 0.70 - ETA: 1:18 - loss: 0.9387 - accuracy: 0.70 - ETA: 1:16 - loss: 0.9398 - accuracy: 0.70 - ETA: 1:13 - loss: 0.9394 - accuracy: 0.70 - ETA: 1:11 - loss: 0.9390 - accuracy: 0.70 - ETA: 1:08 - loss: 0.9410 - accuracy: 0.70 - ETA: 1:05 - loss: 0.9424 - accuracy: 0.70 - ETA: 1:03 - loss: 0.9420 - accuracy: 0.70 - ETA: 1:00 - loss: 0.9424 - accuracy: 0.70 - ETA: 58s - loss: 0.9446 - accuracy: 0.7023 - ETA: 55s - loss: 0.9434 - accuracy: 0.702 - ETA: 52s - loss: 0.9458 - accuracy: 0.702 - ETA: 50s - loss: 0.9470 - accuracy: 0.702 - ETA: 47s - loss: 0.9474 - accuracy: 0.702 - ETA: 44s - loss: 0.9470 - accuracy: 0.702 - ETA: 42s - loss: 0.9458 - accuracy: 0.702 - ETA: 39s - loss: 0.9458 - accuracy: 0.702 - ETA: 36s - loss: 0.9457 - accuracy: 0.702 - ETA: 34s - loss: 0.9447 - accuracy: 0.702 - ETA: 31s - loss: 0.9452 - accuracy: 0.702 - ETA: 28s - loss: 0.9454 - accuracy: 0.702 - ETA: 26s - loss: 0.9452 - accuracy: 0.702 - ETA: 23s - loss: 0.9454 - accuracy: 0.701 - ETA: 20s - loss: 0.9466 - accuracy: 0.701 - ETA: 18s - loss: 0.9464 - accuracy: 0.701 - ETA: 15s - loss: 0.9458 - accuracy: 0.701 - ETA: 12s - loss: 0.9462 - accuracy: 0.701 - ETA: 10s - loss: 0.9459 - accuracy: 0.701 - ETA: 7s - loss: 0.9457 - accuracy: 0.701 - ETA: 4s - loss: 0.9472 - accuracy: 0.70 - ETA: 2s - loss: 0.9473 - accuracy: 0.70 - 443s 23ms/step - loss: 0.9462 - accuracy: 0.7015 - val_loss: 1.3648 - val_accuracy: 0.6979\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 6:39 - loss: 0.6514 - accuracy: 0.79 - ETA: 6:56 - loss: 0.6759 - accuracy: 0.80 - ETA: 6:55 - loss: 0.7353 - accuracy: 0.77 - ETA: 6:55 - loss: 0.8398 - accuracy: 0.74 - ETA: 6:56 - loss: 0.8653 - accuracy: 0.73 - ETA: 6:54 - loss: 0.8764 - accuracy: 0.72 - ETA: 6:47 - loss: 0.8814 - accuracy: 0.72 - ETA: 6:36 - loss: 0.8793 - accuracy: 0.72 - ETA: 6:20 - loss: 0.9067 - accuracy: 0.72 - ETA: 6:05 - loss: 0.8908 - accuracy: 0.72 - ETA: 5:53 - loss: 0.8968 - accuracy: 0.71 - ETA: 5:42 - loss: 0.9160 - accuracy: 0.71 - ETA: 5:42 - loss: 0.9134 - accuracy: 0.71 - ETA: 5:41 - loss: 0.9162 - accuracy: 0.71 - ETA: 5:41 - loss: 0.9124 - accuracy: 0.71 - ETA: 5:39 - loss: 0.9101 - accuracy: 0.71 - ETA: 5:31 - loss: 0.9146 - accuracy: 0.71 - ETA: 5:30 - loss: 0.9081 - accuracy: 0.71 - ETA: 5:29 - loss: 0.9038 - accuracy: 0.71 - ETA: 5:30 - loss: 0.8990 - accuracy: 0.71 - ETA: 5:28 - loss: 0.9157 - accuracy: 0.71 - ETA: 5:27 - loss: 0.9166 - accuracy: 0.71 - ETA: 5:27 - loss: 0.9223 - accuracy: 0.71 - ETA: 5:21 - loss: 0.9224 - accuracy: 0.71 - ETA: 5:21 - loss: 0.9161 - accuracy: 0.71 - ETA: 5:18 - loss: 0.9209 - accuracy: 0.70 - ETA: 5:16 - loss: 0.9178 - accuracy: 0.70 - ETA: 5:13 - loss: 0.9140 - accuracy: 0.71 - ETA: 5:13 - loss: 0.9064 - accuracy: 0.71 - ETA: 5:11 - loss: 0.9113 - accuracy: 0.71 - ETA: 5:07 - loss: 0.9105 - accuracy: 0.71 - ETA: 5:05 - loss: 0.9035 - accuracy: 0.71 - ETA: 5:04 - loss: 0.9055 - accuracy: 0.71 - ETA: 5:03 - loss: 0.9058 - accuracy: 0.71 - ETA: 5:00 - loss: 0.9089 - accuracy: 0.71 - ETA: 4:55 - loss: 0.9113 - accuracy: 0.71 - ETA: 4:51 - loss: 0.9152 - accuracy: 0.71 - ETA: 4:46 - loss: 0.9144 - accuracy: 0.71 - ETA: 4:43 - loss: 0.9174 - accuracy: 0.71 - ETA: 4:41 - loss: 0.9161 - accuracy: 0.71 - ETA: 4:39 - loss: 0.9144 - accuracy: 0.71 - ETA: 4:37 - loss: 0.9138 - accuracy: 0.71 - ETA: 4:35 - loss: 0.9181 - accuracy: 0.71 - ETA: 4:34 - loss: 0.9201 - accuracy: 0.71 - ETA: 4:32 - loss: 0.9213 - accuracy: 0.70 - ETA: 4:29 - loss: 0.9209 - accuracy: 0.70 - ETA: 4:27 - loss: 0.9229 - accuracy: 0.70 - ETA: 4:25 - loss: 0.9225 - accuracy: 0.70 - ETA: 4:23 - loss: 0.9178 - accuracy: 0.70 - ETA: 4:20 - loss: 0.9137 - accuracy: 0.71 - ETA: 4:18 - loss: 0.9152 - accuracy: 0.70 - ETA: 4:16 - loss: 0.9128 - accuracy: 0.71 - ETA: 4:13 - loss: 0.9127 - accuracy: 0.71 - ETA: 4:12 - loss: 0.9145 - accuracy: 0.70 - ETA: 4:10 - loss: 0.9149 - accuracy: 0.71 - ETA: 4:08 - loss: 0.9169 - accuracy: 0.71 - ETA: 4:05 - loss: 0.9187 - accuracy: 0.70 - ETA: 4:02 - loss: 0.9186 - accuracy: 0.70 - ETA: 4:00 - loss: 0.9201 - accuracy: 0.70 - ETA: 3:56 - loss: 0.9176 - accuracy: 0.70 - ETA: 3:53 - loss: 0.9170 - accuracy: 0.70 - ETA: 3:50 - loss: 0.9167 - accuracy: 0.70 - ETA: 3:48 - loss: 0.9149 - accuracy: 0.70 - ETA: 3:45 - loss: 0.9123 - accuracy: 0.71 - ETA: 3:43 - loss: 0.9135 - accuracy: 0.71 - ETA: 3:42 - loss: 0.9123 - accuracy: 0.71 - ETA: 3:39 - loss: 0.9117 - accuracy: 0.71 - ETA: 3:36 - loss: 0.9103 - accuracy: 0.71 - ETA: 3:33 - loss: 0.9080 - accuracy: 0.71 - ETA: 3:30 - loss: 0.9081 - accuracy: 0.71 - ETA: 3:28 - loss: 0.9074 - accuracy: 0.71 - ETA: 3:26 - loss: 0.9093 - accuracy: 0.71 - ETA: 3:23 - loss: 0.9111 - accuracy: 0.71 - ETA: 3:21 - loss: 0.9111 - accuracy: 0.71 - ETA: 3:19 - loss: 0.9105 - accuracy: 0.71 - ETA: 3:16 - loss: 0.9106 - accuracy: 0.71 - ETA: 3:14 - loss: 0.9122 - accuracy: 0.71 - ETA: 3:11 - loss: 0.9124 - accuracy: 0.70 - ETA: 3:09 - loss: 0.9104 - accuracy: 0.71 - ETA: 3:07 - loss: 0.9109 - accuracy: 0.71 - ETA: 3:04 - loss: 0.9117 - accuracy: 0.71 - ETA: 3:01 - loss: 0.9102 - accuracy: 0.71 - ETA: 2:58 - loss: 0.9110 - accuracy: 0.70 - ETA: 2:55 - loss: 0.9136 - accuracy: 0.70 - ETA: 2:52 - loss: 0.9129 - accuracy: 0.70 - ETA: 2:49 - loss: 0.9126 - accuracy: 0.70 - ETA: 2:47 - loss: 0.9119 - accuracy: 0.70 - ETA: 2:45 - loss: 0.9136 - accuracy: 0.70 - ETA: 2:42 - loss: 0.9124 - accuracy: 0.70 - ETA: 2:40 - loss: 0.9129 - accuracy: 0.70 - ETA: 2:37 - loss: 0.9122 - accuracy: 0.70 - ETA: 2:35 - loss: 0.9135 - accuracy: 0.70 - ETA: 2:32 - loss: 0.9140 - accuracy: 0.70 - ETA: 2:30 - loss: 0.9149 - accuracy: 0.70 - ETA: 2:27 - loss: 0.9145 - accuracy: 0.70 - ETA: 2:25 - loss: 0.9141 - accuracy: 0.70 - ETA: 2:22 - loss: 0.9148 - accuracy: 0.70 - ETA: 2:20 - loss: 0.9137 - accuracy: 0.70 - ETA: 2:17 - loss: 0.9124 - accuracy: 0.70 - ETA: 2:15 - loss: 0.9126 - accuracy: 0.70 - ETA: 2:12 - loss: 0.9138 - accuracy: 0.70 - ETA: 2:09 - loss: 0.9137 - accuracy: 0.70 - ETA: 2:07 - loss: 0.9145 - accuracy: 0.70 - ETA: 2:04 - loss: 0.9149 - accuracy: 0.70 - ETA: 2:01 - loss: 0.9120 - accuracy: 0.70 - ETA: 1:58 - loss: 0.9143 - accuracy: 0.70 - ETA: 1:55 - loss: 0.9150 - accuracy: 0.70 - ETA: 1:52 - loss: 0.9136 - accuracy: 0.70 - ETA: 1:50 - loss: 0.9136 - accuracy: 0.70 - ETA: 1:47 - loss: 0.9139 - accuracy: 0.70 - ETA: 1:44 - loss: 0.9151 - accuracy: 0.70 - ETA: 1:41 - loss: 0.9145 - accuracy: 0.70 - ETA: 1:39 - loss: 0.9144 - accuracy: 0.70 - ETA: 1:36 - loss: 0.9130 - accuracy: 0.70 - ETA: 1:34 - loss: 0.9122 - accuracy: 0.70 - ETA: 1:31 - loss: 0.9120 - accuracy: 0.70 - ETA: 1:28 - loss: 0.9111 - accuracy: 0.70 - ETA: 1:26 - loss: 0.9099 - accuracy: 0.70 - ETA: 1:23 - loss: 0.9113 - accuracy: 0.70 - ETA: 1:20 - loss: 0.9111 - accuracy: 0.70 - ETA: 1:17 - loss: 0.9117 - accuracy: 0.70 - ETA: 1:15 - loss: 0.9115 - accuracy: 0.70 - ETA: 1:12 - loss: 0.9110 - accuracy: 0.70 - ETA: 1:10 - loss: 0.9105 - accuracy: 0.70 - ETA: 1:07 - loss: 0.9094 - accuracy: 0.70 - ETA: 1:05 - loss: 0.9100 - accuracy: 0.70 - ETA: 1:02 - loss: 0.9103 - accuracy: 0.70 - ETA: 59s - loss: 0.9089 - accuracy: 0.7099 - ETA: 57s - loss: 0.9113 - accuracy: 0.709 - ETA: 54s - loss: 0.9100 - accuracy: 0.710 - ETA: 51s - loss: 0.9107 - accuracy: 0.709 - ETA: 49s - loss: 0.9101 - accuracy: 0.709 - ETA: 46s - loss: 0.9099 - accuracy: 0.709 - ETA: 44s - loss: 0.9085 - accuracy: 0.710 - ETA: 41s - loss: 0.9073 - accuracy: 0.710 - ETA: 38s - loss: 0.9074 - accuracy: 0.710 - ETA: 36s - loss: 0.9076 - accuracy: 0.710 - ETA: 33s - loss: 0.9079 - accuracy: 0.710 - ETA: 31s - loss: 0.9076 - accuracy: 0.710 - ETA: 28s - loss: 0.9086 - accuracy: 0.710 - ETA: 25s - loss: 0.9078 - accuracy: 0.710 - ETA: 23s - loss: 0.9067 - accuracy: 0.710 - ETA: 20s - loss: 0.9059 - accuracy: 0.711 - ETA: 18s - loss: 0.9052 - accuracy: 0.711 - ETA: 15s - loss: 0.9047 - accuracy: 0.711 - ETA: 12s - loss: 0.9039 - accuracy: 0.711 - ETA: 10s - loss: 0.9021 - accuracy: 0.712 - ETA: 7s - loss: 0.9018 - accuracy: 0.712 - ETA: 4s - loss: 0.9014 - accuracy: 0.71 - ETA: 2s - loss: 0.9006 - accuracy: 0.71 - 441s 23ms/step - loss: 0.9002 - accuracy: 0.7132 - val_loss: 1.3728 - val_accuracy: 0.6981\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:43 - loss: 0.8636 - accuracy: 0.67 - ETA: 5:11 - loss: 0.8385 - accuracy: 0.72 - ETA: 5:48 - loss: 0.8753 - accuracy: 0.71 - ETA: 6:09 - loss: 0.8512 - accuracy: 0.72 - ETA: 6:10 - loss: 0.8699 - accuracy: 0.71 - ETA: 6:00 - loss: 0.8774 - accuracy: 0.71 - ETA: 5:47 - loss: 0.8741 - accuracy: 0.72 - ETA: 5:52 - loss: 0.8646 - accuracy: 0.72 - ETA: 5:57 - loss: 0.8597 - accuracy: 0.73 - ETA: 5:56 - loss: 0.8870 - accuracy: 0.71 - ETA: 5:52 - loss: 0.9078 - accuracy: 0.71 - ETA: 5:54 - loss: 0.9203 - accuracy: 0.70 - ETA: 5:56 - loss: 0.9067 - accuracy: 0.70 - ETA: 5:57 - loss: 0.8996 - accuracy: 0.71 - ETA: 5:57 - loss: 0.9052 - accuracy: 0.71 - ETA: 5:53 - loss: 0.8957 - accuracy: 0.71 - ETA: 5:51 - loss: 0.9009 - accuracy: 0.71 - ETA: 5:50 - loss: 0.8944 - accuracy: 0.71 - ETA: 5:44 - loss: 0.8840 - accuracy: 0.71 - ETA: 5:36 - loss: 0.8918 - accuracy: 0.71 - ETA: 5:28 - loss: 0.8942 - accuracy: 0.71 - ETA: 5:27 - loss: 0.8913 - accuracy: 0.71 - ETA: 5:25 - loss: 0.8915 - accuracy: 0.71 - ETA: 5:25 - loss: 0.8901 - accuracy: 0.71 - ETA: 5:24 - loss: 0.8884 - accuracy: 0.71 - ETA: 5:23 - loss: 0.8866 - accuracy: 0.71 - ETA: 5:22 - loss: 0.8831 - accuracy: 0.71 - ETA: 5:20 - loss: 0.8816 - accuracy: 0.71 - ETA: 5:18 - loss: 0.8789 - accuracy: 0.72 - ETA: 5:15 - loss: 0.8797 - accuracy: 0.72 - ETA: 5:14 - loss: 0.8783 - accuracy: 0.72 - ETA: 5:12 - loss: 0.8773 - accuracy: 0.72 - ETA: 5:10 - loss: 0.8762 - accuracy: 0.72 - ETA: 5:07 - loss: 0.8695 - accuracy: 0.72 - ETA: 5:05 - loss: 0.8677 - accuracy: 0.72 - ETA: 5:03 - loss: 0.8638 - accuracy: 0.72 - ETA: 5:02 - loss: 0.8612 - accuracy: 0.72 - ETA: 5:00 - loss: 0.8631 - accuracy: 0.72 - ETA: 4:58 - loss: 0.8591 - accuracy: 0.72 - ETA: 4:55 - loss: 0.8613 - accuracy: 0.72 - ETA: 4:52 - loss: 0.8626 - accuracy: 0.72 - ETA: 4:50 - loss: 0.8611 - accuracy: 0.72 - ETA: 4:48 - loss: 0.8585 - accuracy: 0.72 - ETA: 4:46 - loss: 0.8596 - accuracy: 0.72 - ETA: 4:43 - loss: 0.8589 - accuracy: 0.72 - ETA: 4:41 - loss: 0.8589 - accuracy: 0.72 - ETA: 4:38 - loss: 0.8604 - accuracy: 0.72 - ETA: 4:36 - loss: 0.8605 - accuracy: 0.72 - ETA: 4:34 - loss: 0.8603 - accuracy: 0.72 - ETA: 4:29 - loss: 0.8608 - accuracy: 0.72 - ETA: 4:26 - loss: 0.8581 - accuracy: 0.72 - ETA: 4:23 - loss: 0.8559 - accuracy: 0.72 - ETA: 4:20 - loss: 0.8552 - accuracy: 0.72 - ETA: 4:18 - loss: 0.8598 - accuracy: 0.72 - ETA: 4:15 - loss: 0.8587 - accuracy: 0.72 - ETA: 4:13 - loss: 0.8603 - accuracy: 0.72 - ETA: 4:11 - loss: 0.8597 - accuracy: 0.72 - ETA: 4:09 - loss: 0.8591 - accuracy: 0.72 - ETA: 4:06 - loss: 0.8555 - accuracy: 0.72 - ETA: 4:04 - loss: 0.8565 - accuracy: 0.72 - ETA: 4:02 - loss: 0.8565 - accuracy: 0.72 - ETA: 4:00 - loss: 0.8577 - accuracy: 0.72 - ETA: 3:57 - loss: 0.8560 - accuracy: 0.72 - ETA: 3:54 - loss: 0.8520 - accuracy: 0.72 - ETA: 3:52 - loss: 0.8532 - accuracy: 0.72 - ETA: 3:49 - loss: 0.8528 - accuracy: 0.72 - ETA: 3:47 - loss: 0.8509 - accuracy: 0.72 - ETA: 3:44 - loss: 0.8480 - accuracy: 0.73 - ETA: 3:41 - loss: 0.8496 - accuracy: 0.73 - ETA: 3:39 - loss: 0.8497 - accuracy: 0.73 - ETA: 3:36 - loss: 0.8483 - accuracy: 0.73 - ETA: 3:32 - loss: 0.8461 - accuracy: 0.73 - ETA: 3:28 - loss: 0.8453 - accuracy: 0.73 - ETA: 3:25 - loss: 0.8448 - accuracy: 0.73 - ETA: 3:22 - loss: 0.8457 - accuracy: 0.73 - ETA: 3:19 - loss: 0.8460 - accuracy: 0.73 - ETA: 3:19 - loss: 0.8477 - accuracy: 0.72 - ETA: 3:16 - loss: 0.8489 - accuracy: 0.72 - ETA: 3:13 - loss: 0.8485 - accuracy: 0.72 - ETA: 3:09 - loss: 0.8500 - accuracy: 0.72 - ETA: 3:06 - loss: 0.8498 - accuracy: 0.72 - ETA: 3:02 - loss: 0.8497 - accuracy: 0.72 - ETA: 2:59 - loss: 0.8498 - accuracy: 0.72 - ETA: 2:56 - loss: 0.8477 - accuracy: 0.72 - ETA: 2:52 - loss: 0.8462 - accuracy: 0.73 - ETA: 2:49 - loss: 0.8442 - accuracy: 0.73 - ETA: 2:46 - loss: 0.8454 - accuracy: 0.73 - ETA: 2:42 - loss: 0.8481 - accuracy: 0.73 - ETA: 2:39 - loss: 0.8513 - accuracy: 0.72 - ETA: 2:36 - loss: 0.8522 - accuracy: 0.72 - ETA: 2:33 - loss: 0.8499 - accuracy: 0.72 - ETA: 2:30 - loss: 0.8505 - accuracy: 0.72 - ETA: 2:27 - loss: 0.8498 - accuracy: 0.72 - ETA: 2:24 - loss: 0.8503 - accuracy: 0.72 - ETA: 2:21 - loss: 0.8498 - accuracy: 0.72 - ETA: 2:18 - loss: 0.8496 - accuracy: 0.72 - ETA: 2:15 - loss: 0.8511 - accuracy: 0.72 - ETA: 2:12 - loss: 0.8505 - accuracy: 0.72 - ETA: 2:09 - loss: 0.8503 - accuracy: 0.72 - ETA: 2:06 - loss: 0.8526 - accuracy: 0.72 - ETA: 2:04 - loss: 0.8518 - accuracy: 0.72 - ETA: 2:01 - loss: 0.8528 - accuracy: 0.72 - ETA: 1:58 - loss: 0.8517 - accuracy: 0.72 - ETA: 1:55 - loss: 0.8512 - accuracy: 0.72 - ETA: 1:52 - loss: 0.8492 - accuracy: 0.72 - ETA: 1:50 - loss: 0.8497 - accuracy: 0.72 - ETA: 1:47 - loss: 0.8507 - accuracy: 0.72 - ETA: 1:44 - loss: 0.8499 - accuracy: 0.72 - ETA: 1:41 - loss: 0.8515 - accuracy: 0.72 - ETA: 1:39 - loss: 0.8507 - accuracy: 0.72 - ETA: 1:36 - loss: 0.8526 - accuracy: 0.72 - ETA: 1:33 - loss: 0.8528 - accuracy: 0.72 - ETA: 1:31 - loss: 0.8517 - accuracy: 0.72 - ETA: 1:28 - loss: 0.8515 - accuracy: 0.72 - ETA: 1:26 - loss: 0.8511 - accuracy: 0.72 - ETA: 1:23 - loss: 0.8502 - accuracy: 0.72 - ETA: 1:21 - loss: 0.8506 - accuracy: 0.72 - ETA: 1:18 - loss: 0.8499 - accuracy: 0.72 - ETA: 1:15 - loss: 0.8496 - accuracy: 0.72 - ETA: 1:13 - loss: 0.8513 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8529 - accuracy: 0.72 - ETA: 1:08 - loss: 0.8505 - accuracy: 0.72 - ETA: 1:05 - loss: 0.8508 - accuracy: 0.72 - ETA: 1:03 - loss: 0.8485 - accuracy: 0.72 - ETA: 1:00 - loss: 0.8472 - accuracy: 0.72 - ETA: 58s - loss: 0.8476 - accuracy: 0.7278 - ETA: 56s - loss: 0.8478 - accuracy: 0.727 - ETA: 53s - loss: 0.8486 - accuracy: 0.727 - ETA: 51s - loss: 0.8498 - accuracy: 0.727 - ETA: 48s - loss: 0.8512 - accuracy: 0.727 - ETA: 46s - loss: 0.8522 - accuracy: 0.727 - ETA: 43s - loss: 0.8515 - accuracy: 0.727 - ETA: 41s - loss: 0.8509 - accuracy: 0.727 - ETA: 39s - loss: 0.8523 - accuracy: 0.727 - ETA: 36s - loss: 0.8506 - accuracy: 0.727 - ETA: 34s - loss: 0.8495 - accuracy: 0.728 - ETA: 31s - loss: 0.8493 - accuracy: 0.727 - ETA: 29s - loss: 0.8489 - accuracy: 0.728 - ETA: 27s - loss: 0.8486 - accuracy: 0.728 - ETA: 25s - loss: 0.8487 - accuracy: 0.728 - ETA: 22s - loss: 0.8482 - accuracy: 0.728 - ETA: 20s - loss: 0.8485 - accuracy: 0.728 - ETA: 18s - loss: 0.8484 - accuracy: 0.728 - ETA: 15s - loss: 0.8478 - accuracy: 0.728 - ETA: 13s - loss: 0.8463 - accuracy: 0.728 - ETA: 11s - loss: 0.8469 - accuracy: 0.728 - ETA: 8s - loss: 0.8474 - accuracy: 0.728 - ETA: 6s - loss: 0.8463 - accuracy: 0.72 - ETA: 4s - loss: 0.8463 - accuracy: 0.72 - ETA: 1s - loss: 0.8470 - accuracy: 0.72 - 364s 19ms/step - loss: 0.8474 - accuracy: 0.7281 - val_loss: 1.3746 - val_accuracy: 0.7039\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:07 - loss: 0.8757 - accuracy: 0.70 - ETA: 4:11 - loss: 0.8130 - accuracy: 0.73 - ETA: 4:16 - loss: 0.7914 - accuracy: 0.73 - ETA: 4:12 - loss: 0.7786 - accuracy: 0.75 - ETA: 4:10 - loss: 0.7651 - accuracy: 0.74 - ETA: 4:07 - loss: 0.7783 - accuracy: 0.74 - ETA: 4:00 - loss: 0.8058 - accuracy: 0.73 - ETA: 3:58 - loss: 0.8067 - accuracy: 0.73 - ETA: 3:55 - loss: 0.8042 - accuracy: 0.74 - ETA: 3:53 - loss: 0.8136 - accuracy: 0.73 - ETA: 3:49 - loss: 0.8264 - accuracy: 0.73 - ETA: 3:50 - loss: 0.8331 - accuracy: 0.73 - ETA: 3:49 - loss: 0.8288 - accuracy: 0.73 - ETA: 3:48 - loss: 0.8319 - accuracy: 0.73 - ETA: 3:46 - loss: 0.8308 - accuracy: 0.73 - ETA: 3:45 - loss: 0.8419 - accuracy: 0.73 - ETA: 3:42 - loss: 0.8368 - accuracy: 0.73 - ETA: 3:41 - loss: 0.8291 - accuracy: 0.74 - ETA: 3:40 - loss: 0.8215 - accuracy: 0.74 - ETA: 3:39 - loss: 0.8278 - accuracy: 0.74 - ETA: 3:35 - loss: 0.8341 - accuracy: 0.73 - ETA: 3:34 - loss: 0.8287 - accuracy: 0.73 - ETA: 3:30 - loss: 0.8270 - accuracy: 0.73 - ETA: 3:29 - loss: 0.8253 - accuracy: 0.73 - ETA: 3:28 - loss: 0.8183 - accuracy: 0.74 - ETA: 3:26 - loss: 0.8251 - accuracy: 0.73 - ETA: 3:24 - loss: 0.8245 - accuracy: 0.73 - ETA: 3:23 - loss: 0.8248 - accuracy: 0.73 - ETA: 3:21 - loss: 0.8280 - accuracy: 0.73 - ETA: 3:20 - loss: 0.8231 - accuracy: 0.73 - ETA: 3:19 - loss: 0.8284 - accuracy: 0.73 - ETA: 3:18 - loss: 0.8348 - accuracy: 0.73 - ETA: 3:17 - loss: 0.8449 - accuracy: 0.73 - ETA: 3:15 - loss: 0.8399 - accuracy: 0.73 - ETA: 3:13 - loss: 0.8438 - accuracy: 0.73 - ETA: 3:12 - loss: 0.8432 - accuracy: 0.73 - ETA: 3:10 - loss: 0.8457 - accuracy: 0.73 - ETA: 3:09 - loss: 0.8483 - accuracy: 0.73 - ETA: 3:07 - loss: 0.8530 - accuracy: 0.72 - ETA: 3:06 - loss: 0.8545 - accuracy: 0.72 - ETA: 3:05 - loss: 0.8554 - accuracy: 0.72 - ETA: 3:03 - loss: 0.8551 - accuracy: 0.72 - ETA: 3:02 - loss: 0.8556 - accuracy: 0.72 - ETA: 3:00 - loss: 0.8607 - accuracy: 0.72 - ETA: 2:58 - loss: 0.8671 - accuracy: 0.72 - ETA: 2:57 - loss: 0.8635 - accuracy: 0.72 - ETA: 2:55 - loss: 0.8641 - accuracy: 0.72 - ETA: 2:53 - loss: 0.8604 - accuracy: 0.72 - ETA: 2:52 - loss: 0.8587 - accuracy: 0.72 - ETA: 2:50 - loss: 0.8588 - accuracy: 0.72 - ETA: 2:49 - loss: 0.8610 - accuracy: 0.72 - ETA: 2:47 - loss: 0.8602 - accuracy: 0.72 - ETA: 2:46 - loss: 0.8546 - accuracy: 0.73 - ETA: 2:44 - loss: 0.8559 - accuracy: 0.72 - ETA: 2:42 - loss: 0.8563 - accuracy: 0.72 - ETA: 2:41 - loss: 0.8533 - accuracy: 0.72 - ETA: 2:39 - loss: 0.8523 - accuracy: 0.73 - ETA: 2:37 - loss: 0.8522 - accuracy: 0.73 - ETA: 2:36 - loss: 0.8468 - accuracy: 0.73 - ETA: 2:34 - loss: 0.8436 - accuracy: 0.73 - ETA: 2:32 - loss: 0.8460 - accuracy: 0.73 - ETA: 2:31 - loss: 0.8466 - accuracy: 0.73 - ETA: 2:29 - loss: 0.8473 - accuracy: 0.73 - ETA: 2:27 - loss: 0.8482 - accuracy: 0.73 - ETA: 2:26 - loss: 0.8465 - accuracy: 0.73 - ETA: 2:24 - loss: 0.8485 - accuracy: 0.73 - ETA: 2:22 - loss: 0.8456 - accuracy: 0.73 - ETA: 2:21 - loss: 0.8447 - accuracy: 0.73 - ETA: 2:19 - loss: 0.8428 - accuracy: 0.73 - ETA: 2:17 - loss: 0.8416 - accuracy: 0.73 - ETA: 2:16 - loss: 0.8422 - accuracy: 0.73 - ETA: 2:14 - loss: 0.8448 - accuracy: 0.73 - ETA: 2:12 - loss: 0.8431 - accuracy: 0.73 - ETA: 2:11 - loss: 0.8444 - accuracy: 0.73 - ETA: 2:09 - loss: 0.8461 - accuracy: 0.72 - ETA: 2:07 - loss: 0.8428 - accuracy: 0.73 - ETA: 2:06 - loss: 0.8438 - accuracy: 0.73 - ETA: 2:04 - loss: 0.8429 - accuracy: 0.73 - ETA: 2:02 - loss: 0.8423 - accuracy: 0.73 - ETA: 2:01 - loss: 0.8415 - accuracy: 0.73 - ETA: 1:59 - loss: 0.8408 - accuracy: 0.73 - ETA: 1:57 - loss: 0.8403 - accuracy: 0.73 - ETA: 1:55 - loss: 0.8380 - accuracy: 0.73 - ETA: 1:54 - loss: 0.8379 - accuracy: 0.73 - ETA: 1:52 - loss: 0.8395 - accuracy: 0.73 - ETA: 1:50 - loss: 0.8380 - accuracy: 0.73 - ETA: 1:49 - loss: 0.8388 - accuracy: 0.73 - ETA: 1:47 - loss: 0.8414 - accuracy: 0.73 - ETA: 1:45 - loss: 0.8429 - accuracy: 0.72 - ETA: 1:44 - loss: 0.8401 - accuracy: 0.73 - ETA: 1:42 - loss: 0.8390 - accuracy: 0.73 - ETA: 1:40 - loss: 0.8378 - accuracy: 0.73 - ETA: 1:38 - loss: 0.8376 - accuracy: 0.73 - ETA: 1:37 - loss: 0.8399 - accuracy: 0.73 - ETA: 1:35 - loss: 0.8384 - accuracy: 0.73 - ETA: 1:33 - loss: 0.8357 - accuracy: 0.73 - ETA: 1:32 - loss: 0.8344 - accuracy: 0.73 - ETA: 1:30 - loss: 0.8336 - accuracy: 0.73 - ETA: 1:28 - loss: 0.8346 - accuracy: 0.73 - ETA: 1:27 - loss: 0.8335 - accuracy: 0.73 - ETA: 1:25 - loss: 0.8337 - accuracy: 0.73 - ETA: 1:23 - loss: 0.8334 - accuracy: 0.73 - ETA: 1:21 - loss: 0.8325 - accuracy: 0.73 - ETA: 1:20 - loss: 0.8327 - accuracy: 0.73 - ETA: 1:18 - loss: 0.8363 - accuracy: 0.73 - ETA: 1:16 - loss: 0.8352 - accuracy: 0.73 - ETA: 1:15 - loss: 0.8338 - accuracy: 0.73 - ETA: 1:13 - loss: 0.8330 - accuracy: 0.73 - ETA: 1:11 - loss: 0.8347 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8339 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8341 - accuracy: 0.73 - ETA: 1:06 - loss: 0.8349 - accuracy: 0.73 - ETA: 1:04 - loss: 0.8348 - accuracy: 0.73 - ETA: 1:03 - loss: 0.8337 - accuracy: 0.73 - ETA: 1:01 - loss: 0.8331 - accuracy: 0.73 - ETA: 59s - loss: 0.8324 - accuracy: 0.7330 - ETA: 57s - loss: 0.8315 - accuracy: 0.733 - ETA: 56s - loss: 0.8310 - accuracy: 0.733 - ETA: 54s - loss: 0.8306 - accuracy: 0.733 - ETA: 52s - loss: 0.8299 - accuracy: 0.733 - ETA: 51s - loss: 0.8300 - accuracy: 0.733 - ETA: 49s - loss: 0.8299 - accuracy: 0.733 - ETA: 47s - loss: 0.8287 - accuracy: 0.733 - ETA: 45s - loss: 0.8280 - accuracy: 0.734 - ETA: 44s - loss: 0.8274 - accuracy: 0.734 - ETA: 42s - loss: 0.8270 - accuracy: 0.734 - ETA: 40s - loss: 0.8275 - accuracy: 0.734 - ETA: 39s - loss: 0.8295 - accuracy: 0.734 - ETA: 37s - loss: 0.8293 - accuracy: 0.734 - ETA: 35s - loss: 0.8298 - accuracy: 0.733 - ETA: 33s - loss: 0.8292 - accuracy: 0.734 - ETA: 32s - loss: 0.8289 - accuracy: 0.734 - ETA: 30s - loss: 0.8292 - accuracy: 0.733 - ETA: 28s - loss: 0.8280 - accuracy: 0.734 - ETA: 27s - loss: 0.8277 - accuracy: 0.734 - ETA: 25s - loss: 0.8269 - accuracy: 0.734 - ETA: 23s - loss: 0.8262 - accuracy: 0.734 - ETA: 22s - loss: 0.8270 - accuracy: 0.734 - ETA: 20s - loss: 0.8243 - accuracy: 0.735 - ETA: 18s - loss: 0.8258 - accuracy: 0.734 - ETA: 16s - loss: 0.8253 - accuracy: 0.734 - ETA: 15s - loss: 0.8258 - accuracy: 0.734 - ETA: 13s - loss: 0.8260 - accuracy: 0.734 - ETA: 11s - loss: 0.8273 - accuracy: 0.734 - ETA: 10s - loss: 0.8268 - accuracy: 0.734 - ETA: 8s - loss: 0.8262 - accuracy: 0.734 - ETA: 6s - loss: 0.8255 - accuracy: 0.73 - ETA: 4s - loss: 0.8247 - accuracy: 0.73 - ETA: 3s - loss: 0.8239 - accuracy: 0.73 - ETA: 1s - loss: 0.8229 - accuracy: 0.73 - 285s 15ms/step - loss: 0.8227 - accuracy: 0.7356 - val_loss: 1.3671 - val_accuracy: 0.7043\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:48 - loss: 1.0015 - accuracy: 0.64 - ETA: 4:31 - loss: 0.9006 - accuracy: 0.68 - ETA: 4:25 - loss: 0.8469 - accuracy: 0.71 - ETA: 4:27 - loss: 0.8427 - accuracy: 0.71 - ETA: 4:21 - loss: 0.8644 - accuracy: 0.70 - ETA: 4:19 - loss: 0.8544 - accuracy: 0.71 - ETA: 4:13 - loss: 0.8558 - accuracy: 0.71 - ETA: 4:09 - loss: 0.8500 - accuracy: 0.71 - ETA: 4:07 - loss: 0.8398 - accuracy: 0.72 - ETA: 4:05 - loss: 0.8285 - accuracy: 0.72 - ETA: 4:03 - loss: 0.8319 - accuracy: 0.72 - ETA: 4:02 - loss: 0.8268 - accuracy: 0.72 - ETA: 4:02 - loss: 0.8323 - accuracy: 0.73 - ETA: 4:01 - loss: 0.8257 - accuracy: 0.73 - ETA: 3:59 - loss: 0.8236 - accuracy: 0.72 - ETA: 3:57 - loss: 0.8320 - accuracy: 0.72 - ETA: 3:55 - loss: 0.8438 - accuracy: 0.72 - ETA: 3:52 - loss: 0.8341 - accuracy: 0.73 - ETA: 3:50 - loss: 0.8203 - accuracy: 0.73 - ETA: 3:47 - loss: 0.8215 - accuracy: 0.73 - ETA: 3:45 - loss: 0.8204 - accuracy: 0.73 - ETA: 3:44 - loss: 0.8290 - accuracy: 0.72 - ETA: 3:43 - loss: 0.8330 - accuracy: 0.72 - ETA: 3:41 - loss: 0.8331 - accuracy: 0.72 - ETA: 3:39 - loss: 0.8269 - accuracy: 0.72 - ETA: 3:36 - loss: 0.8171 - accuracy: 0.73 - ETA: 3:35 - loss: 0.8160 - accuracy: 0.73 - ETA: 3:33 - loss: 0.8189 - accuracy: 0.73 - ETA: 3:31 - loss: 0.8189 - accuracy: 0.73 - ETA: 3:29 - loss: 0.8152 - accuracy: 0.73 - ETA: 3:28 - loss: 0.8119 - accuracy: 0.73 - ETA: 3:27 - loss: 0.8162 - accuracy: 0.73 - ETA: 3:25 - loss: 0.8144 - accuracy: 0.73 - ETA: 3:23 - loss: 0.8170 - accuracy: 0.73 - ETA: 3:22 - loss: 0.8175 - accuracy: 0.73 - ETA: 3:20 - loss: 0.8172 - accuracy: 0.73 - ETA: 3:18 - loss: 0.8165 - accuracy: 0.73 - ETA: 3:16 - loss: 0.8162 - accuracy: 0.73 - ETA: 3:14 - loss: 0.8171 - accuracy: 0.73 - ETA: 3:13 - loss: 0.8146 - accuracy: 0.73 - ETA: 3:11 - loss: 0.8193 - accuracy: 0.73 - ETA: 3:10 - loss: 0.8210 - accuracy: 0.73 - ETA: 3:08 - loss: 0.8161 - accuracy: 0.73 - ETA: 3:06 - loss: 0.8170 - accuracy: 0.73 - ETA: 3:04 - loss: 0.8155 - accuracy: 0.73 - ETA: 3:02 - loss: 0.8154 - accuracy: 0.73 - ETA: 3:01 - loss: 0.8154 - accuracy: 0.73 - ETA: 2:59 - loss: 0.8154 - accuracy: 0.73 - ETA: 2:57 - loss: 0.8153 - accuracy: 0.73 - ETA: 2:56 - loss: 0.8170 - accuracy: 0.73 - ETA: 2:54 - loss: 0.8178 - accuracy: 0.73 - ETA: 2:52 - loss: 0.8149 - accuracy: 0.73 - ETA: 2:50 - loss: 0.8146 - accuracy: 0.73 - ETA: 2:49 - loss: 0.8122 - accuracy: 0.73 - ETA: 2:47 - loss: 0.8091 - accuracy: 0.73 - ETA: 2:45 - loss: 0.8079 - accuracy: 0.73 - ETA: 2:43 - loss: 0.8042 - accuracy: 0.73 - ETA: 2:41 - loss: 0.8043 - accuracy: 0.73 - ETA: 2:40 - loss: 0.8043 - accuracy: 0.73 - ETA: 2:38 - loss: 0.8011 - accuracy: 0.73 - ETA: 2:36 - loss: 0.7995 - accuracy: 0.73 - ETA: 2:35 - loss: 0.7992 - accuracy: 0.73 - ETA: 2:33 - loss: 0.7979 - accuracy: 0.73 - ETA: 2:31 - loss: 0.7953 - accuracy: 0.74 - ETA: 2:29 - loss: 0.7971 - accuracy: 0.73 - ETA: 2:28 - loss: 0.7983 - accuracy: 0.73 - ETA: 2:26 - loss: 0.8003 - accuracy: 0.73 - ETA: 2:24 - loss: 0.7999 - accuracy: 0.73 - ETA: 2:23 - loss: 0.8012 - accuracy: 0.73 - ETA: 2:21 - loss: 0.8038 - accuracy: 0.73 - ETA: 2:19 - loss: 0.8033 - accuracy: 0.73 - ETA: 2:18 - loss: 0.8029 - accuracy: 0.73 - ETA: 2:16 - loss: 0.8026 - accuracy: 0.73 - ETA: 2:14 - loss: 0.8006 - accuracy: 0.73 - ETA: 2:12 - loss: 0.8018 - accuracy: 0.73 - ETA: 2:10 - loss: 0.8011 - accuracy: 0.73 - ETA: 2:09 - loss: 0.8019 - accuracy: 0.73 - ETA: 2:07 - loss: 0.8018 - accuracy: 0.73 - ETA: 2:05 - loss: 0.8007 - accuracy: 0.73 - ETA: 2:03 - loss: 0.8010 - accuracy: 0.73 - ETA: 2:02 - loss: 0.7981 - accuracy: 0.73 - ETA: 2:00 - loss: 0.8002 - accuracy: 0.73 - ETA: 1:58 - loss: 0.8018 - accuracy: 0.73 - ETA: 1:56 - loss: 0.8007 - accuracy: 0.73 - ETA: 1:55 - loss: 0.8010 - accuracy: 0.73 - ETA: 1:53 - loss: 0.8017 - accuracy: 0.73 - ETA: 1:51 - loss: 0.8025 - accuracy: 0.73 - ETA: 1:49 - loss: 0.8029 - accuracy: 0.73 - ETA: 1:48 - loss: 0.8044 - accuracy: 0.73 - ETA: 1:46 - loss: 0.8045 - accuracy: 0.73 - ETA: 1:44 - loss: 0.8047 - accuracy: 0.73 - ETA: 1:42 - loss: 0.8039 - accuracy: 0.73 - ETA: 1:40 - loss: 0.8043 - accuracy: 0.73 - ETA: 1:38 - loss: 0.8042 - accuracy: 0.73 - ETA: 1:37 - loss: 0.8038 - accuracy: 0.73 - ETA: 1:35 - loss: 0.8052 - accuracy: 0.73 - ETA: 1:33 - loss: 0.8047 - accuracy: 0.73 - ETA: 1:32 - loss: 0.8044 - accuracy: 0.73 - ETA: 1:30 - loss: 0.8048 - accuracy: 0.73 - ETA: 1:28 - loss: 0.8043 - accuracy: 0.73 - ETA: 1:26 - loss: 0.8047 - accuracy: 0.73 - ETA: 1:24 - loss: 0.8051 - accuracy: 0.73 - ETA: 1:23 - loss: 0.8058 - accuracy: 0.73 - ETA: 1:21 - loss: 0.8050 - accuracy: 0.73 - ETA: 1:19 - loss: 0.8047 - accuracy: 0.73 - ETA: 1:17 - loss: 0.8051 - accuracy: 0.73 - ETA: 1:16 - loss: 0.8046 - accuracy: 0.73 - ETA: 1:14 - loss: 0.8021 - accuracy: 0.73 - ETA: 1:12 - loss: 0.8021 - accuracy: 0.73 - ETA: 1:10 - loss: 0.8019 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8020 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8016 - accuracy: 0.73 - ETA: 1:05 - loss: 0.8015 - accuracy: 0.73 - ETA: 1:04 - loss: 0.7996 - accuracy: 0.73 - ETA: 1:02 - loss: 0.7991 - accuracy: 0.73 - ETA: 1:00 - loss: 0.7993 - accuracy: 0.73 - ETA: 58s - loss: 0.8000 - accuracy: 0.7391 - ETA: 57s - loss: 0.8000 - accuracy: 0.739 - ETA: 55s - loss: 0.7987 - accuracy: 0.739 - ETA: 53s - loss: 0.7976 - accuracy: 0.740 - ETA: 51s - loss: 0.7980 - accuracy: 0.739 - ETA: 50s - loss: 0.7988 - accuracy: 0.739 - ETA: 48s - loss: 0.8001 - accuracy: 0.739 - ETA: 46s - loss: 0.8003 - accuracy: 0.739 - ETA: 44s - loss: 0.8001 - accuracy: 0.739 - ETA: 43s - loss: 0.8017 - accuracy: 0.738 - ETA: 41s - loss: 0.8008 - accuracy: 0.739 - ETA: 39s - loss: 0.8009 - accuracy: 0.739 - ETA: 37s - loss: 0.8006 - accuracy: 0.739 - ETA: 36s - loss: 0.7997 - accuracy: 0.740 - ETA: 34s - loss: 0.7985 - accuracy: 0.740 - ETA: 32s - loss: 0.7981 - accuracy: 0.740 - ETA: 30s - loss: 0.7975 - accuracy: 0.740 - ETA: 29s - loss: 0.7967 - accuracy: 0.740 - ETA: 27s - loss: 0.7963 - accuracy: 0.741 - ETA: 25s - loss: 0.7958 - accuracy: 0.741 - ETA: 24s - loss: 0.7955 - accuracy: 0.741 - ETA: 22s - loss: 0.7947 - accuracy: 0.741 - ETA: 20s - loss: 0.7946 - accuracy: 0.741 - ETA: 18s - loss: 0.7939 - accuracy: 0.741 - ETA: 17s - loss: 0.7944 - accuracy: 0.741 - ETA: 15s - loss: 0.7945 - accuracy: 0.740 - ETA: 13s - loss: 0.7935 - accuracy: 0.741 - ETA: 11s - loss: 0.7914 - accuracy: 0.741 - ETA: 10s - loss: 0.7918 - accuracy: 0.741 - ETA: 8s - loss: 0.7907 - accuracy: 0.742 - ETA: 6s - loss: 0.7906 - accuracy: 0.74 - ETA: 4s - loss: 0.7912 - accuracy: 0.74 - ETA: 3s - loss: 0.7898 - accuracy: 0.74 - ETA: 1s - loss: 0.7891 - accuracy: 0.74 - 13458s 697ms/step - loss: 0.7898 - accuracy: 0.7430 - val_loss: 1.3944 - val_accuracy: 0.7082\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 19:13 - loss: 0.7787 - accuracy: 0.757 - ETA: 11:50 - loss: 0.7846 - accuracy: 0.730 - ETA: 9:15 - loss: 0.8041 - accuracy: 0.739 - ETA: 8:10 - loss: 0.7782 - accuracy: 0.74 - ETA: 7:07 - loss: 0.7554 - accuracy: 0.75 - ETA: 6:24 - loss: 0.7559 - accuracy: 0.75 - ETA: 5:55 - loss: 0.7673 - accuracy: 0.74 - ETA: 5:31 - loss: 0.7749 - accuracy: 0.74 - ETA: 5:14 - loss: 0.7654 - accuracy: 0.74 - ETA: 5:01 - loss: 0.7716 - accuracy: 0.74 - ETA: 4:53 - loss: 0.7605 - accuracy: 0.74 - ETA: 4:42 - loss: 0.7532 - accuracy: 0.74 - ETA: 4:31 - loss: 0.7487 - accuracy: 0.75 - ETA: 4:25 - loss: 0.7534 - accuracy: 0.75 - ETA: 4:21 - loss: 0.7440 - accuracy: 0.75 - ETA: 4:15 - loss: 0.7513 - accuracy: 0.75 - ETA: 4:09 - loss: 0.7583 - accuracy: 0.75 - ETA: 4:04 - loss: 0.7619 - accuracy: 0.74 - ETA: 3:58 - loss: 0.7586 - accuracy: 0.75 - ETA: 3:54 - loss: 0.7638 - accuracy: 0.74 - ETA: 3:51 - loss: 0.7515 - accuracy: 0.75 - ETA: 3:48 - loss: 0.7571 - accuracy: 0.75 - ETA: 3:45 - loss: 0.7580 - accuracy: 0.75 - ETA: 3:42 - loss: 0.7577 - accuracy: 0.75 - ETA: 3:38 - loss: 0.7589 - accuracy: 0.75 - ETA: 3:35 - loss: 0.7593 - accuracy: 0.75 - ETA: 3:31 - loss: 0.7572 - accuracy: 0.75 - ETA: 3:28 - loss: 0.7542 - accuracy: 0.75 - ETA: 3:25 - loss: 0.7558 - accuracy: 0.75 - ETA: 3:24 - loss: 0.7584 - accuracy: 0.75 - ETA: 3:22 - loss: 0.7514 - accuracy: 0.75 - ETA: 3:18 - loss: 0.7548 - accuracy: 0.75 - ETA: 3:15 - loss: 0.7602 - accuracy: 0.74 - ETA: 3:12 - loss: 0.7578 - accuracy: 0.75 - ETA: 3:09 - loss: 0.7587 - accuracy: 0.75 - ETA: 3:06 - loss: 0.7594 - accuracy: 0.75 - ETA: 3:04 - loss: 0.7593 - accuracy: 0.74 - ETA: 3:01 - loss: 0.7593 - accuracy: 0.74 - ETA: 2:59 - loss: 0.7561 - accuracy: 0.75 - ETA: 2:56 - loss: 0.7611 - accuracy: 0.74 - ETA: 2:53 - loss: 0.7579 - accuracy: 0.75 - ETA: 2:51 - loss: 0.7642 - accuracy: 0.74 - ETA: 2:48 - loss: 0.7619 - accuracy: 0.74 - ETA: 2:46 - loss: 0.7658 - accuracy: 0.74 - ETA: 2:44 - loss: 0.7680 - accuracy: 0.74 - ETA: 2:42 - loss: 0.7713 - accuracy: 0.74 - ETA: 2:39 - loss: 0.7690 - accuracy: 0.74 - ETA: 2:37 - loss: 0.7702 - accuracy: 0.74 - ETA: 2:35 - loss: 0.7708 - accuracy: 0.74 - ETA: 2:33 - loss: 0.7734 - accuracy: 0.74 - ETA: 2:31 - loss: 0.7757 - accuracy: 0.74 - ETA: 2:29 - loss: 0.7779 - accuracy: 0.74 - ETA: 2:27 - loss: 0.7749 - accuracy: 0.74 - ETA: 2:25 - loss: 0.7732 - accuracy: 0.74 - ETA: 2:23 - loss: 0.7760 - accuracy: 0.74 - ETA: 2:21 - loss: 0.7739 - accuracy: 0.74 - ETA: 2:19 - loss: 0.7763 - accuracy: 0.74 - ETA: 2:17 - loss: 0.7785 - accuracy: 0.74 - ETA: 2:15 - loss: 0.7762 - accuracy: 0.74 - ETA: 2:14 - loss: 0.7762 - accuracy: 0.74 - ETA: 2:12 - loss: 0.7773 - accuracy: 0.74 - ETA: 2:10 - loss: 0.7776 - accuracy: 0.74 - ETA: 2:08 - loss: 0.7773 - accuracy: 0.74 - ETA: 2:06 - loss: 0.7750 - accuracy: 0.74 - ETA: 2:04 - loss: 0.7706 - accuracy: 0.74 - ETA: 2:02 - loss: 0.7738 - accuracy: 0.74 - ETA: 2:00 - loss: 0.7723 - accuracy: 0.74 - ETA: 1:58 - loss: 0.7740 - accuracy: 0.74 - ETA: 1:57 - loss: 0.7724 - accuracy: 0.74 - ETA: 1:55 - loss: 0.7720 - accuracy: 0.74 - ETA: 1:53 - loss: 0.7722 - accuracy: 0.74 - ETA: 1:51 - loss: 0.7724 - accuracy: 0.74 - ETA: 1:50 - loss: 0.7730 - accuracy: 0.74 - ETA: 1:48 - loss: 0.7727 - accuracy: 0.74 - ETA: 1:46 - loss: 0.7731 - accuracy: 0.74 - ETA: 1:45 - loss: 0.7726 - accuracy: 0.74 - ETA: 1:43 - loss: 0.7711 - accuracy: 0.74 - ETA: 1:41 - loss: 0.7705 - accuracy: 0.74 - ETA: 1:40 - loss: 0.7685 - accuracy: 0.74 - ETA: 1:38 - loss: 0.7700 - accuracy: 0.74 - ETA: 1:36 - loss: 0.7714 - accuracy: 0.74 - ETA: 1:35 - loss: 0.7718 - accuracy: 0.74 - ETA: 1:33 - loss: 0.7721 - accuracy: 0.74 - ETA: 1:31 - loss: 0.7711 - accuracy: 0.74 - ETA: 1:30 - loss: 0.7724 - accuracy: 0.74 - ETA: 1:28 - loss: 0.7712 - accuracy: 0.74 - ETA: 1:27 - loss: 0.7711 - accuracy: 0.74 - ETA: 1:25 - loss: 0.7707 - accuracy: 0.74 - ETA: 1:24 - loss: 0.7693 - accuracy: 0.74 - ETA: 1:22 - loss: 0.7702 - accuracy: 0.74 - ETA: 1:21 - loss: 0.7697 - accuracy: 0.74 - ETA: 1:19 - loss: 0.7705 - accuracy: 0.74 - ETA: 1:18 - loss: 0.7709 - accuracy: 0.74 - ETA: 1:16 - loss: 0.7710 - accuracy: 0.74 - ETA: 1:15 - loss: 0.7713 - accuracy: 0.74 - ETA: 1:13 - loss: 0.7699 - accuracy: 0.74 - ETA: 1:12 - loss: 0.7703 - accuracy: 0.74 - ETA: 1:10 - loss: 0.7711 - accuracy: 0.74 - ETA: 1:09 - loss: 0.7719 - accuracy: 0.74 - ETA: 1:07 - loss: 0.7722 - accuracy: 0.74 - ETA: 1:06 - loss: 0.7724 - accuracy: 0.74 - ETA: 1:04 - loss: 0.7732 - accuracy: 0.74 - ETA: 1:03 - loss: 0.7718 - accuracy: 0.74 - ETA: 1:02 - loss: 0.7734 - accuracy: 0.74 - ETA: 1:00 - loss: 0.7723 - accuracy: 0.74 - ETA: 59s - loss: 0.7721 - accuracy: 0.7462 - ETA: 57s - loss: 0.7713 - accuracy: 0.746 - ETA: 56s - loss: 0.7705 - accuracy: 0.746 - ETA: 55s - loss: 0.7699 - accuracy: 0.746 - ETA: 53s - loss: 0.7685 - accuracy: 0.747 - ETA: 52s - loss: 0.7689 - accuracy: 0.747 - ETA: 50s - loss: 0.7702 - accuracy: 0.747 - ETA: 49s - loss: 0.7701 - accuracy: 0.747 - ETA: 48s - loss: 0.7697 - accuracy: 0.747 - ETA: 46s - loss: 0.7700 - accuracy: 0.747 - ETA: 45s - loss: 0.7716 - accuracy: 0.747 - ETA: 44s - loss: 0.7735 - accuracy: 0.746 - ETA: 42s - loss: 0.7729 - accuracy: 0.747 - ETA: 41s - loss: 0.7717 - accuracy: 0.747 - ETA: 40s - loss: 0.7731 - accuracy: 0.746 - ETA: 38s - loss: 0.7725 - accuracy: 0.747 - ETA: 37s - loss: 0.7722 - accuracy: 0.747 - ETA: 36s - loss: 0.7705 - accuracy: 0.747 - ETA: 34s - loss: 0.7699 - accuracy: 0.747 - ETA: 33s - loss: 0.7698 - accuracy: 0.747 - ETA: 32s - loss: 0.7676 - accuracy: 0.748 - ETA: 30s - loss: 0.7665 - accuracy: 0.749 - ETA: 29s - loss: 0.7671 - accuracy: 0.748 - ETA: 28s - loss: 0.7675 - accuracy: 0.748 - ETA: 26s - loss: 0.7666 - accuracy: 0.749 - ETA: 25s - loss: 0.7674 - accuracy: 0.748 - ETA: 24s - loss: 0.7660 - accuracy: 0.749 - ETA: 22s - loss: 0.7650 - accuracy: 0.749 - ETA: 21s - loss: 0.7643 - accuracy: 0.749 - ETA: 20s - loss: 0.7639 - accuracy: 0.750 - ETA: 19s - loss: 0.7649 - accuracy: 0.749 - ETA: 17s - loss: 0.7653 - accuracy: 0.749 - ETA: 16s - loss: 0.7655 - accuracy: 0.749 - ETA: 15s - loss: 0.7667 - accuracy: 0.749 - ETA: 13s - loss: 0.7666 - accuracy: 0.748 - ETA: 12s - loss: 0.7675 - accuracy: 0.748 - ETA: 11s - loss: 0.7671 - accuracy: 0.748 - ETA: 10s - loss: 0.7681 - accuracy: 0.748 - ETA: 8s - loss: 0.7670 - accuracy: 0.748 - ETA: 7s - loss: 0.7668 - accuracy: 0.74 - ETA: 6s - loss: 0.7665 - accuracy: 0.74 - ETA: 4s - loss: 0.7664 - accuracy: 0.74 - ETA: 3s - loss: 0.7663 - accuracy: 0.74 - ETA: 2s - loss: 0.7658 - accuracy: 0.74 - ETA: 1s - loss: 0.7668 - accuracy: 0.74 - 208s 11ms/step - loss: 0.7667 - accuracy: 0.7492 - val_loss: 1.3932 - val_accuracy: 0.7138\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:44 - loss: 0.6848 - accuracy: 0.79 - ETA: 2:45 - loss: 0.7506 - accuracy: 0.77 - ETA: 2:43 - loss: 0.7495 - accuracy: 0.75 - ETA: 2:43 - loss: 0.8043 - accuracy: 0.74 - ETA: 2:42 - loss: 0.8031 - accuracy: 0.73 - ETA: 2:40 - loss: 0.7916 - accuracy: 0.74 - ETA: 2:38 - loss: 0.7744 - accuracy: 0.74 - ETA: 2:37 - loss: 0.7625 - accuracy: 0.74 - ETA: 2:37 - loss: 0.7902 - accuracy: 0.74 - ETA: 2:38 - loss: 0.7794 - accuracy: 0.74 - ETA: 2:37 - loss: 0.7710 - accuracy: 0.75 - ETA: 2:36 - loss: 0.7748 - accuracy: 0.75 - ETA: 2:35 - loss: 0.7807 - accuracy: 0.75 - ETA: 2:34 - loss: 0.7866 - accuracy: 0.75 - ETA: 2:32 - loss: 0.7930 - accuracy: 0.74 - ETA: 2:31 - loss: 0.7924 - accuracy: 0.75 - ETA: 2:30 - loss: 0.7797 - accuracy: 0.75 - ETA: 2:29 - loss: 0.7761 - accuracy: 0.75 - ETA: 2:28 - loss: 0.7758 - accuracy: 0.75 - ETA: 2:26 - loss: 0.7712 - accuracy: 0.75 - ETA: 2:25 - loss: 0.7614 - accuracy: 0.75 - ETA: 2:24 - loss: 0.7567 - accuracy: 0.75 - ETA: 2:23 - loss: 0.7571 - accuracy: 0.75 - ETA: 2:22 - loss: 0.7602 - accuracy: 0.75 - ETA: 2:21 - loss: 0.7543 - accuracy: 0.75 - ETA: 2:20 - loss: 0.7519 - accuracy: 0.75 - ETA: 2:18 - loss: 0.7485 - accuracy: 0.75 - ETA: 2:17 - loss: 0.7531 - accuracy: 0.75 - ETA: 2:15 - loss: 0.7536 - accuracy: 0.75 - ETA: 2:14 - loss: 0.7533 - accuracy: 0.75 - ETA: 2:13 - loss: 0.7500 - accuracy: 0.75 - ETA: 2:12 - loss: 0.7476 - accuracy: 0.75 - ETA: 2:11 - loss: 0.7462 - accuracy: 0.75 - ETA: 2:09 - loss: 0.7439 - accuracy: 0.75 - ETA: 2:08 - loss: 0.7410 - accuracy: 0.75 - ETA: 2:07 - loss: 0.7392 - accuracy: 0.75 - ETA: 2:06 - loss: 0.7356 - accuracy: 0.75 - ETA: 2:05 - loss: 0.7366 - accuracy: 0.75 - ETA: 2:03 - loss: 0.7336 - accuracy: 0.75 - ETA: 2:03 - loss: 0.7317 - accuracy: 0.75 - ETA: 2:01 - loss: 0.7308 - accuracy: 0.75 - ETA: 2:00 - loss: 0.7306 - accuracy: 0.75 - ETA: 1:59 - loss: 0.7301 - accuracy: 0.75 - ETA: 1:58 - loss: 0.7325 - accuracy: 0.75 - ETA: 1:56 - loss: 0.7350 - accuracy: 0.75 - ETA: 1:55 - loss: 0.7352 - accuracy: 0.75 - ETA: 1:54 - loss: 0.7363 - accuracy: 0.75 - ETA: 1:53 - loss: 0.7366 - accuracy: 0.75 - ETA: 1:52 - loss: 0.7375 - accuracy: 0.75 - ETA: 1:51 - loss: 0.7374 - accuracy: 0.75 - ETA: 1:50 - loss: 0.7392 - accuracy: 0.75 - ETA: 1:48 - loss: 0.7395 - accuracy: 0.75 - ETA: 1:48 - loss: 0.7367 - accuracy: 0.75 - ETA: 1:47 - loss: 0.7358 - accuracy: 0.75 - ETA: 1:46 - loss: 0.7363 - accuracy: 0.75 - ETA: 1:44 - loss: 0.7371 - accuracy: 0.75 - ETA: 1:43 - loss: 0.7401 - accuracy: 0.75 - ETA: 1:42 - loss: 0.7437 - accuracy: 0.75 - ETA: 1:41 - loss: 0.7408 - accuracy: 0.75 - ETA: 1:40 - loss: 0.7388 - accuracy: 0.75 - ETA: 1:39 - loss: 0.7381 - accuracy: 0.75 - ETA: 1:38 - loss: 0.7366 - accuracy: 0.75 - ETA: 1:37 - loss: 0.7357 - accuracy: 0.75 - ETA: 1:36 - loss: 0.7377 - accuracy: 0.75 - ETA: 1:35 - loss: 0.7368 - accuracy: 0.75 - ETA: 1:34 - loss: 0.7367 - accuracy: 0.75 - ETA: 1:34 - loss: 0.7380 - accuracy: 0.75 - ETA: 1:33 - loss: 0.7389 - accuracy: 0.75 - ETA: 1:32 - loss: 0.7367 - accuracy: 0.75 - ETA: 1:31 - loss: 0.7358 - accuracy: 0.75 - ETA: 1:30 - loss: 0.7361 - accuracy: 0.75 - ETA: 1:29 - loss: 0.7399 - accuracy: 0.75 - ETA: 1:28 - loss: 0.7390 - accuracy: 0.75 - ETA: 1:27 - loss: 0.7377 - accuracy: 0.75 - ETA: 1:26 - loss: 0.7375 - accuracy: 0.75 - ETA: 1:25 - loss: 0.7378 - accuracy: 0.75 - ETA: 1:24 - loss: 0.7385 - accuracy: 0.75 - ETA: 1:23 - loss: 0.7384 - accuracy: 0.75 - ETA: 1:22 - loss: 0.7382 - accuracy: 0.75 - ETA: 1:21 - loss: 0.7390 - accuracy: 0.75 - ETA: 1:20 - loss: 0.7372 - accuracy: 0.75 - ETA: 1:18 - loss: 0.7387 - accuracy: 0.75 - ETA: 1:17 - loss: 0.7384 - accuracy: 0.75 - ETA: 1:16 - loss: 0.7383 - accuracy: 0.75 - ETA: 1:15 - loss: 0.7383 - accuracy: 0.75 - ETA: 1:14 - loss: 0.7397 - accuracy: 0.75 - ETA: 1:13 - loss: 0.7392 - accuracy: 0.75 - ETA: 1:11 - loss: 0.7387 - accuracy: 0.75 - ETA: 1:10 - loss: 0.7401 - accuracy: 0.75 - ETA: 1:09 - loss: 0.7399 - accuracy: 0.75 - ETA: 1:08 - loss: 0.7379 - accuracy: 0.76 - ETA: 1:07 - loss: 0.7377 - accuracy: 0.76 - ETA: 1:06 - loss: 0.7378 - accuracy: 0.76 - ETA: 1:04 - loss: 0.7361 - accuracy: 0.76 - ETA: 1:03 - loss: 0.7351 - accuracy: 0.76 - ETA: 1:02 - loss: 0.7373 - accuracy: 0.76 - ETA: 1:01 - loss: 0.7365 - accuracy: 0.76 - ETA: 1:00 - loss: 0.7368 - accuracy: 0.76 - ETA: 59s - loss: 0.7382 - accuracy: 0.7605 - ETA: 57s - loss: 0.7384 - accuracy: 0.760 - ETA: 56s - loss: 0.7384 - accuracy: 0.760 - ETA: 55s - loss: 0.7385 - accuracy: 0.760 - ETA: 54s - loss: 0.7375 - accuracy: 0.760 - ETA: 53s - loss: 0.7359 - accuracy: 0.761 - ETA: 52s - loss: 0.7354 - accuracy: 0.761 - ETA: 51s - loss: 0.7365 - accuracy: 0.761 - ETA: 50s - loss: 0.7356 - accuracy: 0.761 - ETA: 48s - loss: 0.7344 - accuracy: 0.761 - ETA: 47s - loss: 0.7336 - accuracy: 0.762 - ETA: 46s - loss: 0.7332 - accuracy: 0.761 - ETA: 45s - loss: 0.7330 - accuracy: 0.762 - ETA: 44s - loss: 0.7339 - accuracy: 0.762 - ETA: 43s - loss: 0.7355 - accuracy: 0.761 - ETA: 42s - loss: 0.7352 - accuracy: 0.761 - ETA: 40s - loss: 0.7357 - accuracy: 0.761 - ETA: 39s - loss: 0.7361 - accuracy: 0.761 - ETA: 38s - loss: 0.7365 - accuracy: 0.761 - ETA: 37s - loss: 0.7370 - accuracy: 0.761 - ETA: 36s - loss: 0.7370 - accuracy: 0.761 - ETA: 35s - loss: 0.7349 - accuracy: 0.761 - ETA: 34s - loss: 0.7347 - accuracy: 0.761 - ETA: 33s - loss: 0.7368 - accuracy: 0.761 - ETA: 31s - loss: 0.7372 - accuracy: 0.761 - ETA: 30s - loss: 0.7356 - accuracy: 0.761 - ETA: 29s - loss: 0.7362 - accuracy: 0.761 - ETA: 28s - loss: 0.7360 - accuracy: 0.761 - ETA: 27s - loss: 0.7344 - accuracy: 0.762 - ETA: 26s - loss: 0.7358 - accuracy: 0.761 - ETA: 25s - loss: 0.7384 - accuracy: 0.761 - ETA: 23s - loss: 0.7379 - accuracy: 0.761 - ETA: 22s - loss: 0.7381 - accuracy: 0.761 - ETA: 21s - loss: 0.7386 - accuracy: 0.761 - ETA: 20s - loss: 0.7402 - accuracy: 0.760 - ETA: 19s - loss: 0.7391 - accuracy: 0.760 - ETA: 18s - loss: 0.7396 - accuracy: 0.760 - ETA: 17s - loss: 0.7401 - accuracy: 0.760 - ETA: 15s - loss: 0.7393 - accuracy: 0.760 - ETA: 14s - loss: 0.7400 - accuracy: 0.760 - ETA: 13s - loss: 0.7407 - accuracy: 0.760 - ETA: 12s - loss: 0.7407 - accuracy: 0.760 - ETA: 11s - loss: 0.7413 - accuracy: 0.760 - ETA: 10s - loss: 0.7398 - accuracy: 0.760 - ETA: 8s - loss: 0.7388 - accuracy: 0.760 - ETA: 7s - loss: 0.7384 - accuracy: 0.76 - ETA: 6s - loss: 0.7397 - accuracy: 0.76 - ETA: 5s - loss: 0.7393 - accuracy: 0.76 - ETA: 4s - loss: 0.7409 - accuracy: 0.76 - ETA: 3s - loss: 0.7411 - accuracy: 0.75 - ETA: 2s - loss: 0.7406 - accuracy: 0.75 - ETA: 0s - loss: 0.7411 - accuracy: 0.75 - 187s 10ms/step - loss: 0.7404 - accuracy: 0.7596 - val_loss: 1.3638 - val_accuracy: 0.7155\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:45 - loss: 0.8306 - accuracy: 0.72 - ETA: 2:43 - loss: 0.7325 - accuracy: 0.75 - ETA: 2:42 - loss: 0.6883 - accuracy: 0.77 - ETA: 2:43 - loss: 0.7187 - accuracy: 0.76 - ETA: 2:45 - loss: 0.6926 - accuracy: 0.77 - ETA: 2:44 - loss: 0.6922 - accuracy: 0.77 - ETA: 2:43 - loss: 0.6962 - accuracy: 0.76 - ETA: 2:42 - loss: 0.6881 - accuracy: 0.77 - ETA: 2:40 - loss: 0.6866 - accuracy: 0.77 - ETA: 2:38 - loss: 0.6788 - accuracy: 0.77 - ETA: 2:37 - loss: 0.6989 - accuracy: 0.76 - ETA: 2:36 - loss: 0.7111 - accuracy: 0.76 - ETA: 2:35 - loss: 0.7175 - accuracy: 0.76 - ETA: 2:34 - loss: 0.7123 - accuracy: 0.76 - ETA: 2:33 - loss: 0.6994 - accuracy: 0.76 - ETA: 2:31 - loss: 0.6964 - accuracy: 0.76 - ETA: 2:30 - loss: 0.7065 - accuracy: 0.76 - ETA: 2:28 - loss: 0.7040 - accuracy: 0.76 - ETA: 2:27 - loss: 0.7021 - accuracy: 0.76 - ETA: 2:26 - loss: 0.6976 - accuracy: 0.76 - ETA: 2:25 - loss: 0.6976 - accuracy: 0.76 - ETA: 2:25 - loss: 0.6967 - accuracy: 0.76 - ETA: 2:24 - loss: 0.6999 - accuracy: 0.76 - ETA: 2:23 - loss: 0.7069 - accuracy: 0.76 - ETA: 2:22 - loss: 0.7130 - accuracy: 0.76 - ETA: 2:21 - loss: 0.7100 - accuracy: 0.76 - ETA: 2:19 - loss: 0.7132 - accuracy: 0.76 - ETA: 2:18 - loss: 0.7123 - accuracy: 0.76 - ETA: 2:17 - loss: 0.7126 - accuracy: 0.76 - ETA: 2:16 - loss: 0.7099 - accuracy: 0.76 - ETA: 2:15 - loss: 0.7096 - accuracy: 0.76 - ETA: 2:13 - loss: 0.7115 - accuracy: 0.76 - ETA: 2:12 - loss: 0.7116 - accuracy: 0.76 - ETA: 2:11 - loss: 0.7117 - accuracy: 0.76 - ETA: 2:10 - loss: 0.7110 - accuracy: 0.76 - ETA: 2:09 - loss: 0.7121 - accuracy: 0.76 - ETA: 2:08 - loss: 0.7149 - accuracy: 0.76 - ETA: 2:07 - loss: 0.7175 - accuracy: 0.76 - ETA: 2:06 - loss: 0.7201 - accuracy: 0.76 - ETA: 2:04 - loss: 0.7192 - accuracy: 0.76 - ETA: 2:03 - loss: 0.7241 - accuracy: 0.76 - ETA: 2:02 - loss: 0.7242 - accuracy: 0.76 - ETA: 2:01 - loss: 0.7277 - accuracy: 0.76 - ETA: 2:00 - loss: 0.7250 - accuracy: 0.76 - ETA: 1:58 - loss: 0.7224 - accuracy: 0.76 - ETA: 1:57 - loss: 0.7198 - accuracy: 0.76 - ETA: 1:56 - loss: 0.7185 - accuracy: 0.76 - ETA: 1:55 - loss: 0.7202 - accuracy: 0.76 - ETA: 1:54 - loss: 0.7167 - accuracy: 0.76 - ETA: 1:53 - loss: 0.7161 - accuracy: 0.76 - ETA: 1:51 - loss: 0.7145 - accuracy: 0.76 - ETA: 1:50 - loss: 0.7135 - accuracy: 0.76 - ETA: 1:49 - loss: 0.7118 - accuracy: 0.76 - ETA: 1:48 - loss: 0.7146 - accuracy: 0.76 - ETA: 1:47 - loss: 0.7136 - accuracy: 0.76 - ETA: 1:46 - loss: 0.7121 - accuracy: 0.76 - ETA: 1:45 - loss: 0.7127 - accuracy: 0.76 - ETA: 1:44 - loss: 0.7104 - accuracy: 0.76 - ETA: 1:43 - loss: 0.7102 - accuracy: 0.76 - ETA: 1:41 - loss: 0.7144 - accuracy: 0.76 - ETA: 1:40 - loss: 0.7176 - accuracy: 0.76 - ETA: 1:39 - loss: 0.7190 - accuracy: 0.76 - ETA: 1:38 - loss: 0.7179 - accuracy: 0.76 - ETA: 1:37 - loss: 0.7165 - accuracy: 0.76 - ETA: 1:36 - loss: 0.7154 - accuracy: 0.76 - ETA: 1:35 - loss: 0.7136 - accuracy: 0.76 - ETA: 1:34 - loss: 0.7145 - accuracy: 0.76 - ETA: 1:33 - loss: 0.7145 - accuracy: 0.76 - ETA: 1:32 - loss: 0.7160 - accuracy: 0.76 - ETA: 1:31 - loss: 0.7151 - accuracy: 0.76 - ETA: 1:30 - loss: 0.7151 - accuracy: 0.76 - ETA: 1:28 - loss: 0.7132 - accuracy: 0.76 - ETA: 1:27 - loss: 0.7124 - accuracy: 0.76 - ETA: 1:26 - loss: 0.7098 - accuracy: 0.76 - ETA: 1:25 - loss: 0.7096 - accuracy: 0.76 - ETA: 1:24 - loss: 0.7096 - accuracy: 0.76 - ETA: 1:23 - loss: 0.7078 - accuracy: 0.76 - ETA: 1:22 - loss: 0.7046 - accuracy: 0.76 - ETA: 1:21 - loss: 0.7028 - accuracy: 0.76 - ETA: 1:20 - loss: 0.7027 - accuracy: 0.76 - ETA: 1:18 - loss: 0.7036 - accuracy: 0.76 - ETA: 1:17 - loss: 0.7028 - accuracy: 0.76 - ETA: 1:16 - loss: 0.7036 - accuracy: 0.76 - ETA: 1:15 - loss: 0.7019 - accuracy: 0.76 - ETA: 1:14 - loss: 0.7034 - accuracy: 0.76 - ETA: 1:13 - loss: 0.7028 - accuracy: 0.76 - ETA: 1:11 - loss: 0.7046 - accuracy: 0.76 - ETA: 1:10 - loss: 0.7037 - accuracy: 0.76 - ETA: 1:09 - loss: 0.7034 - accuracy: 0.76 - ETA: 1:08 - loss: 0.7019 - accuracy: 0.76 - ETA: 1:07 - loss: 0.7009 - accuracy: 0.76 - ETA: 1:06 - loss: 0.7016 - accuracy: 0.76 - ETA: 1:05 - loss: 0.7013 - accuracy: 0.76 - ETA: 1:04 - loss: 0.7013 - accuracy: 0.76 - ETA: 1:03 - loss: 0.7025 - accuracy: 0.76 - ETA: 1:02 - loss: 0.7028 - accuracy: 0.76 - ETA: 1:01 - loss: 0.7025 - accuracy: 0.76 - ETA: 59s - loss: 0.7012 - accuracy: 0.7667 - ETA: 58s - loss: 0.7011 - accuracy: 0.766 - ETA: 57s - loss: 0.7002 - accuracy: 0.767 - ETA: 56s - loss: 0.6996 - accuracy: 0.767 - ETA: 55s - loss: 0.6989 - accuracy: 0.767 - ETA: 54s - loss: 0.6981 - accuracy: 0.767 - ETA: 53s - loss: 0.6977 - accuracy: 0.767 - ETA: 52s - loss: 0.6978 - accuracy: 0.767 - ETA: 51s - loss: 0.6974 - accuracy: 0.768 - ETA: 49s - loss: 0.6980 - accuracy: 0.768 - ETA: 48s - loss: 0.6975 - accuracy: 0.768 - ETA: 47s - loss: 0.6967 - accuracy: 0.768 - ETA: 46s - loss: 0.6957 - accuracy: 0.768 - ETA: 45s - loss: 0.6960 - accuracy: 0.768 - ETA: 44s - loss: 0.6973 - accuracy: 0.768 - ETA: 43s - loss: 0.6970 - accuracy: 0.768 - ETA: 41s - loss: 0.6968 - accuracy: 0.767 - ETA: 40s - loss: 0.6969 - accuracy: 0.767 - ETA: 39s - loss: 0.6962 - accuracy: 0.767 - ETA: 38s - loss: 0.6963 - accuracy: 0.768 - ETA: 37s - loss: 0.6958 - accuracy: 0.768 - ETA: 36s - loss: 0.6949 - accuracy: 0.768 - ETA: 35s - loss: 0.6938 - accuracy: 0.768 - ETA: 34s - loss: 0.6943 - accuracy: 0.768 - ETA: 32s - loss: 0.6966 - accuracy: 0.767 - ETA: 31s - loss: 0.6970 - accuracy: 0.767 - ETA: 30s - loss: 0.6977 - accuracy: 0.767 - ETA: 29s - loss: 0.6972 - accuracy: 0.767 - ETA: 28s - loss: 0.6958 - accuracy: 0.768 - ETA: 27s - loss: 0.6964 - accuracy: 0.767 - ETA: 26s - loss: 0.6972 - accuracy: 0.767 - ETA: 24s - loss: 0.6986 - accuracy: 0.767 - ETA: 23s - loss: 0.6972 - accuracy: 0.767 - ETA: 22s - loss: 0.6972 - accuracy: 0.767 - ETA: 21s - loss: 0.6961 - accuracy: 0.768 - ETA: 20s - loss: 0.6968 - accuracy: 0.767 - ETA: 19s - loss: 0.6978 - accuracy: 0.767 - ETA: 18s - loss: 0.6986 - accuracy: 0.767 - ETA: 16s - loss: 0.6981 - accuracy: 0.767 - ETA: 15s - loss: 0.6987 - accuracy: 0.767 - ETA: 14s - loss: 0.6984 - accuracy: 0.767 - ETA: 13s - loss: 0.6998 - accuracy: 0.766 - ETA: 12s - loss: 0.7002 - accuracy: 0.766 - ETA: 11s - loss: 0.7005 - accuracy: 0.766 - ETA: 10s - loss: 0.7006 - accuracy: 0.766 - ETA: 8s - loss: 0.7002 - accuracy: 0.766 - ETA: 7s - loss: 0.7008 - accuracy: 0.76 - ETA: 6s - loss: 0.7002 - accuracy: 0.76 - ETA: 5s - loss: 0.7003 - accuracy: 0.76 - ETA: 4s - loss: 0.7009 - accuracy: 0.76 - ETA: 3s - loss: 0.7009 - accuracy: 0.76 - ETA: 2s - loss: 0.7005 - accuracy: 0.76 - ETA: 0s - loss: 0.7007 - accuracy: 0.76 - 188s 10ms/step - loss: 0.7015 - accuracy: 0.7656 - val_loss: 1.3607 - val_accuracy: 0.7223\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:34 - loss: 0.7232 - accuracy: 0.73 - ETA: 2:37 - loss: 0.5783 - accuracy: 0.79 - ETA: 2:39 - loss: 0.5709 - accuracy: 0.80 - ETA: 2:42 - loss: 0.6109 - accuracy: 0.79 - ETA: 2:42 - loss: 0.5828 - accuracy: 0.80 - ETA: 2:42 - loss: 0.5788 - accuracy: 0.80 - ETA: 2:40 - loss: 0.5976 - accuracy: 0.80 - ETA: 2:39 - loss: 0.6182 - accuracy: 0.79 - ETA: 2:37 - loss: 0.6205 - accuracy: 0.79 - ETA: 2:35 - loss: 0.6530 - accuracy: 0.78 - ETA: 2:34 - loss: 0.6539 - accuracy: 0.77 - ETA: 2:33 - loss: 0.6801 - accuracy: 0.77 - ETA: 2:31 - loss: 0.6720 - accuracy: 0.77 - ETA: 2:30 - loss: 0.6752 - accuracy: 0.77 - ETA: 2:29 - loss: 0.6812 - accuracy: 0.77 - ETA: 2:28 - loss: 0.6774 - accuracy: 0.77 - ETA: 2:27 - loss: 0.6693 - accuracy: 0.77 - ETA: 2:26 - loss: 0.6803 - accuracy: 0.77 - ETA: 2:25 - loss: 0.6821 - accuracy: 0.77 - ETA: 2:24 - loss: 0.6843 - accuracy: 0.77 - ETA: 2:23 - loss: 0.6801 - accuracy: 0.77 - ETA: 2:22 - loss: 0.6777 - accuracy: 0.77 - ETA: 2:21 - loss: 0.6890 - accuracy: 0.77 - ETA: 2:20 - loss: 0.6826 - accuracy: 0.77 - ETA: 2:19 - loss: 0.6823 - accuracy: 0.77 - ETA: 2:17 - loss: 0.6770 - accuracy: 0.78 - ETA: 2:16 - loss: 0.6777 - accuracy: 0.77 - ETA: 2:15 - loss: 0.6785 - accuracy: 0.77 - ETA: 2:14 - loss: 0.6875 - accuracy: 0.77 - ETA: 2:12 - loss: 0.6858 - accuracy: 0.77 - ETA: 2:11 - loss: 0.6856 - accuracy: 0.77 - ETA: 2:10 - loss: 0.6845 - accuracy: 0.77 - ETA: 2:09 - loss: 0.6862 - accuracy: 0.77 - ETA: 2:08 - loss: 0.6844 - accuracy: 0.77 - ETA: 2:07 - loss: 0.6780 - accuracy: 0.77 - ETA: 2:06 - loss: 0.6759 - accuracy: 0.78 - ETA: 2:05 - loss: 0.6757 - accuracy: 0.78 - ETA: 2:04 - loss: 0.6757 - accuracy: 0.77 - ETA: 2:03 - loss: 0.6734 - accuracy: 0.78 - ETA: 2:02 - loss: 0.6784 - accuracy: 0.77 - ETA: 2:01 - loss: 0.6737 - accuracy: 0.78 - ETA: 2:00 - loss: 0.6741 - accuracy: 0.78 - ETA: 1:58 - loss: 0.6767 - accuracy: 0.77 - ETA: 1:57 - loss: 0.6821 - accuracy: 0.77 - ETA: 1:56 - loss: 0.6814 - accuracy: 0.77 - ETA: 1:55 - loss: 0.6792 - accuracy: 0.77 - ETA: 1:54 - loss: 0.6783 - accuracy: 0.77 - ETA: 1:53 - loss: 0.6833 - accuracy: 0.77 - ETA: 1:52 - loss: 0.6814 - accuracy: 0.77 - ETA: 1:51 - loss: 0.6807 - accuracy: 0.77 - ETA: 1:50 - loss: 0.6792 - accuracy: 0.77 - ETA: 1:48 - loss: 0.6822 - accuracy: 0.77 - ETA: 1:47 - loss: 0.6796 - accuracy: 0.77 - ETA: 1:46 - loss: 0.6793 - accuracy: 0.77 - ETA: 1:45 - loss: 0.6810 - accuracy: 0.77 - ETA: 1:43 - loss: 0.6804 - accuracy: 0.77 - ETA: 1:42 - loss: 0.6825 - accuracy: 0.77 - ETA: 1:40 - loss: 0.6853 - accuracy: 0.77 - ETA: 1:39 - loss: 0.6850 - accuracy: 0.77 - ETA: 1:38 - loss: 0.6869 - accuracy: 0.77 - ETA: 1:36 - loss: 0.6879 - accuracy: 0.77 - ETA: 1:35 - loss: 0.6892 - accuracy: 0.77 - ETA: 1:34 - loss: 0.6866 - accuracy: 0.77 - ETA: 1:32 - loss: 0.6842 - accuracy: 0.77 - ETA: 1:31 - loss: 0.6844 - accuracy: 0.77 - ETA: 1:30 - loss: 0.6842 - accuracy: 0.77 - ETA: 1:28 - loss: 0.6858 - accuracy: 0.77 - ETA: 1:27 - loss: 0.6861 - accuracy: 0.77 - ETA: 1:26 - loss: 0.6874 - accuracy: 0.77 - ETA: 1:25 - loss: 0.6870 - accuracy: 0.77 - ETA: 1:23 - loss: 0.6877 - accuracy: 0.77 - ETA: 1:22 - loss: 0.6881 - accuracy: 0.77 - ETA: 1:21 - loss: 0.6887 - accuracy: 0.77 - ETA: 1:20 - loss: 0.6861 - accuracy: 0.77 - ETA: 1:18 - loss: 0.6834 - accuracy: 0.77 - ETA: 1:17 - loss: 0.6851 - accuracy: 0.77 - ETA: 1:16 - loss: 0.6842 - accuracy: 0.77 - ETA: 1:15 - loss: 0.6842 - accuracy: 0.77 - ETA: 1:14 - loss: 0.6833 - accuracy: 0.77 - ETA: 1:12 - loss: 0.6829 - accuracy: 0.77 - ETA: 1:11 - loss: 0.6820 - accuracy: 0.77 - ETA: 1:10 - loss: 0.6812 - accuracy: 0.77 - ETA: 1:09 - loss: 0.6826 - accuracy: 0.77 - ETA: 1:08 - loss: 0.6835 - accuracy: 0.77 - ETA: 1:07 - loss: 0.6847 - accuracy: 0.77 - ETA: 1:06 - loss: 0.6851 - accuracy: 0.77 - ETA: 1:04 - loss: 0.6859 - accuracy: 0.77 - ETA: 1:03 - loss: 0.6861 - accuracy: 0.77 - ETA: 1:02 - loss: 0.6859 - accuracy: 0.77 - ETA: 1:01 - loss: 0.6856 - accuracy: 0.77 - ETA: 1:00 - loss: 0.6871 - accuracy: 0.77 - ETA: 59s - loss: 0.6857 - accuracy: 0.7753 - ETA: 58s - loss: 0.6834 - accuracy: 0.776 - ETA: 57s - loss: 0.6836 - accuracy: 0.776 - ETA: 56s - loss: 0.6845 - accuracy: 0.776 - ETA: 55s - loss: 0.6859 - accuracy: 0.775 - ETA: 54s - loss: 0.6866 - accuracy: 0.775 - ETA: 52s - loss: 0.6862 - accuracy: 0.775 - ETA: 51s - loss: 0.6871 - accuracy: 0.774 - ETA: 50s - loss: 0.6895 - accuracy: 0.774 - ETA: 49s - loss: 0.6887 - accuracy: 0.774 - ETA: 48s - loss: 0.6881 - accuracy: 0.774 - ETA: 47s - loss: 0.6885 - accuracy: 0.774 - ETA: 46s - loss: 0.6889 - accuracy: 0.774 - ETA: 45s - loss: 0.6889 - accuracy: 0.773 - ETA: 44s - loss: 0.6883 - accuracy: 0.774 - ETA: 43s - loss: 0.6889 - accuracy: 0.774 - ETA: 42s - loss: 0.6879 - accuracy: 0.774 - ETA: 41s - loss: 0.6878 - accuracy: 0.774 - ETA: 40s - loss: 0.6886 - accuracy: 0.774 - ETA: 39s - loss: 0.6908 - accuracy: 0.773 - ETA: 38s - loss: 0.6906 - accuracy: 0.773 - ETA: 37s - loss: 0.6889 - accuracy: 0.773 - ETA: 36s - loss: 0.6881 - accuracy: 0.773 - ETA: 35s - loss: 0.6898 - accuracy: 0.773 - ETA: 34s - loss: 0.6902 - accuracy: 0.773 - ETA: 33s - loss: 0.6906 - accuracy: 0.773 - ETA: 32s - loss: 0.6906 - accuracy: 0.772 - ETA: 31s - loss: 0.6908 - accuracy: 0.772 - ETA: 30s - loss: 0.6919 - accuracy: 0.772 - ETA: 29s - loss: 0.6917 - accuracy: 0.772 - ETA: 28s - loss: 0.6919 - accuracy: 0.772 - ETA: 27s - loss: 0.6916 - accuracy: 0.772 - ETA: 26s - loss: 0.6909 - accuracy: 0.772 - ETA: 25s - loss: 0.6905 - accuracy: 0.773 - ETA: 24s - loss: 0.6902 - accuracy: 0.773 - ETA: 23s - loss: 0.6906 - accuracy: 0.773 - ETA: 22s - loss: 0.6901 - accuracy: 0.773 - ETA: 21s - loss: 0.6906 - accuracy: 0.773 - ETA: 20s - loss: 0.6894 - accuracy: 0.773 - ETA: 19s - loss: 0.6895 - accuracy: 0.773 - ETA: 18s - loss: 0.6889 - accuracy: 0.773 - ETA: 17s - loss: 0.6891 - accuracy: 0.773 - ETA: 16s - loss: 0.6886 - accuracy: 0.773 - ETA: 15s - loss: 0.6895 - accuracy: 0.773 - ETA: 14s - loss: 0.6887 - accuracy: 0.773 - ETA: 13s - loss: 0.6890 - accuracy: 0.773 - ETA: 12s - loss: 0.6880 - accuracy: 0.773 - ETA: 11s - loss: 0.6884 - accuracy: 0.773 - ETA: 10s - loss: 0.6880 - accuracy: 0.773 - ETA: 9s - loss: 0.6878 - accuracy: 0.773 - ETA: 8s - loss: 0.6886 - accuracy: 0.77 - ETA: 7s - loss: 0.6879 - accuracy: 0.77 - ETA: 6s - loss: 0.6900 - accuracy: 0.77 - ETA: 5s - loss: 0.6905 - accuracy: 0.77 - ETA: 4s - loss: 0.6906 - accuracy: 0.77 - ETA: 3s - loss: 0.6907 - accuracy: 0.77 - ETA: 2s - loss: 0.6897 - accuracy: 0.77 - ETA: 1s - loss: 0.6897 - accuracy: 0.77 - ETA: 0s - loss: 0.6891 - accuracy: 0.77 - 157s 8ms/step - loss: 0.6891 - accuracy: 0.7734 - val_loss: 1.3707 - val_accuracy: 0.7188\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:24 - loss: 0.7252 - accuracy: 0.75 - ETA: 2:14 - loss: 0.6008 - accuracy: 0.80 - ETA: 2:13 - loss: 0.6409 - accuracy: 0.79 - ETA: 2:11 - loss: 0.6749 - accuracy: 0.78 - ETA: 2:11 - loss: 0.7031 - accuracy: 0.77 - ETA: 2:10 - loss: 0.7168 - accuracy: 0.77 - ETA: 2:10 - loss: 0.7165 - accuracy: 0.77 - ETA: 2:10 - loss: 0.7100 - accuracy: 0.77 - ETA: 2:09 - loss: 0.6976 - accuracy: 0.78 - ETA: 2:07 - loss: 0.6910 - accuracy: 0.78 - ETA: 2:05 - loss: 0.6848 - accuracy: 0.78 - ETA: 2:04 - loss: 0.6787 - accuracy: 0.78 - ETA: 2:03 - loss: 0.6895 - accuracy: 0.77 - ETA: 2:01 - loss: 0.6960 - accuracy: 0.77 - ETA: 2:01 - loss: 0.6867 - accuracy: 0.77 - ETA: 2:00 - loss: 0.6835 - accuracy: 0.77 - ETA: 2:00 - loss: 0.6815 - accuracy: 0.77 - ETA: 1:59 - loss: 0.6727 - accuracy: 0.78 - ETA: 1:58 - loss: 0.6708 - accuracy: 0.78 - ETA: 1:57 - loss: 0.6719 - accuracy: 0.78 - ETA: 1:56 - loss: 0.6652 - accuracy: 0.78 - ETA: 1:56 - loss: 0.6558 - accuracy: 0.78 - ETA: 1:55 - loss: 0.6496 - accuracy: 0.78 - ETA: 1:53 - loss: 0.6504 - accuracy: 0.78 - ETA: 1:53 - loss: 0.6490 - accuracy: 0.78 - ETA: 1:52 - loss: 0.6521 - accuracy: 0.78 - ETA: 1:51 - loss: 0.6494 - accuracy: 0.78 - ETA: 1:50 - loss: 0.6568 - accuracy: 0.78 - ETA: 1:49 - loss: 0.6569 - accuracy: 0.78 - ETA: 1:48 - loss: 0.6544 - accuracy: 0.78 - ETA: 1:48 - loss: 0.6516 - accuracy: 0.78 - ETA: 1:47 - loss: 0.6498 - accuracy: 0.78 - ETA: 1:46 - loss: 0.6490 - accuracy: 0.78 - ETA: 1:45 - loss: 0.6528 - accuracy: 0.78 - ETA: 1:44 - loss: 0.6536 - accuracy: 0.78 - ETA: 1:43 - loss: 0.6569 - accuracy: 0.78 - ETA: 1:42 - loss: 0.6583 - accuracy: 0.78 - ETA: 1:41 - loss: 0.6569 - accuracy: 0.78 - ETA: 1:40 - loss: 0.6575 - accuracy: 0.78 - ETA: 1:39 - loss: 0.6544 - accuracy: 0.78 - ETA: 1:38 - loss: 0.6551 - accuracy: 0.78 - ETA: 1:37 - loss: 0.6548 - accuracy: 0.77 - ETA: 1:36 - loss: 0.6545 - accuracy: 0.78 - ETA: 1:36 - loss: 0.6524 - accuracy: 0.78 - ETA: 1:35 - loss: 0.6489 - accuracy: 0.78 - ETA: 1:34 - loss: 0.6532 - accuracy: 0.78 - ETA: 1:33 - loss: 0.6526 - accuracy: 0.78 - ETA: 1:32 - loss: 0.6532 - accuracy: 0.78 - ETA: 1:31 - loss: 0.6535 - accuracy: 0.78 - ETA: 1:30 - loss: 0.6534 - accuracy: 0.78 - ETA: 1:29 - loss: 0.6524 - accuracy: 0.78 - ETA: 1:28 - loss: 0.6493 - accuracy: 0.78 - ETA: 1:27 - loss: 0.6483 - accuracy: 0.78 - ETA: 1:26 - loss: 0.6486 - accuracy: 0.78 - ETA: 1:25 - loss: 0.6462 - accuracy: 0.78 - ETA: 1:24 - loss: 0.6465 - accuracy: 0.78 - ETA: 1:23 - loss: 0.6481 - accuracy: 0.78 - ETA: 1:22 - loss: 0.6458 - accuracy: 0.78 - ETA: 1:22 - loss: 0.6469 - accuracy: 0.78 - ETA: 1:21 - loss: 0.6476 - accuracy: 0.78 - ETA: 1:20 - loss: 0.6461 - accuracy: 0.78 - ETA: 1:19 - loss: 0.6457 - accuracy: 0.78 - ETA: 1:18 - loss: 0.6471 - accuracy: 0.78 - ETA: 1:17 - loss: 0.6464 - accuracy: 0.78 - ETA: 1:16 - loss: 0.6491 - accuracy: 0.78 - ETA: 1:15 - loss: 0.6483 - accuracy: 0.78 - ETA: 1:14 - loss: 0.6509 - accuracy: 0.78 - ETA: 1:14 - loss: 0.6527 - accuracy: 0.78 - ETA: 1:13 - loss: 0.6509 - accuracy: 0.78 - ETA: 1:12 - loss: 0.6516 - accuracy: 0.78 - ETA: 1:11 - loss: 0.6540 - accuracy: 0.78 - ETA: 1:10 - loss: 0.6531 - accuracy: 0.78 - ETA: 1:09 - loss: 0.6539 - accuracy: 0.78 - ETA: 1:08 - loss: 0.6524 - accuracy: 0.78 - ETA: 1:07 - loss: 0.6518 - accuracy: 0.78 - ETA: 1:06 - loss: 0.6532 - accuracy: 0.78 - ETA: 1:05 - loss: 0.6523 - accuracy: 0.78 - ETA: 1:05 - loss: 0.6523 - accuracy: 0.78 - ETA: 1:04 - loss: 0.6504 - accuracy: 0.78 - ETA: 1:03 - loss: 0.6528 - accuracy: 0.78 - ETA: 1:02 - loss: 0.6519 - accuracy: 0.78 - ETA: 1:01 - loss: 0.6530 - accuracy: 0.78 - ETA: 1:00 - loss: 0.6538 - accuracy: 0.77 - ETA: 59s - loss: 0.6535 - accuracy: 0.7800 - ETA: 59s - loss: 0.6547 - accuracy: 0.779 - ETA: 58s - loss: 0.6553 - accuracy: 0.779 - ETA: 57s - loss: 0.6569 - accuracy: 0.778 - ETA: 56s - loss: 0.6575 - accuracy: 0.778 - ETA: 55s - loss: 0.6573 - accuracy: 0.778 - ETA: 54s - loss: 0.6576 - accuracy: 0.778 - ETA: 53s - loss: 0.6566 - accuracy: 0.778 - ETA: 53s - loss: 0.6546 - accuracy: 0.778 - ETA: 52s - loss: 0.6591 - accuracy: 0.777 - ETA: 51s - loss: 0.6573 - accuracy: 0.778 - ETA: 50s - loss: 0.6588 - accuracy: 0.777 - ETA: 49s - loss: 0.6593 - accuracy: 0.777 - ETA: 48s - loss: 0.6592 - accuracy: 0.777 - ETA: 47s - loss: 0.6596 - accuracy: 0.777 - ETA: 47s - loss: 0.6601 - accuracy: 0.777 - ETA: 46s - loss: 0.6615 - accuracy: 0.777 - ETA: 45s - loss: 0.6603 - accuracy: 0.777 - ETA: 44s - loss: 0.6594 - accuracy: 0.777 - ETA: 43s - loss: 0.6584 - accuracy: 0.778 - ETA: 42s - loss: 0.6579 - accuracy: 0.778 - ETA: 41s - loss: 0.6571 - accuracy: 0.778 - ETA: 40s - loss: 0.6566 - accuracy: 0.778 - ETA: 40s - loss: 0.6558 - accuracy: 0.779 - ETA: 39s - loss: 0.6571 - accuracy: 0.778 - ETA: 38s - loss: 0.6583 - accuracy: 0.778 - ETA: 37s - loss: 0.6577 - accuracy: 0.778 - ETA: 36s - loss: 0.6580 - accuracy: 0.778 - ETA: 35s - loss: 0.6564 - accuracy: 0.778 - ETA: 34s - loss: 0.6550 - accuracy: 0.779 - ETA: 33s - loss: 0.6551 - accuracy: 0.779 - ETA: 32s - loss: 0.6562 - accuracy: 0.778 - ETA: 31s - loss: 0.6558 - accuracy: 0.779 - ETA: 31s - loss: 0.6542 - accuracy: 0.779 - ETA: 30s - loss: 0.6553 - accuracy: 0.779 - ETA: 29s - loss: 0.6548 - accuracy: 0.779 - ETA: 28s - loss: 0.6546 - accuracy: 0.779 - ETA: 27s - loss: 0.6552 - accuracy: 0.778 - ETA: 26s - loss: 0.6548 - accuracy: 0.778 - ETA: 25s - loss: 0.6551 - accuracy: 0.778 - ETA: 24s - loss: 0.6531 - accuracy: 0.779 - ETA: 23s - loss: 0.6519 - accuracy: 0.779 - ETA: 22s - loss: 0.6513 - accuracy: 0.779 - ETA: 21s - loss: 0.6502 - accuracy: 0.780 - ETA: 20s - loss: 0.6497 - accuracy: 0.780 - ETA: 19s - loss: 0.6498 - accuracy: 0.780 - ETA: 19s - loss: 0.6505 - accuracy: 0.779 - ETA: 18s - loss: 0.6500 - accuracy: 0.780 - ETA: 17s - loss: 0.6494 - accuracy: 0.780 - ETA: 16s - loss: 0.6491 - accuracy: 0.779 - ETA: 15s - loss: 0.6487 - accuracy: 0.779 - ETA: 14s - loss: 0.6483 - accuracy: 0.780 - ETA: 13s - loss: 0.6487 - accuracy: 0.780 - ETA: 12s - loss: 0.6480 - accuracy: 0.780 - ETA: 11s - loss: 0.6488 - accuracy: 0.780 - ETA: 10s - loss: 0.6477 - accuracy: 0.780 - ETA: 9s - loss: 0.6495 - accuracy: 0.780 - ETA: 9s - loss: 0.6488 - accuracy: 0.78 - ETA: 8s - loss: 0.6508 - accuracy: 0.77 - ETA: 7s - loss: 0.6507 - accuracy: 0.77 - ETA: 6s - loss: 0.6518 - accuracy: 0.77 - ETA: 5s - loss: 0.6517 - accuracy: 0.77 - ETA: 4s - loss: 0.6524 - accuracy: 0.77 - ETA: 3s - loss: 0.6517 - accuracy: 0.77 - ETA: 2s - loss: 0.6518 - accuracy: 0.77 - ETA: 1s - loss: 0.6522 - accuracy: 0.77 - ETA: 0s - loss: 0.6526 - accuracy: 0.77 - 149s 8ms/step - loss: 0.6526 - accuracy: 0.7787 - val_loss: 1.3862 - val_accuracy: 0.7225\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:22 - loss: 0.6210 - accuracy: 0.80 - ETA: 2:27 - loss: 0.5475 - accuracy: 0.80 - ETA: 2:24 - loss: 0.6066 - accuracy: 0.78 - ETA: 2:18 - loss: 0.6133 - accuracy: 0.79 - ETA: 2:15 - loss: 0.6152 - accuracy: 0.79 - ETA: 2:14 - loss: 0.6173 - accuracy: 0.79 - ETA: 2:12 - loss: 0.5980 - accuracy: 0.80 - ETA: 2:10 - loss: 0.5870 - accuracy: 0.80 - ETA: 2:10 - loss: 0.5911 - accuracy: 0.80 - ETA: 2:08 - loss: 0.5939 - accuracy: 0.79 - ETA: 2:07 - loss: 0.5916 - accuracy: 0.80 - ETA: 2:06 - loss: 0.5904 - accuracy: 0.80 - ETA: 2:04 - loss: 0.5970 - accuracy: 0.80 - ETA: 2:04 - loss: 0.6042 - accuracy: 0.80 - ETA: 2:04 - loss: 0.6064 - accuracy: 0.80 - ETA: 2:02 - loss: 0.6053 - accuracy: 0.80 - ETA: 2:01 - loss: 0.6145 - accuracy: 0.79 - ETA: 2:00 - loss: 0.6145 - accuracy: 0.79 - ETA: 1:59 - loss: 0.6090 - accuracy: 0.80 - ETA: 1:58 - loss: 0.6153 - accuracy: 0.79 - ETA: 1:57 - loss: 0.6182 - accuracy: 0.79 - ETA: 1:57 - loss: 0.6157 - accuracy: 0.79 - ETA: 1:55 - loss: 0.6131 - accuracy: 0.79 - ETA: 1:55 - loss: 0.6247 - accuracy: 0.79 - ETA: 1:54 - loss: 0.6321 - accuracy: 0.79 - ETA: 1:53 - loss: 0.6245 - accuracy: 0.79 - ETA: 1:52 - loss: 0.6231 - accuracy: 0.79 - ETA: 1:51 - loss: 0.6235 - accuracy: 0.79 - ETA: 1:50 - loss: 0.6228 - accuracy: 0.79 - ETA: 1:49 - loss: 0.6220 - accuracy: 0.79 - ETA: 1:48 - loss: 0.6221 - accuracy: 0.79 - ETA: 1:47 - loss: 0.6226 - accuracy: 0.79 - ETA: 1:46 - loss: 0.6258 - accuracy: 0.79 - ETA: 1:45 - loss: 0.6254 - accuracy: 0.79 - ETA: 1:44 - loss: 0.6235 - accuracy: 0.79 - ETA: 1:43 - loss: 0.6282 - accuracy: 0.79 - ETA: 1:42 - loss: 0.6280 - accuracy: 0.79 - ETA: 1:41 - loss: 0.6216 - accuracy: 0.79 - ETA: 1:40 - loss: 0.6238 - accuracy: 0.79 - ETA: 1:39 - loss: 0.6225 - accuracy: 0.79 - ETA: 1:38 - loss: 0.6242 - accuracy: 0.79 - ETA: 1:37 - loss: 0.6234 - accuracy: 0.79 - ETA: 1:36 - loss: 0.6230 - accuracy: 0.79 - ETA: 1:35 - loss: 0.6214 - accuracy: 0.79 - ETA: 1:34 - loss: 0.6211 - accuracy: 0.79 - ETA: 1:33 - loss: 0.6209 - accuracy: 0.79 - ETA: 1:32 - loss: 0.6234 - accuracy: 0.79 - ETA: 1:31 - loss: 0.6261 - accuracy: 0.79 - ETA: 1:30 - loss: 0.6263 - accuracy: 0.79 - ETA: 1:29 - loss: 0.6298 - accuracy: 0.79 - ETA: 1:28 - loss: 0.6310 - accuracy: 0.79 - ETA: 1:27 - loss: 0.6297 - accuracy: 0.79 - ETA: 1:26 - loss: 0.6328 - accuracy: 0.78 - ETA: 1:26 - loss: 0.6326 - accuracy: 0.78 - ETA: 1:25 - loss: 0.6309 - accuracy: 0.79 - ETA: 1:24 - loss: 0.6284 - accuracy: 0.79 - ETA: 1:23 - loss: 0.6282 - accuracy: 0.79 - ETA: 1:22 - loss: 0.6270 - accuracy: 0.79 - ETA: 1:21 - loss: 0.6271 - accuracy: 0.79 - ETA: 1:20 - loss: 0.6283 - accuracy: 0.79 - ETA: 1:19 - loss: 0.6276 - accuracy: 0.79 - ETA: 1:18 - loss: 0.6249 - accuracy: 0.79 - ETA: 1:17 - loss: 0.6273 - accuracy: 0.79 - ETA: 1:16 - loss: 0.6292 - accuracy: 0.79 - ETA: 1:16 - loss: 0.6279 - accuracy: 0.79 - ETA: 1:15 - loss: 0.6293 - accuracy: 0.79 - ETA: 1:14 - loss: 0.6281 - accuracy: 0.79 - ETA: 1:13 - loss: 0.6245 - accuracy: 0.79 - ETA: 1:12 - loss: 0.6245 - accuracy: 0.79 - ETA: 1:11 - loss: 0.6262 - accuracy: 0.79 - ETA: 1:10 - loss: 0.6282 - accuracy: 0.79 - ETA: 1:09 - loss: 0.6303 - accuracy: 0.79 - ETA: 1:08 - loss: 0.6303 - accuracy: 0.79 - ETA: 1:08 - loss: 0.6288 - accuracy: 0.79 - ETA: 1:07 - loss: 0.6279 - accuracy: 0.79 - ETA: 1:06 - loss: 0.6311 - accuracy: 0.79 - ETA: 1:05 - loss: 0.6296 - accuracy: 0.79 - ETA: 1:04 - loss: 0.6301 - accuracy: 0.79 - ETA: 1:03 - loss: 0.6319 - accuracy: 0.79 - ETA: 1:02 - loss: 0.6326 - accuracy: 0.79 - ETA: 1:01 - loss: 0.6319 - accuracy: 0.79 - ETA: 1:01 - loss: 0.6322 - accuracy: 0.79 - ETA: 1:00 - loss: 0.6337 - accuracy: 0.79 - ETA: 59s - loss: 0.6333 - accuracy: 0.7911 - ETA: 58s - loss: 0.6340 - accuracy: 0.790 - ETA: 57s - loss: 0.6341 - accuracy: 0.791 - ETA: 56s - loss: 0.6340 - accuracy: 0.790 - ETA: 55s - loss: 0.6330 - accuracy: 0.791 - ETA: 54s - loss: 0.6319 - accuracy: 0.791 - ETA: 54s - loss: 0.6321 - accuracy: 0.791 - ETA: 53s - loss: 0.6326 - accuracy: 0.791 - ETA: 52s - loss: 0.6317 - accuracy: 0.791 - ETA: 51s - loss: 0.6318 - accuracy: 0.791 - ETA: 50s - loss: 0.6343 - accuracy: 0.790 - ETA: 49s - loss: 0.6346 - accuracy: 0.790 - ETA: 48s - loss: 0.6341 - accuracy: 0.790 - ETA: 47s - loss: 0.6341 - accuracy: 0.790 - ETA: 47s - loss: 0.6340 - accuracy: 0.790 - ETA: 46s - loss: 0.6334 - accuracy: 0.790 - ETA: 45s - loss: 0.6336 - accuracy: 0.790 - ETA: 44s - loss: 0.6361 - accuracy: 0.789 - ETA: 43s - loss: 0.6367 - accuracy: 0.788 - ETA: 42s - loss: 0.6361 - accuracy: 0.788 - ETA: 41s - loss: 0.6347 - accuracy: 0.789 - ETA: 40s - loss: 0.6343 - accuracy: 0.789 - ETA: 39s - loss: 0.6349 - accuracy: 0.789 - ETA: 39s - loss: 0.6351 - accuracy: 0.789 - ETA: 38s - loss: 0.6334 - accuracy: 0.789 - ETA: 37s - loss: 0.6338 - accuracy: 0.789 - ETA: 36s - loss: 0.6325 - accuracy: 0.790 - ETA: 35s - loss: 0.6331 - accuracy: 0.789 - ETA: 34s - loss: 0.6338 - accuracy: 0.789 - ETA: 33s - loss: 0.6340 - accuracy: 0.789 - ETA: 33s - loss: 0.6334 - accuracy: 0.789 - ETA: 32s - loss: 0.6347 - accuracy: 0.789 - ETA: 31s - loss: 0.6350 - accuracy: 0.789 - ETA: 30s - loss: 0.6336 - accuracy: 0.789 - ETA: 29s - loss: 0.6331 - accuracy: 0.789 - ETA: 28s - loss: 0.6329 - accuracy: 0.789 - ETA: 27s - loss: 0.6329 - accuracy: 0.789 - ETA: 26s - loss: 0.6334 - accuracy: 0.789 - ETA: 25s - loss: 0.6323 - accuracy: 0.789 - ETA: 24s - loss: 0.6316 - accuracy: 0.789 - ETA: 24s - loss: 0.6311 - accuracy: 0.789 - ETA: 23s - loss: 0.6307 - accuracy: 0.790 - ETA: 22s - loss: 0.6314 - accuracy: 0.789 - ETA: 21s - loss: 0.6315 - accuracy: 0.789 - ETA: 20s - loss: 0.6301 - accuracy: 0.790 - ETA: 19s - loss: 0.6310 - accuracy: 0.789 - ETA: 18s - loss: 0.6306 - accuracy: 0.789 - ETA: 17s - loss: 0.6315 - accuracy: 0.789 - ETA: 16s - loss: 0.6314 - accuracy: 0.789 - ETA: 15s - loss: 0.6306 - accuracy: 0.790 - ETA: 15s - loss: 0.6305 - accuracy: 0.790 - ETA: 14s - loss: 0.6290 - accuracy: 0.790 - ETA: 13s - loss: 0.6283 - accuracy: 0.791 - ETA: 12s - loss: 0.6276 - accuracy: 0.791 - ETA: 11s - loss: 0.6284 - accuracy: 0.791 - ETA: 10s - loss: 0.6275 - accuracy: 0.791 - ETA: 9s - loss: 0.6280 - accuracy: 0.790 - ETA: 8s - loss: 0.6280 - accuracy: 0.79 - ETA: 7s - loss: 0.6278 - accuracy: 0.79 - ETA: 7s - loss: 0.6285 - accuracy: 0.79 - ETA: 6s - loss: 0.6288 - accuracy: 0.79 - ETA: 5s - loss: 0.6277 - accuracy: 0.79 - ETA: 4s - loss: 0.6281 - accuracy: 0.79 - ETA: 3s - loss: 0.6276 - accuracy: 0.79 - ETA: 2s - loss: 0.6266 - accuracy: 0.79 - ETA: 1s - loss: 0.6263 - accuracy: 0.79 - ETA: 0s - loss: 0.6256 - accuracy: 0.79 - 146s 8ms/step - loss: 0.6257 - accuracy: 0.7911 - val_loss: 1.4111 - val_accuracy: 0.7267\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:35 - loss: 0.6056 - accuracy: 0.82 - ETA: 2:24 - loss: 0.6140 - accuracy: 0.80 - ETA: 2:17 - loss: 0.6139 - accuracy: 0.80 - ETA: 2:15 - loss: 0.5987 - accuracy: 0.80 - ETA: 2:11 - loss: 0.6099 - accuracy: 0.79 - ETA: 2:08 - loss: 0.6247 - accuracy: 0.78 - ETA: 2:08 - loss: 0.6291 - accuracy: 0.78 - ETA: 2:07 - loss: 0.6148 - accuracy: 0.78 - ETA: 2:05 - loss: 0.6297 - accuracy: 0.78 - ETA: 2:04 - loss: 0.6150 - accuracy: 0.78 - ETA: 2:03 - loss: 0.6268 - accuracy: 0.78 - ETA: 2:01 - loss: 0.6281 - accuracy: 0.78 - ETA: 2:00 - loss: 0.6474 - accuracy: 0.77 - ETA: 1:59 - loss: 0.6420 - accuracy: 0.78 - ETA: 1:58 - loss: 0.6375 - accuracy: 0.78 - ETA: 1:57 - loss: 0.6288 - accuracy: 0.78 - ETA: 1:56 - loss: 0.6188 - accuracy: 0.79 - ETA: 1:55 - loss: 0.6241 - accuracy: 0.79 - ETA: 1:55 - loss: 0.6198 - accuracy: 0.79 - ETA: 1:54 - loss: 0.6102 - accuracy: 0.79 - ETA: 1:53 - loss: 0.6087 - accuracy: 0.79 - ETA: 1:52 - loss: 0.6074 - accuracy: 0.79 - ETA: 1:52 - loss: 0.6108 - accuracy: 0.79 - ETA: 1:51 - loss: 0.6126 - accuracy: 0.79 - ETA: 1:50 - loss: 0.6142 - accuracy: 0.79 - ETA: 1:49 - loss: 0.6123 - accuracy: 0.79 - ETA: 1:48 - loss: 0.6180 - accuracy: 0.79 - ETA: 1:47 - loss: 0.6181 - accuracy: 0.79 - ETA: 1:46 - loss: 0.6193 - accuracy: 0.79 - ETA: 1:45 - loss: 0.6165 - accuracy: 0.79 - ETA: 1:44 - loss: 0.6158 - accuracy: 0.79 - ETA: 1:43 - loss: 0.6166 - accuracy: 0.79 - ETA: 1:42 - loss: 0.6180 - accuracy: 0.79 - ETA: 1:42 - loss: 0.6189 - accuracy: 0.79 - ETA: 1:41 - loss: 0.6192 - accuracy: 0.79 - ETA: 1:41 - loss: 0.6200 - accuracy: 0.79 - ETA: 1:40 - loss: 0.6206 - accuracy: 0.79 - ETA: 1:39 - loss: 0.6206 - accuracy: 0.79 - ETA: 1:39 - loss: 0.6194 - accuracy: 0.79 - ETA: 1:38 - loss: 0.6209 - accuracy: 0.79 - ETA: 1:37 - loss: 0.6201 - accuracy: 0.79 - ETA: 1:36 - loss: 0.6219 - accuracy: 0.79 - ETA: 1:36 - loss: 0.6182 - accuracy: 0.79 - ETA: 1:35 - loss: 0.6173 - accuracy: 0.79 - ETA: 1:34 - loss: 0.6182 - accuracy: 0.79 - ETA: 1:33 - loss: 0.6152 - accuracy: 0.79 - ETA: 1:32 - loss: 0.6154 - accuracy: 0.79 - ETA: 1:31 - loss: 0.6148 - accuracy: 0.79 - ETA: 1:30 - loss: 0.6146 - accuracy: 0.79 - ETA: 1:29 - loss: 0.6143 - accuracy: 0.79 - ETA: 1:28 - loss: 0.6155 - accuracy: 0.79 - ETA: 1:27 - loss: 0.6206 - accuracy: 0.79 - ETA: 1:26 - loss: 0.6222 - accuracy: 0.79 - ETA: 1:25 - loss: 0.6258 - accuracy: 0.78 - ETA: 1:24 - loss: 0.6250 - accuracy: 0.78 - ETA: 1:24 - loss: 0.6237 - accuracy: 0.79 - ETA: 1:23 - loss: 0.6211 - accuracy: 0.79 - ETA: 1:22 - loss: 0.6183 - accuracy: 0.79 - ETA: 1:21 - loss: 0.6165 - accuracy: 0.79 - ETA: 1:20 - loss: 0.6163 - accuracy: 0.79 - ETA: 1:19 - loss: 0.6153 - accuracy: 0.79 - ETA: 1:18 - loss: 0.6165 - accuracy: 0.79 - ETA: 1:17 - loss: 0.6173 - accuracy: 0.79 - ETA: 1:17 - loss: 0.6181 - accuracy: 0.79 - ETA: 1:16 - loss: 0.6170 - accuracy: 0.79 - ETA: 1:15 - loss: 0.6144 - accuracy: 0.79 - ETA: 1:14 - loss: 0.6171 - accuracy: 0.79 - ETA: 1:13 - loss: 0.6176 - accuracy: 0.79 - ETA: 1:12 - loss: 0.6216 - accuracy: 0.79 - ETA: 1:11 - loss: 0.6224 - accuracy: 0.79 - ETA: 1:10 - loss: 0.6218 - accuracy: 0.79 - ETA: 1:10 - loss: 0.6216 - accuracy: 0.79 - ETA: 1:09 - loss: 0.6211 - accuracy: 0.79 - ETA: 1:08 - loss: 0.6207 - accuracy: 0.79 - ETA: 1:07 - loss: 0.6203 - accuracy: 0.79 - ETA: 1:06 - loss: 0.6190 - accuracy: 0.79 - ETA: 1:05 - loss: 0.6204 - accuracy: 0.79 - ETA: 1:04 - loss: 0.6208 - accuracy: 0.79 - ETA: 1:03 - loss: 0.6221 - accuracy: 0.79 - ETA: 1:03 - loss: 0.6203 - accuracy: 0.79 - ETA: 1:02 - loss: 0.6202 - accuracy: 0.79 - ETA: 1:01 - loss: 0.6221 - accuracy: 0.79 - ETA: 1:00 - loss: 0.6211 - accuracy: 0.79 - ETA: 59s - loss: 0.6215 - accuracy: 0.7914 - ETA: 58s - loss: 0.6225 - accuracy: 0.790 - ETA: 57s - loss: 0.6201 - accuracy: 0.791 - ETA: 56s - loss: 0.6199 - accuracy: 0.792 - ETA: 55s - loss: 0.6225 - accuracy: 0.791 - ETA: 54s - loss: 0.6237 - accuracy: 0.790 - ETA: 53s - loss: 0.6225 - accuracy: 0.791 - ETA: 53s - loss: 0.6235 - accuracy: 0.790 - ETA: 52s - loss: 0.6228 - accuracy: 0.791 - ETA: 51s - loss: 0.6224 - accuracy: 0.791 - ETA: 50s - loss: 0.6213 - accuracy: 0.791 - ETA: 49s - loss: 0.6208 - accuracy: 0.791 - ETA: 48s - loss: 0.6198 - accuracy: 0.792 - ETA: 47s - loss: 0.6194 - accuracy: 0.792 - ETA: 46s - loss: 0.6200 - accuracy: 0.791 - ETA: 45s - loss: 0.6208 - accuracy: 0.791 - ETA: 45s - loss: 0.6203 - accuracy: 0.790 - ETA: 44s - loss: 0.6217 - accuracy: 0.790 - ETA: 43s - loss: 0.6193 - accuracy: 0.791 - ETA: 42s - loss: 0.6195 - accuracy: 0.791 - ETA: 41s - loss: 0.6201 - accuracy: 0.791 - ETA: 40s - loss: 0.6201 - accuracy: 0.791 - ETA: 39s - loss: 0.6215 - accuracy: 0.790 - ETA: 38s - loss: 0.6247 - accuracy: 0.789 - ETA: 37s - loss: 0.6233 - accuracy: 0.790 - ETA: 36s - loss: 0.6247 - accuracy: 0.789 - ETA: 36s - loss: 0.6278 - accuracy: 0.788 - ETA: 35s - loss: 0.6282 - accuracy: 0.788 - ETA: 34s - loss: 0.6271 - accuracy: 0.788 - ETA: 33s - loss: 0.6260 - accuracy: 0.789 - ETA: 32s - loss: 0.6261 - accuracy: 0.789 - ETA: 31s - loss: 0.6244 - accuracy: 0.789 - ETA: 30s - loss: 0.6236 - accuracy: 0.789 - ETA: 29s - loss: 0.6224 - accuracy: 0.790 - ETA: 29s - loss: 0.6225 - accuracy: 0.789 - ETA: 28s - loss: 0.6228 - accuracy: 0.790 - ETA: 27s - loss: 0.6214 - accuracy: 0.790 - ETA: 26s - loss: 0.6219 - accuracy: 0.790 - ETA: 25s - loss: 0.6217 - accuracy: 0.790 - ETA: 24s - loss: 0.6215 - accuracy: 0.790 - ETA: 23s - loss: 0.6205 - accuracy: 0.790 - ETA: 22s - loss: 0.6212 - accuracy: 0.790 - ETA: 21s - loss: 0.6205 - accuracy: 0.790 - ETA: 21s - loss: 0.6213 - accuracy: 0.790 - ETA: 20s - loss: 0.6201 - accuracy: 0.790 - ETA: 19s - loss: 0.6200 - accuracy: 0.790 - ETA: 18s - loss: 0.6196 - accuracy: 0.790 - ETA: 17s - loss: 0.6201 - accuracy: 0.790 - ETA: 16s - loss: 0.6202 - accuracy: 0.790 - ETA: 15s - loss: 0.6211 - accuracy: 0.790 - ETA: 14s - loss: 0.6215 - accuracy: 0.789 - ETA: 14s - loss: 0.6210 - accuracy: 0.790 - ETA: 13s - loss: 0.6204 - accuracy: 0.790 - ETA: 12s - loss: 0.6215 - accuracy: 0.789 - ETA: 11s - loss: 0.6216 - accuracy: 0.789 - ETA: 10s - loss: 0.6207 - accuracy: 0.790 - ETA: 9s - loss: 0.6210 - accuracy: 0.790 - ETA: 8s - loss: 0.6209 - accuracy: 0.79 - ETA: 7s - loss: 0.6208 - accuracy: 0.79 - ETA: 6s - loss: 0.6203 - accuracy: 0.79 - ETA: 6s - loss: 0.6205 - accuracy: 0.79 - ETA: 5s - loss: 0.6214 - accuracy: 0.78 - ETA: 4s - loss: 0.6204 - accuracy: 0.79 - ETA: 3s - loss: 0.6192 - accuracy: 0.79 - ETA: 2s - loss: 0.6193 - accuracy: 0.79 - ETA: 1s - loss: 0.6189 - accuracy: 0.79 - ETA: 0s - loss: 0.6193 - accuracy: 0.79 - 147s 8ms/step - loss: 0.6202 - accuracy: 0.7905 - val_loss: 1.3799 - val_accuracy: 0.7281\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:36 - loss: 0.7569 - accuracy: 0.75 - ETA: 2:30 - loss: 0.6933 - accuracy: 0.76 - ETA: 2:25 - loss: 0.6105 - accuracy: 0.78 - ETA: 2:26 - loss: 0.6345 - accuracy: 0.77 - ETA: 2:25 - loss: 0.6422 - accuracy: 0.77 - ETA: 2:23 - loss: 0.6379 - accuracy: 0.77 - ETA: 2:21 - loss: 0.6140 - accuracy: 0.78 - ETA: 2:20 - loss: 0.6188 - accuracy: 0.78 - ETA: 2:20 - loss: 0.6129 - accuracy: 0.78 - ETA: 2:19 - loss: 0.6046 - accuracy: 0.78 - ETA: 2:17 - loss: 0.6017 - accuracy: 0.78 - ETA: 2:15 - loss: 0.6133 - accuracy: 0.78 - ETA: 2:13 - loss: 0.6137 - accuracy: 0.78 - ETA: 2:13 - loss: 0.6167 - accuracy: 0.78 - ETA: 2:11 - loss: 0.6137 - accuracy: 0.78 - ETA: 2:10 - loss: 0.6039 - accuracy: 0.78 - ETA: 2:08 - loss: 0.6167 - accuracy: 0.78 - ETA: 2:06 - loss: 0.6143 - accuracy: 0.78 - ETA: 2:05 - loss: 0.6094 - accuracy: 0.78 - ETA: 2:04 - loss: 0.6025 - accuracy: 0.78 - ETA: 2:03 - loss: 0.5987 - accuracy: 0.78 - ETA: 2:02 - loss: 0.5970 - accuracy: 0.79 - ETA: 2:01 - loss: 0.5994 - accuracy: 0.79 - ETA: 1:59 - loss: 0.6039 - accuracy: 0.78 - ETA: 1:58 - loss: 0.5996 - accuracy: 0.79 - ETA: 1:57 - loss: 0.5975 - accuracy: 0.79 - ETA: 1:56 - loss: 0.5942 - accuracy: 0.79 - ETA: 1:55 - loss: 0.5927 - accuracy: 0.79 - ETA: 1:54 - loss: 0.5911 - accuracy: 0.79 - ETA: 1:52 - loss: 0.5924 - accuracy: 0.79 - ETA: 1:52 - loss: 0.5940 - accuracy: 0.79 - ETA: 1:51 - loss: 0.5914 - accuracy: 0.79 - ETA: 1:50 - loss: 0.5885 - accuracy: 0.79 - ETA: 1:49 - loss: 0.5832 - accuracy: 0.79 - ETA: 1:48 - loss: 0.5846 - accuracy: 0.79 - ETA: 1:47 - loss: 0.5815 - accuracy: 0.79 - ETA: 1:46 - loss: 0.5834 - accuracy: 0.79 - ETA: 1:45 - loss: 0.5868 - accuracy: 0.79 - ETA: 1:44 - loss: 0.5853 - accuracy: 0.80 - ETA: 1:43 - loss: 0.5807 - accuracy: 0.80 - ETA: 1:42 - loss: 0.5789 - accuracy: 0.80 - ETA: 1:42 - loss: 0.5766 - accuracy: 0.80 - ETA: 1:41 - loss: 0.5838 - accuracy: 0.80 - ETA: 1:40 - loss: 0.5834 - accuracy: 0.80 - ETA: 1:39 - loss: 0.5849 - accuracy: 0.80 - ETA: 1:38 - loss: 0.5827 - accuracy: 0.80 - ETA: 1:37 - loss: 0.5833 - accuracy: 0.80 - ETA: 1:36 - loss: 0.5850 - accuracy: 0.80 - ETA: 1:35 - loss: 0.5836 - accuracy: 0.80 - ETA: 1:34 - loss: 0.5811 - accuracy: 0.80 - ETA: 1:33 - loss: 0.5810 - accuracy: 0.80 - ETA: 1:32 - loss: 0.5832 - accuracy: 0.80 - ETA: 1:31 - loss: 0.5821 - accuracy: 0.80 - ETA: 1:30 - loss: 0.5848 - accuracy: 0.80 - ETA: 1:30 - loss: 0.5859 - accuracy: 0.80 - ETA: 1:29 - loss: 0.5831 - accuracy: 0.80 - ETA: 1:28 - loss: 0.5842 - accuracy: 0.80 - ETA: 1:27 - loss: 0.5857 - accuracy: 0.80 - ETA: 1:26 - loss: 0.5835 - accuracy: 0.80 - ETA: 1:25 - loss: 0.5839 - accuracy: 0.80 - ETA: 1:24 - loss: 0.5871 - accuracy: 0.80 - ETA: 1:23 - loss: 0.5859 - accuracy: 0.80 - ETA: 1:22 - loss: 0.5836 - accuracy: 0.80 - ETA: 1:21 - loss: 0.5823 - accuracy: 0.80 - ETA: 1:20 - loss: 0.5833 - accuracy: 0.80 - ETA: 1:20 - loss: 0.5834 - accuracy: 0.80 - ETA: 1:19 - loss: 0.5855 - accuracy: 0.80 - ETA: 1:18 - loss: 0.5847 - accuracy: 0.80 - ETA: 1:17 - loss: 0.5832 - accuracy: 0.80 - ETA: 1:16 - loss: 0.5838 - accuracy: 0.80 - ETA: 1:15 - loss: 0.5845 - accuracy: 0.80 - ETA: 1:14 - loss: 0.5854 - accuracy: 0.80 - ETA: 1:13 - loss: 0.5870 - accuracy: 0.80 - ETA: 1:12 - loss: 0.5880 - accuracy: 0.80 - ETA: 1:11 - loss: 0.5878 - accuracy: 0.80 - ETA: 1:10 - loss: 0.5894 - accuracy: 0.80 - ETA: 1:09 - loss: 0.5891 - accuracy: 0.80 - ETA: 1:08 - loss: 0.5888 - accuracy: 0.80 - ETA: 1:07 - loss: 0.5884 - accuracy: 0.80 - ETA: 1:06 - loss: 0.5878 - accuracy: 0.80 - ETA: 1:06 - loss: 0.5877 - accuracy: 0.80 - ETA: 1:05 - loss: 0.5890 - accuracy: 0.80 - ETA: 1:04 - loss: 0.5897 - accuracy: 0.80 - ETA: 1:03 - loss: 0.5897 - accuracy: 0.80 - ETA: 1:02 - loss: 0.5887 - accuracy: 0.80 - ETA: 1:01 - loss: 0.5890 - accuracy: 0.80 - ETA: 1:00 - loss: 0.5890 - accuracy: 0.80 - ETA: 59s - loss: 0.5898 - accuracy: 0.8019 - ETA: 58s - loss: 0.5887 - accuracy: 0.802 - ETA: 57s - loss: 0.5898 - accuracy: 0.801 - ETA: 57s - loss: 0.5891 - accuracy: 0.801 - ETA: 56s - loss: 0.5906 - accuracy: 0.801 - ETA: 55s - loss: 0.5894 - accuracy: 0.801 - ETA: 54s - loss: 0.5903 - accuracy: 0.801 - ETA: 53s - loss: 0.5911 - accuracy: 0.801 - ETA: 52s - loss: 0.5897 - accuracy: 0.801 - ETA: 51s - loss: 0.5906 - accuracy: 0.801 - ETA: 50s - loss: 0.5916 - accuracy: 0.800 - ETA: 49s - loss: 0.5897 - accuracy: 0.801 - ETA: 48s - loss: 0.5901 - accuracy: 0.801 - ETA: 47s - loss: 0.5913 - accuracy: 0.800 - ETA: 46s - loss: 0.5918 - accuracy: 0.800 - ETA: 45s - loss: 0.5924 - accuracy: 0.800 - ETA: 44s - loss: 0.5920 - accuracy: 0.800 - ETA: 43s - loss: 0.5920 - accuracy: 0.800 - ETA: 42s - loss: 0.5913 - accuracy: 0.800 - ETA: 41s - loss: 0.5919 - accuracy: 0.800 - ETA: 40s - loss: 0.5914 - accuracy: 0.800 - ETA: 39s - loss: 0.5920 - accuracy: 0.800 - ETA: 38s - loss: 0.5911 - accuracy: 0.800 - ETA: 37s - loss: 0.5916 - accuracy: 0.800 - ETA: 36s - loss: 0.5917 - accuracy: 0.799 - ETA: 35s - loss: 0.5914 - accuracy: 0.799 - ETA: 34s - loss: 0.5910 - accuracy: 0.799 - ETA: 33s - loss: 0.5918 - accuracy: 0.799 - ETA: 32s - loss: 0.5943 - accuracy: 0.798 - ETA: 31s - loss: 0.5944 - accuracy: 0.798 - ETA: 30s - loss: 0.5948 - accuracy: 0.798 - ETA: 30s - loss: 0.5940 - accuracy: 0.798 - ETA: 29s - loss: 0.5950 - accuracy: 0.798 - ETA: 28s - loss: 0.5946 - accuracy: 0.798 - ETA: 27s - loss: 0.5936 - accuracy: 0.798 - ETA: 26s - loss: 0.5950 - accuracy: 0.798 - ETA: 25s - loss: 0.5972 - accuracy: 0.797 - ETA: 24s - loss: 0.5986 - accuracy: 0.796 - ETA: 23s - loss: 0.6002 - accuracy: 0.796 - ETA: 22s - loss: 0.6015 - accuracy: 0.795 - ETA: 21s - loss: 0.6018 - accuracy: 0.795 - ETA: 20s - loss: 0.6015 - accuracy: 0.795 - ETA: 19s - loss: 0.6011 - accuracy: 0.795 - ETA: 18s - loss: 0.6009 - accuracy: 0.796 - ETA: 17s - loss: 0.6025 - accuracy: 0.795 - ETA: 16s - loss: 0.6017 - accuracy: 0.795 - ETA: 15s - loss: 0.6014 - accuracy: 0.795 - ETA: 14s - loss: 0.6015 - accuracy: 0.795 - ETA: 13s - loss: 0.6016 - accuracy: 0.795 - ETA: 12s - loss: 0.6019 - accuracy: 0.795 - ETA: 12s - loss: 0.6004 - accuracy: 0.795 - ETA: 11s - loss: 0.6013 - accuracy: 0.795 - ETA: 10s - loss: 0.6019 - accuracy: 0.795 - ETA: 9s - loss: 0.6015 - accuracy: 0.795 - ETA: 8s - loss: 0.6012 - accuracy: 0.79 - ETA: 7s - loss: 0.6021 - accuracy: 0.79 - ETA: 6s - loss: 0.6032 - accuracy: 0.79 - ETA: 5s - loss: 0.6039 - accuracy: 0.79 - ETA: 4s - loss: 0.6033 - accuracy: 0.79 - ETA: 3s - loss: 0.6036 - accuracy: 0.79 - ETA: 2s - loss: 0.6033 - accuracy: 0.79 - ETA: 1s - loss: 0.6042 - accuracy: 0.79 - ETA: 0s - loss: 0.6042 - accuracy: 0.79 - 152s 8ms/step - loss: 0.6040 - accuracy: 0.7940 - val_loss: 1.4002 - val_accuracy: 0.7302\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:17 - loss: 0.8494 - accuracy: 0.75 - ETA: 2:11 - loss: 0.7894 - accuracy: 0.74 - ETA: 2:10 - loss: 0.7301 - accuracy: 0.76 - ETA: 2:13 - loss: 0.6723 - accuracy: 0.78 - ETA: 2:15 - loss: 0.6825 - accuracy: 0.77 - ETA: 2:14 - loss: 0.6482 - accuracy: 0.78 - ETA: 2:14 - loss: 0.6468 - accuracy: 0.78 - ETA: 2:12 - loss: 0.6456 - accuracy: 0.78 - ETA: 2:11 - loss: 0.6430 - accuracy: 0.78 - ETA: 2:10 - loss: 0.6458 - accuracy: 0.78 - ETA: 2:08 - loss: 0.6456 - accuracy: 0.78 - ETA: 2:07 - loss: 0.6312 - accuracy: 0.79 - ETA: 2:05 - loss: 0.6189 - accuracy: 0.79 - ETA: 2:05 - loss: 0.6144 - accuracy: 0.79 - ETA: 2:04 - loss: 0.6068 - accuracy: 0.79 - ETA: 2:03 - loss: 0.6201 - accuracy: 0.79 - ETA: 2:02 - loss: 0.6106 - accuracy: 0.79 - ETA: 2:01 - loss: 0.6183 - accuracy: 0.79 - ETA: 2:00 - loss: 0.6150 - accuracy: 0.79 - ETA: 1:59 - loss: 0.6091 - accuracy: 0.79 - ETA: 1:58 - loss: 0.6100 - accuracy: 0.79 - ETA: 1:58 - loss: 0.6147 - accuracy: 0.79 - ETA: 1:57 - loss: 0.6195 - accuracy: 0.79 - ETA: 1:57 - loss: 0.6185 - accuracy: 0.79 - ETA: 1:56 - loss: 0.6093 - accuracy: 0.79 - ETA: 1:55 - loss: 0.6107 - accuracy: 0.79 - ETA: 1:54 - loss: 0.6069 - accuracy: 0.79 - ETA: 1:53 - loss: 0.6061 - accuracy: 0.79 - ETA: 1:52 - loss: 0.6064 - accuracy: 0.79 - ETA: 1:51 - loss: 0.6057 - accuracy: 0.79 - ETA: 1:50 - loss: 0.6059 - accuracy: 0.79 - ETA: 1:49 - loss: 0.6011 - accuracy: 0.79 - ETA: 1:48 - loss: 0.6004 - accuracy: 0.79 - ETA: 1:47 - loss: 0.5984 - accuracy: 0.79 - ETA: 1:46 - loss: 0.5970 - accuracy: 0.79 - ETA: 1:45 - loss: 0.5966 - accuracy: 0.79 - ETA: 1:44 - loss: 0.5930 - accuracy: 0.79 - ETA: 1:43 - loss: 0.5917 - accuracy: 0.79 - ETA: 1:42 - loss: 0.5933 - accuracy: 0.79 - ETA: 1:41 - loss: 0.5962 - accuracy: 0.79 - ETA: 1:41 - loss: 0.5945 - accuracy: 0.79 - ETA: 1:40 - loss: 0.5953 - accuracy: 0.79 - ETA: 1:39 - loss: 0.5917 - accuracy: 0.79 - ETA: 1:38 - loss: 0.5940 - accuracy: 0.79 - ETA: 1:37 - loss: 0.5934 - accuracy: 0.79 - ETA: 1:36 - loss: 0.5911 - accuracy: 0.79 - ETA: 1:35 - loss: 0.5918 - accuracy: 0.79 - ETA: 1:34 - loss: 0.5894 - accuracy: 0.79 - ETA: 1:33 - loss: 0.5881 - accuracy: 0.79 - ETA: 1:32 - loss: 0.5900 - accuracy: 0.79 - ETA: 1:31 - loss: 0.5920 - accuracy: 0.79 - ETA: 1:30 - loss: 0.5924 - accuracy: 0.79 - ETA: 1:29 - loss: 0.5915 - accuracy: 0.79 - ETA: 1:28 - loss: 0.5908 - accuracy: 0.79 - ETA: 1:27 - loss: 0.5907 - accuracy: 0.79 - ETA: 1:26 - loss: 0.5901 - accuracy: 0.79 - ETA: 1:25 - loss: 0.5880 - accuracy: 0.79 - ETA: 1:25 - loss: 0.5848 - accuracy: 0.79 - ETA: 1:24 - loss: 0.5874 - accuracy: 0.79 - ETA: 1:23 - loss: 0.5901 - accuracy: 0.79 - ETA: 1:22 - loss: 0.5905 - accuracy: 0.79 - ETA: 1:21 - loss: 0.5885 - accuracy: 0.79 - ETA: 1:20 - loss: 0.5868 - accuracy: 0.79 - ETA: 1:19 - loss: 0.5867 - accuracy: 0.79 - ETA: 1:18 - loss: 0.5854 - accuracy: 0.79 - ETA: 1:17 - loss: 0.5861 - accuracy: 0.79 - ETA: 1:16 - loss: 0.5862 - accuracy: 0.79 - ETA: 1:15 - loss: 0.5873 - accuracy: 0.79 - ETA: 1:14 - loss: 0.5863 - accuracy: 0.79 - ETA: 1:13 - loss: 0.5873 - accuracy: 0.79 - ETA: 1:12 - loss: 0.5888 - accuracy: 0.79 - ETA: 1:11 - loss: 0.5879 - accuracy: 0.79 - ETA: 1:10 - loss: 0.5868 - accuracy: 0.79 - ETA: 1:09 - loss: 0.5854 - accuracy: 0.79 - ETA: 1:09 - loss: 0.5847 - accuracy: 0.79 - ETA: 1:08 - loss: 0.5851 - accuracy: 0.79 - ETA: 1:07 - loss: 0.5847 - accuracy: 0.79 - ETA: 1:06 - loss: 0.5858 - accuracy: 0.79 - ETA: 1:05 - loss: 0.5854 - accuracy: 0.79 - ETA: 1:05 - loss: 0.5832 - accuracy: 0.79 - ETA: 1:04 - loss: 0.5843 - accuracy: 0.79 - ETA: 1:03 - loss: 0.5856 - accuracy: 0.79 - ETA: 1:02 - loss: 0.5838 - accuracy: 0.79 - ETA: 1:01 - loss: 0.5822 - accuracy: 0.79 - ETA: 1:00 - loss: 0.5810 - accuracy: 0.79 - ETA: 59s - loss: 0.5830 - accuracy: 0.7993 - ETA: 58s - loss: 0.5838 - accuracy: 0.799 - ETA: 58s - loss: 0.5846 - accuracy: 0.798 - ETA: 57s - loss: 0.5824 - accuracy: 0.799 - ETA: 56s - loss: 0.5831 - accuracy: 0.799 - ETA: 55s - loss: 0.5830 - accuracy: 0.799 - ETA: 54s - loss: 0.5828 - accuracy: 0.799 - ETA: 53s - loss: 0.5829 - accuracy: 0.799 - ETA: 52s - loss: 0.5829 - accuracy: 0.799 - ETA: 51s - loss: 0.5845 - accuracy: 0.798 - ETA: 50s - loss: 0.5834 - accuracy: 0.799 - ETA: 49s - loss: 0.5839 - accuracy: 0.799 - ETA: 48s - loss: 0.5828 - accuracy: 0.799 - ETA: 47s - loss: 0.5812 - accuracy: 0.799 - ETA: 46s - loss: 0.5793 - accuracy: 0.800 - ETA: 45s - loss: 0.5814 - accuracy: 0.799 - ETA: 44s - loss: 0.5830 - accuracy: 0.799 - ETA: 44s - loss: 0.5841 - accuracy: 0.798 - ETA: 43s - loss: 0.5856 - accuracy: 0.798 - ETA: 42s - loss: 0.5850 - accuracy: 0.798 - ETA: 41s - loss: 0.5841 - accuracy: 0.798 - ETA: 40s - loss: 0.5845 - accuracy: 0.798 - ETA: 39s - loss: 0.5847 - accuracy: 0.798 - ETA: 38s - loss: 0.5859 - accuracy: 0.797 - ETA: 37s - loss: 0.5853 - accuracy: 0.797 - ETA: 36s - loss: 0.5861 - accuracy: 0.797 - ETA: 35s - loss: 0.5867 - accuracy: 0.797 - ETA: 34s - loss: 0.5858 - accuracy: 0.797 - ETA: 33s - loss: 0.5855 - accuracy: 0.797 - ETA: 32s - loss: 0.5858 - accuracy: 0.797 - ETA: 31s - loss: 0.5861 - accuracy: 0.796 - ETA: 30s - loss: 0.5855 - accuracy: 0.797 - ETA: 30s - loss: 0.5865 - accuracy: 0.796 - ETA: 29s - loss: 0.5862 - accuracy: 0.797 - ETA: 28s - loss: 0.5862 - accuracy: 0.797 - ETA: 27s - loss: 0.5873 - accuracy: 0.797 - ETA: 26s - loss: 0.5876 - accuracy: 0.797 - ETA: 25s - loss: 0.5876 - accuracy: 0.797 - ETA: 24s - loss: 0.5883 - accuracy: 0.796 - ETA: 23s - loss: 0.5876 - accuracy: 0.797 - ETA: 22s - loss: 0.5872 - accuracy: 0.797 - ETA: 21s - loss: 0.5870 - accuracy: 0.797 - ETA: 20s - loss: 0.5862 - accuracy: 0.797 - ETA: 19s - loss: 0.5870 - accuracy: 0.797 - ETA: 19s - loss: 0.5861 - accuracy: 0.797 - ETA: 18s - loss: 0.5842 - accuracy: 0.798 - ETA: 17s - loss: 0.5839 - accuracy: 0.798 - ETA: 16s - loss: 0.5851 - accuracy: 0.798 - ETA: 15s - loss: 0.5850 - accuracy: 0.798 - ETA: 14s - loss: 0.5845 - accuracy: 0.798 - ETA: 13s - loss: 0.5842 - accuracy: 0.798 - ETA: 12s - loss: 0.5849 - accuracy: 0.798 - ETA: 11s - loss: 0.5847 - accuracy: 0.798 - ETA: 10s - loss: 0.5843 - accuracy: 0.798 - ETA: 9s - loss: 0.5849 - accuracy: 0.798 - ETA: 8s - loss: 0.5839 - accuracy: 0.79 - ETA: 8s - loss: 0.5837 - accuracy: 0.79 - ETA: 7s - loss: 0.5838 - accuracy: 0.79 - ETA: 6s - loss: 0.5835 - accuracy: 0.79 - ETA: 5s - loss: 0.5826 - accuracy: 0.79 - ETA: 4s - loss: 0.5814 - accuracy: 0.80 - ETA: 3s - loss: 0.5806 - accuracy: 0.80 - ETA: 2s - loss: 0.5804 - accuracy: 0.80 - ETA: 1s - loss: 0.5794 - accuracy: 0.80 - ETA: 0s - loss: 0.5799 - accuracy: 0.80 - 149s 8ms/step - loss: 0.5797 - accuracy: 0.8017 - val_loss: 1.4179 - val_accuracy: 0.7258\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:33 - loss: 0.7295 - accuracy: 0.76 - ETA: 2:24 - loss: 0.6846 - accuracy: 0.78 - ETA: 2:16 - loss: 0.6318 - accuracy: 0.79 - ETA: 2:13 - loss: 0.6737 - accuracy: 0.78 - ETA: 2:09 - loss: 0.6519 - accuracy: 0.79 - ETA: 2:08 - loss: 0.6346 - accuracy: 0.79 - ETA: 2:06 - loss: 0.6330 - accuracy: 0.79 - ETA: 2:05 - loss: 0.6211 - accuracy: 0.80 - ETA: 2:05 - loss: 0.6131 - accuracy: 0.80 - ETA: 2:06 - loss: 0.5984 - accuracy: 0.80 - ETA: 2:06 - loss: 0.5996 - accuracy: 0.80 - ETA: 2:06 - loss: 0.6003 - accuracy: 0.80 - ETA: 2:05 - loss: 0.5927 - accuracy: 0.80 - ETA: 2:05 - loss: 0.5811 - accuracy: 0.80 - ETA: 2:05 - loss: 0.5755 - accuracy: 0.80 - ETA: 2:04 - loss: 0.5795 - accuracy: 0.80 - ETA: 2:03 - loss: 0.5844 - accuracy: 0.80 - ETA: 2:03 - loss: 0.5804 - accuracy: 0.80 - ETA: 2:02 - loss: 0.5768 - accuracy: 0.80 - ETA: 2:01 - loss: 0.5802 - accuracy: 0.80 - ETA: 2:01 - loss: 0.5817 - accuracy: 0.80 - ETA: 1:59 - loss: 0.5820 - accuracy: 0.80 - ETA: 1:58 - loss: 0.5785 - accuracy: 0.80 - ETA: 1:57 - loss: 0.5742 - accuracy: 0.80 - ETA: 1:56 - loss: 0.5684 - accuracy: 0.80 - ETA: 1:55 - loss: 0.5625 - accuracy: 0.80 - ETA: 1:54 - loss: 0.5578 - accuracy: 0.81 - ETA: 1:54 - loss: 0.5570 - accuracy: 0.81 - ETA: 1:53 - loss: 0.5563 - accuracy: 0.81 - ETA: 1:53 - loss: 0.5618 - accuracy: 0.81 - ETA: 1:52 - loss: 0.5588 - accuracy: 0.81 - ETA: 1:51 - loss: 0.5533 - accuracy: 0.81 - ETA: 1:50 - loss: 0.5521 - accuracy: 0.81 - ETA: 1:49 - loss: 0.5501 - accuracy: 0.81 - ETA: 1:48 - loss: 0.5513 - accuracy: 0.81 - ETA: 1:47 - loss: 0.5507 - accuracy: 0.81 - ETA: 1:46 - loss: 0.5489 - accuracy: 0.81 - ETA: 1:45 - loss: 0.5477 - accuracy: 0.81 - ETA: 1:44 - loss: 0.5454 - accuracy: 0.81 - ETA: 1:43 - loss: 0.5467 - accuracy: 0.81 - ETA: 1:42 - loss: 0.5477 - accuracy: 0.81 - ETA: 1:41 - loss: 0.5484 - accuracy: 0.81 - ETA: 1:40 - loss: 0.5483 - accuracy: 0.81 - ETA: 1:39 - loss: 0.5457 - accuracy: 0.81 - ETA: 1:38 - loss: 0.5480 - accuracy: 0.81 - ETA: 1:37 - loss: 0.5487 - accuracy: 0.81 - ETA: 1:36 - loss: 0.5469 - accuracy: 0.81 - ETA: 1:35 - loss: 0.5476 - accuracy: 0.81 - ETA: 1:34 - loss: 0.5488 - accuracy: 0.81 - ETA: 1:34 - loss: 0.5470 - accuracy: 0.81 - ETA: 1:34 - loss: 0.5494 - accuracy: 0.81 - ETA: 1:35 - loss: 0.5532 - accuracy: 0.81 - ETA: 1:34 - loss: 0.5527 - accuracy: 0.81 - ETA: 1:33 - loss: 0.5511 - accuracy: 0.81 - ETA: 1:32 - loss: 0.5522 - accuracy: 0.81 - ETA: 1:31 - loss: 0.5501 - accuracy: 0.81 - ETA: 1:30 - loss: 0.5487 - accuracy: 0.81 - ETA: 1:29 - loss: 0.5490 - accuracy: 0.81 - ETA: 1:28 - loss: 0.5486 - accuracy: 0.81 - ETA: 1:27 - loss: 0.5478 - accuracy: 0.81 - ETA: 1:26 - loss: 0.5461 - accuracy: 0.81 - ETA: 1:25 - loss: 0.5445 - accuracy: 0.81 - ETA: 1:24 - loss: 0.5472 - accuracy: 0.81 - ETA: 1:23 - loss: 0.5474 - accuracy: 0.81 - ETA: 1:22 - loss: 0.5461 - accuracy: 0.81 - ETA: 1:21 - loss: 0.5451 - accuracy: 0.81 - ETA: 1:20 - loss: 0.5489 - accuracy: 0.81 - ETA: 1:19 - loss: 0.5481 - accuracy: 0.81 - ETA: 1:19 - loss: 0.5484 - accuracy: 0.81 - ETA: 1:20 - loss: 0.5479 - accuracy: 0.81 - ETA: 1:20 - loss: 0.5472 - accuracy: 0.81 - ETA: 1:19 - loss: 0.5479 - accuracy: 0.81 - ETA: 1:19 - loss: 0.5497 - accuracy: 0.81 - ETA: 1:18 - loss: 0.5537 - accuracy: 0.81 - ETA: 1:17 - loss: 0.5553 - accuracy: 0.81 - ETA: 1:17 - loss: 0.5554 - accuracy: 0.81 - ETA: 1:16 - loss: 0.5557 - accuracy: 0.81 - ETA: 1:15 - loss: 0.5570 - accuracy: 0.81 - ETA: 1:14 - loss: 0.5548 - accuracy: 0.81 - ETA: 1:13 - loss: 0.5547 - accuracy: 0.81 - ETA: 1:12 - loss: 0.5548 - accuracy: 0.81 - ETA: 1:11 - loss: 0.5546 - accuracy: 0.81 - ETA: 1:10 - loss: 0.5549 - accuracy: 0.81 - ETA: 1:09 - loss: 0.5580 - accuracy: 0.81 - ETA: 1:08 - loss: 0.5569 - accuracy: 0.81 - ETA: 1:06 - loss: 0.5585 - accuracy: 0.81 - ETA: 1:05 - loss: 0.5588 - accuracy: 0.80 - ETA: 1:04 - loss: 0.5584 - accuracy: 0.80 - ETA: 1:03 - loss: 0.5586 - accuracy: 0.80 - ETA: 1:02 - loss: 0.5610 - accuracy: 0.80 - ETA: 1:01 - loss: 0.5613 - accuracy: 0.80 - ETA: 1:00 - loss: 0.5602 - accuracy: 0.80 - ETA: 59s - loss: 0.5606 - accuracy: 0.8087 - ETA: 58s - loss: 0.5614 - accuracy: 0.808 - ETA: 57s - loss: 0.5617 - accuracy: 0.808 - ETA: 56s - loss: 0.5611 - accuracy: 0.808 - ETA: 55s - loss: 0.5597 - accuracy: 0.808 - ETA: 54s - loss: 0.5597 - accuracy: 0.808 - ETA: 53s - loss: 0.5585 - accuracy: 0.809 - ETA: 52s - loss: 0.5583 - accuracy: 0.808 - ETA: 51s - loss: 0.5588 - accuracy: 0.808 - ETA: 50s - loss: 0.5594 - accuracy: 0.808 - ETA: 49s - loss: 0.5599 - accuracy: 0.808 - ETA: 48s - loss: 0.5600 - accuracy: 0.808 - ETA: 47s - loss: 0.5590 - accuracy: 0.808 - ETA: 46s - loss: 0.5590 - accuracy: 0.808 - ETA: 45s - loss: 0.5582 - accuracy: 0.808 - ETA: 44s - loss: 0.5582 - accuracy: 0.808 - ETA: 43s - loss: 0.5587 - accuracy: 0.808 - ETA: 42s - loss: 0.5580 - accuracy: 0.808 - ETA: 41s - loss: 0.5573 - accuracy: 0.809 - ETA: 40s - loss: 0.5575 - accuracy: 0.809 - ETA: 39s - loss: 0.5585 - accuracy: 0.808 - ETA: 38s - loss: 0.5580 - accuracy: 0.809 - ETA: 37s - loss: 0.5573 - accuracy: 0.809 - ETA: 36s - loss: 0.5575 - accuracy: 0.809 - ETA: 35s - loss: 0.5570 - accuracy: 0.809 - ETA: 33s - loss: 0.5567 - accuracy: 0.809 - ETA: 32s - loss: 0.5577 - accuracy: 0.809 - ETA: 31s - loss: 0.5567 - accuracy: 0.809 - ETA: 30s - loss: 0.5575 - accuracy: 0.809 - ETA: 29s - loss: 0.5576 - accuracy: 0.809 - ETA: 28s - loss: 0.5573 - accuracy: 0.809 - ETA: 27s - loss: 0.5576 - accuracy: 0.808 - ETA: 26s - loss: 0.5580 - accuracy: 0.808 - ETA: 25s - loss: 0.5575 - accuracy: 0.808 - ETA: 24s - loss: 0.5577 - accuracy: 0.808 - ETA: 23s - loss: 0.5566 - accuracy: 0.809 - ETA: 22s - loss: 0.5563 - accuracy: 0.808 - ETA: 21s - loss: 0.5561 - accuracy: 0.809 - ETA: 20s - loss: 0.5568 - accuracy: 0.808 - ETA: 19s - loss: 0.5558 - accuracy: 0.808 - ETA: 18s - loss: 0.5542 - accuracy: 0.809 - ETA: 17s - loss: 0.5551 - accuracy: 0.809 - ETA: 16s - loss: 0.5550 - accuracy: 0.809 - ETA: 15s - loss: 0.5561 - accuracy: 0.808 - ETA: 14s - loss: 0.5568 - accuracy: 0.808 - ETA: 13s - loss: 0.5557 - accuracy: 0.809 - ETA: 12s - loss: 0.5550 - accuracy: 0.809 - ETA: 11s - loss: 0.5551 - accuracy: 0.809 - ETA: 10s - loss: 0.5547 - accuracy: 0.809 - ETA: 9s - loss: 0.5537 - accuracy: 0.809 - ETA: 8s - loss: 0.5538 - accuracy: 0.80 - ETA: 7s - loss: 0.5528 - accuracy: 0.80 - ETA: 6s - loss: 0.5523 - accuracy: 0.81 - ETA: 5s - loss: 0.5528 - accuracy: 0.81 - ETA: 3s - loss: 0.5544 - accuracy: 0.80 - ETA: 2s - loss: 0.5538 - accuracy: 0.81 - ETA: 1s - loss: 0.5543 - accuracy: 0.80 - ETA: 0s - loss: 0.5546 - accuracy: 0.80 - 171s 9ms/step - loss: 0.5558 - accuracy: 0.8096 - val_loss: 1.4001 - val_accuracy: 0.7322\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:36 - loss: 0.4456 - accuracy: 0.85 - ETA: 2:31 - loss: 0.5234 - accuracy: 0.81 - ETA: 2:29 - loss: 0.5133 - accuracy: 0.81 - ETA: 2:28 - loss: 0.4996 - accuracy: 0.82 - ETA: 2:27 - loss: 0.5396 - accuracy: 0.80 - ETA: 2:22 - loss: 0.5355 - accuracy: 0.80 - ETA: 2:20 - loss: 0.5512 - accuracy: 0.80 - ETA: 2:17 - loss: 0.5471 - accuracy: 0.80 - ETA: 2:16 - loss: 0.5420 - accuracy: 0.81 - ETA: 2:16 - loss: 0.5544 - accuracy: 0.80 - ETA: 2:17 - loss: 0.5577 - accuracy: 0.80 - ETA: 2:17 - loss: 0.5549 - accuracy: 0.80 - ETA: 2:19 - loss: 0.5538 - accuracy: 0.80 - ETA: 2:19 - loss: 0.5641 - accuracy: 0.80 - ETA: 2:17 - loss: 0.5648 - accuracy: 0.80 - ETA: 2:16 - loss: 0.5589 - accuracy: 0.80 - ETA: 2:16 - loss: 0.5608 - accuracy: 0.80 - ETA: 2:15 - loss: 0.5617 - accuracy: 0.80 - ETA: 2:14 - loss: 0.5523 - accuracy: 0.80 - ETA: 2:14 - loss: 0.5510 - accuracy: 0.80 - ETA: 2:13 - loss: 0.5480 - accuracy: 0.81 - ETA: 2:12 - loss: 0.5545 - accuracy: 0.80 - ETA: 2:11 - loss: 0.5612 - accuracy: 0.80 - ETA: 2:10 - loss: 0.5654 - accuracy: 0.80 - ETA: 2:09 - loss: 0.5637 - accuracy: 0.80 - ETA: 2:08 - loss: 0.5655 - accuracy: 0.80 - ETA: 2:08 - loss: 0.5649 - accuracy: 0.80 - ETA: 2:07 - loss: 0.5668 - accuracy: 0.80 - ETA: 2:05 - loss: 0.5722 - accuracy: 0.80 - ETA: 2:04 - loss: 0.5674 - accuracy: 0.80 - ETA: 2:03 - loss: 0.5636 - accuracy: 0.80 - ETA: 2:01 - loss: 0.5594 - accuracy: 0.80 - ETA: 2:00 - loss: 0.5583 - accuracy: 0.80 - ETA: 1:59 - loss: 0.5570 - accuracy: 0.80 - ETA: 1:57 - loss: 0.5553 - accuracy: 0.80 - ETA: 1:56 - loss: 0.5504 - accuracy: 0.80 - ETA: 1:55 - loss: 0.5523 - accuracy: 0.80 - ETA: 1:54 - loss: 0.5521 - accuracy: 0.80 - ETA: 1:53 - loss: 0.5509 - accuracy: 0.80 - ETA: 1:51 - loss: 0.5518 - accuracy: 0.80 - ETA: 1:50 - loss: 0.5518 - accuracy: 0.80 - ETA: 1:49 - loss: 0.5442 - accuracy: 0.81 - ETA: 1:48 - loss: 0.5418 - accuracy: 0.81 - ETA: 1:47 - loss: 0.5401 - accuracy: 0.81 - ETA: 1:46 - loss: 0.5409 - accuracy: 0.81 - ETA: 1:45 - loss: 0.5398 - accuracy: 0.81 - ETA: 1:44 - loss: 0.5393 - accuracy: 0.81 - ETA: 1:43 - loss: 0.5376 - accuracy: 0.81 - ETA: 1:42 - loss: 0.5361 - accuracy: 0.81 - ETA: 1:41 - loss: 0.5355 - accuracy: 0.81 - ETA: 1:40 - loss: 0.5342 - accuracy: 0.81 - ETA: 1:40 - loss: 0.5343 - accuracy: 0.81 - ETA: 1:39 - loss: 0.5381 - accuracy: 0.81 - ETA: 1:38 - loss: 0.5385 - accuracy: 0.81 - ETA: 1:37 - loss: 0.5402 - accuracy: 0.81 - ETA: 1:36 - loss: 0.5405 - accuracy: 0.81 - ETA: 1:35 - loss: 0.5400 - accuracy: 0.81 - ETA: 1:34 - loss: 0.5432 - accuracy: 0.81 - ETA: 1:33 - loss: 0.5412 - accuracy: 0.81 - ETA: 1:32 - loss: 0.5417 - accuracy: 0.81 - ETA: 1:31 - loss: 0.5407 - accuracy: 0.81 - ETA: 1:30 - loss: 0.5405 - accuracy: 0.81 - ETA: 1:29 - loss: 0.5414 - accuracy: 0.81 - ETA: 1:28 - loss: 0.5385 - accuracy: 0.81 - ETA: 1:27 - loss: 0.5378 - accuracy: 0.81 - ETA: 1:26 - loss: 0.5366 - accuracy: 0.81 - ETA: 1:25 - loss: 0.5379 - accuracy: 0.81 - ETA: 1:24 - loss: 0.5386 - accuracy: 0.81 - ETA: 1:23 - loss: 0.5391 - accuracy: 0.81 - ETA: 1:22 - loss: 0.5397 - accuracy: 0.81 - ETA: 1:21 - loss: 0.5432 - accuracy: 0.80 - ETA: 1:20 - loss: 0.5432 - accuracy: 0.80 - ETA: 1:19 - loss: 0.5440 - accuracy: 0.80 - ETA: 1:18 - loss: 0.5439 - accuracy: 0.80 - ETA: 1:17 - loss: 0.5438 - accuracy: 0.80 - ETA: 1:16 - loss: 0.5436 - accuracy: 0.80 - ETA: 1:15 - loss: 0.5416 - accuracy: 0.81 - ETA: 1:14 - loss: 0.5426 - accuracy: 0.80 - ETA: 1:13 - loss: 0.5428 - accuracy: 0.80 - ETA: 1:12 - loss: 0.5439 - accuracy: 0.80 - ETA: 1:11 - loss: 0.5440 - accuracy: 0.81 - ETA: 1:10 - loss: 0.5425 - accuracy: 0.81 - ETA: 1:09 - loss: 0.5433 - accuracy: 0.81 - ETA: 1:08 - loss: 0.5427 - accuracy: 0.81 - ETA: 1:07 - loss: 0.5435 - accuracy: 0.81 - ETA: 1:06 - loss: 0.5450 - accuracy: 0.81 - ETA: 1:06 - loss: 0.5489 - accuracy: 0.80 - ETA: 1:05 - loss: 0.5485 - accuracy: 0.80 - ETA: 1:04 - loss: 0.5497 - accuracy: 0.80 - ETA: 1:03 - loss: 0.5506 - accuracy: 0.80 - ETA: 1:02 - loss: 0.5485 - accuracy: 0.80 - ETA: 1:01 - loss: 0.5486 - accuracy: 0.80 - ETA: 1:00 - loss: 0.5486 - accuracy: 0.80 - ETA: 59s - loss: 0.5485 - accuracy: 0.8096 - ETA: 58s - loss: 0.5486 - accuracy: 0.809 - ETA: 57s - loss: 0.5482 - accuracy: 0.810 - ETA: 56s - loss: 0.5481 - accuracy: 0.810 - ETA: 55s - loss: 0.5488 - accuracy: 0.810 - ETA: 54s - loss: 0.5497 - accuracy: 0.810 - ETA: 53s - loss: 0.5493 - accuracy: 0.810 - ETA: 52s - loss: 0.5500 - accuracy: 0.810 - ETA: 51s - loss: 0.5513 - accuracy: 0.809 - ETA: 50s - loss: 0.5510 - accuracy: 0.809 - ETA: 49s - loss: 0.5522 - accuracy: 0.809 - ETA: 48s - loss: 0.5521 - accuracy: 0.809 - ETA: 48s - loss: 0.5529 - accuracy: 0.809 - ETA: 47s - loss: 0.5531 - accuracy: 0.809 - ETA: 46s - loss: 0.5519 - accuracy: 0.809 - ETA: 45s - loss: 0.5538 - accuracy: 0.808 - ETA: 44s - loss: 0.5534 - accuracy: 0.809 - ETA: 43s - loss: 0.5529 - accuracy: 0.809 - ETA: 42s - loss: 0.5519 - accuracy: 0.809 - ETA: 41s - loss: 0.5521 - accuracy: 0.809 - ETA: 40s - loss: 0.5508 - accuracy: 0.810 - ETA: 39s - loss: 0.5515 - accuracy: 0.810 - ETA: 38s - loss: 0.5503 - accuracy: 0.810 - ETA: 37s - loss: 0.5503 - accuracy: 0.810 - ETA: 36s - loss: 0.5494 - accuracy: 0.810 - ETA: 35s - loss: 0.5499 - accuracy: 0.810 - ETA: 34s - loss: 0.5504 - accuracy: 0.810 - ETA: 33s - loss: 0.5509 - accuracy: 0.810 - ETA: 31s - loss: 0.5518 - accuracy: 0.809 - ETA: 30s - loss: 0.5520 - accuracy: 0.809 - ETA: 29s - loss: 0.5516 - accuracy: 0.809 - ETA: 28s - loss: 0.5515 - accuracy: 0.809 - ETA: 27s - loss: 0.5509 - accuracy: 0.809 - ETA: 26s - loss: 0.5511 - accuracy: 0.809 - ETA: 25s - loss: 0.5507 - accuracy: 0.809 - ETA: 24s - loss: 0.5503 - accuracy: 0.809 - ETA: 23s - loss: 0.5507 - accuracy: 0.809 - ETA: 22s - loss: 0.5513 - accuracy: 0.808 - ETA: 20s - loss: 0.5522 - accuracy: 0.808 - ETA: 19s - loss: 0.5509 - accuracy: 0.809 - ETA: 18s - loss: 0.5508 - accuracy: 0.808 - ETA: 17s - loss: 0.5513 - accuracy: 0.809 - ETA: 16s - loss: 0.5514 - accuracy: 0.809 - ETA: 15s - loss: 0.5515 - accuracy: 0.809 - ETA: 14s - loss: 0.5517 - accuracy: 0.809 - ETA: 13s - loss: 0.5521 - accuracy: 0.809 - ETA: 12s - loss: 0.5516 - accuracy: 0.809 - ETA: 11s - loss: 0.5515 - accuracy: 0.809 - ETA: 9s - loss: 0.5511 - accuracy: 0.809 - ETA: 8s - loss: 0.5510 - accuracy: 0.80 - ETA: 7s - loss: 0.5515 - accuracy: 0.80 - ETA: 6s - loss: 0.5513 - accuracy: 0.80 - ETA: 5s - loss: 0.5525 - accuracy: 0.80 - ETA: 4s - loss: 0.5528 - accuracy: 0.80 - ETA: 3s - loss: 0.5523 - accuracy: 0.80 - ETA: 2s - loss: 0.5532 - accuracy: 0.80 - ETA: 0s - loss: 0.5533 - accuracy: 0.80 - 189s 10ms/step - loss: 0.5532 - accuracy: 0.8081 - val_loss: 1.4232 - val_accuracy: 0.7298\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:22 - loss: 0.4560 - accuracy: 0.82 - ETA: 2:17 - loss: 0.6065 - accuracy: 0.78 - ETA: 2:14 - loss: 0.5754 - accuracy: 0.79 - ETA: 2:11 - loss: 0.6078 - accuracy: 0.78 - ETA: 2:12 - loss: 0.6371 - accuracy: 0.78 - ETA: 2:11 - loss: 0.6310 - accuracy: 0.78 - ETA: 2:09 - loss: 0.6252 - accuracy: 0.78 - ETA: 2:09 - loss: 0.6044 - accuracy: 0.79 - ETA: 2:13 - loss: 0.6082 - accuracy: 0.79 - ETA: 2:13 - loss: 0.6026 - accuracy: 0.79 - ETA: 2:12 - loss: 0.5819 - accuracy: 0.80 - ETA: 2:10 - loss: 0.5790 - accuracy: 0.80 - ETA: 2:09 - loss: 0.6000 - accuracy: 0.79 - ETA: 2:08 - loss: 0.6088 - accuracy: 0.79 - ETA: 2:07 - loss: 0.6039 - accuracy: 0.79 - ETA: 2:06 - loss: 0.6040 - accuracy: 0.79 - ETA: 2:05 - loss: 0.5952 - accuracy: 0.80 - ETA: 2:04 - loss: 0.5928 - accuracy: 0.80 - ETA: 2:03 - loss: 0.5886 - accuracy: 0.80 - ETA: 2:02 - loss: 0.5848 - accuracy: 0.80 - ETA: 2:02 - loss: 0.5750 - accuracy: 0.80 - ETA: 2:00 - loss: 0.5751 - accuracy: 0.80 - ETA: 1:59 - loss: 0.5746 - accuracy: 0.80 - ETA: 1:58 - loss: 0.5725 - accuracy: 0.80 - ETA: 1:57 - loss: 0.5703 - accuracy: 0.80 - ETA: 1:56 - loss: 0.5633 - accuracy: 0.81 - ETA: 1:55 - loss: 0.5586 - accuracy: 0.81 - ETA: 1:54 - loss: 0.5560 - accuracy: 0.81 - ETA: 1:53 - loss: 0.5573 - accuracy: 0.81 - ETA: 1:52 - loss: 0.5567 - accuracy: 0.81 - ETA: 1:51 - loss: 0.5555 - accuracy: 0.81 - ETA: 1:50 - loss: 0.5570 - accuracy: 0.81 - ETA: 1:49 - loss: 0.5527 - accuracy: 0.81 - ETA: 1:48 - loss: 0.5510 - accuracy: 0.81 - ETA: 1:48 - loss: 0.5475 - accuracy: 0.81 - ETA: 1:47 - loss: 0.5452 - accuracy: 0.81 - ETA: 1:45 - loss: 0.5401 - accuracy: 0.81 - ETA: 1:44 - loss: 0.5404 - accuracy: 0.81 - ETA: 1:43 - loss: 0.5438 - accuracy: 0.81 - ETA: 1:43 - loss: 0.5425 - accuracy: 0.81 - ETA: 1:42 - loss: 0.5438 - accuracy: 0.81 - ETA: 1:41 - loss: 0.5423 - accuracy: 0.81 - ETA: 1:40 - loss: 0.5436 - accuracy: 0.81 - ETA: 1:39 - loss: 0.5420 - accuracy: 0.81 - ETA: 1:38 - loss: 0.5450 - accuracy: 0.81 - ETA: 1:37 - loss: 0.5441 - accuracy: 0.81 - ETA: 1:36 - loss: 0.5398 - accuracy: 0.81 - ETA: 1:35 - loss: 0.5405 - accuracy: 0.81 - ETA: 1:34 - loss: 0.5425 - accuracy: 0.81 - ETA: 1:33 - loss: 0.5413 - accuracy: 0.81 - ETA: 1:33 - loss: 0.5432 - accuracy: 0.81 - ETA: 1:32 - loss: 0.5424 - accuracy: 0.81 - ETA: 1:31 - loss: 0.5390 - accuracy: 0.81 - ETA: 1:30 - loss: 0.5393 - accuracy: 0.81 - ETA: 1:29 - loss: 0.5389 - accuracy: 0.81 - ETA: 1:29 - loss: 0.5399 - accuracy: 0.81 - ETA: 1:28 - loss: 0.5416 - accuracy: 0.81 - ETA: 1:27 - loss: 0.5399 - accuracy: 0.81 - ETA: 1:27 - loss: 0.5419 - accuracy: 0.81 - ETA: 1:26 - loss: 0.5414 - accuracy: 0.81 - ETA: 1:25 - loss: 0.5408 - accuracy: 0.81 - ETA: 1:24 - loss: 0.5397 - accuracy: 0.81 - ETA: 1:23 - loss: 0.5403 - accuracy: 0.81 - ETA: 1:22 - loss: 0.5413 - accuracy: 0.81 - ETA: 1:21 - loss: 0.5409 - accuracy: 0.81 - ETA: 1:20 - loss: 0.5404 - accuracy: 0.81 - ETA: 1:20 - loss: 0.5396 - accuracy: 0.81 - ETA: 1:19 - loss: 0.5380 - accuracy: 0.81 - ETA: 1:18 - loss: 0.5375 - accuracy: 0.81 - ETA: 1:17 - loss: 0.5346 - accuracy: 0.81 - ETA: 1:16 - loss: 0.5359 - accuracy: 0.81 - ETA: 1:15 - loss: 0.5356 - accuracy: 0.81 - ETA: 1:14 - loss: 0.5358 - accuracy: 0.81 - ETA: 1:13 - loss: 0.5378 - accuracy: 0.81 - ETA: 1:12 - loss: 0.5371 - accuracy: 0.81 - ETA: 1:11 - loss: 0.5381 - accuracy: 0.81 - ETA: 1:10 - loss: 0.5379 - accuracy: 0.81 - ETA: 1:09 - loss: 0.5414 - accuracy: 0.81 - ETA: 1:08 - loss: 0.5405 - accuracy: 0.81 - ETA: 1:07 - loss: 0.5415 - accuracy: 0.81 - ETA: 1:06 - loss: 0.5407 - accuracy: 0.81 - ETA: 1:05 - loss: 0.5399 - accuracy: 0.81 - ETA: 1:04 - loss: 0.5397 - accuracy: 0.81 - ETA: 1:04 - loss: 0.5408 - accuracy: 0.81 - ETA: 1:03 - loss: 0.5392 - accuracy: 0.81 - ETA: 1:02 - loss: 0.5390 - accuracy: 0.81 - ETA: 1:01 - loss: 0.5379 - accuracy: 0.81 - ETA: 1:00 - loss: 0.5396 - accuracy: 0.81 - ETA: 59s - loss: 0.5388 - accuracy: 0.8146 - ETA: 58s - loss: 0.5365 - accuracy: 0.815 - ETA: 57s - loss: 0.5378 - accuracy: 0.815 - ETA: 56s - loss: 0.5355 - accuracy: 0.815 - ETA: 55s - loss: 0.5341 - accuracy: 0.816 - ETA: 54s - loss: 0.5340 - accuracy: 0.816 - ETA: 54s - loss: 0.5360 - accuracy: 0.815 - ETA: 53s - loss: 0.5356 - accuracy: 0.816 - ETA: 52s - loss: 0.5362 - accuracy: 0.815 - ETA: 51s - loss: 0.5353 - accuracy: 0.816 - ETA: 50s - loss: 0.5358 - accuracy: 0.815 - ETA: 49s - loss: 0.5352 - accuracy: 0.815 - ETA: 48s - loss: 0.5346 - accuracy: 0.816 - ETA: 47s - loss: 0.5357 - accuracy: 0.815 - ETA: 46s - loss: 0.5353 - accuracy: 0.816 - ETA: 45s - loss: 0.5354 - accuracy: 0.815 - ETA: 44s - loss: 0.5375 - accuracy: 0.815 - ETA: 43s - loss: 0.5385 - accuracy: 0.814 - ETA: 42s - loss: 0.5378 - accuracy: 0.815 - ETA: 41s - loss: 0.5367 - accuracy: 0.815 - ETA: 40s - loss: 0.5372 - accuracy: 0.815 - ETA: 39s - loss: 0.5368 - accuracy: 0.815 - ETA: 38s - loss: 0.5365 - accuracy: 0.815 - ETA: 37s - loss: 0.5359 - accuracy: 0.815 - ETA: 36s - loss: 0.5358 - accuracy: 0.815 - ETA: 35s - loss: 0.5356 - accuracy: 0.815 - ETA: 34s - loss: 0.5357 - accuracy: 0.815 - ETA: 33s - loss: 0.5361 - accuracy: 0.815 - ETA: 32s - loss: 0.5355 - accuracy: 0.815 - ETA: 32s - loss: 0.5366 - accuracy: 0.815 - ETA: 31s - loss: 0.5381 - accuracy: 0.814 - ETA: 30s - loss: 0.5384 - accuracy: 0.814 - ETA: 29s - loss: 0.5390 - accuracy: 0.814 - ETA: 28s - loss: 0.5387 - accuracy: 0.814 - ETA: 27s - loss: 0.5380 - accuracy: 0.814 - ETA: 26s - loss: 0.5385 - accuracy: 0.814 - ETA: 25s - loss: 0.5368 - accuracy: 0.815 - ETA: 24s - loss: 0.5375 - accuracy: 0.814 - ETA: 23s - loss: 0.5372 - accuracy: 0.814 - ETA: 22s - loss: 0.5385 - accuracy: 0.814 - ETA: 21s - loss: 0.5397 - accuracy: 0.814 - ETA: 20s - loss: 0.5402 - accuracy: 0.814 - ETA: 19s - loss: 0.5408 - accuracy: 0.813 - ETA: 18s - loss: 0.5417 - accuracy: 0.813 - ETA: 17s - loss: 0.5426 - accuracy: 0.813 - ETA: 16s - loss: 0.5431 - accuracy: 0.813 - ETA: 15s - loss: 0.5432 - accuracy: 0.813 - ETA: 14s - loss: 0.5437 - accuracy: 0.812 - ETA: 13s - loss: 0.5433 - accuracy: 0.813 - ETA: 12s - loss: 0.5421 - accuracy: 0.813 - ETA: 11s - loss: 0.5412 - accuracy: 0.814 - ETA: 10s - loss: 0.5420 - accuracy: 0.814 - ETA: 9s - loss: 0.5417 - accuracy: 0.814 - ETA: 8s - loss: 0.5415 - accuracy: 0.81 - ETA: 7s - loss: 0.5411 - accuracy: 0.81 - ETA: 6s - loss: 0.5411 - accuracy: 0.81 - ETA: 5s - loss: 0.5420 - accuracy: 0.81 - ETA: 4s - loss: 0.5413 - accuracy: 0.81 - ETA: 3s - loss: 0.5409 - accuracy: 0.81 - ETA: 2s - loss: 0.5398 - accuracy: 0.81 - ETA: 1s - loss: 0.5405 - accuracy: 0.81 - ETA: 0s - loss: 0.5405 - accuracy: 0.81 - 162s 8ms/step - loss: 0.5416 - accuracy: 0.8145 - val_loss: 1.4353 - val_accuracy: 0.7368\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:27 - loss: 0.5473 - accuracy: 0.81 - ETA: 2:16 - loss: 0.5217 - accuracy: 0.82 - ETA: 2:22 - loss: 0.5012 - accuracy: 0.81 - ETA: 2:19 - loss: 0.5016 - accuracy: 0.82 - ETA: 2:17 - loss: 0.5055 - accuracy: 0.81 - ETA: 2:18 - loss: 0.5190 - accuracy: 0.81 - ETA: 2:18 - loss: 0.5358 - accuracy: 0.81 - ETA: 2:16 - loss: 0.5337 - accuracy: 0.81 - ETA: 2:14 - loss: 0.5255 - accuracy: 0.81 - ETA: 2:13 - loss: 0.5264 - accuracy: 0.81 - ETA: 2:11 - loss: 0.5391 - accuracy: 0.81 - ETA: 2:09 - loss: 0.5436 - accuracy: 0.81 - ETA: 2:08 - loss: 0.5386 - accuracy: 0.81 - ETA: 2:06 - loss: 0.5405 - accuracy: 0.81 - ETA: 2:05 - loss: 0.5340 - accuracy: 0.81 - ETA: 2:04 - loss: 0.5310 - accuracy: 0.81 - ETA: 2:02 - loss: 0.5324 - accuracy: 0.81 - ETA: 2:00 - loss: 0.5344 - accuracy: 0.81 - ETA: 1:59 - loss: 0.5314 - accuracy: 0.81 - ETA: 1:58 - loss: 0.5296 - accuracy: 0.81 - ETA: 1:57 - loss: 0.5308 - accuracy: 0.81 - ETA: 1:56 - loss: 0.5337 - accuracy: 0.81 - ETA: 1:55 - loss: 0.5299 - accuracy: 0.81 - ETA: 1:54 - loss: 0.5254 - accuracy: 0.82 - ETA: 1:54 - loss: 0.5227 - accuracy: 0.82 - ETA: 1:53 - loss: 0.5214 - accuracy: 0.82 - ETA: 1:52 - loss: 0.5174 - accuracy: 0.82 - ETA: 1:51 - loss: 0.5150 - accuracy: 0.82 - ETA: 1:50 - loss: 0.5149 - accuracy: 0.82 - ETA: 1:49 - loss: 0.5180 - accuracy: 0.82 - ETA: 1:48 - loss: 0.5161 - accuracy: 0.82 - ETA: 1:47 - loss: 0.5123 - accuracy: 0.82 - ETA: 1:46 - loss: 0.5142 - accuracy: 0.82 - ETA: 1:45 - loss: 0.5169 - accuracy: 0.82 - ETA: 1:44 - loss: 0.5224 - accuracy: 0.82 - ETA: 1:43 - loss: 0.5215 - accuracy: 0.82 - ETA: 1:42 - loss: 0.5194 - accuracy: 0.82 - ETA: 1:41 - loss: 0.5156 - accuracy: 0.82 - ETA: 1:40 - loss: 0.5188 - accuracy: 0.82 - ETA: 1:39 - loss: 0.5159 - accuracy: 0.82 - ETA: 1:38 - loss: 0.5187 - accuracy: 0.82 - ETA: 1:37 - loss: 0.5201 - accuracy: 0.82 - ETA: 1:37 - loss: 0.5181 - accuracy: 0.82 - ETA: 1:36 - loss: 0.5150 - accuracy: 0.82 - ETA: 1:35 - loss: 0.5149 - accuracy: 0.82 - ETA: 1:34 - loss: 0.5163 - accuracy: 0.82 - ETA: 1:33 - loss: 0.5160 - accuracy: 0.82 - ETA: 1:32 - loss: 0.5148 - accuracy: 0.82 - ETA: 1:31 - loss: 0.5137 - accuracy: 0.82 - ETA: 1:30 - loss: 0.5142 - accuracy: 0.82 - ETA: 1:29 - loss: 0.5141 - accuracy: 0.82 - ETA: 1:28 - loss: 0.5158 - accuracy: 0.82 - ETA: 1:27 - loss: 0.5132 - accuracy: 0.82 - ETA: 1:26 - loss: 0.5124 - accuracy: 0.82 - ETA: 1:25 - loss: 0.5110 - accuracy: 0.82 - ETA: 1:24 - loss: 0.5100 - accuracy: 0.82 - ETA: 1:23 - loss: 0.5119 - accuracy: 0.82 - ETA: 1:22 - loss: 0.5132 - accuracy: 0.82 - ETA: 1:22 - loss: 0.5158 - accuracy: 0.82 - ETA: 1:21 - loss: 0.5162 - accuracy: 0.82 - ETA: 1:20 - loss: 0.5168 - accuracy: 0.82 - ETA: 1:19 - loss: 0.5166 - accuracy: 0.82 - ETA: 1:19 - loss: 0.5164 - accuracy: 0.82 - ETA: 1:18 - loss: 0.5152 - accuracy: 0.82 - ETA: 1:17 - loss: 0.5144 - accuracy: 0.82 - ETA: 1:16 - loss: 0.5153 - accuracy: 0.82 - ETA: 1:15 - loss: 0.5174 - accuracy: 0.82 - ETA: 1:14 - loss: 0.5161 - accuracy: 0.82 - ETA: 1:13 - loss: 0.5151 - accuracy: 0.82 - ETA: 1:12 - loss: 0.5146 - accuracy: 0.82 - ETA: 1:12 - loss: 0.5160 - accuracy: 0.82 - ETA: 1:11 - loss: 0.5154 - accuracy: 0.82 - ETA: 1:10 - loss: 0.5157 - accuracy: 0.82 - ETA: 1:09 - loss: 0.5153 - accuracy: 0.82 - ETA: 1:08 - loss: 0.5182 - accuracy: 0.82 - ETA: 1:07 - loss: 0.5177 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5180 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5171 - accuracy: 0.82 - ETA: 1:04 - loss: 0.5160 - accuracy: 0.82 - ETA: 1:04 - loss: 0.5162 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5167 - accuracy: 0.82 - ETA: 1:02 - loss: 0.5183 - accuracy: 0.81 - ETA: 1:01 - loss: 0.5180 - accuracy: 0.81 - ETA: 1:00 - loss: 0.5185 - accuracy: 0.81 - ETA: 59s - loss: 0.5181 - accuracy: 0.8191 - ETA: 58s - loss: 0.5177 - accuracy: 0.819 - ETA: 57s - loss: 0.5183 - accuracy: 0.819 - ETA: 56s - loss: 0.5177 - accuracy: 0.820 - ETA: 55s - loss: 0.5175 - accuracy: 0.820 - ETA: 54s - loss: 0.5162 - accuracy: 0.820 - ETA: 53s - loss: 0.5161 - accuracy: 0.820 - ETA: 52s - loss: 0.5144 - accuracy: 0.821 - ETA: 52s - loss: 0.5159 - accuracy: 0.820 - ETA: 51s - loss: 0.5166 - accuracy: 0.821 - ETA: 50s - loss: 0.5183 - accuracy: 0.821 - ETA: 49s - loss: 0.5188 - accuracy: 0.821 - ETA: 48s - loss: 0.5197 - accuracy: 0.821 - ETA: 47s - loss: 0.5202 - accuracy: 0.821 - ETA: 46s - loss: 0.5216 - accuracy: 0.820 - ETA: 45s - loss: 0.5204 - accuracy: 0.820 - ETA: 44s - loss: 0.5214 - accuracy: 0.821 - ETA: 43s - loss: 0.5218 - accuracy: 0.820 - ETA: 43s - loss: 0.5226 - accuracy: 0.820 - ETA: 42s - loss: 0.5211 - accuracy: 0.821 - ETA: 41s - loss: 0.5223 - accuracy: 0.820 - ETA: 40s - loss: 0.5238 - accuracy: 0.819 - ETA: 39s - loss: 0.5232 - accuracy: 0.819 - ETA: 38s - loss: 0.5230 - accuracy: 0.820 - ETA: 37s - loss: 0.5222 - accuracy: 0.820 - ETA: 36s - loss: 0.5223 - accuracy: 0.820 - ETA: 35s - loss: 0.5225 - accuracy: 0.820 - ETA: 34s - loss: 0.5237 - accuracy: 0.820 - ETA: 33s - loss: 0.5229 - accuracy: 0.820 - ETA: 33s - loss: 0.5229 - accuracy: 0.819 - ETA: 32s - loss: 0.5237 - accuracy: 0.819 - ETA: 31s - loss: 0.5228 - accuracy: 0.819 - ETA: 30s - loss: 0.5219 - accuracy: 0.820 - ETA: 29s - loss: 0.5210 - accuracy: 0.820 - ETA: 28s - loss: 0.5222 - accuracy: 0.820 - ETA: 27s - loss: 0.5215 - accuracy: 0.820 - ETA: 26s - loss: 0.5229 - accuracy: 0.820 - ETA: 25s - loss: 0.5227 - accuracy: 0.820 - ETA: 24s - loss: 0.5236 - accuracy: 0.819 - ETA: 24s - loss: 0.5237 - accuracy: 0.820 - ETA: 23s - loss: 0.5240 - accuracy: 0.819 - ETA: 22s - loss: 0.5237 - accuracy: 0.820 - ETA: 21s - loss: 0.5232 - accuracy: 0.820 - ETA: 20s - loss: 0.5236 - accuracy: 0.820 - ETA: 19s - loss: 0.5243 - accuracy: 0.819 - ETA: 18s - loss: 0.5253 - accuracy: 0.819 - ETA: 17s - loss: 0.5256 - accuracy: 0.819 - ETA: 16s - loss: 0.5257 - accuracy: 0.819 - ETA: 15s - loss: 0.5257 - accuracy: 0.819 - ETA: 15s - loss: 0.5263 - accuracy: 0.819 - ETA: 14s - loss: 0.5255 - accuracy: 0.819 - ETA: 13s - loss: 0.5248 - accuracy: 0.819 - ETA: 12s - loss: 0.5238 - accuracy: 0.819 - ETA: 11s - loss: 0.5237 - accuracy: 0.819 - ETA: 10s - loss: 0.5244 - accuracy: 0.819 - ETA: 9s - loss: 0.5240 - accuracy: 0.819 - ETA: 8s - loss: 0.5229 - accuracy: 0.81 - ETA: 7s - loss: 0.5246 - accuracy: 0.81 - ETA: 7s - loss: 0.5254 - accuracy: 0.81 - ETA: 6s - loss: 0.5260 - accuracy: 0.81 - ETA: 5s - loss: 0.5257 - accuracy: 0.81 - ETA: 4s - loss: 0.5255 - accuracy: 0.81 - ETA: 3s - loss: 0.5257 - accuracy: 0.81 - ETA: 2s - loss: 0.5263 - accuracy: 0.81 - ETA: 1s - loss: 0.5252 - accuracy: 0.81 - ETA: 0s - loss: 0.5257 - accuracy: 0.81 - 147s 8ms/step - loss: 0.5253 - accuracy: 0.8191 - val_loss: 1.4350 - val_accuracy: 0.7337\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:20 - loss: 0.5167 - accuracy: 0.81 - ETA: 2:15 - loss: 0.4817 - accuracy: 0.83 - ETA: 2:12 - loss: 0.4961 - accuracy: 0.82 - ETA: 2:15 - loss: 0.4835 - accuracy: 0.82 - ETA: 2:13 - loss: 0.4731 - accuracy: 0.83 - ETA: 2:10 - loss: 0.4732 - accuracy: 0.82 - ETA: 2:08 - loss: 0.4752 - accuracy: 0.82 - ETA: 2:06 - loss: 0.4847 - accuracy: 0.82 - ETA: 2:05 - loss: 0.4911 - accuracy: 0.82 - ETA: 2:04 - loss: 0.5157 - accuracy: 0.81 - ETA: 2:02 - loss: 0.5082 - accuracy: 0.81 - ETA: 2:02 - loss: 0.5001 - accuracy: 0.82 - ETA: 2:01 - loss: 0.4906 - accuracy: 0.82 - ETA: 2:00 - loss: 0.4830 - accuracy: 0.82 - ETA: 1:59 - loss: 0.4896 - accuracy: 0.82 - ETA: 1:58 - loss: 0.4923 - accuracy: 0.82 - ETA: 1:57 - loss: 0.4935 - accuracy: 0.82 - ETA: 1:56 - loss: 0.4947 - accuracy: 0.82 - ETA: 1:55 - loss: 0.4979 - accuracy: 0.82 - ETA: 1:54 - loss: 0.4940 - accuracy: 0.82 - ETA: 1:53 - loss: 0.4983 - accuracy: 0.82 - ETA: 1:52 - loss: 0.4959 - accuracy: 0.82 - ETA: 1:52 - loss: 0.4956 - accuracy: 0.82 - ETA: 1:51 - loss: 0.4911 - accuracy: 0.82 - ETA: 1:50 - loss: 0.4895 - accuracy: 0.82 - ETA: 1:49 - loss: 0.4908 - accuracy: 0.82 - ETA: 1:48 - loss: 0.4899 - accuracy: 0.82 - ETA: 1:47 - loss: 0.4938 - accuracy: 0.82 - ETA: 1:47 - loss: 0.4903 - accuracy: 0.82 - ETA: 1:46 - loss: 0.4957 - accuracy: 0.82 - ETA: 1:45 - loss: 0.4980 - accuracy: 0.82 - ETA: 1:44 - loss: 0.4981 - accuracy: 0.82 - ETA: 1:43 - loss: 0.4967 - accuracy: 0.82 - ETA: 1:42 - loss: 0.4958 - accuracy: 0.82 - ETA: 1:42 - loss: 0.4983 - accuracy: 0.82 - ETA: 1:41 - loss: 0.4980 - accuracy: 0.82 - ETA: 1:40 - loss: 0.5000 - accuracy: 0.82 - ETA: 1:39 - loss: 0.4992 - accuracy: 0.82 - ETA: 1:38 - loss: 0.5002 - accuracy: 0.82 - ETA: 1:37 - loss: 0.4998 - accuracy: 0.82 - ETA: 1:36 - loss: 0.4983 - accuracy: 0.82 - ETA: 1:36 - loss: 0.5005 - accuracy: 0.82 - ETA: 1:35 - loss: 0.4983 - accuracy: 0.82 - ETA: 1:34 - loss: 0.4993 - accuracy: 0.82 - ETA: 1:33 - loss: 0.4996 - accuracy: 0.82 - ETA: 1:32 - loss: 0.4981 - accuracy: 0.82 - ETA: 1:31 - loss: 0.4961 - accuracy: 0.82 - ETA: 1:30 - loss: 0.4964 - accuracy: 0.82 - ETA: 1:29 - loss: 0.4970 - accuracy: 0.82 - ETA: 1:28 - loss: 0.5000 - accuracy: 0.82 - ETA: 1:27 - loss: 0.5022 - accuracy: 0.82 - ETA: 1:26 - loss: 0.5022 - accuracy: 0.82 - ETA: 1:25 - loss: 0.5001 - accuracy: 0.82 - ETA: 1:24 - loss: 0.5002 - accuracy: 0.82 - ETA: 1:24 - loss: 0.5008 - accuracy: 0.82 - ETA: 1:23 - loss: 0.5015 - accuracy: 0.82 - ETA: 1:22 - loss: 0.4994 - accuracy: 0.82 - ETA: 1:21 - loss: 0.5012 - accuracy: 0.82 - ETA: 1:20 - loss: 0.5014 - accuracy: 0.82 - ETA: 1:19 - loss: 0.5021 - accuracy: 0.82 - ETA: 1:18 - loss: 0.5041 - accuracy: 0.82 - ETA: 1:18 - loss: 0.5075 - accuracy: 0.82 - ETA: 1:17 - loss: 0.5076 - accuracy: 0.82 - ETA: 1:16 - loss: 0.5098 - accuracy: 0.82 - ETA: 1:15 - loss: 0.5121 - accuracy: 0.82 - ETA: 1:14 - loss: 0.5121 - accuracy: 0.82 - ETA: 1:13 - loss: 0.5119 - accuracy: 0.82 - ETA: 1:12 - loss: 0.5110 - accuracy: 0.82 - ETA: 1:11 - loss: 0.5089 - accuracy: 0.82 - ETA: 1:11 - loss: 0.5126 - accuracy: 0.82 - ETA: 1:10 - loss: 0.5129 - accuracy: 0.82 - ETA: 1:09 - loss: 0.5121 - accuracy: 0.82 - ETA: 1:08 - loss: 0.5105 - accuracy: 0.82 - ETA: 1:07 - loss: 0.5094 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5099 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5078 - accuracy: 0.82 - ETA: 1:04 - loss: 0.5090 - accuracy: 0.82 - ETA: 1:04 - loss: 0.5094 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5116 - accuracy: 0.82 - ETA: 1:02 - loss: 0.5112 - accuracy: 0.82 - ETA: 1:01 - loss: 0.5106 - accuracy: 0.82 - ETA: 1:00 - loss: 0.5129 - accuracy: 0.82 - ETA: 59s - loss: 0.5131 - accuracy: 0.8206 - ETA: 58s - loss: 0.5147 - accuracy: 0.820 - ETA: 57s - loss: 0.5146 - accuracy: 0.819 - ETA: 56s - loss: 0.5144 - accuracy: 0.820 - ETA: 56s - loss: 0.5144 - accuracy: 0.820 - ETA: 55s - loss: 0.5129 - accuracy: 0.820 - ETA: 54s - loss: 0.5106 - accuracy: 0.821 - ETA: 53s - loss: 0.5102 - accuracy: 0.821 - ETA: 52s - loss: 0.5110 - accuracy: 0.821 - ETA: 51s - loss: 0.5100 - accuracy: 0.821 - ETA: 50s - loss: 0.5127 - accuracy: 0.821 - ETA: 49s - loss: 0.5103 - accuracy: 0.822 - ETA: 49s - loss: 0.5105 - accuracy: 0.822 - ETA: 48s - loss: 0.5116 - accuracy: 0.821 - ETA: 47s - loss: 0.5115 - accuracy: 0.821 - ETA: 46s - loss: 0.5109 - accuracy: 0.821 - ETA: 45s - loss: 0.5096 - accuracy: 0.822 - ETA: 44s - loss: 0.5083 - accuracy: 0.822 - ETA: 43s - loss: 0.5088 - accuracy: 0.822 - ETA: 42s - loss: 0.5099 - accuracy: 0.822 - ETA: 41s - loss: 0.5103 - accuracy: 0.822 - ETA: 41s - loss: 0.5094 - accuracy: 0.822 - ETA: 40s - loss: 0.5101 - accuracy: 0.822 - ETA: 39s - loss: 0.5092 - accuracy: 0.822 - ETA: 38s - loss: 0.5099 - accuracy: 0.822 - ETA: 37s - loss: 0.5114 - accuracy: 0.821 - ETA: 36s - loss: 0.5125 - accuracy: 0.821 - ETA: 35s - loss: 0.5125 - accuracy: 0.821 - ETA: 35s - loss: 0.5117 - accuracy: 0.821 - ETA: 34s - loss: 0.5114 - accuracy: 0.821 - ETA: 33s - loss: 0.5112 - accuracy: 0.821 - ETA: 32s - loss: 0.5114 - accuracy: 0.821 - ETA: 31s - loss: 0.5120 - accuracy: 0.821 - ETA: 30s - loss: 0.5126 - accuracy: 0.821 - ETA: 29s - loss: 0.5121 - accuracy: 0.822 - ETA: 28s - loss: 0.5126 - accuracy: 0.822 - ETA: 27s - loss: 0.5125 - accuracy: 0.822 - ETA: 27s - loss: 0.5118 - accuracy: 0.822 - ETA: 26s - loss: 0.5125 - accuracy: 0.821 - ETA: 25s - loss: 0.5127 - accuracy: 0.822 - ETA: 24s - loss: 0.5118 - accuracy: 0.822 - ETA: 23s - loss: 0.5115 - accuracy: 0.822 - ETA: 22s - loss: 0.5114 - accuracy: 0.822 - ETA: 21s - loss: 0.5116 - accuracy: 0.822 - ETA: 20s - loss: 0.5121 - accuracy: 0.822 - ETA: 20s - loss: 0.5121 - accuracy: 0.822 - ETA: 19s - loss: 0.5107 - accuracy: 0.822 - ETA: 18s - loss: 0.5097 - accuracy: 0.822 - ETA: 17s - loss: 0.5101 - accuracy: 0.822 - ETA: 16s - loss: 0.5094 - accuracy: 0.822 - ETA: 15s - loss: 0.5084 - accuracy: 0.823 - ETA: 14s - loss: 0.5085 - accuracy: 0.823 - ETA: 13s - loss: 0.5087 - accuracy: 0.822 - ETA: 13s - loss: 0.5082 - accuracy: 0.822 - ETA: 12s - loss: 0.5075 - accuracy: 0.823 - ETA: 11s - loss: 0.5073 - accuracy: 0.823 - ETA: 10s - loss: 0.5075 - accuracy: 0.823 - ETA: 9s - loss: 0.5070 - accuracy: 0.823 - ETA: 8s - loss: 0.5060 - accuracy: 0.82 - ETA: 7s - loss: 0.5057 - accuracy: 0.82 - ETA: 6s - loss: 0.5059 - accuracy: 0.82 - ETA: 6s - loss: 0.5048 - accuracy: 0.82 - ETA: 5s - loss: 0.5046 - accuracy: 0.82 - ETA: 4s - loss: 0.5044 - accuracy: 0.82 - ETA: 3s - loss: 0.5043 - accuracy: 0.82 - ETA: 2s - loss: 0.5043 - accuracy: 0.82 - ETA: 1s - loss: 0.5048 - accuracy: 0.82 - ETA: 0s - loss: 0.5051 - accuracy: 0.82 - 144s 7ms/step - loss: 0.5060 - accuracy: 0.8237 - val_loss: 1.4301 - val_accuracy: 0.7397\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:25 - loss: 0.6129 - accuracy: 0.77 - ETA: 2:18 - loss: 0.4927 - accuracy: 0.83 - ETA: 2:20 - loss: 0.4966 - accuracy: 0.82 - ETA: 2:18 - loss: 0.4662 - accuracy: 0.83 - ETA: 2:14 - loss: 0.4571 - accuracy: 0.84 - ETA: 2:11 - loss: 0.4346 - accuracy: 0.85 - ETA: 2:09 - loss: 0.4455 - accuracy: 0.84 - ETA: 2:07 - loss: 0.4343 - accuracy: 0.85 - ETA: 2:05 - loss: 0.4384 - accuracy: 0.84 - ETA: 2:04 - loss: 0.4573 - accuracy: 0.84 - ETA: 2:02 - loss: 0.4656 - accuracy: 0.83 - ETA: 2:01 - loss: 0.4777 - accuracy: 0.83 - ETA: 2:00 - loss: 0.4925 - accuracy: 0.82 - ETA: 1:59 - loss: 0.4940 - accuracy: 0.82 - ETA: 1:58 - loss: 0.4869 - accuracy: 0.83 - ETA: 1:57 - loss: 0.4878 - accuracy: 0.83 - ETA: 1:56 - loss: 0.4904 - accuracy: 0.82 - ETA: 1:55 - loss: 0.4999 - accuracy: 0.82 - ETA: 1:54 - loss: 0.4904 - accuracy: 0.82 - ETA: 1:53 - loss: 0.4868 - accuracy: 0.83 - ETA: 1:52 - loss: 0.4861 - accuracy: 0.83 - ETA: 1:51 - loss: 0.4928 - accuracy: 0.82 - ETA: 1:51 - loss: 0.4967 - accuracy: 0.82 - ETA: 1:51 - loss: 0.4929 - accuracy: 0.83 - ETA: 1:50 - loss: 0.4908 - accuracy: 0.83 - ETA: 1:50 - loss: 0.4893 - accuracy: 0.83 - ETA: 1:49 - loss: 0.4962 - accuracy: 0.83 - ETA: 1:48 - loss: 0.4994 - accuracy: 0.82 - ETA: 1:48 - loss: 0.4947 - accuracy: 0.83 - ETA: 1:47 - loss: 0.4966 - accuracy: 0.82 - ETA: 1:46 - loss: 0.4939 - accuracy: 0.82 - ETA: 1:46 - loss: 0.4925 - accuracy: 0.83 - ETA: 1:45 - loss: 0.4934 - accuracy: 0.82 - ETA: 1:44 - loss: 0.4937 - accuracy: 0.83 - ETA: 1:43 - loss: 0.4922 - accuracy: 0.82 - ETA: 1:42 - loss: 0.4944 - accuracy: 0.83 - ETA: 1:41 - loss: 0.4948 - accuracy: 0.83 - ETA: 1:40 - loss: 0.5000 - accuracy: 0.82 - ETA: 1:39 - loss: 0.4970 - accuracy: 0.82 - ETA: 1:39 - loss: 0.4946 - accuracy: 0.83 - ETA: 1:38 - loss: 0.4960 - accuracy: 0.82 - ETA: 1:37 - loss: 0.4951 - accuracy: 0.82 - ETA: 1:36 - loss: 0.4962 - accuracy: 0.82 - ETA: 1:35 - loss: 0.4950 - accuracy: 0.82 - ETA: 1:34 - loss: 0.4971 - accuracy: 0.82 - ETA: 1:33 - loss: 0.4971 - accuracy: 0.82 - ETA: 1:32 - loss: 0.4992 - accuracy: 0.82 - ETA: 1:31 - loss: 0.4999 - accuracy: 0.82 - ETA: 1:30 - loss: 0.4976 - accuracy: 0.82 - ETA: 1:29 - loss: 0.4998 - accuracy: 0.82 - ETA: 1:28 - loss: 0.5005 - accuracy: 0.82 - ETA: 1:27 - loss: 0.4990 - accuracy: 0.82 - ETA: 1:27 - loss: 0.5007 - accuracy: 0.82 - ETA: 1:26 - loss: 0.5020 - accuracy: 0.82 - ETA: 1:25 - loss: 0.5008 - accuracy: 0.82 - ETA: 1:24 - loss: 0.4993 - accuracy: 0.82 - ETA: 1:23 - loss: 0.4979 - accuracy: 0.82 - ETA: 1:22 - loss: 0.4970 - accuracy: 0.82 - ETA: 1:22 - loss: 0.4957 - accuracy: 0.82 - ETA: 1:21 - loss: 0.4964 - accuracy: 0.82 - ETA: 1:20 - loss: 0.4970 - accuracy: 0.82 - ETA: 1:19 - loss: 0.4955 - accuracy: 0.82 - ETA: 1:18 - loss: 0.4955 - accuracy: 0.82 - ETA: 1:17 - loss: 0.4980 - accuracy: 0.82 - ETA: 1:16 - loss: 0.4985 - accuracy: 0.82 - ETA: 1:15 - loss: 0.4964 - accuracy: 0.82 - ETA: 1:14 - loss: 0.4959 - accuracy: 0.82 - ETA: 1:13 - loss: 0.4971 - accuracy: 0.82 - ETA: 1:12 - loss: 0.4977 - accuracy: 0.82 - ETA: 1:11 - loss: 0.4976 - accuracy: 0.82 - ETA: 1:10 - loss: 0.4965 - accuracy: 0.82 - ETA: 1:09 - loss: 0.4974 - accuracy: 0.82 - ETA: 1:08 - loss: 0.4976 - accuracy: 0.82 - ETA: 1:08 - loss: 0.4968 - accuracy: 0.82 - ETA: 1:07 - loss: 0.4972 - accuracy: 0.82 - ETA: 1:06 - loss: 0.4979 - accuracy: 0.82 - ETA: 1:05 - loss: 0.4983 - accuracy: 0.82 - ETA: 1:04 - loss: 0.4977 - accuracy: 0.82 - ETA: 1:03 - loss: 0.4988 - accuracy: 0.82 - ETA: 1:02 - loss: 0.4975 - accuracy: 0.82 - ETA: 1:02 - loss: 0.4956 - accuracy: 0.83 - ETA: 1:01 - loss: 0.4954 - accuracy: 0.83 - ETA: 1:00 - loss: 0.4966 - accuracy: 0.83 - ETA: 59s - loss: 0.4976 - accuracy: 0.8305 - ETA: 58s - loss: 0.4965 - accuracy: 0.831 - ETA: 57s - loss: 0.4958 - accuracy: 0.831 - ETA: 56s - loss: 0.4946 - accuracy: 0.831 - ETA: 55s - loss: 0.4940 - accuracy: 0.832 - ETA: 54s - loss: 0.4937 - accuracy: 0.832 - ETA: 53s - loss: 0.4941 - accuracy: 0.832 - ETA: 53s - loss: 0.4942 - accuracy: 0.831 - ETA: 52s - loss: 0.4937 - accuracy: 0.831 - ETA: 51s - loss: 0.4939 - accuracy: 0.831 - ETA: 50s - loss: 0.4937 - accuracy: 0.831 - ETA: 49s - loss: 0.4932 - accuracy: 0.831 - ETA: 48s - loss: 0.4915 - accuracy: 0.831 - ETA: 47s - loss: 0.4929 - accuracy: 0.831 - ETA: 46s - loss: 0.4916 - accuracy: 0.832 - ETA: 45s - loss: 0.4906 - accuracy: 0.832 - ETA: 45s - loss: 0.4901 - accuracy: 0.832 - ETA: 44s - loss: 0.4909 - accuracy: 0.831 - ETA: 43s - loss: 0.4900 - accuracy: 0.832 - ETA: 42s - loss: 0.4902 - accuracy: 0.832 - ETA: 41s - loss: 0.4910 - accuracy: 0.832 - ETA: 40s - loss: 0.4908 - accuracy: 0.831 - ETA: 39s - loss: 0.4924 - accuracy: 0.831 - ETA: 38s - loss: 0.4923 - accuracy: 0.831 - ETA: 37s - loss: 0.4912 - accuracy: 0.831 - ETA: 36s - loss: 0.4915 - accuracy: 0.831 - ETA: 36s - loss: 0.4912 - accuracy: 0.831 - ETA: 35s - loss: 0.4905 - accuracy: 0.831 - ETA: 34s - loss: 0.4903 - accuracy: 0.832 - ETA: 33s - loss: 0.4912 - accuracy: 0.831 - ETA: 32s - loss: 0.4905 - accuracy: 0.832 - ETA: 31s - loss: 0.4900 - accuracy: 0.832 - ETA: 30s - loss: 0.4901 - accuracy: 0.832 - ETA: 29s - loss: 0.4898 - accuracy: 0.832 - ETA: 29s - loss: 0.4918 - accuracy: 0.831 - ETA: 28s - loss: 0.4919 - accuracy: 0.831 - ETA: 27s - loss: 0.4932 - accuracy: 0.831 - ETA: 26s - loss: 0.4929 - accuracy: 0.831 - ETA: 25s - loss: 0.4929 - accuracy: 0.831 - ETA: 24s - loss: 0.4933 - accuracy: 0.830 - ETA: 23s - loss: 0.4939 - accuracy: 0.830 - ETA: 22s - loss: 0.4945 - accuracy: 0.830 - ETA: 21s - loss: 0.4938 - accuracy: 0.831 - ETA: 21s - loss: 0.4935 - accuracy: 0.831 - ETA: 20s - loss: 0.4952 - accuracy: 0.830 - ETA: 19s - loss: 0.4969 - accuracy: 0.830 - ETA: 18s - loss: 0.4972 - accuracy: 0.830 - ETA: 17s - loss: 0.4973 - accuracy: 0.830 - ETA: 16s - loss: 0.4965 - accuracy: 0.830 - ETA: 15s - loss: 0.4972 - accuracy: 0.830 - ETA: 14s - loss: 0.4962 - accuracy: 0.830 - ETA: 14s - loss: 0.4960 - accuracy: 0.830 - ETA: 13s - loss: 0.4962 - accuracy: 0.830 - ETA: 12s - loss: 0.4961 - accuracy: 0.830 - ETA: 11s - loss: 0.4967 - accuracy: 0.829 - ETA: 10s - loss: 0.4967 - accuracy: 0.829 - ETA: 9s - loss: 0.4968 - accuracy: 0.829 - ETA: 8s - loss: 0.4968 - accuracy: 0.82 - ETA: 7s - loss: 0.4979 - accuracy: 0.82 - ETA: 7s - loss: 0.4973 - accuracy: 0.82 - ETA: 6s - loss: 0.4968 - accuracy: 0.82 - ETA: 5s - loss: 0.4971 - accuracy: 0.82 - ETA: 4s - loss: 0.4971 - accuracy: 0.82 - ETA: 3s - loss: 0.4964 - accuracy: 0.82 - ETA: 2s - loss: 0.4971 - accuracy: 0.82 - ETA: 1s - loss: 0.4971 - accuracy: 0.82 - ETA: 0s - loss: 0.4977 - accuracy: 0.82 - 146s 8ms/step - loss: 0.4975 - accuracy: 0.8290 - val_loss: 1.4298 - val_accuracy: 0.7391\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:36 - loss: 0.3619 - accuracy: 0.86 - ETA: 2:29 - loss: 0.4183 - accuracy: 0.85 - ETA: 2:23 - loss: 0.4527 - accuracy: 0.83 - ETA: 2:19 - loss: 0.4793 - accuracy: 0.82 - ETA: 2:15 - loss: 0.4817 - accuracy: 0.82 - ETA: 2:11 - loss: 0.4676 - accuracy: 0.82 - ETA: 2:09 - loss: 0.4976 - accuracy: 0.81 - ETA: 2:08 - loss: 0.5037 - accuracy: 0.81 - ETA: 2:07 - loss: 0.4866 - accuracy: 0.81 - ETA: 2:05 - loss: 0.4944 - accuracy: 0.81 - ETA: 2:03 - loss: 0.4969 - accuracy: 0.81 - ETA: 2:02 - loss: 0.4941 - accuracy: 0.81 - ETA: 2:01 - loss: 0.4960 - accuracy: 0.82 - ETA: 2:00 - loss: 0.4912 - accuracy: 0.82 - ETA: 2:00 - loss: 0.4938 - accuracy: 0.82 - ETA: 1:59 - loss: 0.4821 - accuracy: 0.82 - ETA: 1:58 - loss: 0.4798 - accuracy: 0.82 - ETA: 1:57 - loss: 0.4815 - accuracy: 0.82 - ETA: 1:57 - loss: 0.4783 - accuracy: 0.82 - ETA: 1:56 - loss: 0.4808 - accuracy: 0.82 - ETA: 1:55 - loss: 0.4763 - accuracy: 0.82 - ETA: 1:54 - loss: 0.4755 - accuracy: 0.82 - ETA: 1:53 - loss: 0.4771 - accuracy: 0.82 - ETA: 1:52 - loss: 0.4729 - accuracy: 0.83 - ETA: 1:51 - loss: 0.4703 - accuracy: 0.83 - ETA: 1:50 - loss: 0.4732 - accuracy: 0.82 - ETA: 1:49 - loss: 0.4724 - accuracy: 0.82 - ETA: 1:49 - loss: 0.4721 - accuracy: 0.82 - ETA: 1:48 - loss: 0.4721 - accuracy: 0.82 - ETA: 1:47 - loss: 0.4709 - accuracy: 0.83 - ETA: 1:46 - loss: 0.4675 - accuracy: 0.83 - ETA: 1:45 - loss: 0.4720 - accuracy: 0.83 - ETA: 1:44 - loss: 0.4748 - accuracy: 0.83 - ETA: 1:43 - loss: 0.4790 - accuracy: 0.82 - ETA: 1:42 - loss: 0.4781 - accuracy: 0.82 - ETA: 1:41 - loss: 0.4850 - accuracy: 0.82 - ETA: 1:40 - loss: 0.4858 - accuracy: 0.82 - ETA: 1:40 - loss: 0.4831 - accuracy: 0.82 - ETA: 1:39 - loss: 0.4795 - accuracy: 0.82 - ETA: 1:38 - loss: 0.4799 - accuracy: 0.82 - ETA: 1:37 - loss: 0.4810 - accuracy: 0.82 - ETA: 1:36 - loss: 0.4824 - accuracy: 0.82 - ETA: 1:35 - loss: 0.4810 - accuracy: 0.82 - ETA: 1:34 - loss: 0.4803 - accuracy: 0.82 - ETA: 1:34 - loss: 0.4792 - accuracy: 0.82 - ETA: 1:33 - loss: 0.4762 - accuracy: 0.83 - ETA: 1:32 - loss: 0.4771 - accuracy: 0.83 - ETA: 1:31 - loss: 0.4806 - accuracy: 0.82 - ETA: 1:30 - loss: 0.4820 - accuracy: 0.82 - ETA: 1:29 - loss: 0.4804 - accuracy: 0.82 - ETA: 1:28 - loss: 0.4803 - accuracy: 0.82 - ETA: 1:27 - loss: 0.4800 - accuracy: 0.82 - ETA: 1:26 - loss: 0.4816 - accuracy: 0.82 - ETA: 1:25 - loss: 0.4813 - accuracy: 0.82 - ETA: 1:24 - loss: 0.4813 - accuracy: 0.82 - ETA: 1:24 - loss: 0.4836 - accuracy: 0.82 - ETA: 1:23 - loss: 0.4821 - accuracy: 0.82 - ETA: 1:22 - loss: 0.4817 - accuracy: 0.82 - ETA: 1:21 - loss: 0.4816 - accuracy: 0.83 - ETA: 1:20 - loss: 0.4817 - accuracy: 0.82 - ETA: 1:19 - loss: 0.4853 - accuracy: 0.82 - ETA: 1:18 - loss: 0.4856 - accuracy: 0.82 - ETA: 1:17 - loss: 0.4849 - accuracy: 0.82 - ETA: 1:16 - loss: 0.4847 - accuracy: 0.82 - ETA: 1:15 - loss: 0.4857 - accuracy: 0.82 - ETA: 1:15 - loss: 0.4841 - accuracy: 0.82 - ETA: 1:14 - loss: 0.4840 - accuracy: 0.83 - ETA: 1:13 - loss: 0.4855 - accuracy: 0.82 - ETA: 1:12 - loss: 0.4860 - accuracy: 0.82 - ETA: 1:11 - loss: 0.4850 - accuracy: 0.83 - ETA: 1:10 - loss: 0.4851 - accuracy: 0.83 - ETA: 1:09 - loss: 0.4852 - accuracy: 0.83 - ETA: 1:08 - loss: 0.4851 - accuracy: 0.83 - ETA: 1:07 - loss: 0.4858 - accuracy: 0.83 - ETA: 1:07 - loss: 0.4859 - accuracy: 0.82 - ETA: 1:06 - loss: 0.4871 - accuracy: 0.83 - ETA: 1:05 - loss: 0.4862 - accuracy: 0.83 - ETA: 1:04 - loss: 0.4853 - accuracy: 0.83 - ETA: 1:03 - loss: 0.4860 - accuracy: 0.83 - ETA: 1:02 - loss: 0.4847 - accuracy: 0.83 - ETA: 1:01 - loss: 0.4851 - accuracy: 0.83 - ETA: 1:00 - loss: 0.4853 - accuracy: 0.83 - ETA: 59s - loss: 0.4850 - accuracy: 0.8308 - ETA: 59s - loss: 0.4838 - accuracy: 0.830 - ETA: 58s - loss: 0.4843 - accuracy: 0.831 - ETA: 57s - loss: 0.4844 - accuracy: 0.831 - ETA: 56s - loss: 0.4858 - accuracy: 0.830 - ETA: 56s - loss: 0.4859 - accuracy: 0.830 - ETA: 55s - loss: 0.4868 - accuracy: 0.830 - ETA: 55s - loss: 0.4857 - accuracy: 0.830 - ETA: 55s - loss: 0.4845 - accuracy: 0.831 - ETA: 54s - loss: 0.4851 - accuracy: 0.830 - ETA: 54s - loss: 0.4847 - accuracy: 0.830 - ETA: 53s - loss: 0.4857 - accuracy: 0.829 - ETA: 53s - loss: 0.4862 - accuracy: 0.829 - ETA: 52s - loss: 0.4850 - accuracy: 0.830 - ETA: 51s - loss: 0.4837 - accuracy: 0.830 - ETA: 51s - loss: 0.4820 - accuracy: 0.830 - ETA: 50s - loss: 0.4822 - accuracy: 0.830 - ETA: 49s - loss: 0.4819 - accuracy: 0.830 - ETA: 49s - loss: 0.4831 - accuracy: 0.830 - ETA: 48s - loss: 0.4834 - accuracy: 0.830 - ETA: 47s - loss: 0.4830 - accuracy: 0.830 - ETA: 47s - loss: 0.4820 - accuracy: 0.830 - ETA: 46s - loss: 0.4830 - accuracy: 0.829 - ETA: 45s - loss: 0.4819 - accuracy: 0.830 - ETA: 44s - loss: 0.4811 - accuracy: 0.830 - ETA: 43s - loss: 0.4810 - accuracy: 0.830 - ETA: 42s - loss: 0.4829 - accuracy: 0.830 - ETA: 41s - loss: 0.4837 - accuracy: 0.830 - ETA: 39s - loss: 0.4842 - accuracy: 0.830 - ETA: 38s - loss: 0.4835 - accuracy: 0.830 - ETA: 38s - loss: 0.4827 - accuracy: 0.830 - ETA: 37s - loss: 0.4843 - accuracy: 0.830 - ETA: 36s - loss: 0.4850 - accuracy: 0.829 - ETA: 35s - loss: 0.4857 - accuracy: 0.829 - ETA: 34s - loss: 0.4843 - accuracy: 0.829 - ETA: 33s - loss: 0.4856 - accuracy: 0.829 - ETA: 32s - loss: 0.4852 - accuracy: 0.829 - ETA: 31s - loss: 0.4849 - accuracy: 0.829 - ETA: 30s - loss: 0.4855 - accuracy: 0.829 - ETA: 29s - loss: 0.4852 - accuracy: 0.829 - ETA: 28s - loss: 0.4846 - accuracy: 0.829 - ETA: 27s - loss: 0.4844 - accuracy: 0.830 - ETA: 26s - loss: 0.4845 - accuracy: 0.830 - ETA: 25s - loss: 0.4852 - accuracy: 0.829 - ETA: 24s - loss: 0.4860 - accuracy: 0.829 - ETA: 23s - loss: 0.4866 - accuracy: 0.829 - ETA: 22s - loss: 0.4868 - accuracy: 0.829 - ETA: 21s - loss: 0.4863 - accuracy: 0.829 - ETA: 20s - loss: 0.4866 - accuracy: 0.829 - ETA: 19s - loss: 0.4870 - accuracy: 0.829 - ETA: 18s - loss: 0.4867 - accuracy: 0.829 - ETA: 16s - loss: 0.4871 - accuracy: 0.829 - ETA: 15s - loss: 0.4866 - accuracy: 0.829 - ETA: 14s - loss: 0.4858 - accuracy: 0.829 - ETA: 13s - loss: 0.4850 - accuracy: 0.829 - ETA: 12s - loss: 0.4852 - accuracy: 0.829 - ETA: 11s - loss: 0.4854 - accuracy: 0.829 - ETA: 10s - loss: 0.4844 - accuracy: 0.830 - ETA: 9s - loss: 0.4845 - accuracy: 0.830 - ETA: 8s - loss: 0.4845 - accuracy: 0.83 - ETA: 7s - loss: 0.4854 - accuracy: 0.83 - ETA: 6s - loss: 0.4850 - accuracy: 0.83 - ETA: 5s - loss: 0.4862 - accuracy: 0.82 - ETA: 4s - loss: 0.4856 - accuracy: 0.83 - ETA: 3s - loss: 0.4850 - accuracy: 0.83 - ETA: 2s - loss: 0.4854 - accuracy: 0.83 - ETA: 1s - loss: 0.4845 - accuracy: 0.83 - ETA: 0s - loss: 0.4845 - accuracy: 0.83 - 160s 8ms/step - loss: 0.4850 - accuracy: 0.8302 - val_loss: 1.4481 - val_accuracy: 0.7424\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:30 - loss: 0.2179 - accuracy: 0.92 - ETA: 2:25 - loss: 0.3135 - accuracy: 0.89 - ETA: 2:21 - loss: 0.3773 - accuracy: 0.85 - ETA: 2:16 - loss: 0.3641 - accuracy: 0.87 - ETA: 2:13 - loss: 0.3803 - accuracy: 0.87 - ETA: 2:11 - loss: 0.4181 - accuracy: 0.86 - ETA: 2:10 - loss: 0.4049 - accuracy: 0.86 - ETA: 2:09 - loss: 0.4207 - accuracy: 0.85 - ETA: 2:09 - loss: 0.4122 - accuracy: 0.85 - ETA: 2:08 - loss: 0.4332 - accuracy: 0.85 - ETA: 2:07 - loss: 0.4305 - accuracy: 0.85 - ETA: 2:05 - loss: 0.4374 - accuracy: 0.85 - ETA: 2:04 - loss: 0.4300 - accuracy: 0.85 - ETA: 2:04 - loss: 0.4173 - accuracy: 0.85 - ETA: 2:03 - loss: 0.4262 - accuracy: 0.85 - ETA: 2:01 - loss: 0.4321 - accuracy: 0.85 - ETA: 2:00 - loss: 0.4395 - accuracy: 0.85 - ETA: 1:59 - loss: 0.4433 - accuracy: 0.84 - ETA: 1:58 - loss: 0.4431 - accuracy: 0.84 - ETA: 1:58 - loss: 0.4446 - accuracy: 0.84 - ETA: 1:56 - loss: 0.4390 - accuracy: 0.85 - ETA: 1:55 - loss: 0.4369 - accuracy: 0.85 - ETA: 1:54 - loss: 0.4375 - accuracy: 0.85 - ETA: 1:53 - loss: 0.4384 - accuracy: 0.85 - ETA: 1:52 - loss: 0.4330 - accuracy: 0.85 - ETA: 1:51 - loss: 0.4375 - accuracy: 0.85 - ETA: 1:50 - loss: 0.4348 - accuracy: 0.85 - ETA: 1:49 - loss: 0.4329 - accuracy: 0.85 - ETA: 1:48 - loss: 0.4325 - accuracy: 0.85 - ETA: 1:47 - loss: 0.4326 - accuracy: 0.85 - ETA: 1:46 - loss: 0.4366 - accuracy: 0.84 - ETA: 1:45 - loss: 0.4438 - accuracy: 0.84 - ETA: 1:44 - loss: 0.4403 - accuracy: 0.84 - ETA: 1:43 - loss: 0.4374 - accuracy: 0.84 - ETA: 1:42 - loss: 0.4383 - accuracy: 0.84 - ETA: 1:41 - loss: 0.4421 - accuracy: 0.84 - ETA: 1:41 - loss: 0.4436 - accuracy: 0.84 - ETA: 1:40 - loss: 0.4448 - accuracy: 0.84 - ETA: 1:39 - loss: 0.4446 - accuracy: 0.84 - ETA: 1:38 - loss: 0.4469 - accuracy: 0.84 - ETA: 1:37 - loss: 0.4450 - accuracy: 0.84 - ETA: 1:36 - loss: 0.4482 - accuracy: 0.84 - ETA: 1:35 - loss: 0.4466 - accuracy: 0.84 - ETA: 1:35 - loss: 0.4456 - accuracy: 0.84 - ETA: 1:34 - loss: 0.4471 - accuracy: 0.84 - ETA: 1:33 - loss: 0.4476 - accuracy: 0.84 - ETA: 1:32 - loss: 0.4492 - accuracy: 0.84 - ETA: 1:31 - loss: 0.4520 - accuracy: 0.84 - ETA: 1:30 - loss: 0.4516 - accuracy: 0.84 - ETA: 1:29 - loss: 0.4530 - accuracy: 0.84 - ETA: 1:28 - loss: 0.4529 - accuracy: 0.84 - ETA: 1:27 - loss: 0.4533 - accuracy: 0.84 - ETA: 1:26 - loss: 0.4535 - accuracy: 0.84 - ETA: 1:25 - loss: 0.4536 - accuracy: 0.84 - ETA: 1:24 - loss: 0.4545 - accuracy: 0.84 - ETA: 1:24 - loss: 0.4557 - accuracy: 0.84 - ETA: 1:23 - loss: 0.4566 - accuracy: 0.84 - ETA: 1:22 - loss: 0.4581 - accuracy: 0.84 - ETA: 1:21 - loss: 0.4587 - accuracy: 0.84 - ETA: 1:20 - loss: 0.4594 - accuracy: 0.84 - ETA: 1:19 - loss: 0.4591 - accuracy: 0.84 - ETA: 1:18 - loss: 0.4611 - accuracy: 0.84 - ETA: 1:17 - loss: 0.4595 - accuracy: 0.84 - ETA: 1:16 - loss: 0.4582 - accuracy: 0.84 - ETA: 1:15 - loss: 0.4605 - accuracy: 0.84 - ETA: 1:15 - loss: 0.4612 - accuracy: 0.84 - ETA: 1:14 - loss: 0.4604 - accuracy: 0.84 - ETA: 1:13 - loss: 0.4595 - accuracy: 0.84 - ETA: 1:12 - loss: 0.4593 - accuracy: 0.84 - ETA: 1:11 - loss: 0.4585 - accuracy: 0.84 - ETA: 1:10 - loss: 0.4612 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4609 - accuracy: 0.84 - ETA: 1:08 - loss: 0.4605 - accuracy: 0.84 - ETA: 1:08 - loss: 0.4607 - accuracy: 0.84 - ETA: 1:07 - loss: 0.4596 - accuracy: 0.84 - ETA: 1:06 - loss: 0.4613 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4605 - accuracy: 0.84 - ETA: 1:04 - loss: 0.4635 - accuracy: 0.83 - ETA: 1:03 - loss: 0.4622 - accuracy: 0.83 - ETA: 1:02 - loss: 0.4643 - accuracy: 0.83 - ETA: 1:02 - loss: 0.4654 - accuracy: 0.83 - ETA: 1:01 - loss: 0.4648 - accuracy: 0.83 - ETA: 1:00 - loss: 0.4667 - accuracy: 0.83 - ETA: 59s - loss: 0.4668 - accuracy: 0.8380 - ETA: 58s - loss: 0.4667 - accuracy: 0.837 - ETA: 57s - loss: 0.4668 - accuracy: 0.837 - ETA: 56s - loss: 0.4673 - accuracy: 0.837 - ETA: 55s - loss: 0.4673 - accuracy: 0.837 - ETA: 55s - loss: 0.4675 - accuracy: 0.837 - ETA: 54s - loss: 0.4683 - accuracy: 0.837 - ETA: 53s - loss: 0.4670 - accuracy: 0.838 - ETA: 52s - loss: 0.4683 - accuracy: 0.837 - ETA: 51s - loss: 0.4684 - accuracy: 0.837 - ETA: 50s - loss: 0.4685 - accuracy: 0.837 - ETA: 49s - loss: 0.4687 - accuracy: 0.837 - ETA: 48s - loss: 0.4703 - accuracy: 0.836 - ETA: 48s - loss: 0.4700 - accuracy: 0.836 - ETA: 47s - loss: 0.4694 - accuracy: 0.837 - ETA: 46s - loss: 0.4690 - accuracy: 0.837 - ETA: 45s - loss: 0.4695 - accuracy: 0.837 - ETA: 44s - loss: 0.4697 - accuracy: 0.836 - ETA: 43s - loss: 0.4684 - accuracy: 0.837 - ETA: 42s - loss: 0.4688 - accuracy: 0.837 - ETA: 41s - loss: 0.4694 - accuracy: 0.836 - ETA: 40s - loss: 0.4687 - accuracy: 0.837 - ETA: 39s - loss: 0.4674 - accuracy: 0.837 - ETA: 39s - loss: 0.4690 - accuracy: 0.836 - ETA: 38s - loss: 0.4688 - accuracy: 0.836 - ETA: 37s - loss: 0.4677 - accuracy: 0.836 - ETA: 36s - loss: 0.4671 - accuracy: 0.837 - ETA: 35s - loss: 0.4682 - accuracy: 0.837 - ETA: 34s - loss: 0.4678 - accuracy: 0.837 - ETA: 33s - loss: 0.4679 - accuracy: 0.836 - ETA: 32s - loss: 0.4679 - accuracy: 0.836 - ETA: 32s - loss: 0.4680 - accuracy: 0.837 - ETA: 31s - loss: 0.4693 - accuracy: 0.836 - ETA: 30s - loss: 0.4694 - accuracy: 0.836 - ETA: 29s - loss: 0.4697 - accuracy: 0.836 - ETA: 28s - loss: 0.4710 - accuracy: 0.835 - ETA: 27s - loss: 0.4706 - accuracy: 0.835 - ETA: 26s - loss: 0.4699 - accuracy: 0.835 - ETA: 25s - loss: 0.4703 - accuracy: 0.835 - ETA: 24s - loss: 0.4704 - accuracy: 0.835 - ETA: 23s - loss: 0.4714 - accuracy: 0.835 - ETA: 23s - loss: 0.4700 - accuracy: 0.835 - ETA: 22s - loss: 0.4701 - accuracy: 0.835 - ETA: 21s - loss: 0.4704 - accuracy: 0.835 - ETA: 20s - loss: 0.4716 - accuracy: 0.834 - ETA: 19s - loss: 0.4706 - accuracy: 0.835 - ETA: 18s - loss: 0.4713 - accuracy: 0.834 - ETA: 17s - loss: 0.4710 - accuracy: 0.834 - ETA: 16s - loss: 0.4707 - accuracy: 0.835 - ETA: 15s - loss: 0.4696 - accuracy: 0.835 - ETA: 15s - loss: 0.4691 - accuracy: 0.835 - ETA: 14s - loss: 0.4701 - accuracy: 0.835 - ETA: 13s - loss: 0.4705 - accuracy: 0.835 - ETA: 12s - loss: 0.4705 - accuracy: 0.835 - ETA: 11s - loss: 0.4704 - accuracy: 0.835 - ETA: 10s - loss: 0.4710 - accuracy: 0.835 - ETA: 9s - loss: 0.4708 - accuracy: 0.835 - ETA: 8s - loss: 0.4691 - accuracy: 0.83 - ETA: 7s - loss: 0.4689 - accuracy: 0.83 - ETA: 7s - loss: 0.4682 - accuracy: 0.83 - ETA: 6s - loss: 0.4689 - accuracy: 0.83 - ETA: 5s - loss: 0.4679 - accuracy: 0.83 - ETA: 4s - loss: 0.4679 - accuracy: 0.83 - ETA: 3s - loss: 0.4678 - accuracy: 0.83 - ETA: 2s - loss: 0.4683 - accuracy: 0.83 - ETA: 1s - loss: 0.4685 - accuracy: 0.83 - ETA: 0s - loss: 0.4695 - accuracy: 0.83 - 147s 8ms/step - loss: 0.4699 - accuracy: 0.8361 - val_loss: 1.4474 - val_accuracy: 0.7428\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:21 - loss: 0.3779 - accuracy: 0.87 - ETA: 2:17 - loss: 0.3777 - accuracy: 0.87 - ETA: 2:16 - loss: 0.3775 - accuracy: 0.86 - ETA: 2:14 - loss: 0.3907 - accuracy: 0.86 - ETA: 2:12 - loss: 0.3678 - accuracy: 0.87 - ETA: 2:11 - loss: 0.3711 - accuracy: 0.86 - ETA: 2:10 - loss: 0.3816 - accuracy: 0.86 - ETA: 2:08 - loss: 0.3955 - accuracy: 0.85 - ETA: 2:06 - loss: 0.3986 - accuracy: 0.85 - ETA: 2:05 - loss: 0.3973 - accuracy: 0.85 - ETA: 2:04 - loss: 0.3888 - accuracy: 0.86 - ETA: 2:03 - loss: 0.4041 - accuracy: 0.85 - ETA: 2:02 - loss: 0.4080 - accuracy: 0.85 - ETA: 2:01 - loss: 0.4053 - accuracy: 0.85 - ETA: 2:00 - loss: 0.4126 - accuracy: 0.85 - ETA: 2:00 - loss: 0.4192 - accuracy: 0.85 - ETA: 2:00 - loss: 0.4228 - accuracy: 0.84 - ETA: 1:59 - loss: 0.4258 - accuracy: 0.84 - ETA: 1:58 - loss: 0.4271 - accuracy: 0.84 - ETA: 1:57 - loss: 0.4412 - accuracy: 0.84 - ETA: 1:56 - loss: 0.4449 - accuracy: 0.84 - ETA: 1:55 - loss: 0.4407 - accuracy: 0.84 - ETA: 1:54 - loss: 0.4445 - accuracy: 0.84 - ETA: 1:53 - loss: 0.4455 - accuracy: 0.84 - ETA: 1:52 - loss: 0.4398 - accuracy: 0.84 - ETA: 1:51 - loss: 0.4358 - accuracy: 0.84 - ETA: 1:50 - loss: 0.4382 - accuracy: 0.84 - ETA: 1:49 - loss: 0.4426 - accuracy: 0.84 - ETA: 1:48 - loss: 0.4375 - accuracy: 0.84 - ETA: 1:47 - loss: 0.4385 - accuracy: 0.84 - ETA: 1:46 - loss: 0.4408 - accuracy: 0.84 - ETA: 1:45 - loss: 0.4430 - accuracy: 0.84 - ETA: 1:44 - loss: 0.4431 - accuracy: 0.84 - ETA: 1:43 - loss: 0.4404 - accuracy: 0.84 - ETA: 1:43 - loss: 0.4404 - accuracy: 0.84 - ETA: 1:42 - loss: 0.4432 - accuracy: 0.84 - ETA: 1:41 - loss: 0.4430 - accuracy: 0.84 - ETA: 1:40 - loss: 0.4416 - accuracy: 0.84 - ETA: 1:39 - loss: 0.4394 - accuracy: 0.84 - ETA: 1:38 - loss: 0.4419 - accuracy: 0.84 - ETA: 1:37 - loss: 0.4419 - accuracy: 0.84 - ETA: 1:36 - loss: 0.4387 - accuracy: 0.84 - ETA: 1:35 - loss: 0.4361 - accuracy: 0.84 - ETA: 1:35 - loss: 0.4362 - accuracy: 0.84 - ETA: 1:34 - loss: 0.4370 - accuracy: 0.84 - ETA: 1:33 - loss: 0.4353 - accuracy: 0.84 - ETA: 1:32 - loss: 0.4344 - accuracy: 0.84 - ETA: 1:31 - loss: 0.4323 - accuracy: 0.84 - ETA: 1:30 - loss: 0.4321 - accuracy: 0.84 - ETA: 1:29 - loss: 0.4330 - accuracy: 0.84 - ETA: 1:29 - loss: 0.4309 - accuracy: 0.84 - ETA: 1:28 - loss: 0.4298 - accuracy: 0.84 - ETA: 1:27 - loss: 0.4327 - accuracy: 0.84 - ETA: 1:26 - loss: 0.4296 - accuracy: 0.84 - ETA: 1:25 - loss: 0.4300 - accuracy: 0.84 - ETA: 1:24 - loss: 0.4307 - accuracy: 0.84 - ETA: 1:23 - loss: 0.4322 - accuracy: 0.84 - ETA: 1:22 - loss: 0.4314 - accuracy: 0.84 - ETA: 1:22 - loss: 0.4312 - accuracy: 0.84 - ETA: 1:21 - loss: 0.4319 - accuracy: 0.84 - ETA: 1:20 - loss: 0.4311 - accuracy: 0.84 - ETA: 1:19 - loss: 0.4324 - accuracy: 0.84 - ETA: 1:18 - loss: 0.4342 - accuracy: 0.84 - ETA: 1:17 - loss: 0.4338 - accuracy: 0.84 - ETA: 1:16 - loss: 0.4333 - accuracy: 0.84 - ETA: 1:15 - loss: 0.4353 - accuracy: 0.84 - ETA: 1:15 - loss: 0.4357 - accuracy: 0.84 - ETA: 1:14 - loss: 0.4360 - accuracy: 0.84 - ETA: 1:13 - loss: 0.4383 - accuracy: 0.84 - ETA: 1:12 - loss: 0.4409 - accuracy: 0.84 - ETA: 1:11 - loss: 0.4388 - accuracy: 0.84 - ETA: 1:10 - loss: 0.4391 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4407 - accuracy: 0.84 - ETA: 1:08 - loss: 0.4418 - accuracy: 0.84 - ETA: 1:08 - loss: 0.4415 - accuracy: 0.84 - ETA: 1:07 - loss: 0.4414 - accuracy: 0.84 - ETA: 1:06 - loss: 0.4434 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4435 - accuracy: 0.84 - ETA: 1:04 - loss: 0.4432 - accuracy: 0.84 - ETA: 1:03 - loss: 0.4447 - accuracy: 0.84 - ETA: 1:02 - loss: 0.4430 - accuracy: 0.84 - ETA: 1:01 - loss: 0.4417 - accuracy: 0.84 - ETA: 1:00 - loss: 0.4415 - accuracy: 0.84 - ETA: 59s - loss: 0.4440 - accuracy: 0.8446 - ETA: 59s - loss: 0.4432 - accuracy: 0.844 - ETA: 58s - loss: 0.4434 - accuracy: 0.845 - ETA: 57s - loss: 0.4422 - accuracy: 0.845 - ETA: 56s - loss: 0.4433 - accuracy: 0.845 - ETA: 55s - loss: 0.4440 - accuracy: 0.844 - ETA: 54s - loss: 0.4436 - accuracy: 0.845 - ETA: 53s - loss: 0.4447 - accuracy: 0.844 - ETA: 52s - loss: 0.4449 - accuracy: 0.844 - ETA: 51s - loss: 0.4444 - accuracy: 0.844 - ETA: 51s - loss: 0.4439 - accuracy: 0.844 - ETA: 50s - loss: 0.4442 - accuracy: 0.844 - ETA: 49s - loss: 0.4443 - accuracy: 0.844 - ETA: 48s - loss: 0.4450 - accuracy: 0.843 - ETA: 47s - loss: 0.4441 - accuracy: 0.844 - ETA: 46s - loss: 0.4455 - accuracy: 0.843 - ETA: 45s - loss: 0.4459 - accuracy: 0.843 - ETA: 44s - loss: 0.4465 - accuracy: 0.843 - ETA: 43s - loss: 0.4480 - accuracy: 0.843 - ETA: 42s - loss: 0.4480 - accuracy: 0.843 - ETA: 42s - loss: 0.4478 - accuracy: 0.842 - ETA: 41s - loss: 0.4480 - accuracy: 0.842 - ETA: 40s - loss: 0.4486 - accuracy: 0.842 - ETA: 39s - loss: 0.4498 - accuracy: 0.842 - ETA: 38s - loss: 0.4502 - accuracy: 0.842 - ETA: 37s - loss: 0.4500 - accuracy: 0.842 - ETA: 36s - loss: 0.4507 - accuracy: 0.842 - ETA: 35s - loss: 0.4511 - accuracy: 0.842 - ETA: 34s - loss: 0.4507 - accuracy: 0.842 - ETA: 34s - loss: 0.4520 - accuracy: 0.841 - ETA: 33s - loss: 0.4515 - accuracy: 0.842 - ETA: 32s - loss: 0.4508 - accuracy: 0.842 - ETA: 31s - loss: 0.4509 - accuracy: 0.842 - ETA: 30s - loss: 0.4508 - accuracy: 0.842 - ETA: 29s - loss: 0.4513 - accuracy: 0.842 - ETA: 28s - loss: 0.4519 - accuracy: 0.841 - ETA: 27s - loss: 0.4522 - accuracy: 0.841 - ETA: 26s - loss: 0.4515 - accuracy: 0.841 - ETA: 25s - loss: 0.4514 - accuracy: 0.841 - ETA: 25s - loss: 0.4524 - accuracy: 0.841 - ETA: 24s - loss: 0.4530 - accuracy: 0.840 - ETA: 23s - loss: 0.4535 - accuracy: 0.840 - ETA: 22s - loss: 0.4536 - accuracy: 0.840 - ETA: 21s - loss: 0.4537 - accuracy: 0.840 - ETA: 20s - loss: 0.4548 - accuracy: 0.840 - ETA: 19s - loss: 0.4544 - accuracy: 0.840 - ETA: 18s - loss: 0.4552 - accuracy: 0.840 - ETA: 17s - loss: 0.4557 - accuracy: 0.840 - ETA: 16s - loss: 0.4553 - accuracy: 0.840 - ETA: 16s - loss: 0.4562 - accuracy: 0.839 - ETA: 15s - loss: 0.4565 - accuracy: 0.839 - ETA: 14s - loss: 0.4561 - accuracy: 0.839 - ETA: 13s - loss: 0.4569 - accuracy: 0.839 - ETA: 12s - loss: 0.4570 - accuracy: 0.839 - ETA: 11s - loss: 0.4564 - accuracy: 0.839 - ETA: 10s - loss: 0.4571 - accuracy: 0.839 - ETA: 9s - loss: 0.4576 - accuracy: 0.839 - ETA: 8s - loss: 0.4578 - accuracy: 0.83 - ETA: 7s - loss: 0.4577 - accuracy: 0.83 - ETA: 7s - loss: 0.4583 - accuracy: 0.83 - ETA: 6s - loss: 0.4577 - accuracy: 0.83 - ETA: 5s - loss: 0.4566 - accuracy: 0.83 - ETA: 4s - loss: 0.4565 - accuracy: 0.83 - ETA: 3s - loss: 0.4573 - accuracy: 0.83 - ETA: 2s - loss: 0.4571 - accuracy: 0.83 - ETA: 1s - loss: 0.4569 - accuracy: 0.83 - ETA: 0s - loss: 0.4563 - accuracy: 0.83 - 147s 8ms/step - loss: 0.4569 - accuracy: 0.8389 - val_loss: 1.4497 - val_accuracy: 0.7418\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:07 - loss: 0.4936 - accuracy: 0.82 - ETA: 2:06 - loss: 0.4507 - accuracy: 0.83 - ETA: 2:05 - loss: 0.4592 - accuracy: 0.83 - ETA: 2:06 - loss: 0.4859 - accuracy: 0.82 - ETA: 2:08 - loss: 0.4583 - accuracy: 0.83 - ETA: 2:09 - loss: 0.4605 - accuracy: 0.83 - ETA: 2:08 - loss: 0.4596 - accuracy: 0.83 - ETA: 2:07 - loss: 0.4557 - accuracy: 0.83 - ETA: 2:06 - loss: 0.4508 - accuracy: 0.83 - ETA: 2:05 - loss: 0.4534 - accuracy: 0.83 - ETA: 2:04 - loss: 0.4475 - accuracy: 0.83 - ETA: 2:03 - loss: 0.4425 - accuracy: 0.84 - ETA: 2:03 - loss: 0.4378 - accuracy: 0.84 - ETA: 2:02 - loss: 0.4405 - accuracy: 0.83 - ETA: 2:01 - loss: 0.4414 - accuracy: 0.84 - ETA: 2:00 - loss: 0.4506 - accuracy: 0.83 - ETA: 1:59 - loss: 0.4407 - accuracy: 0.84 - ETA: 1:58 - loss: 0.4345 - accuracy: 0.84 - ETA: 1:57 - loss: 0.4415 - accuracy: 0.84 - ETA: 1:56 - loss: 0.4341 - accuracy: 0.84 - ETA: 1:55 - loss: 0.4361 - accuracy: 0.84 - ETA: 1:54 - loss: 0.4388 - accuracy: 0.84 - ETA: 1:53 - loss: 0.4424 - accuracy: 0.84 - ETA: 1:52 - loss: 0.4470 - accuracy: 0.83 - ETA: 1:51 - loss: 0.4478 - accuracy: 0.83 - ETA: 1:50 - loss: 0.4518 - accuracy: 0.83 - ETA: 1:49 - loss: 0.4554 - accuracy: 0.83 - ETA: 1:48 - loss: 0.4543 - accuracy: 0.83 - ETA: 1:48 - loss: 0.4553 - accuracy: 0.83 - ETA: 1:47 - loss: 0.4558 - accuracy: 0.83 - ETA: 1:46 - loss: 0.4590 - accuracy: 0.83 - ETA: 1:46 - loss: 0.4585 - accuracy: 0.83 - ETA: 1:45 - loss: 0.4568 - accuracy: 0.83 - ETA: 1:44 - loss: 0.4529 - accuracy: 0.83 - ETA: 1:43 - loss: 0.4500 - accuracy: 0.84 - ETA: 1:42 - loss: 0.4528 - accuracy: 0.83 - ETA: 1:41 - loss: 0.4479 - accuracy: 0.84 - ETA: 1:40 - loss: 0.4489 - accuracy: 0.84 - ETA: 1:39 - loss: 0.4499 - accuracy: 0.84 - ETA: 1:38 - loss: 0.4486 - accuracy: 0.84 - ETA: 1:37 - loss: 0.4482 - accuracy: 0.84 - ETA: 1:36 - loss: 0.4493 - accuracy: 0.84 - ETA: 1:35 - loss: 0.4480 - accuracy: 0.84 - ETA: 1:35 - loss: 0.4485 - accuracy: 0.84 - ETA: 1:34 - loss: 0.4511 - accuracy: 0.83 - ETA: 1:33 - loss: 0.4518 - accuracy: 0.83 - ETA: 1:32 - loss: 0.4499 - accuracy: 0.83 - ETA: 1:31 - loss: 0.4495 - accuracy: 0.83 - ETA: 1:31 - loss: 0.4467 - accuracy: 0.84 - ETA: 1:30 - loss: 0.4458 - accuracy: 0.84 - ETA: 1:29 - loss: 0.4468 - accuracy: 0.84 - ETA: 1:28 - loss: 0.4469 - accuracy: 0.84 - ETA: 1:27 - loss: 0.4462 - accuracy: 0.84 - ETA: 1:26 - loss: 0.4459 - accuracy: 0.84 - ETA: 1:25 - loss: 0.4426 - accuracy: 0.84 - ETA: 1:24 - loss: 0.4431 - accuracy: 0.84 - ETA: 1:24 - loss: 0.4444 - accuracy: 0.84 - ETA: 1:23 - loss: 0.4436 - accuracy: 0.84 - ETA: 1:22 - loss: 0.4449 - accuracy: 0.84 - ETA: 1:21 - loss: 0.4492 - accuracy: 0.84 - ETA: 1:20 - loss: 0.4477 - accuracy: 0.84 - ETA: 1:19 - loss: 0.4476 - accuracy: 0.84 - ETA: 1:18 - loss: 0.4481 - accuracy: 0.84 - ETA: 1:17 - loss: 0.4485 - accuracy: 0.84 - ETA: 1:16 - loss: 0.4479 - accuracy: 0.84 - ETA: 1:15 - loss: 0.4456 - accuracy: 0.84 - ETA: 1:14 - loss: 0.4430 - accuracy: 0.84 - ETA: 1:14 - loss: 0.4424 - accuracy: 0.84 - ETA: 1:13 - loss: 0.4417 - accuracy: 0.84 - ETA: 1:12 - loss: 0.4408 - accuracy: 0.84 - ETA: 1:11 - loss: 0.4409 - accuracy: 0.84 - ETA: 1:10 - loss: 0.4421 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4416 - accuracy: 0.84 - ETA: 1:08 - loss: 0.4419 - accuracy: 0.84 - ETA: 1:07 - loss: 0.4427 - accuracy: 0.84 - ETA: 1:06 - loss: 0.4429 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4432 - accuracy: 0.84 - ETA: 1:04 - loss: 0.4423 - accuracy: 0.84 - ETA: 1:03 - loss: 0.4433 - accuracy: 0.84 - ETA: 1:03 - loss: 0.4433 - accuracy: 0.84 - ETA: 1:02 - loss: 0.4431 - accuracy: 0.84 - ETA: 1:01 - loss: 0.4412 - accuracy: 0.84 - ETA: 1:00 - loss: 0.4412 - accuracy: 0.84 - ETA: 59s - loss: 0.4403 - accuracy: 0.8472 - ETA: 58s - loss: 0.4405 - accuracy: 0.847 - ETA: 57s - loss: 0.4398 - accuracy: 0.847 - ETA: 56s - loss: 0.4394 - accuracy: 0.847 - ETA: 55s - loss: 0.4390 - accuracy: 0.847 - ETA: 55s - loss: 0.4379 - accuracy: 0.847 - ETA: 54s - loss: 0.4399 - accuracy: 0.846 - ETA: 53s - loss: 0.4409 - accuracy: 0.846 - ETA: 52s - loss: 0.4413 - accuracy: 0.846 - ETA: 51s - loss: 0.4426 - accuracy: 0.846 - ETA: 50s - loss: 0.4418 - accuracy: 0.846 - ETA: 49s - loss: 0.4418 - accuracy: 0.846 - ETA: 48s - loss: 0.4420 - accuracy: 0.846 - ETA: 47s - loss: 0.4414 - accuracy: 0.846 - ETA: 47s - loss: 0.4409 - accuracy: 0.846 - ETA: 46s - loss: 0.4401 - accuracy: 0.847 - ETA: 45s - loss: 0.4387 - accuracy: 0.847 - ETA: 44s - loss: 0.4386 - accuracy: 0.847 - ETA: 43s - loss: 0.4394 - accuracy: 0.847 - ETA: 42s - loss: 0.4388 - accuracy: 0.847 - ETA: 41s - loss: 0.4377 - accuracy: 0.847 - ETA: 40s - loss: 0.4380 - accuracy: 0.847 - ETA: 40s - loss: 0.4391 - accuracy: 0.846 - ETA: 39s - loss: 0.4389 - accuracy: 0.847 - ETA: 38s - loss: 0.4393 - accuracy: 0.846 - ETA: 37s - loss: 0.4385 - accuracy: 0.846 - ETA: 36s - loss: 0.4392 - accuracy: 0.846 - ETA: 35s - loss: 0.4402 - accuracy: 0.845 - ETA: 34s - loss: 0.4393 - accuracy: 0.846 - ETA: 33s - loss: 0.4395 - accuracy: 0.846 - ETA: 32s - loss: 0.4395 - accuracy: 0.846 - ETA: 31s - loss: 0.4398 - accuracy: 0.846 - ETA: 31s - loss: 0.4400 - accuracy: 0.845 - ETA: 30s - loss: 0.4405 - accuracy: 0.845 - ETA: 29s - loss: 0.4400 - accuracy: 0.845 - ETA: 28s - loss: 0.4405 - accuracy: 0.845 - ETA: 27s - loss: 0.4409 - accuracy: 0.845 - ETA: 26s - loss: 0.4419 - accuracy: 0.845 - ETA: 25s - loss: 0.4421 - accuracy: 0.845 - ETA: 24s - loss: 0.4414 - accuracy: 0.845 - ETA: 23s - loss: 0.4408 - accuracy: 0.845 - ETA: 23s - loss: 0.4418 - accuracy: 0.845 - ETA: 22s - loss: 0.4418 - accuracy: 0.845 - ETA: 21s - loss: 0.4415 - accuracy: 0.845 - ETA: 20s - loss: 0.4412 - accuracy: 0.845 - ETA: 19s - loss: 0.4415 - accuracy: 0.845 - ETA: 18s - loss: 0.4425 - accuracy: 0.845 - ETA: 17s - loss: 0.4430 - accuracy: 0.844 - ETA: 16s - loss: 0.4443 - accuracy: 0.844 - ETA: 15s - loss: 0.4447 - accuracy: 0.843 - ETA: 15s - loss: 0.4446 - accuracy: 0.843 - ETA: 14s - loss: 0.4455 - accuracy: 0.843 - ETA: 13s - loss: 0.4460 - accuracy: 0.843 - ETA: 12s - loss: 0.4464 - accuracy: 0.843 - ETA: 11s - loss: 0.4462 - accuracy: 0.843 - ETA: 10s - loss: 0.4459 - accuracy: 0.843 - ETA: 9s - loss: 0.4449 - accuracy: 0.843 - ETA: 8s - loss: 0.4442 - accuracy: 0.84 - ETA: 7s - loss: 0.4435 - accuracy: 0.84 - ETA: 7s - loss: 0.4432 - accuracy: 0.84 - ETA: 6s - loss: 0.4436 - accuracy: 0.84 - ETA: 5s - loss: 0.4436 - accuracy: 0.84 - ETA: 4s - loss: 0.4436 - accuracy: 0.84 - ETA: 3s - loss: 0.4440 - accuracy: 0.84 - ETA: 2s - loss: 0.4441 - accuracy: 0.84 - ETA: 1s - loss: 0.4447 - accuracy: 0.84 - ETA: 0s - loss: 0.4444 - accuracy: 0.84 - 146s 8ms/step - loss: 0.4438 - accuracy: 0.8435 - val_loss: 1.4831 - val_accuracy: 0.7399\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 0.3924 - accuracy: 0.85 - ETA: 2:18 - loss: 0.3781 - accuracy: 0.87 - ETA: 2:12 - loss: 0.3908 - accuracy: 0.85 - ETA: 2:10 - loss: 0.4210 - accuracy: 0.85 - ETA: 2:09 - loss: 0.4242 - accuracy: 0.85 - ETA: 2:09 - loss: 0.4251 - accuracy: 0.85 - ETA: 2:07 - loss: 0.4488 - accuracy: 0.84 - ETA: 2:07 - loss: 0.4429 - accuracy: 0.84 - ETA: 2:07 - loss: 0.4396 - accuracy: 0.84 - ETA: 2:07 - loss: 0.4456 - accuracy: 0.84 - ETA: 2:06 - loss: 0.4333 - accuracy: 0.84 - ETA: 2:06 - loss: 0.4365 - accuracy: 0.84 - ETA: 2:05 - loss: 0.4335 - accuracy: 0.84 - ETA: 2:04 - loss: 0.4321 - accuracy: 0.84 - ETA: 2:02 - loss: 0.4243 - accuracy: 0.84 - ETA: 2:01 - loss: 0.4279 - accuracy: 0.85 - ETA: 2:00 - loss: 0.4450 - accuracy: 0.84 - ETA: 1:59 - loss: 0.4407 - accuracy: 0.84 - ETA: 1:58 - loss: 0.4462 - accuracy: 0.84 - ETA: 1:57 - loss: 0.4517 - accuracy: 0.84 - ETA: 1:56 - loss: 0.4566 - accuracy: 0.84 - ETA: 1:55 - loss: 0.4552 - accuracy: 0.84 - ETA: 1:53 - loss: 0.4583 - accuracy: 0.84 - ETA: 1:53 - loss: 0.4552 - accuracy: 0.84 - ETA: 1:52 - loss: 0.4537 - accuracy: 0.84 - ETA: 1:51 - loss: 0.4506 - accuracy: 0.84 - ETA: 1:50 - loss: 0.4528 - accuracy: 0.84 - ETA: 1:49 - loss: 0.4562 - accuracy: 0.84 - ETA: 1:49 - loss: 0.4523 - accuracy: 0.84 - ETA: 1:48 - loss: 0.4470 - accuracy: 0.84 - ETA: 1:47 - loss: 0.4447 - accuracy: 0.84 - ETA: 1:46 - loss: 0.4427 - accuracy: 0.84 - ETA: 1:46 - loss: 0.4394 - accuracy: 0.84 - ETA: 1:45 - loss: 0.4413 - accuracy: 0.84 - ETA: 1:44 - loss: 0.4394 - accuracy: 0.84 - ETA: 1:43 - loss: 0.4384 - accuracy: 0.84 - ETA: 1:42 - loss: 0.4379 - accuracy: 0.84 - ETA: 1:41 - loss: 0.4407 - accuracy: 0.84 - ETA: 1:40 - loss: 0.4469 - accuracy: 0.84 - ETA: 1:39 - loss: 0.4477 - accuracy: 0.84 - ETA: 1:38 - loss: 0.4447 - accuracy: 0.84 - ETA: 1:37 - loss: 0.4449 - accuracy: 0.84 - ETA: 1:36 - loss: 0.4423 - accuracy: 0.84 - ETA: 1:35 - loss: 0.4427 - accuracy: 0.84 - ETA: 1:35 - loss: 0.4395 - accuracy: 0.84 - ETA: 1:34 - loss: 0.4353 - accuracy: 0.84 - ETA: 1:33 - loss: 0.4356 - accuracy: 0.85 - ETA: 1:32 - loss: 0.4369 - accuracy: 0.84 - ETA: 1:31 - loss: 0.4356 - accuracy: 0.85 - ETA: 1:30 - loss: 0.4367 - accuracy: 0.84 - ETA: 1:29 - loss: 0.4358 - accuracy: 0.84 - ETA: 1:28 - loss: 0.4368 - accuracy: 0.84 - ETA: 1:27 - loss: 0.4345 - accuracy: 0.84 - ETA: 1:26 - loss: 0.4326 - accuracy: 0.84 - ETA: 1:25 - loss: 0.4337 - accuracy: 0.84 - ETA: 1:24 - loss: 0.4331 - accuracy: 0.84 - ETA: 1:23 - loss: 0.4325 - accuracy: 0.84 - ETA: 1:23 - loss: 0.4341 - accuracy: 0.84 - ETA: 1:22 - loss: 0.4345 - accuracy: 0.84 - ETA: 1:21 - loss: 0.4367 - accuracy: 0.84 - ETA: 1:20 - loss: 0.4371 - accuracy: 0.84 - ETA: 1:19 - loss: 0.4391 - accuracy: 0.84 - ETA: 1:18 - loss: 0.4393 - accuracy: 0.84 - ETA: 1:17 - loss: 0.4396 - accuracy: 0.84 - ETA: 1:16 - loss: 0.4411 - accuracy: 0.84 - ETA: 1:16 - loss: 0.4412 - accuracy: 0.84 - ETA: 1:15 - loss: 0.4417 - accuracy: 0.84 - ETA: 1:14 - loss: 0.4399 - accuracy: 0.84 - ETA: 1:13 - loss: 0.4394 - accuracy: 0.84 - ETA: 1:12 - loss: 0.4381 - accuracy: 0.84 - ETA: 1:11 - loss: 0.4383 - accuracy: 0.84 - ETA: 1:10 - loss: 0.4385 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4403 - accuracy: 0.84 - ETA: 1:08 - loss: 0.4407 - accuracy: 0.84 - ETA: 1:07 - loss: 0.4437 - accuracy: 0.84 - ETA: 1:06 - loss: 0.4441 - accuracy: 0.84 - ETA: 1:06 - loss: 0.4439 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4447 - accuracy: 0.84 - ETA: 1:04 - loss: 0.4446 - accuracy: 0.84 - ETA: 1:03 - loss: 0.4462 - accuracy: 0.84 - ETA: 1:02 - loss: 0.4475 - accuracy: 0.84 - ETA: 1:01 - loss: 0.4473 - accuracy: 0.84 - ETA: 1:00 - loss: 0.4477 - accuracy: 0.84 - ETA: 59s - loss: 0.4494 - accuracy: 0.8420 - ETA: 58s - loss: 0.4509 - accuracy: 0.842 - ETA: 57s - loss: 0.4506 - accuracy: 0.842 - ETA: 57s - loss: 0.4511 - accuracy: 0.842 - ETA: 56s - loss: 0.4515 - accuracy: 0.842 - ETA: 55s - loss: 0.4513 - accuracy: 0.842 - ETA: 54s - loss: 0.4523 - accuracy: 0.842 - ETA: 53s - loss: 0.4535 - accuracy: 0.841 - ETA: 52s - loss: 0.4520 - accuracy: 0.842 - ETA: 51s - loss: 0.4513 - accuracy: 0.842 - ETA: 50s - loss: 0.4521 - accuracy: 0.842 - ETA: 49s - loss: 0.4535 - accuracy: 0.841 - ETA: 49s - loss: 0.4536 - accuracy: 0.841 - ETA: 48s - loss: 0.4533 - accuracy: 0.841 - ETA: 47s - loss: 0.4523 - accuracy: 0.841 - ETA: 46s - loss: 0.4515 - accuracy: 0.841 - ETA: 45s - loss: 0.4518 - accuracy: 0.841 - ETA: 44s - loss: 0.4511 - accuracy: 0.841 - ETA: 43s - loss: 0.4502 - accuracy: 0.842 - ETA: 42s - loss: 0.4511 - accuracy: 0.842 - ETA: 41s - loss: 0.4518 - accuracy: 0.841 - ETA: 41s - loss: 0.4537 - accuracy: 0.841 - ETA: 40s - loss: 0.4531 - accuracy: 0.841 - ETA: 39s - loss: 0.4528 - accuracy: 0.841 - ETA: 38s - loss: 0.4535 - accuracy: 0.840 - ETA: 37s - loss: 0.4534 - accuracy: 0.840 - ETA: 36s - loss: 0.4539 - accuracy: 0.840 - ETA: 35s - loss: 0.4529 - accuracy: 0.840 - ETA: 34s - loss: 0.4539 - accuracy: 0.840 - ETA: 33s - loss: 0.4536 - accuracy: 0.840 - ETA: 32s - loss: 0.4524 - accuracy: 0.841 - ETA: 32s - loss: 0.4528 - accuracy: 0.840 - ETA: 31s - loss: 0.4537 - accuracy: 0.840 - ETA: 30s - loss: 0.4529 - accuracy: 0.840 - ETA: 29s - loss: 0.4536 - accuracy: 0.840 - ETA: 28s - loss: 0.4539 - accuracy: 0.840 - ETA: 27s - loss: 0.4549 - accuracy: 0.839 - ETA: 26s - loss: 0.4543 - accuracy: 0.839 - ETA: 25s - loss: 0.4539 - accuracy: 0.839 - ETA: 24s - loss: 0.4530 - accuracy: 0.839 - ETA: 24s - loss: 0.4527 - accuracy: 0.840 - ETA: 23s - loss: 0.4529 - accuracy: 0.839 - ETA: 22s - loss: 0.4518 - accuracy: 0.840 - ETA: 21s - loss: 0.4513 - accuracy: 0.840 - ETA: 20s - loss: 0.4510 - accuracy: 0.840 - ETA: 19s - loss: 0.4501 - accuracy: 0.840 - ETA: 18s - loss: 0.4492 - accuracy: 0.840 - ETA: 17s - loss: 0.4496 - accuracy: 0.840 - ETA: 16s - loss: 0.4499 - accuracy: 0.840 - ETA: 15s - loss: 0.4510 - accuracy: 0.840 - ETA: 15s - loss: 0.4503 - accuracy: 0.840 - ETA: 14s - loss: 0.4502 - accuracy: 0.840 - ETA: 13s - loss: 0.4491 - accuracy: 0.841 - ETA: 12s - loss: 0.4492 - accuracy: 0.841 - ETA: 11s - loss: 0.4490 - accuracy: 0.841 - ETA: 10s - loss: 0.4492 - accuracy: 0.841 - ETA: 9s - loss: 0.4494 - accuracy: 0.841 - ETA: 8s - loss: 0.4493 - accuracy: 0.84 - ETA: 7s - loss: 0.4492 - accuracy: 0.84 - ETA: 7s - loss: 0.4482 - accuracy: 0.84 - ETA: 6s - loss: 0.4491 - accuracy: 0.84 - ETA: 5s - loss: 0.4493 - accuracy: 0.84 - ETA: 4s - loss: 0.4480 - accuracy: 0.84 - ETA: 3s - loss: 0.4472 - accuracy: 0.84 - ETA: 2s - loss: 0.4468 - accuracy: 0.84 - ETA: 1s - loss: 0.4477 - accuracy: 0.84 - ETA: 0s - loss: 0.4486 - accuracy: 0.84 - 146s 8ms/step - loss: 0.4482 - accuracy: 0.8413 - val_loss: 1.4670 - val_accuracy: 0.7440\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:23 - loss: 0.4474 - accuracy: 0.84 - ETA: 2:12 - loss: 0.4312 - accuracy: 0.85 - ETA: 2:11 - loss: 0.4632 - accuracy: 0.84 - ETA: 2:11 - loss: 0.4487 - accuracy: 0.84 - ETA: 2:09 - loss: 0.4345 - accuracy: 0.85 - ETA: 2:08 - loss: 0.4228 - accuracy: 0.85 - ETA: 2:09 - loss: 0.4071 - accuracy: 0.85 - ETA: 2:09 - loss: 0.4186 - accuracy: 0.85 - ETA: 2:07 - loss: 0.4115 - accuracy: 0.85 - ETA: 2:06 - loss: 0.4200 - accuracy: 0.85 - ETA: 2:05 - loss: 0.4223 - accuracy: 0.85 - ETA: 2:03 - loss: 0.4208 - accuracy: 0.85 - ETA: 2:03 - loss: 0.4176 - accuracy: 0.85 - ETA: 2:04 - loss: 0.4227 - accuracy: 0.85 - ETA: 2:03 - loss: 0.4266 - accuracy: 0.85 - ETA: 2:02 - loss: 0.4262 - accuracy: 0.85 - ETA: 2:01 - loss: 0.4266 - accuracy: 0.84 - ETA: 2:00 - loss: 0.4236 - accuracy: 0.84 - ETA: 1:59 - loss: 0.4264 - accuracy: 0.84 - ETA: 1:58 - loss: 0.4306 - accuracy: 0.84 - ETA: 1:57 - loss: 0.4247 - accuracy: 0.85 - ETA: 1:56 - loss: 0.4259 - accuracy: 0.85 - ETA: 1:55 - loss: 0.4277 - accuracy: 0.85 - ETA: 1:54 - loss: 0.4302 - accuracy: 0.84 - ETA: 1:54 - loss: 0.4310 - accuracy: 0.84 - ETA: 1:53 - loss: 0.4293 - accuracy: 0.84 - ETA: 1:52 - loss: 0.4329 - accuracy: 0.84 - ETA: 1:51 - loss: 0.4329 - accuracy: 0.84 - ETA: 1:50 - loss: 0.4366 - accuracy: 0.84 - ETA: 1:49 - loss: 0.4390 - accuracy: 0.84 - ETA: 1:48 - loss: 0.4346 - accuracy: 0.84 - ETA: 1:47 - loss: 0.4370 - accuracy: 0.84 - ETA: 1:46 - loss: 0.4382 - accuracy: 0.84 - ETA: 1:45 - loss: 0.4354 - accuracy: 0.84 - ETA: 1:44 - loss: 0.4332 - accuracy: 0.84 - ETA: 1:43 - loss: 0.4326 - accuracy: 0.84 - ETA: 1:42 - loss: 0.4341 - accuracy: 0.84 - ETA: 1:41 - loss: 0.4387 - accuracy: 0.84 - ETA: 1:40 - loss: 0.4383 - accuracy: 0.84 - ETA: 1:39 - loss: 0.4360 - accuracy: 0.84 - ETA: 1:38 - loss: 0.4358 - accuracy: 0.84 - ETA: 1:38 - loss: 0.4374 - accuracy: 0.84 - ETA: 1:37 - loss: 0.4380 - accuracy: 0.84 - ETA: 1:37 - loss: 0.4368 - accuracy: 0.84 - ETA: 1:36 - loss: 0.4338 - accuracy: 0.84 - ETA: 1:35 - loss: 0.4336 - accuracy: 0.84 - ETA: 1:34 - loss: 0.4320 - accuracy: 0.84 - ETA: 1:33 - loss: 0.4308 - accuracy: 0.84 - ETA: 1:33 - loss: 0.4304 - accuracy: 0.84 - ETA: 1:32 - loss: 0.4335 - accuracy: 0.84 - ETA: 1:31 - loss: 0.4317 - accuracy: 0.84 - ETA: 1:29 - loss: 0.4318 - accuracy: 0.84 - ETA: 1:29 - loss: 0.4319 - accuracy: 0.84 - ETA: 1:28 - loss: 0.4327 - accuracy: 0.84 - ETA: 1:27 - loss: 0.4324 - accuracy: 0.84 - ETA: 1:26 - loss: 0.4335 - accuracy: 0.84 - ETA: 1:25 - loss: 0.4339 - accuracy: 0.84 - ETA: 1:24 - loss: 0.4336 - accuracy: 0.84 - ETA: 1:23 - loss: 0.4332 - accuracy: 0.84 - ETA: 1:22 - loss: 0.4331 - accuracy: 0.84 - ETA: 1:21 - loss: 0.4320 - accuracy: 0.84 - ETA: 1:20 - loss: 0.4339 - accuracy: 0.84 - ETA: 1:19 - loss: 0.4336 - accuracy: 0.84 - ETA: 1:19 - loss: 0.4324 - accuracy: 0.84 - ETA: 1:18 - loss: 0.4322 - accuracy: 0.84 - ETA: 1:17 - loss: 0.4330 - accuracy: 0.84 - ETA: 1:16 - loss: 0.4325 - accuracy: 0.84 - ETA: 1:15 - loss: 0.4320 - accuracy: 0.84 - ETA: 1:14 - loss: 0.4312 - accuracy: 0.84 - ETA: 1:13 - loss: 0.4294 - accuracy: 0.84 - ETA: 1:12 - loss: 0.4286 - accuracy: 0.84 - ETA: 1:11 - loss: 0.4270 - accuracy: 0.84 - ETA: 1:10 - loss: 0.4248 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4251 - accuracy: 0.84 - ETA: 1:08 - loss: 0.4259 - accuracy: 0.84 - ETA: 1:07 - loss: 0.4261 - accuracy: 0.84 - ETA: 1:06 - loss: 0.4279 - accuracy: 0.84 - ETA: 1:06 - loss: 0.4271 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4268 - accuracy: 0.84 - ETA: 1:04 - loss: 0.4264 - accuracy: 0.84 - ETA: 1:03 - loss: 0.4273 - accuracy: 0.84 - ETA: 1:02 - loss: 0.4275 - accuracy: 0.84 - ETA: 1:01 - loss: 0.4272 - accuracy: 0.84 - ETA: 1:00 - loss: 0.4269 - accuracy: 0.84 - ETA: 59s - loss: 0.4278 - accuracy: 0.8490 - ETA: 58s - loss: 0.4269 - accuracy: 0.849 - ETA: 57s - loss: 0.4261 - accuracy: 0.849 - ETA: 56s - loss: 0.4268 - accuracy: 0.849 - ETA: 56s - loss: 0.4281 - accuracy: 0.849 - ETA: 55s - loss: 0.4267 - accuracy: 0.849 - ETA: 54s - loss: 0.4252 - accuracy: 0.850 - ETA: 53s - loss: 0.4271 - accuracy: 0.849 - ETA: 52s - loss: 0.4256 - accuracy: 0.850 - ETA: 51s - loss: 0.4240 - accuracy: 0.851 - ETA: 50s - loss: 0.4242 - accuracy: 0.850 - ETA: 49s - loss: 0.4237 - accuracy: 0.851 - ETA: 48s - loss: 0.4235 - accuracy: 0.851 - ETA: 48s - loss: 0.4234 - accuracy: 0.851 - ETA: 47s - loss: 0.4227 - accuracy: 0.851 - ETA: 46s - loss: 0.4221 - accuracy: 0.851 - ETA: 45s - loss: 0.4212 - accuracy: 0.851 - ETA: 44s - loss: 0.4223 - accuracy: 0.851 - ETA: 43s - loss: 0.4214 - accuracy: 0.851 - ETA: 42s - loss: 0.4208 - accuracy: 0.851 - ETA: 41s - loss: 0.4214 - accuracy: 0.851 - ETA: 40s - loss: 0.4225 - accuracy: 0.851 - ETA: 39s - loss: 0.4231 - accuracy: 0.851 - ETA: 38s - loss: 0.4232 - accuracy: 0.850 - ETA: 37s - loss: 0.4262 - accuracy: 0.849 - ETA: 37s - loss: 0.4263 - accuracy: 0.849 - ETA: 36s - loss: 0.4268 - accuracy: 0.849 - ETA: 35s - loss: 0.4265 - accuracy: 0.849 - ETA: 34s - loss: 0.4268 - accuracy: 0.849 - ETA: 33s - loss: 0.4272 - accuracy: 0.849 - ETA: 32s - loss: 0.4272 - accuracy: 0.849 - ETA: 31s - loss: 0.4275 - accuracy: 0.849 - ETA: 30s - loss: 0.4277 - accuracy: 0.849 - ETA: 29s - loss: 0.4270 - accuracy: 0.849 - ETA: 28s - loss: 0.4279 - accuracy: 0.849 - ETA: 27s - loss: 0.4292 - accuracy: 0.848 - ETA: 27s - loss: 0.4287 - accuracy: 0.848 - ETA: 26s - loss: 0.4294 - accuracy: 0.848 - ETA: 25s - loss: 0.4293 - accuracy: 0.848 - ETA: 24s - loss: 0.4284 - accuracy: 0.849 - ETA: 23s - loss: 0.4280 - accuracy: 0.849 - ETA: 22s - loss: 0.4288 - accuracy: 0.848 - ETA: 21s - loss: 0.4294 - accuracy: 0.848 - ETA: 20s - loss: 0.4289 - accuracy: 0.848 - ETA: 19s - loss: 0.4294 - accuracy: 0.848 - ETA: 18s - loss: 0.4283 - accuracy: 0.849 - ETA: 17s - loss: 0.4286 - accuracy: 0.849 - ETA: 17s - loss: 0.4286 - accuracy: 0.849 - ETA: 16s - loss: 0.4278 - accuracy: 0.849 - ETA: 15s - loss: 0.4273 - accuracy: 0.849 - ETA: 14s - loss: 0.4268 - accuracy: 0.850 - ETA: 13s - loss: 0.4269 - accuracy: 0.850 - ETA: 12s - loss: 0.4277 - accuracy: 0.849 - ETA: 11s - loss: 0.4266 - accuracy: 0.850 - ETA: 10s - loss: 0.4265 - accuracy: 0.850 - ETA: 9s - loss: 0.4256 - accuracy: 0.850 - ETA: 8s - loss: 0.4250 - accuracy: 0.85 - ETA: 7s - loss: 0.4248 - accuracy: 0.85 - ETA: 7s - loss: 0.4254 - accuracy: 0.85 - ETA: 6s - loss: 0.4263 - accuracy: 0.85 - ETA: 5s - loss: 0.4254 - accuracy: 0.85 - ETA: 4s - loss: 0.4262 - accuracy: 0.85 - ETA: 3s - loss: 0.4262 - accuracy: 0.85 - ETA: 2s - loss: 0.4265 - accuracy: 0.85 - ETA: 1s - loss: 0.4264 - accuracy: 0.85 - ETA: 0s - loss: 0.4260 - accuracy: 0.85 - 147s 8ms/step - loss: 0.4250 - accuracy: 0.8510 - val_loss: 1.4993 - val_accuracy: 0.7453\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:22 - loss: 0.3137 - accuracy: 0.86 - ETA: 2:11 - loss: 0.3770 - accuracy: 0.86 - ETA: 2:14 - loss: 0.3834 - accuracy: 0.87 - ETA: 2:15 - loss: 0.4046 - accuracy: 0.86 - ETA: 2:16 - loss: 0.4025 - accuracy: 0.86 - ETA: 2:13 - loss: 0.4037 - accuracy: 0.86 - ETA: 2:11 - loss: 0.3949 - accuracy: 0.86 - ETA: 2:11 - loss: 0.4028 - accuracy: 0.86 - ETA: 2:09 - loss: 0.3998 - accuracy: 0.86 - ETA: 2:08 - loss: 0.4059 - accuracy: 0.86 - ETA: 2:07 - loss: 0.3979 - accuracy: 0.86 - ETA: 2:06 - loss: 0.4135 - accuracy: 0.85 - ETA: 2:05 - loss: 0.4175 - accuracy: 0.85 - ETA: 2:03 - loss: 0.4162 - accuracy: 0.85 - ETA: 2:02 - loss: 0.4173 - accuracy: 0.85 - ETA: 2:01 - loss: 0.4120 - accuracy: 0.85 - ETA: 2:01 - loss: 0.4037 - accuracy: 0.85 - ETA: 2:00 - loss: 0.4020 - accuracy: 0.85 - ETA: 1:58 - loss: 0.4140 - accuracy: 0.85 - ETA: 1:57 - loss: 0.4132 - accuracy: 0.85 - ETA: 1:57 - loss: 0.4131 - accuracy: 0.85 - ETA: 1:57 - loss: 0.4119 - accuracy: 0.85 - ETA: 1:55 - loss: 0.4164 - accuracy: 0.85 - ETA: 1:55 - loss: 0.4117 - accuracy: 0.85 - ETA: 1:54 - loss: 0.4120 - accuracy: 0.85 - ETA: 1:53 - loss: 0.4108 - accuracy: 0.85 - ETA: 1:52 - loss: 0.4081 - accuracy: 0.85 - ETA: 1:51 - loss: 0.4064 - accuracy: 0.85 - ETA: 1:50 - loss: 0.4083 - accuracy: 0.85 - ETA: 1:49 - loss: 0.4076 - accuracy: 0.85 - ETA: 1:49 - loss: 0.4040 - accuracy: 0.85 - ETA: 1:49 - loss: 0.4021 - accuracy: 0.85 - ETA: 1:49 - loss: 0.4060 - accuracy: 0.85 - ETA: 1:49 - loss: 0.4052 - accuracy: 0.85 - ETA: 1:48 - loss: 0.4013 - accuracy: 0.85 - ETA: 1:47 - loss: 0.4036 - accuracy: 0.85 - ETA: 1:46 - loss: 0.4018 - accuracy: 0.86 - ETA: 1:46 - loss: 0.4010 - accuracy: 0.86 - ETA: 1:45 - loss: 0.3977 - accuracy: 0.86 - ETA: 1:44 - loss: 0.4005 - accuracy: 0.86 - ETA: 1:43 - loss: 0.3993 - accuracy: 0.86 - ETA: 1:41 - loss: 0.4002 - accuracy: 0.86 - ETA: 1:40 - loss: 0.4050 - accuracy: 0.85 - ETA: 1:39 - loss: 0.4044 - accuracy: 0.85 - ETA: 1:38 - loss: 0.4037 - accuracy: 0.85 - ETA: 1:37 - loss: 0.4044 - accuracy: 0.85 - ETA: 1:36 - loss: 0.4055 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4045 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4011 - accuracy: 0.85 - ETA: 1:33 - loss: 0.4024 - accuracy: 0.85 - ETA: 1:32 - loss: 0.4005 - accuracy: 0.85 - ETA: 1:31 - loss: 0.3996 - accuracy: 0.85 - ETA: 1:30 - loss: 0.4013 - accuracy: 0.85 - ETA: 1:29 - loss: 0.4018 - accuracy: 0.85 - ETA: 1:28 - loss: 0.4015 - accuracy: 0.85 - ETA: 1:27 - loss: 0.4027 - accuracy: 0.85 - ETA: 1:26 - loss: 0.4031 - accuracy: 0.85 - ETA: 1:25 - loss: 0.4050 - accuracy: 0.85 - ETA: 1:24 - loss: 0.4039 - accuracy: 0.85 - ETA: 1:23 - loss: 0.4028 - accuracy: 0.85 - ETA: 1:22 - loss: 0.4011 - accuracy: 0.85 - ETA: 1:21 - loss: 0.4015 - accuracy: 0.85 - ETA: 1:20 - loss: 0.4019 - accuracy: 0.85 - ETA: 1:19 - loss: 0.4036 - accuracy: 0.85 - ETA: 1:18 - loss: 0.4048 - accuracy: 0.85 - ETA: 1:17 - loss: 0.4032 - accuracy: 0.85 - ETA: 1:16 - loss: 0.4033 - accuracy: 0.85 - ETA: 1:15 - loss: 0.4042 - accuracy: 0.85 - ETA: 1:14 - loss: 0.4042 - accuracy: 0.85 - ETA: 1:14 - loss: 0.4048 - accuracy: 0.85 - ETA: 1:13 - loss: 0.4066 - accuracy: 0.85 - ETA: 1:12 - loss: 0.4080 - accuracy: 0.85 - ETA: 1:11 - loss: 0.4079 - accuracy: 0.85 - ETA: 1:10 - loss: 0.4089 - accuracy: 0.85 - ETA: 1:09 - loss: 0.4075 - accuracy: 0.85 - ETA: 1:08 - loss: 0.4084 - accuracy: 0.85 - ETA: 1:07 - loss: 0.4087 - accuracy: 0.85 - ETA: 1:06 - loss: 0.4083 - accuracy: 0.85 - ETA: 1:05 - loss: 0.4101 - accuracy: 0.85 - ETA: 1:04 - loss: 0.4113 - accuracy: 0.85 - ETA: 1:03 - loss: 0.4122 - accuracy: 0.85 - ETA: 1:03 - loss: 0.4134 - accuracy: 0.85 - ETA: 1:02 - loss: 0.4126 - accuracy: 0.85 - ETA: 1:01 - loss: 0.4131 - accuracy: 0.85 - ETA: 1:00 - loss: 0.4128 - accuracy: 0.85 - ETA: 59s - loss: 0.4123 - accuracy: 0.8542 - ETA: 58s - loss: 0.4118 - accuracy: 0.854 - ETA: 57s - loss: 0.4126 - accuracy: 0.854 - ETA: 56s - loss: 0.4142 - accuracy: 0.853 - ETA: 56s - loss: 0.4136 - accuracy: 0.853 - ETA: 55s - loss: 0.4132 - accuracy: 0.853 - ETA: 55s - loss: 0.4138 - accuracy: 0.853 - ETA: 55s - loss: 0.4134 - accuracy: 0.854 - ETA: 55s - loss: 0.4125 - accuracy: 0.854 - ETA: 54s - loss: 0.4121 - accuracy: 0.854 - ETA: 54s - loss: 0.4119 - accuracy: 0.854 - ETA: 53s - loss: 0.4123 - accuracy: 0.854 - ETA: 52s - loss: 0.4128 - accuracy: 0.854 - ETA: 51s - loss: 0.4126 - accuracy: 0.854 - ETA: 50s - loss: 0.4128 - accuracy: 0.854 - ETA: 49s - loss: 0.4113 - accuracy: 0.854 - ETA: 49s - loss: 0.4121 - accuracy: 0.854 - ETA: 47s - loss: 0.4111 - accuracy: 0.855 - ETA: 46s - loss: 0.4111 - accuracy: 0.855 - ETA: 45s - loss: 0.4110 - accuracy: 0.855 - ETA: 44s - loss: 0.4123 - accuracy: 0.855 - ETA: 43s - loss: 0.4132 - accuracy: 0.855 - ETA: 42s - loss: 0.4132 - accuracy: 0.854 - ETA: 42s - loss: 0.4148 - accuracy: 0.854 - ETA: 41s - loss: 0.4143 - accuracy: 0.854 - ETA: 40s - loss: 0.4142 - accuracy: 0.854 - ETA: 39s - loss: 0.4146 - accuracy: 0.854 - ETA: 38s - loss: 0.4149 - accuracy: 0.854 - ETA: 37s - loss: 0.4149 - accuracy: 0.854 - ETA: 36s - loss: 0.4160 - accuracy: 0.853 - ETA: 35s - loss: 0.4160 - accuracy: 0.853 - ETA: 34s - loss: 0.4153 - accuracy: 0.853 - ETA: 33s - loss: 0.4149 - accuracy: 0.854 - ETA: 32s - loss: 0.4149 - accuracy: 0.853 - ETA: 31s - loss: 0.4142 - accuracy: 0.854 - ETA: 30s - loss: 0.4124 - accuracy: 0.854 - ETA: 29s - loss: 0.4115 - accuracy: 0.854 - ETA: 28s - loss: 0.4117 - accuracy: 0.854 - ETA: 27s - loss: 0.4124 - accuracy: 0.854 - ETA: 26s - loss: 0.4127 - accuracy: 0.853 - ETA: 25s - loss: 0.4131 - accuracy: 0.853 - ETA: 24s - loss: 0.4134 - accuracy: 0.853 - ETA: 23s - loss: 0.4131 - accuracy: 0.853 - ETA: 22s - loss: 0.4132 - accuracy: 0.853 - ETA: 21s - loss: 0.4126 - accuracy: 0.853 - ETA: 20s - loss: 0.4123 - accuracy: 0.854 - ETA: 19s - loss: 0.4133 - accuracy: 0.853 - ETA: 18s - loss: 0.4130 - accuracy: 0.853 - ETA: 17s - loss: 0.4127 - accuracy: 0.854 - ETA: 16s - loss: 0.4136 - accuracy: 0.854 - ETA: 15s - loss: 0.4135 - accuracy: 0.854 - ETA: 14s - loss: 0.4142 - accuracy: 0.854 - ETA: 13s - loss: 0.4132 - accuracy: 0.854 - ETA: 12s - loss: 0.4139 - accuracy: 0.853 - ETA: 11s - loss: 0.4138 - accuracy: 0.854 - ETA: 10s - loss: 0.4141 - accuracy: 0.853 - ETA: 9s - loss: 0.4139 - accuracy: 0.853 - ETA: 8s - loss: 0.4133 - accuracy: 0.85 - ETA: 7s - loss: 0.4142 - accuracy: 0.85 - ETA: 6s - loss: 0.4142 - accuracy: 0.85 - ETA: 5s - loss: 0.4142 - accuracy: 0.85 - ETA: 4s - loss: 0.4143 - accuracy: 0.85 - ETA: 3s - loss: 0.4134 - accuracy: 0.85 - ETA: 1s - loss: 0.4140 - accuracy: 0.85 - ETA: 0s - loss: 0.4136 - accuracy: 0.85 - 173s 9ms/step - loss: 0.4142 - accuracy: 0.8536 - val_loss: 1.4797 - val_accuracy: 0.7474\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:47 - loss: 0.3710 - accuracy: 0.85 - ETA: 2:39 - loss: 0.3826 - accuracy: 0.85 - ETA: 2:36 - loss: 0.3592 - accuracy: 0.86 - ETA: 2:35 - loss: 0.3856 - accuracy: 0.85 - ETA: 2:33 - loss: 0.3986 - accuracy: 0.84 - ETA: 2:34 - loss: 0.4151 - accuracy: 0.84 - ETA: 2:33 - loss: 0.4235 - accuracy: 0.84 - ETA: 2:31 - loss: 0.4118 - accuracy: 0.84 - ETA: 2:29 - loss: 0.4235 - accuracy: 0.83 - ETA: 2:27 - loss: 0.4166 - accuracy: 0.84 - ETA: 2:26 - loss: 0.4233 - accuracy: 0.84 - ETA: 2:24 - loss: 0.4291 - accuracy: 0.84 - ETA: 2:22 - loss: 0.4179 - accuracy: 0.84 - ETA: 2:21 - loss: 0.4112 - accuracy: 0.84 - ETA: 2:20 - loss: 0.4187 - accuracy: 0.84 - ETA: 2:18 - loss: 0.4152 - accuracy: 0.84 - ETA: 2:17 - loss: 0.4091 - accuracy: 0.85 - ETA: 2:15 - loss: 0.4049 - accuracy: 0.85 - ETA: 2:14 - loss: 0.4015 - accuracy: 0.85 - ETA: 2:12 - loss: 0.3965 - accuracy: 0.85 - ETA: 2:12 - loss: 0.3966 - accuracy: 0.85 - ETA: 2:11 - loss: 0.3987 - accuracy: 0.85 - ETA: 2:11 - loss: 0.3973 - accuracy: 0.85 - ETA: 2:10 - loss: 0.3972 - accuracy: 0.85 - ETA: 2:09 - loss: 0.4021 - accuracy: 0.85 - ETA: 2:08 - loss: 0.4025 - accuracy: 0.85 - ETA: 2:06 - loss: 0.4086 - accuracy: 0.85 - ETA: 2:05 - loss: 0.4090 - accuracy: 0.85 - ETA: 2:04 - loss: 0.4083 - accuracy: 0.85 - ETA: 2:03 - loss: 0.4103 - accuracy: 0.85 - ETA: 2:02 - loss: 0.4098 - accuracy: 0.85 - ETA: 2:01 - loss: 0.4064 - accuracy: 0.85 - ETA: 2:00 - loss: 0.4127 - accuracy: 0.85 - ETA: 1:58 - loss: 0.4161 - accuracy: 0.85 - ETA: 1:57 - loss: 0.4120 - accuracy: 0.85 - ETA: 1:56 - loss: 0.4147 - accuracy: 0.85 - ETA: 1:55 - loss: 0.4138 - accuracy: 0.85 - ETA: 1:55 - loss: 0.4133 - accuracy: 0.85 - ETA: 1:54 - loss: 0.4121 - accuracy: 0.85 - ETA: 1:53 - loss: 0.4157 - accuracy: 0.85 - ETA: 1:52 - loss: 0.4163 - accuracy: 0.85 - ETA: 1:50 - loss: 0.4144 - accuracy: 0.85 - ETA: 1:49 - loss: 0.4148 - accuracy: 0.85 - ETA: 1:48 - loss: 0.4164 - accuracy: 0.85 - ETA: 1:47 - loss: 0.4191 - accuracy: 0.85 - ETA: 1:46 - loss: 0.4162 - accuracy: 0.85 - ETA: 1:45 - loss: 0.4137 - accuracy: 0.85 - ETA: 1:44 - loss: 0.4137 - accuracy: 0.85 - ETA: 1:43 - loss: 0.4144 - accuracy: 0.85 - ETA: 1:42 - loss: 0.4157 - accuracy: 0.85 - ETA: 1:41 - loss: 0.4156 - accuracy: 0.85 - ETA: 1:40 - loss: 0.4170 - accuracy: 0.85 - ETA: 1:39 - loss: 0.4168 - accuracy: 0.85 - ETA: 1:38 - loss: 0.4149 - accuracy: 0.85 - ETA: 1:37 - loss: 0.4132 - accuracy: 0.85 - ETA: 1:36 - loss: 0.4117 - accuracy: 0.85 - ETA: 1:36 - loss: 0.4099 - accuracy: 0.85 - ETA: 1:35 - loss: 0.4115 - accuracy: 0.85 - ETA: 1:34 - loss: 0.4129 - accuracy: 0.85 - ETA: 1:33 - loss: 0.4122 - accuracy: 0.85 - ETA: 1:32 - loss: 0.4121 - accuracy: 0.85 - ETA: 1:31 - loss: 0.4107 - accuracy: 0.85 - ETA: 1:30 - loss: 0.4114 - accuracy: 0.85 - ETA: 1:29 - loss: 0.4125 - accuracy: 0.85 - ETA: 1:28 - loss: 0.4132 - accuracy: 0.85 - ETA: 1:27 - loss: 0.4146 - accuracy: 0.85 - ETA: 1:26 - loss: 0.4147 - accuracy: 0.85 - ETA: 1:26 - loss: 0.4166 - accuracy: 0.85 - ETA: 1:25 - loss: 0.4175 - accuracy: 0.85 - ETA: 1:24 - loss: 0.4158 - accuracy: 0.85 - ETA: 1:23 - loss: 0.4154 - accuracy: 0.85 - ETA: 1:22 - loss: 0.4141 - accuracy: 0.85 - ETA: 1:21 - loss: 0.4124 - accuracy: 0.85 - ETA: 1:21 - loss: 0.4109 - accuracy: 0.85 - ETA: 1:20 - loss: 0.4117 - accuracy: 0.85 - ETA: 1:19 - loss: 0.4108 - accuracy: 0.85 - ETA: 1:18 - loss: 0.4106 - accuracy: 0.85 - ETA: 1:17 - loss: 0.4101 - accuracy: 0.85 - ETA: 1:16 - loss: 0.4093 - accuracy: 0.85 - ETA: 1:15 - loss: 0.4095 - accuracy: 0.85 - ETA: 1:14 - loss: 0.4100 - accuracy: 0.85 - ETA: 1:12 - loss: 0.4104 - accuracy: 0.85 - ETA: 1:11 - loss: 0.4111 - accuracy: 0.85 - ETA: 1:10 - loss: 0.4117 - accuracy: 0.85 - ETA: 1:09 - loss: 0.4123 - accuracy: 0.85 - ETA: 1:08 - loss: 0.4130 - accuracy: 0.85 - ETA: 1:07 - loss: 0.4141 - accuracy: 0.85 - ETA: 1:05 - loss: 0.4131 - accuracy: 0.85 - ETA: 1:04 - loss: 0.4110 - accuracy: 0.85 - ETA: 1:03 - loss: 0.4120 - accuracy: 0.85 - ETA: 1:02 - loss: 0.4114 - accuracy: 0.85 - ETA: 1:01 - loss: 0.4119 - accuracy: 0.85 - ETA: 1:00 - loss: 0.4114 - accuracy: 0.85 - ETA: 59s - loss: 0.4108 - accuracy: 0.8524 - ETA: 57s - loss: 0.4103 - accuracy: 0.852 - ETA: 56s - loss: 0.4104 - accuracy: 0.852 - ETA: 55s - loss: 0.4101 - accuracy: 0.852 - ETA: 54s - loss: 0.4100 - accuracy: 0.852 - ETA: 53s - loss: 0.4101 - accuracy: 0.853 - ETA: 52s - loss: 0.4115 - accuracy: 0.852 - ETA: 51s - loss: 0.4119 - accuracy: 0.852 - ETA: 50s - loss: 0.4130 - accuracy: 0.852 - ETA: 49s - loss: 0.4129 - accuracy: 0.852 - ETA: 48s - loss: 0.4126 - accuracy: 0.852 - ETA: 47s - loss: 0.4142 - accuracy: 0.852 - ETA: 46s - loss: 0.4142 - accuracy: 0.852 - ETA: 45s - loss: 0.4132 - accuracy: 0.852 - ETA: 44s - loss: 0.4139 - accuracy: 0.852 - ETA: 43s - loss: 0.4138 - accuracy: 0.852 - ETA: 41s - loss: 0.4130 - accuracy: 0.852 - ETA: 40s - loss: 0.4124 - accuracy: 0.852 - ETA: 39s - loss: 0.4120 - accuracy: 0.853 - ETA: 38s - loss: 0.4118 - accuracy: 0.853 - ETA: 37s - loss: 0.4116 - accuracy: 0.853 - ETA: 36s - loss: 0.4112 - accuracy: 0.853 - ETA: 35s - loss: 0.4123 - accuracy: 0.853 - ETA: 34s - loss: 0.4128 - accuracy: 0.852 - ETA: 33s - loss: 0.4132 - accuracy: 0.852 - ETA: 32s - loss: 0.4136 - accuracy: 0.852 - ETA: 31s - loss: 0.4132 - accuracy: 0.852 - ETA: 30s - loss: 0.4124 - accuracy: 0.852 - ETA: 29s - loss: 0.4123 - accuracy: 0.852 - ETA: 28s - loss: 0.4120 - accuracy: 0.852 - ETA: 27s - loss: 0.4116 - accuracy: 0.852 - ETA: 26s - loss: 0.4109 - accuracy: 0.852 - ETA: 25s - loss: 0.4114 - accuracy: 0.852 - ETA: 24s - loss: 0.4119 - accuracy: 0.852 - ETA: 23s - loss: 0.4114 - accuracy: 0.853 - ETA: 22s - loss: 0.4117 - accuracy: 0.853 - ETA: 21s - loss: 0.4113 - accuracy: 0.853 - ETA: 20s - loss: 0.4112 - accuracy: 0.853 - ETA: 19s - loss: 0.4118 - accuracy: 0.852 - ETA: 18s - loss: 0.4132 - accuracy: 0.852 - ETA: 17s - loss: 0.4128 - accuracy: 0.852 - ETA: 16s - loss: 0.4131 - accuracy: 0.852 - ETA: 15s - loss: 0.4127 - accuracy: 0.852 - ETA: 14s - loss: 0.4138 - accuracy: 0.852 - ETA: 13s - loss: 0.4133 - accuracy: 0.852 - ETA: 12s - loss: 0.4129 - accuracy: 0.852 - ETA: 11s - loss: 0.4129 - accuracy: 0.852 - ETA: 10s - loss: 0.4126 - accuracy: 0.852 - ETA: 9s - loss: 0.4132 - accuracy: 0.852 - ETA: 8s - loss: 0.4134 - accuracy: 0.85 - ETA: 7s - loss: 0.4133 - accuracy: 0.85 - ETA: 6s - loss: 0.4134 - accuracy: 0.85 - ETA: 5s - loss: 0.4134 - accuracy: 0.85 - ETA: 4s - loss: 0.4123 - accuracy: 0.85 - ETA: 2s - loss: 0.4117 - accuracy: 0.85 - ETA: 1s - loss: 0.4116 - accuracy: 0.85 - ETA: 0s - loss: 0.4114 - accuracy: 0.85 - 169s 9ms/step - loss: 0.4118 - accuracy: 0.8533 - val_loss: 1.5040 - val_accuracy: 0.7476\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:56 - loss: 0.3918 - accuracy: 0.84 - ETA: 2:49 - loss: 0.3510 - accuracy: 0.85 - ETA: 2:41 - loss: 0.3387 - accuracy: 0.86 - ETA: 2:35 - loss: 0.3353 - accuracy: 0.87 - ETA: 2:32 - loss: 0.3694 - accuracy: 0.86 - ETA: 2:30 - loss: 0.3850 - accuracy: 0.85 - ETA: 2:26 - loss: 0.3777 - accuracy: 0.86 - ETA: 2:23 - loss: 0.3880 - accuracy: 0.85 - ETA: 2:21 - loss: 0.3973 - accuracy: 0.85 - ETA: 2:21 - loss: 0.3968 - accuracy: 0.85 - ETA: 2:23 - loss: 0.3914 - accuracy: 0.85 - ETA: 2:25 - loss: 0.3899 - accuracy: 0.86 - ETA: 2:26 - loss: 0.3809 - accuracy: 0.86 - ETA: 2:26 - loss: 0.3749 - accuracy: 0.86 - ETA: 2:27 - loss: 0.3704 - accuracy: 0.86 - ETA: 2:27 - loss: 0.3734 - accuracy: 0.86 - ETA: 2:28 - loss: 0.3841 - accuracy: 0.86 - ETA: 2:28 - loss: 0.3785 - accuracy: 0.86 - ETA: 2:27 - loss: 0.3782 - accuracy: 0.86 - ETA: 2:26 - loss: 0.3738 - accuracy: 0.86 - ETA: 2:25 - loss: 0.3761 - accuracy: 0.86 - ETA: 2:23 - loss: 0.3842 - accuracy: 0.86 - ETA: 2:22 - loss: 0.3834 - accuracy: 0.86 - ETA: 2:20 - loss: 0.3829 - accuracy: 0.86 - ETA: 2:18 - loss: 0.3846 - accuracy: 0.86 - ETA: 2:17 - loss: 0.3846 - accuracy: 0.86 - ETA: 2:16 - loss: 0.3861 - accuracy: 0.86 - ETA: 2:15 - loss: 0.3840 - accuracy: 0.86 - ETA: 2:13 - loss: 0.3842 - accuracy: 0.86 - ETA: 2:12 - loss: 0.3881 - accuracy: 0.86 - ETA: 2:11 - loss: 0.3869 - accuracy: 0.86 - ETA: 2:09 - loss: 0.3877 - accuracy: 0.86 - ETA: 2:08 - loss: 0.3842 - accuracy: 0.86 - ETA: 2:06 - loss: 0.3855 - accuracy: 0.86 - ETA: 2:05 - loss: 0.3831 - accuracy: 0.86 - ETA: 2:03 - loss: 0.3794 - accuracy: 0.86 - ETA: 2:02 - loss: 0.3772 - accuracy: 0.86 - ETA: 2:01 - loss: 0.3802 - accuracy: 0.86 - ETA: 2:00 - loss: 0.3802 - accuracy: 0.86 - ETA: 1:58 - loss: 0.3822 - accuracy: 0.86 - ETA: 1:57 - loss: 0.3822 - accuracy: 0.86 - ETA: 1:56 - loss: 0.3852 - accuracy: 0.86 - ETA: 1:55 - loss: 0.3835 - accuracy: 0.86 - ETA: 1:54 - loss: 0.3838 - accuracy: 0.86 - ETA: 1:53 - loss: 0.3829 - accuracy: 0.86 - ETA: 1:52 - loss: 0.3817 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3829 - accuracy: 0.86 - ETA: 1:49 - loss: 0.3838 - accuracy: 0.86 - ETA: 1:48 - loss: 0.3848 - accuracy: 0.86 - ETA: 1:47 - loss: 0.3857 - accuracy: 0.86 - ETA: 1:46 - loss: 0.3863 - accuracy: 0.86 - ETA: 1:44 - loss: 0.3857 - accuracy: 0.86 - ETA: 1:43 - loss: 0.3862 - accuracy: 0.86 - ETA: 1:42 - loss: 0.3866 - accuracy: 0.86 - ETA: 1:41 - loss: 0.3851 - accuracy: 0.86 - ETA: 1:40 - loss: 0.3843 - accuracy: 0.86 - ETA: 1:39 - loss: 0.3847 - accuracy: 0.86 - ETA: 1:38 - loss: 0.3818 - accuracy: 0.86 - ETA: 1:37 - loss: 0.3815 - accuracy: 0.86 - ETA: 1:35 - loss: 0.3809 - accuracy: 0.86 - ETA: 1:34 - loss: 0.3839 - accuracy: 0.86 - ETA: 1:33 - loss: 0.3832 - accuracy: 0.86 - ETA: 1:32 - loss: 0.3843 - accuracy: 0.86 - ETA: 1:31 - loss: 0.3834 - accuracy: 0.86 - ETA: 1:30 - loss: 0.3829 - accuracy: 0.86 - ETA: 1:28 - loss: 0.3819 - accuracy: 0.86 - ETA: 1:27 - loss: 0.3813 - accuracy: 0.86 - ETA: 1:26 - loss: 0.3803 - accuracy: 0.86 - ETA: 1:25 - loss: 0.3801 - accuracy: 0.86 - ETA: 1:24 - loss: 0.3806 - accuracy: 0.86 - ETA: 1:23 - loss: 0.3812 - accuracy: 0.86 - ETA: 1:23 - loss: 0.3815 - accuracy: 0.86 - ETA: 1:22 - loss: 0.3829 - accuracy: 0.86 - ETA: 1:21 - loss: 0.3837 - accuracy: 0.86 - ETA: 1:21 - loss: 0.3832 - accuracy: 0.86 - ETA: 1:20 - loss: 0.3837 - accuracy: 0.86 - ETA: 1:18 - loss: 0.3813 - accuracy: 0.86 - ETA: 1:17 - loss: 0.3839 - accuracy: 0.86 - ETA: 1:16 - loss: 0.3854 - accuracy: 0.86 - ETA: 1:15 - loss: 0.3859 - accuracy: 0.86 - ETA: 1:14 - loss: 0.3848 - accuracy: 0.86 - ETA: 1:13 - loss: 0.3852 - accuracy: 0.86 - ETA: 1:12 - loss: 0.3875 - accuracy: 0.86 - ETA: 1:11 - loss: 0.3862 - accuracy: 0.86 - ETA: 1:10 - loss: 0.3863 - accuracy: 0.86 - ETA: 1:09 - loss: 0.3869 - accuracy: 0.86 - ETA: 1:08 - loss: 0.3869 - accuracy: 0.86 - ETA: 1:07 - loss: 0.3866 - accuracy: 0.86 - ETA: 1:05 - loss: 0.3874 - accuracy: 0.86 - ETA: 1:04 - loss: 0.3870 - accuracy: 0.86 - ETA: 1:03 - loss: 0.3873 - accuracy: 0.86 - ETA: 1:02 - loss: 0.3896 - accuracy: 0.86 - ETA: 1:01 - loss: 0.3901 - accuracy: 0.86 - ETA: 1:00 - loss: 0.3899 - accuracy: 0.86 - ETA: 59s - loss: 0.3911 - accuracy: 0.8620 - ETA: 58s - loss: 0.3907 - accuracy: 0.862 - ETA: 57s - loss: 0.3909 - accuracy: 0.862 - ETA: 56s - loss: 0.3911 - accuracy: 0.861 - ETA: 55s - loss: 0.3909 - accuracy: 0.861 - ETA: 54s - loss: 0.3922 - accuracy: 0.861 - ETA: 53s - loss: 0.3938 - accuracy: 0.860 - ETA: 52s - loss: 0.3949 - accuracy: 0.860 - ETA: 51s - loss: 0.3944 - accuracy: 0.860 - ETA: 49s - loss: 0.3949 - accuracy: 0.860 - ETA: 48s - loss: 0.3955 - accuracy: 0.860 - ETA: 47s - loss: 0.3952 - accuracy: 0.860 - ETA: 46s - loss: 0.3956 - accuracy: 0.860 - ETA: 45s - loss: 0.3964 - accuracy: 0.859 - ETA: 44s - loss: 0.3963 - accuracy: 0.859 - ETA: 43s - loss: 0.3959 - accuracy: 0.859 - ETA: 42s - loss: 0.3968 - accuracy: 0.859 - ETA: 41s - loss: 0.3970 - accuracy: 0.859 - ETA: 40s - loss: 0.3973 - accuracy: 0.859 - ETA: 39s - loss: 0.3967 - accuracy: 0.859 - ETA: 38s - loss: 0.3969 - accuracy: 0.859 - ETA: 37s - loss: 0.3967 - accuracy: 0.859 - ETA: 36s - loss: 0.3964 - accuracy: 0.859 - ETA: 35s - loss: 0.3970 - accuracy: 0.859 - ETA: 34s - loss: 0.3970 - accuracy: 0.859 - ETA: 32s - loss: 0.3961 - accuracy: 0.860 - ETA: 31s - loss: 0.3965 - accuracy: 0.859 - ETA: 30s - loss: 0.3957 - accuracy: 0.859 - ETA: 29s - loss: 0.3972 - accuracy: 0.859 - ETA: 28s - loss: 0.3976 - accuracy: 0.859 - ETA: 27s - loss: 0.3978 - accuracy: 0.859 - ETA: 26s - loss: 0.3980 - accuracy: 0.859 - ETA: 25s - loss: 0.3984 - accuracy: 0.859 - ETA: 24s - loss: 0.3979 - accuracy: 0.859 - ETA: 23s - loss: 0.3971 - accuracy: 0.859 - ETA: 22s - loss: 0.3969 - accuracy: 0.859 - ETA: 21s - loss: 0.3974 - accuracy: 0.859 - ETA: 20s - loss: 0.3978 - accuracy: 0.859 - ETA: 19s - loss: 0.3982 - accuracy: 0.859 - ETA: 17s - loss: 0.3987 - accuracy: 0.859 - ETA: 16s - loss: 0.3985 - accuracy: 0.859 - ETA: 15s - loss: 0.3985 - accuracy: 0.859 - ETA: 14s - loss: 0.3987 - accuracy: 0.859 - ETA: 13s - loss: 0.3977 - accuracy: 0.859 - ETA: 12s - loss: 0.3980 - accuracy: 0.859 - ETA: 11s - loss: 0.3988 - accuracy: 0.858 - ETA: 10s - loss: 0.3984 - accuracy: 0.858 - ETA: 9s - loss: 0.3987 - accuracy: 0.858 - ETA: 8s - loss: 0.3980 - accuracy: 0.85 - ETA: 7s - loss: 0.3978 - accuracy: 0.85 - ETA: 6s - loss: 0.3976 - accuracy: 0.85 - ETA: 5s - loss: 0.3975 - accuracy: 0.85 - ETA: 4s - loss: 0.3978 - accuracy: 0.85 - ETA: 3s - loss: 0.3978 - accuracy: 0.85 - ETA: 1s - loss: 0.3976 - accuracy: 0.85 - ETA: 0s - loss: 0.3975 - accuracy: 0.85 - 173s 9ms/step - loss: 0.3976 - accuracy: 0.8591 - val_loss: 1.5114 - val_accuracy: 0.7445\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:44 - loss: 0.3396 - accuracy: 0.89 - ETA: 2:38 - loss: 0.3397 - accuracy: 0.89 - ETA: 2:32 - loss: 0.3450 - accuracy: 0.88 - ETA: 2:33 - loss: 0.3405 - accuracy: 0.88 - ETA: 2:30 - loss: 0.3348 - accuracy: 0.88 - ETA: 2:29 - loss: 0.3451 - accuracy: 0.88 - ETA: 2:28 - loss: 0.3270 - accuracy: 0.88 - ETA: 2:26 - loss: 0.3283 - accuracy: 0.88 - ETA: 2:25 - loss: 0.3432 - accuracy: 0.88 - ETA: 2:24 - loss: 0.3428 - accuracy: 0.87 - ETA: 2:23 - loss: 0.3419 - accuracy: 0.88 - ETA: 2:21 - loss: 0.3587 - accuracy: 0.87 - ETA: 2:20 - loss: 0.3587 - accuracy: 0.87 - ETA: 2:19 - loss: 0.3668 - accuracy: 0.87 - ETA: 2:19 - loss: 0.3663 - accuracy: 0.87 - ETA: 2:18 - loss: 0.3723 - accuracy: 0.86 - ETA: 2:17 - loss: 0.3681 - accuracy: 0.87 - ETA: 2:16 - loss: 0.3676 - accuracy: 0.87 - ETA: 2:14 - loss: 0.3764 - accuracy: 0.86 - ETA: 2:14 - loss: 0.3741 - accuracy: 0.86 - ETA: 2:13 - loss: 0.3721 - accuracy: 0.86 - ETA: 2:12 - loss: 0.3706 - accuracy: 0.86 - ETA: 2:11 - loss: 0.3661 - accuracy: 0.87 - ETA: 2:10 - loss: 0.3687 - accuracy: 0.87 - ETA: 2:09 - loss: 0.3649 - accuracy: 0.87 - ETA: 2:08 - loss: 0.3666 - accuracy: 0.86 - ETA: 2:07 - loss: 0.3701 - accuracy: 0.86 - ETA: 2:06 - loss: 0.3707 - accuracy: 0.86 - ETA: 2:05 - loss: 0.3688 - accuracy: 0.86 - ETA: 2:04 - loss: 0.3708 - accuracy: 0.86 - ETA: 2:03 - loss: 0.3689 - accuracy: 0.86 - ETA: 2:02 - loss: 0.3705 - accuracy: 0.86 - ETA: 2:01 - loss: 0.3688 - accuracy: 0.86 - ETA: 2:00 - loss: 0.3695 - accuracy: 0.86 - ETA: 1:59 - loss: 0.3699 - accuracy: 0.86 - ETA: 1:58 - loss: 0.3706 - accuracy: 0.86 - ETA: 1:57 - loss: 0.3735 - accuracy: 0.86 - ETA: 1:56 - loss: 0.3750 - accuracy: 0.86 - ETA: 1:55 - loss: 0.3749 - accuracy: 0.86 - ETA: 1:54 - loss: 0.3781 - accuracy: 0.86 - ETA: 1:53 - loss: 0.3747 - accuracy: 0.86 - ETA: 1:52 - loss: 0.3760 - accuracy: 0.86 - ETA: 1:51 - loss: 0.3760 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3750 - accuracy: 0.86 - ETA: 1:48 - loss: 0.3741 - accuracy: 0.86 - ETA: 1:48 - loss: 0.3717 - accuracy: 0.86 - ETA: 1:49 - loss: 0.3681 - accuracy: 0.86 - ETA: 1:49 - loss: 0.3693 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3733 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3728 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3747 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3735 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3740 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3727 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3719 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3751 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3768 - accuracy: 0.86 - ETA: 1:49 - loss: 0.3771 - accuracy: 0.86 - ETA: 1:49 - loss: 0.3772 - accuracy: 0.86 - ETA: 1:48 - loss: 0.3775 - accuracy: 0.86 - ETA: 1:47 - loss: 0.3764 - accuracy: 0.86 - ETA: 1:47 - loss: 0.3757 - accuracy: 0.86 - ETA: 1:47 - loss: 0.3782 - accuracy: 0.86 - ETA: 1:46 - loss: 0.3778 - accuracy: 0.86 - ETA: 1:45 - loss: 0.3783 - accuracy: 0.86 - ETA: 1:45 - loss: 0.3785 - accuracy: 0.86 - ETA: 1:44 - loss: 0.3774 - accuracy: 0.86 - ETA: 1:43 - loss: 0.3764 - accuracy: 0.86 - ETA: 1:43 - loss: 0.3766 - accuracy: 0.86 - ETA: 1:42 - loss: 0.3767 - accuracy: 0.86 - ETA: 1:42 - loss: 0.3767 - accuracy: 0.86 - ETA: 1:41 - loss: 0.3763 - accuracy: 0.86 - ETA: 1:40 - loss: 0.3787 - accuracy: 0.86 - ETA: 1:39 - loss: 0.3787 - accuracy: 0.86 - ETA: 1:38 - loss: 0.3781 - accuracy: 0.86 - ETA: 1:37 - loss: 0.3781 - accuracy: 0.86 - ETA: 1:36 - loss: 0.3794 - accuracy: 0.86 - ETA: 1:35 - loss: 0.3780 - accuracy: 0.86 - ETA: 1:34 - loss: 0.3788 - accuracy: 0.86 - ETA: 1:33 - loss: 0.3789 - accuracy: 0.86 - ETA: 1:32 - loss: 0.3781 - accuracy: 0.86 - ETA: 1:32 - loss: 0.3783 - accuracy: 0.86 - ETA: 1:30 - loss: 0.3788 - accuracy: 0.86 - ETA: 1:29 - loss: 0.3802 - accuracy: 0.86 - ETA: 1:28 - loss: 0.3797 - accuracy: 0.86 - ETA: 1:27 - loss: 0.3812 - accuracy: 0.86 - ETA: 1:26 - loss: 0.3816 - accuracy: 0.86 - ETA: 1:25 - loss: 0.3803 - accuracy: 0.86 - ETA: 1:24 - loss: 0.3808 - accuracy: 0.86 - ETA: 1:23 - loss: 0.3799 - accuracy: 0.86 - ETA: 1:22 - loss: 0.3805 - accuracy: 0.86 - ETA: 1:20 - loss: 0.3808 - accuracy: 0.86 - ETA: 1:19 - loss: 0.3815 - accuracy: 0.86 - ETA: 1:18 - loss: 0.3813 - accuracy: 0.86 - ETA: 1:17 - loss: 0.3826 - accuracy: 0.86 - ETA: 1:15 - loss: 0.3815 - accuracy: 0.86 - ETA: 1:14 - loss: 0.3818 - accuracy: 0.86 - ETA: 1:13 - loss: 0.3816 - accuracy: 0.86 - ETA: 1:11 - loss: 0.3824 - accuracy: 0.86 - ETA: 1:10 - loss: 0.3811 - accuracy: 0.86 - ETA: 1:09 - loss: 0.3805 - accuracy: 0.86 - ETA: 1:07 - loss: 0.3801 - accuracy: 0.86 - ETA: 1:06 - loss: 0.3815 - accuracy: 0.86 - ETA: 1:04 - loss: 0.3819 - accuracy: 0.86 - ETA: 1:03 - loss: 0.3810 - accuracy: 0.86 - ETA: 1:02 - loss: 0.3802 - accuracy: 0.86 - ETA: 1:01 - loss: 0.3808 - accuracy: 0.86 - ETA: 59s - loss: 0.3812 - accuracy: 0.8643 - ETA: 58s - loss: 0.3808 - accuracy: 0.864 - ETA: 57s - loss: 0.3810 - accuracy: 0.864 - ETA: 55s - loss: 0.3809 - accuracy: 0.864 - ETA: 54s - loss: 0.3815 - accuracy: 0.864 - ETA: 53s - loss: 0.3818 - accuracy: 0.864 - ETA: 51s - loss: 0.3824 - accuracy: 0.863 - ETA: 50s - loss: 0.3823 - accuracy: 0.863 - ETA: 49s - loss: 0.3826 - accuracy: 0.863 - ETA: 47s - loss: 0.3821 - accuracy: 0.863 - ETA: 46s - loss: 0.3825 - accuracy: 0.863 - ETA: 45s - loss: 0.3829 - accuracy: 0.863 - ETA: 43s - loss: 0.3831 - accuracy: 0.863 - ETA: 42s - loss: 0.3835 - accuracy: 0.862 - ETA: 40s - loss: 0.3840 - accuracy: 0.862 - ETA: 39s - loss: 0.3848 - accuracy: 0.862 - ETA: 38s - loss: 0.3839 - accuracy: 0.862 - ETA: 36s - loss: 0.3841 - accuracy: 0.862 - ETA: 35s - loss: 0.3845 - accuracy: 0.862 - ETA: 34s - loss: 0.3843 - accuracy: 0.862 - ETA: 32s - loss: 0.3851 - accuracy: 0.862 - ETA: 31s - loss: 0.3857 - accuracy: 0.862 - ETA: 29s - loss: 0.3854 - accuracy: 0.862 - ETA: 28s - loss: 0.3843 - accuracy: 0.862 - ETA: 27s - loss: 0.3838 - accuracy: 0.862 - ETA: 25s - loss: 0.3838 - accuracy: 0.862 - ETA: 24s - loss: 0.3840 - accuracy: 0.862 - ETA: 22s - loss: 0.3846 - accuracy: 0.862 - ETA: 21s - loss: 0.3842 - accuracy: 0.862 - ETA: 19s - loss: 0.3844 - accuracy: 0.862 - ETA: 18s - loss: 0.3843 - accuracy: 0.862 - ETA: 17s - loss: 0.3833 - accuracy: 0.862 - ETA: 15s - loss: 0.3836 - accuracy: 0.862 - ETA: 14s - loss: 0.3843 - accuracy: 0.862 - ETA: 12s - loss: 0.3840 - accuracy: 0.862 - ETA: 11s - loss: 0.3837 - accuracy: 0.862 - ETA: 9s - loss: 0.3835 - accuracy: 0.862 - ETA: 8s - loss: 0.3836 - accuracy: 0.86 - ETA: 7s - loss: 0.3833 - accuracy: 0.86 - ETA: 5s - loss: 0.3832 - accuracy: 0.86 - ETA: 4s - loss: 0.3838 - accuracy: 0.86 - ETA: 2s - loss: 0.3836 - accuracy: 0.86 - ETA: 1s - loss: 0.3840 - accuracy: 0.86 - 231s 12ms/step - loss: 0.3833 - accuracy: 0.8628 - val_loss: 1.5277 - val_accuracy: 0.7494\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:16 - loss: 0.3022 - accuracy: 0.86 - ETA: 2:19 - loss: 0.3907 - accuracy: 0.84 - ETA: 2:36 - loss: 0.3638 - accuracy: 0.85 - ETA: 2:31 - loss: 0.3767 - accuracy: 0.85 - ETA: 2:34 - loss: 0.3802 - accuracy: 0.85 - ETA: 2:29 - loss: 0.3756 - accuracy: 0.85 - ETA: 2:25 - loss: 0.4021 - accuracy: 0.84 - ETA: 2:22 - loss: 0.4035 - accuracy: 0.84 - ETA: 2:20 - loss: 0.3873 - accuracy: 0.85 - ETA: 2:20 - loss: 0.3825 - accuracy: 0.85 - ETA: 2:22 - loss: 0.3715 - accuracy: 0.86 - ETA: 2:22 - loss: 0.3690 - accuracy: 0.86 - ETA: 2:20 - loss: 0.3751 - accuracy: 0.86 - ETA: 2:19 - loss: 0.3715 - accuracy: 0.86 - ETA: 2:18 - loss: 0.3735 - accuracy: 0.86 - ETA: 2:17 - loss: 0.3704 - accuracy: 0.86 - ETA: 2:15 - loss: 0.3721 - accuracy: 0.86 - ETA: 2:16 - loss: 0.3782 - accuracy: 0.86 - ETA: 2:14 - loss: 0.3772 - accuracy: 0.86 - ETA: 2:13 - loss: 0.3843 - accuracy: 0.86 - ETA: 2:11 - loss: 0.3772 - accuracy: 0.86 - ETA: 2:09 - loss: 0.3782 - accuracy: 0.86 - ETA: 2:08 - loss: 0.3800 - accuracy: 0.86 - ETA: 2:06 - loss: 0.3837 - accuracy: 0.86 - ETA: 2:06 - loss: 0.3883 - accuracy: 0.86 - ETA: 2:04 - loss: 0.3871 - accuracy: 0.86 - ETA: 2:03 - loss: 0.3881 - accuracy: 0.86 - ETA: 2:02 - loss: 0.3890 - accuracy: 0.86 - ETA: 2:00 - loss: 0.3834 - accuracy: 0.86 - ETA: 1:59 - loss: 0.3809 - accuracy: 0.86 - ETA: 1:57 - loss: 0.3809 - accuracy: 0.86 - ETA: 1:56 - loss: 0.3849 - accuracy: 0.86 - ETA: 1:55 - loss: 0.3814 - accuracy: 0.86 - ETA: 1:53 - loss: 0.3763 - accuracy: 0.86 - ETA: 1:52 - loss: 0.3759 - accuracy: 0.86 - ETA: 1:51 - loss: 0.3732 - accuracy: 0.86 - ETA: 1:50 - loss: 0.3756 - accuracy: 0.86 - ETA: 1:49 - loss: 0.3761 - accuracy: 0.86 - ETA: 1:48 - loss: 0.3741 - accuracy: 0.86 - ETA: 1:47 - loss: 0.3743 - accuracy: 0.86 - ETA: 1:46 - loss: 0.3755 - accuracy: 0.86 - ETA: 1:45 - loss: 0.3753 - accuracy: 0.86 - ETA: 1:44 - loss: 0.3767 - accuracy: 0.86 - ETA: 1:43 - loss: 0.3745 - accuracy: 0.86 - ETA: 1:42 - loss: 0.3772 - accuracy: 0.86 - ETA: 1:41 - loss: 0.3753 - accuracy: 0.86 - ETA: 1:40 - loss: 0.3750 - accuracy: 0.86 - ETA: 1:39 - loss: 0.3755 - accuracy: 0.86 - ETA: 1:38 - loss: 0.3744 - accuracy: 0.86 - ETA: 1:37 - loss: 0.3745 - accuracy: 0.86 - ETA: 1:36 - loss: 0.3758 - accuracy: 0.86 - ETA: 1:35 - loss: 0.3758 - accuracy: 0.86 - ETA: 1:33 - loss: 0.3763 - accuracy: 0.86 - ETA: 1:32 - loss: 0.3759 - accuracy: 0.86 - ETA: 1:32 - loss: 0.3778 - accuracy: 0.86 - ETA: 1:30 - loss: 0.3784 - accuracy: 0.86 - ETA: 1:29 - loss: 0.3793 - accuracy: 0.86 - ETA: 1:28 - loss: 0.3784 - accuracy: 0.86 - ETA: 1:27 - loss: 0.3800 - accuracy: 0.86 - ETA: 1:27 - loss: 0.3814 - accuracy: 0.86 - ETA: 1:26 - loss: 0.3824 - accuracy: 0.86 - ETA: 1:24 - loss: 0.3838 - accuracy: 0.86 - ETA: 1:23 - loss: 0.3836 - accuracy: 0.86 - ETA: 1:22 - loss: 0.3852 - accuracy: 0.86 - ETA: 1:21 - loss: 0.3849 - accuracy: 0.86 - ETA: 1:20 - loss: 0.3843 - accuracy: 0.86 - ETA: 1:19 - loss: 0.3852 - accuracy: 0.86 - ETA: 1:18 - loss: 0.3863 - accuracy: 0.86 - ETA: 1:17 - loss: 0.3863 - accuracy: 0.86 - ETA: 1:16 - loss: 0.3863 - accuracy: 0.86 - ETA: 1:15 - loss: 0.3874 - accuracy: 0.86 - ETA: 1:14 - loss: 0.3890 - accuracy: 0.86 - ETA: 1:13 - loss: 0.3905 - accuracy: 0.86 - ETA: 1:12 - loss: 0.3902 - accuracy: 0.86 - ETA: 1:11 - loss: 0.3905 - accuracy: 0.86 - ETA: 1:10 - loss: 0.3910 - accuracy: 0.86 - ETA: 1:09 - loss: 0.3904 - accuracy: 0.86 - ETA: 1:09 - loss: 0.3895 - accuracy: 0.86 - ETA: 1:08 - loss: 0.3877 - accuracy: 0.86 - ETA: 1:07 - loss: 0.3877 - accuracy: 0.86 - ETA: 1:06 - loss: 0.3883 - accuracy: 0.86 - ETA: 1:05 - loss: 0.3885 - accuracy: 0.86 - ETA: 1:04 - loss: 0.3879 - accuracy: 0.86 - ETA: 1:03 - loss: 0.3880 - accuracy: 0.86 - ETA: 1:02 - loss: 0.3881 - accuracy: 0.86 - ETA: 1:01 - loss: 0.3872 - accuracy: 0.86 - ETA: 1:01 - loss: 0.3859 - accuracy: 0.86 - ETA: 1:01 - loss: 0.3848 - accuracy: 0.86 - ETA: 1:00 - loss: 0.3839 - accuracy: 0.86 - ETA: 1:00 - loss: 0.3828 - accuracy: 0.86 - ETA: 59s - loss: 0.3830 - accuracy: 0.8633 - ETA: 58s - loss: 0.3824 - accuracy: 0.863 - ETA: 58s - loss: 0.3814 - accuracy: 0.863 - ETA: 57s - loss: 0.3799 - accuracy: 0.864 - ETA: 57s - loss: 0.3796 - accuracy: 0.864 - ETA: 56s - loss: 0.3808 - accuracy: 0.864 - ETA: 55s - loss: 0.3804 - accuracy: 0.864 - ETA: 55s - loss: 0.3813 - accuracy: 0.864 - ETA: 54s - loss: 0.3808 - accuracy: 0.864 - ETA: 53s - loss: 0.3798 - accuracy: 0.864 - ETA: 53s - loss: 0.3796 - accuracy: 0.864 - ETA: 52s - loss: 0.3791 - accuracy: 0.864 - ETA: 51s - loss: 0.3806 - accuracy: 0.864 - ETA: 50s - loss: 0.3809 - accuracy: 0.864 - ETA: 48s - loss: 0.3806 - accuracy: 0.864 - ETA: 47s - loss: 0.3798 - accuracy: 0.864 - ETA: 46s - loss: 0.3802 - accuracy: 0.864 - ETA: 45s - loss: 0.3799 - accuracy: 0.864 - ETA: 44s - loss: 0.3796 - accuracy: 0.864 - ETA: 43s - loss: 0.3802 - accuracy: 0.864 - ETA: 42s - loss: 0.3803 - accuracy: 0.864 - ETA: 40s - loss: 0.3804 - accuracy: 0.863 - ETA: 39s - loss: 0.3805 - accuracy: 0.863 - ETA: 38s - loss: 0.3802 - accuracy: 0.864 - ETA: 37s - loss: 0.3797 - accuracy: 0.864 - ETA: 36s - loss: 0.3795 - accuracy: 0.864 - ETA: 35s - loss: 0.3791 - accuracy: 0.864 - ETA: 34s - loss: 0.3792 - accuracy: 0.864 - ETA: 33s - loss: 0.3796 - accuracy: 0.864 - ETA: 32s - loss: 0.3789 - accuracy: 0.864 - ETA: 31s - loss: 0.3785 - accuracy: 0.864 - ETA: 30s - loss: 0.3789 - accuracy: 0.864 - ETA: 29s - loss: 0.3788 - accuracy: 0.864 - ETA: 27s - loss: 0.3793 - accuracy: 0.864 - ETA: 26s - loss: 0.3792 - accuracy: 0.864 - ETA: 25s - loss: 0.3790 - accuracy: 0.864 - ETA: 24s - loss: 0.3794 - accuracy: 0.864 - ETA: 23s - loss: 0.3798 - accuracy: 0.863 - ETA: 22s - loss: 0.3802 - accuracy: 0.863 - ETA: 21s - loss: 0.3791 - accuracy: 0.864 - ETA: 20s - loss: 0.3790 - accuracy: 0.864 - ETA: 19s - loss: 0.3792 - accuracy: 0.864 - ETA: 18s - loss: 0.3798 - accuracy: 0.864 - ETA: 17s - loss: 0.3803 - accuracy: 0.863 - ETA: 16s - loss: 0.3804 - accuracy: 0.863 - ETA: 15s - loss: 0.3809 - accuracy: 0.863 - ETA: 14s - loss: 0.3812 - accuracy: 0.862 - ETA: 13s - loss: 0.3811 - accuracy: 0.863 - ETA: 12s - loss: 0.3809 - accuracy: 0.862 - ETA: 11s - loss: 0.3803 - accuracy: 0.863 - ETA: 10s - loss: 0.3803 - accuracy: 0.863 - ETA: 9s - loss: 0.3804 - accuracy: 0.863 - ETA: 7s - loss: 0.3801 - accuracy: 0.86 - ETA: 6s - loss: 0.3801 - accuracy: 0.86 - ETA: 5s - loss: 0.3810 - accuracy: 0.86 - ETA: 4s - loss: 0.3806 - accuracy: 0.86 - ETA: 3s - loss: 0.3799 - accuracy: 0.86 - ETA: 2s - loss: 0.3798 - accuracy: 0.86 - ETA: 1s - loss: 0.3809 - accuracy: 0.86 - ETA: 0s - loss: 0.3816 - accuracy: 0.86 - 163s 8ms/step - loss: 0.3822 - accuracy: 0.8624 - val_loss: 1.5223 - val_accuracy: 0.7498\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:13 - loss: 0.3294 - accuracy: 0.89 - ETA: 2:09 - loss: 0.4300 - accuracy: 0.85 - ETA: 2:08 - loss: 0.3776 - accuracy: 0.87 - ETA: 2:09 - loss: 0.3676 - accuracy: 0.88 - ETA: 2:08 - loss: 0.3809 - accuracy: 0.87 - ETA: 2:10 - loss: 0.3922 - accuracy: 0.87 - ETA: 2:11 - loss: 0.3943 - accuracy: 0.86 - ETA: 2:10 - loss: 0.3875 - accuracy: 0.87 - ETA: 2:10 - loss: 0.3944 - accuracy: 0.87 - ETA: 2:09 - loss: 0.3908 - accuracy: 0.87 - ETA: 2:08 - loss: 0.3939 - accuracy: 0.86 - ETA: 2:07 - loss: 0.3933 - accuracy: 0.86 - ETA: 2:06 - loss: 0.3914 - accuracy: 0.86 - ETA: 2:04 - loss: 0.3850 - accuracy: 0.86 - ETA: 2:03 - loss: 0.3819 - accuracy: 0.86 - ETA: 2:02 - loss: 0.3811 - accuracy: 0.86 - ETA: 2:01 - loss: 0.3780 - accuracy: 0.86 - ETA: 2:00 - loss: 0.3748 - accuracy: 0.86 - ETA: 1:59 - loss: 0.3777 - accuracy: 0.86 - ETA: 1:58 - loss: 0.3758 - accuracy: 0.86 - ETA: 1:56 - loss: 0.3704 - accuracy: 0.86 - ETA: 1:55 - loss: 0.3666 - accuracy: 0.86 - ETA: 1:54 - loss: 0.3730 - accuracy: 0.86 - ETA: 1:54 - loss: 0.3719 - accuracy: 0.86 - ETA: 1:54 - loss: 0.3694 - accuracy: 0.86 - ETA: 1:53 - loss: 0.3616 - accuracy: 0.87 - ETA: 1:52 - loss: 0.3631 - accuracy: 0.87 - ETA: 1:51 - loss: 0.3625 - accuracy: 0.87 - ETA: 1:50 - loss: 0.3659 - accuracy: 0.87 - ETA: 1:49 - loss: 0.3688 - accuracy: 0.86 - ETA: 1:48 - loss: 0.3679 - accuracy: 0.86 - ETA: 1:47 - loss: 0.3670 - accuracy: 0.86 - ETA: 1:46 - loss: 0.3671 - accuracy: 0.86 - ETA: 1:45 - loss: 0.3696 - accuracy: 0.86 - ETA: 1:44 - loss: 0.3662 - accuracy: 0.87 - ETA: 1:43 - loss: 0.3673 - accuracy: 0.87 - ETA: 1:42 - loss: 0.3683 - accuracy: 0.87 - ETA: 1:41 - loss: 0.3706 - accuracy: 0.86 - ETA: 1:40 - loss: 0.3750 - accuracy: 0.86 - ETA: 1:39 - loss: 0.3752 - accuracy: 0.86 - ETA: 1:38 - loss: 0.3744 - accuracy: 0.86 - ETA: 1:37 - loss: 0.3753 - accuracy: 0.86 - ETA: 1:37 - loss: 0.3721 - accuracy: 0.86 - ETA: 1:36 - loss: 0.3744 - accuracy: 0.86 - ETA: 1:35 - loss: 0.3752 - accuracy: 0.86 - ETA: 1:34 - loss: 0.3741 - accuracy: 0.86 - ETA: 1:33 - loss: 0.3731 - accuracy: 0.86 - ETA: 1:32 - loss: 0.3721 - accuracy: 0.86 - ETA: 1:31 - loss: 0.3696 - accuracy: 0.86 - ETA: 1:30 - loss: 0.3692 - accuracy: 0.86 - ETA: 1:29 - loss: 0.3711 - accuracy: 0.86 - ETA: 1:28 - loss: 0.3702 - accuracy: 0.86 - ETA: 1:27 - loss: 0.3721 - accuracy: 0.86 - ETA: 1:26 - loss: 0.3736 - accuracy: 0.86 - ETA: 1:25 - loss: 0.3719 - accuracy: 0.86 - ETA: 1:24 - loss: 0.3714 - accuracy: 0.86 - ETA: 1:23 - loss: 0.3704 - accuracy: 0.86 - ETA: 1:22 - loss: 0.3709 - accuracy: 0.86 - ETA: 1:21 - loss: 0.3727 - accuracy: 0.86 - ETA: 1:21 - loss: 0.3722 - accuracy: 0.86 - ETA: 1:20 - loss: 0.3721 - accuracy: 0.86 - ETA: 1:19 - loss: 0.3725 - accuracy: 0.86 - ETA: 1:18 - loss: 0.3719 - accuracy: 0.86 - ETA: 1:17 - loss: 0.3707 - accuracy: 0.86 - ETA: 1:16 - loss: 0.3701 - accuracy: 0.86 - ETA: 1:15 - loss: 0.3705 - accuracy: 0.86 - ETA: 1:14 - loss: 0.3733 - accuracy: 0.86 - ETA: 1:13 - loss: 0.3733 - accuracy: 0.86 - ETA: 1:12 - loss: 0.3738 - accuracy: 0.86 - ETA: 1:11 - loss: 0.3721 - accuracy: 0.86 - ETA: 1:11 - loss: 0.3710 - accuracy: 0.86 - ETA: 1:10 - loss: 0.3727 - accuracy: 0.86 - ETA: 1:09 - loss: 0.3739 - accuracy: 0.86 - ETA: 1:08 - loss: 0.3746 - accuracy: 0.86 - ETA: 1:07 - loss: 0.3750 - accuracy: 0.86 - ETA: 1:06 - loss: 0.3745 - accuracy: 0.86 - ETA: 1:05 - loss: 0.3737 - accuracy: 0.86 - ETA: 1:04 - loss: 0.3738 - accuracy: 0.86 - ETA: 1:03 - loss: 0.3730 - accuracy: 0.86 - ETA: 1:03 - loss: 0.3723 - accuracy: 0.86 - ETA: 1:02 - loss: 0.3725 - accuracy: 0.86 - ETA: 1:01 - loss: 0.3743 - accuracy: 0.86 - ETA: 1:00 - loss: 0.3750 - accuracy: 0.86 - ETA: 59s - loss: 0.3761 - accuracy: 0.8654 - ETA: 58s - loss: 0.3747 - accuracy: 0.866 - ETA: 57s - loss: 0.3751 - accuracy: 0.865 - ETA: 56s - loss: 0.3761 - accuracy: 0.865 - ETA: 55s - loss: 0.3751 - accuracy: 0.865 - ETA: 55s - loss: 0.3757 - accuracy: 0.865 - ETA: 54s - loss: 0.3747 - accuracy: 0.865 - ETA: 53s - loss: 0.3754 - accuracy: 0.865 - ETA: 52s - loss: 0.3761 - accuracy: 0.865 - ETA: 51s - loss: 0.3760 - accuracy: 0.865 - ETA: 50s - loss: 0.3779 - accuracy: 0.864 - ETA: 49s - loss: 0.3788 - accuracy: 0.864 - ETA: 48s - loss: 0.3779 - accuracy: 0.864 - ETA: 47s - loss: 0.3782 - accuracy: 0.864 - ETA: 46s - loss: 0.3778 - accuracy: 0.864 - ETA: 46s - loss: 0.3799 - accuracy: 0.864 - ETA: 45s - loss: 0.3806 - accuracy: 0.864 - ETA: 44s - loss: 0.3802 - accuracy: 0.864 - ETA: 43s - loss: 0.3791 - accuracy: 0.864 - ETA: 42s - loss: 0.3780 - accuracy: 0.865 - ETA: 41s - loss: 0.3784 - accuracy: 0.865 - ETA: 40s - loss: 0.3782 - accuracy: 0.865 - ETA: 39s - loss: 0.3793 - accuracy: 0.865 - ETA: 38s - loss: 0.3805 - accuracy: 0.864 - ETA: 38s - loss: 0.3804 - accuracy: 0.864 - ETA: 37s - loss: 0.3795 - accuracy: 0.865 - ETA: 36s - loss: 0.3788 - accuracy: 0.865 - ETA: 35s - loss: 0.3786 - accuracy: 0.865 - ETA: 34s - loss: 0.3791 - accuracy: 0.865 - ETA: 33s - loss: 0.3784 - accuracy: 0.865 - ETA: 32s - loss: 0.3778 - accuracy: 0.865 - ETA: 31s - loss: 0.3787 - accuracy: 0.864 - ETA: 30s - loss: 0.3783 - accuracy: 0.865 - ETA: 30s - loss: 0.3774 - accuracy: 0.865 - ETA: 29s - loss: 0.3767 - accuracy: 0.865 - ETA: 28s - loss: 0.3778 - accuracy: 0.865 - ETA: 27s - loss: 0.3778 - accuracy: 0.865 - ETA: 26s - loss: 0.3771 - accuracy: 0.865 - ETA: 25s - loss: 0.3777 - accuracy: 0.865 - ETA: 24s - loss: 0.3774 - accuracy: 0.865 - ETA: 23s - loss: 0.3767 - accuracy: 0.865 - ETA: 22s - loss: 0.3758 - accuracy: 0.866 - ETA: 22s - loss: 0.3766 - accuracy: 0.865 - ETA: 21s - loss: 0.3771 - accuracy: 0.865 - ETA: 20s - loss: 0.3772 - accuracy: 0.865 - ETA: 19s - loss: 0.3776 - accuracy: 0.865 - ETA: 18s - loss: 0.3778 - accuracy: 0.865 - ETA: 17s - loss: 0.3788 - accuracy: 0.864 - ETA: 16s - loss: 0.3794 - accuracy: 0.864 - ETA: 15s - loss: 0.3787 - accuracy: 0.864 - ETA: 14s - loss: 0.3779 - accuracy: 0.865 - ETA: 14s - loss: 0.3775 - accuracy: 0.865 - ETA: 13s - loss: 0.3781 - accuracy: 0.864 - ETA: 12s - loss: 0.3778 - accuracy: 0.865 - ETA: 11s - loss: 0.3786 - accuracy: 0.864 - ETA: 10s - loss: 0.3790 - accuracy: 0.864 - ETA: 9s - loss: 0.3788 - accuracy: 0.864 - ETA: 8s - loss: 0.3788 - accuracy: 0.86 - ETA: 7s - loss: 0.3780 - accuracy: 0.86 - ETA: 7s - loss: 0.3776 - accuracy: 0.86 - ETA: 6s - loss: 0.3774 - accuracy: 0.86 - ETA: 5s - loss: 0.3772 - accuracy: 0.86 - ETA: 4s - loss: 0.3767 - accuracy: 0.86 - ETA: 3s - loss: 0.3769 - accuracy: 0.86 - ETA: 2s - loss: 0.3772 - accuracy: 0.86 - ETA: 1s - loss: 0.3768 - accuracy: 0.86 - ETA: 0s - loss: 0.3761 - accuracy: 0.86 - 147s 8ms/step - loss: 0.3755 - accuracy: 0.8653 - val_loss: 1.5246 - val_accuracy: 0.7482\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:10 - loss: 0.3101 - accuracy: 0.89 - ETA: 2:11 - loss: 0.3868 - accuracy: 0.85 - ETA: 2:16 - loss: 0.3924 - accuracy: 0.85 - ETA: 2:16 - loss: 0.3810 - accuracy: 0.86 - ETA: 2:13 - loss: 0.3618 - accuracy: 0.86 - ETA: 2:11 - loss: 0.3621 - accuracy: 0.86 - ETA: 2:09 - loss: 0.3683 - accuracy: 0.87 - ETA: 2:08 - loss: 0.3620 - accuracy: 0.87 - ETA: 2:07 - loss: 0.3633 - accuracy: 0.87 - ETA: 2:06 - loss: 0.3695 - accuracy: 0.87 - ETA: 2:04 - loss: 0.3694 - accuracy: 0.87 - ETA: 2:03 - loss: 0.3647 - accuracy: 0.87 - ETA: 2:02 - loss: 0.3683 - accuracy: 0.87 - ETA: 2:01 - loss: 0.3715 - accuracy: 0.87 - ETA: 2:00 - loss: 0.3669 - accuracy: 0.87 - ETA: 1:59 - loss: 0.3648 - accuracy: 0.87 - ETA: 1:57 - loss: 0.3761 - accuracy: 0.86 - ETA: 1:56 - loss: 0.3777 - accuracy: 0.86 - ETA: 1:55 - loss: 0.3799 - accuracy: 0.86 - ETA: 1:54 - loss: 0.3805 - accuracy: 0.86 - ETA: 1:53 - loss: 0.3758 - accuracy: 0.87 - ETA: 1:53 - loss: 0.3739 - accuracy: 0.87 - ETA: 1:52 - loss: 0.3686 - accuracy: 0.87 - ETA: 1:51 - loss: 0.3696 - accuracy: 0.87 - ETA: 1:50 - loss: 0.3694 - accuracy: 0.87 - ETA: 1:49 - loss: 0.3676 - accuracy: 0.87 - ETA: 1:48 - loss: 0.3667 - accuracy: 0.87 - ETA: 1:47 - loss: 0.3652 - accuracy: 0.87 - ETA: 1:46 - loss: 0.3668 - accuracy: 0.87 - ETA: 1:46 - loss: 0.3661 - accuracy: 0.87 - ETA: 1:45 - loss: 0.3652 - accuracy: 0.87 - ETA: 1:44 - loss: 0.3650 - accuracy: 0.87 - ETA: 1:43 - loss: 0.3618 - accuracy: 0.87 - ETA: 1:42 - loss: 0.3630 - accuracy: 0.87 - ETA: 1:41 - loss: 0.3597 - accuracy: 0.87 - ETA: 1:40 - loss: 0.3595 - accuracy: 0.87 - ETA: 1:39 - loss: 0.3631 - accuracy: 0.87 - ETA: 1:38 - loss: 0.3615 - accuracy: 0.87 - ETA: 1:37 - loss: 0.3605 - accuracy: 0.87 - ETA: 1:37 - loss: 0.3600 - accuracy: 0.87 - ETA: 1:36 - loss: 0.3580 - accuracy: 0.87 - ETA: 1:35 - loss: 0.3589 - accuracy: 0.87 - ETA: 1:34 - loss: 0.3594 - accuracy: 0.87 - ETA: 1:33 - loss: 0.3587 - accuracy: 0.87 - ETA: 1:33 - loss: 0.3617 - accuracy: 0.87 - ETA: 1:32 - loss: 0.3640 - accuracy: 0.87 - ETA: 1:31 - loss: 0.3628 - accuracy: 0.87 - ETA: 1:30 - loss: 0.3627 - accuracy: 0.87 - ETA: 1:29 - loss: 0.3653 - accuracy: 0.87 - ETA: 1:28 - loss: 0.3656 - accuracy: 0.87 - ETA: 1:27 - loss: 0.3640 - accuracy: 0.87 - ETA: 1:26 - loss: 0.3660 - accuracy: 0.87 - ETA: 1:25 - loss: 0.3668 - accuracy: 0.87 - ETA: 1:24 - loss: 0.3672 - accuracy: 0.87 - ETA: 1:24 - loss: 0.3661 - accuracy: 0.87 - ETA: 1:23 - loss: 0.3666 - accuracy: 0.87 - ETA: 1:22 - loss: 0.3659 - accuracy: 0.87 - ETA: 1:21 - loss: 0.3677 - accuracy: 0.87 - ETA: 1:20 - loss: 0.3673 - accuracy: 0.87 - ETA: 1:19 - loss: 0.3658 - accuracy: 0.87 - ETA: 1:19 - loss: 0.3638 - accuracy: 0.87 - ETA: 1:18 - loss: 0.3660 - accuracy: 0.87 - ETA: 1:17 - loss: 0.3662 - accuracy: 0.87 - ETA: 1:16 - loss: 0.3682 - accuracy: 0.87 - ETA: 1:15 - loss: 0.3649 - accuracy: 0.87 - ETA: 1:14 - loss: 0.3664 - accuracy: 0.87 - ETA: 1:14 - loss: 0.3647 - accuracy: 0.87 - ETA: 1:13 - loss: 0.3650 - accuracy: 0.87 - ETA: 1:12 - loss: 0.3654 - accuracy: 0.87 - ETA: 1:11 - loss: 0.3654 - accuracy: 0.87 - ETA: 1:10 - loss: 0.3663 - accuracy: 0.87 - ETA: 1:10 - loss: 0.3663 - accuracy: 0.87 - ETA: 1:09 - loss: 0.3647 - accuracy: 0.87 - ETA: 1:08 - loss: 0.3646 - accuracy: 0.87 - ETA: 1:07 - loss: 0.3647 - accuracy: 0.87 - ETA: 1:06 - loss: 0.3673 - accuracy: 0.87 - ETA: 1:06 - loss: 0.3694 - accuracy: 0.86 - ETA: 1:05 - loss: 0.3698 - accuracy: 0.86 - ETA: 1:04 - loss: 0.3712 - accuracy: 0.86 - ETA: 1:03 - loss: 0.3703 - accuracy: 0.86 - ETA: 1:02 - loss: 0.3691 - accuracy: 0.86 - ETA: 1:01 - loss: 0.3698 - accuracy: 0.86 - ETA: 1:00 - loss: 0.3694 - accuracy: 0.86 - ETA: 59s - loss: 0.3694 - accuracy: 0.8695 - ETA: 58s - loss: 0.3693 - accuracy: 0.869 - ETA: 57s - loss: 0.3687 - accuracy: 0.869 - ETA: 57s - loss: 0.3685 - accuracy: 0.869 - ETA: 56s - loss: 0.3686 - accuracy: 0.869 - ETA: 55s - loss: 0.3686 - accuracy: 0.869 - ETA: 54s - loss: 0.3687 - accuracy: 0.869 - ETA: 53s - loss: 0.3700 - accuracy: 0.869 - ETA: 52s - loss: 0.3694 - accuracy: 0.869 - ETA: 52s - loss: 0.3703 - accuracy: 0.869 - ETA: 51s - loss: 0.3706 - accuracy: 0.869 - ETA: 50s - loss: 0.3700 - accuracy: 0.869 - ETA: 49s - loss: 0.3701 - accuracy: 0.869 - ETA: 48s - loss: 0.3711 - accuracy: 0.868 - ETA: 47s - loss: 0.3706 - accuracy: 0.869 - ETA: 46s - loss: 0.3698 - accuracy: 0.869 - ETA: 45s - loss: 0.3695 - accuracy: 0.869 - ETA: 44s - loss: 0.3688 - accuracy: 0.869 - ETA: 43s - loss: 0.3694 - accuracy: 0.869 - ETA: 43s - loss: 0.3683 - accuracy: 0.870 - ETA: 42s - loss: 0.3687 - accuracy: 0.870 - ETA: 41s - loss: 0.3686 - accuracy: 0.869 - ETA: 40s - loss: 0.3672 - accuracy: 0.870 - ETA: 39s - loss: 0.3666 - accuracy: 0.870 - ETA: 38s - loss: 0.3668 - accuracy: 0.870 - ETA: 37s - loss: 0.3663 - accuracy: 0.870 - ETA: 36s - loss: 0.3671 - accuracy: 0.870 - ETA: 35s - loss: 0.3658 - accuracy: 0.870 - ETA: 34s - loss: 0.3656 - accuracy: 0.870 - ETA: 34s - loss: 0.3654 - accuracy: 0.870 - ETA: 33s - loss: 0.3654 - accuracy: 0.870 - ETA: 32s - loss: 0.3654 - accuracy: 0.870 - ETA: 31s - loss: 0.3648 - accuracy: 0.871 - ETA: 30s - loss: 0.3645 - accuracy: 0.871 - ETA: 29s - loss: 0.3648 - accuracy: 0.871 - ETA: 28s - loss: 0.3646 - accuracy: 0.871 - ETA: 27s - loss: 0.3658 - accuracy: 0.870 - ETA: 26s - loss: 0.3658 - accuracy: 0.870 - ETA: 25s - loss: 0.3653 - accuracy: 0.870 - ETA: 25s - loss: 0.3647 - accuracy: 0.870 - ETA: 24s - loss: 0.3651 - accuracy: 0.870 - ETA: 23s - loss: 0.3656 - accuracy: 0.870 - ETA: 22s - loss: 0.3666 - accuracy: 0.869 - ETA: 21s - loss: 0.3674 - accuracy: 0.869 - ETA: 20s - loss: 0.3676 - accuracy: 0.869 - ETA: 19s - loss: 0.3675 - accuracy: 0.869 - ETA: 18s - loss: 0.3675 - accuracy: 0.869 - ETA: 17s - loss: 0.3677 - accuracy: 0.869 - ETA: 16s - loss: 0.3665 - accuracy: 0.870 - ETA: 16s - loss: 0.3662 - accuracy: 0.870 - ETA: 15s - loss: 0.3664 - accuracy: 0.870 - ETA: 14s - loss: 0.3670 - accuracy: 0.870 - ETA: 13s - loss: 0.3655 - accuracy: 0.870 - ETA: 12s - loss: 0.3651 - accuracy: 0.870 - ETA: 11s - loss: 0.3638 - accuracy: 0.871 - ETA: 10s - loss: 0.3645 - accuracy: 0.871 - ETA: 9s - loss: 0.3647 - accuracy: 0.870 - ETA: 8s - loss: 0.3644 - accuracy: 0.87 - ETA: 8s - loss: 0.3646 - accuracy: 0.87 - ETA: 7s - loss: 0.3644 - accuracy: 0.87 - ETA: 6s - loss: 0.3639 - accuracy: 0.87 - ETA: 5s - loss: 0.3636 - accuracy: 0.87 - ETA: 4s - loss: 0.3633 - accuracy: 0.87 - ETA: 3s - loss: 0.3630 - accuracy: 0.87 - ETA: 2s - loss: 0.3634 - accuracy: 0.87 - ETA: 1s - loss: 0.3630 - accuracy: 0.87 - ETA: 0s - loss: 0.3633 - accuracy: 0.87 - 148s 8ms/step - loss: 0.3625 - accuracy: 0.8711 - val_loss: 1.5337 - val_accuracy: 0.7498\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 0.3149 - accuracy: 0.89 - ETA: 2:19 - loss: 0.3156 - accuracy: 0.89 - ETA: 2:16 - loss: 0.3721 - accuracy: 0.87 - ETA: 2:14 - loss: 0.3661 - accuracy: 0.87 - ETA: 2:14 - loss: 0.3692 - accuracy: 0.87 - ETA: 2:12 - loss: 0.3949 - accuracy: 0.85 - ETA: 2:10 - loss: 0.3991 - accuracy: 0.85 - ETA: 2:09 - loss: 0.3925 - accuracy: 0.86 - ETA: 2:10 - loss: 0.3830 - accuracy: 0.86 - ETA: 2:10 - loss: 0.3767 - accuracy: 0.87 - ETA: 2:09 - loss: 0.3865 - accuracy: 0.86 - ETA: 2:07 - loss: 0.3862 - accuracy: 0.86 - ETA: 2:05 - loss: 0.3738 - accuracy: 0.87 - ETA: 2:04 - loss: 0.3819 - accuracy: 0.86 - ETA: 2:03 - loss: 0.3848 - accuracy: 0.86 - ETA: 2:03 - loss: 0.3885 - accuracy: 0.86 - ETA: 2:03 - loss: 0.3851 - accuracy: 0.86 - ETA: 2:01 - loss: 0.3827 - accuracy: 0.86 - ETA: 2:00 - loss: 0.3793 - accuracy: 0.86 - ETA: 1:59 - loss: 0.3779 - accuracy: 0.86 - ETA: 1:58 - loss: 0.3692 - accuracy: 0.86 - ETA: 1:57 - loss: 0.3723 - accuracy: 0.86 - ETA: 1:55 - loss: 0.3718 - accuracy: 0.86 - ETA: 1:54 - loss: 0.3683 - accuracy: 0.86 - ETA: 1:53 - loss: 0.3626 - accuracy: 0.87 - ETA: 1:52 - loss: 0.3643 - accuracy: 0.87 - ETA: 1:51 - loss: 0.3639 - accuracy: 0.87 - ETA: 1:50 - loss: 0.3652 - accuracy: 0.86 - ETA: 1:49 - loss: 0.3690 - accuracy: 0.86 - ETA: 1:48 - loss: 0.3721 - accuracy: 0.86 - ETA: 1:47 - loss: 0.3698 - accuracy: 0.86 - ETA: 1:46 - loss: 0.3677 - accuracy: 0.86 - ETA: 1:45 - loss: 0.3630 - accuracy: 0.87 - ETA: 1:45 - loss: 0.3687 - accuracy: 0.86 - ETA: 1:44 - loss: 0.3680 - accuracy: 0.87 - ETA: 1:44 - loss: 0.3657 - accuracy: 0.87 - ETA: 1:43 - loss: 0.3676 - accuracy: 0.87 - ETA: 1:43 - loss: 0.3676 - accuracy: 0.87 - ETA: 1:42 - loss: 0.3651 - accuracy: 0.87 - ETA: 1:41 - loss: 0.3646 - accuracy: 0.87 - ETA: 1:40 - loss: 0.3654 - accuracy: 0.87 - ETA: 1:39 - loss: 0.3623 - accuracy: 0.87 - ETA: 1:38 - loss: 0.3602 - accuracy: 0.87 - ETA: 1:37 - loss: 0.3600 - accuracy: 0.87 - ETA: 1:36 - loss: 0.3606 - accuracy: 0.87 - ETA: 1:35 - loss: 0.3583 - accuracy: 0.87 - ETA: 1:34 - loss: 0.3608 - accuracy: 0.87 - ETA: 1:34 - loss: 0.3602 - accuracy: 0.87 - ETA: 1:33 - loss: 0.3596 - accuracy: 0.87 - ETA: 1:32 - loss: 0.3625 - accuracy: 0.87 - ETA: 1:32 - loss: 0.3644 - accuracy: 0.87 - ETA: 1:30 - loss: 0.3655 - accuracy: 0.87 - ETA: 1:29 - loss: 0.3668 - accuracy: 0.87 - ETA: 1:29 - loss: 0.3680 - accuracy: 0.87 - ETA: 1:28 - loss: 0.3674 - accuracy: 0.87 - ETA: 1:26 - loss: 0.3670 - accuracy: 0.87 - ETA: 1:25 - loss: 0.3669 - accuracy: 0.87 - ETA: 1:24 - loss: 0.3650 - accuracy: 0.87 - ETA: 1:24 - loss: 0.3634 - accuracy: 0.87 - ETA: 1:23 - loss: 0.3624 - accuracy: 0.87 - ETA: 1:22 - loss: 0.3622 - accuracy: 0.87 - ETA: 1:21 - loss: 0.3615 - accuracy: 0.87 - ETA: 1:19 - loss: 0.3624 - accuracy: 0.87 - ETA: 1:19 - loss: 0.3636 - accuracy: 0.87 - ETA: 1:18 - loss: 0.3634 - accuracy: 0.87 - ETA: 1:17 - loss: 0.3654 - accuracy: 0.87 - ETA: 1:16 - loss: 0.3643 - accuracy: 0.87 - ETA: 1:15 - loss: 0.3660 - accuracy: 0.87 - ETA: 1:14 - loss: 0.3651 - accuracy: 0.87 - ETA: 1:13 - loss: 0.3651 - accuracy: 0.87 - ETA: 1:12 - loss: 0.3646 - accuracy: 0.87 - ETA: 1:12 - loss: 0.3637 - accuracy: 0.87 - ETA: 1:11 - loss: 0.3635 - accuracy: 0.87 - ETA: 1:10 - loss: 0.3620 - accuracy: 0.87 - ETA: 1:09 - loss: 0.3623 - accuracy: 0.87 - ETA: 1:08 - loss: 0.3622 - accuracy: 0.87 - ETA: 1:07 - loss: 0.3629 - accuracy: 0.87 - ETA: 1:06 - loss: 0.3631 - accuracy: 0.87 - ETA: 1:05 - loss: 0.3623 - accuracy: 0.87 - ETA: 1:04 - loss: 0.3631 - accuracy: 0.87 - ETA: 1:03 - loss: 0.3664 - accuracy: 0.87 - ETA: 1:02 - loss: 0.3661 - accuracy: 0.87 - ETA: 1:02 - loss: 0.3657 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3662 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3669 - accuracy: 0.87 - ETA: 59s - loss: 0.3663 - accuracy: 0.8712 - ETA: 58s - loss: 0.3646 - accuracy: 0.871 - ETA: 57s - loss: 0.3647 - accuracy: 0.871 - ETA: 56s - loss: 0.3658 - accuracy: 0.871 - ETA: 55s - loss: 0.3655 - accuracy: 0.871 - ETA: 55s - loss: 0.3651 - accuracy: 0.872 - ETA: 54s - loss: 0.3646 - accuracy: 0.872 - ETA: 53s - loss: 0.3651 - accuracy: 0.872 - ETA: 52s - loss: 0.3648 - accuracy: 0.872 - ETA: 51s - loss: 0.3648 - accuracy: 0.872 - ETA: 50s - loss: 0.3660 - accuracy: 0.871 - ETA: 49s - loss: 0.3681 - accuracy: 0.871 - ETA: 48s - loss: 0.3680 - accuracy: 0.870 - ETA: 47s - loss: 0.3669 - accuracy: 0.870 - ETA: 46s - loss: 0.3661 - accuracy: 0.871 - ETA: 46s - loss: 0.3662 - accuracy: 0.870 - ETA: 45s - loss: 0.3661 - accuracy: 0.870 - ETA: 44s - loss: 0.3678 - accuracy: 0.870 - ETA: 43s - loss: 0.3683 - accuracy: 0.869 - ETA: 42s - loss: 0.3683 - accuracy: 0.869 - ETA: 41s - loss: 0.3683 - accuracy: 0.870 - ETA: 40s - loss: 0.3680 - accuracy: 0.870 - ETA: 39s - loss: 0.3686 - accuracy: 0.869 - ETA: 38s - loss: 0.3694 - accuracy: 0.869 - ETA: 37s - loss: 0.3688 - accuracy: 0.869 - ETA: 36s - loss: 0.3684 - accuracy: 0.869 - ETA: 35s - loss: 0.3674 - accuracy: 0.869 - ETA: 34s - loss: 0.3666 - accuracy: 0.870 - ETA: 33s - loss: 0.3666 - accuracy: 0.870 - ETA: 33s - loss: 0.3679 - accuracy: 0.870 - ETA: 32s - loss: 0.3676 - accuracy: 0.870 - ETA: 31s - loss: 0.3674 - accuracy: 0.870 - ETA: 30s - loss: 0.3662 - accuracy: 0.870 - ETA: 29s - loss: 0.3656 - accuracy: 0.870 - ETA: 28s - loss: 0.3669 - accuracy: 0.870 - ETA: 27s - loss: 0.3667 - accuracy: 0.870 - ETA: 26s - loss: 0.3681 - accuracy: 0.870 - ETA: 25s - loss: 0.3688 - accuracy: 0.869 - ETA: 24s - loss: 0.3686 - accuracy: 0.869 - ETA: 23s - loss: 0.3688 - accuracy: 0.869 - ETA: 22s - loss: 0.3698 - accuracy: 0.869 - ETA: 22s - loss: 0.3697 - accuracy: 0.869 - ETA: 21s - loss: 0.3692 - accuracy: 0.869 - ETA: 20s - loss: 0.3690 - accuracy: 0.869 - ETA: 19s - loss: 0.3687 - accuracy: 0.869 - ETA: 18s - loss: 0.3674 - accuracy: 0.869 - ETA: 17s - loss: 0.3674 - accuracy: 0.869 - ETA: 16s - loss: 0.3677 - accuracy: 0.869 - ETA: 15s - loss: 0.3669 - accuracy: 0.869 - ETA: 14s - loss: 0.3663 - accuracy: 0.870 - ETA: 13s - loss: 0.3664 - accuracy: 0.870 - ETA: 12s - loss: 0.3657 - accuracy: 0.870 - ETA: 11s - loss: 0.3659 - accuracy: 0.870 - ETA: 10s - loss: 0.3654 - accuracy: 0.870 - ETA: 10s - loss: 0.3661 - accuracy: 0.870 - ETA: 9s - loss: 0.3662 - accuracy: 0.870 - ETA: 8s - loss: 0.3666 - accuracy: 0.87 - ETA: 7s - loss: 0.3669 - accuracy: 0.87 - ETA: 6s - loss: 0.3663 - accuracy: 0.87 - ETA: 5s - loss: 0.3657 - accuracy: 0.87 - ETA: 4s - loss: 0.3654 - accuracy: 0.87 - ETA: 3s - loss: 0.3656 - accuracy: 0.87 - ETA: 2s - loss: 0.3652 - accuracy: 0.87 - ETA: 1s - loss: 0.3644 - accuracy: 0.87 - ETA: 0s - loss: 0.3633 - accuracy: 0.87 - 150s 8ms/step - loss: 0.3629 - accuracy: 0.8710 - val_loss: 1.5826 - val_accuracy: 0.7465\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:22 - loss: 0.3527 - accuracy: 0.89 - ETA: 2:14 - loss: 0.3378 - accuracy: 0.89 - ETA: 2:11 - loss: 0.3121 - accuracy: 0.89 - ETA: 2:12 - loss: 0.3133 - accuracy: 0.89 - ETA: 2:10 - loss: 0.3180 - accuracy: 0.89 - ETA: 2:08 - loss: 0.3048 - accuracy: 0.89 - ETA: 2:07 - loss: 0.3011 - accuracy: 0.89 - ETA: 2:06 - loss: 0.3026 - accuracy: 0.90 - ETA: 2:08 - loss: 0.3018 - accuracy: 0.90 - ETA: 2:09 - loss: 0.3084 - accuracy: 0.89 - ETA: 2:10 - loss: 0.3136 - accuracy: 0.89 - ETA: 2:10 - loss: 0.3195 - accuracy: 0.89 - ETA: 2:10 - loss: 0.3177 - accuracy: 0.89 - ETA: 2:12 - loss: 0.3242 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3273 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3219 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3267 - accuracy: 0.88 - ETA: 2:10 - loss: 0.3383 - accuracy: 0.88 - ETA: 2:10 - loss: 0.3359 - accuracy: 0.88 - ETA: 2:09 - loss: 0.3363 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3342 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3327 - accuracy: 0.88 - ETA: 2:06 - loss: 0.3296 - accuracy: 0.88 - ETA: 2:05 - loss: 0.3280 - accuracy: 0.88 - ETA: 2:04 - loss: 0.3275 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3252 - accuracy: 0.88 - ETA: 2:01 - loss: 0.3274 - accuracy: 0.88 - ETA: 2:00 - loss: 0.3261 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3290 - accuracy: 0.88 - ETA: 1:57 - loss: 0.3316 - accuracy: 0.88 - ETA: 1:56 - loss: 0.3304 - accuracy: 0.88 - ETA: 1:55 - loss: 0.3277 - accuracy: 0.88 - ETA: 1:53 - loss: 0.3286 - accuracy: 0.88 - ETA: 1:52 - loss: 0.3284 - accuracy: 0.88 - ETA: 1:51 - loss: 0.3309 - accuracy: 0.88 - ETA: 1:50 - loss: 0.3334 - accuracy: 0.88 - ETA: 1:48 - loss: 0.3347 - accuracy: 0.88 - ETA: 1:47 - loss: 0.3362 - accuracy: 0.87 - ETA: 1:46 - loss: 0.3355 - accuracy: 0.87 - ETA: 1:45 - loss: 0.3375 - accuracy: 0.87 - ETA: 1:44 - loss: 0.3370 - accuracy: 0.87 - ETA: 1:43 - loss: 0.3375 - accuracy: 0.87 - ETA: 1:42 - loss: 0.3374 - accuracy: 0.87 - ETA: 1:41 - loss: 0.3413 - accuracy: 0.87 - ETA: 1:40 - loss: 0.3413 - accuracy: 0.87 - ETA: 1:39 - loss: 0.3409 - accuracy: 0.87 - ETA: 1:38 - loss: 0.3418 - accuracy: 0.87 - ETA: 1:36 - loss: 0.3432 - accuracy: 0.87 - ETA: 1:35 - loss: 0.3431 - accuracy: 0.87 - ETA: 1:34 - loss: 0.3435 - accuracy: 0.87 - ETA: 1:33 - loss: 0.3418 - accuracy: 0.87 - ETA: 1:32 - loss: 0.3425 - accuracy: 0.87 - ETA: 1:32 - loss: 0.3391 - accuracy: 0.87 - ETA: 1:31 - loss: 0.3371 - accuracy: 0.87 - ETA: 1:30 - loss: 0.3391 - accuracy: 0.87 - ETA: 1:29 - loss: 0.3392 - accuracy: 0.87 - ETA: 1:28 - loss: 0.3390 - accuracy: 0.87 - ETA: 1:27 - loss: 0.3389 - accuracy: 0.87 - ETA: 1:26 - loss: 0.3421 - accuracy: 0.87 - ETA: 1:25 - loss: 0.3403 - accuracy: 0.87 - ETA: 1:24 - loss: 0.3418 - accuracy: 0.87 - ETA: 1:23 - loss: 0.3432 - accuracy: 0.87 - ETA: 1:22 - loss: 0.3430 - accuracy: 0.87 - ETA: 1:21 - loss: 0.3422 - accuracy: 0.87 - ETA: 1:20 - loss: 0.3420 - accuracy: 0.87 - ETA: 1:19 - loss: 0.3429 - accuracy: 0.87 - ETA: 1:18 - loss: 0.3430 - accuracy: 0.87 - ETA: 1:17 - loss: 0.3429 - accuracy: 0.87 - ETA: 1:16 - loss: 0.3436 - accuracy: 0.87 - ETA: 1:15 - loss: 0.3437 - accuracy: 0.87 - ETA: 1:14 - loss: 0.3458 - accuracy: 0.87 - ETA: 1:13 - loss: 0.3444 - accuracy: 0.87 - ETA: 1:12 - loss: 0.3447 - accuracy: 0.87 - ETA: 1:11 - loss: 0.3438 - accuracy: 0.87 - ETA: 1:10 - loss: 0.3440 - accuracy: 0.87 - ETA: 1:09 - loss: 0.3435 - accuracy: 0.87 - ETA: 1:08 - loss: 0.3434 - accuracy: 0.87 - ETA: 1:07 - loss: 0.3435 - accuracy: 0.87 - ETA: 1:06 - loss: 0.3448 - accuracy: 0.87 - ETA: 1:05 - loss: 0.3443 - accuracy: 0.87 - ETA: 1:04 - loss: 0.3448 - accuracy: 0.87 - ETA: 1:03 - loss: 0.3446 - accuracy: 0.87 - ETA: 1:02 - loss: 0.3440 - accuracy: 0.87 - ETA: 1:02 - loss: 0.3447 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3446 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3428 - accuracy: 0.87 - ETA: 59s - loss: 0.3409 - accuracy: 0.8789 - ETA: 58s - loss: 0.3408 - accuracy: 0.878 - ETA: 57s - loss: 0.3398 - accuracy: 0.879 - ETA: 56s - loss: 0.3389 - accuracy: 0.879 - ETA: 55s - loss: 0.3394 - accuracy: 0.879 - ETA: 54s - loss: 0.3383 - accuracy: 0.879 - ETA: 53s - loss: 0.3381 - accuracy: 0.879 - ETA: 52s - loss: 0.3386 - accuracy: 0.879 - ETA: 51s - loss: 0.3382 - accuracy: 0.879 - ETA: 50s - loss: 0.3387 - accuracy: 0.879 - ETA: 49s - loss: 0.3382 - accuracy: 0.879 - ETA: 48s - loss: 0.3364 - accuracy: 0.879 - ETA: 47s - loss: 0.3389 - accuracy: 0.878 - ETA: 46s - loss: 0.3385 - accuracy: 0.879 - ETA: 46s - loss: 0.3393 - accuracy: 0.878 - ETA: 45s - loss: 0.3394 - accuracy: 0.878 - ETA: 44s - loss: 0.3403 - accuracy: 0.878 - ETA: 43s - loss: 0.3409 - accuracy: 0.878 - ETA: 42s - loss: 0.3427 - accuracy: 0.877 - ETA: 41s - loss: 0.3428 - accuracy: 0.877 - ETA: 40s - loss: 0.3423 - accuracy: 0.878 - ETA: 39s - loss: 0.3421 - accuracy: 0.878 - ETA: 38s - loss: 0.3413 - accuracy: 0.878 - ETA: 37s - loss: 0.3412 - accuracy: 0.878 - ETA: 36s - loss: 0.3417 - accuracy: 0.878 - ETA: 35s - loss: 0.3428 - accuracy: 0.877 - ETA: 34s - loss: 0.3435 - accuracy: 0.877 - ETA: 33s - loss: 0.3427 - accuracy: 0.877 - ETA: 32s - loss: 0.3427 - accuracy: 0.877 - ETA: 32s - loss: 0.3424 - accuracy: 0.877 - ETA: 31s - loss: 0.3425 - accuracy: 0.877 - ETA: 30s - loss: 0.3426 - accuracy: 0.877 - ETA: 29s - loss: 0.3426 - accuracy: 0.877 - ETA: 28s - loss: 0.3435 - accuracy: 0.877 - ETA: 27s - loss: 0.3447 - accuracy: 0.876 - ETA: 26s - loss: 0.3449 - accuracy: 0.876 - ETA: 25s - loss: 0.3456 - accuracy: 0.876 - ETA: 24s - loss: 0.3466 - accuracy: 0.875 - ETA: 23s - loss: 0.3458 - accuracy: 0.876 - ETA: 22s - loss: 0.3463 - accuracy: 0.875 - ETA: 21s - loss: 0.3463 - accuracy: 0.875 - ETA: 21s - loss: 0.3462 - accuracy: 0.876 - ETA: 20s - loss: 0.3474 - accuracy: 0.876 - ETA: 19s - loss: 0.3475 - accuracy: 0.876 - ETA: 18s - loss: 0.3475 - accuracy: 0.876 - ETA: 17s - loss: 0.3483 - accuracy: 0.876 - ETA: 16s - loss: 0.3478 - accuracy: 0.876 - ETA: 15s - loss: 0.3476 - accuracy: 0.875 - ETA: 14s - loss: 0.3478 - accuracy: 0.875 - ETA: 13s - loss: 0.3483 - accuracy: 0.875 - ETA: 12s - loss: 0.3480 - accuracy: 0.875 - ETA: 11s - loss: 0.3483 - accuracy: 0.875 - ETA: 10s - loss: 0.3491 - accuracy: 0.875 - ETA: 10s - loss: 0.3497 - accuracy: 0.875 - ETA: 9s - loss: 0.3500 - accuracy: 0.875 - ETA: 8s - loss: 0.3493 - accuracy: 0.87 - ETA: 7s - loss: 0.3486 - accuracy: 0.87 - ETA: 6s - loss: 0.3478 - accuracy: 0.87 - ETA: 5s - loss: 0.3473 - accuracy: 0.87 - ETA: 4s - loss: 0.3484 - accuracy: 0.87 - ETA: 3s - loss: 0.3486 - accuracy: 0.87 - ETA: 2s - loss: 0.3484 - accuracy: 0.87 - ETA: 1s - loss: 0.3480 - accuracy: 0.87 - ETA: 0s - loss: 0.3479 - accuracy: 0.87 - 151s 8ms/step - loss: 0.3478 - accuracy: 0.8761 - val_loss: 1.5549 - val_accuracy: 0.7496\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:18 - loss: 0.3621 - accuracy: 0.86 - ETA: 2:25 - loss: 0.3061 - accuracy: 0.88 - ETA: 2:25 - loss: 0.3216 - accuracy: 0.88 - ETA: 2:21 - loss: 0.3091 - accuracy: 0.88 - ETA: 2:20 - loss: 0.3048 - accuracy: 0.89 - ETA: 2:17 - loss: 0.3066 - accuracy: 0.89 - ETA: 2:14 - loss: 0.3087 - accuracy: 0.89 - ETA: 2:12 - loss: 0.3048 - accuracy: 0.89 - ETA: 2:10 - loss: 0.3067 - accuracy: 0.89 - ETA: 2:08 - loss: 0.3033 - accuracy: 0.89 - ETA: 2:06 - loss: 0.3023 - accuracy: 0.89 - ETA: 2:05 - loss: 0.3085 - accuracy: 0.89 - ETA: 2:04 - loss: 0.3196 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3388 - accuracy: 0.88 - ETA: 2:02 - loss: 0.3456 - accuracy: 0.88 - ETA: 2:01 - loss: 0.3436 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3342 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3367 - accuracy: 0.88 - ETA: 1:58 - loss: 0.3394 - accuracy: 0.88 - ETA: 2:00 - loss: 0.3371 - accuracy: 0.88 - ETA: 2:01 - loss: 0.3421 - accuracy: 0.87 - ETA: 2:01 - loss: 0.3445 - accuracy: 0.87 - ETA: 2:01 - loss: 0.3464 - accuracy: 0.87 - ETA: 2:00 - loss: 0.3514 - accuracy: 0.87 - ETA: 1:59 - loss: 0.3538 - accuracy: 0.87 - ETA: 1:58 - loss: 0.3588 - accuracy: 0.87 - ETA: 1:57 - loss: 0.3582 - accuracy: 0.87 - ETA: 1:55 - loss: 0.3579 - accuracy: 0.87 - ETA: 1:54 - loss: 0.3551 - accuracy: 0.87 - ETA: 1:53 - loss: 0.3570 - accuracy: 0.87 - ETA: 1:52 - loss: 0.3550 - accuracy: 0.87 - ETA: 1:51 - loss: 0.3548 - accuracy: 0.87 - ETA: 1:49 - loss: 0.3532 - accuracy: 0.87 - ETA: 1:48 - loss: 0.3524 - accuracy: 0.87 - ETA: 1:47 - loss: 0.3504 - accuracy: 0.87 - ETA: 1:46 - loss: 0.3496 - accuracy: 0.87 - ETA: 1:46 - loss: 0.3488 - accuracy: 0.87 - ETA: 1:45 - loss: 0.3467 - accuracy: 0.87 - ETA: 1:43 - loss: 0.3460 - accuracy: 0.87 - ETA: 1:42 - loss: 0.3520 - accuracy: 0.87 - ETA: 1:41 - loss: 0.3532 - accuracy: 0.87 - ETA: 1:40 - loss: 0.3526 - accuracy: 0.87 - ETA: 1:39 - loss: 0.3516 - accuracy: 0.87 - ETA: 1:38 - loss: 0.3536 - accuracy: 0.87 - ETA: 1:37 - loss: 0.3545 - accuracy: 0.87 - ETA: 1:36 - loss: 0.3535 - accuracy: 0.87 - ETA: 1:35 - loss: 0.3537 - accuracy: 0.87 - ETA: 1:34 - loss: 0.3530 - accuracy: 0.87 - ETA: 1:33 - loss: 0.3545 - accuracy: 0.87 - ETA: 1:32 - loss: 0.3559 - accuracy: 0.87 - ETA: 1:31 - loss: 0.3553 - accuracy: 0.87 - ETA: 1:30 - loss: 0.3524 - accuracy: 0.87 - ETA: 1:29 - loss: 0.3554 - accuracy: 0.87 - ETA: 1:28 - loss: 0.3542 - accuracy: 0.87 - ETA: 1:28 - loss: 0.3537 - accuracy: 0.87 - ETA: 1:27 - loss: 0.3544 - accuracy: 0.87 - ETA: 1:26 - loss: 0.3535 - accuracy: 0.87 - ETA: 1:25 - loss: 0.3561 - accuracy: 0.87 - ETA: 1:24 - loss: 0.3559 - accuracy: 0.87 - ETA: 1:23 - loss: 0.3561 - accuracy: 0.87 - ETA: 1:22 - loss: 0.3541 - accuracy: 0.87 - ETA: 1:21 - loss: 0.3531 - accuracy: 0.87 - ETA: 1:20 - loss: 0.3522 - accuracy: 0.87 - ETA: 1:19 - loss: 0.3518 - accuracy: 0.87 - ETA: 1:18 - loss: 0.3517 - accuracy: 0.87 - ETA: 1:17 - loss: 0.3529 - accuracy: 0.87 - ETA: 1:16 - loss: 0.3535 - accuracy: 0.87 - ETA: 1:15 - loss: 0.3533 - accuracy: 0.87 - ETA: 1:14 - loss: 0.3511 - accuracy: 0.87 - ETA: 1:13 - loss: 0.3516 - accuracy: 0.87 - ETA: 1:12 - loss: 0.3535 - accuracy: 0.87 - ETA: 1:11 - loss: 0.3539 - accuracy: 0.87 - ETA: 1:10 - loss: 0.3518 - accuracy: 0.87 - ETA: 1:10 - loss: 0.3507 - accuracy: 0.87 - ETA: 1:09 - loss: 0.3526 - accuracy: 0.87 - ETA: 1:08 - loss: 0.3510 - accuracy: 0.87 - ETA: 1:07 - loss: 0.3500 - accuracy: 0.87 - ETA: 1:06 - loss: 0.3499 - accuracy: 0.87 - ETA: 1:05 - loss: 0.3501 - accuracy: 0.87 - ETA: 1:04 - loss: 0.3512 - accuracy: 0.87 - ETA: 1:03 - loss: 0.3505 - accuracy: 0.87 - ETA: 1:02 - loss: 0.3500 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3501 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3500 - accuracy: 0.87 - ETA: 59s - loss: 0.3507 - accuracy: 0.8745 - ETA: 58s - loss: 0.3503 - accuracy: 0.874 - ETA: 58s - loss: 0.3500 - accuracy: 0.874 - ETA: 57s - loss: 0.3488 - accuracy: 0.875 - ETA: 56s - loss: 0.3490 - accuracy: 0.875 - ETA: 55s - loss: 0.3496 - accuracy: 0.875 - ETA: 54s - loss: 0.3494 - accuracy: 0.875 - ETA: 53s - loss: 0.3506 - accuracy: 0.875 - ETA: 52s - loss: 0.3504 - accuracy: 0.875 - ETA: 51s - loss: 0.3508 - accuracy: 0.875 - ETA: 50s - loss: 0.3497 - accuracy: 0.875 - ETA: 49s - loss: 0.3495 - accuracy: 0.875 - ETA: 48s - loss: 0.3482 - accuracy: 0.876 - ETA: 48s - loss: 0.3475 - accuracy: 0.876 - ETA: 47s - loss: 0.3492 - accuracy: 0.875 - ETA: 46s - loss: 0.3494 - accuracy: 0.875 - ETA: 45s - loss: 0.3510 - accuracy: 0.875 - ETA: 44s - loss: 0.3511 - accuracy: 0.874 - ETA: 43s - loss: 0.3511 - accuracy: 0.874 - ETA: 42s - loss: 0.3517 - accuracy: 0.874 - ETA: 41s - loss: 0.3514 - accuracy: 0.874 - ETA: 40s - loss: 0.3527 - accuracy: 0.874 - ETA: 39s - loss: 0.3521 - accuracy: 0.874 - ETA: 38s - loss: 0.3508 - accuracy: 0.874 - ETA: 37s - loss: 0.3517 - accuracy: 0.874 - ETA: 37s - loss: 0.3511 - accuracy: 0.874 - ETA: 36s - loss: 0.3517 - accuracy: 0.874 - ETA: 35s - loss: 0.3521 - accuracy: 0.873 - ETA: 34s - loss: 0.3534 - accuracy: 0.873 - ETA: 33s - loss: 0.3533 - accuracy: 0.873 - ETA: 32s - loss: 0.3526 - accuracy: 0.873 - ETA: 31s - loss: 0.3523 - accuracy: 0.874 - ETA: 30s - loss: 0.3512 - accuracy: 0.874 - ETA: 29s - loss: 0.3504 - accuracy: 0.874 - ETA: 28s - loss: 0.3525 - accuracy: 0.873 - ETA: 27s - loss: 0.3526 - accuracy: 0.873 - ETA: 26s - loss: 0.3522 - accuracy: 0.873 - ETA: 26s - loss: 0.3525 - accuracy: 0.873 - ETA: 25s - loss: 0.3524 - accuracy: 0.873 - ETA: 24s - loss: 0.3521 - accuracy: 0.873 - ETA: 23s - loss: 0.3518 - accuracy: 0.873 - ETA: 22s - loss: 0.3514 - accuracy: 0.873 - ETA: 21s - loss: 0.3515 - accuracy: 0.873 - ETA: 20s - loss: 0.3512 - accuracy: 0.873 - ETA: 19s - loss: 0.3501 - accuracy: 0.874 - ETA: 18s - loss: 0.3506 - accuracy: 0.874 - ETA: 17s - loss: 0.3503 - accuracy: 0.874 - ETA: 17s - loss: 0.3502 - accuracy: 0.874 - ETA: 16s - loss: 0.3504 - accuracy: 0.874 - ETA: 15s - loss: 0.3502 - accuracy: 0.874 - ETA: 14s - loss: 0.3509 - accuracy: 0.873 - ETA: 13s - loss: 0.3504 - accuracy: 0.873 - ETA: 12s - loss: 0.3504 - accuracy: 0.873 - ETA: 11s - loss: 0.3513 - accuracy: 0.873 - ETA: 10s - loss: 0.3517 - accuracy: 0.873 - ETA: 9s - loss: 0.3513 - accuracy: 0.873 - ETA: 9s - loss: 0.3518 - accuracy: 0.87 - ETA: 8s - loss: 0.3516 - accuracy: 0.87 - ETA: 7s - loss: 0.3522 - accuracy: 0.87 - ETA: 6s - loss: 0.3517 - accuracy: 0.87 - ETA: 5s - loss: 0.3512 - accuracy: 0.87 - ETA: 4s - loss: 0.3514 - accuracy: 0.87 - ETA: 3s - loss: 0.3519 - accuracy: 0.87 - ETA: 2s - loss: 0.3515 - accuracy: 0.87 - ETA: 1s - loss: 0.3513 - accuracy: 0.87 - ETA: 0s - loss: 0.3517 - accuracy: 0.87 - 159s 8ms/step - loss: 0.3511 - accuracy: 0.8740 - val_loss: 1.5662 - val_accuracy: 0.7525\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:49 - loss: 0.4046 - accuracy: 0.83 - ETA: 2:57 - loss: 0.3598 - accuracy: 0.85 - ETA: 3:00 - loss: 0.3686 - accuracy: 0.86 - ETA: 2:58 - loss: 0.3744 - accuracy: 0.85 - ETA: 2:53 - loss: 0.3613 - accuracy: 0.87 - ETA: 2:52 - loss: 0.3561 - accuracy: 0.86 - ETA: 2:51 - loss: 0.3581 - accuracy: 0.86 - ETA: 2:52 - loss: 0.3574 - accuracy: 0.87 - ETA: 2:52 - loss: 0.3662 - accuracy: 0.86 - ETA: 2:50 - loss: 0.3593 - accuracy: 0.87 - ETA: 2:48 - loss: 0.3632 - accuracy: 0.86 - ETA: 2:46 - loss: 0.3554 - accuracy: 0.86 - ETA: 2:44 - loss: 0.3573 - accuracy: 0.86 - ETA: 2:41 - loss: 0.3517 - accuracy: 0.87 - ETA: 2:40 - loss: 0.3446 - accuracy: 0.87 - ETA: 2:40 - loss: 0.3506 - accuracy: 0.87 - ETA: 2:39 - loss: 0.3508 - accuracy: 0.87 - ETA: 2:37 - loss: 0.3407 - accuracy: 0.87 - ETA: 2:35 - loss: 0.3395 - accuracy: 0.87 - ETA: 2:34 - loss: 0.3402 - accuracy: 0.87 - ETA: 2:32 - loss: 0.3383 - accuracy: 0.87 - ETA: 2:31 - loss: 0.3345 - accuracy: 0.87 - ETA: 2:29 - loss: 0.3315 - accuracy: 0.87 - ETA: 2:28 - loss: 0.3329 - accuracy: 0.87 - ETA: 2:26 - loss: 0.3342 - accuracy: 0.87 - ETA: 2:24 - loss: 0.3358 - accuracy: 0.87 - ETA: 2:23 - loss: 0.3350 - accuracy: 0.87 - ETA: 2:22 - loss: 0.3400 - accuracy: 0.87 - ETA: 2:21 - loss: 0.3381 - accuracy: 0.87 - ETA: 2:20 - loss: 0.3384 - accuracy: 0.87 - ETA: 2:19 - loss: 0.3362 - accuracy: 0.87 - ETA: 2:18 - loss: 0.3334 - accuracy: 0.87 - ETA: 2:16 - loss: 0.3352 - accuracy: 0.87 - ETA: 2:15 - loss: 0.3383 - accuracy: 0.87 - ETA: 2:13 - loss: 0.3368 - accuracy: 0.87 - ETA: 2:12 - loss: 0.3329 - accuracy: 0.87 - ETA: 2:11 - loss: 0.3311 - accuracy: 0.87 - ETA: 2:09 - loss: 0.3308 - accuracy: 0.87 - ETA: 2:08 - loss: 0.3289 - accuracy: 0.87 - ETA: 2:07 - loss: 0.3281 - accuracy: 0.87 - ETA: 2:05 - loss: 0.3303 - accuracy: 0.87 - ETA: 2:04 - loss: 0.3331 - accuracy: 0.87 - ETA: 2:03 - loss: 0.3336 - accuracy: 0.87 - ETA: 2:01 - loss: 0.3319 - accuracy: 0.87 - ETA: 2:00 - loss: 0.3354 - accuracy: 0.87 - ETA: 1:59 - loss: 0.3358 - accuracy: 0.87 - ETA: 1:58 - loss: 0.3339 - accuracy: 0.87 - ETA: 1:57 - loss: 0.3334 - accuracy: 0.87 - ETA: 1:56 - loss: 0.3330 - accuracy: 0.87 - ETA: 1:54 - loss: 0.3331 - accuracy: 0.87 - ETA: 1:53 - loss: 0.3322 - accuracy: 0.87 - ETA: 1:52 - loss: 0.3330 - accuracy: 0.87 - ETA: 1:50 - loss: 0.3327 - accuracy: 0.87 - ETA: 1:49 - loss: 0.3332 - accuracy: 0.87 - ETA: 1:48 - loss: 0.3345 - accuracy: 0.87 - ETA: 1:47 - loss: 0.3337 - accuracy: 0.87 - ETA: 1:45 - loss: 0.3344 - accuracy: 0.87 - ETA: 1:44 - loss: 0.3356 - accuracy: 0.87 - ETA: 1:43 - loss: 0.3359 - accuracy: 0.87 - ETA: 1:42 - loss: 0.3352 - accuracy: 0.87 - ETA: 1:41 - loss: 0.3347 - accuracy: 0.87 - ETA: 1:40 - loss: 0.3355 - accuracy: 0.87 - ETA: 1:39 - loss: 0.3337 - accuracy: 0.87 - ETA: 1:38 - loss: 0.3365 - accuracy: 0.87 - ETA: 1:36 - loss: 0.3361 - accuracy: 0.87 - ETA: 1:35 - loss: 0.3353 - accuracy: 0.87 - ETA: 1:34 - loss: 0.3345 - accuracy: 0.87 - ETA: 1:33 - loss: 0.3342 - accuracy: 0.87 - ETA: 1:32 - loss: 0.3372 - accuracy: 0.87 - ETA: 1:30 - loss: 0.3360 - accuracy: 0.87 - ETA: 1:29 - loss: 0.3348 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3358 - accuracy: 0.87 - ETA: 1:27 - loss: 0.3351 - accuracy: 0.87 - ETA: 1:26 - loss: 0.3363 - accuracy: 0.87 - ETA: 1:25 - loss: 0.3364 - accuracy: 0.87 - ETA: 1:24 - loss: 0.3353 - accuracy: 0.87 - ETA: 1:22 - loss: 0.3366 - accuracy: 0.87 - ETA: 1:21 - loss: 0.3375 - accuracy: 0.87 - ETA: 1:20 - loss: 0.3374 - accuracy: 0.87 - ETA: 1:19 - loss: 0.3383 - accuracy: 0.87 - ETA: 1:18 - loss: 0.3380 - accuracy: 0.87 - ETA: 1:17 - loss: 0.3394 - accuracy: 0.87 - ETA: 1:15 - loss: 0.3402 - accuracy: 0.87 - ETA: 1:14 - loss: 0.3389 - accuracy: 0.87 - ETA: 1:13 - loss: 0.3401 - accuracy: 0.87 - ETA: 1:12 - loss: 0.3411 - accuracy: 0.87 - ETA: 1:11 - loss: 0.3394 - accuracy: 0.87 - ETA: 1:10 - loss: 0.3397 - accuracy: 0.87 - ETA: 1:09 - loss: 0.3402 - accuracy: 0.87 - ETA: 1:08 - loss: 0.3391 - accuracy: 0.87 - ETA: 1:07 - loss: 0.3387 - accuracy: 0.87 - ETA: 1:05 - loss: 0.3386 - accuracy: 0.87 - ETA: 1:04 - loss: 0.3380 - accuracy: 0.87 - ETA: 1:03 - loss: 0.3377 - accuracy: 0.87 - ETA: 1:02 - loss: 0.3382 - accuracy: 0.87 - ETA: 1:01 - loss: 0.3389 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3404 - accuracy: 0.87 - ETA: 59s - loss: 0.3411 - accuracy: 0.8774 - ETA: 58s - loss: 0.3414 - accuracy: 0.877 - ETA: 57s - loss: 0.3424 - accuracy: 0.877 - ETA: 55s - loss: 0.3413 - accuracy: 0.877 - ETA: 54s - loss: 0.3408 - accuracy: 0.877 - ETA: 53s - loss: 0.3417 - accuracy: 0.877 - ETA: 52s - loss: 0.3409 - accuracy: 0.877 - ETA: 51s - loss: 0.3404 - accuracy: 0.877 - ETA: 50s - loss: 0.3399 - accuracy: 0.878 - ETA: 49s - loss: 0.3409 - accuracy: 0.877 - ETA: 47s - loss: 0.3403 - accuracy: 0.877 - ETA: 46s - loss: 0.3403 - accuracy: 0.877 - ETA: 45s - loss: 0.3398 - accuracy: 0.877 - ETA: 44s - loss: 0.3399 - accuracy: 0.877 - ETA: 43s - loss: 0.3391 - accuracy: 0.878 - ETA: 42s - loss: 0.3395 - accuracy: 0.877 - ETA: 41s - loss: 0.3402 - accuracy: 0.877 - ETA: 39s - loss: 0.3403 - accuracy: 0.877 - ETA: 38s - loss: 0.3409 - accuracy: 0.877 - ETA: 38s - loss: 0.3408 - accuracy: 0.877 - ETA: 37s - loss: 0.3415 - accuracy: 0.877 - ETA: 35s - loss: 0.3413 - accuracy: 0.877 - ETA: 34s - loss: 0.3414 - accuracy: 0.876 - ETA: 33s - loss: 0.3414 - accuracy: 0.876 - ETA: 32s - loss: 0.3411 - accuracy: 0.876 - ETA: 31s - loss: 0.3421 - accuracy: 0.876 - ETA: 30s - loss: 0.3432 - accuracy: 0.876 - ETA: 29s - loss: 0.3433 - accuracy: 0.876 - ETA: 27s - loss: 0.3429 - accuracy: 0.876 - ETA: 26s - loss: 0.3418 - accuracy: 0.877 - ETA: 25s - loss: 0.3416 - accuracy: 0.877 - ETA: 24s - loss: 0.3412 - accuracy: 0.877 - ETA: 23s - loss: 0.3410 - accuracy: 0.877 - ETA: 22s - loss: 0.3404 - accuracy: 0.877 - ETA: 21s - loss: 0.3401 - accuracy: 0.877 - ETA: 20s - loss: 0.3398 - accuracy: 0.878 - ETA: 18s - loss: 0.3403 - accuracy: 0.877 - ETA: 17s - loss: 0.3404 - accuracy: 0.877 - ETA: 16s - loss: 0.3419 - accuracy: 0.876 - ETA: 15s - loss: 0.3420 - accuracy: 0.876 - ETA: 14s - loss: 0.3417 - accuracy: 0.876 - ETA: 13s - loss: 0.3418 - accuracy: 0.876 - ETA: 12s - loss: 0.3420 - accuracy: 0.876 - ETA: 11s - loss: 0.3417 - accuracy: 0.876 - ETA: 9s - loss: 0.3418 - accuracy: 0.876 - ETA: 8s - loss: 0.3419 - accuracy: 0.87 - ETA: 7s - loss: 0.3426 - accuracy: 0.87 - ETA: 6s - loss: 0.3420 - accuracy: 0.87 - ETA: 5s - loss: 0.3420 - accuracy: 0.87 - ETA: 4s - loss: 0.3416 - accuracy: 0.87 - ETA: 3s - loss: 0.3414 - accuracy: 0.87 - ETA: 2s - loss: 0.3411 - accuracy: 0.87 - ETA: 0s - loss: 0.3408 - accuracy: 0.87 - 183s 9ms/step - loss: 0.3411 - accuracy: 0.8768 - val_loss: 1.5353 - val_accuracy: 0.7525\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:43 - loss: 0.2824 - accuracy: 0.92 - ETA: 2:39 - loss: 0.2906 - accuracy: 0.90 - ETA: 2:38 - loss: 0.2788 - accuracy: 0.90 - ETA: 2:37 - loss: 0.2957 - accuracy: 0.89 - ETA: 2:37 - loss: 0.2997 - accuracy: 0.89 - ETA: 2:39 - loss: 0.3028 - accuracy: 0.88 - ETA: 2:37 - loss: 0.3070 - accuracy: 0.88 - ETA: 2:36 - loss: 0.3195 - accuracy: 0.88 - ETA: 2:35 - loss: 0.3278 - accuracy: 0.88 - ETA: 2:35 - loss: 0.3242 - accuracy: 0.88 - ETA: 2:35 - loss: 0.3213 - accuracy: 0.88 - ETA: 2:35 - loss: 0.3224 - accuracy: 0.88 - ETA: 2:34 - loss: 0.3225 - accuracy: 0.88 - ETA: 2:33 - loss: 0.3210 - accuracy: 0.88 - ETA: 2:32 - loss: 0.3236 - accuracy: 0.88 - ETA: 2:31 - loss: 0.3313 - accuracy: 0.88 - ETA: 2:30 - loss: 0.3356 - accuracy: 0.88 - ETA: 2:29 - loss: 0.3330 - accuracy: 0.88 - ETA: 2:27 - loss: 0.3280 - accuracy: 0.88 - ETA: 2:25 - loss: 0.3246 - accuracy: 0.88 - ETA: 2:24 - loss: 0.3243 - accuracy: 0.88 - ETA: 2:22 - loss: 0.3236 - accuracy: 0.88 - ETA: 2:21 - loss: 0.3210 - accuracy: 0.88 - ETA: 2:20 - loss: 0.3222 - accuracy: 0.88 - ETA: 2:20 - loss: 0.3272 - accuracy: 0.88 - ETA: 2:19 - loss: 0.3257 - accuracy: 0.88 - ETA: 2:18 - loss: 0.3254 - accuracy: 0.88 - ETA: 2:17 - loss: 0.3240 - accuracy: 0.88 - ETA: 2:15 - loss: 0.3261 - accuracy: 0.88 - ETA: 2:14 - loss: 0.3249 - accuracy: 0.88 - ETA: 2:13 - loss: 0.3262 - accuracy: 0.88 - ETA: 2:11 - loss: 0.3261 - accuracy: 0.88 - ETA: 2:10 - loss: 0.3313 - accuracy: 0.88 - ETA: 2:09 - loss: 0.3328 - accuracy: 0.88 - ETA: 2:08 - loss: 0.3320 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3305 - accuracy: 0.88 - ETA: 2:06 - loss: 0.3283 - accuracy: 0.88 - ETA: 2:05 - loss: 0.3270 - accuracy: 0.88 - ETA: 2:04 - loss: 0.3298 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3278 - accuracy: 0.88 - ETA: 2:02 - loss: 0.3294 - accuracy: 0.88 - ETA: 2:00 - loss: 0.3282 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3321 - accuracy: 0.88 - ETA: 1:58 - loss: 0.3291 - accuracy: 0.88 - ETA: 1:57 - loss: 0.3297 - accuracy: 0.88 - ETA: 1:56 - loss: 0.3324 - accuracy: 0.88 - ETA: 1:55 - loss: 0.3327 - accuracy: 0.88 - ETA: 1:53 - loss: 0.3331 - accuracy: 0.88 - ETA: 1:52 - loss: 0.3338 - accuracy: 0.88 - ETA: 1:51 - loss: 0.3314 - accuracy: 0.88 - ETA: 1:50 - loss: 0.3291 - accuracy: 0.88 - ETA: 1:49 - loss: 0.3295 - accuracy: 0.88 - ETA: 1:48 - loss: 0.3307 - accuracy: 0.88 - ETA: 1:47 - loss: 0.3316 - accuracy: 0.88 - ETA: 1:46 - loss: 0.3314 - accuracy: 0.88 - ETA: 1:45 - loss: 0.3310 - accuracy: 0.88 - ETA: 1:44 - loss: 0.3321 - accuracy: 0.88 - ETA: 1:43 - loss: 0.3295 - accuracy: 0.88 - ETA: 1:42 - loss: 0.3305 - accuracy: 0.88 - ETA: 1:40 - loss: 0.3298 - accuracy: 0.88 - ETA: 1:40 - loss: 0.3292 - accuracy: 0.88 - ETA: 1:39 - loss: 0.3295 - accuracy: 0.88 - ETA: 1:37 - loss: 0.3310 - accuracy: 0.88 - ETA: 1:36 - loss: 0.3317 - accuracy: 0.88 - ETA: 1:35 - loss: 0.3312 - accuracy: 0.88 - ETA: 1:34 - loss: 0.3313 - accuracy: 0.88 - ETA: 1:33 - loss: 0.3306 - accuracy: 0.88 - ETA: 1:32 - loss: 0.3314 - accuracy: 0.88 - ETA: 1:31 - loss: 0.3305 - accuracy: 0.88 - ETA: 1:30 - loss: 0.3300 - accuracy: 0.88 - ETA: 1:29 - loss: 0.3284 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3293 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3301 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3292 - accuracy: 0.88 - ETA: 1:24 - loss: 0.3284 - accuracy: 0.88 - ETA: 1:23 - loss: 0.3298 - accuracy: 0.88 - ETA: 1:22 - loss: 0.3289 - accuracy: 0.88 - ETA: 1:21 - loss: 0.3277 - accuracy: 0.88 - ETA: 1:20 - loss: 0.3282 - accuracy: 0.88 - ETA: 1:19 - loss: 0.3288 - accuracy: 0.88 - ETA: 1:17 - loss: 0.3289 - accuracy: 0.88 - ETA: 1:16 - loss: 0.3306 - accuracy: 0.88 - ETA: 1:15 - loss: 0.3308 - accuracy: 0.88 - ETA: 1:14 - loss: 0.3297 - accuracy: 0.88 - ETA: 1:13 - loss: 0.3317 - accuracy: 0.88 - ETA: 1:12 - loss: 0.3317 - accuracy: 0.88 - ETA: 1:11 - loss: 0.3323 - accuracy: 0.88 - ETA: 1:10 - loss: 0.3326 - accuracy: 0.88 - ETA: 1:09 - loss: 0.3328 - accuracy: 0.88 - ETA: 1:08 - loss: 0.3332 - accuracy: 0.88 - ETA: 1:07 - loss: 0.3332 - accuracy: 0.88 - ETA: 1:06 - loss: 0.3331 - accuracy: 0.88 - ETA: 1:05 - loss: 0.3332 - accuracy: 0.87 - ETA: 1:04 - loss: 0.3328 - accuracy: 0.88 - ETA: 1:03 - loss: 0.3339 - accuracy: 0.88 - ETA: 1:01 - loss: 0.3353 - accuracy: 0.87 - ETA: 1:00 - loss: 0.3346 - accuracy: 0.87 - ETA: 59s - loss: 0.3343 - accuracy: 0.8802 - ETA: 58s - loss: 0.3358 - accuracy: 0.879 - ETA: 57s - loss: 0.3351 - accuracy: 0.879 - ETA: 56s - loss: 0.3348 - accuracy: 0.879 - ETA: 55s - loss: 0.3358 - accuracy: 0.879 - ETA: 54s - loss: 0.3357 - accuracy: 0.879 - ETA: 52s - loss: 0.3363 - accuracy: 0.879 - ETA: 51s - loss: 0.3365 - accuracy: 0.878 - ETA: 50s - loss: 0.3358 - accuracy: 0.879 - ETA: 49s - loss: 0.3354 - accuracy: 0.879 - ETA: 48s - loss: 0.3356 - accuracy: 0.879 - ETA: 47s - loss: 0.3363 - accuracy: 0.879 - ETA: 46s - loss: 0.3354 - accuracy: 0.880 - ETA: 45s - loss: 0.3351 - accuracy: 0.880 - ETA: 43s - loss: 0.3344 - accuracy: 0.880 - ETA: 42s - loss: 0.3338 - accuracy: 0.880 - ETA: 41s - loss: 0.3341 - accuracy: 0.880 - ETA: 40s - loss: 0.3340 - accuracy: 0.880 - ETA: 39s - loss: 0.3338 - accuracy: 0.880 - ETA: 38s - loss: 0.3342 - accuracy: 0.880 - ETA: 37s - loss: 0.3337 - accuracy: 0.881 - ETA: 35s - loss: 0.3327 - accuracy: 0.881 - ETA: 34s - loss: 0.3334 - accuracy: 0.880 - ETA: 33s - loss: 0.3328 - accuracy: 0.881 - ETA: 32s - loss: 0.3325 - accuracy: 0.881 - ETA: 31s - loss: 0.3327 - accuracy: 0.881 - ETA: 30s - loss: 0.3326 - accuracy: 0.881 - ETA: 29s - loss: 0.3318 - accuracy: 0.881 - ETA: 27s - loss: 0.3314 - accuracy: 0.881 - ETA: 26s - loss: 0.3309 - accuracy: 0.882 - ETA: 25s - loss: 0.3310 - accuracy: 0.881 - ETA: 24s - loss: 0.3312 - accuracy: 0.881 - ETA: 23s - loss: 0.3322 - accuracy: 0.881 - ETA: 22s - loss: 0.3331 - accuracy: 0.881 - ETA: 21s - loss: 0.3323 - accuracy: 0.881 - ETA: 20s - loss: 0.3325 - accuracy: 0.881 - ETA: 18s - loss: 0.3320 - accuracy: 0.881 - ETA: 17s - loss: 0.3322 - accuracy: 0.881 - ETA: 16s - loss: 0.3330 - accuracy: 0.881 - ETA: 15s - loss: 0.3342 - accuracy: 0.881 - ETA: 14s - loss: 0.3346 - accuracy: 0.881 - ETA: 13s - loss: 0.3353 - accuracy: 0.880 - ETA: 12s - loss: 0.3355 - accuracy: 0.880 - ETA: 11s - loss: 0.3358 - accuracy: 0.880 - ETA: 9s - loss: 0.3360 - accuracy: 0.880 - ETA: 8s - loss: 0.3359 - accuracy: 0.88 - ETA: 7s - loss: 0.3346 - accuracy: 0.88 - ETA: 6s - loss: 0.3338 - accuracy: 0.88 - ETA: 5s - loss: 0.3337 - accuracy: 0.88 - ETA: 4s - loss: 0.3334 - accuracy: 0.88 - ETA: 3s - loss: 0.3328 - accuracy: 0.88 - ETA: 2s - loss: 0.3334 - accuracy: 0.88 - ETA: 0s - loss: 0.3330 - accuracy: 0.88 - 182s 9ms/step - loss: 0.3329 - accuracy: 0.8817 - val_loss: 1.5420 - val_accuracy: 0.7530\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:46 - loss: 0.3845 - accuracy: 0.85 - ETA: 2:42 - loss: 0.3929 - accuracy: 0.85 - ETA: 2:40 - loss: 0.3185 - accuracy: 0.88 - ETA: 2:41 - loss: 0.3127 - accuracy: 0.88 - ETA: 2:47 - loss: 0.3025 - accuracy: 0.88 - ETA: 2:47 - loss: 0.3027 - accuracy: 0.88 - ETA: 2:45 - loss: 0.3151 - accuracy: 0.88 - ETA: 2:44 - loss: 0.3129 - accuracy: 0.88 - ETA: 2:42 - loss: 0.3182 - accuracy: 0.88 - ETA: 2:39 - loss: 0.3138 - accuracy: 0.88 - ETA: 2:38 - loss: 0.3185 - accuracy: 0.88 - ETA: 2:37 - loss: 0.3190 - accuracy: 0.88 - ETA: 2:37 - loss: 0.3130 - accuracy: 0.89 - ETA: 2:35 - loss: 0.3116 - accuracy: 0.89 - ETA: 2:33 - loss: 0.3066 - accuracy: 0.89 - ETA: 2:31 - loss: 0.3186 - accuracy: 0.88 - ETA: 2:30 - loss: 0.3129 - accuracy: 0.89 - ETA: 2:28 - loss: 0.3179 - accuracy: 0.88 - ETA: 2:28 - loss: 0.3178 - accuracy: 0.88 - ETA: 2:27 - loss: 0.3180 - accuracy: 0.88 - ETA: 2:25 - loss: 0.3192 - accuracy: 0.88 - ETA: 2:24 - loss: 0.3210 - accuracy: 0.88 - ETA: 2:22 - loss: 0.3149 - accuracy: 0.88 - ETA: 2:21 - loss: 0.3105 - accuracy: 0.89 - ETA: 2:19 - loss: 0.3086 - accuracy: 0.89 - ETA: 2:18 - loss: 0.3106 - accuracy: 0.89 - ETA: 2:17 - loss: 0.3092 - accuracy: 0.89 - ETA: 2:16 - loss: 0.3109 - accuracy: 0.88 - ETA: 2:14 - loss: 0.3074 - accuracy: 0.89 - ETA: 2:13 - loss: 0.3093 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3084 - accuracy: 0.88 - ETA: 2:11 - loss: 0.3061 - accuracy: 0.88 - ETA: 2:10 - loss: 0.3083 - accuracy: 0.88 - ETA: 2:09 - loss: 0.3093 - accuracy: 0.88 - ETA: 2:08 - loss: 0.3128 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3115 - accuracy: 0.88 - ETA: 2:06 - loss: 0.3091 - accuracy: 0.88 - ETA: 2:04 - loss: 0.3076 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3097 - accuracy: 0.88 - ETA: 2:02 - loss: 0.3092 - accuracy: 0.88 - ETA: 2:01 - loss: 0.3078 - accuracy: 0.88 - ETA: 2:00 - loss: 0.3059 - accuracy: 0.88 - ETA: 1:58 - loss: 0.3042 - accuracy: 0.89 - ETA: 1:57 - loss: 0.3052 - accuracy: 0.88 - ETA: 1:56 - loss: 0.3024 - accuracy: 0.89 - ETA: 1:55 - loss: 0.3043 - accuracy: 0.89 - ETA: 1:54 - loss: 0.3028 - accuracy: 0.89 - ETA: 1:53 - loss: 0.3019 - accuracy: 0.89 - ETA: 1:52 - loss: 0.3029 - accuracy: 0.89 - ETA: 1:51 - loss: 0.3029 - accuracy: 0.89 - ETA: 1:50 - loss: 0.3055 - accuracy: 0.88 - ETA: 1:48 - loss: 0.3065 - accuracy: 0.88 - ETA: 1:47 - loss: 0.3093 - accuracy: 0.88 - ETA: 1:46 - loss: 0.3093 - accuracy: 0.88 - ETA: 1:45 - loss: 0.3093 - accuracy: 0.88 - ETA: 1:44 - loss: 0.3104 - accuracy: 0.88 - ETA: 1:43 - loss: 0.3114 - accuracy: 0.88 - ETA: 1:41 - loss: 0.3104 - accuracy: 0.88 - ETA: 1:40 - loss: 0.3096 - accuracy: 0.88 - ETA: 1:39 - loss: 0.3105 - accuracy: 0.88 - ETA: 1:38 - loss: 0.3120 - accuracy: 0.88 - ETA: 1:37 - loss: 0.3123 - accuracy: 0.88 - ETA: 1:36 - loss: 0.3136 - accuracy: 0.88 - ETA: 1:35 - loss: 0.3126 - accuracy: 0.88 - ETA: 1:34 - loss: 0.3115 - accuracy: 0.88 - ETA: 1:33 - loss: 0.3109 - accuracy: 0.88 - ETA: 1:31 - loss: 0.3138 - accuracy: 0.88 - ETA: 1:30 - loss: 0.3120 - accuracy: 0.88 - ETA: 1:29 - loss: 0.3116 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3110 - accuracy: 0.89 - ETA: 1:27 - loss: 0.3101 - accuracy: 0.89 - ETA: 1:26 - loss: 0.3094 - accuracy: 0.89 - ETA: 1:25 - loss: 0.3097 - accuracy: 0.89 - ETA: 1:24 - loss: 0.3107 - accuracy: 0.88 - ETA: 1:23 - loss: 0.3112 - accuracy: 0.88 - ETA: 1:22 - loss: 0.3130 - accuracy: 0.88 - ETA: 1:20 - loss: 0.3133 - accuracy: 0.88 - ETA: 1:19 - loss: 0.3137 - accuracy: 0.88 - ETA: 1:18 - loss: 0.3136 - accuracy: 0.88 - ETA: 1:17 - loss: 0.3129 - accuracy: 0.88 - ETA: 1:16 - loss: 0.3136 - accuracy: 0.88 - ETA: 1:15 - loss: 0.3126 - accuracy: 0.88 - ETA: 1:14 - loss: 0.3122 - accuracy: 0.88 - ETA: 1:13 - loss: 0.3115 - accuracy: 0.88 - ETA: 1:12 - loss: 0.3115 - accuracy: 0.88 - ETA: 1:10 - loss: 0.3103 - accuracy: 0.88 - ETA: 1:09 - loss: 0.3124 - accuracy: 0.88 - ETA: 1:08 - loss: 0.3126 - accuracy: 0.88 - ETA: 1:07 - loss: 0.3117 - accuracy: 0.88 - ETA: 1:06 - loss: 0.3113 - accuracy: 0.88 - ETA: 1:05 - loss: 0.3130 - accuracy: 0.88 - ETA: 1:04 - loss: 0.3138 - accuracy: 0.88 - ETA: 1:03 - loss: 0.3141 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3148 - accuracy: 0.88 - ETA: 1:01 - loss: 0.3132 - accuracy: 0.88 - ETA: 1:00 - loss: 0.3131 - accuracy: 0.88 - ETA: 58s - loss: 0.3125 - accuracy: 0.8888 - ETA: 57s - loss: 0.3125 - accuracy: 0.888 - ETA: 56s - loss: 0.3127 - accuracy: 0.888 - ETA: 55s - loss: 0.3139 - accuracy: 0.888 - ETA: 54s - loss: 0.3141 - accuracy: 0.888 - ETA: 53s - loss: 0.3137 - accuracy: 0.888 - ETA: 52s - loss: 0.3132 - accuracy: 0.889 - ETA: 51s - loss: 0.3120 - accuracy: 0.889 - ETA: 50s - loss: 0.3131 - accuracy: 0.889 - ETA: 49s - loss: 0.3143 - accuracy: 0.888 - ETA: 47s - loss: 0.3136 - accuracy: 0.888 - ETA: 46s - loss: 0.3137 - accuracy: 0.888 - ETA: 45s - loss: 0.3131 - accuracy: 0.889 - ETA: 44s - loss: 0.3128 - accuracy: 0.889 - ETA: 43s - loss: 0.3123 - accuracy: 0.889 - ETA: 42s - loss: 0.3130 - accuracy: 0.889 - ETA: 41s - loss: 0.3126 - accuracy: 0.889 - ETA: 40s - loss: 0.3139 - accuracy: 0.888 - ETA: 39s - loss: 0.3149 - accuracy: 0.888 - ETA: 38s - loss: 0.3160 - accuracy: 0.888 - ETA: 37s - loss: 0.3172 - accuracy: 0.887 - ETA: 35s - loss: 0.3169 - accuracy: 0.888 - ETA: 34s - loss: 0.3183 - accuracy: 0.888 - ETA: 33s - loss: 0.3183 - accuracy: 0.888 - ETA: 32s - loss: 0.3192 - accuracy: 0.887 - ETA: 31s - loss: 0.3197 - accuracy: 0.887 - ETA: 30s - loss: 0.3189 - accuracy: 0.888 - ETA: 29s - loss: 0.3192 - accuracy: 0.887 - ETA: 28s - loss: 0.3195 - accuracy: 0.887 - ETA: 27s - loss: 0.3193 - accuracy: 0.887 - ETA: 26s - loss: 0.3186 - accuracy: 0.887 - ETA: 25s - loss: 0.3184 - accuracy: 0.887 - ETA: 23s - loss: 0.3202 - accuracy: 0.887 - ETA: 22s - loss: 0.3201 - accuracy: 0.887 - ETA: 21s - loss: 0.3201 - accuracy: 0.887 - ETA: 20s - loss: 0.3205 - accuracy: 0.887 - ETA: 19s - loss: 0.3204 - accuracy: 0.887 - ETA: 18s - loss: 0.3208 - accuracy: 0.887 - ETA: 17s - loss: 0.3208 - accuracy: 0.886 - ETA: 16s - loss: 0.3208 - accuracy: 0.886 - ETA: 15s - loss: 0.3203 - accuracy: 0.887 - ETA: 14s - loss: 0.3200 - accuracy: 0.887 - ETA: 13s - loss: 0.3201 - accuracy: 0.887 - ETA: 11s - loss: 0.3199 - accuracy: 0.887 - ETA: 10s - loss: 0.3198 - accuracy: 0.887 - ETA: 9s - loss: 0.3202 - accuracy: 0.887 - ETA: 8s - loss: 0.3204 - accuracy: 0.88 - ETA: 7s - loss: 0.3207 - accuracy: 0.88 - ETA: 6s - loss: 0.3199 - accuracy: 0.88 - ETA: 5s - loss: 0.3194 - accuracy: 0.88 - ETA: 4s - loss: 0.3199 - accuracy: 0.88 - ETA: 3s - loss: 0.3195 - accuracy: 0.88 - ETA: 2s - loss: 0.3203 - accuracy: 0.88 - ETA: 0s - loss: 0.3193 - accuracy: 0.88 - 179s 9ms/step - loss: 0.3189 - accuracy: 0.8873 - val_loss: 1.5983 - val_accuracy: 0.7542\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:01 - loss: 0.1815 - accuracy: 0.91 - ETA: 3:00 - loss: 0.2410 - accuracy: 0.90 - ETA: 2:57 - loss: 0.2942 - accuracy: 0.89 - ETA: 2:54 - loss: 0.3400 - accuracy: 0.87 - ETA: 2:50 - loss: 0.3357 - accuracy: 0.87 - ETA: 2:47 - loss: 0.3119 - accuracy: 0.88 - ETA: 2:44 - loss: 0.3000 - accuracy: 0.89 - ETA: 2:42 - loss: 0.2859 - accuracy: 0.89 - ETA: 2:39 - loss: 0.2902 - accuracy: 0.89 - ETA: 2:37 - loss: 0.2807 - accuracy: 0.90 - ETA: 2:35 - loss: 0.2755 - accuracy: 0.90 - ETA: 2:35 - loss: 0.2864 - accuracy: 0.89 - ETA: 2:33 - loss: 0.2955 - accuracy: 0.89 - ETA: 2:32 - loss: 0.2998 - accuracy: 0.89 - ETA: 2:30 - loss: 0.2996 - accuracy: 0.89 - ETA: 2:30 - loss: 0.2996 - accuracy: 0.89 - ETA: 2:30 - loss: 0.3010 - accuracy: 0.89 - ETA: 2:28 - loss: 0.2987 - accuracy: 0.89 - ETA: 2:27 - loss: 0.2998 - accuracy: 0.89 - ETA: 2:25 - loss: 0.3007 - accuracy: 0.89 - ETA: 2:24 - loss: 0.3013 - accuracy: 0.89 - ETA: 2:23 - loss: 0.3044 - accuracy: 0.88 - ETA: 2:23 - loss: 0.2994 - accuracy: 0.89 - ETA: 2:21 - loss: 0.3001 - accuracy: 0.89 - ETA: 2:21 - loss: 0.2974 - accuracy: 0.89 - ETA: 2:20 - loss: 0.2973 - accuracy: 0.89 - ETA: 2:18 - loss: 0.2934 - accuracy: 0.89 - ETA: 2:17 - loss: 0.2929 - accuracy: 0.89 - ETA: 2:16 - loss: 0.2956 - accuracy: 0.89 - ETA: 2:15 - loss: 0.2967 - accuracy: 0.89 - ETA: 2:15 - loss: 0.3006 - accuracy: 0.88 - ETA: 2:13 - loss: 0.2996 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3011 - accuracy: 0.88 - ETA: 2:11 - loss: 0.2981 - accuracy: 0.89 - ETA: 2:10 - loss: 0.3006 - accuracy: 0.88 - ETA: 2:08 - loss: 0.2997 - accuracy: 0.89 - ETA: 2:07 - loss: 0.3027 - accuracy: 0.88 - ETA: 2:06 - loss: 0.3012 - accuracy: 0.89 - ETA: 2:05 - loss: 0.3029 - accuracy: 0.89 - ETA: 2:04 - loss: 0.3046 - accuracy: 0.89 - ETA: 2:03 - loss: 0.3048 - accuracy: 0.88 - ETA: 2:01 - loss: 0.3079 - accuracy: 0.88 - ETA: 2:00 - loss: 0.3081 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3093 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3114 - accuracy: 0.88 - ETA: 1:57 - loss: 0.3128 - accuracy: 0.88 - ETA: 1:56 - loss: 0.3158 - accuracy: 0.88 - ETA: 1:55 - loss: 0.3137 - accuracy: 0.88 - ETA: 1:54 - loss: 0.3155 - accuracy: 0.88 - ETA: 1:53 - loss: 0.3151 - accuracy: 0.88 - ETA: 1:52 - loss: 0.3157 - accuracy: 0.88 - ETA: 1:50 - loss: 0.3170 - accuracy: 0.88 - ETA: 1:50 - loss: 0.3209 - accuracy: 0.88 - ETA: 1:49 - loss: 0.3183 - accuracy: 0.88 - ETA: 1:48 - loss: 0.3176 - accuracy: 0.88 - ETA: 1:47 - loss: 0.3163 - accuracy: 0.88 - ETA: 1:46 - loss: 0.3155 - accuracy: 0.88 - ETA: 1:45 - loss: 0.3136 - accuracy: 0.88 - ETA: 1:44 - loss: 0.3141 - accuracy: 0.88 - ETA: 1:43 - loss: 0.3174 - accuracy: 0.88 - ETA: 1:42 - loss: 0.3188 - accuracy: 0.88 - ETA: 1:41 - loss: 0.3198 - accuracy: 0.88 - ETA: 1:40 - loss: 0.3212 - accuracy: 0.88 - ETA: 1:39 - loss: 0.3213 - accuracy: 0.88 - ETA: 1:37 - loss: 0.3217 - accuracy: 0.88 - ETA: 1:36 - loss: 0.3191 - accuracy: 0.88 - ETA: 1:35 - loss: 0.3183 - accuracy: 0.88 - ETA: 1:34 - loss: 0.3204 - accuracy: 0.88 - ETA: 1:33 - loss: 0.3210 - accuracy: 0.88 - ETA: 1:31 - loss: 0.3210 - accuracy: 0.88 - ETA: 1:30 - loss: 0.3230 - accuracy: 0.88 - ETA: 1:29 - loss: 0.3222 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3203 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3200 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3195 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3199 - accuracy: 0.88 - ETA: 1:24 - loss: 0.3202 - accuracy: 0.88 - ETA: 1:23 - loss: 0.3201 - accuracy: 0.88 - ETA: 1:21 - loss: 0.3195 - accuracy: 0.88 - ETA: 1:20 - loss: 0.3196 - accuracy: 0.88 - ETA: 1:19 - loss: 0.3196 - accuracy: 0.88 - ETA: 1:18 - loss: 0.3211 - accuracy: 0.88 - ETA: 1:17 - loss: 0.3210 - accuracy: 0.88 - ETA: 1:16 - loss: 0.3218 - accuracy: 0.88 - ETA: 1:14 - loss: 0.3233 - accuracy: 0.88 - ETA: 1:13 - loss: 0.3232 - accuracy: 0.88 - ETA: 1:12 - loss: 0.3234 - accuracy: 0.88 - ETA: 1:11 - loss: 0.3238 - accuracy: 0.88 - ETA: 1:10 - loss: 0.3241 - accuracy: 0.88 - ETA: 1:09 - loss: 0.3253 - accuracy: 0.88 - ETA: 1:08 - loss: 0.3270 - accuracy: 0.88 - ETA: 1:07 - loss: 0.3274 - accuracy: 0.88 - ETA: 1:05 - loss: 0.3272 - accuracy: 0.88 - ETA: 1:04 - loss: 0.3267 - accuracy: 0.88 - ETA: 1:03 - loss: 0.3267 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3263 - accuracy: 0.88 - ETA: 1:01 - loss: 0.3251 - accuracy: 0.88 - ETA: 1:00 - loss: 0.3252 - accuracy: 0.88 - ETA: 58s - loss: 0.3261 - accuracy: 0.8830 - ETA: 57s - loss: 0.3251 - accuracy: 0.883 - ETA: 56s - loss: 0.3249 - accuracy: 0.883 - ETA: 55s - loss: 0.3241 - accuracy: 0.883 - ETA: 54s - loss: 0.3238 - accuracy: 0.883 - ETA: 53s - loss: 0.3233 - accuracy: 0.883 - ETA: 52s - loss: 0.3240 - accuracy: 0.883 - ETA: 51s - loss: 0.3234 - accuracy: 0.883 - ETA: 49s - loss: 0.3231 - accuracy: 0.883 - ETA: 48s - loss: 0.3236 - accuracy: 0.883 - ETA: 47s - loss: 0.3250 - accuracy: 0.883 - ETA: 46s - loss: 0.3251 - accuracy: 0.882 - ETA: 45s - loss: 0.3245 - accuracy: 0.883 - ETA: 44s - loss: 0.3248 - accuracy: 0.883 - ETA: 42s - loss: 0.3250 - accuracy: 0.883 - ETA: 41s - loss: 0.3247 - accuracy: 0.883 - ETA: 40s - loss: 0.3248 - accuracy: 0.883 - ETA: 39s - loss: 0.3253 - accuracy: 0.883 - ETA: 38s - loss: 0.3246 - accuracy: 0.883 - ETA: 37s - loss: 0.3255 - accuracy: 0.883 - ETA: 35s - loss: 0.3255 - accuracy: 0.883 - ETA: 34s - loss: 0.3255 - accuracy: 0.883 - ETA: 33s - loss: 0.3259 - accuracy: 0.883 - ETA: 32s - loss: 0.3256 - accuracy: 0.883 - ETA: 31s - loss: 0.3254 - accuracy: 0.883 - ETA: 30s - loss: 0.3248 - accuracy: 0.883 - ETA: 29s - loss: 0.3245 - accuracy: 0.884 - ETA: 27s - loss: 0.3238 - accuracy: 0.884 - ETA: 26s - loss: 0.3235 - accuracy: 0.884 - ETA: 25s - loss: 0.3241 - accuracy: 0.884 - ETA: 24s - loss: 0.3241 - accuracy: 0.884 - ETA: 23s - loss: 0.3244 - accuracy: 0.884 - ETA: 22s - loss: 0.3242 - accuracy: 0.884 - ETA: 21s - loss: 0.3236 - accuracy: 0.884 - ETA: 20s - loss: 0.3230 - accuracy: 0.884 - ETA: 19s - loss: 0.3232 - accuracy: 0.884 - ETA: 17s - loss: 0.3231 - accuracy: 0.884 - ETA: 16s - loss: 0.3226 - accuracy: 0.884 - ETA: 15s - loss: 0.3224 - accuracy: 0.884 - ETA: 14s - loss: 0.3225 - accuracy: 0.884 - ETA: 13s - loss: 0.3247 - accuracy: 0.884 - ETA: 12s - loss: 0.3256 - accuracy: 0.884 - ETA: 11s - loss: 0.3258 - accuracy: 0.883 - ETA: 10s - loss: 0.3262 - accuracy: 0.883 - ETA: 8s - loss: 0.3267 - accuracy: 0.883 - ETA: 7s - loss: 0.3264 - accuracy: 0.88 - ETA: 6s - loss: 0.3267 - accuracy: 0.88 - ETA: 5s - loss: 0.3257 - accuracy: 0.88 - ETA: 4s - loss: 0.3252 - accuracy: 0.88 - ETA: 3s - loss: 0.3248 - accuracy: 0.88 - ETA: 2s - loss: 0.3253 - accuracy: 0.88 - ETA: 0s - loss: 0.3243 - accuracy: 0.88 - 184s 10ms/step - loss: 0.3245 - accuracy: 0.8846 - val_loss: 1.6071 - val_accuracy: 0.7532\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:54 - loss: 0.3609 - accuracy: 0.87 - ETA: 2:48 - loss: 0.3680 - accuracy: 0.86 - ETA: 2:46 - loss: 0.3354 - accuracy: 0.88 - ETA: 2:47 - loss: 0.3056 - accuracy: 0.89 - ETA: 2:46 - loss: 0.2978 - accuracy: 0.89 - ETA: 2:44 - loss: 0.2980 - accuracy: 0.89 - ETA: 2:45 - loss: 0.2987 - accuracy: 0.89 - ETA: 2:47 - loss: 0.3090 - accuracy: 0.89 - ETA: 2:47 - loss: 0.3129 - accuracy: 0.88 - ETA: 2:44 - loss: 0.3069 - accuracy: 0.89 - ETA: 2:42 - loss: 0.3034 - accuracy: 0.89 - ETA: 2:41 - loss: 0.2971 - accuracy: 0.89 - ETA: 2:40 - loss: 0.2990 - accuracy: 0.88 - ETA: 2:39 - loss: 0.3037 - accuracy: 0.88 - ETA: 2:37 - loss: 0.3013 - accuracy: 0.88 - ETA: 2:36 - loss: 0.2972 - accuracy: 0.89 - ETA: 2:35 - loss: 0.2986 - accuracy: 0.89 - ETA: 2:34 - loss: 0.2949 - accuracy: 0.89 - ETA: 2:32 - loss: 0.2967 - accuracy: 0.88 - ETA: 2:30 - loss: 0.2979 - accuracy: 0.88 - ETA: 2:29 - loss: 0.2975 - accuracy: 0.89 - ETA: 2:28 - loss: 0.3031 - accuracy: 0.88 - ETA: 2:27 - loss: 0.3054 - accuracy: 0.88 - ETA: 2:25 - loss: 0.3042 - accuracy: 0.88 - ETA: 2:25 - loss: 0.3032 - accuracy: 0.88 - ETA: 2:24 - loss: 0.3116 - accuracy: 0.88 - ETA: 2:23 - loss: 0.3140 - accuracy: 0.88 - ETA: 2:21 - loss: 0.3094 - accuracy: 0.88 - ETA: 2:20 - loss: 0.3073 - accuracy: 0.88 - ETA: 2:19 - loss: 0.3080 - accuracy: 0.88 - ETA: 2:18 - loss: 0.3082 - accuracy: 0.88 - ETA: 2:16 - loss: 0.3099 - accuracy: 0.88 - ETA: 2:15 - loss: 0.3099 - accuracy: 0.88 - ETA: 2:13 - loss: 0.3069 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3068 - accuracy: 0.88 - ETA: 2:11 - loss: 0.3035 - accuracy: 0.88 - ETA: 2:10 - loss: 0.3042 - accuracy: 0.88 - ETA: 2:09 - loss: 0.3024 - accuracy: 0.88 - ETA: 2:08 - loss: 0.3036 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3035 - accuracy: 0.88 - ETA: 2:05 - loss: 0.3049 - accuracy: 0.88 - ETA: 2:04 - loss: 0.3088 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3092 - accuracy: 0.88 - ETA: 2:02 - loss: 0.3077 - accuracy: 0.88 - ETA: 2:01 - loss: 0.3050 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3050 - accuracy: 0.89 - ETA: 1:58 - loss: 0.3060 - accuracy: 0.89 - ETA: 1:57 - loss: 0.3057 - accuracy: 0.88 - ETA: 1:56 - loss: 0.3082 - accuracy: 0.88 - ETA: 1:55 - loss: 0.3086 - accuracy: 0.88 - ETA: 1:54 - loss: 0.3083 - accuracy: 0.88 - ETA: 1:53 - loss: 0.3081 - accuracy: 0.88 - ETA: 1:51 - loss: 0.3078 - accuracy: 0.88 - ETA: 1:50 - loss: 0.3083 - accuracy: 0.88 - ETA: 1:49 - loss: 0.3084 - accuracy: 0.88 - ETA: 1:48 - loss: 0.3082 - accuracy: 0.88 - ETA: 1:47 - loss: 0.3094 - accuracy: 0.88 - ETA: 1:46 - loss: 0.3088 - accuracy: 0.88 - ETA: 1:44 - loss: 0.3105 - accuracy: 0.88 - ETA: 1:43 - loss: 0.3130 - accuracy: 0.88 - ETA: 1:42 - loss: 0.3116 - accuracy: 0.88 - ETA: 1:41 - loss: 0.3125 - accuracy: 0.88 - ETA: 1:40 - loss: 0.3129 - accuracy: 0.88 - ETA: 1:39 - loss: 0.3128 - accuracy: 0.88 - ETA: 1:38 - loss: 0.3140 - accuracy: 0.88 - ETA: 1:37 - loss: 0.3151 - accuracy: 0.88 - ETA: 1:35 - loss: 0.3149 - accuracy: 0.88 - ETA: 1:34 - loss: 0.3145 - accuracy: 0.88 - ETA: 1:33 - loss: 0.3154 - accuracy: 0.88 - ETA: 1:32 - loss: 0.3153 - accuracy: 0.88 - ETA: 1:31 - loss: 0.3159 - accuracy: 0.88 - ETA: 1:30 - loss: 0.3173 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3181 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3180 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3187 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3177 - accuracy: 0.88 - ETA: 1:24 - loss: 0.3176 - accuracy: 0.88 - ETA: 1:23 - loss: 0.3172 - accuracy: 0.88 - ETA: 1:22 - loss: 0.3168 - accuracy: 0.88 - ETA: 1:21 - loss: 0.3162 - accuracy: 0.88 - ETA: 1:19 - loss: 0.3165 - accuracy: 0.88 - ETA: 1:18 - loss: 0.3165 - accuracy: 0.88 - ETA: 1:17 - loss: 0.3174 - accuracy: 0.88 - ETA: 1:16 - loss: 0.3181 - accuracy: 0.88 - ETA: 1:15 - loss: 0.3178 - accuracy: 0.88 - ETA: 1:14 - loss: 0.3180 - accuracy: 0.88 - ETA: 1:12 - loss: 0.3190 - accuracy: 0.88 - ETA: 1:11 - loss: 0.3188 - accuracy: 0.88 - ETA: 1:10 - loss: 0.3183 - accuracy: 0.88 - ETA: 1:09 - loss: 0.3177 - accuracy: 0.88 - ETA: 1:08 - loss: 0.3175 - accuracy: 0.88 - ETA: 1:07 - loss: 0.3178 - accuracy: 0.88 - ETA: 1:06 - loss: 0.3170 - accuracy: 0.88 - ETA: 1:04 - loss: 0.3156 - accuracy: 0.88 - ETA: 1:03 - loss: 0.3159 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3159 - accuracy: 0.88 - ETA: 1:01 - loss: 0.3144 - accuracy: 0.88 - ETA: 1:00 - loss: 0.3145 - accuracy: 0.88 - ETA: 59s - loss: 0.3146 - accuracy: 0.8842 - ETA: 58s - loss: 0.3146 - accuracy: 0.884 - ETA: 56s - loss: 0.3147 - accuracy: 0.884 - ETA: 55s - loss: 0.3154 - accuracy: 0.884 - ETA: 54s - loss: 0.3169 - accuracy: 0.883 - ETA: 53s - loss: 0.3158 - accuracy: 0.883 - ETA: 52s - loss: 0.3162 - accuracy: 0.883 - ETA: 51s - loss: 0.3156 - accuracy: 0.884 - ETA: 50s - loss: 0.3152 - accuracy: 0.884 - ETA: 48s - loss: 0.3151 - accuracy: 0.884 - ETA: 47s - loss: 0.3154 - accuracy: 0.884 - ETA: 46s - loss: 0.3145 - accuracy: 0.884 - ETA: 45s - loss: 0.3152 - accuracy: 0.884 - ETA: 44s - loss: 0.3156 - accuracy: 0.884 - ETA: 43s - loss: 0.3148 - accuracy: 0.884 - ETA: 42s - loss: 0.3153 - accuracy: 0.884 - ETA: 41s - loss: 0.3160 - accuracy: 0.883 - ETA: 40s - loss: 0.3169 - accuracy: 0.883 - ETA: 39s - loss: 0.3154 - accuracy: 0.884 - ETA: 39s - loss: 0.3157 - accuracy: 0.884 - ETA: 38s - loss: 0.3161 - accuracy: 0.883 - ETA: 37s - loss: 0.3159 - accuracy: 0.883 - ETA: 35s - loss: 0.3170 - accuracy: 0.883 - ETA: 35s - loss: 0.3164 - accuracy: 0.883 - ETA: 33s - loss: 0.3161 - accuracy: 0.884 - ETA: 32s - loss: 0.3164 - accuracy: 0.884 - ETA: 31s - loss: 0.3167 - accuracy: 0.884 - ETA: 30s - loss: 0.3169 - accuracy: 0.883 - ETA: 29s - loss: 0.3178 - accuracy: 0.883 - ETA: 28s - loss: 0.3180 - accuracy: 0.883 - ETA: 27s - loss: 0.3180 - accuracy: 0.883 - ETA: 25s - loss: 0.3185 - accuracy: 0.883 - ETA: 24s - loss: 0.3186 - accuracy: 0.882 - ETA: 23s - loss: 0.3185 - accuracy: 0.883 - ETA: 22s - loss: 0.3178 - accuracy: 0.883 - ETA: 20s - loss: 0.3183 - accuracy: 0.883 - ETA: 19s - loss: 0.3183 - accuracy: 0.883 - ETA: 18s - loss: 0.3178 - accuracy: 0.883 - ETA: 17s - loss: 0.3184 - accuracy: 0.883 - ETA: 16s - loss: 0.3181 - accuracy: 0.883 - ETA: 14s - loss: 0.3179 - accuracy: 0.884 - ETA: 13s - loss: 0.3178 - accuracy: 0.884 - ETA: 12s - loss: 0.3182 - accuracy: 0.883 - ETA: 10s - loss: 0.3185 - accuracy: 0.883 - ETA: 9s - loss: 0.3188 - accuracy: 0.883 - ETA: 8s - loss: 0.3189 - accuracy: 0.88 - ETA: 7s - loss: 0.3188 - accuracy: 0.88 - ETA: 6s - loss: 0.3186 - accuracy: 0.88 - ETA: 4s - loss: 0.3182 - accuracy: 0.88 - ETA: 3s - loss: 0.3194 - accuracy: 0.88 - ETA: 2s - loss: 0.3190 - accuracy: 0.88 - ETA: 1s - loss: 0.3189 - accuracy: 0.88 - 199s 10ms/step - loss: 0.3187 - accuracy: 0.8838 - val_loss: 1.5929 - val_accuracy: 0.7532\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:57 - loss: 0.4794 - accuracy: 0.83 - ETA: 2:57 - loss: 0.3650 - accuracy: 0.87 - ETA: 2:53 - loss: 0.3785 - accuracy: 0.87 - ETA: 2:49 - loss: 0.3401 - accuracy: 0.88 - ETA: 2:49 - loss: 0.3238 - accuracy: 0.88 - ETA: 2:45 - loss: 0.3142 - accuracy: 0.88 - ETA: 2:43 - loss: 0.3082 - accuracy: 0.88 - ETA: 2:41 - loss: 0.3075 - accuracy: 0.88 - ETA: 2:40 - loss: 0.3207 - accuracy: 0.88 - ETA: 2:38 - loss: 0.3242 - accuracy: 0.88 - ETA: 2:36 - loss: 0.3269 - accuracy: 0.87 - ETA: 2:35 - loss: 0.3229 - accuracy: 0.88 - ETA: 2:34 - loss: 0.3138 - accuracy: 0.88 - ETA: 2:33 - loss: 0.3175 - accuracy: 0.88 - ETA: 2:32 - loss: 0.3280 - accuracy: 0.88 - ETA: 2:32 - loss: 0.3212 - accuracy: 0.88 - ETA: 2:31 - loss: 0.3230 - accuracy: 0.88 - ETA: 2:30 - loss: 0.3199 - accuracy: 0.88 - ETA: 2:29 - loss: 0.3208 - accuracy: 0.88 - ETA: 2:28 - loss: 0.3218 - accuracy: 0.88 - ETA: 2:26 - loss: 0.3195 - accuracy: 0.88 - ETA: 2:25 - loss: 0.3268 - accuracy: 0.88 - ETA: 2:25 - loss: 0.3283 - accuracy: 0.88 - ETA: 2:24 - loss: 0.3268 - accuracy: 0.88 - ETA: 2:22 - loss: 0.3302 - accuracy: 0.88 - ETA: 2:21 - loss: 0.3263 - accuracy: 0.88 - ETA: 2:20 - loss: 0.3280 - accuracy: 0.88 - ETA: 2:19 - loss: 0.3246 - accuracy: 0.88 - ETA: 2:17 - loss: 0.3262 - accuracy: 0.88 - ETA: 2:17 - loss: 0.3338 - accuracy: 0.88 - ETA: 2:16 - loss: 0.3327 - accuracy: 0.88 - ETA: 2:15 - loss: 0.3303 - accuracy: 0.88 - ETA: 2:13 - loss: 0.3313 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3338 - accuracy: 0.88 - ETA: 2:11 - loss: 0.3319 - accuracy: 0.88 - ETA: 2:10 - loss: 0.3306 - accuracy: 0.88 - ETA: 2:09 - loss: 0.3307 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3328 - accuracy: 0.88 - ETA: 2:06 - loss: 0.3303 - accuracy: 0.88 - ETA: 2:05 - loss: 0.3300 - accuracy: 0.88 - ETA: 2:04 - loss: 0.3289 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3279 - accuracy: 0.88 - ETA: 2:02 - loss: 0.3291 - accuracy: 0.88 - ETA: 2:01 - loss: 0.3296 - accuracy: 0.88 - ETA: 2:00 - loss: 0.3285 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3282 - accuracy: 0.88 - ETA: 1:58 - loss: 0.3253 - accuracy: 0.88 - ETA: 1:57 - loss: 0.3234 - accuracy: 0.88 - ETA: 1:55 - loss: 0.3237 - accuracy: 0.88 - ETA: 1:54 - loss: 0.3218 - accuracy: 0.88 - ETA: 1:53 - loss: 0.3217 - accuracy: 0.88 - ETA: 1:52 - loss: 0.3226 - accuracy: 0.88 - ETA: 1:51 - loss: 0.3225 - accuracy: 0.88 - ETA: 1:50 - loss: 0.3203 - accuracy: 0.88 - ETA: 1:48 - loss: 0.3193 - accuracy: 0.88 - ETA: 1:47 - loss: 0.3193 - accuracy: 0.88 - ETA: 1:46 - loss: 0.3174 - accuracy: 0.88 - ETA: 1:45 - loss: 0.3171 - accuracy: 0.88 - ETA: 1:44 - loss: 0.3170 - accuracy: 0.88 - ETA: 1:43 - loss: 0.3170 - accuracy: 0.88 - ETA: 1:42 - loss: 0.3172 - accuracy: 0.88 - ETA: 1:41 - loss: 0.3184 - accuracy: 0.88 - ETA: 1:39 - loss: 0.3179 - accuracy: 0.88 - ETA: 1:38 - loss: 0.3187 - accuracy: 0.88 - ETA: 1:37 - loss: 0.3206 - accuracy: 0.88 - ETA: 1:36 - loss: 0.3193 - accuracy: 0.88 - ETA: 1:35 - loss: 0.3189 - accuracy: 0.88 - ETA: 1:34 - loss: 0.3172 - accuracy: 0.88 - ETA: 1:32 - loss: 0.3175 - accuracy: 0.88 - ETA: 1:31 - loss: 0.3175 - accuracy: 0.88 - ETA: 1:30 - loss: 0.3173 - accuracy: 0.88 - ETA: 1:29 - loss: 0.3166 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3161 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3162 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3142 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3165 - accuracy: 0.88 - ETA: 1:23 - loss: 0.3158 - accuracy: 0.88 - ETA: 1:22 - loss: 0.3153 - accuracy: 0.88 - ETA: 1:21 - loss: 0.3160 - accuracy: 0.88 - ETA: 1:20 - loss: 0.3172 - accuracy: 0.88 - ETA: 1:19 - loss: 0.3163 - accuracy: 0.88 - ETA: 1:18 - loss: 0.3155 - accuracy: 0.88 - ETA: 1:16 - loss: 0.3157 - accuracy: 0.88 - ETA: 1:15 - loss: 0.3144 - accuracy: 0.88 - ETA: 1:14 - loss: 0.3168 - accuracy: 0.88 - ETA: 1:13 - loss: 0.3173 - accuracy: 0.88 - ETA: 1:12 - loss: 0.3157 - accuracy: 0.88 - ETA: 1:11 - loss: 0.3163 - accuracy: 0.88 - ETA: 1:10 - loss: 0.3166 - accuracy: 0.88 - ETA: 1:08 - loss: 0.3171 - accuracy: 0.88 - ETA: 1:07 - loss: 0.3171 - accuracy: 0.88 - ETA: 1:06 - loss: 0.3168 - accuracy: 0.88 - ETA: 1:05 - loss: 0.3155 - accuracy: 0.88 - ETA: 1:04 - loss: 0.3137 - accuracy: 0.88 - ETA: 1:03 - loss: 0.3131 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3123 - accuracy: 0.88 - ETA: 1:00 - loss: 0.3130 - accuracy: 0.88 - ETA: 59s - loss: 0.3123 - accuracy: 0.8865 - ETA: 58s - loss: 0.3132 - accuracy: 0.886 - ETA: 57s - loss: 0.3128 - accuracy: 0.886 - ETA: 56s - loss: 0.3124 - accuracy: 0.886 - ETA: 55s - loss: 0.3120 - accuracy: 0.886 - ETA: 54s - loss: 0.3119 - accuracy: 0.887 - ETA: 53s - loss: 0.3111 - accuracy: 0.887 - ETA: 51s - loss: 0.3112 - accuracy: 0.887 - ETA: 50s - loss: 0.3112 - accuracy: 0.886 - ETA: 49s - loss: 0.3102 - accuracy: 0.887 - ETA: 48s - loss: 0.3105 - accuracy: 0.887 - ETA: 47s - loss: 0.3103 - accuracy: 0.887 - ETA: 46s - loss: 0.3112 - accuracy: 0.887 - ETA: 45s - loss: 0.3115 - accuracy: 0.887 - ETA: 44s - loss: 0.3112 - accuracy: 0.887 - ETA: 42s - loss: 0.3111 - accuracy: 0.887 - ETA: 41s - loss: 0.3109 - accuracy: 0.887 - ETA: 40s - loss: 0.3104 - accuracy: 0.887 - ETA: 39s - loss: 0.3102 - accuracy: 0.887 - ETA: 38s - loss: 0.3096 - accuracy: 0.887 - ETA: 37s - loss: 0.3095 - accuracy: 0.887 - ETA: 36s - loss: 0.3093 - accuracy: 0.887 - ETA: 35s - loss: 0.3097 - accuracy: 0.888 - ETA: 33s - loss: 0.3098 - accuracy: 0.887 - ETA: 32s - loss: 0.3096 - accuracy: 0.887 - ETA: 31s - loss: 0.3087 - accuracy: 0.888 - ETA: 30s - loss: 0.3086 - accuracy: 0.888 - ETA: 29s - loss: 0.3091 - accuracy: 0.887 - ETA: 28s - loss: 0.3091 - accuracy: 0.888 - ETA: 27s - loss: 0.3100 - accuracy: 0.887 - ETA: 25s - loss: 0.3099 - accuracy: 0.887 - ETA: 24s - loss: 0.3097 - accuracy: 0.887 - ETA: 23s - loss: 0.3099 - accuracy: 0.887 - ETA: 22s - loss: 0.3105 - accuracy: 0.887 - ETA: 21s - loss: 0.3102 - accuracy: 0.887 - ETA: 20s - loss: 0.3100 - accuracy: 0.887 - ETA: 19s - loss: 0.3107 - accuracy: 0.887 - ETA: 18s - loss: 0.3109 - accuracy: 0.887 - ETA: 16s - loss: 0.3106 - accuracy: 0.887 - ETA: 15s - loss: 0.3102 - accuracy: 0.887 - ETA: 14s - loss: 0.3110 - accuracy: 0.887 - ETA: 13s - loss: 0.3106 - accuracy: 0.887 - ETA: 12s - loss: 0.3111 - accuracy: 0.887 - ETA: 11s - loss: 0.3106 - accuracy: 0.887 - ETA: 10s - loss: 0.3113 - accuracy: 0.887 - ETA: 8s - loss: 0.3110 - accuracy: 0.887 - ETA: 7s - loss: 0.3107 - accuracy: 0.88 - ETA: 6s - loss: 0.3105 - accuracy: 0.88 - ETA: 5s - loss: 0.3107 - accuracy: 0.88 - ETA: 4s - loss: 0.3107 - accuracy: 0.88 - ETA: 3s - loss: 0.3108 - accuracy: 0.88 - ETA: 2s - loss: 0.3110 - accuracy: 0.88 - ETA: 0s - loss: 0.3112 - accuracy: 0.88 - 186s 10ms/step - loss: 0.3117 - accuracy: 0.8869 - val_loss: 1.6136 - val_accuracy: 0.7536\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:54 - loss: 0.2710 - accuracy: 0.91 - ETA: 2:44 - loss: 0.2696 - accuracy: 0.91 - ETA: 2:44 - loss: 0.2742 - accuracy: 0.90 - ETA: 2:42 - loss: 0.2740 - accuracy: 0.90 - ETA: 2:40 - loss: 0.2797 - accuracy: 0.89 - ETA: 2:38 - loss: 0.3027 - accuracy: 0.88 - ETA: 2:37 - loss: 0.3064 - accuracy: 0.88 - ETA: 2:39 - loss: 0.3151 - accuracy: 0.87 - ETA: 2:38 - loss: 0.3220 - accuracy: 0.87 - ETA: 2:37 - loss: 0.3147 - accuracy: 0.88 - ETA: 2:35 - loss: 0.3081 - accuracy: 0.88 - ETA: 2:34 - loss: 0.2984 - accuracy: 0.88 - ETA: 2:34 - loss: 0.3093 - accuracy: 0.88 - ETA: 2:32 - loss: 0.3074 - accuracy: 0.88 - ETA: 2:31 - loss: 0.3046 - accuracy: 0.88 - ETA: 2:29 - loss: 0.3041 - accuracy: 0.88 - ETA: 2:29 - loss: 0.3028 - accuracy: 0.88 - ETA: 2:28 - loss: 0.3007 - accuracy: 0.88 - ETA: 2:27 - loss: 0.2975 - accuracy: 0.88 - ETA: 2:26 - loss: 0.2993 - accuracy: 0.88 - ETA: 2:26 - loss: 0.2969 - accuracy: 0.88 - ETA: 2:26 - loss: 0.2990 - accuracy: 0.88 - ETA: 2:26 - loss: 0.2980 - accuracy: 0.88 - ETA: 2:24 - loss: 0.2957 - accuracy: 0.89 - ETA: 2:23 - loss: 0.2908 - accuracy: 0.89 - ETA: 2:21 - loss: 0.2876 - accuracy: 0.89 - ETA: 2:20 - loss: 0.2828 - accuracy: 0.89 - ETA: 2:19 - loss: 0.2853 - accuracy: 0.89 - ETA: 2:17 - loss: 0.2873 - accuracy: 0.89 - ETA: 2:16 - loss: 0.2852 - accuracy: 0.89 - ETA: 2:15 - loss: 0.2865 - accuracy: 0.89 - ETA: 2:14 - loss: 0.2853 - accuracy: 0.89 - ETA: 2:13 - loss: 0.2844 - accuracy: 0.89 - ETA: 2:12 - loss: 0.2841 - accuracy: 0.89 - ETA: 2:11 - loss: 0.2862 - accuracy: 0.89 - ETA: 2:11 - loss: 0.2861 - accuracy: 0.89 - ETA: 2:10 - loss: 0.2883 - accuracy: 0.89 - ETA: 2:08 - loss: 0.2873 - accuracy: 0.89 - ETA: 2:07 - loss: 0.2874 - accuracy: 0.89 - ETA: 2:06 - loss: 0.2870 - accuracy: 0.89 - ETA: 2:05 - loss: 0.2879 - accuracy: 0.89 - ETA: 2:03 - loss: 0.2881 - accuracy: 0.89 - ETA: 2:02 - loss: 0.2862 - accuracy: 0.89 - ETA: 2:01 - loss: 0.2851 - accuracy: 0.89 - ETA: 2:00 - loss: 0.2860 - accuracy: 0.89 - ETA: 1:59 - loss: 0.2887 - accuracy: 0.89 - ETA: 1:58 - loss: 0.2885 - accuracy: 0.89 - ETA: 1:56 - loss: 0.2888 - accuracy: 0.89 - ETA: 1:55 - loss: 0.2902 - accuracy: 0.89 - ETA: 1:56 - loss: 0.2923 - accuracy: 0.89 - ETA: 1:56 - loss: 0.2919 - accuracy: 0.89 - ETA: 1:55 - loss: 0.2949 - accuracy: 0.89 - ETA: 1:54 - loss: 0.2954 - accuracy: 0.89 - ETA: 1:52 - loss: 0.2946 - accuracy: 0.89 - ETA: 1:51 - loss: 0.2941 - accuracy: 0.89 - ETA: 1:50 - loss: 0.2925 - accuracy: 0.89 - ETA: 1:49 - loss: 0.2923 - accuracy: 0.89 - ETA: 1:48 - loss: 0.2923 - accuracy: 0.89 - ETA: 1:46 - loss: 0.2933 - accuracy: 0.89 - ETA: 1:45 - loss: 0.2956 - accuracy: 0.89 - ETA: 1:44 - loss: 0.2946 - accuracy: 0.89 - ETA: 1:42 - loss: 0.2949 - accuracy: 0.89 - ETA: 1:41 - loss: 0.2980 - accuracy: 0.89 - ETA: 1:40 - loss: 0.2985 - accuracy: 0.89 - ETA: 1:39 - loss: 0.2980 - accuracy: 0.89 - ETA: 1:38 - loss: 0.2981 - accuracy: 0.89 - ETA: 1:36 - loss: 0.2974 - accuracy: 0.89 - ETA: 1:35 - loss: 0.2979 - accuracy: 0.89 - ETA: 1:34 - loss: 0.2978 - accuracy: 0.89 - ETA: 1:33 - loss: 0.2994 - accuracy: 0.89 - ETA: 1:32 - loss: 0.3008 - accuracy: 0.89 - ETA: 1:31 - loss: 0.3017 - accuracy: 0.89 - ETA: 1:30 - loss: 0.3018 - accuracy: 0.89 - ETA: 1:29 - loss: 0.3021 - accuracy: 0.89 - ETA: 1:28 - loss: 0.3005 - accuracy: 0.89 - ETA: 1:26 - loss: 0.2997 - accuracy: 0.89 - ETA: 1:25 - loss: 0.2988 - accuracy: 0.89 - ETA: 1:24 - loss: 0.2981 - accuracy: 0.89 - ETA: 1:23 - loss: 0.2962 - accuracy: 0.89 - ETA: 1:22 - loss: 0.2956 - accuracy: 0.89 - ETA: 1:21 - loss: 0.2949 - accuracy: 0.89 - ETA: 1:20 - loss: 0.2947 - accuracy: 0.89 - ETA: 1:19 - loss: 0.2960 - accuracy: 0.89 - ETA: 1:18 - loss: 0.2969 - accuracy: 0.89 - ETA: 1:16 - loss: 0.2963 - accuracy: 0.89 - ETA: 1:15 - loss: 0.2964 - accuracy: 0.89 - ETA: 1:14 - loss: 0.2954 - accuracy: 0.89 - ETA: 1:13 - loss: 0.2981 - accuracy: 0.89 - ETA: 1:12 - loss: 0.2989 - accuracy: 0.89 - ETA: 1:10 - loss: 0.2988 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2996 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2991 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2986 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2986 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2985 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2980 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2970 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2974 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2974 - accuracy: 0.89 - ETA: 58s - loss: 0.2986 - accuracy: 0.8930 - ETA: 57s - loss: 0.2983 - accuracy: 0.893 - ETA: 56s - loss: 0.2990 - accuracy: 0.893 - ETA: 55s - loss: 0.2991 - accuracy: 0.893 - ETA: 54s - loss: 0.2983 - accuracy: 0.893 - ETA: 53s - loss: 0.2978 - accuracy: 0.893 - ETA: 51s - loss: 0.2974 - accuracy: 0.893 - ETA: 50s - loss: 0.2968 - accuracy: 0.893 - ETA: 49s - loss: 0.2979 - accuracy: 0.893 - ETA: 48s - loss: 0.2985 - accuracy: 0.893 - ETA: 47s - loss: 0.2979 - accuracy: 0.893 - ETA: 45s - loss: 0.2981 - accuracy: 0.892 - ETA: 44s - loss: 0.2979 - accuracy: 0.892 - ETA: 43s - loss: 0.2970 - accuracy: 0.893 - ETA: 42s - loss: 0.2972 - accuracy: 0.893 - ETA: 41s - loss: 0.2976 - accuracy: 0.893 - ETA: 40s - loss: 0.2978 - accuracy: 0.892 - ETA: 38s - loss: 0.2987 - accuracy: 0.892 - ETA: 37s - loss: 0.2988 - accuracy: 0.892 - ETA: 36s - loss: 0.2987 - accuracy: 0.892 - ETA: 35s - loss: 0.2981 - accuracy: 0.892 - ETA: 34s - loss: 0.2986 - accuracy: 0.892 - ETA: 33s - loss: 0.2983 - accuracy: 0.892 - ETA: 31s - loss: 0.2991 - accuracy: 0.892 - ETA: 30s - loss: 0.2992 - accuracy: 0.892 - ETA: 29s - loss: 0.2989 - accuracy: 0.892 - ETA: 28s - loss: 0.2991 - accuracy: 0.892 - ETA: 27s - loss: 0.2988 - accuracy: 0.892 - ETA: 26s - loss: 0.2998 - accuracy: 0.891 - ETA: 25s - loss: 0.2992 - accuracy: 0.892 - ETA: 23s - loss: 0.2993 - accuracy: 0.891 - ETA: 22s - loss: 0.3000 - accuracy: 0.891 - ETA: 21s - loss: 0.2996 - accuracy: 0.891 - ETA: 20s - loss: 0.2992 - accuracy: 0.892 - ETA: 19s - loss: 0.2998 - accuracy: 0.892 - ETA: 18s - loss: 0.2996 - accuracy: 0.892 - ETA: 17s - loss: 0.2997 - accuracy: 0.892 - ETA: 15s - loss: 0.2988 - accuracy: 0.892 - ETA: 14s - loss: 0.2997 - accuracy: 0.892 - ETA: 13s - loss: 0.3005 - accuracy: 0.891 - ETA: 12s - loss: 0.3009 - accuracy: 0.891 - ETA: 11s - loss: 0.3011 - accuracy: 0.891 - ETA: 10s - loss: 0.3007 - accuracy: 0.891 - ETA: 8s - loss: 0.3008 - accuracy: 0.891 - ETA: 7s - loss: 0.3006 - accuracy: 0.89 - ETA: 6s - loss: 0.3010 - accuracy: 0.89 - ETA: 5s - loss: 0.3009 - accuracy: 0.89 - ETA: 4s - loss: 0.3010 - accuracy: 0.89 - ETA: 3s - loss: 0.3004 - accuracy: 0.89 - ETA: 2s - loss: 0.3004 - accuracy: 0.89 - ETA: 0s - loss: 0.3006 - accuracy: 0.89 - 186s 10ms/step - loss: 0.3008 - accuracy: 0.8913 - val_loss: 1.6152 - val_accuracy: 0.7563\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:49 - loss: 0.4214 - accuracy: 0.85 - ETA: 2:43 - loss: 0.3817 - accuracy: 0.87 - ETA: 2:45 - loss: 0.3553 - accuracy: 0.88 - ETA: 2:43 - loss: 0.3511 - accuracy: 0.87 - ETA: 2:41 - loss: 0.3464 - accuracy: 0.87 - ETA: 2:38 - loss: 0.3404 - accuracy: 0.87 - ETA: 2:36 - loss: 0.3400 - accuracy: 0.87 - ETA: 2:34 - loss: 0.3336 - accuracy: 0.87 - ETA: 2:32 - loss: 0.3288 - accuracy: 0.88 - ETA: 2:30 - loss: 0.3278 - accuracy: 0.88 - ETA: 2:29 - loss: 0.3211 - accuracy: 0.88 - ETA: 2:29 - loss: 0.3195 - accuracy: 0.88 - ETA: 2:30 - loss: 0.3261 - accuracy: 0.88 - ETA: 2:30 - loss: 0.3278 - accuracy: 0.87 - ETA: 2:29 - loss: 0.3259 - accuracy: 0.88 - ETA: 2:29 - loss: 0.3196 - accuracy: 0.88 - ETA: 2:28 - loss: 0.3156 - accuracy: 0.88 - ETA: 2:27 - loss: 0.3211 - accuracy: 0.88 - ETA: 2:26 - loss: 0.3352 - accuracy: 0.87 - ETA: 2:25 - loss: 0.3375 - accuracy: 0.87 - ETA: 2:24 - loss: 0.3426 - accuracy: 0.87 - ETA: 2:22 - loss: 0.3400 - accuracy: 0.87 - ETA: 2:21 - loss: 0.3348 - accuracy: 0.87 - ETA: 2:20 - loss: 0.3344 - accuracy: 0.87 - ETA: 2:18 - loss: 0.3346 - accuracy: 0.87 - ETA: 2:17 - loss: 0.3380 - accuracy: 0.87 - ETA: 2:16 - loss: 0.3394 - accuracy: 0.87 - ETA: 2:15 - loss: 0.3410 - accuracy: 0.87 - ETA: 2:14 - loss: 0.3355 - accuracy: 0.87 - ETA: 2:13 - loss: 0.3288 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3265 - accuracy: 0.88 - ETA: 2:11 - loss: 0.3250 - accuracy: 0.88 - ETA: 2:10 - loss: 0.3204 - accuracy: 0.88 - ETA: 2:09 - loss: 0.3206 - accuracy: 0.88 - ETA: 2:08 - loss: 0.3214 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3261 - accuracy: 0.88 - ETA: 2:06 - loss: 0.3230 - accuracy: 0.88 - ETA: 2:05 - loss: 0.3237 - accuracy: 0.88 - ETA: 2:04 - loss: 0.3226 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3229 - accuracy: 0.88 - ETA: 2:02 - loss: 0.3236 - accuracy: 0.88 - ETA: 2:01 - loss: 0.3260 - accuracy: 0.88 - ETA: 2:00 - loss: 0.3261 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3258 - accuracy: 0.88 - ETA: 1:58 - loss: 0.3241 - accuracy: 0.88 - ETA: 1:56 - loss: 0.3248 - accuracy: 0.88 - ETA: 1:55 - loss: 0.3236 - accuracy: 0.88 - ETA: 1:54 - loss: 0.3244 - accuracy: 0.88 - ETA: 1:53 - loss: 0.3214 - accuracy: 0.88 - ETA: 1:52 - loss: 0.3219 - accuracy: 0.88 - ETA: 1:50 - loss: 0.3249 - accuracy: 0.88 - ETA: 1:49 - loss: 0.3244 - accuracy: 0.88 - ETA: 1:48 - loss: 0.3237 - accuracy: 0.88 - ETA: 1:47 - loss: 0.3232 - accuracy: 0.88 - ETA: 1:46 - loss: 0.3235 - accuracy: 0.88 - ETA: 1:45 - loss: 0.3209 - accuracy: 0.88 - ETA: 1:44 - loss: 0.3198 - accuracy: 0.88 - ETA: 1:43 - loss: 0.3197 - accuracy: 0.88 - ETA: 1:42 - loss: 0.3188 - accuracy: 0.88 - ETA: 1:41 - loss: 0.3183 - accuracy: 0.88 - ETA: 1:40 - loss: 0.3178 - accuracy: 0.88 - ETA: 1:38 - loss: 0.3162 - accuracy: 0.88 - ETA: 1:37 - loss: 0.3160 - accuracy: 0.88 - ETA: 1:36 - loss: 0.3170 - accuracy: 0.88 - ETA: 1:35 - loss: 0.3161 - accuracy: 0.88 - ETA: 1:34 - loss: 0.3156 - accuracy: 0.88 - ETA: 1:33 - loss: 0.3161 - accuracy: 0.88 - ETA: 1:32 - loss: 0.3148 - accuracy: 0.88 - ETA: 1:30 - loss: 0.3149 - accuracy: 0.88 - ETA: 1:29 - loss: 0.3144 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3147 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3135 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3141 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3133 - accuracy: 0.88 - ETA: 1:24 - loss: 0.3135 - accuracy: 0.88 - ETA: 1:23 - loss: 0.3138 - accuracy: 0.88 - ETA: 1:22 - loss: 0.3131 - accuracy: 0.88 - ETA: 1:20 - loss: 0.3146 - accuracy: 0.88 - ETA: 1:19 - loss: 0.3136 - accuracy: 0.88 - ETA: 1:18 - loss: 0.3143 - accuracy: 0.88 - ETA: 1:17 - loss: 0.3139 - accuracy: 0.88 - ETA: 1:16 - loss: 0.3155 - accuracy: 0.88 - ETA: 1:15 - loss: 0.3146 - accuracy: 0.88 - ETA: 1:14 - loss: 0.3149 - accuracy: 0.88 - ETA: 1:13 - loss: 0.3147 - accuracy: 0.88 - ETA: 1:12 - loss: 0.3143 - accuracy: 0.88 - ETA: 1:10 - loss: 0.3139 - accuracy: 0.88 - ETA: 1:09 - loss: 0.3138 - accuracy: 0.88 - ETA: 1:08 - loss: 0.3134 - accuracy: 0.88 - ETA: 1:07 - loss: 0.3130 - accuracy: 0.88 - ETA: 1:06 - loss: 0.3133 - accuracy: 0.88 - ETA: 1:05 - loss: 0.3124 - accuracy: 0.88 - ETA: 1:04 - loss: 0.3115 - accuracy: 0.88 - ETA: 1:03 - loss: 0.3110 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3099 - accuracy: 0.88 - ETA: 1:00 - loss: 0.3098 - accuracy: 0.88 - ETA: 59s - loss: 0.3087 - accuracy: 0.8897 - ETA: 58s - loss: 0.3105 - accuracy: 0.889 - ETA: 57s - loss: 0.3101 - accuracy: 0.889 - ETA: 56s - loss: 0.3094 - accuracy: 0.889 - ETA: 55s - loss: 0.3081 - accuracy: 0.889 - ETA: 54s - loss: 0.3080 - accuracy: 0.889 - ETA: 53s - loss: 0.3093 - accuracy: 0.889 - ETA: 52s - loss: 0.3091 - accuracy: 0.889 - ETA: 50s - loss: 0.3091 - accuracy: 0.889 - ETA: 49s - loss: 0.3093 - accuracy: 0.889 - ETA: 48s - loss: 0.3083 - accuracy: 0.889 - ETA: 47s - loss: 0.3076 - accuracy: 0.889 - ETA: 46s - loss: 0.3072 - accuracy: 0.889 - ETA: 45s - loss: 0.3076 - accuracy: 0.889 - ETA: 44s - loss: 0.3088 - accuracy: 0.889 - ETA: 43s - loss: 0.3090 - accuracy: 0.889 - ETA: 42s - loss: 0.3080 - accuracy: 0.889 - ETA: 40s - loss: 0.3082 - accuracy: 0.889 - ETA: 39s - loss: 0.3072 - accuracy: 0.889 - ETA: 38s - loss: 0.3063 - accuracy: 0.890 - ETA: 37s - loss: 0.3068 - accuracy: 0.889 - ETA: 36s - loss: 0.3069 - accuracy: 0.889 - ETA: 35s - loss: 0.3063 - accuracy: 0.889 - ETA: 34s - loss: 0.3071 - accuracy: 0.889 - ETA: 33s - loss: 0.3065 - accuracy: 0.889 - ETA: 32s - loss: 0.3062 - accuracy: 0.889 - ETA: 30s - loss: 0.3058 - accuracy: 0.890 - ETA: 29s - loss: 0.3052 - accuracy: 0.890 - ETA: 28s - loss: 0.3060 - accuracy: 0.890 - ETA: 27s - loss: 0.3054 - accuracy: 0.890 - ETA: 26s - loss: 0.3044 - accuracy: 0.890 - ETA: 25s - loss: 0.3047 - accuracy: 0.890 - ETA: 24s - loss: 0.3046 - accuracy: 0.890 - ETA: 23s - loss: 0.3040 - accuracy: 0.890 - ETA: 22s - loss: 0.3041 - accuracy: 0.890 - ETA: 20s - loss: 0.3041 - accuracy: 0.890 - ETA: 19s - loss: 0.3041 - accuracy: 0.890 - ETA: 18s - loss: 0.3041 - accuracy: 0.890 - ETA: 17s - loss: 0.3050 - accuracy: 0.890 - ETA: 16s - loss: 0.3049 - accuracy: 0.890 - ETA: 15s - loss: 0.3051 - accuracy: 0.890 - ETA: 14s - loss: 0.3045 - accuracy: 0.890 - ETA: 13s - loss: 0.3053 - accuracy: 0.890 - ETA: 12s - loss: 0.3051 - accuracy: 0.890 - ETA: 10s - loss: 0.3053 - accuracy: 0.890 - ETA: 9s - loss: 0.3064 - accuracy: 0.890 - ETA: 8s - loss: 0.3068 - accuracy: 0.89 - ETA: 7s - loss: 0.3065 - accuracy: 0.89 - ETA: 6s - loss: 0.3061 - accuracy: 0.89 - ETA: 5s - loss: 0.3059 - accuracy: 0.89 - ETA: 4s - loss: 0.3058 - accuracy: 0.89 - ETA: 3s - loss: 0.3057 - accuracy: 0.89 - ETA: 2s - loss: 0.3053 - accuracy: 0.89 - ETA: 0s - loss: 0.3049 - accuracy: 0.89 - 181s 9ms/step - loss: 0.3050 - accuracy: 0.8905 - val_loss: 1.6125 - val_accuracy: 0.7550\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:49 - loss: 0.4504 - accuracy: 0.85 - ETA: 2:47 - loss: 0.3747 - accuracy: 0.87 - ETA: 2:44 - loss: 0.2966 - accuracy: 0.90 - ETA: 2:41 - loss: 0.2727 - accuracy: 0.91 - ETA: 2:39 - loss: 0.2561 - accuracy: 0.91 - ETA: 2:38 - loss: 0.2722 - accuracy: 0.91 - ETA: 2:37 - loss: 0.2785 - accuracy: 0.90 - ETA: 2:38 - loss: 0.2713 - accuracy: 0.90 - ETA: 2:39 - loss: 0.2659 - accuracy: 0.90 - ETA: 2:38 - loss: 0.2672 - accuracy: 0.90 - ETA: 2:37 - loss: 0.2651 - accuracy: 0.90 - ETA: 2:36 - loss: 0.2639 - accuracy: 0.90 - ETA: 2:36 - loss: 0.2661 - accuracy: 0.90 - ETA: 2:35 - loss: 0.2759 - accuracy: 0.90 - ETA: 2:34 - loss: 0.2718 - accuracy: 0.90 - ETA: 2:33 - loss: 0.2713 - accuracy: 0.90 - ETA: 2:32 - loss: 0.2761 - accuracy: 0.90 - ETA: 2:31 - loss: 0.2807 - accuracy: 0.90 - ETA: 2:29 - loss: 0.2847 - accuracy: 0.90 - ETA: 2:28 - loss: 0.2875 - accuracy: 0.90 - ETA: 2:27 - loss: 0.2931 - accuracy: 0.89 - ETA: 2:26 - loss: 0.2957 - accuracy: 0.89 - ETA: 2:25 - loss: 0.2939 - accuracy: 0.89 - ETA: 2:23 - loss: 0.2917 - accuracy: 0.89 - ETA: 2:22 - loss: 0.2924 - accuracy: 0.89 - ETA: 2:20 - loss: 0.2951 - accuracy: 0.89 - ETA: 2:19 - loss: 0.2989 - accuracy: 0.89 - ETA: 2:18 - loss: 0.2961 - accuracy: 0.89 - ETA: 2:17 - loss: 0.2931 - accuracy: 0.89 - ETA: 2:16 - loss: 0.2919 - accuracy: 0.89 - ETA: 2:15 - loss: 0.2905 - accuracy: 0.89 - ETA: 2:14 - loss: 0.2908 - accuracy: 0.89 - ETA: 2:13 - loss: 0.2917 - accuracy: 0.89 - ETA: 2:12 - loss: 0.2928 - accuracy: 0.89 - ETA: 2:10 - loss: 0.2926 - accuracy: 0.89 - ETA: 2:10 - loss: 0.2965 - accuracy: 0.89 - ETA: 2:09 - loss: 0.2968 - accuracy: 0.89 - ETA: 2:07 - loss: 0.2965 - accuracy: 0.89 - ETA: 2:06 - loss: 0.2980 - accuracy: 0.89 - ETA: 2:05 - loss: 0.3021 - accuracy: 0.89 - ETA: 2:04 - loss: 0.3059 - accuracy: 0.89 - ETA: 2:03 - loss: 0.3054 - accuracy: 0.89 - ETA: 2:01 - loss: 0.3052 - accuracy: 0.89 - ETA: 2:00 - loss: 0.3038 - accuracy: 0.89 - ETA: 1:59 - loss: 0.3049 - accuracy: 0.89 - ETA: 1:58 - loss: 0.3072 - accuracy: 0.89 - ETA: 1:57 - loss: 0.3082 - accuracy: 0.89 - ETA: 1:56 - loss: 0.3060 - accuracy: 0.89 - ETA: 1:55 - loss: 0.3065 - accuracy: 0.89 - ETA: 1:54 - loss: 0.3068 - accuracy: 0.89 - ETA: 1:53 - loss: 0.3078 - accuracy: 0.89 - ETA: 1:51 - loss: 0.3081 - accuracy: 0.89 - ETA: 1:50 - loss: 0.3086 - accuracy: 0.89 - ETA: 1:49 - loss: 0.3070 - accuracy: 0.89 - ETA: 1:48 - loss: 0.3064 - accuracy: 0.89 - ETA: 1:47 - loss: 0.3067 - accuracy: 0.89 - ETA: 1:46 - loss: 0.3059 - accuracy: 0.89 - ETA: 1:44 - loss: 0.3059 - accuracy: 0.89 - ETA: 1:43 - loss: 0.3060 - accuracy: 0.89 - ETA: 1:42 - loss: 0.3068 - accuracy: 0.89 - ETA: 1:41 - loss: 0.3057 - accuracy: 0.89 - ETA: 1:40 - loss: 0.3059 - accuracy: 0.89 - ETA: 1:39 - loss: 0.3033 - accuracy: 0.89 - ETA: 1:37 - loss: 0.3034 - accuracy: 0.89 - ETA: 1:37 - loss: 0.3040 - accuracy: 0.89 - ETA: 1:36 - loss: 0.3034 - accuracy: 0.89 - ETA: 1:34 - loss: 0.3023 - accuracy: 0.89 - ETA: 1:33 - loss: 0.3032 - accuracy: 0.89 - ETA: 1:32 - loss: 0.3037 - accuracy: 0.89 - ETA: 1:31 - loss: 0.3032 - accuracy: 0.89 - ETA: 1:30 - loss: 0.3028 - accuracy: 0.89 - ETA: 1:29 - loss: 0.3047 - accuracy: 0.89 - ETA: 1:28 - loss: 0.3048 - accuracy: 0.89 - ETA: 1:26 - loss: 0.3070 - accuracy: 0.89 - ETA: 1:25 - loss: 0.3092 - accuracy: 0.88 - ETA: 1:24 - loss: 0.3084 - accuracy: 0.88 - ETA: 1:23 - loss: 0.3095 - accuracy: 0.88 - ETA: 1:22 - loss: 0.3098 - accuracy: 0.88 - ETA: 1:21 - loss: 0.3089 - accuracy: 0.88 - ETA: 1:20 - loss: 0.3074 - accuracy: 0.88 - ETA: 1:19 - loss: 0.3062 - accuracy: 0.89 - ETA: 1:18 - loss: 0.3053 - accuracy: 0.89 - ETA: 1:16 - loss: 0.3059 - accuracy: 0.89 - ETA: 1:15 - loss: 0.3056 - accuracy: 0.89 - ETA: 1:14 - loss: 0.3047 - accuracy: 0.89 - ETA: 1:13 - loss: 0.3043 - accuracy: 0.89 - ETA: 1:12 - loss: 0.3042 - accuracy: 0.89 - ETA: 1:11 - loss: 0.3044 - accuracy: 0.89 - ETA: 1:10 - loss: 0.3041 - accuracy: 0.89 - ETA: 1:08 - loss: 0.3031 - accuracy: 0.89 - ETA: 1:07 - loss: 0.3032 - accuracy: 0.89 - ETA: 1:06 - loss: 0.3037 - accuracy: 0.89 - ETA: 1:05 - loss: 0.3038 - accuracy: 0.89 - ETA: 1:04 - loss: 0.3041 - accuracy: 0.89 - ETA: 1:03 - loss: 0.3049 - accuracy: 0.89 - ETA: 1:02 - loss: 0.3053 - accuracy: 0.89 - ETA: 1:01 - loss: 0.3051 - accuracy: 0.89 - ETA: 59s - loss: 0.3047 - accuracy: 0.8911 - ETA: 58s - loss: 0.3035 - accuracy: 0.891 - ETA: 57s - loss: 0.3025 - accuracy: 0.892 - ETA: 56s - loss: 0.3020 - accuracy: 0.892 - ETA: 55s - loss: 0.3017 - accuracy: 0.892 - ETA: 54s - loss: 0.3014 - accuracy: 0.892 - ETA: 53s - loss: 0.3014 - accuracy: 0.892 - ETA: 51s - loss: 0.3022 - accuracy: 0.892 - ETA: 50s - loss: 0.3024 - accuracy: 0.892 - ETA: 49s - loss: 0.3016 - accuracy: 0.892 - ETA: 48s - loss: 0.3012 - accuracy: 0.892 - ETA: 47s - loss: 0.3008 - accuracy: 0.892 - ETA: 46s - loss: 0.3012 - accuracy: 0.892 - ETA: 45s - loss: 0.3008 - accuracy: 0.892 - ETA: 44s - loss: 0.3008 - accuracy: 0.892 - ETA: 42s - loss: 0.3005 - accuracy: 0.892 - ETA: 41s - loss: 0.3006 - accuracy: 0.892 - ETA: 40s - loss: 0.3001 - accuracy: 0.892 - ETA: 39s - loss: 0.2996 - accuracy: 0.892 - ETA: 38s - loss: 0.2992 - accuracy: 0.893 - ETA: 37s - loss: 0.2989 - accuracy: 0.893 - ETA: 36s - loss: 0.2989 - accuracy: 0.893 - ETA: 34s - loss: 0.2990 - accuracy: 0.893 - ETA: 33s - loss: 0.2990 - accuracy: 0.892 - ETA: 32s - loss: 0.2995 - accuracy: 0.892 - ETA: 31s - loss: 0.2995 - accuracy: 0.892 - ETA: 30s - loss: 0.2998 - accuracy: 0.892 - ETA: 29s - loss: 0.3000 - accuracy: 0.892 - ETA: 28s - loss: 0.2998 - accuracy: 0.892 - ETA: 27s - loss: 0.3001 - accuracy: 0.892 - ETA: 25s - loss: 0.2997 - accuracy: 0.892 - ETA: 24s - loss: 0.3000 - accuracy: 0.892 - ETA: 23s - loss: 0.2998 - accuracy: 0.892 - ETA: 22s - loss: 0.2994 - accuracy: 0.893 - ETA: 21s - loss: 0.2988 - accuracy: 0.893 - ETA: 20s - loss: 0.2990 - accuracy: 0.893 - ETA: 19s - loss: 0.2981 - accuracy: 0.893 - ETA: 18s - loss: 0.2996 - accuracy: 0.893 - ETA: 16s - loss: 0.2991 - accuracy: 0.893 - ETA: 15s - loss: 0.2989 - accuracy: 0.893 - ETA: 14s - loss: 0.2985 - accuracy: 0.893 - ETA: 13s - loss: 0.2991 - accuracy: 0.893 - ETA: 12s - loss: 0.2982 - accuracy: 0.893 - ETA: 11s - loss: 0.2989 - accuracy: 0.893 - ETA: 10s - loss: 0.2990 - accuracy: 0.893 - ETA: 8s - loss: 0.2987 - accuracy: 0.893 - ETA: 7s - loss: 0.2989 - accuracy: 0.89 - ETA: 6s - loss: 0.2990 - accuracy: 0.89 - ETA: 5s - loss: 0.2991 - accuracy: 0.89 - ETA: 4s - loss: 0.2992 - accuracy: 0.89 - ETA: 3s - loss: 0.2999 - accuracy: 0.89 - ETA: 2s - loss: 0.2995 - accuracy: 0.89 - ETA: 0s - loss: 0.2995 - accuracy: 0.89 - 186s 10ms/step - loss: 0.2990 - accuracy: 0.8932 - val_loss: 1.6089 - val_accuracy: 0.7561\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:50 - loss: 0.2476 - accuracy: 0.92 - ETA: 2:47 - loss: 0.3022 - accuracy: 0.90 - ETA: 2:46 - loss: 0.2977 - accuracy: 0.90 - ETA: 2:44 - loss: 0.2737 - accuracy: 0.91 - ETA: 2:42 - loss: 0.2610 - accuracy: 0.91 - ETA: 2:42 - loss: 0.2542 - accuracy: 0.91 - ETA: 2:42 - loss: 0.2477 - accuracy: 0.91 - ETA: 2:41 - loss: 0.2612 - accuracy: 0.90 - ETA: 2:39 - loss: 0.2505 - accuracy: 0.91 - ETA: 2:38 - loss: 0.2502 - accuracy: 0.91 - ETA: 2:37 - loss: 0.2535 - accuracy: 0.90 - ETA: 2:36 - loss: 0.2495 - accuracy: 0.91 - ETA: 2:35 - loss: 0.2525 - accuracy: 0.91 - ETA: 2:35 - loss: 0.2580 - accuracy: 0.90 - ETA: 2:34 - loss: 0.2569 - accuracy: 0.90 - ETA: 2:32 - loss: 0.2551 - accuracy: 0.91 - ETA: 2:31 - loss: 0.2607 - accuracy: 0.90 - ETA: 2:29 - loss: 0.2618 - accuracy: 0.90 - ETA: 2:28 - loss: 0.2662 - accuracy: 0.90 - ETA: 2:27 - loss: 0.2678 - accuracy: 0.90 - ETA: 2:26 - loss: 0.2685 - accuracy: 0.90 - ETA: 2:25 - loss: 0.2657 - accuracy: 0.90 - ETA: 2:24 - loss: 0.2653 - accuracy: 0.90 - ETA: 2:23 - loss: 0.2626 - accuracy: 0.90 - ETA: 2:22 - loss: 0.2647 - accuracy: 0.90 - ETA: 2:20 - loss: 0.2699 - accuracy: 0.90 - ETA: 2:19 - loss: 0.2699 - accuracy: 0.90 - ETA: 2:19 - loss: 0.2707 - accuracy: 0.90 - ETA: 2:18 - loss: 0.2730 - accuracy: 0.90 - ETA: 2:17 - loss: 0.2740 - accuracy: 0.90 - ETA: 2:16 - loss: 0.2703 - accuracy: 0.90 - ETA: 2:15 - loss: 0.2723 - accuracy: 0.90 - ETA: 2:13 - loss: 0.2726 - accuracy: 0.90 - ETA: 2:12 - loss: 0.2712 - accuracy: 0.90 - ETA: 2:11 - loss: 0.2732 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2740 - accuracy: 0.90 - ETA: 2:08 - loss: 0.2753 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2751 - accuracy: 0.90 - ETA: 2:06 - loss: 0.2788 - accuracy: 0.90 - ETA: 2:05 - loss: 0.2770 - accuracy: 0.90 - ETA: 2:04 - loss: 0.2790 - accuracy: 0.90 - ETA: 2:03 - loss: 0.2769 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2798 - accuracy: 0.90 - ETA: 2:00 - loss: 0.2810 - accuracy: 0.90 - ETA: 1:59 - loss: 0.2817 - accuracy: 0.90 - ETA: 1:58 - loss: 0.2784 - accuracy: 0.90 - ETA: 1:57 - loss: 0.2805 - accuracy: 0.90 - ETA: 1:55 - loss: 0.2810 - accuracy: 0.90 - ETA: 1:54 - loss: 0.2827 - accuracy: 0.90 - ETA: 1:53 - loss: 0.2826 - accuracy: 0.90 - ETA: 1:52 - loss: 0.2828 - accuracy: 0.89 - ETA: 1:51 - loss: 0.2842 - accuracy: 0.89 - ETA: 1:49 - loss: 0.2829 - accuracy: 0.89 - ETA: 1:48 - loss: 0.2829 - accuracy: 0.89 - ETA: 1:46 - loss: 0.2849 - accuracy: 0.89 - ETA: 1:45 - loss: 0.2847 - accuracy: 0.89 - ETA: 1:43 - loss: 0.2834 - accuracy: 0.89 - ETA: 1:42 - loss: 0.2841 - accuracy: 0.89 - ETA: 1:41 - loss: 0.2842 - accuracy: 0.89 - ETA: 1:39 - loss: 0.2843 - accuracy: 0.89 - ETA: 1:38 - loss: 0.2840 - accuracy: 0.89 - ETA: 1:37 - loss: 0.2837 - accuracy: 0.89 - ETA: 1:35 - loss: 0.2825 - accuracy: 0.89 - ETA: 1:34 - loss: 0.2823 - accuracy: 0.89 - ETA: 1:33 - loss: 0.2824 - accuracy: 0.89 - ETA: 1:32 - loss: 0.2840 - accuracy: 0.89 - ETA: 1:30 - loss: 0.2843 - accuracy: 0.89 - ETA: 1:29 - loss: 0.2834 - accuracy: 0.89 - ETA: 1:28 - loss: 0.2841 - accuracy: 0.89 - ETA: 1:26 - loss: 0.2841 - accuracy: 0.89 - ETA: 1:25 - loss: 0.2844 - accuracy: 0.89 - ETA: 1:24 - loss: 0.2838 - accuracy: 0.89 - ETA: 1:23 - loss: 0.2842 - accuracy: 0.89 - ETA: 1:22 - loss: 0.2834 - accuracy: 0.89 - ETA: 1:20 - loss: 0.2842 - accuracy: 0.89 - ETA: 1:19 - loss: 0.2836 - accuracy: 0.89 - ETA: 1:18 - loss: 0.2832 - accuracy: 0.89 - ETA: 1:17 - loss: 0.2831 - accuracy: 0.89 - ETA: 1:15 - loss: 0.2827 - accuracy: 0.89 - ETA: 1:14 - loss: 0.2820 - accuracy: 0.89 - ETA: 1:13 - loss: 0.2818 - accuracy: 0.89 - ETA: 1:12 - loss: 0.2833 - accuracy: 0.89 - ETA: 1:11 - loss: 0.2840 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2841 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2843 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2851 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2857 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2860 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2865 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2866 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2870 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2874 - accuracy: 0.89 - ETA: 59s - loss: 0.2885 - accuracy: 0.8966 - ETA: 58s - loss: 0.2888 - accuracy: 0.896 - ETA: 57s - loss: 0.2900 - accuracy: 0.896 - ETA: 56s - loss: 0.2897 - accuracy: 0.896 - ETA: 55s - loss: 0.2899 - accuracy: 0.896 - ETA: 54s - loss: 0.2902 - accuracy: 0.896 - ETA: 53s - loss: 0.2901 - accuracy: 0.896 - ETA: 52s - loss: 0.2896 - accuracy: 0.896 - ETA: 51s - loss: 0.2897 - accuracy: 0.896 - ETA: 50s - loss: 0.2896 - accuracy: 0.896 - ETA: 49s - loss: 0.2899 - accuracy: 0.896 - ETA: 47s - loss: 0.2895 - accuracy: 0.896 - ETA: 46s - loss: 0.2887 - accuracy: 0.896 - ETA: 45s - loss: 0.2887 - accuracy: 0.896 - ETA: 44s - loss: 0.2880 - accuracy: 0.896 - ETA: 43s - loss: 0.2883 - accuracy: 0.896 - ETA: 42s - loss: 0.2883 - accuracy: 0.896 - ETA: 41s - loss: 0.2881 - accuracy: 0.896 - ETA: 40s - loss: 0.2873 - accuracy: 0.897 - ETA: 39s - loss: 0.2882 - accuracy: 0.896 - ETA: 38s - loss: 0.2882 - accuracy: 0.897 - ETA: 37s - loss: 0.2890 - accuracy: 0.896 - ETA: 36s - loss: 0.2888 - accuracy: 0.896 - ETA: 35s - loss: 0.2889 - accuracy: 0.896 - ETA: 34s - loss: 0.2887 - accuracy: 0.896 - ETA: 33s - loss: 0.2885 - accuracy: 0.896 - ETA: 32s - loss: 0.2884 - accuracy: 0.896 - ETA: 31s - loss: 0.2882 - accuracy: 0.896 - ETA: 30s - loss: 0.2881 - accuracy: 0.896 - ETA: 29s - loss: 0.2878 - accuracy: 0.896 - ETA: 28s - loss: 0.2875 - accuracy: 0.896 - ETA: 26s - loss: 0.2874 - accuracy: 0.897 - ETA: 25s - loss: 0.2882 - accuracy: 0.896 - ETA: 24s - loss: 0.2894 - accuracy: 0.896 - ETA: 23s - loss: 0.2886 - accuracy: 0.896 - ETA: 22s - loss: 0.2881 - accuracy: 0.896 - ETA: 21s - loss: 0.2876 - accuracy: 0.897 - ETA: 20s - loss: 0.2882 - accuracy: 0.896 - ETA: 19s - loss: 0.2876 - accuracy: 0.896 - ETA: 18s - loss: 0.2873 - accuracy: 0.897 - ETA: 17s - loss: 0.2894 - accuracy: 0.896 - ETA: 16s - loss: 0.2890 - accuracy: 0.896 - ETA: 15s - loss: 0.2887 - accuracy: 0.896 - ETA: 14s - loss: 0.2894 - accuracy: 0.896 - ETA: 13s - loss: 0.2899 - accuracy: 0.896 - ETA: 12s - loss: 0.2901 - accuracy: 0.895 - ETA: 11s - loss: 0.2908 - accuracy: 0.895 - ETA: 10s - loss: 0.2907 - accuracy: 0.895 - ETA: 9s - loss: 0.2914 - accuracy: 0.895 - ETA: 8s - loss: 0.2913 - accuracy: 0.89 - ETA: 7s - loss: 0.2914 - accuracy: 0.89 - ETA: 6s - loss: 0.2912 - accuracy: 0.89 - ETA: 5s - loss: 0.2906 - accuracy: 0.89 - ETA: 4s - loss: 0.2900 - accuracy: 0.89 - ETA: 3s - loss: 0.2912 - accuracy: 0.89 - ETA: 2s - loss: 0.2908 - accuracy: 0.89 - ETA: 1s - loss: 0.2904 - accuracy: 0.89 - ETA: 0s - loss: 0.2902 - accuracy: 0.89 - 161s 8ms/step - loss: 0.2909 - accuracy: 0.8955 - val_loss: 1.6276 - val_accuracy: 0.7552\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:26 - loss: 0.3305 - accuracy: 0.87 - ETA: 2:23 - loss: 0.2575 - accuracy: 0.90 - ETA: 2:19 - loss: 0.2419 - accuracy: 0.91 - ETA: 2:16 - loss: 0.2556 - accuracy: 0.91 - ETA: 2:13 - loss: 0.2836 - accuracy: 0.90 - ETA: 2:11 - loss: 0.2889 - accuracy: 0.90 - ETA: 2:10 - loss: 0.2825 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2711 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2663 - accuracy: 0.91 - ETA: 2:06 - loss: 0.2757 - accuracy: 0.90 - ETA: 2:06 - loss: 0.2800 - accuracy: 0.90 - ETA: 2:05 - loss: 0.2860 - accuracy: 0.90 - ETA: 2:04 - loss: 0.2843 - accuracy: 0.90 - ETA: 2:03 - loss: 0.2759 - accuracy: 0.90 - ETA: 2:03 - loss: 0.2730 - accuracy: 0.90 - ETA: 2:03 - loss: 0.2800 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2781 - accuracy: 0.89 - ETA: 2:01 - loss: 0.2805 - accuracy: 0.89 - ETA: 1:59 - loss: 0.2838 - accuracy: 0.89 - ETA: 1:59 - loss: 0.2888 - accuracy: 0.89 - ETA: 1:58 - loss: 0.2869 - accuracy: 0.89 - ETA: 1:56 - loss: 0.2873 - accuracy: 0.89 - ETA: 1:55 - loss: 0.2917 - accuracy: 0.89 - ETA: 1:55 - loss: 0.2900 - accuracy: 0.89 - ETA: 1:53 - loss: 0.2874 - accuracy: 0.89 - ETA: 1:52 - loss: 0.2848 - accuracy: 0.89 - ETA: 1:51 - loss: 0.2835 - accuracy: 0.89 - ETA: 1:50 - loss: 0.2817 - accuracy: 0.89 - ETA: 1:50 - loss: 0.2824 - accuracy: 0.89 - ETA: 1:49 - loss: 0.2818 - accuracy: 0.89 - ETA: 1:48 - loss: 0.2849 - accuracy: 0.89 - ETA: 1:47 - loss: 0.2850 - accuracy: 0.89 - ETA: 1:46 - loss: 0.2837 - accuracy: 0.89 - ETA: 1:46 - loss: 0.2850 - accuracy: 0.89 - ETA: 1:45 - loss: 0.2861 - accuracy: 0.89 - ETA: 1:44 - loss: 0.2841 - accuracy: 0.89 - ETA: 1:43 - loss: 0.2848 - accuracy: 0.89 - ETA: 1:42 - loss: 0.2838 - accuracy: 0.89 - ETA: 1:42 - loss: 0.2807 - accuracy: 0.89 - ETA: 1:41 - loss: 0.2807 - accuracy: 0.89 - ETA: 1:40 - loss: 0.2842 - accuracy: 0.89 - ETA: 1:39 - loss: 0.2879 - accuracy: 0.89 - ETA: 1:38 - loss: 0.2863 - accuracy: 0.89 - ETA: 1:37 - loss: 0.2837 - accuracy: 0.89 - ETA: 1:36 - loss: 0.2841 - accuracy: 0.89 - ETA: 1:35 - loss: 0.2834 - accuracy: 0.89 - ETA: 1:34 - loss: 0.2836 - accuracy: 0.89 - ETA: 1:33 - loss: 0.2847 - accuracy: 0.89 - ETA: 1:32 - loss: 0.2841 - accuracy: 0.89 - ETA: 1:31 - loss: 0.2848 - accuracy: 0.89 - ETA: 1:31 - loss: 0.2822 - accuracy: 0.89 - ETA: 1:30 - loss: 0.2815 - accuracy: 0.89 - ETA: 1:29 - loss: 0.2796 - accuracy: 0.89 - ETA: 1:28 - loss: 0.2796 - accuracy: 0.89 - ETA: 1:27 - loss: 0.2796 - accuracy: 0.89 - ETA: 1:26 - loss: 0.2799 - accuracy: 0.89 - ETA: 1:25 - loss: 0.2785 - accuracy: 0.89 - ETA: 1:24 - loss: 0.2780 - accuracy: 0.89 - ETA: 1:23 - loss: 0.2790 - accuracy: 0.89 - ETA: 1:22 - loss: 0.2777 - accuracy: 0.89 - ETA: 1:22 - loss: 0.2766 - accuracy: 0.89 - ETA: 1:21 - loss: 0.2770 - accuracy: 0.89 - ETA: 1:20 - loss: 0.2769 - accuracy: 0.89 - ETA: 1:19 - loss: 0.2766 - accuracy: 0.89 - ETA: 1:18 - loss: 0.2773 - accuracy: 0.89 - ETA: 1:18 - loss: 0.2764 - accuracy: 0.89 - ETA: 1:17 - loss: 0.2747 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2769 - accuracy: 0.89 - ETA: 1:16 - loss: 0.2761 - accuracy: 0.89 - ETA: 1:15 - loss: 0.2768 - accuracy: 0.89 - ETA: 1:15 - loss: 0.2788 - accuracy: 0.89 - ETA: 1:14 - loss: 0.2797 - accuracy: 0.89 - ETA: 1:13 - loss: 0.2794 - accuracy: 0.89 - ETA: 1:12 - loss: 0.2777 - accuracy: 0.89 - ETA: 1:11 - loss: 0.2782 - accuracy: 0.89 - ETA: 1:11 - loss: 0.2781 - accuracy: 0.89 - ETA: 1:10 - loss: 0.2782 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2792 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2801 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2787 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2797 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2802 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2796 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2798 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2786 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2780 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2782 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2792 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2786 - accuracy: 0.89 - ETA: 59s - loss: 0.2790 - accuracy: 0.8990 - ETA: 58s - loss: 0.2800 - accuracy: 0.898 - ETA: 57s - loss: 0.2808 - accuracy: 0.898 - ETA: 56s - loss: 0.2807 - accuracy: 0.897 - ETA: 55s - loss: 0.2815 - accuracy: 0.897 - ETA: 55s - loss: 0.2809 - accuracy: 0.897 - ETA: 54s - loss: 0.2804 - accuracy: 0.898 - ETA: 53s - loss: 0.2802 - accuracy: 0.898 - ETA: 52s - loss: 0.2822 - accuracy: 0.897 - ETA: 51s - loss: 0.2822 - accuracy: 0.897 - ETA: 50s - loss: 0.2822 - accuracy: 0.897 - ETA: 49s - loss: 0.2814 - accuracy: 0.898 - ETA: 49s - loss: 0.2812 - accuracy: 0.898 - ETA: 48s - loss: 0.2825 - accuracy: 0.897 - ETA: 47s - loss: 0.2825 - accuracy: 0.897 - ETA: 46s - loss: 0.2821 - accuracy: 0.897 - ETA: 45s - loss: 0.2815 - accuracy: 0.898 - ETA: 44s - loss: 0.2815 - accuracy: 0.898 - ETA: 43s - loss: 0.2814 - accuracy: 0.898 - ETA: 42s - loss: 0.2814 - accuracy: 0.897 - ETA: 41s - loss: 0.2809 - accuracy: 0.898 - ETA: 40s - loss: 0.2804 - accuracy: 0.898 - ETA: 39s - loss: 0.2807 - accuracy: 0.898 - ETA: 38s - loss: 0.2810 - accuracy: 0.898 - ETA: 37s - loss: 0.2821 - accuracy: 0.897 - ETA: 36s - loss: 0.2816 - accuracy: 0.898 - ETA: 35s - loss: 0.2815 - accuracy: 0.898 - ETA: 34s - loss: 0.2810 - accuracy: 0.898 - ETA: 33s - loss: 0.2806 - accuracy: 0.898 - ETA: 32s - loss: 0.2793 - accuracy: 0.898 - ETA: 31s - loss: 0.2789 - accuracy: 0.899 - ETA: 30s - loss: 0.2791 - accuracy: 0.898 - ETA: 29s - loss: 0.2780 - accuracy: 0.899 - ETA: 28s - loss: 0.2780 - accuracy: 0.899 - ETA: 27s - loss: 0.2772 - accuracy: 0.899 - ETA: 26s - loss: 0.2769 - accuracy: 0.899 - ETA: 25s - loss: 0.2767 - accuracy: 0.899 - ETA: 24s - loss: 0.2764 - accuracy: 0.899 - ETA: 23s - loss: 0.2766 - accuracy: 0.899 - ETA: 22s - loss: 0.2762 - accuracy: 0.899 - ETA: 21s - loss: 0.2764 - accuracy: 0.899 - ETA: 20s - loss: 0.2759 - accuracy: 0.899 - ETA: 19s - loss: 0.2756 - accuracy: 0.900 - ETA: 18s - loss: 0.2755 - accuracy: 0.900 - ETA: 17s - loss: 0.2762 - accuracy: 0.900 - ETA: 16s - loss: 0.2769 - accuracy: 0.899 - ETA: 15s - loss: 0.2765 - accuracy: 0.899 - ETA: 14s - loss: 0.2769 - accuracy: 0.899 - ETA: 13s - loss: 0.2770 - accuracy: 0.899 - ETA: 12s - loss: 0.2769 - accuracy: 0.899 - ETA: 11s - loss: 0.2762 - accuracy: 0.899 - ETA: 10s - loss: 0.2759 - accuracy: 0.899 - ETA: 9s - loss: 0.2757 - accuracy: 0.900 - ETA: 8s - loss: 0.2754 - accuracy: 0.90 - ETA: 7s - loss: 0.2754 - accuracy: 0.90 - ETA: 6s - loss: 0.2761 - accuracy: 0.89 - ETA: 5s - loss: 0.2760 - accuracy: 0.89 - ETA: 4s - loss: 0.2764 - accuracy: 0.89 - ETA: 3s - loss: 0.2758 - accuracy: 0.89 - ETA: 1s - loss: 0.2766 - accuracy: 0.89 - ETA: 0s - loss: 0.2759 - accuracy: 0.89 - 172s 9ms/step - loss: 0.2756 - accuracy: 0.8997 - val_loss: 1.6470 - val_accuracy: 0.7556\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:58 - loss: 0.3241 - accuracy: 0.88 - ETA: 2:58 - loss: 0.3001 - accuracy: 0.89 - ETA: 2:55 - loss: 0.3006 - accuracy: 0.88 - ETA: 2:51 - loss: 0.2748 - accuracy: 0.89 - ETA: 2:47 - loss: 0.2621 - accuracy: 0.89 - ETA: 2:45 - loss: 0.2585 - accuracy: 0.89 - ETA: 2:43 - loss: 0.2578 - accuracy: 0.90 - ETA: 2:40 - loss: 0.2747 - accuracy: 0.89 - ETA: 2:40 - loss: 0.2715 - accuracy: 0.89 - ETA: 2:37 - loss: 0.2683 - accuracy: 0.90 - ETA: 2:38 - loss: 0.2757 - accuracy: 0.89 - ETA: 2:37 - loss: 0.2836 - accuracy: 0.89 - ETA: 2:35 - loss: 0.2921 - accuracy: 0.89 - ETA: 2:33 - loss: 0.2948 - accuracy: 0.89 - ETA: 2:32 - loss: 0.2989 - accuracy: 0.89 - ETA: 2:31 - loss: 0.2917 - accuracy: 0.89 - ETA: 2:31 - loss: 0.2850 - accuracy: 0.89 - ETA: 2:29 - loss: 0.2790 - accuracy: 0.89 - ETA: 2:27 - loss: 0.2814 - accuracy: 0.89 - ETA: 2:26 - loss: 0.2810 - accuracy: 0.89 - ETA: 2:25 - loss: 0.2842 - accuracy: 0.89 - ETA: 2:24 - loss: 0.2845 - accuracy: 0.89 - ETA: 2:22 - loss: 0.2851 - accuracy: 0.89 - ETA: 2:21 - loss: 0.2841 - accuracy: 0.89 - ETA: 2:20 - loss: 0.2863 - accuracy: 0.89 - ETA: 2:19 - loss: 0.2874 - accuracy: 0.89 - ETA: 2:17 - loss: 0.2874 - accuracy: 0.89 - ETA: 2:16 - loss: 0.2870 - accuracy: 0.89 - ETA: 2:16 - loss: 0.2849 - accuracy: 0.89 - ETA: 2:15 - loss: 0.2830 - accuracy: 0.89 - ETA: 2:14 - loss: 0.2844 - accuracy: 0.89 - ETA: 2:13 - loss: 0.2827 - accuracy: 0.89 - ETA: 2:12 - loss: 0.2820 - accuracy: 0.89 - ETA: 2:10 - loss: 0.2824 - accuracy: 0.89 - ETA: 2:09 - loss: 0.2828 - accuracy: 0.89 - ETA: 2:08 - loss: 0.2810 - accuracy: 0.89 - ETA: 2:07 - loss: 0.2833 - accuracy: 0.89 - ETA: 2:06 - loss: 0.2847 - accuracy: 0.89 - ETA: 2:05 - loss: 0.2825 - accuracy: 0.89 - ETA: 2:04 - loss: 0.2828 - accuracy: 0.89 - ETA: 2:02 - loss: 0.2807 - accuracy: 0.89 - ETA: 2:01 - loss: 0.2780 - accuracy: 0.89 - ETA: 2:00 - loss: 0.2786 - accuracy: 0.89 - ETA: 1:59 - loss: 0.2802 - accuracy: 0.89 - ETA: 1:59 - loss: 0.2785 - accuracy: 0.89 - ETA: 1:57 - loss: 0.2789 - accuracy: 0.89 - ETA: 1:56 - loss: 0.2780 - accuracy: 0.89 - ETA: 1:55 - loss: 0.2779 - accuracy: 0.89 - ETA: 1:54 - loss: 0.2774 - accuracy: 0.89 - ETA: 1:53 - loss: 0.2778 - accuracy: 0.89 - ETA: 1:52 - loss: 0.2790 - accuracy: 0.89 - ETA: 1:51 - loss: 0.2815 - accuracy: 0.89 - ETA: 1:50 - loss: 0.2816 - accuracy: 0.89 - ETA: 1:48 - loss: 0.2814 - accuracy: 0.89 - ETA: 1:47 - loss: 0.2816 - accuracy: 0.89 - ETA: 1:46 - loss: 0.2796 - accuracy: 0.89 - ETA: 1:45 - loss: 0.2818 - accuracy: 0.89 - ETA: 1:44 - loss: 0.2815 - accuracy: 0.89 - ETA: 1:43 - loss: 0.2833 - accuracy: 0.89 - ETA: 1:42 - loss: 0.2817 - accuracy: 0.89 - ETA: 1:41 - loss: 0.2831 - accuracy: 0.89 - ETA: 1:40 - loss: 0.2833 - accuracy: 0.89 - ETA: 1:38 - loss: 0.2830 - accuracy: 0.89 - ETA: 1:37 - loss: 0.2814 - accuracy: 0.89 - ETA: 1:36 - loss: 0.2819 - accuracy: 0.89 - ETA: 1:35 - loss: 0.2807 - accuracy: 0.89 - ETA: 1:34 - loss: 0.2799 - accuracy: 0.89 - ETA: 1:33 - loss: 0.2800 - accuracy: 0.89 - ETA: 1:31 - loss: 0.2806 - accuracy: 0.89 - ETA: 1:30 - loss: 0.2809 - accuracy: 0.89 - ETA: 1:29 - loss: 0.2785 - accuracy: 0.89 - ETA: 1:28 - loss: 0.2783 - accuracy: 0.89 - ETA: 1:27 - loss: 0.2772 - accuracy: 0.89 - ETA: 1:26 - loss: 0.2759 - accuracy: 0.89 - ETA: 1:25 - loss: 0.2760 - accuracy: 0.89 - ETA: 1:24 - loss: 0.2773 - accuracy: 0.89 - ETA: 1:23 - loss: 0.2763 - accuracy: 0.89 - ETA: 1:22 - loss: 0.2784 - accuracy: 0.89 - ETA: 1:21 - loss: 0.2799 - accuracy: 0.89 - ETA: 1:20 - loss: 0.2804 - accuracy: 0.89 - ETA: 1:19 - loss: 0.2792 - accuracy: 0.89 - ETA: 1:18 - loss: 0.2789 - accuracy: 0.89 - ETA: 1:17 - loss: 0.2778 - accuracy: 0.89 - ETA: 1:16 - loss: 0.2767 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2765 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2775 - accuracy: 0.89 - ETA: 1:13 - loss: 0.2792 - accuracy: 0.89 - ETA: 1:12 - loss: 0.2793 - accuracy: 0.89 - ETA: 1:10 - loss: 0.2792 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2805 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2803 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2815 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2812 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2814 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2817 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2825 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2839 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2848 - accuracy: 0.89 - ETA: 59s - loss: 0.2855 - accuracy: 0.8966 - ETA: 58s - loss: 0.2856 - accuracy: 0.896 - ETA: 56s - loss: 0.2846 - accuracy: 0.897 - ETA: 55s - loss: 0.2855 - accuracy: 0.897 - ETA: 54s - loss: 0.2854 - accuracy: 0.897 - ETA: 53s - loss: 0.2852 - accuracy: 0.897 - ETA: 52s - loss: 0.2861 - accuracy: 0.897 - ETA: 51s - loss: 0.2858 - accuracy: 0.897 - ETA: 50s - loss: 0.2866 - accuracy: 0.896 - ETA: 49s - loss: 0.2875 - accuracy: 0.896 - ETA: 48s - loss: 0.2885 - accuracy: 0.896 - ETA: 47s - loss: 0.2898 - accuracy: 0.895 - ETA: 45s - loss: 0.2900 - accuracy: 0.895 - ETA: 44s - loss: 0.2895 - accuracy: 0.895 - ETA: 43s - loss: 0.2896 - accuracy: 0.895 - ETA: 42s - loss: 0.2897 - accuracy: 0.895 - ETA: 41s - loss: 0.2900 - accuracy: 0.895 - ETA: 40s - loss: 0.2902 - accuracy: 0.895 - ETA: 38s - loss: 0.2900 - accuracy: 0.895 - ETA: 37s - loss: 0.2901 - accuracy: 0.895 - ETA: 36s - loss: 0.2892 - accuracy: 0.896 - ETA: 35s - loss: 0.2889 - accuracy: 0.896 - ETA: 34s - loss: 0.2890 - accuracy: 0.896 - ETA: 33s - loss: 0.2875 - accuracy: 0.896 - ETA: 31s - loss: 0.2873 - accuracy: 0.896 - ETA: 30s - loss: 0.2879 - accuracy: 0.896 - ETA: 29s - loss: 0.2876 - accuracy: 0.896 - ETA: 28s - loss: 0.2879 - accuracy: 0.896 - ETA: 27s - loss: 0.2878 - accuracy: 0.896 - ETA: 26s - loss: 0.2880 - accuracy: 0.896 - ETA: 25s - loss: 0.2872 - accuracy: 0.896 - ETA: 23s - loss: 0.2870 - accuracy: 0.896 - ETA: 22s - loss: 0.2863 - accuracy: 0.896 - ETA: 21s - loss: 0.2863 - accuracy: 0.896 - ETA: 20s - loss: 0.2862 - accuracy: 0.896 - ETA: 19s - loss: 0.2859 - accuracy: 0.896 - ETA: 18s - loss: 0.2871 - accuracy: 0.896 - ETA: 16s - loss: 0.2861 - accuracy: 0.896 - ETA: 15s - loss: 0.2868 - accuracy: 0.896 - ETA: 14s - loss: 0.2866 - accuracy: 0.896 - ETA: 13s - loss: 0.2866 - accuracy: 0.896 - ETA: 12s - loss: 0.2863 - accuracy: 0.896 - ETA: 11s - loss: 0.2866 - accuracy: 0.896 - ETA: 10s - loss: 0.2863 - accuracy: 0.896 - ETA: 8s - loss: 0.2862 - accuracy: 0.896 - ETA: 7s - loss: 0.2856 - accuracy: 0.89 - ETA: 6s - loss: 0.2866 - accuracy: 0.89 - ETA: 5s - loss: 0.2860 - accuracy: 0.89 - ETA: 4s - loss: 0.2861 - accuracy: 0.89 - ETA: 3s - loss: 0.2855 - accuracy: 0.89 - ETA: 2s - loss: 0.2857 - accuracy: 0.89 - ETA: 1s - loss: 0.2855 - accuracy: 0.89 - 187s 10ms/step - loss: 0.2864 - accuracy: 0.8962 - val_loss: 1.6486 - val_accuracy: 0.7544\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:44 - loss: 0.2162 - accuracy: 0.89 - ETA: 2:31 - loss: 0.2619 - accuracy: 0.89 - ETA: 2:29 - loss: 0.2192 - accuracy: 0.90 - ETA: 2:29 - loss: 0.2593 - accuracy: 0.89 - ETA: 2:26 - loss: 0.2641 - accuracy: 0.88 - ETA: 2:23 - loss: 0.2592 - accuracy: 0.89 - ETA: 2:24 - loss: 0.2559 - accuracy: 0.89 - ETA: 2:25 - loss: 0.2523 - accuracy: 0.89 - ETA: 2:24 - loss: 0.2653 - accuracy: 0.89 - ETA: 2:22 - loss: 0.2680 - accuracy: 0.89 - ETA: 2:21 - loss: 0.2706 - accuracy: 0.89 - ETA: 2:19 - loss: 0.2764 - accuracy: 0.89 - ETA: 2:19 - loss: 0.2743 - accuracy: 0.89 - ETA: 2:18 - loss: 0.2767 - accuracy: 0.89 - ETA: 2:17 - loss: 0.2761 - accuracy: 0.89 - ETA: 2:15 - loss: 0.2795 - accuracy: 0.89 - ETA: 2:13 - loss: 0.2801 - accuracy: 0.89 - ETA: 2:12 - loss: 0.2792 - accuracy: 0.89 - ETA: 2:10 - loss: 0.2763 - accuracy: 0.89 - ETA: 2:08 - loss: 0.2723 - accuracy: 0.89 - ETA: 2:07 - loss: 0.2694 - accuracy: 0.89 - ETA: 2:05 - loss: 0.2728 - accuracy: 0.89 - ETA: 2:05 - loss: 0.2748 - accuracy: 0.89 - ETA: 2:04 - loss: 0.2735 - accuracy: 0.89 - ETA: 2:03 - loss: 0.2707 - accuracy: 0.89 - ETA: 2:02 - loss: 0.2778 - accuracy: 0.89 - ETA: 2:00 - loss: 0.2747 - accuracy: 0.89 - ETA: 1:59 - loss: 0.2763 - accuracy: 0.89 - ETA: 1:58 - loss: 0.2730 - accuracy: 0.89 - ETA: 1:57 - loss: 0.2714 - accuracy: 0.89 - ETA: 1:56 - loss: 0.2720 - accuracy: 0.89 - ETA: 1:55 - loss: 0.2752 - accuracy: 0.89 - ETA: 1:54 - loss: 0.2758 - accuracy: 0.89 - ETA: 1:53 - loss: 0.2780 - accuracy: 0.89 - ETA: 1:51 - loss: 0.2750 - accuracy: 0.89 - ETA: 1:50 - loss: 0.2751 - accuracy: 0.89 - ETA: 1:49 - loss: 0.2735 - accuracy: 0.89 - ETA: 1:48 - loss: 0.2753 - accuracy: 0.89 - ETA: 1:47 - loss: 0.2733 - accuracy: 0.89 - ETA: 1:46 - loss: 0.2742 - accuracy: 0.89 - ETA: 1:45 - loss: 0.2718 - accuracy: 0.89 - ETA: 1:44 - loss: 0.2698 - accuracy: 0.89 - ETA: 1:43 - loss: 0.2699 - accuracy: 0.89 - ETA: 1:43 - loss: 0.2719 - accuracy: 0.89 - ETA: 1:42 - loss: 0.2706 - accuracy: 0.89 - ETA: 1:41 - loss: 0.2714 - accuracy: 0.89 - ETA: 1:40 - loss: 0.2754 - accuracy: 0.89 - ETA: 1:39 - loss: 0.2735 - accuracy: 0.89 - ETA: 1:38 - loss: 0.2715 - accuracy: 0.89 - ETA: 1:37 - loss: 0.2697 - accuracy: 0.89 - ETA: 1:36 - loss: 0.2708 - accuracy: 0.89 - ETA: 1:35 - loss: 0.2695 - accuracy: 0.89 - ETA: 1:34 - loss: 0.2681 - accuracy: 0.90 - ETA: 1:33 - loss: 0.2675 - accuracy: 0.90 - ETA: 1:32 - loss: 0.2677 - accuracy: 0.90 - ETA: 1:31 - loss: 0.2663 - accuracy: 0.90 - ETA: 1:30 - loss: 0.2670 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2683 - accuracy: 0.90 - ETA: 1:28 - loss: 0.2689 - accuracy: 0.90 - ETA: 1:27 - loss: 0.2695 - accuracy: 0.89 - ETA: 1:26 - loss: 0.2696 - accuracy: 0.89 - ETA: 1:25 - loss: 0.2705 - accuracy: 0.89 - ETA: 1:24 - loss: 0.2703 - accuracy: 0.89 - ETA: 1:23 - loss: 0.2707 - accuracy: 0.89 - ETA: 1:22 - loss: 0.2709 - accuracy: 0.89 - ETA: 1:21 - loss: 0.2715 - accuracy: 0.89 - ETA: 1:20 - loss: 0.2719 - accuracy: 0.89 - ETA: 1:19 - loss: 0.2717 - accuracy: 0.89 - ETA: 1:18 - loss: 0.2710 - accuracy: 0.89 - ETA: 1:17 - loss: 0.2705 - accuracy: 0.89 - ETA: 1:16 - loss: 0.2698 - accuracy: 0.90 - ETA: 1:16 - loss: 0.2694 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2707 - accuracy: 0.89 - ETA: 1:14 - loss: 0.2694 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2698 - accuracy: 0.90 - ETA: 1:12 - loss: 0.2710 - accuracy: 0.89 - ETA: 1:11 - loss: 0.2710 - accuracy: 0.89 - ETA: 1:10 - loss: 0.2717 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2741 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2746 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2748 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2748 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2746 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2740 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2736 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2726 - accuracy: 0.90 - ETA: 1:01 - loss: 0.2733 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2736 - accuracy: 0.89 - ETA: 59s - loss: 0.2733 - accuracy: 0.9001 - ETA: 58s - loss: 0.2729 - accuracy: 0.900 - ETA: 57s - loss: 0.2742 - accuracy: 0.899 - ETA: 56s - loss: 0.2742 - accuracy: 0.899 - ETA: 55s - loss: 0.2739 - accuracy: 0.899 - ETA: 54s - loss: 0.2744 - accuracy: 0.899 - ETA: 53s - loss: 0.2735 - accuracy: 0.900 - ETA: 52s - loss: 0.2736 - accuracy: 0.900 - ETA: 51s - loss: 0.2748 - accuracy: 0.899 - ETA: 50s - loss: 0.2759 - accuracy: 0.899 - ETA: 49s - loss: 0.2761 - accuracy: 0.899 - ETA: 48s - loss: 0.2747 - accuracy: 0.899 - ETA: 47s - loss: 0.2751 - accuracy: 0.899 - ETA: 46s - loss: 0.2751 - accuracy: 0.899 - ETA: 45s - loss: 0.2749 - accuracy: 0.899 - ETA: 44s - loss: 0.2747 - accuracy: 0.899 - ETA: 43s - loss: 0.2746 - accuracy: 0.899 - ETA: 42s - loss: 0.2737 - accuracy: 0.900 - ETA: 41s - loss: 0.2749 - accuracy: 0.899 - ETA: 41s - loss: 0.2750 - accuracy: 0.899 - ETA: 40s - loss: 0.2746 - accuracy: 0.899 - ETA: 39s - loss: 0.2757 - accuracy: 0.899 - ETA: 38s - loss: 0.2746 - accuracy: 0.899 - ETA: 37s - loss: 0.2747 - accuracy: 0.899 - ETA: 36s - loss: 0.2749 - accuracy: 0.899 - ETA: 35s - loss: 0.2746 - accuracy: 0.899 - ETA: 34s - loss: 0.2749 - accuracy: 0.899 - ETA: 33s - loss: 0.2753 - accuracy: 0.899 - ETA: 32s - loss: 0.2755 - accuracy: 0.899 - ETA: 31s - loss: 0.2755 - accuracy: 0.899 - ETA: 30s - loss: 0.2753 - accuracy: 0.899 - ETA: 29s - loss: 0.2753 - accuracy: 0.899 - ETA: 28s - loss: 0.2754 - accuracy: 0.899 - ETA: 27s - loss: 0.2750 - accuracy: 0.899 - ETA: 26s - loss: 0.2743 - accuracy: 0.899 - ETA: 25s - loss: 0.2743 - accuracy: 0.899 - ETA: 24s - loss: 0.2741 - accuracy: 0.899 - ETA: 23s - loss: 0.2739 - accuracy: 0.899 - ETA: 22s - loss: 0.2747 - accuracy: 0.899 - ETA: 21s - loss: 0.2752 - accuracy: 0.899 - ETA: 20s - loss: 0.2744 - accuracy: 0.899 - ETA: 19s - loss: 0.2748 - accuracy: 0.899 - ETA: 19s - loss: 0.2742 - accuracy: 0.899 - ETA: 18s - loss: 0.2749 - accuracy: 0.899 - ETA: 17s - loss: 0.2746 - accuracy: 0.899 - ETA: 16s - loss: 0.2739 - accuracy: 0.900 - ETA: 15s - loss: 0.2735 - accuracy: 0.900 - ETA: 14s - loss: 0.2733 - accuracy: 0.900 - ETA: 13s - loss: 0.2737 - accuracy: 0.900 - ETA: 12s - loss: 0.2731 - accuracy: 0.900 - ETA: 11s - loss: 0.2729 - accuracy: 0.900 - ETA: 10s - loss: 0.2737 - accuracy: 0.899 - ETA: 9s - loss: 0.2743 - accuracy: 0.899 - ETA: 8s - loss: 0.2747 - accuracy: 0.89 - ETA: 7s - loss: 0.2743 - accuracy: 0.89 - ETA: 6s - loss: 0.2738 - accuracy: 0.89 - ETA: 5s - loss: 0.2729 - accuracy: 0.89 - ETA: 4s - loss: 0.2727 - accuracy: 0.90 - ETA: 3s - loss: 0.2727 - accuracy: 0.90 - ETA: 2s - loss: 0.2724 - accuracy: 0.90 - ETA: 1s - loss: 0.2722 - accuracy: 0.90 - ETA: 0s - loss: 0.2723 - accuracy: 0.90 - 156s 8ms/step - loss: 0.2731 - accuracy: 0.8999 - val_loss: 1.6531 - val_accuracy: 0.7559\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:34 - loss: 0.3439 - accuracy: 0.85 - ETA: 2:27 - loss: 0.3521 - accuracy: 0.86 - ETA: 2:21 - loss: 0.3113 - accuracy: 0.87 - ETA: 2:19 - loss: 0.3116 - accuracy: 0.87 - ETA: 2:18 - loss: 0.3108 - accuracy: 0.87 - ETA: 2:16 - loss: 0.2941 - accuracy: 0.88 - ETA: 2:15 - loss: 0.2862 - accuracy: 0.88 - ETA: 2:15 - loss: 0.2848 - accuracy: 0.88 - ETA: 2:14 - loss: 0.2769 - accuracy: 0.88 - ETA: 2:13 - loss: 0.2880 - accuracy: 0.88 - ETA: 2:13 - loss: 0.2957 - accuracy: 0.88 - ETA: 2:13 - loss: 0.3052 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3018 - accuracy: 0.88 - ETA: 2:11 - loss: 0.2972 - accuracy: 0.88 - ETA: 2:10 - loss: 0.2907 - accuracy: 0.89 - ETA: 2:08 - loss: 0.2824 - accuracy: 0.89 - ETA: 2:07 - loss: 0.2860 - accuracy: 0.89 - ETA: 2:06 - loss: 0.2796 - accuracy: 0.89 - ETA: 2:05 - loss: 0.2781 - accuracy: 0.89 - ETA: 2:04 - loss: 0.2732 - accuracy: 0.89 - ETA: 2:04 - loss: 0.2729 - accuracy: 0.89 - ETA: 2:03 - loss: 0.2728 - accuracy: 0.89 - ETA: 2:02 - loss: 0.2739 - accuracy: 0.89 - ETA: 2:01 - loss: 0.2758 - accuracy: 0.89 - ETA: 2:00 - loss: 0.2733 - accuracy: 0.89 - ETA: 1:59 - loss: 0.2709 - accuracy: 0.89 - ETA: 1:58 - loss: 0.2696 - accuracy: 0.89 - ETA: 1:57 - loss: 0.2698 - accuracy: 0.89 - ETA: 1:57 - loss: 0.2690 - accuracy: 0.89 - ETA: 1:55 - loss: 0.2724 - accuracy: 0.89 - ETA: 1:55 - loss: 0.2699 - accuracy: 0.89 - ETA: 1:54 - loss: 0.2658 - accuracy: 0.90 - ETA: 1:53 - loss: 0.2651 - accuracy: 0.90 - ETA: 1:52 - loss: 0.2656 - accuracy: 0.90 - ETA: 1:50 - loss: 0.2669 - accuracy: 0.90 - ETA: 1:50 - loss: 0.2655 - accuracy: 0.90 - ETA: 1:48 - loss: 0.2641 - accuracy: 0.90 - ETA: 1:47 - loss: 0.2675 - accuracy: 0.89 - ETA: 1:46 - loss: 0.2646 - accuracy: 0.90 - ETA: 1:45 - loss: 0.2674 - accuracy: 0.89 - ETA: 1:44 - loss: 0.2680 - accuracy: 0.90 - ETA: 1:43 - loss: 0.2682 - accuracy: 0.89 - ETA: 1:42 - loss: 0.2679 - accuracy: 0.89 - ETA: 1:41 - loss: 0.2680 - accuracy: 0.89 - ETA: 1:40 - loss: 0.2695 - accuracy: 0.89 - ETA: 1:39 - loss: 0.2666 - accuracy: 0.89 - ETA: 1:38 - loss: 0.2645 - accuracy: 0.90 - ETA: 1:37 - loss: 0.2662 - accuracy: 0.90 - ETA: 1:36 - loss: 0.2672 - accuracy: 0.89 - ETA: 1:35 - loss: 0.2671 - accuracy: 0.90 - ETA: 1:34 - loss: 0.2664 - accuracy: 0.90 - ETA: 1:33 - loss: 0.2667 - accuracy: 0.90 - ETA: 1:32 - loss: 0.2650 - accuracy: 0.90 - ETA: 1:31 - loss: 0.2653 - accuracy: 0.90 - ETA: 1:30 - loss: 0.2655 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2657 - accuracy: 0.90 - ETA: 1:28 - loss: 0.2656 - accuracy: 0.90 - ETA: 1:27 - loss: 0.2654 - accuracy: 0.90 - ETA: 1:26 - loss: 0.2656 - accuracy: 0.90 - ETA: 1:25 - loss: 0.2653 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2652 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2652 - accuracy: 0.90 - ETA: 1:23 - loss: 0.2652 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2687 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2685 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2687 - accuracy: 0.90 - ETA: 1:19 - loss: 0.2698 - accuracy: 0.90 - ETA: 1:18 - loss: 0.2687 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2695 - accuracy: 0.90 - ETA: 1:16 - loss: 0.2707 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2720 - accuracy: 0.89 - ETA: 1:14 - loss: 0.2729 - accuracy: 0.89 - ETA: 1:13 - loss: 0.2738 - accuracy: 0.89 - ETA: 1:12 - loss: 0.2738 - accuracy: 0.89 - ETA: 1:11 - loss: 0.2748 - accuracy: 0.89 - ETA: 1:10 - loss: 0.2753 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2743 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2741 - accuracy: 0.89 - ETA: 1:08 - loss: 0.2745 - accuracy: 0.89 - ETA: 1:07 - loss: 0.2758 - accuracy: 0.89 - ETA: 1:06 - loss: 0.2758 - accuracy: 0.89 - ETA: 1:05 - loss: 0.2770 - accuracy: 0.89 - ETA: 1:04 - loss: 0.2765 - accuracy: 0.89 - ETA: 1:03 - loss: 0.2750 - accuracy: 0.89 - ETA: 1:02 - loss: 0.2753 - accuracy: 0.89 - ETA: 1:01 - loss: 0.2765 - accuracy: 0.89 - ETA: 1:00 - loss: 0.2761 - accuracy: 0.89 - ETA: 59s - loss: 0.2763 - accuracy: 0.8978 - ETA: 58s - loss: 0.2758 - accuracy: 0.898 - ETA: 57s - loss: 0.2761 - accuracy: 0.897 - ETA: 56s - loss: 0.2754 - accuracy: 0.897 - ETA: 55s - loss: 0.2770 - accuracy: 0.897 - ETA: 54s - loss: 0.2769 - accuracy: 0.897 - ETA: 53s - loss: 0.2769 - accuracy: 0.897 - ETA: 52s - loss: 0.2765 - accuracy: 0.897 - ETA: 51s - loss: 0.2764 - accuracy: 0.897 - ETA: 50s - loss: 0.2762 - accuracy: 0.897 - ETA: 50s - loss: 0.2761 - accuracy: 0.897 - ETA: 49s - loss: 0.2763 - accuracy: 0.897 - ETA: 48s - loss: 0.2759 - accuracy: 0.897 - ETA: 47s - loss: 0.2754 - accuracy: 0.897 - ETA: 46s - loss: 0.2742 - accuracy: 0.898 - ETA: 45s - loss: 0.2741 - accuracy: 0.898 - ETA: 44s - loss: 0.2736 - accuracy: 0.898 - ETA: 43s - loss: 0.2747 - accuracy: 0.898 - ETA: 42s - loss: 0.2753 - accuracy: 0.898 - ETA: 41s - loss: 0.2759 - accuracy: 0.897 - ETA: 40s - loss: 0.2767 - accuracy: 0.897 - ETA: 39s - loss: 0.2764 - accuracy: 0.897 - ETA: 38s - loss: 0.2759 - accuracy: 0.897 - ETA: 37s - loss: 0.2753 - accuracy: 0.897 - ETA: 36s - loss: 0.2758 - accuracy: 0.897 - ETA: 35s - loss: 0.2754 - accuracy: 0.897 - ETA: 34s - loss: 0.2747 - accuracy: 0.897 - ETA: 33s - loss: 0.2744 - accuracy: 0.898 - ETA: 32s - loss: 0.2752 - accuracy: 0.897 - ETA: 32s - loss: 0.2755 - accuracy: 0.897 - ETA: 31s - loss: 0.2754 - accuracy: 0.897 - ETA: 30s - loss: 0.2750 - accuracy: 0.897 - ETA: 29s - loss: 0.2757 - accuracy: 0.897 - ETA: 28s - loss: 0.2755 - accuracy: 0.897 - ETA: 27s - loss: 0.2749 - accuracy: 0.897 - ETA: 26s - loss: 0.2756 - accuracy: 0.897 - ETA: 25s - loss: 0.2759 - accuracy: 0.897 - ETA: 24s - loss: 0.2768 - accuracy: 0.896 - ETA: 23s - loss: 0.2774 - accuracy: 0.896 - ETA: 22s - loss: 0.2776 - accuracy: 0.896 - ETA: 21s - loss: 0.2786 - accuracy: 0.896 - ETA: 20s - loss: 0.2780 - accuracy: 0.896 - ETA: 19s - loss: 0.2783 - accuracy: 0.896 - ETA: 18s - loss: 0.2778 - accuracy: 0.896 - ETA: 17s - loss: 0.2773 - accuracy: 0.896 - ETA: 16s - loss: 0.2768 - accuracy: 0.896 - ETA: 15s - loss: 0.2764 - accuracy: 0.897 - ETA: 14s - loss: 0.2759 - accuracy: 0.897 - ETA: 14s - loss: 0.2755 - accuracy: 0.897 - ETA: 13s - loss: 0.2753 - accuracy: 0.897 - ETA: 12s - loss: 0.2748 - accuracy: 0.897 - ETA: 11s - loss: 0.2741 - accuracy: 0.898 - ETA: 10s - loss: 0.2745 - accuracy: 0.897 - ETA: 9s - loss: 0.2745 - accuracy: 0.897 - ETA: 8s - loss: 0.2740 - accuracy: 0.89 - ETA: 7s - loss: 0.2742 - accuracy: 0.89 - ETA: 6s - loss: 0.2742 - accuracy: 0.89 - ETA: 5s - loss: 0.2742 - accuracy: 0.89 - ETA: 4s - loss: 0.2744 - accuracy: 0.89 - ETA: 3s - loss: 0.2740 - accuracy: 0.89 - ETA: 2s - loss: 0.2734 - accuracy: 0.89 - ETA: 1s - loss: 0.2736 - accuracy: 0.89 - ETA: 0s - loss: 0.2735 - accuracy: 0.89 - 156s 8ms/step - loss: 0.2737 - accuracy: 0.8979 - val_loss: 1.6485 - val_accuracy: 0.7573\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 0.3170 - accuracy: 0.88 - ETA: 2:24 - loss: 0.3035 - accuracy: 0.89 - ETA: 2:19 - loss: 0.2771 - accuracy: 0.90 - ETA: 2:17 - loss: 0.2474 - accuracy: 0.91 - ETA: 2:14 - loss: 0.2319 - accuracy: 0.91 - ETA: 2:15 - loss: 0.2650 - accuracy: 0.90 - ETA: 2:13 - loss: 0.2754 - accuracy: 0.90 - ETA: 2:11 - loss: 0.2624 - accuracy: 0.90 - ETA: 2:10 - loss: 0.2638 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2660 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2672 - accuracy: 0.90 - ETA: 2:08 - loss: 0.2639 - accuracy: 0.90 - ETA: 2:06 - loss: 0.2631 - accuracy: 0.90 - ETA: 2:05 - loss: 0.2661 - accuracy: 0.90 - ETA: 2:05 - loss: 0.2647 - accuracy: 0.90 - ETA: 2:05 - loss: 0.2697 - accuracy: 0.89 - ETA: 2:04 - loss: 0.2726 - accuracy: 0.89 - ETA: 2:03 - loss: 0.2690 - accuracy: 0.90 - ETA: 2:03 - loss: 0.2653 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2666 - accuracy: 0.90 - ETA: 2:01 - loss: 0.2600 - accuracy: 0.90 - ETA: 2:00 - loss: 0.2552 - accuracy: 0.90 - ETA: 1:59 - loss: 0.2593 - accuracy: 0.90 - ETA: 1:58 - loss: 0.2578 - accuracy: 0.90 - ETA: 1:58 - loss: 0.2596 - accuracy: 0.90 - ETA: 1:56 - loss: 0.2598 - accuracy: 0.90 - ETA: 1:55 - loss: 0.2549 - accuracy: 0.90 - ETA: 1:54 - loss: 0.2568 - accuracy: 0.90 - ETA: 1:54 - loss: 0.2563 - accuracy: 0.90 - ETA: 1:52 - loss: 0.2546 - accuracy: 0.90 - ETA: 1:52 - loss: 0.2573 - accuracy: 0.90 - ETA: 1:51 - loss: 0.2605 - accuracy: 0.90 - ETA: 1:50 - loss: 0.2617 - accuracy: 0.90 - ETA: 1:49 - loss: 0.2623 - accuracy: 0.90 - ETA: 1:48 - loss: 0.2616 - accuracy: 0.90 - ETA: 1:47 - loss: 0.2590 - accuracy: 0.90 - ETA: 1:47 - loss: 0.2577 - accuracy: 0.90 - ETA: 1:46 - loss: 0.2570 - accuracy: 0.90 - ETA: 1:45 - loss: 0.2604 - accuracy: 0.90 - ETA: 1:44 - loss: 0.2618 - accuracy: 0.90 - ETA: 1:43 - loss: 0.2633 - accuracy: 0.90 - ETA: 1:42 - loss: 0.2662 - accuracy: 0.90 - ETA: 1:41 - loss: 0.2686 - accuracy: 0.90 - ETA: 1:40 - loss: 0.2690 - accuracy: 0.90 - ETA: 1:39 - loss: 0.2696 - accuracy: 0.90 - ETA: 1:38 - loss: 0.2687 - accuracy: 0.90 - ETA: 1:37 - loss: 0.2697 - accuracy: 0.90 - ETA: 1:36 - loss: 0.2689 - accuracy: 0.90 - ETA: 1:35 - loss: 0.2684 - accuracy: 0.90 - ETA: 1:35 - loss: 0.2706 - accuracy: 0.90 - ETA: 1:34 - loss: 0.2672 - accuracy: 0.90 - ETA: 1:33 - loss: 0.2671 - accuracy: 0.90 - ETA: 1:32 - loss: 0.2680 - accuracy: 0.90 - ETA: 1:31 - loss: 0.2666 - accuracy: 0.90 - ETA: 1:30 - loss: 0.2653 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2634 - accuracy: 0.90 - ETA: 1:28 - loss: 0.2657 - accuracy: 0.90 - ETA: 1:27 - loss: 0.2663 - accuracy: 0.90 - ETA: 1:26 - loss: 0.2641 - accuracy: 0.90 - ETA: 1:25 - loss: 0.2642 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2639 - accuracy: 0.90 - ETA: 1:23 - loss: 0.2634 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2640 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2644 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2649 - accuracy: 0.90 - ETA: 1:19 - loss: 0.2654 - accuracy: 0.90 - ETA: 1:18 - loss: 0.2653 - accuracy: 0.90 - ETA: 1:18 - loss: 0.2657 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2650 - accuracy: 0.90 - ETA: 1:16 - loss: 0.2652 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2655 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2648 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2651 - accuracy: 0.90 - ETA: 1:12 - loss: 0.2650 - accuracy: 0.90 - ETA: 1:11 - loss: 0.2661 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2650 - accuracy: 0.90 - ETA: 1:09 - loss: 0.2647 - accuracy: 0.90 - ETA: 1:08 - loss: 0.2648 - accuracy: 0.90 - ETA: 1:07 - loss: 0.2641 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2633 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2621 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2626 - accuracy: 0.90 - ETA: 1:03 - loss: 0.2630 - accuracy: 0.90 - ETA: 1:03 - loss: 0.2634 - accuracy: 0.90 - ETA: 1:02 - loss: 0.2647 - accuracy: 0.90 - ETA: 1:01 - loss: 0.2653 - accuracy: 0.90 - ETA: 1:00 - loss: 0.2650 - accuracy: 0.90 - ETA: 59s - loss: 0.2649 - accuracy: 0.9036 - ETA: 58s - loss: 0.2636 - accuracy: 0.904 - ETA: 57s - loss: 0.2653 - accuracy: 0.903 - ETA: 56s - loss: 0.2645 - accuracy: 0.903 - ETA: 55s - loss: 0.2640 - accuracy: 0.904 - ETA: 54s - loss: 0.2630 - accuracy: 0.904 - ETA: 53s - loss: 0.2633 - accuracy: 0.904 - ETA: 52s - loss: 0.2641 - accuracy: 0.903 - ETA: 51s - loss: 0.2651 - accuracy: 0.903 - ETA: 50s - loss: 0.2646 - accuracy: 0.903 - ETA: 50s - loss: 0.2643 - accuracy: 0.903 - ETA: 49s - loss: 0.2640 - accuracy: 0.903 - ETA: 48s - loss: 0.2636 - accuracy: 0.903 - ETA: 47s - loss: 0.2632 - accuracy: 0.903 - ETA: 46s - loss: 0.2633 - accuracy: 0.904 - ETA: 45s - loss: 0.2639 - accuracy: 0.903 - ETA: 44s - loss: 0.2644 - accuracy: 0.903 - ETA: 43s - loss: 0.2645 - accuracy: 0.903 - ETA: 42s - loss: 0.2646 - accuracy: 0.903 - ETA: 41s - loss: 0.2655 - accuracy: 0.903 - ETA: 40s - loss: 0.2653 - accuracy: 0.903 - ETA: 39s - loss: 0.2655 - accuracy: 0.903 - ETA: 38s - loss: 0.2657 - accuracy: 0.903 - ETA: 37s - loss: 0.2649 - accuracy: 0.904 - ETA: 36s - loss: 0.2640 - accuracy: 0.904 - ETA: 35s - loss: 0.2639 - accuracy: 0.904 - ETA: 34s - loss: 0.2652 - accuracy: 0.903 - ETA: 33s - loss: 0.2649 - accuracy: 0.904 - ETA: 32s - loss: 0.2643 - accuracy: 0.904 - ETA: 32s - loss: 0.2638 - accuracy: 0.904 - ETA: 31s - loss: 0.2648 - accuracy: 0.903 - ETA: 30s - loss: 0.2640 - accuracy: 0.904 - ETA: 29s - loss: 0.2641 - accuracy: 0.904 - ETA: 28s - loss: 0.2652 - accuracy: 0.903 - ETA: 27s - loss: 0.2647 - accuracy: 0.903 - ETA: 26s - loss: 0.2645 - accuracy: 0.903 - ETA: 25s - loss: 0.2639 - accuracy: 0.903 - ETA: 24s - loss: 0.2642 - accuracy: 0.903 - ETA: 23s - loss: 0.2643 - accuracy: 0.903 - ETA: 22s - loss: 0.2642 - accuracy: 0.903 - ETA: 21s - loss: 0.2645 - accuracy: 0.903 - ETA: 20s - loss: 0.2644 - accuracy: 0.903 - ETA: 19s - loss: 0.2648 - accuracy: 0.903 - ETA: 18s - loss: 0.2642 - accuracy: 0.903 - ETA: 17s - loss: 0.2643 - accuracy: 0.903 - ETA: 16s - loss: 0.2644 - accuracy: 0.903 - ETA: 15s - loss: 0.2642 - accuracy: 0.903 - ETA: 15s - loss: 0.2634 - accuracy: 0.903 - ETA: 14s - loss: 0.2631 - accuracy: 0.903 - ETA: 13s - loss: 0.2637 - accuracy: 0.903 - ETA: 12s - loss: 0.2641 - accuracy: 0.903 - ETA: 11s - loss: 0.2647 - accuracy: 0.903 - ETA: 10s - loss: 0.2650 - accuracy: 0.903 - ETA: 9s - loss: 0.2650 - accuracy: 0.903 - ETA: 8s - loss: 0.2652 - accuracy: 0.90 - ETA: 7s - loss: 0.2663 - accuracy: 0.90 - ETA: 6s - loss: 0.2659 - accuracy: 0.90 - ETA: 5s - loss: 0.2663 - accuracy: 0.90 - ETA: 4s - loss: 0.2661 - accuracy: 0.90 - ETA: 3s - loss: 0.2658 - accuracy: 0.90 - ETA: 2s - loss: 0.2659 - accuracy: 0.90 - ETA: 1s - loss: 0.2661 - accuracy: 0.90 - ETA: 0s - loss: 0.2657 - accuracy: 0.90 - 154s 8ms/step - loss: 0.2653 - accuracy: 0.9028 - val_loss: 1.6600 - val_accuracy: 0.7550\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:33 - loss: 0.3358 - accuracy: 0.88 - ETA: 2:27 - loss: 0.3559 - accuracy: 0.87 - ETA: 2:23 - loss: 0.3206 - accuracy: 0.88 - ETA: 2:22 - loss: 0.3057 - accuracy: 0.89 - ETA: 2:23 - loss: 0.3144 - accuracy: 0.89 - ETA: 2:23 - loss: 0.2930 - accuracy: 0.90 - ETA: 2:21 - loss: 0.2785 - accuracy: 0.90 - ETA: 2:19 - loss: 0.2702 - accuracy: 0.90 - ETA: 2:18 - loss: 0.2625 - accuracy: 0.90 - ETA: 2:16 - loss: 0.2552 - accuracy: 0.90 - ETA: 2:15 - loss: 0.2693 - accuracy: 0.90 - ETA: 2:13 - loss: 0.2612 - accuracy: 0.90 - ETA: 2:12 - loss: 0.2550 - accuracy: 0.90 - ETA: 2:11 - loss: 0.2612 - accuracy: 0.90 - ETA: 2:10 - loss: 0.2624 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2698 - accuracy: 0.90 - ETA: 2:08 - loss: 0.2762 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2737 - accuracy: 0.90 - ETA: 2:06 - loss: 0.2729 - accuracy: 0.90 - ETA: 2:05 - loss: 0.2696 - accuracy: 0.90 - ETA: 2:04 - loss: 0.2665 - accuracy: 0.90 - ETA: 2:04 - loss: 0.2653 - accuracy: 0.90 - ETA: 2:03 - loss: 0.2658 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2654 - accuracy: 0.90 - ETA: 2:01 - loss: 0.2661 - accuracy: 0.90 - ETA: 2:00 - loss: 0.2671 - accuracy: 0.90 - ETA: 1:58 - loss: 0.2689 - accuracy: 0.90 - ETA: 1:57 - loss: 0.2671 - accuracy: 0.90 - ETA: 1:56 - loss: 0.2648 - accuracy: 0.90 - ETA: 1:55 - loss: 0.2613 - accuracy: 0.90 - ETA: 1:54 - loss: 0.2643 - accuracy: 0.90 - ETA: 1:53 - loss: 0.2667 - accuracy: 0.90 - ETA: 1:52 - loss: 0.2645 - accuracy: 0.90 - ETA: 1:51 - loss: 0.2640 - accuracy: 0.90 - ETA: 1:50 - loss: 0.2652 - accuracy: 0.90 - ETA: 1:49 - loss: 0.2630 - accuracy: 0.90 - ETA: 1:49 - loss: 0.2627 - accuracy: 0.90 - ETA: 1:49 - loss: 0.2650 - accuracy: 0.90 - ETA: 1:48 - loss: 0.2681 - accuracy: 0.90 - ETA: 1:48 - loss: 0.2668 - accuracy: 0.90 - ETA: 1:47 - loss: 0.2695 - accuracy: 0.90 - ETA: 1:46 - loss: 0.2698 - accuracy: 0.90 - ETA: 1:44 - loss: 0.2689 - accuracy: 0.90 - ETA: 1:43 - loss: 0.2686 - accuracy: 0.90 - ETA: 1:42 - loss: 0.2683 - accuracy: 0.90 - ETA: 1:41 - loss: 0.2680 - accuracy: 0.90 - ETA: 1:40 - loss: 0.2662 - accuracy: 0.90 - ETA: 1:39 - loss: 0.2694 - accuracy: 0.90 - ETA: 1:38 - loss: 0.2706 - accuracy: 0.90 - ETA: 1:37 - loss: 0.2694 - accuracy: 0.90 - ETA: 1:36 - loss: 0.2694 - accuracy: 0.90 - ETA: 1:35 - loss: 0.2675 - accuracy: 0.90 - ETA: 1:35 - loss: 0.2695 - accuracy: 0.90 - ETA: 1:34 - loss: 0.2694 - accuracy: 0.90 - ETA: 1:33 - loss: 0.2708 - accuracy: 0.90 - ETA: 1:32 - loss: 0.2700 - accuracy: 0.90 - ETA: 1:31 - loss: 0.2702 - accuracy: 0.90 - ETA: 1:30 - loss: 0.2710 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2690 - accuracy: 0.90 - ETA: 1:28 - loss: 0.2683 - accuracy: 0.90 - ETA: 1:27 - loss: 0.2674 - accuracy: 0.90 - ETA: 1:26 - loss: 0.2684 - accuracy: 0.90 - ETA: 1:25 - loss: 0.2669 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2648 - accuracy: 0.90 - ETA: 1:23 - loss: 0.2642 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2633 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2631 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2625 - accuracy: 0.90 - ETA: 1:19 - loss: 0.2611 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2610 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2605 - accuracy: 0.90 - ETA: 1:16 - loss: 0.2602 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2599 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2608 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2607 - accuracy: 0.90 - ETA: 1:12 - loss: 0.2609 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2595 - accuracy: 0.90 - ETA: 1:09 - loss: 0.2598 - accuracy: 0.90 - ETA: 1:08 - loss: 0.2604 - accuracy: 0.90 - ETA: 1:07 - loss: 0.2605 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2596 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2583 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2576 - accuracy: 0.90 - ETA: 1:03 - loss: 0.2592 - accuracy: 0.90 - ETA: 1:02 - loss: 0.2599 - accuracy: 0.90 - ETA: 1:02 - loss: 0.2594 - accuracy: 0.90 - ETA: 1:01 - loss: 0.2580 - accuracy: 0.90 - ETA: 1:00 - loss: 0.2585 - accuracy: 0.90 - ETA: 59s - loss: 0.2576 - accuracy: 0.9059 - ETA: 58s - loss: 0.2560 - accuracy: 0.906 - ETA: 57s - loss: 0.2562 - accuracy: 0.906 - ETA: 56s - loss: 0.2554 - accuracy: 0.906 - ETA: 55s - loss: 0.2560 - accuracy: 0.906 - ETA: 54s - loss: 0.2568 - accuracy: 0.906 - ETA: 53s - loss: 0.2584 - accuracy: 0.905 - ETA: 52s - loss: 0.2588 - accuracy: 0.905 - ETA: 51s - loss: 0.2578 - accuracy: 0.905 - ETA: 50s - loss: 0.2570 - accuracy: 0.905 - ETA: 49s - loss: 0.2574 - accuracy: 0.905 - ETA: 48s - loss: 0.2566 - accuracy: 0.906 - ETA: 47s - loss: 0.2566 - accuracy: 0.906 - ETA: 46s - loss: 0.2584 - accuracy: 0.905 - ETA: 45s - loss: 0.2587 - accuracy: 0.905 - ETA: 44s - loss: 0.2582 - accuracy: 0.906 - ETA: 43s - loss: 0.2570 - accuracy: 0.906 - ETA: 42s - loss: 0.2564 - accuracy: 0.906 - ETA: 41s - loss: 0.2560 - accuracy: 0.906 - ETA: 40s - loss: 0.2562 - accuracy: 0.906 - ETA: 39s - loss: 0.2561 - accuracy: 0.907 - ETA: 38s - loss: 0.2568 - accuracy: 0.906 - ETA: 37s - loss: 0.2576 - accuracy: 0.906 - ETA: 36s - loss: 0.2590 - accuracy: 0.905 - ETA: 35s - loss: 0.2583 - accuracy: 0.906 - ETA: 34s - loss: 0.2583 - accuracy: 0.906 - ETA: 34s - loss: 0.2582 - accuracy: 0.905 - ETA: 33s - loss: 0.2578 - accuracy: 0.906 - ETA: 32s - loss: 0.2571 - accuracy: 0.906 - ETA: 31s - loss: 0.2571 - accuracy: 0.906 - ETA: 30s - loss: 0.2577 - accuracy: 0.905 - ETA: 29s - loss: 0.2576 - accuracy: 0.905 - ETA: 28s - loss: 0.2572 - accuracy: 0.905 - ETA: 27s - loss: 0.2577 - accuracy: 0.905 - ETA: 26s - loss: 0.2577 - accuracy: 0.905 - ETA: 25s - loss: 0.2574 - accuracy: 0.905 - ETA: 24s - loss: 0.2577 - accuracy: 0.905 - ETA: 23s - loss: 0.2581 - accuracy: 0.905 - ETA: 22s - loss: 0.2591 - accuracy: 0.905 - ETA: 21s - loss: 0.2594 - accuracy: 0.905 - ETA: 20s - loss: 0.2593 - accuracy: 0.904 - ETA: 19s - loss: 0.2591 - accuracy: 0.904 - ETA: 18s - loss: 0.2590 - accuracy: 0.904 - ETA: 17s - loss: 0.2585 - accuracy: 0.904 - ETA: 16s - loss: 0.2589 - accuracy: 0.904 - ETA: 15s - loss: 0.2584 - accuracy: 0.904 - ETA: 14s - loss: 0.2583 - accuracy: 0.905 - ETA: 14s - loss: 0.2578 - accuracy: 0.905 - ETA: 13s - loss: 0.2573 - accuracy: 0.905 - ETA: 12s - loss: 0.2576 - accuracy: 0.905 - ETA: 11s - loss: 0.2574 - accuracy: 0.905 - ETA: 10s - loss: 0.2572 - accuracy: 0.905 - ETA: 9s - loss: 0.2578 - accuracy: 0.905 - ETA: 8s - loss: 0.2577 - accuracy: 0.90 - ETA: 7s - loss: 0.2572 - accuracy: 0.90 - ETA: 6s - loss: 0.2569 - accuracy: 0.90 - ETA: 5s - loss: 0.2567 - accuracy: 0.90 - ETA: 4s - loss: 0.2572 - accuracy: 0.90 - ETA: 3s - loss: 0.2575 - accuracy: 0.90 - ETA: 2s - loss: 0.2573 - accuracy: 0.90 - ETA: 1s - loss: 0.2581 - accuracy: 0.90 - ETA: 0s - loss: 0.2578 - accuracy: 0.90 - 153s 8ms/step - loss: 0.2575 - accuracy: 0.9052 - val_loss: 1.6651 - val_accuracy: 0.7571\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:22 - loss: 0.1805 - accuracy: 0.93 - ETA: 2:17 - loss: 0.2089 - accuracy: 0.92 - ETA: 2:19 - loss: 0.2070 - accuracy: 0.91 - ETA: 2:16 - loss: 0.2232 - accuracy: 0.91 - ETA: 2:14 - loss: 0.2364 - accuracy: 0.91 - ETA: 2:12 - loss: 0.2270 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2518 - accuracy: 0.90 - ETA: 2:10 - loss: 0.2594 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2591 - accuracy: 0.90 - ETA: 2:08 - loss: 0.2518 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2444 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2464 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2531 - accuracy: 0.90 - ETA: 2:06 - loss: 0.2557 - accuracy: 0.90 - ETA: 2:05 - loss: 0.2564 - accuracy: 0.90 - ETA: 2:03 - loss: 0.2463 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2446 - accuracy: 0.90 - ETA: 2:01 - loss: 0.2461 - accuracy: 0.90 - ETA: 2:00 - loss: 0.2474 - accuracy: 0.90 - ETA: 1:59 - loss: 0.2442 - accuracy: 0.90 - ETA: 1:58 - loss: 0.2432 - accuracy: 0.90 - ETA: 1:57 - loss: 0.2534 - accuracy: 0.90 - ETA: 1:56 - loss: 0.2523 - accuracy: 0.90 - ETA: 1:55 - loss: 0.2504 - accuracy: 0.90 - ETA: 1:54 - loss: 0.2581 - accuracy: 0.90 - ETA: 1:54 - loss: 0.2592 - accuracy: 0.90 - ETA: 1:52 - loss: 0.2601 - accuracy: 0.90 - ETA: 1:52 - loss: 0.2601 - accuracy: 0.90 - ETA: 1:51 - loss: 0.2571 - accuracy: 0.90 - ETA: 1:50 - loss: 0.2554 - accuracy: 0.90 - ETA: 1:50 - loss: 0.2557 - accuracy: 0.90 - ETA: 1:49 - loss: 0.2559 - accuracy: 0.90 - ETA: 1:48 - loss: 0.2590 - accuracy: 0.90 - ETA: 1:47 - loss: 0.2617 - accuracy: 0.90 - ETA: 1:46 - loss: 0.2600 - accuracy: 0.90 - ETA: 1:45 - loss: 0.2585 - accuracy: 0.90 - ETA: 1:44 - loss: 0.2574 - accuracy: 0.90 - ETA: 1:43 - loss: 0.2585 - accuracy: 0.90 - ETA: 1:42 - loss: 0.2560 - accuracy: 0.90 - ETA: 1:41 - loss: 0.2583 - accuracy: 0.90 - ETA: 1:40 - loss: 0.2571 - accuracy: 0.90 - ETA: 1:39 - loss: 0.2542 - accuracy: 0.90 - ETA: 1:38 - loss: 0.2524 - accuracy: 0.90 - ETA: 1:37 - loss: 0.2553 - accuracy: 0.90 - ETA: 1:36 - loss: 0.2548 - accuracy: 0.90 - ETA: 1:35 - loss: 0.2533 - accuracy: 0.90 - ETA: 1:35 - loss: 0.2562 - accuracy: 0.90 - ETA: 1:34 - loss: 0.2550 - accuracy: 0.90 - ETA: 1:33 - loss: 0.2537 - accuracy: 0.90 - ETA: 1:32 - loss: 0.2563 - accuracy: 0.90 - ETA: 1:31 - loss: 0.2556 - accuracy: 0.90 - ETA: 1:30 - loss: 0.2547 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2546 - accuracy: 0.90 - ETA: 1:28 - loss: 0.2544 - accuracy: 0.90 - ETA: 1:27 - loss: 0.2551 - accuracy: 0.90 - ETA: 1:26 - loss: 0.2543 - accuracy: 0.90 - ETA: 1:25 - loss: 0.2549 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2551 - accuracy: 0.90 - ETA: 1:23 - loss: 0.2568 - accuracy: 0.90 - ETA: 1:23 - loss: 0.2582 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2561 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2553 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2547 - accuracy: 0.90 - ETA: 1:19 - loss: 0.2534 - accuracy: 0.90 - ETA: 1:18 - loss: 0.2541 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2544 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2552 - accuracy: 0.90 - ETA: 1:16 - loss: 0.2554 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2551 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2549 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2544 - accuracy: 0.90 - ETA: 1:12 - loss: 0.2551 - accuracy: 0.90 - ETA: 1:11 - loss: 0.2542 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2548 - accuracy: 0.90 - ETA: 1:09 - loss: 0.2552 - accuracy: 0.90 - ETA: 1:08 - loss: 0.2542 - accuracy: 0.90 - ETA: 1:07 - loss: 0.2558 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2567 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2565 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2575 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2573 - accuracy: 0.90 - ETA: 1:03 - loss: 0.2569 - accuracy: 0.90 - ETA: 1:02 - loss: 0.2559 - accuracy: 0.90 - ETA: 1:01 - loss: 0.2569 - accuracy: 0.90 - ETA: 1:00 - loss: 0.2567 - accuracy: 0.90 - ETA: 59s - loss: 0.2563 - accuracy: 0.9038 - ETA: 58s - loss: 0.2559 - accuracy: 0.904 - ETA: 57s - loss: 0.2557 - accuracy: 0.904 - ETA: 56s - loss: 0.2552 - accuracy: 0.904 - ETA: 56s - loss: 0.2552 - accuracy: 0.904 - ETA: 55s - loss: 0.2549 - accuracy: 0.904 - ETA: 54s - loss: 0.2554 - accuracy: 0.904 - ETA: 53s - loss: 0.2557 - accuracy: 0.904 - ETA: 52s - loss: 0.2549 - accuracy: 0.904 - ETA: 51s - loss: 0.2549 - accuracy: 0.904 - ETA: 50s - loss: 0.2558 - accuracy: 0.904 - ETA: 49s - loss: 0.2566 - accuracy: 0.904 - ETA: 48s - loss: 0.2555 - accuracy: 0.904 - ETA: 47s - loss: 0.2568 - accuracy: 0.904 - ETA: 46s - loss: 0.2577 - accuracy: 0.903 - ETA: 46s - loss: 0.2572 - accuracy: 0.904 - ETA: 45s - loss: 0.2564 - accuracy: 0.904 - ETA: 44s - loss: 0.2557 - accuracy: 0.904 - ETA: 43s - loss: 0.2547 - accuracy: 0.904 - ETA: 42s - loss: 0.2545 - accuracy: 0.904 - ETA: 41s - loss: 0.2543 - accuracy: 0.904 - ETA: 40s - loss: 0.2548 - accuracy: 0.904 - ETA: 39s - loss: 0.2561 - accuracy: 0.904 - ETA: 38s - loss: 0.2561 - accuracy: 0.904 - ETA: 37s - loss: 0.2557 - accuracy: 0.904 - ETA: 36s - loss: 0.2561 - accuracy: 0.904 - ETA: 35s - loss: 0.2565 - accuracy: 0.904 - ETA: 34s - loss: 0.2569 - accuracy: 0.904 - ETA: 33s - loss: 0.2567 - accuracy: 0.904 - ETA: 32s - loss: 0.2564 - accuracy: 0.904 - ETA: 32s - loss: 0.2556 - accuracy: 0.904 - ETA: 31s - loss: 0.2560 - accuracy: 0.904 - ETA: 30s - loss: 0.2560 - accuracy: 0.904 - ETA: 29s - loss: 0.2553 - accuracy: 0.904 - ETA: 28s - loss: 0.2548 - accuracy: 0.904 - ETA: 27s - loss: 0.2544 - accuracy: 0.905 - ETA: 26s - loss: 0.2540 - accuracy: 0.905 - ETA: 25s - loss: 0.2539 - accuracy: 0.905 - ETA: 24s - loss: 0.2534 - accuracy: 0.905 - ETA: 23s - loss: 0.2543 - accuracy: 0.905 - ETA: 22s - loss: 0.2544 - accuracy: 0.905 - ETA: 21s - loss: 0.2543 - accuracy: 0.905 - ETA: 21s - loss: 0.2544 - accuracy: 0.905 - ETA: 20s - loss: 0.2544 - accuracy: 0.905 - ETA: 19s - loss: 0.2552 - accuracy: 0.905 - ETA: 18s - loss: 0.2548 - accuracy: 0.905 - ETA: 17s - loss: 0.2549 - accuracy: 0.905 - ETA: 16s - loss: 0.2546 - accuracy: 0.905 - ETA: 15s - loss: 0.2546 - accuracy: 0.905 - ETA: 14s - loss: 0.2545 - accuracy: 0.905 - ETA: 13s - loss: 0.2550 - accuracy: 0.905 - ETA: 12s - loss: 0.2544 - accuracy: 0.905 - ETA: 11s - loss: 0.2547 - accuracy: 0.905 - ETA: 10s - loss: 0.2552 - accuracy: 0.905 - ETA: 10s - loss: 0.2546 - accuracy: 0.905 - ETA: 9s - loss: 0.2549 - accuracy: 0.905 - ETA: 8s - loss: 0.2555 - accuracy: 0.90 - ETA: 7s - loss: 0.2554 - accuracy: 0.90 - ETA: 6s - loss: 0.2550 - accuracy: 0.90 - ETA: 5s - loss: 0.2554 - accuracy: 0.90 - ETA: 4s - loss: 0.2554 - accuracy: 0.90 - ETA: 3s - loss: 0.2548 - accuracy: 0.90 - ETA: 2s - loss: 0.2549 - accuracy: 0.90 - ETA: 1s - loss: 0.2554 - accuracy: 0.90 - ETA: 0s - loss: 0.2559 - accuracy: 0.90 - 150s 8ms/step - loss: 0.2560 - accuracy: 0.9048 - val_loss: 1.6919 - val_accuracy: 0.7577\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 0.2977 - accuracy: 0.89 - ETA: 2:22 - loss: 0.2501 - accuracy: 0.91 - ETA: 2:18 - loss: 0.2573 - accuracy: 0.91 - ETA: 2:16 - loss: 0.2374 - accuracy: 0.91 - ETA: 2:18 - loss: 0.2191 - accuracy: 0.92 - ETA: 2:17 - loss: 0.2183 - accuracy: 0.92 - ETA: 2:15 - loss: 0.2312 - accuracy: 0.91 - ETA: 2:13 - loss: 0.2327 - accuracy: 0.91 - ETA: 2:12 - loss: 0.2437 - accuracy: 0.91 - ETA: 2:10 - loss: 0.2460 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2451 - accuracy: 0.90 - ETA: 2:08 - loss: 0.2401 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2404 - accuracy: 0.90 - ETA: 2:05 - loss: 0.2367 - accuracy: 0.90 - ETA: 2:04 - loss: 0.2340 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2341 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2360 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2376 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2338 - accuracy: 0.91 - ETA: 2:00 - loss: 0.2317 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2350 - accuracy: 0.91 - ETA: 1:58 - loss: 0.2382 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2432 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2430 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2402 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2418 - accuracy: 0.91 - ETA: 1:53 - loss: 0.2407 - accuracy: 0.91 - ETA: 1:53 - loss: 0.2387 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2366 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2395 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2408 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2404 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2422 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2425 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2433 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2419 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2418 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2413 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2428 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2403 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2435 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2448 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2482 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2485 - accuracy: 0.90 - ETA: 1:37 - loss: 0.2477 - accuracy: 0.90 - ETA: 1:36 - loss: 0.2472 - accuracy: 0.90 - ETA: 1:35 - loss: 0.2479 - accuracy: 0.90 - ETA: 1:34 - loss: 0.2510 - accuracy: 0.90 - ETA: 1:33 - loss: 0.2502 - accuracy: 0.90 - ETA: 1:32 - loss: 0.2511 - accuracy: 0.90 - ETA: 1:32 - loss: 0.2498 - accuracy: 0.90 - ETA: 1:31 - loss: 0.2496 - accuracy: 0.90 - ETA: 1:30 - loss: 0.2497 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2489 - accuracy: 0.90 - ETA: 1:28 - loss: 0.2504 - accuracy: 0.90 - ETA: 1:27 - loss: 0.2525 - accuracy: 0.90 - ETA: 1:26 - loss: 0.2521 - accuracy: 0.90 - ETA: 1:25 - loss: 0.2530 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2522 - accuracy: 0.90 - ETA: 1:23 - loss: 0.2527 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2546 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2547 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2533 - accuracy: 0.90 - ETA: 1:19 - loss: 0.2539 - accuracy: 0.90 - ETA: 1:18 - loss: 0.2544 - accuracy: 0.90 - ETA: 1:18 - loss: 0.2551 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2543 - accuracy: 0.90 - ETA: 1:16 - loss: 0.2532 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2532 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2542 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2540 - accuracy: 0.90 - ETA: 1:12 - loss: 0.2547 - accuracy: 0.90 - ETA: 1:11 - loss: 0.2545 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2539 - accuracy: 0.90 - ETA: 1:09 - loss: 0.2548 - accuracy: 0.90 - ETA: 1:08 - loss: 0.2550 - accuracy: 0.90 - ETA: 1:07 - loss: 0.2550 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2551 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2558 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2559 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2560 - accuracy: 0.90 - ETA: 1:03 - loss: 0.2558 - accuracy: 0.90 - ETA: 1:02 - loss: 0.2550 - accuracy: 0.90 - ETA: 1:01 - loss: 0.2554 - accuracy: 0.90 - ETA: 1:00 - loss: 0.2571 - accuracy: 0.90 - ETA: 59s - loss: 0.2570 - accuracy: 0.9061 - ETA: 58s - loss: 0.2575 - accuracy: 0.905 - ETA: 57s - loss: 0.2570 - accuracy: 0.906 - ETA: 56s - loss: 0.2567 - accuracy: 0.906 - ETA: 55s - loss: 0.2560 - accuracy: 0.906 - ETA: 54s - loss: 0.2550 - accuracy: 0.906 - ETA: 53s - loss: 0.2548 - accuracy: 0.906 - ETA: 53s - loss: 0.2544 - accuracy: 0.906 - ETA: 52s - loss: 0.2544 - accuracy: 0.906 - ETA: 51s - loss: 0.2545 - accuracy: 0.906 - ETA: 50s - loss: 0.2540 - accuracy: 0.907 - ETA: 49s - loss: 0.2536 - accuracy: 0.907 - ETA: 48s - loss: 0.2538 - accuracy: 0.907 - ETA: 47s - loss: 0.2536 - accuracy: 0.907 - ETA: 46s - loss: 0.2541 - accuracy: 0.907 - ETA: 45s - loss: 0.2544 - accuracy: 0.907 - ETA: 44s - loss: 0.2542 - accuracy: 0.907 - ETA: 43s - loss: 0.2544 - accuracy: 0.907 - ETA: 42s - loss: 0.2538 - accuracy: 0.907 - ETA: 41s - loss: 0.2534 - accuracy: 0.907 - ETA: 41s - loss: 0.2546 - accuracy: 0.907 - ETA: 40s - loss: 0.2548 - accuracy: 0.907 - ETA: 39s - loss: 0.2556 - accuracy: 0.906 - ETA: 38s - loss: 0.2562 - accuracy: 0.906 - ETA: 37s - loss: 0.2560 - accuracy: 0.906 - ETA: 36s - loss: 0.2555 - accuracy: 0.907 - ETA: 35s - loss: 0.2564 - accuracy: 0.906 - ETA: 34s - loss: 0.2564 - accuracy: 0.906 - ETA: 33s - loss: 0.2568 - accuracy: 0.906 - ETA: 32s - loss: 0.2571 - accuracy: 0.906 - ETA: 31s - loss: 0.2571 - accuracy: 0.906 - ETA: 30s - loss: 0.2569 - accuracy: 0.906 - ETA: 30s - loss: 0.2572 - accuracy: 0.906 - ETA: 29s - loss: 0.2576 - accuracy: 0.906 - ETA: 28s - loss: 0.2566 - accuracy: 0.906 - ETA: 27s - loss: 0.2565 - accuracy: 0.906 - ETA: 26s - loss: 0.2555 - accuracy: 0.907 - ETA: 25s - loss: 0.2557 - accuracy: 0.907 - ETA: 24s - loss: 0.2550 - accuracy: 0.907 - ETA: 23s - loss: 0.2549 - accuracy: 0.907 - ETA: 22s - loss: 0.2550 - accuracy: 0.907 - ETA: 21s - loss: 0.2546 - accuracy: 0.907 - ETA: 20s - loss: 0.2547 - accuracy: 0.907 - ETA: 20s - loss: 0.2540 - accuracy: 0.908 - ETA: 19s - loss: 0.2536 - accuracy: 0.908 - ETA: 18s - loss: 0.2537 - accuracy: 0.908 - ETA: 17s - loss: 0.2526 - accuracy: 0.908 - ETA: 16s - loss: 0.2530 - accuracy: 0.908 - ETA: 15s - loss: 0.2526 - accuracy: 0.908 - ETA: 14s - loss: 0.2533 - accuracy: 0.908 - ETA: 13s - loss: 0.2537 - accuracy: 0.908 - ETA: 12s - loss: 0.2549 - accuracy: 0.907 - ETA: 11s - loss: 0.2555 - accuracy: 0.907 - ETA: 10s - loss: 0.2558 - accuracy: 0.907 - ETA: 9s - loss: 0.2552 - accuracy: 0.907 - ETA: 9s - loss: 0.2554 - accuracy: 0.90 - ETA: 8s - loss: 0.2554 - accuracy: 0.90 - ETA: 7s - loss: 0.2550 - accuracy: 0.90 - ETA: 6s - loss: 0.2546 - accuracy: 0.90 - ETA: 5s - loss: 0.2555 - accuracy: 0.90 - ETA: 4s - loss: 0.2555 - accuracy: 0.90 - ETA: 3s - loss: 0.2549 - accuracy: 0.90 - ETA: 2s - loss: 0.2541 - accuracy: 0.90 - ETA: 1s - loss: 0.2543 - accuracy: 0.90 - ETA: 0s - loss: 0.2547 - accuracy: 0.90 - 149s 8ms/step - loss: 0.2545 - accuracy: 0.9077 - val_loss: 1.6614 - val_accuracy: 0.7556\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:12 - loss: 0.2742 - accuracy: 0.89 - ETA: 2:11 - loss: 0.2246 - accuracy: 0.91 - ETA: 2:12 - loss: 0.2979 - accuracy: 0.88 - ETA: 2:10 - loss: 0.2577 - accuracy: 0.89 - ETA: 2:10 - loss: 0.2777 - accuracy: 0.89 - ETA: 2:08 - loss: 0.2606 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2604 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2625 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2633 - accuracy: 0.89 - ETA: 2:06 - loss: 0.2598 - accuracy: 0.90 - ETA: 2:05 - loss: 0.2540 - accuracy: 0.90 - ETA: 2:04 - loss: 0.2543 - accuracy: 0.90 - ETA: 2:03 - loss: 0.2434 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2397 - accuracy: 0.90 - ETA: 2:01 - loss: 0.2362 - accuracy: 0.90 - ETA: 2:01 - loss: 0.2434 - accuracy: 0.90 - ETA: 2:01 - loss: 0.2434 - accuracy: 0.90 - ETA: 2:00 - loss: 0.2401 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2355 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2354 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2382 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2388 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2435 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2415 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2460 - accuracy: 0.91 - ETA: 1:53 - loss: 0.2450 - accuracy: 0.91 - ETA: 1:53 - loss: 0.2452 - accuracy: 0.90 - ETA: 1:52 - loss: 0.2415 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2418 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2412 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2425 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2403 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2414 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2414 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2425 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2436 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2434 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2427 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2448 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2446 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2430 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2434 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2432 - accuracy: 0.91 - ETA: 1:37 - loss: 0.2433 - accuracy: 0.91 - ETA: 1:36 - loss: 0.2433 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2418 - accuracy: 0.91 - ETA: 1:34 - loss: 0.2450 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2462 - accuracy: 0.91 - ETA: 1:32 - loss: 0.2486 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2497 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2506 - accuracy: 0.90 - ETA: 1:30 - loss: 0.2506 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2508 - accuracy: 0.90 - ETA: 1:28 - loss: 0.2501 - accuracy: 0.90 - ETA: 1:27 - loss: 0.2491 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2483 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2491 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2476 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2464 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2475 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2473 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2472 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2464 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2457 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2442 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2435 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2425 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2425 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2424 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2419 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2421 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2410 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2410 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2413 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2412 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2426 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2425 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2421 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2418 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2426 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2425 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2434 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2445 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2458 - accuracy: 0.91 - ETA: 59s - loss: 0.2460 - accuracy: 0.9101 - ETA: 58s - loss: 0.2460 - accuracy: 0.910 - ETA: 58s - loss: 0.2463 - accuracy: 0.910 - ETA: 57s - loss: 0.2466 - accuracy: 0.909 - ETA: 56s - loss: 0.2461 - accuracy: 0.910 - ETA: 55s - loss: 0.2461 - accuracy: 0.910 - ETA: 54s - loss: 0.2468 - accuracy: 0.910 - ETA: 53s - loss: 0.2470 - accuracy: 0.909 - ETA: 52s - loss: 0.2476 - accuracy: 0.909 - ETA: 51s - loss: 0.2474 - accuracy: 0.909 - ETA: 50s - loss: 0.2476 - accuracy: 0.909 - ETA: 49s - loss: 0.2478 - accuracy: 0.909 - ETA: 48s - loss: 0.2473 - accuracy: 0.909 - ETA: 48s - loss: 0.2488 - accuracy: 0.909 - ETA: 47s - loss: 0.2499 - accuracy: 0.908 - ETA: 46s - loss: 0.2513 - accuracy: 0.908 - ETA: 45s - loss: 0.2517 - accuracy: 0.908 - ETA: 44s - loss: 0.2529 - accuracy: 0.908 - ETA: 43s - loss: 0.2522 - accuracy: 0.908 - ETA: 42s - loss: 0.2517 - accuracy: 0.908 - ETA: 41s - loss: 0.2508 - accuracy: 0.908 - ETA: 40s - loss: 0.2505 - accuracy: 0.908 - ETA: 40s - loss: 0.2512 - accuracy: 0.908 - ETA: 39s - loss: 0.2515 - accuracy: 0.908 - ETA: 38s - loss: 0.2513 - accuracy: 0.908 - ETA: 37s - loss: 0.2509 - accuracy: 0.908 - ETA: 36s - loss: 0.2507 - accuracy: 0.908 - ETA: 35s - loss: 0.2500 - accuracy: 0.908 - ETA: 34s - loss: 0.2491 - accuracy: 0.909 - ETA: 33s - loss: 0.2500 - accuracy: 0.908 - ETA: 32s - loss: 0.2499 - accuracy: 0.908 - ETA: 31s - loss: 0.2495 - accuracy: 0.908 - ETA: 30s - loss: 0.2489 - accuracy: 0.908 - ETA: 29s - loss: 0.2481 - accuracy: 0.909 - ETA: 29s - loss: 0.2485 - accuracy: 0.908 - ETA: 28s - loss: 0.2483 - accuracy: 0.908 - ETA: 27s - loss: 0.2481 - accuracy: 0.909 - ETA: 26s - loss: 0.2479 - accuracy: 0.909 - ETA: 25s - loss: 0.2472 - accuracy: 0.909 - ETA: 24s - loss: 0.2472 - accuracy: 0.909 - ETA: 23s - loss: 0.2470 - accuracy: 0.909 - ETA: 22s - loss: 0.2472 - accuracy: 0.909 - ETA: 21s - loss: 0.2474 - accuracy: 0.909 - ETA: 20s - loss: 0.2481 - accuracy: 0.908 - ETA: 19s - loss: 0.2477 - accuracy: 0.909 - ETA: 19s - loss: 0.2488 - accuracy: 0.909 - ETA: 18s - loss: 0.2489 - accuracy: 0.909 - ETA: 17s - loss: 0.2482 - accuracy: 0.909 - ETA: 16s - loss: 0.2486 - accuracy: 0.909 - ETA: 15s - loss: 0.2486 - accuracy: 0.909 - ETA: 14s - loss: 0.2482 - accuracy: 0.909 - ETA: 13s - loss: 0.2482 - accuracy: 0.909 - ETA: 12s - loss: 0.2477 - accuracy: 0.909 - ETA: 11s - loss: 0.2474 - accuracy: 0.909 - ETA: 10s - loss: 0.2473 - accuracy: 0.909 - ETA: 9s - loss: 0.2469 - accuracy: 0.909 - ETA: 9s - loss: 0.2468 - accuracy: 0.90 - ETA: 8s - loss: 0.2471 - accuracy: 0.90 - ETA: 7s - loss: 0.2475 - accuracy: 0.90 - ETA: 6s - loss: 0.2477 - accuracy: 0.90 - ETA: 5s - loss: 0.2472 - accuracy: 0.90 - ETA: 4s - loss: 0.2484 - accuracy: 0.90 - ETA: 3s - loss: 0.2484 - accuracy: 0.90 - ETA: 2s - loss: 0.2484 - accuracy: 0.90 - ETA: 1s - loss: 0.2478 - accuracy: 0.90 - ETA: 0s - loss: 0.2483 - accuracy: 0.90 - 149s 8ms/step - loss: 0.2476 - accuracy: 0.9095 - val_loss: 1.6993 - val_accuracy: 0.7594\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:21 - loss: 0.2966 - accuracy: 0.91 - ETA: 2:14 - loss: 0.2847 - accuracy: 0.90 - ETA: 2:14 - loss: 0.2799 - accuracy: 0.90 - ETA: 2:13 - loss: 0.2743 - accuracy: 0.89 - ETA: 2:12 - loss: 0.2673 - accuracy: 0.89 - ETA: 2:10 - loss: 0.2621 - accuracy: 0.89 - ETA: 2:09 - loss: 0.2596 - accuracy: 0.89 - ETA: 2:09 - loss: 0.2499 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2456 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2509 - accuracy: 0.90 - ETA: 2:08 - loss: 0.2489 - accuracy: 0.90 - ETA: 2:08 - loss: 0.2560 - accuracy: 0.90 - ETA: 2:08 - loss: 0.2526 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2484 - accuracy: 0.90 - ETA: 2:05 - loss: 0.2467 - accuracy: 0.90 - ETA: 2:04 - loss: 0.2503 - accuracy: 0.90 - ETA: 2:03 - loss: 0.2592 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2587 - accuracy: 0.90 - ETA: 2:01 - loss: 0.2540 - accuracy: 0.90 - ETA: 2:00 - loss: 0.2514 - accuracy: 0.90 - ETA: 1:59 - loss: 0.2457 - accuracy: 0.90 - ETA: 1:58 - loss: 0.2504 - accuracy: 0.90 - ETA: 1:56 - loss: 0.2503 - accuracy: 0.90 - ETA: 1:55 - loss: 0.2489 - accuracy: 0.90 - ETA: 1:54 - loss: 0.2510 - accuracy: 0.90 - ETA: 1:53 - loss: 0.2484 - accuracy: 0.90 - ETA: 1:52 - loss: 0.2490 - accuracy: 0.90 - ETA: 1:51 - loss: 0.2524 - accuracy: 0.90 - ETA: 1:51 - loss: 0.2557 - accuracy: 0.90 - ETA: 1:50 - loss: 0.2556 - accuracy: 0.90 - ETA: 1:49 - loss: 0.2557 - accuracy: 0.90 - ETA: 1:48 - loss: 0.2560 - accuracy: 0.90 - ETA: 1:47 - loss: 0.2581 - accuracy: 0.90 - ETA: 1:46 - loss: 0.2567 - accuracy: 0.90 - ETA: 1:45 - loss: 0.2555 - accuracy: 0.90 - ETA: 1:44 - loss: 0.2559 - accuracy: 0.90 - ETA: 1:43 - loss: 0.2568 - accuracy: 0.90 - ETA: 1:42 - loss: 0.2605 - accuracy: 0.90 - ETA: 1:41 - loss: 0.2620 - accuracy: 0.90 - ETA: 1:41 - loss: 0.2637 - accuracy: 0.90 - ETA: 1:40 - loss: 0.2646 - accuracy: 0.90 - ETA: 1:39 - loss: 0.2632 - accuracy: 0.90 - ETA: 1:38 - loss: 0.2630 - accuracy: 0.90 - ETA: 1:37 - loss: 0.2599 - accuracy: 0.90 - ETA: 1:36 - loss: 0.2587 - accuracy: 0.90 - ETA: 1:35 - loss: 0.2578 - accuracy: 0.90 - ETA: 1:34 - loss: 0.2563 - accuracy: 0.90 - ETA: 1:33 - loss: 0.2556 - accuracy: 0.90 - ETA: 1:32 - loss: 0.2538 - accuracy: 0.90 - ETA: 1:31 - loss: 0.2534 - accuracy: 0.90 - ETA: 1:30 - loss: 0.2528 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2515 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2545 - accuracy: 0.90 - ETA: 1:28 - loss: 0.2543 - accuracy: 0.90 - ETA: 1:27 - loss: 0.2544 - accuracy: 0.90 - ETA: 1:26 - loss: 0.2539 - accuracy: 0.90 - ETA: 1:25 - loss: 0.2550 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2545 - accuracy: 0.90 - ETA: 1:23 - loss: 0.2555 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2560 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2571 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2574 - accuracy: 0.90 - ETA: 1:19 - loss: 0.2558 - accuracy: 0.90 - ETA: 1:18 - loss: 0.2547 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2558 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2570 - accuracy: 0.90 - ETA: 1:16 - loss: 0.2560 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2550 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2545 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2541 - accuracy: 0.90 - ETA: 1:12 - loss: 0.2536 - accuracy: 0.90 - ETA: 1:11 - loss: 0.2528 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2524 - accuracy: 0.90 - ETA: 1:09 - loss: 0.2516 - accuracy: 0.90 - ETA: 1:08 - loss: 0.2508 - accuracy: 0.90 - ETA: 1:07 - loss: 0.2501 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2486 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2492 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2501 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2506 - accuracy: 0.90 - ETA: 1:03 - loss: 0.2513 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2514 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2522 - accuracy: 0.90 - ETA: 1:01 - loss: 0.2516 - accuracy: 0.90 - ETA: 1:00 - loss: 0.2513 - accuracy: 0.90 - ETA: 59s - loss: 0.2513 - accuracy: 0.9098 - ETA: 58s - loss: 0.2513 - accuracy: 0.909 - ETA: 58s - loss: 0.2515 - accuracy: 0.909 - ETA: 57s - loss: 0.2511 - accuracy: 0.909 - ETA: 56s - loss: 0.2504 - accuracy: 0.909 - ETA: 55s - loss: 0.2497 - accuracy: 0.910 - ETA: 54s - loss: 0.2495 - accuracy: 0.910 - ETA: 53s - loss: 0.2485 - accuracy: 0.910 - ETA: 52s - loss: 0.2486 - accuracy: 0.910 - ETA: 51s - loss: 0.2499 - accuracy: 0.910 - ETA: 50s - loss: 0.2493 - accuracy: 0.910 - ETA: 49s - loss: 0.2505 - accuracy: 0.910 - ETA: 48s - loss: 0.2501 - accuracy: 0.910 - ETA: 47s - loss: 0.2498 - accuracy: 0.910 - ETA: 46s - loss: 0.2493 - accuracy: 0.910 - ETA: 46s - loss: 0.2497 - accuracy: 0.910 - ETA: 45s - loss: 0.2505 - accuracy: 0.910 - ETA: 44s - loss: 0.2501 - accuracy: 0.910 - ETA: 43s - loss: 0.2509 - accuracy: 0.910 - ETA: 42s - loss: 0.2505 - accuracy: 0.910 - ETA: 41s - loss: 0.2505 - accuracy: 0.910 - ETA: 40s - loss: 0.2503 - accuracy: 0.910 - ETA: 39s - loss: 0.2514 - accuracy: 0.910 - ETA: 38s - loss: 0.2509 - accuracy: 0.910 - ETA: 37s - loss: 0.2517 - accuracy: 0.910 - ETA: 36s - loss: 0.2510 - accuracy: 0.910 - ETA: 35s - loss: 0.2500 - accuracy: 0.911 - ETA: 34s - loss: 0.2504 - accuracy: 0.911 - ETA: 33s - loss: 0.2505 - accuracy: 0.910 - ETA: 32s - loss: 0.2510 - accuracy: 0.910 - ETA: 32s - loss: 0.2505 - accuracy: 0.911 - ETA: 31s - loss: 0.2498 - accuracy: 0.911 - ETA: 30s - loss: 0.2506 - accuracy: 0.911 - ETA: 29s - loss: 0.2501 - accuracy: 0.911 - ETA: 28s - loss: 0.2500 - accuracy: 0.911 - ETA: 27s - loss: 0.2501 - accuracy: 0.910 - ETA: 26s - loss: 0.2498 - accuracy: 0.910 - ETA: 25s - loss: 0.2499 - accuracy: 0.910 - ETA: 24s - loss: 0.2500 - accuracy: 0.910 - ETA: 23s - loss: 0.2499 - accuracy: 0.910 - ETA: 22s - loss: 0.2497 - accuracy: 0.910 - ETA: 21s - loss: 0.2489 - accuracy: 0.910 - ETA: 21s - loss: 0.2482 - accuracy: 0.911 - ETA: 20s - loss: 0.2485 - accuracy: 0.911 - ETA: 19s - loss: 0.2481 - accuracy: 0.911 - ETA: 18s - loss: 0.2480 - accuracy: 0.911 - ETA: 17s - loss: 0.2475 - accuracy: 0.911 - ETA: 16s - loss: 0.2481 - accuracy: 0.911 - ETA: 15s - loss: 0.2488 - accuracy: 0.911 - ETA: 14s - loss: 0.2490 - accuracy: 0.911 - ETA: 13s - loss: 0.2491 - accuracy: 0.911 - ETA: 12s - loss: 0.2491 - accuracy: 0.911 - ETA: 11s - loss: 0.2488 - accuracy: 0.911 - ETA: 10s - loss: 0.2490 - accuracy: 0.911 - ETA: 10s - loss: 0.2488 - accuracy: 0.911 - ETA: 9s - loss: 0.2488 - accuracy: 0.911 - ETA: 8s - loss: 0.2484 - accuracy: 0.91 - ETA: 7s - loss: 0.2485 - accuracy: 0.91 - ETA: 6s - loss: 0.2488 - accuracy: 0.91 - ETA: 5s - loss: 0.2488 - accuracy: 0.91 - ETA: 4s - loss: 0.2487 - accuracy: 0.91 - ETA: 3s - loss: 0.2486 - accuracy: 0.91 - ETA: 2s - loss: 0.2480 - accuracy: 0.91 - ETA: 1s - loss: 0.2480 - accuracy: 0.91 - ETA: 0s - loss: 0.2486 - accuracy: 0.91 - 151s 8ms/step - loss: 0.2487 - accuracy: 0.9108 - val_loss: 1.6940 - val_accuracy: 0.7590\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:15 - loss: 0.2467 - accuracy: 0.89 - ETA: 2:11 - loss: 0.2349 - accuracy: 0.90 - ETA: 2:10 - loss: 0.2181 - accuracy: 0.91 - ETA: 2:10 - loss: 0.2269 - accuracy: 0.90 - ETA: 2:12 - loss: 0.2397 - accuracy: 0.90 - ETA: 2:12 - loss: 0.2425 - accuracy: 0.90 - ETA: 2:11 - loss: 0.2536 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2381 - accuracy: 0.90 - ETA: 2:09 - loss: 0.2301 - accuracy: 0.90 - ETA: 2:07 - loss: 0.2197 - accuracy: 0.91 - ETA: 2:06 - loss: 0.2220 - accuracy: 0.91 - ETA: 2:05 - loss: 0.2307 - accuracy: 0.91 - ETA: 2:04 - loss: 0.2275 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2268 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2242 - accuracy: 0.91 - ETA: 2:02 - loss: 0.2320 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2355 - accuracy: 0.91 - ETA: 2:00 - loss: 0.2359 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2371 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2353 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2393 - accuracy: 0.91 - ETA: 1:58 - loss: 0.2447 - accuracy: 0.91 - ETA: 1:58 - loss: 0.2447 - accuracy: 0.90 - ETA: 1:57 - loss: 0.2411 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2439 - accuracy: 0.90 - ETA: 1:54 - loss: 0.2444 - accuracy: 0.90 - ETA: 1:53 - loss: 0.2443 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2446 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2410 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2414 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2446 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2482 - accuracy: 0.90 - ETA: 1:47 - loss: 0.2478 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2486 - accuracy: 0.90 - ETA: 1:45 - loss: 0.2502 - accuracy: 0.90 - ETA: 1:44 - loss: 0.2504 - accuracy: 0.90 - ETA: 1:43 - loss: 0.2511 - accuracy: 0.90 - ETA: 1:42 - loss: 0.2516 - accuracy: 0.90 - ETA: 1:41 - loss: 0.2534 - accuracy: 0.90 - ETA: 1:41 - loss: 0.2530 - accuracy: 0.90 - ETA: 1:40 - loss: 0.2528 - accuracy: 0.90 - ETA: 1:39 - loss: 0.2509 - accuracy: 0.90 - ETA: 1:38 - loss: 0.2521 - accuracy: 0.90 - ETA: 1:37 - loss: 0.2531 - accuracy: 0.90 - ETA: 1:36 - loss: 0.2528 - accuracy: 0.90 - ETA: 1:35 - loss: 0.2531 - accuracy: 0.90 - ETA: 1:34 - loss: 0.2525 - accuracy: 0.90 - ETA: 1:33 - loss: 0.2515 - accuracy: 0.90 - ETA: 1:32 - loss: 0.2510 - accuracy: 0.90 - ETA: 1:31 - loss: 0.2524 - accuracy: 0.90 - ETA: 1:30 - loss: 0.2535 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2528 - accuracy: 0.90 - ETA: 1:29 - loss: 0.2548 - accuracy: 0.90 - ETA: 1:28 - loss: 0.2534 - accuracy: 0.90 - ETA: 1:27 - loss: 0.2551 - accuracy: 0.90 - ETA: 1:26 - loss: 0.2546 - accuracy: 0.90 - ETA: 1:25 - loss: 0.2547 - accuracy: 0.90 - ETA: 1:24 - loss: 0.2565 - accuracy: 0.90 - ETA: 1:23 - loss: 0.2568 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2575 - accuracy: 0.90 - ETA: 1:22 - loss: 0.2553 - accuracy: 0.90 - ETA: 1:21 - loss: 0.2555 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2545 - accuracy: 0.90 - ETA: 1:19 - loss: 0.2538 - accuracy: 0.90 - ETA: 1:18 - loss: 0.2536 - accuracy: 0.90 - ETA: 1:17 - loss: 0.2525 - accuracy: 0.90 - ETA: 1:16 - loss: 0.2517 - accuracy: 0.90 - ETA: 1:15 - loss: 0.2513 - accuracy: 0.90 - ETA: 1:14 - loss: 0.2515 - accuracy: 0.90 - ETA: 1:13 - loss: 0.2518 - accuracy: 0.90 - ETA: 1:12 - loss: 0.2522 - accuracy: 0.90 - ETA: 1:11 - loss: 0.2526 - accuracy: 0.90 - ETA: 1:10 - loss: 0.2523 - accuracy: 0.90 - ETA: 1:09 - loss: 0.2512 - accuracy: 0.90 - ETA: 1:08 - loss: 0.2519 - accuracy: 0.90 - ETA: 1:08 - loss: 0.2521 - accuracy: 0.90 - ETA: 1:07 - loss: 0.2517 - accuracy: 0.90 - ETA: 1:06 - loss: 0.2509 - accuracy: 0.90 - ETA: 1:05 - loss: 0.2520 - accuracy: 0.90 - ETA: 1:04 - loss: 0.2524 - accuracy: 0.90 - ETA: 1:03 - loss: 0.2521 - accuracy: 0.90 - ETA: 1:02 - loss: 0.2507 - accuracy: 0.90 - ETA: 1:01 - loss: 0.2516 - accuracy: 0.90 - ETA: 1:00 - loss: 0.2499 - accuracy: 0.90 - ETA: 59s - loss: 0.2495 - accuracy: 0.9084 - ETA: 58s - loss: 0.2493 - accuracy: 0.908 - ETA: 57s - loss: 0.2501 - accuracy: 0.908 - ETA: 56s - loss: 0.2493 - accuracy: 0.908 - ETA: 55s - loss: 0.2491 - accuracy: 0.908 - ETA: 54s - loss: 0.2502 - accuracy: 0.908 - ETA: 54s - loss: 0.2488 - accuracy: 0.908 - ETA: 53s - loss: 0.2484 - accuracy: 0.908 - ETA: 52s - loss: 0.2481 - accuracy: 0.908 - ETA: 51s - loss: 0.2478 - accuracy: 0.908 - ETA: 50s - loss: 0.2468 - accuracy: 0.909 - ETA: 49s - loss: 0.2463 - accuracy: 0.909 - ETA: 48s - loss: 0.2460 - accuracy: 0.909 - ETA: 47s - loss: 0.2465 - accuracy: 0.909 - ETA: 46s - loss: 0.2470 - accuracy: 0.909 - ETA: 45s - loss: 0.2471 - accuracy: 0.909 - ETA: 45s - loss: 0.2470 - accuracy: 0.909 - ETA: 44s - loss: 0.2463 - accuracy: 0.909 - ETA: 43s - loss: 0.2459 - accuracy: 0.909 - ETA: 42s - loss: 0.2470 - accuracy: 0.909 - ETA: 41s - loss: 0.2468 - accuracy: 0.909 - ETA: 40s - loss: 0.2468 - accuracy: 0.909 - ETA: 39s - loss: 0.2462 - accuracy: 0.909 - ETA: 38s - loss: 0.2466 - accuracy: 0.909 - ETA: 37s - loss: 0.2467 - accuracy: 0.909 - ETA: 36s - loss: 0.2468 - accuracy: 0.909 - ETA: 35s - loss: 0.2468 - accuracy: 0.909 - ETA: 35s - loss: 0.2474 - accuracy: 0.909 - ETA: 34s - loss: 0.2492 - accuracy: 0.908 - ETA: 33s - loss: 0.2483 - accuracy: 0.908 - ETA: 32s - loss: 0.2486 - accuracy: 0.908 - ETA: 31s - loss: 0.2499 - accuracy: 0.908 - ETA: 30s - loss: 0.2492 - accuracy: 0.908 - ETA: 29s - loss: 0.2484 - accuracy: 0.909 - ETA: 28s - loss: 0.2480 - accuracy: 0.909 - ETA: 27s - loss: 0.2480 - accuracy: 0.909 - ETA: 26s - loss: 0.2484 - accuracy: 0.909 - ETA: 25s - loss: 0.2478 - accuracy: 0.909 - ETA: 25s - loss: 0.2485 - accuracy: 0.909 - ETA: 24s - loss: 0.2486 - accuracy: 0.909 - ETA: 23s - loss: 0.2487 - accuracy: 0.909 - ETA: 22s - loss: 0.2483 - accuracy: 0.909 - ETA: 21s - loss: 0.2487 - accuracy: 0.909 - ETA: 20s - loss: 0.2485 - accuracy: 0.909 - ETA: 19s - loss: 0.2482 - accuracy: 0.909 - ETA: 18s - loss: 0.2481 - accuracy: 0.909 - ETA: 17s - loss: 0.2481 - accuracy: 0.909 - ETA: 16s - loss: 0.2481 - accuracy: 0.909 - ETA: 16s - loss: 0.2481 - accuracy: 0.909 - ETA: 15s - loss: 0.2481 - accuracy: 0.909 - ETA: 14s - loss: 0.2484 - accuracy: 0.909 - ETA: 13s - loss: 0.2483 - accuracy: 0.909 - ETA: 12s - loss: 0.2481 - accuracy: 0.909 - ETA: 11s - loss: 0.2485 - accuracy: 0.909 - ETA: 10s - loss: 0.2484 - accuracy: 0.909 - ETA: 9s - loss: 0.2482 - accuracy: 0.909 - ETA: 8s - loss: 0.2484 - accuracy: 0.90 - ETA: 7s - loss: 0.2476 - accuracy: 0.90 - ETA: 7s - loss: 0.2481 - accuracy: 0.90 - ETA: 6s - loss: 0.2484 - accuracy: 0.90 - ETA: 5s - loss: 0.2482 - accuracy: 0.90 - ETA: 4s - loss: 0.2479 - accuracy: 0.90 - ETA: 3s - loss: 0.2490 - accuracy: 0.90 - ETA: 2s - loss: 0.2491 - accuracy: 0.90 - ETA: 1s - loss: 0.2494 - accuracy: 0.90 - ETA: 0s - loss: 0.2489 - accuracy: 0.90 - 147s 8ms/step - loss: 0.2489 - accuracy: 0.9097 - val_loss: 1.7108 - val_accuracy: 0.7592\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:26 - loss: 0.1567 - accuracy: 0.92 - ETA: 2:25 - loss: 0.1811 - accuracy: 0.93 - ETA: 2:20 - loss: 0.2017 - accuracy: 0.92 - ETA: 2:15 - loss: 0.1934 - accuracy: 0.93 - ETA: 2:12 - loss: 0.2209 - accuracy: 0.92 - ETA: 2:10 - loss: 0.2308 - accuracy: 0.92 - ETA: 2:09 - loss: 0.2371 - accuracy: 0.91 - ETA: 2:10 - loss: 0.2381 - accuracy: 0.91 - ETA: 2:08 - loss: 0.2464 - accuracy: 0.91 - ETA: 2:06 - loss: 0.2368 - accuracy: 0.91 - ETA: 2:05 - loss: 0.2379 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2271 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2292 - accuracy: 0.92 - ETA: 2:01 - loss: 0.2287 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2301 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2364 - accuracy: 0.91 - ETA: 1:58 - loss: 0.2354 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2359 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2374 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2369 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2438 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2487 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2514 - accuracy: 0.91 - ETA: 1:53 - loss: 0.2470 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2467 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2465 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2470 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2467 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2459 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2442 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2449 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2416 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2420 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2453 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2443 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2407 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2405 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2396 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2370 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2360 - accuracy: 0.91 - ETA: 1:37 - loss: 0.2364 - accuracy: 0.91 - ETA: 1:36 - loss: 0.2355 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2362 - accuracy: 0.91 - ETA: 1:34 - loss: 0.2341 - accuracy: 0.91 - ETA: 1:34 - loss: 0.2340 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2355 - accuracy: 0.91 - ETA: 1:32 - loss: 0.2362 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2389 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2381 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2359 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2344 - accuracy: 0.91 - ETA: 1:28 - loss: 0.2354 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2353 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2357 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2358 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2358 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2345 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2344 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2332 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2328 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2336 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2319 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2339 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2337 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2340 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2352 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2356 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2354 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2363 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2357 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2357 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2358 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2360 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2363 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2349 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2345 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2336 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2324 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2321 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2327 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2328 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2331 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2323 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2317 - accuracy: 0.91 - ETA: 59s - loss: 0.2317 - accuracy: 0.9161 - ETA: 58s - loss: 0.2320 - accuracy: 0.915 - ETA: 57s - loss: 0.2326 - accuracy: 0.915 - ETA: 56s - loss: 0.2323 - accuracy: 0.915 - ETA: 55s - loss: 0.2332 - accuracy: 0.915 - ETA: 54s - loss: 0.2328 - accuracy: 0.915 - ETA: 53s - loss: 0.2337 - accuracy: 0.915 - ETA: 53s - loss: 0.2331 - accuracy: 0.915 - ETA: 52s - loss: 0.2331 - accuracy: 0.915 - ETA: 51s - loss: 0.2333 - accuracy: 0.915 - ETA: 50s - loss: 0.2332 - accuracy: 0.915 - ETA: 49s - loss: 0.2327 - accuracy: 0.915 - ETA: 48s - loss: 0.2312 - accuracy: 0.915 - ETA: 47s - loss: 0.2327 - accuracy: 0.914 - ETA: 46s - loss: 0.2331 - accuracy: 0.914 - ETA: 45s - loss: 0.2337 - accuracy: 0.914 - ETA: 44s - loss: 0.2344 - accuracy: 0.914 - ETA: 43s - loss: 0.2342 - accuracy: 0.914 - ETA: 43s - loss: 0.2354 - accuracy: 0.913 - ETA: 42s - loss: 0.2359 - accuracy: 0.913 - ETA: 41s - loss: 0.2372 - accuracy: 0.912 - ETA: 40s - loss: 0.2377 - accuracy: 0.912 - ETA: 39s - loss: 0.2372 - accuracy: 0.913 - ETA: 38s - loss: 0.2378 - accuracy: 0.912 - ETA: 37s - loss: 0.2387 - accuracy: 0.912 - ETA: 36s - loss: 0.2386 - accuracy: 0.912 - ETA: 35s - loss: 0.2383 - accuracy: 0.912 - ETA: 35s - loss: 0.2375 - accuracy: 0.912 - ETA: 34s - loss: 0.2374 - accuracy: 0.912 - ETA: 33s - loss: 0.2379 - accuracy: 0.913 - ETA: 32s - loss: 0.2374 - accuracy: 0.913 - ETA: 31s - loss: 0.2377 - accuracy: 0.912 - ETA: 30s - loss: 0.2386 - accuracy: 0.912 - ETA: 29s - loss: 0.2404 - accuracy: 0.912 - ETA: 28s - loss: 0.2398 - accuracy: 0.912 - ETA: 27s - loss: 0.2403 - accuracy: 0.912 - ETA: 26s - loss: 0.2403 - accuracy: 0.912 - ETA: 26s - loss: 0.2403 - accuracy: 0.912 - ETA: 25s - loss: 0.2401 - accuracy: 0.912 - ETA: 24s - loss: 0.2399 - accuracy: 0.912 - ETA: 23s - loss: 0.2398 - accuracy: 0.912 - ETA: 22s - loss: 0.2395 - accuracy: 0.912 - ETA: 21s - loss: 0.2402 - accuracy: 0.912 - ETA: 20s - loss: 0.2397 - accuracy: 0.912 - ETA: 19s - loss: 0.2398 - accuracy: 0.912 - ETA: 18s - loss: 0.2397 - accuracy: 0.912 - ETA: 17s - loss: 0.2399 - accuracy: 0.912 - ETA: 17s - loss: 0.2393 - accuracy: 0.912 - ETA: 16s - loss: 0.2387 - accuracy: 0.913 - ETA: 15s - loss: 0.2384 - accuracy: 0.913 - ETA: 14s - loss: 0.2379 - accuracy: 0.913 - ETA: 13s - loss: 0.2371 - accuracy: 0.913 - ETA: 12s - loss: 0.2381 - accuracy: 0.913 - ETA: 11s - loss: 0.2381 - accuracy: 0.913 - ETA: 10s - loss: 0.2378 - accuracy: 0.913 - ETA: 9s - loss: 0.2377 - accuracy: 0.913 - ETA: 8s - loss: 0.2376 - accuracy: 0.91 - ETA: 8s - loss: 0.2377 - accuracy: 0.91 - ETA: 7s - loss: 0.2381 - accuracy: 0.91 - ETA: 6s - loss: 0.2381 - accuracy: 0.91 - ETA: 5s - loss: 0.2377 - accuracy: 0.91 - ETA: 4s - loss: 0.2383 - accuracy: 0.91 - ETA: 3s - loss: 0.2388 - accuracy: 0.91 - ETA: 2s - loss: 0.2400 - accuracy: 0.91 - ETA: 1s - loss: 0.2402 - accuracy: 0.91 - ETA: 0s - loss: 0.2398 - accuracy: 0.91 - 148s 8ms/step - loss: 0.2398 - accuracy: 0.9125 - val_loss: 1.7067 - val_accuracy: 0.7612\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:20 - loss: 0.2851 - accuracy: 0.90 - ETA: 2:15 - loss: 0.2594 - accuracy: 0.91 - ETA: 2:14 - loss: 0.2526 - accuracy: 0.90 - ETA: 2:12 - loss: 0.2267 - accuracy: 0.91 - ETA: 2:12 - loss: 0.2263 - accuracy: 0.90 - ETA: 2:10 - loss: 0.2275 - accuracy: 0.91 - ETA: 2:09 - loss: 0.2200 - accuracy: 0.91 - ETA: 2:08 - loss: 0.2248 - accuracy: 0.91 - ETA: 2:07 - loss: 0.2167 - accuracy: 0.91 - ETA: 2:06 - loss: 0.2156 - accuracy: 0.91 - ETA: 2:05 - loss: 0.2103 - accuracy: 0.91 - ETA: 2:04 - loss: 0.2109 - accuracy: 0.91 - ETA: 2:04 - loss: 0.2092 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2050 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2057 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2030 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2058 - accuracy: 0.91 - ETA: 2:00 - loss: 0.2021 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2065 - accuracy: 0.91 - ETA: 1:58 - loss: 0.2086 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2090 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2124 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2150 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2207 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2221 - accuracy: 0.91 - ETA: 1:53 - loss: 0.2215 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2212 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2240 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2232 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2209 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2211 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2175 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2196 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2199 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2215 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2260 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2261 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2260 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2276 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2292 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2278 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2302 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2298 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2300 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2297 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2294 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2288 - accuracy: 0.91 - ETA: 1:37 - loss: 0.2293 - accuracy: 0.91 - ETA: 1:36 - loss: 0.2291 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2298 - accuracy: 0.91 - ETA: 1:34 - loss: 0.2284 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2276 - accuracy: 0.91 - ETA: 1:32 - loss: 0.2267 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2284 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2285 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2275 - accuracy: 0.91 - ETA: 1:28 - loss: 0.2277 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2267 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2265 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2261 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2245 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2249 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2237 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2251 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2254 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2271 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2280 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2282 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2274 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2289 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2301 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2300 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2292 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2301 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2314 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2311 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2308 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2303 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2299 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2312 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2301 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2288 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2287 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2287 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2290 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2309 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2311 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2311 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2317 - accuracy: 0.91 - ETA: 59s - loss: 0.2320 - accuracy: 0.9112 - ETA: 58s - loss: 0.2319 - accuracy: 0.911 - ETA: 57s - loss: 0.2313 - accuracy: 0.911 - ETA: 56s - loss: 0.2319 - accuracy: 0.911 - ETA: 55s - loss: 0.2320 - accuracy: 0.911 - ETA: 54s - loss: 0.2323 - accuracy: 0.911 - ETA: 53s - loss: 0.2329 - accuracy: 0.911 - ETA: 52s - loss: 0.2320 - accuracy: 0.912 - ETA: 51s - loss: 0.2319 - accuracy: 0.912 - ETA: 50s - loss: 0.2323 - accuracy: 0.912 - ETA: 49s - loss: 0.2329 - accuracy: 0.912 - ETA: 48s - loss: 0.2341 - accuracy: 0.911 - ETA: 47s - loss: 0.2350 - accuracy: 0.911 - ETA: 46s - loss: 0.2349 - accuracy: 0.911 - ETA: 45s - loss: 0.2353 - accuracy: 0.911 - ETA: 44s - loss: 0.2351 - accuracy: 0.911 - ETA: 43s - loss: 0.2357 - accuracy: 0.911 - ETA: 42s - loss: 0.2356 - accuracy: 0.911 - ETA: 41s - loss: 0.2362 - accuracy: 0.910 - ETA: 40s - loss: 0.2353 - accuracy: 0.911 - ETA: 39s - loss: 0.2350 - accuracy: 0.911 - ETA: 38s - loss: 0.2348 - accuracy: 0.911 - ETA: 37s - loss: 0.2346 - accuracy: 0.911 - ETA: 36s - loss: 0.2339 - accuracy: 0.911 - ETA: 35s - loss: 0.2341 - accuracy: 0.911 - ETA: 34s - loss: 0.2343 - accuracy: 0.911 - ETA: 33s - loss: 0.2337 - accuracy: 0.911 - ETA: 32s - loss: 0.2333 - accuracy: 0.911 - ETA: 31s - loss: 0.2329 - accuracy: 0.911 - ETA: 30s - loss: 0.2317 - accuracy: 0.912 - ETA: 29s - loss: 0.2313 - accuracy: 0.912 - ETA: 28s - loss: 0.2309 - accuracy: 0.912 - ETA: 27s - loss: 0.2310 - accuracy: 0.912 - ETA: 26s - loss: 0.2316 - accuracy: 0.912 - ETA: 26s - loss: 0.2318 - accuracy: 0.912 - ETA: 25s - loss: 0.2314 - accuracy: 0.912 - ETA: 24s - loss: 0.2308 - accuracy: 0.912 - ETA: 23s - loss: 0.2316 - accuracy: 0.912 - ETA: 22s - loss: 0.2323 - accuracy: 0.912 - ETA: 21s - loss: 0.2319 - accuracy: 0.912 - ETA: 20s - loss: 0.2314 - accuracy: 0.912 - ETA: 19s - loss: 0.2312 - accuracy: 0.912 - ETA: 18s - loss: 0.2308 - accuracy: 0.912 - ETA: 17s - loss: 0.2314 - accuracy: 0.912 - ETA: 16s - loss: 0.2314 - accuracy: 0.912 - ETA: 15s - loss: 0.2319 - accuracy: 0.912 - ETA: 14s - loss: 0.2315 - accuracy: 0.912 - ETA: 13s - loss: 0.2307 - accuracy: 0.912 - ETA: 12s - loss: 0.2300 - accuracy: 0.912 - ETA: 11s - loss: 0.2309 - accuracy: 0.912 - ETA: 10s - loss: 0.2306 - accuracy: 0.913 - ETA: 9s - loss: 0.2307 - accuracy: 0.913 - ETA: 8s - loss: 0.2312 - accuracy: 0.91 - ETA: 7s - loss: 0.2319 - accuracy: 0.91 - ETA: 6s - loss: 0.2318 - accuracy: 0.91 - ETA: 5s - loss: 0.2311 - accuracy: 0.91 - ETA: 4s - loss: 0.2315 - accuracy: 0.91 - ETA: 3s - loss: 0.2318 - accuracy: 0.91 - ETA: 2s - loss: 0.2322 - accuracy: 0.91 - ETA: 1s - loss: 0.2324 - accuracy: 0.91 - ETA: 0s - loss: 0.2329 - accuracy: 0.91 - 157s 8ms/step - loss: 0.2333 - accuracy: 0.9123 - val_loss: 1.7067 - val_accuracy: 0.7621\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:41 - loss: 0.2574 - accuracy: 0.90 - ETA: 2:40 - loss: 0.2559 - accuracy: 0.90 - ETA: 2:37 - loss: 0.2362 - accuracy: 0.91 - ETA: 2:56 - loss: 0.2357 - accuracy: 0.91 - ETA: 2:59 - loss: 0.2246 - accuracy: 0.91 - ETA: 3:02 - loss: 0.2222 - accuracy: 0.91 - ETA: 3:10 - loss: 0.2159 - accuracy: 0.91 - ETA: 3:05 - loss: 0.2068 - accuracy: 0.92 - ETA: 3:01 - loss: 0.2043 - accuracy: 0.92 - ETA: 2:58 - loss: 0.2215 - accuracy: 0.91 - ETA: 2:53 - loss: 0.2203 - accuracy: 0.91 - ETA: 2:49 - loss: 0.2185 - accuracy: 0.91 - ETA: 2:46 - loss: 0.2249 - accuracy: 0.91 - ETA: 2:45 - loss: 0.2195 - accuracy: 0.91 - ETA: 2:43 - loss: 0.2238 - accuracy: 0.91 - ETA: 2:42 - loss: 0.2255 - accuracy: 0.91 - ETA: 2:40 - loss: 0.2235 - accuracy: 0.91 - ETA: 2:38 - loss: 0.2280 - accuracy: 0.91 - ETA: 2:37 - loss: 0.2282 - accuracy: 0.91 - ETA: 2:36 - loss: 0.2316 - accuracy: 0.91 - ETA: 2:36 - loss: 0.2322 - accuracy: 0.91 - ETA: 2:34 - loss: 0.2343 - accuracy: 0.91 - ETA: 2:32 - loss: 0.2328 - accuracy: 0.91 - ETA: 2:30 - loss: 0.2356 - accuracy: 0.91 - ETA: 2:29 - loss: 0.2328 - accuracy: 0.91 - ETA: 2:27 - loss: 0.2329 - accuracy: 0.91 - ETA: 2:25 - loss: 0.2353 - accuracy: 0.91 - ETA: 2:24 - loss: 0.2352 - accuracy: 0.91 - ETA: 2:24 - loss: 0.2314 - accuracy: 0.91 - ETA: 2:22 - loss: 0.2313 - accuracy: 0.91 - ETA: 2:21 - loss: 0.2288 - accuracy: 0.91 - ETA: 2:19 - loss: 0.2287 - accuracy: 0.91 - ETA: 2:18 - loss: 0.2290 - accuracy: 0.91 - ETA: 2:17 - loss: 0.2328 - accuracy: 0.91 - ETA: 2:18 - loss: 0.2306 - accuracy: 0.91 - ETA: 2:21 - loss: 0.2300 - accuracy: 0.91 - ETA: 2:20 - loss: 0.2318 - accuracy: 0.91 - ETA: 2:18 - loss: 0.2321 - accuracy: 0.91 - ETA: 2:17 - loss: 0.2339 - accuracy: 0.91 - ETA: 2:17 - loss: 0.2335 - accuracy: 0.91 - ETA: 2:16 - loss: 0.2335 - accuracy: 0.91 - ETA: 2:15 - loss: 0.2343 - accuracy: 0.91 - ETA: 2:13 - loss: 0.2347 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2371 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2365 - accuracy: 0.91 - ETA: 2:10 - loss: 0.2369 - accuracy: 0.91 - ETA: 2:08 - loss: 0.2384 - accuracy: 0.91 - ETA: 2:06 - loss: 0.2374 - accuracy: 0.91 - ETA: 2:05 - loss: 0.2384 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2395 - accuracy: 0.91 - ETA: 2:02 - loss: 0.2392 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2372 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2373 - accuracy: 0.91 - ETA: 1:58 - loss: 0.2357 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2350 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2366 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2351 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2355 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2356 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2349 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2363 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2349 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2331 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2319 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2321 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2321 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2325 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2326 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2325 - accuracy: 0.91 - ETA: 1:36 - loss: 0.2341 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2332 - accuracy: 0.91 - ETA: 1:34 - loss: 0.2322 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2305 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2306 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2333 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2327 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2336 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2332 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2329 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2333 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2332 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2329 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2322 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2314 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2305 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2299 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2290 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2295 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2298 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2300 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2295 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2308 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2315 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2303 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2305 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2304 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2302 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2298 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2295 - accuracy: 0.91 - ETA: 59s - loss: 0.2292 - accuracy: 0.9158 - ETA: 58s - loss: 0.2285 - accuracy: 0.916 - ETA: 57s - loss: 0.2287 - accuracy: 0.916 - ETA: 56s - loss: 0.2293 - accuracy: 0.915 - ETA: 55s - loss: 0.2297 - accuracy: 0.915 - ETA: 54s - loss: 0.2301 - accuracy: 0.915 - ETA: 52s - loss: 0.2306 - accuracy: 0.915 - ETA: 51s - loss: 0.2302 - accuracy: 0.915 - ETA: 50s - loss: 0.2305 - accuracy: 0.915 - ETA: 49s - loss: 0.2305 - accuracy: 0.915 - ETA: 48s - loss: 0.2305 - accuracy: 0.914 - ETA: 47s - loss: 0.2308 - accuracy: 0.914 - ETA: 46s - loss: 0.2305 - accuracy: 0.914 - ETA: 44s - loss: 0.2306 - accuracy: 0.915 - ETA: 43s - loss: 0.2306 - accuracy: 0.915 - ETA: 42s - loss: 0.2314 - accuracy: 0.914 - ETA: 41s - loss: 0.2317 - accuracy: 0.914 - ETA: 40s - loss: 0.2324 - accuracy: 0.914 - ETA: 38s - loss: 0.2320 - accuracy: 0.914 - ETA: 37s - loss: 0.2326 - accuracy: 0.914 - ETA: 36s - loss: 0.2338 - accuracy: 0.913 - ETA: 35s - loss: 0.2344 - accuracy: 0.913 - ETA: 34s - loss: 0.2346 - accuracy: 0.913 - ETA: 33s - loss: 0.2346 - accuracy: 0.913 - ETA: 31s - loss: 0.2353 - accuracy: 0.913 - ETA: 30s - loss: 0.2361 - accuracy: 0.913 - ETA: 29s - loss: 0.2367 - accuracy: 0.913 - ETA: 28s - loss: 0.2364 - accuracy: 0.913 - ETA: 27s - loss: 0.2359 - accuracy: 0.913 - ETA: 25s - loss: 0.2355 - accuracy: 0.913 - ETA: 24s - loss: 0.2356 - accuracy: 0.913 - ETA: 23s - loss: 0.2357 - accuracy: 0.913 - ETA: 22s - loss: 0.2353 - accuracy: 0.913 - ETA: 21s - loss: 0.2348 - accuracy: 0.913 - ETA: 20s - loss: 0.2347 - accuracy: 0.913 - ETA: 18s - loss: 0.2341 - accuracy: 0.914 - ETA: 17s - loss: 0.2344 - accuracy: 0.914 - ETA: 16s - loss: 0.2339 - accuracy: 0.914 - ETA: 15s - loss: 0.2344 - accuracy: 0.914 - ETA: 14s - loss: 0.2345 - accuracy: 0.913 - ETA: 13s - loss: 0.2341 - accuracy: 0.914 - ETA: 11s - loss: 0.2345 - accuracy: 0.914 - ETA: 10s - loss: 0.2348 - accuracy: 0.914 - ETA: 9s - loss: 0.2345 - accuracy: 0.914 - ETA: 8s - loss: 0.2343 - accuracy: 0.91 - ETA: 7s - loss: 0.2339 - accuracy: 0.91 - ETA: 5s - loss: 0.2333 - accuracy: 0.91 - ETA: 4s - loss: 0.2343 - accuracy: 0.91 - ETA: 3s - loss: 0.2344 - accuracy: 0.91 - ETA: 2s - loss: 0.2358 - accuracy: 0.91 - ETA: 1s - loss: 0.2360 - accuracy: 0.91 - 206s 11ms/step - loss: 0.2359 - accuracy: 0.9141 - val_loss: 1.6888 - val_accuracy: 0.7621\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:51 - loss: 0.2586 - accuracy: 0.89 - ETA: 2:47 - loss: 0.2337 - accuracy: 0.91 - ETA: 2:54 - loss: 0.2668 - accuracy: 0.91 - ETA: 2:49 - loss: 0.2670 - accuracy: 0.91 - ETA: 2:45 - loss: 0.2598 - accuracy: 0.90 - ETA: 2:41 - loss: 0.2317 - accuracy: 0.91 - ETA: 2:39 - loss: 0.2281 - accuracy: 0.91 - ETA: 2:39 - loss: 0.2348 - accuracy: 0.91 - ETA: 2:39 - loss: 0.2364 - accuracy: 0.91 - ETA: 2:38 - loss: 0.2328 - accuracy: 0.92 - ETA: 2:37 - loss: 0.2329 - accuracy: 0.91 - ETA: 2:37 - loss: 0.2477 - accuracy: 0.91 - ETA: 2:37 - loss: 0.2452 - accuracy: 0.91 - ETA: 2:35 - loss: 0.2451 - accuracy: 0.91 - ETA: 2:33 - loss: 0.2415 - accuracy: 0.91 - ETA: 2:32 - loss: 0.2441 - accuracy: 0.91 - ETA: 2:32 - loss: 0.2383 - accuracy: 0.91 - ETA: 2:33 - loss: 0.2330 - accuracy: 0.91 - ETA: 2:34 - loss: 0.2326 - accuracy: 0.91 - ETA: 2:33 - loss: 0.2349 - accuracy: 0.91 - ETA: 2:32 - loss: 0.2369 - accuracy: 0.91 - ETA: 2:30 - loss: 0.2330 - accuracy: 0.91 - ETA: 2:29 - loss: 0.2329 - accuracy: 0.91 - ETA: 2:27 - loss: 0.2400 - accuracy: 0.91 - ETA: 2:25 - loss: 0.2421 - accuracy: 0.91 - ETA: 2:24 - loss: 0.2447 - accuracy: 0.91 - ETA: 2:22 - loss: 0.2465 - accuracy: 0.91 - ETA: 2:21 - loss: 0.2438 - accuracy: 0.91 - ETA: 2:20 - loss: 0.2428 - accuracy: 0.91 - ETA: 2:19 - loss: 0.2418 - accuracy: 0.91 - ETA: 2:18 - loss: 0.2422 - accuracy: 0.91 - ETA: 2:17 - loss: 0.2421 - accuracy: 0.91 - ETA: 2:15 - loss: 0.2432 - accuracy: 0.91 - ETA: 2:14 - loss: 0.2426 - accuracy: 0.91 - ETA: 2:13 - loss: 0.2418 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2424 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2407 - accuracy: 0.91 - ETA: 2:10 - loss: 0.2396 - accuracy: 0.91 - ETA: 2:08 - loss: 0.2375 - accuracy: 0.91 - ETA: 2:07 - loss: 0.2385 - accuracy: 0.91 - ETA: 2:06 - loss: 0.2372 - accuracy: 0.91 - ETA: 2:04 - loss: 0.2390 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2384 - accuracy: 0.91 - ETA: 2:02 - loss: 0.2379 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2386 - accuracy: 0.91 - ETA: 2:00 - loss: 0.2398 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2405 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2391 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2394 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2383 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2365 - accuracy: 0.91 - ETA: 1:53 - loss: 0.2355 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2345 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2340 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2347 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2337 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2321 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2313 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2327 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2328 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2316 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2325 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2325 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2328 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2322 - accuracy: 0.91 - ETA: 1:37 - loss: 0.2317 - accuracy: 0.91 - ETA: 1:36 - loss: 0.2303 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2296 - accuracy: 0.91 - ETA: 1:34 - loss: 0.2288 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2285 - accuracy: 0.91 - ETA: 1:32 - loss: 0.2284 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2283 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2293 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2289 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2292 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2289 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2291 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2298 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2305 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2309 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2305 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2314 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2316 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2301 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2302 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2304 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2311 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2302 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2300 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2304 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2288 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2280 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2271 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2270 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2265 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2254 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2265 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2270 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2273 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2269 - accuracy: 0.91 - ETA: 59s - loss: 0.2267 - accuracy: 0.9185 - ETA: 58s - loss: 0.2263 - accuracy: 0.918 - ETA: 57s - loss: 0.2265 - accuracy: 0.918 - ETA: 55s - loss: 0.2263 - accuracy: 0.918 - ETA: 54s - loss: 0.2260 - accuracy: 0.918 - ETA: 53s - loss: 0.2262 - accuracy: 0.918 - ETA: 52s - loss: 0.2267 - accuracy: 0.918 - ETA: 51s - loss: 0.2265 - accuracy: 0.918 - ETA: 50s - loss: 0.2268 - accuracy: 0.918 - ETA: 49s - loss: 0.2267 - accuracy: 0.918 - ETA: 47s - loss: 0.2268 - accuracy: 0.918 - ETA: 46s - loss: 0.2268 - accuracy: 0.918 - ETA: 45s - loss: 0.2269 - accuracy: 0.919 - ETA: 44s - loss: 0.2270 - accuracy: 0.918 - ETA: 42s - loss: 0.2272 - accuracy: 0.918 - ETA: 41s - loss: 0.2269 - accuracy: 0.918 - ETA: 40s - loss: 0.2271 - accuracy: 0.918 - ETA: 39s - loss: 0.2275 - accuracy: 0.918 - ETA: 38s - loss: 0.2263 - accuracy: 0.919 - ETA: 36s - loss: 0.2269 - accuracy: 0.918 - ETA: 35s - loss: 0.2274 - accuracy: 0.918 - ETA: 34s - loss: 0.2272 - accuracy: 0.918 - ETA: 33s - loss: 0.2272 - accuracy: 0.918 - ETA: 31s - loss: 0.2281 - accuracy: 0.918 - ETA: 30s - loss: 0.2281 - accuracy: 0.918 - ETA: 29s - loss: 0.2285 - accuracy: 0.918 - ETA: 28s - loss: 0.2294 - accuracy: 0.917 - ETA: 27s - loss: 0.2299 - accuracy: 0.917 - ETA: 26s - loss: 0.2300 - accuracy: 0.917 - ETA: 24s - loss: 0.2296 - accuracy: 0.917 - ETA: 23s - loss: 0.2302 - accuracy: 0.917 - ETA: 22s - loss: 0.2302 - accuracy: 0.917 - ETA: 21s - loss: 0.2298 - accuracy: 0.917 - ETA: 20s - loss: 0.2299 - accuracy: 0.917 - ETA: 18s - loss: 0.2298 - accuracy: 0.916 - ETA: 17s - loss: 0.2292 - accuracy: 0.917 - ETA: 16s - loss: 0.2299 - accuracy: 0.917 - ETA: 15s - loss: 0.2312 - accuracy: 0.916 - ETA: 14s - loss: 0.2307 - accuracy: 0.916 - ETA: 12s - loss: 0.2311 - accuracy: 0.916 - ETA: 11s - loss: 0.2308 - accuracy: 0.916 - ETA: 10s - loss: 0.2311 - accuracy: 0.916 - ETA: 9s - loss: 0.2314 - accuracy: 0.916 - ETA: 8s - loss: 0.2319 - accuracy: 0.91 - ETA: 6s - loss: 0.2316 - accuracy: 0.91 - ETA: 5s - loss: 0.2318 - accuracy: 0.91 - ETA: 4s - loss: 0.2319 - accuracy: 0.91 - ETA: 3s - loss: 0.2322 - accuracy: 0.91 - ETA: 2s - loss: 0.2323 - accuracy: 0.91 - ETA: 1s - loss: 0.2324 - accuracy: 0.91 - 190s 10ms/step - loss: 0.2330 - accuracy: 0.9159 - val_loss: 1.7299 - val_accuracy: 0.7619\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:30 - loss: 0.2748 - accuracy: 0.89 - ETA: 2:32 - loss: 0.2228 - accuracy: 0.91 - ETA: 2:28 - loss: 0.2508 - accuracy: 0.89 - ETA: 2:29 - loss: 0.2719 - accuracy: 0.89 - ETA: 2:27 - loss: 0.2652 - accuracy: 0.89 - ETA: 2:23 - loss: 0.2426 - accuracy: 0.90 - ETA: 2:22 - loss: 0.2284 - accuracy: 0.90 - ETA: 2:19 - loss: 0.2259 - accuracy: 0.90 - ETA: 2:17 - loss: 0.2279 - accuracy: 0.90 - ETA: 2:15 - loss: 0.2305 - accuracy: 0.90 - ETA: 2:14 - loss: 0.2307 - accuracy: 0.91 - ETA: 2:13 - loss: 0.2278 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2310 - accuracy: 0.91 - ETA: 2:09 - loss: 0.2353 - accuracy: 0.91 - ETA: 2:08 - loss: 0.2400 - accuracy: 0.91 - ETA: 2:07 - loss: 0.2367 - accuracy: 0.91 - ETA: 2:06 - loss: 0.2420 - accuracy: 0.91 - ETA: 2:05 - loss: 0.2431 - accuracy: 0.91 - ETA: 2:04 - loss: 0.2537 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2575 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2506 - accuracy: 0.90 - ETA: 2:02 - loss: 0.2475 - accuracy: 0.91 - ETA: 2:00 - loss: 0.2435 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2397 - accuracy: 0.91 - ETA: 1:58 - loss: 0.2391 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2411 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2386 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2357 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2345 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2356 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2385 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2387 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2360 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2365 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2357 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2348 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2374 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2370 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2363 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2363 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2362 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2352 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2348 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2329 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2323 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2322 - accuracy: 0.91 - ETA: 1:37 - loss: 0.2335 - accuracy: 0.91 - ETA: 1:36 - loss: 0.2334 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2356 - accuracy: 0.91 - ETA: 1:34 - loss: 0.2364 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2376 - accuracy: 0.91 - ETA: 1:32 - loss: 0.2379 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2386 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2382 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2367 - accuracy: 0.91 - ETA: 1:28 - loss: 0.2362 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2357 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2361 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2356 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2359 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2374 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2380 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2382 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2401 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2402 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2412 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2405 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2387 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2381 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2406 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2405 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2413 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2414 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2413 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2407 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2407 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2415 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2430 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2422 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2417 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2420 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2419 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2421 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2407 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2392 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2379 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2376 - accuracy: 0.91 - ETA: 59s - loss: 0.2375 - accuracy: 0.9122 - ETA: 58s - loss: 0.2383 - accuracy: 0.911 - ETA: 57s - loss: 0.2385 - accuracy: 0.911 - ETA: 56s - loss: 0.2381 - accuracy: 0.912 - ETA: 55s - loss: 0.2386 - accuracy: 0.911 - ETA: 54s - loss: 0.2381 - accuracy: 0.912 - ETA: 53s - loss: 0.2375 - accuracy: 0.912 - ETA: 52s - loss: 0.2360 - accuracy: 0.912 - ETA: 51s - loss: 0.2355 - accuracy: 0.912 - ETA: 50s - loss: 0.2345 - accuracy: 0.913 - ETA: 49s - loss: 0.2341 - accuracy: 0.913 - ETA: 48s - loss: 0.2348 - accuracy: 0.913 - ETA: 47s - loss: 0.2353 - accuracy: 0.912 - ETA: 46s - loss: 0.2360 - accuracy: 0.912 - ETA: 45s - loss: 0.2362 - accuracy: 0.912 - ETA: 44s - loss: 0.2349 - accuracy: 0.913 - ETA: 43s - loss: 0.2352 - accuracy: 0.912 - ETA: 42s - loss: 0.2350 - accuracy: 0.913 - ETA: 41s - loss: 0.2343 - accuracy: 0.913 - ETA: 41s - loss: 0.2354 - accuracy: 0.912 - ETA: 40s - loss: 0.2358 - accuracy: 0.912 - ETA: 39s - loss: 0.2356 - accuracy: 0.912 - ETA: 38s - loss: 0.2354 - accuracy: 0.912 - ETA: 37s - loss: 0.2350 - accuracy: 0.913 - ETA: 36s - loss: 0.2351 - accuracy: 0.913 - ETA: 35s - loss: 0.2344 - accuracy: 0.913 - ETA: 34s - loss: 0.2344 - accuracy: 0.913 - ETA: 33s - loss: 0.2342 - accuracy: 0.913 - ETA: 32s - loss: 0.2339 - accuracy: 0.913 - ETA: 31s - loss: 0.2338 - accuracy: 0.913 - ETA: 30s - loss: 0.2342 - accuracy: 0.913 - ETA: 29s - loss: 0.2344 - accuracy: 0.913 - ETA: 28s - loss: 0.2350 - accuracy: 0.913 - ETA: 27s - loss: 0.2349 - accuracy: 0.912 - ETA: 26s - loss: 0.2350 - accuracy: 0.913 - ETA: 25s - loss: 0.2355 - accuracy: 0.913 - ETA: 25s - loss: 0.2355 - accuracy: 0.913 - ETA: 24s - loss: 0.2344 - accuracy: 0.913 - ETA: 23s - loss: 0.2341 - accuracy: 0.913 - ETA: 22s - loss: 0.2341 - accuracy: 0.913 - ETA: 21s - loss: 0.2342 - accuracy: 0.913 - ETA: 20s - loss: 0.2344 - accuracy: 0.913 - ETA: 19s - loss: 0.2349 - accuracy: 0.913 - ETA: 18s - loss: 0.2347 - accuracy: 0.913 - ETA: 17s - loss: 0.2355 - accuracy: 0.913 - ETA: 16s - loss: 0.2348 - accuracy: 0.913 - ETA: 15s - loss: 0.2344 - accuracy: 0.913 - ETA: 14s - loss: 0.2344 - accuracy: 0.913 - ETA: 13s - loss: 0.2350 - accuracy: 0.913 - ETA: 12s - loss: 0.2348 - accuracy: 0.913 - ETA: 12s - loss: 0.2360 - accuracy: 0.913 - ETA: 11s - loss: 0.2360 - accuracy: 0.913 - ETA: 10s - loss: 0.2365 - accuracy: 0.912 - ETA: 9s - loss: 0.2367 - accuracy: 0.912 - ETA: 8s - loss: 0.2373 - accuracy: 0.91 - ETA: 7s - loss: 0.2365 - accuracy: 0.91 - ETA: 6s - loss: 0.2355 - accuracy: 0.91 - ETA: 5s - loss: 0.2348 - accuracy: 0.91 - ETA: 4s - loss: 0.2352 - accuracy: 0.91 - ETA: 3s - loss: 0.2362 - accuracy: 0.91 - ETA: 2s - loss: 0.2361 - accuracy: 0.91 - ETA: 1s - loss: 0.2363 - accuracy: 0.91 - ETA: 0s - loss: 0.2360 - accuracy: 0.91 - 153s 8ms/step - loss: 0.2356 - accuracy: 0.9133 - val_loss: 1.7107 - val_accuracy: 0.7596\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 0.2642 - accuracy: 0.90 - ETA: 2:20 - loss: 0.2828 - accuracy: 0.91 - ETA: 2:18 - loss: 0.2398 - accuracy: 0.92 - ETA: 2:16 - loss: 0.2417 - accuracy: 0.91 - ETA: 2:15 - loss: 0.2255 - accuracy: 0.92 - ETA: 2:16 - loss: 0.2358 - accuracy: 0.91 - ETA: 2:15 - loss: 0.2493 - accuracy: 0.91 - ETA: 2:15 - loss: 0.2426 - accuracy: 0.91 - ETA: 2:13 - loss: 0.2373 - accuracy: 0.91 - ETA: 2:12 - loss: 0.2292 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2315 - accuracy: 0.91 - ETA: 2:12 - loss: 0.2297 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2290 - accuracy: 0.91 - ETA: 2:10 - loss: 0.2239 - accuracy: 0.92 - ETA: 2:09 - loss: 0.2213 - accuracy: 0.92 - ETA: 2:08 - loss: 0.2171 - accuracy: 0.92 - ETA: 2:07 - loss: 0.2148 - accuracy: 0.92 - ETA: 2:06 - loss: 0.2181 - accuracy: 0.92 - ETA: 2:04 - loss: 0.2172 - accuracy: 0.92 - ETA: 2:03 - loss: 0.2186 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2148 - accuracy: 0.92 - ETA: 2:01 - loss: 0.2183 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2180 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2160 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2161 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2145 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2139 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2140 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2169 - accuracy: 0.92 - ETA: 1:54 - loss: 0.2184 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2169 - accuracy: 0.92 - ETA: 1:52 - loss: 0.2212 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2211 - accuracy: 0.92 - ETA: 1:50 - loss: 0.2220 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2225 - accuracy: 0.92 - ETA: 1:48 - loss: 0.2224 - accuracy: 0.92 - ETA: 1:47 - loss: 0.2240 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2246 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2235 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2238 - accuracy: 0.92 - ETA: 1:43 - loss: 0.2272 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2293 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2307 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2317 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2315 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2333 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2344 - accuracy: 0.91 - ETA: 1:37 - loss: 0.2343 - accuracy: 0.91 - ETA: 1:36 - loss: 0.2380 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2385 - accuracy: 0.91 - ETA: 1:34 - loss: 0.2392 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2392 - accuracy: 0.91 - ETA: 1:32 - loss: 0.2389 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2380 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2378 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2378 - accuracy: 0.91 - ETA: 1:28 - loss: 0.2355 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2348 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2350 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2339 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2336 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2338 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2343 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2336 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2336 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2330 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2322 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2329 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2335 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2321 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2313 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2328 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2331 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2337 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2335 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2338 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2330 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2339 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2334 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2345 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2360 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2352 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2346 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2343 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2345 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2341 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2334 - accuracy: 0.91 - ETA: 59s - loss: 0.2337 - accuracy: 0.9153 - ETA: 58s - loss: 0.2332 - accuracy: 0.915 - ETA: 57s - loss: 0.2335 - accuracy: 0.915 - ETA: 56s - loss: 0.2335 - accuracy: 0.915 - ETA: 55s - loss: 0.2338 - accuracy: 0.915 - ETA: 54s - loss: 0.2332 - accuracy: 0.915 - ETA: 53s - loss: 0.2325 - accuracy: 0.915 - ETA: 52s - loss: 0.2322 - accuracy: 0.916 - ETA: 51s - loss: 0.2308 - accuracy: 0.916 - ETA: 50s - loss: 0.2300 - accuracy: 0.916 - ETA: 49s - loss: 0.2301 - accuracy: 0.916 - ETA: 49s - loss: 0.2291 - accuracy: 0.917 - ETA: 48s - loss: 0.2295 - accuracy: 0.917 - ETA: 47s - loss: 0.2289 - accuracy: 0.917 - ETA: 46s - loss: 0.2302 - accuracy: 0.917 - ETA: 45s - loss: 0.2299 - accuracy: 0.917 - ETA: 44s - loss: 0.2298 - accuracy: 0.917 - ETA: 43s - loss: 0.2294 - accuracy: 0.917 - ETA: 42s - loss: 0.2298 - accuracy: 0.917 - ETA: 41s - loss: 0.2300 - accuracy: 0.917 - ETA: 40s - loss: 0.2309 - accuracy: 0.917 - ETA: 39s - loss: 0.2303 - accuracy: 0.917 - ETA: 38s - loss: 0.2304 - accuracy: 0.917 - ETA: 37s - loss: 0.2303 - accuracy: 0.917 - ETA: 36s - loss: 0.2305 - accuracy: 0.917 - ETA: 35s - loss: 0.2306 - accuracy: 0.917 - ETA: 34s - loss: 0.2299 - accuracy: 0.917 - ETA: 33s - loss: 0.2293 - accuracy: 0.917 - ETA: 33s - loss: 0.2291 - accuracy: 0.917 - ETA: 32s - loss: 0.2289 - accuracy: 0.917 - ETA: 31s - loss: 0.2291 - accuracy: 0.917 - ETA: 30s - loss: 0.2277 - accuracy: 0.917 - ETA: 29s - loss: 0.2274 - accuracy: 0.917 - ETA: 28s - loss: 0.2275 - accuracy: 0.918 - ETA: 27s - loss: 0.2278 - accuracy: 0.917 - ETA: 26s - loss: 0.2275 - accuracy: 0.918 - ETA: 25s - loss: 0.2291 - accuracy: 0.917 - ETA: 24s - loss: 0.2289 - accuracy: 0.917 - ETA: 23s - loss: 0.2283 - accuracy: 0.917 - ETA: 22s - loss: 0.2278 - accuracy: 0.917 - ETA: 21s - loss: 0.2275 - accuracy: 0.917 - ETA: 20s - loss: 0.2283 - accuracy: 0.917 - ETA: 19s - loss: 0.2281 - accuracy: 0.917 - ETA: 18s - loss: 0.2285 - accuracy: 0.917 - ETA: 17s - loss: 0.2282 - accuracy: 0.917 - ETA: 16s - loss: 0.2278 - accuracy: 0.917 - ETA: 15s - loss: 0.2273 - accuracy: 0.917 - ETA: 15s - loss: 0.2269 - accuracy: 0.917 - ETA: 14s - loss: 0.2274 - accuracy: 0.917 - ETA: 13s - loss: 0.2268 - accuracy: 0.917 - ETA: 12s - loss: 0.2266 - accuracy: 0.918 - ETA: 11s - loss: 0.2263 - accuracy: 0.918 - ETA: 10s - loss: 0.2262 - accuracy: 0.918 - ETA: 9s - loss: 0.2264 - accuracy: 0.918 - ETA: 8s - loss: 0.2261 - accuracy: 0.91 - ETA: 7s - loss: 0.2260 - accuracy: 0.91 - ETA: 6s - loss: 0.2262 - accuracy: 0.91 - ETA: 5s - loss: 0.2252 - accuracy: 0.91 - ETA: 4s - loss: 0.2249 - accuracy: 0.91 - ETA: 3s - loss: 0.2248 - accuracy: 0.91 - ETA: 2s - loss: 0.2256 - accuracy: 0.91 - ETA: 1s - loss: 0.2254 - accuracy: 0.91 - ETA: 0s - loss: 0.2253 - accuracy: 0.91 - 155s 8ms/step - loss: 0.2260 - accuracy: 0.9185 - val_loss: 1.7419 - val_accuracy: 0.7623\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:26 - loss: 0.2740 - accuracy: 0.92 - ETA: 2:20 - loss: 0.2878 - accuracy: 0.91 - ETA: 2:21 - loss: 0.2558 - accuracy: 0.90 - ETA: 2:17 - loss: 0.2448 - accuracy: 0.90 - ETA: 2:15 - loss: 0.2507 - accuracy: 0.90 - ETA: 2:14 - loss: 0.2477 - accuracy: 0.90 - ETA: 2:13 - loss: 0.2337 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2346 - accuracy: 0.90 - ETA: 2:10 - loss: 0.2302 - accuracy: 0.91 - ETA: 2:09 - loss: 0.2293 - accuracy: 0.91 - ETA: 2:08 - loss: 0.2272 - accuracy: 0.91 - ETA: 2:07 - loss: 0.2239 - accuracy: 0.91 - ETA: 2:06 - loss: 0.2284 - accuracy: 0.91 - ETA: 2:04 - loss: 0.2224 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2145 - accuracy: 0.91 - ETA: 2:02 - loss: 0.2169 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2170 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2171 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2157 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2132 - accuracy: 0.91 - ETA: 1:58 - loss: 0.2147 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2187 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2207 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2220 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2242 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2252 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2269 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2268 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2271 - accuracy: 0.91 - ETA: 1:58 - loss: 0.2234 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2247 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2232 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2210 - accuracy: 0.91 - ETA: 1:53 - loss: 0.2201 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2203 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2227 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2219 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2260 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2279 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2270 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2252 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2242 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2235 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2237 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2237 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2227 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2234 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2245 - accuracy: 0.91 - ETA: 1:37 - loss: 0.2266 - accuracy: 0.91 - ETA: 1:36 - loss: 0.2272 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2282 - accuracy: 0.91 - ETA: 1:34 - loss: 0.2277 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2274 - accuracy: 0.91 - ETA: 1:32 - loss: 0.2279 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2267 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2264 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2250 - accuracy: 0.91 - ETA: 1:28 - loss: 0.2241 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2246 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2237 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2244 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2260 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2265 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2276 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2283 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2293 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2285 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2294 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2284 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2294 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2303 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2291 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2286 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2281 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2276 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2275 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2262 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2278 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2264 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2253 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2248 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2249 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2248 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2238 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2240 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2235 - accuracy: 0.91 - ETA: 59s - loss: 0.2234 - accuracy: 0.9179 - ETA: 58s - loss: 0.2226 - accuracy: 0.918 - ETA: 57s - loss: 0.2221 - accuracy: 0.918 - ETA: 56s - loss: 0.2209 - accuracy: 0.918 - ETA: 55s - loss: 0.2212 - accuracy: 0.918 - ETA: 54s - loss: 0.2223 - accuracy: 0.917 - ETA: 54s - loss: 0.2223 - accuracy: 0.917 - ETA: 53s - loss: 0.2222 - accuracy: 0.918 - ETA: 52s - loss: 0.2219 - accuracy: 0.918 - ETA: 51s - loss: 0.2220 - accuracy: 0.918 - ETA: 50s - loss: 0.2221 - accuracy: 0.918 - ETA: 49s - loss: 0.2216 - accuracy: 0.918 - ETA: 48s - loss: 0.2219 - accuracy: 0.918 - ETA: 47s - loss: 0.2217 - accuracy: 0.918 - ETA: 46s - loss: 0.2213 - accuracy: 0.918 - ETA: 45s - loss: 0.2223 - accuracy: 0.917 - ETA: 44s - loss: 0.2222 - accuracy: 0.917 - ETA: 43s - loss: 0.2230 - accuracy: 0.917 - ETA: 42s - loss: 0.2229 - accuracy: 0.917 - ETA: 41s - loss: 0.2228 - accuracy: 0.917 - ETA: 41s - loss: 0.2221 - accuracy: 0.918 - ETA: 40s - loss: 0.2225 - accuracy: 0.918 - ETA: 39s - loss: 0.2221 - accuracy: 0.918 - ETA: 38s - loss: 0.2221 - accuracy: 0.918 - ETA: 37s - loss: 0.2222 - accuracy: 0.917 - ETA: 36s - loss: 0.2226 - accuracy: 0.917 - ETA: 35s - loss: 0.2229 - accuracy: 0.917 - ETA: 34s - loss: 0.2227 - accuracy: 0.917 - ETA: 33s - loss: 0.2218 - accuracy: 0.917 - ETA: 32s - loss: 0.2213 - accuracy: 0.917 - ETA: 31s - loss: 0.2217 - accuracy: 0.918 - ETA: 31s - loss: 0.2214 - accuracy: 0.917 - ETA: 30s - loss: 0.2213 - accuracy: 0.918 - ETA: 29s - loss: 0.2214 - accuracy: 0.918 - ETA: 28s - loss: 0.2206 - accuracy: 0.918 - ETA: 27s - loss: 0.2199 - accuracy: 0.918 - ETA: 26s - loss: 0.2203 - accuracy: 0.918 - ETA: 25s - loss: 0.2200 - accuracy: 0.918 - ETA: 24s - loss: 0.2194 - accuracy: 0.918 - ETA: 23s - loss: 0.2197 - accuracy: 0.918 - ETA: 22s - loss: 0.2200 - accuracy: 0.918 - ETA: 21s - loss: 0.2210 - accuracy: 0.918 - ETA: 20s - loss: 0.2211 - accuracy: 0.918 - ETA: 19s - loss: 0.2209 - accuracy: 0.919 - ETA: 18s - loss: 0.2211 - accuracy: 0.919 - ETA: 17s - loss: 0.2220 - accuracy: 0.919 - ETA: 16s - loss: 0.2215 - accuracy: 0.919 - ETA: 15s - loss: 0.2220 - accuracy: 0.919 - ETA: 14s - loss: 0.2218 - accuracy: 0.919 - ETA: 13s - loss: 0.2220 - accuracy: 0.919 - ETA: 13s - loss: 0.2217 - accuracy: 0.919 - ETA: 12s - loss: 0.2218 - accuracy: 0.919 - ETA: 11s - loss: 0.2218 - accuracy: 0.919 - ETA: 10s - loss: 0.2217 - accuracy: 0.919 - ETA: 9s - loss: 0.2209 - accuracy: 0.920 - ETA: 8s - loss: 0.2210 - accuracy: 0.92 - ETA: 7s - loss: 0.2210 - accuracy: 0.92 - ETA: 6s - loss: 0.2210 - accuracy: 0.92 - ETA: 5s - loss: 0.2208 - accuracy: 0.92 - ETA: 4s - loss: 0.2206 - accuracy: 0.92 - ETA: 3s - loss: 0.2202 - accuracy: 0.92 - ETA: 2s - loss: 0.2207 - accuracy: 0.92 - ETA: 1s - loss: 0.2205 - accuracy: 0.92 - ETA: 0s - loss: 0.2204 - accuracy: 0.92 - 153s 8ms/step - loss: 0.2203 - accuracy: 0.9204 - val_loss: 1.7547 - val_accuracy: 0.7612\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:23 - loss: 0.1744 - accuracy: 0.94 - ETA: 2:17 - loss: 0.1845 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1958 - accuracy: 0.93 - ETA: 2:21 - loss: 0.1944 - accuracy: 0.93 - ETA: 2:20 - loss: 0.2018 - accuracy: 0.92 - ETA: 2:18 - loss: 0.1933 - accuracy: 0.93 - ETA: 2:18 - loss: 0.1906 - accuracy: 0.93 - ETA: 2:17 - loss: 0.1902 - accuracy: 0.93 - ETA: 2:15 - loss: 0.1843 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1809 - accuracy: 0.93 - ETA: 2:12 - loss: 0.1816 - accuracy: 0.93 - ETA: 2:10 - loss: 0.1852 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1848 - accuracy: 0.93 - ETA: 2:08 - loss: 0.1858 - accuracy: 0.93 - ETA: 2:07 - loss: 0.1864 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1892 - accuracy: 0.93 - ETA: 2:04 - loss: 0.1876 - accuracy: 0.93 - ETA: 2:03 - loss: 0.1898 - accuracy: 0.93 - ETA: 2:02 - loss: 0.1929 - accuracy: 0.93 - ETA: 2:01 - loss: 0.1951 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2018 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2045 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2020 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2025 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2035 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2095 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2120 - accuracy: 0.92 - ETA: 1:54 - loss: 0.2099 - accuracy: 0.92 - ETA: 1:52 - loss: 0.2109 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2175 - accuracy: 0.92 - ETA: 1:50 - loss: 0.2162 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2185 - accuracy: 0.92 - ETA: 1:48 - loss: 0.2180 - accuracy: 0.92 - ETA: 1:47 - loss: 0.2214 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2215 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2223 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2206 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2188 - accuracy: 0.91 - ETA: 1:43 - loss: 0.2187 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2175 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2162 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2149 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2135 - accuracy: 0.92 - ETA: 1:38 - loss: 0.2140 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2156 - accuracy: 0.92 - ETA: 1:36 - loss: 0.2184 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2163 - accuracy: 0.92 - ETA: 1:34 - loss: 0.2168 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2165 - accuracy: 0.92 - ETA: 1:32 - loss: 0.2166 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2176 - accuracy: 0.92 - ETA: 1:30 - loss: 0.2166 - accuracy: 0.92 - ETA: 1:30 - loss: 0.2191 - accuracy: 0.92 - ETA: 1:29 - loss: 0.2206 - accuracy: 0.91 - ETA: 1:28 - loss: 0.2188 - accuracy: 0.92 - ETA: 1:27 - loss: 0.2191 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2203 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2197 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2211 - accuracy: 0.92 - ETA: 1:23 - loss: 0.2204 - accuracy: 0.92 - ETA: 1:22 - loss: 0.2216 - accuracy: 0.92 - ETA: 1:21 - loss: 0.2216 - accuracy: 0.92 - ETA: 1:20 - loss: 0.2223 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2224 - accuracy: 0.92 - ETA: 1:18 - loss: 0.2228 - accuracy: 0.92 - ETA: 1:18 - loss: 0.2216 - accuracy: 0.92 - ETA: 1:17 - loss: 0.2226 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2225 - accuracy: 0.92 - ETA: 1:15 - loss: 0.2214 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2209 - accuracy: 0.92 - ETA: 1:13 - loss: 0.2200 - accuracy: 0.92 - ETA: 1:12 - loss: 0.2205 - accuracy: 0.92 - ETA: 1:11 - loss: 0.2225 - accuracy: 0.92 - ETA: 1:10 - loss: 0.2225 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2231 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2231 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2225 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2222 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2226 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2225 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2228 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2240 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2240 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2242 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2254 - accuracy: 0.91 - ETA: 59s - loss: 0.2262 - accuracy: 0.9185 - ETA: 58s - loss: 0.2277 - accuracy: 0.917 - ETA: 57s - loss: 0.2285 - accuracy: 0.917 - ETA: 56s - loss: 0.2292 - accuracy: 0.917 - ETA: 55s - loss: 0.2285 - accuracy: 0.917 - ETA: 54s - loss: 0.2281 - accuracy: 0.917 - ETA: 53s - loss: 0.2278 - accuracy: 0.917 - ETA: 52s - loss: 0.2294 - accuracy: 0.917 - ETA: 51s - loss: 0.2292 - accuracy: 0.917 - ETA: 50s - loss: 0.2304 - accuracy: 0.916 - ETA: 50s - loss: 0.2306 - accuracy: 0.916 - ETA: 49s - loss: 0.2305 - accuracy: 0.916 - ETA: 48s - loss: 0.2302 - accuracy: 0.917 - ETA: 47s - loss: 0.2301 - accuracy: 0.917 - ETA: 46s - loss: 0.2302 - accuracy: 0.916 - ETA: 45s - loss: 0.2290 - accuracy: 0.917 - ETA: 44s - loss: 0.2299 - accuracy: 0.916 - ETA: 43s - loss: 0.2303 - accuracy: 0.916 - ETA: 42s - loss: 0.2302 - accuracy: 0.916 - ETA: 41s - loss: 0.2306 - accuracy: 0.916 - ETA: 40s - loss: 0.2307 - accuracy: 0.916 - ETA: 40s - loss: 0.2314 - accuracy: 0.915 - ETA: 39s - loss: 0.2315 - accuracy: 0.915 - ETA: 38s - loss: 0.2308 - accuracy: 0.916 - ETA: 37s - loss: 0.2312 - accuracy: 0.915 - ETA: 36s - loss: 0.2310 - accuracy: 0.915 - ETA: 35s - loss: 0.2305 - accuracy: 0.915 - ETA: 34s - loss: 0.2308 - accuracy: 0.915 - ETA: 33s - loss: 0.2312 - accuracy: 0.915 - ETA: 32s - loss: 0.2317 - accuracy: 0.915 - ETA: 31s - loss: 0.2308 - accuracy: 0.915 - ETA: 31s - loss: 0.2311 - accuracy: 0.915 - ETA: 30s - loss: 0.2315 - accuracy: 0.915 - ETA: 29s - loss: 0.2313 - accuracy: 0.915 - ETA: 28s - loss: 0.2324 - accuracy: 0.915 - ETA: 27s - loss: 0.2322 - accuracy: 0.915 - ETA: 26s - loss: 0.2319 - accuracy: 0.915 - ETA: 25s - loss: 0.2327 - accuracy: 0.915 - ETA: 24s - loss: 0.2326 - accuracy: 0.915 - ETA: 23s - loss: 0.2330 - accuracy: 0.915 - ETA: 22s - loss: 0.2327 - accuracy: 0.915 - ETA: 21s - loss: 0.2330 - accuracy: 0.915 - ETA: 21s - loss: 0.2329 - accuracy: 0.915 - ETA: 20s - loss: 0.2322 - accuracy: 0.915 - ETA: 19s - loss: 0.2312 - accuracy: 0.915 - ETA: 18s - loss: 0.2321 - accuracy: 0.915 - ETA: 17s - loss: 0.2323 - accuracy: 0.915 - ETA: 16s - loss: 0.2322 - accuracy: 0.915 - ETA: 15s - loss: 0.2326 - accuracy: 0.915 - ETA: 14s - loss: 0.2332 - accuracy: 0.915 - ETA: 13s - loss: 0.2328 - accuracy: 0.915 - ETA: 12s - loss: 0.2335 - accuracy: 0.914 - ETA: 11s - loss: 0.2328 - accuracy: 0.915 - ETA: 10s - loss: 0.2324 - accuracy: 0.915 - ETA: 9s - loss: 0.2329 - accuracy: 0.915 - ETA: 9s - loss: 0.2335 - accuracy: 0.91 - ETA: 8s - loss: 0.2330 - accuracy: 0.91 - ETA: 7s - loss: 0.2328 - accuracy: 0.91 - ETA: 6s - loss: 0.2324 - accuracy: 0.91 - ETA: 5s - loss: 0.2324 - accuracy: 0.91 - ETA: 4s - loss: 0.2321 - accuracy: 0.91 - ETA: 3s - loss: 0.2316 - accuracy: 0.91 - ETA: 2s - loss: 0.2312 - accuracy: 0.91 - ETA: 1s - loss: 0.2314 - accuracy: 0.91 - ETA: 0s - loss: 0.2311 - accuracy: 0.91 - 150s 8ms/step - loss: 0.2311 - accuracy: 0.9154 - val_loss: 1.7412 - val_accuracy: 0.7612\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:36 - loss: 0.1613 - accuracy: 0.94 - ETA: 2:24 - loss: 0.1820 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1906 - accuracy: 0.93 - ETA: 2:15 - loss: 0.1999 - accuracy: 0.92 - ETA: 2:12 - loss: 0.2093 - accuracy: 0.92 - ETA: 2:09 - loss: 0.2056 - accuracy: 0.92 - ETA: 2:07 - loss: 0.2040 - accuracy: 0.92 - ETA: 2:06 - loss: 0.2115 - accuracy: 0.92 - ETA: 2:05 - loss: 0.2132 - accuracy: 0.92 - ETA: 2:05 - loss: 0.2131 - accuracy: 0.92 - ETA: 2:03 - loss: 0.2119 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2159 - accuracy: 0.92 - ETA: 2:01 - loss: 0.2163 - accuracy: 0.92 - ETA: 2:01 - loss: 0.2132 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2095 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2124 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2119 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2089 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2078 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2093 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2107 - accuracy: 0.92 - ETA: 1:54 - loss: 0.2139 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2141 - accuracy: 0.92 - ETA: 1:52 - loss: 0.2135 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2152 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2145 - accuracy: 0.92 - ETA: 1:50 - loss: 0.2154 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2152 - accuracy: 0.92 - ETA: 1:47 - loss: 0.2135 - accuracy: 0.92 - ETA: 1:46 - loss: 0.2093 - accuracy: 0.92 - ETA: 1:46 - loss: 0.2087 - accuracy: 0.92 - ETA: 1:45 - loss: 0.2134 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2136 - accuracy: 0.92 - ETA: 1:43 - loss: 0.2117 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2142 - accuracy: 0.92 - ETA: 1:41 - loss: 0.2120 - accuracy: 0.92 - ETA: 1:41 - loss: 0.2115 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2093 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2091 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2081 - accuracy: 0.92 - ETA: 1:38 - loss: 0.2090 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2104 - accuracy: 0.92 - ETA: 1:36 - loss: 0.2105 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2109 - accuracy: 0.92 - ETA: 1:34 - loss: 0.2104 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2100 - accuracy: 0.92 - ETA: 1:32 - loss: 0.2106 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2101 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2118 - accuracy: 0.92 - ETA: 1:30 - loss: 0.2101 - accuracy: 0.92 - ETA: 1:29 - loss: 0.2106 - accuracy: 0.92 - ETA: 1:28 - loss: 0.2104 - accuracy: 0.92 - ETA: 1:27 - loss: 0.2095 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2098 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2098 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2101 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2113 - accuracy: 0.92 - ETA: 1:23 - loss: 0.2122 - accuracy: 0.92 - ETA: 1:22 - loss: 0.2132 - accuracy: 0.92 - ETA: 1:22 - loss: 0.2116 - accuracy: 0.92 - ETA: 1:21 - loss: 0.2113 - accuracy: 0.92 - ETA: 1:20 - loss: 0.2103 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2099 - accuracy: 0.92 - ETA: 1:18 - loss: 0.2099 - accuracy: 0.92 - ETA: 1:17 - loss: 0.2107 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2100 - accuracy: 0.92 - ETA: 1:15 - loss: 0.2107 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2094 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2101 - accuracy: 0.92 - ETA: 1:13 - loss: 0.2093 - accuracy: 0.92 - ETA: 1:12 - loss: 0.2085 - accuracy: 0.92 - ETA: 1:11 - loss: 0.2098 - accuracy: 0.92 - ETA: 1:10 - loss: 0.2086 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2089 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2097 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2119 - accuracy: 0.92 - ETA: 1:07 - loss: 0.2127 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2116 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2117 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2120 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2116 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2106 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2110 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2111 - accuracy: 0.92 - ETA: 59s - loss: 0.2127 - accuracy: 0.9218 - ETA: 58s - loss: 0.2122 - accuracy: 0.921 - ETA: 57s - loss: 0.2114 - accuracy: 0.922 - ETA: 57s - loss: 0.2112 - accuracy: 0.922 - ETA: 56s - loss: 0.2112 - accuracy: 0.922 - ETA: 55s - loss: 0.2116 - accuracy: 0.922 - ETA: 54s - loss: 0.2122 - accuracy: 0.922 - ETA: 53s - loss: 0.2124 - accuracy: 0.922 - ETA: 52s - loss: 0.2126 - accuracy: 0.922 - ETA: 51s - loss: 0.2125 - accuracy: 0.922 - ETA: 50s - loss: 0.2123 - accuracy: 0.922 - ETA: 49s - loss: 0.2116 - accuracy: 0.922 - ETA: 48s - loss: 0.2119 - accuracy: 0.922 - ETA: 47s - loss: 0.2126 - accuracy: 0.922 - ETA: 47s - loss: 0.2139 - accuracy: 0.921 - ETA: 46s - loss: 0.2133 - accuracy: 0.921 - ETA: 45s - loss: 0.2142 - accuracy: 0.921 - ETA: 44s - loss: 0.2146 - accuracy: 0.921 - ETA: 43s - loss: 0.2136 - accuracy: 0.921 - ETA: 42s - loss: 0.2129 - accuracy: 0.921 - ETA: 41s - loss: 0.2124 - accuracy: 0.921 - ETA: 40s - loss: 0.2129 - accuracy: 0.921 - ETA: 39s - loss: 0.2139 - accuracy: 0.921 - ETA: 38s - loss: 0.2136 - accuracy: 0.921 - ETA: 38s - loss: 0.2127 - accuracy: 0.921 - ETA: 37s - loss: 0.2125 - accuracy: 0.921 - ETA: 36s - loss: 0.2126 - accuracy: 0.921 - ETA: 35s - loss: 0.2123 - accuracy: 0.921 - ETA: 34s - loss: 0.2125 - accuracy: 0.922 - ETA: 33s - loss: 0.2122 - accuracy: 0.922 - ETA: 32s - loss: 0.2130 - accuracy: 0.922 - ETA: 31s - loss: 0.2132 - accuracy: 0.921 - ETA: 30s - loss: 0.2133 - accuracy: 0.921 - ETA: 29s - loss: 0.2133 - accuracy: 0.921 - ETA: 28s - loss: 0.2136 - accuracy: 0.921 - ETA: 28s - loss: 0.2139 - accuracy: 0.921 - ETA: 27s - loss: 0.2140 - accuracy: 0.921 - ETA: 26s - loss: 0.2139 - accuracy: 0.921 - ETA: 25s - loss: 0.2140 - accuracy: 0.921 - ETA: 24s - loss: 0.2138 - accuracy: 0.921 - ETA: 23s - loss: 0.2132 - accuracy: 0.921 - ETA: 22s - loss: 0.2135 - accuracy: 0.921 - ETA: 21s - loss: 0.2131 - accuracy: 0.921 - ETA: 20s - loss: 0.2132 - accuracy: 0.922 - ETA: 19s - loss: 0.2131 - accuracy: 0.922 - ETA: 19s - loss: 0.2131 - accuracy: 0.922 - ETA: 18s - loss: 0.2128 - accuracy: 0.922 - ETA: 17s - loss: 0.2126 - accuracy: 0.922 - ETA: 16s - loss: 0.2128 - accuracy: 0.922 - ETA: 15s - loss: 0.2128 - accuracy: 0.922 - ETA: 14s - loss: 0.2126 - accuracy: 0.922 - ETA: 13s - loss: 0.2126 - accuracy: 0.922 - ETA: 12s - loss: 0.2124 - accuracy: 0.922 - ETA: 11s - loss: 0.2123 - accuracy: 0.922 - ETA: 10s - loss: 0.2120 - accuracy: 0.922 - ETA: 9s - loss: 0.2125 - accuracy: 0.922 - ETA: 8s - loss: 0.2128 - accuracy: 0.92 - ETA: 8s - loss: 0.2124 - accuracy: 0.92 - ETA: 7s - loss: 0.2125 - accuracy: 0.92 - ETA: 6s - loss: 0.2123 - accuracy: 0.92 - ETA: 5s - loss: 0.2118 - accuracy: 0.92 - ETA: 4s - loss: 0.2119 - accuracy: 0.92 - ETA: 3s - loss: 0.2117 - accuracy: 0.92 - ETA: 2s - loss: 0.2112 - accuracy: 0.92 - ETA: 1s - loss: 0.2112 - accuracy: 0.92 - ETA: 0s - loss: 0.2111 - accuracy: 0.92 - 149s 8ms/step - loss: 0.2115 - accuracy: 0.9219 - val_loss: 1.7936 - val_accuracy: 0.7614\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:20 - loss: 0.2101 - accuracy: 0.92 - ETA: 2:15 - loss: 0.2030 - accuracy: 0.92 - ETA: 2:14 - loss: 0.2075 - accuracy: 0.92 - ETA: 2:13 - loss: 0.2077 - accuracy: 0.92 - ETA: 2:12 - loss: 0.2100 - accuracy: 0.92 - ETA: 2:11 - loss: 0.2256 - accuracy: 0.91 - ETA: 2:09 - loss: 0.2183 - accuracy: 0.91 - ETA: 2:08 - loss: 0.2190 - accuracy: 0.92 - ETA: 2:07 - loss: 0.2247 - accuracy: 0.91 - ETA: 2:06 - loss: 0.2284 - accuracy: 0.91 - ETA: 2:05 - loss: 0.2219 - accuracy: 0.91 - ETA: 2:04 - loss: 0.2167 - accuracy: 0.91 - ETA: 2:04 - loss: 0.2157 - accuracy: 0.92 - ETA: 2:04 - loss: 0.2093 - accuracy: 0.92 - ETA: 2:03 - loss: 0.2114 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2106 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2087 - accuracy: 0.92 - ETA: 2:01 - loss: 0.2175 - accuracy: 0.91 - ETA: 2:00 - loss: 0.2183 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2154 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2167 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2173 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2190 - accuracy: 0.91 - ETA: 1:55 - loss: 0.2195 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2184 - accuracy: 0.91 - ETA: 1:53 - loss: 0.2218 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2275 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2245 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2262 - accuracy: 0.91 - ETA: 1:50 - loss: 0.2250 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2253 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2211 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2197 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2169 - accuracy: 0.92 - ETA: 1:46 - loss: 0.2183 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2181 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2165 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2162 - accuracy: 0.92 - ETA: 1:43 - loss: 0.2187 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2172 - accuracy: 0.91 - ETA: 1:41 - loss: 0.2174 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2164 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2172 - accuracy: 0.91 - ETA: 1:38 - loss: 0.2176 - accuracy: 0.91 - ETA: 1:37 - loss: 0.2165 - accuracy: 0.91 - ETA: 1:36 - loss: 0.2169 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2175 - accuracy: 0.91 - ETA: 1:34 - loss: 0.2187 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2171 - accuracy: 0.91 - ETA: 1:32 - loss: 0.2177 - accuracy: 0.91 - ETA: 1:31 - loss: 0.2179 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2173 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2179 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2168 - accuracy: 0.91 - ETA: 1:28 - loss: 0.2159 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2150 - accuracy: 0.91 - ETA: 1:26 - loss: 0.2142 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2146 - accuracy: 0.91 - ETA: 1:24 - loss: 0.2152 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2157 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2156 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2180 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2180 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2185 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2213 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2223 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2217 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2232 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2249 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2241 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2244 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2236 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2236 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2246 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2254 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2247 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2243 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2232 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2222 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2209 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2201 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2205 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2200 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2193 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2186 - accuracy: 0.92 - ETA: 59s - loss: 0.2186 - accuracy: 0.9206 - ETA: 58s - loss: 0.2189 - accuracy: 0.920 - ETA: 57s - loss: 0.2179 - accuracy: 0.920 - ETA: 56s - loss: 0.2169 - accuracy: 0.921 - ETA: 55s - loss: 0.2163 - accuracy: 0.921 - ETA: 54s - loss: 0.2157 - accuracy: 0.921 - ETA: 53s - loss: 0.2161 - accuracy: 0.921 - ETA: 52s - loss: 0.2158 - accuracy: 0.921 - ETA: 51s - loss: 0.2163 - accuracy: 0.921 - ETA: 50s - loss: 0.2162 - accuracy: 0.921 - ETA: 50s - loss: 0.2158 - accuracy: 0.921 - ETA: 49s - loss: 0.2161 - accuracy: 0.921 - ETA: 48s - loss: 0.2158 - accuracy: 0.921 - ETA: 47s - loss: 0.2152 - accuracy: 0.922 - ETA: 46s - loss: 0.2166 - accuracy: 0.921 - ETA: 45s - loss: 0.2167 - accuracy: 0.921 - ETA: 44s - loss: 0.2165 - accuracy: 0.922 - ETA: 43s - loss: 0.2166 - accuracy: 0.922 - ETA: 42s - loss: 0.2160 - accuracy: 0.922 - ETA: 41s - loss: 0.2166 - accuracy: 0.922 - ETA: 40s - loss: 0.2163 - accuracy: 0.922 - ETA: 40s - loss: 0.2158 - accuracy: 0.922 - ETA: 39s - loss: 0.2162 - accuracy: 0.922 - ETA: 38s - loss: 0.2161 - accuracy: 0.922 - ETA: 37s - loss: 0.2159 - accuracy: 0.922 - ETA: 36s - loss: 0.2163 - accuracy: 0.922 - ETA: 35s - loss: 0.2162 - accuracy: 0.922 - ETA: 34s - loss: 0.2161 - accuracy: 0.922 - ETA: 33s - loss: 0.2154 - accuracy: 0.922 - ETA: 32s - loss: 0.2147 - accuracy: 0.922 - ETA: 31s - loss: 0.2139 - accuracy: 0.922 - ETA: 30s - loss: 0.2145 - accuracy: 0.922 - ETA: 30s - loss: 0.2149 - accuracy: 0.922 - ETA: 29s - loss: 0.2147 - accuracy: 0.922 - ETA: 28s - loss: 0.2148 - accuracy: 0.922 - ETA: 27s - loss: 0.2151 - accuracy: 0.922 - ETA: 26s - loss: 0.2152 - accuracy: 0.922 - ETA: 25s - loss: 0.2147 - accuracy: 0.922 - ETA: 24s - loss: 0.2144 - accuracy: 0.922 - ETA: 23s - loss: 0.2139 - accuracy: 0.922 - ETA: 22s - loss: 0.2134 - accuracy: 0.922 - ETA: 21s - loss: 0.2141 - accuracy: 0.922 - ETA: 20s - loss: 0.2151 - accuracy: 0.922 - ETA: 19s - loss: 0.2156 - accuracy: 0.922 - ETA: 19s - loss: 0.2161 - accuracy: 0.922 - ETA: 18s - loss: 0.2154 - accuracy: 0.922 - ETA: 17s - loss: 0.2152 - accuracy: 0.922 - ETA: 16s - loss: 0.2154 - accuracy: 0.922 - ETA: 15s - loss: 0.2155 - accuracy: 0.922 - ETA: 14s - loss: 0.2162 - accuracy: 0.921 - ETA: 13s - loss: 0.2172 - accuracy: 0.921 - ETA: 12s - loss: 0.2170 - accuracy: 0.921 - ETA: 11s - loss: 0.2169 - accuracy: 0.921 - ETA: 10s - loss: 0.2171 - accuracy: 0.921 - ETA: 9s - loss: 0.2170 - accuracy: 0.921 - ETA: 9s - loss: 0.2166 - accuracy: 0.92 - ETA: 8s - loss: 0.2166 - accuracy: 0.92 - ETA: 7s - loss: 0.2169 - accuracy: 0.92 - ETA: 6s - loss: 0.2161 - accuracy: 0.92 - ETA: 5s - loss: 0.2160 - accuracy: 0.92 - ETA: 4s - loss: 0.2164 - accuracy: 0.92 - ETA: 3s - loss: 0.2167 - accuracy: 0.92 - ETA: 2s - loss: 0.2165 - accuracy: 0.92 - ETA: 1s - loss: 0.2162 - accuracy: 0.92 - ETA: 0s - loss: 0.2160 - accuracy: 0.92 - 149s 8ms/step - loss: 0.2162 - accuracy: 0.9211 - val_loss: 1.7447 - val_accuracy: 0.7631\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:28 - loss: 0.2703 - accuracy: 0.90 - ETA: 2:19 - loss: 0.2909 - accuracy: 0.90 - ETA: 2:18 - loss: 0.2257 - accuracy: 0.92 - ETA: 2:15 - loss: 0.2060 - accuracy: 0.92 - ETA: 2:14 - loss: 0.2189 - accuracy: 0.92 - ETA: 2:12 - loss: 0.2339 - accuracy: 0.91 - ETA: 2:13 - loss: 0.2326 - accuracy: 0.91 - ETA: 2:13 - loss: 0.2389 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2302 - accuracy: 0.92 - ETA: 2:10 - loss: 0.2235 - accuracy: 0.92 - ETA: 2:09 - loss: 0.2176 - accuracy: 0.92 - ETA: 2:08 - loss: 0.2174 - accuracy: 0.92 - ETA: 2:07 - loss: 0.2159 - accuracy: 0.92 - ETA: 2:06 - loss: 0.2176 - accuracy: 0.92 - ETA: 2:05 - loss: 0.2178 - accuracy: 0.92 - ETA: 2:04 - loss: 0.2187 - accuracy: 0.92 - ETA: 2:03 - loss: 0.2160 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2173 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2183 - accuracy: 0.92 - ETA: 2:01 - loss: 0.2167 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2197 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2190 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2172 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2151 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2094 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2087 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2070 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2064 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2039 - accuracy: 0.92 - ETA: 1:52 - loss: 0.2038 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2026 - accuracy: 0.92 - ETA: 1:50 - loss: 0.2026 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2033 - accuracy: 0.92 - ETA: 1:48 - loss: 0.2028 - accuracy: 0.92 - ETA: 1:47 - loss: 0.2025 - accuracy: 0.92 - ETA: 1:46 - loss: 0.2039 - accuracy: 0.92 - ETA: 1:45 - loss: 0.2029 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2059 - accuracy: 0.92 - ETA: 1:43 - loss: 0.2098 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2118 - accuracy: 0.92 - ETA: 1:41 - loss: 0.2128 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2141 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2127 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2112 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2103 - accuracy: 0.92 - ETA: 1:36 - loss: 0.2098 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2118 - accuracy: 0.92 - ETA: 1:34 - loss: 0.2132 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2143 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2134 - accuracy: 0.92 - ETA: 1:32 - loss: 0.2119 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2128 - accuracy: 0.92 - ETA: 1:30 - loss: 0.2129 - accuracy: 0.92 - ETA: 1:29 - loss: 0.2132 - accuracy: 0.92 - ETA: 1:28 - loss: 0.2123 - accuracy: 0.92 - ETA: 1:27 - loss: 0.2132 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2128 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2137 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2145 - accuracy: 0.92 - ETA: 1:23 - loss: 0.2129 - accuracy: 0.92 - ETA: 1:22 - loss: 0.2139 - accuracy: 0.92 - ETA: 1:21 - loss: 0.2141 - accuracy: 0.92 - ETA: 1:20 - loss: 0.2158 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2148 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2140 - accuracy: 0.92 - ETA: 1:18 - loss: 0.2142 - accuracy: 0.92 - ETA: 1:17 - loss: 0.2150 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2139 - accuracy: 0.92 - ETA: 1:15 - loss: 0.2143 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2150 - accuracy: 0.92 - ETA: 1:13 - loss: 0.2154 - accuracy: 0.92 - ETA: 1:12 - loss: 0.2146 - accuracy: 0.92 - ETA: 1:11 - loss: 0.2168 - accuracy: 0.92 - ETA: 1:10 - loss: 0.2174 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2174 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2164 - accuracy: 0.92 - ETA: 1:07 - loss: 0.2158 - accuracy: 0.92 - ETA: 1:07 - loss: 0.2154 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2158 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2157 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2163 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2159 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2155 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2144 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2144 - accuracy: 0.92 - ETA: 59s - loss: 0.2142 - accuracy: 0.9214 - ETA: 58s - loss: 0.2140 - accuracy: 0.921 - ETA: 57s - loss: 0.2148 - accuracy: 0.921 - ETA: 56s - loss: 0.2144 - accuracy: 0.921 - ETA: 55s - loss: 0.2143 - accuracy: 0.921 - ETA: 54s - loss: 0.2132 - accuracy: 0.921 - ETA: 54s - loss: 0.2127 - accuracy: 0.922 - ETA: 53s - loss: 0.2125 - accuracy: 0.922 - ETA: 52s - loss: 0.2130 - accuracy: 0.921 - ETA: 51s - loss: 0.2133 - accuracy: 0.921 - ETA: 50s - loss: 0.2132 - accuracy: 0.921 - ETA: 49s - loss: 0.2126 - accuracy: 0.922 - ETA: 48s - loss: 0.2126 - accuracy: 0.922 - ETA: 47s - loss: 0.2123 - accuracy: 0.922 - ETA: 46s - loss: 0.2120 - accuracy: 0.922 - ETA: 45s - loss: 0.2117 - accuracy: 0.922 - ETA: 44s - loss: 0.2113 - accuracy: 0.922 - ETA: 43s - loss: 0.2111 - accuracy: 0.922 - ETA: 43s - loss: 0.2120 - accuracy: 0.922 - ETA: 42s - loss: 0.2124 - accuracy: 0.921 - ETA: 41s - loss: 0.2120 - accuracy: 0.922 - ETA: 40s - loss: 0.2124 - accuracy: 0.922 - ETA: 39s - loss: 0.2124 - accuracy: 0.922 - ETA: 38s - loss: 0.2131 - accuracy: 0.921 - ETA: 37s - loss: 0.2128 - accuracy: 0.922 - ETA: 36s - loss: 0.2128 - accuracy: 0.922 - ETA: 35s - loss: 0.2137 - accuracy: 0.921 - ETA: 34s - loss: 0.2134 - accuracy: 0.921 - ETA: 33s - loss: 0.2131 - accuracy: 0.922 - ETA: 32s - loss: 0.2131 - accuracy: 0.922 - ETA: 31s - loss: 0.2139 - accuracy: 0.922 - ETA: 31s - loss: 0.2134 - accuracy: 0.922 - ETA: 30s - loss: 0.2133 - accuracy: 0.922 - ETA: 29s - loss: 0.2145 - accuracy: 0.921 - ETA: 28s - loss: 0.2146 - accuracy: 0.921 - ETA: 27s - loss: 0.2146 - accuracy: 0.921 - ETA: 26s - loss: 0.2144 - accuracy: 0.921 - ETA: 25s - loss: 0.2152 - accuracy: 0.921 - ETA: 24s - loss: 0.2151 - accuracy: 0.921 - ETA: 23s - loss: 0.2154 - accuracy: 0.921 - ETA: 22s - loss: 0.2149 - accuracy: 0.921 - ETA: 21s - loss: 0.2150 - accuracy: 0.921 - ETA: 20s - loss: 0.2149 - accuracy: 0.921 - ETA: 20s - loss: 0.2144 - accuracy: 0.921 - ETA: 19s - loss: 0.2145 - accuracy: 0.921 - ETA: 18s - loss: 0.2147 - accuracy: 0.921 - ETA: 17s - loss: 0.2144 - accuracy: 0.921 - ETA: 16s - loss: 0.2154 - accuracy: 0.921 - ETA: 15s - loss: 0.2153 - accuracy: 0.921 - ETA: 14s - loss: 0.2152 - accuracy: 0.921 - ETA: 13s - loss: 0.2157 - accuracy: 0.921 - ETA: 12s - loss: 0.2157 - accuracy: 0.921 - ETA: 11s - loss: 0.2160 - accuracy: 0.921 - ETA: 10s - loss: 0.2151 - accuracy: 0.921 - ETA: 9s - loss: 0.2147 - accuracy: 0.921 - ETA: 9s - loss: 0.2144 - accuracy: 0.92 - ETA: 8s - loss: 0.2139 - accuracy: 0.92 - ETA: 7s - loss: 0.2142 - accuracy: 0.92 - ETA: 6s - loss: 0.2150 - accuracy: 0.92 - ETA: 5s - loss: 0.2143 - accuracy: 0.92 - ETA: 4s - loss: 0.2143 - accuracy: 0.92 - ETA: 3s - loss: 0.2146 - accuracy: 0.92 - ETA: 2s - loss: 0.2149 - accuracy: 0.92 - ETA: 1s - loss: 0.2146 - accuracy: 0.92 - ETA: 0s - loss: 0.2148 - accuracy: 0.92 - 151s 8ms/step - loss: 0.2143 - accuracy: 0.9221 - val_loss: 1.7476 - val_accuracy: 0.7672\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:29 - loss: 0.2765 - accuracy: 0.89 - ETA: 2:22 - loss: 0.2211 - accuracy: 0.92 - ETA: 2:18 - loss: 0.1857 - accuracy: 0.92 - ETA: 2:16 - loss: 0.1740 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1716 - accuracy: 0.93 - ETA: 2:12 - loss: 0.1759 - accuracy: 0.93 - ETA: 2:11 - loss: 0.1759 - accuracy: 0.93 - ETA: 2:10 - loss: 0.1715 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1719 - accuracy: 0.93 - ETA: 2:08 - loss: 0.1749 - accuracy: 0.93 - ETA: 2:07 - loss: 0.1765 - accuracy: 0.93 - ETA: 2:05 - loss: 0.1837 - accuracy: 0.93 - ETA: 2:04 - loss: 0.1846 - accuracy: 0.93 - ETA: 2:03 - loss: 0.1839 - accuracy: 0.93 - ETA: 2:02 - loss: 0.1839 - accuracy: 0.93 - ETA: 2:01 - loss: 0.1857 - accuracy: 0.93 - ETA: 2:01 - loss: 0.1919 - accuracy: 0.92 - ETA: 2:00 - loss: 0.1904 - accuracy: 0.92 - ETA: 2:00 - loss: 0.1970 - accuracy: 0.92 - ETA: 2:00 - loss: 0.1930 - accuracy: 0.92 - ETA: 1:59 - loss: 0.1927 - accuracy: 0.92 - ETA: 1:58 - loss: 0.1921 - accuracy: 0.92 - ETA: 1:57 - loss: 0.1901 - accuracy: 0.93 - ETA: 1:55 - loss: 0.1909 - accuracy: 0.93 - ETA: 1:54 - loss: 0.1955 - accuracy: 0.92 - ETA: 1:53 - loss: 0.1934 - accuracy: 0.92 - ETA: 1:52 - loss: 0.1947 - accuracy: 0.92 - ETA: 1:52 - loss: 0.1925 - accuracy: 0.93 - ETA: 1:51 - loss: 0.1941 - accuracy: 0.92 - ETA: 1:50 - loss: 0.1945 - accuracy: 0.92 - ETA: 1:49 - loss: 0.1936 - accuracy: 0.92 - ETA: 1:48 - loss: 0.1925 - accuracy: 0.92 - ETA: 1:47 - loss: 0.1930 - accuracy: 0.92 - ETA: 1:46 - loss: 0.1950 - accuracy: 0.92 - ETA: 1:45 - loss: 0.1940 - accuracy: 0.92 - ETA: 1:44 - loss: 0.1916 - accuracy: 0.92 - ETA: 1:43 - loss: 0.1930 - accuracy: 0.92 - ETA: 1:42 - loss: 0.1944 - accuracy: 0.92 - ETA: 1:41 - loss: 0.1927 - accuracy: 0.92 - ETA: 1:40 - loss: 0.1947 - accuracy: 0.92 - ETA: 1:40 - loss: 0.1942 - accuracy: 0.92 - ETA: 1:39 - loss: 0.1936 - accuracy: 0.92 - ETA: 1:38 - loss: 0.1932 - accuracy: 0.92 - ETA: 1:37 - loss: 0.1944 - accuracy: 0.92 - ETA: 1:36 - loss: 0.1961 - accuracy: 0.92 - ETA: 1:35 - loss: 0.1941 - accuracy: 0.92 - ETA: 1:34 - loss: 0.1940 - accuracy: 0.93 - ETA: 1:33 - loss: 0.1936 - accuracy: 0.93 - ETA: 1:32 - loss: 0.1953 - accuracy: 0.92 - ETA: 1:31 - loss: 0.1957 - accuracy: 0.92 - ETA: 1:30 - loss: 0.1977 - accuracy: 0.92 - ETA: 1:29 - loss: 0.1980 - accuracy: 0.92 - ETA: 1:29 - loss: 0.1968 - accuracy: 0.92 - ETA: 1:28 - loss: 0.1983 - accuracy: 0.92 - ETA: 1:27 - loss: 0.1992 - accuracy: 0.92 - ETA: 1:26 - loss: 0.1993 - accuracy: 0.92 - ETA: 1:25 - loss: 0.1976 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2011 - accuracy: 0.92 - ETA: 1:23 - loss: 0.1995 - accuracy: 0.92 - ETA: 1:22 - loss: 0.2006 - accuracy: 0.92 - ETA: 1:21 - loss: 0.1994 - accuracy: 0.92 - ETA: 1:21 - loss: 0.1985 - accuracy: 0.92 - ETA: 1:20 - loss: 0.1979 - accuracy: 0.92 - ETA: 1:19 - loss: 0.1973 - accuracy: 0.92 - ETA: 1:18 - loss: 0.1983 - accuracy: 0.92 - ETA: 1:17 - loss: 0.1997 - accuracy: 0.92 - ETA: 1:16 - loss: 0.1996 - accuracy: 0.92 - ETA: 1:15 - loss: 0.1999 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2001 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2003 - accuracy: 0.92 - ETA: 1:13 - loss: 0.2007 - accuracy: 0.92 - ETA: 1:12 - loss: 0.2017 - accuracy: 0.92 - ETA: 1:11 - loss: 0.2020 - accuracy: 0.92 - ETA: 1:10 - loss: 0.2012 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2014 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2015 - accuracy: 0.92 - ETA: 1:07 - loss: 0.2015 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2012 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2010 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2008 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2001 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2001 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2010 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2008 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2010 - accuracy: 0.92 - ETA: 59s - loss: 0.2015 - accuracy: 0.9270 - ETA: 58s - loss: 0.2015 - accuracy: 0.926 - ETA: 57s - loss: 0.2011 - accuracy: 0.927 - ETA: 56s - loss: 0.2004 - accuracy: 0.927 - ETA: 55s - loss: 0.2007 - accuracy: 0.927 - ETA: 54s - loss: 0.2013 - accuracy: 0.926 - ETA: 53s - loss: 0.2019 - accuracy: 0.926 - ETA: 52s - loss: 0.2009 - accuracy: 0.927 - ETA: 52s - loss: 0.2007 - accuracy: 0.926 - ETA: 51s - loss: 0.2004 - accuracy: 0.926 - ETA: 50s - loss: 0.2004 - accuracy: 0.926 - ETA: 49s - loss: 0.2014 - accuracy: 0.926 - ETA: 48s - loss: 0.2019 - accuracy: 0.925 - ETA: 47s - loss: 0.2017 - accuracy: 0.925 - ETA: 46s - loss: 0.2020 - accuracy: 0.925 - ETA: 45s - loss: 0.2015 - accuracy: 0.925 - ETA: 44s - loss: 0.2017 - accuracy: 0.925 - ETA: 43s - loss: 0.2029 - accuracy: 0.925 - ETA: 42s - loss: 0.2043 - accuracy: 0.925 - ETA: 42s - loss: 0.2046 - accuracy: 0.924 - ETA: 41s - loss: 0.2045 - accuracy: 0.925 - ETA: 40s - loss: 0.2045 - accuracy: 0.924 - ETA: 39s - loss: 0.2052 - accuracy: 0.924 - ETA: 38s - loss: 0.2054 - accuracy: 0.924 - ETA: 37s - loss: 0.2054 - accuracy: 0.924 - ETA: 36s - loss: 0.2055 - accuracy: 0.924 - ETA: 35s - loss: 0.2056 - accuracy: 0.924 - ETA: 34s - loss: 0.2053 - accuracy: 0.924 - ETA: 33s - loss: 0.2056 - accuracy: 0.924 - ETA: 32s - loss: 0.2049 - accuracy: 0.924 - ETA: 31s - loss: 0.2055 - accuracy: 0.924 - ETA: 30s - loss: 0.2051 - accuracy: 0.924 - ETA: 30s - loss: 0.2046 - accuracy: 0.924 - ETA: 29s - loss: 0.2041 - accuracy: 0.925 - ETA: 28s - loss: 0.2040 - accuracy: 0.925 - ETA: 27s - loss: 0.2034 - accuracy: 0.925 - ETA: 26s - loss: 0.2027 - accuracy: 0.925 - ETA: 25s - loss: 0.2023 - accuracy: 0.925 - ETA: 24s - loss: 0.2024 - accuracy: 0.925 - ETA: 23s - loss: 0.2024 - accuracy: 0.925 - ETA: 22s - loss: 0.2018 - accuracy: 0.926 - ETA: 21s - loss: 0.2019 - accuracy: 0.926 - ETA: 20s - loss: 0.2024 - accuracy: 0.925 - ETA: 19s - loss: 0.2022 - accuracy: 0.925 - ETA: 19s - loss: 0.2019 - accuracy: 0.925 - ETA: 18s - loss: 0.2016 - accuracy: 0.925 - ETA: 17s - loss: 0.2014 - accuracy: 0.926 - ETA: 16s - loss: 0.2011 - accuracy: 0.926 - ETA: 15s - loss: 0.2013 - accuracy: 0.925 - ETA: 14s - loss: 0.2026 - accuracy: 0.925 - ETA: 13s - loss: 0.2024 - accuracy: 0.925 - ETA: 12s - loss: 0.2033 - accuracy: 0.924 - ETA: 11s - loss: 0.2032 - accuracy: 0.925 - ETA: 10s - loss: 0.2046 - accuracy: 0.924 - ETA: 9s - loss: 0.2048 - accuracy: 0.924 - ETA: 9s - loss: 0.2050 - accuracy: 0.92 - ETA: 8s - loss: 0.2048 - accuracy: 0.92 - ETA: 7s - loss: 0.2050 - accuracy: 0.92 - ETA: 6s - loss: 0.2052 - accuracy: 0.92 - ETA: 5s - loss: 0.2051 - accuracy: 0.92 - ETA: 4s - loss: 0.2050 - accuracy: 0.92 - ETA: 3s - loss: 0.2044 - accuracy: 0.92 - ETA: 2s - loss: 0.2045 - accuracy: 0.92 - ETA: 1s - loss: 0.2045 - accuracy: 0.92 - ETA: 0s - loss: 0.2040 - accuracy: 0.92 - 149s 8ms/step - loss: 0.2042 - accuracy: 0.9241 - val_loss: 1.7709 - val_accuracy: 0.7660\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:18 - loss: 0.1491 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1632 - accuracy: 0.94 - ETA: 2:16 - loss: 0.1639 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1657 - accuracy: 0.93 - ETA: 2:13 - loss: 0.1729 - accuracy: 0.93 - ETA: 2:11 - loss: 0.1855 - accuracy: 0.92 - ETA: 2:10 - loss: 0.1879 - accuracy: 0.92 - ETA: 2:08 - loss: 0.1876 - accuracy: 0.92 - ETA: 2:06 - loss: 0.1894 - accuracy: 0.92 - ETA: 2:05 - loss: 0.2017 - accuracy: 0.92 - ETA: 2:04 - loss: 0.2025 - accuracy: 0.92 - ETA: 2:03 - loss: 0.1999 - accuracy: 0.92 - ETA: 2:03 - loss: 0.2022 - accuracy: 0.92 - ETA: 2:02 - loss: 0.1998 - accuracy: 0.92 - ETA: 2:01 - loss: 0.2007 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2020 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2011 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2005 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2053 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2088 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2145 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2130 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2128 - accuracy: 0.92 - ETA: 1:52 - loss: 0.2155 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2137 - accuracy: 0.92 - ETA: 1:50 - loss: 0.2155 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2192 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2184 - accuracy: 0.91 - ETA: 1:48 - loss: 0.2171 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2160 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2151 - accuracy: 0.91 - ETA: 1:46 - loss: 0.2146 - accuracy: 0.92 - ETA: 1:45 - loss: 0.2147 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2135 - accuracy: 0.92 - ETA: 1:43 - loss: 0.2130 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2141 - accuracy: 0.92 - ETA: 1:41 - loss: 0.2145 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2136 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2137 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2176 - accuracy: 0.92 - ETA: 1:38 - loss: 0.2178 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2183 - accuracy: 0.92 - ETA: 1:36 - loss: 0.2182 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2183 - accuracy: 0.92 - ETA: 1:34 - loss: 0.2203 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2218 - accuracy: 0.91 - ETA: 1:32 - loss: 0.2196 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2183 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2218 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2214 - accuracy: 0.91 - ETA: 1:29 - loss: 0.2200 - accuracy: 0.92 - ETA: 1:28 - loss: 0.2188 - accuracy: 0.92 - ETA: 1:27 - loss: 0.2175 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2191 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2191 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2195 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2202 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2216 - accuracy: 0.91 - ETA: 1:22 - loss: 0.2228 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2215 - accuracy: 0.91 - ETA: 1:20 - loss: 0.2211 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2204 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2189 - accuracy: 0.91 - ETA: 1:17 - loss: 0.2195 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2193 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2193 - accuracy: 0.91 - ETA: 1:15 - loss: 0.2204 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2209 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2209 - accuracy: 0.91 - ETA: 1:12 - loss: 0.2223 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2222 - accuracy: 0.91 - ETA: 1:10 - loss: 0.2216 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2214 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2209 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2219 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2208 - accuracy: 0.91 - ETA: 1:07 - loss: 0.2200 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2200 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2205 - accuracy: 0.91 - ETA: 1:04 - loss: 0.2208 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2209 - accuracy: 0.91 - ETA: 1:02 - loss: 0.2208 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2211 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2209 - accuracy: 0.91 - ETA: 59s - loss: 0.2216 - accuracy: 0.9199 - ETA: 58s - loss: 0.2202 - accuracy: 0.920 - ETA: 58s - loss: 0.2197 - accuracy: 0.920 - ETA: 57s - loss: 0.2195 - accuracy: 0.920 - ETA: 56s - loss: 0.2197 - accuracy: 0.920 - ETA: 55s - loss: 0.2196 - accuracy: 0.920 - ETA: 54s - loss: 0.2200 - accuracy: 0.920 - ETA: 53s - loss: 0.2201 - accuracy: 0.920 - ETA: 52s - loss: 0.2201 - accuracy: 0.920 - ETA: 51s - loss: 0.2201 - accuracy: 0.920 - ETA: 50s - loss: 0.2206 - accuracy: 0.919 - ETA: 49s - loss: 0.2204 - accuracy: 0.919 - ETA: 48s - loss: 0.2195 - accuracy: 0.920 - ETA: 47s - loss: 0.2190 - accuracy: 0.920 - ETA: 46s - loss: 0.2190 - accuracy: 0.920 - ETA: 45s - loss: 0.2181 - accuracy: 0.920 - ETA: 45s - loss: 0.2177 - accuracy: 0.920 - ETA: 44s - loss: 0.2174 - accuracy: 0.920 - ETA: 43s - loss: 0.2166 - accuracy: 0.920 - ETA: 42s - loss: 0.2164 - accuracy: 0.920 - ETA: 41s - loss: 0.2158 - accuracy: 0.921 - ETA: 40s - loss: 0.2176 - accuracy: 0.920 - ETA: 39s - loss: 0.2178 - accuracy: 0.920 - ETA: 38s - loss: 0.2173 - accuracy: 0.920 - ETA: 37s - loss: 0.2163 - accuracy: 0.920 - ETA: 36s - loss: 0.2159 - accuracy: 0.921 - ETA: 35s - loss: 0.2157 - accuracy: 0.920 - ETA: 35s - loss: 0.2153 - accuracy: 0.921 - ETA: 34s - loss: 0.2150 - accuracy: 0.921 - ETA: 33s - loss: 0.2160 - accuracy: 0.920 - ETA: 32s - loss: 0.2153 - accuracy: 0.921 - ETA: 31s - loss: 0.2151 - accuracy: 0.921 - ETA: 30s - loss: 0.2147 - accuracy: 0.921 - ETA: 29s - loss: 0.2144 - accuracy: 0.921 - ETA: 28s - loss: 0.2143 - accuracy: 0.921 - ETA: 27s - loss: 0.2144 - accuracy: 0.921 - ETA: 26s - loss: 0.2148 - accuracy: 0.921 - ETA: 26s - loss: 0.2145 - accuracy: 0.921 - ETA: 25s - loss: 0.2151 - accuracy: 0.921 - ETA: 24s - loss: 0.2156 - accuracy: 0.921 - ETA: 23s - loss: 0.2159 - accuracy: 0.921 - ETA: 22s - loss: 0.2152 - accuracy: 0.921 - ETA: 21s - loss: 0.2162 - accuracy: 0.921 - ETA: 20s - loss: 0.2161 - accuracy: 0.921 - ETA: 19s - loss: 0.2159 - accuracy: 0.921 - ETA: 18s - loss: 0.2155 - accuracy: 0.921 - ETA: 17s - loss: 0.2153 - accuracy: 0.921 - ETA: 17s - loss: 0.2159 - accuracy: 0.921 - ETA: 16s - loss: 0.2155 - accuracy: 0.921 - ETA: 15s - loss: 0.2149 - accuracy: 0.921 - ETA: 14s - loss: 0.2144 - accuracy: 0.921 - ETA: 13s - loss: 0.2151 - accuracy: 0.921 - ETA: 12s - loss: 0.2155 - accuracy: 0.921 - ETA: 11s - loss: 0.2156 - accuracy: 0.921 - ETA: 10s - loss: 0.2154 - accuracy: 0.921 - ETA: 9s - loss: 0.2148 - accuracy: 0.921 - ETA: 8s - loss: 0.2153 - accuracy: 0.92 - ETA: 8s - loss: 0.2156 - accuracy: 0.92 - ETA: 7s - loss: 0.2149 - accuracy: 0.92 - ETA: 6s - loss: 0.2144 - accuracy: 0.92 - ETA: 5s - loss: 0.2145 - accuracy: 0.92 - ETA: 4s - loss: 0.2144 - accuracy: 0.92 - ETA: 3s - loss: 0.2149 - accuracy: 0.92 - ETA: 2s - loss: 0.2149 - accuracy: 0.92 - ETA: 1s - loss: 0.2145 - accuracy: 0.92 - ETA: 0s - loss: 0.2143 - accuracy: 0.92 - 147s 8ms/step - loss: 0.2139 - accuracy: 0.9219 - val_loss: 1.7477 - val_accuracy: 0.7652\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:21 - loss: 0.3089 - accuracy: 0.89 - ETA: 2:15 - loss: 0.2252 - accuracy: 0.92 - ETA: 2:15 - loss: 0.2158 - accuracy: 0.92 - ETA: 2:13 - loss: 0.2034 - accuracy: 0.92 - ETA: 2:11 - loss: 0.1982 - accuracy: 0.92 - ETA: 2:11 - loss: 0.2085 - accuracy: 0.92 - ETA: 2:09 - loss: 0.1980 - accuracy: 0.92 - ETA: 2:08 - loss: 0.1945 - accuracy: 0.92 - ETA: 2:09 - loss: 0.1914 - accuracy: 0.92 - ETA: 2:09 - loss: 0.2041 - accuracy: 0.92 - ETA: 2:07 - loss: 0.2013 - accuracy: 0.92 - ETA: 2:06 - loss: 0.1974 - accuracy: 0.92 - ETA: 2:04 - loss: 0.2008 - accuracy: 0.92 - ETA: 2:03 - loss: 0.1945 - accuracy: 0.92 - ETA: 2:02 - loss: 0.1936 - accuracy: 0.92 - ETA: 2:01 - loss: 0.1895 - accuracy: 0.93 - ETA: 2:00 - loss: 0.1905 - accuracy: 0.92 - ETA: 1:59 - loss: 0.1885 - accuracy: 0.93 - ETA: 1:57 - loss: 0.1868 - accuracy: 0.93 - ETA: 1:56 - loss: 0.1971 - accuracy: 0.92 - ETA: 1:55 - loss: 0.1964 - accuracy: 0.92 - ETA: 1:54 - loss: 0.1983 - accuracy: 0.92 - ETA: 1:53 - loss: 0.1923 - accuracy: 0.92 - ETA: 1:52 - loss: 0.1930 - accuracy: 0.92 - ETA: 1:51 - loss: 0.1911 - accuracy: 0.92 - ETA: 1:50 - loss: 0.1936 - accuracy: 0.92 - ETA: 1:50 - loss: 0.1924 - accuracy: 0.92 - ETA: 1:50 - loss: 0.1923 - accuracy: 0.92 - ETA: 1:48 - loss: 0.1929 - accuracy: 0.92 - ETA: 1:47 - loss: 0.1944 - accuracy: 0.92 - ETA: 1:47 - loss: 0.1927 - accuracy: 0.92 - ETA: 1:46 - loss: 0.1939 - accuracy: 0.92 - ETA: 1:45 - loss: 0.1944 - accuracy: 0.92 - ETA: 1:44 - loss: 0.1963 - accuracy: 0.92 - ETA: 1:43 - loss: 0.2016 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2043 - accuracy: 0.92 - ETA: 1:41 - loss: 0.2016 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2026 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2030 - accuracy: 0.92 - ETA: 1:38 - loss: 0.2006 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2026 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2050 - accuracy: 0.92 - ETA: 1:36 - loss: 0.2058 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2065 - accuracy: 0.92 - ETA: 1:34 - loss: 0.2045 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2045 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2038 - accuracy: 0.92 - ETA: 1:32 - loss: 0.2025 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2018 - accuracy: 0.92 - ETA: 1:30 - loss: 0.2009 - accuracy: 0.92 - ETA: 1:29 - loss: 0.2010 - accuracy: 0.92 - ETA: 1:28 - loss: 0.2012 - accuracy: 0.92 - ETA: 1:27 - loss: 0.2046 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2040 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2038 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2033 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2039 - accuracy: 0.92 - ETA: 1:23 - loss: 0.2048 - accuracy: 0.92 - ETA: 1:22 - loss: 0.2039 - accuracy: 0.92 - ETA: 1:21 - loss: 0.2039 - accuracy: 0.92 - ETA: 1:20 - loss: 0.2043 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2034 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2028 - accuracy: 0.92 - ETA: 1:18 - loss: 0.2014 - accuracy: 0.92 - ETA: 1:17 - loss: 0.2009 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2017 - accuracy: 0.92 - ETA: 1:15 - loss: 0.2000 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2001 - accuracy: 0.92 - ETA: 1:13 - loss: 0.2012 - accuracy: 0.92 - ETA: 1:12 - loss: 0.2038 - accuracy: 0.92 - ETA: 1:11 - loss: 0.2037 - accuracy: 0.92 - ETA: 1:10 - loss: 0.2042 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2038 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2035 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2047 - accuracy: 0.92 - ETA: 1:07 - loss: 0.2046 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2031 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2031 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2049 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2045 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2050 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2041 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2044 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2046 - accuracy: 0.92 - ETA: 59s - loss: 0.2035 - accuracy: 0.9235 - ETA: 58s - loss: 0.2049 - accuracy: 0.923 - ETA: 58s - loss: 0.2044 - accuracy: 0.923 - ETA: 57s - loss: 0.2046 - accuracy: 0.923 - ETA: 56s - loss: 0.2047 - accuracy: 0.923 - ETA: 55s - loss: 0.2043 - accuracy: 0.923 - ETA: 54s - loss: 0.2047 - accuracy: 0.923 - ETA: 53s - loss: 0.2048 - accuracy: 0.923 - ETA: 52s - loss: 0.2059 - accuracy: 0.923 - ETA: 51s - loss: 0.2046 - accuracy: 0.923 - ETA: 50s - loss: 0.2051 - accuracy: 0.923 - ETA: 50s - loss: 0.2052 - accuracy: 0.923 - ETA: 49s - loss: 0.2051 - accuracy: 0.923 - ETA: 48s - loss: 0.2050 - accuracy: 0.923 - ETA: 47s - loss: 0.2055 - accuracy: 0.923 - ETA: 46s - loss: 0.2054 - accuracy: 0.923 - ETA: 45s - loss: 0.2056 - accuracy: 0.923 - ETA: 44s - loss: 0.2051 - accuracy: 0.923 - ETA: 43s - loss: 0.2048 - accuracy: 0.923 - ETA: 42s - loss: 0.2053 - accuracy: 0.923 - ETA: 41s - loss: 0.2060 - accuracy: 0.922 - ETA: 41s - loss: 0.2060 - accuracy: 0.923 - ETA: 40s - loss: 0.2059 - accuracy: 0.922 - ETA: 39s - loss: 0.2055 - accuracy: 0.922 - ETA: 38s - loss: 0.2062 - accuracy: 0.922 - ETA: 37s - loss: 0.2071 - accuracy: 0.922 - ETA: 36s - loss: 0.2062 - accuracy: 0.922 - ETA: 35s - loss: 0.2066 - accuracy: 0.922 - ETA: 34s - loss: 0.2068 - accuracy: 0.922 - ETA: 33s - loss: 0.2066 - accuracy: 0.922 - ETA: 32s - loss: 0.2063 - accuracy: 0.922 - ETA: 31s - loss: 0.2056 - accuracy: 0.923 - ETA: 31s - loss: 0.2057 - accuracy: 0.923 - ETA: 30s - loss: 0.2052 - accuracy: 0.923 - ETA: 29s - loss: 0.2048 - accuracy: 0.923 - ETA: 28s - loss: 0.2044 - accuracy: 0.923 - ETA: 27s - loss: 0.2048 - accuracy: 0.923 - ETA: 26s - loss: 0.2053 - accuracy: 0.922 - ETA: 25s - loss: 0.2051 - accuracy: 0.922 - ETA: 24s - loss: 0.2053 - accuracy: 0.922 - ETA: 23s - loss: 0.2049 - accuracy: 0.922 - ETA: 22s - loss: 0.2055 - accuracy: 0.922 - ETA: 21s - loss: 0.2052 - accuracy: 0.922 - ETA: 20s - loss: 0.2047 - accuracy: 0.923 - ETA: 19s - loss: 0.2053 - accuracy: 0.922 - ETA: 19s - loss: 0.2053 - accuracy: 0.922 - ETA: 18s - loss: 0.2054 - accuracy: 0.922 - ETA: 17s - loss: 0.2050 - accuracy: 0.923 - ETA: 16s - loss: 0.2047 - accuracy: 0.923 - ETA: 15s - loss: 0.2051 - accuracy: 0.922 - ETA: 14s - loss: 0.2055 - accuracy: 0.922 - ETA: 13s - loss: 0.2056 - accuracy: 0.922 - ETA: 12s - loss: 0.2062 - accuracy: 0.922 - ETA: 11s - loss: 0.2062 - accuracy: 0.922 - ETA: 10s - loss: 0.2057 - accuracy: 0.922 - ETA: 9s - loss: 0.2053 - accuracy: 0.923 - ETA: 9s - loss: 0.2050 - accuracy: 0.92 - ETA: 8s - loss: 0.2042 - accuracy: 0.92 - ETA: 7s - loss: 0.2037 - accuracy: 0.92 - ETA: 6s - loss: 0.2038 - accuracy: 0.92 - ETA: 5s - loss: 0.2040 - accuracy: 0.92 - ETA: 4s - loss: 0.2038 - accuracy: 0.92 - ETA: 3s - loss: 0.2034 - accuracy: 0.92 - ETA: 2s - loss: 0.2028 - accuracy: 0.92 - ETA: 1s - loss: 0.2033 - accuracy: 0.92 - ETA: 0s - loss: 0.2030 - accuracy: 0.92 - 149s 8ms/step - loss: 0.2038 - accuracy: 0.9234 - val_loss: 1.7702 - val_accuracy: 0.7639\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:11 - loss: 0.1432 - accuracy: 0.94 - ETA: 2:08 - loss: 0.1587 - accuracy: 0.94 - ETA: 2:09 - loss: 0.1462 - accuracy: 0.94 - ETA: 2:14 - loss: 0.1666 - accuracy: 0.93 - ETA: 2:13 - loss: 0.1903 - accuracy: 0.92 - ETA: 2:11 - loss: 0.1854 - accuracy: 0.93 - ETA: 2:10 - loss: 0.1811 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1727 - accuracy: 0.93 - ETA: 2:08 - loss: 0.1782 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1822 - accuracy: 0.93 - ETA: 2:05 - loss: 0.1819 - accuracy: 0.93 - ETA: 2:05 - loss: 0.1843 - accuracy: 0.93 - ETA: 2:05 - loss: 0.1852 - accuracy: 0.93 - ETA: 2:04 - loss: 0.1890 - accuracy: 0.93 - ETA: 2:03 - loss: 0.1926 - accuracy: 0.92 - ETA: 2:02 - loss: 0.1962 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2015 - accuracy: 0.92 - ETA: 2:01 - loss: 0.2040 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2051 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2091 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2094 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2082 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2085 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2073 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2110 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2150 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2145 - accuracy: 0.92 - ETA: 1:52 - loss: 0.2162 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2182 - accuracy: 0.92 - ETA: 1:50 - loss: 0.2160 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2137 - accuracy: 0.92 - ETA: 1:48 - loss: 0.2117 - accuracy: 0.92 - ETA: 1:47 - loss: 0.2096 - accuracy: 0.92 - ETA: 1:46 - loss: 0.2095 - accuracy: 0.92 - ETA: 1:45 - loss: 0.2081 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2069 - accuracy: 0.92 - ETA: 1:43 - loss: 0.2079 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2077 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2086 - accuracy: 0.92 - ETA: 1:41 - loss: 0.2080 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2074 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2082 - accuracy: 0.92 - ETA: 1:38 - loss: 0.2082 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2070 - accuracy: 0.92 - ETA: 1:36 - loss: 0.2071 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2049 - accuracy: 0.92 - ETA: 1:34 - loss: 0.2053 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2049 - accuracy: 0.92 - ETA: 1:32 - loss: 0.2076 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2065 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2060 - accuracy: 0.92 - ETA: 1:29 - loss: 0.2052 - accuracy: 0.92 - ETA: 1:29 - loss: 0.2054 - accuracy: 0.92 - ETA: 1:28 - loss: 0.2059 - accuracy: 0.92 - ETA: 1:27 - loss: 0.2060 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2065 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2068 - accuracy: 0.92 - ETA: 1:24 - loss: 0.2098 - accuracy: 0.92 - ETA: 1:23 - loss: 0.2103 - accuracy: 0.92 - ETA: 1:22 - loss: 0.2127 - accuracy: 0.92 - ETA: 1:21 - loss: 0.2130 - accuracy: 0.92 - ETA: 1:20 - loss: 0.2121 - accuracy: 0.92 - ETA: 1:19 - loss: 0.2121 - accuracy: 0.92 - ETA: 1:18 - loss: 0.2119 - accuracy: 0.92 - ETA: 1:18 - loss: 0.2109 - accuracy: 0.92 - ETA: 1:17 - loss: 0.2112 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2102 - accuracy: 0.92 - ETA: 1:15 - loss: 0.2102 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2119 - accuracy: 0.92 - ETA: 1:13 - loss: 0.2126 - accuracy: 0.92 - ETA: 1:12 - loss: 0.2128 - accuracy: 0.92 - ETA: 1:11 - loss: 0.2121 - accuracy: 0.92 - ETA: 1:10 - loss: 0.2119 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2115 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2108 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2096 - accuracy: 0.92 - ETA: 1:07 - loss: 0.2086 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2086 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2086 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2070 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2073 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2078 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2069 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2074 - accuracy: 0.92 - ETA: 59s - loss: 0.2076 - accuracy: 0.9241 - ETA: 58s - loss: 0.2070 - accuracy: 0.924 - ETA: 58s - loss: 0.2069 - accuracy: 0.924 - ETA: 57s - loss: 0.2066 - accuracy: 0.924 - ETA: 56s - loss: 0.2063 - accuracy: 0.924 - ETA: 55s - loss: 0.2055 - accuracy: 0.925 - ETA: 54s - loss: 0.2047 - accuracy: 0.925 - ETA: 53s - loss: 0.2039 - accuracy: 0.925 - ETA: 52s - loss: 0.2039 - accuracy: 0.925 - ETA: 51s - loss: 0.2038 - accuracy: 0.925 - ETA: 50s - loss: 0.2037 - accuracy: 0.926 - ETA: 49s - loss: 0.2043 - accuracy: 0.925 - ETA: 49s - loss: 0.2049 - accuracy: 0.925 - ETA: 48s - loss: 0.2045 - accuracy: 0.925 - ETA: 47s - loss: 0.2042 - accuracy: 0.925 - ETA: 46s - loss: 0.2043 - accuracy: 0.925 - ETA: 45s - loss: 0.2050 - accuracy: 0.925 - ETA: 44s - loss: 0.2048 - accuracy: 0.925 - ETA: 43s - loss: 0.2046 - accuracy: 0.925 - ETA: 42s - loss: 0.2048 - accuracy: 0.925 - ETA: 41s - loss: 0.2041 - accuracy: 0.925 - ETA: 40s - loss: 0.2051 - accuracy: 0.925 - ETA: 39s - loss: 0.2054 - accuracy: 0.924 - ETA: 38s - loss: 0.2063 - accuracy: 0.924 - ETA: 38s - loss: 0.2063 - accuracy: 0.924 - ETA: 37s - loss: 0.2064 - accuracy: 0.924 - ETA: 36s - loss: 0.2059 - accuracy: 0.924 - ETA: 35s - loss: 0.2059 - accuracy: 0.924 - ETA: 34s - loss: 0.2053 - accuracy: 0.925 - ETA: 33s - loss: 0.2058 - accuracy: 0.924 - ETA: 32s - loss: 0.2061 - accuracy: 0.924 - ETA: 31s - loss: 0.2063 - accuracy: 0.924 - ETA: 30s - loss: 0.2062 - accuracy: 0.924 - ETA: 29s - loss: 0.2060 - accuracy: 0.924 - ETA: 28s - loss: 0.2061 - accuracy: 0.924 - ETA: 28s - loss: 0.2065 - accuracy: 0.924 - ETA: 27s - loss: 0.2062 - accuracy: 0.924 - ETA: 26s - loss: 0.2059 - accuracy: 0.924 - ETA: 25s - loss: 0.2058 - accuracy: 0.924 - ETA: 24s - loss: 0.2051 - accuracy: 0.925 - ETA: 23s - loss: 0.2063 - accuracy: 0.924 - ETA: 22s - loss: 0.2067 - accuracy: 0.924 - ETA: 21s - loss: 0.2060 - accuracy: 0.925 - ETA: 20s - loss: 0.2058 - accuracy: 0.925 - ETA: 19s - loss: 0.2056 - accuracy: 0.925 - ETA: 18s - loss: 0.2056 - accuracy: 0.925 - ETA: 18s - loss: 0.2058 - accuracy: 0.925 - ETA: 17s - loss: 0.2059 - accuracy: 0.924 - ETA: 16s - loss: 0.2052 - accuracy: 0.925 - ETA: 15s - loss: 0.2051 - accuracy: 0.925 - ETA: 14s - loss: 0.2057 - accuracy: 0.924 - ETA: 13s - loss: 0.2058 - accuracy: 0.924 - ETA: 12s - loss: 0.2061 - accuracy: 0.924 - ETA: 11s - loss: 0.2055 - accuracy: 0.924 - ETA: 10s - loss: 0.2058 - accuracy: 0.924 - ETA: 9s - loss: 0.2056 - accuracy: 0.924 - ETA: 8s - loss: 0.2065 - accuracy: 0.92 - ETA: 8s - loss: 0.2058 - accuracy: 0.92 - ETA: 7s - loss: 0.2056 - accuracy: 0.92 - ETA: 6s - loss: 0.2054 - accuracy: 0.92 - ETA: 5s - loss: 0.2054 - accuracy: 0.92 - ETA: 4s - loss: 0.2057 - accuracy: 0.92 - ETA: 3s - loss: 0.2058 - accuracy: 0.92 - ETA: 2s - loss: 0.2063 - accuracy: 0.92 - ETA: 1s - loss: 0.2056 - accuracy: 0.92 - ETA: 0s - loss: 0.2063 - accuracy: 0.92 - 149s 8ms/step - loss: 0.2062 - accuracy: 0.9245 - val_loss: 1.7545 - val_accuracy: 0.7681\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:11 - loss: 0.1984 - accuracy: 0.94 - ETA: 2:08 - loss: 0.1710 - accuracy: 0.94 - ETA: 2:08 - loss: 0.1837 - accuracy: 0.93 - ETA: 2:07 - loss: 0.2091 - accuracy: 0.92 - ETA: 2:07 - loss: 0.2056 - accuracy: 0.92 - ETA: 2:06 - loss: 0.2110 - accuracy: 0.92 - ETA: 2:06 - loss: 0.2139 - accuracy: 0.92 - ETA: 2:05 - loss: 0.2228 - accuracy: 0.91 - ETA: 2:04 - loss: 0.2248 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2193 - accuracy: 0.91 - ETA: 2:02 - loss: 0.2174 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2209 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2121 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2085 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2014 - accuracy: 0.92 - ETA: 1:59 - loss: 0.2032 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2031 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2013 - accuracy: 0.92 - ETA: 1:57 - loss: 0.2000 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2021 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2020 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2017 - accuracy: 0.92 - ETA: 1:55 - loss: 0.2048 - accuracy: 0.92 - ETA: 1:54 - loss: 0.2084 - accuracy: 0.92 - ETA: 1:54 - loss: 0.2070 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2110 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2124 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2092 - accuracy: 0.92 - ETA: 1:52 - loss: 0.2093 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2096 - accuracy: 0.92 - ETA: 1:50 - loss: 0.2100 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2092 - accuracy: 0.92 - ETA: 1:48 - loss: 0.2073 - accuracy: 0.92 - ETA: 1:47 - loss: 0.2058 - accuracy: 0.92 - ETA: 1:46 - loss: 0.2036 - accuracy: 0.92 - ETA: 1:45 - loss: 0.2034 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2067 - accuracy: 0.92 - ETA: 1:43 - loss: 0.2079 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2082 - accuracy: 0.92 - ETA: 1:41 - loss: 0.2092 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2095 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2091 - accuracy: 0.92 - ETA: 1:38 - loss: 0.2070 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2063 - accuracy: 0.92 - ETA: 1:36 - loss: 0.2057 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2056 - accuracy: 0.92 - ETA: 1:34 - loss: 0.2033 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2031 - accuracy: 0.92 - ETA: 1:32 - loss: 0.2025 - accuracy: 0.92 - ETA: 1:31 - loss: 0.2009 - accuracy: 0.92 - ETA: 1:31 - loss: 0.1995 - accuracy: 0.92 - ETA: 1:30 - loss: 0.1994 - accuracy: 0.92 - ETA: 1:29 - loss: 0.1978 - accuracy: 0.92 - ETA: 1:28 - loss: 0.1983 - accuracy: 0.92 - ETA: 1:27 - loss: 0.1986 - accuracy: 0.92 - ETA: 1:26 - loss: 0.1989 - accuracy: 0.92 - ETA: 1:25 - loss: 0.1987 - accuracy: 0.92 - ETA: 1:24 - loss: 0.1974 - accuracy: 0.92 - ETA: 1:23 - loss: 0.1984 - accuracy: 0.92 - ETA: 1:22 - loss: 0.1977 - accuracy: 0.92 - ETA: 1:21 - loss: 0.1971 - accuracy: 0.92 - ETA: 1:20 - loss: 0.1966 - accuracy: 0.92 - ETA: 1:19 - loss: 0.1961 - accuracy: 0.92 - ETA: 1:18 - loss: 0.1965 - accuracy: 0.92 - ETA: 1:17 - loss: 0.1974 - accuracy: 0.92 - ETA: 1:16 - loss: 0.1981 - accuracy: 0.92 - ETA: 1:15 - loss: 0.1971 - accuracy: 0.92 - ETA: 1:15 - loss: 0.1988 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2004 - accuracy: 0.92 - ETA: 1:13 - loss: 0.1991 - accuracy: 0.92 - ETA: 1:12 - loss: 0.1986 - accuracy: 0.92 - ETA: 1:11 - loss: 0.1980 - accuracy: 0.92 - ETA: 1:11 - loss: 0.1995 - accuracy: 0.92 - ETA: 1:10 - loss: 0.1986 - accuracy: 0.92 - ETA: 1:09 - loss: 0.1974 - accuracy: 0.92 - ETA: 1:08 - loss: 0.1976 - accuracy: 0.92 - ETA: 1:07 - loss: 0.1973 - accuracy: 0.92 - ETA: 1:06 - loss: 0.1971 - accuracy: 0.92 - ETA: 1:05 - loss: 0.1975 - accuracy: 0.92 - ETA: 1:04 - loss: 0.1972 - accuracy: 0.92 - ETA: 1:03 - loss: 0.1966 - accuracy: 0.92 - ETA: 1:02 - loss: 0.1968 - accuracy: 0.92 - ETA: 1:01 - loss: 0.1957 - accuracy: 0.92 - ETA: 1:00 - loss: 0.1957 - accuracy: 0.92 - ETA: 1:00 - loss: 0.1950 - accuracy: 0.92 - ETA: 59s - loss: 0.1949 - accuracy: 0.9275 - ETA: 58s - loss: 0.1943 - accuracy: 0.927 - ETA: 57s - loss: 0.1945 - accuracy: 0.927 - ETA: 56s - loss: 0.1938 - accuracy: 0.928 - ETA: 55s - loss: 0.1936 - accuracy: 0.928 - ETA: 54s - loss: 0.1936 - accuracy: 0.928 - ETA: 53s - loss: 0.1928 - accuracy: 0.928 - ETA: 52s - loss: 0.1938 - accuracy: 0.928 - ETA: 51s - loss: 0.1943 - accuracy: 0.928 - ETA: 50s - loss: 0.1938 - accuracy: 0.928 - ETA: 49s - loss: 0.1948 - accuracy: 0.927 - ETA: 49s - loss: 0.1952 - accuracy: 0.927 - ETA: 48s - loss: 0.1953 - accuracy: 0.927 - ETA: 47s - loss: 0.1955 - accuracy: 0.927 - ETA: 46s - loss: 0.1957 - accuracy: 0.927 - ETA: 45s - loss: 0.1955 - accuracy: 0.927 - ETA: 44s - loss: 0.1957 - accuracy: 0.927 - ETA: 43s - loss: 0.1948 - accuracy: 0.927 - ETA: 42s - loss: 0.1956 - accuracy: 0.927 - ETA: 41s - loss: 0.1954 - accuracy: 0.927 - ETA: 40s - loss: 0.1958 - accuracy: 0.927 - ETA: 39s - loss: 0.1954 - accuracy: 0.927 - ETA: 39s - loss: 0.1954 - accuracy: 0.927 - ETA: 38s - loss: 0.1949 - accuracy: 0.927 - ETA: 37s - loss: 0.1964 - accuracy: 0.926 - ETA: 36s - loss: 0.1967 - accuracy: 0.926 - ETA: 35s - loss: 0.1982 - accuracy: 0.926 - ETA: 34s - loss: 0.1990 - accuracy: 0.926 - ETA: 33s - loss: 0.1984 - accuracy: 0.926 - ETA: 32s - loss: 0.1983 - accuracy: 0.926 - ETA: 31s - loss: 0.1987 - accuracy: 0.926 - ETA: 30s - loss: 0.1989 - accuracy: 0.926 - ETA: 29s - loss: 0.1988 - accuracy: 0.926 - ETA: 29s - loss: 0.1985 - accuracy: 0.926 - ETA: 28s - loss: 0.1984 - accuracy: 0.926 - ETA: 27s - loss: 0.1987 - accuracy: 0.926 - ETA: 26s - loss: 0.1994 - accuracy: 0.925 - ETA: 25s - loss: 0.1995 - accuracy: 0.925 - ETA: 24s - loss: 0.1993 - accuracy: 0.925 - ETA: 23s - loss: 0.1987 - accuracy: 0.926 - ETA: 22s - loss: 0.1990 - accuracy: 0.926 - ETA: 21s - loss: 0.2002 - accuracy: 0.925 - ETA: 20s - loss: 0.2001 - accuracy: 0.925 - ETA: 19s - loss: 0.1999 - accuracy: 0.925 - ETA: 19s - loss: 0.2001 - accuracy: 0.925 - ETA: 18s - loss: 0.2002 - accuracy: 0.925 - ETA: 17s - loss: 0.2006 - accuracy: 0.925 - ETA: 16s - loss: 0.2002 - accuracy: 0.925 - ETA: 15s - loss: 0.2004 - accuracy: 0.925 - ETA: 14s - loss: 0.2006 - accuracy: 0.925 - ETA: 13s - loss: 0.2004 - accuracy: 0.925 - ETA: 12s - loss: 0.2003 - accuracy: 0.925 - ETA: 11s - loss: 0.2006 - accuracy: 0.925 - ETA: 10s - loss: 0.2008 - accuracy: 0.925 - ETA: 9s - loss: 0.2000 - accuracy: 0.925 - ETA: 8s - loss: 0.2004 - accuracy: 0.92 - ETA: 8s - loss: 0.1998 - accuracy: 0.92 - ETA: 7s - loss: 0.1996 - accuracy: 0.92 - ETA: 6s - loss: 0.2002 - accuracy: 0.92 - ETA: 5s - loss: 0.2007 - accuracy: 0.92 - ETA: 4s - loss: 0.2002 - accuracy: 0.92 - ETA: 3s - loss: 0.2003 - accuracy: 0.92 - ETA: 2s - loss: 0.2000 - accuracy: 0.92 - ETA: 1s - loss: 0.2000 - accuracy: 0.92 - ETA: 0s - loss: 0.1994 - accuracy: 0.92 - 149s 8ms/step - loss: 0.1994 - accuracy: 0.9261 - val_loss: 1.8200 - val_accuracy: 0.7658\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:25 - loss: 0.1763 - accuracy: 0.92 - ETA: 2:22 - loss: 0.1477 - accuracy: 0.94 - ETA: 2:22 - loss: 0.1778 - accuracy: 0.92 - ETA: 2:17 - loss: 0.1810 - accuracy: 0.92 - ETA: 2:15 - loss: 0.1664 - accuracy: 0.93 - ETA: 2:13 - loss: 0.1711 - accuracy: 0.93 - ETA: 2:12 - loss: 0.1695 - accuracy: 0.93 - ETA: 2:10 - loss: 0.1668 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1632 - accuracy: 0.93 - ETA: 2:10 - loss: 0.1719 - accuracy: 0.93 - ETA: 2:10 - loss: 0.1758 - accuracy: 0.93 - ETA: 2:08 - loss: 0.1801 - accuracy: 0.92 - ETA: 2:07 - loss: 0.1801 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1884 - accuracy: 0.92 - ETA: 2:04 - loss: 0.1953 - accuracy: 0.92 - ETA: 2:03 - loss: 0.1937 - accuracy: 0.92 - ETA: 2:02 - loss: 0.1920 - accuracy: 0.92 - ETA: 2:01 - loss: 0.1911 - accuracy: 0.92 - ETA: 2:00 - loss: 0.1932 - accuracy: 0.92 - ETA: 1:59 - loss: 0.1963 - accuracy: 0.92 - ETA: 1:58 - loss: 0.1987 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2017 - accuracy: 0.92 - ETA: 1:55 - loss: 0.1982 - accuracy: 0.92 - ETA: 1:54 - loss: 0.1975 - accuracy: 0.92 - ETA: 1:53 - loss: 0.1955 - accuracy: 0.92 - ETA: 1:52 - loss: 0.1941 - accuracy: 0.92 - ETA: 1:51 - loss: 0.1939 - accuracy: 0.92 - ETA: 1:51 - loss: 0.1957 - accuracy: 0.92 - ETA: 1:50 - loss: 0.1933 - accuracy: 0.92 - ETA: 1:49 - loss: 0.1949 - accuracy: 0.92 - ETA: 1:48 - loss: 0.1954 - accuracy: 0.92 - ETA: 1:48 - loss: 0.1957 - accuracy: 0.92 - ETA: 1:47 - loss: 0.1948 - accuracy: 0.92 - ETA: 1:46 - loss: 0.1964 - accuracy: 0.92 - ETA: 1:45 - loss: 0.1971 - accuracy: 0.92 - ETA: 1:44 - loss: 0.1962 - accuracy: 0.92 - ETA: 1:43 - loss: 0.1955 - accuracy: 0.92 - ETA: 1:42 - loss: 0.1941 - accuracy: 0.92 - ETA: 1:41 - loss: 0.1942 - accuracy: 0.92 - ETA: 1:40 - loss: 0.1946 - accuracy: 0.92 - ETA: 1:39 - loss: 0.1917 - accuracy: 0.92 - ETA: 1:38 - loss: 0.1934 - accuracy: 0.92 - ETA: 1:37 - loss: 0.1926 - accuracy: 0.92 - ETA: 1:37 - loss: 0.1929 - accuracy: 0.92 - ETA: 1:36 - loss: 0.1935 - accuracy: 0.92 - ETA: 1:35 - loss: 0.1936 - accuracy: 0.92 - ETA: 1:34 - loss: 0.1935 - accuracy: 0.92 - ETA: 1:33 - loss: 0.1937 - accuracy: 0.92 - ETA: 1:32 - loss: 0.1937 - accuracy: 0.92 - ETA: 1:31 - loss: 0.1939 - accuracy: 0.92 - ETA: 1:31 - loss: 0.1953 - accuracy: 0.92 - ETA: 1:30 - loss: 0.1947 - accuracy: 0.92 - ETA: 1:29 - loss: 0.1950 - accuracy: 0.92 - ETA: 1:28 - loss: 0.1955 - accuracy: 0.92 - ETA: 1:27 - loss: 0.1970 - accuracy: 0.92 - ETA: 1:26 - loss: 0.1955 - accuracy: 0.92 - ETA: 1:25 - loss: 0.1957 - accuracy: 0.92 - ETA: 1:24 - loss: 0.1963 - accuracy: 0.92 - ETA: 1:23 - loss: 0.1971 - accuracy: 0.92 - ETA: 1:22 - loss: 0.1963 - accuracy: 0.92 - ETA: 1:21 - loss: 0.1951 - accuracy: 0.92 - ETA: 1:21 - loss: 0.1945 - accuracy: 0.92 - ETA: 1:20 - loss: 0.1940 - accuracy: 0.92 - ETA: 1:19 - loss: 0.1939 - accuracy: 0.92 - ETA: 1:18 - loss: 0.1924 - accuracy: 0.92 - ETA: 1:17 - loss: 0.1941 - accuracy: 0.92 - ETA: 1:16 - loss: 0.1928 - accuracy: 0.92 - ETA: 1:15 - loss: 0.1933 - accuracy: 0.92 - ETA: 1:14 - loss: 0.1941 - accuracy: 0.92 - ETA: 1:13 - loss: 0.1944 - accuracy: 0.92 - ETA: 1:12 - loss: 0.1952 - accuracy: 0.92 - ETA: 1:11 - loss: 0.1950 - accuracy: 0.92 - ETA: 1:10 - loss: 0.1940 - accuracy: 0.92 - ETA: 1:10 - loss: 0.1940 - accuracy: 0.92 - ETA: 1:09 - loss: 0.1933 - accuracy: 0.92 - ETA: 1:08 - loss: 0.1931 - accuracy: 0.92 - ETA: 1:07 - loss: 0.1932 - accuracy: 0.92 - ETA: 1:06 - loss: 0.1943 - accuracy: 0.92 - ETA: 1:05 - loss: 0.1938 - accuracy: 0.92 - ETA: 1:04 - loss: 0.1939 - accuracy: 0.92 - ETA: 1:03 - loss: 0.1939 - accuracy: 0.92 - ETA: 1:02 - loss: 0.1950 - accuracy: 0.92 - ETA: 1:01 - loss: 0.1949 - accuracy: 0.92 - ETA: 1:00 - loss: 0.1947 - accuracy: 0.92 - ETA: 59s - loss: 0.1948 - accuracy: 0.9288 - ETA: 59s - loss: 0.1942 - accuracy: 0.929 - ETA: 58s - loss: 0.1948 - accuracy: 0.928 - ETA: 57s - loss: 0.1945 - accuracy: 0.928 - ETA: 56s - loss: 0.1948 - accuracy: 0.928 - ETA: 55s - loss: 0.1946 - accuracy: 0.928 - ETA: 54s - loss: 0.1942 - accuracy: 0.928 - ETA: 53s - loss: 0.1947 - accuracy: 0.928 - ETA: 52s - loss: 0.1947 - accuracy: 0.928 - ETA: 51s - loss: 0.1937 - accuracy: 0.928 - ETA: 50s - loss: 0.1934 - accuracy: 0.928 - ETA: 49s - loss: 0.1938 - accuracy: 0.928 - ETA: 48s - loss: 0.1934 - accuracy: 0.928 - ETA: 48s - loss: 0.1928 - accuracy: 0.928 - ETA: 47s - loss: 0.1930 - accuracy: 0.928 - ETA: 46s - loss: 0.1930 - accuracy: 0.928 - ETA: 45s - loss: 0.1933 - accuracy: 0.928 - ETA: 44s - loss: 0.1934 - accuracy: 0.928 - ETA: 43s - loss: 0.1931 - accuracy: 0.928 - ETA: 42s - loss: 0.1933 - accuracy: 0.928 - ETA: 41s - loss: 0.1924 - accuracy: 0.929 - ETA: 40s - loss: 0.1922 - accuracy: 0.929 - ETA: 39s - loss: 0.1922 - accuracy: 0.929 - ETA: 38s - loss: 0.1922 - accuracy: 0.929 - ETA: 37s - loss: 0.1933 - accuracy: 0.928 - ETA: 37s - loss: 0.1936 - accuracy: 0.928 - ETA: 36s - loss: 0.1942 - accuracy: 0.928 - ETA: 35s - loss: 0.1948 - accuracy: 0.928 - ETA: 34s - loss: 0.1950 - accuracy: 0.928 - ETA: 33s - loss: 0.1950 - accuracy: 0.928 - ETA: 32s - loss: 0.1953 - accuracy: 0.927 - ETA: 31s - loss: 0.1954 - accuracy: 0.927 - ETA: 30s - loss: 0.1956 - accuracy: 0.927 - ETA: 29s - loss: 0.1951 - accuracy: 0.928 - ETA: 28s - loss: 0.1949 - accuracy: 0.928 - ETA: 27s - loss: 0.1955 - accuracy: 0.928 - ETA: 27s - loss: 0.1964 - accuracy: 0.928 - ETA: 26s - loss: 0.1957 - accuracy: 0.928 - ETA: 25s - loss: 0.1952 - accuracy: 0.928 - ETA: 24s - loss: 0.1960 - accuracy: 0.928 - ETA: 23s - loss: 0.1953 - accuracy: 0.928 - ETA: 22s - loss: 0.1955 - accuracy: 0.928 - ETA: 21s - loss: 0.1950 - accuracy: 0.928 - ETA: 21s - loss: 0.1950 - accuracy: 0.928 - ETA: 20s - loss: 0.1943 - accuracy: 0.928 - ETA: 19s - loss: 0.1950 - accuracy: 0.928 - ETA: 18s - loss: 0.1959 - accuracy: 0.927 - ETA: 17s - loss: 0.1957 - accuracy: 0.928 - ETA: 16s - loss: 0.1954 - accuracy: 0.928 - ETA: 16s - loss: 0.1959 - accuracy: 0.927 - ETA: 15s - loss: 0.1963 - accuracy: 0.927 - ETA: 14s - loss: 0.1963 - accuracy: 0.927 - ETA: 13s - loss: 0.1963 - accuracy: 0.927 - ETA: 12s - loss: 0.1960 - accuracy: 0.928 - ETA: 11s - loss: 0.1957 - accuracy: 0.928 - ETA: 10s - loss: 0.1954 - accuracy: 0.928 - ETA: 9s - loss: 0.1953 - accuracy: 0.928 - ETA: 8s - loss: 0.1950 - accuracy: 0.92 - ETA: 7s - loss: 0.1944 - accuracy: 0.92 - ETA: 6s - loss: 0.1944 - accuracy: 0.92 - ETA: 5s - loss: 0.1944 - accuracy: 0.92 - ETA: 4s - loss: 0.1948 - accuracy: 0.92 - ETA: 3s - loss: 0.1942 - accuracy: 0.92 - ETA: 2s - loss: 0.1937 - accuracy: 0.92 - ETA: 1s - loss: 0.1943 - accuracy: 0.92 - ETA: 0s - loss: 0.1944 - accuracy: 0.92 - 182s 9ms/step - loss: 0.1940 - accuracy: 0.9284 - val_loss: 1.7821 - val_accuracy: 0.7689\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:13 - loss: 0.2573 - accuracy: 0.89 - ETA: 4:10 - loss: 0.2279 - accuracy: 0.91 - ETA: 3:58 - loss: 0.2254 - accuracy: 0.91 - ETA: 3:53 - loss: 0.1870 - accuracy: 0.93 - ETA: 3:47 - loss: 0.1978 - accuracy: 0.92 - ETA: 3:49 - loss: 0.1939 - accuracy: 0.92 - ETA: 3:48 - loss: 0.1948 - accuracy: 0.92 - ETA: 3:47 - loss: 0.1854 - accuracy: 0.92 - ETA: 3:48 - loss: 0.1879 - accuracy: 0.92 - ETA: 3:44 - loss: 0.1967 - accuracy: 0.92 - ETA: 3:42 - loss: 0.2043 - accuracy: 0.91 - ETA: 3:40 - loss: 0.2032 - accuracy: 0.91 - ETA: 3:37 - loss: 0.2037 - accuracy: 0.91 - ETA: 3:36 - loss: 0.2064 - accuracy: 0.91 - ETA: 3:35 - loss: 0.2141 - accuracy: 0.91 - ETA: 3:35 - loss: 0.2120 - accuracy: 0.91 - ETA: 3:33 - loss: 0.2103 - accuracy: 0.91 - ETA: 3:32 - loss: 0.2080 - accuracy: 0.92 - ETA: 3:31 - loss: 0.2095 - accuracy: 0.91 - ETA: 3:28 - loss: 0.2067 - accuracy: 0.92 - ETA: 3:27 - loss: 0.2034 - accuracy: 0.92 - ETA: 3:26 - loss: 0.2000 - accuracy: 0.92 - ETA: 3:24 - loss: 0.2025 - accuracy: 0.92 - ETA: 3:23 - loss: 0.2037 - accuracy: 0.92 - ETA: 3:22 - loss: 0.2067 - accuracy: 0.92 - ETA: 3:21 - loss: 0.2120 - accuracy: 0.92 - ETA: 3:19 - loss: 0.2128 - accuracy: 0.92 - ETA: 3:18 - loss: 0.2108 - accuracy: 0.92 - ETA: 3:18 - loss: 0.2078 - accuracy: 0.92 - ETA: 3:17 - loss: 0.2084 - accuracy: 0.92 - ETA: 3:15 - loss: 0.2080 - accuracy: 0.92 - ETA: 3:13 - loss: 0.2058 - accuracy: 0.92 - ETA: 3:11 - loss: 0.2041 - accuracy: 0.92 - ETA: 3:10 - loss: 0.2042 - accuracy: 0.92 - ETA: 3:08 - loss: 0.2043 - accuracy: 0.92 - ETA: 3:06 - loss: 0.2036 - accuracy: 0.92 - ETA: 3:05 - loss: 0.2034 - accuracy: 0.92 - ETA: 3:03 - loss: 0.2016 - accuracy: 0.92 - ETA: 3:02 - loss: 0.2020 - accuracy: 0.92 - ETA: 3:00 - loss: 0.2025 - accuracy: 0.92 - ETA: 2:59 - loss: 0.2016 - accuracy: 0.92 - ETA: 2:57 - loss: 0.2007 - accuracy: 0.92 - ETA: 2:56 - loss: 0.2003 - accuracy: 0.92 - ETA: 2:53 - loss: 0.1993 - accuracy: 0.92 - ETA: 2:52 - loss: 0.1984 - accuracy: 0.92 - ETA: 2:50 - loss: 0.1997 - accuracy: 0.92 - ETA: 2:49 - loss: 0.1999 - accuracy: 0.92 - ETA: 2:47 - loss: 0.1987 - accuracy: 0.92 - ETA: 2:45 - loss: 0.1994 - accuracy: 0.92 - ETA: 2:44 - loss: 0.2006 - accuracy: 0.92 - ETA: 2:42 - loss: 0.2033 - accuracy: 0.92 - ETA: 2:40 - loss: 0.2014 - accuracy: 0.92 - ETA: 2:39 - loss: 0.2018 - accuracy: 0.92 - ETA: 2:37 - loss: 0.2010 - accuracy: 0.92 - ETA: 2:36 - loss: 0.2025 - accuracy: 0.92 - ETA: 2:34 - loss: 0.2028 - accuracy: 0.92 - ETA: 2:33 - loss: 0.2033 - accuracy: 0.92 - ETA: 2:31 - loss: 0.2033 - accuracy: 0.92 - ETA: 2:30 - loss: 0.2032 - accuracy: 0.92 - ETA: 2:28 - loss: 0.2035 - accuracy: 0.92 - ETA: 2:27 - loss: 0.2031 - accuracy: 0.92 - ETA: 2:25 - loss: 0.2029 - accuracy: 0.92 - ETA: 2:23 - loss: 0.2025 - accuracy: 0.92 - ETA: 2:21 - loss: 0.2024 - accuracy: 0.92 - ETA: 2:20 - loss: 0.2021 - accuracy: 0.92 - ETA: 2:19 - loss: 0.2028 - accuracy: 0.92 - ETA: 2:17 - loss: 0.2024 - accuracy: 0.92 - ETA: 2:15 - loss: 0.2019 - accuracy: 0.92 - ETA: 2:14 - loss: 0.2015 - accuracy: 0.92 - ETA: 2:12 - loss: 0.2013 - accuracy: 0.92 - ETA: 2:10 - loss: 0.2001 - accuracy: 0.92 - ETA: 2:09 - loss: 0.2015 - accuracy: 0.92 - ETA: 2:07 - loss: 0.2006 - accuracy: 0.92 - ETA: 2:05 - loss: 0.2000 - accuracy: 0.92 - ETA: 2:04 - loss: 0.1990 - accuracy: 0.92 - ETA: 2:02 - loss: 0.1986 - accuracy: 0.92 - ETA: 2:00 - loss: 0.1978 - accuracy: 0.92 - ETA: 1:59 - loss: 0.1978 - accuracy: 0.92 - ETA: 1:57 - loss: 0.1971 - accuracy: 0.92 - ETA: 1:56 - loss: 0.1954 - accuracy: 0.92 - ETA: 1:54 - loss: 0.1953 - accuracy: 0.92 - ETA: 1:52 - loss: 0.1953 - accuracy: 0.92 - ETA: 1:51 - loss: 0.1959 - accuracy: 0.92 - ETA: 1:49 - loss: 0.1955 - accuracy: 0.92 - ETA: 1:47 - loss: 0.1942 - accuracy: 0.92 - ETA: 1:46 - loss: 0.1953 - accuracy: 0.92 - ETA: 1:44 - loss: 0.1950 - accuracy: 0.92 - ETA: 1:43 - loss: 0.1943 - accuracy: 0.92 - ETA: 1:41 - loss: 0.1939 - accuracy: 0.92 - ETA: 1:39 - loss: 0.1941 - accuracy: 0.92 - ETA: 1:38 - loss: 0.1944 - accuracy: 0.92 - ETA: 1:36 - loss: 0.1937 - accuracy: 0.92 - ETA: 1:34 - loss: 0.1931 - accuracy: 0.92 - ETA: 1:33 - loss: 0.1921 - accuracy: 0.92 - ETA: 1:31 - loss: 0.1922 - accuracy: 0.92 - ETA: 1:30 - loss: 0.1921 - accuracy: 0.92 - ETA: 1:28 - loss: 0.1929 - accuracy: 0.92 - ETA: 1:26 - loss: 0.1923 - accuracy: 0.92 - ETA: 1:25 - loss: 0.1926 - accuracy: 0.92 - ETA: 1:23 - loss: 0.1937 - accuracy: 0.92 - ETA: 1:21 - loss: 0.1932 - accuracy: 0.92 - ETA: 1:20 - loss: 0.1929 - accuracy: 0.92 - ETA: 1:18 - loss: 0.1928 - accuracy: 0.92 - ETA: 1:17 - loss: 0.1928 - accuracy: 0.92 - ETA: 1:15 - loss: 0.1934 - accuracy: 0.92 - ETA: 1:13 - loss: 0.1938 - accuracy: 0.92 - ETA: 1:12 - loss: 0.1935 - accuracy: 0.92 - ETA: 1:10 - loss: 0.1933 - accuracy: 0.92 - ETA: 1:08 - loss: 0.1930 - accuracy: 0.92 - ETA: 1:07 - loss: 0.1925 - accuracy: 0.92 - ETA: 1:05 - loss: 0.1932 - accuracy: 0.92 - ETA: 1:04 - loss: 0.1929 - accuracy: 0.92 - ETA: 1:02 - loss: 0.1927 - accuracy: 0.92 - ETA: 1:00 - loss: 0.1927 - accuracy: 0.92 - ETA: 59s - loss: 0.1923 - accuracy: 0.9272 - ETA: 57s - loss: 0.1923 - accuracy: 0.927 - ETA: 55s - loss: 0.1917 - accuracy: 0.927 - ETA: 54s - loss: 0.1920 - accuracy: 0.927 - ETA: 52s - loss: 0.1916 - accuracy: 0.927 - ETA: 50s - loss: 0.1923 - accuracy: 0.927 - ETA: 49s - loss: 0.1920 - accuracy: 0.927 - ETA: 47s - loss: 0.1920 - accuracy: 0.927 - ETA: 46s - loss: 0.1913 - accuracy: 0.927 - ETA: 44s - loss: 0.1916 - accuracy: 0.927 - ETA: 42s - loss: 0.1916 - accuracy: 0.927 - ETA: 41s - loss: 0.1912 - accuracy: 0.927 - ETA: 39s - loss: 0.1914 - accuracy: 0.927 - ETA: 37s - loss: 0.1913 - accuracy: 0.927 - ETA: 36s - loss: 0.1911 - accuracy: 0.927 - ETA: 34s - loss: 0.1906 - accuracy: 0.928 - ETA: 32s - loss: 0.1905 - accuracy: 0.928 - ETA: 31s - loss: 0.1902 - accuracy: 0.928 - ETA: 29s - loss: 0.1904 - accuracy: 0.928 - ETA: 27s - loss: 0.1904 - accuracy: 0.928 - ETA: 26s - loss: 0.1898 - accuracy: 0.928 - ETA: 24s - loss: 0.1894 - accuracy: 0.928 - ETA: 22s - loss: 0.1892 - accuracy: 0.928 - ETA: 21s - loss: 0.1894 - accuracy: 0.928 - ETA: 19s - loss: 0.1895 - accuracy: 0.928 - ETA: 17s - loss: 0.1893 - accuracy: 0.928 - ETA: 16s - loss: 0.1894 - accuracy: 0.928 - ETA: 14s - loss: 0.1895 - accuracy: 0.928 - ETA: 12s - loss: 0.1891 - accuracy: 0.928 - ETA: 11s - loss: 0.1883 - accuracy: 0.928 - ETA: 9s - loss: 0.1886 - accuracy: 0.928 - ETA: 8s - loss: 0.1888 - accuracy: 0.92 - ETA: 6s - loss: 0.1887 - accuracy: 0.92 - ETA: 4s - loss: 0.1884 - accuracy: 0.92 - ETA: 3s - loss: 0.1883 - accuracy: 0.92 - ETA: 1s - loss: 0.1881 - accuracy: 0.92 - 275s 14ms/step - loss: 0.1882 - accuracy: 0.9289 - val_loss: 1.8448 - val_accuracy: 0.7658\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:49 - loss: 0.1860 - accuracy: 0.93 - ETA: 3:53 - loss: 0.2221 - accuracy: 0.91 - ETA: 3:59 - loss: 0.2052 - accuracy: 0.92 - ETA: 3:56 - loss: 0.1878 - accuracy: 0.92 - ETA: 3:53 - loss: 0.1871 - accuracy: 0.92 - ETA: 3:51 - loss: 0.1754 - accuracy: 0.92 - ETA: 3:50 - loss: 0.1789 - accuracy: 0.93 - ETA: 3:51 - loss: 0.1783 - accuracy: 0.92 - ETA: 3:51 - loss: 0.1667 - accuracy: 0.93 - ETA: 3:50 - loss: 0.1665 - accuracy: 0.93 - ETA: 3:47 - loss: 0.1661 - accuracy: 0.93 - ETA: 3:45 - loss: 0.1658 - accuracy: 0.93 - ETA: 3:44 - loss: 0.1644 - accuracy: 0.93 - ETA: 3:43 - loss: 0.1687 - accuracy: 0.93 - ETA: 3:42 - loss: 0.1700 - accuracy: 0.93 - ETA: 3:40 - loss: 0.1709 - accuracy: 0.93 - ETA: 3:39 - loss: 0.1715 - accuracy: 0.93 - ETA: 3:38 - loss: 0.1786 - accuracy: 0.93 - ETA: 3:37 - loss: 0.1774 - accuracy: 0.93 - ETA: 3:35 - loss: 0.1720 - accuracy: 0.93 - ETA: 3:33 - loss: 0.1796 - accuracy: 0.93 - ETA: 3:31 - loss: 0.1812 - accuracy: 0.93 - ETA: 3:30 - loss: 0.1792 - accuracy: 0.93 - ETA: 3:29 - loss: 0.1800 - accuracy: 0.93 - ETA: 3:27 - loss: 0.1809 - accuracy: 0.93 - ETA: 3:26 - loss: 0.1799 - accuracy: 0.93 - ETA: 3:25 - loss: 0.1810 - accuracy: 0.93 - ETA: 3:23 - loss: 0.1798 - accuracy: 0.93 - ETA: 3:22 - loss: 0.1815 - accuracy: 0.93 - ETA: 3:20 - loss: 0.1816 - accuracy: 0.93 - ETA: 3:18 - loss: 0.1819 - accuracy: 0.93 - ETA: 3:17 - loss: 0.1804 - accuracy: 0.93 - ETA: 3:16 - loss: 0.1810 - accuracy: 0.93 - ETA: 3:13 - loss: 0.1813 - accuracy: 0.93 - ETA: 3:12 - loss: 0.1818 - accuracy: 0.93 - ETA: 3:10 - loss: 0.1841 - accuracy: 0.93 - ETA: 3:08 - loss: 0.1830 - accuracy: 0.93 - ETA: 3:07 - loss: 0.1847 - accuracy: 0.93 - ETA: 3:05 - loss: 0.1837 - accuracy: 0.93 - ETA: 3:03 - loss: 0.1856 - accuracy: 0.93 - ETA: 3:01 - loss: 0.1868 - accuracy: 0.93 - ETA: 3:00 - loss: 0.1871 - accuracy: 0.93 - ETA: 2:58 - loss: 0.1882 - accuracy: 0.93 - ETA: 2:56 - loss: 0.1861 - accuracy: 0.93 - ETA: 2:55 - loss: 0.1864 - accuracy: 0.93 - ETA: 2:53 - loss: 0.1846 - accuracy: 0.93 - ETA: 2:51 - loss: 0.1844 - accuracy: 0.93 - ETA: 2:50 - loss: 0.1835 - accuracy: 0.93 - ETA: 2:48 - loss: 0.1846 - accuracy: 0.93 - ETA: 2:46 - loss: 0.1848 - accuracy: 0.93 - ETA: 2:45 - loss: 0.1862 - accuracy: 0.93 - ETA: 2:43 - loss: 0.1861 - accuracy: 0.93 - ETA: 2:41 - loss: 0.1871 - accuracy: 0.93 - ETA: 2:40 - loss: 0.1858 - accuracy: 0.93 - ETA: 2:38 - loss: 0.1857 - accuracy: 0.93 - ETA: 2:36 - loss: 0.1858 - accuracy: 0.93 - ETA: 2:35 - loss: 0.1847 - accuracy: 0.93 - ETA: 2:33 - loss: 0.1836 - accuracy: 0.93 - ETA: 2:31 - loss: 0.1839 - accuracy: 0.93 - ETA: 2:30 - loss: 0.1841 - accuracy: 0.93 - ETA: 2:28 - loss: 0.1839 - accuracy: 0.93 - ETA: 2:27 - loss: 0.1846 - accuracy: 0.93 - ETA: 2:25 - loss: 0.1858 - accuracy: 0.93 - ETA: 2:23 - loss: 0.1859 - accuracy: 0.93 - ETA: 2:22 - loss: 0.1847 - accuracy: 0.93 - ETA: 2:20 - loss: 0.1853 - accuracy: 0.93 - ETA: 2:18 - loss: 0.1863 - accuracy: 0.93 - ETA: 2:16 - loss: 0.1848 - accuracy: 0.93 - ETA: 2:15 - loss: 0.1841 - accuracy: 0.93 - ETA: 2:13 - loss: 0.1834 - accuracy: 0.93 - ETA: 2:11 - loss: 0.1820 - accuracy: 0.93 - ETA: 2:10 - loss: 0.1825 - accuracy: 0.93 - ETA: 2:08 - loss: 0.1826 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1822 - accuracy: 0.93 - ETA: 2:05 - loss: 0.1822 - accuracy: 0.93 - ETA: 2:03 - loss: 0.1822 - accuracy: 0.93 - ETA: 2:01 - loss: 0.1822 - accuracy: 0.93 - ETA: 2:00 - loss: 0.1814 - accuracy: 0.93 - ETA: 1:58 - loss: 0.1811 - accuracy: 0.93 - ETA: 1:56 - loss: 0.1814 - accuracy: 0.93 - ETA: 1:55 - loss: 0.1824 - accuracy: 0.93 - ETA: 1:53 - loss: 0.1830 - accuracy: 0.93 - ETA: 1:51 - loss: 0.1835 - accuracy: 0.93 - ETA: 1:50 - loss: 0.1835 - accuracy: 0.93 - ETA: 1:48 - loss: 0.1835 - accuracy: 0.93 - ETA: 1:46 - loss: 0.1842 - accuracy: 0.93 - ETA: 1:45 - loss: 0.1842 - accuracy: 0.93 - ETA: 1:43 - loss: 0.1839 - accuracy: 0.93 - ETA: 1:41 - loss: 0.1831 - accuracy: 0.93 - ETA: 1:40 - loss: 0.1831 - accuracy: 0.93 - ETA: 1:38 - loss: 0.1824 - accuracy: 0.93 - ETA: 1:36 - loss: 0.1817 - accuracy: 0.93 - ETA: 1:35 - loss: 0.1815 - accuracy: 0.93 - ETA: 1:33 - loss: 0.1815 - accuracy: 0.93 - ETA: 1:31 - loss: 0.1814 - accuracy: 0.93 - ETA: 1:30 - loss: 0.1813 - accuracy: 0.93 - ETA: 1:28 - loss: 0.1816 - accuracy: 0.93 - ETA: 1:26 - loss: 0.1818 - accuracy: 0.93 - ETA: 1:25 - loss: 0.1824 - accuracy: 0.93 - ETA: 1:23 - loss: 0.1832 - accuracy: 0.93 - ETA: 1:22 - loss: 0.1841 - accuracy: 0.93 - ETA: 1:20 - loss: 0.1845 - accuracy: 0.93 - ETA: 1:18 - loss: 0.1854 - accuracy: 0.93 - ETA: 1:16 - loss: 0.1851 - accuracy: 0.93 - ETA: 1:15 - loss: 0.1859 - accuracy: 0.93 - ETA: 1:13 - loss: 0.1861 - accuracy: 0.93 - ETA: 1:12 - loss: 0.1856 - accuracy: 0.93 - ETA: 1:10 - loss: 0.1864 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1863 - accuracy: 0.93 - ETA: 1:07 - loss: 0.1874 - accuracy: 0.92 - ETA: 1:05 - loss: 0.1874 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1872 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1878 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1883 - accuracy: 0.92 - ETA: 58s - loss: 0.1900 - accuracy: 0.9294 - ETA: 57s - loss: 0.1906 - accuracy: 0.929 - ETA: 55s - loss: 0.1906 - accuracy: 0.929 - ETA: 54s - loss: 0.1898 - accuracy: 0.929 - ETA: 52s - loss: 0.1908 - accuracy: 0.929 - ETA: 50s - loss: 0.1906 - accuracy: 0.929 - ETA: 49s - loss: 0.1914 - accuracy: 0.928 - ETA: 47s - loss: 0.1914 - accuracy: 0.928 - ETA: 45s - loss: 0.1912 - accuracy: 0.928 - ETA: 44s - loss: 0.1915 - accuracy: 0.928 - ETA: 42s - loss: 0.1914 - accuracy: 0.928 - ETA: 40s - loss: 0.1909 - accuracy: 0.928 - ETA: 39s - loss: 0.1903 - accuracy: 0.929 - ETA: 37s - loss: 0.1908 - accuracy: 0.928 - ETA: 35s - loss: 0.1907 - accuracy: 0.929 - ETA: 34s - loss: 0.1905 - accuracy: 0.929 - ETA: 32s - loss: 0.1906 - accuracy: 0.929 - ETA: 31s - loss: 0.1911 - accuracy: 0.928 - ETA: 29s - loss: 0.1908 - accuracy: 0.928 - ETA: 27s - loss: 0.1912 - accuracy: 0.928 - ETA: 26s - loss: 0.1903 - accuracy: 0.929 - ETA: 24s - loss: 0.1903 - accuracy: 0.929 - ETA: 22s - loss: 0.1905 - accuracy: 0.929 - ETA: 21s - loss: 0.1904 - accuracy: 0.929 - ETA: 19s - loss: 0.1914 - accuracy: 0.928 - ETA: 17s - loss: 0.1915 - accuracy: 0.928 - ETA: 16s - loss: 0.1920 - accuracy: 0.928 - ETA: 14s - loss: 0.1922 - accuracy: 0.928 - ETA: 12s - loss: 0.1919 - accuracy: 0.928 - ETA: 11s - loss: 0.1916 - accuracy: 0.928 - ETA: 9s - loss: 0.1911 - accuracy: 0.929 - ETA: 8s - loss: 0.1910 - accuracy: 0.92 - ETA: 6s - loss: 0.1912 - accuracy: 0.92 - ETA: 4s - loss: 0.1924 - accuracy: 0.92 - ETA: 3s - loss: 0.1920 - accuracy: 0.92 - ETA: 1s - loss: 0.1923 - accuracy: 0.92 - 275s 14ms/step - loss: 0.1924 - accuracy: 0.9284 - val_loss: 1.7865 - val_accuracy: 0.7668\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:54 - loss: 0.1770 - accuracy: 0.93 - ETA: 4:12 - loss: 0.1955 - accuracy: 0.92 - ETA: 4:06 - loss: 0.1914 - accuracy: 0.92 - ETA: 4:03 - loss: 0.2065 - accuracy: 0.92 - ETA: 4:00 - loss: 0.1913 - accuracy: 0.93 - ETA: 3:58 - loss: 0.1930 - accuracy: 0.93 - ETA: 3:56 - loss: 0.1904 - accuracy: 0.93 - ETA: 3:56 - loss: 0.1847 - accuracy: 0.93 - ETA: 3:52 - loss: 0.1970 - accuracy: 0.93 - ETA: 3:52 - loss: 0.1998 - accuracy: 0.92 - ETA: 3:51 - loss: 0.2088 - accuracy: 0.92 - ETA: 3:51 - loss: 0.1982 - accuracy: 0.92 - ETA: 3:48 - loss: 0.1946 - accuracy: 0.93 - ETA: 3:47 - loss: 0.1993 - accuracy: 0.92 - ETA: 3:46 - loss: 0.1929 - accuracy: 0.93 - ETA: 3:44 - loss: 0.1957 - accuracy: 0.93 - ETA: 3:44 - loss: 0.1983 - accuracy: 0.92 - ETA: 3:42 - loss: 0.1998 - accuracy: 0.92 - ETA: 3:39 - loss: 0.2021 - accuracy: 0.92 - ETA: 3:38 - loss: 0.1993 - accuracy: 0.92 - ETA: 3:37 - loss: 0.1967 - accuracy: 0.92 - ETA: 3:35 - loss: 0.1941 - accuracy: 0.92 - ETA: 3:34 - loss: 0.1946 - accuracy: 0.92 - ETA: 3:32 - loss: 0.1923 - accuracy: 0.92 - ETA: 3:31 - loss: 0.1884 - accuracy: 0.93 - ETA: 3:29 - loss: 0.1860 - accuracy: 0.93 - ETA: 3:28 - loss: 0.1837 - accuracy: 0.93 - ETA: 3:25 - loss: 0.1826 - accuracy: 0.93 - ETA: 3:23 - loss: 0.1868 - accuracy: 0.93 - ETA: 3:21 - loss: 0.1862 - accuracy: 0.93 - ETA: 3:19 - loss: 0.1865 - accuracy: 0.93 - ETA: 3:17 - loss: 0.1838 - accuracy: 0.93 - ETA: 3:16 - loss: 0.1850 - accuracy: 0.93 - ETA: 3:14 - loss: 0.1878 - accuracy: 0.93 - ETA: 3:12 - loss: 0.1850 - accuracy: 0.93 - ETA: 3:11 - loss: 0.1846 - accuracy: 0.93 - ETA: 3:09 - loss: 0.1877 - accuracy: 0.92 - ETA: 3:07 - loss: 0.1873 - accuracy: 0.92 - ETA: 3:06 - loss: 0.1863 - accuracy: 0.92 - ETA: 3:04 - loss: 0.1848 - accuracy: 0.93 - ETA: 3:03 - loss: 0.1845 - accuracy: 0.93 - ETA: 3:02 - loss: 0.1830 - accuracy: 0.93 - ETA: 3:00 - loss: 0.1828 - accuracy: 0.93 - ETA: 2:58 - loss: 0.1813 - accuracy: 0.93 - ETA: 2:57 - loss: 0.1825 - accuracy: 0.93 - ETA: 2:55 - loss: 0.1830 - accuracy: 0.93 - ETA: 2:53 - loss: 0.1845 - accuracy: 0.93 - ETA: 2:51 - loss: 0.1846 - accuracy: 0.92 - ETA: 2:49 - loss: 0.1878 - accuracy: 0.92 - ETA: 2:48 - loss: 0.1877 - accuracy: 0.92 - ETA: 2:46 - loss: 0.1892 - accuracy: 0.92 - ETA: 2:45 - loss: 0.1897 - accuracy: 0.92 - ETA: 2:43 - loss: 0.1887 - accuracy: 0.92 - ETA: 2:42 - loss: 0.1904 - accuracy: 0.92 - ETA: 2:39 - loss: 0.1913 - accuracy: 0.92 - ETA: 2:38 - loss: 0.1930 - accuracy: 0.92 - ETA: 2:36 - loss: 0.1944 - accuracy: 0.92 - ETA: 2:34 - loss: 0.1925 - accuracy: 0.92 - ETA: 2:33 - loss: 0.1936 - accuracy: 0.92 - ETA: 2:31 - loss: 0.1933 - accuracy: 0.92 - ETA: 2:29 - loss: 0.1938 - accuracy: 0.92 - ETA: 2:28 - loss: 0.1929 - accuracy: 0.92 - ETA: 2:26 - loss: 0.1922 - accuracy: 0.92 - ETA: 2:24 - loss: 0.1926 - accuracy: 0.92 - ETA: 2:23 - loss: 0.1932 - accuracy: 0.92 - ETA: 2:21 - loss: 0.1932 - accuracy: 0.92 - ETA: 2:19 - loss: 0.1924 - accuracy: 0.92 - ETA: 2:17 - loss: 0.1929 - accuracy: 0.92 - ETA: 2:16 - loss: 0.1927 - accuracy: 0.92 - ETA: 2:14 - loss: 0.1913 - accuracy: 0.92 - ETA: 2:12 - loss: 0.1911 - accuracy: 0.92 - ETA: 2:11 - loss: 0.1907 - accuracy: 0.92 - ETA: 2:09 - loss: 0.1909 - accuracy: 0.92 - ETA: 2:07 - loss: 0.1913 - accuracy: 0.92 - ETA: 2:05 - loss: 0.1910 - accuracy: 0.92 - ETA: 2:04 - loss: 0.1906 - accuracy: 0.92 - ETA: 2:02 - loss: 0.1902 - accuracy: 0.92 - ETA: 2:00 - loss: 0.1906 - accuracy: 0.92 - ETA: 1:59 - loss: 0.1909 - accuracy: 0.92 - ETA: 1:57 - loss: 0.1915 - accuracy: 0.92 - ETA: 1:56 - loss: 0.1917 - accuracy: 0.92 - ETA: 1:54 - loss: 0.1910 - accuracy: 0.92 - ETA: 1:52 - loss: 0.1910 - accuracy: 0.92 - ETA: 1:51 - loss: 0.1914 - accuracy: 0.92 - ETA: 1:49 - loss: 0.1916 - accuracy: 0.92 - ETA: 1:47 - loss: 0.1916 - accuracy: 0.92 - ETA: 1:46 - loss: 0.1914 - accuracy: 0.92 - ETA: 1:44 - loss: 0.1911 - accuracy: 0.92 - ETA: 1:42 - loss: 0.1901 - accuracy: 0.92 - ETA: 1:41 - loss: 0.1898 - accuracy: 0.92 - ETA: 1:39 - loss: 0.1900 - accuracy: 0.92 - ETA: 1:38 - loss: 0.1904 - accuracy: 0.92 - ETA: 1:36 - loss: 0.1901 - accuracy: 0.92 - ETA: 1:34 - loss: 0.1902 - accuracy: 0.92 - ETA: 1:33 - loss: 0.1902 - accuracy: 0.92 - ETA: 1:31 - loss: 0.1898 - accuracy: 0.92 - ETA: 1:29 - loss: 0.1903 - accuracy: 0.92 - ETA: 1:28 - loss: 0.1894 - accuracy: 0.92 - ETA: 1:26 - loss: 0.1894 - accuracy: 0.92 - ETA: 1:24 - loss: 0.1887 - accuracy: 0.92 - ETA: 1:23 - loss: 0.1891 - accuracy: 0.92 - ETA: 1:21 - loss: 0.1889 - accuracy: 0.92 - ETA: 1:19 - loss: 0.1891 - accuracy: 0.92 - ETA: 1:18 - loss: 0.1893 - accuracy: 0.92 - ETA: 1:16 - loss: 0.1888 - accuracy: 0.92 - ETA: 1:14 - loss: 0.1893 - accuracy: 0.92 - ETA: 1:13 - loss: 0.1899 - accuracy: 0.92 - ETA: 1:11 - loss: 0.1899 - accuracy: 0.92 - ETA: 1:09 - loss: 0.1907 - accuracy: 0.92 - ETA: 1:08 - loss: 0.1905 - accuracy: 0.92 - ETA: 1:06 - loss: 0.1898 - accuracy: 0.92 - ETA: 1:04 - loss: 0.1899 - accuracy: 0.92 - ETA: 1:03 - loss: 0.1906 - accuracy: 0.92 - ETA: 1:01 - loss: 0.1905 - accuracy: 0.92 - ETA: 59s - loss: 0.1909 - accuracy: 0.9298 - ETA: 58s - loss: 0.1918 - accuracy: 0.929 - ETA: 56s - loss: 0.1912 - accuracy: 0.929 - ETA: 54s - loss: 0.1914 - accuracy: 0.929 - ETA: 53s - loss: 0.1911 - accuracy: 0.929 - ETA: 51s - loss: 0.1908 - accuracy: 0.929 - ETA: 49s - loss: 0.1909 - accuracy: 0.929 - ETA: 48s - loss: 0.1909 - accuracy: 0.929 - ETA: 46s - loss: 0.1921 - accuracy: 0.929 - ETA: 44s - loss: 0.1924 - accuracy: 0.929 - ETA: 43s - loss: 0.1927 - accuracy: 0.929 - ETA: 41s - loss: 0.1929 - accuracy: 0.929 - ETA: 39s - loss: 0.1928 - accuracy: 0.929 - ETA: 38s - loss: 0.1931 - accuracy: 0.929 - ETA: 36s - loss: 0.1933 - accuracy: 0.929 - ETA: 34s - loss: 0.1936 - accuracy: 0.928 - ETA: 33s - loss: 0.1931 - accuracy: 0.929 - ETA: 31s - loss: 0.1934 - accuracy: 0.929 - ETA: 29s - loss: 0.1929 - accuracy: 0.929 - ETA: 28s - loss: 0.1925 - accuracy: 0.929 - ETA: 26s - loss: 0.1929 - accuracy: 0.929 - ETA: 24s - loss: 0.1928 - accuracy: 0.929 - ETA: 23s - loss: 0.1923 - accuracy: 0.929 - ETA: 21s - loss: 0.1919 - accuracy: 0.929 - ETA: 19s - loss: 0.1917 - accuracy: 0.929 - ETA: 18s - loss: 0.1914 - accuracy: 0.929 - ETA: 16s - loss: 0.1911 - accuracy: 0.930 - ETA: 14s - loss: 0.1916 - accuracy: 0.929 - ETA: 13s - loss: 0.1914 - accuracy: 0.929 - ETA: 11s - loss: 0.1921 - accuracy: 0.929 - ETA: 9s - loss: 0.1921 - accuracy: 0.929 - ETA: 8s - loss: 0.1917 - accuracy: 0.92 - ETA: 6s - loss: 0.1921 - accuracy: 0.92 - ETA: 4s - loss: 0.1919 - accuracy: 0.92 - ETA: 3s - loss: 0.1922 - accuracy: 0.92 - ETA: 1s - loss: 0.1916 - accuracy: 0.92 - 277s 14ms/step - loss: 0.1918 - accuracy: 0.9295 - val_loss: 1.8233 - val_accuracy: 0.7666\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:12 - loss: 0.2205 - accuracy: 0.90 - ETA: 4:02 - loss: 0.1982 - accuracy: 0.92 - ETA: 3:51 - loss: 0.2031 - accuracy: 0.91 - ETA: 3:53 - loss: 0.1808 - accuracy: 0.92 - ETA: 3:54 - loss: 0.1698 - accuracy: 0.92 - ETA: 3:49 - loss: 0.1767 - accuracy: 0.92 - ETA: 3:48 - loss: 0.1779 - accuracy: 0.92 - ETA: 3:48 - loss: 0.1776 - accuracy: 0.92 - ETA: 3:48 - loss: 0.1743 - accuracy: 0.92 - ETA: 3:46 - loss: 0.1707 - accuracy: 0.92 - ETA: 3:45 - loss: 0.1735 - accuracy: 0.92 - ETA: 3:43 - loss: 0.1735 - accuracy: 0.92 - ETA: 3:42 - loss: 0.1686 - accuracy: 0.93 - ETA: 3:41 - loss: 0.1733 - accuracy: 0.93 - ETA: 3:40 - loss: 0.1752 - accuracy: 0.92 - ETA: 3:39 - loss: 0.1824 - accuracy: 0.92 - ETA: 3:37 - loss: 0.1809 - accuracy: 0.92 - ETA: 3:35 - loss: 0.1855 - accuracy: 0.92 - ETA: 3:33 - loss: 0.1881 - accuracy: 0.92 - ETA: 3:31 - loss: 0.1871 - accuracy: 0.92 - ETA: 3:30 - loss: 0.1880 - accuracy: 0.92 - ETA: 3:28 - loss: 0.1842 - accuracy: 0.92 - ETA: 3:27 - loss: 0.1817 - accuracy: 0.93 - ETA: 3:26 - loss: 0.1795 - accuracy: 0.93 - ETA: 3:24 - loss: 0.1808 - accuracy: 0.93 - ETA: 3:22 - loss: 0.1827 - accuracy: 0.92 - ETA: 3:21 - loss: 0.1845 - accuracy: 0.92 - ETA: 3:19 - loss: 0.1821 - accuracy: 0.93 - ETA: 3:17 - loss: 0.1849 - accuracy: 0.92 - ETA: 3:16 - loss: 0.1833 - accuracy: 0.92 - ETA: 3:13 - loss: 0.1834 - accuracy: 0.92 - ETA: 3:12 - loss: 0.1864 - accuracy: 0.92 - ETA: 3:10 - loss: 0.1866 - accuracy: 0.92 - ETA: 3:09 - loss: 0.1871 - accuracy: 0.92 - ETA: 3:07 - loss: 0.1877 - accuracy: 0.92 - ETA: 3:05 - loss: 0.1880 - accuracy: 0.92 - ETA: 3:04 - loss: 0.1873 - accuracy: 0.92 - ETA: 3:02 - loss: 0.1895 - accuracy: 0.92 - ETA: 3:00 - loss: 0.1887 - accuracy: 0.92 - ETA: 3:00 - loss: 0.1873 - accuracy: 0.92 - ETA: 2:58 - loss: 0.1872 - accuracy: 0.92 - ETA: 2:57 - loss: 0.1874 - accuracy: 0.92 - ETA: 2:56 - loss: 0.1871 - accuracy: 0.92 - ETA: 2:54 - loss: 0.1846 - accuracy: 0.93 - ETA: 2:52 - loss: 0.1845 - accuracy: 0.92 - ETA: 2:51 - loss: 0.1832 - accuracy: 0.93 - ETA: 2:49 - loss: 0.1846 - accuracy: 0.93 - ETA: 2:48 - loss: 0.1849 - accuracy: 0.93 - ETA: 2:46 - loss: 0.1868 - accuracy: 0.92 - ETA: 2:44 - loss: 0.1862 - accuracy: 0.93 - ETA: 2:43 - loss: 0.1892 - accuracy: 0.92 - ETA: 2:41 - loss: 0.1888 - accuracy: 0.92 - ETA: 2:40 - loss: 0.1882 - accuracy: 0.93 - ETA: 2:38 - loss: 0.1888 - accuracy: 0.92 - ETA: 2:36 - loss: 0.1898 - accuracy: 0.92 - ETA: 2:35 - loss: 0.1899 - accuracy: 0.92 - ETA: 2:33 - loss: 0.1917 - accuracy: 0.92 - ETA: 2:32 - loss: 0.1920 - accuracy: 0.92 - ETA: 2:30 - loss: 0.1931 - accuracy: 0.92 - ETA: 2:29 - loss: 0.1921 - accuracy: 0.92 - ETA: 2:27 - loss: 0.1921 - accuracy: 0.92 - ETA: 2:26 - loss: 0.1908 - accuracy: 0.92 - ETA: 2:24 - loss: 0.1922 - accuracy: 0.92 - ETA: 2:22 - loss: 0.1922 - accuracy: 0.92 - ETA: 2:20 - loss: 0.1925 - accuracy: 0.92 - ETA: 2:19 - loss: 0.1931 - accuracy: 0.92 - ETA: 2:17 - loss: 0.1924 - accuracy: 0.92 - ETA: 2:16 - loss: 0.1921 - accuracy: 0.92 - ETA: 2:14 - loss: 0.1929 - accuracy: 0.92 - ETA: 2:12 - loss: 0.1931 - accuracy: 0.92 - ETA: 2:11 - loss: 0.1933 - accuracy: 0.92 - ETA: 2:09 - loss: 0.1939 - accuracy: 0.92 - ETA: 2:07 - loss: 0.1940 - accuracy: 0.92 - ETA: 2:05 - loss: 0.1940 - accuracy: 0.92 - ETA: 2:04 - loss: 0.1926 - accuracy: 0.92 - ETA: 2:02 - loss: 0.1933 - accuracy: 0.92 - ETA: 2:00 - loss: 0.1934 - accuracy: 0.92 - ETA: 1:59 - loss: 0.1937 - accuracy: 0.92 - ETA: 1:57 - loss: 0.1942 - accuracy: 0.92 - ETA: 1:55 - loss: 0.1967 - accuracy: 0.92 - ETA: 1:54 - loss: 0.1952 - accuracy: 0.92 - ETA: 1:52 - loss: 0.1943 - accuracy: 0.92 - ETA: 1:51 - loss: 0.1950 - accuracy: 0.92 - ETA: 1:49 - loss: 0.1947 - accuracy: 0.92 - ETA: 1:47 - loss: 0.1958 - accuracy: 0.92 - ETA: 1:46 - loss: 0.1972 - accuracy: 0.92 - ETA: 1:44 - loss: 0.1983 - accuracy: 0.92 - ETA: 1:42 - loss: 0.1979 - accuracy: 0.92 - ETA: 1:41 - loss: 0.1979 - accuracy: 0.92 - ETA: 1:39 - loss: 0.1982 - accuracy: 0.92 - ETA: 1:38 - loss: 0.1987 - accuracy: 0.92 - ETA: 1:36 - loss: 0.1987 - accuracy: 0.92 - ETA: 1:34 - loss: 0.1992 - accuracy: 0.92 - ETA: 1:33 - loss: 0.1998 - accuracy: 0.92 - ETA: 1:31 - loss: 0.1996 - accuracy: 0.92 - ETA: 1:30 - loss: 0.1998 - accuracy: 0.92 - ETA: 1:28 - loss: 0.1992 - accuracy: 0.92 - ETA: 1:26 - loss: 0.1989 - accuracy: 0.92 - ETA: 1:25 - loss: 0.1988 - accuracy: 0.92 - ETA: 1:23 - loss: 0.1986 - accuracy: 0.92 - ETA: 1:21 - loss: 0.1999 - accuracy: 0.92 - ETA: 1:20 - loss: 0.1998 - accuracy: 0.92 - ETA: 1:18 - loss: 0.1997 - accuracy: 0.92 - ETA: 1:16 - loss: 0.1996 - accuracy: 0.92 - ETA: 1:15 - loss: 0.1991 - accuracy: 0.92 - ETA: 1:13 - loss: 0.1995 - accuracy: 0.92 - ETA: 1:12 - loss: 0.1996 - accuracy: 0.92 - ETA: 1:10 - loss: 0.1995 - accuracy: 0.92 - ETA: 1:08 - loss: 0.1992 - accuracy: 0.92 - ETA: 1:07 - loss: 0.1992 - accuracy: 0.92 - ETA: 1:05 - loss: 0.2000 - accuracy: 0.92 - ETA: 1:03 - loss: 0.2000 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2001 - accuracy: 0.92 - ETA: 1:00 - loss: 0.2000 - accuracy: 0.92 - ETA: 59s - loss: 0.1991 - accuracy: 0.9263 - ETA: 57s - loss: 0.1992 - accuracy: 0.926 - ETA: 55s - loss: 0.1987 - accuracy: 0.926 - ETA: 54s - loss: 0.1987 - accuracy: 0.926 - ETA: 52s - loss: 0.1984 - accuracy: 0.926 - ETA: 50s - loss: 0.1988 - accuracy: 0.926 - ETA: 49s - loss: 0.1978 - accuracy: 0.926 - ETA: 47s - loss: 0.1976 - accuracy: 0.926 - ETA: 45s - loss: 0.1980 - accuracy: 0.926 - ETA: 44s - loss: 0.1979 - accuracy: 0.926 - ETA: 42s - loss: 0.1976 - accuracy: 0.926 - ETA: 40s - loss: 0.1975 - accuracy: 0.926 - ETA: 39s - loss: 0.1969 - accuracy: 0.927 - ETA: 37s - loss: 0.1962 - accuracy: 0.927 - ETA: 36s - loss: 0.1957 - accuracy: 0.927 - ETA: 34s - loss: 0.1963 - accuracy: 0.927 - ETA: 32s - loss: 0.1966 - accuracy: 0.927 - ETA: 31s - loss: 0.1961 - accuracy: 0.927 - ETA: 29s - loss: 0.1959 - accuracy: 0.927 - ETA: 27s - loss: 0.1951 - accuracy: 0.927 - ETA: 26s - loss: 0.1950 - accuracy: 0.927 - ETA: 24s - loss: 0.1946 - accuracy: 0.928 - ETA: 22s - loss: 0.1944 - accuracy: 0.928 - ETA: 21s - loss: 0.1937 - accuracy: 0.928 - ETA: 19s - loss: 0.1935 - accuracy: 0.928 - ETA: 17s - loss: 0.1932 - accuracy: 0.928 - ETA: 16s - loss: 0.1934 - accuracy: 0.928 - ETA: 14s - loss: 0.1939 - accuracy: 0.928 - ETA: 12s - loss: 0.1937 - accuracy: 0.928 - ETA: 11s - loss: 0.1934 - accuracy: 0.928 - ETA: 9s - loss: 0.1928 - accuracy: 0.928 - ETA: 8s - loss: 0.1925 - accuracy: 0.92 - ETA: 6s - loss: 0.1920 - accuracy: 0.92 - ETA: 4s - loss: 0.1921 - accuracy: 0.92 - ETA: 3s - loss: 0.1922 - accuracy: 0.92 - ETA: 1s - loss: 0.1925 - accuracy: 0.92 - 276s 14ms/step - loss: 0.1922 - accuracy: 0.9291 - val_loss: 1.8503 - val_accuracy: 0.7677\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:30 - loss: 0.1358 - accuracy: 0.96 - ETA: 4:11 - loss: 0.1449 - accuracy: 0.94 - ETA: 4:06 - loss: 0.1677 - accuracy: 0.93 - ETA: 3:59 - loss: 0.1677 - accuracy: 0.93 - ETA: 4:00 - loss: 0.1606 - accuracy: 0.93 - ETA: 4:00 - loss: 0.1677 - accuracy: 0.93 - ETA: 4:02 - loss: 0.1655 - accuracy: 0.93 - ETA: 3:59 - loss: 0.1666 - accuracy: 0.93 - ETA: 3:58 - loss: 0.1671 - accuracy: 0.93 - ETA: 3:58 - loss: 0.1754 - accuracy: 0.92 - ETA: 3:55 - loss: 0.1811 - accuracy: 0.92 - ETA: 3:56 - loss: 0.1815 - accuracy: 0.92 - ETA: 3:53 - loss: 0.1862 - accuracy: 0.92 - ETA: 3:50 - loss: 0.1869 - accuracy: 0.92 - ETA: 3:49 - loss: 0.1902 - accuracy: 0.92 - ETA: 3:47 - loss: 0.1926 - accuracy: 0.92 - ETA: 3:44 - loss: 0.1952 - accuracy: 0.92 - ETA: 3:44 - loss: 0.1940 - accuracy: 0.92 - ETA: 3:42 - loss: 0.1900 - accuracy: 0.92 - ETA: 3:40 - loss: 0.1890 - accuracy: 0.92 - ETA: 3:38 - loss: 0.1883 - accuracy: 0.92 - ETA: 3:37 - loss: 0.1887 - accuracy: 0.92 - ETA: 3:34 - loss: 0.1883 - accuracy: 0.92 - ETA: 3:33 - loss: 0.1873 - accuracy: 0.92 - ETA: 3:31 - loss: 0.1868 - accuracy: 0.92 - ETA: 3:29 - loss: 0.1867 - accuracy: 0.92 - ETA: 3:27 - loss: 0.1889 - accuracy: 0.92 - ETA: 3:26 - loss: 0.1916 - accuracy: 0.92 - ETA: 3:25 - loss: 0.1901 - accuracy: 0.92 - ETA: 3:23 - loss: 0.1913 - accuracy: 0.92 - ETA: 3:21 - loss: 0.1901 - accuracy: 0.92 - ETA: 3:19 - loss: 0.1911 - accuracy: 0.92 - ETA: 3:17 - loss: 0.1917 - accuracy: 0.92 - ETA: 3:16 - loss: 0.1928 - accuracy: 0.92 - ETA: 3:14 - loss: 0.1937 - accuracy: 0.92 - ETA: 3:12 - loss: 0.1910 - accuracy: 0.92 - ETA: 3:10 - loss: 0.1910 - accuracy: 0.92 - ETA: 3:08 - loss: 0.1885 - accuracy: 0.92 - ETA: 3:07 - loss: 0.1865 - accuracy: 0.92 - ETA: 3:05 - loss: 0.1872 - accuracy: 0.92 - ETA: 3:03 - loss: 0.1850 - accuracy: 0.92 - ETA: 3:01 - loss: 0.1850 - accuracy: 0.92 - ETA: 2:59 - loss: 0.1859 - accuracy: 0.92 - ETA: 2:57 - loss: 0.1866 - accuracy: 0.92 - ETA: 2:56 - loss: 0.1846 - accuracy: 0.92 - ETA: 2:54 - loss: 0.1856 - accuracy: 0.92 - ETA: 2:53 - loss: 0.1863 - accuracy: 0.92 - ETA: 2:51 - loss: 0.1878 - accuracy: 0.92 - ETA: 2:50 - loss: 0.1881 - accuracy: 0.92 - ETA: 2:48 - loss: 0.1885 - accuracy: 0.92 - ETA: 2:46 - loss: 0.1880 - accuracy: 0.92 - ETA: 2:44 - loss: 0.1876 - accuracy: 0.92 - ETA: 2:43 - loss: 0.1861 - accuracy: 0.92 - ETA: 2:41 - loss: 0.1855 - accuracy: 0.92 - ETA: 2:40 - loss: 0.1850 - accuracy: 0.92 - ETA: 2:38 - loss: 0.1842 - accuracy: 0.92 - ETA: 2:36 - loss: 0.1837 - accuracy: 0.92 - ETA: 2:35 - loss: 0.1831 - accuracy: 0.92 - ETA: 2:33 - loss: 0.1835 - accuracy: 0.92 - ETA: 2:31 - loss: 0.1817 - accuracy: 0.92 - ETA: 2:29 - loss: 0.1818 - accuracy: 0.92 - ETA: 2:28 - loss: 0.1805 - accuracy: 0.93 - ETA: 2:26 - loss: 0.1797 - accuracy: 0.93 - ETA: 2:24 - loss: 0.1791 - accuracy: 0.93 - ETA: 2:23 - loss: 0.1802 - accuracy: 0.93 - ETA: 2:21 - loss: 0.1805 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1798 - accuracy: 0.93 - ETA: 2:18 - loss: 0.1797 - accuracy: 0.93 - ETA: 2:16 - loss: 0.1800 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1809 - accuracy: 0.93 - ETA: 2:12 - loss: 0.1820 - accuracy: 0.92 - ETA: 2:11 - loss: 0.1822 - accuracy: 0.92 - ETA: 2:09 - loss: 0.1817 - accuracy: 0.92 - ETA: 2:08 - loss: 0.1810 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1826 - accuracy: 0.92 - ETA: 2:05 - loss: 0.1825 - accuracy: 0.92 - ETA: 2:03 - loss: 0.1827 - accuracy: 0.92 - ETA: 2:01 - loss: 0.1829 - accuracy: 0.92 - ETA: 2:00 - loss: 0.1827 - accuracy: 0.92 - ETA: 1:58 - loss: 0.1822 - accuracy: 0.92 - ETA: 1:56 - loss: 0.1822 - accuracy: 0.92 - ETA: 1:54 - loss: 0.1830 - accuracy: 0.92 - ETA: 1:53 - loss: 0.1830 - accuracy: 0.92 - ETA: 1:51 - loss: 0.1825 - accuracy: 0.92 - ETA: 1:50 - loss: 0.1831 - accuracy: 0.92 - ETA: 1:48 - loss: 0.1832 - accuracy: 0.92 - ETA: 1:46 - loss: 0.1831 - accuracy: 0.92 - ETA: 1:45 - loss: 0.1831 - accuracy: 0.92 - ETA: 1:43 - loss: 0.1830 - accuracy: 0.92 - ETA: 1:41 - loss: 0.1823 - accuracy: 0.92 - ETA: 1:40 - loss: 0.1825 - accuracy: 0.92 - ETA: 1:38 - loss: 0.1825 - accuracy: 0.93 - ETA: 1:36 - loss: 0.1832 - accuracy: 0.93 - ETA: 1:35 - loss: 0.1832 - accuracy: 0.93 - ETA: 1:33 - loss: 0.1830 - accuracy: 0.93 - ETA: 1:31 - loss: 0.1831 - accuracy: 0.92 - ETA: 1:30 - loss: 0.1828 - accuracy: 0.93 - ETA: 1:28 - loss: 0.1829 - accuracy: 0.92 - ETA: 1:26 - loss: 0.1823 - accuracy: 0.93 - ETA: 1:25 - loss: 0.1824 - accuracy: 0.93 - ETA: 1:23 - loss: 0.1826 - accuracy: 0.93 - ETA: 1:21 - loss: 0.1833 - accuracy: 0.93 - ETA: 1:20 - loss: 0.1836 - accuracy: 0.92 - ETA: 1:18 - loss: 0.1833 - accuracy: 0.92 - ETA: 1:16 - loss: 0.1831 - accuracy: 0.93 - ETA: 1:15 - loss: 0.1830 - accuracy: 0.93 - ETA: 1:13 - loss: 0.1837 - accuracy: 0.93 - ETA: 1:11 - loss: 0.1833 - accuracy: 0.93 - ETA: 1:10 - loss: 0.1824 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1826 - accuracy: 0.93 - ETA: 1:06 - loss: 0.1825 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1821 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1817 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1823 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1817 - accuracy: 0.93 - ETA: 58s - loss: 0.1810 - accuracy: 0.9316 - ETA: 56s - loss: 0.1817 - accuracy: 0.931 - ETA: 54s - loss: 0.1816 - accuracy: 0.931 - ETA: 53s - loss: 0.1817 - accuracy: 0.931 - ETA: 51s - loss: 0.1819 - accuracy: 0.931 - ETA: 49s - loss: 0.1816 - accuracy: 0.930 - ETA: 48s - loss: 0.1819 - accuracy: 0.931 - ETA: 46s - loss: 0.1817 - accuracy: 0.931 - ETA: 44s - loss: 0.1814 - accuracy: 0.931 - ETA: 43s - loss: 0.1812 - accuracy: 0.931 - ETA: 41s - loss: 0.1811 - accuracy: 0.931 - ETA: 39s - loss: 0.1815 - accuracy: 0.931 - ETA: 38s - loss: 0.1816 - accuracy: 0.931 - ETA: 36s - loss: 0.1817 - accuracy: 0.931 - ETA: 34s - loss: 0.1817 - accuracy: 0.931 - ETA: 33s - loss: 0.1815 - accuracy: 0.931 - ETA: 31s - loss: 0.1812 - accuracy: 0.931 - ETA: 29s - loss: 0.1802 - accuracy: 0.931 - ETA: 28s - loss: 0.1804 - accuracy: 0.931 - ETA: 26s - loss: 0.1805 - accuracy: 0.931 - ETA: 24s - loss: 0.1803 - accuracy: 0.931 - ETA: 23s - loss: 0.1806 - accuracy: 0.931 - ETA: 21s - loss: 0.1815 - accuracy: 0.931 - ETA: 19s - loss: 0.1816 - accuracy: 0.931 - ETA: 18s - loss: 0.1815 - accuracy: 0.931 - ETA: 16s - loss: 0.1814 - accuracy: 0.931 - ETA: 14s - loss: 0.1810 - accuracy: 0.931 - ETA: 13s - loss: 0.1812 - accuracy: 0.931 - ETA: 11s - loss: 0.1811 - accuracy: 0.931 - ETA: 9s - loss: 0.1819 - accuracy: 0.931 - ETA: 8s - loss: 0.1815 - accuracy: 0.93 - ETA: 6s - loss: 0.1823 - accuracy: 0.93 - ETA: 4s - loss: 0.1821 - accuracy: 0.93 - ETA: 3s - loss: 0.1824 - accuracy: 0.93 - ETA: 1s - loss: 0.1822 - accuracy: 0.93 - 277s 14ms/step - loss: 0.1817 - accuracy: 0.9307 - val_loss: 1.8552 - val_accuracy: 0.7652\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:43 - loss: 0.2991 - accuracy: 0.88 - ETA: 3:49 - loss: 0.2935 - accuracy: 0.89 - ETA: 3:54 - loss: 0.3245 - accuracy: 0.88 - ETA: 3:49 - loss: 0.2657 - accuracy: 0.90 - ETA: 3:50 - loss: 0.2555 - accuracy: 0.90 - ETA: 3:54 - loss: 0.2521 - accuracy: 0.90 - ETA: 3:52 - loss: 0.2504 - accuracy: 0.90 - ETA: 3:54 - loss: 0.2340 - accuracy: 0.91 - ETA: 3:52 - loss: 0.2282 - accuracy: 0.91 - ETA: 3:47 - loss: 0.2276 - accuracy: 0.91 - ETA: 3:44 - loss: 0.2194 - accuracy: 0.91 - ETA: 3:45 - loss: 0.2147 - accuracy: 0.92 - ETA: 3:45 - loss: 0.2131 - accuracy: 0.92 - ETA: 3:44 - loss: 0.2072 - accuracy: 0.92 - ETA: 3:44 - loss: 0.2065 - accuracy: 0.92 - ETA: 3:41 - loss: 0.2040 - accuracy: 0.92 - ETA: 3:40 - loss: 0.1996 - accuracy: 0.92 - ETA: 3:39 - loss: 0.1957 - accuracy: 0.92 - ETA: 3:37 - loss: 0.1908 - accuracy: 0.92 - ETA: 3:35 - loss: 0.1875 - accuracy: 0.93 - ETA: 3:33 - loss: 0.1973 - accuracy: 0.92 - ETA: 3:31 - loss: 0.1944 - accuracy: 0.92 - ETA: 3:31 - loss: 0.1970 - accuracy: 0.92 - ETA: 3:30 - loss: 0.1950 - accuracy: 0.92 - ETA: 3:28 - loss: 0.1953 - accuracy: 0.92 - ETA: 3:26 - loss: 0.1948 - accuracy: 0.92 - ETA: 3:25 - loss: 0.1950 - accuracy: 0.92 - ETA: 3:23 - loss: 0.1903 - accuracy: 0.93 - ETA: 3:21 - loss: 0.1892 - accuracy: 0.93 - ETA: 3:19 - loss: 0.1887 - accuracy: 0.93 - ETA: 3:17 - loss: 0.1896 - accuracy: 0.93 - ETA: 3:15 - loss: 0.1919 - accuracy: 0.92 - ETA: 3:14 - loss: 0.1926 - accuracy: 0.92 - ETA: 3:12 - loss: 0.1917 - accuracy: 0.92 - ETA: 3:11 - loss: 0.1959 - accuracy: 0.92 - ETA: 3:09 - loss: 0.1946 - accuracy: 0.92 - ETA: 3:08 - loss: 0.1949 - accuracy: 0.92 - ETA: 3:06 - loss: 0.1950 - accuracy: 0.92 - ETA: 3:04 - loss: 0.1939 - accuracy: 0.92 - ETA: 3:03 - loss: 0.1932 - accuracy: 0.92 - ETA: 3:01 - loss: 0.1914 - accuracy: 0.92 - ETA: 3:00 - loss: 0.1917 - accuracy: 0.92 - ETA: 2:58 - loss: 0.1917 - accuracy: 0.93 - ETA: 2:56 - loss: 0.1910 - accuracy: 0.93 - ETA: 2:55 - loss: 0.1911 - accuracy: 0.92 - ETA: 2:53 - loss: 0.1914 - accuracy: 0.92 - ETA: 2:51 - loss: 0.1920 - accuracy: 0.92 - ETA: 2:50 - loss: 0.1931 - accuracy: 0.92 - ETA: 2:48 - loss: 0.1954 - accuracy: 0.92 - ETA: 2:46 - loss: 0.1940 - accuracy: 0.92 - ETA: 2:44 - loss: 0.1942 - accuracy: 0.92 - ETA: 2:42 - loss: 0.1943 - accuracy: 0.92 - ETA: 2:41 - loss: 0.1942 - accuracy: 0.92 - ETA: 2:39 - loss: 0.1953 - accuracy: 0.92 - ETA: 2:37 - loss: 0.1955 - accuracy: 0.92 - ETA: 2:36 - loss: 0.1950 - accuracy: 0.92 - ETA: 2:34 - loss: 0.1938 - accuracy: 0.92 - ETA: 2:32 - loss: 0.1940 - accuracy: 0.92 - ETA: 2:31 - loss: 0.1920 - accuracy: 0.92 - ETA: 2:29 - loss: 0.1904 - accuracy: 0.93 - ETA: 2:27 - loss: 0.1916 - accuracy: 0.92 - ETA: 2:25 - loss: 0.1900 - accuracy: 0.93 - ETA: 2:24 - loss: 0.1895 - accuracy: 0.93 - ETA: 2:22 - loss: 0.1903 - accuracy: 0.93 - ETA: 2:20 - loss: 0.1921 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1931 - accuracy: 0.92 - ETA: 2:17 - loss: 0.1942 - accuracy: 0.92 - ETA: 2:15 - loss: 0.1950 - accuracy: 0.92 - ETA: 2:14 - loss: 0.1951 - accuracy: 0.92 - ETA: 2:12 - loss: 0.1946 - accuracy: 0.92 - ETA: 2:10 - loss: 0.1938 - accuracy: 0.92 - ETA: 2:09 - loss: 0.1963 - accuracy: 0.92 - ETA: 2:07 - loss: 0.1957 - accuracy: 0.92 - ETA: 2:06 - loss: 0.1948 - accuracy: 0.92 - ETA: 2:04 - loss: 0.1953 - accuracy: 0.92 - ETA: 2:02 - loss: 0.1952 - accuracy: 0.92 - ETA: 2:01 - loss: 0.1953 - accuracy: 0.92 - ETA: 1:59 - loss: 0.1958 - accuracy: 0.92 - ETA: 1:57 - loss: 0.1961 - accuracy: 0.92 - ETA: 1:56 - loss: 0.1954 - accuracy: 0.92 - ETA: 1:54 - loss: 0.1953 - accuracy: 0.92 - ETA: 1:52 - loss: 0.1957 - accuracy: 0.92 - ETA: 1:51 - loss: 0.1958 - accuracy: 0.92 - ETA: 1:49 - loss: 0.1954 - accuracy: 0.92 - ETA: 1:47 - loss: 0.1954 - accuracy: 0.92 - ETA: 1:46 - loss: 0.1950 - accuracy: 0.92 - ETA: 1:44 - loss: 0.1952 - accuracy: 0.92 - ETA: 1:43 - loss: 0.1962 - accuracy: 0.92 - ETA: 1:41 - loss: 0.1959 - accuracy: 0.92 - ETA: 1:39 - loss: 0.1952 - accuracy: 0.92 - ETA: 1:38 - loss: 0.1957 - accuracy: 0.92 - ETA: 1:36 - loss: 0.1946 - accuracy: 0.92 - ETA: 1:34 - loss: 0.1948 - accuracy: 0.92 - ETA: 1:33 - loss: 0.1936 - accuracy: 0.92 - ETA: 1:31 - loss: 0.1937 - accuracy: 0.92 - ETA: 1:29 - loss: 0.1941 - accuracy: 0.92 - ETA: 1:28 - loss: 0.1951 - accuracy: 0.92 - ETA: 1:26 - loss: 0.1952 - accuracy: 0.92 - ETA: 1:24 - loss: 0.1957 - accuracy: 0.92 - ETA: 1:23 - loss: 0.1953 - accuracy: 0.92 - ETA: 1:21 - loss: 0.1957 - accuracy: 0.92 - ETA: 1:20 - loss: 0.1956 - accuracy: 0.92 - ETA: 1:18 - loss: 0.1953 - accuracy: 0.92 - ETA: 1:16 - loss: 0.1950 - accuracy: 0.92 - ETA: 1:15 - loss: 0.1951 - accuracy: 0.93 - ETA: 1:13 - loss: 0.1952 - accuracy: 0.92 - ETA: 1:11 - loss: 0.1948 - accuracy: 0.93 - ETA: 1:10 - loss: 0.1945 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1947 - accuracy: 0.93 - ETA: 1:06 - loss: 0.1945 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1944 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1940 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1938 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1934 - accuracy: 0.93 - ETA: 58s - loss: 0.1937 - accuracy: 0.9301 - ETA: 57s - loss: 0.1942 - accuracy: 0.929 - ETA: 55s - loss: 0.1934 - accuracy: 0.930 - ETA: 53s - loss: 0.1934 - accuracy: 0.930 - ETA: 52s - loss: 0.1931 - accuracy: 0.930 - ETA: 50s - loss: 0.1929 - accuracy: 0.930 - ETA: 48s - loss: 0.1932 - accuracy: 0.929 - ETA: 47s - loss: 0.1933 - accuracy: 0.929 - ETA: 45s - loss: 0.1936 - accuracy: 0.929 - ETA: 43s - loss: 0.1937 - accuracy: 0.929 - ETA: 42s - loss: 0.1931 - accuracy: 0.929 - ETA: 40s - loss: 0.1931 - accuracy: 0.929 - ETA: 39s - loss: 0.1932 - accuracy: 0.929 - ETA: 37s - loss: 0.1926 - accuracy: 0.929 - ETA: 35s - loss: 0.1928 - accuracy: 0.929 - ETA: 34s - loss: 0.1925 - accuracy: 0.929 - ETA: 32s - loss: 0.1925 - accuracy: 0.929 - ETA: 30s - loss: 0.1921 - accuracy: 0.929 - ETA: 29s - loss: 0.1914 - accuracy: 0.929 - ETA: 27s - loss: 0.1913 - accuracy: 0.929 - ETA: 25s - loss: 0.1911 - accuracy: 0.929 - ETA: 24s - loss: 0.1912 - accuracy: 0.929 - ETA: 22s - loss: 0.1908 - accuracy: 0.930 - ETA: 21s - loss: 0.1905 - accuracy: 0.930 - ETA: 19s - loss: 0.1904 - accuracy: 0.930 - ETA: 17s - loss: 0.1911 - accuracy: 0.929 - ETA: 16s - loss: 0.1908 - accuracy: 0.929 - ETA: 14s - loss: 0.1912 - accuracy: 0.929 - ETA: 12s - loss: 0.1915 - accuracy: 0.929 - ETA: 11s - loss: 0.1916 - accuracy: 0.929 - ETA: 9s - loss: 0.1911 - accuracy: 0.929 - ETA: 7s - loss: 0.1913 - accuracy: 0.92 - ETA: 6s - loss: 0.1907 - accuracy: 0.93 - ETA: 4s - loss: 0.1905 - accuracy: 0.93 - ETA: 3s - loss: 0.1901 - accuracy: 0.93 - ETA: 1s - loss: 0.1897 - accuracy: 0.93 - 273s 14ms/step - loss: 0.1897 - accuracy: 0.9306 - val_loss: 1.8571 - val_accuracy: 0.7674\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:20 - loss: 0.0930 - accuracy: 0.97 - ETA: 4:17 - loss: 0.1241 - accuracy: 0.96 - ETA: 4:14 - loss: 0.1293 - accuracy: 0.95 - ETA: 4:08 - loss: 0.1273 - accuracy: 0.95 - ETA: 4:03 - loss: 0.1289 - accuracy: 0.95 - ETA: 4:02 - loss: 0.1320 - accuracy: 0.95 - ETA: 4:02 - loss: 0.1548 - accuracy: 0.94 - ETA: 3:59 - loss: 0.1648 - accuracy: 0.94 - ETA: 3:55 - loss: 0.1553 - accuracy: 0.94 - ETA: 3:53 - loss: 0.1612 - accuracy: 0.94 - ETA: 3:49 - loss: 0.1647 - accuracy: 0.93 - ETA: 3:48 - loss: 0.1677 - accuracy: 0.93 - ETA: 3:47 - loss: 0.1712 - accuracy: 0.93 - ETA: 3:44 - loss: 0.1669 - accuracy: 0.93 - ETA: 3:43 - loss: 0.1749 - accuracy: 0.93 - ETA: 3:41 - loss: 0.1771 - accuracy: 0.93 - ETA: 3:39 - loss: 0.1747 - accuracy: 0.93 - ETA: 3:37 - loss: 0.1739 - accuracy: 0.93 - ETA: 3:35 - loss: 0.1717 - accuracy: 0.93 - ETA: 3:33 - loss: 0.1708 - accuracy: 0.93 - ETA: 3:31 - loss: 0.1736 - accuracy: 0.93 - ETA: 3:29 - loss: 0.1740 - accuracy: 0.93 - ETA: 3:28 - loss: 0.1737 - accuracy: 0.93 - ETA: 3:26 - loss: 0.1755 - accuracy: 0.93 - ETA: 3:25 - loss: 0.1791 - accuracy: 0.93 - ETA: 3:25 - loss: 0.1791 - accuracy: 0.93 - ETA: 3:23 - loss: 0.1804 - accuracy: 0.93 - ETA: 3:22 - loss: 0.1827 - accuracy: 0.93 - ETA: 3:20 - loss: 0.1842 - accuracy: 0.93 - ETA: 3:18 - loss: 0.1852 - accuracy: 0.92 - ETA: 3:17 - loss: 0.1848 - accuracy: 0.92 - ETA: 3:16 - loss: 0.1841 - accuracy: 0.92 - ETA: 3:15 - loss: 0.1829 - accuracy: 0.93 - ETA: 3:13 - loss: 0.1813 - accuracy: 0.93 - ETA: 3:12 - loss: 0.1780 - accuracy: 0.93 - ETA: 3:10 - loss: 0.1783 - accuracy: 0.93 - ETA: 3:09 - loss: 0.1778 - accuracy: 0.93 - ETA: 3:07 - loss: 0.1756 - accuracy: 0.93 - ETA: 3:05 - loss: 0.1750 - accuracy: 0.93 - ETA: 3:04 - loss: 0.1747 - accuracy: 0.93 - ETA: 3:02 - loss: 0.1740 - accuracy: 0.93 - ETA: 3:01 - loss: 0.1737 - accuracy: 0.93 - ETA: 2:59 - loss: 0.1754 - accuracy: 0.93 - ETA: 2:58 - loss: 0.1756 - accuracy: 0.93 - ETA: 2:56 - loss: 0.1758 - accuracy: 0.93 - ETA: 2:54 - loss: 0.1753 - accuracy: 0.93 - ETA: 2:52 - loss: 0.1753 - accuracy: 0.93 - ETA: 2:50 - loss: 0.1747 - accuracy: 0.93 - ETA: 2:49 - loss: 0.1770 - accuracy: 0.93 - ETA: 2:47 - loss: 0.1766 - accuracy: 0.93 - ETA: 2:45 - loss: 0.1763 - accuracy: 0.93 - ETA: 2:44 - loss: 0.1753 - accuracy: 0.93 - ETA: 2:42 - loss: 0.1756 - accuracy: 0.93 - ETA: 2:40 - loss: 0.1753 - accuracy: 0.93 - ETA: 2:39 - loss: 0.1752 - accuracy: 0.93 - ETA: 2:37 - loss: 0.1748 - accuracy: 0.93 - ETA: 2:35 - loss: 0.1747 - accuracy: 0.93 - ETA: 2:33 - loss: 0.1742 - accuracy: 0.93 - ETA: 2:32 - loss: 0.1742 - accuracy: 0.93 - ETA: 2:30 - loss: 0.1737 - accuracy: 0.93 - ETA: 2:29 - loss: 0.1737 - accuracy: 0.93 - ETA: 2:27 - loss: 0.1736 - accuracy: 0.93 - ETA: 2:25 - loss: 0.1733 - accuracy: 0.93 - ETA: 2:24 - loss: 0.1730 - accuracy: 0.93 - ETA: 2:22 - loss: 0.1731 - accuracy: 0.93 - ETA: 2:20 - loss: 0.1727 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1731 - accuracy: 0.93 - ETA: 2:17 - loss: 0.1731 - accuracy: 0.93 - ETA: 2:15 - loss: 0.1727 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1734 - accuracy: 0.93 - ETA: 2:12 - loss: 0.1742 - accuracy: 0.93 - ETA: 2:11 - loss: 0.1754 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1754 - accuracy: 0.93 - ETA: 2:07 - loss: 0.1743 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1754 - accuracy: 0.93 - ETA: 2:04 - loss: 0.1744 - accuracy: 0.93 - ETA: 2:02 - loss: 0.1757 - accuracy: 0.93 - ETA: 2:01 - loss: 0.1754 - accuracy: 0.93 - ETA: 1:59 - loss: 0.1757 - accuracy: 0.93 - ETA: 1:57 - loss: 0.1745 - accuracy: 0.93 - ETA: 1:56 - loss: 0.1751 - accuracy: 0.93 - ETA: 1:54 - loss: 0.1759 - accuracy: 0.93 - ETA: 1:52 - loss: 0.1757 - accuracy: 0.93 - ETA: 1:51 - loss: 0.1753 - accuracy: 0.93 - ETA: 1:49 - loss: 0.1749 - accuracy: 0.93 - ETA: 1:47 - loss: 0.1741 - accuracy: 0.93 - ETA: 1:46 - loss: 0.1753 - accuracy: 0.93 - ETA: 1:44 - loss: 0.1746 - accuracy: 0.93 - ETA: 1:42 - loss: 0.1741 - accuracy: 0.93 - ETA: 1:41 - loss: 0.1740 - accuracy: 0.93 - ETA: 1:39 - loss: 0.1737 - accuracy: 0.93 - ETA: 1:37 - loss: 0.1745 - accuracy: 0.93 - ETA: 1:36 - loss: 0.1743 - accuracy: 0.93 - ETA: 1:34 - loss: 0.1737 - accuracy: 0.93 - ETA: 1:32 - loss: 0.1742 - accuracy: 0.93 - ETA: 1:31 - loss: 0.1741 - accuracy: 0.93 - ETA: 1:29 - loss: 0.1744 - accuracy: 0.93 - ETA: 1:27 - loss: 0.1743 - accuracy: 0.93 - ETA: 1:26 - loss: 0.1741 - accuracy: 0.93 - ETA: 1:24 - loss: 0.1748 - accuracy: 0.93 - ETA: 1:23 - loss: 0.1751 - accuracy: 0.93 - ETA: 1:21 - loss: 0.1754 - accuracy: 0.93 - ETA: 1:19 - loss: 0.1753 - accuracy: 0.93 - ETA: 1:18 - loss: 0.1749 - accuracy: 0.93 - ETA: 1:16 - loss: 0.1752 - accuracy: 0.93 - ETA: 1:14 - loss: 0.1757 - accuracy: 0.93 - ETA: 1:13 - loss: 0.1761 - accuracy: 0.93 - ETA: 1:11 - loss: 0.1758 - accuracy: 0.93 - ETA: 1:09 - loss: 0.1752 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1750 - accuracy: 0.93 - ETA: 1:06 - loss: 0.1751 - accuracy: 0.93 - ETA: 1:04 - loss: 0.1751 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1756 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1755 - accuracy: 0.93 - ETA: 59s - loss: 0.1755 - accuracy: 0.9341 - ETA: 58s - loss: 0.1756 - accuracy: 0.934 - ETA: 56s - loss: 0.1766 - accuracy: 0.934 - ETA: 54s - loss: 0.1764 - accuracy: 0.934 - ETA: 53s - loss: 0.1763 - accuracy: 0.934 - ETA: 51s - loss: 0.1768 - accuracy: 0.933 - ETA: 49s - loss: 0.1768 - accuracy: 0.933 - ETA: 48s - loss: 0.1773 - accuracy: 0.933 - ETA: 46s - loss: 0.1773 - accuracy: 0.933 - ETA: 44s - loss: 0.1773 - accuracy: 0.933 - ETA: 43s - loss: 0.1773 - accuracy: 0.933 - ETA: 41s - loss: 0.1773 - accuracy: 0.933 - ETA: 39s - loss: 0.1783 - accuracy: 0.933 - ETA: 38s - loss: 0.1784 - accuracy: 0.933 - ETA: 36s - loss: 0.1786 - accuracy: 0.933 - ETA: 34s - loss: 0.1787 - accuracy: 0.933 - ETA: 33s - loss: 0.1785 - accuracy: 0.933 - ETA: 31s - loss: 0.1781 - accuracy: 0.933 - ETA: 29s - loss: 0.1785 - accuracy: 0.933 - ETA: 28s - loss: 0.1783 - accuracy: 0.933 - ETA: 26s - loss: 0.1777 - accuracy: 0.933 - ETA: 24s - loss: 0.1782 - accuracy: 0.933 - ETA: 23s - loss: 0.1787 - accuracy: 0.933 - ETA: 21s - loss: 0.1786 - accuracy: 0.933 - ETA: 19s - loss: 0.1784 - accuracy: 0.933 - ETA: 18s - loss: 0.1787 - accuracy: 0.933 - ETA: 16s - loss: 0.1788 - accuracy: 0.933 - ETA: 14s - loss: 0.1786 - accuracy: 0.933 - ETA: 13s - loss: 0.1786 - accuracy: 0.933 - ETA: 11s - loss: 0.1789 - accuracy: 0.933 - ETA: 9s - loss: 0.1790 - accuracy: 0.933 - ETA: 8s - loss: 0.1795 - accuracy: 0.93 - ETA: 6s - loss: 0.1792 - accuracy: 0.93 - ETA: 4s - loss: 0.1793 - accuracy: 0.93 - ETA: 3s - loss: 0.1786 - accuracy: 0.93 - ETA: 1s - loss: 0.1786 - accuracy: 0.93 - 276s 14ms/step - loss: 0.1785 - accuracy: 0.9332 - val_loss: 1.8606 - val_accuracy: 0.7668\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:14 - loss: 0.1228 - accuracy: 0.94 - ETA: 4:09 - loss: 0.1108 - accuracy: 0.96 - ETA: 4:02 - loss: 0.1178 - accuracy: 0.96 - ETA: 4:02 - loss: 0.1224 - accuracy: 0.95 - ETA: 4:02 - loss: 0.1194 - accuracy: 0.95 - ETA: 4:04 - loss: 0.1273 - accuracy: 0.95 - ETA: 3:59 - loss: 0.1397 - accuracy: 0.95 - ETA: 3:59 - loss: 0.1540 - accuracy: 0.94 - ETA: 3:59 - loss: 0.1599 - accuracy: 0.93 - ETA: 3:56 - loss: 0.1629 - accuracy: 0.93 - ETA: 3:55 - loss: 0.1728 - accuracy: 0.93 - ETA: 3:55 - loss: 0.1707 - accuracy: 0.93 - ETA: 3:52 - loss: 0.1705 - accuracy: 0.93 - ETA: 3:50 - loss: 0.1695 - accuracy: 0.93 - ETA: 3:49 - loss: 0.1760 - accuracy: 0.93 - ETA: 3:46 - loss: 0.1775 - accuracy: 0.93 - ETA: 3:43 - loss: 0.1745 - accuracy: 0.93 - ETA: 3:42 - loss: 0.1773 - accuracy: 0.93 - ETA: 3:40 - loss: 0.1752 - accuracy: 0.93 - ETA: 3:38 - loss: 0.1751 - accuracy: 0.93 - ETA: 3:36 - loss: 0.1789 - accuracy: 0.93 - ETA: 3:34 - loss: 0.1768 - accuracy: 0.93 - ETA: 3:32 - loss: 0.1760 - accuracy: 0.93 - ETA: 3:31 - loss: 0.1773 - accuracy: 0.93 - ETA: 3:30 - loss: 0.1784 - accuracy: 0.93 - ETA: 3:28 - loss: 0.1783 - accuracy: 0.93 - ETA: 3:27 - loss: 0.1796 - accuracy: 0.93 - ETA: 3:26 - loss: 0.1787 - accuracy: 0.93 - ETA: 3:24 - loss: 0.1801 - accuracy: 0.93 - ETA: 3:23 - loss: 0.1811 - accuracy: 0.93 - ETA: 3:21 - loss: 0.1793 - accuracy: 0.93 - ETA: 3:19 - loss: 0.1793 - accuracy: 0.93 - ETA: 3:18 - loss: 0.1784 - accuracy: 0.93 - ETA: 3:16 - loss: 0.1766 - accuracy: 0.93 - ETA: 3:14 - loss: 0.1772 - accuracy: 0.93 - ETA: 3:12 - loss: 0.1773 - accuracy: 0.93 - ETA: 3:10 - loss: 0.1767 - accuracy: 0.93 - ETA: 3:09 - loss: 0.1764 - accuracy: 0.93 - ETA: 3:07 - loss: 0.1769 - accuracy: 0.93 - ETA: 3:05 - loss: 0.1774 - accuracy: 0.93 - ETA: 3:04 - loss: 0.1766 - accuracy: 0.93 - ETA: 3:02 - loss: 0.1765 - accuracy: 0.93 - ETA: 3:00 - loss: 0.1739 - accuracy: 0.93 - ETA: 2:58 - loss: 0.1720 - accuracy: 0.93 - ETA: 2:56 - loss: 0.1722 - accuracy: 0.93 - ETA: 2:54 - loss: 0.1729 - accuracy: 0.93 - ETA: 2:53 - loss: 0.1716 - accuracy: 0.93 - ETA: 2:51 - loss: 0.1702 - accuracy: 0.93 - ETA: 2:49 - loss: 0.1694 - accuracy: 0.93 - ETA: 2:47 - loss: 0.1679 - accuracy: 0.93 - ETA: 2:46 - loss: 0.1692 - accuracy: 0.93 - ETA: 2:44 - loss: 0.1700 - accuracy: 0.93 - ETA: 2:43 - loss: 0.1694 - accuracy: 0.93 - ETA: 2:41 - loss: 0.1683 - accuracy: 0.93 - ETA: 2:39 - loss: 0.1680 - accuracy: 0.93 - ETA: 2:37 - loss: 0.1698 - accuracy: 0.93 - ETA: 2:36 - loss: 0.1701 - accuracy: 0.93 - ETA: 2:34 - loss: 0.1705 - accuracy: 0.93 - ETA: 2:32 - loss: 0.1703 - accuracy: 0.93 - ETA: 2:30 - loss: 0.1696 - accuracy: 0.93 - ETA: 2:29 - loss: 0.1693 - accuracy: 0.93 - ETA: 2:27 - loss: 0.1714 - accuracy: 0.93 - ETA: 2:25 - loss: 0.1721 - accuracy: 0.93 - ETA: 2:24 - loss: 0.1717 - accuracy: 0.93 - ETA: 2:22 - loss: 0.1722 - accuracy: 0.93 - ETA: 2:20 - loss: 0.1717 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1719 - accuracy: 0.93 - ETA: 2:17 - loss: 0.1727 - accuracy: 0.93 - ETA: 2:15 - loss: 0.1729 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1727 - accuracy: 0.93 - ETA: 2:12 - loss: 0.1730 - accuracy: 0.93 - ETA: 2:11 - loss: 0.1729 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1736 - accuracy: 0.93 - ETA: 2:07 - loss: 0.1736 - accuracy: 0.93 - ETA: 2:05 - loss: 0.1734 - accuracy: 0.93 - ETA: 2:04 - loss: 0.1731 - accuracy: 0.93 - ETA: 2:02 - loss: 0.1730 - accuracy: 0.93 - ETA: 2:00 - loss: 0.1729 - accuracy: 0.93 - ETA: 1:59 - loss: 0.1738 - accuracy: 0.93 - ETA: 1:57 - loss: 0.1745 - accuracy: 0.93 - ETA: 1:55 - loss: 0.1758 - accuracy: 0.93 - ETA: 1:54 - loss: 0.1757 - accuracy: 0.93 - ETA: 1:52 - loss: 0.1752 - accuracy: 0.93 - ETA: 1:50 - loss: 0.1753 - accuracy: 0.93 - ETA: 1:48 - loss: 0.1750 - accuracy: 0.93 - ETA: 1:47 - loss: 0.1751 - accuracy: 0.93 - ETA: 1:45 - loss: 0.1756 - accuracy: 0.93 - ETA: 1:43 - loss: 0.1758 - accuracy: 0.93 - ETA: 1:42 - loss: 0.1764 - accuracy: 0.93 - ETA: 1:40 - loss: 0.1754 - accuracy: 0.93 - ETA: 1:38 - loss: 0.1761 - accuracy: 0.93 - ETA: 1:37 - loss: 0.1761 - accuracy: 0.93 - ETA: 1:35 - loss: 0.1753 - accuracy: 0.93 - ETA: 1:33 - loss: 0.1759 - accuracy: 0.93 - ETA: 1:32 - loss: 0.1773 - accuracy: 0.93 - ETA: 1:30 - loss: 0.1765 - accuracy: 0.93 - ETA: 1:28 - loss: 0.1760 - accuracy: 0.93 - ETA: 1:27 - loss: 0.1759 - accuracy: 0.93 - ETA: 1:25 - loss: 0.1756 - accuracy: 0.93 - ETA: 1:23 - loss: 0.1754 - accuracy: 0.93 - ETA: 1:22 - loss: 0.1760 - accuracy: 0.93 - ETA: 1:20 - loss: 0.1750 - accuracy: 0.93 - ETA: 1:18 - loss: 0.1756 - accuracy: 0.93 - ETA: 1:17 - loss: 0.1756 - accuracy: 0.93 - ETA: 1:15 - loss: 0.1754 - accuracy: 0.93 - ETA: 1:14 - loss: 0.1747 - accuracy: 0.93 - ETA: 1:12 - loss: 0.1747 - accuracy: 0.93 - ETA: 1:10 - loss: 0.1751 - accuracy: 0.93 - ETA: 1:09 - loss: 0.1755 - accuracy: 0.93 - ETA: 1:07 - loss: 0.1752 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1761 - accuracy: 0.93 - ETA: 1:04 - loss: 0.1756 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1754 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1758 - accuracy: 0.93 - ETA: 59s - loss: 0.1755 - accuracy: 0.9348 - ETA: 57s - loss: 0.1753 - accuracy: 0.934 - ETA: 55s - loss: 0.1761 - accuracy: 0.934 - ETA: 54s - loss: 0.1763 - accuracy: 0.934 - ETA: 52s - loss: 0.1767 - accuracy: 0.934 - ETA: 51s - loss: 0.1769 - accuracy: 0.934 - ETA: 49s - loss: 0.1769 - accuracy: 0.934 - ETA: 47s - loss: 0.1764 - accuracy: 0.934 - ETA: 46s - loss: 0.1767 - accuracy: 0.934 - ETA: 44s - loss: 0.1763 - accuracy: 0.934 - ETA: 42s - loss: 0.1764 - accuracy: 0.934 - ETA: 41s - loss: 0.1758 - accuracy: 0.934 - ETA: 39s - loss: 0.1758 - accuracy: 0.934 - ETA: 37s - loss: 0.1752 - accuracy: 0.934 - ETA: 36s - loss: 0.1753 - accuracy: 0.934 - ETA: 34s - loss: 0.1756 - accuracy: 0.934 - ETA: 32s - loss: 0.1764 - accuracy: 0.934 - ETA: 31s - loss: 0.1773 - accuracy: 0.934 - ETA: 29s - loss: 0.1779 - accuracy: 0.933 - ETA: 27s - loss: 0.1773 - accuracy: 0.933 - ETA: 26s - loss: 0.1775 - accuracy: 0.934 - ETA: 24s - loss: 0.1772 - accuracy: 0.934 - ETA: 22s - loss: 0.1772 - accuracy: 0.934 - ETA: 21s - loss: 0.1775 - accuracy: 0.934 - ETA: 19s - loss: 0.1775 - accuracy: 0.934 - ETA: 18s - loss: 0.1769 - accuracy: 0.934 - ETA: 16s - loss: 0.1768 - accuracy: 0.934 - ETA: 14s - loss: 0.1775 - accuracy: 0.933 - ETA: 13s - loss: 0.1777 - accuracy: 0.933 - ETA: 11s - loss: 0.1784 - accuracy: 0.933 - ETA: 9s - loss: 0.1781 - accuracy: 0.934 - ETA: 8s - loss: 0.1781 - accuracy: 0.93 - ETA: 6s - loss: 0.1777 - accuracy: 0.93 - ETA: 4s - loss: 0.1785 - accuracy: 0.93 - ETA: 3s - loss: 0.1783 - accuracy: 0.93 - ETA: 1s - loss: 0.1789 - accuracy: 0.93 - 275s 14ms/step - loss: 0.1788 - accuracy: 0.9337 - val_loss: 1.8565 - val_accuracy: 0.7664\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 3:56 - loss: 0.1048 - accuracy: 0.96 - ETA: 4:01 - loss: 0.1583 - accuracy: 0.93 - ETA: 4:05 - loss: 0.1439 - accuracy: 0.94 - ETA: 4:07 - loss: 0.1354 - accuracy: 0.94 - ETA: 4:02 - loss: 0.1391 - accuracy: 0.94 - ETA: 4:01 - loss: 0.1428 - accuracy: 0.94 - ETA: 4:00 - loss: 0.1441 - accuracy: 0.94 - ETA: 4:00 - loss: 0.1462 - accuracy: 0.94 - ETA: 3:59 - loss: 0.1496 - accuracy: 0.94 - ETA: 3:58 - loss: 0.1475 - accuracy: 0.94 - ETA: 3:56 - loss: 0.1474 - accuracy: 0.94 - ETA: 3:55 - loss: 0.1567 - accuracy: 0.94 - ETA: 3:54 - loss: 0.1583 - accuracy: 0.94 - ETA: 3:51 - loss: 0.1587 - accuracy: 0.94 - ETA: 3:47 - loss: 0.1522 - accuracy: 0.94 - ETA: 3:46 - loss: 0.1488 - accuracy: 0.94 - ETA: 3:44 - loss: 0.1528 - accuracy: 0.94 - ETA: 3:44 - loss: 0.1541 - accuracy: 0.94 - ETA: 3:42 - loss: 0.1533 - accuracy: 0.94 - ETA: 3:41 - loss: 0.1518 - accuracy: 0.94 - ETA: 3:39 - loss: 0.1502 - accuracy: 0.94 - ETA: 3:37 - loss: 0.1520 - accuracy: 0.94 - ETA: 3:36 - loss: 0.1534 - accuracy: 0.94 - ETA: 3:33 - loss: 0.1517 - accuracy: 0.94 - ETA: 3:30 - loss: 0.1500 - accuracy: 0.94 - ETA: 3:29 - loss: 0.1512 - accuracy: 0.94 - ETA: 3:27 - loss: 0.1528 - accuracy: 0.94 - ETA: 3:25 - loss: 0.1542 - accuracy: 0.94 - ETA: 3:24 - loss: 0.1588 - accuracy: 0.94 - ETA: 3:22 - loss: 0.1581 - accuracy: 0.94 - ETA: 3:20 - loss: 0.1605 - accuracy: 0.94 - ETA: 3:18 - loss: 0.1603 - accuracy: 0.94 - ETA: 3:17 - loss: 0.1602 - accuracy: 0.94 - ETA: 3:14 - loss: 0.1580 - accuracy: 0.94 - ETA: 3:13 - loss: 0.1572 - accuracy: 0.94 - ETA: 3:12 - loss: 0.1565 - accuracy: 0.94 - ETA: 3:10 - loss: 0.1593 - accuracy: 0.94 - ETA: 3:08 - loss: 0.1600 - accuracy: 0.93 - ETA: 3:07 - loss: 0.1593 - accuracy: 0.93 - ETA: 3:05 - loss: 0.1611 - accuracy: 0.93 - ETA: 3:03 - loss: 0.1613 - accuracy: 0.93 - ETA: 3:02 - loss: 0.1625 - accuracy: 0.93 - ETA: 3:00 - loss: 0.1614 - accuracy: 0.93 - ETA: 2:58 - loss: 0.1604 - accuracy: 0.93 - ETA: 2:56 - loss: 0.1612 - accuracy: 0.94 - ETA: 2:54 - loss: 0.1618 - accuracy: 0.93 - ETA: 2:53 - loss: 0.1605 - accuracy: 0.94 - ETA: 2:51 - loss: 0.1625 - accuracy: 0.93 - ETA: 2:49 - loss: 0.1626 - accuracy: 0.93 - ETA: 2:47 - loss: 0.1647 - accuracy: 0.93 - ETA: 2:46 - loss: 0.1637 - accuracy: 0.93 - ETA: 2:44 - loss: 0.1634 - accuracy: 0.93 - ETA: 2:42 - loss: 0.1638 - accuracy: 0.93 - ETA: 2:40 - loss: 0.1638 - accuracy: 0.93 - ETA: 2:38 - loss: 0.1637 - accuracy: 0.93 - ETA: 2:37 - loss: 0.1642 - accuracy: 0.93 - ETA: 2:35 - loss: 0.1653 - accuracy: 0.93 - ETA: 2:34 - loss: 0.1675 - accuracy: 0.93 - ETA: 2:32 - loss: 0.1675 - accuracy: 0.93 - ETA: 2:30 - loss: 0.1681 - accuracy: 0.93 - ETA: 2:29 - loss: 0.1685 - accuracy: 0.93 - ETA: 2:27 - loss: 0.1700 - accuracy: 0.93 - ETA: 2:25 - loss: 0.1705 - accuracy: 0.93 - ETA: 2:23 - loss: 0.1713 - accuracy: 0.93 - ETA: 2:22 - loss: 0.1708 - accuracy: 0.93 - ETA: 2:20 - loss: 0.1708 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1706 - accuracy: 0.93 - ETA: 2:17 - loss: 0.1696 - accuracy: 0.93 - ETA: 2:16 - loss: 0.1707 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1696 - accuracy: 0.93 - ETA: 2:12 - loss: 0.1690 - accuracy: 0.93 - ETA: 2:11 - loss: 0.1691 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1699 - accuracy: 0.93 - ETA: 2:07 - loss: 0.1701 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1693 - accuracy: 0.93 - ETA: 2:04 - loss: 0.1699 - accuracy: 0.93 - ETA: 2:02 - loss: 0.1713 - accuracy: 0.93 - ETA: 2:01 - loss: 0.1730 - accuracy: 0.93 - ETA: 1:59 - loss: 0.1733 - accuracy: 0.93 - ETA: 1:58 - loss: 0.1730 - accuracy: 0.93 - ETA: 1:56 - loss: 0.1732 - accuracy: 0.93 - ETA: 1:54 - loss: 0.1732 - accuracy: 0.93 - ETA: 1:53 - loss: 0.1737 - accuracy: 0.93 - ETA: 1:51 - loss: 0.1743 - accuracy: 0.93 - ETA: 1:49 - loss: 0.1732 - accuracy: 0.93 - ETA: 1:48 - loss: 0.1725 - accuracy: 0.93 - ETA: 1:46 - loss: 0.1739 - accuracy: 0.93 - ETA: 1:44 - loss: 0.1754 - accuracy: 0.93 - ETA: 1:43 - loss: 0.1748 - accuracy: 0.93 - ETA: 1:41 - loss: 0.1746 - accuracy: 0.93 - ETA: 1:39 - loss: 0.1744 - accuracy: 0.93 - ETA: 1:38 - loss: 0.1745 - accuracy: 0.93 - ETA: 1:36 - loss: 0.1749 - accuracy: 0.93 - ETA: 1:34 - loss: 0.1744 - accuracy: 0.93 - ETA: 1:33 - loss: 0.1743 - accuracy: 0.93 - ETA: 1:31 - loss: 0.1742 - accuracy: 0.93 - ETA: 1:29 - loss: 0.1741 - accuracy: 0.93 - ETA: 1:28 - loss: 0.1737 - accuracy: 0.93 - ETA: 1:26 - loss: 0.1732 - accuracy: 0.93 - ETA: 1:25 - loss: 0.1735 - accuracy: 0.93 - ETA: 1:23 - loss: 0.1730 - accuracy: 0.93 - ETA: 1:21 - loss: 0.1724 - accuracy: 0.93 - ETA: 1:19 - loss: 0.1720 - accuracy: 0.93 - ETA: 1:18 - loss: 0.1722 - accuracy: 0.93 - ETA: 1:16 - loss: 0.1724 - accuracy: 0.93 - ETA: 1:14 - loss: 0.1728 - accuracy: 0.93 - ETA: 1:13 - loss: 0.1724 - accuracy: 0.93 - ETA: 1:11 - loss: 0.1724 - accuracy: 0.93 - ETA: 1:09 - loss: 0.1713 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1708 - accuracy: 0.93 - ETA: 1:06 - loss: 0.1705 - accuracy: 0.93 - ETA: 1:04 - loss: 0.1707 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1716 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1716 - accuracy: 0.93 - ETA: 59s - loss: 0.1723 - accuracy: 0.9365 - ETA: 58s - loss: 0.1722 - accuracy: 0.936 - ETA: 56s - loss: 0.1728 - accuracy: 0.936 - ETA: 54s - loss: 0.1726 - accuracy: 0.936 - ETA: 53s - loss: 0.1725 - accuracy: 0.936 - ETA: 51s - loss: 0.1724 - accuracy: 0.936 - ETA: 49s - loss: 0.1722 - accuracy: 0.936 - ETA: 48s - loss: 0.1725 - accuracy: 0.936 - ETA: 46s - loss: 0.1735 - accuracy: 0.935 - ETA: 44s - loss: 0.1730 - accuracy: 0.936 - ETA: 43s - loss: 0.1724 - accuracy: 0.936 - ETA: 41s - loss: 0.1724 - accuracy: 0.936 - ETA: 39s - loss: 0.1725 - accuracy: 0.936 - ETA: 38s - loss: 0.1725 - accuracy: 0.936 - ETA: 36s - loss: 0.1721 - accuracy: 0.936 - ETA: 34s - loss: 0.1722 - accuracy: 0.936 - ETA: 33s - loss: 0.1717 - accuracy: 0.936 - ETA: 31s - loss: 0.1718 - accuracy: 0.936 - ETA: 29s - loss: 0.1722 - accuracy: 0.936 - ETA: 27s - loss: 0.1719 - accuracy: 0.936 - ETA: 26s - loss: 0.1718 - accuracy: 0.936 - ETA: 24s - loss: 0.1720 - accuracy: 0.936 - ETA: 22s - loss: 0.1721 - accuracy: 0.936 - ETA: 21s - loss: 0.1723 - accuracy: 0.936 - ETA: 19s - loss: 0.1721 - accuracy: 0.936 - ETA: 18s - loss: 0.1720 - accuracy: 0.936 - ETA: 16s - loss: 0.1713 - accuracy: 0.936 - ETA: 14s - loss: 0.1716 - accuracy: 0.936 - ETA: 13s - loss: 0.1722 - accuracy: 0.936 - ETA: 11s - loss: 0.1727 - accuracy: 0.936 - ETA: 9s - loss: 0.1728 - accuracy: 0.936 - ETA: 8s - loss: 0.1730 - accuracy: 0.93 - ETA: 6s - loss: 0.1731 - accuracy: 0.93 - ETA: 4s - loss: 0.1726 - accuracy: 0.93 - ETA: 3s - loss: 0.1723 - accuracy: 0.93 - ETA: 1s - loss: 0.1725 - accuracy: 0.93 - 274s 14ms/step - loss: 0.1730 - accuracy: 0.9365 - val_loss: 1.8756 - val_accuracy: 0.7681\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 4:14 - loss: 0.1814 - accuracy: 0.93 - ETA: 4:11 - loss: 0.1968 - accuracy: 0.92 - ETA: 4:04 - loss: 0.1819 - accuracy: 0.92 - ETA: 3:59 - loss: 0.1818 - accuracy: 0.92 - ETA: 3:56 - loss: 0.1720 - accuracy: 0.93 - ETA: 3:57 - loss: 0.1657 - accuracy: 0.93 - ETA: 3:58 - loss: 0.1750 - accuracy: 0.93 - ETA: 3:55 - loss: 0.1708 - accuracy: 0.93 - ETA: 3:55 - loss: 0.1699 - accuracy: 0.93 - ETA: 3:55 - loss: 0.1621 - accuracy: 0.93 - ETA: 3:52 - loss: 0.1642 - accuracy: 0.93 - ETA: 3:51 - loss: 0.1657 - accuracy: 0.93 - ETA: 3:49 - loss: 0.1625 - accuracy: 0.93 - ETA: 3:47 - loss: 0.1591 - accuracy: 0.94 - ETA: 3:46 - loss: 0.1598 - accuracy: 0.93 - ETA: 3:44 - loss: 0.1597 - accuracy: 0.93 - ETA: 3:42 - loss: 0.1573 - accuracy: 0.93 - ETA: 3:41 - loss: 0.1555 - accuracy: 0.94 - ETA: 3:39 - loss: 0.1603 - accuracy: 0.93 - ETA: 3:37 - loss: 0.1632 - accuracy: 0.93 - ETA: 3:35 - loss: 0.1611 - accuracy: 0.93 - ETA: 3:34 - loss: 0.1604 - accuracy: 0.93 - ETA: 3:31 - loss: 0.1610 - accuracy: 0.93 - ETA: 3:29 - loss: 0.1641 - accuracy: 0.93 - ETA: 3:27 - loss: 0.1678 - accuracy: 0.93 - ETA: 3:26 - loss: 0.1709 - accuracy: 0.93 - ETA: 3:24 - loss: 0.1711 - accuracy: 0.93 - ETA: 3:22 - loss: 0.1691 - accuracy: 0.93 - ETA: 3:20 - loss: 0.1677 - accuracy: 0.93 - ETA: 3:18 - loss: 0.1663 - accuracy: 0.93 - ETA: 3:17 - loss: 0.1674 - accuracy: 0.93 - ETA: 3:15 - loss: 0.1706 - accuracy: 0.93 - ETA: 3:13 - loss: 0.1697 - accuracy: 0.93 - ETA: 3:12 - loss: 0.1691 - accuracy: 0.93 - ETA: 3:10 - loss: 0.1698 - accuracy: 0.93 - ETA: 3:08 - loss: 0.1682 - accuracy: 0.93 - ETA: 3:07 - loss: 0.1719 - accuracy: 0.93 - ETA: 3:05 - loss: 0.1722 - accuracy: 0.93 - ETA: 3:04 - loss: 0.1728 - accuracy: 0.93 - ETA: 3:02 - loss: 0.1717 - accuracy: 0.93 - ETA: 3:01 - loss: 0.1712 - accuracy: 0.93 - ETA: 2:59 - loss: 0.1701 - accuracy: 0.93 - ETA: 2:57 - loss: 0.1711 - accuracy: 0.93 - ETA: 2:55 - loss: 0.1710 - accuracy: 0.93 - ETA: 2:54 - loss: 0.1715 - accuracy: 0.93 - ETA: 2:52 - loss: 0.1713 - accuracy: 0.93 - ETA: 2:50 - loss: 0.1708 - accuracy: 0.93 - ETA: 2:49 - loss: 0.1715 - accuracy: 0.93 - ETA: 2:47 - loss: 0.1720 - accuracy: 0.93 - ETA: 2:44 - loss: 0.1723 - accuracy: 0.93 - ETA: 2:42 - loss: 0.1730 - accuracy: 0.93 - ETA: 2:41 - loss: 0.1723 - accuracy: 0.93 - ETA: 2:39 - loss: 0.1720 - accuracy: 0.93 - ETA: 2:37 - loss: 0.1707 - accuracy: 0.93 - ETA: 2:36 - loss: 0.1704 - accuracy: 0.93 - ETA: 2:35 - loss: 0.1714 - accuracy: 0.93 - ETA: 2:33 - loss: 0.1721 - accuracy: 0.93 - ETA: 2:32 - loss: 0.1728 - accuracy: 0.93 - ETA: 2:30 - loss: 0.1732 - accuracy: 0.93 - ETA: 2:29 - loss: 0.1728 - accuracy: 0.93 - ETA: 2:27 - loss: 0.1718 - accuracy: 0.93 - ETA: 2:25 - loss: 0.1724 - accuracy: 0.93 - ETA: 2:24 - loss: 0.1735 - accuracy: 0.93 - ETA: 2:22 - loss: 0.1747 - accuracy: 0.93 - ETA: 2:21 - loss: 0.1755 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1754 - accuracy: 0.93 - ETA: 2:18 - loss: 0.1761 - accuracy: 0.93 - ETA: 2:16 - loss: 0.1761 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1763 - accuracy: 0.93 - ETA: 2:13 - loss: 0.1758 - accuracy: 0.93 - ETA: 2:11 - loss: 0.1762 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1763 - accuracy: 0.93 - ETA: 2:08 - loss: 0.1756 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1757 - accuracy: 0.93 - ETA: 2:05 - loss: 0.1761 - accuracy: 0.93 - ETA: 2:03 - loss: 0.1765 - accuracy: 0.93 - ETA: 2:01 - loss: 0.1758 - accuracy: 0.93 - ETA: 2:00 - loss: 0.1747 - accuracy: 0.93 - ETA: 1:58 - loss: 0.1741 - accuracy: 0.93 - ETA: 1:57 - loss: 0.1747 - accuracy: 0.93 - ETA: 1:55 - loss: 0.1742 - accuracy: 0.93 - ETA: 1:53 - loss: 0.1736 - accuracy: 0.93 - ETA: 1:52 - loss: 0.1726 - accuracy: 0.93 - ETA: 1:50 - loss: 0.1723 - accuracy: 0.93 - ETA: 1:49 - loss: 0.1713 - accuracy: 0.93 - ETA: 1:47 - loss: 0.1720 - accuracy: 0.93 - ETA: 1:46 - loss: 0.1725 - accuracy: 0.93 - ETA: 1:44 - loss: 0.1726 - accuracy: 0.93 - ETA: 1:42 - loss: 0.1730 - accuracy: 0.93 - ETA: 1:40 - loss: 0.1726 - accuracy: 0.93 - ETA: 1:38 - loss: 0.1721 - accuracy: 0.93 - ETA: 1:36 - loss: 0.1714 - accuracy: 0.93 - ETA: 1:34 - loss: 0.1714 - accuracy: 0.93 - ETA: 1:32 - loss: 0.1720 - accuracy: 0.93 - ETA: 1:31 - loss: 0.1728 - accuracy: 0.93 - ETA: 1:29 - loss: 0.1726 - accuracy: 0.93 - ETA: 1:27 - loss: 0.1725 - accuracy: 0.93 - ETA: 1:26 - loss: 0.1721 - accuracy: 0.93 - ETA: 1:24 - loss: 0.1727 - accuracy: 0.93 - ETA: 1:23 - loss: 0.1722 - accuracy: 0.93 - ETA: 1:21 - loss: 0.1720 - accuracy: 0.93 - ETA: 1:19 - loss: 0.1720 - accuracy: 0.93 - ETA: 1:17 - loss: 0.1718 - accuracy: 0.93 - ETA: 1:16 - loss: 0.1725 - accuracy: 0.93 - ETA: 1:14 - loss: 0.1731 - accuracy: 0.93 - ETA: 1:12 - loss: 0.1729 - accuracy: 0.93 - ETA: 1:10 - loss: 0.1726 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1733 - accuracy: 0.93 - ETA: 1:07 - loss: 0.1727 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1723 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1719 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1723 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1730 - accuracy: 0.93 - ETA: 58s - loss: 0.1729 - accuracy: 0.9356 - ETA: 57s - loss: 0.1723 - accuracy: 0.935 - ETA: 55s - loss: 0.1723 - accuracy: 0.935 - ETA: 54s - loss: 0.1719 - accuracy: 0.936 - ETA: 52s - loss: 0.1722 - accuracy: 0.935 - ETA: 51s - loss: 0.1718 - accuracy: 0.935 - ETA: 49s - loss: 0.1719 - accuracy: 0.935 - ETA: 48s - loss: 0.1716 - accuracy: 0.936 - ETA: 46s - loss: 0.1719 - accuracy: 0.936 - ETA: 44s - loss: 0.1722 - accuracy: 0.935 - ETA: 43s - loss: 0.1724 - accuracy: 0.935 - ETA: 41s - loss: 0.1726 - accuracy: 0.935 - ETA: 40s - loss: 0.1723 - accuracy: 0.935 - ETA: 38s - loss: 0.1724 - accuracy: 0.935 - ETA: 36s - loss: 0.1733 - accuracy: 0.935 - ETA: 35s - loss: 0.1736 - accuracy: 0.935 - ETA: 33s - loss: 0.1735 - accuracy: 0.935 - ETA: 31s - loss: 0.1733 - accuracy: 0.935 - ETA: 30s - loss: 0.1737 - accuracy: 0.935 - ETA: 28s - loss: 0.1741 - accuracy: 0.935 - ETA: 26s - loss: 0.1747 - accuracy: 0.934 - ETA: 25s - loss: 0.1749 - accuracy: 0.934 - ETA: 23s - loss: 0.1744 - accuracy: 0.935 - ETA: 21s - loss: 0.1738 - accuracy: 0.935 - ETA: 20s - loss: 0.1736 - accuracy: 0.935 - ETA: 18s - loss: 0.1732 - accuracy: 0.935 - ETA: 17s - loss: 0.1738 - accuracy: 0.935 - ETA: 15s - loss: 0.1740 - accuracy: 0.935 - ETA: 13s - loss: 0.1745 - accuracy: 0.935 - ETA: 12s - loss: 0.1744 - accuracy: 0.935 - ETA: 10s - loss: 0.1740 - accuracy: 0.935 - ETA: 9s - loss: 0.1736 - accuracy: 0.935 - ETA: 7s - loss: 0.1739 - accuracy: 0.93 - ETA: 5s - loss: 0.1733 - accuracy: 0.93 - ETA: 4s - loss: 0.1733 - accuracy: 0.93 - ETA: 2s - loss: 0.1739 - accuracy: 0.93 - ETA: 1s - loss: 0.1734 - accuracy: 0.93 - 240s 12ms/step - loss: 0.1734 - accuracy: 0.9359 - val_loss: 1.9034 - val_accuracy: 0.7670\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:08 - loss: 0.1276 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1538 - accuracy: 0.94 - ETA: 2:09 - loss: 0.1468 - accuracy: 0.94 - ETA: 2:08 - loss: 0.1394 - accuracy: 0.94 - ETA: 2:06 - loss: 0.1472 - accuracy: 0.94 - ETA: 2:07 - loss: 0.1569 - accuracy: 0.93 - ETA: 2:08 - loss: 0.1682 - accuracy: 0.93 - ETA: 2:07 - loss: 0.1758 - accuracy: 0.93 - ETA: 2:07 - loss: 0.1887 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1798 - accuracy: 0.93 - ETA: 2:05 - loss: 0.1871 - accuracy: 0.92 - ETA: 2:04 - loss: 0.1853 - accuracy: 0.92 - ETA: 2:03 - loss: 0.1870 - accuracy: 0.92 - ETA: 2:02 - loss: 0.1871 - accuracy: 0.93 - ETA: 2:01 - loss: 0.1824 - accuracy: 0.93 - ETA: 2:00 - loss: 0.1799 - accuracy: 0.93 - ETA: 1:59 - loss: 0.1772 - accuracy: 0.93 - ETA: 1:59 - loss: 0.1800 - accuracy: 0.93 - ETA: 1:58 - loss: 0.1825 - accuracy: 0.93 - ETA: 1:57 - loss: 0.1832 - accuracy: 0.93 - ETA: 1:56 - loss: 0.1886 - accuracy: 0.93 - ETA: 1:55 - loss: 0.1910 - accuracy: 0.93 - ETA: 1:54 - loss: 0.1932 - accuracy: 0.93 - ETA: 1:54 - loss: 0.1900 - accuracy: 0.93 - ETA: 1:53 - loss: 0.1892 - accuracy: 0.93 - ETA: 1:53 - loss: 0.1860 - accuracy: 0.93 - ETA: 1:51 - loss: 0.1869 - accuracy: 0.93 - ETA: 1:50 - loss: 0.1863 - accuracy: 0.93 - ETA: 1:49 - loss: 0.1877 - accuracy: 0.93 - ETA: 1:48 - loss: 0.1878 - accuracy: 0.93 - ETA: 1:47 - loss: 0.1863 - accuracy: 0.93 - ETA: 1:46 - loss: 0.1852 - accuracy: 0.93 - ETA: 1:45 - loss: 0.1831 - accuracy: 0.93 - ETA: 1:44 - loss: 0.1852 - accuracy: 0.93 - ETA: 1:43 - loss: 0.1863 - accuracy: 0.93 - ETA: 1:43 - loss: 0.1858 - accuracy: 0.93 - ETA: 1:41 - loss: 0.1840 - accuracy: 0.93 - ETA: 1:40 - loss: 0.1826 - accuracy: 0.93 - ETA: 1:39 - loss: 0.1819 - accuracy: 0.93 - ETA: 1:38 - loss: 0.1802 - accuracy: 0.93 - ETA: 1:38 - loss: 0.1819 - accuracy: 0.93 - ETA: 1:37 - loss: 0.1814 - accuracy: 0.93 - ETA: 1:36 - loss: 0.1816 - accuracy: 0.93 - ETA: 1:35 - loss: 0.1829 - accuracy: 0.93 - ETA: 1:34 - loss: 0.1835 - accuracy: 0.93 - ETA: 1:33 - loss: 0.1825 - accuracy: 0.93 - ETA: 1:32 - loss: 0.1823 - accuracy: 0.93 - ETA: 1:32 - loss: 0.1814 - accuracy: 0.93 - ETA: 1:31 - loss: 0.1797 - accuracy: 0.93 - ETA: 1:30 - loss: 0.1785 - accuracy: 0.93 - ETA: 1:29 - loss: 0.1780 - accuracy: 0.93 - ETA: 1:28 - loss: 0.1776 - accuracy: 0.93 - ETA: 1:27 - loss: 0.1782 - accuracy: 0.93 - ETA: 1:26 - loss: 0.1771 - accuracy: 0.93 - ETA: 1:25 - loss: 0.1767 - accuracy: 0.93 - ETA: 1:24 - loss: 0.1767 - accuracy: 0.93 - ETA: 1:23 - loss: 0.1756 - accuracy: 0.93 - ETA: 1:22 - loss: 0.1767 - accuracy: 0.93 - ETA: 1:21 - loss: 0.1753 - accuracy: 0.93 - ETA: 1:21 - loss: 0.1752 - accuracy: 0.93 - ETA: 1:20 - loss: 0.1757 - accuracy: 0.93 - ETA: 1:19 - loss: 0.1747 - accuracy: 0.93 - ETA: 1:18 - loss: 0.1750 - accuracy: 0.93 - ETA: 1:17 - loss: 0.1772 - accuracy: 0.93 - ETA: 1:16 - loss: 0.1778 - accuracy: 0.93 - ETA: 1:16 - loss: 0.1787 - accuracy: 0.93 - ETA: 1:15 - loss: 0.1778 - accuracy: 0.93 - ETA: 1:14 - loss: 0.1781 - accuracy: 0.93 - ETA: 1:13 - loss: 0.1777 - accuracy: 0.93 - ETA: 1:12 - loss: 0.1771 - accuracy: 0.93 - ETA: 1:11 - loss: 0.1776 - accuracy: 0.93 - ETA: 1:10 - loss: 0.1769 - accuracy: 0.93 - ETA: 1:09 - loss: 0.1767 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1767 - accuracy: 0.93 - ETA: 1:07 - loss: 0.1760 - accuracy: 0.93 - ETA: 1:07 - loss: 0.1756 - accuracy: 0.93 - ETA: 1:06 - loss: 0.1741 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1746 - accuracy: 0.93 - ETA: 1:04 - loss: 0.1746 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1744 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1748 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1746 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1743 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1736 - accuracy: 0.93 - ETA: 59s - loss: 0.1738 - accuracy: 0.9358 - ETA: 58s - loss: 0.1729 - accuracy: 0.936 - ETA: 57s - loss: 0.1725 - accuracy: 0.936 - ETA: 56s - loss: 0.1722 - accuracy: 0.936 - ETA: 55s - loss: 0.1718 - accuracy: 0.936 - ETA: 54s - loss: 0.1720 - accuracy: 0.936 - ETA: 53s - loss: 0.1717 - accuracy: 0.936 - ETA: 52s - loss: 0.1716 - accuracy: 0.937 - ETA: 52s - loss: 0.1710 - accuracy: 0.937 - ETA: 51s - loss: 0.1709 - accuracy: 0.937 - ETA: 50s - loss: 0.1713 - accuracy: 0.937 - ETA: 49s - loss: 0.1719 - accuracy: 0.936 - ETA: 48s - loss: 0.1719 - accuracy: 0.936 - ETA: 47s - loss: 0.1718 - accuracy: 0.936 - ETA: 46s - loss: 0.1728 - accuracy: 0.936 - ETA: 45s - loss: 0.1731 - accuracy: 0.936 - ETA: 44s - loss: 0.1734 - accuracy: 0.936 - ETA: 44s - loss: 0.1732 - accuracy: 0.936 - ETA: 43s - loss: 0.1736 - accuracy: 0.936 - ETA: 42s - loss: 0.1740 - accuracy: 0.936 - ETA: 41s - loss: 0.1736 - accuracy: 0.936 - ETA: 40s - loss: 0.1734 - accuracy: 0.936 - ETA: 39s - loss: 0.1732 - accuracy: 0.936 - ETA: 38s - loss: 0.1731 - accuracy: 0.936 - ETA: 37s - loss: 0.1729 - accuracy: 0.936 - ETA: 36s - loss: 0.1746 - accuracy: 0.935 - ETA: 35s - loss: 0.1742 - accuracy: 0.935 - ETA: 35s - loss: 0.1748 - accuracy: 0.935 - ETA: 34s - loss: 0.1750 - accuracy: 0.935 - ETA: 33s - loss: 0.1743 - accuracy: 0.935 - ETA: 32s - loss: 0.1747 - accuracy: 0.935 - ETA: 31s - loss: 0.1742 - accuracy: 0.936 - ETA: 30s - loss: 0.1735 - accuracy: 0.936 - ETA: 29s - loss: 0.1736 - accuracy: 0.936 - ETA: 28s - loss: 0.1735 - accuracy: 0.936 - ETA: 27s - loss: 0.1736 - accuracy: 0.935 - ETA: 26s - loss: 0.1736 - accuracy: 0.936 - ETA: 26s - loss: 0.1739 - accuracy: 0.936 - ETA: 25s - loss: 0.1741 - accuracy: 0.935 - ETA: 24s - loss: 0.1738 - accuracy: 0.935 - ETA: 23s - loss: 0.1742 - accuracy: 0.935 - ETA: 22s - loss: 0.1748 - accuracy: 0.935 - ETA: 21s - loss: 0.1747 - accuracy: 0.935 - ETA: 20s - loss: 0.1752 - accuracy: 0.935 - ETA: 19s - loss: 0.1748 - accuracy: 0.935 - ETA: 18s - loss: 0.1744 - accuracy: 0.935 - ETA: 17s - loss: 0.1746 - accuracy: 0.935 - ETA: 17s - loss: 0.1748 - accuracy: 0.935 - ETA: 16s - loss: 0.1748 - accuracy: 0.935 - ETA: 15s - loss: 0.1748 - accuracy: 0.935 - ETA: 14s - loss: 0.1747 - accuracy: 0.935 - ETA: 13s - loss: 0.1757 - accuracy: 0.935 - ETA: 12s - loss: 0.1762 - accuracy: 0.934 - ETA: 11s - loss: 0.1760 - accuracy: 0.935 - ETA: 10s - loss: 0.1766 - accuracy: 0.934 - ETA: 9s - loss: 0.1761 - accuracy: 0.934 - ETA: 8s - loss: 0.1764 - accuracy: 0.93 - ETA: 8s - loss: 0.1766 - accuracy: 0.93 - ETA: 7s - loss: 0.1768 - accuracy: 0.93 - ETA: 6s - loss: 0.1767 - accuracy: 0.93 - ETA: 5s - loss: 0.1769 - accuracy: 0.93 - ETA: 4s - loss: 0.1765 - accuracy: 0.93 - ETA: 3s - loss: 0.1761 - accuracy: 0.93 - ETA: 2s - loss: 0.1760 - accuracy: 0.93 - ETA: 1s - loss: 0.1760 - accuracy: 0.93 - ETA: 0s - loss: 0.1762 - accuracy: 0.93 - 147s 8ms/step - loss: 0.1761 - accuracy: 0.9350 - val_loss: 1.8385 - val_accuracy: 0.7666\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19312/19312 [==============================] - ETA: 2:20 - loss: 0.0835 - accuracy: 0.96 - ETA: 2:19 - loss: 0.0870 - accuracy: 0.95 - ETA: 2:25 - loss: 0.1333 - accuracy: 0.94 - ETA: 2:27 - loss: 0.1360 - accuracy: 0.94 - ETA: 2:24 - loss: 0.1501 - accuracy: 0.93 - ETA: 2:22 - loss: 0.1552 - accuracy: 0.93 - ETA: 2:20 - loss: 0.1576 - accuracy: 0.93 - ETA: 2:17 - loss: 0.1590 - accuracy: 0.93 - ETA: 2:15 - loss: 0.1553 - accuracy: 0.93 - ETA: 2:14 - loss: 0.1529 - accuracy: 0.93 - ETA: 2:13 - loss: 0.1496 - accuracy: 0.93 - ETA: 2:11 - loss: 0.1508 - accuracy: 0.93 - ETA: 2:09 - loss: 0.1585 - accuracy: 0.93 - ETA: 2:07 - loss: 0.1582 - accuracy: 0.93 - ETA: 2:06 - loss: 0.1556 - accuracy: 0.93 - ETA: 2:04 - loss: 0.1602 - accuracy: 0.93 - ETA: 2:04 - loss: 0.1607 - accuracy: 0.93 - ETA: 2:02 - loss: 0.1663 - accuracy: 0.93 - ETA: 2:01 - loss: 0.1658 - accuracy: 0.93 - ETA: 2:00 - loss: 0.1697 - accuracy: 0.93 - ETA: 1:59 - loss: 0.1701 - accuracy: 0.93 - ETA: 1:59 - loss: 0.1699 - accuracy: 0.93 - ETA: 1:58 - loss: 0.1721 - accuracy: 0.93 - ETA: 1:57 - loss: 0.1689 - accuracy: 0.93 - ETA: 1:56 - loss: 0.1672 - accuracy: 0.93 - ETA: 1:55 - loss: 0.1656 - accuracy: 0.93 - ETA: 1:54 - loss: 0.1632 - accuracy: 0.93 - ETA: 1:53 - loss: 0.1634 - accuracy: 0.93 - ETA: 1:52 - loss: 0.1623 - accuracy: 0.93 - ETA: 1:51 - loss: 0.1603 - accuracy: 0.93 - ETA: 1:50 - loss: 0.1624 - accuracy: 0.93 - ETA: 1:49 - loss: 0.1636 - accuracy: 0.93 - ETA: 1:47 - loss: 0.1634 - accuracy: 0.93 - ETA: 1:47 - loss: 0.1614 - accuracy: 0.94 - ETA: 1:46 - loss: 0.1610 - accuracy: 0.94 - ETA: 1:45 - loss: 0.1622 - accuracy: 0.94 - ETA: 1:44 - loss: 0.1630 - accuracy: 0.94 - ETA: 1:43 - loss: 0.1616 - accuracy: 0.94 - ETA: 1:43 - loss: 0.1601 - accuracy: 0.94 - ETA: 1:41 - loss: 0.1609 - accuracy: 0.94 - ETA: 1:40 - loss: 0.1595 - accuracy: 0.94 - ETA: 1:39 - loss: 0.1599 - accuracy: 0.94 - ETA: 1:38 - loss: 0.1595 - accuracy: 0.94 - ETA: 1:37 - loss: 0.1599 - accuracy: 0.94 - ETA: 1:36 - loss: 0.1604 - accuracy: 0.94 - ETA: 1:35 - loss: 0.1607 - accuracy: 0.94 - ETA: 1:34 - loss: 0.1599 - accuracy: 0.94 - ETA: 1:33 - loss: 0.1601 - accuracy: 0.94 - ETA: 1:32 - loss: 0.1602 - accuracy: 0.94 - ETA: 1:31 - loss: 0.1594 - accuracy: 0.94 - ETA: 1:30 - loss: 0.1598 - accuracy: 0.94 - ETA: 1:29 - loss: 0.1593 - accuracy: 0.94 - ETA: 1:29 - loss: 0.1600 - accuracy: 0.94 - ETA: 1:28 - loss: 0.1591 - accuracy: 0.94 - ETA: 1:27 - loss: 0.1597 - accuracy: 0.94 - ETA: 1:26 - loss: 0.1600 - accuracy: 0.94 - ETA: 1:25 - loss: 0.1613 - accuracy: 0.94 - ETA: 1:24 - loss: 0.1624 - accuracy: 0.94 - ETA: 1:23 - loss: 0.1617 - accuracy: 0.94 - ETA: 1:22 - loss: 0.1619 - accuracy: 0.94 - ETA: 1:21 - loss: 0.1618 - accuracy: 0.94 - ETA: 1:20 - loss: 0.1635 - accuracy: 0.94 - ETA: 1:19 - loss: 0.1631 - accuracy: 0.94 - ETA: 1:18 - loss: 0.1644 - accuracy: 0.94 - ETA: 1:17 - loss: 0.1646 - accuracy: 0.93 - ETA: 1:16 - loss: 0.1645 - accuracy: 0.93 - ETA: 1:15 - loss: 0.1661 - accuracy: 0.93 - ETA: 1:15 - loss: 0.1666 - accuracy: 0.93 - ETA: 1:14 - loss: 0.1662 - accuracy: 0.93 - ETA: 1:13 - loss: 0.1658 - accuracy: 0.93 - ETA: 1:12 - loss: 0.1655 - accuracy: 0.93 - ETA: 1:11 - loss: 0.1669 - accuracy: 0.93 - ETA: 1:10 - loss: 0.1683 - accuracy: 0.93 - ETA: 1:09 - loss: 0.1687 - accuracy: 0.93 - ETA: 1:08 - loss: 0.1685 - accuracy: 0.93 - ETA: 1:07 - loss: 0.1692 - accuracy: 0.93 - ETA: 1:06 - loss: 0.1693 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1705 - accuracy: 0.93 - ETA: 1:05 - loss: 0.1699 - accuracy: 0.93 - ETA: 1:04 - loss: 0.1701 - accuracy: 0.93 - ETA: 1:03 - loss: 0.1720 - accuracy: 0.93 - ETA: 1:02 - loss: 0.1722 - accuracy: 0.93 - ETA: 1:01 - loss: 0.1717 - accuracy: 0.93 - ETA: 1:00 - loss: 0.1720 - accuracy: 0.93 - ETA: 59s - loss: 0.1724 - accuracy: 0.9383 - ETA: 58s - loss: 0.1720 - accuracy: 0.938 - ETA: 57s - loss: 0.1716 - accuracy: 0.938 - ETA: 56s - loss: 0.1713 - accuracy: 0.938 - ETA: 55s - loss: 0.1709 - accuracy: 0.938 - ETA: 54s - loss: 0.1718 - accuracy: 0.938 - ETA: 53s - loss: 0.1725 - accuracy: 0.937 - ETA: 53s - loss: 0.1716 - accuracy: 0.937 - ETA: 52s - loss: 0.1711 - accuracy: 0.937 - ETA: 51s - loss: 0.1708 - accuracy: 0.937 - ETA: 50s - loss: 0.1713 - accuracy: 0.937 - ETA: 49s - loss: 0.1710 - accuracy: 0.937 - ETA: 48s - loss: 0.1710 - accuracy: 0.937 - ETA: 47s - loss: 0.1704 - accuracy: 0.937 - ETA: 46s - loss: 0.1709 - accuracy: 0.937 - ETA: 45s - loss: 0.1703 - accuracy: 0.937 - ETA: 45s - loss: 0.1705 - accuracy: 0.937 - ETA: 44s - loss: 0.1718 - accuracy: 0.937 - ETA: 43s - loss: 0.1718 - accuracy: 0.937 - ETA: 42s - loss: 0.1723 - accuracy: 0.936 - ETA: 41s - loss: 0.1718 - accuracy: 0.936 - ETA: 40s - loss: 0.1733 - accuracy: 0.936 - ETA: 39s - loss: 0.1739 - accuracy: 0.936 - ETA: 38s - loss: 0.1742 - accuracy: 0.935 - ETA: 37s - loss: 0.1737 - accuracy: 0.935 - ETA: 37s - loss: 0.1727 - accuracy: 0.936 - ETA: 36s - loss: 0.1731 - accuracy: 0.936 - ETA: 35s - loss: 0.1732 - accuracy: 0.936 - ETA: 34s - loss: 0.1728 - accuracy: 0.936 - ETA: 33s - loss: 0.1726 - accuracy: 0.936 - ETA: 32s - loss: 0.1726 - accuracy: 0.936 - ETA: 31s - loss: 0.1723 - accuracy: 0.936 - ETA: 30s - loss: 0.1728 - accuracy: 0.936 - ETA: 29s - loss: 0.1727 - accuracy: 0.936 - ETA: 28s - loss: 0.1734 - accuracy: 0.936 - ETA: 27s - loss: 0.1734 - accuracy: 0.936 - ETA: 27s - loss: 0.1729 - accuracy: 0.936 - ETA: 26s - loss: 0.1736 - accuracy: 0.936 - ETA: 25s - loss: 0.1737 - accuracy: 0.936 - ETA: 24s - loss: 0.1742 - accuracy: 0.936 - ETA: 23s - loss: 0.1737 - accuracy: 0.936 - ETA: 22s - loss: 0.1739 - accuracy: 0.936 - ETA: 21s - loss: 0.1737 - accuracy: 0.936 - ETA: 20s - loss: 0.1735 - accuracy: 0.936 - ETA: 19s - loss: 0.1730 - accuracy: 0.936 - ETA: 18s - loss: 0.1735 - accuracy: 0.936 - ETA: 17s - loss: 0.1729 - accuracy: 0.936 - ETA: 17s - loss: 0.1724 - accuracy: 0.936 - ETA: 16s - loss: 0.1723 - accuracy: 0.936 - ETA: 15s - loss: 0.1726 - accuracy: 0.936 - ETA: 14s - loss: 0.1729 - accuracy: 0.936 - ETA: 13s - loss: 0.1724 - accuracy: 0.937 - ETA: 12s - loss: 0.1726 - accuracy: 0.936 - ETA: 11s - loss: 0.1724 - accuracy: 0.936 - ETA: 10s - loss: 0.1718 - accuracy: 0.937 - ETA: 9s - loss: 0.1723 - accuracy: 0.937 - ETA: 8s - loss: 0.1720 - accuracy: 0.93 - ETA: 8s - loss: 0.1718 - accuracy: 0.93 - ETA: 7s - loss: 0.1716 - accuracy: 0.93 - ETA: 6s - loss: 0.1713 - accuracy: 0.93 - ETA: 5s - loss: 0.1717 - accuracy: 0.93 - ETA: 4s - loss: 0.1712 - accuracy: 0.93 - ETA: 3s - loss: 0.1704 - accuracy: 0.93 - ETA: 2s - loss: 0.1709 - accuracy: 0.93 - ETA: 1s - loss: 0.1707 - accuracy: 0.93 - ETA: 0s - loss: 0.1707 - accuracy: 0.93 - 147s 8ms/step - loss: 0.1711 - accuracy: 0.9373 - val_loss: 1.8853 - val_accuracy: 0.7670\n",
      "2020-12-07 23:32:02.889407\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "t5=datetime.datetime.now()\n",
    "print(t5)\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n",
    "t6=datetime.datetime.now()\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [2.543064232617092, 2.128092293463822, 1.9209597594843169, 1.7586684368934955, 1.6682839810317485, 1.6040539585252953, 1.5539723037315665, 1.5060167545659076, 1.4464838115491094, 1.4384222333785244, 1.4034507383493489, 1.3961543877146017, 1.386048931985643, 1.3759585773754772, 1.3647748665376143, 1.3727522363423759, 1.3746287541054723, 1.3670828868252172, 1.3944316498856535, 1.3931749530844768, 1.36380215598624, 1.3606852098734736, 1.370707597846594, 1.386237204753728, 1.4110885568226956, 1.379910412647384, 1.4001946901529565, 1.4178872443943888, 1.4000828987595753, 1.423151642053264, 1.4352707804594753, 1.4349861796733188, 1.4300956708793933, 1.4297822687437778, 1.4480632939035538, 1.4473555734819643, 1.4496670387427637, 1.4830834057593252, 1.4670313458483173, 1.499301611821729, 1.4797102429156324, 1.5040458300316597, 1.5113910691144181, 1.5276995547984447, 1.522271712760941, 1.5246256832060396, 1.5336875947619304, 1.5826321942980528, 1.554944272514307, 1.5662393035244857, 1.5352992609584521, 1.5419658995188155, 1.5983072975008206, 1.6070873707711857, 1.592877525057845, 1.6136364481369638, 1.6152450485144572, 1.6124505269944631, 1.608882746407151, 1.627624932296233, 1.6470384266984268, 1.6485813154792115, 1.653089457526911, 1.6485211660610664, 1.660039378609759, 1.6651464328185253, 1.6919453808377065, 1.6614124703836826, 1.6993216120399386, 1.694010504705611, 1.7107624440589142, 1.7067140516323391, 1.7066987159460023, 1.6887997804307178, 1.7299355611121785, 1.7107195219753641, 1.74194749842324, 1.7546746533562319, 1.7411902743754464, 1.793586186874873, 1.7447261757968153, 1.7476449576093682, 1.7708670612101378, 1.7476623381954168, 1.770167344153162, 1.7544529126973645, 1.81996152812735, 1.78214115147562, 1.844773296565342, 1.7865174016638508, 1.8232930440738795, 1.8502815822608032, 1.8551915766265137, 1.8570553506968506, 1.8606454492429938, 1.8564818780055374, 1.8756397684851303, 1.9034079243169608, 1.8385253505791708, 1.885322064537764], 'val_accuracy': [0.42451852560043335, 0.5114930868148804, 0.5491819977760315, 0.5837647318840027, 0.5984675884246826, 0.60882169008255, 0.6243528723716736, 0.6413335800170898, 0.6477531790733337, 0.6591426730155945, 0.6694967746734619, 0.6742596626281738, 0.6804721355438232, 0.6978670358657837, 0.6978670358657837, 0.6980741620063782, 0.7038724422454834, 0.7042865753173828, 0.7082211375236511, 0.7138124108314514, 0.7154690623283386, 0.7223027348518372, 0.718782365322113, 0.7225098609924316, 0.7266514897346497, 0.7281010746955872, 0.7301718592643738, 0.725823163986206, 0.7322427034378052, 0.7297577261924744, 0.7367985248565674, 0.7336922883987427, 0.7396976351737976, 0.7390764355659485, 0.7423897385597229, 0.7428038716316223, 0.741768479347229, 0.7399047613143921, 0.7440463900566101, 0.7452889084815979, 0.7473596930503845, 0.7475667595863342, 0.7444605231285095, 0.7494305372238159, 0.7498446702957153, 0.7481880187988281, 0.7498446702957153, 0.7465313673019409, 0.7496376037597656, 0.7525367736816406, 0.7525367736816406, 0.75295090675354, 0.7541934251785278, 0.7531580328941345, 0.7531580328941345, 0.7535721659660339, 0.7562642097473145, 0.7550217509269714, 0.7560571432113647, 0.7552288174629211, 0.7556430101394653, 0.7544004917144775, 0.755850076675415, 0.7572996616363525, 0.7550217509269714, 0.7570925951004028, 0.757713794708252, 0.7556430101394653, 0.7593704462051392, 0.7589563131332397, 0.7591633796691895, 0.7612342238426208, 0.7620625495910645, 0.7620625495910645, 0.7618554830551147, 0.7595775723457336, 0.7622696161270142, 0.7612342238426208, 0.7612342238426208, 0.7614412903785706, 0.7630979418754578, 0.7672395706176758, 0.7659971117973328, 0.7651687860488892, 0.7639262676239014, 0.7680678963661194, 0.7657900452613831, 0.768896222114563, 0.7657900452613831, 0.7668254375457764, 0.7666183710098267, 0.76765376329422, 0.7651687860488892, 0.7674466967582703, 0.7668254375457764, 0.7664112448692322, 0.7680678963661194, 0.7670325040817261, 0.7666183710098267, 0.7670325040817261], 'loss': [19.71399732473574, 2.5898169785762684, 2.214834160516355, 1.980281593686999, 1.7914266377909676, 1.635950635757541, 1.4861396843476442, 1.407102721727082, 1.3119443353780953, 1.2190336455168957, 1.1508670041851496, 1.100201891489827, 1.0409129820980114, 0.9840128699806769, 0.9461582474404361, 0.9001559527234391, 0.8474132826037909, 0.8226800121447224, 0.7898188783496297, 0.7666743673760731, 0.7404119814834816, 0.7015008843922872, 0.6891106927602273, 0.6525820831474235, 0.6256930046369936, 0.6202498269950247, 0.6039793956052595, 0.5796619877404384, 0.5557676210024185, 0.5531686002692607, 0.5416051137022668, 0.5253348488548915, 0.5060198073458256, 0.4974544699911056, 0.4850407609192912, 0.46986535914989175, 0.45686572202494447, 0.4438297083136852, 0.448218044384314, 0.42496924966499644, 0.4141645623616374, 0.41180618491267607, 0.39762576478714773, 0.3833044139481618, 0.3822250583987643, 0.37551706071322677, 0.3624695520585691, 0.36294162078346215, 0.3477695776641912, 0.3511030835214487, 0.34112413172002853, 0.33288951868742284, 0.3188866232062729, 0.32451669018724877, 0.3187169342023238, 0.31167400372156745, 0.30077169439273127, 0.3049582907900696, 0.2990467417259896, 0.2908954272708719, 0.27564459400870334, 0.2863669183595969, 0.27309181757870055, 0.2737110780849868, 0.26534951283799385, 0.25750054712866394, 0.25604153116478245, 0.2545339336129586, 0.24764937619187166, 0.24866936823110888, 0.24888372166944914, 0.23980028203872975, 0.23331084175848624, 0.23586628521239353, 0.23295888038045034, 0.23564216945175306, 0.22599635982473923, 0.22025546894502127, 0.23110622529313893, 0.21154945488793847, 0.2162171767927342, 0.21429987233240147, 0.20418778559395176, 0.21394591176667882, 0.20378853278211453, 0.20615884527107262, 0.19938282194518805, 0.19398981179693264, 0.1881503172299046, 0.1923770165779221, 0.1917845719272476, 0.1922143143790758, 0.1816876653486179, 0.1897211987046832, 0.17851050846223113, 0.17878124888217833, 0.17301686845145742, 0.17336192675237333, 0.1760613895588506, 0.1710951266672953], 'accuracy': [0.25787076, 0.3935377, 0.4563484, 0.49684134, 0.53034383, 0.5556649, 0.58694077, 0.60609984, 0.61904514, 0.6397059, 0.65814, 0.6660108, 0.6783347, 0.69174606, 0.7015327, 0.7131835, 0.7281483, 0.7356048, 0.7429578, 0.7492233, 0.75963134, 0.76558614, 0.77340513, 0.7786868, 0.79111433, 0.79049295, 0.7940141, 0.8016777, 0.80960023, 0.8080986, 0.81451946, 0.81907624, 0.82368475, 0.82901824, 0.8302092, 0.83606046, 0.83890843, 0.8434652, 0.8412904, 0.8509735, 0.85361433, 0.8532519, 0.85910314, 0.8628314, 0.86241716, 0.8653169, 0.8710646, 0.87096107, 0.87613916, 0.87401617, 0.87681234, 0.88173157, 0.8873239, 0.88463134, 0.88380283, 0.88690966, 0.8912593, 0.8904826, 0.89317524, 0.89545363, 0.8996997, 0.89623034, 0.8999068, 0.89788735, 0.9027548, 0.9051885, 0.904826, 0.907674, 0.90948635, 0.91083264, 0.9097452, 0.91254145, 0.9123343, 0.91414666, 0.9159072, 0.91326636, 0.91849625, 0.9203604, 0.9153894, 0.92186207, 0.92108536, 0.9220692, 0.92408866, 0.92186207, 0.9233637, 0.9245029, 0.9260563, 0.9283865, 0.9288525, 0.9284383, 0.9295257, 0.9290596, 0.93071663, 0.9306131, 0.93320215, 0.93372, 0.93646437, 0.9358948, 0.9349627, 0.9372929]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFlCAYAAADyLnFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdeXwU9eE//tcce+YOCSAgl4AX4kEFlKuCBbWmICICJViheBS0YlXUoqByyOFRoRTP9ieo6BfR4oH6ERWqoqIoYCQCCih3SCDJbpI9Zt6/P2Z3s5tkwwKzCRNez8cDkp2dnXnPO8m85v2e4y0JIQSIiIjI8uTGLgARERGZg6FORETURDDUiYiImgiGOhERURPBUCciImoiGOpERERNBEOdqIYZM2ZgyJAhGDJkCLp27YrBgwdHXldVVSW8nNWrV2PGjBn1znPgwAGMHDnyRIsckZ+fj/fee8+05TWEkpISnHnmmfXOc9ttt6Fnz56orKxsoFIRWZPa2AUgOtlMnTo18v2AAQMwf/58nHfeece8nIEDB2LgwIH1ztOiRQssW7bsmJd9Kjlw4ADWr1+PCy64AG+++SZGjRrV2EUiOmkx1ImOUdeuXTFw4EAUFhZi/vz5+PHHH/Hqq68iEAigtLQUEyZMwOjRo7FixQq8//77ePrpp5Gfn48LLrgAGzZswL59+3DJJZfgkUcewd69e5GXl4dvv/0WCxYswJ49e1BUVIQ9e/agRYsWmDdvHpo3b45NmzZh+vTpCAQCaNu2Lfbu3Yt7770XPXv2TLjcr776KpYsWQJZlpGTk4MHHngAHTp0wNdff41HH30Uuq4DAG6++WYMHjw47vRouq5j1qxZ2LhxI7xeL4QQmDFjBrp37457770Xqamp+PHHH7F//36ceeaZmDNnDlJSUvDBBx/giSeegMvlQteuXest92uvvYZLLrkEgwcPxj/+8Q+MHDkSkiQBADZu3IgZM2agsrISNpsN99xzDy655JK4088880ysW7cO2dnZABB5vW3bNsycORNutxterxevv/465s6dW+d2eb1ezJgxAxs2bICiKLj88stxyy23oH///njttdfQoUMHAMCf/vQnjBkzBpdffnnCPyOiEyaIKK7LLrtMbNq0KWZaly5dxBtvvCGEEMLj8YgRI0aIkpISIYQQ3377rbjggguEEEK8/vrr4qabbhJCCDFmzBhx++23C03TRHl5uejTp49Yt26d+PXXXyPzP/XUU2LgwIGivLxcCCHEzTffLP7xj3+IQCAg+vXrJz755BMhhBDr1q0TZ555pvjiiy9qlXfMmDFi1apVtaZ//vnn4vLLLxfFxcWRsl155ZVC13UxduxY8fbbbwshhNiyZYuYPn26EELEnR5tw4YN4rbbbhOapgkhhHj66afFzTffLIQQYsqUKeL6668XPp9P+P1+MXToULF8+XJRVFQkunfvLrZt2yaEEGLx4sWiS5cuddZ/IBAQffr0ER999JHw+Xzi4osvjtSD3+8XvXv3Fh9//LEQQojNmzeLq6++Wvh8vjqna5omunTpEqmD8M+yuLhYfPHFF+Kss84Su3fvPup2zZo1S0yePFkEg0Hh8/nEH//4R/HFF1+IGTNmiDlz5gghhNi1a5fo37+/CAaDdW4XUbKwpU50HH7zm98AAFJSUrB48WKsWbMGO3fuRGFhISoqKur8zGWXXQZZlpGamop27dqhtLQUbdq0iZmnR48eSE1NBQCcc845KC0txdatWwEA/fv3BwD06tULnTt3Pqby/u9//8NVV10VaaEOGzYMM2fOxO7du3HllVfi4YcfxkcffYRLL70Ud955JwDEnR7twgsvREZGBpYtW4Zff/0VX375JVJSUiLv9+3bF3a7HQDQpUsXlJaW4ptvvkGXLl3QqVMnAMD111+Pxx9/vM5yr169Grquo2/fvlBVFVdddRVefPFF9O/fH1u3boUsy/jtb38LwOhBeeutt1BQUFDn9KM57bTT0Lp166Nu1+eff4777rsPiqJAURQsXboUANC8eXOMGTMGkydPxquvvorhw4dDUZSjrpfITLxQjug4uN1uAMD+/fsxdOhQ7NmzB927d8cdd9wR9zNOpzPyvSRJEHUMu1DXPIqi1Jr3WMMi3IUeTQiBYDCIkSNHYuXKlejduzc+/fRT/OEPf4DP54s7Pdonn3yCm2++GYBxDUHN893xtjl6e1Q1ftvi5ZdfRlVVFQYNGoQBAwbgww8/xKeffopt27ZBUZRIN3zY1q1b404PBoMx0/x+f8zr8M/0aNulqmrM8vft24fDhw+jQ4cOOPPMM7F69Wq8/fbbuO666+JuF1GyMNSJTsD333+P7Oxs/OUvf0GfPn3w8ccfAwA0TTNtHWeccQbsdjvWrl0LANi0aRO2bt1aK7jq07dvX7z77rsoKSkBALz++uvIzMxEu3btMHLkSGzZsgXDhg3DI488grKyMhQVFcWdHu2zzz7DZZddhtGjR6Nr16748MMPj7rtF198MbZv347CwkIAwIoVK+qcb8eOHVi/fj1WrFiBjz76CB999BE+/fRTXHzxxXjxxRfRsWNHSJKEzz77DABQUFCAG264Ie50XdeRnZ2NzZs3AwDefvvtuGWsb7suueQSvPHGG9B1HX6/H7fffjvWr18PABg9ejTmzp2Lbt26oUWLFvXWA1EysPud6AT07t0by5cvxxVXXAFJktCjRw9kZ2dj165dpq1DVVUsWLAA06ZNw+OPP4727dsjJycnphUc7Z577sF9990XeT169Gjcfffd+NOf/hQTbk8//TRkWcZdd92FWbNm4cknn4QkSZg0aRLatGkTd3q0kSNH4m9/+xvy8vIQDAbRu3dvfPDBB3X2DIRlZ2dj/vz5uOuuu2Cz2XDxxRfXOd8rr7yCyy+/HO3atYuZPnHiRNx8882YPHkyFixYgFmzZmHu3Lmw2WxYsGAB7HZ73OlTp07Fww8/jPT0dFx66aXIzc2tc931bdekSZMwc+ZMDBkyBJqm4aqrrsKgQYMAGKdYpk6dauptikTHQhJ19QES0Ullzpw5GD9+PHJycrBv3z4MGTIEH374IdLT0xu7aBTl22+/xdSpU/H2228fU08KkVnYUieygNatW+NPf/oTVFWN3F7FQD+5TJkyBV999RWeeOIJBjo1GrbUiYiImgheKEdERNREMNSJiIiaCIY6ERFRE2H5C+WKispNXV5WlhuHD9f9RDBKHOvRHKxHc7AezcF6NMeJ1mNublrc99hSr0FV+VhHM7AezcF6NAfr0RysR3Mksx4Z6kRERE0EQ52IiKiJYKgTERE1EQx1IiKiJiJpV78HAgHcf//92LNnD/x+P2699VZ06tQJ9957LyRJQufOnTFt2jTIcvVxRVVVFe6++24UFxcjJSUFc+bMiYz/TERERPVLWkt95cqVyMzMxMsvv4xnn30WjzzyCGbPno077rgDL7/8MoQQWL16dcxnXnnlFXTp0gUvv/wyhg4dikWLFiWreERERE1O0kL9iiuuwF//+tfIa0VRUFBQgB49egAA+vXrh88//zzmM9988w369u0beX/dunXJKh4REVGTk7Tu95SUFACAx+PB7bffjjvuuANz5syJjF6UkpKC8vLYB8d4PB6kpaXFfb8uWVlu0+/5q+/Gfkoc69EcrEdzsB7NwXo0R7LqMalPlNu3bx8mTpyI0aNHIy8vD/PmzYu85/V6aw0dmZqaCq/XG/f9upj9dKPc3DTTn1J3KmI9moP1aA7WozmsWo8+nw8ffLAKeXlDjzrvu+++hfT0dPTp0/+Y1vGHPwzGypXvJzTvidZjfQcESQv1Q4cOYdy4cXjwwQdxySWXAADOOeccfPnll+jZsyfWrl2LXr16xXzmoosuwpo1a9CtWzesXbsW3bt3T1bxiIioEbz20XasLzxo6jIvPqs5RgzoFPf9kpJivPXWmwmF+lVX5ZlZtAaXtFBfvHgxysrKsGjRosgFb3//+98xY8YMPP744+jYsSMGDx4MABg3bhwWL16MUaNGYcqUKRg1ahRsNhsee+yxZBWvTtv3lKKkIoBst61B10tERMnz4osvYOfOHejb92L85jc9UFlZiXvvfQDvvfcOCgt/QEVFBdq374D775+G559/Gs2aNUPbtu3x0ksvwmZTsW/fXgwY8DvccMP4o65r69ZCPPHEPCiKArvdjnvumYqsrCw8+OC98Hq98PmqcN9996Jjx3Mwc+Z07NmzG36/H6NGjcHAgYNOeFuTFupTp07F1KlTa01funRprWkvvPBC5PunnnoqWUU6quff2QK7TcZDN/ZotDIQETVlIwZ0qrdVnQxjx47DTz9tR8+el6C8vBx33HEXvF7jGq4nn1wEXdeRnz8CRUWxPQgHDuzDf/7zCgKBAIYOvSKhUJ8zZybuvXcqOnc+E//73ydYuPBxjBt3M0pKivHkk4tw+PBhlJUVoaLCiw0bvsZzzy2BJEn46qsvTNlWy4/SZiZN01Gp6Y1dDCIiSpK2bdsBABwOJw4fPoxp0+6H2+1GZWUlgsFgzLwdO3aCqqpQVRUOhzOh5R86VITOnc8EAJx//kVYvHghOnY8A8OGjcD06X9HMBjE+PE3wu1OweTJ92Du3JmoqPBi0KArTdk+hnoURZbgDzLUiYiaEkmSIYSxb5dl4w6sL774DAcPHsDDD8/G4cOHsXbtxxBC1Pjcsa8rJycX27dvQ6dOnfHddxtw+ult8dNP21FR4cW8ef/AoUOHMHHiePzzn8/jxx+3YPbs+fD5fLj22t9j8OCroKonFssM9SiKIkPza41dDCIiMlFWVhYCgSB8Pl9k2tlnn4v//Od53HTTn2C329GqVWscOlR0wuuaMuXveOKJuRBCQFEU3HvvA8jJycW///0M3nvvHaiqDbfffjuaNWuGkpJi3HjjaLhcbowcOeaEAx0AJFHz0MRizLy94sHnv8Lh8iosuKOfacs8VVn11peTDevRHKxHc7AezWHJW9qsSFEkaLqlj3GIiChJPv10DZYte6nW9OuuG4X+/S9rhBLVxlCPosgSghpDnYiIauvTp/8xP5SmoXHo1SiyLEHXeaEcERFZE0M9iipL0AWgW/syAyIiOkUx1KOEb3XQeV6diIgsiKEeRZGN6uDFckREZEUM9ShKqKWu8WI5IqImw+fz4a233kxo3nfffQuffromySVKHl79HiXS/c5z6kRESbFi+9v49uBmU5d5YfPzMKzT1XHf5yhtp6hIS53d70RETUZDjNL2+uuvYs2ajxEMBpGamoqZM+dB1zXMmvUQ9u/fj2AwiMmT70bnzl0wefKD2LXr18i0rl27mbatDPUo1d3vvK2NiCgZhnW6ut5WdTIke5Q2XddRWlqKJ59cBFmWceedk7BlSwG2bClAy5at8NBDs/Hzz9vx9ddfoaBgM1q3bo377384Mo2hniQKr34nImrSkjFKmyzLsNlsmD7973C5XDh48CCCwSB++WUXevW6NLKsjh07Yd68WRg0aGDMNDPxQrkoMrvfiYianPpGaXvooVm46aaJ8PmqjnuUtu3bt2Ht2k/w8MOzMXnyPZF1tWvXAVu2/AAA2LNnN6ZP/zvateuAzZs3x0wzE1vqURSFt7QRETU1yR6lrU2b0+FyuTB+fD7sdhuaNcvBoUNFGDJkGGbPfhiTJt0ETdPw17/+DR06nIEnnpgdM81MHKUtyksfbMXqDbvx8LgeaNM81bTlnoo4mpM5WI/mYD2ag/VoDo7S1kDY/U5ERPFwlDaLURSGOhER1Y2jtFlM9X3qvKWNiIish6Eehbe0ERGRlTHUo4TPqQcZ6kREZEEM9ShsqRMRkZUx1KNw6FUiolPXpEk3YdeunXHfHz48L+Ze95MRr36PInPoVSKipCr6f8tQ/vV6U5eZ9puLkXvdSFOXaVUM9SgKh14lImpy7r//blx33UhceGF3bNlSgEWLnkJmZhY8nnKUlh5BXt41uOaa4Qkvb9++vXj00UcQDAYhSRL++te70LlzF8ycOR179uyG3+/HqFFjMHDgIDz99D+xYcPX0HUdv/vdYIwYMTqJW5rkUN+4cSPmz5+PJUuWYPLkyTh06BAAYM+ePTj//PPxxBNPROYVQqBfv35o3749AOCCCy7A3/5m7uPzjoajtBERJVfudSMbvFWdlzcUq1a9jQsv7I53330bF130G3TseAb69x+AQ4eKMGnSTccU6v/855MYPvx69O37W2zb9iMeffQRLFiwGBs2fI3nnlsCSZLw1VdfAADef/9dLFz4DHJycvHuu28laxMjkhbqzz77LFauXAmXywUAkQAvLS3F2LFjcd9998XM/8svv+Dcc8/F4sWLk1Wko+IT5YiImp6ePS/BokX/QFlZKTZt+hbz5z+FxYsXYs2aj+F2p9Qane1odu7cifPPvwgA0LnzmTh48ADc7hRMnnwP5s6diYoKLwYNuhIAMH36TDz99EIUFxdHRmxLpqRdKNe2bVssWLCg1vQFCxZgzJgxaN68ecz0goICHDhwAPn5+ZgwYQJ+/vnnZBUtLl79TkTU9MiyjMsuuxzz5z+Kvn1/i2XLlqJr12548MFHMGDA5bVGZzua9u3bY9OmbwEA27b9iOzsZjh06BB+/HELZs+ej7lzn8S//vUU/H4/Pv54NaZPn4WnnlqMVavexv79+5KxiRFJa6kPHjwYu3fvjplWXFyMdevW1WqlA0Bubi5uuukmXHnllfj6669x99134/XXXz/qerKy3FBVxZQyZ2aWAgBcKY56H5hPiWEdmoP1aA7WozmsWo9jx47G5Zdfjvfffx+7d+/G9OnT8fHHHyAzMxN2uw0ZGQ7Y7Sqystxxt1FRZOTmpuGBB/6OBx54AMuXv4JgMIg5c2bjrLPa45VXyjBhQj7cbjfGjx+P1q2boWXLHPz5z2OQkZGBfv36omvXzgCSV49JHaVt9+7duPPOO/Haa68BAF566SWUlZXh1ltvrTVvZWUlFEWB3W4HAPTp0wf/+9//IB1lQFszRwxaX3gQ/3rze/zxd10wsHsb05Z7KuJoTuZgPZqD9WgO1qM5mswobevWrasz0AFg4cKFyMzMxIQJE1BYWIhWrVodNdDNJks8p05EdCr74YfvsWjRU7WmDxw46JgupmssDRrqO3bswOmnnx4zbdy4cVi8eDFuuukm3H333VizZg0URcHs2bMbsmgAeE6diOhUd845XbFw4TONXYzjltRQb9OmTaTrHQDeeeedWvO88MILAAC73Y5nnmnciqweepW3tBERkfXwMbFReEsbERFZGUM9isrudyIisjCGehS21ImIyMoY6lEY6kREp66jjdJmBRzQJYoaGnqV3e9ERMnx+Uc/4efCg6Yus+NZzXHpgDNMXaZVMdSjcOhVIqKmx6xR2j7++EOsWPH/Io+VnTFjLtLT0/Hkk/OwZUsBAoEgxo+/Cb1796s1rW/f3yZ5Kw0M9SiRUdo49CoRUVJcOuCMBm9VmzVK26+//oJ58/4Bp9OJuXNn4quv1sHhcKK09AieffZFFBcfwuuvvwZdF7WmMdQbAYdeJSJqeswapS0rKxszZkyD2+3Grl070bVrNxw4sAvnntsNANCsWQ5uuukvWLLkP7WmNRReKBdF5i1tRERNjhmjtHk8Hjz//NN46KFZmDJlKhwOB4QQaN++PQoLf4jMc+edk+qc1lDYUo/C7ncioqbp97//A0aMGIJly97Avn17MX/+bHzwwSpkZGRAURT4/f56P5+SkoLzzjsf48aNgcvlQlpaGg4dKsJVV+Xh66+/wq23joemabjxxgno1evSWtMaSlJHaWsIZo4YVOrxYfLCz3DxWc1x69Cupi33VMTRnMzBejQH69EcrEdzNJlR2k52isJb2oiITmUcpa0J4dCrRESnNquP0sYL5aIofKIcERFZGEM9SnjoVZ1DrxIRkQUx1KPw2e9ERGRlDPUosiRBlhjqRERkTQz1GmRZZqgTEZElMdRrUBSJoU5ERJbEUK9BlSXep05ERJbEUK+B3e9ERGRVDPUaVHa/ExGRRTHUa1BkiUOvEhGRJTHUa5AVGbq1x7ghIqJTFEO9BlWWoGkMdSIish6Geg28pY2IiKyKoV6DIsu8pY2IiCwpqaG+ceNG5OfnAwAKCgrQt29f5OfnIz8/H++++27MvFVVVbjtttswevRoTJgwASUlJcksWlxsqRMRkVUlbTz1Z599FitXroTL5QIA/PDDD7jxxhsxbty4Oud/5ZVX0KVLF9x222145513sGjRIkydOjVZxYtL5X3qRERkUUlrqbdt2xYLFiyIvP7+++/xySef4I9//CPuv/9+eDyemPm/+eYb9O3bFwDQr18/rFu3LllFq5csS9A49CoREVlQ0lrqgwcPxu7duyOvu3Xrhuuuuw5du3bFv/71L/zzn//ElClTIu97PB6kpaUBAFJSUlBeXp7QerKy3FBVxbRyK4oEIYBmzVIjQ7HS8cnNTWvsIjQJrEdzsB7NwXo0R7LqMWmhXtPvfvc7pKenR75/5JFHYt5PTU2F1+sFAHi93si8R3P4cIWp5VRlo/PiwMEyqAqvIzxeublpKCpK7MCM4mM9moP1aA7WozlOtB7rOyBosNQaP348Nm3aBABYt24dzj333Jj3L7roIqxZswYAsHbtWnTv3r2hihZDVozWOc+rExGR1TRYqE+fPh2zZs1Cfn4+NmzYgL/85S8AgHHjxsHv92PUqFHYtm0bRo0ahVdffRWTJk1qqKLFCLfUeVsbERFZjSSEtZ+JanZX0LPvbMG6zfvw1F/7ItVlM3XZpxJ205mD9WgO1qM5WI/maBLd71YRvjiO3e9ERGQ1DPUa2P1ORERWxVCvQQlfKMfhV4mIyGIY6jUo4e53a19qQEREpyCGeg1K6N50Dr9KRERWw1CvIdxS5zl1IiKyGoZ6DQofPkNERBbFUK9BCV39zlAnIiKrYajXoCrsficiImtiqNdQ/fAZ3tJGRETWwlCvgd3vRERkVQz1Gtj9TkREVsVQryF8S1uQoU5ERBbDUK8h/PAZttSJiMhqGOo1KByljYiILIqhXoPCq9+JiMiiGOo1sPudiIisiqFeQ6SlzgFdiIjIYhjqNURGaePQq0REZDEM9RrYUiciIqtiqNfAoVeJiMiqGOo1qAofE0tERNbEUK+BA7oQEZFVMdRr4LPfiYjIqhjqNXCUNiIisiqGeg0yHxNLREQWxVCvIdz9zlAnIiKrUZO58I0bN2L+/PlYsmQJtmzZgkceeQSKosBut2POnDnIycmJmX/o0KFIS0sDALRp0wazZ89OZvHqFO5+5zl1IiKymqSF+rPPPouVK1fC5XIBAGbOnIkHHngAZ599NpYtW4Znn30W9913X2R+n88HAFiyZEmyipQQhS11IiKyqKR1v7dt2xYLFiyIvH788cdx9tlnAwA0TYPD4YiZv7CwEJWVlRg3bhzGjh2L7777LllFqxeHXiUiIqtKWkt98ODB2L17d+R18+bNAQAbNmzA0qVL8dJLL8XM73Q6MX78eFx33XXYuXMnJkyYgPfeew+qWn8Rs7LcUFXFtHLvKfIAAOx2Fbm5aaYt91TE+jMH69EcrEdzsB7Nkax6TCjU/X4/7Hb7Ca/s3Xffxb/+9S8888wzyM7OjnmvQ4cOaNeuHSRJQocOHZCZmYmioiKcdtpp9S7z8OGKEy5XtPA5da/Xh6KiclOXfSrJzU1j/ZmA9WgO1qM5WI/mONF6rO+AIKHu90GDBuGhhx7Cpk2bjrsQ//3vf7F06VIsWbIEp59+eq33ly9fjkcffRQAcODAAXg8HuTm5h73+o5X5D51jtJGREQWk1Cor1q1Cueffz4ef/xx5OXl4fnnn0dRUVHCK9E0DTNnzoTX68Vtt92G/Px8PPXUUwCAe+65B3v37sXw4cNRXl6OUaNGYfLkyZg1a9ZRu96TgU+UIyIiq5KEOLYm6f/93/9hxowZKCsrwyWXXIIpU6agXbt2ySrfUZndFWR32TFm2nvo3iUXE4edZ+qyTyXspjMH69EcrEdzsB7Nkczu94Sawrt27cJ///tfvPPOO2jVqhXuuusuDBo0CF988QUmTJiADz744LgLd7LhKG1ERGRVCYX6jTfeiGHDhuGFF15A69atI9P79++Pzz77LGmFawy8pY2IiKwqoXPq7733Hs4++2y0bt0aJSUlWL58OcK99vfff39SC9jQlMg5dQ69SkRE1pJQqE+bNi2mi/3LL7/EtGnTklaoxsRR2oiIyKoS6n7//vvv8dZbbwEAsrOzMW/ePOTl5SW1YI1FliVIYKgTEZH1JNRS13UdBw8ejLwuLi6GLDfdAd4UReItbUREZDkJtdRvueUWXHPNNejevTsAY/S1pnYuPZosSwgy1ImIyGISCvW8vDz06NED3333HVRVxdSpUyPPcm+KFJktdSIisp6EQr2kpASrVq2C1+uFEAIFBQXYvXs35s6dm+zyNQpFlhnqRERkOQmdGL/jjjuwZcsWrFy5EpWVlXj//feb9Dl1dr8TEZEVJZTMBw8exJw5czBgwAAMGjQIS5cuxQ8//JDssjUao/ud96kTEZG1JBTqGRkZAIzhUQsLC5GVlZXUQjU2RZZ4SxsREVlOQufUe/Xqhdtvvx1TpkzBuHHjUFBQAKfTmeyyNRpZlhAIsKVORETWklCo33DDDfB4PGjdujUef/xxrF+/HhMnTkx22RoNr34nIiIrSijU//jHP2LVqlUAgHPPPRfnnntuUgvV2BRZgqYx1ImIyFoSCvWzzjoLb775Jrp16xbT7d6qVaukFawxKbIM7diGmSciImp0CYX6xo0bsXHjxphpkiRh9erVSSlUY5PZUiciIgtKKNQ/+uijZJfjpMJz6kREZEUJhfp9991X5/TZs2ebWpiThSJL0IWAEAKSJDV2cYiIiBKSUKj36NEj8n0wGMTq1avRsWPHpBWqscmyEeSaLqAqDHUiIrKGhEL9mmuuiXk9fPhwjBo1KikFOhkooSDXdQEojVwYIiKiBB3XA9x/+umnmPHVmxpFqm6pExERWUXCt7SFzy0LIZCdnY0777wzqQVrTNHd70RERFaRUKgXFhZGvj8VLh5TFPgjTJsAACAASURBVKMDg6FORERWklD3+5dffomRI0cCAHbs2IGBAwdiw4YNSS1YY1LkqHPqREREFpFQqD/66KN4+OGHAQAdO3bEM888g5kzZya1YI1JiXS/c1AXIiKyjoRC3efzoUuXLpHXZ5xxBoLB4FE/t3HjRuTn5wMAdu3ahVGjRmH06NGYNm1arfHKq6qqcNttt2H06NGYMGECSkpKjmU7TMVz6kREZEUJhXrHjh0xb948bN26Fdu2bcMTTzyB9u3b1/uZZ599FlOnToXP5wNgPKjmjjvuwMsvvwwhRK1HzL7yyivo0qULXn75ZQwdOhSLFi06vi0yAbvfiYjIihIK9ZkzZ6KyshJ/+9vfMGXKFFRWVmLGjBn1fqZt27ZYsGBB5HVBQUHkITb9+vXD559/HjP/N998g759+0beX7du3TFtiJki3e98/jsREVlIQqGempqK3r1746233sJzzz2HLl26IDU1td7PDB48GKpafXF99FXzKSkpKC8vj5nf4/EgLS0t7vsNid3vRERkRQnd0jZ16lTouo6BAwcCMK6G37RpU+TiuUTIcvXxg9frRXp6esz7qamp8Hq9cd+PJyvLDVU197FvaanG8LLpGS7k5qaZuuxTCevOHKxHc7AezcF6NEey6jGhUP/+++/x1ltvAQCys7Mxb9485OXlHdOKzjnnHHz55Zfo2bMn1q5di169esW8f9FFF2HNmjXo1q0b1q5di+7duye03MOHK46pHEeTm5sGX1UAAFBc7EWRK6Eqohpyc9NQVNR4vS1NBevRHKxHc7AezXGi9VjfAUFC3e+6rsc8Fra4uDim5Z2IKVOmYMGCBbj++usRCAQwePBgAMC4cePg9/sxatQobNu2DaNGjcKrr76KSZMmHdPyzSTzljYiIrKghJqht9xyC6655ppI63njxo34+9//ftTPtWnTBq+99hoAoEOHDli6dGmteV544YXI90899VRChU42lefUiYjIghIK9by8PPTo0QPfffcdVFXF1KlT4XK5kl22RiPzljYiIrKghPvQW7RogcGDByM3NxdPPPEE+vXrl8xyNarw0KtsqRMRkZUkFOperxfLli3DkCFDIuOoL1u2LKkFa0wcepWIiKyo3u73H374AcuWLcOqVatw3nnnYcyYMVi0aBFmz57dUOVrFOx+JyIiK6q3pT5s2DCUl5fjv//9L1544QVcd911x3zVuxWFh14N8up3IiKykHoTetGiRQgGgxg6dCjuvPNOfPjhhxCi6bde+ex3IiKyonpDfcCAAViwYAHee+89nH/++Vi4cCH279+Phx56CNu2bWuoMjY4hbe0ERGRBSXUl56dnY0bbrgBb775JpYvXw5ZljF27Nhkl63R8NnvRERkRfVeKDd27Fj06NED/fr1Q7du3QAYj3s955xzcO+99zZIARsDu9+JiMiK6g315557DuvXr8c777yD2bNno3Xr1ujXrx/69OmD7Ozshipjg+PQq0REZEX1hrrdbkfv3r3Ru3dvAMCePXuwZs0aTJ06FR6PBy+++GKDFLKhsfudiIisKOEhyA4ePIjWrVujc+fOEEJgyJAhySxXo1JCt+3pp8CV/kRE1HQkdKHctGnT8OSTT2L79u246667UFBQgOnTpye5aI2nuvud96kTEZF1JBTqmzdvxsyZM7Fq1SoMHz4cs2bNwo4dO5JdtkbDW9qIiMiKEgp1TdOg6zpWr16Nfv36obKyEpWVlckuW6PhOXUiIrKihEJ96NCh6NOnD1q3bo3zzz8f1157La6//vpkl63R8JY2IiKyooQulLvxxhtxww03RJ77/tJLLyErKyupBWtMHHqViIisKKGW+scff4zHHnsMXq8XV155Ja644gqsWLEi2WVrNDKHXiUiIgtKKNQXLlyIvLw8vPvuu+jWrRs++ugjLF26NNllazThUdrY/U5ERFaS8DiqZ511Fj755BMMGDAAKSkpCAQCySxXo6q++p23tBERkXUkFOo5OTl45JFHsHnzZvTt2xePPvooWrVqleyyNRpe/U5ERFaUUKg/9thjOO+887B06VK43W6cfvrpeOyxx5JdtkajMtSJiMiCErr6PSUlBV6vF/Pnz0cwGETPnj3hdruTXbZGI/OWNiIisqCEQn3u3LnYtWsXrr32WgghsGLFCvz666+YOnVqssvXKPhEOSIisqKEQv2zzz7Dm2++GblP/be//S3y8vKSWrDGxKFXiYjIihJ+TGwwGIx5rShK0grV2CLd7xyljYiILCShlnpeXh7Gjh2L3//+9wCAd955B1dffXVSC9aYwkOvcpQ2IiKykoRC/ZZbbsE555yDdevWQQiBW265BZ988skxr2zFihV44403AAA+nw9btmzBZ599hvT0dADAjBkzsGHDBqSkpAAAFi1ahLS0tGNez4niOXUiIrKihEIdAPr164d+/fpFXt95553HPKb6sGHDMGzYMADAQw89hGuvvTYS6ABQUFCA5557DtnZ2ce0XLPJsgQJvPqdiIisJeEnytUkTuB88+bNm7F9+/aYkd50XceuXbvw4IMPYuTIkVi+fPlxL98MsiyxpU5ERJaScEu9Jik06MnxePrppzFx4sSYaRUVFRgzZgxuvPFGaJqGsWPHomvXrjjrrLPqXVZWlhuqau5Fe7m5aVAUGZIiIze34bv/mwrWnTlYj+ZgPZqD9WiOZNVjvaGen59fZ3gLIeDz+Y5rhWVlZfj555/Rq1evmOkulwtjx46Fy+UCAPTq1QuFhYVHDfXDhyuOqxzx5OamoaioHIoM+HxBFBWVm7r8U0W4HunEsB7NwXo0B+vRHCdaj/UdENQb6rfddttxrzSe9evX49JLL601fefOnZg8eTLeeOMN6LqODRs24JprrjF9/YmSJYnn1ImIyFLqDfUePXqYvsIdO3agTZs2kdf//ve/0bZtWwwcOBB5eXkYMWIEbDYbhgwZgs6dO5u+/kQpisxz6kREZCnHfU79eP35z3+OeX3jjTdGvp8wYQImTJjQ0EWqkyJLHHqViIgs5bivfm/q2P1ORERWw1CPQ1EkBBnqRERkIQz1OBSZLXUiIrIWhnocDHUiIrIahnocsszudyIishaGehxsqRMRkdUw1ONQZBmaxlAnIiLrYKjHIcsSdCFOaOAaIiKihsRQjyM8prrOUCciIotgqMcRDnV2wRMRkVUw1OOQw6HOi+WIiMgiGOpxKAx1IiKyGIZ6HJFz6gx1IiKyCIZ6HIpiVA1b6kREZBUM9ThkKdz9zuFXiYjIGhjqcbD7nYiIrIahHoei8EI5IiKyFoZ6HLyljYiIrIahHge734mIyGoY6nHwPnUiIrIahnocisxb2oiIyFoY6nFEzqlrvKWNiIisgaEeB8+pExGR1TDU4+A5dSIishqGehwMdSIishqGehzsficiIqthqMfBh88QEZHVqA29wqFDhyItLQ0A0KZNG8yePTvy3muvvYZly5ZBVVXceuutuOyyyxq6eBHsficiIqtp0FD3+XwAgCVLltR6r6ioCEuWLMHrr78On8+H0aNHo3fv3rDb7Q1ZxIjqoVd5SxsREVlDg3a/FxYWorKyEuPGjcPYsWPx3XffRd7btGkTLrzwQtjtdqSlpaFt27YoLCxsyOLFqB56lS11IiKyhgZtqTudTowfPx7XXXcddu7ciQkTJuC9996DqqrweDyRbnkASElJgcfjOeoys7LcUFXF1HLm5qYhK/NIqBwO5OamHeUTVBfWmzlYj+ZgPZqD9WiOZNVjg4Z6hw4d0K5dO0iShA4dOiAzMxNFRUU47bTTkJqaCq/XG5nX6/XGhHw8hw9XmFrG3Nw0FBWVw+s1ThUcKa1EUVG5qes4FYTrkU4M69EcrEdzsB7NcaL1WN8BQYN2vy9fvhyPPvooAODAgQPweDzIzc0FAHTr1g3ffPMNfD4fysvL8dNPP6FLly4NWbwY7H4nIiKradCW+vDhw3Hfffdh1KhRkCQJs2bNwpIlS9C2bVsMHDgQ+fn5GD16NIQQmDx5MhwOR0MWL4aihJ/9zlAnIiJraNBQt9vteOyxx2KmXXTRRZHvR4wYgREjRjRkkeKKPHxGMNSJiMga+PCZODj0KhERWQ1DPQ4OvUpERFbDUI+D3e9ERGQ1DPU4Io+J5YVyRERkEQz1ODigCxERWQ1DPQ4OvUpERFbDUI+Do7QREZHVMNTjYPc7ERFZDUM9Dg69SkREVsNQj0OReE6diIishaEeR+TZ7wx1IiKyCIZ6HDynTkREVsNQj4O3tBERkdUw1OPgLW1ERGQ1DPU4GOpERGQ1DPU4wkOvsvudiIisgqEeR+iONg69SkRElsFQj0OSJCiyBI1DrxIRkUUw1OuhyBKHXiUiIstgqNdDliWeUyciIstgqNdDkSVe/U5ERJbBUK8HQ52IiKyEoV4Pdr8TEZGVMNTrocgyh14lIiLLYKjXg93vRERkJQz1eigKQ52IiKyDoV4PnlMnIiIrURtyZYFAAPfffz/27NkDv9+PW2+9FQMHDoy8/+9//xvLly9HdnY2AOChhx5Cx44dG7KIMdj9TkREVtKgob5y5UpkZmZi3rx5OHz4MK655pqYUC8oKMCcOXPQtWvXhixWRNm6z6C77ZDPvxgA4LAp8AU0/HKgHG1bpDVKmYiIiBLVoN3vV1xxBf76179GXiuKEvN+QUEBnnnmGYwaNQpPP/10QxYNAFC6dg22L/gnvD8UAACu7NkOQgALV2yGpzLQ4OUhIiI6FpIQDT9iicfjwa233ooRI0YgLy8vMn3hwoUYPXo0UlNTMWnSJIwaNQqXXXZZvcsKBjWoqlLvPAmXa/tP2HTPfVDT03HhU0/Alp6Gpau24NUPt6L7Wc3x4PhekEPjrBMREZ1sGjzU9+3bh4kTJ2L06NEYPnx4ZLoQAh6PB2lpRjf3Sy+9hCNHjmDixIn1Lq+oqNzU8vnWfohdLy5F6oXdcdpfJkEI4Mn/txHf7yjBH3q3x9C+jXeO30pyc9NM/9mciliP5mA9moP1aI4Trcfc3Pingxu0+/3QoUMYN24c7r777phAB4zW+9VXXw2v1wshBL788stGObfeeugf4OpyJjzffoOy/62FLEu46Q/nIifDiZWf7cR32w81eJmIiIgS0aChvnjxYpSVlWHRokXIz89Hfn4+Vq5ciVdffRVpaWmYPHkyxo4di9GjR6NTp07o379/QxYPACApClr++SbIbjcOLnsJ/v37keqyYeI158GmynhmZQGDnYiITkqNck7dTGZ3BYW7RcrXf4V9Ty+CvXUbtJp4O+zNm+ObHw/imbd+QCCoY2ifDri6d3vIEs+x14XddOZgPZqD9WgO1qM5mkz3u5WkXdwDmQMuh3/Pbux66AGUfroWF3XJxf1juqNZuhNvfroDC1/fjIqqYGMXlYiICABDvV7NR49Bywk3Q5JlHPjPC9i7aAHapAAP/uk3OLtdFr7bfgiPvPg1tu8pbeyiEhERNezDZ6woveclcHXqgv3PPwPvtxuwc/t2NBsyFJOH98WKT3fhvS9/wewl32DARW0wrH9HuBysUiKik4EQAiIYADQdQtdCX3VACAghACEAEZoW+ieEgCQrgCxDUox2r15RCa3CC72iAprXC62sFMGyUgSPlEL3emBr0RKujmfAecYZsDVvAWgaAkUH4d+/D/6DB5Fy3vlwtGrVINvMc+o1xDvXIXQdh//vfRSvfBPC54OtZUvkXjsCe5t1wP/3/o/YV1yBrDQH8gefiQs65ZhaJiviuTdzsB7NwXo8NnrAj8D+A5CcDtia5UCSjXBLRj0KXYd/7x5U/vQT/Hv3QElLgy03F7ZmOVAzM+Hfvw9VO3agasfPqPplF9S0dDjatYezXTs42rYDhECg+BAChw4hWFyM4JHDCJaVQSs1gheaZmp5j0Z2uaD7/THrzbhsIFr8MT/yOpnn1BnqNRytsoOlR1C88k2Url0DCAHnGZ2QcnFPrAvm4L+bjkDTBc5pn4Vr+5+BDqelm1o2K+FO1BysR3OczPUodB16VZXRUpRlI0BlGZAkSNEX4obfi/6sENBKj8B/8CC0sjLILhdklxtKihuSzW60KA8fNoKutBR6VRWE3wfd54PwByDZVEgOB2SHE5LNhuChIvj27IZ//36jPAAkux32lqfB3qoVUnObodJbZbRydR263wet3APNUw7d44HQNCipqVBS06CkpUJSbdC8Hmge45/w+4z1OV2QnU5ACPh27TS2PwFqVpaxnED9T/iUbDYoGRlQ09MhO12QFAVQFOOrJIXqUQIkCZAlSJIc1TKXjNa7Fmq5Q0BxuSC7U6C43ZDdKVAzMkLLz4DsckUOSqp+/glVu3ZCSUkx6uy0VrCfdhrc55wL2W6PlI+hXo+GDvUw3969OPT6a/Bu/C4yTWrVBoXO1vi2Kg37HDnoenZrXNOvI1rlpJhaRis4mXeiVsJ6PD5CCAi/H3plBTRvBTJTbTh82AuhCwBGt6vQNGOnHWpRSbJs7PhlGRBGa1X4/dD9PohAwJhP0yA0DSIQgFZWZrQIy8qgeT1QUlOhZmZBzcyEkp4BrbwMgUNFRguypBhC04xQkWVIigoR8EOvrEw40ABAdjohu92QXW6jhXqoCMLvN7XuZKcT9janw9G6NfQqH/x798C/f1+9QSqpKpS0dECRoXs8tbdJlqGkpEJ2OKD7fNB9VZFy21q2hKtjJzjP6ATH6W2hez2heitC8PAR2JrnwtnhDDg7dISang6hafDv24uqXTvh+/UXSKoNtmbNoDbLgS0nB2pmFmSXK/aA6CTDUK9HY4V6WKC4GN6N38Kz8TtUFG6JdLkIAIfsGdjnzIG7bTucf0lXtDizI5SMjJP6l80sDCNzNFQ9CiEQLCmG/8AByA4H1PQMKOnpkB2O6nmCQeiBAGSbDZJa/7Ujus8H3+5f4fvlFwRKio1QDAQggkFA6JAcTsgOB2SnE5KihsLXA83rhV5ZGTm3ifA/WTb+biQppjVrtLAkIygqKiLnPfWKCmNdDUSy2+OHqyxDzc426ix8UKBpkG12yC4nZJc7Ug9C6MY8ofO+0UQwaNRTZSX0igpACNhycmFr3hy25i2gZmRAr6qC7vVCq6yA8PuhpKcbBxpZWVAzMo2WvMMBye6AbLdDBAOhkPVB+HxQs7OhZjertY8Suo5AUREy3DKOHKmM9CTINjuUtDRIDkfMZ/RAALrXA90fgJKaYrSWa/YyBINGPUT9jp0qGOr1aOxQj6ZVVKDyx0JU7fgZlT9tR8XPP0MKxP6hS+4UOFq1gqNVK9hbtoK9VSs4Tm8LNSPDjOKfNBjqx0boOoKlpUZmuVMiXXW5uWk4eKDUCLzycuiVlUYoBIMQwQCEPwC9qjLS4tP9fkiK0RI0wk8xuhLD4ajrkXAWAeOz/v374d+3D8JXu8UoO50AjJ105ByhJFWHRWamEQ7hMmkagsXF8B/YXyuUkk5RQt2jbijuFONrSgpklxspGSmorAwAsoRwt6ukKpELogDEtt6FgGy3Q7LbjRC02SApSnW9hlqmaka6cfBjs0P3+RA8cgTB0iPQykqhpKYZLcesbKOF3gTw79ocDPV6nEyhXpPQdVTt3Ysfv/4B2779Ec4jRcj1H0FWoBwSYqtdzcqGo317ONu1h5qRAUm1Gee7VJvRrZfdDGpmZq2j3ZNVQ//xCyHi9oAIIYzAq6ys7k71+Y2rYaNJkrHjDnfDSjIQtUihaUZ4VlZAq6io7mIMrVcKrcsITyMggqWHESwpQaCkBFrpEUBRIDtdUFwuSA4H9IoK45xn6ZHIOUzA6M6UU1IgCYFgeXlSA1JSVdhatISjVSvYWp5mdC2HLjIyDjQkI9zsdkg2G/Sqqsh52rq6ZGWnE47T28LRth0cbdvC3rwFpNBnJZsNEiTofp/xM6mqgggGjRBOSTFC2O0ywjbcMgeqD0hCX6uvWBYQuh5qfdrj/g4wjMzBejQHQ70eJ3OoR9N1ga8KD+D9r37F7n1HkOUvQ46/FK30MnSUy5HtOQjZe5T1KgrUrCwoKamQVLX6n80GSbVBttsg2UKti/AONPx9qLtNstshqWqopRdq7QW1qNYcAAgj3ELLh6xAr/AiWFpqnD8sKzU+IyGy45VdLqgZmVAzM6FmZCKrZTZKy32R7lHoxq0lut9vtBBD59UiLcyKCmiecuM8ZXkZhM9ntISysqBmZkFJT6/uWqzwhr5WREJWr6qCZLMZFwm53ZBdTug+f+gCnfIGvwK2JklVoWRmGhcXhc+jCmH8TDMzoWZlQ83MgiQZPT6a1+hGVm0K4A5feJRmnCsMHexJihraZhdkV+hAwWYzwi7czavrkGQJkKovvIqEq80G2WY3uoaPoyUphIDu9UIEg8bnVdVo/aq2k+4UE8PIHKxHczDU62GVUI9WVuFH4a7D+GFnCb7fUYKSMh8gBLKlKlycGUCnZjacnu2ETRLVF+SUFCNQbPzTKysiF+00OZIEJTUVksMBrbQ0/sU5oQOJ8NW+stNpHCyEzjdqlRWQHQ4oKalQ0lKNi3RcbkgOoztVtjuAmkEWvmhKD93TGtVyBgDIsnHQ4DK6eGWnA9VN+dABUeggR5IlQFagZmRAzW5mnHeMCrrwhVySzVZv7wt3ouZgPZqD9WiOZIY6n5TSCNLddvQ4uwV6nN0CQgjs3F+ODVuL8PWPRXi/pALvHwGUHRLOapeFi7rk4rye2WiZ4azz4hWhBY0LkPyhc6QBf+h7f6RVLPz+yHTd7zNaVpGWvi10bjF0K0dovHgR1CC0IBAMQgQ1yG531G0c6ZBUm3EOEkZXc7glH751xqUIeD2Vke5RSZarW4ihrlzZ6Yzc2iK73FDS04xeiFDIhVuCwSOHoXk8xnzhLto6LryxEkmSIJ2CFwgRUXIx1BuZJEnocFo6OpyWjmH9OmLvIS82bC3Chq2HULCjBAU7SgAAWWkOdGqdgU5tMtDxtHS0ykmBy6FCku2AzQ64G3lDMjJgP636iUlmHNFLoVa7kpp6oqUjIjolMNRPIpIkoXVuKlrnpiKvdwccKq3Et9sOYesvR7BtTynWFx7E+sKDkflzMpxonZOCNs1T0b5lGtq1TEOz9NoteiIiOjUw1E9iORku/O43p+N3vzkdQggcPFKJ7btL8csBD/Yc8mBPkRcbfyrGxp+KI59JddnQvmUa2rZIQ9sWqWjXMg25mS4OEUtEdApgqFuEJElokeVGiyw3ep9XPb28wo9fDnqwa385du4rw8795fh+h3EBXpjDpiAn04mcdCdyMl3IzXShZbYbpzVzo1mGk4FPZEEidE1L+CsASAjd4RD6qgsdmtChCx260IzrVEKfAUKnuCQFiiRDlmToQkATQWi6jqCo/fAepVLDEZ8H0ddX61HlCC9TghTZrxjvIVTGGt8bGxJ5VXOboret3roILTda9G5NhNcR57pwXRiPgw1/rbHwUJ2F56l+P7yK6N5RCVKtsnfK7IgUW8OcI2WoW1ya245z22fj3PbZkWmeygB+PVCOXQc8+OVAOXYXeXGotBJ7iry1Pm9TZbTMdqN1bgpOz01Fm+apaJ2TgsxUB2SZYW8WIYwdRvQOFzB2Jn4tgKAeREAPQAvdWiigQxcCfocXJd7qn5uAgKZr0ETon65H5tWEDtSxA9QjyxSh+bTQMowdfUw5Q/MbYaBBDz//W6oOi8gOSwjo0KPmr/6cpuuRMoafISBDDi0Dxh0CkCI7RWMZIrJjjfmH2jvRcDnrCoHwDtioS+OrTVWgaQKyFF6rFFq2HtpZhwIx5mejRQWiHrPsuqIh/DOuM5wQDpTq1+HtCZcHqPn5OtZxDEFHJ49+rS/F9WcObZB1MdSboFSXDWe3z8bZUUEvhIC3KohDpZU4eLgS+0sqsL+4AvuKK7CvxItfD3rwBQ5E5pcApLhsSE+xI91tQ2aqA1npDmSnOZGd5kB6ih2pbhvSXDbjgr0EW/tCCASFBk0PxoRAUNfg1/zwaX74NT8CevWtbNEBqAtjp6pDIKgHEdQ1aML4arw2/gVEEBCo3WrRtdD6jcCpGSBajR15OKDCO3gAMTvpcECG3w8HXXgHr0eFVE3hgKTkkCBBkYxHyUoSoOt6pJUqICCHWqdyeGCPqACGEJDl6hasDNk4IJDkmOAPE8JYniIrkGu0lsOHLlL0gUzUQ3XCUR/5XLhMqPk3JULrj15W7DqqD2x04zEIofIrsgI56sAqfChh/H6Gfud1PTSvDEVSQ3UXexum02mDzxeM1C8AyKE6ib27U4QO0nRIobqLfEYComrFuAs0/JS/UAs/psehVj1E14iosczqeoiep3q7UWt5kd+FyDrlqFZ+eBtrlqn68DlmXTV6K8IHs+flnBN3G8zGUD9FSJKEVJcNLoeMljl2nKW74dcC8Gt+VAZ9OHCkDPuKS3HwiAclngpU+f2oCgZQHgygxK8BRwD5iA5IApIkQrscATn0t2wMgiQgyQKSrEORJUAAMgDooRam0KBBg5BCv/gitHMREiCMrxKqv4+UPfK9scyYP1xJGMuTROhzMiRdrv6MFPqTC70vx7wvxSxDCq9XyJCEYryWwjud0B89AEnIkXJVt0CNeapboQg9jdSooEhwhOsjNK5IeLnhHaOM8CNLjXkVRYauxQa/JEkwnukT2hHqofmFFNnTRH8istML7zxj/q8uY+QBbuG6Cy8v/Ah2CISPTSLBJKo/I0mRd6p3nKHpQgBS6OcuEG6X1vgdjd7ZiqiH6EXNGL2OukiQ6pzHZpMRDOrRM0atQ0R+HgIisr7qeglvQ6jrWNTu6o0uX2R+PdQ1rdfdZRtNRG1nZPlxWuv1ifz+hcpRV5nDv4YxBxfGimuXKTw5VJYgAGg6dF1A16O2KRyYUWEYOW5B+FdKimyfrocOrnRRRz2jus5Cvyzh98K9h/HqP6Z7Pfr3Rq7+vaj5s6yzHus4aIv8/7RD0gAAEn1JREFUakRVZK06rPNATEdWXw+aXZxVd6FNxlBvBFpQh98fhN8XhN+nQdN06JowvuoCwYAOfyCACl8VKquqUOkPwOf3wx8IwB8IQgvqRrdr6A9L1wV0TYemh3YgGiACEhCUIQUUSHrs/dz1HfkCTmTDmdwKoFpCmYKa7XnzhyQJrym5IsFRo6WX8OflqAMqqToMjK/hQIpdR2T5AnUmp4hKKYFwayp2OTU7nKIDMTqwo0Mrdv7qsJAkCXJ4O+QaPTN1lDFyQBJVjtqhcRTh0yJaqMxyuMw1yhs+YKjxM6kVT5IUejS+sQxVNc67y1E/n+iDr/BBUfRSY34uMH62cugBTdUdFtUHVpEQD5UdIvZAILL/ilMtNQ8sIuEd/lmi9s8yuoB1/ZrG/MyjjkjDB4XRwr8r1Z+VkJrWcM+kYKgfIyEEKisC8JRVwVPmQ4XHD78/iIBfi/wLBnUEg5oR3gENVVWheXwatEB1a+fExH/wigQduhqEUDQIlx+SKqq7jiLdQnKolWl8rygSFFmGrIS66uSorjBJgiyHuvEUGbJszKsoChTF6K5TFaN7T9MBf0ADFBlHyqvg9QXhqQrA59cQ1ASCmg5N0+EP6PAFq0e0i26Uhb+Xo3aKigzYVAV2mwK7TYZNVeB0KHDZFThtKpw2GS6nDW6nCrdTRYrLDlWtPqoXurEjkhVjW2VFDrWmYo/Y5fD2KdVdrNF/5NEt5PDODkDUzsnYChH9Rx/e0aN6Rx+9UwwvQAovJyrMcnJSUVzsiaw/OmSEbuygwssLL7PmPi+88xaieocjRVZmvGcMCiYiYVS905NqBYMVb5nkk9DMwXo8+THU49A0Hft+PYKi/R6UlVah/EglykqNINeCiaeygIAuB6ErQWiKBt0V/j4Q+hqEkHXIMkKBI0NVFdjtKhx2Gxw2O5x2G5wOB5x2B9wOBxw2G1RVhU1WYVMV2BQ7nDYbHHYHnKoDTtUOVWncH20if/yVviCKS6twqKwKJWVVKPP6Ueb1o9Trh6cyAE0X0DQBTTcOBrz+ICor/fCVHvvjcWVJgqpKsKsKHDYZdpsCh02By6Ea/+zG98ZBgQ0pThVOuwqbKsOmGC0Uu6rALstw2JTI59Wo8E8Gl9sOh9eWtOUTUdPCUI/iqwrgu69+weZv92D3zsMI+GPDQ7YL6G4//I4KeJUyVNm9CNh80BUjqI3w1iBkHW6HEykOF1KdKch0piPTkYEMRxYyHRlIUd1w21xwqy44VSccih2yZN1Hnh4vl0NFm+bGFffHQtcFKv1BeCoCKK8IoLzCj/LK0NfwtEo/NE1Euu10AQQ1Hf5Q74mnMoDi0ir4j+EArS6KLMFpV+C0q3A6FDhDge+0K5Hwd9rDBwHGz1gLnzIRAk67ilSXccFhqtsGl12FzRY6gLDJSPMF4Q9okVayIif3IIKIrI2hHuXd5d9j/+5SAEBqhh3K6RXY69iJYvkgAo4K6IoR8k7FgRxXM5zuaoYcVztkOTOR5chEljMDWY5MpNjcp2RINxRZlpDitCHFaUOL7KPPX5+gpqPKr6HKF0SFLwhvVRAVVQFUVAVR6dcQ1HQEgrpxQBDQ4Qto8Ac1+PwafAHj6//f3v3HVFX/fwB/nh8cVK4gNnEff8BHVNDGmGK5r0v5wre5sNZAv/0gNmpra9PRStOWkBIEGb8mqG2t2ayNILXRwrb0DzMlrC9tJDkcUWtaQRqU+Ml7vdx7fn3/OOdeLkopcuXK5fnYnLucyz3v+7rA63Ve5/0+x+3VMejVMPCXBx5Vh26McFIuSAQAkYqESMUqICJ9BYViFQ8R8tBMZKvDLkCWBMj2aQdZFK3vt09jREZINxQJiiwOK1QEQfBPXDIME5IkIkISERFh/y+LLDaI7hJM6gHSVsXj9yt/4Kx6Bm3XzsCEiSh5GhbGzMe/o+Px7+j5mD99LqZHOPgHLEzIkgjHVBGOqcFrcVsFgI5BO/F7VQODXg0e1YBoz+D1JcFBrzasu+Dx6v5ugqoZkGQJgx7Vfy5d1Qx4vDoG7de/4vTCo4b+bn0CrGseyJJoFQuK7C86JFHwdyes5YFWx0EWBXtOxlDREWH/7+tURMhWoQLTOg1jmFanRhQBWRyaC+L7XtkuMpQIEVN93RNFhgoBl/qc8KpWfP3Fkd1JkSXxhpnNEZJgFSySyAs00YTBpB7g/7Qv0fKfrwAA8xxzsDb+v7E8LhWSOPp7TdPkJdvJZdqUsRcKtzI3wTBNfxHh1YyAmc3WNt/cBF/Xwavp8KiGv9twPa+qw+3VMOixXtNax2tPxhOsBK1q1r5UbaiTEdjRcHs0XLnqGfb6Q69hnYK4kx2NYJNEa16FVThYRQjgmzQ51BUJnFUtCVbREvh84O9XAYiiXZjIor9A8hU+smTF3rAnPPqWewn2hM1hy8HsiY8AIMvWayoRkr9gksShQkjT7FNSmg5VNaBESNZEU3tuia8g0w1rZU50vwt//TVo3cxRACRRhCL7CikJggCoqgHVLmwN0yr2lID3ZGL4KgHf74tV3NkTdu3JqiymRm9ck7phGCgpKUF3dzcURUF5eTkSEhL82w8fPoyDBw9ClmVs2rQJmZmZ4zk8yKKE5f9KwQOz/wtLYhfzaJwmBFEQ7Bb83Vej+1r2voIgkHWBHhOabhcdhgFdN6HqBlQ1oGOhW1fikwIKC8O0loBqgQWLblgrT3QDHrs74vZYp0amTImAoRn2fAURpgm7i2J1PTTNGLYCwTABTRv+mqpuWCs4NAOaYV3cRcfQeurrk5U1wdMa58QpX+4ugl04WKeOrILECIhv4Fr5v1viJgqCXVRY3R9REOzP0vpsDRP+ybMRdvFxPUm0ig5Jsn4Or1+qaSLwmgRD3TjJLsr+Z/lcLEkIw3Xqx48fh9frxaFDh9DR0YGKigq8/fbbAID+/n7U19ejqakJHo8HeXl5eOCBB6AoyriN738XP8olG0RBJAoCRGnkv7a+RC2JAO7wBP9Q/17rxtCEzMA5D8OfY51e8RUSqm74CxZfAvMVNYFLKH2Fk29duigMFVCqPtRNUTV9qGtjH3nL9lG870jaqxpwDar+uSW+UyWSvWTSERUJp8tjF2TWKiHVPtpXNeuKj4q9UkSWRYiCPQbVeo5uF2iBSyN1Y+h9arrpL9h0w/QXbbph+MfumzDqW+suBqyVH+kSBbph2uPTcfWaanUHZBGyaC2DFQXAqxpwulV4NWP4RYoCXmMsZsdODc+k3t7ejjVr1gAAli1bhs7OTv+2s2fPYvny5VAUBYqiID4+Ht9//z1SU1PHc4hEREEniTefOOtr008dh/HcrlAXR6Hi6wzc0B2wCQL81/TwnQbxnbIwTAR1zs7NjGtSdzqdcDiGli9JkgRN0yDLMpxOJ6ZPn+7fFhUVBafTOdLLEBERjZuhVSS3/j0R/3CBsDtpXJO6w+GAK+COU4ZhQJblEbe5XK5hSf7vxMZOgzyaSN+CWbNuvl+6OcYxOBjH4GAcg4NxDI47FcdxTeppaWn44osv8PDDD6OjowNJSUn+bampqairq4PH44HX68VPP/00bPvfGRi4FtQxTtb2UrAxjsHBOAYH4xgcjGNwjDWO/1QQjGtSX7t2LU6fPo3c3FyYpoldu3bhvffeQ3x8PB588EHk5+cjLy8Ppmliy5YtiIwcv4vgExERTXSCOZpbJ92Fgl01shINDsYxOBjH4GAcg4NxDI47eaTOa5kSERGFCSZ1IiKiMMGkTkREFCaY1ImIiMIEkzoREVGYYFInIiIKE0zqREREYWLCr1MnIiIiC4/UiYiIwgSTOhERUZhgUiciIgoTTOpERERhgkmdiIgoTDCpExERhYlxvZ/63cwwDJSUlKC7uxuKoqC8vBwJCQmhHtaEoKoqioqK0NvbC6/Xi02bNmHRokXYvn07BEHA4sWL8dprr0EUWUPeij///BMbNmzAgQMHIMsy43gb3nnnHZw4cQKqquKpp57CypUrGcdRUlUV27dvR29vL0RRRFlZGX8eR+m7775DTU0N6uvr8fPPP48Yu7feegsnT56ELMsoKipCamrqmPbJT8N2/PhxeL1eHDp0CFu3bkVFRUWohzRhHDlyBDNmzEBjYyP279+PsrIyvPnmm9i8eTMaGxthmiY+//zzUA9zQlBVFcXFxZgyZQoAMI63oa2tDWfOnMGHH36I+vp6XLp0iXG8DadOnYKmaTh48CAKCgpQV1fHOI7C/v37sWPHDng8HgAj/y6fO3cO33zzDT766CPs3r0bpaWlY94vk7qtvb0da9asAQAsW7YMnZ2dIR7RxJGVlYUXX3zR/1iSJJw7dw4rV64EAKSnp+Orr74K1fAmlMrKSuTm5iIuLg4AGMfb0NraiqSkJBQUFGDjxo3IyMhgHG/DggULoOs6DMOA0+mELMuM4yjEx8dj3759/scjxa69vR2rV6+GIAiYM2cOdF3H5cuXx7RfJnWb0+mEw+HwP5YkCZqmhXBEE0dUVBQcDgecTideeOEFbN68GaZpQhAE//arV6+GeJR3v48//hgzZ870F5cAGMfbMDAwgM7OTuzZswelpaXYtm0b43gbpk2bht7eXqxbtw47d+5Efn4+4zgKDz30EGR56Az3SLG7Pu8EI6Y8p25zOBxwuVz+x4ZhDPtA6J9dvHgRBQUFyMvLw6OPPorq6mr/NpfLhejo6BCObmJoamqCIAj4+uuv0dXVhVdeeWVY1c443poZM2YgMTERiqIgMTERkZGRuHTpkn8743hr3n//faxevRpbt27FxYsX8cwzz0BVVf92xnF0Auce+GJ3fd5xuVyYPn362PYzpu8OI2lpaWhpaQEAdHR0ICkpKcQjmjj++OMPPPvss3j55Zfx2GOPAQDuvfdetLW1AQBaWlpw3333hXKIE0JDQwM++OAD1NfXY+nSpaisrER6ejrjOEorVqzAl19+CdM08fvvv8PtdmPVqlWM4yhFR0f7E0xMTAw0TePv9RiMFLu0tDS0trbCMAz89ttvMAwDM2fOHNN+eEMXm2/2+w8//ADTNLFr1y4sXLgw1MOaEMrLy3H06FEkJib6v/bqq6+ivLwcqqoiMTER5eXlkCQphKOcWPLz81FSUgJRFLFz507GcZSqqqrQ1tYG0zSxZcsWzJs3j3EcJZfLhaKiIvT390NVVTz99NNISUlhHEehp6cHL730Eg4fPozz58+PGLt9+/ahpaUFhmGgsLBwzIUSkzoREVGYYPudiIgoTDCpExERhQkmdSIiojDBpE5ERBQmmNSJiIjCBJM60STR09ODlJQUZGdnD/vX0NAQtH20tbUhPz//lp6bm5sLt9uNkydPora2NmhjIJrMeMk0okkkLi4Ozc3NoR4G3G43BEHA1KlT8e2332LFihWhHhJRWGBSJyIAwKpVq7B27VqcOXMGUVFRqKmpwbx589DR0YE33ngDHo8HsbGxeP3115GQkICuri4UFxdjcHAQMTExqKmpAQBcvnwZzz33HH755RcsWLAAe/fuhaIo/v0UFhaira0NXq8X2dnZuHDhAk6dOoWUlBTcc889oXr7RGGBF58hmiR6enqQlZV1w5USq6qqkJycjOTkZFRUVGD9+vWor6/H6dOnsXfvXmRlZaGurg6pqak4evQo3n33XTQ1NeGRRx7Btm3bkJmZicbGRvz666/IyMjAxo0bceTIEcydOxdPPPEEnn/+eWRkZAzbZ0NDAxRFweOPP46cnBx88skn4xgJovDFI3WiSeSf2u+RkZHIyckBAKxfvx67d+/GhQsXEB0djdTUVADAunXrUFxcjN7eXvT39yMzMxMAkJeXB8A6p75kyRLMnz8fALBw4UIMDAzcsK8ff/wRGzZsQF9fH2bNmhX090k0WTGpExEA6y5SvltDGoYBSZJgGMYNz/M193zPBQCPx4O+vj4AGHZ3Q0EQcH0zsLCwEMeOHUN7ezvcbjeuXbuG7OxsHDhwgO13ojHi7HciAmBNXjtx4gQA697u6enpSExMxJUrV3D27FkAwGeffYY5c+Zg7ty5mD17NlpbWwEAzc3N2LNnzy3tp7S0FIsWLcKnn36KnJwclJaWorm5mQmdKAh4pE40ifT19SE7O3vY1+6//37s2LEDAHDs2DHU1tYiLi4OlZWVUBQFtbW1KCsrg9vtRkxMjH/5WXV1NUpKSlBdXY3Y2FhUVVXh/PnzNx1DV1cXli5dCsC6zfGTTz4Z5HdJNHlxohwRAQCSk5PR3d0d6mEQ0Riw/U5ERBQmeKROREQUJnikTkREFCaY1ImIiMIEkzoREVGYYFInIiIKE0zqREREYYJJnYiIKEz8PywGzO8cMECGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = np.arange(0, len(history.history['loss']))\n",
    "\n",
    "# You can chose the style of your preference\n",
    "# print(plt.style.available) to see the available options\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "plt.figure()\n",
    "plt.plot(N, history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(N, history.history['accuracy'], label = \"train_acc\")\n",
    "plt.plot(N, history.history['val_loss'], label = \"val_loss\")\n",
    "plt.plot(N, history.history['val_accuracy'], label = \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# Make sure there exists a folder called output in the current directory\n",
    "# or replace 'output' with whatever direcory you want to put in the plots\n",
    "plt.show()\n",
    "plt.savefig('../Output/EpochResNet101V2.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
